{"prompt": "Rephrase the abstract of an article with title 'The Search for Million Degree Gas Through The NVII Hyperfine Line'.   Gas in the million degree range occurs in a variety of astronomical environments, and it may be the main component of the elusive missing baryons at low redshift. The NVII ion is found in this material and it has a hyperfine spin-flip transition with a rest frequency of 53.042 GHz, which can be observed for z > 0.1, when it is shifted into a suitably transparent radio band. We used the 42-48 GHz spectrometer on the Green Bank Telescope to search for both emission and absorption from this NVII transmission. For absorption studies, 3C273, 3C 279, 3C 345, and 4C+39.25 were observed but no feature were seen above the 5 sigma level. For emission line studies, we observed Abell 1835, Abell 2390 and the star-forming galaxy PKS 1345+12, but no features were seen exceeding 5 sigma. We examine whether the strongest emission feature, in Abell 2390 (3.7 sigma), and the strongest absorption feature, toward 4C+39.25 (3.8 sigma), might be expected from theoretical models. The emission feature would require ~1E10 Msolar of 1E6 K gas, which is inconsistent with X-ray limits for the O VII Kalpha line, so it is unlikely to be real. The NVII absorption feature requires a NVII column of 6E16 cm^-2, higher than model predictions by at least an order of magnitude, which makes it inconsistent with model expectations. The individual observations were less than 1 hr in length, so for lengthy observations, we show that NVII absorption line observations can begin to be useful in in the search for hot intergalactic gas.  ", "human_text": "  Gas in the million degree range occurs in a variety of astronomical environments, and it may be the main component of the elusive missing baryons at low redshift. The NVII ion is found in this material and it has a hyperfine spin-flip transition with a rest frequency of 53.042 GHz, which can be observed for z > 0.1, when it is shifted into a suitably transparent radio band. We used the 42-48 GHz spectrometer on the Green Bank Telescope to search for both emission and absorption from this NVII transmission. For absorption studies, 3C273, 3C 279, 3C 345, and 4C+39.25 were observed but no feature were seen above the 5 sigma level. For emission line studies, we observed Abell 1835, Abell 2390 and the star-forming galaxy PKS 1345+12, but no features were seen exceeding 5 sigma. We examine whether the strongest emission feature, in Abell 2390 (3.7 sigma), and the strongest absorption feature, toward 4C+39.25 (3.8 sigma), might be expected from theoretical models. The emission feature would require ~1E10 Msolar of 1E6 K gas, which is inconsistent with X-ray limits for the O VII Kalpha line, so it is unlikely to be real. The NVII absorption feature requires a NVII column of 6E16 cm^-2, higher than model predictions by at least an order of magnitude, which makes it inconsistent with model expectations. The individual observations were less than 1 hr in length, so for lengthy observations, we show that NVII absorption line observations can begin to be useful in in the search for hot intergalactic gas. ", "machine_text": " We present the results from using the a 42-48 GHz spectrometer on the Green Bank Telescope to observe the NVII hyperfine spin-flip transition with a rest frequency of 53.042 GHz in an effort to search for million degree gas in astrophysical environments. This transition can be observed for redshifts larger than 0.1, when shifted into a suitable transparent radio band. We observed 3C273, 3C 279, 3C 345, and 4C+39.25 for absorption studies, as well as Abell 1835, Abell 2390 and PKS 1345+12 in emission line studies, with no evidence seen above the 5 sigma confidence level. Analysis of the strongest emission and absorption features, seen in Abell 2390 (3.7 sigma) and 4C+39.25 (3.8 sigma) respectively, lead to the conclusion that these features are unlikely to be real. With longer observations, NVII absorption line studies may become a valuable tool in the search for hot intergalactic gas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2242}
{"prompt": "Rephrase the abstract of an article with title 'Cranked Hartree-Fock-Bogoliubov Calculation for Rotating Bose-Einstein   Condensates'.   A rotating bosonic many-body system in a harmonic trap is studied with the 3D-Cranked Hartree-Fock-Bogoliubov method at zero temperature, which has been applied to nuclear many-body systems at high spin. This method is a variational method extended from the Hartree-Fock theory, which can treat the pairing correlations in a self-consistent manner. An advantage of this method is that a finite-range interaction between constituent particles can be used in the calculation, unlike the original Gross-Pitaevskii approach. To demonstrate the validity of our method, we present a calculation for a toy model, that is, a rotating system of ten bosonic particles interacting through the repulsive quadrupole-quadrupole interaction in a harmonic trap. It is found that the yrast states, the lowest-energy states for the given total angular momentum, does not correspond to the Bose-Einstein condensate, except a few special cases. One of such cases is a vortex state, which appears when the total angular momentum $L$ is twice the particle number $N$ (i.e., $L=2N$).  ", "human_text": "  A rotating bosonic many-body system in a harmonic trap is studied with the 3D-Cranked Hartree-Fock-Bogoliubov method at zero temperature, which has been applied to nuclear many-body systems at high spin. This method is a variational method extended from the Hartree-Fock theory, which can treat the pairing correlations in a self-consistent manner. An advantage of this method is that a finite-range interaction between constituent particles can be used in the calculation, unlike the original Gross-Pitaevskii approach. To demonstrate the validity of our method, we present a calculation for a toy model, that is, a rotating system of ten bosonic particles interacting through the repulsive quadrupole-quadrupole interaction in a harmonic trap. It is found that the yrast states, the lowest-energy states for the given total angular momentum, does not correspond to the Bose-Einstein condensate, except a few special cases. One of such cases is a vortex state, which appears when the total angular momentum $L$ is twice the particle number $N$ (i.e., $L=2N$). ", "machine_text": " This paper presents a study of a rotationally driven system of many-body bosons in a harmonic trap. The calculation was accomplished using the 3D-Cranked Hartree-Fock-Bogoliubov (HF-B) method, which is an extended variational approach that incorporates pairing correlations. Unlike the original Gross-Pitaevskii theory, this method can incorporate finite-range interactions between particles. As an example, a system of ten bosons interacting with a repulsive quadrupole-quadrupole force was used to demonstrate the validity of our method. The results showed that the yrast states, or lowest-energy states for a given total angular momentum, do not generally form a Bose-Einstein condensate, but rather a vortex state when the total angular momentum ($L$) is twice the particle number ($N$), i.e. $L=2N$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0196}
{"prompt": "Rephrase the abstract of an article with title 'The VVDS type-1 AGN sample: The faint end of the luminosity function'.   In a previous paper (Gavignaud et al. 2006), we presented the type-1 Active Galactic Nuclei (AGN) sample obtained from the first epoch data of the VIMOS-VLT Deep Survey (VVDS). The sample consists of 130 faint, broad-line AGN with redshift up to z=5 and 17.5< I <24.0, selected on the basis of their spectra. In this paper we present the measurement of the Optical Luminosity Function up to z=3.6 derived from this sample, we compare our results with previous results from brighter samples both at low and at high redshift. Our data, more than one magnitude fainter than previous optical surveys, allow us to constrain the faint part of the luminosity function up to high redshift. By combining our faint VVDS sample with the large sample of bright AGN extracted from the SDSS DR3 (Richards et al., 2006b) and testing a number of different evolutionary models, we find that the model which better represents the combined luminosity functions, over a wide range of redshift and luminosity, is a luminosity dependent density evolution (LDDE) model, similar to those derived from the major X-surveys. Such a parameterization allows the redshift of the AGN space density peak to change as a function of luminosity and explains the excess of faint AGN that we find at 1.0< z <1.5. On the basis of this model we find, for the first time from the analysis of optically selected samples, that the peak of the AGN space density shifts significantly towards lower redshift going to lower luminosity objects. This result, already found in a number of X-ray selected samples of AGN, is consistent with a scenario of \"AGN cosmic downsizing\", in which the density of more luminous AGN, possibly associated to more massive black holes, peaks earlier in the history of the Universe, than that of low luminosity ones.  ", "human_text": "  In a previous paper (Gavignaud et al. 2006), we presented the type-1 Active Galactic Nuclei (AGN) sample obtained from the first epoch data of the VIMOS-VLT Deep Survey (VVDS). The sample consists of 130 faint, broad-line AGN with redshift up to z=5 and 17.5< I <24.0, selected on the basis of their spectra. In this paper we present the measurement of the Optical Luminosity Function up to z=3.6 derived from this sample, we compare our results with previous results from brighter samples both at low and at high redshift. Our data, more than one magnitude fainter than previous optical surveys, allow us to constrain the faint part of the luminosity function up to high redshift. By combining our faint VVDS sample with the large sample of bright AGN extracted from the SDSS DR3 (Richards et al., 2006b) and testing a number of different evolutionary models, we find that the model which better represents the combined luminosity functions, over a wide range of redshift and luminosity, is a luminosity dependent density evolution (LDDE) model, similar to those derived from the major X-surveys. Such a parameterization allows the redshift of the AGN space density peak to change as a function of luminosity and explains the excess of faint AGN that we find at 1.0< z <1.5. On the basis of this model we find, for the first time from the analysis of optically selected samples, that the peak of the AGN space density shifts significantly towards lower redshift going to lower luminosity objects. This result, already found in a number of X-ray selected samples of AGN, is consistent with a scenario of \"AGN cosmic downsizing\", in which the density of more luminous AGN, possibly associated to more massive black holes, peaks earlier in the history of the Universe, than that of low luminosity ones. ", "machine_text": " In this paper, we analyze an AGN sample obtained from the first epoch VVDS survey. This sample is comprised of 130 faint, broad-line AGN with redshift up to z=5 and 17.5 < I< 24, and has allowed us to measure the Optical Luminosity Function up to z=3.6. We compare our results to previous literature and find that the model which best fits the combined luminosity functions is a Luminosity Dependent Density Evolution (LDDE) model, similar to the one derived from X-ray surveys. For the first time in an optical sample, we observe a \"cosmic downsizing\" phenomena, in which the AGN density peaks at lower redshift for lower luminosity objects. This supports the idea that more luminous AGN are linked to more massive black holes and peaked earlier in the Universe's evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.166}
{"prompt": "Rephrase the abstract of an article with title 'Experimental studies on vacancy induced ferromagnetism in undoped TiO2'.   Room temperature ferromagnetism is observed in undoped TiO2 films deposited on Si substrates using pulsed laser deposition (PLD). The ferromagnetic properties of the samples depend on the oxygen partial pressure during the PLD synthesis. The appearance of higher binding energy component (HBEC) in the oxygen 1s core peak from x-ray photoelectron spectroscopy (XPS) suggests the presence of oxygen vacancies in these samples. The amount of oxygen during the synthesis determines the vacancy concentration in the samples which is directly related to the magnetic behavior of the samples. The magnetic moment decreases with oxygen vacancy concentration in the samples. Valence band measurements were performed to study the electronic structure of both stoichometric and reduced TiO2. The analyses show the presence of Ti 3d band near the Fermi level in reduced TiO2 samples. These bands are otherwise empty in stoichiometric TiO2 and reside in the conduction band which makes them unobservable by XPS. The existence of this Ti 3d band near the Fermi level can possibly lead to Stoner splitting of the band.  ", "human_text": "  Room temperature ferromagnetism is observed in undoped TiO2 films deposited on Si substrates using pulsed laser deposition (PLD). The ferromagnetic properties of the samples depend on the oxygen partial pressure during the PLD synthesis. The appearance of higher binding energy component (HBEC) in the oxygen 1s core peak from x-ray photoelectron spectroscopy (XPS) suggests the presence of oxygen vacancies in these samples. The amount of oxygen during the synthesis determines the vacancy concentration in the samples which is directly related to the magnetic behavior of the samples. The magnetic moment decreases with oxygen vacancy concentration in the samples. Valence band measurements were performed to study the electronic structure of both stoichometric and reduced TiO2. The analyses show the presence of Ti 3d band near the Fermi level in reduced TiO2 samples. These bands are otherwise empty in stoichiometric TiO2 and reside in the conduction band which makes them unobservable by XPS. The existence of this Ti 3d band near the Fermi level can possibly lead to Stoner splitting of the band. ", "machine_text": "This work highlights the experimental studies on the impact of oxygen vacancies on the induced ferromagnetism in undoped TiO2 thin films. Pulsed laser deposition is used to deposit the thin films on Si substrates with different oxygen partial pressures, controlling the oxygen vacancy concentrations. As the vacancy concentration increases, the magnetic moment of the samples decreases. Through X-ray photoelectron spectroscopy, the presence of higher binding energy component is observed, suggesting the presence of oxygen vacancies in the samples. Valence band measurements were used to examine the electronic structure of both stoichiometric and reduced TiO2 thin films. These measurements indicate the presence of Ti 3d bands in the vicinity of the Fermi level which provides the basis for Stoner splitting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2621}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of Ultra-Low Potassium Contaminations with Accelerator Mass   Spectrometry'.   Levels of trace radiopurity in active detector materials is a subject of major concern in low-background experiments. Among the radio-isotopes, $\\k40$ is one of the most abundant and yet whose signatures are difficult to reject. Procedures were devised to measure trace potassium concentrations in the inorganic salt CsI as well as in organic liquid scintillator (LS) with Accelerator Mass Spectrometry (AMS), giving, respectively, the $\\k40$-contamination levels of $\\sim 10^{-10}$ and $\\sim 10^{-13}$ g/g. Measurement flexibilities and sensitivities are improved over conventional methods. The projected limiting sensitivities if no excess of potassium signals had been observed over background are $8 \\times 10^{-13}$ g/g and $3 \\times 10^{-17}$ g/g for the CsI and LS, respectively. Studies of the LS samples indicate that the radioactive contaminations come mainly in the dye solutes, while the base solvents are orders of magnitude cleaner. The work demonstrate the possibilities of measuring naturally-occurring isotopes with the AMS techniques.  ", "human_text": "  Levels of trace radiopurity in active detector materials is a subject of major concern in low-background experiments. Among the radio-isotopes, $\\k40$ is one of the most abundant and yet whose signatures are difficult to reject. Procedures were devised to measure trace potassium concentrations in the inorganic salt CsI as well as in organic liquid scintillator (LS) with Accelerator Mass Spectrometry (AMS), giving, respectively, the $\\k40$-contamination levels of $\\sim 10^{-10}$ and $\\sim 10^{-13}$ g/g. Measurement flexibilities and sensitivities are improved over conventional methods. The projected limiting sensitivities if no excess of potassium signals had been observed over background are $8 \\times 10^{-13}$ g/g and $3 \\times 10^{-17}$ g/g for the CsI and LS, respectively. Studies of the LS samples indicate that the radioactive contaminations come mainly in the dye solutes, while the base solvents are orders of magnitude cleaner. The work demonstrate the possibilities of measuring naturally-occurring isotopes with the AMS techniques. ", "machine_text": " The present study explores the use of Accelerator Mass Spectrometry (AMS) to detect ultra-low levels of potassium contamination in an inorganic salt (CsI) and an organic liquid scintillator (LS). Results show trace amounts of $\\k40$ in both samples, at concentrations of $\\sim 10^{-10}$ g/g and $\\sim 10^{-13}$ g/g respectively. The use of these techniques has improved the sensitivity and measurement of potassium contamination, with projected limits of $8 \\times 10^{-13}$ g/g and $3 \\times10^{-17}$ g/g for CsI and LS samples respectively. In addition, analysis of the LS samples revealed that the majority of the radioactive components came from the dye solutes present in the liquid scintillator, indicated by concentrations orders of magnitude higher than those in the base solvents. The results illustrate the effectiveness of AMS for measuring naturally-occurring isotopes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0059}
{"prompt": "Rephrase the abstract of an article with title 'Optical Transitions in New Trends Organic Materials'.   The PTCDA (3,4,9,10-Perylene-tetracarboxylic dianhydride) and the NTCDA (1,4,5,8-Naphtalenetetracarboxylic dianhydride) are aromatic, stable, planar and highly symmetric with unusual electrical properties. The PTCDA is a semiconductor organic crystalline of particular interest due to its excellent properties and electronic potential that are used in optoelectronic devices and the NTCDA it is monoclinic and its space group is similar to that of the PTCDA. Recently, alternate layers of PTCDA and NTCDA were growth forming multiple structures of quantum wells showing a new class of materials with new optic lineal properties. Some have assured that their big utilities would be centered in the construction of diodes and of possible guides of waves. We have carried out calculations semi-empirical of the electronic structures and of optic properties of the PTCDA and of the NTCDA that show us that they are structures highly orderly polymeric, semiconductors in a negative load state (charge state= -2)  ", "human_text": "  The PTCDA (3,4,9,10-Perylene-tetracarboxylic dianhydride) and the NTCDA (1,4,5,8-Naphtalenetetracarboxylic dianhydride) are aromatic, stable, planar and highly symmetric with unusual electrical properties. The PTCDA is a semiconductor organic crystalline of particular interest due to its excellent properties and electronic potential that are used in optoelectronic devices and the NTCDA it is monoclinic and its space group is similar to that of the PTCDA. Recently, alternate layers of PTCDA and NTCDA were growth forming multiple structures of quantum wells showing a new class of materials with new optic lineal properties. Some have assured that their big utilities would be centered in the construction of diodes and of possible guides of waves. We have carried out calculations semi-empirical of the electronic structures and of optic properties of the PTCDA and of the NTCDA that show us that they are structures highly orderly polymeric, semiconductors in a negative load state (charge state= -2) ", "machine_text": " This study investigates the structure, electronic, and optical properties of organic crystals, specifically the PTCDA (3,4,9,10-Perylene-tetracarboxylic dianhydride) and NTCDA (1,4,5,8-Naphtalenetetracarboxylic dianhydride). These aromatic compounds are stable, planar, and highly symmetrical and exhibit interesting properties useful in optoelectronic devices. Alternate layers of PTCDA and NTCDA grown together have created new structures with increased optical lineal properties. Subsequent semi-empirical calculations of this new material's electronic structures and optical properties showed them to be highly organized polymeric semiconductors in a negative charge state (-2). These results suggest the potential of these structures for use in devices such as diode waveguides.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3965}
{"prompt": "Rephrase the abstract of an article with title 'Domain wall switching: optimizing the energy landscape'.   It has recently been suggested that exchange spring media offer a way to increase media density without causing thermal instability (superparamagnetism), by using a hard and a soft layer coupled by exchange. Victora has suggested a figure of merit xi = 2 E_b/mu_0 m_s H_sw, the ratio of the energy barrier to that of a Stoner-Wohlfarth system with the same switching field, which is 1 for a Stoner-Wohlfarth (coherently switching) particle and 2 for an optimal two-layer composite medium. A number of theoretical approaches have been used for this problem (e.g., various numbers of coupled Stoner-Wohlfarth layers and continuum micromagnetics). In this paper we show that many of these approaches can be regarded as special cases or approximations to a variational formulation of the problem, in which the energy is minimized for fixed magnetization. The results can be easily visualized in terms of a plot of the energy as a function of magnetic moment m_z, in which both the switching field [the maximum slope of E(m_z)] and the stability (determined by the energy barrier E_b) are geometrically visible. In this formulation we can prove a rigorous limit on the figure of merit xi, which can be no higher than 4. We also show that a quadratic anistropy suggested by Suess et al comes very close to this limit.  ", "human_text": "  It has recently been suggested that exchange spring media offer a way to increase media density without causing thermal instability (superparamagnetism), by using a hard and a soft layer coupled by exchange. Victora has suggested a figure of merit xi = 2 E_b/mu_0 m_s H_sw, the ratio of the energy barrier to that of a Stoner-Wohlfarth system with the same switching field, which is 1 for a Stoner-Wohlfarth (coherently switching) particle and 2 for an optimal two-layer composite medium. A number of theoretical approaches have been used for this problem (e.g., various numbers of coupled Stoner-Wohlfarth layers and continuum micromagnetics). In this paper we show that many of these approaches can be regarded as special cases or approximations to a variational formulation of the problem, in which the energy is minimized for fixed magnetization. The results can be easily visualized in terms of a plot of the energy as a function of magnetic moment m_z, in which both the switching field [the maximum slope of E(m_z)] and the stability (determined by the energy barrier E_b) are geometrically visible. In this formulation we can prove a rigorous limit on the figure of merit xi, which can be no higher than 4. We also show that a quadratic anistropy suggested by Suess et al comes very close to this limit. ", "machine_text": "This article examines the optimization of the energy landscape domain wall switching. Various approaches such as the use of multiple Stoner-Wohlfarth layers and continuum micromagnetics have been explored, with the end goal of minimizing the energy for concentration of magnetization. The stability and switching field are both important factors in reaching optimal results, as illustrated in a visualized plot of the energy depending on the value of the magnetic moment m_z. It is calculated that the potential figure of merit xi can reach no higher than 4. There is evidence of a quadratical anisotropic parameter that is proposed by Suess et al which was found to reach this limit.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0913}
{"prompt": "Rephrase the abstract of an article with title 'GRI: The Gamma-Ray Imager mission'.   With the INTEGRAL observatory, ESA has provided a unique tool to the astronomical community revealing hundreds of sources, new classes of objects, extraordinary views of antimatter annihilation in our Galaxy, and fingerprints of recent nucleosynthesis processes. While INTEGRAL provides the global overview over the soft gamma-ray sky, there is a growing need to perform deeper, more focused investigations of gamma-ray sources. In soft X-rays a comparable step was taken going from the Einstein and the EXOSAT satellites to the Chandra and XMM/Newton observatories. Technological advances in the past years in the domain of gamma-ray focusing using Laue diffraction have paved the way towards a new gamma-ray mission, providing major improvements regarding sensitivity and angular resolution. Such a future Gamma-Ray Imager will allow studies of particle acceleration processes and explosion physics in unprecedented detail, providing essential clues on the innermost nature of the most violent and most energetic processes in the Universe.  ", "human_text": "  With the INTEGRAL observatory, ESA has provided a unique tool to the astronomical community revealing hundreds of sources, new classes of objects, extraordinary views of antimatter annihilation in our Galaxy, and fingerprints of recent nucleosynthesis processes. While INTEGRAL provides the global overview over the soft gamma-ray sky, there is a growing need to perform deeper, more focused investigations of gamma-ray sources. In soft X-rays a comparable step was taken going from the Einstein and the EXOSAT satellites to the Chandra and XMM/Newton observatories. Technological advances in the past years in the domain of gamma-ray focusing using Laue diffraction have paved the way towards a new gamma-ray mission, providing major improvements regarding sensitivity and angular resolution. Such a future Gamma-Ray Imager will allow studies of particle acceleration processes and explosion physics in unprecedented detail, providing essential clues on the innermost nature of the most violent and most energetic processes in the Universe. ", "machine_text": "The Gamma-Ray Imager (GRI) mission promises to take a major leap forward in gamma-ray observation, allowing for a deeper and more focused view of sources than ever before. Developments in Laue diffraction have enabled increased sensitivity and angular clarity, making it possible to investigate particle acceleration and explosion physics with unprecedented detail. This will be of immeasurable value in understanding the energetic and violent processes of the Universe.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1754}
{"prompt": "Rephrase the abstract of an article with title 'Validating module network learning algorithms using simulated data'.   In recent years, several authors have used probabilistic graphical models to learn expression modules and their regulatory programs from gene expression data. Here, we demonstrate the use of the synthetic data generator SynTReN for the purpose of testing and comparing module network learning algorithms. We introduce a software package for learning module networks, called LeMoNe, which incorporates a novel strategy for learning regulatory programs. Novelties include the use of a bottom-up Bayesian hierarchical clustering to construct the regulatory programs, and the use of a conditional entropy measure to assign regulators to the regulation program nodes. Using SynTReN data, we test the performance of LeMoNe in a completely controlled situation and assess the effect of the methodological changes we made with respect to an existing software package, namely Genomica. Additionally, we assess the effect of various parameters, such as the size of the data set and the amount of noise, on the inference performance. Overall, application of Genomica and LeMoNe to simulated data sets gave comparable results. However, LeMoNe offers some advantages, one of them being that the learning process is considerably faster for larger data sets. Additionally, we show that the location of the regulators in the LeMoNe regulation programs and their conditional entropy may be used to prioritize regulators for functional validation, and that the combination of the bottom-up clustering strategy with the conditional entropy-based assignment of regulators improves the handling of missing or hidden regulators.  ", "human_text": "  In recent years, several authors have used probabilistic graphical models to learn expression modules and their regulatory programs from gene expression data. Here, we demonstrate the use of the synthetic data generator SynTReN for the purpose of testing and comparing module network learning algorithms. We introduce a software package for learning module networks, called LeMoNe, which incorporates a novel strategy for learning regulatory programs. Novelties include the use of a bottom-up Bayesian hierarchical clustering to construct the regulatory programs, and the use of a conditional entropy measure to assign regulators to the regulation program nodes. Using SynTReN data, we test the performance of LeMoNe in a completely controlled situation and assess the effect of the methodological changes we made with respect to an existing software package, namely Genomica. Additionally, we assess the effect of various parameters, such as the size of the data set and the amount of noise, on the inference performance. Overall, application of Genomica and LeMoNe to simulated data sets gave comparable results. However, LeMoNe offers some advantages, one of them being that the learning process is considerably faster for larger data sets. Additionally, we show that the location of the regulators in the LeMoNe regulation programs and their conditional entropy may be used to prioritize regulators for functional validation, and that the combination of the bottom-up clustering strategy with the conditional entropy-based assignment of regulators improves the handling of missing or hidden regulators. ", "machine_text": " This study demonstrated the capacity of the synthetic data generator SynTReN to validate and compare algorithms for learning expression module networks. We proposed a new software, titled LeMoNe, for module network learning that utilizes a bottom-up Bayesian hierarchical clustering process to build regulatory programs, and a conditional entropy measure to assign regulators to program nodes. Testing with simulated data sets enabled us to assess the potentials of Genomica and LeMoNe and the effects of various parameters, like dataset size and noise, on their performance. Despite some discrepancies, both algorithms generated similar outcomes and LeMoNe is significantly faster with large datasets. Further, we showed that the regulation program inferring regulators through LeMoNe's conditional entropy metric could be used to prioritize regulators for further validational tests and that the combination of the clustering strategy and the entropy-based assignment method is effective in identifying missing or hidden regulators.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0666}
{"prompt": "Rephrase the abstract of an article with title 'Visible spectroscopic and photometric survey of Jupiter Trojans: final   results on dynamical families'.   We present the results of a visible spectroscopic and photometric survey of Jupiter Trojans belonging to different dynamical families carried out at the ESO-NTT telescope. We obtained data on 47 objects, 23 belonging to the L5 swarm and 24 to the L4 one. These data together with those already published by Fornasier et al. (2004a) and Dotto et al. (2006), constitute a total sample of visible spectra for 80 objects. The survey allows us to investigate six families (Aneas, Anchises, Misenus, Phereclos, Sarpedon, Panthoos) in the L5 cloud and four L4 families (Eurybates, Menelaus, 1986 WD and 1986 TS6). The sample that we measured is dominated by D--type asteroids, with the exception of the Eurybates family in the L4 swarm, where there is a dominance of C- and P-type asteroids. All the spectra that we obtained are featureless with the exception of some Eurybates members, where a drop--off of the reflectance is detected shortward of 5200 A. Similar features are seen in main belt C-type asteroids and commonly attributed to the intervalence charge transfer transition in oxidized iron. Our sample comprises fainter and smaller Trojans as compared to the literature's data and allows us to investigate the properties of objects with estimated diameter smaller than 40--50 km. The analysis of the spectral slopes and colors versus the estimated diameters shows that the blue and red objects have indistinguishable size distribution. We perform a statistical investigation of the Trojans's spectra property distributions as a function of their orbital and physical parameters, and in comparison with other classes of minor bodies in the outer Solar System. Trojans at lower inclination appear significantly bluer than those at higher inclination, but this effect is strongly driven by the Eurybates family.  ", "human_text": "  We present the results of a visible spectroscopic and photometric survey of Jupiter Trojans belonging to different dynamical families carried out at the ESO-NTT telescope. We obtained data on 47 objects, 23 belonging to the L5 swarm and 24 to the L4 one. These data together with those already published by Fornasier et al. (2004a) and Dotto et al. (2006), constitute a total sample of visible spectra for 80 objects. The survey allows us to investigate six families (Aneas, Anchises, Misenus, Phereclos, Sarpedon, Panthoos) in the L5 cloud and four L4 families (Eurybates, Menelaus, 1986 WD and 1986 TS6). The sample that we measured is dominated by D--type asteroids, with the exception of the Eurybates family in the L4 swarm, where there is a dominance of C- and P-type asteroids. All the spectra that we obtained are featureless with the exception of some Eurybates members, where a drop--off of the reflectance is detected shortward of 5200 A. Similar features are seen in main belt C-type asteroids and commonly attributed to the intervalence charge transfer transition in oxidized iron. Our sample comprises fainter and smaller Trojans as compared to the literature's data and allows us to investigate the properties of objects with estimated diameter smaller than 40--50 km. The analysis of the spectral slopes and colors versus the estimated diameters shows that the blue and red objects have indistinguishable size distribution. We perform a statistical investigation of the Trojans's spectra property distributions as a function of their orbital and physical parameters, and in comparison with other classes of minor bodies in the outer Solar System. Trojans at lower inclination appear significantly bluer than those at higher inclination, but this effect is strongly driven by the Eurybates family. ", "machine_text": " We present the findings for a visible spectroscopic and photometric examination of Jupiter Trojans associated with different dynamical families conducted at the ESO-NTT telescope. The survey includes data on 47 objects - 23 in the L5 swarm and 24 in the L4 swarm - in addition to already published Fornasier et al. (2004a) and Dotto et al. (2006) survey data, giving a total of 80 surveyed objects. Our sample reflects a dominance of D-type asteroids, with the exception of the Eurybates family in the L4 swarm which consists mostly of C- and P-type asteroids. Some Eurybates members were identified as having a dropoff in reflectance shortward of 5200A, a phenomenon seen in main belt C-type asteroids and attributed to the intervalence charge transfer transition in oxidized iron. The sample was found to include fainter and smaller Trojans and enabled the investigation of asteroids with diameters of 40-50km and less. The analysis of spectral slopes, colors and diameters showed no difference between blue and red objects. A statistical evaluation of the distributions based on the Trojans' physical and orbital parameters was conducted, as well as a comparison to other classes of minor bodies in the outer Solar System. The results revealed that Trojans at lower inclinations tend to be bluer than those at higher inclinations, mainly due to the dominance of the Eurybates family.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.035}
{"prompt": "Rephrase the abstract of an article with title 'Cosmology from String Theory'.   We explore the cosmological content of Salam-Sezgin six dimensional supergravity, and find a solution to the field equations in qualitative agreement with observation of distant supernovae, primordial nucleosynthesis abundances, and recent measurements of the cosmic microwave background. The carrier of the acceleration in the present de Sitter epoch is a quintessence field slowly rolling down its exponential potential. Intrinsic to this model is a second modulus which is automatically stabilized and acts as a source of cold dark matter with a mass proportional to an exponential function of the quintessence field (hence realizing VAMP models within a String context). However, any attempt to saturate the present cold dark matter component in this manner leads to unacceptable deviations from cosmological data -- a numerical study reveals that this source can account for up to about 7% of the total cold dark matter budget. We also show that (1) the model will support a de Sitter energy in agreement with observation at the expense of a miniscule breaking of supersymmetry in the compact space; (2) variations in the fine structure constant are controlled by the stabilized modulus and are negligible; (3) ``fifth''forces are carried by the stabilized modulus and are short range; (4) the long time behavior of the model in four dimensions is that of a Robertson-Walker universe with a constant expansion rate (w = -1/3). Finally, we present a String theory background by lifting our six dimensional cosmological solution to ten dimensions.  ", "human_text": "  We explore the cosmological content of Salam-Sezgin six dimensional supergravity, and find a solution to the field equations in qualitative agreement with observation of distant supernovae, primordial nucleosynthesis abundances, and recent measurements of the cosmic microwave background. The carrier of the acceleration in the present de Sitter epoch is a quintessence field slowly rolling down its exponential potential. Intrinsic to this model is a second modulus which is automatically stabilized and acts as a source of cold dark matter with a mass proportional to an exponential function of the quintessence field (hence realizing VAMP models within a String context). However, any attempt to saturate the present cold dark matter component in this manner leads to unacceptable deviations from cosmological data -- a numerical study reveals that this source can account for up to about 7% of the total cold dark matter budget. We also show that (1) the model will support a de Sitter energy in agreement with observation at the expense of a miniscule breaking of supersymmetry in the compact space; (2) variations in the fine structure constant are controlled by the stabilized modulus and are negligible; (3) ``fifth''forces are carried by the stabilized modulus and are short range; (4) the long time behavior of the model in four dimensions is that of a Robertson-Walker universe with a constant expansion rate (w = -1/3). Finally, we present a String theory background by lifting our six dimensional cosmological solution to ten dimensions. ", "machine_text": " We examine the implications of string theory on the cosmological landscape, particularly the solutions that can be found to the field equations in the Salam-Sezgind six-dimensional supergravity. This models complements our observations of distant supernovae, primordial nucleosynthesis abundance and recent measurements of cosmic microwave background. We find that a quintessence field slowly rolling down its exponential potential is the driving force behind the present day de Sitter epoch. Additionally, a second modulus is a source of cold dark matter, which when fully saturated, leads to unacceptable deviations from cosmological data. Numerical studies show this can account for up to 7% of total cold dark matter. Further components of this model are de Sitter energy that is consistent with observation, variations in fine structure constant that are negligible, fifth-forces that are short-ranged and a Robertson-Walker universe with a steady expansion rate. We demonstrate all this can be seen in a ten-dimensional String theory context.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0928}
{"prompt": "Rephrase the abstract of an article with title 'BEC-BCS Crossover of a Trapped Two-Component Fermi Gas with Unequal   Masses'.   We determine the energetically lowest lying states in the BEC-BCS crossover regime of s-wave interacting two-component Fermi gases under harmonic confinement by solving the many-body Schrodinger equation using two distinct approaches. Essentially exact basis set expansion techniques are applied to determine the energy spectrum of systems with N=4 fermions. Fixed-node diffusion Monte Carlo methods are applied to systems with up to N=20 fermions, and a discussion of different guiding functions used in the Monte Carlo approach to impose the proper symmetry of the fermionic system is presented. The energies are calculated as a function of the s-wave scattering length a_s for N=2-20 fermions and different mass ratios \\kappa of the two species. On the BEC and BCS sides, our energies agree with analytically-determined first-order correction terms. We extract the scattering length and the effective range of the dimer-dimer system up to \\kappa = 20. Our energies for the strongly-interacting trapped system in the unitarity regime show no shell structure, and are well described by a simple expression, whose functional form can be derived using the local density approximation, with one or two parameters. The universal parameter \\xi for the trapped system for various \\kappa is determined, and comparisons with results for the homogeneous system are presented.  ", "human_text": "  We determine the energetically lowest lying states in the BEC-BCS crossover regime of s-wave interacting two-component Fermi gases under harmonic confinement by solving the many-body Schrodinger equation using two distinct approaches. Essentially exact basis set expansion techniques are applied to determine the energy spectrum of systems with N=4 fermions. Fixed-node diffusion Monte Carlo methods are applied to systems with up to N=20 fermions, and a discussion of different guiding functions used in the Monte Carlo approach to impose the proper symmetry of the fermionic system is presented. The energies are calculated as a function of the s-wave scattering length a_s for N=2-20 fermions and different mass ratios \\kappa of the two species. On the BEC and BCS sides, our energies agree with analytically-determined first-order correction terms. We extract the scattering length and the effective range of the dimer-dimer system up to \\kappa = 20. Our energies for the strongly-interacting trapped system in the unitarity regime show no shell structure, and are well described by a simple expression, whose functional form can be derived using the local density approximation, with one or two parameters. The universal parameter \\xi for the trapped system for various \\kappa is determined, and comparisons with results for the homogeneous system are presented. ", "machine_text": " We investigate the structure of s-wave interacting two-component Fermi gases subject to a harmonic trapping potential, in the context of the BEC-BCS crossover regime. Two distinct approaches are used to solve the Schrodinger equation for systems with up to N=20 fermions. Exact basis set expansion is applied to N=4, while a Fixed-node diffusion Monte Carlo method allows us to study larger systems. We show that on the BEC and BCS sides, our results, expressed as a function of the s-wave scattering length and of the mass ratio \\kappa of the two species, agree with first order correction terms. For the unitarity regime, we deduce the scattering length and effective range of the dimer-dimer system up to \\kappa = 20. We find that the energies of the strongly-interacting trapped system present no shell structure, and are approximately described by a simple expression that depends on one or two parameters. Additionally, we determine the universal parameter \\xi for the trapped system, and compare it to results for the homogeneous case.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0671}
{"prompt": "Rephrase the abstract of an article with title 'CKM and Tri-bimaximal MNS Matrices in a SU(5) x (d)T Model'.   We propose a model based on SU(5) x {}^{(d)}T which successfully gives rise to near tri-bimaximal leptonic mixing as well as realistic CKM matrix elements for the quarks. The Georgi-Jarlskog relations for three generations are also obtained. Due to the {}^{(d)}T transformation property of the matter fields, the b-quark mass can be generated only when the {}^{(d)}T symmetry is broken, giving a dynamical origin for the hierarchy between m_{b} and m_{t}. There are only nine operators allowed in the Yukawa sector up to at least mass dimension seven due to an additional Z_{12} x Z'_{12} symmetry, which also forbids, up to some high orders, operators that lead to proton decay. The resulting model has a total of nine parameters in the charged fermion and neutrino sectors, and hence is very predictive. In addition to the prediction for \\theta_{13} \\simeq \\theta_{c}/3 \\sqrt{2}, the model gives rise to a sum rule, \\tan^{2}\\theta_{\\odot} \\simeq \\tan^{2} \\theta_{\\odot, \\mathrm{TBM}} - {1/2} \\theta_{c} \\cos\\beta, which is a consequence of the Georgi-Jarlskog relations in the quark sector. This deviation could account for the difference between the experimental best fit value for the solar mixing angle and the value predicted by the tri-bimaximal mixing matrix.  ", "human_text": "  We propose a model based on SU(5) x {}^{(d)}T which successfully gives rise to near tri-bimaximal leptonic mixing as well as realistic CKM matrix elements for the quarks. The Georgi-Jarlskog relations for three generations are also obtained. Due to the {}^{(d)}T transformation property of the matter fields, the b-quark mass can be generated only when the {}^{(d)}T symmetry is broken, giving a dynamical origin for the hierarchy between m_{b} and m_{t}. There are only nine operators allowed in the Yukawa sector up to at least mass dimension seven due to an additional Z_{12} x Z'_{12} symmetry, which also forbids, up to some high orders, operators that lead to proton decay. The resulting model has a total of nine parameters in the charged fermion and neutrino sectors, and hence is very predictive. In addition to the prediction for \\theta_{13} \\simeq \\theta_{c}/3 \\sqrt{2}, the model gives rise to a sum rule, \\tan^{2}\\theta_{\\odot} \\simeq \\tan^{2} \\theta_{\\odot, \\mathrm{TBM}} - {1/2} \\theta_{c} \\cos\\beta, which is a consequence of the Georgi-Jarlskog relations in the quark sector. This deviation could account for the difference between the experimental best fit value for the solar mixing angle and the value predicted by the tri-bimaximal mixing matrix. ", "machine_text": " We propose a model based on SU(5) x {}^{(d)}T which gives rise to interactions allowing for near tri-bimaximal leptonic and realistic CKM matrix elements for the quarks. The Georgi-Jarlskog relations among the three generations of fermions are also obtained. As a result of the {}^{(d)}T transformation properties of the matter fields, the model dynamically generates a mass hierarchy between the b and t quarks. There are nine operators in the Yukawa sector, enabled by a Z_{12} x Z'_{12} symmetry which also suppresses, up to some high orders, operators leading to proton decay. In total, the model contains nine parameters making it highly predictive. In addition to the prediction for \\theta_{13} \\simeq \\theta_{c}/3 \\sqrt{2}, a sum rule is derived, \\tan^{2}\\theta_{\\odot} \\simeq \\tan^{2} \\theta_{\\odot, \\mathrm{TBM}} - {1/2} \\theta_{c} \\cos\\beta, which is a combined consequence of the Georgi-Jarlskog relations in the quark sector and the deviation between the experimental best fit value and the value predicted by the tri-bimaximal mixing matrix.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0714}
{"prompt": "Rephrase the abstract of an article with title 'Five Intermediate-Period Planets from the N2K Sample'.   We report the detection of five Jovian mass planets orbiting high metallicity stars. Four of these stars were first observed as part of the N2K program and exhibited low RMS velocity scatter after three consecutive observations. However, follow-up observations over the last three years now reveal the presence of longer period planets with orbital periods ranging from 21 days to a few years. HD 11506 is a G0V star with a planet of \\msini = 4.74 \\mjup in a 3.85 year orbit. HD 17156 is a G0V star with a 3.12 \\mjup planet in a 21.2 day orbit. The eccentricity of this orbit is 0.67, one of the highest known for a planet with a relatively short period. The orbital period for this planet places it in a region of parameter space where relatively few planets have been detected. HD 125612 is a G3V star with a planet of \\msini = 3.5 \\mjup in a 1.4 year orbit. HD 170469 is a G5IV star with a planet of \\msini = 0.67 \\mjup in a 3.13 year orbit. HD 231701 is an F8V star with planet of 1.08 \\mjup in a 142 day orbit. All of these stars have supersolar metallicity. Three of the five stars were observed photometrically but showed no evidence of brightness variability. A transit search conducted for HD 17156 was negative but covered only 25% of the search space and so is not conclusive.  ", "human_text": "  We report the detection of five Jovian mass planets orbiting high metallicity stars. Four of these stars were first observed as part of the N2K program and exhibited low RMS velocity scatter after three consecutive observations. However, follow-up observations over the last three years now reveal the presence of longer period planets with orbital periods ranging from 21 days to a few years. HD 11506 is a G0V star with a planet of \\msini = 4.74 \\mjup in a 3.85 year orbit. HD 17156 is a G0V star with a 3.12 \\mjup planet in a 21.2 day orbit. The eccentricity of this orbit is 0.67, one of the highest known for a planet with a relatively short period. The orbital period for this planet places it in a region of parameter space where relatively few planets have been detected. HD 125612 is a G3V star with a planet of \\msini = 3.5 \\mjup in a 1.4 year orbit. HD 170469 is a G5IV star with a planet of \\msini = 0.67 \\mjup in a 3.13 year orbit. HD 231701 is an F8V star with planet of 1.08 \\mjup in a 142 day orbit. All of these stars have supersolar metallicity. Three of the five stars were observed photometrically but showed no evidence of brightness variability. A transit search conducted for HD 17156 was negative but covered only 25% of the search space and so is not conclusive. ", "machine_text": " After an initial round of observations conducted through the N2K program, subsequent follow-up over the past three years has shown that these four stars each possess a Jovian-mass planet. The orbital periods range from 21 days up to a few years, and the planets have minimum masses from 0.67 to 4.74 \\mjup. All of the stars have supersolar metallicity. HD 17156 has an eccentricity of 0.67, one of the highest known for a planet with a relatively short period. A transit search was conducted but was unsuccessful, covering only 25% of the search space. We have identified five new intermediate-period planets from the N2K sample.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1191}
{"prompt": "Rephrase the abstract of an article with title 'Critical Current of Type-II Superconductors in a Broken Bose Glass State'.   The tilt modulus of a defective Abrikosov vortex lattice pinned by material line defects is computed using the boson analogy. It tends to infinity at long wavelength, which yields a Bose glass state that is robust to the addition of weak point-pinning centers, and which implies a restoring force per vortex line for rigid translations about mechanical equilibrium that is independent of magnetic field. It also indicates that the Bose glass state breaks into pieces along the direction of the correlated pinning centers if the latter have finite length. The critical current is predicted to crossover from two dimensional to three dimensional behavior as a function of sample thickness along the correlated pinning centers in such case. That crossover notably can occur at a film thickness that is much larger than that expected from point pins of comparable strength. The above is compared to the dependence on thickness shown by the critical current in certain films of high-temperature superconductors currently being developed for wire technology.  ", "human_text": "  The tilt modulus of a defective Abrikosov vortex lattice pinned by material line defects is computed using the boson analogy. It tends to infinity at long wavelength, which yields a Bose glass state that is robust to the addition of weak point-pinning centers, and which implies a restoring force per vortex line for rigid translations about mechanical equilibrium that is independent of magnetic field. It also indicates that the Bose glass state breaks into pieces along the direction of the correlated pinning centers if the latter have finite length. The critical current is predicted to crossover from two dimensional to three dimensional behavior as a function of sample thickness along the correlated pinning centers in such case. That crossover notably can occur at a film thickness that is much larger than that expected from point pins of comparable strength. The above is compared to the dependence on thickness shown by the critical current in certain films of high-temperature superconductors currently being developed for wire technology. ", "machine_text": "This article examines the current-carrying capabilities of type-II superconductors in a state known as a Bose glass. An analytical computation of a material's tilt modulus is used to evaluate the strength of a broken Bose glass state, which allows it to maintain its form even in the presence of weak, point pinning. The study suggests that the critical current of these superconductors is dependent on the sample's thickness, and can transition between two and three dimensional behaviour as a result. Additionally, it is shown that the film thickness needed for this transition may be larger than what is indicated through the point pinning strength. Comparisons are drawn between the results of the study and high-temperature superconductors being developed for wire technology to validate its findings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1536}
{"prompt": "Rephrase the abstract of an article with title 'Structure and magnetism of self-organized Ge(1-x)Mn(x) nano-columns'.   We report on the structural and magnetic properties of thin Ge(1-x)Mn(x)films grown by molecular beam epitaxy (MBE) on Ge(001) substrates at temperatures (Tg) ranging from 80deg C to 200deg C, with average Mn contents between 1 % and 11 %. Their crystalline structure, morphology and composition have been investigated by transmission electron microscopy (TEM), electron energy loss spectroscopy and x-ray diffraction. In the whole range of growth temperatures and Mn concentrations, we observed the formation of manganese rich nanostructures embedded in a nearly pure germanium matrix. Growth temperature mostly determines the structural properties of Mn-rich nanostructures. For low growth temperatures (below 120deg C), we evidenced a two-dimensional spinodal decomposition resulting in the formation of vertical one-dimensional nanostructures (nanocolumns). Moreover we show in this paper the influence of growth parameters (Tg and Mn content) on this decomposition i.e. on nanocolumns size and density. For temperatures higher than 180deg C, we observed the formation of Ge3Mn5 clusters. For intermediate growth temperatures nanocolumns and nanoclusters coexist. Combining high resolution TEM and superconducting quantum interference device magnetometry, we could evidence at least four different magnetic phases in Ge(1-x)Mn(x) films: (i) paramagnetic diluted Mn atoms in the germanium matrix, (ii) superparamagnetic and ferromagnetic low-Tc nanocolumns (120 K < Tc < 170 K), (iii) high-Tc nanocolumns (Tc> 400 K) and (iv) Ge3Mn5 clusters.  ", "human_text": "  We report on the structural and magnetic properties of thin Ge(1-x)Mn(x)films grown by molecular beam epitaxy (MBE) on Ge(001) substrates at temperatures (Tg) ranging from 80deg C to 200deg C, with average Mn contents between 1 % and 11 %. Their crystalline structure, morphology and composition have been investigated by transmission electron microscopy (TEM), electron energy loss spectroscopy and x-ray diffraction. In the whole range of growth temperatures and Mn concentrations, we observed the formation of manganese rich nanostructures embedded in a nearly pure germanium matrix. Growth temperature mostly determines the structural properties of Mn-rich nanostructures. For low growth temperatures (below 120deg C), we evidenced a two-dimensional spinodal decomposition resulting in the formation of vertical one-dimensional nanostructures (nanocolumns). Moreover we show in this paper the influence of growth parameters (Tg and Mn content) on this decomposition i.e. on nanocolumns size and density. For temperatures higher than 180deg C, we observed the formation of Ge3Mn5 clusters. For intermediate growth temperatures nanocolumns and nanoclusters coexist. Combining high resolution TEM and superconducting quantum interference device magnetometry, we could evidence at least four different magnetic phases in Ge(1-x)Mn(x) films: (i) paramagnetic diluted Mn atoms in the germanium matrix, (ii) superparamagnetic and ferromagnetic low-Tc nanocolumns (120 K < Tc < 170 K), (iii) high-Tc nanocolumns (Tc> 400 K) and (iv) Ge3Mn5 clusters. ", "machine_text": " In this study, we explored the structural and magnetic characteristics of Ge(1-x)Mn(x) films grown by molecular beam epitaxy (MBE). We discovered that the growth temperature plays a major role in the decomposition of the films, resulting in the formation of vertical one-dimensional nanostructures (nanocolumns) at low temperatures (\u2264120\u00b0C), and Ge3Mn5 clusters at higher temperatures (\u2265180\u00b0C). Our experimental results then demonstrated the presence of at least four different magnetic phases, including paramagnetic diluted Mn atoms, low-Tc nanocolumns (120 K < Tc < 170 K), high-Tc nanocolumns (Tc> 400 K), and Ge3Mn5 clusters, depending on the growth temperature and Mn content. Combining transmission electron microscopy and superconducting quantum interference device magnetometry, we are able to provide a comprehensive analysis of the structure and magnetism of self-organized Ge(1-x)Mn(x) nano-columns.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0566}
{"prompt": "Rephrase the abstract of an article with title 'Cooling and heating by adiabatic magnetization in the   Ni$_{50}$Mn$_{34}$In$_{16}$ magnetic shape memory alloy'.   We report on measurements of the adiabatic temperature change in the inverse magnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy. It is shown that this alloy heats up with the application of a magnetic field around the Curie point due to the conventional magnetocaloric effect. In contrast, the inverse magnetocaloric effect associated with the martensitic transition results in the unusual decrease of temperature by adiabatic magnetization. We also provide magnetization and specific heat data which enable to compare the measured temperature changes to the values indirectly computed from thermodynamic relationships. Good agreement is obtained for the conventional effect at the second-order paramagnetic-ferromagnetic phase transition. However, at the first order structural transition the measured values at high fields are lower than the computed ones. Irreversible thermodynamics arguments are given to show that such a discrepancy is due to the irreversibility of the first-order martensitic transition.  ", "human_text": "  We report on measurements of the adiabatic temperature change in the inverse magnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy. It is shown that this alloy heats up with the application of a magnetic field around the Curie point due to the conventional magnetocaloric effect. In contrast, the inverse magnetocaloric effect associated with the martensitic transition results in the unusual decrease of temperature by adiabatic magnetization. We also provide magnetization and specific heat data which enable to compare the measured temperature changes to the values indirectly computed from thermodynamic relationships. Good agreement is obtained for the conventional effect at the second-order paramagnetic-ferromagnetic phase transition. However, at the first order structural transition the measured values at high fields are lower than the computed ones. Irreversible thermodynamics arguments are given to show that such a discrepancy is due to the irreversibility of the first-order martensitic transition. ", "machine_text": " In this study, we investigate the adiabatic temperature alteration of the inverse magnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy attained through magnetic field application around the Curie point. Using magnetization and specific heat measurements, we analyze and compare the induced temperature changes relative to thermodynamic calculations. Our results show that the conventional magnetocaloric effect causes the temperature of the alloy to rise, yet temperatures markedly reduce due to the inverse magnetocaloric effect associated with the martensitic transition. We found that the observed conventional effect observed at the second-order paramagnetic-ferromagnetic phase transition was in concurrence with our calculations. Conversely, the first order structural transition results showed that the calculated temperature increases were lower than the recorded values at high fields - a phenomenon termed here as irreversible thermodynamics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1241}
{"prompt": "Rephrase the abstract of an article with title 'Fabrication of half metallicity in a ferromagnetic metal'.   We investigate the growth of half metallic phase in a ferromagnetic material using state-of-the-art full potential linearized augmented plane wave method. To address the issue, we have substituted Ti at the Ru-sites in SrRuO3, where SrRuO3 is a ferromagnetic material. Calculated results establish Ti4+ valence states (similar to SrTiO3), which was predicted experimentally. Thus, Ti substitution dilutes the Ru-O-Ru connectivity, which is manifested in the calculated results in the form of significant band narrowing leading to finite gap between t2g and eg bands. At 75% substitution, a large gap (> 2 eV) appears at the Fermi level, e_F in the up spin density of states, while the down spin states contributes at e_F characterizing the system a half-metallic ferromagnet. The t2g - eg gap can be tailored judiciously by tuning Ti concentrations to minimize thermal effects, which is often the major bottleneck to achieve high spin polarization at elevated temperatures in other materials. This study, thus, provides a novel but simple way to fabricate half-metallicity in ferromagnetic materials, which are potential candidates for spin-based technology.  ", "human_text": "  We investigate the growth of half metallic phase in a ferromagnetic material using state-of-the-art full potential linearized augmented plane wave method. To address the issue, we have substituted Ti at the Ru-sites in SrRuO3, where SrRuO3 is a ferromagnetic material. Calculated results establish Ti4+ valence states (similar to SrTiO3), which was predicted experimentally. Thus, Ti substitution dilutes the Ru-O-Ru connectivity, which is manifested in the calculated results in the form of significant band narrowing leading to finite gap between t2g and eg bands. At 75% substitution, a large gap (> 2 eV) appears at the Fermi level, e_F in the up spin density of states, while the down spin states contributes at e_F characterizing the system a half-metallic ferromagnet. The t2g - eg gap can be tailored judiciously by tuning Ti concentrations to minimize thermal effects, which is often the major bottleneck to achieve high spin polarization at elevated temperatures in other materials. This study, thus, provides a novel but simple way to fabricate half-metallicity in ferromagnetic materials, which are potential candidates for spin-based technology. ", "machine_text": " We investigate a technique to fabricate half-metallicity in a ferromagnetic material by substituting Ti at the Ru-sites in SrRuO3, which is a known ferromagnetic material. By employing full potential linearized augmented plane wave method, we find that Ti4+ valence states, similar to SrTiO3, are obtained. Significant band narrowing is shown as a result of this Ti substitution, leading to a finite gap between the t2g and eg bands. When 75% substitution is done, a large gap (larger than 2 eV) is formed at the Fermi level in the spin density of states of the up spin electrons, while the spin density of states of the down spin electrons contribute at the Fermi level, thus characterizing the system a half-metallic ferromagnet. This study provides a simple and effective way to fabricate half-metallicity in ferromagnetic materials, which is important for developing spin-based technologies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0321}
{"prompt": "Rephrase the abstract of an article with title 'Hall drift of axisymmetric magnetic fields in solid neutron-star matter'.   Hall drift, i. e., transport of magnetic flux by the moving electrons giving rise to the electrical current, may be the dominant effect causing the evolution of the magnetic field in the solid crust of neutron stars. It is a nonlinear process that, despite a number of efforts, is still not fully understood. We use the Hall induction equation in axial symmetry to obtain some general properties of nonevolving fields, as well as analyzing the evolution of purely toroidal fields, their poloidal perturbations, and current-free, purely poloidal fields. We also analyze energy conservation in Hall instabilities and write down a variational principle for Hall equilibria. We show that the evolution of any toroidal magnetic field can be described by Burgers' equation, as previously found in plane-parallel geometry. It leads to sharp current sheets that dissipate on the Hall time scale, yielding a stationary field configuration that depends on a single, suitably defined coordinate. This field, however, is unstable to poloidal perturbations, which grow as their field lines are stretched by the background electron flow, as in instabilities earlier found numerically. On the other hand, current-free poloidal configurations are stable and could represent a long-lived crustal field supported by currents in the fluid stellar core.  ", "human_text": "  Hall drift, i. e., transport of magnetic flux by the moving electrons giving rise to the electrical current, may be the dominant effect causing the evolution of the magnetic field in the solid crust of neutron stars. It is a nonlinear process that, despite a number of efforts, is still not fully understood. We use the Hall induction equation in axial symmetry to obtain some general properties of nonevolving fields, as well as analyzing the evolution of purely toroidal fields, their poloidal perturbations, and current-free, purely poloidal fields. We also analyze energy conservation in Hall instabilities and write down a variational principle for Hall equilibria. We show that the evolution of any toroidal magnetic field can be described by Burgers' equation, as previously found in plane-parallel geometry. It leads to sharp current sheets that dissipate on the Hall time scale, yielding a stationary field configuration that depends on a single, suitably defined coordinate. This field, however, is unstable to poloidal perturbations, which grow as their field lines are stretched by the background electron flow, as in instabilities earlier found numerically. On the other hand, current-free poloidal configurations are stable and could represent a long-lived crustal field supported by currents in the fluid stellar core. ", "machine_text": "The Hall drift, or transport of magnetic flux by moving electrons producing an electrical current, may be the main factor leading to the evolution of the magnetic field in the solid crust of neutron stars. In this article, the Hall induction equation in axial symmetry is utilised to explore the nonlinear process that has still not been fully comprehended and understand the properties of non-evolving fields as well as the evolution of purely toroidal fields, their poloidal perturbations, and current-free, purely poloidal fields. Additionally, it is shown that the evolution of any toroidal magnetic field can be detailed through Burgers' equation. The stability of poloidal magnetic field is discussed and it is shown that these are stable and could be representatives of a long-term polarized crustal field, maintained by currents in the fluid stellar core.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1901}
{"prompt": "Rephrase the abstract of an article with title 'Free zero-range processes on networks'.   A free zero-range process (FRZP) is a simple stochastic process describing the dynamics of a gas of particles hopping between neighboring nodes of a network. We discuss three different cases of increasing complexity: (a) FZRP on a rigid geometry where the network is fixed during the process, (b) FZRP on a random graph chosen from a given ensemble of networks, (c) FZRP on a dynamical network whose topology continuously changes during the process in a way which depends on the current distribution of particles. The case (a) provides a very simple realization of the phenomenon of condensation which manifests as the appearance of a condensate of particles on the node with maximal degree. The case (b) is very interesting since the averaging over typical ensembles of graphs acts as a kind of homogenization of the system which makes all nodes identical from the point of view of the FZRP. In the case (c), the distribution of particles and the dynamics of network are coupled to each other. The strength of this coupling depends on the ratio of two time scales: for changes of the topology and of the FZRP. We will discuss a specific example of that type of interaction and show that it leads to an interesting phase diagram.  ", "human_text": "  A free zero-range process (FRZP) is a simple stochastic process describing the dynamics of a gas of particles hopping between neighboring nodes of a network. We discuss three different cases of increasing complexity: (a) FZRP on a rigid geometry where the network is fixed during the process, (b) FZRP on a random graph chosen from a given ensemble of networks, (c) FZRP on a dynamical network whose topology continuously changes during the process in a way which depends on the current distribution of particles. The case (a) provides a very simple realization of the phenomenon of condensation which manifests as the appearance of a condensate of particles on the node with maximal degree. The case (b) is very interesting since the averaging over typical ensembles of graphs acts as a kind of homogenization of the system which makes all nodes identical from the point of view of the FZRP. In the case (c), the distribution of particles and the dynamics of network are coupled to each other. The strength of this coupling depends on the ratio of two time scales: for changes of the topology and of the FZRP. We will discuss a specific example of that type of interaction and show that it leads to an interesting phase diagram. ", "machine_text": " This article examines the dynamics of a gas of particles hopping between the nodes of a network in the context of a free zero-range process (FZRP). Three different cases of increasing complexity are discussed. These include FZRP on a rigid geometry, FZRP on a random graph drawn from a given network, and a form of FZRP where the network's topology continuously changes as the process evolves, depending on the particle distribution. The first case examines the intriguing phenomenon of condensation, which appears as a collection of particles on the node presenting the highest degree. The second considers the role of averaging over various graph ensembles, making all nodes identical with respect to the FZRP. In the final case, the distribution of particles and the dynamics of the network are interconnected, with their strength of coupling depending on the ratio of two time-scales, relating to the topology and the FZRP. A particular example is analyzed, demonstrating an interesting phase diagram in the results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0549}
{"prompt": "Rephrase the abstract of an article with title 'Reduced dimensionality in layered quantum dimer magnets: Frustration vs.   inhomogeneous condensates'.   Motivated by recent experiments on BaCuSi2O6, we investigate magnetic excitations and quantum phase transitions of layered dimer magnets with inter-layer frustration. We consider two scenarios, (A) a lattice with one dimer per unit cell and perfect inter-layer frustration, and (B) an enlarged unit cell with inequivalent layers, with and without perfect frustration. In all situations, the critical behavior at asymptotically low temperatures is three-dimensional, but the corresponding crossover scale may be tiny. Magnetic ordering in case (B) can be discussed in terms of two condensates; remarkably, perfect frustration renders the proximity effect ineffective. Then, the ordering transition will be generically split, with clear signatures in measurable properties. Using a generalized bond-operator method, we calculate the low-temperature magnetic properties in the paramagnetic and antiferromagnetic phases. Based on the available experimental data on BaCuSi2O6, we propose that scenario (B) with inequivalent layers and imperfect frustration is realized in this material, likely with an additional modulation of the inter-layer couling along the c axis.  ", "human_text": "  Motivated by recent experiments on BaCuSi2O6, we investigate magnetic excitations and quantum phase transitions of layered dimer magnets with inter-layer frustration. We consider two scenarios, (A) a lattice with one dimer per unit cell and perfect inter-layer frustration, and (B) an enlarged unit cell with inequivalent layers, with and without perfect frustration. In all situations, the critical behavior at asymptotically low temperatures is three-dimensional, but the corresponding crossover scale may be tiny. Magnetic ordering in case (B) can be discussed in terms of two condensates; remarkably, perfect frustration renders the proximity effect ineffective. Then, the ordering transition will be generically split, with clear signatures in measurable properties. Using a generalized bond-operator method, we calculate the low-temperature magnetic properties in the paramagnetic and antiferromagnetic phases. Based on the available experimental data on BaCuSi2O6, we propose that scenario (B) with inequivalent layers and imperfect frustration is realized in this material, likely with an additional modulation of the inter-layer couling along the c axis. ", "machine_text": "  Motivated by experiments on BaCuSi2O6, this study examines the magnetic excitations and transitions in layered quantum dimer magnets when considering two scenarios: (A) one dimer per unit cell and complete inter-layer frustration; and (B) an enlarged cell with inequivalent layers, either with or without perfect frustration. Calculations of the material's low-temperature magnetic characteristics based on a generalized bond-operator method reveal critical behavior that is three-dimensional at the lowest temperature, albeit with a tiny crossover scale. In the second case, it is demonstrated that the magnetic order can be interpreted as stemming from two condensates, and that complete frustration weakens the proximity influence. Consequently, the ordering transition typically becomes separated, leading to observable effects. Comparison with the available data indicates that BaCuSi2O6 likely implements scenario (B) with distinct layers and partially frustrated interactions, supplemented by an additional modulation of inter-layer couplings along the c-axis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1351}
{"prompt": "Rephrase the abstract of an article with title 'SLE in self-dual critical Z(N) spin systems: CFT predictions'.   The Schramm-Loewner evolution (SLE) describes the continuum limit of domain walls at phase transitions in two dimensional statistical systems. We consider here the SLEs in the self-dual Z(N) spin models at the critical point. For N=2 and N=3 these models correspond to the Ising and three-state Potts model. For N>5 the critical self-dual Z(N) spin models are described in the continuum limit by non-minimal conformal field theories with central charge c>=1. By studying the representations of the corresponding chiral algebra, we show that two particular operators satisfy a two level null vector condition which, for N>=4, presents an additional term coming from the extra symmetry currents action. For N=2,3 these operators correspond to the boundary conditions changing operators associated to the SLE_{16/3} (Ising model) and to the SLE_{24/5} and SLE_{10/3} (three-state Potts model). We suggest a definition of the interfaces within the Z(N) lattice models. The scaling limit of these interfaces is expected to be described at the self-dual critical point and for N>=4 by the SLE_{4(N+1)/(N+2)} and SLE_{4(N+2)/(N+1)} processes.  ", "human_text": "  The Schramm-Loewner evolution (SLE) describes the continuum limit of domain walls at phase transitions in two dimensional statistical systems. We consider here the SLEs in the self-dual Z(N) spin models at the critical point. For N=2 and N=3 these models correspond to the Ising and three-state Potts model. For N>5 the critical self-dual Z(N) spin models are described in the continuum limit by non-minimal conformal field theories with central charge c>=1. By studying the representations of the corresponding chiral algebra, we show that two particular operators satisfy a two level null vector condition which, for N>=4, presents an additional term coming from the extra symmetry currents action. For N=2,3 these operators correspond to the boundary conditions changing operators associated to the SLE_{16/3} (Ising model) and to the SLE_{24/5} and SLE_{10/3} (three-state Potts model). We suggest a definition of the interfaces within the Z(N) lattice models. The scaling limit of these interfaces is expected to be described at the self-dual critical point and for N>=4 by the SLE_{4(N+1)/(N+2)} and SLE_{4(N+2)/(N+1)} processes. ", "machine_text": " This article looks at the SLEs of self-dual Z(N) spin systems at the critical point. For N=2 and 3, these models represent the Ising and three-state Potts models respectively. By studying the chiral algebras represented by N>5 critical self-dual Z(N) spin models, we show that two operators satisfy a two-level null vector condition, which for N>=4 presents an additional term from symmetry currents. We suggest a definition for the interfaces within the Z(N) lattice models. The scaling limit of these interfaces is expected to be described by the SLE_{4(N+1)/(N+2)} and SLE_{4(N+2)/(N+1)} processes, when taken at the self-dual critical point and for N>=4.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2749}
{"prompt": "Rephrase the abstract of an article with title 'Thermal derivation of the Coleman-De Luccia tunneling prescription'.   We derive the rate for transitions between de Sitter vacua by treating the field theory on the static patch as a thermal system. This reproduces the Coleman-De Luccia formalism for calculating the rate, but leads to a modified interpretation of the bounce solution and a different prediction for the evolution of the system after tunneling. The bounce is seen to correspond to a sequence of configurations interpolating between initial and final configurations on either side of the tunneling barrier, all of which are restricted to the static patch. The final configuration, which gives the initial data on the static patch for evolution after tunneling, is obtained from one half of a slice through the center of the bounce, while the other half gives the configuration before tunneling. The formalism makes no statement about the fields beyond the horizon.   This approach resolves several puzzling aspects and interpretational issues concerning the Coleman-De Luccia and Hawking-Moss bounces. We work in the limit where the back reaction of matter on metric can be ignored, but argue that the qualitative aspects remain in the more general case. The extension to tunneling between anti-de Sitter vacua is discussed.  ", "human_text": "  We derive the rate for transitions between de Sitter vacua by treating the field theory on the static patch as a thermal system. This reproduces the Coleman-De Luccia formalism for calculating the rate, but leads to a modified interpretation of the bounce solution and a different prediction for the evolution of the system after tunneling. The bounce is seen to correspond to a sequence of configurations interpolating between initial and final configurations on either side of the tunneling barrier, all of which are restricted to the static patch. The final configuration, which gives the initial data on the static patch for evolution after tunneling, is obtained from one half of a slice through the center of the bounce, while the other half gives the configuration before tunneling. The formalism makes no statement about the fields beyond the horizon.   This approach resolves several puzzling aspects and interpretational issues concerning the Coleman-De Luccia and Hawking-Moss bounces. We work in the limit where the back reaction of matter on metric can be ignored, but argue that the qualitative aspects remain in the more general case. The extension to tunneling between anti-de Sitter vacua is discussed. ", "machine_text": " Using a thermal model, we investigate the rate at which transitions between de Sitter vacua occur, leading to a Coleman-De Luccia prescription. Our interpretation of the bounce generated by this method offers an alternative prediction for the evolution of the system after it has tunneled. This interpretation suggests that all configurations contained within the static patch leading to the initial and final states of the tunneling process adhere to the bounce solution. The configurations before and after tunneling are halves of a given slice through its center. We concentrate on the case where the matter fields have no effect on the metric, but nevertheless assume that the results may be transferred to more general cases. Finally, we briefly touch upon the idea of tunneling between anti-de Sitter vacua.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1573}
{"prompt": "Rephrase the abstract of an article with title 'Discrete Choices under Social Influence: Generic Properties'.   We consider a model of socially interacting individuals that make a binary choice in a context of positive additive endogenous externalities. It encompasses as particular cases several models from the sociology and economics literature. We extend previous results to the case of a general distribution of idiosyncratic preferences, called here Idiosyncratic Willingnesses to Pay (IWP). Positive additive externalities yield a family of inverse demand curves that include the classical downward sloping ones but also new ones with non constant convexity. When j, the ratio of the social influence strength to the standard deviation of the IWP distribution, is small enough, the inverse demand is a classical monotonic (decreasing) function of the adoption rate. Even if the IWP distribution is mono-modal, there is a critical value of j above which the inverse demand is non monotonic, decreasing for small and high adoption rates, but increasing within some intermediate range. Depending on the price there are thus either one or two equilibria. Beyond this first result, we exhibit the generic properties of the boundaries limiting the regions where the system presents different types of equilibria (unique or multiple). These properties are shown to depend only on qualitative features of the IWP distribution: modality (number of maxima), smoothness and type of support (compact or infinite). The main results are summarized as phase diagrams in the space of the model parameters, on which the regions of multiple equilibria are precisely delimited.  ", "human_text": "  We consider a model of socially interacting individuals that make a binary choice in a context of positive additive endogenous externalities. It encompasses as particular cases several models from the sociology and economics literature. We extend previous results to the case of a general distribution of idiosyncratic preferences, called here Idiosyncratic Willingnesses to Pay (IWP). Positive additive externalities yield a family of inverse demand curves that include the classical downward sloping ones but also new ones with non constant convexity. When j, the ratio of the social influence strength to the standard deviation of the IWP distribution, is small enough, the inverse demand is a classical monotonic (decreasing) function of the adoption rate. Even if the IWP distribution is mono-modal, there is a critical value of j above which the inverse demand is non monotonic, decreasing for small and high adoption rates, but increasing within some intermediate range. Depending on the price there are thus either one or two equilibria. Beyond this first result, we exhibit the generic properties of the boundaries limiting the regions where the system presents different types of equilibria (unique or multiple). These properties are shown to depend only on qualitative features of the IWP distribution: modality (number of maxima), smoothness and type of support (compact or infinite). The main results are summarized as phase diagrams in the space of the model parameters, on which the regions of multiple equilibria are precisely delimited. ", "machine_text": " We explore how individuals interact in the context of binary choices, with the presence of positive additive externalities. We extend known results to the study of Idiosyncratic Willingnesses to Pay (IWP), a general distribution of preferences. The result is a newly developed family of inverse demand curves, including decreasing slopes as well as non-uniform convexity. When the social influence effect is small relative to the standard deviation of the IWP distribution, inverse demand will normally be monotone. However, once the social influence surpasses a certain threshold, the inverse demand may become non-monotone within an intermediate rate of adoption, increasing or decreasing with the rate of adoption. Furthermore, the generic properties depending on the modality, smoothness and support of the IWP distribution allow for a precise delineation of the regions of multiple equilibria. We summarized the principal results in a phase diagram.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2333}
{"prompt": "Rephrase the abstract of an article with title 'Outflows and the Physical Properties of Quasars'.   We have investigated a sample of 5088 quasars from the Sloan Digital Sky Survey Second Data Release in order to determine how the frequency and properties of broad absorptions lines (BALs) depend on black hole mass, bolometric luminosity, Eddington fraction (L/L_Edd), and spectral slope. We focus only on high-ionization BALs and find a number of significant results. While quasars accreting near the Eddington limit are more likely to show BALs than lower $L/L_{Edd}$ systems, BALs are present in quasars accreting at only a few percent Eddington. We find a stronger effect with bolometric luminosity, such that the most luminous quasars are more likely to show BALs. There is an additional effect, previously known, that BAL quasars are redder on average than unabsorbed quasars. The strongest effects involving the quasar physical properties and BAL properties are related to terminal outflow velocity. Maximum observed outflow velocities increase with both the bolometric luminosity and the blueness of the spectral slope, suggesting that the ultraviolet luminosity to a great extent determines the acceleration. These results support the idea of outflow acceleration via ultraviolet line scattering.  ", "human_text": "  We have investigated a sample of 5088 quasars from the Sloan Digital Sky Survey Second Data Release in order to determine how the frequency and properties of broad absorptions lines (BALs) depend on black hole mass, bolometric luminosity, Eddington fraction (L/L_Edd), and spectral slope. We focus only on high-ionization BALs and find a number of significant results. While quasars accreting near the Eddington limit are more likely to show BALs than lower $L/L_{Edd}$ systems, BALs are present in quasars accreting at only a few percent Eddington. We find a stronger effect with bolometric luminosity, such that the most luminous quasars are more likely to show BALs. There is an additional effect, previously known, that BAL quasars are redder on average than unabsorbed quasars. The strongest effects involving the quasar physical properties and BAL properties are related to terminal outflow velocity. Maximum observed outflow velocities increase with both the bolometric luminosity and the blueness of the spectral slope, suggesting that the ultraviolet luminosity to a great extent determines the acceleration. These results support the idea of outflow acceleration via ultraviolet line scattering. ", "machine_text": " In this paper, we investigate the physical properties of a sample of 5088 quasars from the Sloan Digital Sky Survey Second Data Release in order to determine how the frequency and properties of broad absorption lines (BALs) depend on various factors. Specifically, we consider black hole mass, bolometric luminosity, Eddington fraction (L/L_Edd) and spectral slope. Our findings suggest that quasars with elevated Eddington fractions are more likely to exhibit BALs than those with lower fractions. Additionally, an increase in luminosity produces a greater likelihood the quasar will show BALs. Additionally, further evidence supports the idea of outflows becoming accelerated due to ultraviolet light scattering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1546}
{"prompt": "Rephrase the abstract of an article with title 'The Infrared Camera (IRC) for AKARI - Design and Imaging Performance'.   The Infrared Camera (IRC) is one of two focal-plane instruments on the AKARI satellite. It is designed for wide-field deep imaging and low-resolution spectroscopy in the near- to mid-infrared (1.8--26.5um) in the pointed observation mode of AKARI. IRC is also operated in the survey mode to make an all-sky survey at 9 and 18um. It comprises three channels. The NIR channel (1.8--5.5um) employs a 512 x 412 InSb array, whereas both the MIR-S (4.6--13.4um) and MIR-L (12.6--26.5um) channels use 256 x 256 Si:As impurity band conduction arrays. Each of the three channels has a field-of-view of about 10' x 10' and are operated simultaneously. The NIR and MIR-S share the same field-of-view by virtue of a beam splitter. The MIR-L observes the sky about $25' away from the NIR/MIR-S field-of-view. IRC gives us deep insights into the formation and evolution of galaxies, the evolution of planetary disks, the process of star-formation, the properties of interstellar matter under various physical conditions, and the nature and evolution of solar system objects. The in-flight performance of IRC has been confirmed to be in agreement with the pre-flight expectation. This paper summarizes the design and the in-flight operation and imaging performance of IRC.  ", "human_text": "  The Infrared Camera (IRC) is one of two focal-plane instruments on the AKARI satellite. It is designed for wide-field deep imaging and low-resolution spectroscopy in the near- to mid-infrared (1.8--26.5um) in the pointed observation mode of AKARI. IRC is also operated in the survey mode to make an all-sky survey at 9 and 18um. It comprises three channels. The NIR channel (1.8--5.5um) employs a 512 x 412 InSb array, whereas both the MIR-S (4.6--13.4um) and MIR-L (12.6--26.5um) channels use 256 x 256 Si:As impurity band conduction arrays. Each of the three channels has a field-of-view of about 10' x 10' and are operated simultaneously. The NIR and MIR-S share the same field-of-view by virtue of a beam splitter. The MIR-L observes the sky about $25' away from the NIR/MIR-S field-of-view. IRC gives us deep insights into the formation and evolution of galaxies, the evolution of planetary disks, the process of star-formation, the properties of interstellar matter under various physical conditions, and the nature and evolution of solar system objects. The in-flight performance of IRC has been confirmed to be in agreement with the pre-flight expectation. This paper summarizes the design and the in-flight operation and imaging performance of IRC. ", "machine_text": " The Infrared Camera (IRC), located on the AKARI satellite, provides exceptional depth and low-resolution spectroscopy with its three channels operating simultaneously in the near- to mid-infrared (1.8--26.5um) range. The NIR channel (1.8--5.5um) is equipped with a 512 x 412 InSb array, whereas the MIR-S (4.6--13.4um) and MIR-L (12.6--26.5um) channels use 256 x 256 Si:As impurity band conduction arrays, all affording a 10' x 10' field-of-view. The MIR-L observes the sky approximately $25' away from the NIR/MIR-S field-of-view which is shared due to use of a beam splitter. Through use of IRC, we are provided with new information on the formation and evolution of galaxies, the evolution of planetary disks, the process of star-formation, the properties of interstellar matter under various physical conditions, and the nature and evolution of solar system objects. This paper acquaints us with the design of IRC, its in-flight operation, and its imaging performance which is verified to match well with pre-launch expectations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4144}
{"prompt": "Rephrase the abstract of an article with title 'Poisson approximation for non-backtracking random walks'.   Random walks on expander graphs were thoroughly studied, with the important motivation that, under some natural conditions, these walks mix quickly and provide an efficient method of sampling the vertices of a graph. Alon, Benjamini, Lubetzky and Sodin studied non-backtracking random walks on regular graphs, and showed that their mixing rate may be up to twice as fast as that of the simple random walk. As an application, they showed that the maximal number of visits to a vertex, made by a non-backtracking random walk of length $n$ on a high-girth $n$-vertex regular expander, is typically $(1+o(1))\\frac{\\log n}{\\log\\log n}$, as in the case of the balls and bins experiment. They further asked whether one can establish the precise distribution of the visits such a walk makes.   In this work, we answer the above question by combining a generalized form of Brun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote the number of vertices visited precisely $t$ times by a non-backtracking random walk of length $n$ on a regular $n$-vertex expander of fixed degree and girth $g$. We prove that if $g=\\omega(1)$, then for any fixed $t$, $N_t/n$ is typically $\\frac{1}{\\mathrm{e}t!}+o(1)$. Furthermore, if $g=\\Omega(\\log\\log n)$, then $N_t/n$ is typically $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all $t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq (1+o(1))\\frac{\\log n}{\\log\\log n}$. In particular, we obtain the above result on the typical maximal number of visits to a single vertex, with an improved threshold window. The essence of the proof lies in showing that variables counting the number of visits to a set of sufficiently distant vertices are asymptotically independent Poisson variables.  ", "human_text": "  Random walks on expander graphs were thoroughly studied, with the important motivation that, under some natural conditions, these walks mix quickly and provide an efficient method of sampling the vertices of a graph. Alon, Benjamini, Lubetzky and Sodin studied non-backtracking random walks on regular graphs, and showed that their mixing rate may be up to twice as fast as that of the simple random walk. As an application, they showed that the maximal number of visits to a vertex, made by a non-backtracking random walk of length $n$ on a high-girth $n$-vertex regular expander, is typically $(1+o(1))\\frac{\\log n}{\\log\\log n}$, as in the case of the balls and bins experiment. They further asked whether one can establish the precise distribution of the visits such a walk makes.   In this work, we answer the above question by combining a generalized form of Brun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote the number of vertices visited precisely $t$ times by a non-backtracking random walk of length $n$ on a regular $n$-vertex expander of fixed degree and girth $g$. We prove that if $g=\\omega(1)$, then for any fixed $t$, $N_t/n$ is typically $\\frac{1}{\\mathrm{e}t!}+o(1)$. Furthermore, if $g=\\Omega(\\log\\log n)$, then $N_t/n$ is typically $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all $t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq (1+o(1))\\frac{\\log n}{\\log\\log n}$. In particular, we obtain the above result on the typical maximal number of visits to a single vertex, with an improved threshold window. The essence of the proof lies in showing that variables counting the number of visits to a set of sufficiently distant vertices are asymptotically independent Poisson variables. ", "machine_text": " This paper tackles the challenging problem of elucidating the precise distribution of the visits made by a non-backtracking random walk of length $n$, on a regular $n$-vertex expander of fixed degree and girth $g$. Our main result is an application of a generalized form of Brun's sieve, combined with some extensions of the ideas of Alon et al, which shows that if $g=\\omega(1)$, then for any fixed $t$, the number of vertices visited precisely $t$ times is typically $\\frac{1}{\\mathrm{e}t!}+o(1)$. We further demonstrate that if $g=\\Omega(\\log\\log n)$, then it is $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all $t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq (1+o(1))\\frac{\\log n}{\\log\\log n}$. This yields an improved result on the typical maximal number of visits to a single vertex. Our proof shows that variables counting the number of visits to a set of sufficiently distant vertices are asymptotically independent Poisson variables.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0867}
{"prompt": "Rephrase the abstract of an article with title 'Sunyaev-Zel'dovich profiles and scaling relations: modelling effects and   observational biases'.   We use high-resolution hydrodynamic re-simulations to investigate the properties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters. We compare results obtained using different physical models for the intracluster medium (ICM), and show how they modify the SZ emission in terms of cluster profiles and scaling relations. We also produce realistic mock observations to verify whether the results from hydrodynamic simulations can be confirmed. We find that SZ profiles depend marginally on the modelled physical processes, while they exhibit a strong dependence on cluster mass. The central and total SZ emission strongly correlate with the cluster X-ray luminosity and temperature. The logarithmic slopes of these scaling relations differ from the self-similar predictions by less than 0.2; the normalization of the relations is lower for simulations including radiative cooling. The observational test suggests that SZ cluster profiles are unlikely to be able to probe the ICM physics. The total SZ decrement appears to be an observable much more robust than the central intensity, and we suggest using the former to investigate scaling relations.  ", "human_text": "  We use high-resolution hydrodynamic re-simulations to investigate the properties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters. We compare results obtained using different physical models for the intracluster medium (ICM), and show how they modify the SZ emission in terms of cluster profiles and scaling relations. We also produce realistic mock observations to verify whether the results from hydrodynamic simulations can be confirmed. We find that SZ profiles depend marginally on the modelled physical processes, while they exhibit a strong dependence on cluster mass. The central and total SZ emission strongly correlate with the cluster X-ray luminosity and temperature. The logarithmic slopes of these scaling relations differ from the self-similar predictions by less than 0.2; the normalization of the relations is lower for simulations including radiative cooling. The observational test suggests that SZ cluster profiles are unlikely to be able to probe the ICM physics. The total SZ decrement appears to be an observable much more robust than the central intensity, and we suggest using the former to investigate scaling relations. ", "machine_text": " We studied the impact of incorporating different physical models of intracluster medium (ICM) on the thermal Sunyaev-Zel'dovich (SZ) emission from galaxy clusters. With the help of high-resolution hydrodynamic re-simulations, we explored modifications in the SZ profiles and scaling relations. Additionally, realistic mock observations were used to examine the validity of results from the simulations. It was revealed that SZ clusters' features are largely unaffiliated with ICM physics; on the other hand, dependence on the mass of the clusters was notable. The X-ray luminosity and temperature of clusters showed considerable agreement with logarithmic slopes of the scaling relations, while the normalization was discovered to be lesser in simulations including radiative cooling. Eventually, we suggested analyzing the total SZ decrement in preference to the central intensity for probing the scaling relations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2535}
{"prompt": "Rephrase the abstract of an article with title 'Immunohistochemical pitfalls in the demonstration of insulin-degrading   enzyme in normal and neoplastic human tissues'.   Previously, we have identified the cytoplasmic zinc metalloprotease insulin-degrading enzyme(IDE) in human tissues by an immunohistochemical method involving no antigen retrieval (AR) by pressure cooking to avoid artifacts by endogenous biotin exposure and a detection kit based on the labeled streptavidin biotin (LSAB) method. Thereby, we also employed 3% hydrogen peroxide(H2O2) for the inhibition of endogenous peroxidase activity and incubated the tissue sections with the biotinylated secondary antibody at room temperature (RT). We now add the immunohistochemical details that had led us to this optimized procedure as they also bear a more general relevance when demonstrating intracellular tissue antigens. Our most important result is that endogenous peroxidase inhibition by 0.3% H2O2 coincided with an apparently positive IDE staining in an investigated breast cancer specimen whereas combining a block by 3% H2O2 with an incubation of the biotinylated secondary antibody at RT, yet not at 37 degrees Celsius, revealed this specimen as almost entirely IDE-negative. Our present data caution against three different immunohistochemical pitfalls that might cause falsely positive results and artifacts when using an LSAB- and peroxidase-based detection method: pressure cooking for AR, insufficient quenching of endogenous peroxidases and heating of tissue sections while incubating with biotinylated secondary antibodies.  ", "human_text": "  Previously, we have identified the cytoplasmic zinc metalloprotease insulin-degrading enzyme(IDE) in human tissues by an immunohistochemical method involving no antigen retrieval (AR) by pressure cooking to avoid artifacts by endogenous biotin exposure and a detection kit based on the labeled streptavidin biotin (LSAB) method. Thereby, we also employed 3% hydrogen peroxide(H2O2) for the inhibition of endogenous peroxidase activity and incubated the tissue sections with the biotinylated secondary antibody at room temperature (RT). We now add the immunohistochemical details that had led us to this optimized procedure as they also bear a more general relevance when demonstrating intracellular tissue antigens. Our most important result is that endogenous peroxidase inhibition by 0.3% H2O2 coincided with an apparently positive IDE staining in an investigated breast cancer specimen whereas combining a block by 3% H2O2 with an incubation of the biotinylated secondary antibody at RT, yet not at 37 degrees Celsius, revealed this specimen as almost entirely IDE-negative. Our present data caution against three different immunohistochemical pitfalls that might cause falsely positive results and artifacts when using an LSAB- and peroxidase-based detection method: pressure cooking for AR, insufficient quenching of endogenous peroxidases and heating of tissue sections while incubating with biotinylated secondary antibodies. ", "machine_text": " Through the use of an immunohistochemical method utilizing no antigen retrieval (AR) by pressure cooking and a detection kit based on the labeled streptavidin biotin (LSAB) method, we identified the cytoplasmic zinc metalloprotease insulin-degrading enzyme (IDE) in normal and neoplastic human tissues. An important outcome of our experiments is that the combination of a blocking step with 3% hydrogen peroxide (H2O2) and an incubation of the biotinylated secondary antibody at room temperature (RT), not at 37 degrees Celsius, revealed nearly no IDE expression in a breast cancer specimen surveyed previously. Our findings forewarn potential immunohistochemical pitfalls including pressure cooking for AR, insufficient quenching of endogenous peroxidases, and heating of tissue sections during incubation with biotinylated secondary antibodies, which can give inaccurate, false-positive results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0374}
{"prompt": "Rephrase the abstract of an article with title 'Multifractality and scale invariance in human heartbeat dynamics'.   Human heart rate is known to display complex fluctuations. Evidence of multifractality in heart rate fluctuations in healthy state has been reported [Ivanov et al., Nature {\\bf 399}, 461 (1999)]. This multifractal character could be manifested as a dependence on scale or beat number of the probability density functions (PDFs) of the heart rate increments. On the other hand, scale invariance has been recently reported in a detrended analysis of healthy heart rate increments [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. In this paper, we resolve this paradox by clarifying that the scale invariance reported is actually exhibited by the PDFs of the sum of detrended healthy heartbeat intervals taken over different number of beats, and demonstrating that the PDFs of detrended healthy heart rate increments are scale dependent. Our work also establishes that this scale invariance is a general feature of human heartbeat dynamics, which is shared by heart rate fluctuations in both healthy and pathological states.  ", "human_text": "  Human heart rate is known to display complex fluctuations. Evidence of multifractality in heart rate fluctuations in healthy state has been reported [Ivanov et al., Nature {\\bf 399}, 461 (1999)]. This multifractal character could be manifested as a dependence on scale or beat number of the probability density functions (PDFs) of the heart rate increments. On the other hand, scale invariance has been recently reported in a detrended analysis of healthy heart rate increments [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. In this paper, we resolve this paradox by clarifying that the scale invariance reported is actually exhibited by the PDFs of the sum of detrended healthy heartbeat intervals taken over different number of beats, and demonstrating that the PDFs of detrended healthy heart rate increments are scale dependent. Our work also establishes that this scale invariance is a general feature of human heartbeat dynamics, which is shared by heart rate fluctuations in both healthy and pathological states. ", "machine_text": " The study of human heart rate has uncovered a complexity of fluctuation patterns. Previously, multifractality had been observed in heart rate fluctuations of healthy individuals [Ivanov et al., Nature {\\bf 399}, 461 (1999)]. Additionally, recent works have highlighted the presence of scale invariance in heart rate fluctuations, as seen in detrended analyses of healthy subjects [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. This paper provides clarification of this paradox by demonstrating that the scale invariance is present in the probability density functions (PDFs) of summed detrended heart rate intervals, and not in that of detrended heart rate increments. Our findings moreover uncover a general feature of human heartbeat dynamics, to be shared by healthy and pathological states alike.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2415}
{"prompt": "Rephrase the abstract of an article with title 'Does confining the hard-sphere fluid between hard walls change its   average properties?'.   We use grand canonical transition-matrix Monte Carlo and discontinuous molecular dynamics simulations to generate precise thermodynamic and kinetic data for the equilibrium hard-sphere fluid confined between smooth hard walls. These simulations show that the pronounced inhomogeneous structuring of the fluid normal to the confining walls, often the primary focus of density functional theory studies, has a negligible effect on many of its average properties over a surprisingly broad range of conditions. We present one consequence of this insensitivity to confinement: a simple analytical equation relating the average density of the confined fluid to that of the bulk fluid with equal activity. Nontrivial implications of confinement for average fluid properties do emerge in this system, but only when the fluid is both (i) dense and (ii) confined to a gap smaller than approximately three particle diameters. For this limited set of conditions, we find that \"in-phase\" oscillatory deviations in excess entropy and self-diffusivity (relative to the behavior of the bulk fluid at the same average density) occur as a function of gap size. These paired thermodynamic/kinetic deviations from bulk behavior appear to reflect the geometric packing frustration that arises when the confined space cannot naturally accommodate an integer number of particle layers.  ", "human_text": "  We use grand canonical transition-matrix Monte Carlo and discontinuous molecular dynamics simulations to generate precise thermodynamic and kinetic data for the equilibrium hard-sphere fluid confined between smooth hard walls. These simulations show that the pronounced inhomogeneous structuring of the fluid normal to the confining walls, often the primary focus of density functional theory studies, has a negligible effect on many of its average properties over a surprisingly broad range of conditions. We present one consequence of this insensitivity to confinement: a simple analytical equation relating the average density of the confined fluid to that of the bulk fluid with equal activity. Nontrivial implications of confinement for average fluid properties do emerge in this system, but only when the fluid is both (i) dense and (ii) confined to a gap smaller than approximately three particle diameters. For this limited set of conditions, we find that \"in-phase\" oscillatory deviations in excess entropy and self-diffusivity (relative to the behavior of the bulk fluid at the same average density) occur as a function of gap size. These paired thermodynamic/kinetic deviations from bulk behavior appear to reflect the geometric packing frustration that arises when the confined space cannot naturally accommodate an integer number of particle layers. ", "machine_text": " We investigate the effects of confining a hard-sphere fluid within smooth hard walls by means of grand canonical transition-matrix Monte Carlo and discontinuous molecular dynamics simulations. Results demonstrate that the non-uniform structuring of the fluid, usually studied by density functional theory, has a minor influence  on its average properties within a wide range of conditions. Therefore, an analytical expression is provided to relate the confined and bulk fluid average densities of equal activity. While the bulk system is unaltered by confinement, we observe a distinct oscillating behavior in excess entropy and self-diffusivity when the confined space is  dense and smaller than three particle diameters. Such thermodynamic and kinetic deviations result from the geometric frustration that arises due to difficulties in packing an integer number of layers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2224}
{"prompt": "Rephrase the abstract of an article with title 'Detection of VHE gamma-ray emission from the distant blazar 1ES 1101-232   with H.E.S.S. and broadband characterisation'.   The blazar 1ES 1101-232 was observed with the High Energy Stereoscopic System (H.E.S.S.) of Atmospheric Cherenkov Telescopes (ACT) in 2004 and 2005, for a live time of 43 hours. VHE (E > 10^11 eV) gamma-rays were detected for the first time from this object. VHE observations of blazars are used to investigate the inner parts of the blazar jets, and also to study the extragalactic background light (EBL) in the near-infrared band. Observations in 2005 were conducted in a multiwavelength campaign, together with the RXTE satellite and optical observations. In 2004, simultaneous observations with XMM-Newton were obtained. 1ES 1101-232 was detected with H.E.S.S. with an excess of 649 photons, at a significance of 10 sigma. The measured VHE gamma-ray flux amounts to dN/dE = (5.63 +- 0.89) x 10^-13 (E/TeV)^-(2.94 +- 0.20) cm^-2 s^-1 TeV^-1, above a spectral energy threshold of 225 GeV. No significant variation of the VHE gamma-ray flux on any time scale was found. 1ES 1101-232 exhibits a very hard spectrum, and at a redshift of z=0.186, is the blazar with the highest confirmed redshift detected in VHE gamma-rays so far. The data allow the construction of truly simultaneous spectral energy distributions of the source, from the optical to the VHE band. Using an EBL model with \\nu F_\\nu = 14 nW m^-2 sr^-1 at 1.5 \\mu m as presented in Aharonian et al. (Nature, 2006, 440, 1018) suggests an intrinsic VHE power output peak of the source at above 3 TeV.  ", "human_text": "  The blazar 1ES 1101-232 was observed with the High Energy Stereoscopic System (H.E.S.S.) of Atmospheric Cherenkov Telescopes (ACT) in 2004 and 2005, for a live time of 43 hours. VHE (E > 10^11 eV) gamma-rays were detected for the first time from this object. VHE observations of blazars are used to investigate the inner parts of the blazar jets, and also to study the extragalactic background light (EBL) in the near-infrared band. Observations in 2005 were conducted in a multiwavelength campaign, together with the RXTE satellite and optical observations. In 2004, simultaneous observations with XMM-Newton were obtained. 1ES 1101-232 was detected with H.E.S.S. with an excess of 649 photons, at a significance of 10 sigma. The measured VHE gamma-ray flux amounts to dN/dE = (5.63 +- 0.89) x 10^-13 (E/TeV)^-(2.94 +- 0.20) cm^-2 s^-1 TeV^-1, above a spectral energy threshold of 225 GeV. No significant variation of the VHE gamma-ray flux on any time scale was found. 1ES 1101-232 exhibits a very hard spectrum, and at a redshift of z=0.186, is the blazar with the highest confirmed redshift detected in VHE gamma-rays so far. The data allow the construction of truly simultaneous spectral energy distributions of the source, from the optical to the VHE band. Using an EBL model with \\nu F_\\nu = 14 nW m^-2 sr^-1 at 1.5 \\mu m as presented in Aharonian et al. (Nature, 2006, 440, 1018) suggests an intrinsic VHE power output peak of the source at above 3 TeV. ", "machine_text": " A 43 hour live time observation with the High Energy Stereoscopic System (H.E.S.S.) of Atmospheric Cherenkov Telescopes (ACT) research found VHE (E > 10^11 eV) gamma-rays detected from a distant blazar, 1ES 1101-232, for the first time. This finding can be used to investigate the inner parts of the blazar jets as well as the extragalactic background light (EBL) in the near-infrared band. During the observation period of 2004 and 2005, H.E.S.S. detected 649 photons with a significance of 10 sigma. The VHE gamma-ray flux had a measurement of dN/dE = (5.63 +- 0.89) x 10^-13 (E/TeV)^-(2.94 +- 0.20) cm^-2 s^-1 TeV^-1, with a spectral energy threshold of 225 GeV. Also found was the lack of notable flux variation on any time scale and a very hard spectrum. Lastly, 1ES 1101-232 has the highest confirmed redshift detected in VHE gamma-rays so far, at z = 0.186. Simultaneous spectral energy distributions were constructed of the source, from the optical to the VHE band, using an EBL model with a peak of 3 TeV.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2946}
{"prompt": "Rephrase the abstract of an article with title 'Capillary ordering and layering transitions in two-dimensional hard-rod   fluids'.   In this article we calculate the surface phase diagram of a two-dimensional hard-rod fluid confined between two hard lines. In a first stage we study the semi-infinite system consisting of an isotropic fluid in contact with a single hard line. We have found complete wetting by the columnar phase at the wall-isotropic fluid interface. When the fluid is confined between two hard walls, capillary columnar ordering occurs via a first-order phase transition. For higher chemical potentials the system exhibits layering transitions even for very narrow slits (near the one-dimensional limit). The theoretical model used was a density-functional theory based on the Fundamental-Measure Functional applied to a fluid of hard rectangles in the restricted-orientation approximation (Zwanzig model). The results presented here can be checked experimentally in two-dimensional granular media made of rods, where vertical motions induced by an external source and excluded volume interactions between the grains allow the system to explore those stationary states which entropically maximize packing configurations. We claim that some of the surface phenomena found here can be present in two-dimensional granular-media fluids.  ", "human_text": "  In this article we calculate the surface phase diagram of a two-dimensional hard-rod fluid confined between two hard lines. In a first stage we study the semi-infinite system consisting of an isotropic fluid in contact with a single hard line. We have found complete wetting by the columnar phase at the wall-isotropic fluid interface. When the fluid is confined between two hard walls, capillary columnar ordering occurs via a first-order phase transition. For higher chemical potentials the system exhibits layering transitions even for very narrow slits (near the one-dimensional limit). The theoretical model used was a density-functional theory based on the Fundamental-Measure Functional applied to a fluid of hard rectangles in the restricted-orientation approximation (Zwanzig model). The results presented here can be checked experimentally in two-dimensional granular media made of rods, where vertical motions induced by an external source and excluded volume interactions between the grains allow the system to explore those stationary states which entropically maximize packing configurations. We claim that some of the surface phenomena found here can be present in two-dimensional granular-media fluids. ", "machine_text": " This paper examines the surface phase diagram of a two-dimensional fluid of hard rods confined between two rigid lines. Utilizing a density-functional theory based on the Fundamental-Measure Functional and the Zwanzig model for restricted orientation, we discovered that the wall-fluid interface is fully wetted by the columnar phase. Through a first-order transition, confinement between the two walls leads to capillary columnar ordering. For higher chemical potentials, we also identified layering transitions occurring even for narrow slits close to the one-dimensional limit. We conjecture that these surface phenomena could be observed experimentally in two-dimensional systems of rods where external forces can induce vertical motion and excluded volume effects may lead to entropically-maximized packing configurations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1467}
{"prompt": "Rephrase the abstract of an article with title 'Selection Bias in Observing the Cosmological Evolution of the Mbh-sigma   and Mbh-L Relationships'.   Programs to observe evolution in the Mbh-sigma or Mbh-L relations typically compare black-hole masses, Mbh, in high-redshift galaxies selected by nuclear activity to Mbh in local galaxies selected by luminosity L, or stellar velocity dispersion sigma. Because AGN luminosity is likely to depend on Mbh, selection effects are different for high-redshift and local samples, potentially producing a false signal of evolution. This bias arises because cosmic scatter in the Mbh-sigma and Mbh-L relations means that the mean log(L) or log(sigma) among galaxies that host a black hole of given Mbh, may be substantially different than the log(L) or log(sigma) obtained from inverting the Mbh-L or Mbh-sigma relations for the same nominal Mbh. The bias is particularly strong at high Mbh, where the luminosity and dispersion functions of galaxies are falling rapidly. The most massive black holes occur more often as rare outliers in galaxies of modest mass than in the even rarer high-mass galaxies, which would otherwise be the sole location of such black holes in the absence of cosmic scatter. Because of this bias, Mbh will typically appear to be too large in the distant sample for a given L or sigma. For the largest black holes and the largest plausible cosmic scatter, the bias can reach a factor of 3 in Mbh for the Mbh-sigma relation and a factor of 9 for the Mbh-L relation. Unfortunately, the actual cosmic scatter is not known well enough to correct for the bias. Measuring evolution of the Mbh and galaxy property relations requires object selection to be precisely defined and exactly the same at all redshifts.  ", "human_text": "  Programs to observe evolution in the Mbh-sigma or Mbh-L relations typically compare black-hole masses, Mbh, in high-redshift galaxies selected by nuclear activity to Mbh in local galaxies selected by luminosity L, or stellar velocity dispersion sigma. Because AGN luminosity is likely to depend on Mbh, selection effects are different for high-redshift and local samples, potentially producing a false signal of evolution. This bias arises because cosmic scatter in the Mbh-sigma and Mbh-L relations means that the mean log(L) or log(sigma) among galaxies that host a black hole of given Mbh, may be substantially different than the log(L) or log(sigma) obtained from inverting the Mbh-L or Mbh-sigma relations for the same nominal Mbh. The bias is particularly strong at high Mbh, where the luminosity and dispersion functions of galaxies are falling rapidly. The most massive black holes occur more often as rare outliers in galaxies of modest mass than in the even rarer high-mass galaxies, which would otherwise be the sole location of such black holes in the absence of cosmic scatter. Because of this bias, Mbh will typically appear to be too large in the distant sample for a given L or sigma. For the largest black holes and the largest plausible cosmic scatter, the bias can reach a factor of 3 in Mbh for the Mbh-sigma relation and a factor of 9 for the Mbh-L relation. Unfortunately, the actual cosmic scatter is not known well enough to correct for the bias. Measuring evolution of the Mbh and galaxy property relations requires object selection to be precisely defined and exactly the same at all redshifts. ", "machine_text": " Observing the evolution of the Mbh-sigma and Mbh-L relations requires careful consideration of selection bias, as AGN luminosity is known to be linked to black-hole mass. This bias comes from cosmic scatter in the mentioned relations, meaning the mean luminosity or stellar velocity dispersions for galaxies of a given Mbh may be different from those given by inverting said relations. The bias is particularly pronounced for high Mbh, where luminosity and dispersion functions for galaxies drop off rapidly. This can lead to Mbh being perceived as larger in distant samples for certain luminosities or dispersions. To properly measure evolution, selection must be accurately replicated across all redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4103}
{"prompt": "Rephrase the abstract of an article with title 'Constraining GRB progenitor models by probing Wolf-Rayet wind geometries   in the Large Magellanic Cloud'.   The favoured progenitors of long-duration gamma-ray bursts (GRBs) are rapidly rotating Wolf-Rayet (WR) stars. However, most Galactic WR stars are slow rotators, as stellar winds are thought to remove angular momentum. This poses a challenge to the collapsar model. Recent observations indicate that GRBs occur predominately in low metallicity (Z) environments, which may resolve the problem: lower Z leads to less mass loss, which may inhibit angular momentum removal, allowing WR stars to remain rotating rapidly until collapse. We wish to determine whether low Z WR stars rotate on average more rapidly than Galactic WR stars, and perform a Very Large Telescope (VLT) linear spectropolarimetry survey of WR stars in the low Z environment of the Large Magellanic Cloud (LMC) and compare our results with the Galactic sample. We find that only 2 out of 13 (i.e. 15%) of LMC WR stars show line polarization effects, compared to a similarly low fraction of ~15-20% for Galactic WR stars. The low incidence of line polarization effects in LMC WR stars suggests that the threshold metallicity where significant differences in WR rotational properties occur is below that of the LMC (Z ~ 0.5 Zsun), possibly constraining GRB progenitor channels to this upper metallicity.  ", "human_text": "  The favoured progenitors of long-duration gamma-ray bursts (GRBs) are rapidly rotating Wolf-Rayet (WR) stars. However, most Galactic WR stars are slow rotators, as stellar winds are thought to remove angular momentum. This poses a challenge to the collapsar model. Recent observations indicate that GRBs occur predominately in low metallicity (Z) environments, which may resolve the problem: lower Z leads to less mass loss, which may inhibit angular momentum removal, allowing WR stars to remain rotating rapidly until collapse. We wish to determine whether low Z WR stars rotate on average more rapidly than Galactic WR stars, and perform a Very Large Telescope (VLT) linear spectropolarimetry survey of WR stars in the low Z environment of the Large Magellanic Cloud (LMC) and compare our results with the Galactic sample. We find that only 2 out of 13 (i.e. 15%) of LMC WR stars show line polarization effects, compared to a similarly low fraction of ~15-20% for Galactic WR stars. The low incidence of line polarization effects in LMC WR stars suggests that the threshold metallicity where significant differences in WR rotational properties occur is below that of the LMC (Z ~ 0.5 Zsun), possibly constraining GRB progenitor channels to this upper metallicity. ", "machine_text": " This study aimed to investigate whether GRB progenitors, namely rapidly rotating Wolf-Rayet (WR) stars, could be constrained by the low-metallicity environment of the Large Magellanic Cloud (LMC). To this end, observations using the Very Large Telescope (VLT) linear spectropolarimetry were carried out on WR stars in the LMC and compared with those from the Galactic sample. We found that only 15% of LMC WR stars showed line polarization effects, similar to the Galactic samples. This suggests that the threshold metallicity where a difference in WR rotational properties occurs is less than that of the LMC (i.e. < 0.5 Zsun). This may in turn imply that GRB progenitor channels are limited to this upper metallicity.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.269}
{"prompt": "Rephrase the abstract of an article with title 'Anisotropic Locations of Satellite Galaxies: Clues to the Orientations   of Galaxies within their Dark Matter Halos'.   We investigate the locations of the satellites of relatively isolated host galaxies in the Sloan Digital Sky Survey and the Millennium Run simulation. Provided we use two distinct prescriptions to embed luminous galaxies within the simulated dark matter halos (ellipticals share the shapes of their halos, while disks have angular momenta that are aligned with the net angular momenta of their halos), we find a fair agreement between observation and theory. Averaged over scales r_p \\le 500 kpc, the satellites of red, high-mass hosts with low star formation rates are found preferentially near the major axes of their hosts. In contrast, the satellites of blue, low-mass hosts with low star formation rates show little to no anisotropy when averaged over the same scale. The difference between the locations of the satellites of red and blue hosts cannot be explained by the effects of interlopers in the data. Instead, it is caused primarily by marked differences in the dependence of the mean satellite location, <\\phi>, on the projected distance at which the satellites are found. We also find that the locations of red, high-mass satellites with low star formation rates show considerably more anisotropy than do the locations of blue, low--mass satellites with high star formation rates. There are two contributors to this result. First, the blue satellites have only recently arrived within their hosts' halos, while the red satellites arrived in the far distant past. Second, the sample of blue satellites is heavily contaminated by interlopers, which suppresses the measured anisotropy compared to the intrinsic anisotropy.  ", "human_text": "  We investigate the locations of the satellites of relatively isolated host galaxies in the Sloan Digital Sky Survey and the Millennium Run simulation. Provided we use two distinct prescriptions to embed luminous galaxies within the simulated dark matter halos (ellipticals share the shapes of their halos, while disks have angular momenta that are aligned with the net angular momenta of their halos), we find a fair agreement between observation and theory. Averaged over scales r_p \\le 500 kpc, the satellites of red, high-mass hosts with low star formation rates are found preferentially near the major axes of their hosts. In contrast, the satellites of blue, low-mass hosts with low star formation rates show little to no anisotropy when averaged over the same scale. The difference between the locations of the satellites of red and blue hosts cannot be explained by the effects of interlopers in the data. Instead, it is caused primarily by marked differences in the dependence of the mean satellite location, <\\phi>, on the projected distance at which the satellites are found. We also find that the locations of red, high-mass satellites with low star formation rates show considerably more anisotropy than do the locations of blue, low--mass satellites with high star formation rates. There are two contributors to this result. First, the blue satellites have only recently arrived within their hosts' halos, while the red satellites arrived in the far distant past. Second, the sample of blue satellites is heavily contaminated by interlopers, which suppresses the measured anisotropy compared to the intrinsic anisotropy. ", "machine_text": " In this article, we explore the positioning of isolated satellites of host galaxies in the Sloan Digital Sky Survey and the Millennium Run simulation in comparison. We discover a good correspondence between the observations and the theory when two distinct prescriptions to embed luminous galaxies within the simulated dark matter halos are applied. Looking at scales of up to 500 kpc, it is evident that the satellites of red hosts with low star formation rates are generally situated near the host's major axes, whereas the satellites orbiting blue, low-mass hosts with similar star formation rates show very little anisotropy. The difference in the positioning of the blue and red satellites likely stems from the varying dependence of their mean location in relation to the projected distance between them and the interloper contamination in the latter sample. Furthermore, the red satellites exhibit much greater anisotropy than the blue due to their ancient arrival date in their hosts' halos as well as the lower anisotropy rate because of the interloper pollution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3441}
{"prompt": "Rephrase the abstract of an article with title 'Dirac Neutrino Dark Matter'.   We investigate the possibility that dark matter is made of heavy Dirac neutrinos with mass in the range [O(1) GeV- a few TeV] and with suppressed but non-zero coupling to the Standard Model Z as well as a coupling to an additional Z' gauge boson. The first part of this paper provides a model-independent analysis for the relic density and direct detection in terms of four main parameters: the mass, the couplings to the Z, to the Z' and to the Higgs. These WIMP candidates arise naturally as Kaluza-Klein states in extra-dimensional models with extended electroweak gauge group SU(2)_L* SU(2)_R * U(1). They can be stable because of Kaluza-Klein parity or of other discrete symmetries related to baryon number for instance, or even, in the low mass and low coupling limits, just because of a phase-space-suppressed decay width. An interesting aspect of warped models is that the extra Z' typically couples only to the third generation, thus avoiding the usual experimental constraints. In the second part of the paper, we illustrate the situation in details in a warped GUT model.  ", "human_text": "  We investigate the possibility that dark matter is made of heavy Dirac neutrinos with mass in the range [O(1) GeV- a few TeV] and with suppressed but non-zero coupling to the Standard Model Z as well as a coupling to an additional Z' gauge boson. The first part of this paper provides a model-independent analysis for the relic density and direct detection in terms of four main parameters: the mass, the couplings to the Z, to the Z' and to the Higgs. These WIMP candidates arise naturally as Kaluza-Klein states in extra-dimensional models with extended electroweak gauge group SU(2)_L* SU(2)_R * U(1). They can be stable because of Kaluza-Klein parity or of other discrete symmetries related to baryon number for instance, or even, in the low mass and low coupling limits, just because of a phase-space-suppressed decay width. An interesting aspect of warped models is that the extra Z' typically couples only to the third generation, thus avoiding the usual experimental constraints. In the second part of the paper, we illustrate the situation in details in a warped GUT model. ", "machine_text": "This article investigates the potential of Dirac Neutrinos as the composition of dark matter. A model-independent summary is given of the four main parameters determining the relic density and direct detection: mass, couplings to the Z, to the Z' and to the Higgs. The article additionally explores how extended electroweak gauge groups and discrete symmetries allow for these WIMP candidates to be stable, as well as describing how the extra Z' tends to couple mainly to the third generation, therefore avoiding various existing constraints. Ultimately, a warped GUT model is used to illustrate the situation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0526}
{"prompt": "Rephrase the abstract of an article with title 'An X-ray Survey in SA 57 with XMM-Newton'.   The maximum number density of Active Galactic Nuclei (AGNs), as deduced from X-ray studies, occurs at z<~1, with lower luminosity objects peaking at smaller redshifts. Optical studies lead to a different evolutionary behaviour, with a number density peaking at z~2 independently of the intrinsic luminosity, but this result is limited to active nuclei brighter than the host galaxy. A selection based on optical variability can detect low luminosity AGNs (LLAGNs), where the host galaxy light prevents the identification by non-stellar colours. We want to collect X-ray data in a field where it exists an optically-selected sample of \"variable galaxies'', i.e. variable objects with diffuse appearance, to investigate the X-ray and optical properties of the population of AGNs, particularly of low luminosity ones, where the host galaxy is visible. We observed a field of 0.2 deg^2 in the Selected Area 57, for 67ks with XMM-Newton. We detected X-ray sources, and we correlated the list with a photographic survey of SA 57, complete to B_J~23 and with available spectroscopic data. We obtained a catalogue of 140 X-ray sources to limiting fluxes 5x10^-16, 2x10^-15 erg/cm^2/s in the 0.5-2 keV and 2-10 keV respectively, 98 of which are identified in the optical bands. The X-ray detection of part of the variability-selected candidates confirms their AGN nature. Diffuse variable objects populate the low luminosity side of the sample. Only 25/44 optically-selected QSOs are detected in X-rays. 15% of all QSOs in the field have X/O<0.1.  ", "human_text": "  The maximum number density of Active Galactic Nuclei (AGNs), as deduced from X-ray studies, occurs at z<~1, with lower luminosity objects peaking at smaller redshifts. Optical studies lead to a different evolutionary behaviour, with a number density peaking at z~2 independently of the intrinsic luminosity, but this result is limited to active nuclei brighter than the host galaxy. A selection based on optical variability can detect low luminosity AGNs (LLAGNs), where the host galaxy light prevents the identification by non-stellar colours. We want to collect X-ray data in a field where it exists an optically-selected sample of \"variable galaxies'', i.e. variable objects with diffuse appearance, to investigate the X-ray and optical properties of the population of AGNs, particularly of low luminosity ones, where the host galaxy is visible. We observed a field of 0.2 deg^2 in the Selected Area 57, for 67ks with XMM-Newton. We detected X-ray sources, and we correlated the list with a photographic survey of SA 57, complete to B_J~23 and with available spectroscopic data. We obtained a catalogue of 140 X-ray sources to limiting fluxes 5x10^-16, 2x10^-15 erg/cm^2/s in the 0.5-2 keV and 2-10 keV respectively, 98 of which are identified in the optical bands. The X-ray detection of part of the variability-selected candidates confirms their AGN nature. Diffuse variable objects populate the low luminosity side of the sample. Only 25/44 optically-selected QSOs are detected in X-rays. 15% of all QSOs in the field have X/O<0.1. ", "machine_text": " We conducted a 67 ks X-ray survey in the SA 57 area with XMM-Newton to examine the X-ray and optical properties of a population of AGNs, particularly of low-luminosity AGNs, as well as to detect diffuse and variable objects. Our resulting catalogue of 140 X-ray sources has a limiting flux of 5x10^-16, 2x10^-15 erg/cm^2/s in the 0.5-2 keV and 2-10 keV, respectively. We confirm the AGN nature of some of the optically-selected variables by their X-ray detection, however, only 25 out of 44 optically-selected quasars were detected. The results indicate that variable objects may be mostly low-lumiosity and 15% of all quasars in the field have X/O<0.1.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3552}
{"prompt": "Rephrase the abstract of an article with title 'Glimpsing through the high redshift neutral hydrogen fog'.   We analyze the transmitted flux in a sample of 17 QSOs spectra at 5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral hydrogen fraction, xHI, at z~6. We study separately the narrow transmission windows (peaks) and the wide dark portions (gaps) in the observed absorption spectra. By comparing the statistics of these spectral features with Lyalpha forest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at z=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The frequency and physical sizes of the peaks imply an origin in cosmic underdense regions and/or in HII regions around faint quasars or galaxies. In one case (the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along the LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density is explained by the first-ever detected transverse proximity effect in the HI Lyalpha forest; this indicates that at least some peaks result from a locally enhanced radiation field. We then obtain a strong lower limit on the foreground QSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be systematically larger than the simulated ones. Reasons for such discrepancy might reside either in the photoionization equilibrium assumption or in radiative transfer effects.  ", "human_text": "  We analyze the transmitted flux in a sample of 17 QSOs spectra at 5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral hydrogen fraction, xHI, at z~6. We study separately the narrow transmission windows (peaks) and the wide dark portions (gaps) in the observed absorption spectra. By comparing the statistics of these spectral features with Lyalpha forest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at z=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The frequency and physical sizes of the peaks imply an origin in cosmic underdense regions and/or in HII regions around faint quasars or galaxies. In one case (the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along the LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density is explained by the first-ever detected transverse proximity effect in the HI Lyalpha forest; this indicates that at least some peaks result from a locally enhanced radiation field. We then obtain a strong lower limit on the foreground QSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be systematically larger than the simulated ones. Reasons for such discrepancy might reside either in the photoionization equilibrium assumption or in radiative transfer effects. ", "machine_text": " Analyzing 17 QSO spectra in a redshift range of 5.74<zem<6.42, we make an attempt to obtain a precise estimate of the ratio of neutral hydrogen atoms to the total number of hydrogen atoms in the extensive volumes of the universe at z~6. Performing a Ly\u03b1 forest simulation, we infer that xHI (the volume-averaged neutral hydrogen fraction) increases steadily from 10^-4.4 at z=5.3 to 10^-4.2 at z=5.6. The maximal upper limit is 0.36 at z=6.3. Examining the transmission windows or peaks, as well as the wide dark portions or gaps occurring between them, we infer that they stem from a mixture of cosmological underdensities and HII areas around faint quasars or galaxies. We observe a transverse proximity effect in the HI Ly\u03b1 forest in the case of the intervening HII region of a faint quasar located at z=5.70 and its impact on SDSS J1148+5251 at z=6.42, the first of its kind. This interlock provides a lower limit for the lifetime of the foreground quasar of 11 million years at least. The widths of the detected peaks seem broader than the simulated ones, suggesting that either the assumption of the photoionization equilibrium is flawed or radiative transfer effects are in play.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1053}
{"prompt": "Rephrase the abstract of an article with title 'The aqueous and crystalline forms of L-alanine zwitterion'.   The structural properties of L-alanine amino acid in aqueous solution and in crystalline phase have been studied by means of density-functional electronic-structure and molecular dynamics simulations. The solvated zwitterionic structure of L-alanine (+NH3-C2H4-COO-) was systematically compared to the structure of its zwitterionic crystalline analogue acquired from both computer simulations and experiments. It turns out that the structural properties of an alanine molecule in aqueous solution can differ significantly from those in crystalline phase, these differences being mainly attributed to hydrogen bonding interactions. In particular, we found that the largest difference between the two alanine forms can be seen for the orientation and bond lengths of the carboxylate (COO-) group: in aqueous solution the C-O bond lengths appear to strongly correlate with the number of water molecules which form hydrogen bonds with the COO- group. Furthermore, the hydrogen bond lengths are shorter and the hydrogen bond angles are larger for L-alanine in water as compared to crystal. Overall, our findings strongly suggest that the generally accepted approach of extending the structural information acquired from crystallographic data to a L-alanine molecule in aqueous solution should be used with caution.  ", "human_text": "  The structural properties of L-alanine amino acid in aqueous solution and in crystalline phase have been studied by means of density-functional electronic-structure and molecular dynamics simulations. The solvated zwitterionic structure of L-alanine (+NH3-C2H4-COO-) was systematically compared to the structure of its zwitterionic crystalline analogue acquired from both computer simulations and experiments. It turns out that the structural properties of an alanine molecule in aqueous solution can differ significantly from those in crystalline phase, these differences being mainly attributed to hydrogen bonding interactions. In particular, we found that the largest difference between the two alanine forms can be seen for the orientation and bond lengths of the carboxylate (COO-) group: in aqueous solution the C-O bond lengths appear to strongly correlate with the number of water molecules which form hydrogen bonds with the COO- group. Furthermore, the hydrogen bond lengths are shorter and the hydrogen bond angles are larger for L-alanine in water as compared to crystal. Overall, our findings strongly suggest that the generally accepted approach of extending the structural information acquired from crystallographic data to a L-alanine molecule in aqueous solution should be used with caution. ", "machine_text": " The structural properties of the L-alanine amino acid were examined through density-functional electronic-structure and molecular dynamics simulations in both aqueous and crystalline form. It was found that the two forms of L-alanine can be significantly different in terms of hydrogen bonding interactions, with the bond lengths and angles of the carboxylate (COO-) group distinguished. The analysis suggests that the bond lengths of the C-O bonds are directly related to the number of water molecules interacting with the COO- unit, which tend to be longer in the crystalline form of the amino acid. The hydrogen bond lengths and angles are also observed to be shorter and larger in the aqueous form compared to the crystalline one. Consequently, our results imply that the information obtained from crystallographic data should be used with care when applied to the aqueous form of L-alanine.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.27}
{"prompt": "Rephrase the abstract of an article with title 'Investigations of the Non-Linear LMC Cepheid Period-Luminosity Relation   with Testimator and Schwarz Information Criterion Methods'.   In this paper, we investigate the linearity versus non-linearity of the Large Magellanic Cloud (LMC) Cepheid period-luminosity (P-L) relation using two statistical approaches not previously applied to this problem: the testimator method and the Schwarz Information Criterion (SIC). The testimator method is extended to multiple stages for the first time, shown to be unbiased and the variance of the estimated slope can be proved to be smaller than the standard slope estimated from linear regression theory. The Schwarz Information Criterion (also known as the Bayesian Information Criterion) is more conservative than the Akaike Information Criterion and tends to choose lower order models. By using simulated data sets, we verify that these statistical techniques can be used to detect intrinsically linear and/or non-linear P-L relations. These methods are then applied to independent LMC Cepheid data sets from the OGLE project and the MACHO project, respectively. Our results imply that there is a change of slope in longer period ranges for all of the data sets. This strongly supports previous results, obtained from independent statistical tests, that the observed LMC P-L relation is non-linear with a break period at/around 10 days.  ", "human_text": "  In this paper, we investigate the linearity versus non-linearity of the Large Magellanic Cloud (LMC) Cepheid period-luminosity (P-L) relation using two statistical approaches not previously applied to this problem: the testimator method and the Schwarz Information Criterion (SIC). The testimator method is extended to multiple stages for the first time, shown to be unbiased and the variance of the estimated slope can be proved to be smaller than the standard slope estimated from linear regression theory. The Schwarz Information Criterion (also known as the Bayesian Information Criterion) is more conservative than the Akaike Information Criterion and tends to choose lower order models. By using simulated data sets, we verify that these statistical techniques can be used to detect intrinsically linear and/or non-linear P-L relations. These methods are then applied to independent LMC Cepheid data sets from the OGLE project and the MACHO project, respectively. Our results imply that there is a change of slope in longer period ranges for all of the data sets. This strongly supports previous results, obtained from independent statistical tests, that the observed LMC P-L relation is non-linear with a break period at/around 10 days. ", "machine_text": "In this research, we utilize two analytical methods, the testimator method and the Schwarz Information Criterion (SIC), to examine the linearity of the Large Magellanic Cloud Cepheid period-luminosity (P-L) relation. We demonstrate that the testimator approach is both unbiased and reduces the variance of the estimated slope. Applying SIC proves to be more conservative than the Akaike Information Criterion and usually opts for a lower order. We then apply these strategies to test simulated data sets to examine intrinsically linear or non-linear P-L relations. Ultimately, we apply the methods to independent LMC Cepheid data sets from the OGLE and MACHO projects, which exhibits changes in slope in the longer period ranges in all data sets, suggesting the non-linearity of the observed P-L correlation with a break period at approx. 10 days.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3601}
{"prompt": "Rephrase the abstract of an article with title 'Determination of the size, mass, and density of \"exomoons\" from   photometric transit timing variations'.   Precise photometric measurements of the upcoming space missions allow the size, mass, and density of satellites of exoplanets to be determined. Here we present such an analysis using the photometric transit timing variation ($TTV_p$). We examined the light curve effects of both the transiting planet and its satellite. We define the photometric central time of the transit that is equivalent to the transit of a fixed photocenter. This point orbits the barycenter, and leads to the photometric transit timing variations. The exact value of $TTV_p$ depends on the ratio of the density, the mass, and the size of the satellite and the planet. Since two of those parameters are independent, a reliable estimation of the density ratio leads to an estimation of the size and the mass of the exomoon. Upper estimations of the parameters are possible in the case when an upper limit of $TTV_p$ is known. In case the density ratio cannot be estimated reliably, we propose an approximation with assuming equal densities. The presented photocenter $TTV_p$ analysis predicts the size of the satellite better than the mass. We simulated transits of the Earth-Moon system in front of the Sun. The estimated size and mass of the Moon are 0.020 Earth-mass and 0.274 Earth-size if equal densities are assumed. This result is comparable to the real values within a factor of 2. If we include the real density ratio (about 0.6), the results are 0.010 Earth-Mass and 0.253 Earth-size, which agree with the real values within 20%.  ", "human_text": "  Precise photometric measurements of the upcoming space missions allow the size, mass, and density of satellites of exoplanets to be determined. Here we present such an analysis using the photometric transit timing variation ($TTV_p$). We examined the light curve effects of both the transiting planet and its satellite. We define the photometric central time of the transit that is equivalent to the transit of a fixed photocenter. This point orbits the barycenter, and leads to the photometric transit timing variations. The exact value of $TTV_p$ depends on the ratio of the density, the mass, and the size of the satellite and the planet. Since two of those parameters are independent, a reliable estimation of the density ratio leads to an estimation of the size and the mass of the exomoon. Upper estimations of the parameters are possible in the case when an upper limit of $TTV_p$ is known. In case the density ratio cannot be estimated reliably, we propose an approximation with assuming equal densities. The presented photocenter $TTV_p$ analysis predicts the size of the satellite better than the mass. We simulated transits of the Earth-Moon system in front of the Sun. The estimated size and mass of the Moon are 0.020 Earth-mass and 0.274 Earth-size if equal densities are assumed. This result is comparable to the real values within a factor of 2. If we include the real density ratio (about 0.6), the results are 0.010 Earth-Mass and 0.253 Earth-size, which agree with the real values within 20%. ", "machine_text": "   Photometric measurements taken by forthcoming space missions allow us to determine the size, mass, and density of exoplanets' satellites. We have conducted an analysis on the photometric transit timing variation ($TTV_p$) to analyze the light curve effects of the transiting planet and its satellite. We introduce the concept of the 'photocenter' time of the transit, which is equivalent to the transit of a fixed photocenter that orbits the barycenter, resulting in the photometric transit timing variations whose exact value depends on the ratio of the density, mass, and size of the satellite and the planet. When the density ratio is known, it permits a reliable estimation of the size and mass of an exomoon. An upper limit of $TTV_p$ can be set if the density ratio cannot be estimated accurately. We tested this method on the Earth-Moon system transit in front of the Sun and found that when assuming similar densities, the estimated size and mass of the Moon (0.020 Earth-mass and 0.274 Earth-size) were comparable to the real values within a factor of 2. When using the real density ratio (about 0.6), the results were 0.010 Earth-Mass and 0.253 Earth-size, which showed agreement with the true values within 20%.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1046}
{"prompt": "Rephrase the abstract of an article with title 'Is There a Universal Mass Function?'.   Following an old idea of Fritz Zwicky, we make an attempt to establish a universal mass function for astronomical objects on all scales. The object classes considered are: solar system planets and small bodies, exoplanets, brown dwarfs, stars and stellar remnants, open and globular clusters, molecular clouds, galaxies, groups and clusters of galaxies. For comparison we also include CDM halos taken from numerical simulations. We show that the mass functions of individual object classes, when properly normalized, can indeed be concatenated to build a surprisingly continuous mass function of the universe, from approximately M = 10^(-20)Msun (sub-kilometer size asteroids) up to M = 10^(16)Msun (rich clusters of galaxies), covering 36 orders of magnitude in mass. Most individual mass functions roughly follow a power law of the form phi(M) propto M^(-2). A notable exception are planets and small bodies which seem to obey a flatter distribution. CDM halos from high-resolution numerical simulations show a very similar relation, again of universal slope -2, from clusters of galaxies all the way down to the planetary mass scale. On the scale of stars and star clusters this is a remarkable coincidence, as the formation processes involved are thought to be totally different (bottom-up gravitational clustering of DM halos versus top-down gravoturbulent fragmentation of gas clouds).  ", "human_text": "  Following an old idea of Fritz Zwicky, we make an attempt to establish a universal mass function for astronomical objects on all scales. The object classes considered are: solar system planets and small bodies, exoplanets, brown dwarfs, stars and stellar remnants, open and globular clusters, molecular clouds, galaxies, groups and clusters of galaxies. For comparison we also include CDM halos taken from numerical simulations. We show that the mass functions of individual object classes, when properly normalized, can indeed be concatenated to build a surprisingly continuous mass function of the universe, from approximately M = 10^(-20)Msun (sub-kilometer size asteroids) up to M = 10^(16)Msun (rich clusters of galaxies), covering 36 orders of magnitude in mass. Most individual mass functions roughly follow a power law of the form phi(M) propto M^(-2). A notable exception are planets and small bodies which seem to obey a flatter distribution. CDM halos from high-resolution numerical simulations show a very similar relation, again of universal slope -2, from clusters of galaxies all the way down to the planetary mass scale. On the scale of stars and star clusters this is a remarkable coincidence, as the formation processes involved are thought to be totally different (bottom-up gravitational clustering of DM halos versus top-down gravoturbulent fragmentation of gas clouds). ", "machine_text": " In this paper we attempt to determine whether a universal mass function exists for all types of astronomical bodies. We identify nine distinct categories, including solar systems, exoplanets, brown dwarfs, stars, stellar remnants, open and globular clusters, molecular clouds, galaxies, and clusters of galaxies, along with data from high resolution numerical simulations of CDM halos. We conclude that the mass functions of each individual class, when normalized correctly, can indeed be combined to form an uninterrupted universal mass function ranging from mass values of 10^(-20)Msun to 10^(16)Msun, and spaning 36 orders of magnitude. A notable exception is seen with planets and small bodies, which appear to obey a flatter distribution. Remarkably, CDM halos from the simulations indicate a relation with a slope of -2 from galactic clusters to the planetary mass scale. This similarity is of great interest, as the formation processes for these objects are thought to be vastly different.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1599}
{"prompt": "Rephrase the abstract of an article with title 'Dahlberg's bilinear estimate for solutions of divergence form complex   elliptic equations'.   We consider divergence form elliptic operators $L=-\\dv A(x)\\nabla$, defined in $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$, where the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly elliptic, complex and $t$-independent. Using recently obtained results concerning the boundedness and invertibility of layer potentials associated to such operators, we show that if $Lu=0$ in $\\mathbb{R}^{n+1}_+$, then for any vector-valued ${\\bf v} \\in W^{1,2}_{loc},$ we have the bilinear estimate $$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq C\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| + \\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv (\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is the usual non-tangential maximal operator. The result is new even in the case of real symmetric coefficients, and generalizes the analogous result of Dahlberg for harmonic functions on Lipschitz graph domains.  ", "human_text": "  We consider divergence form elliptic operators $L=-\\dv A(x)\\nabla$, defined in $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$, where the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly elliptic, complex and $t$-independent. Using recently obtained results concerning the boundedness and invertibility of layer potentials associated to such operators, we show that if $Lu=0$ in $\\mathbb{R}^{n+1}_+$, then for any vector-valued ${\\bf v} \\in W^{1,2}_{loc},$ we have the bilinear estimate $$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq C\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| + \\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv (\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is the usual non-tangential maximal operator. The result is new even in the case of real symmetric coefficients, and generalizes the analogous result of Dahlberg for harmonic functions on Lipschitz graph domains. ", "machine_text": "  We analyze the boundedness and invertibility of layer potentials associated to divergence form complex elliptic operators $L=-\\dv A(x)\\nabla$, where $A$ is a $L^{\\infty}$ coefficient matrix of size $(n+1)\\times(n+1)$, uniform elliptic and $t$-independent in $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$. Using the aforementioned results, we establish a new bilinear estimate for any ${\\bf v} \\in W^{1,2}_{loc}$. This is $$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq C\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| + \\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv (\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is the standard non-tangential maximal operator. This estimate can be applied for solutions of $Lu=0$ in $\\mathbb{R}^{n+1}_+$, and it is novel even when the coefficients are real and symmetric. Furthermore, it is a generalization of the analogous result by Dahlberg for harmonic functions on Lipschitz graph domains.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0839}
{"prompt": "Rephrase the abstract of an article with title 'First proper motions of thin dust filaments at the Galactic Center'.   Context: L'-band (3.8 micron) images of the Galactic Center show a large number of thin filaments in the mini-spiral, located west of the mini-cavity and along the inner edge of the Northern Arm. One possible mechanism that could produce such structures is the interaction of a central wind with the mini-spiral. Additionally, we identify similar features that appear to be associated with stars. Aims: We present the first proper motion measurements of the thin dust filaments observed in the central parsec around SgrA* and investigate possible mechanisms that could be responsible for the observed motions. Methods: The observations have been carried out using the NACO adaptive optics system at the ESO VLT. The images have been transformed to a common coordinate system and features of interest were extracted. Then a cross-correlation technique could be performed in order to determine the offsets between the features with respect to their position in the reference epoch. Results: We derive the proper motions of a number of filaments and 2 cometary shaped dusty sources close (in projection) to SgrA*. We show that the shape and the motion of the filaments does not agree with a purely Keplerian motion of the gas in the potential of the supermassive black hole at the position of SgrA*. Therefore, additional mechanisms must be responsible for their formation and motion. We argue that the properties of the filaments are probably related to an outflow from the disk of young mass-losing stars around SgrA*. In part, the outflow may originate from the black hole itself. We also present some evidence and theoretical considerations that the outflow may be collimated.  ", "human_text": "  Context: L'-band (3.8 micron) images of the Galactic Center show a large number of thin filaments in the mini-spiral, located west of the mini-cavity and along the inner edge of the Northern Arm. One possible mechanism that could produce such structures is the interaction of a central wind with the mini-spiral. Additionally, we identify similar features that appear to be associated with stars. Aims: We present the first proper motion measurements of the thin dust filaments observed in the central parsec around SgrA* and investigate possible mechanisms that could be responsible for the observed motions. Methods: The observations have been carried out using the NACO adaptive optics system at the ESO VLT. The images have been transformed to a common coordinate system and features of interest were extracted. Then a cross-correlation technique could be performed in order to determine the offsets between the features with respect to their position in the reference epoch. Results: We derive the proper motions of a number of filaments and 2 cometary shaped dusty sources close (in projection) to SgrA*. We show that the shape and the motion of the filaments does not agree with a purely Keplerian motion of the gas in the potential of the supermassive black hole at the position of SgrA*. Therefore, additional mechanisms must be responsible for their formation and motion. We argue that the properties of the filaments are probably related to an outflow from the disk of young mass-losing stars around SgrA*. In part, the outflow may originate from the black hole itself. We also present some evidence and theoretical considerations that the outflow may be collimated. ", "machine_text": "  This paper presents the first proper motion measurements of thin dust filaments observed in the central parsec around the supermassive black hole SgrA*. We show that the shape and motion of the filaments does not match the expected Keplerian motion in the gravitational potential of SgrA*. Using the NACO adaptive optics system at the ESO VLT, we measure the offsets between features with respect to their position in a reference epoch in order to determine the proper motions of filaments and two sources close to SgrA*. We propose that the formation and motion of the filaments may be related to an outflow coming from a disk of young mass-losing stars and/or the black hole itself, which could be collimated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3675}
{"prompt": "Rephrase the abstract of an article with title 'Extended Optical Model Analyses of Elastic Scattering and Fusion Cross   Section Data for the 7Li+208Pb System at Near-Coulomb-Barrier Energies using   the Folding Potential'.   Simultaneous $\\chi^{2}$ analyses previously made for elastic scattering and fusion cross section data for the $^{6}$Li+$^{208}$Pb system is extended to the $^{7}$Li+$^{208}$Pb system at near-Coulomb-barrier energies based on the extended optical model approach, in which the polarization potential is decomposed into direct reaction (DR) and fusion parts. Use is made of the double folding potential as a bare potential. It is found that the experimental elastic scattering and fusion data are well reproduced without introducing any normalization factor for the double folding potential and that both the DR and fusion parts of the polarization potential determined from the $\\chi^{2}$ analyses satisfy separately the dispersion relation. Further, we find that the real part of the fusion portion of the polarization potential is attractive while that of the DR part is repulsive except at energies far below the Coulomb barrier energy. A comparison is made of the present results with those obtained from the Continuum Discretized Coupled Channel (CDCC) calculations and a previous study based on the conventional optical model with a double folding potential. We also compare the present results for the $^7$Li+$^{208}$Pb system with the analysis previously made for the $^{6}$Li+$^{208}$Pb system.  ", "human_text": "  Simultaneous $\\chi^{2}$ analyses previously made for elastic scattering and fusion cross section data for the $^{6}$Li+$^{208}$Pb system is extended to the $^{7}$Li+$^{208}$Pb system at near-Coulomb-barrier energies based on the extended optical model approach, in which the polarization potential is decomposed into direct reaction (DR) and fusion parts. Use is made of the double folding potential as a bare potential. It is found that the experimental elastic scattering and fusion data are well reproduced without introducing any normalization factor for the double folding potential and that both the DR and fusion parts of the polarization potential determined from the $\\chi^{2}$ analyses satisfy separately the dispersion relation. Further, we find that the real part of the fusion portion of the polarization potential is attractive while that of the DR part is repulsive except at energies far below the Coulomb barrier energy. A comparison is made of the present results with those obtained from the Continuum Discretized Coupled Channel (CDCC) calculations and a previous study based on the conventional optical model with a double folding potential. We also compare the present results for the $^7$Li+$^{208}$Pb system with the analysis previously made for the $^{6}$Li+$^{208}$Pb system. ", "machine_text": " The advanced optical model is employed to analyze dynamically the simultaneous $\\chi^2$ for both elastic scattering and fusion cross section data for $^7$Li+$^{208}$Pb at near-Coulomb-barrier energies. A double folding potential is used as the bare potential and no normalization is needed to explain the experimental data. The decomposition of the polarization potential into direct reaction (DR) and fusion parts indicates that the fusion part is attractive while the DR part is repulsive, apart from energies beneath the Coulomb barrier. We compare the current study with CDCC calculations and an earlier optical model study using a double folding potential. Additionally, the current results are contrasted with the previous analysis on the $^6$Li+$^{208}$Pb system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0586}
{"prompt": "Rephrase the abstract of an article with title 'The Reliability on the Direction of the Incident Neutrino for the Fully   Contained Events and Partially Contained Events due to QEL in the   Super-Kamiokande'.   In the SK analysis of the neutrino events for [Fully Contained Events] and [Partially Contained Events] on their zenith angle distribution, it is assumed that the zenith angle of the incident neutrino is the same as that of the detected charged lepton. In the present paper, we examine the validity of [the SK assumption on the direction] of the incident neutrinos. Concretely speaking, we analyze muon-like events due to QEL. For the purpose, we develop [Time Sequential Monte Carlo Simulation] to extract the conclusion on the validity of the SK assumption. In our [Time Sequential Simulation], we simulate every physical process concerned as exactly as possible without any approximation.   From the comparison between the zenith angle distributon of the emitted muons under [the SK assumption on the direction] and the corresponding one obtained under our [Time Sequential Simulation], it is concluded that the measurement of the direction of the incident neutrino for the neutrino events occurring inside the detector in the SK analysis turns out to be unreliable, which holds irrespective of the existence and/or non-existence of the neutrino oscillation.  ", "human_text": "  In the SK analysis of the neutrino events for [Fully Contained Events] and [Partially Contained Events] on their zenith angle distribution, it is assumed that the zenith angle of the incident neutrino is the same as that of the detected charged lepton. In the present paper, we examine the validity of [the SK assumption on the direction] of the incident neutrinos. Concretely speaking, we analyze muon-like events due to QEL. For the purpose, we develop [Time Sequential Monte Carlo Simulation] to extract the conclusion on the validity of the SK assumption. In our [Time Sequential Simulation], we simulate every physical process concerned as exactly as possible without any approximation.   From the comparison between the zenith angle distributon of the emitted muons under [the SK assumption on the direction] and the corresponding one obtained under our [Time Sequential Simulation], it is concluded that the measurement of the direction of the incident neutrino for the neutrino events occurring inside the detector in the SK analysis turns out to be unreliable, which holds irrespective of the existence and/or non-existence of the neutrino oscillation. ", "machine_text": " In this article, we analyze the validity of the SK assumption that the direction of the incident neutrino is the same as that of the detected charged lepton for Fully Contained Events and Partially Contained Events due to QEL. We develop a Time Sequential Monte Carlo Simulation to simulate every physical process concerned in order to determine the accuracy of this SK assumption. By comparing the zenith angle distribution of the emitted muons under the SK assumption and the one produced by the Time Sequential Simulation, we conclude that the measurement of the direction of the incident neutrino for the events occurring inside the detector in the SK analysis is not reliable, regardless of whether or not neutrino oscillation exists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.019}
{"prompt": "Rephrase the abstract of an article with title 'Tight binding formulation of the dielectric response in semiconductor   nanocrystals'.   We report on a theoretical derivation of the electronic dielectric response of semiconductor nanocrystals using a tight-binding framework. Extending to the nanoscale the Hanke and Sham approach [Phys. Rev. B 12, 4501 (1975)] developed for bulk semiconductors, we show how local field effects can be included in the study of confined systems. A great advantage of this scheme is that of being formulated in terms of localized orbitals and thus it requires very few computational resources and times. Applications to the optical and screening properties of semiconductor nanocrystals are presented here and discussed. Results concerning the absorption cross section, the static polarizability and the screening function of InAs (direct gap) and Si (indirect gap) nanocrystals compare well to both first principles results and experimental data. We also show that the present scheme allows us to easily go beyond the continuum dielectric model, based on the Clausius-Mossotti equation, which is frequently used to include the nanocrystal surface polarization. Our calculations indicate that the continuum dielectric model, used in conjunction with a size dependent dielectric constant, underestimates the nanocrystal polarizability, leading to exceedingly strong surface polarization fields.  ", "human_text": "  We report on a theoretical derivation of the electronic dielectric response of semiconductor nanocrystals using a tight-binding framework. Extending to the nanoscale the Hanke and Sham approach [Phys. Rev. B 12, 4501 (1975)] developed for bulk semiconductors, we show how local field effects can be included in the study of confined systems. A great advantage of this scheme is that of being formulated in terms of localized orbitals and thus it requires very few computational resources and times. Applications to the optical and screening properties of semiconductor nanocrystals are presented here and discussed. Results concerning the absorption cross section, the static polarizability and the screening function of InAs (direct gap) and Si (indirect gap) nanocrystals compare well to both first principles results and experimental data. We also show that the present scheme allows us to easily go beyond the continuum dielectric model, based on the Clausius-Mossotti equation, which is frequently used to include the nanocrystal surface polarization. Our calculations indicate that the continuum dielectric model, used in conjunction with a size dependent dielectric constant, underestimates the nanocrystal polarizability, leading to exceedingly strong surface polarization fields. ", "machine_text": " This article presents a method for calculating the optical and screening properties of semiconductor nanocrystals using a tight-binding approach. This approach enables the inclusion of local field effects due to the confinement of nanocrystals. Applications to absorption, polarizability and screening functions of InAs and Si nanocrystals show good agreement with first-principles and experimental results. In addition, this method permits examination of the continuum dielectric model commonly employed to account for nanocrystal surface polarization. The differences between this model, which uses a size-dependent dielectric constant, and the approach of this article, which considers local polarization fields, are discussed. Our calculations suggest that the continuum dielectric model underestimates the nanocrystal polarizability, leading to notably strong surface polarization fields.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2163}
{"prompt": "Rephrase the abstract of an article with title 'A study of the evolution of the accretion disk of V2051 Oph through two   outburst cycles'.   We follow the changes in the structure of the accretion disk of the dwarf nova V2051 Oph along two separate outbursts in order to investigate the causes of its recurrent outbursts. We apply eclipse mapping techniques to a set of light curves covering a normal (July 2000) and a low-amplitude (August 2002) outburst to derive maps of the disk surface brightness distribution at different phases along the outburst cycles. The sequence of eclipse maps of the 2000 July outburst reveal that the disk shrinks at outburst onset while an uneclipsed component of 13 per cent of the total light develops. The derived radial intensity distributions suggest the presence of an outward-moving heating wave during rise and of an inward-moving cooling wave during decline. The inferred speed of the outward-moving heating wave is ~ 1.6 km/s, while the speed of the cooling wave is a fraction of that. A comparison of the measured cooling wave velocity on consecutive nights indicates that the cooling wave accelerates as it travels towards disk center, in contradiction with the prediction of the disk instability model. From the inferred speed of the heating wave we derive a viscosity parameter alpha_{hot} ~ 0.13, comparable to the measured viscosity parameter in quiescence. The 2002 August outburst had lower amplitude (\\Delta B ~ 0.8 mag) and the disk at outburst maximum was smaller than on 2000 July. For an assumed distance of 92 pc, we find that along both outbursts the disk brightness temperatures remain below the minimum expected according to the disk instability model. The results suggest that the outbursts of V2051 Oph are caused by bursts of increased mass transfer from the mass-donor star.  ", "human_text": "  We follow the changes in the structure of the accretion disk of the dwarf nova V2051 Oph along two separate outbursts in order to investigate the causes of its recurrent outbursts. We apply eclipse mapping techniques to a set of light curves covering a normal (July 2000) and a low-amplitude (August 2002) outburst to derive maps of the disk surface brightness distribution at different phases along the outburst cycles. The sequence of eclipse maps of the 2000 July outburst reveal that the disk shrinks at outburst onset while an uneclipsed component of 13 per cent of the total light develops. The derived radial intensity distributions suggest the presence of an outward-moving heating wave during rise and of an inward-moving cooling wave during decline. The inferred speed of the outward-moving heating wave is ~ 1.6 km/s, while the speed of the cooling wave is a fraction of that. A comparison of the measured cooling wave velocity on consecutive nights indicates that the cooling wave accelerates as it travels towards disk center, in contradiction with the prediction of the disk instability model. From the inferred speed of the heating wave we derive a viscosity parameter alpha_{hot} ~ 0.13, comparable to the measured viscosity parameter in quiescence. The 2002 August outburst had lower amplitude (\\Delta B ~ 0.8 mag) and the disk at outburst maximum was smaller than on 2000 July. For an assumed distance of 92 pc, we find that along both outbursts the disk brightness temperatures remain below the minimum expected according to the disk instability model. The results suggest that the outbursts of V2051 Oph are caused by bursts of increased mass transfer from the mass-donor star. ", "machine_text": " This article examines the alterations to the accretion disk of the dwarf nova V2051 Oph over two separate outbursts. Employing eclipse mapping analysis on light curves from a normal (July 2000) and a low-amplitude (August 2002) outburst, we create maps of the disk surface brightness evolution and trace the motion of heating and cooling waves. Our determinations illustrate that the outward-moving heating wave moved at a rate of ~1.6 km/s, while the inward-cooling wave was much slower, and accelerates as it proceeds towards the middle of the disk. Results imply the outburst of V2051 Oph is activated by augmentations to the mass from the mass donor star, as the disk brightness temperatures remain lower than expected according to the disk instability model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2442}
{"prompt": "Rephrase the abstract of an article with title 'Staggered Heavy Baryon Chiral Perturbation Theory'.   Although taste violations significantly affect the results of staggered calculations of pseudoscalar and heavy-light mesonic quantities, those entering staggered calculations of baryonic quantities have not been quantified. Here I develop staggered chiral perturbation theory in the light-quark baryon sector by mapping the Symanzik action into heavy baryon chiral perturbation theory. For 2+1 dynamical quark flavors, the masses of flavor-symmetric nucleons are calculated to third order in partially quenched and fully dynamical staggered chiral perturbation theory. To this order the expansion includes the leading chiral logarithms, which come from loops with virtual decuplet-like states, as well as terms the order of the cubed pion mass, which come from loops with virtual octet-like states. Taste violations enter through the meson propagators in loops and tree-level terms the order of the squared lattice spacing. The pattern of taste symmetry breaking and the resulting degeneracies and mixings are discussed in detail. The resulting chiral forms are appropriate to lattice results obtained with operators already in use and could be used to study the restoration of taste symmetry in the continuum limit. I assume that the fourth root of the fermion determinant can be incorporated in staggered chiral perturbation theory using the replica method.  ", "human_text": "  Although taste violations significantly affect the results of staggered calculations of pseudoscalar and heavy-light mesonic quantities, those entering staggered calculations of baryonic quantities have not been quantified. Here I develop staggered chiral perturbation theory in the light-quark baryon sector by mapping the Symanzik action into heavy baryon chiral perturbation theory. For 2+1 dynamical quark flavors, the masses of flavor-symmetric nucleons are calculated to third order in partially quenched and fully dynamical staggered chiral perturbation theory. To this order the expansion includes the leading chiral logarithms, which come from loops with virtual decuplet-like states, as well as terms the order of the cubed pion mass, which come from loops with virtual octet-like states. Taste violations enter through the meson propagators in loops and tree-level terms the order of the squared lattice spacing. The pattern of taste symmetry breaking and the resulting degeneracies and mixings are discussed in detail. The resulting chiral forms are appropriate to lattice results obtained with operators already in use and could be used to study the restoration of taste symmetry in the continuum limit. I assume that the fourth root of the fermion determinant can be incorporated in staggered chiral perturbation theory using the replica method. ", "machine_text": "In this article, I investigate the role of taste violations in the results of calculations involving staggered baryonic quantities, presenting a mapping of the Symanzik action into heavy baryon chiral perturbation theory. By calculating the masses of flavor-symmetric nucleons to the third order in both partially quenched and fully dynamical staggered chiral perturbation theory for two plus one dynamical quark flavors, I explain the effects of taste symmetry breaking, the resultant degeneracies, and mixings. The resulting chiral forms are applicable to lattice results obtained with currently used operators, and could be used to analyze the restoration of taste symmetry in the continuum limit. An attempt is made to incorporate the fourth root of the fermion determinant into staggered chiral perturbation theory through the replica method.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.149}
{"prompt": "Rephrase the abstract of an article with title 'Phase Spaces in Special Relativity: Towards Eliminating Gravitational   Singularities'.   This paper shows one way to construct phase spaces in special relativity by expanding Minkowski Space. These spaces appear to indicate that we can dispense with gravitational singularities. The key mathematical ideas in the present approach are to include a complex phase factor, such as, e^{i\\phi} in the Lorentz transformation and to use both the proper time and the proper mass as parameters. To develop the most general case, a complex parameter \\sigma=s+im, is introduced, where s is the proper time, and m is the proper mass, and \\sigma and {\\sigma}/{|\\sigma|} are used to parameterize the position of a particle (or reference frame) in space-time-matter phase space. A new reference variable, u={m}/{r}, is needed (in addition to velocity), and assumed to be bounded by 0 and {c^{2}}/{G}=1, in geometrized units. Several results are derived: The equation E=mc^2 apparently needs to be modified to E^2={s^2c^{10}}/{G^2}+m^2c^4, but a simpler (invariant) parameter is the \"energy to length\" ratio, which is {c^4}/{G} for any spherical region of space-time-matter. The generalized \"momentum vector\" becomes completely \"masslike\" for u\\approx 0.79, which we think indicates the existence of a maximal gravity field. Thus, gravitational singularities do not occur. Instead, as u approaches 1 matter is apparently simply crushed into free space. In the last section of this paper we attempt some further generalizations of the phase space ideas developed in this paper.  ", "human_text": "  This paper shows one way to construct phase spaces in special relativity by expanding Minkowski Space. These spaces appear to indicate that we can dispense with gravitational singularities. The key mathematical ideas in the present approach are to include a complex phase factor, such as, e^{i\\phi} in the Lorentz transformation and to use both the proper time and the proper mass as parameters. To develop the most general case, a complex parameter \\sigma=s+im, is introduced, where s is the proper time, and m is the proper mass, and \\sigma and {\\sigma}/{|\\sigma|} are used to parameterize the position of a particle (or reference frame) in space-time-matter phase space. A new reference variable, u={m}/{r}, is needed (in addition to velocity), and assumed to be bounded by 0 and {c^{2}}/{G}=1, in geometrized units. Several results are derived: The equation E=mc^2 apparently needs to be modified to E^2={s^2c^{10}}/{G^2}+m^2c^4, but a simpler (invariant) parameter is the \"energy to length\" ratio, which is {c^4}/{G} for any spherical region of space-time-matter. The generalized \"momentum vector\" becomes completely \"masslike\" for u\\approx 0.79, which we think indicates the existence of a maximal gravity field. Thus, gravitational singularities do not occur. Instead, as u approaches 1 matter is apparently simply crushed into free space. In the last section of this paper we attempt some further generalizations of the phase space ideas developed in this paper. ", "machine_text": " This article investigates the possibility of constructing phase spaces in special relativity via expanding Minkowski Space. Complex phase factors such as e^{i\\phi} in the Lorentz transformation and the use of both proper time and proper mass as parameters are included to construct the most general case. A new reference variable u={m}/{r}, along with bounded velocity are used to parameterize the position of a particle in the space-time-matter phase space. Equations derived indicate that the E=mc^2 formula needs to be modified, yet a simpler (invariant) parameter is the \"energy to length\" ratio becomes {c^4}/{G}. Furthermore, maximal gravity fields are observed when u\\approx 0.79 instead of a singularity occurring. The article concludes by posing some questions for further generalization on the specified phase space ideas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2043}
{"prompt": "Rephrase the abstract of an article with title 'Quantum simulation of interacting high-dimensional systems: the   influence of noise'.   We consider the simulation of interacting high-dimensional systems using pairwise interacting qubits. The main tool in this context is the generation of effective many-body interactions, and we examine a number of different protocols for obtaining them. These methods include the usage of higher-order processes (commutator method), unitary conjugation or graph state encoding, as well as teleportation based approaches. We illustrate and compare these methods in detail and analyze the time cost for simulation. In the second part of the article, we investigate the influence of noise on the simulation process. We concentrate on errors in the interaction Hamiltonians and consider two generic noise models, (i) timing errors in pairwise interactions and (ii) noisy pairwise interactions described by Master equations of Lindblad form. We analyze and compare the effect of noise for the different simulation methods and propose a way to significantly reduce the influence of noise by making use of entanglement purification together with a teleportation based protocol.  ", "human_text": "  We consider the simulation of interacting high-dimensional systems using pairwise interacting qubits. The main tool in this context is the generation of effective many-body interactions, and we examine a number of different protocols for obtaining them. These methods include the usage of higher-order processes (commutator method), unitary conjugation or graph state encoding, as well as teleportation based approaches. We illustrate and compare these methods in detail and analyze the time cost for simulation. In the second part of the article, we investigate the influence of noise on the simulation process. We concentrate on errors in the interaction Hamiltonians and consider two generic noise models, (i) timing errors in pairwise interactions and (ii) noisy pairwise interactions described by Master equations of Lindblad form. We analyze and compare the effect of noise for the different simulation methods and propose a way to significantly reduce the influence of noise by making use of entanglement purification together with a teleportation based protocol. ", "machine_text": " This article examines the simulation of high-dimensional systems that interact with one another, employing qubits as our main tool. We study a variety of methods of creating effective many-body interactions, including higher-order processes (commutator method), unitary conjugation, graph state encoding, and teleportation based approaches. We evaluate and compare the time taken for each of these methods, and investigate how noise can affect the simulation. We explore two generic noise models: timing errors in pairwise interactions, and noisy pairwise interactions described by Master equations of the Lindblad form. We evaluate the impact of noise on the different simulation methods, and suggest a way to combat noise by combining entanglement purification with a teleportation-based protocol.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0154}
{"prompt": "Rephrase the abstract of an article with title 'Route to Lambda in conformally coupled phantom cosmology'.   In this letter we investigate acceleration in the flat cosmological model with a conformally coupled phantom field and we show that acceleration is its generic feature. We reduce the dynamics of the model to a 3-dimensional dynamical system and analyze it on a invariant 2-dimensional submanifold. Then the concordance FRW model with the cosmological constant $\\Lambda$ is a global attractor situated on a 2-dimensional invariant space. We also study the behaviour near this attractor, which can be approximated by the dynamics of the linearized part of the system. We demonstrate that trajectories of the conformally coupled phantom scalar field with a simple quadratic potential crosses the cosmological constant barrier infinitely many times in the phase space. The universal behaviour of the scalar field and its potential is also calculated. We conclude that the phantom scalar field conformally coupled to gravity gives a natural dynamical mechanism of concentration of the equation of state coefficient around the magical value $w_{\\text{eff}}=-1$. We demonstrate route to Lambda through the infinite times crossing the $w_{\\text{eff}}=-1$ phantom divide.  ", "human_text": "  In this letter we investigate acceleration in the flat cosmological model with a conformally coupled phantom field and we show that acceleration is its generic feature. We reduce the dynamics of the model to a 3-dimensional dynamical system and analyze it on a invariant 2-dimensional submanifold. Then the concordance FRW model with the cosmological constant $\\Lambda$ is a global attractor situated on a 2-dimensional invariant space. We also study the behaviour near this attractor, which can be approximated by the dynamics of the linearized part of the system. We demonstrate that trajectories of the conformally coupled phantom scalar field with a simple quadratic potential crosses the cosmological constant barrier infinitely many times in the phase space. The universal behaviour of the scalar field and its potential is also calculated. We conclude that the phantom scalar field conformally coupled to gravity gives a natural dynamical mechanism of concentration of the equation of state coefficient around the magical value $w_{\\text{eff}}=-1$. We demonstrate route to Lambda through the infinite times crossing the $w_{\\text{eff}}=-1$ phantom divide. ", "machine_text": " We analyze acceleration in the flat cosmological model with a conformally coupled phantom field to explore the route to Lambda in this type of cosmology. We reduce the model to a 3-dimensional dynamical system and study the behavior on an invariant 2-dimensional submanifold, finding that the concordance FRW model with the cosmological constant $\\Lambda$ is a global attractor situated on the 2-dimensional space. By examining the system near this attractor, we find that trajectories of the conformally coupled phantom scalar field with a simple quadratic potential cross the cosmological constant barrier infinitely many times in the phase space, giving a dynamical mechanism of concentration of the equation of state coefficient around the value of $w_{\\text{eff}}=-1$. We thus demonstrate a route to Lambda through the infinite times crossings of the $w_{\\text{eff}}=-1$ phantom divide.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1651}
{"prompt": "Rephrase the abstract of an article with title 'Vortices in Bose-Einstein Condensates: Theory'.   Vortices are pervasive in nature, representing the breakdown of laminar fluid flow and hence playing a key role in turbulence. The fluid rotation associated with a vortex can be parameterized by the circulation $\\Gamma=\\oint {\\rm d}{\\bf r}\\cdot{\\bf v}({\\bf r})$ about the vortex, where ${\\bf v}({\\bf r})$ is the fluid velocity field. While classical vortices can take any value of circulation, superfluids are irrotational, and any rotation or angular momentum is constrained to occur through vortices with quantized circulation. Quantized vortices also play a key role in the dissipation of transport in superfluids. In BECs quantized vortices have been observed in several forms, including single vortices, vortex lattices, and vortex pairs and rings. The recent observation of quantized vortices in a fermionic gas was taken as a clear signature of the underlying condensation and superfluidity of fermion pairs. In addition to BECs, quantized vortices also occur in superfluid Helium, nonlinear optics, and type-II superconductors.  ", "human_text": "  Vortices are pervasive in nature, representing the breakdown of laminar fluid flow and hence playing a key role in turbulence. The fluid rotation associated with a vortex can be parameterized by the circulation $\\Gamma=\\oint {\\rm d}{\\bf r}\\cdot{\\bf v}({\\bf r})$ about the vortex, where ${\\bf v}({\\bf r})$ is the fluid velocity field. While classical vortices can take any value of circulation, superfluids are irrotational, and any rotation or angular momentum is constrained to occur through vortices with quantized circulation. Quantized vortices also play a key role in the dissipation of transport in superfluids. In BECs quantized vortices have been observed in several forms, including single vortices, vortex lattices, and vortex pairs and rings. The recent observation of quantized vortices in a fermionic gas was taken as a clear signature of the underlying condensation and superfluidity of fermion pairs. In addition to BECs, quantized vortices also occur in superfluid Helium, nonlinear optics, and type-II superconductors. ", "machine_text": "This article presents a theoretical overview of the role of vortices in Bose-Einstein condensates (BECs). It discusses the circulation of fluid surrounding a vortex, the quantization of vortices in superfluids, and their wide occurrence. It examines the observation of single vortices, vortex lattices, and vortex pairs and rings in BECs, as well as the observation of quantized vortices in a fermionic gas indicating the resultant condensation and superfluidity of fermion pairs. It then considers other fields involving quantized vortices, such as superfluid Helium, nonlinear optics, and type-II superconductors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0146}
{"prompt": "Rephrase the abstract of an article with title 'Phase Transitions in the Coloring of Random Graphs'.   We consider the problem of coloring the vertices of a large sparse random graph with a given number of colors so that no adjacent vertices have the same color. Using the cavity method, we present a detailed and systematic analytical study of the space of proper colorings (solutions).   We show that for a fixed number of colors and as the average vertex degree (number of constraints) increases, the set of solutions undergoes several phase transitions similar to those observed in the mean field theory of glasses. First, at the clustering transition, the entropically dominant part of the phase space decomposes into an exponential number of pure states so that beyond this transition a uniform sampling of solutions becomes hard. Afterward, the space of solutions condenses over a finite number of the largest states and consequently the total entropy of solutions becomes smaller than the annealed one. Another transition takes place when in all the entropically dominant states a finite fraction of nodes freezes so that each of these nodes is allowed a single color in all the solutions inside the state. Eventually, above the coloring threshold, no more solutions are available. We compute all the critical connectivities for Erdos-Renyi and regular random graphs and determine their asymptotic values for large number of colors.   Finally, we discuss the algorithmic consequences of our findings. We argue that the onset of computational hardness is not associated with the clustering transition and we suggest instead that the freezing transition might be the relevant phenomenon. We also discuss the performance of a simple local Walk-COL algorithm and of the belief propagation algorithm in the light of our results.  ", "human_text": "  We consider the problem of coloring the vertices of a large sparse random graph with a given number of colors so that no adjacent vertices have the same color. Using the cavity method, we present a detailed and systematic analytical study of the space of proper colorings (solutions).   We show that for a fixed number of colors and as the average vertex degree (number of constraints) increases, the set of solutions undergoes several phase transitions similar to those observed in the mean field theory of glasses. First, at the clustering transition, the entropically dominant part of the phase space decomposes into an exponential number of pure states so that beyond this transition a uniform sampling of solutions becomes hard. Afterward, the space of solutions condenses over a finite number of the largest states and consequently the total entropy of solutions becomes smaller than the annealed one. Another transition takes place when in all the entropically dominant states a finite fraction of nodes freezes so that each of these nodes is allowed a single color in all the solutions inside the state. Eventually, above the coloring threshold, no more solutions are available. We compute all the critical connectivities for Erdos-Renyi and regular random graphs and determine their asymptotic values for large number of colors.   Finally, we discuss the algorithmic consequences of our findings. We argue that the onset of computational hardness is not associated with the clustering transition and we suggest instead that the freezing transition might be the relevant phenomenon. We also discuss the performance of a simple local Walk-COL algorithm and of the belief propagation algorithm in the light of our results. ", "machine_text": " We present a detailed and systematic analysis of the space of proper colorings (solutions) to a random graph with a given number of colors, and no adjacent vertices having the same color. Using the cavity method, we show that with increasing average vertex degree, the set of solutions undergoes several phase transitions which are similar to those seen in the mean field theory of glasses. Firstly, there is a clustering transition, where the most entropically dominant part of the phase space divides into an exponential number of pure states, making uniform sampling of solutions difficult. Thereafter, the space of solutions becomes concentrated into a finite number of the largest states, reducing the total entropy of solutions compared to the annealed one. Additionally, a freezing transition happens when a finite fraction of nodes freeze in the most entropically dominant states, with each node being given one color in all solutions in the state. Finally, above the coloring threshold, no further solutions are available. We compute the critical connectivities for Erdos-Renyi and regular random graphs, determining their asymptotic values for a high number of colors. We discuss the algorithmic consequences of our findings, arguing that the onset of computational complexity is not closely connected to the clustering transition. We evaluate the performance of a simple local Walk-COL algorithm and the belief propagation approach in the light of our results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1269}
{"prompt": "Rephrase the abstract of an article with title 'Multiperiodicity in the newly discovered mid-late Be star V2104 Cygni'.   We obtained the first long, homogenous time-series of V2104Cyg, consisting of 679 datapoints, with the uvbybeta photometers of Sierra Nevada and San Pedro Martir Observatories with the aim to detect and subsequently interpret the intrinsic frequencies of this previously unstudied variable star, which turned out to be a Be star. We try to figure out its place among the variable B stars on the upper Main Sequence. In order to obtain additional information on physical parameters we collected a few spectra with the ELODIE and FIES instruments. We searched for frequencies in the uvby passbands using 2 different frequency analysis methods and used the S/N>4 criterion to select the significant periodicities. We obtained an estimate of the physical parameters of the underlying B star of spectral type between B5 and B7, by correcting for the presence of a circumstellar disk, using a formalism based on the strenght of the Halpha line emission. We detected 3 independent frequencies with amplitudes below 0.01mag, f1 = 4.7126 c/d, f2 = 2.2342 c/d and f3 = 4.671 c/d, and discovered that V2104Cyg is a Be star. The fast rotation (vsini=290+/-10 km/s, and 27<i<45) hampered the investigation of the associated pulsational parameters l. Nevertheless, the most plausible explanation for the observed variability of this mid-late type Be star is a non-radial pulsation model. This paper is based on observations obtained at the Observatorio Astronomico Nacional San Pedro Martir (Mexico), Observatorio de Sierra Nevada (Spain), Observatoire de Haute Provence (France), and on observations made with the Nordic Optical Telescope, Observatorio Roque de los Muchachos, La Palma, Spain.  ", "human_text": "  We obtained the first long, homogenous time-series of V2104Cyg, consisting of 679 datapoints, with the uvbybeta photometers of Sierra Nevada and San Pedro Martir Observatories with the aim to detect and subsequently interpret the intrinsic frequencies of this previously unstudied variable star, which turned out to be a Be star. We try to figure out its place among the variable B stars on the upper Main Sequence. In order to obtain additional information on physical parameters we collected a few spectra with the ELODIE and FIES instruments. We searched for frequencies in the uvby passbands using 2 different frequency analysis methods and used the S/N>4 criterion to select the significant periodicities. We obtained an estimate of the physical parameters of the underlying B star of spectral type between B5 and B7, by correcting for the presence of a circumstellar disk, using a formalism based on the strenght of the Halpha line emission. We detected 3 independent frequencies with amplitudes below 0.01mag, f1 = 4.7126 c/d, f2 = 2.2342 c/d and f3 = 4.671 c/d, and discovered that V2104Cyg is a Be star. The fast rotation (vsini=290+/-10 km/s, and 27<i<45) hampered the investigation of the associated pulsational parameters l. Nevertheless, the most plausible explanation for the observed variability of this mid-late type Be star is a non-radial pulsation model. This paper is based on observations obtained at the Observatorio Astronomico Nacional San Pedro Martir (Mexico), Observatorio de Sierra Nevada (Spain), Observatoire de Haute Provence (France), and on observations made with the Nordic Optical Telescope, Observatorio Roque de los Muchachos, La Palma, Spain. ", "machine_text": " We investigated the previously unstudied variable star V2104 Cygni using two different frequency analysis methods to detect and interpret its intrinsic frequencies. We obtained 679 datapoints with the uvbybeta photometers of the Sierra Nevada and San Pedro Martir Observatories, as well as a few spectra with the ELODIE and FIES instruments. We employed a S/N>4 criterion to identify significant periodicities, which revealed 3 independent frequencies of amplitudes lower than 0.01mag. Our findings have led us to estimate the underlying B star spectral type between B5 and B7, via corrections to the strength of the Halpha line emission in the presence of a circumstellar disk. The star's rapid rotation of up to 290 +/- 10 km/s (27 < i < 45) has prevented us from examining its associated pulsational parameters. The most plausible explanation for the detected variability of this mid-late type Be star is a non-radial pulsation model. Supporting data for this study were acquired from the San Pedro Martir, Sierra Nevada, and Haute Provence Observatories, as well as the Nordic Optical Telescope, and Observatorio Roque de los Muchachos, in La Palma, Spain.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2943}
{"prompt": "Rephrase the abstract of an article with title 'On Cuspidal Representations of General Linear Groups over Discrete   Valuation Rings'.   We define a new notion of cuspidality for representations of $\\GL_n$ over a finite quotient $\\Oh_k$ of the ring of integers $\\Oh$ of a non-Archimedean local field $F$ using geometric and infinitesimal induction functors, which involve automorphism groups $G_\\lambda$ of torsion $\\Oh$\\nobreakdash-modules. When $n$ is a prime, we show that this notion of cuspidality is equivalent to strong cuspidality, which arises in the construction of supercuspidal representations of $\\GL_n(F)$. We show that strongly cuspidal representations share many features of cuspidal representations of finite general linear groups. In the function field case, we show that the construction of the representations of $\\GL_n(\\Oh_k)$ for $k\\geq 2$ for all $n$ is equivalent to the construction of the representations of all the groups $G_\\lambda$. A functional equation for zeta functions for representations of $\\GL_n(\\Oh_k)$ is established for representations which are not contained in an infinitesimally induced representation. All the cuspidal representations for $\\GL_4(\\Oh_2)$ are constructed. Not all these representations are strongly cuspidal.  ", "human_text": "  We define a new notion of cuspidality for representations of $\\GL_n$ over a finite quotient $\\Oh_k$ of the ring of integers $\\Oh$ of a non-Archimedean local field $F$ using geometric and infinitesimal induction functors, which involve automorphism groups $G_\\lambda$ of torsion $\\Oh$\\nobreakdash-modules. When $n$ is a prime, we show that this notion of cuspidality is equivalent to strong cuspidality, which arises in the construction of supercuspidal representations of $\\GL_n(F)$. We show that strongly cuspidal representations share many features of cuspidal representations of finite general linear groups. In the function field case, we show that the construction of the representations of $\\GL_n(\\Oh_k)$ for $k\\geq 2$ for all $n$ is equivalent to the construction of the representations of all the groups $G_\\lambda$. A functional equation for zeta functions for representations of $\\GL_n(\\Oh_k)$ is established for representations which are not contained in an infinitesimally induced representation. All the cuspidal representations for $\\GL_4(\\Oh_2)$ are constructed. Not all these representations are strongly cuspidal. ", "machine_text": " We present a new definition of cuspidality for representations of $\\GL_n$ over discrete valuation rings of a non-Archimedean local field $F$. With this, we connect strongly cuspidal representations of $\\GL_n(F)$ with a definition for cuspidal representations of finite general linear groups. In the function field case, we also demonstrate how the representations of $\\GL_n(\\Oh_k)$ for $k\\geq 2$ and all $n$ are linked to the representations of the groups $G_\\lambda$. Furthermore, we provide a functional equation for zeta functions for those representations that are not induced from those of $G_\\lambda$. Lastly, we establish that all the cuspidal representations for $\\GL_4(\\Oh_2)$ have been constructed, not all of which are strongly cuspidal.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0058}
{"prompt": "Rephrase the abstract of an article with title 'Characterizing the Low-Redshift Intergalactic Medium towards PKS1302-102'.   We present a detailed analysis of the intergalactic metal-line absorption systems in the archival HST/STIS and FUSE ultraviolet spectra of the low-redshift quasar PKS1302-102 (z_QSO = 0.2784). We supplement the archive data with CLOUDY ionization models and a survey of galaxies in the quasar field. There are 15 strong Lya absorbers with column densities logN_HI > 14. Of these, six are associated with at least CIII 977 absorption (logN(C^++) > 13); this implies a redshift density dN_CIII/dz = 36+13/-9 (68% confidence limits) for the five detections with rest equivalent width W_r > 50 mA. Two systems show OVI 1031,1037 absorption in addition to CIII (logN(O^+5) > 14). One is a partial Lyman limit system (logN_HI = 17) with associated CIII, OVI, and SiIII 1206 absorption. There are three tentative OVI systems that do not have CIII detected. For one OVI doublet with both lines detected at 3 sigma with W_r > 50 mA, dN_OVI/dz = 7+9/-4. We also search for OVI doublets without Lya absorption but identify none. From CLOUDY modeling, these metal-line systems have metallicities spanning the range -4 < [M/H] < -0.3. The two OVI systems with associated CIII absorption cannot be single-phase, collisionally-ionized media based on the relative abundances of the metals and kinematic arguments. From the galaxy survey, we discover that the absorption systems are in a diverse set of galactic environments. Each metal-line system has at least one galaxy within 500 km/s and 600 h^-1 kpc with L > 0.1 L_*.  ", "human_text": "  We present a detailed analysis of the intergalactic metal-line absorption systems in the archival HST/STIS and FUSE ultraviolet spectra of the low-redshift quasar PKS1302-102 (z_QSO = 0.2784). We supplement the archive data with CLOUDY ionization models and a survey of galaxies in the quasar field. There are 15 strong Lya absorbers with column densities logN_HI > 14. Of these, six are associated with at least CIII 977 absorption (logN(C^++) > 13); this implies a redshift density dN_CIII/dz = 36+13/-9 (68% confidence limits) for the five detections with rest equivalent width W_r > 50 mA. Two systems show OVI 1031,1037 absorption in addition to CIII (logN(O^+5) > 14). One is a partial Lyman limit system (logN_HI = 17) with associated CIII, OVI, and SiIII 1206 absorption. There are three tentative OVI systems that do not have CIII detected. For one OVI doublet with both lines detected at 3 sigma with W_r > 50 mA, dN_OVI/dz = 7+9/-4. We also search for OVI doublets without Lya absorption but identify none. From CLOUDY modeling, these metal-line systems have metallicities spanning the range -4 < [M/H] < -0.3. The two OVI systems with associated CIII absorption cannot be single-phase, collisionally-ionized media based on the relative abundances of the metals and kinematic arguments. From the galaxy survey, we discover that the absorption systems are in a diverse set of galactic environments. Each metal-line system has at least one galaxy within 500 km/s and 600 h^-1 kpc with L > 0.1 L_*. ", "machine_text": " We uncover the makeup of the low-redshift intergalactic medium (IGM) in the direction of quasar PKS1302-102 (z_QSO = 0.2784) using archival HST/STIS and FUSE ultraviolet spectra. We determine that there are 15 Ly\u03b1-absorbing systems with column densities logN_HI > 14, six of which contain CIII 977 intergalactic metal absorption (logN(C^++) > 13) and two of which contain both OVI 1031, 1037 and CIII absorption (logN(O^+5) > 14). Additionally, we detect three tentatively OVI systems that lack associated CIII absorption. Performing CLOUDY ionization modeling, these metal-line systems have metallicities spanning -4 < [M/H] < -0.3. Our analysis of these metal-line absorbers suggest the presence of multiple-phase, photo-ionized media which is further supported by a survey of the galaxies in the quasar field. Each metal-line system has at least one luminous galaxy within 500 km/s and 600 h^-1 kpc of the quasar.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1285}
{"prompt": "Rephrase the abstract of an article with title 'Matter-Wave Bright Solitons with a Finite Background in Spinor   Bose-Einstein Condensates'.   We investigate dynamical properties of bright solitons with a finite background in the F=1 spinor Bose-Einstein condensate (BEC), based on an integrable spinor model which is equivalent to the matrix nonlinear Schr\\\"{o}dinger equation with a self-focusing nonlineality. We apply the inverse scattering method formulated for nonvanishing boundary conditions. The resulting soliton solutions can be regarded as a generalization of those under vanishing boundary conditions. One-soliton solutions are derived in an explicit manner. According to the behaviors at the infinity, they are classified into two kinds, domain-wall (DW) type and phase-shift (PS) type. The DW-type implies the ferromagnetic state with nonzero total spin and the PS-type implies the polar state, where the total spin amounts to zero. We also discuss two-soliton collisions. In particular, the spin-mixing phenomenon is confirmed in a collision involving the DW-type. The results are consistent with those of the previous studies for bright solitons under vanishing boundary conditions and dark solitons. As a result, we establish the robustness and the usefulness of the multiple matter-wave solitons in the spinor BECs.  ", "human_text": "  We investigate dynamical properties of bright solitons with a finite background in the F=1 spinor Bose-Einstein condensate (BEC), based on an integrable spinor model which is equivalent to the matrix nonlinear Schr\\\"{o}dinger equation with a self-focusing nonlineality. We apply the inverse scattering method formulated for nonvanishing boundary conditions. The resulting soliton solutions can be regarded as a generalization of those under vanishing boundary conditions. One-soliton solutions are derived in an explicit manner. According to the behaviors at the infinity, they are classified into two kinds, domain-wall (DW) type and phase-shift (PS) type. The DW-type implies the ferromagnetic state with nonzero total spin and the PS-type implies the polar state, where the total spin amounts to zero. We also discuss two-soliton collisions. In particular, the spin-mixing phenomenon is confirmed in a collision involving the DW-type. The results are consistent with those of the previous studies for bright solitons under vanishing boundary conditions and dark solitons. As a result, we establish the robustness and the usefulness of the multiple matter-wave solitons in the spinor BECs. ", "machine_text": "This paper examines the dynamics of bright solitons with finite background in spinor Bose-Einstein Condensates (BECs) that are modeled as a matrix nonlinear Schr\\\"{o}dinger equation with self-focusing nonlinearity. The inverse scattering method is employed to study soliton solutions that have been extended from vanishing boundary conditions. These solitons are classified into two types termed 'domain-wall' (DW) or 'phase-shift' (PS) depending on their behavior at infinity. The DW type corresponds to a ferromagnetic state with a non-zero total spin, while the PS type carries a zero total spin meaning a polar state. The collisions of two solitons are further researched and the spin-mixing is confirmed in a collision involving a DW type. Moreover, the robustness and the usefulness of solitons in spinor BECs are emphasized.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0082}
{"prompt": "Rephrase the abstract of an article with title 'Nonlocal Excitation Spectra in 2D Doped Hubbard Model'.   Single-particle excitation spectra of the two-dimensional Hubbard model on the square lattice near half filling and at zero temperature are investigated on the basis of the self-consistent projection operator method. The method guarantees a high accuracy of the spectra with high energy and high momentum resolutions. It takes into account long-range intersite correlations as well as the strong on-site correlations. Effects of nonlocal excitations are clarified by comparing the results with those of the single-site approximation. The calculated spectra verify the quantum Monte-Carlo results for finite temperatures. The spectra at the Fermi level yield a hole-like Fermi surface in the underdoped region and an electron-like Fermi surface in the overdoped region. From a numerical analysis of the momentum dependent effective mass and self-energy, it is concluded that a marginal Fermi-liquid like state persists even at finite doping concentrations in the strongly correlated region because a van Hove singularity is pinned to the Fermi surface. It is also found that a kink structure appears in the quasiparticle energy band in the same region. The kink is shown to be caused by a mixing between the quasiparticle band and an excitation band with strong short-range antiferromagnetic correlations. These results suggest an explanation for some of the unusual properties of the normal state in high-$T_{\\rm c}$ cuprates.  ", "human_text": "  Single-particle excitation spectra of the two-dimensional Hubbard model on the square lattice near half filling and at zero temperature are investigated on the basis of the self-consistent projection operator method. The method guarantees a high accuracy of the spectra with high energy and high momentum resolutions. It takes into account long-range intersite correlations as well as the strong on-site correlations. Effects of nonlocal excitations are clarified by comparing the results with those of the single-site approximation. The calculated spectra verify the quantum Monte-Carlo results for finite temperatures. The spectra at the Fermi level yield a hole-like Fermi surface in the underdoped region and an electron-like Fermi surface in the overdoped region. From a numerical analysis of the momentum dependent effective mass and self-energy, it is concluded that a marginal Fermi-liquid like state persists even at finite doping concentrations in the strongly correlated region because a van Hove singularity is pinned to the Fermi surface. It is also found that a kink structure appears in the quasiparticle energy band in the same region. The kink is shown to be caused by a mixing between the quasiparticle band and an excitation band with strong short-range antiferromagnetic correlations. These results suggest an explanation for some of the unusual properties of the normal state in high-$T_{\\rm c}$ cuprates. ", "machine_text": " The self-consistent projection operator method is used to explore the single-particle excitation spectra of the two-dimensional Hubbard model at half filling and zero temperature. By assessing the effects of nonlocal excitations, the obtained spectra validate the accuracy of quantum Monte-Carlo results for finite temperatures. It is found that the Fermi surface in the doping region changes from hole-like to electron-like and the kink structure appears in the quasiparticle energy band due to a mixing between the quasiparticle band and an excitation band with strong short-range antiferromagnetic correlations. The study provides a possible explanation for the anomalous properties observed in the normal state of high-$T_{\\rm c}$ cuprates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0581}
{"prompt": "Rephrase the abstract of an article with title 'Grain Retention and Formation of Planetesimals near the Snow Line in   MRI-driven Turbulent Protoplanetary Disks'.   The first challenge in the formation of both terrestrial planets and the cores of gas giants is the retention of grains in protoplanetary disks. In most regions of these disks, gas attains sub-Keplerian speeds as a consequence of a negative pressure gradient. Hydrodynamic drag leads to orbital decay and depletion of the solid material in the disk, with characteristic timescales as short as only a few hundred years for meter-sized objects at 1 AU. In this paper, we suggest a particle retention mechanism which promotes the accumulation of grains and the formation of planetesimals near the water sublimation front or ``snow line.'' This model is based on the assumption that, in the regions most interesting for planet formation, the viscous evolution of the disk is due to turbulence driven by the magneto-rotational instability (MRI) in the surface layers of the disk. The depth to which MRI effectively generates turbulence is a strong function of the grain size and abundance. A sharp increase in the grain-to-gas density ratio across the snow line reduces the column depth of the active layer. As the disk evolves towards a quasi-steady-state, this change in the active layer creates a local maximum in radial distribution of the gas surface density and pressure, causing the gas to rotate at super-Keplerian speed and halting the inward migration of grains. This senario presents a robust process for grain retention which may aid in the formation of proto-gas-giant cores preferentially near the snow line.  ", "human_text": "  The first challenge in the formation of both terrestrial planets and the cores of gas giants is the retention of grains in protoplanetary disks. In most regions of these disks, gas attains sub-Keplerian speeds as a consequence of a negative pressure gradient. Hydrodynamic drag leads to orbital decay and depletion of the solid material in the disk, with characteristic timescales as short as only a few hundred years for meter-sized objects at 1 AU. In this paper, we suggest a particle retention mechanism which promotes the accumulation of grains and the formation of planetesimals near the water sublimation front or ``snow line.'' This model is based on the assumption that, in the regions most interesting for planet formation, the viscous evolution of the disk is due to turbulence driven by the magneto-rotational instability (MRI) in the surface layers of the disk. The depth to which MRI effectively generates turbulence is a strong function of the grain size and abundance. A sharp increase in the grain-to-gas density ratio across the snow line reduces the column depth of the active layer. As the disk evolves towards a quasi-steady-state, this change in the active layer creates a local maximum in radial distribution of the gas surface density and pressure, causing the gas to rotate at super-Keplerian speed and halting the inward migration of grains. This senario presents a robust process for grain retention which may aid in the formation of proto-gas-giant cores preferentially near the snow line. ", "machine_text": " This paper proposes a mechanism for the retention of solid, grain-sized material in protostellar disks and the eventual formation of planetesimals, preferentially occurring at the water sublimation front, or snow line. This mechanism, based on turbulence driven by the magneto-rotational instability (MRI), is rooted in the fact that the disk's column depth of the active layer is a strong function of the grain size and abundance. With a sharp increase in the grain-to-gas ratio at the snow line, the active layer reduces, resulting in a local maximum of gas surface density and pressure. The gas moves at super-Keplerian velocities, effectively stagnating the inward migration of grains and potentially promoting the growth of proto-gas-giants cores in this already denser region. This model provides a robust environment for particle retention, facilitating the formation of planetesimals.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1272}
{"prompt": "Rephrase the abstract of an article with title 'Old Main-Sequence Turnoff Photometry in the Small Magellanic Cloud. I.   Constraints on the Star Formation History in Different Fields'.   We present ground-based B and R-band color-magnitude diagrams (CMDs), reaching the oldest main-sequence turnoffs with good photometric accuracy for twelve fields in the Small Magellanic Cloud (SMC). Our fields, located between ~1 and ~4 degrees from the center of the galaxy, are situated in different parts of the SMC such as the \"Wing'' area, and towards the West and South. In this paper we perform a first analysis of the stellar content in our SMC fields through comparison with theoretical isochrones and color functions (CFs). We find that the underlying spheroidally distributed population is composed of both intermediate-age and old stars and that its age composition does not show strong galacto-centric gradients. The three fields situated toward the east, in the Wing region, show very active current star formation. However, only in the eastern field closest to the center do we find an enhancement of recent star formation with respect to a constant SFR(t). The fields corresponding to the western side of the SMC present a much less populated young MS, and the CF analysis indicates that the SFR(t) greatly diminished around 2 Gyr ago in these parts. Field smc0057, the closest to the center of the galaxy and located in the southern part, shows recent star formation, while the rest of the southern fields present few bright MS stars. The structure of the red clump in all the CMDs is consistent with the large amount of intermediate-age stars inferred from the CMDs and color functions. None of the SMC fields presented here are dominated by old stellar populations, a fact that is in agreement with the lack of a conspicuous horizontal branch in all these SMC CMDs. This could indicate that a disk population is ruling over a possible old halo in all the observed fields.  ", "human_text": "  We present ground-based B and R-band color-magnitude diagrams (CMDs), reaching the oldest main-sequence turnoffs with good photometric accuracy for twelve fields in the Small Magellanic Cloud (SMC). Our fields, located between ~1 and ~4 degrees from the center of the galaxy, are situated in different parts of the SMC such as the \"Wing'' area, and towards the West and South. In this paper we perform a first analysis of the stellar content in our SMC fields through comparison with theoretical isochrones and color functions (CFs). We find that the underlying spheroidally distributed population is composed of both intermediate-age and old stars and that its age composition does not show strong galacto-centric gradients. The three fields situated toward the east, in the Wing region, show very active current star formation. However, only in the eastern field closest to the center do we find an enhancement of recent star formation with respect to a constant SFR(t). The fields corresponding to the western side of the SMC present a much less populated young MS, and the CF analysis indicates that the SFR(t) greatly diminished around 2 Gyr ago in these parts. Field smc0057, the closest to the center of the galaxy and located in the southern part, shows recent star formation, while the rest of the southern fields present few bright MS stars. The structure of the red clump in all the CMDs is consistent with the large amount of intermediate-age stars inferred from the CMDs and color functions. None of the SMC fields presented here are dominated by old stellar populations, a fact that is in agreement with the lack of a conspicuous horizontal branch in all these SMC CMDs. This could indicate that a disk population is ruling over a possible old halo in all the observed fields. ", "machine_text": " In this paper, we analyze the stellar content of twelve fields in the Small Magellanic Cloud (SMC), located between ~1 and ~4 degrees from the center of the galaxy, by analyzing ground-based B and R-band color-magnitude diagrams (CMDs) reaching the oldest main-sequence turnoffs. Our analysis, including a comparison with theoretical isochrones and color functions, finds that the underlying spheroidal population in the SMC is composed of both intermediate-age and old stars. While the three fields from the Wing region show very active current star formation, the fields from the West and South have a much less populated young main-sequence, with a strong depletion of star formation at around 2 Gyr ago. Further, the red clump in all CMDs is consistent with the large amount of intermediate-age stars. This could indicate that a disk population has overruled any possible old halo in all the observed fields.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1151}
{"prompt": "Rephrase the abstract of an article with title 'Correlated modulation between the redshifted Fe K alpha line and the   continuum emission in NGC 3783'.   It has been suggested that X-ray observations of rapidly variable Seyfert galaxies may hold the key to probe the gas orbital motions in the innermost regions of accretion discs around black holes and, thus, trace flow patterns under the effect of the hole strong gravitational field. We explore this possibility analizing XMM-Newton observations of the seyfert 1 galaxy NGC 3783. A detiled time-resolved spectral analysis is performed down to the shortest possible time-scales (few ks) using \"excess maps\" and cross-correlating light curves in different energy bands. In addition to a constant core of the Fe K alpha line, we detected a variable and redshifted Fe K alpha emission feature between 5.3-6.1 keV. The line exhibits a modulation on a time-scale of 27 ks that is similar to and in phase with a modulation of the 0.3-10 keV source continuum. The time-scale of the correlated variability of the redshifted Fe line and continuum agrees with the local dynamical time-scale of the accretion disc at 10 r_g around a black hole of 10^7 M_sun. Given the shape of the redshfted line emission and the overall X-ray variability pattern, the line is likely to arise from the relativistic region near the black hole.  ", "human_text": "  It has been suggested that X-ray observations of rapidly variable Seyfert galaxies may hold the key to probe the gas orbital motions in the innermost regions of accretion discs around black holes and, thus, trace flow patterns under the effect of the hole strong gravitational field. We explore this possibility analizing XMM-Newton observations of the seyfert 1 galaxy NGC 3783. A detiled time-resolved spectral analysis is performed down to the shortest possible time-scales (few ks) using \"excess maps\" and cross-correlating light curves in different energy bands. In addition to a constant core of the Fe K alpha line, we detected a variable and redshifted Fe K alpha emission feature between 5.3-6.1 keV. The line exhibits a modulation on a time-scale of 27 ks that is similar to and in phase with a modulation of the 0.3-10 keV source continuum. The time-scale of the correlated variability of the redshifted Fe line and continuum agrees with the local dynamical time-scale of the accretion disc at 10 r_g around a black hole of 10^7 M_sun. Given the shape of the redshfted line emission and the overall X-ray variability pattern, the line is likely to arise from the relativistic region near the black hole. ", "machine_text": " The X-ray emission of the Seyfert 1 galaxy NGC 3783 has been closely inspected with XMM-Newton in an effort to probe, through orbital motions, the innermost regions around the black hole. Our analysis revealed a time-variable and redshifted Fe K line emission that is correlated to the source continuum on a time-scale of 27 ks. This value agrees with the local dynamical time-scale of the black hole disc at 10 r_g. The line shape and overall X-ray pattern suggest the origin of the line likely lies in the vicinity of the black hole, under its large gravitational field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0226}
{"prompt": "Rephrase the abstract of an article with title 'The chemical composition of the circumstellar envelopes around yellow   hypergiant stars'.   The yellow hypergiant stars (YHGs) are extremely luminous and massive objects whose general properties are poorly known. Only two of this kind of star show massive circumstellar envelopes, IRC+10420 and AFGL2343. We aim to study the chemistry of the circumstellar envelopes around these two sources, by comparison with well known AGB stars and protoplanetary nebulae. We also estimate the abundances of the observed molecular species. We have performed single-dish observations of different transitions for twelve molecular species. We have compared the ratio of the intensities of the molecular transitions and of the estimated abundances in AFGL2343 and IRC+10420 with those in O-rich and C-rich AGB stars and protoplanetary nebulae. Both YHGs, AFGL2343, and IRC+10420, have been found to have an O-rich chemistry similar to that in O-rich AGB stars, though for AFGL2343 the emission of most molecules compared with 13CO lines is relatively weak. Clear differences with the other evolved sources appear when we compare the line intensity corrected for distance and the profile widths which are, respectively, very intense and very wide in YHGs. The abundances obtained for IRC+10420 agree with those found in AGB stars, but in general those found in AFGL2343, except for 13CO, are too low. This apparently low molecular abundance in AFGL2343 could be due to the fact that these molecules are present only in an inner region of the shell where the mass is relatively low.  ", "human_text": "  The yellow hypergiant stars (YHGs) are extremely luminous and massive objects whose general properties are poorly known. Only two of this kind of star show massive circumstellar envelopes, IRC+10420 and AFGL2343. We aim to study the chemistry of the circumstellar envelopes around these two sources, by comparison with well known AGB stars and protoplanetary nebulae. We also estimate the abundances of the observed molecular species. We have performed single-dish observations of different transitions for twelve molecular species. We have compared the ratio of the intensities of the molecular transitions and of the estimated abundances in AFGL2343 and IRC+10420 with those in O-rich and C-rich AGB stars and protoplanetary nebulae. Both YHGs, AFGL2343, and IRC+10420, have been found to have an O-rich chemistry similar to that in O-rich AGB stars, though for AFGL2343 the emission of most molecules compared with 13CO lines is relatively weak. Clear differences with the other evolved sources appear when we compare the line intensity corrected for distance and the profile widths which are, respectively, very intense and very wide in YHGs. The abundances obtained for IRC+10420 agree with those found in AGB stars, but in general those found in AFGL2343, except for 13CO, are too low. This apparently low molecular abundance in AFGL2343 could be due to the fact that these molecules are present only in an inner region of the shell where the mass is relatively low. ", "machine_text": " The current study focuses on the chemistry of the circumstellar envelopes that surround two of the rare and luminous yellow hypergiant stars (YHGs): IRC+10420 and AFGL2343. We consider the ratios of the intensities of various molecular transitions as well as the estimated abundances in both the YHGs and compare it to those found in O-rich and C-rich AGB stars and protoplanetary nebulae. From our single-dish observations for twelve molecular species, we have found that these two YHGs have an O-rich chemistry that is similar to that of O-rich AGB stars. However, the line intensities of most molecules are relatively weak in AFGL2343 than in 13CO lines, and the line intensity corrected for distance and profile widths are high in YHGs compared to the evolved sources. Moreover, the observed abundances for IRC+ 10420 correspond with those found in AGB stars whereas AFGL2343 has lower concentrations of these molecules, except for 13CO. This can possibly be attributed to the fact that these molecules are present only in the inner parts of the shell, where the mass is lower.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1639}
{"prompt": "Rephrase the abstract of an article with title 'Parametric Learning and Monte Carlo Optimization'.   This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine-Learning (PL), and `blackbox' or `oracle'-based optimization (BO). We make four contributions. First, we prove that MCO is mathematically identical to a broad class of PL problems. This identity potentially provides a new application domain for all broadly applicable PL techniques: MCO. Second, we introduce immediate sampling, a new version of the Probability Collectives (PC) algorithm for blackbox optimization. Immediate sampling transforms the original BO problem into an MCO problem. Accordingly, by combining these first two contributions, we can apply all PL techniques to BO. In our third contribution we validate this way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling. Finally, conventional MC and MCO procedures ignore the relationship between the sample point locations and the associated values of the integrand; only the values of the integrand at those locations are considered. We demonstrate that one can exploit the sample location information using PL techniques, for example by forming a fit of the sample locations to the associated values of the integrand. This provides an additional way to apply PL techniques to improve MCO.  ", "human_text": "  This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine-Learning (PL), and `blackbox' or `oracle'-based optimization (BO). We make four contributions. First, we prove that MCO is mathematically identical to a broad class of PL problems. This identity potentially provides a new application domain for all broadly applicable PL techniques: MCO. Second, we introduce immediate sampling, a new version of the Probability Collectives (PC) algorithm for blackbox optimization. Immediate sampling transforms the original BO problem into an MCO problem. Accordingly, by combining these first two contributions, we can apply all PL techniques to BO. In our third contribution we validate this way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling. Finally, conventional MC and MCO procedures ignore the relationship between the sample point locations and the associated values of the integrand; only the values of the integrand at those locations are considered. We demonstrate that one can exploit the sample location information using PL techniques, for example by forming a fit of the sample locations to the associated values of the integrand. This provides an additional way to apply PL techniques to improve MCO. ", "machine_text": "This article examines the interplay between Monte Carlo Optimization (MCO) of a parametric integral, Parametric Learning (PL), and 'blackbox'/'oracle'-based optimization (BO). We observe four main contributions: (1) we prove the mathematical equivalence of MCO and a number of PL problems, thus providing an additional application field for PL; (2) we develop an original version of the Probability Collectives (PC) algorithm for BO, 'immediate sampling', which transforms BO into MCO; (3) we show how cross-validation and bagging can be used to enhance immediate sampling; and (4) we investigate how fitting a model to the sample point locations combined with their associated integrand values can lead to improvements in MCO.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1274}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of the Spin-Transfer-Torque Vector in Magnetic Tunnel   Junctions'.   Spin-polarized currents can transfer spin angular momentum to a ferromagnet, generating a torque that can efficiently reorient its magnetization. Achieving quantitative measurements of the spin-transfer-torque vector in magnetic tunnel junctions (MTJs) is important for understanding fundamental mechanisms affecting spin-dependent tunneling, and for developing magnetic memories and nanoscale microwave oscillators. Here we present direct measurements of both the magnitude and direction of the spin torque in Co60Fe20B20/MgO/Co60Fe20B20 MTJs. At low bias V, the differential torque vector d{tau}/dV lies in the plane defined by the electrode magnetizations, and its magnitude is in excellent agreement with a prediction for highly-spin-polarized tunneling. With increasing bias, the in-plane component d{tau}_{parallel}/dV remains large, in striking contrast to the decreasing magnetoresistance ratio. The differential torque vector also rotates out of the plane under bias; we measure a perpendicular component tau_{perp}(V) with bias dependence proportional to V^2 for low V, that becomes as large as 30% of the in-plane torque.  ", "human_text": "  Spin-polarized currents can transfer spin angular momentum to a ferromagnet, generating a torque that can efficiently reorient its magnetization. Achieving quantitative measurements of the spin-transfer-torque vector in magnetic tunnel junctions (MTJs) is important for understanding fundamental mechanisms affecting spin-dependent tunneling, and for developing magnetic memories and nanoscale microwave oscillators. Here we present direct measurements of both the magnitude and direction of the spin torque in Co60Fe20B20/MgO/Co60Fe20B20 MTJs. At low bias V, the differential torque vector d{tau}/dV lies in the plane defined by the electrode magnetizations, and its magnitude is in excellent agreement with a prediction for highly-spin-polarized tunneling. With increasing bias, the in-plane component d{tau}_{parallel}/dV remains large, in striking contrast to the decreasing magnetoresistance ratio. The differential torque vector also rotates out of the plane under bias; we measure a perpendicular component tau_{perp}(V) with bias dependence proportional to V^2 for low V, that becomes as large as 30% of the in-plane torque. ", "machine_text": " The effects of spin-polarized currents on the reorientation of the magnetization of ferromagnets are substantial. To understand and exploit their influence, it is necessary to quantify the spin-transfer-torque vector in magnetic tunnel junctions (MTJs). Herein, accurate measurements of both the magnitude and direction of this torque in Co60Fe20B20/MgO/Co60Fe20B20 MTJs have been made and compared to predictions for highly-spin-polarized tunneling. The in-plane component d{tau}_{parallel}/dV remains large, even when the bias voltage is increased; a perpendicular component tau_{perp}(V) with a bias dependence proportional to V^2, which can reach 30 percent of the in-plane torque, has also been measured. These findings present an essential step towards understanding the mechanisms underlying spin-dependent tunneling and exploiting them for the development of future applications such as memory cells and nanoscale microwave oscillators.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4207}
{"prompt": "Rephrase the abstract of an article with title 'Are collisions with neutral hydrogen important for modelling the Second   Solar Spectrum of Ti I and Ca II ?'.   The physical interpretation of scattering line polarization offers a novel diagnostic window for exploring the thermal and magnetic structure of the quiet regions of the solar atmosphere. Here we evaluate the impact of isotropic collisions with neutral hydrogen atoms on the scattering polarization signals of the 13 lines of multiplet 42 of Ti I and on those of the K line and of the IR triplet of Ca II, with emphasis on the collisional transfer rates between nearby J-levels. To this end, we calculate the linear polarization produced by scattering processes considering realistic multilevel models and solving the statistical equilibrium equations for the multipolar components of the atomic density matrix. We confirm that the lower levels of the 13 lines of multiplet 42 of Ti I are completely depolarized by elastic collisions. We find that upper-level collisional depolarization turns out to have an unnoticeable impact on the emergent linear polarization amplitudes, except for the ${\\lambda 4536$ line for which it is possible to notice a rather small depolarization caused by the collisional transfer rates. Concerning the Ca II lines, we show that the collisional rates play no role on the polarization of the upper level of the K line, while they have a rather small depolarizing effect on the atomic polarization of the metastable lower levels of the Ca II IR triplet.  ", "human_text": "  The physical interpretation of scattering line polarization offers a novel diagnostic window for exploring the thermal and magnetic structure of the quiet regions of the solar atmosphere. Here we evaluate the impact of isotropic collisions with neutral hydrogen atoms on the scattering polarization signals of the 13 lines of multiplet 42 of Ti I and on those of the K line and of the IR triplet of Ca II, with emphasis on the collisional transfer rates between nearby J-levels. To this end, we calculate the linear polarization produced by scattering processes considering realistic multilevel models and solving the statistical equilibrium equations for the multipolar components of the atomic density matrix. We confirm that the lower levels of the 13 lines of multiplet 42 of Ti I are completely depolarized by elastic collisions. We find that upper-level collisional depolarization turns out to have an unnoticeable impact on the emergent linear polarization amplitudes, except for the ${\\lambda 4536$ line for which it is possible to notice a rather small depolarization caused by the collisional transfer rates. Concerning the Ca II lines, we show that the collisional rates play no role on the polarization of the upper level of the K line, while they have a rather small depolarizing effect on the atomic polarization of the metastable lower levels of the Ca II IR triplet. ", "machine_text": "This article investigates the significance of scattering line polarization for exploring the quiet regions of the solar atmosphere. By utilizing multilevel models and calculating the linear polarization produced by scattering processes, we assess the effect of collisions with neutral hydrogen on the thirteen lines in multiplet 42 of Ti I and on the K line and IR triplet of Ca II, focusing on the exchange of energy levels caused by these collisions. Though this depolarization affects the ${\\lambda 4536$ line of Ti I significantly, its effect on the other lines is minimal. We also find that the depolarization of the Ca II lines is barely noticeable. This research offers further understanding of the thermal and magnetic structure of the quiet regions of the solar atmosphere.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1968}
{"prompt": "Rephrase the abstract of an article with title 'Imaging the Cosmic Matter Distribution using Gravitational Lensing of   Pregalactic HI'.   21-cm emission from neutral hydrogen during and before the epoch of cosmic reionisation is gravitationally lensed by material at all lower redshifts. Low-frequency radio observations of this emission can be used to reconstruct the projected mass distribution of foreground material, both light and dark. We compare the potential imaging capabilities of such 21-cm lensing with those of future galaxy lensing surveys. We use the Millennium Simulation to simulate large-area maps of the lensing convergence with the noise, resolution and redshift-weighting achievable with a variety of idealised observation programmes. We find that the signal-to-noise of 21-cm lens maps can far exceed that of any map made using galaxy lensing. If the irreducible noise limit can be reached with a sufficiently large radio telescope, the projected convergence map provides a high-fidelity image of the true matter distribution, allowing the dark matter halos of individual galaxies to be viewed directly, and giving a wealth of statistical and morphological information about the relative distributions of mass and light. For instrumental designs like that planned for the Square Kilometer Array (SKA), high-fidelity mass imaging may be possible near the resolution limit of the core array of the telescope.  ", "human_text": "  21-cm emission from neutral hydrogen during and before the epoch of cosmic reionisation is gravitationally lensed by material at all lower redshifts. Low-frequency radio observations of this emission can be used to reconstruct the projected mass distribution of foreground material, both light and dark. We compare the potential imaging capabilities of such 21-cm lensing with those of future galaxy lensing surveys. We use the Millennium Simulation to simulate large-area maps of the lensing convergence with the noise, resolution and redshift-weighting achievable with a variety of idealised observation programmes. We find that the signal-to-noise of 21-cm lens maps can far exceed that of any map made using galaxy lensing. If the irreducible noise limit can be reached with a sufficiently large radio telescope, the projected convergence map provides a high-fidelity image of the true matter distribution, allowing the dark matter halos of individual galaxies to be viewed directly, and giving a wealth of statistical and morphological information about the relative distributions of mass and light. For instrumental designs like that planned for the Square Kilometer Array (SKA), high-fidelity mass imaging may be possible near the resolution limit of the core array of the telescope. ", "machine_text": "This paper investigates the potential of using 21-cm emissions from neutral hydrogen during and before the epoch of cosmic reionisation to reconstruct the projected mass distribution of foreground material, both light and dark, via gravitational lensing. Using the Millennium Simulation, large-area maps of the lensing convergence with realistic noise, resolution, and redshift-weighting achievable with a variety of idealised observation programmes are simulated. Results suggest that the signal-to-noise of 21-cm lens maps can be larger than those of maps made with galaxy lensing. Additionally, if the irreducible noise limit can be achieved with a large enough telescope, a high-fidelity image of the true matter distribution can be obtained, making it possible to view individual galaxies' dark matter halos and gain insight into the relative distributions of mass and light. Finally, mass imaging near the resolution limit of the core array of the Square Kilometer Array (SKA) is possible.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0849}
{"prompt": "Rephrase the abstract of an article with title 'The Common Origin of Linear and Nonlinear Chiral Multiplets in N=4   Mechanics'.   Elaborating on previous work (hep-th/0605211, hep-th/0611247), we show how the linear and nonlinear chiral multiplets of N=4 supersymmetric mechanics with the off-shell content (2,4,2) can be obtained by gauging three distinct two-parameter isometries of the ``root'' (4,4,0) multiplet actions. In particular, two different gauge groups, one abelian and one non-abelian, lead, albeit in a disguised form in the second case, to the same (unique) nonlinear chiral multiplet. This provides an evidence that no other nonlinear chiral N=4 multiplets exist. General sigma model type actions are discussed, together with the restricted potential terms coming from the Fayet-Iliopoulos terms associated with abelian gauge superfields. As in our previous work, we use the manifestly supersymmetric language of N=4, d=1 harmonic superspace. A novel point is the necessity to use in parallel the \\lambda and \\tau gauge frames, with the ``bridges'' between these two frames playing a crucial role. It is the N=4 harmonic analyticity which, though being non-manifest in the \\tau frame, gives rise to both linear and nonlinear chirality constraints.  ", "human_text": "  Elaborating on previous work (hep-th/0605211, hep-th/0611247), we show how the linear and nonlinear chiral multiplets of N=4 supersymmetric mechanics with the off-shell content (2,4,2) can be obtained by gauging three distinct two-parameter isometries of the ``root'' (4,4,0) multiplet actions. In particular, two different gauge groups, one abelian and one non-abelian, lead, albeit in a disguised form in the second case, to the same (unique) nonlinear chiral multiplet. This provides an evidence that no other nonlinear chiral N=4 multiplets exist. General sigma model type actions are discussed, together with the restricted potential terms coming from the Fayet-Iliopoulos terms associated with abelian gauge superfields. As in our previous work, we use the manifestly supersymmetric language of N=4, d=1 harmonic superspace. A novel point is the necessity to use in parallel the \\lambda and \\tau gauge frames, with the ``bridges'' between these two frames playing a crucial role. It is the N=4 harmonic analyticity which, though being non-manifest in the \\tau frame, gives rise to both linear and nonlinear chirality constraints. ", "machine_text": " This paper reveals the shared origin of linear and nonlinear chiral multiplets in N=4 mechanics with the (2,4,2) off-shell content. By gauging two distinct two-parameter isometries of the (4,4,0) multiplet action--one abelian, the other non-abelian--we uncover disguises of the same (unique) nonlinear chiral multiplet. This lends support to the idea that no other nonlinear N=4 chiral multiplets exist. We employ the language of N=4, d=1 harmonic superspace, using simultaneously the \\lambda and \\tau gauge frames, with the interconnections between them playing a vital role. As it turns out, it is the underlying N=4 harmonic analyticity that supplies both linear and nonlinear chirality constraints in the \\tau gauge, in spite of its non-manifest structure. Our approach additionally touches upon the possible sigma model type actions featuring restricted potential forms, followed by the discussion of their associated Fayet-Iliopoulos terms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0706}
{"prompt": "Rephrase the abstract of an article with title 'Stretching Homopolymers'.   Force induced stretching of polymers is important in a variety of contexts. We have used theory and simulations to describe the response of homopolymers, with $N$ monomers, to force ($f$) in good and poor solvents. In good solvents and for {{sufficiently large}} $N$ we show, in accord with scaling predictions, that the mean extension along the $f$ axis $<Z>\\sim f$ for small $f$, and $<Z>\\sim f^{{2/3}}$ (the Pincus regime) for intermediate values of $f$. The theoretical predictions for $\\la Z\\ra$ as a function of $f$ are in excellent agreement with simulations for N=100 and 1600. However, even with N=1600, the expected Pincus regime is not observed due to the the breakdown of the assumptions in the blob picture for finite $N$. {{We predict the Pincus scaling in a good solvent will be observed for $N\\gtrsim 10^5$}}. The force-dependent structure factors for a polymer in a poor solvent show that there are a hierarchy of structures, depending on the nature of the solvent. For a weakly hydrophobic polymer, various structures (ideal conformations, self-avoiding chains, globules, and rods) emerge on distinct length scales as $f$ is varied. A strongly hydrophobic polymer remains globular as long as $f$ is less than a critical value $f_c$. Above $f_c$, an abrupt first order transition to a rod-like structure occurs. Our predictions can be tested using single molecule experiments.  ", "human_text": "  Force induced stretching of polymers is important in a variety of contexts. We have used theory and simulations to describe the response of homopolymers, with $N$ monomers, to force ($f$) in good and poor solvents. In good solvents and for {{sufficiently large}} $N$ we show, in accord with scaling predictions, that the mean extension along the $f$ axis $<Z>\\sim f$ for small $f$, and $<Z>\\sim f^{{2/3}}$ (the Pincus regime) for intermediate values of $f$. The theoretical predictions for $\\la Z\\ra$ as a function of $f$ are in excellent agreement with simulations for N=100 and 1600. However, even with N=1600, the expected Pincus regime is not observed due to the the breakdown of the assumptions in the blob picture for finite $N$. {{We predict the Pincus scaling in a good solvent will be observed for $N\\gtrsim 10^5$}}. The force-dependent structure factors for a polymer in a poor solvent show that there are a hierarchy of structures, depending on the nature of the solvent. For a weakly hydrophobic polymer, various structures (ideal conformations, self-avoiding chains, globules, and rods) emerge on distinct length scales as $f$ is varied. A strongly hydrophobic polymer remains globular as long as $f$ is less than a critical value $f_c$. Above $f_c$, an abrupt first order transition to a rod-like structure occurs. Our predictions can be tested using single molecule experiments. ", "machine_text": " The properties of homopolymers when exposed to external force are of tremendous importance. To provide deeper insight, we have studied this using theoretical and computational approaches. Our results show that increasing the number of monomers, $N$, beyond a certain value, along with appropriate solvent conditions, allows for extension to follow a scaling of $<Z>\\sim f$ and $<Z>\\sim f^{{2/3}}$, respectively, for small and intermediate values of force ($f$). Corresponding to these regimes, simulations from N=100 to 1600 showcase excellent agreement which however, does not interpret for lower N. {{We predict, however, that the scaling behaviour should be firmly established for $N\\gtrsim 10^5$ in good solvent conditions.}} Moreover, the force-dependent structure factors for poor solvents exhibit a hierarchical arrangement of structures upon varying the force -- from ideal conformations, globules to rod-like structures. Hints of a first order transition from globular to rod-like structures can be experienced when the force is greater than its critical value $f_c$. Our findings may potentially be verified experimentally.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3029}
{"prompt": "Rephrase the abstract of an article with title 'The XMM-SSC survey of hard-spectrum XMM-Newton sources 1: optically   bright sources'.   We present optical and X-ray data for a sample of serendipitous XMM-Newton sources that are selected to have 0.5-2 keV vs 2-4.5 keV X-ray hardness ratios which are harder than the X-ray background. The sources have 2-4.5 keV X-ray flux >= 10^-14 cgs, and in this paper we examine a subsample of 42 optically bright (r < 21) sources; this subsample is 100 per cent spectroscopically identified. All but one of the optical counterparts are extragalactic, and we argue that the single exception, a Galactic M star, is probably a coincidental association. The X-ray spectra are consistent with heavily absorbed power laws (21.8 < log NH < 23.4), and all of them appear to be absorbed AGN. The majority of the sources show only narrow emission lines in their optical spectra, implying that they are type-2 AGN. Only a small fraction of the sources (7/42) show broad optical emission lines, and all of these have NH < 10^23 cm^-2. This implies that ratios of X-ray absorption to optical/UV extinction equivalent to > 100 times the Galactic gas-to-dust ratio are rare in AGN absorbers (at most a few percent of the population), and may be restricted to broad absorption-line QSOs. Seven objects appear to have an additional soft X-ray component in addition to the heavily absorbed power law. We consider the implications of our results in the light of the AGN unified scheme. We find that the soft components in narrow-line objects are consistent with the unified scheme provided that > 4 per cent of broad-line AGN have ionised absorbers that attenuate their soft X-ray flux by >50 per cent. In at least one of the X-ray absorbed, broad-line AGN in our sample the X-ray spectrum requires an ionised absorber, consistent with this picture.  ", "human_text": "  We present optical and X-ray data for a sample of serendipitous XMM-Newton sources that are selected to have 0.5-2 keV vs 2-4.5 keV X-ray hardness ratios which are harder than the X-ray background. The sources have 2-4.5 keV X-ray flux >= 10^-14 cgs, and in this paper we examine a subsample of 42 optically bright (r < 21) sources; this subsample is 100 per cent spectroscopically identified. All but one of the optical counterparts are extragalactic, and we argue that the single exception, a Galactic M star, is probably a coincidental association. The X-ray spectra are consistent with heavily absorbed power laws (21.8 < log NH < 23.4), and all of them appear to be absorbed AGN. The majority of the sources show only narrow emission lines in their optical spectra, implying that they are type-2 AGN. Only a small fraction of the sources (7/42) show broad optical emission lines, and all of these have NH < 10^23 cm^-2. This implies that ratios of X-ray absorption to optical/UV extinction equivalent to > 100 times the Galactic gas-to-dust ratio are rare in AGN absorbers (at most a few percent of the population), and may be restricted to broad absorption-line QSOs. Seven objects appear to have an additional soft X-ray component in addition to the heavily absorbed power law. We consider the implications of our results in the light of the AGN unified scheme. We find that the soft components in narrow-line objects are consistent with the unified scheme provided that > 4 per cent of broad-line AGN have ionised absorbers that attenuate their soft X-ray flux by >50 per cent. In at least one of the X-ray absorbed, broad-line AGN in our sample the X-ray spectrum requires an ionised absorber, consistent with this picture. ", "machine_text": "This research examines the optical and X-ray data of 42 serendipitously discovered  XMM-Newton sources whose X-ray hardness ratio is higher than the average X-ray background. All of these sources have 2-4.5 keV X-ray fluxes of at least 10^-14 cgs, and their optical counterparts are all found to be extragalactic apart from one Milky Way M star which likely has negligible connection. The X-ray spectra are consistent with heavily absorbed power law emission, hinting at a population of type-2 AGN. Amongst this sample, seven sources have a distinct secondary soft X-ray component, which is consistent with the AGN unified model if > 4 per cent of broad-line AGN features an ionised absorber that reduces their soft X-ray flux by more than half. In support of this, one of the X-ray absorbed, broad-line AGN in the sample clearly has an ionised absorber.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2971}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic Evolution of Black Holes and Spheroids. II: Scaling Relations at   z=0.36'.   We combine Hubble Space Telescope images of a sample of 20 Seyfert galaxies at z=0.36 with spectroscopic information from the Keck Telescope to determine the black hole mass - spheroid luminosity relation (M-L), the Fundamental Plane (FP) of the host galaxies and the M-sigma relation. Assuming pure luminosity evolution, we find that the host spheroids had smaller luminosity and stellar velocity dispersion than today for a fixed M. The offsets correspond to Delta log L_B,0=0.40+-0.11+-0.15 (Delta log M = 0.51+-0.14+-0.19) and Delta log sigma = 0.13+-0.03+-0.05 (Delta log M = 0.54+-0.12+-0.21), respectively for the M-L and M-sigma relation. A detailed analysis of known systematic errors and selection effects shows that they cannot account for the observed offset. The data are inconsistent with pure luminosity evolution and the existence of universal and tight scaling relations. To obey the three local scaling relations by z=0 the distant spheroids have to grow their stellar mass by approximately 60% (\\Delta log M_sph=0.20+-0.14) in the next 4 billion years. The measured evolution can be expressed as M/ M_sph ~ (1+z)^{1.5+-1.0}. Based on the disturbed morphologies of a fraction of the sample (6/20) we suggest collisional mergers with disk-dominated systems as evolutionary mechanism.  ", "human_text": "  We combine Hubble Space Telescope images of a sample of 20 Seyfert galaxies at z=0.36 with spectroscopic information from the Keck Telescope to determine the black hole mass - spheroid luminosity relation (M-L), the Fundamental Plane (FP) of the host galaxies and the M-sigma relation. Assuming pure luminosity evolution, we find that the host spheroids had smaller luminosity and stellar velocity dispersion than today for a fixed M. The offsets correspond to Delta log L_B,0=0.40+-0.11+-0.15 (Delta log M = 0.51+-0.14+-0.19) and Delta log sigma = 0.13+-0.03+-0.05 (Delta log M = 0.54+-0.12+-0.21), respectively for the M-L and M-sigma relation. A detailed analysis of known systematic errors and selection effects shows that they cannot account for the observed offset. The data are inconsistent with pure luminosity evolution and the existence of universal and tight scaling relations. To obey the three local scaling relations by z=0 the distant spheroids have to grow their stellar mass by approximately 60% (\\Delta log M_sph=0.20+-0.14) in the next 4 billion years. The measured evolution can be expressed as M/ M_sph ~ (1+z)^{1.5+-1.0}. Based on the disturbed morphologies of a fraction of the sample (6/20) we suggest collisional mergers with disk-dominated systems as evolutionary mechanism. ", "machine_text": " Using a sample of 20 Seyfert galaxies at z=0.36 combined with Hubble Space Telescope (HST) imaging and spectroscopic information from the Keck Telescope, we investigate the cosmic evolution of black holes and host spheroids by determining the black hole mass-luminosity (M-L) relation, the Fundamental Plane and the M-sigma relation. We find that the host spheroids present less luminosity and stellar velocity dispersion than today assuming pure luminosity evolution. This suggests an increase in stellar mass of approximately 60% in the next 4 billion years to obey the three local scaling relations. Systematic errors and selection effects cannot explain the observed offset. We conclude that the measured evolution can be expressed by M/M_sph ~ (1+z)^{1.5+-1.0}, and hypothesise possible incursion from collisional mergers with disk-dominated systems as the dominant evolutionary mechanism.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0519}
{"prompt": "Rephrase the abstract of an article with title 'How tight is the Lieb-Oxford bound?'.   Density-functional theory requires ever better exchange-correlation (xc) functionals for the ever more precise description of many-body effects on electronic structure. Universal constraints on the xc energy are important ingredients in the construction of improved functionals. Here we investigate one such universal property of xc functionals: the Lieb-Oxford lower bound on the exchange-correlation energy, $E_{xc}[n] \\ge -C \\int d^3r n^{4/3}$, where $C\\leq C_{LO}=1.68$. To this end, we perform a survey of available exact or near-exact data on xc energies of atoms, ions, molecules, solids, and some model Hamiltonians (the electron liquid, Hooke's atom and the Hubbard model). All physically realistic density distributions investigated are consistent with the tighter limit $C \\leq 1$. For large classes of systems one can obtain class-specific (but not fully universal) similar bounds. The Lieb-Oxford bound with $C_{LO}=1.68$ is a key ingredient in the construction of modern xc functionals, and a substantial change in the prefactor $C$ will have consequences for the performance of these functionals.  ", "human_text": "  Density-functional theory requires ever better exchange-correlation (xc) functionals for the ever more precise description of many-body effects on electronic structure. Universal constraints on the xc energy are important ingredients in the construction of improved functionals. Here we investigate one such universal property of xc functionals: the Lieb-Oxford lower bound on the exchange-correlation energy, $E_{xc}[n] \\ge -C \\int d^3r n^{4/3}$, where $C\\leq C_{LO}=1.68$. To this end, we perform a survey of available exact or near-exact data on xc energies of atoms, ions, molecules, solids, and some model Hamiltonians (the electron liquid, Hooke's atom and the Hubbard model). All physically realistic density distributions investigated are consistent with the tighter limit $C \\leq 1$. For large classes of systems one can obtain class-specific (but not fully universal) similar bounds. The Lieb-Oxford bound with $C_{LO}=1.68$ is a key ingredient in the construction of modern xc functionals, and a substantial change in the prefactor $C$ will have consequences for the performance of these functionals. ", "machine_text": " This paper examines the accuracy of the universal Lieb-Oxford lower bound on the exchange-correlation energy, $E_{xc}[n] \\ge -C \\int d^3r n^{4/3}$. To achieve this, we analyze available exact and nearly exact data on xc energies of atoms, ions, molecules, solids, and some model Hamiltonians. We determine that all observed physical density distributions are in line with the tighter limit of $C \\leq 1$. In addition, we find that for a variety of systems, a specific but not strictly universal bounded value can be assigned. The Lieb-Oxford bound, with a value of $C_{LO}=1.68$, is applied to the development of modern xc functionals, and for that reason any major change in the pre-factor of $C$ will affect the performance of these functionals.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2987}
{"prompt": "Rephrase the abstract of an article with title 'The Discovery of an Active Galactic Nucleus in the Late-type Galaxy NGC   3621: Spitzer Spectroscopic Observations'.   We report the discovery of an Active Galactic Nucleus (AGN) in the nearby SAd galaxy NGC 3621 using Spitzer high spectral resolution observations. These observations reveal the presence of [NeV] 14 um and 24 um emission which is centrally concentrated and peaks at the position of the near-infrared nucleus. Using the [NeV] line luminosity, we estimate that the nuclear bolometric luminosity of the AGN is ~ 5 X 10^41 ergs s^-1, which corresponds based on the Eddington limit to a lower mass limit of the black hole of ~ 4 X 10^3 Msun. Using an order of magnitude estimate for the bulge mass based on the Hubble type of the galaxy, we find that this lower mass limit does not put a strain on the well-known relationship between the black hole mass and the host galaxy's stellar velocity dispersion established in predominantly early-type galaxies. Mutli-wavelength follow-up observations of NGC 3621 are required to obtain more precise estimates of the bulge mass, black hole mass, accretion rate, and nuclear bolometric luminosity. The discovery reported here adds to the growing evidence that a black hole can form and grow in a galaxy with no or minimal bulge.  ", "human_text": "  We report the discovery of an Active Galactic Nucleus (AGN) in the nearby SAd galaxy NGC 3621 using Spitzer high spectral resolution observations. These observations reveal the presence of [NeV] 14 um and 24 um emission which is centrally concentrated and peaks at the position of the near-infrared nucleus. Using the [NeV] line luminosity, we estimate that the nuclear bolometric luminosity of the AGN is ~ 5 X 10^41 ergs s^-1, which corresponds based on the Eddington limit to a lower mass limit of the black hole of ~ 4 X 10^3 Msun. Using an order of magnitude estimate for the bulge mass based on the Hubble type of the galaxy, we find that this lower mass limit does not put a strain on the well-known relationship between the black hole mass and the host galaxy's stellar velocity dispersion established in predominantly early-type galaxies. Mutli-wavelength follow-up observations of NGC 3621 are required to obtain more precise estimates of the bulge mass, black hole mass, accretion rate, and nuclear bolometric luminosity. The discovery reported here adds to the growing evidence that a black hole can form and grow in a galaxy with no or minimal bulge. ", "machine_text": " Spitzer high resolution spectroscopic observations have led to the discovery of an Active Galactic Nucleus (AGN) in the nearby SAd galaxy NGC3621. These observations indicate the presence of [NeV] 14 and 24 um emissions, which peak at the near-infrared nucleus. Through analysis of the [NeV] line luminosity, nuclear bolometric luminosity is estimated to be ~5X10^41 ergs s^-1. Taking into account the Hubble type of the galaxy, this leads to a lower mass limit for the black hole of ~4X10^3 Msun, which is consistent with the established correlation of black hole mass to stellar velocity dispersion in predominantly early-type galaxies. In order further investigate this AGN, additional follow-up multi-wavelength observations are necessary to accurately measure the bulge mass, black hole mass, rate of accretion, and nuclear bolometric luminosity. This discovery supports the idea that black holes can form and develop in galaxies containing minimal or no bulge.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.105}
{"prompt": "Rephrase the abstract of an article with title 'Configuration Space Methods and Time Ordering for Scalar Propagators in   (Anti and) de Sitter Spacetimes'.   In this master thesis a configuration space method presented by C. Dullemond and E. van Beveren for computing all propagators of a scalar field (Wightman, Hadamard and Schwinger functions,retarded, advanced and Feynman propagator) is reviewed for four-dimensional Minkowski and Anti de Sitter spacetime AdS_4. This method is then applied for AdS_d as well as de Sitter spacetime dS_d of arbitrary dimension d, obtaining results in agreement with the literature. The advantages of the method are that it needs neither mode summation nor analytic continuation from euclidean time, while delivering the propagators above including (i-epsilon)-prescription, plus as a nice bonus the conformal dimension of a corresponding CFT field. General properties of the considered spacetimes (namely various coordinate systems and their metrics, chordal distances, relations between conformal dimensions \\Delta and the mass m of the scalar field, geodesics and the invariance of time ordering) are also examined and compiled from various sources, providing an overview of geometrical properties of AdS and dS spacetimes.  ", "human_text": "  In this master thesis a configuration space method presented by C. Dullemond and E. van Beveren for computing all propagators of a scalar field (Wightman, Hadamard and Schwinger functions,retarded, advanced and Feynman propagator) is reviewed for four-dimensional Minkowski and Anti de Sitter spacetime AdS_4. This method is then applied for AdS_d as well as de Sitter spacetime dS_d of arbitrary dimension d, obtaining results in agreement with the literature. The advantages of the method are that it needs neither mode summation nor analytic continuation from euclidean time, while delivering the propagators above including (i-epsilon)-prescription, plus as a nice bonus the conformal dimension of a corresponding CFT field. General properties of the considered spacetimes (namely various coordinate systems and their metrics, chordal distances, relations between conformal dimensions \\Delta and the mass m of the scalar field, geodesics and the invariance of time ordering) are also examined and compiled from various sources, providing an overview of geometrical properties of AdS and dS spacetimes. ", "machine_text": "This thesis reviews a configuration space method presented by C. Dullemond and E. van Beveren for computing all propagators of a scalar field in four-dimensional Minkowski and Anti de Sitter spacetimes AdS_4. Subsequently, this method is further applied to AdS_d and de Sitter dS_d for arbitrary dimension d, where the results agree with prior works. As a bonus, the conformal dimensions of the corresponding CFT fields are derived. Moreover, through assembling facts from various sources, the investigation compiles general geometric properties of AdS and dS spacetime into an overview, such as various coordinates, metrics, chordal distances, connections between conformal dimensions \\Delta and the scalar field's mass m, geodesic as well as the invariance of time ordering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1887}
{"prompt": "Rephrase the abstract of an article with title 'Radion Phenomenology in Realistic Warped Space Models'.   We investigate the phenomenology of the Randall-Sundrum radion in realistic models of electroweak symmetry breaking with bulk gauge and fermion fields, since the radion may turn out to be the lightest particle in such models. We calculate the coupling of the radion in such scenarios to bulk fermion and gauge modes. Special attention needs to be devoted to the coupling to massless gauge fields (photon, gluon), since it is well known that loop effects may be important for these fields. We also present a detailed explanation of these couplings from the CFT interpretation. We then use these couplings to determine the radion branching fractions and discuss some of the discovery potential of the LHC for the radion. We find that the gamma-gamma signal is enhanced over most of the range of the radion mass over the gamma-gamma signal of a SM Higgs, as long as the RS scale is sufficiently low. However, the signal significance depends strongly on free parameters that characterize the magnitude of bare brane-localized kinetic terms for the massless gauge fields. In the absence of such terms, the signal can be be enhanced over the traditional RS1 models (where all standard model fields are localized on the IR brane), but the signal can also be reduced compared to RS1 if the brane localized terms are sizeable. We also show that for larger radion masses, where the gamma-gamma signal is no longer significant, one can use the usual 4 lepton signal to discover the radion.  ", "human_text": "  We investigate the phenomenology of the Randall-Sundrum radion in realistic models of electroweak symmetry breaking with bulk gauge and fermion fields, since the radion may turn out to be the lightest particle in such models. We calculate the coupling of the radion in such scenarios to bulk fermion and gauge modes. Special attention needs to be devoted to the coupling to massless gauge fields (photon, gluon), since it is well known that loop effects may be important for these fields. We also present a detailed explanation of these couplings from the CFT interpretation. We then use these couplings to determine the radion branching fractions and discuss some of the discovery potential of the LHC for the radion. We find that the gamma-gamma signal is enhanced over most of the range of the radion mass over the gamma-gamma signal of a SM Higgs, as long as the RS scale is sufficiently low. However, the signal significance depends strongly on free parameters that characterize the magnitude of bare brane-localized kinetic terms for the massless gauge fields. In the absence of such terms, the signal can be be enhanced over the traditional RS1 models (where all standard model fields are localized on the IR brane), but the signal can also be reduced compared to RS1 if the brane localized terms are sizeable. We also show that for larger radion masses, where the gamma-gamma signal is no longer significant, one can use the usual 4 lepton signal to discover the radion. ", "machine_text": " We explore the implications of Randall-Sundrum radion in realistic warped space models, which include bulk gauge and fermion fields. We focus on the coupling of the radion to massless gauge fields (such as photons and gluons) due to the possibility of loop effects. We explain the couplings from the viewpoint of the conformal field theory. Using the obtained couplings, we calculate the radion decay branching fractions and the possibility for its detection at the LHC. In particular, we find that gamma spectra from the radion is enhanced from the ones from the Standard Model Higgs when the Randall-Sundrum scale is low. This signal can be amplified or suppressed depending on the size of the brane-localized kinetic terms. We depict the possibility to discover the radion through the four lepton channel in the case of larger radion masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3844}
{"prompt": "Rephrase the abstract of an article with title 'Molecular line intensities as measures of cloud masses - II. Conversion   factors for specific galaxy types'.   We present theoretically-established values of the CO-to-H2 and C-to-H2 conversion factors that may be used to estimate the gas masses of external galaxies. We consider four distinct galaxy types, represented by M51, NGC 6946, M82 and SMC N27. The physical parameters that best represent the conditions within the molecular clouds in each of the galaxy types are estimated using a chi^2 analysis of several observed atomic fine structure and CO rotational lines. This analysis is explored over a wide range of density, radiation field, extinction, and other relevant parameters. Using these estimated physical conditions in methods that we have previously established, CO-to-H2 conversion factors are then computed for CO transitions up to J=9-8. For the conventional CO(1-0) transition, the computed conversion factor varies significantly below and above the canonical value for the Milky Way in the four galaxy types considered. Since atomic carbon emission is now frequently used as a probe of external galaxies, we also present, for the first time, the C-to-H2 conversion factor for this emission in the four galaxy types considered.  ", "human_text": "  We present theoretically-established values of the CO-to-H2 and C-to-H2 conversion factors that may be used to estimate the gas masses of external galaxies. We consider four distinct galaxy types, represented by M51, NGC 6946, M82 and SMC N27. The physical parameters that best represent the conditions within the molecular clouds in each of the galaxy types are estimated using a chi^2 analysis of several observed atomic fine structure and CO rotational lines. This analysis is explored over a wide range of density, radiation field, extinction, and other relevant parameters. Using these estimated physical conditions in methods that we have previously established, CO-to-H2 conversion factors are then computed for CO transitions up to J=9-8. For the conventional CO(1-0) transition, the computed conversion factor varies significantly below and above the canonical value for the Milky Way in the four galaxy types considered. Since atomic carbon emission is now frequently used as a probe of external galaxies, we also present, for the first time, the C-to-H2 conversion factor for this emission in the four galaxy types considered. ", "machine_text": "This article provides theoretical predictions of conversion factors for gas mass quantification in four different galaxy types. We use chi-squared analysis to estimate physical parameters-- such as density, radiation field, and extinction-- that represent the conditions within the clouds of each galaxy type. Using methods established in a prior paper, we then calculate CO-to-H2 and C-to-H2 conversion factors which may be significantly different from the canonical value  applicable to the Milky Way. This investigation is establishing a new framework  for mass estimation for external galaxies expressed through CO and C emission.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2603}
{"prompt": "Rephrase the abstract of an article with title 'L'Univers en expansion et probl\\`emes d'\\'energie'.   In this paper we first construct a mathematical model for the Universe expansion that started up with the original Big Bang. Next, we discuss the problematic of the mechanical and physical laws invariance regarding the spatial frame exchanges. We then prove the (theoretical) existence of a variable metric $g_t$, depending on time and satisfying to a simplified Einstein equation, so that all free ordinary trajectories are geodesics. This is done by considering the classical Galileo-Newtonian space and time relation, by using generalized Newtonian principles and adding the approved physical new ones (as covariance principle, Mach principle, the Einstein equivalence principle ...) in order to establish a new cosmological model of the dynamical Universe as being $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$, where $B_e(O,t)$ is the Euclidean ball of radius $t$ in $\\mathbb R^3$. The cosmological metric $g_t$ is totally determined, at time $t$, by the mass energy distribution $E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove that the total and global cosmological energy distribution $E_t(X)$ satisfies to the wave equation whose solutions are characterized by pseudo-frequencies depending on time and related to the spectrum of the Dirichlet problem on the unit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\\Delta$. Our model is consistent in the sense that all Newtonian and classical physical laws are valid as particular cases in classical situations. Then, we show that all basic results of Modern Physics are still valid without using the second postulate of special relativity nor the uncertainty principle.  ", "human_text": "  In this paper we first construct a mathematical model for the Universe expansion that started up with the original Big Bang. Next, we discuss the problematic of the mechanical and physical laws invariance regarding the spatial frame exchanges. We then prove the (theoretical) existence of a variable metric $g_t$, depending on time and satisfying to a simplified Einstein equation, so that all free ordinary trajectories are geodesics. This is done by considering the classical Galileo-Newtonian space and time relation, by using generalized Newtonian principles and adding the approved physical new ones (as covariance principle, Mach principle, the Einstein equivalence principle ...) in order to establish a new cosmological model of the dynamical Universe as being $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$, where $B_e(O,t)$ is the Euclidean ball of radius $t$ in $\\mathbb R^3$. The cosmological metric $g_t$ is totally determined, at time $t$, by the mass energy distribution $E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove that the total and global cosmological energy distribution $E_t(X)$ satisfies to the wave equation whose solutions are characterized by pseudo-frequencies depending on time and related to the spectrum of the Dirichlet problem on the unit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\\Delta$. Our model is consistent in the sense that all Newtonian and classical physical laws are valid as particular cases in classical situations. Then, we show that all basic results of Modern Physics are still valid without using the second postulate of special relativity nor the uncertainty principle. ", "machine_text": " In this article, we analyze the expanding Universe and the related energy problems. To begin, we develop a mathematical model for the Universe's growth starting with the Big Bang. Then, we address issues regarding the invariance of mechanical and physical laws when dealing with spatial frames exchanges. To demonstrate the (theoretical) existence of a variable metric, which depends on time and abides by a simplified Einstein equation, allowing all ordinary trajectories to be geodesics, we utilize classical Galileo-Newtonian space time relations in addition to approved physical new applications such as the Covariance Principle, Mach Principle, and the Einstein Equivalence Principle. We present a new cosmological model of the dynamic Universe as $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$ alongside the cosmological metric $g_t$ which is at a current time $t$ totally determined by the mass energy distribution $E_t(X)$ on $B_e(O,t)$. Furthermore, we explore the phenomenon of blackholes and prove that the overall cosmological energy distribution $E_t(X)$ accords with a wave equation with solutions characterized by pseudo-frequencies subject to the Dirichlet problem on the unit ball $B_e(O,1)$ and the Laplace-Beltrami Operator -$\\Delta$. With this, we can ascertain that all Newtonian and classical physical laws are applicable in classical circumstances, and all core tenets of Modern Physics remain valid without utilizing the second postulate of special relativity or the uncertainty principle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1248}
{"prompt": "Rephrase the abstract of an article with title 'Using force covariance to derive effective stochastic interactions in   dissipative particle dynamics'.   There exist methods for determining effective conservative interactions in coarse grained particle based mesoscopic simulations. The resulting models can be used to capture thermal equilibrium behavior, but in the model system we study do not correctly represent transport properties. In this article we suggest the use of force covariance to determine the full functional form of dissipative and stochastic interactions. We show that a combination of the radial distribution function and a force covariance function can be used to determine all interactions in dissipative particle dynamics. Furthermore we use the method to test if the effective interactions in dissipative particle dynamics (DPD) can be adjusted to produce a force covariance consistent with a projection of a microscopic Lennard-Jones simulation. The results indicate that the DPD ansatz may not be consistent with the underlying microscopic dynamics. We discuss how this result relates to theoretical studies reported in the literature.  ", "human_text": "  There exist methods for determining effective conservative interactions in coarse grained particle based mesoscopic simulations. The resulting models can be used to capture thermal equilibrium behavior, but in the model system we study do not correctly represent transport properties. In this article we suggest the use of force covariance to determine the full functional form of dissipative and stochastic interactions. We show that a combination of the radial distribution function and a force covariance function can be used to determine all interactions in dissipative particle dynamics. Furthermore we use the method to test if the effective interactions in dissipative particle dynamics (DPD) can be adjusted to produce a force covariance consistent with a projection of a microscopic Lennard-Jones simulation. The results indicate that the DPD ansatz may not be consistent with the underlying microscopic dynamics. We discuss how this result relates to theoretical studies reported in the literature. ", "machine_text": " This paper explores a technique for deriving full, effective dissipative and stochastic interactions in mesoscopic simulations by utilizing force covariance. We demonstrate that a combination of the radial distribution function and a force covariance function can be employed to ascertain all interactions in dissipative particle dynamics. Examining the effectiveness of the method, we use the force covariance approach to assess whether the effective interactions of dissipative particle dynamics (DPD) are suitable to reflect the projection of a microscopic Lennard-Jones simulation. Our findings signify that, while the DPD model may correctly reproduce equilibrium behavior, it is not aligned with the underlying microscopic dynamics. We also comment on the connection of this outcome to results from other technical research in literature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3324}
{"prompt": "Rephrase the abstract of an article with title 'Solutions of fractional reaction-diffusion equations in terms of the   H-function'.   This paper deals with the investigation of the solution of an unified fractional reaction-diffusion equation associated with the Caputo derivative as the time-derivative and Riesz-Feller fractional derivative as the space-derivative. The solution is derived by the application of the Laplace and Fourier transforms in closed form in terms of the H-function. The results derived are of general nature and include the results investigated earlier by many authors, notably by Mainardi et al. (2001, 2005) for the fundamental solution of the space-time fractional diffusion equation, and Saxena et al. (2006a, b) for fractional reaction- diffusion equations. The advantage of using Riesz-Feller derivative lies in the fact that the solution of the fractional reaction-diffusion equation containing this derivative includes the fundamental solution for space-time fractional diffusion, which itself is a generalization of neutral fractional diffusion, space-fractional diffusion, and time-fractional diffusion. These specialized types of diffusion can be interpreted as spatial probability density functions evolving in time and are expressible in terms of the H-functions in compact form.  ", "human_text": "  This paper deals with the investigation of the solution of an unified fractional reaction-diffusion equation associated with the Caputo derivative as the time-derivative and Riesz-Feller fractional derivative as the space-derivative. The solution is derived by the application of the Laplace and Fourier transforms in closed form in terms of the H-function. The results derived are of general nature and include the results investigated earlier by many authors, notably by Mainardi et al. (2001, 2005) for the fundamental solution of the space-time fractional diffusion equation, and Saxena et al. (2006a, b) for fractional reaction- diffusion equations. The advantage of using Riesz-Feller derivative lies in the fact that the solution of the fractional reaction-diffusion equation containing this derivative includes the fundamental solution for space-time fractional diffusion, which itself is a generalization of neutral fractional diffusion, space-fractional diffusion, and time-fractional diffusion. These specialized types of diffusion can be interpreted as spatial probability density functions evolving in time and are expressible in terms of the H-functions in compact form. ", "machine_text": "This article explores methods for finding solutions to fractional reaction-diffusion equations utilising Laplace and Fourier transforms and the H-function. These solutions encompass previous research conducted by Mainardi et al. (2001, 2005) and Saxena et al. (2006a, b). Moreover, the advantage of utilising a Riesz-Feller derivative can be seen in the obtainment of solutions which incorporate a fundamental space-time fractional diffusion, as well as generalised neutral fractional, space-fractional and time-fractional diffusion. These types of diffusion can be interpreted as shifting spatial probability densities and can be expressed in terms of the H-function succinctly.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0329}
{"prompt": "Rephrase the abstract of an article with title 'Truecluster matching'.   Cluster matching by permuting cluster labels is important in many clustering contexts such as cluster validation and cluster ensemble techniques. The classic approach is to minimize the euclidean distance between two cluster solutions which induces inappropriate stability in certain settings. Therefore, we present the truematch algorithm that introduces two improvements best explained in the crisp case. First, instead of maximizing the trace of the cluster crosstable, we propose to maximize a chi-square transformation of this crosstable. Thus, the trace will not be dominated by the cells with the largest counts but by the cells with the most non-random observations, taking into account the marginals. Second, we suggest a probabilistic component in order to break ties and to make the matching algorithm truly random on random data. The truematch algorithm is designed as a building block of the truecluster framework and scales in polynomial time. First simulation results confirm that the truematch algorithm gives more consistent truecluster results for unequal cluster sizes. Free R software is available.  ", "human_text": "  Cluster matching by permuting cluster labels is important in many clustering contexts such as cluster validation and cluster ensemble techniques. The classic approach is to minimize the euclidean distance between two cluster solutions which induces inappropriate stability in certain settings. Therefore, we present the truematch algorithm that introduces two improvements best explained in the crisp case. First, instead of maximizing the trace of the cluster crosstable, we propose to maximize a chi-square transformation of this crosstable. Thus, the trace will not be dominated by the cells with the largest counts but by the cells with the most non-random observations, taking into account the marginals. Second, we suggest a probabilistic component in order to break ties and to make the matching algorithm truly random on random data. The truematch algorithm is designed as a building block of the truecluster framework and scales in polynomial time. First simulation results confirm that the truematch algorithm gives more consistent truecluster results for unequal cluster sizes. Free R software is available. ", "machine_text": "The infamous truematch algorithm offers two main improvements to traditional cluster matching techniques. First, it maximizes the chi-square transformation of a crosstable rather than solely relying on the trace. This leads to a more comprehensive assessment of the clusters, as it factors in all entries of the crosstable and utilizes the marginal values. Second, it provides a probabilistic solution to breaking ties in the matching process, allowing truly random matchup results when needed. In addition, it is designed to work within the truecluster framework and runs in polynomial time. Initial simulation results show that truematch produces more reliable results. Free R software is available.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4302}
{"prompt": "Rephrase the abstract of an article with title 'Dual Field Theories In (d-1)+1 Emergent Spacetimes From A Unifying Field   Theory In d+2 Spacetime'.   According to Two-Time Physics, there is more to space-time than can be garnered with the ordinary formulation of physics. Two-Time Physics has shown that the Standard Model of Particles and Forces is successfully reproduced by a two-time field theory in 4 space and 2 time dimensions projected as a holographic image on an emergent spacetime in 3+1 dimensions. Among the successes of this approach is the resolution of the strong CP problem of QCD as an outcome of the restrictions imposed by the higher symmetry structures in 4+2 dimensions. In this paper we launch a program to construct the duals of the Standard Model as other holographic images of the same 4+2 dimensional theory on a variety of emergent spacetimes in 3+1 dimensions. These dual field theories are obtained as a family of gauge choices in the master 4+2 field theory. In the present paper we deal with some of the simpler gauge choices which lead to interacting Klein-Gordon field theories for the conformal scalar with a predicted SO(d,2) symmetry in a variety of interesting curved spacetimes in (d-1)+1 dimensions. More challenging and more interesting gauge choices (including some that relate to mass) which are left to future work are also outlined. Through this approach we discover a new realm of previously unexplored dualities and hidden symmetries that exist both in the macroscopic and microscopic worlds, at the classical and quantum levels. Such phenomena predicted by 2T-physics can in principle be confirmed both by theory and experiment. 1T-physics can be used to analyze the predictions but in most instances gives no clue that the predicted phenomena exist in the first place. This point of view suggests a new paradigm for the construction of a fundamental theory that is likely to impact on the quest for unification.  ", "human_text": "  According to Two-Time Physics, there is more to space-time than can be garnered with the ordinary formulation of physics. Two-Time Physics has shown that the Standard Model of Particles and Forces is successfully reproduced by a two-time field theory in 4 space and 2 time dimensions projected as a holographic image on an emergent spacetime in 3+1 dimensions. Among the successes of this approach is the resolution of the strong CP problem of QCD as an outcome of the restrictions imposed by the higher symmetry structures in 4+2 dimensions. In this paper we launch a program to construct the duals of the Standard Model as other holographic images of the same 4+2 dimensional theory on a variety of emergent spacetimes in 3+1 dimensions. These dual field theories are obtained as a family of gauge choices in the master 4+2 field theory. In the present paper we deal with some of the simpler gauge choices which lead to interacting Klein-Gordon field theories for the conformal scalar with a predicted SO(d,2) symmetry in a variety of interesting curved spacetimes in (d-1)+1 dimensions. More challenging and more interesting gauge choices (including some that relate to mass) which are left to future work are also outlined. Through this approach we discover a new realm of previously unexplored dualities and hidden symmetries that exist both in the macroscopic and microscopic worlds, at the classical and quantum levels. Such phenomena predicted by 2T-physics can in principle be confirmed both by theory and experiment. 1T-physics can be used to analyze the predictions but in most instances gives no clue that the predicted phenomena exist in the first place. This point of view suggests a new paradigm for the construction of a fundamental theory that is likely to impact on the quest for unification. ", "machine_text": " Two-Time Physics opens the possibility for a more in-depth description of the space-time by allowing the Standard Model of Particles and Forces to be successfully expressed as a two-time field theory. This approach provides a resolution for the strong CP problem of QCD, found through its higher dimensional symmetry structures. As a part of this paper, a process is described to build the duals of the Standard Model using the same four and two dimensional theory as holographic images. Particularly, the effects of a variety of interesting curved spacetimes in (d-1)+1 dimensions are studied in order to demonstrate the effects of simpler gauge choices made while creating the master 4+2 dimensional field theory. The result is the establishment of Klein-Gordon field theories with SO(d,2) symmetry. Furthermore, more challenging and more intricate gauge choices, such as those related to mass, are proposed for future work. This progression suggests a new framework of dualities and hidden symmetries found both in the macroscopic and microscopic universes and at the classical and quantum levels. Through this, One-Time Physics may be used to confirm the 2T-physics predictions through theory and experiment, providing a distinct approach toward the unification of theories.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2834}
{"prompt": "Rephrase the abstract of an article with title 'Jet-breaks in the X-ray Light-Curves of Swift GRB Afterglows'.   In the set of 236 GRB afterglows observed by Swift between January 2005 and March 2007, we identify 30 X-ray light-curves whose power-law fall-off exhibit a steepening (\"break\") at 0.1-10 day after trigger, to a decay steeper than t^{-1.5}. For most of these afterglows, the X-ray spectral slope and the decay indices before and after the break can be accommodated by the standard jet model although a different origin of the breaks cannot be ruled out. In addition, there are 27 other afterglows whose X-ray light-curves may also exhibit a late break to a steep decay, but the evidence is not that compelling.   The X-ray emissions of 38 afterglows decay slower than t^{-1.5} until after 3 day, half of them exhibiting such a slow decay until after 10 day.   Therefore, the fraction of well-monitored Swift afterglows with potential jet-breaks is around 60 percent, whether we count only the strongest cases for each type or all of them. This fraction is comparable to the 75 percent of pre-Swift afterglows whose optical light-curves displayed similar breaks at ~1 day.   The properties of the prompt emission of Swift afterglows with light-curve breaks show the same correlations (peak energy of GRB spectrum with the burst isotropic output and with burst collimated output) as previously found for pre-Swift optical afterglows with light-curve breaks (the Amati and Ghirlanda relations, respectively). However, we find that Ghirlanda relation is largely a consequence of Amati's and that the use of the jet-break time leads to a stronger Ghirlanda correlation only when the few outliers to the Amati relation are included.  ", "human_text": "  In the set of 236 GRB afterglows observed by Swift between January 2005 and March 2007, we identify 30 X-ray light-curves whose power-law fall-off exhibit a steepening (\"break\") at 0.1-10 day after trigger, to a decay steeper than t^{-1.5}. For most of these afterglows, the X-ray spectral slope and the decay indices before and after the break can be accommodated by the standard jet model although a different origin of the breaks cannot be ruled out. In addition, there are 27 other afterglows whose X-ray light-curves may also exhibit a late break to a steep decay, but the evidence is not that compelling.   The X-ray emissions of 38 afterglows decay slower than t^{-1.5} until after 3 day, half of them exhibiting such a slow decay until after 10 day.   Therefore, the fraction of well-monitored Swift afterglows with potential jet-breaks is around 60 percent, whether we count only the strongest cases for each type or all of them. This fraction is comparable to the 75 percent of pre-Swift afterglows whose optical light-curves displayed similar breaks at ~1 day.   The properties of the prompt emission of Swift afterglows with light-curve breaks show the same correlations (peak energy of GRB spectrum with the burst isotropic output and with burst collimated output) as previously found for pre-Swift optical afterglows with light-curve breaks (the Amati and Ghirlanda relations, respectively). However, we find that Ghirlanda relation is largely a consequence of Amati's and that the use of the jet-break time leads to a stronger Ghirlanda correlation only when the few outliers to the Amati relation are included. ", "machine_text": " This article discusses the observation of 236 GRB afterglows out of which 30 have their X-ray light-curves exhibiting an abrupt steepening (\"break\") anywhere between 0.1 and 10 days after the trigger. It is argued that majority of these can be attributed to a standard jet model, however, other possibilities are yet to be ruled out. Meanwhile, 27 other afterglows appear to display a similar break, even though the evidence is not that convincing. It is theorized then, that the fraction of well-monitored Swift afterglows with potential jet-breaks should be around 60 percent, comparable to the 75 percent of those prior to Swift studied using 1 day optical light-curves breaks. Further, the correlation between the peak energy of GRB spectrum for isotropic and collimated output with the jet-breaker time is explored, indicating an amended version of the previously established Amati and Ghirlanda relations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1015}
{"prompt": "Rephrase the abstract of an article with title 'X-ray detection of the substellar twin 2MASS J11011926-7732383 AB'.   2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star forming region, is a rare wide-separation brown dwarf binary. XMM-Newton and Chandra observations of 2M1101AB have allowed us to examine the influence of physical parameters (mass, bolometric luminosity and effective temperature) on X-ray emission from a coeval pair of substellar objects. The spatial resolution of XMM-Newton is not sufficient to separate contributions from the two components in the binary. The X-ray source detected with XMM-Newton has a column density compatible with the infrared extinction of component A. On the other hand, the binary is resolved with Chandra, and the bulk of the X-ray emission is clearly associated with the photospherically cooler component B. These apparently contradictory results point at strong variability of 2M1101's X-ray emission. Combined with previous sensitive X-ray observations from low-mass members of ChaI, we find a decline of X-ray luminosity with decreasing (sub)stellar mass that is typical for star forming regions. 2M1101B is the coolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in X-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members, and therefore relatively luminous. Most bona fide brown dwarfs of Cha I have remained below the sensitivity limits of available X-ray observations, because of their low luminosity associated with higher age.  ", "human_text": "  2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star forming region, is a rare wide-separation brown dwarf binary. XMM-Newton and Chandra observations of 2M1101AB have allowed us to examine the influence of physical parameters (mass, bolometric luminosity and effective temperature) on X-ray emission from a coeval pair of substellar objects. The spatial resolution of XMM-Newton is not sufficient to separate contributions from the two components in the binary. The X-ray source detected with XMM-Newton has a column density compatible with the infrared extinction of component A. On the other hand, the binary is resolved with Chandra, and the bulk of the X-ray emission is clearly associated with the photospherically cooler component B. These apparently contradictory results point at strong variability of 2M1101's X-ray emission. Combined with previous sensitive X-ray observations from low-mass members of ChaI, we find a decline of X-ray luminosity with decreasing (sub)stellar mass that is typical for star forming regions. 2M1101B is the coolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in X-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members, and therefore relatively luminous. Most bona fide brown dwarfs of Cha I have remained below the sensitivity limits of available X-ray observations, because of their low luminosity associated with higher age. ", "machine_text": " Using X-ray detection methods, we have studied the twin brown dwarf 2MASS J11011926-7732383 AB (hereafter 2M1101AB) present in the Cha I star formation region. XMM-Newton and Chandra data are used to observe the influence on X-ray emission of physical parameters (mass, bolometric luminosity, and effective temperature) for this coeval pair of substellar bodies. Although the XMM-Newton resolution is not adequate to distinguish contributions from the two components of the binary, the column density of the X-ray source detected with it is analogous to the infrared extinction of component A. Also, Chandra can resolve the binary and suggests that the bulk of the X-ray emission is related to the photospherically cooler component B. These seemingly discrepant conclusions appear to be indicates of the X-ray emission's intense variability. When combined with formerly conducted sensitive X-ray surveys of low-mass members of Cha I, it can be understood that X-ray luminosity slowly declines as (sub)stellar mass decreases, as is regularly seen in star formation regions. 2M1101B, the coolest (M8.25 type) and least massive brown dwarf in Cha I thus far detected in X-rays, is also one of the youngest (~ 1 Myr) substellar members of Cha I and therefore relatively luminous. Most bona fide brown dwarfs of Cha I have remained out of reach of the sensitivity limits of available X-ray observations due to the combination of their low luminosity and higher age.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2301}
{"prompt": "Rephrase the abstract of an article with title 'Geometrical properties of local dynamics in Hamiltonian systems: the   Generalized Alignment Index (GALI) method'.   We investigate the detailed dynamics of multidimensional Hamiltonian systems by studying the evolution of volume elements formed by unit deviation vectors about their orbits. The behavior of these volumes is strongly influenced by the regular or chaotic nature of the motion, the number of deviation vectors, their linear (in)dependence and the spectrum of Lyapunov exponents. The different time evolution of these volumes can be used to identify rapidly and efficiently the nature of the dynamics, leading to the introduction of quantities that clearly distinguish between chaotic behavior and quasiperiodic motion on $N$-dimensional tori. More specifically we introduce the Generalized Alignment Index of order $k$ (GALI$_k$) as the volume of a generalized parallelepiped, whose edges are $k$ initially linearly independent unit deviation vectors from the studied orbit whose magnitude is normalized to unity at every time step. The GALI$_k$ is a generalization of the Smaller Alignment Index (SALI) (GALI$_2$ $\\propto$ SALI). However, GALI$_k$ provides significantly more detailed information on the local dynamics, allows for a faster and clearer distinction between order and chaos than SALI and works even in cases where the SALI method is inconclusive.  ", "human_text": "  We investigate the detailed dynamics of multidimensional Hamiltonian systems by studying the evolution of volume elements formed by unit deviation vectors about their orbits. The behavior of these volumes is strongly influenced by the regular or chaotic nature of the motion, the number of deviation vectors, their linear (in)dependence and the spectrum of Lyapunov exponents. The different time evolution of these volumes can be used to identify rapidly and efficiently the nature of the dynamics, leading to the introduction of quantities that clearly distinguish between chaotic behavior and quasiperiodic motion on $N$-dimensional tori. More specifically we introduce the Generalized Alignment Index of order $k$ (GALI$_k$) as the volume of a generalized parallelepiped, whose edges are $k$ initially linearly independent unit deviation vectors from the studied orbit whose magnitude is normalized to unity at every time step. The GALI$_k$ is a generalization of the Smaller Alignment Index (SALI) (GALI$_2$ $\\propto$ SALI). However, GALI$_k$ provides significantly more detailed information on the local dynamics, allows for a faster and clearer distinction between order and chaos than SALI and works even in cases where the SALI method is inconclusive. ", "machine_text": " We analyze the dynamical characteristics of Hamiltonian systems in multiple dimensions by examining changes in the volume of a unit deviance vector around its orbit. This volume is heavily influenced by the regularity or chaoticity of the motion, the number of deviance vectors, their linear dependency and the spectrum of its Lyapunov exponents. The fluctuating shape of this volume can be used to quickly categorize the nature of the system, leading to the development of measures that allow for a clear distinction between chaos and quasiperiodic motion on N-dimensional tori. In particular, we introduce the Generalized Alignment Index of order k (GALI$_k$), which is the volume of a generalized parallelepiped included with k initially independent unit deviance vectors of size normalized to one at each time step. This GALI$_k$ index is an extension of the Smaller Alignment Index (SALI) and provides a deeper analysis of the local dynamics. It is more efficient in distinguishing between order and chaos than SALI and can be applied even when SALI yields inconclusive results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3155}
{"prompt": "Rephrase the abstract of an article with title 'Finite-size effects in roughness distribution scaling'.   We study numerically finite-size corrections in scaling relations for roughness distributions of various interface growth models. The most common relation, which considers the average roughness $<w_2>$ as scaling factor, is not obeyed in the steady states of a group of ballistic-like models in 2+1 dimensions, even when very large system sizes are considered. On the other hand, good collapse of the same data is obtained with a scaling relation that involves the root mean square fluctuation of the roughness, which can be explained by finite-size effects on second moments of the scaling functions. We also obtain data collapse with an alternative scaling relation that accounts for the effect of the intrinsic width, which is a constant correction term previously proposed for the scaling of $<w_2>$. This illustrates how finite-size corrections can be obtained from roughness distributions scaling. However, we discard the usual interpretation that the intrinsic width is a consequence of high surface steps by analyzing data of restricted solid-on-solid models with various maximal height differences between neighboring columns. We also observe that large finite-size corrections in the roughness distributions are usually accompanied by huge corrections in height distributions and average local slopes, as well as in estimates of scaling exponents. The molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1 dimensions is a case example in which none of the proposed scaling relations works properly, while the other measured quantities do not converge to the expected asymptotic values. Thus, although roughness distributions are clearly better than other quantities to determine the universality class of a growing system, it is not the final solution for this task.  ", "human_text": "  We study numerically finite-size corrections in scaling relations for roughness distributions of various interface growth models. The most common relation, which considers the average roughness $<w_2>$ as scaling factor, is not obeyed in the steady states of a group of ballistic-like models in 2+1 dimensions, even when very large system sizes are considered. On the other hand, good collapse of the same data is obtained with a scaling relation that involves the root mean square fluctuation of the roughness, which can be explained by finite-size effects on second moments of the scaling functions. We also obtain data collapse with an alternative scaling relation that accounts for the effect of the intrinsic width, which is a constant correction term previously proposed for the scaling of $<w_2>$. This illustrates how finite-size corrections can be obtained from roughness distributions scaling. However, we discard the usual interpretation that the intrinsic width is a consequence of high surface steps by analyzing data of restricted solid-on-solid models with various maximal height differences between neighboring columns. We also observe that large finite-size corrections in the roughness distributions are usually accompanied by huge corrections in height distributions and average local slopes, as well as in estimates of scaling exponents. The molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1 dimensions is a case example in which none of the proposed scaling relations works properly, while the other measured quantities do not converge to the expected asymptotic values. Thus, although roughness distributions are clearly better than other quantities to determine the universality class of a growing system, it is not the final solution for this task. ", "machine_text": " In this article, we investigate numerically the finite-size effects that affect the scaling behavior of roughness distributions in different interface growth models. Contrary to the usual assumption that the average roughness $<w_2>$ is a suitable scaling factor, we observe that this result is not valid for a variety of ballistic-like models in 2+1 dimensions, even when large system sizes are considered. To explain this phenomenon, we propose a scaling relation that involves the root mean square fluctuation of the roughness, which successfully collapses the data. We also find that accounting for the constant intrinsic width correction term significantly improves the scaling of $<w_2>$. Moreover, our study disproves the conventional assertion that intrinsic width originates from high surface steps by analyzing data from restricted solid-on-solid models with a range of maximal height variations between neighbor columns. Finally, we find that finite size corrections in roughness distributions are often coupled with sizable corrections in height distributions, average local slopes, and estimates of scaling exponents. As a case example, we analyze the molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1 dimensions, and find that none of the proposed scaling relations yield satisfactory results. Our findings demonstrate that roughness distributions are superior tools for determining the universality class of a growing system, though they cannot provide a definite solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1307}
{"prompt": "Rephrase the abstract of an article with title 'Finite determination of regular (a,b)-modules'.   The concept of (a,b)-module comes from the study the Gauss-Manin lattices of an isolated singularity of a germ of an holomorphic function. It is a very simple ''abstract algebraic structure'', but very rich, whose prototype is the formal completion of the Brieskorn-module of an isolated singularity. The aim of this article is to prove a very basic theorem on regular (a,b)-modules showing that a given regular (a,b)-module is completely characterized by some ''finite order jet'' of its structure. Moreover a very simple bound for such a sufficient order is given in term of the rank and of two very simple invariants : the regularity order which count the number of times you need to apply \\ $b^{-1}.a \\simeq \\partial_z.z$ in order to reach a simple pole (a,b)-module. The second invariant is the ''width'' which corresponds, in the simple pole case, to the maximal integral difference between to eigenvalues of $b^{-1}.a$   (the logarithm of the monodromy). In the computation of examples this theorem is quite helpfull because it tells you at which power of $b$ in the expansions you may stop without loosing any information.  ", "human_text": "  The concept of (a,b)-module comes from the study the Gauss-Manin lattices of an isolated singularity of a germ of an holomorphic function. It is a very simple ''abstract algebraic structure'', but very rich, whose prototype is the formal completion of the Brieskorn-module of an isolated singularity. The aim of this article is to prove a very basic theorem on regular (a,b)-modules showing that a given regular (a,b)-module is completely characterized by some ''finite order jet'' of its structure. Moreover a very simple bound for such a sufficient order is given in term of the rank and of two very simple invariants : the regularity order which count the number of times you need to apply \\ $b^{-1}.a \\simeq \\partial_z.z$ in order to reach a simple pole (a,b)-module. The second invariant is the ''width'' which corresponds, in the simple pole case, to the maximal integral difference between to eigenvalues of $b^{-1}.a$   (the logarithm of the monodromy). In the computation of examples this theorem is quite helpfull because it tells you at which power of $b$ in the expansions you may stop without loosing any information. ", "machine_text": " This article investigates a basic theorem regarding regular (a,b)-modules, which determines that a given regular (a,b)-module is entirely specified by a 'finite order jet' of its structure. A simple bound for this sufficient order is explained--in terms of rank and two basic invariants--the regularity order, which counts the number of times the operator $\\partial_z.z$ must be applied in order to achieve a simple pole (a, b)-module; and the 'width' which, in the case of a simple pole, is the largest integral difference between the eigenvalues of $b^{-1}.a$ (the logarithm of the monodromy). This theorem proves helpful in the computation of examples as it specifies up to which power of $b$ in an expansion must be taken into account to not lose any information.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2995}
{"prompt": "Rephrase the abstract of an article with title 'A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman   Break Galaxy at z=3.07'.   We report the detection of CO(3-2) emission from a bright, gravitationally lensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07 using the Plateau de Bure Interferometer. This is only the second detection of molecular gas emission from an LBG and yields an intrinsic molecular gas mass of (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG indicates that it comprises two components separated by ~2 kpc. The CO emission is unresolved, and appears to be centered on the intrinsically fainter (and also less highly magnified) of the two UV components. The width of the CO line indicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc. Employing mid-infrared observations from Spitzer we derive a stellar mass of ~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the molecular gas will be consumed in ~40 Myr. The gas fractions, star-formation efficiencies and line widths suggests that LBGJ213512 is a high-redshift, gas-rich analog of a local luminous infrared galaxy. This galaxy has a similar gas-to-dynamical mass fraction as observed in the submillimeter-selected population, although the gas surface density and star-formation efficiency is a factor of 3x less, suggesting less vigorous activity. We discuss the uncertainties in our conclusions arising from adopting a CO-to-H2 conversion factor appropriate for either the Milky Way or local luminous infrared galaxies. These observations demonstrate that current facilities, when aided by fortuitous gravitational magnification, can study 'ordinary' galaxies at high-redshift and so act as pathfinders for ALMA.  ", "human_text": "  We report the detection of CO(3-2) emission from a bright, gravitationally lensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07 using the Plateau de Bure Interferometer. This is only the second detection of molecular gas emission from an LBG and yields an intrinsic molecular gas mass of (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG indicates that it comprises two components separated by ~2 kpc. The CO emission is unresolved, and appears to be centered on the intrinsically fainter (and also less highly magnified) of the two UV components. The width of the CO line indicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc. Employing mid-infrared observations from Spitzer we derive a stellar mass of ~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the molecular gas will be consumed in ~40 Myr. The gas fractions, star-formation efficiencies and line widths suggests that LBGJ213512 is a high-redshift, gas-rich analog of a local luminous infrared galaxy. This galaxy has a similar gas-to-dynamical mass fraction as observed in the submillimeter-selected population, although the gas surface density and star-formation efficiency is a factor of 3x less, suggesting less vigorous activity. We discuss the uncertainties in our conclusions arising from adopting a CO-to-H2 conversion factor appropriate for either the Milky Way or local luminous infrared galaxies. These observations demonstrate that current facilities, when aided by fortuitous gravitational magnification, can study 'ordinary' galaxies at high-redshift and so act as pathfinders for ALMA. ", "machine_text": " We use the Plateau de Bure Interferometer to detect CO(3-2) emission from a bright, gravitationally magnified Lyman Break Galaxy, LBGJ213512.73-010143, at z=3.07. This is the second detection of molecular gas from an LBG, from which we infer an intrinsic molecular gas mass of (2.4+/-0.4)x10^9 Mo. Through lens reconstruction of the UV morphology of the LBG, we find two components separated by ~2 kpc; CO emission appears to be centered on the fainter UV component. The velocity width of the line indicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc. Using analysis of mid-infrared observations from Spitzer, we determine the stellar mass to be ~(6+/-2)x10^9 Mo, and the star-formation rate to be ~60 Mo/yr; this suggests the molecular gas could be consumed in ~40 Myr. Our study reveals the Cosmic Eye to be a high-redshift, gas-rich analog of a local luminous infrared galaxy, though with a lower gas fraction, gas surface density and star-formation efficiency than submillimeter-selected galaxies. This observation serves as an example of how current facilities, augmented by gravitational magnification, can study 'ordinary' galaxies at high-redshift, foreshadowing the capabilities of ALMA.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1721}
{"prompt": "Rephrase the abstract of an article with title 'Measuring energy dependent polarization in soft gamma-rays using Compton   scattering in PoGOLite'.   Linear polarization in X- and gamma-rays is an important diagnostic of many astrophysical sources, foremost giving information about their geometry, magnetic fields, and radiation mechanisms. However, very few X-ray polarization measurements have been made, and then only mono-energetic detections, whilst several objects are assumed to have energy dependent polarization signatures. In this paper we investigate whether detection of energy dependent polarization from cosmic sources is possible using the Compton technique, in particular with the proposed PoGOLite balloon-experiment, in the 25-100 keV range. We use Geant4 simulations of a PoGOLite model and input photon spectra based on Cygnus X-1 and accreting magnetic pulsars (100 mCrab). Effective observing times of 6 and 35 hours were simulated, corresponding to a standard and a long duration flight respectively. Both smooth and sharp energy variations of the polarization are investigated and compared to constant polarization signals using chi-square statistics. We can reject constant polarization, with energy, for the Cygnus X-1 spectrum (in the hard state), if the reflected component is assumed to be completely polarized, whereas the distinction cannot be made for weaker polarization. For the accreting pulsar, constant polarization can be rejected in the case of polarization in a narrow energy band with at least 50% polarization, and similarly for a negative step distribution from 30% to 0% polarization.  ", "human_text": "  Linear polarization in X- and gamma-rays is an important diagnostic of many astrophysical sources, foremost giving information about their geometry, magnetic fields, and radiation mechanisms. However, very few X-ray polarization measurements have been made, and then only mono-energetic detections, whilst several objects are assumed to have energy dependent polarization signatures. In this paper we investigate whether detection of energy dependent polarization from cosmic sources is possible using the Compton technique, in particular with the proposed PoGOLite balloon-experiment, in the 25-100 keV range. We use Geant4 simulations of a PoGOLite model and input photon spectra based on Cygnus X-1 and accreting magnetic pulsars (100 mCrab). Effective observing times of 6 and 35 hours were simulated, corresponding to a standard and a long duration flight respectively. Both smooth and sharp energy variations of the polarization are investigated and compared to constant polarization signals using chi-square statistics. We can reject constant polarization, with energy, for the Cygnus X-1 spectrum (in the hard state), if the reflected component is assumed to be completely polarized, whereas the distinction cannot be made for weaker polarization. For the accreting pulsar, constant polarization can be rejected in the case of polarization in a narrow energy band with at least 50% polarization, and similarly for a negative step distribution from 30% to 0% polarization. ", "machine_text": " This paper studies the possibility of detecting and measuring changes in linear polarization of different X- and gamma-ray spectral energy ranges that arise from multiple astrophysical sources. Of particular interest is the PoGOLite balloon-experiment and the 25-100 keV range of radiation. Using Geant4 simulations, we analyze hypothetical photon spectra based on Cygnus X-1 and accreting magnetic pulsars, with effective times of 6 and 35 hours which correspond to a standard and long duration flight. We compare simulated energy-dependent and constant polarization signals to identify any departures from the constant polarization scenario. Results of the comparative analysis indicated that, in the case of Cygnus X-1, energy-dependent polarization can be detected when the reflected component is assumed to be completely polarized. Inversely, the simulated spectra of accreting pulsars, depending on the degree of polarization, could enable rejection of constant polarization in the case of an energy concentrated signal with at least 50% polarization, and for a decrease from 30% to 0%.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1603}
{"prompt": "Rephrase the abstract of an article with title 'The metallicity distributions in high-latitudes with SDSS'.   We present metallicities and their variations with different parameters for 36 high-latitude fields covering Galactic longitudes 0<l<360. The metallicities for relatively short vertical distances (z<2.5 kpc) show systematic fluctuations with Galactic longitude, similar to those of the thick-disc scaleheight, which may be interpreted as indicating a common origin, viz., the flare effect of the disc. This suggestion is supported by the metallicity variations which we find as functions of radial distance. The metallicity variation at larger vertical distances (6.5<z<9.5 kpc) is small but monotonic. Three different vertical metallicity gradients could be detected: d[M/H]/dz=-0.22(+/-0.03), d[M/H]/dz=-0.38 (+/-0.06), and d[M/H]/dz=-0.08 (+/-0.07) dex/kpc for the intervals z<3, 3<z<5, and 5<z<10 kpc, respectively. Since our data cover the whole Galactic longitude interval, the resulting metallicity gradients can be interpreted as properties of the larger-scale Galaxy. The first gradient confirms the dissipational formation of the disc at short z-distances. The steeper gradient corresponds to the transition region between different population components of the Galaxy, and finally, the lowest value provides an adequate description of the inner-halo metallicity gradient.  ", "human_text": "  We present metallicities and their variations with different parameters for 36 high-latitude fields covering Galactic longitudes 0<l<360. The metallicities for relatively short vertical distances (z<2.5 kpc) show systematic fluctuations with Galactic longitude, similar to those of the thick-disc scaleheight, which may be interpreted as indicating a common origin, viz., the flare effect of the disc. This suggestion is supported by the metallicity variations which we find as functions of radial distance. The metallicity variation at larger vertical distances (6.5<z<9.5 kpc) is small but monotonic. Three different vertical metallicity gradients could be detected: d[M/H]/dz=-0.22(+/-0.03), d[M/H]/dz=-0.38 (+/-0.06), and d[M/H]/dz=-0.08 (+/-0.07) dex/kpc for the intervals z<3, 3<z<5, and 5<z<10 kpc, respectively. Since our data cover the whole Galactic longitude interval, the resulting metallicity gradients can be interpreted as properties of the larger-scale Galaxy. The first gradient confirms the dissipational formation of the disc at short z-distances. The steeper gradient corresponds to the transition region between different population components of the Galaxy, and finally, the lowest value provides an adequate description of the inner-halo metallicity gradient. ", "machine_text": "We investigate the metallicity distributions in high-latitudes with the Sloan Digital Sky Survey (SDSS). Data covers Galactic longitudes 0<l<360. We observe significant fluctuations in metallicity at z<2.5 kpc, similar to those in the thick-disc scaleheight, as a result of the Galactic flare effect. Additionally, our results suggest three different vertical metallicity gradients of d[M/H]/dz=-0.22(+/-0.03), d[M/H]/dz=-0.38 (+/-0.06), and d[M/H]/dz=-0.08 (+/-0.07) dex/kpc for z<3, 3<z<5, and 5<z<10 kpc, respectively. Our data indicates the dissipational formation of the disc at short distances, a transition between different population components of the Galaxy, and a low value to describe the inner-halo metallicity gradient.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3477}
{"prompt": "Rephrase the abstract of an article with title 'Neutral Networks of Sequence to Shape Maps'.   In this paper we present a novel framework for sequence to shape maps. These combinatorial maps realize exponentially many shapes, and have preimages which contain extended connected subgraphs of diameter n (neutral networks). We prove that all basic properties of RNA folding maps also hold for combinatorial maps. Our construction is as follows: suppose we are given a graph $H$ over the $\\{1 >...,n\\}$ and an alphabet of nucleotides together with a symmetric relation $\\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of length n is the maximal H subgraph in which all pairs of nucleotides incident to H-edges satisfy $\\mathcal{R}$. Our main result is to prove the existence of at least $\\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes that have a preimage with diameter $n$ and a connected component of size at least $(\\frac{1+\\sqrt{5}}{2})^n+(\\frac{1-\\sqrt{5}}{2})^n$. Furthermore, we show that there exists a certain subset of shapes which carries a natural graph structure. In this graph any two shapes are connected by a path of shapes with respective neutral networks of distance one. We finally discuss our results and provide a comparison with RNA folding maps.  ", "human_text": "  In this paper we present a novel framework for sequence to shape maps. These combinatorial maps realize exponentially many shapes, and have preimages which contain extended connected subgraphs of diameter n (neutral networks). We prove that all basic properties of RNA folding maps also hold for combinatorial maps. Our construction is as follows: suppose we are given a graph $H$ over the $\\{1 >...,n\\}$ and an alphabet of nucleotides together with a symmetric relation $\\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of length n is the maximal H subgraph in which all pairs of nucleotides incident to H-edges satisfy $\\mathcal{R}$. Our main result is to prove the existence of at least $\\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes that have a preimage with diameter $n$ and a connected component of size at least $(\\frac{1+\\sqrt{5}}{2})^n+(\\frac{1-\\sqrt{5}}{2})^n$. Furthermore, we show that there exists a certain subset of shapes which carries a natural graph structure. In this graph any two shapes are connected by a path of shapes with respective neutral networks of distance one. We finally discuss our results and provide a comparison with RNA folding maps. ", "machine_text": " This article proposes a framework to generate a wide range of shapes, known as sequence to shape maps, using an input combination of graphs, nucleotides and a symmetrical relation $\\mathcal{R}$. These shapes have preimages that contain connected subgraphs of length n (neutral networks) and our proof shows that properties of RNA folding maps remain consistent. Our method involves taking a graph $H$ with elements from the $\\{1,..., n\\}$ set and exploiting the combination of base pairing rules and the symmetric relation $\\mathcal{R}$ to perceive the sequence shape. We observe that the number of such shapes is at least $\\sqrt{2}^{n-1}$ with preimages with diameter of n and connection components of size $\\frac{1+\\sqrt{5}}{2} ^n + \\frac{1- \\sqrt{5}}{2}^n$. We conclude with evidence to support a natural graph structure among the shapes and how they are connected by a path of neutral networks. Finally, we compare our findings with those of the RNA folding maps.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.076}
{"prompt": "Rephrase the abstract of an article with title 'Interplay between thermal percolation and jamming upon dimer adsorption   on binary alloys'.   Using Monte Carlo simulations we study jamming and percolation processes upon the random sequential adsorption of dimers on binary alloys with different degrees of structural order. We obtain the equimolar mixtures used as substrates by applying the isomorphism between an alloy and the Ising model (conserved order parameter). The annealing temperature $T$ of the mixture then is a continuous parameter that characterizes the different sets of substrates, shaping the deposition process. As the alloy undergoes an order-disorder phase transition at the Onsager critical temperature ($T_{c}$), the jamming and percolating properties of the dimers deposited over the substrate are subjected to non-trivial changes. These are reflected in a density-temperature phase diagram with three well-defined regions. We find that for $T < T^* = 1.22 T_{c}$ the occurrence of jamming prevents the onset of percolating clusters, while percolation is possible for $T > T^{*}$. Particular attention is focused close to $T^{*}$, where the interplay between jamming and percolation restricts fluctuations, forcing exponents seemingly different from the standard percolation universality class. By analogy with a thermal transition, we study the onset of percolation by using the {\\it temperature} (in this case, the substrate annealing temperature) as a control parameter. By proposing thermal scaling Ansatzes we analyze the behavior of the percolation threshold and its thermally induced fluctuations. Also, the fractal dimension of the percolating cluster is determined. Based on these measurements and the excellent data collapsing, we conclude that the universality class of standard percolation is preserved for all temperatures.  ", "human_text": "  Using Monte Carlo simulations we study jamming and percolation processes upon the random sequential adsorption of dimers on binary alloys with different degrees of structural order. We obtain the equimolar mixtures used as substrates by applying the isomorphism between an alloy and the Ising model (conserved order parameter). The annealing temperature $T$ of the mixture then is a continuous parameter that characterizes the different sets of substrates, shaping the deposition process. As the alloy undergoes an order-disorder phase transition at the Onsager critical temperature ($T_{c}$), the jamming and percolating properties of the dimers deposited over the substrate are subjected to non-trivial changes. These are reflected in a density-temperature phase diagram with three well-defined regions. We find that for $T < T^* = 1.22 T_{c}$ the occurrence of jamming prevents the onset of percolating clusters, while percolation is possible for $T > T^{*}$. Particular attention is focused close to $T^{*}$, where the interplay between jamming and percolation restricts fluctuations, forcing exponents seemingly different from the standard percolation universality class. By analogy with a thermal transition, we study the onset of percolation by using the {\\it temperature} (in this case, the substrate annealing temperature) as a control parameter. By proposing thermal scaling Ansatzes we analyze the behavior of the percolation threshold and its thermally induced fluctuations. Also, the fractal dimension of the percolating cluster is determined. Based on these measurements and the excellent data collapsing, we conclude that the universality class of standard percolation is preserved for all temperatures. ", "machine_text": " Using Monte Carlo simulations, we analyze the effects of order and disorder on the jamming and percolating processes resulting from the random sequential adsorption of dimers on binary alloys. Equimolar mixtures are obtained by applying the Ising model and the substrate annealing temperature $T$ is used to characterize the different types of substrates. At the Onsager critical temperature ($T_{c}$), changes in jamming and percolation features are produced, visible in a density-temperature phase diagram with three distinct regions. We find that jamming phenomena prevailing when $T < T^{*} = 1.22 T_{c}$ hinder the emergence of percolating clusters, and only become possible when $T > T^{*}$. Furthermore, at values close to $T^{*}$, fluctuations are restrained due to the interplay between jamming and percolation, presenting different exponents than those of the standard percolation universality class. By analyzing the threshold of percolation through thermal scaling Ansatzes, together with the fractal dimension of the percolating cluster, it is concluded that the universality class of standard percolation is preserved for all temperatures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0562}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic Streaming Field at Low Redshift'.   We study the expansion of the nearby Universe using a sample of Type Ia supernovae at redshifts below 0.08. These supernovae allow peculiar velocities to be measured at unprecedented precision. We have investigated in detail the possibility of a varying Hubble constant with redshift and found no evidence of a monopole term for the nearby Universe. A large scale streaming motion is found at an amplitude of about $340^{63}_{-71}$ km/sec, aligned in the direction of $(l_0, b_0) = (312^{\\rm o}.0^{13.5}_{-7.4}, 25^{\\rm o}.7^{8.0}_{-9.2})$, which is close to the direction of the center of Shapley supercluster of galaxies. The large scale streaming motion is best fit by a function involving a strong bipolar term. The streaming velocity field extends from the lowest redshift ($\\sim 0.007$) to beyond 0.025 and likely out to even higher redshifts. The velocity field at redshift below 0.01 can be equally well described by a dipole field or by the same bipolar streaming velocity field that reaches out to beyond $z \\sim 0.025$. We are also able to deduce a robust estimate of the random velocity component of the peculiar velocity field. Within the volume of redshift below 0.01 (weighted average redshift of $\\sim$ 0.067), this thermal component is found to be about 270 km/sec. After correcting this smooth streaming motion, we are able to significantly improve the Hubble expansion fits of these supernovae. The CMAGIC method gives a dramatic decrease of $\\chi^2$ from 90 to 63 for 69 degrees of freedom, and yields a residual scatter of only 0.12 magnitude; the maximum light method gives also a moderate improvement.  ", "human_text": "  We study the expansion of the nearby Universe using a sample of Type Ia supernovae at redshifts below 0.08. These supernovae allow peculiar velocities to be measured at unprecedented precision. We have investigated in detail the possibility of a varying Hubble constant with redshift and found no evidence of a monopole term for the nearby Universe. A large scale streaming motion is found at an amplitude of about $340^{63}_{-71}$ km/sec, aligned in the direction of $(l_0, b_0) = (312^{\\rm o}.0^{13.5}_{-7.4}, 25^{\\rm o}.7^{8.0}_{-9.2})$, which is close to the direction of the center of Shapley supercluster of galaxies. The large scale streaming motion is best fit by a function involving a strong bipolar term. The streaming velocity field extends from the lowest redshift ($\\sim 0.007$) to beyond 0.025 and likely out to even higher redshifts. The velocity field at redshift below 0.01 can be equally well described by a dipole field or by the same bipolar streaming velocity field that reaches out to beyond $z \\sim 0.025$. We are also able to deduce a robust estimate of the random velocity component of the peculiar velocity field. Within the volume of redshift below 0.01 (weighted average redshift of $\\sim$ 0.067), this thermal component is found to be about 270 km/sec. After correcting this smooth streaming motion, we are able to significantly improve the Hubble expansion fits of these supernovae. The CMAGIC method gives a dramatic decrease of $\\chi^2$ from 90 to 63 for 69 degrees of freedom, and yields a residual scatter of only 0.12 magnitude; the maximum light method gives also a moderate improvement. ", "machine_text": " Using supernovae at redshifts up to 0.08, we observe peculiar velocities with unprecedented precision. Investigations suggest a substantial streaming motion with an amplitude of approximately 340 km/s in the direction of $(l_0, b_0)=(312^{\\rm o}.0^{13.5}_{-7.4}, 25^{\\rm o}.7^{8.0}_{-9.2})$, which is near to the Shapley supercluster of galaxies. Visually, the velocity field appears to be a bipolar form which extends from 0.007 to $z\\sim 0.025$ and likely beyond. Further, there is an estimated 270 km/s random component to the field inside the volume at 0.01. The CMAGIC and maximum light metrics show considerable improvements in the Hubble expansion measurements following the correction of this streaming motion, with a decrease in $\\chi^2$ from 90 to 63 and a residual scatter of 0.12 magnitude.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0368}
{"prompt": "Rephrase the abstract of an article with title 'Comparison of dust-to-gas ratios in luminous, ultraluminous, and   hyperluminous infrared galaxies'.   The dust-to-gas ratios in three different samples of luminous, ultraluminous, and hyperluminous infrared galaxies are calculated by modelling their radio to soft X-ray spectral energy distributions using composite models which account for the photoionizing radiation from HII regions, starbursts, or AGNs, and for shocks. The models are limited to a set which broadly reproduces the mid-IR fine structure line ratios of local, IR bright, starburst galaxies. The results show that two types of clouds contribute to the IR emission. Those characterized by low shock velocities and low preshock densities explain the far-IR dust emission, while those with higher velocities and densities contribute to mid-IR dust emission. An AGN is found in nearly all of the ultraluminous IR galaxies and in half of the luminous IR galaxies of the sample. High IR luminosities depend on dust-to-gas ratios of about 0.1 by mass, however, most hyperluminous IR galaxies show dust-to-gas ratios much lower than those calculated for the luminous and ultraluminous IR galaxies.  ", "human_text": "  The dust-to-gas ratios in three different samples of luminous, ultraluminous, and hyperluminous infrared galaxies are calculated by modelling their radio to soft X-ray spectral energy distributions using composite models which account for the photoionizing radiation from HII regions, starbursts, or AGNs, and for shocks. The models are limited to a set which broadly reproduces the mid-IR fine structure line ratios of local, IR bright, starburst galaxies. The results show that two types of clouds contribute to the IR emission. Those characterized by low shock velocities and low preshock densities explain the far-IR dust emission, while those with higher velocities and densities contribute to mid-IR dust emission. An AGN is found in nearly all of the ultraluminous IR galaxies and in half of the luminous IR galaxies of the sample. High IR luminosities depend on dust-to-gas ratios of about 0.1 by mass, however, most hyperluminous IR galaxies show dust-to-gas ratios much lower than those calculated for the luminous and ultraluminous IR galaxies. ", "machine_text": "This study investigates the dust-to-gas ratio in different types of luminous, ultraluminous, and hyperluminous infrared galaxies. Through modelling the radio to soft X-ray spectral energy distributions, two types of clouds are discovered to contribute to the infrared emission; those with low shock velocities and low preshock densities and those with high velocities and densities. The results indicate that AGN's are present in nearly all of the ultraluminous and half of the luminous IR galaxies, while high IR luminosities rely on dust-to-gas ratios of 0.1 by mass. However, dust-to-gas ratios in hyper luminous IR galaxies are found to be significantly lower than those of luminous and ultraluminous IR galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3519}
{"prompt": "Rephrase the abstract of an article with title 'The RMS Survey: 13CO observations of candidate massive YSOs in the   southern hemisphere'.   Abridged: The Red MSX Source (RMS) survey is an ongoing multi-wavelength observational programme designed to return a large, well-selected sample of massive young stellar objects (MYSOs). Here we present 13CO observations made towards 854 MYSOs candidates located in the 3rd and 4th quadrants. We detected 13CO emission towards a total of 751 of the 854 RMS sources observed (~88%). In total 2185 emission components are detected above 3$\\sigma$ level. Multiple emission profiles are observed towards the majority of these sources - 455 sources (~60%) - with an average of ~4 molecular clouds along the line of sight. These multiple emission features make it difficult to assign a kinematic velocity to many of our sample. We have used archival CS (J=2-1) and maser velocities to resolved the component multiplicity towards 82 sources and have derived a criterion which is used to identify the most likely component for a further 202 multiple component sources. Combined with the single component detections we have obtained unambiguous kinematic velocities towards 580 sources (~80% of the detections). The 171 sources for which we have not been able to determine the kinematic velocity will require additional line data. Using the rotation curve of Brand and Blitz (1993) and their radial velocities we calculate kinematic distances for all components detected.  ", "human_text": "  Abridged: The Red MSX Source (RMS) survey is an ongoing multi-wavelength observational programme designed to return a large, well-selected sample of massive young stellar objects (MYSOs). Here we present 13CO observations made towards 854 MYSOs candidates located in the 3rd and 4th quadrants. We detected 13CO emission towards a total of 751 of the 854 RMS sources observed (~88%). In total 2185 emission components are detected above 3$\\sigma$ level. Multiple emission profiles are observed towards the majority of these sources - 455 sources (~60%) - with an average of ~4 molecular clouds along the line of sight. These multiple emission features make it difficult to assign a kinematic velocity to many of our sample. We have used archival CS (J=2-1) and maser velocities to resolved the component multiplicity towards 82 sources and have derived a criterion which is used to identify the most likely component for a further 202 multiple component sources. Combined with the single component detections we have obtained unambiguous kinematic velocities towards 580 sources (~80% of the detections). The 171 sources for which we have not been able to determine the kinematic velocity will require additional line data. Using the rotation curve of Brand and Blitz (1993) and their radial velocities we calculate kinematic distances for all components detected. ", "machine_text": " This research presents 13CO observations of 854 candidate massive young stellar objects (MYSOs) located in the third and fourth quadrants of the southern hemisphere. The RMS survey reveals emission of the molecule in 751 of these sources, yielding a total of 2185 detectable components with a signal-to-noise ratio of at least 3. The majority of sources (455, or 60%) display multiple emission profiles in line with the assessment that a large number of molecular clouds exist along their line of sight. A criterion is applied to pinpoint single components out of these multiples, allowing for the derivation of kinematic velocities in an estimated 580 sources, or ~80% of the detections. Utilizing the Brand an Blitz (1993) data for rotation curves and radial velocities, individual kinematic distances are calculated for the detected components. On the other hand, further lines may be required to clarify the kinematic characteristics of the other 171 sources.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4597}
{"prompt": "Rephrase the abstract of an article with title 'Planets around evolved intermediate-mass stars. I. Two substellar   companions in the open clusters NGC 2423 and NGC 4349'.   Context. Many efforts are being made to characterize extrasolar planetary systems and unveil the fundamental mechanisms of planet formation. An important aspect of the problem, which remains largely unknown, is to understand how the planet formation process depends on the mass of the parent star. In particular, as most planets discovered to date orbit a solar-mass primary, little is known about planet formation around more massive stars. Aims. To investigate this point, we present first results from a radial velocity planet search around red giants in the clump of intermediate-age open clusters. We choose clusters harbouring red giants with masses between 1.5 and 4 M_sun, using the well-known cluster parameters to accurately determine the stellar masses. We are therefore exploring a poorly-known domain of primary masses, which will bring new insights into the properties of extrasolar planetary systems. Methods. We are following a sample of about 115 red giants with the Coralie and HARPS spectrographs to obtain high-precision radial velocity (RV) measurements and detect giant planets around these stars. We use bisector and activity index diagnostics to distinguish between planetary-induced RV variations and stellar photospheric jitter. Results. We present the discoveries of a giant planet and a brown dwarf in the open clusters NGC 2423 and NGC 4349, orbiting the 2.4 M_sun-star NGC2423 No3 (TYC 5409-2156-1) and the 3.9 M_sun-star NGC4349 No127 (TYC 8975-2606-1). These low-mass companions have orbital periods of 714 and 678 days and minimum masses of 10.6 and 19.8 M_jup, respectively. Combined with the other known planetary systems, these detections indicate that the frequency of massive planets is higher around intermediate-mass stars, and therefore probably scales with the mass of the protoplanetary disk.  ", "human_text": "  Context. Many efforts are being made to characterize extrasolar planetary systems and unveil the fundamental mechanisms of planet formation. An important aspect of the problem, which remains largely unknown, is to understand how the planet formation process depends on the mass of the parent star. In particular, as most planets discovered to date orbit a solar-mass primary, little is known about planet formation around more massive stars. Aims. To investigate this point, we present first results from a radial velocity planet search around red giants in the clump of intermediate-age open clusters. We choose clusters harbouring red giants with masses between 1.5 and 4 M_sun, using the well-known cluster parameters to accurately determine the stellar masses. We are therefore exploring a poorly-known domain of primary masses, which will bring new insights into the properties of extrasolar planetary systems. Methods. We are following a sample of about 115 red giants with the Coralie and HARPS spectrographs to obtain high-precision radial velocity (RV) measurements and detect giant planets around these stars. We use bisector and activity index diagnostics to distinguish between planetary-induced RV variations and stellar photospheric jitter. Results. We present the discoveries of a giant planet and a brown dwarf in the open clusters NGC 2423 and NGC 4349, orbiting the 2.4 M_sun-star NGC2423 No3 (TYC 5409-2156-1) and the 3.9 M_sun-star NGC4349 No127 (TYC 8975-2606-1). These low-mass companions have orbital periods of 714 and 678 days and minimum masses of 10.6 and 19.8 M_jup, respectively. Combined with the other known planetary systems, these detections indicate that the frequency of massive planets is higher around intermediate-mass stars, and therefore probably scales with the mass of the protoplanetary disk. ", "machine_text": " This paper presents the results of a survey for extrasolar planets orbiting intermediate-mass stars in two open clusters, NGC 2423 and NGC 4349. The observations were taken with the Coralie and HARPS spectrographs to obtain high precision radial velocity measurements and search for giant planets. In total, 115 red giants were studied, with masses between 1.5-4 solar masses. After assessing any stellar jitter, two low-mass companions were detected, a giant planet and a brown dwarf, each with a distinct orbital period and minimum mass. These findings add to the current knowledge of extrasolar planetary systems, revealing that the frequency of massive planets is larger around intermediate-mass stars. This implies a higher likelihood of more planetary masses forming in proportion to the mass of a protoplanetary disk.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2174}
{"prompt": "Rephrase the abstract of an article with title 'Unifying Evolutionary and Network Dynamics'.   Many important real-world networks manifest \"small-world\" properties such as scale-free degree distributions, small diameters, and clustering. The most common model of growth for these networks is \"preferential attachment\", where nodes acquire new links with probability proportional to the number of links they already have. We show that preferential attachment is a special case of the process of molecular evolution. We present a new single-parameter model of network growth that unifies varieties of preferential attachment with the quasispecies equation (which models molecular evolution), and also with the Erdos-Renyi random graph model. We suggest some properties of evolutionary models that might be applied to the study of networks. We also derive the form of the degree distribution resulting from our algorithm, and we show through simulations that the process also models aspects of network growth. The unification allows mathematical machinery developed for evolutionary dynamics to be applied in the study of network dynamics, and vice versa.  ", "human_text": "  Many important real-world networks manifest \"small-world\" properties such as scale-free degree distributions, small diameters, and clustering. The most common model of growth for these networks is \"preferential attachment\", where nodes acquire new links with probability proportional to the number of links they already have. We show that preferential attachment is a special case of the process of molecular evolution. We present a new single-parameter model of network growth that unifies varieties of preferential attachment with the quasispecies equation (which models molecular evolution), and also with the Erdos-Renyi random graph model. We suggest some properties of evolutionary models that might be applied to the study of networks. We also derive the form of the degree distribution resulting from our algorithm, and we show through simulations that the process also models aspects of network growth. The unification allows mathematical machinery developed for evolutionary dynamics to be applied in the study of network dynamics, and vice versa. ", "machine_text": " This article unifies the dynamics of networks and of molecular evolution through a single-parameter model. This model combines the preferential attachment network growth process with the quasispecies equation (a model for molecular evolution) and the Erdos-Renyi random graph model. We discuss the resulting implications for both evolutionary and network dynamics and show how mathematical tools from one realm can be applied to the other. We determine and simulate the form of the degree distribution of the unified model and show that it also models aspects of network growth. Our work provides a bridge for connecting two seemingly disparate spheres of study and allows for new insights into the complexities of growth dynamics in networks.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1811}
{"prompt": "Rephrase the abstract of an article with title 'G-convergence and homogenization of viscoelastic flows'.   The paper is devoted to homogenization of two-phase incompressible viscoelastic flows with disordered microstructure. We study two cases. In the first case, both phases are modeled as Kelvin-Voight viscoelastic materials. In the second case, one phase is a Kelvin-Voight material, and the other is a viscous Newtonian fluid. The microscale system contains the conservation of mass and balance of momentum equations. The inertial terms in the momentum equation incorporate the actual interface advected by the flow. In the constitutive equations, a frozen interface is employed. The interface geometry is arbitrary: we do not assume periodicity, statistical homogeneity or scale separation. The problem is homogenized using G-convergence and oscillating test functions. Since the microscale system is not parabolic, previously known constructions of the test functions do not work here. The test functions developed in the paper are non-local in time and satisfy divergence-free constraint exactly. The latter feature enables us to avoid working with pressure directly. We show that the effective medium is a single phase viscoelastic material that is not necessarily of Kelvin-Voight type. The effective constitutive equation contains a long memory viscoelastic term, as well as instantaneous elastic and viscous terms.  ", "human_text": "  The paper is devoted to homogenization of two-phase incompressible viscoelastic flows with disordered microstructure. We study two cases. In the first case, both phases are modeled as Kelvin-Voight viscoelastic materials. In the second case, one phase is a Kelvin-Voight material, and the other is a viscous Newtonian fluid. The microscale system contains the conservation of mass and balance of momentum equations. The inertial terms in the momentum equation incorporate the actual interface advected by the flow. In the constitutive equations, a frozen interface is employed. The interface geometry is arbitrary: we do not assume periodicity, statistical homogeneity or scale separation. The problem is homogenized using G-convergence and oscillating test functions. Since the microscale system is not parabolic, previously known constructions of the test functions do not work here. The test functions developed in the paper are non-local in time and satisfy divergence-free constraint exactly. The latter feature enables us to avoid working with pressure directly. We show that the effective medium is a single phase viscoelastic material that is not necessarily of Kelvin-Voight type. The effective constitutive equation contains a long memory viscoelastic term, as well as instantaneous elastic and viscous terms. ", "machine_text": " This paper investigates the homogenization of two-phase incompressible viscoelastic flows with arbitrary interface geometries, like periodicity, statistical homogeneity, or scale separation. Utilizing G-convergence and oscillating test functions, customarily non-local in time, that satisfy divergence-free constraints, we arrive at an effective medium in the form of a single phase viscoelastic material, which may not be of the Kelvin-Voight type. The resultant effective constitutive equation retains a long memory viscoelastic term as well as instantaneous elastic and viscous terms. This novel approach accounts for the conservation of mass and momentum equations, coupled with the interface advection of the flow.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1088}
{"prompt": "Rephrase the abstract of an article with title 'Identifying Dark Matter Burners in the Galactic center'.   If the supermassive black hole (SMBH) at the center of our Galaxy grew adiabatically, then a dense \"spike\" of dark matter is expected to have formed around it. Assuming that dark matter is composed primarily of weakly interacting massive particles (WIMPs), a star orbiting close enough to the SMBH can capture WIMPs at an extremely high rate. The stellar luminosity due to annihilation of captured WIMPs in the stellar core may be comparable to or even exceed the luminosity of the star due to thermonuclear burning. The model thus predicts the existence of unusual stars, i.e. \"WIMP burners\", in the vicinity of an adiabatically grown SMBH. We find that the most efficient WIMP burners are stars with degenerate electron cores, e.g. white dwarfs (WD) or degenerate cores with envelopes. If found, such stars would provide evidence for the existence of particle dark matter and could possibly be used to establish its density profile. In our previous paper we computed the luminosity from WIMP burning for a range of dark matter spike density profiles, degenerate core masses, and distances from the SMBH. Here we compare our results with the observed stars closest to the Galactic center and find that they could be consistent with WIMP burners in the form of degenerate cores with envelopes. We also cross-check the WIMP burner hypothesis with the EGRET observed flux of gamma-rays from the Galactic center, which imposes a constraint on the dark matter spike density profile and annihilation cross-section. We find that the EGRET data is consistent with the WIMP burner hypothesis. New high precision measurements by GLAST will confirm or set stringent limits on a dark matter spike at the Galactic center, which will in turn support or set stringent limits on the existence of WIMP burners at the Galactic center.  ", "human_text": "  If the supermassive black hole (SMBH) at the center of our Galaxy grew adiabatically, then a dense \"spike\" of dark matter is expected to have formed around it. Assuming that dark matter is composed primarily of weakly interacting massive particles (WIMPs), a star orbiting close enough to the SMBH can capture WIMPs at an extremely high rate. The stellar luminosity due to annihilation of captured WIMPs in the stellar core may be comparable to or even exceed the luminosity of the star due to thermonuclear burning. The model thus predicts the existence of unusual stars, i.e. \"WIMP burners\", in the vicinity of an adiabatically grown SMBH. We find that the most efficient WIMP burners are stars with degenerate electron cores, e.g. white dwarfs (WD) or degenerate cores with envelopes. If found, such stars would provide evidence for the existence of particle dark matter and could possibly be used to establish its density profile. In our previous paper we computed the luminosity from WIMP burning for a range of dark matter spike density profiles, degenerate core masses, and distances from the SMBH. Here we compare our results with the observed stars closest to the Galactic center and find that they could be consistent with WIMP burners in the form of degenerate cores with envelopes. We also cross-check the WIMP burner hypothesis with the EGRET observed flux of gamma-rays from the Galactic center, which imposes a constraint on the dark matter spike density profile and annihilation cross-section. We find that the EGRET data is consistent with the WIMP burner hypothesis. New high precision measurements by GLAST will confirm or set stringent limits on a dark matter spike at the Galactic center, which will in turn support or set stringent limits on the existence of WIMP burners at the Galactic center. ", "machine_text": " An investigation has been conducted to identify objects within the vicinity of the supermassive black hole at the center of the Galaxy that, if consistent with the model of an adiabatically grown SMBH, could provide proof of particle dark matter. It has been hypothesized that stars sufficiently close to the SMBH will capture weakly interactive massive particles (WIMPs), leading to the formation of a dark matter spike and the production of stellar luminosity due to the annihilation of captured WIMPs in the stellar core. Accordingly, if discovered, these stars could act as evidence of dark matter and potentially define the density distribution of the spike. Our study has compared the predicted luminosity from WIMP burning with observed stars close to the Galactic center and, additionally, used the gamma-ray flux from the Galactic center as reported by EGRET to constrain both the dark matter density profile and annihilation cross-section. This anaylysis demonstrates that the EGRET data is consistent with the WIMP burner hypothesis. Further, upcoming high precision measurements from GLAST will indeed bolster our understanding of the aforementioned structure as well as the amount of evidence for these anomalous stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1324}
{"prompt": "Rephrase the abstract of an article with title 'Quantifying social group evolution'.   The rich set of interactions between individuals in the society results in complex community structure, capturing highly connected circles of friends, families, or professional cliques in a social network. Thanks to frequent changes in the activity and communication patterns of individuals, the associated social and communication network is subject to constant evolution. Our knowledge of the mechanisms governing the underlying community dynamics is limited, but is essential for a deeper understanding of the development and self-optimisation of the society as a whole. We have developed a new algorithm based on clique percolation, that allows, for the first time, to investigate the time dependence of overlapping communities on a large scale and as such, to uncover basic relationships characterising community evolution. Our focus is on networks capturing the collaboration between scientists and the calls between mobile phone users. We find that large groups persist longer if they are capable of dynamically altering their membership, suggesting that an ability to change the composition results in better adaptability. The behaviour of small groups displays the opposite tendency, the condition for stability being that their composition remains unchanged. We also show that the knowledge of the time commitment of the members to a given community can be used for estimating the community's lifetime. These findings offer a new view on the fundamental differences between the dynamics of small groups and large institutions.  ", "human_text": "  The rich set of interactions between individuals in the society results in complex community structure, capturing highly connected circles of friends, families, or professional cliques in a social network. Thanks to frequent changes in the activity and communication patterns of individuals, the associated social and communication network is subject to constant evolution. Our knowledge of the mechanisms governing the underlying community dynamics is limited, but is essential for a deeper understanding of the development and self-optimisation of the society as a whole. We have developed a new algorithm based on clique percolation, that allows, for the first time, to investigate the time dependence of overlapping communities on a large scale and as such, to uncover basic relationships characterising community evolution. Our focus is on networks capturing the collaboration between scientists and the calls between mobile phone users. We find that large groups persist longer if they are capable of dynamically altering their membership, suggesting that an ability to change the composition results in better adaptability. The behaviour of small groups displays the opposite tendency, the condition for stability being that their composition remains unchanged. We also show that the knowledge of the time commitment of the members to a given community can be used for estimating the community's lifetime. These findings offer a new view on the fundamental differences between the dynamics of small groups and large institutions. ", "machine_text": " By leveraging a new clique percolation algorithm, this article investigates the temporal evolution of social and communication networks, allowing us to gain insights into the mechanisms which shape communities. Applying the technique to networks which capture the collaboration between scientists and the calls between mobile phone users, we identify the conditions which lead to the stability and adaptability in large and small social groups. Additionally, we quantitatively show that the level of engagement of the individuals involved can be used to estimate the lifespan of a community. Our results provide a new way of understanding the differences between the evolutionary trajectories of large organizations and small clusters of people.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0744}
{"prompt": "Rephrase the abstract of an article with title 'Interior Point Decoding for Linear Vector Channels'.   In this paper, a novel decoding algorithm for low-density parity-check (LDPC) codes based on convex optimization is presented. The decoding algorithm, called interior point decoding, is designed for linear vector channels. The linear vector channels include many practically important channels such as inter symbol interference channels and partial response channels. It is shown that the maximum likelihood decoding (MLD) rule for a linear vector channel can be relaxed to a convex optimization problem, which is called a relaxed MLD problem. The proposed decoding algorithm is based on a numerical optimization technique so called interior point method with barrier function. Approximate variations of the gradient descent and the Newton methods are used to solve the convex optimization problem. In a decoding process of the proposed algorithm, a search point always lies in the fundamental polytope defined based on a low-density parity-check matrix. Compared with a convectional joint message passing decoder, the proposed decoding algorithm achieves better BER performance with less complexity in the case of partial response channels in many cases.  ", "human_text": "  In this paper, a novel decoding algorithm for low-density parity-check (LDPC) codes based on convex optimization is presented. The decoding algorithm, called interior point decoding, is designed for linear vector channels. The linear vector channels include many practically important channels such as inter symbol interference channels and partial response channels. It is shown that the maximum likelihood decoding (MLD) rule for a linear vector channel can be relaxed to a convex optimization problem, which is called a relaxed MLD problem. The proposed decoding algorithm is based on a numerical optimization technique so called interior point method with barrier function. Approximate variations of the gradient descent and the Newton methods are used to solve the convex optimization problem. In a decoding process of the proposed algorithm, a search point always lies in the fundamental polytope defined based on a low-density parity-check matrix. Compared with a convectional joint message passing decoder, the proposed decoding algorithm achieves better BER performance with less complexity in the case of partial response channels in many cases. ", "machine_text": "In this article, a novel scheme of decoding Low-Density Parity-Check (LDPC) using convex optimization instead of Maximum Likelihood Decoding (MLD), referred to as Interior Point Decoding (IPD), is proposed. It is designed for linear vector channels, such as Inter Symbol Interference (ISI) and Partial Response (PR) channels. MLD for linear vector channels is converted into a convex, optimisation problem referred to as Relaxed MLD. This problem is solved with an Interior Point Method Barrier Function and its approximate variations, the Gradient Descent and Newton Method. IPD search for points in a fundamental polytope determined by the low-density parity-check matrix. It has shown that IPD exhibits a better Bit Error Rate (BER) performance with lesser complexities when compared to the Joint Message Passing Decoder, in the case of Partial Response channels.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.399}
{"prompt": "Rephrase the abstract of an article with title 'Hamiltonian Theory of Adiabatic Motion of Relativistic Charged Particles'.   A general Hamiltonian theory for the adiabatic motion of relativistic charged particles confined by slowly-varying background electromagnetic fields is presented based on a unified Lie-transform perturbation analysis in extended phase space (which includes energy and time as independent coordinates) for all three adiabatic invariants. First, the guiding-center equations of motion for a relativistic particle are derived from the particle Lagrangian. Covariant aspects of the resulting relativistic guiding-center equations of motion are discussed and contrasted with previous works. Next, the second and third invariants for the bounce motion and drift motion, respectively, are obtained by successively removing the bounce phase and the drift phase from the guiding-center Lagrangian. First-order corrections to the second and third adiabatic invariants for a relativistic particle are derived. These results simplify and generalize previous works to all three adiabatic motions of relativistic magnetically-trapped particles.  ", "human_text": "  A general Hamiltonian theory for the adiabatic motion of relativistic charged particles confined by slowly-varying background electromagnetic fields is presented based on a unified Lie-transform perturbation analysis in extended phase space (which includes energy and time as independent coordinates) for all three adiabatic invariants. First, the guiding-center equations of motion for a relativistic particle are derived from the particle Lagrangian. Covariant aspects of the resulting relativistic guiding-center equations of motion are discussed and contrasted with previous works. Next, the second and third invariants for the bounce motion and drift motion, respectively, are obtained by successively removing the bounce phase and the drift phase from the guiding-center Lagrangian. First-order corrections to the second and third adiabatic invariants for a relativistic particle are derived. These results simplify and generalize previous works to all three adiabatic motions of relativistic magnetically-trapped particles. ", "machine_text": " This article presents a comprehensive Hamiltonian theory for the adiabatic motion of relativistic charged particles confined by slowly changing electromagnetic fields. An extended Lie-transform perturbation analysis is used to obtain the equations of motion in the extended phase space that transforms energy and time into independent coordinates for all three adiabatic invariants. The relativistic particle Lagrangian is applied to derive the guiding-center equations of motion, which are discussed with regards to their covariant properties compared to existing works. The second and third adiabatic invariants of the bounce motion and drift motion, respectively, are obtained by successive removal of the bounce and drift phases from the guiding-center's Lagrangian. The paper finally derives first-order corrections to the second and third adiabatic invariants of the relativistic particle, which simplify and generalize previous works to encompass all three types of adiabatic motion of magnetically-trapped particles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1925}
{"prompt": "Rephrase the abstract of an article with title 'The generator coordinate method in time-dependent density-functional   theory: memory made simple'.   The generator coordinate (GC) method is a variational approach to the quantum many-body problem in which interacting many-body wave functions are constructed as superpositions of (generally nonorthogonal) eigenstates of auxiliary Hamiltonians containing a deformation parameter. This paper presents a time-dependent extension of the GC method as a new approach to improve existing approximations of the exchange-correlation (XC) potential in time-dependent density-functional theory (TDDFT). The time-dependent GC method is shown to be a conceptually and computationally simple tool to build memory effects into any existing adiabatic XC potential. As an illustration, the method is applied to driven parametric oscillations of two interacting electrons in a harmonic potential (Hooke's atom). It is demonstrated that a proper choice of time-dependent generator coordinates in conjunction with the adiabatic local-density approximation reproduces the exact linear and nonlinear two-electron dynamics quite accurately, including features associated with double excitations that cannot be captured by TDDFT in the adiabatic approximation.  ", "human_text": "  The generator coordinate (GC) method is a variational approach to the quantum many-body problem in which interacting many-body wave functions are constructed as superpositions of (generally nonorthogonal) eigenstates of auxiliary Hamiltonians containing a deformation parameter. This paper presents a time-dependent extension of the GC method as a new approach to improve existing approximations of the exchange-correlation (XC) potential in time-dependent density-functional theory (TDDFT). The time-dependent GC method is shown to be a conceptually and computationally simple tool to build memory effects into any existing adiabatic XC potential. As an illustration, the method is applied to driven parametric oscillations of two interacting electrons in a harmonic potential (Hooke's atom). It is demonstrated that a proper choice of time-dependent generator coordinates in conjunction with the adiabatic local-density approximation reproduces the exact linear and nonlinear two-electron dynamics quite accurately, including features associated with double excitations that cannot be captured by TDDFT in the adiabatic approximation. ", "machine_text": " In this paper, we propose a novel method based on the generator coordinate (GC) approach to incorporate memory effects into any existing approximation of the exchange-correlation (XC) potential in time-dependent density-functional theory (TDDFT). This time-dependent GC method is proven to be simpler in implementation than other approaches, and is used to study the driven parametric oscillations of two interacting electrons in a harmonic potential (Hooke's atom). Our results suggest that a suitable choice of time-dependent generator coordinates combined with the adiabatic local-density approximation accurately reproduces the exact dynamics of this system, including the occurrence of double excitations which are not captured by traditional TDDFT in adiabatic approximation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2855}
{"prompt": "Rephrase the abstract of an article with title 'Microscopic theory of quantum dot interactions with quantum light: local   field effect'.   A theory of both linear and nonlinear electromagnetic response of a single QD exposed to quantum light, accounting the depolarization induced local--field has been developed. Based on the microscopic Hamiltonian accounting for the electron--hole exchange interaction, an effective two--body Hamiltonian has been derived and expressed in terms of the incident electric field, with a separate term describing the QD depolarization. The quantum equations of motion have been formulated and solved with the Hamiltonian for various types of the QD excitation, such as Fock qubit, coherent fields, vacuum state of electromagnetic field and light with arbitrary photonic state distribution. For a QD exposed to coherent light, we predict the appearance of two oscillatory regimes in the Rabi effect separated by the bifurcation. In the first regime, the standard collapse--revivals phenomenon do not reveal itself and the QD population inversion is found to be negative, while in the second one, the collapse--revivals picture is found to be strongly distorted as compared with that predicted by the standard Jaynes-Cummings model. %The model developed can easily be extended to %%electromagnetic excitation. For the case of QD interaction with arbitrary quantum light state in the linear regime, it has been shown that the local field induce a fine structure of the absorbtion spectrum. Instead of a single line with frequency corresponding to which the exciton transition frequency, a duplet is appeared with one component shifted by the amount of the local field coupling parameter. It has been demonstrated the strong light--mater coupling regime arises in the weak-field limit. A physical interpretation of the predicted effects has been proposed.  ", "human_text": "  A theory of both linear and nonlinear electromagnetic response of a single QD exposed to quantum light, accounting the depolarization induced local--field has been developed. Based on the microscopic Hamiltonian accounting for the electron--hole exchange interaction, an effective two--body Hamiltonian has been derived and expressed in terms of the incident electric field, with a separate term describing the QD depolarization. The quantum equations of motion have been formulated and solved with the Hamiltonian for various types of the QD excitation, such as Fock qubit, coherent fields, vacuum state of electromagnetic field and light with arbitrary photonic state distribution. For a QD exposed to coherent light, we predict the appearance of two oscillatory regimes in the Rabi effect separated by the bifurcation. In the first regime, the standard collapse--revivals phenomenon do not reveal itself and the QD population inversion is found to be negative, while in the second one, the collapse--revivals picture is found to be strongly distorted as compared with that predicted by the standard Jaynes-Cummings model. %The model developed can easily be extended to %%electromagnetic excitation. For the case of QD interaction with arbitrary quantum light state in the linear regime, it has been shown that the local field induce a fine structure of the absorbtion spectrum. Instead of a single line with frequency corresponding to which the exciton transition frequency, a duplet is appeared with one component shifted by the amount of the local field coupling parameter. It has been demonstrated the strong light--mater coupling regime arises in the weak-field limit. A physical interpretation of the predicted effects has been proposed. ", "machine_text": " This article presents a microscopic theory of quantum dot (QD) interactions with quantum light that considers the local-field-induced depolarization. A two-body Hamiltonian has been derived and expressed in terms of the incident electric field, with a separate term describing the depolarization effect of the QD. Through the equations of motion, this theory has been applied to the study of various types of excitations within the QD, such as a Fock qubit, coherent fields, vacuum state electromagnetic field light and arbitrary photonic state distributions.  Results show the appearance of two oscillatory regimes in the Rabi effect when a QD is exposed to coherent light, separated by a bifurcation effect. The first regime does not reveal the standard collapse-revival phenomenon, with a negative population inversion, while the second regime greatly distorts the expected collapse-revival as compared to thestandard Jaynes-Cummings model. Moreover, in the linear regime, the local field induces a split in the absorbtion spectrum, usually dominated by a single line corresponding to the exciton transition frequency, and a shift of one component due to the local field coupling parameter. It has also been demonstrated that a strong light-matter coupling arises in a weak-field limit. Physical interpretation and further implications of the derived results are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0267}
{"prompt": "Rephrase the abstract of an article with title 'Detection of two-sided alternatives in a Brownian motion model'.   This work examines the problem of sequential detection of a change in the drift of a Brownian motion in the case of two-sided alternatives. Applications to real life situations in which two-sided changes can occur are discussed. Traditionally, 2-CUSUM stopping rules have been used for this problem due to their asymptotically optimal character as the mean time between false alarms tends to $\\infty$. In particular, attention has focused on 2-CUSUM harmonic mean rules due to the simplicity in calculating their first moments. In this paper, we derive closed-form expressions for the first moment of a general 2-CUSUM stopping rule. We use these expressions to obtain explicit upper and lower bounds for it. Moreover, we derive an expression for the rate of change of this first moment as one of the threshold parameters changes. Based on these expressions we obtain explicit upper and lower bounds to this rate of change. Using these expressions we are able to find the best 2-CUSUM stopping rule with respect to the extended Lorden criterion. In fact, we demonstrate not only the existence but also the uniqueness of the best 2-CUSUM stopping both in the case of a symmetric change and in the case of a non-symmetric case. Furthermore, we discuss the existence of a modification of the 2-CUSUM stopping rule that has a strictly better performance than its classical 2-CUSUM counterpart for small values of the mean time between false alarms. We conclude with a discussion on the open problem of strict optimality in the case of two-sided alternatives.  ", "human_text": "  This work examines the problem of sequential detection of a change in the drift of a Brownian motion in the case of two-sided alternatives. Applications to real life situations in which two-sided changes can occur are discussed. Traditionally, 2-CUSUM stopping rules have been used for this problem due to their asymptotically optimal character as the mean time between false alarms tends to $\\infty$. In particular, attention has focused on 2-CUSUM harmonic mean rules due to the simplicity in calculating their first moments. In this paper, we derive closed-form expressions for the first moment of a general 2-CUSUM stopping rule. We use these expressions to obtain explicit upper and lower bounds for it. Moreover, we derive an expression for the rate of change of this first moment as one of the threshold parameters changes. Based on these expressions we obtain explicit upper and lower bounds to this rate of change. Using these expressions we are able to find the best 2-CUSUM stopping rule with respect to the extended Lorden criterion. In fact, we demonstrate not only the existence but also the uniqueness of the best 2-CUSUM stopping both in the case of a symmetric change and in the case of a non-symmetric case. Furthermore, we discuss the existence of a modification of the 2-CUSUM stopping rule that has a strictly better performance than its classical 2-CUSUM counterpart for small values of the mean time between false alarms. We conclude with a discussion on the open problem of strict optimality in the case of two-sided alternatives. ", "machine_text": " In this study, we analyze the problem of detecting a shift in the random drift of a Brownian motion in the event of two-sided alternatives. Although the 2-CUSUM stopping rules have shown superior performance for this task over the years due to their asymptotic optimality, the calculation of their first moments is complex. Our research aids in these calculations by finding closed-form expressions for the first moment of a general two-sided CUSUM stopping rule, and derived upper and lower bounds for it. We also offer an expression for the change rate of the first moment and provide upper and lower bounds. Comparisons to the extended Lorden criterion demonstrate the existence and uniqueness of the best two-sided CUSUM rule in both symmetric and non-symmetric cases. Furthermore, we suggest a modification of the conventional two-sided CUSUM stopping rule that offers improved performance in the event of small time between false alarms. Ultimately, we raise the issue of finding a strictly optimal approach in the case of two-sided alternatives.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3094}
{"prompt": "Rephrase the abstract of an article with title 'Phenomenology with Massive Neutrinos'.   The current status and some perspectives of the phenomenology of massive neutrinos is reviewed. We start with the phenomenology of neutrino oscillations in vacuum and in matter. We summarize the results of neutrino experiments using solar, atmospheric, reactor and accelerator neutrino beams. We update the leptonic parameters derived from the three-neutrino oscillation interpretation of this data. We describe the method and present results on our understanding of the solar and atmospheric neutrino fluxes by direct extraction from the corresponding neutrino event rates. We present some tests of different forms of new physics which induce new sources of leptonic flavor transitions in vacuum and in matter which can be performed with the present neutrino data. The aim and potential of future neutrino experiments and facilities to further advance in these fronts is also briefly summarized. Last, the implications of the LSND observations are discussed, and the status of extended models which could accommodate all flavor-mixing signals is presented in the light of the recent results from MiniBooNE.  ", "human_text": "  The current status and some perspectives of the phenomenology of massive neutrinos is reviewed. We start with the phenomenology of neutrino oscillations in vacuum and in matter. We summarize the results of neutrino experiments using solar, atmospheric, reactor and accelerator neutrino beams. We update the leptonic parameters derived from the three-neutrino oscillation interpretation of this data. We describe the method and present results on our understanding of the solar and atmospheric neutrino fluxes by direct extraction from the corresponding neutrino event rates. We present some tests of different forms of new physics which induce new sources of leptonic flavor transitions in vacuum and in matter which can be performed with the present neutrino data. The aim and potential of future neutrino experiments and facilities to further advance in these fronts is also briefly summarized. Last, the implications of the LSND observations are discussed, and the status of extended models which could accommodate all flavor-mixing signals is presented in the light of the recent results from MiniBooNE. ", "machine_text": "This article reviews the current state of the phenomenology of massive neutrinos. We examine the phenomenon of neutrino oscillation in both vacuum and in matter, and then present the leptonic parameters derived from the three-neutrino oscillation interpretation of the data obtained from the solar, atmospheric, reactor and accelerator neutrino beams. The article further explores the potential role of new physics in inducing leptonic flavor transitions in both matter and vacuum, and examines the implications of the LSND observations. The article also outlines the aims and possibilities of future neutrino experiments and facilities in furthering our understanding of these topics, and has also presented the updated results of MiniBooNE on the status of extended models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.18}
{"prompt": "Rephrase the abstract of an article with title 'Charm-quark fragmentation with an effective coupling constant'.   We use a recently proposed non-perturbative model, based on an effective strong coupling constant and free from tunable parameters, to study c-flavoured hadron production in e+e- annihilation. Charm-quark production is described in the framework of perturbative fragmentation functions, with NLO coefficient functions, NLL non-singlet DGLAP evolution and NNLL large-x resummation. We model hadronization effects by means of the effective coupling constant in the NNLO approximation and compare our results with experimental data taken at the Z0 pole and at the Upsilon(4S) resonance. We find that, within the experimental and theoretical uncertainties, our model is able to give a reasonable description of D*+-meson spectra from ALEPH for x<1-Lambda/m_c. More serious discrepancies are instead present when comparing with D and D^* data from BELLE and CLEO in x-space. Within the errors, our model is nonetheless capable of reproducing the first ten Mellin moments of all considered data sets. However, the fairly large theoretical uncertainties call for a full NNLO/NNLL analysis.  ", "human_text": "  We use a recently proposed non-perturbative model, based on an effective strong coupling constant and free from tunable parameters, to study c-flavoured hadron production in e+e- annihilation. Charm-quark production is described in the framework of perturbative fragmentation functions, with NLO coefficient functions, NLL non-singlet DGLAP evolution and NNLL large-x resummation. We model hadronization effects by means of the effective coupling constant in the NNLO approximation and compare our results with experimental data taken at the Z0 pole and at the Upsilon(4S) resonance. We find that, within the experimental and theoretical uncertainties, our model is able to give a reasonable description of D*+-meson spectra from ALEPH for x<1-Lambda/m_c. More serious discrepancies are instead present when comparing with D and D^* data from BELLE and CLEO in x-space. Within the errors, our model is nonetheless capable of reproducing the first ten Mellin moments of all considered data sets. However, the fairly large theoretical uncertainties call for a full NNLO/NNLL analysis. ", "machine_text": " A non-perturbative model, with an effective strong coupling constant and devoid of adjustable parameters, is used to explore the charm-quark fragmentation in e+e\u2212 annihilation. Perturbative fragmentation functions, containing NLO coefficient functions, NLL non-singlet DGLAP evolution, and NNLL large-x resummation, are employed in this model. We utilize the effective coupling constant in the NNLO approximation to investigate the hadronization effects and compare our results to experimental data from the Z0 pole and the Upsilon(4S) resonance. Generally, our model agrees well with D*+-meson spectra from ALEPH. However, discrepancies were found when compared to D and D* data from BELLE and CLEO. Even so, our model is able to reproduce the first 10 Mellin moments of the data sets within the respective uncertainty limits. Although there are visible improvements in our analysis, a comprehensive NNLO/NNLL analysis is still necessary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2357}
{"prompt": "Rephrase the abstract of an article with title 'The Calibration and Data Products of the Galaxy Evolution Explorer'.   We describe the calibration status and data products pertaining to the GR2 and GR3 data releases of the Galaxy Evolution Explorer (GALEX). These releases have identical pipeline calibrations that are significantly improved over the GR1 data release. GALEX continues to survey the sky in the Far Ultraviolet (FUV, ~154 nm) and Near Ultraviolet (NUV, ~232 nm) bands, providing simultaneous imaging with a pair of photon counting, microchannel plate, delay line readout detectors. These 1.25 degree field-of-view detectors are well-suited to ultraviolet observations because of their excellent red rejection and negligible background. A dithered mode of observing and photon list output pose complex requirements on the data processing pipeline, entangling detector calibrations and aspect reconstruction algorithms. Recent improvements have achieved photometric repeatability of 0.05 and 0.03 mAB in the FUV and NUV, respectively. We have detected a long term drift of order 1% FUV and 6% NUV over the mission. Astrometric precision is of order 0.5\" RMS in both bands. In this paper we provide the GALEX user with a broad overview of the calibration issues likely to be confronted in the current release. Improvements are likely as the GALEX mission continues into an extended phase with a healthy instrument, no consumables, and increased opportunities for guest investigations.  ", "human_text": "  We describe the calibration status and data products pertaining to the GR2 and GR3 data releases of the Galaxy Evolution Explorer (GALEX). These releases have identical pipeline calibrations that are significantly improved over the GR1 data release. GALEX continues to survey the sky in the Far Ultraviolet (FUV, ~154 nm) and Near Ultraviolet (NUV, ~232 nm) bands, providing simultaneous imaging with a pair of photon counting, microchannel plate, delay line readout detectors. These 1.25 degree field-of-view detectors are well-suited to ultraviolet observations because of their excellent red rejection and negligible background. A dithered mode of observing and photon list output pose complex requirements on the data processing pipeline, entangling detector calibrations and aspect reconstruction algorithms. Recent improvements have achieved photometric repeatability of 0.05 and 0.03 mAB in the FUV and NUV, respectively. We have detected a long term drift of order 1% FUV and 6% NUV over the mission. Astrometric precision is of order 0.5\" RMS in both bands. In this paper we provide the GALEX user with a broad overview of the calibration issues likely to be confronted in the current release. Improvements are likely as the GALEX mission continues into an extended phase with a healthy instrument, no consumables, and increased opportunities for guest investigations. ", "machine_text": " This paper outlines the GR2 and GR3 data releases of the Galaxy Evolution Explorer (GALEX) which have seen improvements in the pipeline calibration of the Far Ultraviolet (FUV) and Near Ultraviolet (NUV) bands. Using its 1.25 degree field-of-view detectors, GALEX surveys the sky and provides photometric repeatability of 0.05 and 0.03 mAB in the FUV and NUV bands respectively, along with astrometric precision of 0.5\" RMS in both bands. Additionally, the mission has seen a steady 1% FUV and 6% NUV drift over its run. As the GALEX mission continues into the extended phase, this paper outlines the calibration issues that users may encounter, with the hopes of further improvements as the instrument is kept healthy and guest investigations are enabled.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0755}
{"prompt": "Rephrase the abstract of an article with title 'Linked by Loops: Network Structure and Switch Integration in Complex   Dynamical Systems'.   Simple nonlinear dynamical systems with multiple stable stationary states are often taken as models for switchlike biological systems. This paper considers the interaction of multiple such simple multistable systems when they are embedded together into a larger dynamical \"supersystem.\" Attention is focused on the network structure of the resulting set of coupled differential equations, and the consequences of this structure on the propensity of the embedded switches to act independently versus cooperatively. Specifically, it is argued that both larger average and larger variance of the node degree distribution lead to increased switch independence. Given the frequency of empirical observations of high variance degree distributions (e.g., power-law) in biological networks, it is suggested that the results presented here may aid in identifying switch-integrating subnetworks as comparatively homogenous, low-degree, substructures. Potential applications to ecological problems such as the relationship of stability and complexity are also briefly discussed.  ", "human_text": "  Simple nonlinear dynamical systems with multiple stable stationary states are often taken as models for switchlike biological systems. This paper considers the interaction of multiple such simple multistable systems when they are embedded together into a larger dynamical \"supersystem.\" Attention is focused on the network structure of the resulting set of coupled differential equations, and the consequences of this structure on the propensity of the embedded switches to act independently versus cooperatively. Specifically, it is argued that both larger average and larger variance of the node degree distribution lead to increased switch independence. Given the frequency of empirical observations of high variance degree distributions (e.g., power-law) in biological networks, it is suggested that the results presented here may aid in identifying switch-integrating subnetworks as comparatively homogenous, low-degree, substructures. Potential applications to ecological problems such as the relationship of stability and complexity are also briefly discussed. ", "machine_text": " This paper investigates the influence of a network's structure on the functioning of multiple identical but interconnected simple nonlinear dynamical systems exhibiting multiple stable stationary states, which are commonly used for modeling switch-like behavior in biological systems. It is shown that both an increase in the average degree and higher variance in the degree distribution across the nodes result in a higher tendency of the switches to act independently instead of cooperatively. Given the common occurrence of power-law degree distributions in biological networks, this paper proposes that the finding might help to identify any subnetworks that integrate the switches as comparatively low-degree and homogenous structures. In addition, the potential applications of these results to address ecological issues such as the integration of complexity and stability are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.364}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical Objects for Cohomologically Expanding Maps'.   The goal of this paper is to construct invariant dynamical objects for a (not necessarily invertible) smooth self map of a compact manifold. We prove a result that takes advantage of differences in rates of expansion in the terms of a sheaf cohomological long exact sequence to create unique lifts of finite dimensional invariant subspaces of one term of the sequence to invariant subspaces of the preceding term. This allows us to take invariant cohomological classes and under the right circumstances construct unique currents of a given type, including unique measures of a given type, that represent those classes and are invariant under pullback. A dynamically interesting self map may have a plethora of invariant measures, so the uniquess of the constructed currents is important. It means that if local growth is not too big compared to the growth rate of the cohomological class then the expanding cohomological class gives sufficient \"marching orders\" to the system to prohibit the formation of any other such invariant current of the same type (say from some local dynamical subsystem). Because we use subsheaves of the sheaf of currents we give conditions under which a subsheaf will have the same cohomology as the sheaf containing it. Using a smoothing argument this allows us to show that the sheaf cohomology of the currents under consideration can be canonically identified with the deRham cohomology groups. Our main theorem can be applied in both the smooth and holomorphic setting.  ", "human_text": "  The goal of this paper is to construct invariant dynamical objects for a (not necessarily invertible) smooth self map of a compact manifold. We prove a result that takes advantage of differences in rates of expansion in the terms of a sheaf cohomological long exact sequence to create unique lifts of finite dimensional invariant subspaces of one term of the sequence to invariant subspaces of the preceding term. This allows us to take invariant cohomological classes and under the right circumstances construct unique currents of a given type, including unique measures of a given type, that represent those classes and are invariant under pullback. A dynamically interesting self map may have a plethora of invariant measures, so the uniquess of the constructed currents is important. It means that if local growth is not too big compared to the growth rate of the cohomological class then the expanding cohomological class gives sufficient \"marching orders\" to the system to prohibit the formation of any other such invariant current of the same type (say from some local dynamical subsystem). Because we use subsheaves of the sheaf of currents we give conditions under which a subsheaf will have the same cohomology as the sheaf containing it. Using a smoothing argument this allows us to show that the sheaf cohomology of the currents under consideration can be canonically identified with the deRham cohomology groups. Our main theorem can be applied in both the smooth and holomorphic setting. ", "machine_text": "This article explores the construction of uniquely determined dynamical objects that are invariant under the pullback action of a (not necessarily invertible) smooth self-map of a compact manifold. Taking advantage of differences in expansion rates between terms inside of a sheaf cohomological long exact sequence, we are able to lift finite-dimensional invariant subspaces from one term to the preceding one, which then allows for the formation of unique invariant currents and measures of a given type. We also discuss conditions for which the subsheaf cohomology of these currents is identical to the sheaf cohomology, as well as conditions to canonically identify the sheaf cohomology of the currents to the deRham cohomology groups. Our theorem can be applied to both smooth and holomorphic settings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0069}
{"prompt": "Rephrase the abstract of an article with title 'Weight structures vs. $t$-structures; weight filtrations, spectral   sequences, and complexes (for motives and in general)'.   This paper is dedicated to triangulated categories endowed with weight structures (a new notion; D. Pauksztello has independently introduced them as co-t-structures). This axiomatizes the properties of stupid truncations of complexes in $K(B)$. We also construct weight structures for Voevodsky's categories of motives and for various categories of spectra. A weight structure $w$ defines Postnikov towers of objects; these towers are canonical and functorial 'up to morphisms that are zero on cohomology'. For $Hw$ being the heart of $w$ (in $DM_{gm}$ we have $Hw=Chow$) we define a canonical conservative 'weakly exact' functor $t$ from our $C$ to a certain weak category of complexes $K_w(Hw)$. For any (co)homological functor $H:C\\to A$ for an abelian $A$ we construct a weight spectral sequence $T:H(X^i[j])\\implies H(X[i+j])$ where $(X^i)=t(X)$; it is canonical and functorial starting from $E_2$. This spectral sequences specializes to the 'usual' (Deligne's) weight spectral sequences for 'classical' realizations of motives and to Atiyah-Hirzebruch spectral sequences for spectra. Under certain restrictions, we prove that $K_0(C)\\cong K_0(Hw)$ and $K_0(End C)\\cong K_0(End Hw)$.   The definition of a weight structure is almost dual to those of a t-structure; yet several properties differ. One can often construct a certain $t$-structure which is 'adjacent' to $w$ and vice versa. This is the case for the Voevodsky's $DM^{eff}_-$ (one obtains certain new Chow weight and t-structures for it; the heart of the latter is 'dual' to $Chow^{eff}$) and for the stable homotopy category. The Chow t-structure is closely related to unramified cohomology.  ", "human_text": "  This paper is dedicated to triangulated categories endowed with weight structures (a new notion; D. Pauksztello has independently introduced them as co-t-structures). This axiomatizes the properties of stupid truncations of complexes in $K(B)$. We also construct weight structures for Voevodsky's categories of motives and for various categories of spectra. A weight structure $w$ defines Postnikov towers of objects; these towers are canonical and functorial 'up to morphisms that are zero on cohomology'. For $Hw$ being the heart of $w$ (in $DM_{gm}$ we have $Hw=Chow$) we define a canonical conservative 'weakly exact' functor $t$ from our $C$ to a certain weak category of complexes $K_w(Hw)$. For any (co)homological functor $H:C\\to A$ for an abelian $A$ we construct a weight spectral sequence $T:H(X^i[j])\\implies H(X[i+j])$ where $(X^i)=t(X)$; it is canonical and functorial starting from $E_2$. This spectral sequences specializes to the 'usual' (Deligne's) weight spectral sequences for 'classical' realizations of motives and to Atiyah-Hirzebruch spectral sequences for spectra. Under certain restrictions, we prove that $K_0(C)\\cong K_0(Hw)$ and $K_0(End C)\\cong K_0(End Hw)$.   The definition of a weight structure is almost dual to those of a t-structure; yet several properties differ. One can often construct a certain $t$-structure which is 'adjacent' to $w$ and vice versa. This is the case for the Voevodsky's $DM^{eff}_-$ (one obtains certain new Chow weight and t-structures for it; the heart of the latter is 'dual' to $Chow^{eff}$) and for the stable homotopy category. The Chow t-structure is closely related to unramified cohomology. ", "machine_text": "This article explores weight structures, which are a new kind of triangulated category, focusing on the relationship between them and t-structures, and how these understandings can be applied to various categories including Voevodsky's categories of motives and spectra. These weight structures allow for the construction of towers of objects and canonically conservative weakly exact functors from a category $C$ to weak categories of complexes. A weight spectral sequence is also defined that generalizes the Deligne spectral sequence for classical realizations of motives and the Atiyah-Hirzebruch spectral sequence for spectra. Further, some duality statements are presented between categories and $K$-groups. Lastly, the article examines cases in which a weight structure and an adjacent t-structure is formed, such as in Voevodsky's $DM^{eff}_-$ and the stable homotopy category.  This paper considers weight structures, a new notion of triangulated categories, in contrast to related $t$-structures. Through applications in Voevodsky's categories of motives and spectra, this article explores the nature of these weight structures, detailing how the construction of towers of objects and weight spectral sequences are made possible. Weakly exact functors are also defined, and duality is demonstrated between categories and $K$-groups. The examination of the relationship between a weight structure and an adjacent t-structure is discussed in Voevodsky's $DM^{eff}_-$ and the stable homotopy category.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.4003}
{"prompt": "Rephrase the abstract of an article with title 'Gas-grain chemistry in cold interstellar cloud cores with a microscopic   Monte Carlo approach to surface chemistry'.   AIM: We have recently developed a microscopic Monte Carlo approach to study surface chemistry on interstellar grains and the morphology of ice mantles. The method is designed to eliminate the problems inherent in the rate-equation formalism to surface chemistry. Here we report the first use of this method in a chemical model of cold interstellar cloud cores that includes both gas-phase and surface chemistry. The surface chemical network consists of a small number of diffusive reactions that can produce molecular oxygen, water, carbon dioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation is started by running a gas-phase model including accretion onto grains but no surface chemistry or evaporation. The starting surface consists of either flat or rough olivine. We introduce the surface chemistry of the three species H, O and CO in an iterative manner using our stochastic technique. Under the conditions of the simulation, only atomic hydrogen can evaporate to a significant extent. Although it has little effect on other gas-phase species, the evaporation of atomic hydrogen changes its gas-phase abundance, which in turn changes the flux of atomic hydrogen onto grains. The effect on the surface chemistry is treated until convergence occurs. We neglect all non-thermal desorptive processes. RESULTS: We determine the mantle abundances of assorted molecules as a function of time through 2x10^5 yr. Our method also allows determination of the abundance of each molecule in specific monolayers. The mantle results can be compared with observations of water, carbon dioxide, carbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than a slight underproduction of mantle CO, our results are in very good agreement with observations.  ", "human_text": "  AIM: We have recently developed a microscopic Monte Carlo approach to study surface chemistry on interstellar grains and the morphology of ice mantles. The method is designed to eliminate the problems inherent in the rate-equation formalism to surface chemistry. Here we report the first use of this method in a chemical model of cold interstellar cloud cores that includes both gas-phase and surface chemistry. The surface chemical network consists of a small number of diffusive reactions that can produce molecular oxygen, water, carbon dioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation is started by running a gas-phase model including accretion onto grains but no surface chemistry or evaporation. The starting surface consists of either flat or rough olivine. We introduce the surface chemistry of the three species H, O and CO in an iterative manner using our stochastic technique. Under the conditions of the simulation, only atomic hydrogen can evaporate to a significant extent. Although it has little effect on other gas-phase species, the evaporation of atomic hydrogen changes its gas-phase abundance, which in turn changes the flux of atomic hydrogen onto grains. The effect on the surface chemistry is treated until convergence occurs. We neglect all non-thermal desorptive processes. RESULTS: We determine the mantle abundances of assorted molecules as a function of time through 2x10^5 yr. Our method also allows determination of the abundance of each molecule in specific monolayers. The mantle results can be compared with observations of water, carbon dioxide, carbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than a slight underproduction of mantle CO, our results are in very good agreement with observations. ", "machine_text": " This paper describes the development and initial application of a microscopic Monte Carlo approach to model surface chemistry in cold interstellar cloud cores. The technique eliminates the issues encountered by the rate-equation formalism in simulating surface chemistry. The surface chemical network combines three diffusive reactions of H, O, and CO to produce molecules such as molecular oxygen, water, carbon dioxide, formaldehyde, methanol and various radicals. Starting with either a flat or rough olivine surface and using a gas-phase model including accretion onto grains but no surface chemistry or evaporation, we considered the effects of atomic hydrogen evaporation and its impact on the gas-phase abundance and flux onto grains. Our simulations demonstrate agreement with observations of water, CO2, CO, and methanol ices in W33A and Elias 16, with only slight underproduction of mantle CO. This technique should enable further advances in the understanding of gas-grain chemistry in interstellar clouds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2704}
{"prompt": "Rephrase the abstract of an article with title 'An Abelian two-Higgs model of strongly correlated electrons: phase   structure, strengthening of phase transition and QCD at finite density'.   We investigate non-perturbative features of a three-dimensional Abelian Higgs model with singly- and doubly-charged scalar fields coupled to a single compact Abelian gauge field. The model is pretending to describe various planar systems of strongly correlated electrons such as high-Tc superconductivity in the overdoped regime and exotic materials possessing excitations with fractionalized quantum numbers. The complicated phase structure of the model is studied thoroughly using numerical tools and analytical arguments. In the three-dimensional space of coupling parameters we identify the Fermi liquid, the spin gap, the superconductor and the strange metallic phases. The behavior of three kinds of topological defects -- holon and spinon vortices and monopoles - is explored in various phases. We also observe a new effect, the strong enhancement of the phase transition strength reflected in a lower order of the transition: at sufficiently strong gauge coupling the two second order phase transitions -- corresponding to spinon-pair and holon condensation lines - join partially in the phase diagram and become a first order phase transition in that region. The last observation may have an analogue in Quantum Chromodynamics at non-zero temperature and finite baryon density. We argue that at sufficiently large baryon density the finite-temperature transition between the (3-flavor paired) color superconducting phase and the quark-gluon plasma phases should be much stronger compared with the transition between 2-flavor paired and 3-flavor paired superconducting phases.  ", "human_text": "  We investigate non-perturbative features of a three-dimensional Abelian Higgs model with singly- and doubly-charged scalar fields coupled to a single compact Abelian gauge field. The model is pretending to describe various planar systems of strongly correlated electrons such as high-Tc superconductivity in the overdoped regime and exotic materials possessing excitations with fractionalized quantum numbers. The complicated phase structure of the model is studied thoroughly using numerical tools and analytical arguments. In the three-dimensional space of coupling parameters we identify the Fermi liquid, the spin gap, the superconductor and the strange metallic phases. The behavior of three kinds of topological defects -- holon and spinon vortices and monopoles - is explored in various phases. We also observe a new effect, the strong enhancement of the phase transition strength reflected in a lower order of the transition: at sufficiently strong gauge coupling the two second order phase transitions -- corresponding to spinon-pair and holon condensation lines - join partially in the phase diagram and become a first order phase transition in that region. The last observation may have an analogue in Quantum Chromodynamics at non-zero temperature and finite baryon density. We argue that at sufficiently large baryon density the finite-temperature transition between the (3-flavor paired) color superconducting phase and the quark-gluon plasma phases should be much stronger compared with the transition between 2-flavor paired and 3-flavor paired superconducting phases. ", "machine_text": "This paper examines non-perturbative qualities of an Abelian Higgs model made out of singleton and double charged scalar fields, plus a single restricted Abelian gauge field. These components together can represent various examples of strongly correlated electronic systems, such as the high temperature superconductivity found in the overdoped regime and various materials possessing fractional quantum numbers. Through the use of analytical systems, as well as numerical facilitation, this article looks into the complicated phase structure of the model, locating peculiar features like Fermi Liquid, Spin Gap, Superconductor, and Strange Metallic Phases, as well as holon, spinon vortices, and monopoles. Additionally, the study came to note a radical intensification of the phase transition strength, converging to an initially second order transition eventually becoming the first order. The same phenomenon may occur in Quantum Chromodynamics when the temperature is nonzero, yet with a finite density of baryons. Thus, at a high enough baryon density, the change from a 2-flavor superconducting space to the 3-flavor one should yield a larger phase transition strength than usual.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1528}
{"prompt": "Rephrase the abstract of an article with title 'Meta-nematic transitions in a bilayer system: Application to the bilayer   ruthenate'.   It was suggested that the two consecutive metamagnetic transitions and the large residual resistivity discovered in Sr$_3$Ru$_2$O$_7$ can be understood via the nematic order and its domains in a single layer system. However, a recently reported anisotropy between two longitudinal resistivities induced by tilting the magnetic field away from the c-axis cannot be explained within the single layer nematic picture. To fill the gap in our understanding within the nematic order scenario, we investigate the effects of bilayer coupling and in-plane magnetic field on the electronic nematic phases in a bilayer system. We propose that the in-plane magnetic field in the bilayer system modifies the energetics of the domain formation, since it breaks the degeneracy of two different nematic orientations. Thus the system reveals a pure nematic phase with a resistivity anisotropy in the presence of an in-plane magnetic field. In addition to the nematic phase, the bilayer coupling opens a novel route to a hidden nematic phase that preserves the x-y symmetry of the Fermi surfaces.  ", "human_text": "  It was suggested that the two consecutive metamagnetic transitions and the large residual resistivity discovered in Sr$_3$Ru$_2$O$_7$ can be understood via the nematic order and its domains in a single layer system. However, a recently reported anisotropy between two longitudinal resistivities induced by tilting the magnetic field away from the c-axis cannot be explained within the single layer nematic picture. To fill the gap in our understanding within the nematic order scenario, we investigate the effects of bilayer coupling and in-plane magnetic field on the electronic nematic phases in a bilayer system. We propose that the in-plane magnetic field in the bilayer system modifies the energetics of the domain formation, since it breaks the degeneracy of two different nematic orientations. Thus the system reveals a pure nematic phase with a resistivity anisotropy in the presence of an in-plane magnetic field. In addition to the nematic phase, the bilayer coupling opens a novel route to a hidden nematic phase that preserves the x-y symmetry of the Fermi surfaces. ", "machine_text": "This paper explores the effects of bilayer coupling and in-plane magnetic field on meta-nematic transitions in a bilayer system, as it pertains to the bilayer ruthenate Sr$_3$Ru$_2$O$_7$. We hypothesize that the in-plane magnetic field in the bilayer system creates a pure nematic phase with a resistivity anisotropy when it impacts the energetics of domain formation by breaking the degeneracy of two different nematic orientations. Additionally, we postulate that bilayer coupling opens a pathway to a previously undiscovered nematic phase which preserves the x-y symmetry of the Fermi surfaces.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1069}
{"prompt": "Rephrase the abstract of an article with title 'Nonleptonic two-body B-decays including axial-vector mesons in the final   state'.   We present a systematic study of exclusive charmless nonleptonic two-body B decays including axial-vector mesons in the final state. We calculate branching ratios of B\\to PA, VA and AA decays, where A, V and P denote an axial-vector, a vector and a pseudoscalar meson, respectively. We assume naive factorization hypothesis and use the improved version of the nonrelativistic ISGW quark model for form factors in B\\to A transitions. We include contributions that arise from the effective \\Delta B=1 weak Hamiltonian H_{eff}. The respective factorized amplitude of these decays are explicitly showed and their penguin contributions are classified. We find that decays B^-to a_1^0\\pi^-,\\barB^0\\to a_1^{\\pm}\\pi^{\\mp}, B^-\\to a_1^-\\bar K^0, \\bar B^0\\to a_1^+K^-, \\bar B^0\\to f_1\\bar K^0, B^-\\to f_1K^-, B^-\\to K_1^-(1400)\\etap, B^-\\to b_1^-\\bar K^{0}, and \\bar B^0\\to b_1^+\\pi^-(K^-) have branching ratios of the order of 10^{-5}. We also study the dependence of branching ratios for B \\to K_1P(V,A) decays (K_1=K_1(1270),K_1(1400)) with respect to the mixing angle between K_A and K_B.  ", "human_text": "  We present a systematic study of exclusive charmless nonleptonic two-body B decays including axial-vector mesons in the final state. We calculate branching ratios of B\\to PA, VA and AA decays, where A, V and P denote an axial-vector, a vector and a pseudoscalar meson, respectively. We assume naive factorization hypothesis and use the improved version of the nonrelativistic ISGW quark model for form factors in B\\to A transitions. We include contributions that arise from the effective \\Delta B=1 weak Hamiltonian H_{eff}. The respective factorized amplitude of these decays are explicitly showed and their penguin contributions are classified. We find that decays B^-to a_1^0\\pi^-,\\barB^0\\to a_1^{\\pm}\\pi^{\\mp}, B^-\\to a_1^-\\bar K^0, \\bar B^0\\to a_1^+K^-, \\bar B^0\\to f_1\\bar K^0, B^-\\to f_1K^-, B^-\\to K_1^-(1400)\\etap, B^-\\to b_1^-\\bar K^{0}, and \\bar B^0\\to b_1^+\\pi^-(K^-) have branching ratios of the order of 10^{-5}. We also study the dependence of branching ratios for B \\to K_1P(V,A) decays (K_1=K_1(1270),K_1(1400)) with respect to the mixing angle between K_A and K_B. ", "machine_text": "This paper looks at non-leptonic, two-body B decay that end in axial-vector mesons. We use the naive factorization hypothesis and an upgraded nonrelativistic ISGW quark model with the effective $\\Delta B=1$ weak Hamiltonian as our theoretical framework to calculate branching ratios. We describe the resulting decays B$^-$ to $\\alpha_1^0\\pi^-$, $\\overline{B^0}$ to $\\alpha_1^{\\pm}\\pi^{\\mp}$, $B^-\\to \\alpha_1^-\\overline{K^0}$, $\\overline{B^0}$ to $\\alpha_1^+K^-$, $\\overline{B^0}$ to ${f_1}\\overline{K^0}$,$ B^-\\to {f_1}K^-$, $B^-\\to K_1^-\\eta'$, $B^-\\to {b_1}^-\\overline{K^0}$, and $\\overline{B^0}$ to ${b^+_1}\\pi^-$ to be of the order of $10^{-5}$. We examine the dependence of the $B^-\\to K_1P(V,A)$ decays (K_1=K_1(1270),K_1(1400)) on the mixing angle achievable between K_A and K_B.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1181}
{"prompt": "Rephrase the abstract of an article with title 'On the nature of two superconducting transitions in the specific heat of   PrOs$_4$Sb$_{12}$: Effects of crystal grinding'.   Specific heat, dc- and ac-magnetic susceptibility are reported for a large single crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room temperature effective paramagnetic moment of the crystal was consistent with the Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The crystal showed two distinct anomalies in the specific heat and an overall discontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at $T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at $T_{c2}$ was very sharp, consistent with a good quality of the crystal. We observed a shoulder in $\\chi$' and two peaks in $\\chi$'' below $T_{c1}$. However, there were no signatures in $\\chi$' of the lower temperature transition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which suppresses the upper superconducting transition in both the specific heat and magnetic susceptibility. $\\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in the powdered sample. Existing data on ground, polished, and sliced crystals suggests the existence of a length scale of order 100 $\\mu$, characterizing the higher temperature superconducting phase.  ", "human_text": "  Specific heat, dc- and ac-magnetic susceptibility are reported for a large single crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room temperature effective paramagnetic moment of the crystal was consistent with the Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The crystal showed two distinct anomalies in the specific heat and an overall discontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at $T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at $T_{c2}$ was very sharp, consistent with a good quality of the crystal. We observed a shoulder in $\\chi$' and two peaks in $\\chi$'' below $T_{c1}$. However, there were no signatures in $\\chi$' of the lower temperature transition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which suppresses the upper superconducting transition in both the specific heat and magnetic susceptibility. $\\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in the powdered sample. Existing data on ground, polished, and sliced crystals suggests the existence of a length scale of order 100 $\\mu$, characterizing the higher temperature superconducting phase. ", "machine_text": " The physical properties of a large single crystal of PrOs$_4$Sb$_{12}$, such as specific heat, dc- and ac-magnetic susceptibility, were studied and exhibited two distinct anomalies in the specific heat, as well as an overall discontinuity of more than 1000 mJ/K$^2$mol. The upper transition (at $T_{c1}$) showed a rounded shape, while the lower one, at $T_{c2}$, presented a very sharp anomaly. The magnetic susceptibility showed two peaks below $T_{c1}$, however, no signatures of the lower temperature transition were observed. It was discovered PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding and this suppression of the upper transition was observed in both the specific heat and magnetic susceptibility of the powdered sample, showing a decrease in $\\Delta C/T_{c}$ to 140 mJ/K$^2$ mol. Existing data on grinding, polishing, and slicing single crystals indicates the existence of a length scale of about 100 $\\mu$, imparticular for its higher temperature superconducting phase.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4659}
{"prompt": "Rephrase the abstract of an article with title 'Spectral study on the dips of Cir X-1'.   We present X-ray spectral analyses of low mass X-ray binary Cir X-1 during X-ray dips, using the Rossi X-ray Timing Explorer (RXTE) data. Each dip was divided into several segments, and the spectrum of each segment was fitted with a three-component blackbody model, in which two components are affected by partial covering and the third one is unaffected. A Gaussian emission line is also included in the spectral model to represent the Fe Ka line at ~ 6.4 keV. The fitted temperatures of the two partially covered components are about 2 keV and 1 keV, while the uncovered component has a temperature of ~ 0.5-0.6 keV. The equivalent blackbody emission radius of the hottest component is the smallest and that of the coolest component is the biggest. During dips, the fluxes of the two hot components are linearly correlated, while that of the third component doesn't show any significant variation. The Fe line flux remains constant within errors during the short dips. However, during the long dips the line flux changes significantly and is positively correlated with the fluxes of the two hot components. These results suggest: (1) the temperature of the X-ray emitting region decreases with radius, (2) the Fe Ka line emitting region is close to the hot continuum emitting region, and (3) the size of the Fe line emitting region is bigger than the size of the obscuring matters causing short dips but smaller than the sizes of those causing long dips.  ", "human_text": "  We present X-ray spectral analyses of low mass X-ray binary Cir X-1 during X-ray dips, using the Rossi X-ray Timing Explorer (RXTE) data. Each dip was divided into several segments, and the spectrum of each segment was fitted with a three-component blackbody model, in which two components are affected by partial covering and the third one is unaffected. A Gaussian emission line is also included in the spectral model to represent the Fe Ka line at ~ 6.4 keV. The fitted temperatures of the two partially covered components are about 2 keV and 1 keV, while the uncovered component has a temperature of ~ 0.5-0.6 keV. The equivalent blackbody emission radius of the hottest component is the smallest and that of the coolest component is the biggest. During dips, the fluxes of the two hot components are linearly correlated, while that of the third component doesn't show any significant variation. The Fe line flux remains constant within errors during the short dips. However, during the long dips the line flux changes significantly and is positively correlated with the fluxes of the two hot components. These results suggest: (1) the temperature of the X-ray emitting region decreases with radius, (2) the Fe Ka line emitting region is close to the hot continuum emitting region, and (3) the size of the Fe line emitting region is bigger than the size of the obscuring matters causing short dips but smaller than the sizes of those causing long dips. ", "machine_text": " This paper investigates the X-ray spectral features of the low-mass X-ray binary Cir X-1 during periods of immersion known as 'dips'. For each dip, multiple segments were analysed with a 3-component blackbody model - two of which are partially blocked by matter- with a Gaussian emission line included to represent the Fe Ka line of 6.4 keV. Results showed the steep temperature separation of 2 and 1 KeV between the two blocked components and the 0.5-0.6 KeV of the uncovered component. In addition, the fluxes of the two hotter components displayed linear correlation in dips, but no variation for the third component. Variation in the Fe Ka line flux was only present during long dips, having a positive relation with the hot fluxes. This suggests decreasing temperatures with radius; a close proximity of the Fe Ka line to the hot continuum; and a larger Fe Ka line than those of obscuring material causing the short dips, but smaller than the size of obscuring material responsible for long dips.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.401}
{"prompt": "Rephrase the abstract of an article with title 'Regularization of spherical and axisymmetric evolution codes in   numerical relativity'.   Several interesting astrophysical phenomena are symmetric with respect to the rotation axis, like the head-on collision of compact bodies, the collapse and/or accretion of fields with a large variety of geometries, or some forms of gravitational waves. Most current numerical relativity codes, however, can not take advantage of these symmetries due to the fact that singularities in the adapted coordinates, either at the origin or at the axis of symmetry, rapidly cause the simulation to crash. Because of this regularity problem it has become common practice to use full-blown Cartesian three-dimensional codes to simulate axi-symmetric systems. In this work we follow a recent idea idea of Rinne and Stewart and present a simple procedure to regularize the equations both in spherical and axi-symmetric spaces. We explicitly show the regularity of the evolution equations, describe the corresponding numerical code, and present several examples clearly showing the regularity of our evolutions.  ", "human_text": "  Several interesting astrophysical phenomena are symmetric with respect to the rotation axis, like the head-on collision of compact bodies, the collapse and/or accretion of fields with a large variety of geometries, or some forms of gravitational waves. Most current numerical relativity codes, however, can not take advantage of these symmetries due to the fact that singularities in the adapted coordinates, either at the origin or at the axis of symmetry, rapidly cause the simulation to crash. Because of this regularity problem it has become common practice to use full-blown Cartesian three-dimensional codes to simulate axi-symmetric systems. In this work we follow a recent idea idea of Rinne and Stewart and present a simple procedure to regularize the equations both in spherical and axi-symmetric spaces. We explicitly show the regularity of the evolution equations, describe the corresponding numerical code, and present several examples clearly showing the regularity of our evolutions. ", "machine_text": "This paper considers the potential impact of regularizing numerical relativity codes that analyze spherical and axisymmetric mutations. We discuss the regularity issues resulting from using adapted coordinates to simulate axisymmetric systems, and elucidate a new approach proposed by Rinne and Stewart. We then demonstrate how this idea can be applied to regularize the equations both in spherical and axisymmetric spaces. To illustrate the regularity of our approaches, numerical codes and examples are provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0923}
{"prompt": "Rephrase the abstract of an article with title 'Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in   hypre and PETSc'.   We describe our software package Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as a stand-alone serial library, as an external package to PETSc (``Portable, Extensible Toolkit for Scientific Computation'', a general purpose suite of tools for the scalable solution of partial differential equations and related problems developed by Argonne National Laboratory), and is also built into {\\it hypre} (``High Performance Preconditioners'', scalable linear solvers package developed by Lawrence Livermore National Laboratory). The present BLOPEX release includes only one solver--the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it hypre} provides users with advanced high-quality parallel preconditioners for linear systems, in particular, with domain decomposition and multigrid preconditioners. With BLOPEX, the same preconditioners can now be efficiently used for symmetric eigenvalue problems. PETSc facilitates the integration of independently developed application modules with strict attention to component interoperability, and makes BLOPEX extremely easy to compile and use with preconditioners that are available via PETSc. We present the LOBPCG algorithm in BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability of BLOPEX by testing it on a number of distributed and shared memory parallel systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition and {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem, the standard 7-point finite-difference approximation of the 3-D Laplacian, with the problem size in the range $10^5-10^8$.  ", "human_text": "  We describe our software package Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as a stand-alone serial library, as an external package to PETSc (``Portable, Extensible Toolkit for Scientific Computation'', a general purpose suite of tools for the scalable solution of partial differential equations and related problems developed by Argonne National Laboratory), and is also built into {\\it hypre} (``High Performance Preconditioners'', scalable linear solvers package developed by Lawrence Livermore National Laboratory). The present BLOPEX release includes only one solver--the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it hypre} provides users with advanced high-quality parallel preconditioners for linear systems, in particular, with domain decomposition and multigrid preconditioners. With BLOPEX, the same preconditioners can now be efficiently used for symmetric eigenvalue problems. PETSc facilitates the integration of independently developed application modules with strict attention to component interoperability, and makes BLOPEX extremely easy to compile and use with preconditioners that are available via PETSc. We present the LOBPCG algorithm in BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability of BLOPEX by testing it on a number of distributed and shared memory parallel systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition and {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem, the standard 7-point finite-difference approximation of the 3-D Laplacian, with the problem size in the range $10^5-10^8$. ", "machine_text": "We present the software package BLOPEX, which is available as a stand-alone serial library as well as an external package for PETSc and integrated into hypre. It includes the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) algorithm for symmetric eigenvalue problems. We demonstrate the scalability of BLOPEX by testing it on various distributed and shared memory computers which use PETSc domain decomposition and hypre multigrid preconditioners. We examine the performance of BLOPEX on the standard 7-point finite-difference approximation of the 3-D Laplacian with problem sizes ranging from $10^5$ to $10^8$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2626}
{"prompt": "Rephrase the abstract of an article with title 'Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity'.   A generalized geometric method is developed for constructing exact solutions of gravitational field equations in Einstein theory and generalizations. First, we apply the formalism of nonholonomic frame deformations (formally considered for nonholonomic manifolds and Finsler spaces) when the gravitational field equations transform into systems of nonlinear partial differential equations which can be integrated in general form. The new classes of solutions are defined by generic off-diagonal metrics depending on integration functions on one, two and three (or three and four) variables if we consider four (or five) dimensional spacetimes. Second, we use a general scheme when one (two) parameter families of exact solutions are defined by any source-free solutions of Einstein's equations with one (two) Killing vector field(s). A successive iteration procedure results in new classes of solutions characterized by an infinite number of parameters for a non-Abelian group involving arbitrary functions on one variable. Five classes of exact off-diagonal solutions are constructed in vacuum Einstein and in string gravity describing solitonic pp-wave interactions. We explore possible physical consequences of such solutions derived from primary Schwarzschild or pp-wave metrics.  ", "human_text": "  A generalized geometric method is developed for constructing exact solutions of gravitational field equations in Einstein theory and generalizations. First, we apply the formalism of nonholonomic frame deformations (formally considered for nonholonomic manifolds and Finsler spaces) when the gravitational field equations transform into systems of nonlinear partial differential equations which can be integrated in general form. The new classes of solutions are defined by generic off-diagonal metrics depending on integration functions on one, two and three (or three and four) variables if we consider four (or five) dimensional spacetimes. Second, we use a general scheme when one (two) parameter families of exact solutions are defined by any source-free solutions of Einstein's equations with one (two) Killing vector field(s). A successive iteration procedure results in new classes of solutions characterized by an infinite number of parameters for a non-Abelian group involving arbitrary functions on one variable. Five classes of exact off-diagonal solutions are constructed in vacuum Einstein and in string gravity describing solitonic pp-wave interactions. We explore possible physical consequences of such solutions derived from primary Schwarzschild or pp-wave metrics. ", "machine_text": " In this article, we develop a geometric approach to constructing exact solutions for gravity consisting of Einstein theory and its generalizations. Specifically, nonholonomic frame deformations are used to transform the gravitational field equations into sets of nonlinear partial differential equations which can be solved in general form. These solutions can be generically characterized by metrics depending on integration functions involving one, two, three, or four variables. Moreover, exact solutions with a parameter family may be obtained by source-free solutions of Einstein's equations with at least one Killing vector field. Additionally, a successive iteration procedure creates new classes of solutions specified by an infinite number of parameters with a non-Abelian group related to arbitrary functions of one variable. Finally, five classes of exact off-diagonal solutions are generated in vacuum Einstein and string gravity describing solitonic pp-wave interactions emerging from the primary Schwarzschild or pp-wave metrics. The potential physical implications of these solutions are also investigated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3986}
{"prompt": "Rephrase the abstract of an article with title 'Hypersurfaces in H^{n+1} and conformally invariant equations: the   generalized Christoffel and Nirenberg problems'.   Our first objective in this paper is to give a natural formulation of the Christoffel problem for hypersurfaces in $H^{n+1}$, by means of the hyperbolic Gauss map and the notion of hyperbolic curvature radii for hypersurfaces. Our second objective is to provide an explicit equivalence of this Christoffel problem with the famous problem of prescribing scalar curvature on $\\S^n$ for conformal metrics, posed by Nirenberg and Kazdan-Warner. This construction lets us translate into the hyperbolic setting the known results for the scalar curvature problem, and also provides a hypersurface theory interpretation of such an intrinsic problem from conformal geometry. Our third objective is to place the above result into a more general framework. Specifically, we will show how the problem of prescribing the hyperbolic Gauss map and a given function of the hyperbolic curvature radii in $H^{n+1}$ is strongly related to some important problems on conformally invariant PDEs in terms of the Schouten tensor. This provides a bridge between the theory of conformal metrics on $\\S^n$ and the theory of hypersurfaces with prescribed hyperbolic Gauss map in $\\H^{n+1}$. The fourth objective is to use the above correspondence to prove that for a wide family of Weingarten functionals $W(\\k_1,..., \\k_n)$, the only compact immersed hypersurfaces in $H^{n+1}$ on which $W$ is constant are round spheres.  ", "human_text": "  Our first objective in this paper is to give a natural formulation of the Christoffel problem for hypersurfaces in $H^{n+1}$, by means of the hyperbolic Gauss map and the notion of hyperbolic curvature radii for hypersurfaces. Our second objective is to provide an explicit equivalence of this Christoffel problem with the famous problem of prescribing scalar curvature on $\\S^n$ for conformal metrics, posed by Nirenberg and Kazdan-Warner. This construction lets us translate into the hyperbolic setting the known results for the scalar curvature problem, and also provides a hypersurface theory interpretation of such an intrinsic problem from conformal geometry. Our third objective is to place the above result into a more general framework. Specifically, we will show how the problem of prescribing the hyperbolic Gauss map and a given function of the hyperbolic curvature radii in $H^{n+1}$ is strongly related to some important problems on conformally invariant PDEs in terms of the Schouten tensor. This provides a bridge between the theory of conformal metrics on $\\S^n$ and the theory of hypersurfaces with prescribed hyperbolic Gauss map in $\\H^{n+1}$. The fourth objective is to use the above correspondence to prove that for a wide family of Weingarten functionals $W(\\k_1,..., \\k_n)$, the only compact immersed hypersurfaces in $H^{n+1}$ on which $W$ is constant are round spheres. ", "machine_text": "In the present paper, we investigate the relationship between hypersurfaces in hyperbolic space $H^{n+1}$ and conformally invariant equations. Through a hyperbolic Gauss map and the notion of hyperbolic curvature radii,we formulate the Christoffel problem. This direct connection also allows us to make a direct comparison between the scalar curvature problem posed by Nirenberg and Kazdan-Warner on the $\\mathbb{S}^n$ manifold, and provide an insight into its hypersurface interpretation. Additionally, this serves as a bridge to link the theory of hypersurfaces with prescribed hyperbolic Gauss map in $H^{n+1}$ with some important problems in conformally invariant PDEs regarding the Schouten tensor. We further analyse this relationship to prove that certain Weingarten functionals are constant only on round spheres among all compactly immersed hypersurfaces in $H^{n+1}$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2314}
{"prompt": "Rephrase the abstract of an article with title 'Thermal Stability of Metallic Single-Walled Carbon Nanotubes: An O(N)   Tight-Binding Molecular Dynamics Simulation Study'.   Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to investigate the thermal stability of (10,10) metallic Single-Walled Carbon Nanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial direction. Velocity Verlet algorithm along with the canonical ensemble molecular dynamics (NVT) is used to simulate the tubes at the targeted temperatures. The effects of slow and rapid temperature increases on the physical characteristics, structural stability and the energetics of the tube are investigated and compared. Simulations are carried out starting from room temperature and the temperature is raised in steps of 300K. Stability of the simulated metallic SWCNT is examined at each step before it is heated to higher temperatures. First indication of structural deformation is observed at 600K. For higher heat treatments the deformations are more pronounced and the bond breaking temperature is reached around 2500K. Gradual (slow) heating and thermal equilibrium (fast heating) methods give the value of radial thermal expansion coefficient in the temperature range between 300K-600K as 0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both methods give the same value of 0.089x10^{-5}(1/K). The ratio of the total energy per atom with respect to temperature is found to be 3x10^{-4} eV/K.  ", "human_text": "  Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to investigate the thermal stability of (10,10) metallic Single-Walled Carbon Nanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial direction. Velocity Verlet algorithm along with the canonical ensemble molecular dynamics (NVT) is used to simulate the tubes at the targeted temperatures. The effects of slow and rapid temperature increases on the physical characteristics, structural stability and the energetics of the tube are investigated and compared. Simulations are carried out starting from room temperature and the temperature is raised in steps of 300K. Stability of the simulated metallic SWCNT is examined at each step before it is heated to higher temperatures. First indication of structural deformation is observed at 600K. For higher heat treatments the deformations are more pronounced and the bond breaking temperature is reached around 2500K. Gradual (slow) heating and thermal equilibrium (fast heating) methods give the value of radial thermal expansion coefficient in the temperature range between 300K-600K as 0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both methods give the same value of 0.089x10^{-5}(1/K). The ratio of the total energy per atom with respect to temperature is found to be 3x10^{-4} eV/K. ", "machine_text": " Using the Order(N) Tight-Binding Molecular Dynamics Simulation, the thermal stability of a (10,10) metallic Single-Walled Carbon Nanotube (SWCNT) is investigated. After applying the periodic boundary conditions (PBC) in axial direction and the Velocity Verlet algorithm along with the canonical ensemble molecular dynamics (NVT), simulations of the SWCNT were performed at increasing temperatures, starting from 300K and expanding in steps of 300K. The effects on the physical characteristics, structural stability, and energetics when the temperature was raised in both slow and rapid increments were studied. Signs of deformation occurred at 600K, while bond breaking was found at 2500K. Thermal expansion coefficient between 300K-600K was measured as 0.31 x 10^(-5) (1/K) when temperatures were increased slowly and 0.089 x 10^(-5) (1/K) when heated quickly and over 600K both methods yielded the same result. Additionally, a ratio of total energy per atom to temperature was obtained, of 3 x 10^(-4) eV/K.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1625}
{"prompt": "Rephrase the abstract of an article with title 'Matter density perturbations and effective gravitational constant in   modified gravity models of dark energy'.   We derive the equation of matter density perturbations on sub-horizon scales for a general Lagrangian density f(R, phi, X) that is a function of a Ricci scalar R, a scalar field phi and a kinetic term X=-(nabla phi)^2/2. This is useful to constrain modified gravity dark energy models from observations of large-scale structure and weak lensing. We obtain the solutions for the matter perturbation delta_m as well as the gravitational potential Phi for some analytically solvable models. In a f(R) dark energy model with the Lagrangian density f(R)=alpha R^{1+m}-Lambda, the growth rates of perturbations exhibit notable differences from those in the standard Einstein gravity unless m is very close to 0. In scalar-tensor models with the Lagrangian density f=F(phi)R+2p(phi,X) we relate the models with coupled dark energy scenarios in the Einstein frame and reproduce the equations of perturbations known in the current literature by making a conformal transformation. We also estimate the evolution of perturbations in both Jordan and Einstein frames when the energy fraction of dark energy is constant during the matter-dominated epoch.  ", "human_text": "  We derive the equation of matter density perturbations on sub-horizon scales for a general Lagrangian density f(R, phi, X) that is a function of a Ricci scalar R, a scalar field phi and a kinetic term X=-(nabla phi)^2/2. This is useful to constrain modified gravity dark energy models from observations of large-scale structure and weak lensing. We obtain the solutions for the matter perturbation delta_m as well as the gravitational potential Phi for some analytically solvable models. In a f(R) dark energy model with the Lagrangian density f(R)=alpha R^{1+m}-Lambda, the growth rates of perturbations exhibit notable differences from those in the standard Einstein gravity unless m is very close to 0. In scalar-tensor models with the Lagrangian density f=F(phi)R+2p(phi,X) we relate the models with coupled dark energy scenarios in the Einstein frame and reproduce the equations of perturbations known in the current literature by making a conformal transformation. We also estimate the evolution of perturbations in both Jordan and Einstein frames when the energy fraction of dark energy is constant during the matter-dominated epoch. ", "machine_text": " We present an investigation of matter density perturbations and the effective gravitational constant in modified gravity models of dark energy. The analysis focuses on the sub-horizon scales by deriving an equation from a general Lagrangian density depending on Ricci scalar R, a scalar field phi and a kinetic term X. This allows us to constraint potential observations of large-scale structure and weak lensing. We determine the matter perturbations, delta_m, and the gravitational potential Phi for a class of analytically solvable models, specifically a f(R) dark energy model with a Lagrangian density of alpha R^{1+m}-Lambda. Furthermore, scalar-tensor models with the Lagrangian density f=F(phi)R+2p(phi,X) are related to coupled dark energy scenarios in the Einstein frame, and a conformal transformation produces the same perturbations found within the current literature. Finally, we estimate the evolution of perturbations in both Jordan and Einstein frames when dark energy energy fraction is kept constant during the matter-dominated epoch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1032}
{"prompt": "Rephrase the abstract of an article with title 'Ab initio statistical mechanics of surface adsorption and desorption: I.   H$_2$O on MgO (001) at low coverage'.   We present a general computational scheme based on molecular dynamics (m.d.) simulation for calculating the chemical potential of adsorbed molecules in thermal equilibrium on the surface of a material. The scheme is based on the calculation of the mean force in m.d. simulations in which the height of a chosen molecule above the surface is constrained, and subsequent integration of the mean force to obtain the potential of mean force and hence the chemical potential. The scheme is valid at any coverage and temperature, so that in principle it allows the calculation of the chemical potential as a function of coverage and temperature. It avoids all statistical mechanical approximations, except for the use of classical statistical mechanics for the nuclei, and assumes nothing in advance about the adsorption sites. From the chemical potential, the absolute desorption rate of the molecules can be computed, provided the equilibration rate on the surface is faster than the desorption rate. We apply the theory by {\\em ab initio} m.d. simulation to the case of H$_2$O on MgO (001) in the low-coverage limit, using the Perdew-Burke-Ernzerhof (PBE) form of exchange-correlation. The calculations yield an {\\em ab initio} value of the Polanyi-Wigner frequency prefactor, which is more than two orders of magnitude greater than the value of $10^{13}$ s$^{-1}$ often assumed in the past. Provisional comparison with experiment suggests that the PBE adsorption energy may be too low, but the extension of the calculations to higher coverages is needed before firm conclusions can be drawn. The possibility of including quantum nuclear effects by using path-integral simulations is noted.  ", "human_text": "  We present a general computational scheme based on molecular dynamics (m.d.) simulation for calculating the chemical potential of adsorbed molecules in thermal equilibrium on the surface of a material. The scheme is based on the calculation of the mean force in m.d. simulations in which the height of a chosen molecule above the surface is constrained, and subsequent integration of the mean force to obtain the potential of mean force and hence the chemical potential. The scheme is valid at any coverage and temperature, so that in principle it allows the calculation of the chemical potential as a function of coverage and temperature. It avoids all statistical mechanical approximations, except for the use of classical statistical mechanics for the nuclei, and assumes nothing in advance about the adsorption sites. From the chemical potential, the absolute desorption rate of the molecules can be computed, provided the equilibration rate on the surface is faster than the desorption rate. We apply the theory by {\\em ab initio} m.d. simulation to the case of H$_2$O on MgO (001) in the low-coverage limit, using the Perdew-Burke-Ernzerhof (PBE) form of exchange-correlation. The calculations yield an {\\em ab initio} value of the Polanyi-Wigner frequency prefactor, which is more than two orders of magnitude greater than the value of $10^{13}$ s$^{-1}$ often assumed in the past. Provisional comparison with experiment suggests that the PBE adsorption energy may be too low, but the extension of the calculations to higher coverages is needed before firm conclusions can be drawn. The possibility of including quantum nuclear effects by using path-integral simulations is noted. ", "machine_text": "This article introduces a computational approach, based on molecular dynamics (m.d.) simulations, for determining the chemical potential of molecules adsorbed onto solid surfaces. The method allows for the calculation of adsorption and desorption from any coverage and temperature without any pre-assumed statistical mechanics approximations of adsorption sites. To demonstrate the technique, ab initio m.d. simulations of H$_2$O on MgO (001) are performed at low coverage. Results suggest that the PBE exchange-correlation form accurately captures the adsorption energy, however this needs to be further tested by increasing coverage. Moreover, the Polanyi-Wigner frequency prefactor is found to be two orders of magnitude larger than typically assumed prior. In addition, the method allows for the incorporation of quantum nuclear effects via path-integral simulations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1}
{"prompt": "Rephrase the abstract of an article with title 'Dust Formation and He II 4686 emission in the Dense Shell of the   Peculiar Type Ib Supernova 2006jc'.   We present evidence for the formation of dust grains in an unusual Type Ib SN based on late-time spectra of SN 2006jc. The progenitor suffered an LBV-like outburst just 2 yr earlier, and we propose that the dust formation is a consequence of the SN blast wave overtaking that LBV-like shell. The key evidence for dust formation is (a) the appearance of a red/near-IR continuum source fit by 1600 K graphite grains, and (b) fading of the redshifted sides of He I emission lines, yielding progressively more asymmetric blueshifted lines as dust obscures receding material. This provides the strongest case yet for dust formation in any SN Ib/c. Both developments occurred between 51 and 75 d after peak, while other SNe observed to form dust did so after a few hundred days. Geometric considerations indicate that dust formed in the dense swept-up shell between the forward and reverse shocks, and not in the freely expanding SN ejecta. Rapid cooling leading to dust formation may have been aided by extremely high shell densities, as indicated by He I line ratios. The brief epoch of dust formation is accompanied by He II 4686 emission and enhanced X-ray emission. These clues suggest that the unusual dust formation in this object was not due to properties of the SN itself, but instead -- like most peculiarities of SN 2006jc -- was a consequence of the dense environment created by an LBV-like eruption 2 yr before the SN.  ", "human_text": "  We present evidence for the formation of dust grains in an unusual Type Ib SN based on late-time spectra of SN 2006jc. The progenitor suffered an LBV-like outburst just 2 yr earlier, and we propose that the dust formation is a consequence of the SN blast wave overtaking that LBV-like shell. The key evidence for dust formation is (a) the appearance of a red/near-IR continuum source fit by 1600 K graphite grains, and (b) fading of the redshifted sides of He I emission lines, yielding progressively more asymmetric blueshifted lines as dust obscures receding material. This provides the strongest case yet for dust formation in any SN Ib/c. Both developments occurred between 51 and 75 d after peak, while other SNe observed to form dust did so after a few hundred days. Geometric considerations indicate that dust formed in the dense swept-up shell between the forward and reverse shocks, and not in the freely expanding SN ejecta. Rapid cooling leading to dust formation may have been aided by extremely high shell densities, as indicated by He I line ratios. The brief epoch of dust formation is accompanied by He II 4686 emission and enhanced X-ray emission. These clues suggest that the unusual dust formation in this object was not due to properties of the SN itself, but instead -- like most peculiarities of SN 2006jc -- was a consequence of the dense environment created by an LBV-like eruption 2 yr before the SN. ", "machine_text": " Recent spectroscopy of the peculiar Type Ib SN 2006jc reveals evidence that dust grains were formed in its aftermath. Our proposed explanation is that the SN blast wave crashing against the LBV-like shell expelled from the progenitor two years before, caused the formation of dust. This is strongly attested to by (a) the red/near-IR continuum that can be fitted by the presence of 1600 K graphite grains, and (b) progressive asymmetry in He I emission lines as the receding material gets obscured by the shroud of dust. This is the first convincing proof of dust formation in any SN Ib/c less than a hundred days after peak. Our calculations point to dust formation having taken place in the space between the forward and reverse shocks, where the swept-up shell is denser, rather than in the freely expanding SN ejecta. This is further supported by He I line ratios, He II 4686 emission, and increased X-ray radiation detected during the brief interval of dust formation. Ultimately, the uniqueness of the dust formation event in SN 2006jc can be attributed to the anomalous conditions in the environment at the time of the SN, brought about by the intense LBV-like eruption of its progenitor.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2249}
{"prompt": "Rephrase the abstract of an article with title 'Mass-to-light Ratio of Ly-alpha Emitters: Implications of Ly-alpha   Surveys at Redshifts z=5.7, 6.5, 7, and 8.8'.   Using a simple method to interpret the luminosity function of Ly-alpha emitters, we explore properties of Ly-alpha emitters from 5.7 < z < 8.8 with various assumptions about metallicity and stellar mass spectra. We constrain a mass-to-'observed' light ratio, M_h/L_band. For narrow-band surveys, L_band is simply related to the intrinsic Ly-alpha luminosity with a survival fraction of Ly-alpha photons, alpha_esc. The mass-to-'bolometric light', M_h/L_bol, can also be deduced, once the metallicity and stellar mass spectrum are given. The inferred M_h/L_bol is more sensitive to metallicity than to the mass spectrum. We find the following constraints on a mass-to-light ratio of Ly-alpha emitters from 5.7 < z < 7: (M_h/L_bol)(alpha_{esc}epsilon^{1/gamma})^{-1}=21-38, 14-26, and 9-17 for Z=0, 1/50, and 1 Z_sun, respectively, where epsilon is the 'duty cycle' of Ly-alpha emitters, and gamma ~ 2 is a local slope of the cumulative luminosity function. Only weak lower limits are obtained for z=8.8. Therefore, Ly-alpha emitters are consistent with either starburst galaxies M_h/L_bol ~ 0.1-1 with a smaller Ly-alpha survival fraction, alpha_{esc}epsilon^{1/gamma} ~0.01-0.05, or normal populations (M_h/L_bol ~ 10) if a good fraction of Ly-alpha photons survived, alpha_{esc}epsilon^{1/gamma} ~ 0.5-1. We find no evidence for the end of reionization in the luminosity functions of Ly-alpha emitters discovered in the current Ly-alpha surveys, including recent discovery of one Ly-alpha emitter at z=7. The data are consistent with no evolution of intrinsic properties of Ly-alpha emitters or neutral fraction in the intergalactic medium up to z=7. No detection of sources at z=8.8 does not yield a significant constraint yet. We also show that the lack of detection at z=8.8 does not rule out the high-z galaxies being the origin of the excess NIRB.  ", "human_text": "  Using a simple method to interpret the luminosity function of Ly-alpha emitters, we explore properties of Ly-alpha emitters from 5.7 < z < 8.8 with various assumptions about metallicity and stellar mass spectra. We constrain a mass-to-'observed' light ratio, M_h/L_band. For narrow-band surveys, L_band is simply related to the intrinsic Ly-alpha luminosity with a survival fraction of Ly-alpha photons, alpha_esc. The mass-to-'bolometric light', M_h/L_bol, can also be deduced, once the metallicity and stellar mass spectrum are given. The inferred M_h/L_bol is more sensitive to metallicity than to the mass spectrum. We find the following constraints on a mass-to-light ratio of Ly-alpha emitters from 5.7 < z < 7: (M_h/L_bol)(alpha_{esc}epsilon^{1/gamma})^{-1}=21-38, 14-26, and 9-17 for Z=0, 1/50, and 1 Z_sun, respectively, where epsilon is the 'duty cycle' of Ly-alpha emitters, and gamma ~ 2 is a local slope of the cumulative luminosity function. Only weak lower limits are obtained for z=8.8. Therefore, Ly-alpha emitters are consistent with either starburst galaxies M_h/L_bol ~ 0.1-1 with a smaller Ly-alpha survival fraction, alpha_{esc}epsilon^{1/gamma} ~0.01-0.05, or normal populations (M_h/L_bol ~ 10) if a good fraction of Ly-alpha photons survived, alpha_{esc}epsilon^{1/gamma} ~ 0.5-1. We find no evidence for the end of reionization in the luminosity functions of Ly-alpha emitters discovered in the current Ly-alpha surveys, including recent discovery of one Ly-alpha emitter at z=7. The data are consistent with no evolution of intrinsic properties of Ly-alpha emitters or neutral fraction in the intergalactic medium up to z=7. No detection of sources at z=8.8 does not yield a significant constraint yet. We also show that the lack of detection at z=8.8 does not rule out the high-z galaxies being the origin of the excess NIRB. ", "machine_text": "  We present a method of analyzing luminosity functions of Ly-alpha emitters spanning a range of redshifts from 5.7 to 8.8, in order to demonstrate the constraints on their mass-to-light ratio (M_h/L_band). Our analysis shows that, when considering the survival fraction of Ly-alpha photons (alpha_esc) and the 'duty cycle' of emitters (epsilon), a ratio of M_h/L_bol of 21-38, 14-26, and 9-17 can be derived respectively for three different metallicity scenarios (Z = 0, 1/50, and 1 Z_sun). These results suggest that Ly-alpha emitters are either starburst galaxies, with M_h/L_bol values around 0.1-1 and smaller Ly-alpha survival allowing for alpha_escepsilon^(1/gamma) to be approximately 0.01-0.05, or normal populations, if it is assumed that a large percentage of Ly-alpha photons survived (alpha_escepsilon^(1/gamma) is 0.5-1). Our investigation reveals no strong evidence of reionization and/or evolution of Ly-alpha emitter properties found in recent Ly-alpha surveys, and the absence of sources at z=8.8 provides no significant constraints either. Nevertheless, the data is sufficient to imply that these sources could still be responsible for the observed excess NIRB.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1801}
{"prompt": "Rephrase the abstract of an article with title 'K-band Imaging of strong CaII-absorber host galaxies at z~1'.   We present K-band imaging of fields around 30 strong CaII absorption line systems, at 0.7<z<1.1, three of which are confirmed Damped Lyman-alpha systems. A significant excess of galaxies is found within 6\"0 (~50kpc) from the absorber line-of-sight. The excess galaxies are preferentially luminous compared to the population of field galaxies. A model in which field galaxies possess a luminosity-dependent cross-section for CaII absorption of the form (L/L*)^0.7 reproduces the observations well. The luminosity-dependent cross-section for the CaII absorbers appears to be significantly stronger than the established (L/L*)^0.4 dependence for MgII absorbers. The associated galaxies lie at large physical distances from the CaII-absorbing gas; we find a mean impact parameter of 24kpc (H0=70km\\s\\Mpc). Combined with the observed number density of CaII absorbers the large physical separations result in an inferred filling factor of only ~10 per cent. The physical origin of the strong CaII absorption remains unclear, possible explanations vary from very extended disks of the luminous galaxies to associated dwarf galaxy neighbours, remnants of outflows from the luminous galaxies, or tidal debris from cannibalism of smaller galaxies.  ", "human_text": "  We present K-band imaging of fields around 30 strong CaII absorption line systems, at 0.7<z<1.1, three of which are confirmed Damped Lyman-alpha systems. A significant excess of galaxies is found within 6\"0 (~50kpc) from the absorber line-of-sight. The excess galaxies are preferentially luminous compared to the population of field galaxies. A model in which field galaxies possess a luminosity-dependent cross-section for CaII absorption of the form (L/L*)^0.7 reproduces the observations well. The luminosity-dependent cross-section for the CaII absorbers appears to be significantly stronger than the established (L/L*)^0.4 dependence for MgII absorbers. The associated galaxies lie at large physical distances from the CaII-absorbing gas; we find a mean impact parameter of 24kpc (H0=70km\\s\\Mpc). Combined with the observed number density of CaII absorbers the large physical separations result in an inferred filling factor of only ~10 per cent. The physical origin of the strong CaII absorption remains unclear, possible explanations vary from very extended disks of the luminous galaxies to associated dwarf galaxy neighbours, remnants of outflows from the luminous galaxies, or tidal debris from cannibalism of smaller galaxies. ", "machine_text": "We report K-band imaging of observed strong CaII absorption line systems in galaxies at redshifts of 0.7 to 1.1; three of these systems have been confirmed as Damped Lyman-alpha systems. Analysis of these fields reveals an abundance of luminous galaxies located within 50kpc from the line of sight of the absorbers, which contrasts to their prevalence in comparison with field galaxies. It appears that these galaxies have a luminosity-dependent cross-section that is stronger than the one established for MgII absorbers. The impact parameter of the galaxies associated with the absorbers is 24kpc, resulting in a filling factor of only 10%. It is difficult to discern the physical origin of this CaII absorption, but possibilities range from extended disks of luminous galaxies to outflows or tidal debris from smaller galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1355}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical non-axisymmetric instabilities in rotating relativistic stars'.   We present new results on dynamical instabilities in rapidly rotating neutron-stars. In particular, using numerical simulations in full General Relativity, we analyse the effects that the stellar compactness has on the threshold for the onset of the dynamical bar-mode instability, as well as on the appearance of other dynamical instabilities. By using an extrapolation technique developed and tested in our previous study [1], we explicitly determine the threshold for a wide range of compactnesses using four sequences of models of constant baryonic mass comprising a total of 59 stellar models. Our calculation of the threshold is in good agreement with the Newtonian prediction and improves the previous post-Newtonian estimates. In addition, we find that for stars with sufficiently large mass and compactness, the m=3 deformation is the fastest growing one. For all of the models considered, the non-axisymmetric instability is suppressed on a dynamical timescale with an m=1 deformation dominating the final stages of the instability. These results, together with those presented in [1], suggest that an m=1 deformation represents a general and late-time feature of non-axisymmetric dynamical instabilities both in full General Relativity and in Newtonian gravity.  ", "human_text": "  We present new results on dynamical instabilities in rapidly rotating neutron-stars. In particular, using numerical simulations in full General Relativity, we analyse the effects that the stellar compactness has on the threshold for the onset of the dynamical bar-mode instability, as well as on the appearance of other dynamical instabilities. By using an extrapolation technique developed and tested in our previous study [1], we explicitly determine the threshold for a wide range of compactnesses using four sequences of models of constant baryonic mass comprising a total of 59 stellar models. Our calculation of the threshold is in good agreement with the Newtonian prediction and improves the previous post-Newtonian estimates. In addition, we find that for stars with sufficiently large mass and compactness, the m=3 deformation is the fastest growing one. For all of the models considered, the non-axisymmetric instability is suppressed on a dynamical timescale with an m=1 deformation dominating the final stages of the instability. These results, together with those presented in [1], suggest that an m=1 deformation represents a general and late-time feature of non-axisymmetric dynamical instabilities both in full General Relativity and in Newtonian gravity. ", "machine_text": "This study presents new findings on the effect of stellar compactness on the non-axisymmetric instabilities of rapidly rotating neutron stars, utilizing numerical simulations in full General Relativity. By extrapolating the results of a previous study, we determine a threshold for the onset of the bar-mode instability for 59 different star models. Our conclusions are in line with the Newtonian expectation and improve previous post-Newtonian estimates. Additionally, we discover that for very massive and compact stars, the fastest-growing deformation is the m=3 mode. We illustrate that further to the Newtonian speculation, an m=1 deformation is bound to be a widespread late-time feature of non-axisymmetric instabilities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1826}
{"prompt": "Rephrase the abstract of an article with title 'A noncommutative Bohnenblust-Spitzer identity for Rota-Baxter algebras   solves Bogoliubov's recursion'.   The Bogoliubov recursion is a particular procedure appearing in the process of renormalization in perturbative quantum field theory. It provides convergent expressions for otherwise divergent integrals. We develop here a theory of functional identities for noncommutative Rota-Baxter algebras which is shown to encode, among others, this process in the context of Connes-Kreimer's Hopf algebra of renormalization. Our results generalize the seminal Cartier-Rota theory of classical Spitzer-type identities for commutative Rota-Baxter algebras. In the classical, commutative, case, these identities can be understood as deriving from the theory of symmetric functions. Here, we show that an analogous property holds for noncommutative Rota-Baxter algebras. That is, we show that functional identities in the noncommutative setting can be derived from the theory of noncommutative symmetric functions. Lie idempotents, and particularly the Dynkin idempotent play a crucial role in the process. Their action on the pro-unipotent groups such as those of perturbative renormalization is described in detail along the way.  ", "human_text": "  The Bogoliubov recursion is a particular procedure appearing in the process of renormalization in perturbative quantum field theory. It provides convergent expressions for otherwise divergent integrals. We develop here a theory of functional identities for noncommutative Rota-Baxter algebras which is shown to encode, among others, this process in the context of Connes-Kreimer's Hopf algebra of renormalization. Our results generalize the seminal Cartier-Rota theory of classical Spitzer-type identities for commutative Rota-Baxter algebras. In the classical, commutative, case, these identities can be understood as deriving from the theory of symmetric functions. Here, we show that an analogous property holds for noncommutative Rota-Baxter algebras. That is, we show that functional identities in the noncommutative setting can be derived from the theory of noncommutative symmetric functions. Lie idempotents, and particularly the Dynkin idempotent play a crucial role in the process. Their action on the pro-unipotent groups such as those of perturbative renormalization is described in detail along the way. ", "machine_text": "We explore the implications of a noncommutative version of the classic Bohnenblust-Spitzer identity for Rota-Baxter algebras, which encompasses the process of renormalization as found in Connes-Kreimer's Hopf algebra of renormalization. We show that, in a manner analogous to how the commutative setting relies on the theory of symmetric functions, the noncommutative setting has functional identities which derive from the theory of noncommutative symmetric functions. The key role played by the Lie Idempotents, with special attention to the Dynkin Idempotent and the perturbative renormalization pro-unipotent groups, are discussed at length.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1265}
{"prompt": "Rephrase the abstract of an article with title 'Solar-like oscillations in the metal-poor subgiant nu Indi: II. Acoustic   spectrum and mode lifetime'.   Convection in stars excites resonant acoustic waves which depend on the sound speed inside the star, which in turn depends on properties of the stellar interior. Therefore, asteroseismology is an unrivaled method to probe the internal structure of a star. We made a seismic study of the metal-poor subgiant star nu Indi with the goal of constraining its interior structure. Our study is based on a time series of 1201 radial velocity measurements spread over 14 nights obtained from two sites, Siding Spring Observatory in Australia and ESO La Silla Observatory in Chile. The power spectrum of the high precision velocity time series clearly presents several identifiable peaks between 200 and 500 uHz showing regularity with a large and small spacing of 25.14 +- 0.09 uHz and 2.96 +- 0.22 uHz at 330 uHz. Thirteen individual modes have been identified with amplitudes in the range 53 to 173 cm/s. The mode damping time is estimated to be about 16 days (1-sigma range between 9 and 50 days), substantially longer than in other stars like the Sun, the alpha Cen system or the giant xi Hya.  ", "human_text": "  Convection in stars excites resonant acoustic waves which depend on the sound speed inside the star, which in turn depends on properties of the stellar interior. Therefore, asteroseismology is an unrivaled method to probe the internal structure of a star. We made a seismic study of the metal-poor subgiant star nu Indi with the goal of constraining its interior structure. Our study is based on a time series of 1201 radial velocity measurements spread over 14 nights obtained from two sites, Siding Spring Observatory in Australia and ESO La Silla Observatory in Chile. The power spectrum of the high precision velocity time series clearly presents several identifiable peaks between 200 and 500 uHz showing regularity with a large and small spacing of 25.14 +- 0.09 uHz and 2.96 +- 0.22 uHz at 330 uHz. Thirteen individual modes have been identified with amplitudes in the range 53 to 173 cm/s. The mode damping time is estimated to be about 16 days (1-sigma range between 9 and 50 days), substantially longer than in other stars like the Sun, the alpha Cen system or the giant xi Hya. ", "machine_text": " Asteroseismology is a powerful tool for understanding the internal structures of stars by measuring the oscillations caused by convection. This study examined nu Indi, a metal-poor subgiant star, to better familiarize ourselves with its interior. Using a time series of 1201 radial velocity measurements, taken over 14 nights at Siding Spring Observatory in Australia and ESO La Silla Observatory in Chile, we identified 13 individual oscillations with amplitudes ranging from 53 to 173 cm/s. The regularity of the oscillations was quickly evident, with a large and small spacing of 25.14 +- 0.09 uHz and 2.96 +- 0.22 uHz at 330 uHz. Additionally, the mode damping time was calculated to be about 16 days, with a 1-sigma range of between 9 and 50 days, significantly higher than that of other stars such as the Sun or alpha Cen.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0795}
{"prompt": "Rephrase the abstract of an article with title 'Graph state generation with noisy mirror-inverting spin chains'.   We investigate the influence of noise on a graph state generation scheme which exploits a mirror inverting spin chain. Within this scheme the spin chain is used repeatedly as an entanglement bus (EB) to create multi-partite entanglement. The noise model we consider comprises of each spin of this EB being exposed to independent local noise which degrades the capabilities of the EB. Here we concentrate on quantifying its performance as a single-qubit channel and as a mediator of a two-qubit entangling gate, since these are basic operations necessary for graph state generation using the EB. In particular, for the single-qubit case we numerically calculate the average channel fidelity and whether the channel becomes entanglement breaking, i.e., expunges any entanglement the transferred qubit may have with other external qubits. We find that neither local decay nor dephasing noise cause entanglement breaking. This is in contrast to local thermal and depolarizing noise where we determine a critical length and critical noise coupling, respectively, at which entanglement breaking occurs. The critical noise coupling for local depolarizing noise is found to exhibit a power-law dependence on the chain length. For two qubits we similarly compute the average gate fidelity and whether the ability for this gate to create entanglement is maintained. The concatenation of these noisy gates for the construction of a five qubit linear cluster state and a Greenberger-Horne-Zeilinger state indicates that the level of noise that can be tolerated for graph state generation is tightly constrained.  ", "human_text": "  We investigate the influence of noise on a graph state generation scheme which exploits a mirror inverting spin chain. Within this scheme the spin chain is used repeatedly as an entanglement bus (EB) to create multi-partite entanglement. The noise model we consider comprises of each spin of this EB being exposed to independent local noise which degrades the capabilities of the EB. Here we concentrate on quantifying its performance as a single-qubit channel and as a mediator of a two-qubit entangling gate, since these are basic operations necessary for graph state generation using the EB. In particular, for the single-qubit case we numerically calculate the average channel fidelity and whether the channel becomes entanglement breaking, i.e., expunges any entanglement the transferred qubit may have with other external qubits. We find that neither local decay nor dephasing noise cause entanglement breaking. This is in contrast to local thermal and depolarizing noise where we determine a critical length and critical noise coupling, respectively, at which entanglement breaking occurs. The critical noise coupling for local depolarizing noise is found to exhibit a power-law dependence on the chain length. For two qubits we similarly compute the average gate fidelity and whether the ability for this gate to create entanglement is maintained. The concatenation of these noisy gates for the construction of a five qubit linear cluster state and a Greenberger-Horne-Zeilinger state indicates that the level of noise that can be tolerated for graph state generation is tightly constrained. ", "machine_text": " In this work, we explore the consequences of introducing noise onto a proposed graph state generation scheme based on a mirror inverting spin chain. To measure the performance of this chain as a quantum processor, we calculate the average channel fidelity for single qubits, and the average gate fidelity for two-qubit entangling operations. We also evaluate whether these operations maintain the entangling capabilities and become entanglement breaking when exposed to local decaying, dephasing, thermal, and depolarizing noise. Surprisingly, we find that local decay and dephasing noise do not induce entanglement breaking. However, thermal and depolarizing noise are found to lead to a critical length and critical noise coupling respectively, beyond which entanglement breaking occurs. The critical noise coupling for local depolarizing noise is also observed to exhibit a power-law dependence as a function of chain length. In addition, the average gate fidelity of a constructed five qubit linear cluster state and a Greenberger-Horne-Zeilinger state suggest that the noise tolerated for graph state generation is limiting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3584}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of interstellar dust and stardust in the solar neighbourhood'.   The abundance evolution of interstellar dust species originating from stellar sources and from condensation in molecular clouds in the local interstellar medium of the Milky Way is studied and the input of dust material to the Solar System is determined. A one-zone chemical evolution model of the Milky Way for the elemental composition of the disk combined with an evolution model for its interstellar dust component similar to that of Dwek (1998) is developed. The dust model considers dust-mass return from AGB stars as calculated from synthetic AGB models combined with models for dust condensation in stellar outflows. Supernova dust formation is included in a simple parameterized form which is gauged by observed abundances of presolar dust grains with supernova origin. For dust growth in the ISM a simple method is developed for coupling this with disk and dust evolution models. The time evolution of the abundance of the following dust species is followed in the model: silicate, carbon, silicon carbide, and iron dust from AGB stars and from SNe as well as silicate, carbon, and iron dust grown in molecular clouds. It is shown that the interstellar dust population is dominated by dust accreted in molecular clouds; most of the dust material entering the Solar System at its formation does not show isotopic abundance anomalies of the refractory elements, i.e., inconspicuous isotopic abundances do not point to a Solar System origin of dust grains. The observed abundance ratios of presolar dust grains formed in SN ejecta and in AGB star outflows requires that for the ejecta from SNe the fraction of refractory elements condensed into dust is 0.15 for carbon dust and is quite small ($\\sim10^{-4}$) for other dust species.  ", "human_text": "  The abundance evolution of interstellar dust species originating from stellar sources and from condensation in molecular clouds in the local interstellar medium of the Milky Way is studied and the input of dust material to the Solar System is determined. A one-zone chemical evolution model of the Milky Way for the elemental composition of the disk combined with an evolution model for its interstellar dust component similar to that of Dwek (1998) is developed. The dust model considers dust-mass return from AGB stars as calculated from synthetic AGB models combined with models for dust condensation in stellar outflows. Supernova dust formation is included in a simple parameterized form which is gauged by observed abundances of presolar dust grains with supernova origin. For dust growth in the ISM a simple method is developed for coupling this with disk and dust evolution models. The time evolution of the abundance of the following dust species is followed in the model: silicate, carbon, silicon carbide, and iron dust from AGB stars and from SNe as well as silicate, carbon, and iron dust grown in molecular clouds. It is shown that the interstellar dust population is dominated by dust accreted in molecular clouds; most of the dust material entering the Solar System at its formation does not show isotopic abundance anomalies of the refractory elements, i.e., inconspicuous isotopic abundances do not point to a Solar System origin of dust grains. The observed abundance ratios of presolar dust grains formed in SN ejecta and in AGB star outflows requires that for the ejecta from SNe the fraction of refractory elements condensed into dust is 0.15 for carbon dust and is quite small ($\\sim10^{-4}$) for other dust species. ", "machine_text": " This paper develops a model of chemical evolution in the Milky Way disk that combines the elemental composition of its interstellar medium with a one-zone dust component similar to that proposed by Dwek (1998). It examines the abundance of various dust species including silicate, carbon, silicate carbide, and iron dust from stars including asymptotic giant branch stars and supernova, as well as dust grown in molecular clouds. The results demonstrate that the dust population of the interstellar medium is primarily composed of this material accreted in molecular clouds. It is found that the dust which form the Solar System yields insignificant isotopic abundance anomalies of the refractory elements, indicating that most of the dust is not a product of the Solar System's own formation. The observed abundance ratios of presolar dust grains suggest that the fraction of refractory elements condensed into dust is about 0.15 for carbon dust and very small for most other dust species.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1155}
{"prompt": "Rephrase the abstract of an article with title 'The tensor part of the Skyrme energy density functional. I. Spherical   nuclei'.   We perform a systematic study of the impact of the J^2 tensor term in the Skyrme energy functional on properties of spherical nuclei. In the Skyrme energy functional, the tensor terms originate both from zero-range central and tensor forces. We build a set of 36 parameterizations, which covers a wide range of the parameter space of the isoscalar and isovector tensor term coupling constants, with a fit protocol very similar to that of the successful SLy parameterizations. We analyze the impact of the tensor terms on a large variety of observables in spherical mean-field calculations, such as the spin-orbit splittings and single-particle spectra of doubly-magic nuclei, the evolution of spin-orbit splittings along chains of semi-magic nuclei, mass residuals of spherical nuclei, and known anomalies of charge radii. Our main conclusion is that the currently used central and spin-orbit parts of the Skyrme energy density functional are not flexible enough to allow for the presence of large tensor terms.  ", "human_text": "  We perform a systematic study of the impact of the J^2 tensor term in the Skyrme energy functional on properties of spherical nuclei. In the Skyrme energy functional, the tensor terms originate both from zero-range central and tensor forces. We build a set of 36 parameterizations, which covers a wide range of the parameter space of the isoscalar and isovector tensor term coupling constants, with a fit protocol very similar to that of the successful SLy parameterizations. We analyze the impact of the tensor terms on a large variety of observables in spherical mean-field calculations, such as the spin-orbit splittings and single-particle spectra of doubly-magic nuclei, the evolution of spin-orbit splittings along chains of semi-magic nuclei, mass residuals of spherical nuclei, and known anomalies of charge radii. Our main conclusion is that the currently used central and spin-orbit parts of the Skyrme energy density functional are not flexible enough to allow for the presence of large tensor terms. ", "machine_text": " This paper conducts an evaluation of how the J^2 tensor component affects the effects of the Skyrme energy density functional on properties of spherical nuclei. We develop a set of 36 parameterizations, using a fitting process near identical to the successful SLy parameterizations, by considering the effects of isoscalar and isovector tensor term coupling constants. We measure the influence of the tensor terms on shape of spin-orbit splittings and single-particle spectrums of doubly-magic nuclei, shifts in spin-orbit splittings in sequences of semi-magic nuclei, mass anomalies of spherical nuclei, and noticeable inconsistencies in charge radii. Our ultimate realization is that the central and spin-orbit components of the Skyrme energy density functional are not flexible enough to permit for larger tensor terms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0731}
{"prompt": "Rephrase the abstract of an article with title 'Statistical Mechanics of Nonlinear On-line Learning for Ensemble   Teachers'.   We analyze the generalization performance of a student in a model composed of nonlinear perceptrons: a true teacher, ensemble teachers, and the student. We calculate the generalization error of the student analytically or numerically using statistical mechanics in the framework of on-line learning. We treat two well-known learning rules: Hebbian learning and perceptron learning. As a result, it is proven that the nonlinear model shows qualitatively different behaviors from the linear model. Moreover, it is clarified that Hebbian learning and perceptron learning show qualitatively different behaviors from each other. In Hebbian learning, we can analytically obtain the solutions. In this case, the generalization error monotonically decreases. The steady value of the generalization error is independent of the learning rate. The larger the number of teachers is and the more variety the ensemble teachers have, the smaller the generalization error is. In perceptron learning, we have to numerically obtain the solutions. In this case, the dynamical behaviors of the generalization error are non-monotonic. The smaller the learning rate is, the larger the number of teachers is; and the more variety the ensemble teachers have, the smaller the minimum value of the generalization error is.  ", "human_text": "  We analyze the generalization performance of a student in a model composed of nonlinear perceptrons: a true teacher, ensemble teachers, and the student. We calculate the generalization error of the student analytically or numerically using statistical mechanics in the framework of on-line learning. We treat two well-known learning rules: Hebbian learning and perceptron learning. As a result, it is proven that the nonlinear model shows qualitatively different behaviors from the linear model. Moreover, it is clarified that Hebbian learning and perceptron learning show qualitatively different behaviors from each other. In Hebbian learning, we can analytically obtain the solutions. In this case, the generalization error monotonically decreases. The steady value of the generalization error is independent of the learning rate. The larger the number of teachers is and the more variety the ensemble teachers have, the smaller the generalization error is. In perceptron learning, we have to numerically obtain the solutions. In this case, the dynamical behaviors of the generalization error are non-monotonic. The smaller the learning rate is, the larger the number of teachers is; and the more variety the ensemble teachers have, the smaller the minimum value of the generalization error is. ", "machine_text": " In this article, we examine the generalization capability of a learner composed of non-linear perceptrons, including a 'true teacher', ensemble teachers, and student. Utilizing the framework of on-line learning, statistical mechanics are used to numerically and analytically identify the student's generalization error. We investigate two major learning rules, Hebbian learning and Perceptron learning, and distinguish them as having fundamentally different behavior from the study of linear models. Applying Hebbian learning, solutions can be obtained analytically, with the generalization error steadily diminishing until it reaches a predetermined steady value that does not vary with changes to the learning rate. The accuracy of the model is found to be inversely proportional to the number of teachers, but increases with the variety of the ensemble teachers. For Perceptron learning, numerical solutions must be obtained, and the results of the model display dynamic non-monotonic behavior. Here, modifying the learning rate will have an inverse effect on the minimum value of the generalization error, but is determined instead by the number of teachers, and the variety of the ensemble teachers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2318}
{"prompt": "Rephrase the abstract of an article with title 'On the Connection between Mass Loss and Evolution of C-rich AGB stars'.   The mass loss properties of carbon AGB stars are not very well constrained at present. A variety of empirical or theoretical formulae with different parameterisations are available in the literature and the agreement between them is anything but good. These simple mass loss prescriptions are nontheless used in many models of stellar evolution without much consideration of their applicability in various cases. We present here an on-going project aiming at a better description of the mass loss, that could be used to improve stellar evolution models -- especially the evolution during the TP-AGB phase. As a first step, we have considered the mass loss evolution during a He-shell flash. Using stellar parameters sampled from a stellar evolutionary track, we have computed the time evolution of the atmospheric layers and wind acceleration region during a flash event with detailed frequency-dependent radiation-hydrodynamical models including dust formation. Based on these results, we have also simulated the subsequent long-term dynamical evolution of the circumstellar envelope (CSE), including the formation of a detached shell. We find that existing simple mass loss prescriptions imply different mass loss evolutions compared with our model. The second step of the project deals with the dependence of mass loss on the basic stellar parameters. At the moment we are computing a large grid of wind models for C-rich AGB stars. Preliminary results show that simple parameterisations are difficult to obtain in certain regions of the parameter space considered, due to strong non-linearities in the wind mechanism.  ", "human_text": "  The mass loss properties of carbon AGB stars are not very well constrained at present. A variety of empirical or theoretical formulae with different parameterisations are available in the literature and the agreement between them is anything but good. These simple mass loss prescriptions are nontheless used in many models of stellar evolution without much consideration of their applicability in various cases. We present here an on-going project aiming at a better description of the mass loss, that could be used to improve stellar evolution models -- especially the evolution during the TP-AGB phase. As a first step, we have considered the mass loss evolution during a He-shell flash. Using stellar parameters sampled from a stellar evolutionary track, we have computed the time evolution of the atmospheric layers and wind acceleration region during a flash event with detailed frequency-dependent radiation-hydrodynamical models including dust formation. Based on these results, we have also simulated the subsequent long-term dynamical evolution of the circumstellar envelope (CSE), including the formation of a detached shell. We find that existing simple mass loss prescriptions imply different mass loss evolutions compared with our model. The second step of the project deals with the dependence of mass loss on the basic stellar parameters. At the moment we are computing a large grid of wind models for C-rich AGB stars. Preliminary results show that simple parameterisations are difficult to obtain in certain regions of the parameter space considered, due to strong non-linearities in the wind mechanism. ", "machine_text": " In this paper, we explore how the mass loss from C-rich AGB stars depends on their evolutionary stage. We consider the mass loss evolution during He-shell flashes and the subsequent long-term dynamical evolution of the circumstellar envelope. Our analysis uses detailed frequency-dependent radiation-hydrodynamical models for the flash event and circumstellar envelope, which include dust formation. We discover that existing simple formulae for mass loss do not match the findings of our models. Next, we are calculating a grid of wind models to observe how mass loss depends on the stellar parameters. Early results show that it is not possible to make simple parameterisations due to the irregularity of the wind mechanism in certain regions of parameter space. Ultimately, our goal is to improve stellar evolution models, in particular the TP-AGB phase, with an improved description of mass loss.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2315}
{"prompt": "Rephrase the abstract of an article with title 'Shrinking binary and planetary orbits by Kozai cycles with tidal   friction'.   At least two arguments suggest that the orbits of a large fraction of binary stars and extrasolar planets shrank by 1-2 orders of magnitude after formation: (i) the physical radius of a star shrinks by a large factor from birth to the main sequence, yet many main-sequence stars have companions orbiting only a few stellar radii away, and (ii) in current theories of planet formation, the region within ~0.1 AU of a protostar is too hot and rarefied for a Jupiter-mass planet to form, yet many \"hot Jupiters\" are observed at such distances. We investigate orbital shrinkage by the combined effects of secular perturbations from a distant companion star (Kozai oscillations) and tidal friction. We integrate the relevant equations of motion to predict the distribution of orbital elements produced by this process. Binary stars with orbital periods of 0.1 to 10 days, with a median of ~2 d, are produced from binaries with much longer periods (10 d to 10^5 d), consistent with observations indicating that most or all short-period binaries have distant companions (tertiaries). We also make two new testable predictions: (1) For periods between 3 and 10 d, the distribution of the mutual inclination between the inner binary and the tertiary orbit should peak strongly near 40 deg and 140 deg. (2) Extrasolar planets whose host stars have a distant binary companion may also undergo this process, in which case the orbit of the resulting hot Jupiter will typically be misaligned with the equator of its host star.  ", "human_text": "  At least two arguments suggest that the orbits of a large fraction of binary stars and extrasolar planets shrank by 1-2 orders of magnitude after formation: (i) the physical radius of a star shrinks by a large factor from birth to the main sequence, yet many main-sequence stars have companions orbiting only a few stellar radii away, and (ii) in current theories of planet formation, the region within ~0.1 AU of a protostar is too hot and rarefied for a Jupiter-mass planet to form, yet many \"hot Jupiters\" are observed at such distances. We investigate orbital shrinkage by the combined effects of secular perturbations from a distant companion star (Kozai oscillations) and tidal friction. We integrate the relevant equations of motion to predict the distribution of orbital elements produced by this process. Binary stars with orbital periods of 0.1 to 10 days, with a median of ~2 d, are produced from binaries with much longer periods (10 d to 10^5 d), consistent with observations indicating that most or all short-period binaries have distant companions (tertiaries). We also make two new testable predictions: (1) For periods between 3 and 10 d, the distribution of the mutual inclination between the inner binary and the tertiary orbit should peak strongly near 40 deg and 140 deg. (2) Extrasolar planets whose host stars have a distant binary companion may also undergo this process, in which case the orbit of the resulting hot Jupiter will typically be misaligned with the equator of its host star. ", "machine_text": "This article examines the possibility that binary stars and extrasolar planets experience shrinking orbits by 1-2 orders of magnitude after formation. It suggests that this could be caused by the combined actions of Kozai cycles and tidal friction. To test this hypothesis, the equations of motion were integrated in order to determine the range of orbital elements. It was found that systems with an initial period of 10 days to 10^5 days could produce binaries with periods of 0.1 to 10 days; the majority of these being 2 days. Additionally, two testable predictions were made: (1) For periods between 3 and 10 days, there should be a peak in the distribution of the mutual inclination of the inner binary and tertiary orbits near 40 and 140 degrees. (2) In cases where the host star has a distant binary companion, the resulting hot Jupiter is likely to have an orbit misaligned with the equator of its host star.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4285}
{"prompt": "Rephrase the abstract of an article with title 'Long-Term Evolution of Massive Black Hole Binaries. III. Binary   Evolution in Collisional Nuclei'.   [Abridged] In galactic nuclei with sufficiently short relaxation times, binary supermassive black holes can evolve beyond their stalling radii via continued interaction with stars. We study this \"collisional\" evolutionary regime using both fully self-consistent N-body integrations and approximate Fokker-Planck models. The N-body integrations employ particle numbers up to 0.26M and a direct-summation potential solver; close interactions involving the binary are treated using a new implementation of the Mikkola-Aarseth chain regularization algorithm. Even at these large values of N, two-body scattering occurs at high enough rates in the simulations that they can not be simply scaled to the large-N regime of real galaxies. The Fokker-Planck model is used to bridge this gap; it includes, for the first time, binary-induced changes in the stellar density and potential. The Fokker-Planck model is shown to accurately reproduce the results of the N-body integrations, and is then extended to the much larger N regime of real galaxies. Analytic expressions are derived that accurately reproduce the time dependence of the binary semi-major axis as predicted by the Fokker-Planck model. Gravitational wave coalescence is shown to occur in <10 Gyr in nuclei with velocity dispersions below about 80 km/s. Formation of a core results from a competition between ejection of stars by the binary and re-supply of depleted orbits via two-body scattering. Mass deficits as large as ~4 times the binary mass are produced before coalescence. After the two black holes coalesce, a Bahcall-Wolf cusp appears around the single hole in one relaxation time, resulting in a nuclear density profile consisting of a flat core with an inner, compact cluster, similar to what is observed at the centers of low-luminosity spheroids.  ", "human_text": "  [Abridged] In galactic nuclei with sufficiently short relaxation times, binary supermassive black holes can evolve beyond their stalling radii via continued interaction with stars. We study this \"collisional\" evolutionary regime using both fully self-consistent N-body integrations and approximate Fokker-Planck models. The N-body integrations employ particle numbers up to 0.26M and a direct-summation potential solver; close interactions involving the binary are treated using a new implementation of the Mikkola-Aarseth chain regularization algorithm. Even at these large values of N, two-body scattering occurs at high enough rates in the simulations that they can not be simply scaled to the large-N regime of real galaxies. The Fokker-Planck model is used to bridge this gap; it includes, for the first time, binary-induced changes in the stellar density and potential. The Fokker-Planck model is shown to accurately reproduce the results of the N-body integrations, and is then extended to the much larger N regime of real galaxies. Analytic expressions are derived that accurately reproduce the time dependence of the binary semi-major axis as predicted by the Fokker-Planck model. Gravitational wave coalescence is shown to occur in <10 Gyr in nuclei with velocity dispersions below about 80 km/s. Formation of a core results from a competition between ejection of stars by the binary and re-supply of depleted orbits via two-body scattering. Mass deficits as large as ~4 times the binary mass are produced before coalescence. After the two black holes coalesce, a Bahcall-Wolf cusp appears around the single hole in one relaxation time, resulting in a nuclear density profile consisting of a flat core with an inner, compact cluster, similar to what is observed at the centers of low-luminosity spheroids. ", "machine_text": " This paper examines the long-term evolution of supermassive black hole binaries in galactic nuclei with short relaxation times, where the binary is able to progress beyond its stalling point via continued interactions with stars. The study was performed using robust N-body integrations and a novel Fokker-Planck model, which considers binary-induced changes in stellar density. Results indicate that gravitational wave coalescence is likely to occur within 10 Gyr in nuclei with velocity dispersions below 80 km/s, resulting in a density profile of a flat core containing an inner, compact cluster. Moreover, mass deficits up to 4x the binary mass can form prior to coalescence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2745}
{"prompt": "Rephrase the abstract of an article with title 'Variation of fundamental constants: theory and observations'.   Review of recent works devoted to the variation of the fundamental constants is presented including atomic clocks, quasar absorption spectra, and Oklo natural nuclear reactor data. Assuming linear variation with time we can compare different results. From the quasar absorption spectra:   $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$. A combination of this result and the atomic clock results gives the best limt on variation of $\\alpha$: $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$. The Oklo natural reactor gives the best limit on the variation of $m_s/\\Lambda_{QCD}$ where $m_s$ is the strange quark mass.   Huge enhancement of the relative variation effects happens in transitions between close atomic, molecular and nuclear energy levels. We suggest several new cases where the levels are very narrow. Large enhancement of the variation effects is also possible in cold atomic and molecular collisions near Feshbach resonance. Massive bodies (stars or galaxies) can also affect physical constants. They have large scalar charge $S$ proportional to number of particles which produces a Coulomb-like scalar field $U=S/r$. This leads to a variation of the fundamental constants proportional to the gravitational potential, e.g. $\\delta \\alpha/ \\alpha = k_\\alpha \\delta (GM/ r c^2)$. We compare different manifestations of this effect.The strongest limit   $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$.  ", "human_text": "  Review of recent works devoted to the variation of the fundamental constants is presented including atomic clocks, quasar absorption spectra, and Oklo natural nuclear reactor data. Assuming linear variation with time we can compare different results. From the quasar absorption spectra:   $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$. A combination of this result and the atomic clock results gives the best limt on variation of $\\alpha$: $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$. The Oklo natural reactor gives the best limit on the variation of $m_s/\\Lambda_{QCD}$ where $m_s$ is the strange quark mass.   Huge enhancement of the relative variation effects happens in transitions between close atomic, molecular and nuclear energy levels. We suggest several new cases where the levels are very narrow. Large enhancement of the variation effects is also possible in cold atomic and molecular collisions near Feshbach resonance. Massive bodies (stars or galaxies) can also affect physical constants. They have large scalar charge $S$ proportional to number of particles which produces a Coulomb-like scalar field $U=S/r$. This leads to a variation of the fundamental constants proportional to the gravitational potential, e.g. $\\delta \\alpha/ \\alpha = k_\\alpha \\delta (GM/ r c^2)$. We compare different manifestations of this effect.The strongest limit   $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$. ", "machine_text": "This article offers a review of recent research into the potential fluctuations of fundamental constants such as atomic clocks, quasar absorption spectra, and Oklo natural nuclear reactor data. Assessing linear variability with time, comparative studies from quasar absorption data suggest $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$ and the best limit of $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$ came from both quasar absorption data and atomic clocks. The Oklo natural reactor results in the strongest limit on the variantion of $m_s/\\Lambda_{QCD}$ with the strange quark mass. It is also possible for large enhancement of relative variation effects to occur in atomic, molecular and nuclear transitions between close energy levels, in cold atomic and molecular collisions near Feshbach resonance, and in massive bodies such as stars and galaxies whose Coulomb-like scalar field produces a proportionate variation of constants. Following the comparison of these various phenomenon, the strongest limit of $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$ could be inferred.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3704}
{"prompt": "Rephrase the abstract of an article with title 'Comparison of Dissipative Particle Dynamics and Langevin thermostats for   out-of-equilibrium simulations of polymeric systems'.   In this work we compare and characterize the behavior of Langevin and Dissipative Particle Dynamics (DPD) thermostats in a broad range of non-equilibrium simulations of polymeric systems. Polymer brushes in relative sliding motion, polymeric liquids in Poiseuille and Couette flows, and brush-melt interfaces are used as model systems to analyze the efficiency and limitations of different Langevin and DPD thermostat implementations. Widely used coarse-grained bead-spring models under good and poor solvent conditions are employed to assess the effects of the thermostats. We considered equilibrium, transient, and steady state examples for testing the ability of the thermostats to maintain constant temperature and to reproduce the underlying physical phenomena in non-equilibrium situations. The common practice of switching-off the Langevin thermostat in the flow direction is also critically revisited. The efficiency of different weight functions for the DPD thermostat is quantitatively analyzed as a function of the solvent quality and the non-equilibrium situation.  ", "human_text": "  In this work we compare and characterize the behavior of Langevin and Dissipative Particle Dynamics (DPD) thermostats in a broad range of non-equilibrium simulations of polymeric systems. Polymer brushes in relative sliding motion, polymeric liquids in Poiseuille and Couette flows, and brush-melt interfaces are used as model systems to analyze the efficiency and limitations of different Langevin and DPD thermostat implementations. Widely used coarse-grained bead-spring models under good and poor solvent conditions are employed to assess the effects of the thermostats. We considered equilibrium, transient, and steady state examples for testing the ability of the thermostats to maintain constant temperature and to reproduce the underlying physical phenomena in non-equilibrium situations. The common practice of switching-off the Langevin thermostat in the flow direction is also critically revisited. The efficiency of different weight functions for the DPD thermostat is quantitatively analyzed as a function of the solvent quality and the non-equilibrium situation. ", "machine_text": "In this paper, we evaluate and compare the performance of Langevin and Dissipative Particle Dynamics (DPD) thermostats in a range of non-equilibrium simulations involving polymeric systems. We consider simulations to investigate polymer brushes in sliding motion, polymer liquids exposed to Poiseuille and Couette flows, and brush-melt interfaces with bead-spring models that are exposed to varying degrees of solvent quality. We will look at equilibrium, transient, and steady-state situations to assess the capacity of the two thermostats to maintain temperature conditions and to accurately reproduce physical phenomena in out-of-equilibrium conditions. Additionally, we answer the question of whether it is necessary or beneficial to discontinue the Langevin thermostat when running flow simulations. Finally, we provide a quantitative analysis of how various weight functions influence the efficiency of the DPD thermostat in terms of solvent quality and non-equilibrium states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2624}
{"prompt": "Rephrase the abstract of an article with title 'Extremal black holes in D=5: SUSY vs. Gauss-Bonnet corrections'.   We analyse near-horizon solutions and compare the results for the black hole entropy of five-dimensional spherically symmetric extremal black holes when the N=2 SUGRA actions are supplied with two different types of higher-order corrections: (1) supersymmetric completion of gravitational Chern-Simons term, and (2) Gauss-Bonnet term. We show that for large BPS black holes lowest order \\alpha' corrections to the entropy are the same, but for non-BPS are generally different. We pay special attention to the class of prepotentials connected with K3\\times T^2 and T^6 compactifications. For supersymmetric correction we find beside BPS also a set of non-BPS solutions. In the particular case of T^6 compactification (equivalent to the heterotic string on $T^4\\times S^1$) we find the (almost) complete set of solutions (with exception of some non-BPS small black holes), and show that entropy of small black holes is different from statistical entropy obtained by counting of microstates of heterotic string theory. We also find complete set of solutions for K3\\times T^2 and T^6 case when correction is given by Gauss-Bonnet term. Contrary to four-dimensional case, obtained entropy is different from the one with supersymmetric correction. We show that in Gauss-Bonnet case entropy of small ``BPS'' black holes agrees with microscopic entropy in the known cases.  ", "human_text": "  We analyse near-horizon solutions and compare the results for the black hole entropy of five-dimensional spherically symmetric extremal black holes when the N=2 SUGRA actions are supplied with two different types of higher-order corrections: (1) supersymmetric completion of gravitational Chern-Simons term, and (2) Gauss-Bonnet term. We show that for large BPS black holes lowest order \\alpha' corrections to the entropy are the same, but for non-BPS are generally different. We pay special attention to the class of prepotentials connected with K3\\times T^2 and T^6 compactifications. For supersymmetric correction we find beside BPS also a set of non-BPS solutions. In the particular case of T^6 compactification (equivalent to the heterotic string on $T^4\\times S^1$) we find the (almost) complete set of solutions (with exception of some non-BPS small black holes), and show that entropy of small black holes is different from statistical entropy obtained by counting of microstates of heterotic string theory. We also find complete set of solutions for K3\\times T^2 and T^6 case when correction is given by Gauss-Bonnet term. Contrary to four-dimensional case, obtained entropy is different from the one with supersymmetric correction. We show that in Gauss-Bonnet case entropy of small ``BPS'' black holes agrees with microscopic entropy in the known cases. ", "machine_text": " In this article, we present an analysis of near-horizon solutions and compare the results of their black hole entropy in five-dimensional spherically symmetric extremal black holes when different types of higher-order corrections are applied. Specifically, we supply N=2 SUGRA actions with two different types of corrections, namely the gravitational Chern-Simons term supersymmetrically completed and the Gauss-Bonnet term. We demonstrate that for large BPS black holes, the lowest order \\alpha' corrections have the same entropy, however, for non-BPS black holes, they are generally different. Furthermore, we pay special attention to the class of prepotentials connected with the K3\\times T^2 and T^6 compactifications. In the former instance, we obtain both BPS and non-BPS solutions, while in the latter (equivalent to the heterotic string on $T^4\\times S^1$) we find the almost complete set of solutions to the exception of non-BPS small black holes. We show that their entropy is distinct from the statistical entropy arriving from counting the microstates of heterotic string theory. Additionally, we acquire a complete set of solutions when the correction is given by the Gauss-Bonnet term for the two popular compactifications. Contrary to the four-dimensional picture, the obtained entropy does not match with that of the supersymmetric correction. Lastly, for the ``BPS'' small black holes, we observe that in the Gauss-Bonnet case, their entropy complies with its microscopic counterpart in known contexts. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1167}
{"prompt": "Rephrase the abstract of an article with title 'Quantum Theory of Flicker Noise in Metal Films'.   Flicker (1/f^gamma) voltage noise spectrum is derived from finite-temperature quantum electromagnetic fluctuations produced by elementary charge carriers in external electric field. It is suggested that deviations of the frequency exponent \\gamma from unity, observed in thin metal films, can be attributed to quantum backreaction of the conducting medium on the fluctuating field of the charge carrier. This backreaction is described phenomenologically in terms of the effective momentum space dimensionality, D. Using the dimensional continuation technique, it is shown that the combined action of the photon heat bath and external field results in a 1/f^gamma-contribution to the spectral density of the two-point correlation function of electromagnetic field. The frequency exponent is found to be equal to 1 + delta, where delta = 3 - D is a reduction of the momentum space dimensionality. This result is applied to the case of a biased conducting sample, and a general expression for the voltage power spectrum is obtained which possesses all characteristic properties of observed flicker noise spectra. The range of validity of this expression covers well the whole measured frequency band. Gauge independence of the power spectrum is proved. It is shown that the obtained results naturally resolve the problem of divergence of the total noise power. A detailed comparison with the experimental data on flicker noise measurements in metal films is given.  ", "human_text": "  Flicker (1/f^gamma) voltage noise spectrum is derived from finite-temperature quantum electromagnetic fluctuations produced by elementary charge carriers in external electric field. It is suggested that deviations of the frequency exponent \\gamma from unity, observed in thin metal films, can be attributed to quantum backreaction of the conducting medium on the fluctuating field of the charge carrier. This backreaction is described phenomenologically in terms of the effective momentum space dimensionality, D. Using the dimensional continuation technique, it is shown that the combined action of the photon heat bath and external field results in a 1/f^gamma-contribution to the spectral density of the two-point correlation function of electromagnetic field. The frequency exponent is found to be equal to 1 + delta, where delta = 3 - D is a reduction of the momentum space dimensionality. This result is applied to the case of a biased conducting sample, and a general expression for the voltage power spectrum is obtained which possesses all characteristic properties of observed flicker noise spectra. The range of validity of this expression covers well the whole measured frequency band. Gauge independence of the power spectrum is proved. It is shown that the obtained results naturally resolve the problem of divergence of the total noise power. A detailed comparison with the experimental data on flicker noise measurements in metal films is given. ", "machine_text": "This article examines the measurement of flicker voltage noise power spectrum in thin metal films, with the aim of examining the deviation of the frequency exponent \\gamma from the theoretical value of 1. This deviation is attributed to the quantum backreaction of the conducting medium on the fluctuating charge carriers in the external electric field. Results of a dimensional continuation technique are used to explain 1/f^gamma-contribution to the two-point correlation function of electromagnetic fields and ultimately the voltage power spectrum. A general expression for the voltage power spectrum is formulated, and subsequent analysis shows this expression to resolve the divergence of total noise power. A comparison with the experimental data is made and discussed in detail.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2818}
{"prompt": "Rephrase the abstract of an article with title 'Differentially rotating force-free magnetosphere of an aligned rotator:   analytical solutions in split-monopole approximation'.   In this paper we consider stationary force-free magnetosphere of an aligned rotator when plasma in the open field line region rotates differentially due to presence of a zone with the accelerating electric field in the polar cap of pulsar. We study the impact of differential rotation on the current density distribution in the magnetosphere. Using split-monopole approximation we obtain analytical expressions for physical parameters of differentially rotating magnetosphere. We find the range of admitted current density distributions under the requirement that the potential drop in the polar cap is less than the vacuum potential drop. We show that the current density distribution could deviate significantly from the ``classical'' Michel distribution and could be made almost constant over the polar cap even when the potential drop in the accelerating zone is of the order of 10 per cents of the vacuum potential drop. We argue that differential rotation of the open magnetic field lines could play an important role in adjusting between the magnetosphere and the polar cap cascade zone and could affect the value of pulsar breaking index.  ", "human_text": "  In this paper we consider stationary force-free magnetosphere of an aligned rotator when plasma in the open field line region rotates differentially due to presence of a zone with the accelerating electric field in the polar cap of pulsar. We study the impact of differential rotation on the current density distribution in the magnetosphere. Using split-monopole approximation we obtain analytical expressions for physical parameters of differentially rotating magnetosphere. We find the range of admitted current density distributions under the requirement that the potential drop in the polar cap is less than the vacuum potential drop. We show that the current density distribution could deviate significantly from the ``classical'' Michel distribution and could be made almost constant over the polar cap even when the potential drop in the accelerating zone is of the order of 10 per cents of the vacuum potential drop. We argue that differential rotation of the open magnetic field lines could play an important role in adjusting between the magnetosphere and the polar cap cascade zone and could affect the value of pulsar breaking index. ", "machine_text": " This article studies the effects of differentially-rotating magnetospheres on the current density distribution of an aligned rotator. Using split-monopole approximation, analytical expressions of physical parameters of such magnetospheres are derived. The range of current density distribution allowed is explored, with an additional requirement that the potential drop in the polar cap should not exceed the vacuum potential drop. It is suggested that the current density distribution could change significantly from the normal Michel distribution, even when the potential drop in the acceleration zone is of order 10% of the vacuum potential drop. Lastly, the role of differential rotation of open magnetic field lines in adjusting the magnetosphere and polar cap cascade zone, and its impact on the pulsar breaking index are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2141}
{"prompt": "Rephrase the abstract of an article with title 'Observations and Modeling of Line Asymmetries in Chromospheric Flares'.   For many years various asymmetrical profiles of different spectral lines emitted from solar flares have been frequently observed. These asymmetries or line shifts are caused predominantly by vertical mass motions in flaring layers and they provide a good diagnostics for plasma flows during solar flares. There are many controversial results of observations and theoretical analysis of plasma flows in solar chromospheric flares. The main difficulty is the interpretation of line shifts or asymmetries. For many years, methods based on bisector techniques were used but they give a reliable results only for some specific conditions and in most cases cannot be applied. The most promising approach is to use the non-LTE techniques applied for flaring atmosphere. The calculation of synthetic line profiles is performed with the radiative transfer techniques and the assumed physical conditions correspond to flaring atmosphere. I will present an overview of different observations and interpretations of line asymmetries in chromospheric flares. I will explain what we have learnt about the chromospheric evaporation in the frame of hydrodynamical models as well as reconnection models. A critical review will be done on the classical methods used to derive Doppler-shifts for optically thick chomospheric lines. In particular, details on the new approach for interpreting chromospheric line asymmetries based on the non-LTE techniques will be presented.  ", "human_text": "  For many years various asymmetrical profiles of different spectral lines emitted from solar flares have been frequently observed. These asymmetries or line shifts are caused predominantly by vertical mass motions in flaring layers and they provide a good diagnostics for plasma flows during solar flares. There are many controversial results of observations and theoretical analysis of plasma flows in solar chromospheric flares. The main difficulty is the interpretation of line shifts or asymmetries. For many years, methods based on bisector techniques were used but they give a reliable results only for some specific conditions and in most cases cannot be applied. The most promising approach is to use the non-LTE techniques applied for flaring atmosphere. The calculation of synthetic line profiles is performed with the radiative transfer techniques and the assumed physical conditions correspond to flaring atmosphere. I will present an overview of different observations and interpretations of line asymmetries in chromospheric flares. I will explain what we have learnt about the chromospheric evaporation in the frame of hydrodynamical models as well as reconnection models. A critical review will be done on the classical methods used to derive Doppler-shifts for optically thick chomospheric lines. In particular, details on the new approach for interpreting chromospheric line asymmetries based on the non-LTE techniques will be presented. ", "machine_text": " This article provides an overview of the asymmetrical profiles of different spectral lines seen in solar flares, as well as the modelings used to explain them. These line shifts can be attributed to vertical mass motions inside the flaring layers, making them a prime candiate to measure plasma flow during a solar flare. While attempts have been made using the bisector technique, most results are not reliable under certain conditions and therefore a non-LTE technique is used to calculate synthetic line profiles that correspond to flaring atmosphere. This article will include an overview on different observations of line asymmetries in chromospheric flares, and discuss data on chromospheric evaporation as well as reconnection models. A critical review of the classical methods for calculating Doppler shifts for optically thick chromospheric lines will be done, with details on the new approach being presented.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2436}
{"prompt": "Rephrase the abstract of an article with title 'Resummation of Large Logarithms in $\\gamma^* \\pi^0 \\to \\gamma $'.   In the collinear factorization of the form factor for the transition $\\gamma^* \\pi^0 \\to \\gamma$ the hard part contains double log terms as $\\ln^2 x$ with $x$ as the momentum fraction of partons from 0 to 1. A simple exponentiation for resummation leads to divergent results. We study the resummation of these $\\ln^2 x$ terms. We show that the $\\ln^2 x$ terms come partly from the light-cone wave function(LCWF) and partly from the form factor. We introduce a jet factor to factorize the $\\ln^2 x$ term in the form factor. To handel the $\\ln^2 x$ terms from the LCWF we introduce a nonstandard light-cone wave function(NLCWF) with the gauge links off the light-cone direction. An interesting relation between two wave function is found. With the introduced NLCWF and the jet factor we can re-factorize the form factor and obtain a new hard part which does not contain terms with $\\ln^2 x$. Beside the renormalization scale $\\mu$ the introduce NLCWF and jet factor have extra scales to characterize their $x$-behaviors. Using the evolutions of the extra scales and the relation we can do the resummation perturbatively in sense that the LCWF is the only nonpertubative object in the resumed formula. Our results with some models of LCWF show that there is a significant difference between numerical predictions with the resummation and that without the resummation, and the resummed predictions can describe the experimental data.  ", "human_text": "  In the collinear factorization of the form factor for the transition $\\gamma^* \\pi^0 \\to \\gamma$ the hard part contains double log terms as $\\ln^2 x$ with $x$ as the momentum fraction of partons from 0 to 1. A simple exponentiation for resummation leads to divergent results. We study the resummation of these $\\ln^2 x$ terms. We show that the $\\ln^2 x$ terms come partly from the light-cone wave function(LCWF) and partly from the form factor. We introduce a jet factor to factorize the $\\ln^2 x$ term in the form factor. To handel the $\\ln^2 x$ terms from the LCWF we introduce a nonstandard light-cone wave function(NLCWF) with the gauge links off the light-cone direction. An interesting relation between two wave function is found. With the introduced NLCWF and the jet factor we can re-factorize the form factor and obtain a new hard part which does not contain terms with $\\ln^2 x$. Beside the renormalization scale $\\mu$ the introduce NLCWF and jet factor have extra scales to characterize their $x$-behaviors. Using the evolutions of the extra scales and the relation we can do the resummation perturbatively in sense that the LCWF is the only nonpertubative object in the resumed formula. Our results with some models of LCWF show that there is a significant difference between numerical predictions with the resummation and that without the resummation, and the resummed predictions can describe the experimental data. ", "machine_text": "This article presents a study of the resummation of the double log terms $\\ln^2 x$ in the collinear factorization of the form factor for the transition $\\gamma^* \\pi^0 \\to \\gamma$. We introduce a nonstandard light-cone wave function and a jet factor to factorize the $\\ln^2 x$ term in the form factor and show that these objects have extra scales to characterize their $x$-behaviors. We then leverage the evolutions of the extra scales and the relation of these two wave functions to do the resummation perturbatively. Our results demonstrate that a significant difference exists between the numerical predictions with and without resummation, and that the resummed values can more accurately fit the available experimental data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3782}
{"prompt": "Rephrase the abstract of an article with title 'Dyson Indices and Hilbert-Schmidt Separability Functions and   Probabilities'.   A confluence of numerical and theoretical results leads us to conjecture that the Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional convex sets of complex and real two-qubit states (representable by 4 x 4 density matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning are the modifications of two ansatze, recently advanced (quant-ph/0609006), involving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11} rho_{44})/(rho_{22} rho_{33}). We, now, set the separability function S_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the complex case -- conforming to a pattern we find, manifesting the Dyson indices (1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2} (nu). We also investigate the real and complex qubit-qutrit cases. Now, there are two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}), nu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably coalesce into the product, eta = nu_1 nu_2 = rho_{11} \\rho_{66}}{\\rho_{33} \\rho_{44}}, so that the real and complex separability functions are again univariate in nature.  ", "human_text": "  A confluence of numerical and theoretical results leads us to conjecture that the Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional convex sets of complex and real two-qubit states (representable by 4 x 4 density matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning are the modifications of two ansatze, recently advanced (quant-ph/0609006), involving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11} rho_{44})/(rho_{22} rho_{33}). We, now, set the separability function S_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the complex case -- conforming to a pattern we find, manifesting the Dyson indices (1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2} (nu). We also investigate the real and complex qubit-qutrit cases. Now, there are two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}), nu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably coalesce into the product, eta = nu_1 nu_2 = rho_{11} \\rho_{66}}{\\rho_{33} \\rho_{44}}, so that the real and complex separability functions are again univariate in nature. ", "machine_text": "We examine the implications of our conjecture with respect to Dyson indices,  Hilbert-Schmidt separability probabilities, and Beta function ansatze for  real and complex two-qubit states, qutrits, and higher-dimensional states. We  find that our conjectured relation of separability probabilities to Dyson  indices is in accord with random matrix theory, as demonstrated in the studies  of the real and complex qubit-qutrit cases. Moreover, the conjectured  separability functions based on Beta functions are further supported in  numerical and theoretical analyses, as well as studies involving higher  dimensional real and complex states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3723}
{"prompt": "Rephrase the abstract of an article with title 'GRB 050410 and GRB 050412: are they really dark GRBs?'.   We present a detailed analysis of the prompt and afterglow emission of GRB 050410 and GRB 050412 detected by Swift for which no optical counterpart was observed. The 15-150 keV energy distribution of the GRB 050410 prompt emission shows a peak energy at 53 keV. The XRT light curve of this GRB decays as a power law with a slope of alpha=1.06+/-0.04. The spectrum is well reproduced by an absorbed power law with a spectral index Gamma_x=2.4+/-0.4 and a low energy absorption N_H=4(+3;-2)x10^21 cm^(-2) which is higher than the Galactic value. The 15-150 keV prompt emission in GRB 050412 is modelled with a hard (Gamma=0.7+/-0.2) power law. The XRT light curve follows a broken power law with the first slope alpha_1=0.7+/-0.4, the break time T_break=254(-41;+79) s and the second slope alpha_2=2.8(-0.8;+0.5). The spectrum is fitted by a power law with spectral index Gamma_x=1.3+/-0.2 which is absorbed at low energies by the Galactic column. The GRB 050410 afterglow reveals the expected characteristics of the third component of the canonical Swift light curve. Conversely, a complex phenomenology was detected in the GRB 050412 because of the presence of the very early break. The light curve in this case can be interpreted as being the last peak of the prompt emission. The two bursts present tight upper limits for the optical emission, however, neither of them can be clearly classified as dark. For GRB 050410, the suppression of the optical afterglow could be attributed to a low density interstellar medium surrounding the burst. For GRB 050412, the evaluation of the darkness is more difficult due to the ambiguity in the extrapolation of the X-ray afterglow light curve.  ", "human_text": "  We present a detailed analysis of the prompt and afterglow emission of GRB 050410 and GRB 050412 detected by Swift for which no optical counterpart was observed. The 15-150 keV energy distribution of the GRB 050410 prompt emission shows a peak energy at 53 keV. The XRT light curve of this GRB decays as a power law with a slope of alpha=1.06+/-0.04. The spectrum is well reproduced by an absorbed power law with a spectral index Gamma_x=2.4+/-0.4 and a low energy absorption N_H=4(+3;-2)x10^21 cm^(-2) which is higher than the Galactic value. The 15-150 keV prompt emission in GRB 050412 is modelled with a hard (Gamma=0.7+/-0.2) power law. The XRT light curve follows a broken power law with the first slope alpha_1=0.7+/-0.4, the break time T_break=254(-41;+79) s and the second slope alpha_2=2.8(-0.8;+0.5). The spectrum is fitted by a power law with spectral index Gamma_x=1.3+/-0.2 which is absorbed at low energies by the Galactic column. The GRB 050410 afterglow reveals the expected characteristics of the third component of the canonical Swift light curve. Conversely, a complex phenomenology was detected in the GRB 050412 because of the presence of the very early break. The light curve in this case can be interpreted as being the last peak of the prompt emission. The two bursts present tight upper limits for the optical emission, however, neither of them can be clearly classified as dark. For GRB 050410, the suppression of the optical afterglow could be attributed to a low density interstellar medium surrounding the burst. For GRB 050412, the evaluation of the darkness is more difficult due to the ambiguity in the extrapolation of the X-ray afterglow light curve. ", "machine_text": " This article analyses the prompt and afterglow emission of GRB 050410 and GRB 050412, two bursts detected by Swift with no observed optical counterparts. Our analysis examined the 15-150 keV energy distribution of the GRB 050410 prompt emission, which revealed a peak energy at 53 keV, as well as the XRT light curve, the spectrum, and the GRB 050412 afterglow. Although both bursts had tight upper limits for the optical emission, neither of them could be definitively deemed 'dark' GRBs. For GRB 050410, this could be due to the relatively low density of the interstellar medium surrounding the burst, while it was more difficult to determine in GRB 050412 due to the ambiguity in the extrapolation of the X-ray afterglow light curve.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3191}
{"prompt": "Rephrase the abstract of an article with title 'Information-Based Asset Pricing'.   A new framework for asset price dynamics is introduced in which the concept of noisy information about future cash flows is used to derive the price processes. In this framework an asset is defined by its cash-flow structure. Each cash flow is modelled by a random variable that can be expressed as a function of a collection of independent random variables called market factors. With each such \"X-factor\" we associate a market information process, the values of which are accessible to market agents. Each information process is a sum of two terms; one contains true information about the value of the market factor; the other represents \"noise\". The noise term is modelled by an independent Brownian bridge. The market filtration is assumed to be that generated by the aggregate of the independent information processes. The price of an asset is given by the expectation of the discounted cash flows in the risk-neutral measure, conditional on the information provided by the market filtration. When the cash flows are the dividend payments associated with equities, an explicit model is obtained for the share-price, and the prices of options on dividend-paying assets are derived. Remarkably, the resulting formula for the price of a European call option is of the Black-Scholes-Merton type. The information-based framework also generates a natural explanation for the origin of stochastic volatility.  ", "human_text": "  A new framework for asset price dynamics is introduced in which the concept of noisy information about future cash flows is used to derive the price processes. In this framework an asset is defined by its cash-flow structure. Each cash flow is modelled by a random variable that can be expressed as a function of a collection of independent random variables called market factors. With each such \"X-factor\" we associate a market information process, the values of which are accessible to market agents. Each information process is a sum of two terms; one contains true information about the value of the market factor; the other represents \"noise\". The noise term is modelled by an independent Brownian bridge. The market filtration is assumed to be that generated by the aggregate of the independent information processes. The price of an asset is given by the expectation of the discounted cash flows in the risk-neutral measure, conditional on the information provided by the market filtration. When the cash flows are the dividend payments associated with equities, an explicit model is obtained for the share-price, and the prices of options on dividend-paying assets are derived. Remarkably, the resulting formula for the price of a European call option is of the Black-Scholes-Merton type. The information-based framework also generates a natural explanation for the origin of stochastic volatility. ", "machine_text": "This paper introduces a new pricing framework, based on the concept of noisy information about future cash flows and the associated market filtration. The dynamics of asset prices are determined by the expectation of discounted cash flows, conditional on the information provided by the market information process. A model is obtained for share prices, and options on dividend-paying assets are derived from the resulting formulae. This shows that the Black-Scholes-Merton formula applies to this framework, and provides an explanation for the phenomenon of stochastic volatility.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1976}
{"prompt": "Rephrase the abstract of an article with title 'Effective inverse spectral problem for rational Lax matrices and   applications'.   We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the desingularization of the characteristic polynomial) and some additional data. Using a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu)) we provide a residue-formula for the entries of the Lax matrix in terms of bases of dual differentials of weights nu and 1-nu respectively. All objects are described in the most explicit terms using Theta functions. Via a sequence of ``elementary twists'', we construct sequences of Lax matrices sharing the same spectral curve and polar structure and related by conjugations by rational matrices. Particular choices of elementary twists lead to construction of sequences of Lax matrices related to finite--band recurrence relations (i.e. difference operators) sharing the same shape. Recurrences of this kind are satisfied by several types of orthogonal and biorthogonal polynomials. The relevance of formulae obtained to the study of the large degree asymptotics for these polynomials is indicated.  ", "human_text": "  We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the desingularization of the characteristic polynomial) and some additional data. Using a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu)) we provide a residue-formula for the entries of the Lax matrix in terms of bases of dual differentials of weights nu and 1-nu respectively. All objects are described in the most explicit terms using Theta functions. Via a sequence of ``elementary twists'', we construct sequences of Lax matrices sharing the same spectral curve and polar structure and related by conjugations by rational matrices. Particular choices of elementary twists lead to construction of sequences of Lax matrices related to finite--band recurrence relations (i.e. difference operators) sharing the same shape. Recurrences of this kind are satisfied by several types of orthogonal and biorthogonal polynomials. The relevance of formulae obtained to the study of the large degree asymptotics for these polynomials is indicated. ", "machine_text": "This paper provides a method to invert the spectral problem for rational Lax matrices of size R+1, based on the curve of the associated characteristic polynomial and additional data. We make use of twisted Cauchy-like kernels to formulate an integral residue formula to represent the entries of Lax matrices, with all components being expressed in terms of Theta functions. Different elements in the matrix are realized with the aid of 'elementary twists', leading to the construction of sequences of Lax matrices that have the same spectral curve and polar structure, but related by rational conjugations. Our formulae are further used to derive certain finite-band recurrence relations, which are satisfied by various types of orthogonal and biorthogonal polynomials. Such models are relevant to the study of the leading-order behavior of these polynomials at large degree.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.012}
{"prompt": "Rephrase the abstract of an article with title 'Survival of the mm-cm size grain population observed in protoplanetary   disks'.   Millimeter interferometry provides evidence for the presence of mm to cm size \"pebbles\" in the outer parts of disks around pre-main-sequence stars. The observations suggest that large grains are produced relatively early in disk evolution (< 1 Myr) and remain at large radii for longer periods of time (5 to 10 Myr). Simple theoretical estimates of the radial drift time of solid particles, however, imply that they would drift inward over a time scale of less than 0.1 Myr. In this paper, we address this conflict between theory and observation, using more detailed theoretical models, including the effects of sedimentation, collective drag forces and turbulent viscosity. We find that, although these effects slow down the radial drift of the dust particles, this reduction is not sufficient to explain the observationally determined long survival time of mm/cm-sized grains in protoplanetary disks. However, if for some reason the gas to dust ratio in the disk is reduced by at least a factor of 20 from the canonical value of 100 (for instance through photoevaporation of the gas), then the radial drift time scales become sufficiently large to be in agreement with observations.  ", "human_text": "  Millimeter interferometry provides evidence for the presence of mm to cm size \"pebbles\" in the outer parts of disks around pre-main-sequence stars. The observations suggest that large grains are produced relatively early in disk evolution (< 1 Myr) and remain at large radii for longer periods of time (5 to 10 Myr). Simple theoretical estimates of the radial drift time of solid particles, however, imply that they would drift inward over a time scale of less than 0.1 Myr. In this paper, we address this conflict between theory and observation, using more detailed theoretical models, including the effects of sedimentation, collective drag forces and turbulent viscosity. We find that, although these effects slow down the radial drift of the dust particles, this reduction is not sufficient to explain the observationally determined long survival time of mm/cm-sized grains in protoplanetary disks. However, if for some reason the gas to dust ratio in the disk is reduced by at least a factor of 20 from the canonical value of 100 (for instance through photoevaporation of the gas), then the radial drift time scales become sufficiently large to be in agreement with observations. ", "machine_text": " Observations from millimeter interferometry of pre-main-sequence stars' disks reveal the existence of pebble-sized particles, ranging in size from millimeters to centimeters, which are estimated to remain in the outer parts of these disks for up to 10 million years. This survival rate goes against the predictions of theoretical models of radial drift, which suggest that such particles should drift inwardly within 0.1 million years. This conflict is investigated through advanced theoretical models, incorporating sedimentation, collective drag forces, and turbulent viscosity. It is found that, despite slowing the radial drift somewhat, this alone is not enough to explain the discrepancy between estimates. However, if the gas to dust ratio of the disk was reduced by a factor of 20 (e.g. through photoevaporation), the radial drift time frames become compatible with observations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2332}
{"prompt": "Rephrase the abstract of an article with title 'Separation of the visible and dark matter in the Einstein ring LBG   J213512.73-010143'.   We model the mass distribution in the recently discovered Einstein ring LBG J213512.73-010143 (the `Cosmic Eye') using archival Hubble Space Telescope imaging. We reconstruct the mass density profile of the z=0.73 lens and the surface brightness distribution of the z=3.07 source and find that the observed ring is best fit with a dual-component lens model consisting of a baryonic Sersic component nested within a dark matter halo. The dark matter halo has an inner slope of 1.42+/-0.23, consistent with CDM simulations after allowing for baryon contraction. The baryonic component has a B-band mass-to-light ratio of 1.71+0.28-0.38 (solar units) which when evolved to the present day is in agreement with local ellipticals. Within the Einstein radius of 0.77'' (5.6 kpc), the baryons account for (46+/-11)% of the total lens mass. External shear from a nearby foreground cluster is accurately predicted by the model. The reconstructed surface brightness distribution in the source plane clearly shows two peaks. Through a generalisation of our lens inversion method, we conclude that the redshifts of both peaks are consistent with each other, suggesting that we are seeing structure within a single galaxy.  ", "human_text": "  We model the mass distribution in the recently discovered Einstein ring LBG J213512.73-010143 (the `Cosmic Eye') using archival Hubble Space Telescope imaging. We reconstruct the mass density profile of the z=0.73 lens and the surface brightness distribution of the z=3.07 source and find that the observed ring is best fit with a dual-component lens model consisting of a baryonic Sersic component nested within a dark matter halo. The dark matter halo has an inner slope of 1.42+/-0.23, consistent with CDM simulations after allowing for baryon contraction. The baryonic component has a B-band mass-to-light ratio of 1.71+0.28-0.38 (solar units) which when evolved to the present day is in agreement with local ellipticals. Within the Einstein radius of 0.77'' (5.6 kpc), the baryons account for (46+/-11)% of the total lens mass. External shear from a nearby foreground cluster is accurately predicted by the model. The reconstructed surface brightness distribution in the source plane clearly shows two peaks. Through a generalisation of our lens inversion method, we conclude that the redshifts of both peaks are consistent with each other, suggesting that we are seeing structure within a single galaxy. ", "machine_text": " The newly identified Einstein ring LBG J213512.73-010143 (the 'Cosmic Eye') has been explored for its mass distribution using data from the Hubble Space Telescope. Our analysis reveals a dual-component lens made up of both baryonic and dark matter components. The dark matter halo has a central slope that aligns with the parameters produced by CDM simulations, and the baryonic component has a B-band mass-to-light ratio in line with local ellipticals. In addition, the model correctly predicts the external shear from a neighbouring cluster. By generalising an inversion method, we find that the two visible peaks across the light source identify themselves as a single galaxy. Thus, we can assign a mass proportion of 46% (+/- 11%) to the baryons within the Einstein radius of 0.77\" (5.6 kpc).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.172}
{"prompt": "Rephrase the abstract of an article with title 'Common Envelope Evolution Redux'.   Common envelopes form in dynamical time scale mass exchange, when the envelope of a donor star engulfs a much denser companion, and the core of the donor plus the dense companion star spiral inward through this dissipative envelope. As conceived by Paczynski and Ostriker, this process must be responsible for the creation of short-period binaries with degenerate components, and, indeed, it has proven capable of accounting for short-period binaries containing one white dwarf component. However, attempts to reconstruct the evolutionary histories of close double white dwarfs have proven more problematic, and point to the need for enhanced systemic mass loss, either during the close of the first, slow episode of mass transfer that produced the first white dwarf, or during the detached phase preceding the final, common envelope episode. The survival of long-period interacting binaries with massive white dwarfs, such as the recurrent novae T CrB and RS Oph, also presents interpretative difficulties for simple energetic treatments of common envelope evolution. Their existence implies that major terms are missing from usual formulations of the energy budget for common envelope evolution. The most plausible missing energy term is the energy released by recombination in the common envelope, and, indeed, a simple reformulation the energy budget explicitly including recombination resolves this issue.  ", "human_text": "  Common envelopes form in dynamical time scale mass exchange, when the envelope of a donor star engulfs a much denser companion, and the core of the donor plus the dense companion star spiral inward through this dissipative envelope. As conceived by Paczynski and Ostriker, this process must be responsible for the creation of short-period binaries with degenerate components, and, indeed, it has proven capable of accounting for short-period binaries containing one white dwarf component. However, attempts to reconstruct the evolutionary histories of close double white dwarfs have proven more problematic, and point to the need for enhanced systemic mass loss, either during the close of the first, slow episode of mass transfer that produced the first white dwarf, or during the detached phase preceding the final, common envelope episode. The survival of long-period interacting binaries with massive white dwarfs, such as the recurrent novae T CrB and RS Oph, also presents interpretative difficulties for simple energetic treatments of common envelope evolution. Their existence implies that major terms are missing from usual formulations of the energy budget for common envelope evolution. The most plausible missing energy term is the energy released by recombination in the common envelope, and, indeed, a simple reformulation the energy budget explicitly including recombination resolves this issue. ", "machine_text": " This article investigates common envelope evolution, an astrophysical process that occurs when the envelope of a donor star envelops a much denser companion. As proposed by Paczynski and Ostriker, this mass exchange creates short-period binary systems with degenerate components. Reconstructing the evolutionary histories of close double white dwarf systems has been more challenging, as it is likely that enhanced systemic mass loss is needed. The presence of long-period interacting binaries and recurrent novae, such as T CrB and RS Oph, suggests that the energy budget for common envelope evolution may be incomplete. Recombination energy could potentially satisfy the missing energy term and serve to resolve this issue. The research discussed in this article critiques and refines the theoretical formulation of common envelope evolution and the energy budget to account for the complexities of the process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.028}
{"prompt": "Rephrase the abstract of an article with title 'MICS Asia Phase II - Sensitivity to the aerosol module'.   In the framework of the model inter-comparison study - Asia Phase II (MICS2), where eight models are compared over East Asia, this paper studies the influence of different parameterizations used in the aerosol module on the aerosol concentrations of sulfate and nitrate in PM10. An intracomparison of aerosol concentrations is done for March 2001 using different configurations of the aerosol module of one of the model used for the intercomparison. Single modifications of a reference setup for model configurations are performed and compared to a reference case. These modifications concern the size distribution, i.e. the number of sections, and physical processes, i.e. coagulation, condensation/evaporation, cloud chemistry, heterogeneous reactions and sea-salt emissions. Comparing monthly averaged concentrations at different stations, the importance of each parameterization is first assessed. It is found that sulfate concentrations are little sensitive to sea-salt emissions and to whether condensation is computed dynamically or by assuming thermodynamic equilibrium. Nitrate concentrations are little sensitive to cloud chemistry. However, a very high sensitivity to heterogeneous reactions is observed. Thereafter, the variability of the aerosol concentrations to the use of different chemistry transport models (CTMs) and the variability to the use of different parameterizations in the aerosol module are compared. For sulfate, the variability to the use of different parameterizations in the aerosol module is lower than the variability to the use of different CTMs. However, for nitrate, for monthly averaged concentrations averaged over four stations, these two variabilities have the same order of magnitude.  ", "human_text": "  In the framework of the model inter-comparison study - Asia Phase II (MICS2), where eight models are compared over East Asia, this paper studies the influence of different parameterizations used in the aerosol module on the aerosol concentrations of sulfate and nitrate in PM10. An intracomparison of aerosol concentrations is done for March 2001 using different configurations of the aerosol module of one of the model used for the intercomparison. Single modifications of a reference setup for model configurations are performed and compared to a reference case. These modifications concern the size distribution, i.e. the number of sections, and physical processes, i.e. coagulation, condensation/evaporation, cloud chemistry, heterogeneous reactions and sea-salt emissions. Comparing monthly averaged concentrations at different stations, the importance of each parameterization is first assessed. It is found that sulfate concentrations are little sensitive to sea-salt emissions and to whether condensation is computed dynamically or by assuming thermodynamic equilibrium. Nitrate concentrations are little sensitive to cloud chemistry. However, a very high sensitivity to heterogeneous reactions is observed. Thereafter, the variability of the aerosol concentrations to the use of different chemistry transport models (CTMs) and the variability to the use of different parameterizations in the aerosol module are compared. For sulfate, the variability to the use of different parameterizations in the aerosol module is lower than the variability to the use of different CTMs. However, for nitrate, for monthly averaged concentrations averaged over four stations, these two variabilities have the same order of magnitude. ", "machine_text": "This paper investigates the response of sulfate and nitrate aerosol concentrations in PM10 to the parameters of an aerosol module within the framework of Model Inter-Comparison Study (MICS) Asia Phase II. A reference configuration resulted in a comparison of aerosol concentrations in two models. Single variations were then assessed against this reference, such as size distribution, physical processes and various emissions \u2013 with a focus on how these modifications respond to concentrations in PM10. Results yielded little effect from sea-salt emissions but higher sensitivity to heterogeneous reactions, while nitrate was found to be insensitive to cloud chemistry. Finally, investigating the variability of the models, the response of sulfate concentrations was seen to be lower than that of a Chemistry Transport Model, whereas the response of nitrate concentrations was found to be of similar magnitude to the model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.319}
{"prompt": "Rephrase the abstract of an article with title 'Instabilities in the time-dependent neutrino disc in Gamma-Ray Bursts'.   We investigate the properties and evolution of accretion tori formed after the coalescence of two compact objects. At these extreme densities and temperatures, the accreting torus is cooled mainly by neutrino emission produced primarily by electron and positron capture on nucleons (beta reactions). We solve for the disc structure and its time evolution by introducing a detailed treatment of the equation of state which includes photodisintegration of helium, the condition of beta-equilibrium, and neutrino opacities. We self-consistently calculate the chemical equilibrium in the gas consisting of helium, free protons, neutrons and electron-positron pairs and compute the chemical potentials of the species, as well as the electron fraction throughout the disc. We find that, for sufficiently large accretion rates (> 10 solar masses per second), the inner regions of the disk become opaque and develop a viscous and thermal instability. The identification of this instability might be relevant for GRB observations.  ", "human_text": "  We investigate the properties and evolution of accretion tori formed after the coalescence of two compact objects. At these extreme densities and temperatures, the accreting torus is cooled mainly by neutrino emission produced primarily by electron and positron capture on nucleons (beta reactions). We solve for the disc structure and its time evolution by introducing a detailed treatment of the equation of state which includes photodisintegration of helium, the condition of beta-equilibrium, and neutrino opacities. We self-consistently calculate the chemical equilibrium in the gas consisting of helium, free protons, neutrons and electron-positron pairs and compute the chemical potentials of the species, as well as the electron fraction throughout the disc. We find that, for sufficiently large accretion rates (> 10 solar masses per second), the inner regions of the disk become opaque and develop a viscous and thermal instability. The identification of this instability might be relevant for GRB observations. ", "machine_text": " This paper examines the features and evolution of the accretion tori formed when two compact objects collide. Upon recognizing these extreme temperature and density levels, neutrino radiation produced by electron and positron capture on nuclei (beta reactions) is primarily used to cool the accreting torus. We consider a methodical treatment of the equation of state which involves analyzing the photodisintegration of helium, beta equilibrium, and neutrino opacities in order to ascertain the disc structure and its alterations over time. We expand upon this by evaluating the chemical equilibrium of the gas which is comprised of helium, free protons, neutrons, electron-positron pairs to figure out the chemical potentials of the individual parts and establish the electron fraction throughout the disc. Our findings suggest that for very high accretion rates (exceeding ten solar masses per second), the inner areas of the disc turn out to be opaque and result in a viscous and thermal instability. This form of instability could be useful in aiding the comprehension of GRB phenomena from an observational angle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1325}
{"prompt": "Rephrase the abstract of an article with title 'Synchrotron Radio Emission from a Fast Halo Coronal Mass Ejection'.   An interplanetary (IP) type-II-like radio burst is analyzed. It occurred on 2003 June 17-18 in association with a fast halo coronal mass ejection (CME), an M6.8 soft-X-ray (SXR) flare, and produced a solar proton event. Unlike coronal type II bursts and the ma jority of IP type II radio emissions, the IP type-II-like event associated with the fast halo CME on June 17-18 varies smoothly in time and frequency and has a frequency bandwidth that is several times larger than is typical for coronal and IP type II emissions. Moreover, the frequency change with time is inconsistent with that expected from plasma radiation associated with a CME-driven shock. I suggest that this IP type-II-like event, referred to here as an IP type II-S event, is not due to plasma radiation but, rather, incoherent synchrotron radiation from near-relativistic electrons entrained in the CME magnetic field, or in the sheath region between the shock and the CME driver. This event may be an example of a new and distinct class of interplanetary radio phenomenon.  ", "human_text": "  An interplanetary (IP) type-II-like radio burst is analyzed. It occurred on 2003 June 17-18 in association with a fast halo coronal mass ejection (CME), an M6.8 soft-X-ray (SXR) flare, and produced a solar proton event. Unlike coronal type II bursts and the ma jority of IP type II radio emissions, the IP type-II-like event associated with the fast halo CME on June 17-18 varies smoothly in time and frequency and has a frequency bandwidth that is several times larger than is typical for coronal and IP type II emissions. Moreover, the frequency change with time is inconsistent with that expected from plasma radiation associated with a CME-driven shock. I suggest that this IP type-II-like event, referred to here as an IP type II-S event, is not due to plasma radiation but, rather, incoherent synchrotron radiation from near-relativistic electrons entrained in the CME magnetic field, or in the sheath region between the shock and the CME driver. This event may be an example of a new and distinct class of interplanetary radio phenomenon. ", "machine_text": " This article studies an interplanetary (IP) type-II-like radio burst which appeared on 2003 June 17-18 in connection to a fast halo coronal mass ejection (CME), an M6.8 soft-X-ray (SXR) flare, and a solar proton event. Unlike typical coronal type II bursts, this type-II-like event varied smoothly in time and frequency and had a frequency bandwidth significantly wider than the norm. Additionally, its frequency shift with time didn't fit with expectations of plasma radiation associated with a CME-driven shock. It is thus hypothesized that this so-called IP type II-S event stems not from plasma radiation, but from synchrotron radiation of near-relativistic electrons caught in the CME magnetic field or the sheath region between the shock and the CME driver. Thus, this event could be representative of an altogether new type of interplanetary radio phenomenon.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3108}
{"prompt": "Rephrase the abstract of an article with title 'Modeling Heterogeneous Materials via Two-Point Correlation Functions: I.   Basic Principles'.   Heterogeneous materials abound in nature and man-made situations. Examples include porous media, biological materials, and composite materials. Diverse and interesting properties exhibited by these materials result from their complex microstructures, which also make it difficult to model the materials. In this first part of a series of two papers, we collect the known necessary conditions on the standard two-point correlation function S2(r) and formulate a new conjecture. In particular, we argue that given a complete two-point correlation function space, S2(r) of any statistically homogeneous material can be expressed through a map on a selected set of bases of the function space. We provide new examples of realizable two-point correlation functions and suggest a set of analytical basis functions. Moreover, we devise an efficient and isotropy- preserving construction algorithm, namely, the Lattice-Point algorithm to generate realizations of materials from their two- point correlation functions based on the Yeong-Torquato technique. Subsequent analysis can be performed on the generated images to obtain desired macroscopic properties. These developments are integrated here into a general scheme that enables one to model and categorize heterogeneous materials via two-point correlation functions.  ", "human_text": "  Heterogeneous materials abound in nature and man-made situations. Examples include porous media, biological materials, and composite materials. Diverse and interesting properties exhibited by these materials result from their complex microstructures, which also make it difficult to model the materials. In this first part of a series of two papers, we collect the known necessary conditions on the standard two-point correlation function S2(r) and formulate a new conjecture. In particular, we argue that given a complete two-point correlation function space, S2(r) of any statistically homogeneous material can be expressed through a map on a selected set of bases of the function space. We provide new examples of realizable two-point correlation functions and suggest a set of analytical basis functions. Moreover, we devise an efficient and isotropy- preserving construction algorithm, namely, the Lattice-Point algorithm to generate realizations of materials from their two- point correlation functions based on the Yeong-Torquato technique. Subsequent analysis can be performed on the generated images to obtain desired macroscopic properties. These developments are integrated here into a general scheme that enables one to model and categorize heterogeneous materials via two-point correlation functions. ", "machine_text": "This article presents a new method for modeling heterogeneous materials with two-point correlation functions. Necessary conditions on the two-point correlation function S2(r) are set out, and a conjecture is formulated. Realizable two-point correlation functions and analytical basis functions are provided and a construction algorithm, the Lattice-Point algorithm, is devised to generate materials from two-point correlation functions based on the Yeong-Torquato technique. This technique can be used to categorize and analyze these materials in terms of their macroscopic properties.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2434}
{"prompt": "Rephrase the abstract of an article with title 'The lower mass function of the young open cluster Blanco 1: from 30 Mjup   to 3 Mo'.   We performed a deep wide field optical survey of the young (~100-150 Myr) open cluster Blanco1 to study its low mass population well down into the brown dwarf regime and estimate its mass function over the whole cluster mass range.The survey covers 2.3 square degrees in the I and z-bands down to I ~ z ~ 24 with the CFH12K camera. Considering two different cluster ages (100 and 150 Myr), we selected cluster member candidates on the basis of their location in the (I,I-z) CMD relative to the isochrones, and estimated the contamination by foreground late-type field dwarfs using statistical arguments, infrared photometry and low-resolution optical spectroscopy. We find that our survey should contain about 57% of the cluster members in the 0.03-0.6 Mo mass range, including 30-40 brown dwarfs. The candidate's radial distribution presents evidence that mass segregation has already occured in the cluster. We took it into account to estimate the cluster mass function across the stellar/substellar boundary. We find that, between 0.03Mo and 0.6Mo, the cluster mass distribution does not depend much on its exact age, and is well represented by a single power-law, with an index alpha=0.69 +/- 0.15. Over the whole mass domain, from 0.03Mo to 3Mo, the mass function is better fitted by a log-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06. Comparison between the Blanco1 mass function, other young open clusters' MF, and the galactic disc MF suggests that the IMF, from the substellar domain to the higher mass part, does not depend much on initial conditions. We discuss the implications of this result on theories developed to date to explain the origin of the mass distribution.  ", "human_text": "  We performed a deep wide field optical survey of the young (~100-150 Myr) open cluster Blanco1 to study its low mass population well down into the brown dwarf regime and estimate its mass function over the whole cluster mass range.The survey covers 2.3 square degrees in the I and z-bands down to I ~ z ~ 24 with the CFH12K camera. Considering two different cluster ages (100 and 150 Myr), we selected cluster member candidates on the basis of their location in the (I,I-z) CMD relative to the isochrones, and estimated the contamination by foreground late-type field dwarfs using statistical arguments, infrared photometry and low-resolution optical spectroscopy. We find that our survey should contain about 57% of the cluster members in the 0.03-0.6 Mo mass range, including 30-40 brown dwarfs. The candidate's radial distribution presents evidence that mass segregation has already occured in the cluster. We took it into account to estimate the cluster mass function across the stellar/substellar boundary. We find that, between 0.03Mo and 0.6Mo, the cluster mass distribution does not depend much on its exact age, and is well represented by a single power-law, with an index alpha=0.69 +/- 0.15. Over the whole mass domain, from 0.03Mo to 3Mo, the mass function is better fitted by a log-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06. Comparison between the Blanco1 mass function, other young open clusters' MF, and the galactic disc MF suggests that the IMF, from the substellar domain to the higher mass part, does not depend much on initial conditions. We discuss the implications of this result on theories developed to date to explain the origin of the mass distribution. ", "machine_text": " We conducted a wide-area survey of the young (~100-150 Myr) open cluster, Blanco1, with the CFH12K camera, in order to gain insight into its low-mass population and to measure its mass function across the stellar/substellar boundary. Using this data and a statistical approach, along with infrared photometry and optical spectroscopy, we identified 57% of Blanco1's cluster members in the range 0.03-0.6 Mo, including 30-40 brown dwarfs. Our findings indicate that mass segregation may have occurred in the cluster, and we incorporated this into our analysis of the mass distribution, which was well-fitted by a single power-law with an index of alpha=0.69 +/- 0.15 over the range 0.03Mo to 0.6Mo, and a log-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06 throughout an even greater mass domain from 0.03Mo to 3Mo. Through comparisons of the Blanco1 mass function with those of other young open clusters and the galactic disc, we produced evidence that the initial mass function (IMF) need not be reliant on established conditions. We discussed the implications that this has on various theories concerning the origin of the mass distribution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2102}
{"prompt": "Rephrase the abstract of an article with title 'The Physics Case for the New Muon (g-2) Experiment'.   This White Paper briefly reviews the present status of the muon (g-2) experiment and the physics motivation for a new effort. The present comparison between experiment and theory indicates a tantalizing $3.4 \\sigma$ deviation. An improvement in precision on this comparison by a factor of 2--with the central value remaining unchanged--will exceed the ``discovery'' threshold, with a sensitivity above $6 \\sigma$. The 2.5-fold reduction improvement goal of the new Brookhaven E969 experiment, along with continued steady reduction of the standard model theory uncertainty, will achieve this more definitive test.   Already, the (g-2) result is arguably the most compelling indicator of physics beyond the standard model and, at the very least, it represents a major constraint for speculative new theories such as supersymmetry or extra dimensions. In this report, we summarize the present experimental status and provide an up-to-date accounting of the standard model theory, including the expectations for improvement in the hadronic contributions, which dominate the overall uncertainty. Our primary focus is on the physics case that motivates improved experimental and theoretical efforts. Accordingly, we give examples of specific new-physics implications in the context of direct searches at the LHC as well as general arguments about the role of an improved (g-2) measurement. A brief summary of the plans for an upgraded effort complete the report.  ", "human_text": "  This White Paper briefly reviews the present status of the muon (g-2) experiment and the physics motivation for a new effort. The present comparison between experiment and theory indicates a tantalizing $3.4 \\sigma$ deviation. An improvement in precision on this comparison by a factor of 2--with the central value remaining unchanged--will exceed the ``discovery'' threshold, with a sensitivity above $6 \\sigma$. The 2.5-fold reduction improvement goal of the new Brookhaven E969 experiment, along with continued steady reduction of the standard model theory uncertainty, will achieve this more definitive test.   Already, the (g-2) result is arguably the most compelling indicator of physics beyond the standard model and, at the very least, it represents a major constraint for speculative new theories such as supersymmetry or extra dimensions. In this report, we summarize the present experimental status and provide an up-to-date accounting of the standard model theory, including the expectations for improvement in the hadronic contributions, which dominate the overall uncertainty. Our primary focus is on the physics case that motivates improved experimental and theoretical efforts. Accordingly, we give examples of specific new-physics implications in the context of direct searches at the LHC as well as general arguments about the role of an improved (g-2) measurement. A brief summary of the plans for an upgraded effort complete the report. ", "machine_text": "This paper reviews the present condition and physics background of the muon (g-2) experiment, noting a noteworthy disagreement between the experiment and theories of 3.4 standard deviations. A new Brookhaven E969 experiment is planned with the aim of determining a more detailed examination of this discrepancy by shrinking the margin of error by up to a factor of two while still preserving the central value. This article also outlines possible theories beyond the Standard Model, and precisely how a more accurate assessment of (g-2) can give greater insight into these theories and findings from the Large Hadron Collider. Ultimately, this paper sketches the plans for a more advanced experiment and offers a compelling case for the physics behind it.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4617}
{"prompt": "Rephrase the abstract of an article with title 'Surface plasmon polaritons and surface phonon polaritons on metallic and   semiconducting spheres: Exact and semiclassical descriptions'.   We study the interaction of an electromagnetic field with a non-absorbing or absorbing dispersive sphere in the framework of complex angular momentum techniques. We assume that the dielectric function of the sphere presents a Drude-like behavior or an ionic crystal behavior modelling metallic and semiconducting materials. We more particularly emphasize and interpret the modifications induced in the resonance spectrum by absorption. We prove that \"resonant surface polariton modes\" are generated by a unique surface wave, i.e., a surface (plasmon or phonon) polariton, propagating close to the sphere surface. This surface polariton corresponds to a particular Regge pole of the electric part (TM) of the S matrix of the sphere. From the associated Regge trajectory we can construct semiclassically the spectrum of the complex frequencies of the resonant surface polariton modes which can be considered as Breit-Wigner-type resonances. Furthermore, by taking into account the Stokes phenomenon, we derive an asymptotic expression for the position in the complex angular momentum plane of the surface polariton Regge pole. We then describe semiclassically the surface polariton and provide analytical expressions for its dispersion relation and its damping in the non-absorbing and absorbing cases. In these analytic expressions, we more particularly exhibit well-isolated terms directly linked to absorption. Finally, we explain why the photon-sphere system can be considered as an artificial atom (a ``plasmonic atom\" or \"phononic atom\") and we briefly discuss the implication of our results in the context of the Casimir effect.  ", "human_text": "  We study the interaction of an electromagnetic field with a non-absorbing or absorbing dispersive sphere in the framework of complex angular momentum techniques. We assume that the dielectric function of the sphere presents a Drude-like behavior or an ionic crystal behavior modelling metallic and semiconducting materials. We more particularly emphasize and interpret the modifications induced in the resonance spectrum by absorption. We prove that \"resonant surface polariton modes\" are generated by a unique surface wave, i.e., a surface (plasmon or phonon) polariton, propagating close to the sphere surface. This surface polariton corresponds to a particular Regge pole of the electric part (TM) of the S matrix of the sphere. From the associated Regge trajectory we can construct semiclassically the spectrum of the complex frequencies of the resonant surface polariton modes which can be considered as Breit-Wigner-type resonances. Furthermore, by taking into account the Stokes phenomenon, we derive an asymptotic expression for the position in the complex angular momentum plane of the surface polariton Regge pole. We then describe semiclassically the surface polariton and provide analytical expressions for its dispersion relation and its damping in the non-absorbing and absorbing cases. In these analytic expressions, we more particularly exhibit well-isolated terms directly linked to absorption. Finally, we explain why the photon-sphere system can be considered as an artificial atom (a ``plasmonic atom\" or \"phononic atom\") and we briefly discuss the implication of our results in the context of the Casimir effect. ", "machine_text": " This paper examines the influence of electromagnetic fields on non-absorbent or absorbent dispersed spheres, exploring Drude-like and ionic crystal behaviours in particular. The observation of resonance spectrums and surface polariton modes are detailed, alongside Breit-Wigner-type resonances and Stokes phenomena. Analytic expressions are provided for the dispersion relation, damping and absorption of surface polaritons. Analogies are made to artificial atoms, and implications for the Casimir effect are outlined.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4212}
{"prompt": "Rephrase the abstract of an article with title 'The Thurston norm via Normal Surfaces'.   Given a triangulation of a closed, oriented, irreducible, atoroidal 3-manifold every oriented, incompressible surface may be isotoped into normal position relative to the triangulation. Such a normal oriented surface is then encoded by non-negative integer weights, 14 for each 3-simplex, that describe how many copies of each oriented normal disc type there are. The Euler characteristic and homology class are both linear functions of the weights. There is a convex polytope in the space of weights, defined by linear equations given by the combinatorics of the triangulation, whose image under the homology map is the unit ball, B, of the Thurston norm.   Applications of this approach include (1) an algorithm to compute B and hence the Thurston norm of any homology class, (2) an explicit exponential bound on the number of vertices of B in terms of the number of simplices in the triangulation, (3) an algorithm to determine the fibred faces of B and hence an algorithm to decide whether a 3-manifold fibres over the circle.  ", "human_text": "  Given a triangulation of a closed, oriented, irreducible, atoroidal 3-manifold every oriented, incompressible surface may be isotoped into normal position relative to the triangulation. Such a normal oriented surface is then encoded by non-negative integer weights, 14 for each 3-simplex, that describe how many copies of each oriented normal disc type there are. The Euler characteristic and homology class are both linear functions of the weights. There is a convex polytope in the space of weights, defined by linear equations given by the combinatorics of the triangulation, whose image under the homology map is the unit ball, B, of the Thurston norm.   Applications of this approach include (1) an algorithm to compute B and hence the Thurston norm of any homology class, (2) an explicit exponential bound on the number of vertices of B in terms of the number of simplices in the triangulation, (3) an algorithm to determine the fibred faces of B and hence an algorithm to decide whether a 3-manifold fibres over the circle. ", "machine_text": " Using a given triangulation for a closed, orientable, irreducible, atoroidal 3-manifold, we define an encoding of each normal, oriented surface using non-negative integer weights and use this to construct a convex polytope in the relevant space of weights which maps to the unit-ball of the Thurston norm via a linear homology map. This has several applications, including a linear-time algorithm to compute the Thurston norm and intricate upper-bounds on the number of vertices of the polytope in terms of the number of simplices. Moreover, one can efficiently decide if a 3-manifold stems from a fibred face of the polytope in order to determine if the 3-manifold is capable of fibreing over the circle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0673}
{"prompt": "Rephrase the abstract of an article with title 'A Cascade Model for Particle Concentration and Enstrophy in Fully   Developed Turbulence with Mass Loading Feedback'.   A cascade model is described based on multiplier distributions determined from 3D direct numerical simulations (DNS) of turbulent particle laden flows, which include two-way coupling between the phases at global mass loadings equal to unity. The governing Eulerian equations are solved using pseudo-spectral methods on up to 512**3 computional grid points. DNS results for particle concentration and enstrophy at Taylor microscale Reynolds numbers in the range 34 - 170 were used to directly determine multiplier distributions (PDFs) on spatial scales 3 times the Kolmogorov length scale. The width of the PDFs, which is a measure of intermittency, decreases with increasing mass loading within the local region where the multipliers are measured. The functional form of this dependence is not sensitive to Reynolds numbers in the range considered. A partition correlation probability is included in the cascade model to account for the observed spatial anticorrelation between particle concentration and enstrophy. Joint probability distribution functions of concentration and enstrophy generated using the cascade model are shown to be in excellent agreement with those derived directly from our 3D simulations. Probabilities predicted by the cascade model are presented at Reynolds numbers well beyond what is achievable by direct simulation. These results clearly indicate that particle mass loading significantly reduces the probabilities of high particle concentration and enstrophy relative to those resulting from unloaded runs. Particle mass density appears to reach a limit at around 100 times the gas density. This approach has promise for significant computational savings in certain applications.  ", "human_text": "  A cascade model is described based on multiplier distributions determined from 3D direct numerical simulations (DNS) of turbulent particle laden flows, which include two-way coupling between the phases at global mass loadings equal to unity. The governing Eulerian equations are solved using pseudo-spectral methods on up to 512**3 computional grid points. DNS results for particle concentration and enstrophy at Taylor microscale Reynolds numbers in the range 34 - 170 were used to directly determine multiplier distributions (PDFs) on spatial scales 3 times the Kolmogorov length scale. The width of the PDFs, which is a measure of intermittency, decreases with increasing mass loading within the local region where the multipliers are measured. The functional form of this dependence is not sensitive to Reynolds numbers in the range considered. A partition correlation probability is included in the cascade model to account for the observed spatial anticorrelation between particle concentration and enstrophy. Joint probability distribution functions of concentration and enstrophy generated using the cascade model are shown to be in excellent agreement with those derived directly from our 3D simulations. Probabilities predicted by the cascade model are presented at Reynolds numbers well beyond what is achievable by direct simulation. These results clearly indicate that particle mass loading significantly reduces the probabilities of high particle concentration and enstrophy relative to those resulting from unloaded runs. Particle mass density appears to reach a limit at around 100 times the gas density. This approach has promise for significant computational savings in certain applications. ", "machine_text": " A cascade model is developed for particle concentration and enstrophy in fully developed turbulence with mass loading feedback, assessed using 3D direct numerical simulations. The governing Eulerian equations are solved using pseudo-spectral methods on up to 512**3 grid points, and the resultant multiplier distributions, which present a measure of intermittency, decrease with increasing mass loading within the local region where the multipliers are measured. A partition correlation probability is proposed to account for the spatial anticorrelation between particle concentration and enstrophy, and joint probability distribution functions of concentration and enstrophy produced by the cascade model are found to correlate closely with those determined directly from the simulations. Probabilities are also predicted at Reynolds numbers well beyond direct simulation capability, indicating that particle mass loading decreases the probability of high concentrations and enstrophy relative to unloaded runs. It is concluded that this model may enable significant computational savings in certain applications, and suggests a particle mass density threshold of around 100 times the gas density.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.181}
{"prompt": "Rephrase the abstract of an article with title 'Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale   bar funnelling gas into the nuclear region'.   This work is part of the NUGA survey of CO emission in nearby active galaxies. We present observations of NGC4569, a member of the Virgo Cluster. We analyse the molecular gas distribution and kinematics in the central region and we investigate a possible link to the strong starburst present at the nucleus. 70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is found to be concentrated within the inner 800 pc and is distributed along the large scale stellar bar seen in near-infrared observations. A hole in the CO distribution coincides with the nucleus where most of the Halpha emission and blue light are emitted. The kinematics are modelled in three different ways, ranging from the purely geometrical to the most physical. This approach allows us to constrain progressively the physical properties of the galaxy and eventually to emerge with a reasonable fit to an analytical model of orbits in a barred potential. Fitting an axisymmetric model shows that the non-circular motions must be comparable in amplitude to the circular motions (120 km/s). Fitting a model based on elliptical orbits allows us to identify with confidence the single inner Lindblad resonance (ILR) of the large scale bar. Finally, a model based on analytical solutions for the gas particle orbits in a weakly barred potential constrained by the ILR radius reproduces the observations well. The mass inflow rate is then estimated and discussed based on the best fit model solution. The gravitational torques implied by this model are able to efficiently funnel the gas inside the ILR down to 300 pc, although another mechanism must take over to fuel the nuclear starburst inside 100 pc.  ", "human_text": "  This work is part of the NUGA survey of CO emission in nearby active galaxies. We present observations of NGC4569, a member of the Virgo Cluster. We analyse the molecular gas distribution and kinematics in the central region and we investigate a possible link to the strong starburst present at the nucleus. 70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is found to be concentrated within the inner 800 pc and is distributed along the large scale stellar bar seen in near-infrared observations. A hole in the CO distribution coincides with the nucleus where most of the Halpha emission and blue light are emitted. The kinematics are modelled in three different ways, ranging from the purely geometrical to the most physical. This approach allows us to constrain progressively the physical properties of the galaxy and eventually to emerge with a reasonable fit to an analytical model of orbits in a barred potential. Fitting an axisymmetric model shows that the non-circular motions must be comparable in amplitude to the circular motions (120 km/s). Fitting a model based on elliptical orbits allows us to identify with confidence the single inner Lindblad resonance (ILR) of the large scale bar. Finally, a model based on analytical solutions for the gas particle orbits in a weakly barred potential constrained by the ILR radius reproduces the observations well. The mass inflow rate is then estimated and discussed based on the best fit model solution. The gravitational torques implied by this model are able to efficiently funnel the gas inside the ILR down to 300 pc, although another mechanism must take over to fuel the nuclear starburst inside 100 pc. ", "machine_text": " This work is part of the NUGA survey that examines the presence of molecular gas in nearby galaxies. In this paper, we analyse the observations of NGC4569, located in the Virgo Cluster, to investigate the correlation between the starburst at the nucleus and the molecular gas content. We find that 70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is concentrated in the area of 800 pc or less and is evenly distributed along the long-scale stellar bar in the near-infrared images. The gap in the CO distribution matches the nucleus, where most of the Halpha and blue light emissions arise. To obtain better understanding of the galaxy's physical characteristics, we use three models to measure the kinematics of the gas: a pure geometrical one, one based on elliptical orbits, and one using analytical solutions of orbits in a slightly barred potential. We then calculate the mass inflow rate from the most accurate model. The data suggests that the gravitational tugs from the large scale bar can funnel gas from the inner Lindblad Resonance down to a distance of 300 pc. However, another mechanism may be necessary to fuel the starburst at 100 pc or less.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3662}
{"prompt": "Rephrase the abstract of an article with title 'The dynamics of the early universe and the initial conditions for   inflation in a model with radiation and a Chaplygin gas'.   The modeling of the early universe is done through the quantization of a Friedmann-Robertson-Walker model with positive curvature. The material content consists of two fluids: radiation and Chaplygin gas. The quantization of these models is made by following the Wheeler and DeWitt's prescriptions. Using the Schutz formalism, the time notion is recovered and the Wheeler-DeWitt equation transforms into a time dependent Schr\\\"{o}dinger equation, which rules the dynamics of the early universe, under the action of an effective potential $V_{ef}$. Using a finite differences method and the Crank-Nicholson scheme, in a code implemented in the program OCTAVE, we solve the corresponding time dependent Schr\\\"{o}dinger equation and obtain the time evolution of a initial wave packet. This wave packet satisfies appropriate boundary conditions. The calculation of the tunneling probabilities shows that the universe may emerge from the Planck era to an inflationary phase. It also shows that, the tunneling probability is a function of the mean energy of the initial wave packet and of two parameters related to the Chaplygin gas. We also show a comparison between these results and those obtained by the WKB approximation.  ", "human_text": "  The modeling of the early universe is done through the quantization of a Friedmann-Robertson-Walker model with positive curvature. The material content consists of two fluids: radiation and Chaplygin gas. The quantization of these models is made by following the Wheeler and DeWitt's prescriptions. Using the Schutz formalism, the time notion is recovered and the Wheeler-DeWitt equation transforms into a time dependent Schr\\\"{o}dinger equation, which rules the dynamics of the early universe, under the action of an effective potential $V_{ef}$. Using a finite differences method and the Crank-Nicholson scheme, in a code implemented in the program OCTAVE, we solve the corresponding time dependent Schr\\\"{o}dinger equation and obtain the time evolution of a initial wave packet. This wave packet satisfies appropriate boundary conditions. The calculation of the tunneling probabilities shows that the universe may emerge from the Planck era to an inflationary phase. It also shows that, the tunneling probability is a function of the mean energy of the initial wave packet and of two parameters related to the Chaplygin gas. We also show a comparison between these results and those obtained by the WKB approximation. ", "machine_text": " A Friedmann-Robertson-Walker model with positive curvature is employed to understand the dynamics of the early universe and the initial conditions for inflation. This particular model contains two fluids, radiation and a Chaplygin gas, and is quantized using the Wheeler-DeWitt prescriptions. The Schutz formalism permits the transformation of the Wheeler-DeWitt equation into a time-dependent Schr\\\"{o}dinger equation, the dynamics of which can be described by an effective potential $V_{ef}$. Using a code implemented in OCTAVE and finite differences method, the time-dependent Schr\\\"{o}dinger equation can be solved and the time evolution of an initial wave packet determined. The wave packet satisfies appropriate boundary conditions and the calculation of tunneling probabilities shows that the universe may transition from the Planck era to an inflationary phase. The tunneling probability can further be affected by the mean energy of the initial wave packet and two parameters related to the Chaplygin gas, and these results are verified by the WKB approximation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2585}
{"prompt": "Rephrase the abstract of an article with title 'A Systematic Study of the Final Masses of Gas Giant Planets'.   We construct an analytic model for the rate of gas accretion onto a planet embedded in a protoplanetary disk as a function of planetary mass, disk viscosity, disk scale height, and unperturbed surface density in order to study the long-term accretion and final masses of gas giant planets. We first derive an analytical formula for surface density profile near the planetary orbit from considerations of the balance of force and the dynamical stability. Using it in the empirical formula linking surface density with gas accretion rate that is derived based on hydrodynamic simulations of Tanigawa and Watanabe (2002, ApJ 586, 506), we then simulate the mass evolution of gas giant planets in viscously-evolving disks. We finally determine the final mass as a function of semi-major axis of the planet. We find that the disk can be divided into three regions characterized by different processes by which the final mass is determined. In the inner region, the planet grows quickly and forms a deep gap to suppress the growth by itself before disk dissipation. The final mass of the planet in this region is found to increase with the semi-major axis in a similar way to the mass given by the viscous condition for gap opening, but the former is larger by a factor of approximately 10 than the latter. In the intermediate region, viscous diffusion of the disk gas limits the gas accretion before the planet form a deep gap. The final mass can be up to the disk mass, when disk viscous evolution occurs faster than disk evaporation. In the outer region, planets capture only tiny amounts of gas within the lifetime of the disk to form Neptune-like planets. We derive analytic formulae for the final masses in the different regions and the locations of the boundaries, which are helpful to gain a systematic understanding of the masses of gas giant planets.  ", "human_text": "  We construct an analytic model for the rate of gas accretion onto a planet embedded in a protoplanetary disk as a function of planetary mass, disk viscosity, disk scale height, and unperturbed surface density in order to study the long-term accretion and final masses of gas giant planets. We first derive an analytical formula for surface density profile near the planetary orbit from considerations of the balance of force and the dynamical stability. Using it in the empirical formula linking surface density with gas accretion rate that is derived based on hydrodynamic simulations of Tanigawa and Watanabe (2002, ApJ 586, 506), we then simulate the mass evolution of gas giant planets in viscously-evolving disks. We finally determine the final mass as a function of semi-major axis of the planet. We find that the disk can be divided into three regions characterized by different processes by which the final mass is determined. In the inner region, the planet grows quickly and forms a deep gap to suppress the growth by itself before disk dissipation. The final mass of the planet in this region is found to increase with the semi-major axis in a similar way to the mass given by the viscous condition for gap opening, but the former is larger by a factor of approximately 10 than the latter. In the intermediate region, viscous diffusion of the disk gas limits the gas accretion before the planet form a deep gap. The final mass can be up to the disk mass, when disk viscous evolution occurs faster than disk evaporation. In the outer region, planets capture only tiny amounts of gas within the lifetime of the disk to form Neptune-like planets. We derive analytic formulae for the final masses in the different regions and the locations of the boundaries, which are helpful to gain a systematic understanding of the masses of gas giant planets. ", "machine_text": " This paper focuses on understanding how the final mass of gas giant planets is determined in protoplanetary disks. To address this issue, we construct an analytical model which relates the rate of gas accretion onto a planet to the planetary mass, disk viscosity, disk scale height and unperturbed surface density in the disk. Furthermore, utilizing an empirical formula relating surface density and gas accretion rate derived from hydrodynamical simulations of Tanigawa and Watanabe (2002), we carry out a series of simulations analyzing the mass evolution of gas giant planets in viscous disks. Our results indicate that the disk can be divided into three regions, each with its own process for determining the planet's final mass. In the inner region, the planet rapidly reaches a limit before the disk dissipates, with the final mass larger than the mass given by the viscous condition for gap-opening by a factor of 10. In the intermediate region, the gas accretion onto the planet is limited by viscous diffusion while in the outer region, planets capture only minimal amounts of gas to form Neptune-like planets. We provide analytical formulae for the final masses and the boundaries in these regions, allowing for a systematic understanding of the masses of gas giant planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4343}
{"prompt": "Rephrase the abstract of an article with title 'The power of choice in network growth'.   The \"power of choice\" has been shown to radically alter the behavior of a number of randomized algorithms. Here we explore the effects of choice on models of tree and network growth. In our models each new node has k randomly chosen contacts, where k > 1 is a constant. It then attaches to whichever one of these contacts is most desirable in some sense, such as its distance from the root or its degree. Even when the new node has just two choices, i.e., when k=2, the resulting network can be very different from a random graph or tree. For instance, if the new node attaches to the contact which is closest to the root of the tree, the distribution of depths changes from Poisson to a traveling wave solution. If the new node attaches to the contact with the smallest degree, the degree distribution is closer to uniform than in a random graph, so that with high probability there are no nodes in the network with degree greater than O(log log N). Finally, if the new node attaches to the contact with the largest degree, we find that the degree distribution is a power law with exponent -1 up to degrees roughly equal to k, with an exponential cutoff beyond that; thus, in this case, we need k >> 1 to see a power law over a wide range of degrees.  ", "human_text": "  The \"power of choice\" has been shown to radically alter the behavior of a number of randomized algorithms. Here we explore the effects of choice on models of tree and network growth. In our models each new node has k randomly chosen contacts, where k > 1 is a constant. It then attaches to whichever one of these contacts is most desirable in some sense, such as its distance from the root or its degree. Even when the new node has just two choices, i.e., when k=2, the resulting network can be very different from a random graph or tree. For instance, if the new node attaches to the contact which is closest to the root of the tree, the distribution of depths changes from Poisson to a traveling wave solution. If the new node attaches to the contact with the smallest degree, the degree distribution is closer to uniform than in a random graph, so that with high probability there are no nodes in the network with degree greater than O(log log N). Finally, if the new node attaches to the contact with the largest degree, we find that the degree distribution is a power law with exponent -1 up to degrees roughly equal to k, with an exponential cutoff beyond that; thus, in this case, we need k >> 1 to see a power law over a wide range of degrees. ", "machine_text": "  The effects of introducing choice into tree and network growth models are studied in this paper. At each step, the newly introduced node connects to one of its k randomly chosen contacts, chosen based on some criterion, such as distance to the root or degree. We find that even when k=2, the resulting network has notable differences from a regular random graph or tree. For instance, if the new node attaches to the nearest contact to the root, we observe an alteration of the depths distribution from Poisson to a traveling wave solution. Additionally, when the node attaches to the contact with the smallest degree, we observe the degree distribution is closer to uniform than in a random graph, and when the node attaches to the largest degree, the degree distribution is a power law with exponent -1 up until k degrees, followed by an exponential cutoff. Consequently, large k values are necessary to observe a power law over a wide degree range.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1882}
{"prompt": "Rephrase the abstract of an article with title 'Constraining dark energy via baryon acoustic oscillations in the   (an)isotropic light-cone power spectrum'.   The measurement of the scale of the baryon acoustic oscillations (BAO) in the galaxy power spectrum as a function of redshift is a promising method to constrain the equation-of-state parameter of the dark energy w. To measure the scale of the BAO precisely, a substantial volume of space must be surveyed. We test whether light-cone effects are important and whether the scaling relations used to compensate for an incorrect reference cosmology are in this case sufficiently accurate. We investigate the degeneracies in the cosmological parameters and the benefits of using the two-dimensional anisotropic power spectrum. Finally, we estimate the uncertainty with which w can be measured by proposed surveys at redshifts of about z=3 and z=1, respectively.   In the simulated survey we find that light-cone effects are small and that the simple scaling relations used to correct for the cosmological distortion work fairly well even for large survey volumes. The analysis of the two-dimensional anisotropic power spectra enables an independent determination to be made of the apparent scale of the BAO, perpendicular and parallel to the line of sight. This is essential for two-parameter w-models, such as the redshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for the matter and baryon density and Delta(H_0)=5% for the Hubble constant, we estimate that the BAO measurements of future surveys around z=3 and z=1 will be able to constrain, independently of other cosmological probes, a constant w to ~ 12% and ~ 11% (68% c.l.), respectively.  ", "human_text": "  The measurement of the scale of the baryon acoustic oscillations (BAO) in the galaxy power spectrum as a function of redshift is a promising method to constrain the equation-of-state parameter of the dark energy w. To measure the scale of the BAO precisely, a substantial volume of space must be surveyed. We test whether light-cone effects are important and whether the scaling relations used to compensate for an incorrect reference cosmology are in this case sufficiently accurate. We investigate the degeneracies in the cosmological parameters and the benefits of using the two-dimensional anisotropic power spectrum. Finally, we estimate the uncertainty with which w can be measured by proposed surveys at redshifts of about z=3 and z=1, respectively.   In the simulated survey we find that light-cone effects are small and that the simple scaling relations used to correct for the cosmological distortion work fairly well even for large survey volumes. The analysis of the two-dimensional anisotropic power spectra enables an independent determination to be made of the apparent scale of the BAO, perpendicular and parallel to the line of sight. This is essential for two-parameter w-models, such as the redshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for the matter and baryon density and Delta(H_0)=5% for the Hubble constant, we estimate that the BAO measurements of future surveys around z=3 and z=1 will be able to constrain, independently of other cosmological probes, a constant w to ~ 12% and ~ 11% (68% c.l.), respectively. ", "machine_text": " Baryon acoustic oscillations (BAO) of the galaxy power spectrum could be used to tightly constrain the properties of dark energy given an observed large enough space volume. This study examines projected light-cone effects and the use of scaling relations for an incorrect cosmological reference. Furthermore, the cosmological degeneracies and the use of anisotropic two-dimensional power spectra are explored. The goodness of the measurements depended highly on the assumed values of matter and baryon density, as well as the Hubble rate. The BAO data from upcoming surveys around redshifts z=3 and z=1 were used to estimate that a constant dark energy equation-of-state w can be constrained to ~12% and ~11% at the 68% c.l., respectively; when Planck priors and a Delta(H_0) of 5% are used.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0354}
{"prompt": "Rephrase the abstract of an article with title 'Positivity and almost positivity of biharmonic Green's functions under   Dirichlet boundary conditions'.   In general, for higher order elliptic equations and boundary value problems like the biharmonic equation and the linear clamped plate boundary value problem neither a maximum principle nor a comparison principle or -- equivalently -- a positivity preserving property is available. The problem is rather involved since the clamped boundary conditions prevent the boundary value problem {from} being reasonably written as a system of second order boundary value problems.   It is shown that, on the other hand, for bounded smooth domains $\\Omega \\subset\\mathbb{R}^n$, the negative part of the corresponding Green's function is \"small\" when compared with its singular positive part, provided $n\\ge 3$.   Moreover, the biharmonic Green's function in balls $B\\subset\\mathbb{R}^n$ under Dirichlet (i.e. clamped) boundary conditions is known explicitly and is positive. It has been known for some time that positivity is preserved under small regular perturbations of the domain, if $n=2$. In the present paper, such a stability result is proved for $n\\ge 3$. Keywords: Biharmonic Green's functions, positivity, almost positivity, blow-up procedure.  ", "human_text": "  In general, for higher order elliptic equations and boundary value problems like the biharmonic equation and the linear clamped plate boundary value problem neither a maximum principle nor a comparison principle or -- equivalently -- a positivity preserving property is available. The problem is rather involved since the clamped boundary conditions prevent the boundary value problem {from} being reasonably written as a system of second order boundary value problems.   It is shown that, on the other hand, for bounded smooth domains $\\Omega \\subset\\mathbb{R}^n$, the negative part of the corresponding Green's function is \"small\" when compared with its singular positive part, provided $n\\ge 3$.   Moreover, the biharmonic Green's function in balls $B\\subset\\mathbb{R}^n$ under Dirichlet (i.e. clamped) boundary conditions is known explicitly and is positive. It has been known for some time that positivity is preserved under small regular perturbations of the domain, if $n=2$. In the present paper, such a stability result is proved for $n\\ge 3$. Keywords: Biharmonic Green's functions, positivity, almost positivity, blow-up procedure. ", "machine_text": " This paper examines the positivity and near-positivity of biharmonic Green's function with Dirichlet boundary conditions. When higher order elliptic equations and boundary value problems such as the biharmonic equation and the linear clamped plate boundary value problem are considered, a maximum principle, comparison principle, or positivity are not available. This is due to the clamped boundary conditions not allowing the boundary value problem to be thoroughly written as a system of second order boundary value problems. It is revealed, however, that for bounded domains $\\Omega\\subset\\mathbb{R}^n$, with $n\\ge 3$, the negative portion of the Green's function is minor compared to its singular positive portion. Additionally, the biharmonic Green's function for balls $B\\subset\\mathbb{R}^n$ has been proven to be positive under Dirichlet boundary conditions, and is known explicitly. It has been known for some time that the perturbations of the domain in two-dimensions lead to positivity being preserved, and the present study shows this to be true for any $n\\ge 3$ as well.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3301}
{"prompt": "Rephrase the abstract of an article with title 'Radial density profiles of time-delay lensing galaxies'.   We present non-parametric radial mass profiles for ten QSO strong lensing galaxies. Five of the galaxies have profiles close to $\\rho(r)\\propto r^{-2}$, while the rest are closer to r^{-1}, consistent with an NFW profile. The former are all relatively isolated early-types and dominated by their stellar light. The latter --though the modeling code did not know this-- are either in clusters, or have very high mass-to-light, suggesting dark-matter dominant lenses (one is a actually pair of merging galaxies). The same models give $H_0^{-1} = 15.2_{-1.7}^{+2.5}\\Gyr$ ($H_0 = 64_{-9}^{+8} \\legacy$), consistent with a previous determination. When tested on simulated lenses taken from a cosmological hydrodynamical simulation, our modeling pipeline recovers both H_0 and $\\rho(r)$ within estimated uncertainties. Our result is contrary to some recent claims that lensing time delays imply either a low H_0 or galaxy profiles much steeper than r^{-2}. We diagnose these claims as resulting from an invalid modeling approximation: that small deviations from a power-law profile have a small effect on lensing time-delays. In fact, as we show using using both perturbation theory and numerical computation from a galaxy-formation simulation, a first-order perturbation of an isothermal lens can produce a zeroth-order change in the time delays.  ", "human_text": "  We present non-parametric radial mass profiles for ten QSO strong lensing galaxies. Five of the galaxies have profiles close to $\\rho(r)\\propto r^{-2}$, while the rest are closer to r^{-1}, consistent with an NFW profile. The former are all relatively isolated early-types and dominated by their stellar light. The latter --though the modeling code did not know this-- are either in clusters, or have very high mass-to-light, suggesting dark-matter dominant lenses (one is a actually pair of merging galaxies). The same models give $H_0^{-1} = 15.2_{-1.7}^{+2.5}\\Gyr$ ($H_0 = 64_{-9}^{+8} \\legacy$), consistent with a previous determination. When tested on simulated lenses taken from a cosmological hydrodynamical simulation, our modeling pipeline recovers both H_0 and $\\rho(r)$ within estimated uncertainties. Our result is contrary to some recent claims that lensing time delays imply either a low H_0 or galaxy profiles much steeper than r^{-2}. We diagnose these claims as resulting from an invalid modeling approximation: that small deviations from a power-law profile have a small effect on lensing time-delays. In fact, as we show using using both perturbation theory and numerical computation from a galaxy-formation simulation, a first-order perturbation of an isothermal lens can produce a zeroth-order change in the time delays. ", "machine_text": " Through this study, we investigate the mass profiles of 10 quasar strong lensing galaxies. Five of the galaxies have density profiles that are similar to $r^{-2}$ while the other five are close to $r^{-1}$, which is similar to the NFW profile. The former lens samples are mainly isolated early-type galaxies with higher stellar mass, while the latter ones are either in clusters or have a high mass-to-light ratio, indicating that they are dominated by dark matter. Furthermore, the same models give an estimated value for the Hubble constant ($H_0$) of 64 $\\pm$ 9 (km/s)/Mpc. To determine accuracy, the same model was applied to simulated lenses from cosmological hydrodynamic simulations and it was observed that the calculated $H_0$ and radial density profiles were consistent with the expected results. This implies that several recent studies that suggested low values for $H_0$ and profiles much steeper than $r^{-2}$ may have used an inappropriate modeling approximation. Additionally, our analysis demonstrates that perturbations of an isothermal lens can lead to changes in time-delays at a zeroth order.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3267}
{"prompt": "Rephrase the abstract of an article with title 'A Unified Approach to Energy-Efficient Power Control in Large CDMA   Systems'.   A unified approach to energy-efficient power control is proposed for code-division multiple access (CDMA) networks. The approach is applicable to a large family of multiuser receivers including the matched filter, the decorrelator, the linear minimum mean-square error (MMSE) receiver, and the (nonlinear) optimal detectors. It exploits the linear relationship that has been shown to exist between the transmit power and the output signal-to-interference-plus-noise ratio (SIR) in the large-system limit. It is shown that, for this family of receivers, when users seek to selfishly maximize their own energy efficiency, the Nash equilibrium is SIR-balanced. In addition, a unified power control (UPC) algorithm for reaching the Nash equilibrium is proposed. The algorithm adjusts the user's transmit powers by iteratively computing the large-system multiuser efficiency, which is independent of instantaneous spreading sequences. The convergence of the algorithm is proved for the matched filter, the decorrelator, and the MMSE receiver, and is demonstrated by means of simulation for an optimal detector. Moreover, the performance of the algorithm in finite-size systems is studied and compared with that of a conventional power control scheme, in which user powers depend on the instantaneous spreading sequences.  ", "human_text": "  A unified approach to energy-efficient power control is proposed for code-division multiple access (CDMA) networks. The approach is applicable to a large family of multiuser receivers including the matched filter, the decorrelator, the linear minimum mean-square error (MMSE) receiver, and the (nonlinear) optimal detectors. It exploits the linear relationship that has been shown to exist between the transmit power and the output signal-to-interference-plus-noise ratio (SIR) in the large-system limit. It is shown that, for this family of receivers, when users seek to selfishly maximize their own energy efficiency, the Nash equilibrium is SIR-balanced. In addition, a unified power control (UPC) algorithm for reaching the Nash equilibrium is proposed. The algorithm adjusts the user's transmit powers by iteratively computing the large-system multiuser efficiency, which is independent of instantaneous spreading sequences. The convergence of the algorithm is proved for the matched filter, the decorrelator, and the MMSE receiver, and is demonstrated by means of simulation for an optimal detector. Moreover, the performance of the algorithm in finite-size systems is studied and compared with that of a conventional power control scheme, in which user powers depend on the instantaneous spreading sequences. ", "machine_text": " This paper presents a unified power control algorithm for maximizing energy-efficiency in large CDMA networks. This approach is applicable to a range of multiuser receivers, including the matched filter, decorrelator, linear minimum mean-square error receiver, and optimal detectors. It exploits the linear relation between power and output signal-to-interference-plus-noise ratio in large systems, demonstrating that selfish users will seek SIR-balanced equilibriums. The power control algorithm is shown to converge for the matched filter, decorrelator, and MMSE receiver when calculating multiuser efficiency through the iterative process, free from the user's instantaneous spreading sequences. Its performance is tested and compared to conventional power control in finite-size systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3881}
{"prompt": "Rephrase the abstract of an article with title 'Nonequilibrium spin-dependent phenomena in mesoscopic   superconductor-normal metal tunnel structures'.   We analyze the broad range of spin-dependent nonequilibrium transport properties of hybrid systems composed of a normal region tunnel coupled to two superconductors with exchange fields induced by the proximity to thin ferromagnetic layers and highlight its functionalities. By calculating the quasiparticle distribution functions in the normal region we find that they are spin-dependent and strongly sensitive to the relative angle between exchange fields in the two superconductors. The impact of inelastic collisions on their properties is addressed. As a result, the electric current flowing through the system is found to be strongly dependent on the relative angle between exchange fields, giving rise to a huge value of magnetoresistance. Moreover, the current presents a complete spin-polarization in a wide range of bias voltages, even in the quasiequilibrium case. In the nonequilibrium limit we parametrize the distributions with an ``effective`` temperature, which turns out to be strongly spin-dependent, though quite sensitive to inelastic collisions. By tunnel coupling the normal region to an additional superconducting electrode we show that it is possible to implement a spin-polarized current source of both spin species, depending on the bias voltages applied.  ", "human_text": "  We analyze the broad range of spin-dependent nonequilibrium transport properties of hybrid systems composed of a normal region tunnel coupled to two superconductors with exchange fields induced by the proximity to thin ferromagnetic layers and highlight its functionalities. By calculating the quasiparticle distribution functions in the normal region we find that they are spin-dependent and strongly sensitive to the relative angle between exchange fields in the two superconductors. The impact of inelastic collisions on their properties is addressed. As a result, the electric current flowing through the system is found to be strongly dependent on the relative angle between exchange fields, giving rise to a huge value of magnetoresistance. Moreover, the current presents a complete spin-polarization in a wide range of bias voltages, even in the quasiequilibrium case. In the nonequilibrium limit we parametrize the distributions with an ``effective`` temperature, which turns out to be strongly spin-dependent, though quite sensitive to inelastic collisions. By tunnel coupling the normal region to an additional superconducting electrode we show that it is possible to implement a spin-polarized current source of both spin species, depending on the bias voltages applied. ", "machine_text": " We explore the wide array of spin-dependent, non-equilibrium transport phenomena in systems that feature a normal region coupled to two superconductors where exchange fields are generated by their proximity to thin ferromagnetic layers. By calculating the quasiparticle distribution functions in the normal region, we observe that they possess spin-dependence, as well as being highly sensitive to the angle between the exchange fields of the two superconductors. We also examine the effect of inelastic collisions on these properties. Our results show that the current that flows through the system is strongly affected by the relative angle between exchange fields, resulting in an exceedingly high value of magnetoresistance. Furthermore, the current is completely spin-polarized within a large range of bias voltages, even in the quasi-equilibrium situation. In the non-equilibrium limit, we use an ``effective`` temperature to characterize the distributions and find that it is spin-dependent, though quite susceptible to inelastic collisions. Lastly, by connecting the normal region to an extra superconducting electrode, we establish that it is possible to produce spin-polarized current sources of either spin species, depending on the applied bias voltages.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0152}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of Phase-Space Density in Dark Matter Halos'.   The evolution of the phase-space density profile in dark matter (DM) halos is investigated by means of constrained simulations, designed to control the merging history of a given DM halo. Halos evolve through a series of quiescent phases of a slow accretion intermitted by violent events of major mergers. In the quiescent phases the density of the halo closely follows the NFW profile and the phase-space density profile, Q(r), is given by the Taylor & Navarro power law, r^{-beta}, where beta ~ 1.9 and stays remarkably stable over the Hubble time. Expressing the phase-space density by the NFW parameters, Q(r)=Qs (r/Rs)^{-beta}, the evolution of Q is determined by Qs. We have found that the effective mass surface density within Rs, Sigma_s = rhos Rs, remains constant throughout the evolution of a given DM halo along the main branch of its merging tree. This invariance entails that Qs ~ Rs^{-5/2} and Q(r) ~ Sigma_s^{-1/2} Rs^{-5/2} (r/ Rs)^{-beta}. It follows that the phase-space density remains constant, in the sense of Qs=const., in the quiescent phases and it decreases as Rs^{-5/2} in the violent ones. The physical origin of the NFW density profile and the phase-space density power law is still unknown. Yet, the numerical experiments show that halos recover these relations after the violent phases. The major mergers drive Rs to increase and Qs to decrease discontinuously while keeping Qs Rs^{5/2} = const. The virial equilibrium in the quiescent phases implies that a DM halos evolves along a sequence of NFW profiles with constant energy per unit volume (i.e., pressure) within Rs.  ", "human_text": "  The evolution of the phase-space density profile in dark matter (DM) halos is investigated by means of constrained simulations, designed to control the merging history of a given DM halo. Halos evolve through a series of quiescent phases of a slow accretion intermitted by violent events of major mergers. In the quiescent phases the density of the halo closely follows the NFW profile and the phase-space density profile, Q(r), is given by the Taylor & Navarro power law, r^{-beta}, where beta ~ 1.9 and stays remarkably stable over the Hubble time. Expressing the phase-space density by the NFW parameters, Q(r)=Qs (r/Rs)^{-beta}, the evolution of Q is determined by Qs. We have found that the effective mass surface density within Rs, Sigma_s = rhos Rs, remains constant throughout the evolution of a given DM halo along the main branch of its merging tree. This invariance entails that Qs ~ Rs^{-5/2} and Q(r) ~ Sigma_s^{-1/2} Rs^{-5/2} (r/ Rs)^{-beta}. It follows that the phase-space density remains constant, in the sense of Qs=const., in the quiescent phases and it decreases as Rs^{-5/2} in the violent ones. The physical origin of the NFW density profile and the phase-space density power law is still unknown. Yet, the numerical experiments show that halos recover these relations after the violent phases. The major mergers drive Rs to increase and Qs to decrease discontinuously while keeping Qs Rs^{5/2} = const. The virial equilibrium in the quiescent phases implies that a DM halos evolves along a sequence of NFW profiles with constant energy per unit volume (i.e., pressure) within Rs. ", "machine_text": " Through constrained simulations, this study examines the evolution of the phase-space density profile in dark matter halos. Quiescent phases of slow accretion and sporadic major mergers reveal that the phase-space density follows a Taylor & Navarro power law which is remarkably stable over time (r^{-beta}, where beta ~ 1.9). Changes in the phase-space density is attributed to the effective mass surface density (\u03a3_s) within the halo radius (Rs) remains constant, leading to Qs ~ Rs^-5/2 and Q(r) ~ Sigma_s^-1/2 Rs^-5/2 (r/ Rs)^-beta. Violent phases of major mergers drive Rs to increase and Qs to decrease discontinuously while keeping Qs Rs^5/2 = constant. In the quiescent phases, the virial equilibrium of DM halos dictate that a given halo evolves along a sequence of NFW profiles with a constant energy per unit volume (i.e., pressure) within the limits of Rs. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0006}
{"prompt": "Rephrase the abstract of an article with title 'Cryptoplanet update'.   We have had several talks recently reviewing 11 years of exoplanet discoveries through radial velocity variations, or from transits, or from microlensing. More than 200 exoplanets have been found, including some around pulsars that we do not discuss here.   My physical definition for a planet is a roughly spherical, self-gravitating body more massive than 10**26 g formed from the leftover material in a protostellar disk after the protostar forms. Radiation from the protostar pushes the inner wall of the disk outward. The material agglomerates and forms planets in radial sequence. The outer planets are formed slowly by classical dynamical mechanisms acting in the snow zone. Planets have dense cores because of agglomeration.   Not one of the exoplanets discovered thus far is a planet. They are cryptoplanets formed from matter ejected by protostars. When protostars have excessive infall at high latitudes, they partially balance angular momentum through outflow at the equator as they spin up. The ejected matter is trapped in the magnetic torus formed between the star and the disk, like a tokamak. The tokamak eventully reconnects and magnetic compression forms self-gravitating remnants trapped and compressed by a closed spherical magnetic field, spheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They can merge with each other or fall into the star or be ejected. They can grow by accreting gas. They have a low density core and abundances characteristic of the protostar. Their masses, radii, densities, and orbits are random, and are inconsistent with the parameters for planets. They tend to have lower density than planets.  ", "human_text": "  We have had several talks recently reviewing 11 years of exoplanet discoveries through radial velocity variations, or from transits, or from microlensing. More than 200 exoplanets have been found, including some around pulsars that we do not discuss here.   My physical definition for a planet is a roughly spherical, self-gravitating body more massive than 10**26 g formed from the leftover material in a protostellar disk after the protostar forms. Radiation from the protostar pushes the inner wall of the disk outward. The material agglomerates and forms planets in radial sequence. The outer planets are formed slowly by classical dynamical mechanisms acting in the snow zone. Planets have dense cores because of agglomeration.   Not one of the exoplanets discovered thus far is a planet. They are cryptoplanets formed from matter ejected by protostars. When protostars have excessive infall at high latitudes, they partially balance angular momentum through outflow at the equator as they spin up. The ejected matter is trapped in the magnetic torus formed between the star and the disk, like a tokamak. The tokamak eventully reconnects and magnetic compression forms self-gravitating remnants trapped and compressed by a closed spherical magnetic field, spheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They can merge with each other or fall into the star or be ejected. They can grow by accreting gas. They have a low density core and abundances characteristic of the protostar. Their masses, radii, densities, and orbits are random, and are inconsistent with the parameters for planets. They tend to have lower density than planets. ", "machine_text": " This article provides an update on the discoveries of exoplanets over the last 11 years. A physical definition of a planet as an object made of the leftover material from a protostellar disk is described, noting their radial sequence formation and dense cores. After careful inspection, it is concluded that none of the exoplanets discovered thus far are planets in the traditional sense, instead being cryptoplanets formed by matter ejected by protostars. Their characteristics of mass, radius, orbit and density are random, making them different to planets. This article offers an analysis of this phenomena, how they can merge or become ejected, and how they differ in density to planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.286}
{"prompt": "Rephrase the abstract of an article with title 'Is the Concentration of Dark Matter Halos at Virialization Universal ?'.   Several recent studies suggest a correlation between dark matter halo mass and the shape of the density profile. We re-analyze simulations from Ricotti (2003) in which such a correlation was proposed. We use a standard analysis of the halo density profiles and compare the old simulations to new ones performed with Gadget2, including higher resolution runs. We confirm Ricotti's result that, at virialization, the central log slopes alpha, at 5%-10% of the virial radius are correlated with the halo mass and that the halo concentration is a universal constant. Our results do not contradict the majority of published papers: when using a split power law to fit the density profiles, due to the alpha-concentration degeneracy, the fits are consistent with halos having a universal shape with alpha=1 or 1.5 and concentrations that depend on the mass, in agreement with results published elsewhere.   Recently, several groups have found no evidence for convergence of the inner halo profile to a constant power law. The choice of a split power law parameterization used in this letter is motivated by the need to compare our results to previous ones and is formally valid because we are not able to resolve regions where the slope of the fitting function reaches its asymptotic constant value. Using a non-parameterized technique, we also show that the density profiles of dwarf galaxies at z ~ 10 have a log slope shallower than 0.5 within 5% of the virial radius.  ", "human_text": "  Several recent studies suggest a correlation between dark matter halo mass and the shape of the density profile. We re-analyze simulations from Ricotti (2003) in which such a correlation was proposed. We use a standard analysis of the halo density profiles and compare the old simulations to new ones performed with Gadget2, including higher resolution runs. We confirm Ricotti's result that, at virialization, the central log slopes alpha, at 5%-10% of the virial radius are correlated with the halo mass and that the halo concentration is a universal constant. Our results do not contradict the majority of published papers: when using a split power law to fit the density profiles, due to the alpha-concentration degeneracy, the fits are consistent with halos having a universal shape with alpha=1 or 1.5 and concentrations that depend on the mass, in agreement with results published elsewhere.   Recently, several groups have found no evidence for convergence of the inner halo profile to a constant power law. The choice of a split power law parameterization used in this letter is motivated by the need to compare our results to previous ones and is formally valid because we are not able to resolve regions where the slope of the fitting function reaches its asymptotic constant value. Using a non-parameterized technique, we also show that the density profiles of dwarf galaxies at z ~ 10 have a log slope shallower than 0.5 within 5% of the virial radius. ", "machine_text": " This study examines the relationship between dark matter halo mass and its density profile at the time of virialization, based on simulations by Ricotti (2003). Analysis of data generated by both Gadget2 and higher resolution runs leads to confirmation of Ricotti's hypothesis that, at the time of virialization, a universal constant concentration of halos can be correlated with their mass. This result is consistent with other papers that use split power law parameterization to fit the density profiles, which reveals an alpha-concentration degeneracy that suggests a universal shape of the halo with specific alpha values (1 or 1.5) and concentrations that are dependent on its mass. Additionally, a non-parameterized technique is employed to show that the density profiles of dwarf galaxies at z ~ 10 generally have a log slope softer than 0.5 within the central 5% of the virial radius.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0856}
{"prompt": "Rephrase the abstract of an article with title 'SubmilliJansky Transients in Archival Radio Observations'.   [ABRIDGED] We report the results of a 944-epoch survey for transient sources with archival data from the Very Large Array spanning 22 years with a typical epoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a single field of view with a full-width at half-maximum of 8.6' and 5.1', respectively, and achieved a typical point-source detection threshold at the beam center of ~300 microJy per epoch. Ten transient sources were detected with a significance threshold such that only one false positive would be expected. Of these transients, eight were detected in only a single epoch. Two transients were too faint to be detected in individual epochs but were detected in two-month averages. None of the ten transients was detected in longer-term averages or associated with persistent emission in the deep image produced from the combination of all epochs. The cumulative rate for the short timescale radio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2 yr^-1, where the uncertainty is due to the unknown duration of the transients, 20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/- 0.4 transient per square degrees above a flux density of 370 microJy. Two transients are associated with galaxies at z=0.040 and z=0.249. These may be similar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB 980428. Six transients have no counterparts in the optical or infrared (R=27, Ks=18). The hosts and progenitors of these transients are unknown.  ", "human_text": "  [ABRIDGED] We report the results of a 944-epoch survey for transient sources with archival data from the Very Large Array spanning 22 years with a typical epoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a single field of view with a full-width at half-maximum of 8.6' and 5.1', respectively, and achieved a typical point-source detection threshold at the beam center of ~300 microJy per epoch. Ten transient sources were detected with a significance threshold such that only one false positive would be expected. Of these transients, eight were detected in only a single epoch. Two transients were too faint to be detected in individual epochs but were detected in two-month averages. None of the ten transients was detected in longer-term averages or associated with persistent emission in the deep image produced from the combination of all epochs. The cumulative rate for the short timescale radio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2 yr^-1, where the uncertainty is due to the unknown duration of the transients, 20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/- 0.4 transient per square degrees above a flux density of 370 microJy. Two transients are associated with galaxies at z=0.040 and z=0.249. These may be similar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB 980428. Six transients have no counterparts in the optical or infrared (R=27, Ks=18). The hosts and progenitors of these transients are unknown. ", "machine_text": " We present results from a 944-epoch survey of archival data from the Very Large Array taken over 22 years, featuring a single field of view with a full-width at half-maximum of 8.6' and 5.1' at 5 and 8.4 GHz, respectively. The point-source detection threshold at the beam center is approximately 300 microJy per epoch. Ten transient sources were discovered, most of which were only detected once - two were only detected in two-month averages. The cumulative rate of short timescale radio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2 yr^-1. These transients were not found in any long-term averages or persistent emission in the image formed by all epochs. Two transients were associated with galaxies at redshifts 0.040 and 0.249 and may be similar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB 980428. The host and progenitor of the remaining six transients is as yet unknown.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3158}
{"prompt": "Rephrase the abstract of an article with title 'Hydrodynamic Limit for a Particle System with degenerate rates'.   We study the hydrodynamic limit for some conservative particle systems with degenerate rates, namely with nearest neighbor exchange rates which vanish for certain configurations. These models belong to the class of {\\sl kinetically constrained lattice gases} (KCLG) which have been introduced and intensively studied in physics literature as simple models for the liquid/glass transition. Due to the degeneracy of rates for KCLG there exists {\\sl blocked configurations} which do not evolve under the dynamics and in general the hyperplanes of configurations with a fixed number of particles can be decomposed into different irreducible sets. As a consequence, both the Entropy and Relative Entropy method cannot be straightforwardly applied to prove the hydrodynamic limit. In particular, some care should be put when proving the One and Two block Lemmas which guarantee local convergence to equilibrium. We show that, for initial profiles smooth enough and bounded away from zero and one, the macroscopic density profile for our KCLG evolves under the diffusive time scaling according to the porous medium equation. Then we prove the same result for more general profiles for a slightly perturbed dynamics obtained by adding jumps of the Symmetric Simple Exclusion. The role of the latter is to remove the degeneracy of rates and at the same time they are properly slowed down in order not to change the macroscopic behavior. The equilibrium fluctuations and the magnitude of the spectral gap for this perturbed model are also obtained.  ", "human_text": "  We study the hydrodynamic limit for some conservative particle systems with degenerate rates, namely with nearest neighbor exchange rates which vanish for certain configurations. These models belong to the class of {\\sl kinetically constrained lattice gases} (KCLG) which have been introduced and intensively studied in physics literature as simple models for the liquid/glass transition. Due to the degeneracy of rates for KCLG there exists {\\sl blocked configurations} which do not evolve under the dynamics and in general the hyperplanes of configurations with a fixed number of particles can be decomposed into different irreducible sets. As a consequence, both the Entropy and Relative Entropy method cannot be straightforwardly applied to prove the hydrodynamic limit. In particular, some care should be put when proving the One and Two block Lemmas which guarantee local convergence to equilibrium. We show that, for initial profiles smooth enough and bounded away from zero and one, the macroscopic density profile for our KCLG evolves under the diffusive time scaling according to the porous medium equation. Then we prove the same result for more general profiles for a slightly perturbed dynamics obtained by adding jumps of the Symmetric Simple Exclusion. The role of the latter is to remove the degeneracy of rates and at the same time they are properly slowed down in order not to change the macroscopic behavior. The equilibrium fluctuations and the magnitude of the spectral gap for this perturbed model are also obtained. ", "machine_text": "We explore the hydrodynamic limit of a specific particle system which features degenerate rates, also known as 'kinetically constrained lattice gases'. These models are known to comprise configurations that are 'blocked', unable to evolve under the dynamics. It is more difficult to prove the hydrodynamic limit with the Entropy and Relative Entropy methods due to the presence of such blocked  configurations. We show that when the initial profile is sufficiently smooth and bounded away from 0 and 1, the density profile of this KCLG evolves according to the porous medium equation under a diffusive time scaling. Additionally, we provide a perturbed dynamics achieved by introducing jumps for the Symmetric Simple Exclusion into the model and analyse the magnitude of the equilibrium fluctuations and the size of the spectral gap.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2242}
{"prompt": "Rephrase the abstract of an article with title 'A Three-Stage Search for Supermassive Black Hole Binaries in LISA Data'.   Gravitational waves from the inspiral and coalescence of supermassive black-hole (SMBH) binaries with masses ~10^6 Msun are likely to be among the strongest sources for the Laser Interferometer Space Antenna (LISA). We describe a three-stage data-analysis pipeline designed to search for and measure the parameters of SMBH binaries in LISA data. The first stage uses a time-frequency track-search method to search for inspiral signals and provide a coarse estimate of the black-hole masses m_1, m_2 and of the coalescence time of the binary t_c. The second stage uses a sequence of matched-filter template banks, seeded by the first stage, to improve the measurement accuracy of the masses and coalescence time. Finally, a Markov Chain Monte Carlo search is used to estimate all nine physical parameters of the binary. Using results from the second stage substantially shortens the Markov Chain burn-in time and allows us to determine the number of SMBH-binary signals in the data before starting parameter estimation. We demonstrate our analysis pipeline using simulated data from the first LISA Mock Data Challenge. We discuss our plan for improving this pipeline and the challenges that will be faced in real LISA data analysis.  ", "human_text": "  Gravitational waves from the inspiral and coalescence of supermassive black-hole (SMBH) binaries with masses ~10^6 Msun are likely to be among the strongest sources for the Laser Interferometer Space Antenna (LISA). We describe a three-stage data-analysis pipeline designed to search for and measure the parameters of SMBH binaries in LISA data. The first stage uses a time-frequency track-search method to search for inspiral signals and provide a coarse estimate of the black-hole masses m_1, m_2 and of the coalescence time of the binary t_c. The second stage uses a sequence of matched-filter template banks, seeded by the first stage, to improve the measurement accuracy of the masses and coalescence time. Finally, a Markov Chain Monte Carlo search is used to estimate all nine physical parameters of the binary. Using results from the second stage substantially shortens the Markov Chain burn-in time and allows us to determine the number of SMBH-binary signals in the data before starting parameter estimation. We demonstrate our analysis pipeline using simulated data from the first LISA Mock Data Challenge. We discuss our plan for improving this pipeline and the challenges that will be faced in real LISA data analysis. ", "machine_text": "This paper presents a multi-stage, data-driven approach to investigate and measure supermassive binary black-hole systems in data from the Laser Interferometer Space Antenna (LISA). Using the first LISA Mock Data Challenge, the proposed three-stage pipeline combines a time-frequency track search, a matched-filter template bank, and a Markov Chain Monte Carlo search to estimate all nine physical parameters of the binary. Additionally, improved measurement accuracy from the second stage is leveraged to reduce the burn-in time for the Markov Chain process. Future plans to enhance and refine the pipeline for implementation in real LISA analysis are also discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2447}
{"prompt": "Rephrase the abstract of an article with title 'The magnetic fields of large Virgo Cluster spirals'.   Because of its proximity the Virgo Cluster is an excellent target for studying interactions of galaxies with the cluster environment. Both the high-velocity tidal interactions and effects of ram pressure stripping by the intracluster gas can be investigated. Optical and/or \\ion{H}{i} observations do not always show effects of weak interactions between galaxies and their encounters with the cluster medium. For this reason we searched for possible anomalies in the magnetic field structure in Virgo Cluster spirals which could be attributed to perturbations in their gas distribution and kinematics. Five angularly large Virgo Cluster spiral galaxies (NGC 4501, NGC 4438, NGC 4535, NGC 4548 and NGC 4654) were the targets for a sensitive total power and polarization study using the 100-m radio telescope in Effelsberg at 4.85 GHz. For two objects polarization data at higher frequencies have been obtained allowing Faraday rotation analysis. Distorted magnetic field structures were identified in all galaxies. Interaction-induced magnetized outflows were found in NGC 4438 (due to nuclear activity) and NGC 4654 (a combination of tidal tails and ram pressure effects). Almost all objects (except the anaemic NGC 4548) exhibit distortions in polarized radio continuum attributable to influence of the ambient gas. For some galaxies they agree with observations of other species, but sometimes (NGC 4535) the magnetic field is the only tracer of the interaction with the cluster environment. The cluster environment clearly affects the evolution of the galaxies due to ram pressure and tidal effects. Magnetic fields provide a very long-lasting memory of past interactions. Therefore, they are a good tracer of weak interactions which are difficult to detect by other observations.  ", "human_text": "  Because of its proximity the Virgo Cluster is an excellent target for studying interactions of galaxies with the cluster environment. Both the high-velocity tidal interactions and effects of ram pressure stripping by the intracluster gas can be investigated. Optical and/or \\ion{H}{i} observations do not always show effects of weak interactions between galaxies and their encounters with the cluster medium. For this reason we searched for possible anomalies in the magnetic field structure in Virgo Cluster spirals which could be attributed to perturbations in their gas distribution and kinematics. Five angularly large Virgo Cluster spiral galaxies (NGC 4501, NGC 4438, NGC 4535, NGC 4548 and NGC 4654) were the targets for a sensitive total power and polarization study using the 100-m radio telescope in Effelsberg at 4.85 GHz. For two objects polarization data at higher frequencies have been obtained allowing Faraday rotation analysis. Distorted magnetic field structures were identified in all galaxies. Interaction-induced magnetized outflows were found in NGC 4438 (due to nuclear activity) and NGC 4654 (a combination of tidal tails and ram pressure effects). Almost all objects (except the anaemic NGC 4548) exhibit distortions in polarized radio continuum attributable to influence of the ambient gas. For some galaxies they agree with observations of other species, but sometimes (NGC 4535) the magnetic field is the only tracer of the interaction with the cluster environment. The cluster environment clearly affects the evolution of the galaxies due to ram pressure and tidal effects. Magnetic fields provide a very long-lasting memory of past interactions. Therefore, they are a good tracer of weak interactions which are difficult to detect by other observations. ", "machine_text": " Through observations of the 100-m radio telescope in Effelsberg at 4.85 GHz, this study examined possible anomalies in the magnetic fields of five large Virgo Cluster spiral galaxies (NGC 4501, NGC 4438, NGC 4535, NGC 4548 and NGC 4654). Distorted magnetic field structures were found in all galaxies and interaction-induced magnetized outflows detected in two of them. Magnetic fields are useful for tracing weak interactions that are not evidenced by other observations, including ram pressure and tidal effects from the nearby Virgo Cluster that affect the galaxies' evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4586}
{"prompt": "Rephrase the abstract of an article with title 'The impact of accretion disk winds on the X-ray spectrum of AGN: Part 1   - XSCORT'.   (abridged) The accretion disk in AGN is expected to produce strong outflows, in particular a UV-line driven wind. Despite providing a good fit to the data, current spectral models of the X-ray spectrum of AGN observed through an accretion disk wind are ad-hoc in their treatment of the properties of the wind material. In order to address these limitations we adopt a numerical computation method that links a series of radiative transfer calculations, incorporating the effect of a global velocity field in a self-consistent manner (XSCORT). We present a series of example spectra from the XSCORT code that allow us to examine the shape of AGN X-ray spectra seen through a wind, for a range of velocity and density distributions, total column densities and initial ionization parameters. These detailed spectral models clearly show considerable complexity and structure that is strongly affected by all these factors. The presence of sharp features in the XSCORT spectra contrasts strongly with both the previous models and with the smooth nature of the observed X-ray spectra of AGN with soft X-ray excesses, demonstrating that accretion disk winds are unlikely to be the origin of this mysterious spectral feature. The most significant parameter affecting the presence of the sharp features in the models is the terminal velocity of the wind. Increasing the terminal velocity of the absorbing material to ~c, and hence dramatically increasing the velocity dispersion across the wind, could potentially remove these features resulting in a spectrum similar to the previous models. Such a fast moving outflow cannot be associated with a radiatively driven accretion disk wind, however the presence of a highly relativistic jet may provide an origin for such material.  ", "human_text": "  (abridged) The accretion disk in AGN is expected to produce strong outflows, in particular a UV-line driven wind. Despite providing a good fit to the data, current spectral models of the X-ray spectrum of AGN observed through an accretion disk wind are ad-hoc in their treatment of the properties of the wind material. In order to address these limitations we adopt a numerical computation method that links a series of radiative transfer calculations, incorporating the effect of a global velocity field in a self-consistent manner (XSCORT). We present a series of example spectra from the XSCORT code that allow us to examine the shape of AGN X-ray spectra seen through a wind, for a range of velocity and density distributions, total column densities and initial ionization parameters. These detailed spectral models clearly show considerable complexity and structure that is strongly affected by all these factors. The presence of sharp features in the XSCORT spectra contrasts strongly with both the previous models and with the smooth nature of the observed X-ray spectra of AGN with soft X-ray excesses, demonstrating that accretion disk winds are unlikely to be the origin of this mysterious spectral feature. The most significant parameter affecting the presence of the sharp features in the models is the terminal velocity of the wind. Increasing the terminal velocity of the absorbing material to ~c, and hence dramatically increasing the velocity dispersion across the wind, could potentially remove these features resulting in a spectrum similar to the previous models. Such a fast moving outflow cannot be associated with a radiatively driven accretion disk wind, however the presence of a highly relativistic jet may provide an origin for such material. ", "machine_text": " This paper employs the XSCORT code to examine the impact that an accretion disk wind has on the X-ray spectrum of AGN. Results from the study show that for a range of velocity, density distributions, total column densities and initial ionization parameters, the spectra of AGN with soft X-ray excesses seen through an accretion disk wind, involve substantial complexity and structure. Notably, the presence of sharp features produced by the XSCORT code contrasts sharply with the smooth nature of the observed X-ray spectra of AGN, casting doubt on the ability of accretion disk winds to produce soft X-ray excesses. Further study suggests that a terminal velocity of roughly the speed of light would need to be involved in order to remove these features, but that such an outflow cannot likely be associated with a radiatively driven accretion disk wind. Suggesting that a highly relativistic jet may be a more suitable source for the material.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1885}
{"prompt": "Rephrase the abstract of an article with title 'Molecular Line Emission from Massive Protostellar Disks: Predictions for   ALMA and the EVLA'.   We compute the molecular line emission of massive protostellar disks by solving the equation of radiative transfer through the cores and disks produced by the recent radiation-hydrodynamic simulations of Krumholz, Klein, & McKee. We find that in several representative lines the disks show brightness temperatures of hundreds of Kelvin over velocity channels ~10 km s^-1 wide, extending over regions hundreds of AU in size. We process the computed intensities to model the performance of next-generation radio and submillimeter telescopes. Our calculations show that observations using facilities such as the EVLA and ALMA should be able to detect massive protostellar disks and measure their rotation curves, at least in the nearest massive star-forming regions. They should also detect significant sub-structure and non-axisymmetry in the disks, and in some cases may be able to detect star-disk velocity offsets of a few km s^-1, both of which are the result of strong gravitational instability in massive disks. We use our simulations to explore the strengths and weaknesses of different observational techniques, and we also discuss how observations of massive protostellar disks may be used to distinguish between alternative models of massive star formation.  ", "human_text": "  We compute the molecular line emission of massive protostellar disks by solving the equation of radiative transfer through the cores and disks produced by the recent radiation-hydrodynamic simulations of Krumholz, Klein, & McKee. We find that in several representative lines the disks show brightness temperatures of hundreds of Kelvin over velocity channels ~10 km s^-1 wide, extending over regions hundreds of AU in size. We process the computed intensities to model the performance of next-generation radio and submillimeter telescopes. Our calculations show that observations using facilities such as the EVLA and ALMA should be able to detect massive protostellar disks and measure their rotation curves, at least in the nearest massive star-forming regions. They should also detect significant sub-structure and non-axisymmetry in the disks, and in some cases may be able to detect star-disk velocity offsets of a few km s^-1, both of which are the result of strong gravitational instability in massive disks. We use our simulations to explore the strengths and weaknesses of different observational techniques, and we also discuss how observations of massive protostellar disks may be used to distinguish between alternative models of massive star formation. ", "machine_text": " We use next-generation radio and submillimeter telescopes such as the EVLA and ALMA to detect molecular line emission from massive protostellar disks. By running radiation-hydrodynamic simulations of the disks, we determine that the brightness temperatures of the disk core could be up to hundreds of Kelvin, extending over velocity channels of 10 km s-1 and regions of hundreds of AU. Based on our findings, we predict that these observations should be capable of detecting the massive protostellar disks and their rotational curves in nearby star-forming regions. Additionally, we predict that non-axisymmetry and substructure should be detectable, as well as velocity offsets between the stars and disks of several km s^-1, caused by strong gravitational instability. Our simulations aid in exploring the effectiveness of different observation techniques and comparing alternative models of massive star formation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0536}
{"prompt": "Rephrase the abstract of an article with title 'On a generalised model for time-dependent variance with long-term memory'.   The ARCH process (R. F. Engle, 1982) constitutes a paradigmatic generator of stochastic time series with time-dependent variance like it appears on a wide broad of systems besides economics in which ARCH was born. Although the ARCH process captures the so-called \"volatility clustering\" and the asymptotic power-law probability density distribution of the random variable, it is not capable to reproduce further statistical properties of many of these time series such as: the strong persistence of the instantaneous variance characterised by large values of the Hurst exponent (H > 0.8), and asymptotic power-law decay of the absolute values self-correlation function. By means of considering an effective return obtained from a correlation of past returns that has a q-exponential form we are able to fix the limitations of the original model. Moreover, this improvement can be obtained through the correct choice of a sole additional parameter, $q_{m}$. The assessment of its validity and usefulness is made by mimicking daily fluctuations of SP500 financial index.  ", "human_text": "  The ARCH process (R. F. Engle, 1982) constitutes a paradigmatic generator of stochastic time series with time-dependent variance like it appears on a wide broad of systems besides economics in which ARCH was born. Although the ARCH process captures the so-called \"volatility clustering\" and the asymptotic power-law probability density distribution of the random variable, it is not capable to reproduce further statistical properties of many of these time series such as: the strong persistence of the instantaneous variance characterised by large values of the Hurst exponent (H > 0.8), and asymptotic power-law decay of the absolute values self-correlation function. By means of considering an effective return obtained from a correlation of past returns that has a q-exponential form we are able to fix the limitations of the original model. Moreover, this improvement can be obtained through the correct choice of a sole additional parameter, $q_{m}$. The assessment of its validity and usefulness is made by mimicking daily fluctuations of SP500 financial index. ", "machine_text": "This paper proposes a generalised ARCH model with long-term memory to capture and reproduce the time-dependent variance, volatility clustering and power-law probability density distribution of stochastic time series. The model also offers the ability to accurately reproduce the strong persistence of the instantaneous variance as shown by large values of the Hurst exponent and the asymptotic power-law decay of the absolute values self-correlation function. This is accomplished through the introduction of a single effective return parameter, $q_{m}$, obtained from the correlation of past returns with a q-exponential form. This model is applied in the context of the daily fluctuations of the SP500 financial index to assess its validity and usefulness.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3248}
{"prompt": "Rephrase the abstract of an article with title 'The Black Hole Binary Nova Scorpii 1994 (GRO J1655-40): An improved   chemical analysis'.   The chemical analysis of secondary stars of low mass X-ray binaries provides an opportunity to study the formation processes of compact objects, either black holes or neutron stars. Following the discovery of overabundances of $\\alpha$-elements in the HIRES/Keck spectrum of the secondary star of Nova Scorpii 1994 (Israelian et al. 1999), we obtained UVES/VLT high-resolution spectroscopy with the aim of performing a detailed abundance analysis of this secondary star. Using a $\\chi2$-minimization procedure and a grid of synthetic spectra, we derive the stellar parameters and atmospheric abundances of O, Mg, Al, Ca, Ti, Fe and Ni, using a new UVES spectrum and the HIRES spectrum.The abundances of Al, Ca, Ti, Fe and Ni seem to be consistent with solar values, whereas Na, and especially O, Mg, Si and S are significantly enhanced in comparison with Galactic trends of these elements. A comparison with spherically and non-spherically symmetric supernova explosion models may provide stringent constraints to the model parameters as mass-cut and the explosion energy, in particular from the relative abundances of Si, S, Ca, Ti, Fe and Ni. Most probably the black hole in this system formed in a hypernova explosion of a 30--35 \\Msun progenitor star with a mass-cut in the range 2--3.5 \\Msun. However, these models produce abundances of Al and Na almost ten times higher than the observed values.  ", "human_text": "  The chemical analysis of secondary stars of low mass X-ray binaries provides an opportunity to study the formation processes of compact objects, either black holes or neutron stars. Following the discovery of overabundances of $\\alpha$-elements in the HIRES/Keck spectrum of the secondary star of Nova Scorpii 1994 (Israelian et al. 1999), we obtained UVES/VLT high-resolution spectroscopy with the aim of performing a detailed abundance analysis of this secondary star. Using a $\\chi2$-minimization procedure and a grid of synthetic spectra, we derive the stellar parameters and atmospheric abundances of O, Mg, Al, Ca, Ti, Fe and Ni, using a new UVES spectrum and the HIRES spectrum.The abundances of Al, Ca, Ti, Fe and Ni seem to be consistent with solar values, whereas Na, and especially O, Mg, Si and S are significantly enhanced in comparison with Galactic trends of these elements. A comparison with spherically and non-spherically symmetric supernova explosion models may provide stringent constraints to the model parameters as mass-cut and the explosion energy, in particular from the relative abundances of Si, S, Ca, Ti, Fe and Ni. Most probably the black hole in this system formed in a hypernova explosion of a 30--35 \\Msun progenitor star with a mass-cut in the range 2--3.5 \\Msun. However, these models produce abundances of Al and Na almost ten times higher than the observed values. ", "machine_text": " This article examines the chemical composition of the secondary stars in low mass X-ray binary systems, to gain insight into the formation of black holes and neutron stars. Through UVES/VLT spectroscopy and the HIRES spectrum of Nova Scorpii 1994's secondary star (Israelian et al. 1999), we derive the atmospheric abundances of O, Mg, Al, Ca, Ti, Fe, and Ni using the $\\chi2$-minimization procedure and grid of synthetic spectra. The majority of the elements share similarities with solar values, while Na and primarily O, Mg, Si, and S have significantly augmented as compared to Galactic trends. We analyze existing supernova explosion models to constrain their parameters, such as the mass-cut and the explosion energy, in relation to relative abundances of elements like Si, S, Ca, Ti, Fe and Ni. Results indicate that a hypernova explosion of a 30-35 \\Msun progenitor star with a mass-cut between 2-3.5 \\Msun, is likely the formation process of the black hole. However, the output of these models vastly overestimates the concentrations of Al and Na that are found in the observed spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2693}
{"prompt": "Rephrase the abstract of an article with title 'Clustered Star Formation in the Small Magellanic Cloud. A Spitzer/IRAC   View of the Star-Forming Region NGC 602/N 90'.   We present Spitzer/IRAC photometry on the star-forming HII region N 90, related to the young stellar association NGC 602 in the Small Magellanic Cloud. Our photometry revealed bright mid-infrared sources, which we classify with the use of a scheme based on templates and models of red sources in the Milky Way, and criteria recently developed from the Spitzer Survey of the SMC for the selection of candidate Young Stellar Objects (YSOs). We detected 57 sources in all four IRAC channels in a 6.2' x 4.8' field-of-view centered on N 90; 22 of these sources are classified as candidate YSOs. We compare the locations of these objects with the position of optical sources recently found in the same region with high-resolution HST/ACS imaging of NGC 602, and we find that 17 candidate YSOs have one or more optical counterparts. All of these optical sources are identified as pre-main sequence stars, indicating, thus, ongoing clustered star formation events in the region. The positions of the detected YSOs and their related PMS clusters give a clear picture of the current star formation in N 90, according to which the young stellar association photo-ionizes the surrounding interstellar medium, revealing the HII nebula, and triggering sequential star formation events mainly along the eastern and southern rims of the formed cavity of the parental molecular cloud.  ", "human_text": "  We present Spitzer/IRAC photometry on the star-forming HII region N 90, related to the young stellar association NGC 602 in the Small Magellanic Cloud. Our photometry revealed bright mid-infrared sources, which we classify with the use of a scheme based on templates and models of red sources in the Milky Way, and criteria recently developed from the Spitzer Survey of the SMC for the selection of candidate Young Stellar Objects (YSOs). We detected 57 sources in all four IRAC channels in a 6.2' x 4.8' field-of-view centered on N 90; 22 of these sources are classified as candidate YSOs. We compare the locations of these objects with the position of optical sources recently found in the same region with high-resolution HST/ACS imaging of NGC 602, and we find that 17 candidate YSOs have one or more optical counterparts. All of these optical sources are identified as pre-main sequence stars, indicating, thus, ongoing clustered star formation events in the region. The positions of the detected YSOs and their related PMS clusters give a clear picture of the current star formation in N 90, according to which the young stellar association photo-ionizes the surrounding interstellar medium, revealing the HII nebula, and triggering sequential star formation events mainly along the eastern and southern rims of the formed cavity of the parental molecular cloud. ", "machine_text": " We examine the mid-infrared emission of the star-forming HII region N 90, associated with the young stellar association NGC 602 in the Small Magellanic Cloud, using Spitzer/IRAC photometry. We classify 57 sources in a 6.2' x 4.8' field-of-view centered on N 90, of which 22 are identified as Young Stellar Objects.  Comparing these possible YSOs to optical sources registered with high-resolution HST/ACS observations, we pinpoint 17 young stars that are suggestive of ongoing clustered star formation events in the region.  Our survey reveals a pattern of sequential star formation at the edges of a parental molecular cloud cavity, ionized by the growing NGC 602 association.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3359}
{"prompt": "Rephrase the abstract of an article with title 'The Physical Nature of Polar Broad Absorption Line Quasars'.   It has been shown based on radio variability arguments that some BALQSOs (broad absorption line quasars) are viewed along the polar axis (orthogonal to accretion disk) in the recent article of Zhou et al. These arguments are based on the brightness temperature, $T_{b}$ exceeding $10^{12} ^{\\circ}$ K which leads to the well-known inverse Compton catastrophe unless the radio jet is relativistic and is viewed along its axis. In this letter, we expand the Zhou et al sample of polar BALQSOs to the entire SDSS DR5. In the process, we clarify a mistake in their calculation of brightness temperature. The expanded sample of high $T_{b}$ BALQSOS, has an inordinately large fraction of LoBALQSOs (low ionization BALQSOs). We consider this an important clue to understanding the nature of the polar BALQSOs. This is expected in the polar BALQSO analytical/numerical models of Punsly in which LoBALQSOs occur when the line of sight is very close to the polar axis, where the outflow density is the highest.  ", "human_text": "  It has been shown based on radio variability arguments that some BALQSOs (broad absorption line quasars) are viewed along the polar axis (orthogonal to accretion disk) in the recent article of Zhou et al. These arguments are based on the brightness temperature, $T_{b}$ exceeding $10^{12} ^{\\circ}$ K which leads to the well-known inverse Compton catastrophe unless the radio jet is relativistic and is viewed along its axis. In this letter, we expand the Zhou et al sample of polar BALQSOs to the entire SDSS DR5. In the process, we clarify a mistake in their calculation of brightness temperature. The expanded sample of high $T_{b}$ BALQSOS, has an inordinately large fraction of LoBALQSOs (low ionization BALQSOs). We consider this an important clue to understanding the nature of the polar BALQSOs. This is expected in the polar BALQSO analytical/numerical models of Punsly in which LoBALQSOs occur when the line of sight is very close to the polar axis, where the outflow density is the highest. ", "machine_text": " By examining a larger sample of polar Broad Absorption Line Quasars (BALQSOs) from the SDSS DR5, this paper aims to provide an explantion to the underlying physical nature of these celestial bodies. The argument put forward by Zhou et al, based on the radio variability of some BALQSOs, was that these objects are viewed in a polar orientation relative to their accretion disks. This paper verifies the calculation of brightness temperature, $T_{b}$, made by Zhou et al., and then extends this knowledge to an entire sample of polar BALQSOs. In doing so, we observe an exaggerated number of LoBALQSOs (low ionization BALQSOs) in this group. This is seen as a key piece of evidence to understanding the nature of polar BALQSOs, as it supports the prediction of polar BALQSO analytical and numerical models put forward by Punsly, where LoBALQSOs tend to present in environments where the line of sight is close to the polar axis and the outflow density is high.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2407}
{"prompt": "Rephrase the abstract of an article with title 'The discovery of a massive supercluster at z=0.9 in the UKIDSS DXS'.   We analyse the first publicly released deep field of the UKIDSS Deep eXtragalactic Survey (DXS) to identify candidate galaxy over-densities at z~1 across ~1 sq. degree in the ELAIS-N1 field. Using I-K, J-K and K-3.6um colours we identify and spectroscopically follow-up five candidate structures with Gemini/GMOS and confirm they are all true over-densities with between five and nineteen members each. Surprisingly, all five structures lie in a narrow redshift range at z=0.89+/-0.01, although they are spread across 30Mpc on the sky. We also find a more distant over-density at z=1.09 in one of the spectroscopic survey regions. These five over-dense regions lying in a narrow redshift range indicate the presence of a supercluster in this field and by comparing with mock cluster catalogs from N-body simulations we discuss the likely properties of this structure. Overall, we show that the properties of this supercluster are similar to the well-studied Shapley and Hercules superclusters at lower redshift.  ", "human_text": "  We analyse the first publicly released deep field of the UKIDSS Deep eXtragalactic Survey (DXS) to identify candidate galaxy over-densities at z~1 across ~1 sq. degree in the ELAIS-N1 field. Using I-K, J-K and K-3.6um colours we identify and spectroscopically follow-up five candidate structures with Gemini/GMOS and confirm they are all true over-densities with between five and nineteen members each. Surprisingly, all five structures lie in a narrow redshift range at z=0.89+/-0.01, although they are spread across 30Mpc on the sky. We also find a more distant over-density at z=1.09 in one of the spectroscopic survey regions. These five over-dense regions lying in a narrow redshift range indicate the presence of a supercluster in this field and by comparing with mock cluster catalogs from N-body simulations we discuss the likely properties of this structure. Overall, we show that the properties of this supercluster are similar to the well-studied Shapley and Hercules superclusters at lower redshift. ", "machine_text": " A comprehensive analysis of the initial UKIDSS Deep eXtragalactic Survey (DXS) data of the ELAIS-N1 field revealed candidate galaxy over-densities at z~1 within an area of one square degree. By utilizing I-K, J-K, and K-3.6um colour indices the five structures were further spectroscopically observed at the Gemini/GMOS and confirmed to be real over-densities having up to nineteen members each. Strikingly, they are located in a very precise redshift range (z=0.89+/-0.01), but spread across a 30Mpc distance on the sky. What is more, a sixth over-density was identified at z=1.09. Comparisons with a mock cluster catalog from N-body simulations indicate that the supercluster discovered in the ELAIS-N1 Field has similar characteristics to the Shapley and Hercules superclusters at lower redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.009}
{"prompt": "Rephrase the abstract of an article with title 'Recent progresses in the simulation of small-scale magnetic fields'.   New high-resolution observations reveal that small-scale magnetic flux concentrations have a delicate substructure on a spatial scale of 0.1''. Its basic structure can be interpreted in terms of a magnetic flux sheet or tube that vertically extends through the ambient weak-field or field-free atmosphere with which it is in mechanical equilibrium. A more refined interpretation comes from new three-dimensional magnetohydrodynamic simulations that are capable of reproducing the corrugated shape of magnetic flux concentrations and their signature in the visible continuum. Furthermore it is shown that the characteristic asymmetric shape of the contrast profile of facular granules is an effect of radiative transfer across the rarefied atmosphere of the magnetic flux concentration. I also discuss three-dimensional radiation magnetohydrodynamic simulations of the integral layers from the top of the convection zone to the mid-chromosphere. They show a highly dynamic chromospheric magnetic field, marked by rapidly moving filaments of stronger than average magnetic field that form in the compression zone downstream and along propagating shock fronts. The simulations confirm the picture of flux concentrations that strongly expand through the photosphere into a more homogeneous, space filling chromospheric field. Future directions in the simulation of small-scale magnetic fields are indicated by a few examples of very recent work.  ", "human_text": "  New high-resolution observations reveal that small-scale magnetic flux concentrations have a delicate substructure on a spatial scale of 0.1''. Its basic structure can be interpreted in terms of a magnetic flux sheet or tube that vertically extends through the ambient weak-field or field-free atmosphere with which it is in mechanical equilibrium. A more refined interpretation comes from new three-dimensional magnetohydrodynamic simulations that are capable of reproducing the corrugated shape of magnetic flux concentrations and their signature in the visible continuum. Furthermore it is shown that the characteristic asymmetric shape of the contrast profile of facular granules is an effect of radiative transfer across the rarefied atmosphere of the magnetic flux concentration. I also discuss three-dimensional radiation magnetohydrodynamic simulations of the integral layers from the top of the convection zone to the mid-chromosphere. They show a highly dynamic chromospheric magnetic field, marked by rapidly moving filaments of stronger than average magnetic field that form in the compression zone downstream and along propagating shock fronts. The simulations confirm the picture of flux concentrations that strongly expand through the photosphere into a more homogeneous, space filling chromospheric field. Future directions in the simulation of small-scale magnetic fields are indicated by a few examples of very recent work. ", "machine_text": " Recent progress in the simulation of small-scale magnetic fields has explored the intricate substructures on a scale of 0.1''. It appears that magnetic flux concentrations can extend in a vertical fashion through the atmosphere, resulting in a mechanical equilibrium with the surrounding field-free atmosphere. Advanced three-dimensional magnetohydrodynamic simulations have been able to recreate the curved shapes of these flux concentrations, as well as the asymmetric profile of the associated facular granules caused by radiative transfer. Models now also extend to encompass the full range of layers from the convection zone to the mid-chromosphere, signifying a dynamic chromospheric magnetic field marked by filaments of high field strength propagating within the compression zone along with shock fronts. As such, magnetic flux concentrations appear to expand through the photosphere and into a more homogeneous chromospheric field. Finally, this paper will touch upon recent works to give prospective directions for future simulations of small-scale magnetic fields.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1848}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of the Atmospheric Muon Charge Ratio at TeV Energies with   MINOS'.   The 5.4 kton MINOS far detector has been taking charge-separated cosmic ray muon data since the beginning of August, 2003 at a depth of 2070 meters-water-equivalent in the Soudan Underground Laboratory, Minnesota, USA. The data with both forward and reversed magnetic field running configurations were combined to minimize systematic errors in the determination of the underground muon charge ratio. When averaged, two independent analyses find the charge ratio underground to be 1.374 +/- 0.004 (stat.) +0.012 -0.010(sys.). Using the map of the Soudan rock overburden, the muon momenta as measured underground were projected to the corresponding values at the surface in the energy range 1-7 TeV. Within this range of energies at the surface, the MINOS data are consistent with the charge ratio being energy independent at the two standard deviation level. When the MINOS results are compared with measurements at lower energies, a clear rise in the charge ratio in the energy range 0.3 -- 1.0 TeV is apparent. A qualitative model shows that the rise is consistent with an increasing contribution of kaon decays to the muon charge ratio.  ", "human_text": "  The 5.4 kton MINOS far detector has been taking charge-separated cosmic ray muon data since the beginning of August, 2003 at a depth of 2070 meters-water-equivalent in the Soudan Underground Laboratory, Minnesota, USA. The data with both forward and reversed magnetic field running configurations were combined to minimize systematic errors in the determination of the underground muon charge ratio. When averaged, two independent analyses find the charge ratio underground to be 1.374 +/- 0.004 (stat.) +0.012 -0.010(sys.). Using the map of the Soudan rock overburden, the muon momenta as measured underground were projected to the corresponding values at the surface in the energy range 1-7 TeV. Within this range of energies at the surface, the MINOS data are consistent with the charge ratio being energy independent at the two standard deviation level. When the MINOS results are compared with measurements at lower energies, a clear rise in the charge ratio in the energy range 0.3 -- 1.0 TeV is apparent. A qualitative model shows that the rise is consistent with an increasing contribution of kaon decays to the muon charge ratio. ", "machine_text": " The 5.4 kton MINOS detector located at the Soudan Underground Laboratory in Minnesota, USA has been observing cosmic ray muons since August 2003 at a depth of 2070 meters-water-equivalent. Reversing the magnetic field allowed two analyses to be combined and thereby reduced systematic errors while determining the charge ratio of underground muons, measured to be 1.374 +/- 0.004 (stat.) +0.012 -0.010(sys.). Further analysis of the resulting data, in the energy range 1-7 TeV, showed the charge ratio is consistent with being energy independent at the two standard deviation level. Comparing the MINOS measurements to those at lower energies reveals a rise in the charge ratio between 0.3-1.0 TeV, possibly due to increasing kaon decays contributing to the charge ratio.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3815}
{"prompt": "Rephrase the abstract of an article with title 'Non-resonant and Resonant X-ray Scattering Studies on Multiferroic   TbMn2O5'.   Comprehensive x-ray scattering studies, including resonant scattering at Mn L-edge, Tb L- and M-edges, were performed on single crystals of TbMn2O5. X-ray intensities were observed at a forbidden Bragg position in the ferroelectric phases, in addition to the lattice and the magnetic modulation peaks. Temperature dependences of their intensities and the relation between the modulation wave vectors provide direct evidences of exchange striction induced ferroelectricity. Resonant x-ray scattering results demonstrate the presence of multiple magnetic orders by exhibiting their different temperature dependences. The commensurate-to-incommensurate phase transition around 24 K is attributed to discommensuration through phase slipping of the magnetic orders in spin frustrated geometries. We proposed that the low temperature incommensurate phase consists of the commensurate magnetic domains separated by anti-phase domain walls which reduce spontaneous polarizations abruptly at the transition.  ", "human_text": "  Comprehensive x-ray scattering studies, including resonant scattering at Mn L-edge, Tb L- and M-edges, were performed on single crystals of TbMn2O5. X-ray intensities were observed at a forbidden Bragg position in the ferroelectric phases, in addition to the lattice and the magnetic modulation peaks. Temperature dependences of their intensities and the relation between the modulation wave vectors provide direct evidences of exchange striction induced ferroelectricity. Resonant x-ray scattering results demonstrate the presence of multiple magnetic orders by exhibiting their different temperature dependences. The commensurate-to-incommensurate phase transition around 24 K is attributed to discommensuration through phase slipping of the magnetic orders in spin frustrated geometries. We proposed that the low temperature incommensurate phase consists of the commensurate magnetic domains separated by anti-phase domain walls which reduce spontaneous polarizations abruptly at the transition. ", "machine_text": " In this article, non-resonant and resonant x-ray scattering techniques were applied to single crystals of TbMn2O5 to gain a comprehensive understanding of its properties. Several intensities were detected at forbidden Bragg positions in the ferroelectric phases, as well as lattice and magnetism modulation peaks. Temperature dependent intensity of the peaks and the wave vector connection showed clear proof of exchange striction induced ferroelectricity. Through resonant scattering at Mn L-edge, Tb L- and M-edges, multiple magnetic orders with different temperature dependences were revealed. The transformation from a commensurate to incommensurate phase at 24 K is caused by discommensuration through spin frustration by the phase slipping of the magnetic orders. It is proposed that the low temperature incommensurate phase is formed by the separation of commensurate magnetic domains with anti-phased domain walls significantly reducing the spontaneous polarizations at the transition.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0533}
{"prompt": "Rephrase the abstract of an article with title 'Age constraints in the double pulsar system J0737-3039'.   We investigate the age constraints that can be placed on the double pulsar system using models for the spin-down of the first-born 22.7-ms pulsar A and the 2.77-s pulsar B with characteristic ages of 210 and 50 Myr respectively. Standard models assuming dipolar spin-down of both pulsars suggest that the time since the formation of B is ~50 Myr, i.e. close to B's characteristic age. However, adopting models which account for the impact of A's relativistic wind on B's spin-down we find that the formation of B took place either 80 or 180 Myr ago, depending the interaction mechanism. Formation 80 Myr ago, closer to B's characteristic age, would result in the contribution from J0737-3039 to the inferred coalescence rates for double neutron star binaries increasing by 40%. The 180 Myr age is closer to A's characteristic age and would be consistent with the most recent estimates of the coalescence rate. The new age constraints do not significantly impact recent estimates of the kick velocity, tilt angle between pre and post-supernova orbital planes or pre-supernova mass of B's progenitor.  ", "human_text": "  We investigate the age constraints that can be placed on the double pulsar system using models for the spin-down of the first-born 22.7-ms pulsar A and the 2.77-s pulsar B with characteristic ages of 210 and 50 Myr respectively. Standard models assuming dipolar spin-down of both pulsars suggest that the time since the formation of B is ~50 Myr, i.e. close to B's characteristic age. However, adopting models which account for the impact of A's relativistic wind on B's spin-down we find that the formation of B took place either 80 or 180 Myr ago, depending the interaction mechanism. Formation 80 Myr ago, closer to B's characteristic age, would result in the contribution from J0737-3039 to the inferred coalescence rates for double neutron star binaries increasing by 40%. The 180 Myr age is closer to A's characteristic age and would be consistent with the most recent estimates of the coalescence rate. The new age constraints do not significantly impact recent estimates of the kick velocity, tilt angle between pre and post-supernova orbital planes or pre-supernova mass of B's progenitor. ", "machine_text": " We study the age of the double pulsar system J0737-3039 based on the spin-down of the first-born 22.7-ms pulsar A and the 2.77-s pulsar B, whose characteristic ages are 210 and 50 Myr, respectively. Conventional models for dipolar spin-down of two pulsars suggest that B has only been around for ~50 Myr, close to its characteristic age. Nevertheless, we look into models that take into account the influence of A's relativistic wind on B's spin-down, which reveals that B could have been born 80 or 180 Myr ago depending on which interaction mechanism applies. An 80-Myr age would be closer to the characteristic age of B, while the 180-Myr age would match the recent estimates of coalescence rate. Furthermore, the new age limits have minimal impact on the estimates of kick velocity, pre-supernova mass of B's progenitor, and tilt angle between the pre- and post-supernova orbital planes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3269}
{"prompt": "Rephrase the abstract of an article with title 'Numerical propagation of high energy cosmic rays in the Galaxy I:   technical issues'.   We present the results of a numerical simulation of propagation of cosmic rays with energy above $10^{15}$ eV in a complex magnetic field, made in general of a large scale component and a turbulent component. Several configurations are investigated that may represent specific aspects of a realistic magnetic field of the Galaxy, though the main purpose of this investigation is not to achieve a realistic description of the propagation in the Galaxy, but rather to assess the role of several effects that define the complex problem of propagation. Our simulations of Cosmic Rays in the Galaxy will be presented in Paper II. We identified several effects that are difficult to interpret in a purely diffusive approach and that play a crucial role in the propagation of cosmic rays in the complex magnetic field of the Galaxy. We discuss at length the problem of the extrapolation of our results to much lower energies where data are available on the confinement time of cosmic rays in the Galaxy. The confinement time and its dependence on particles' rigidity are crucial ingredients for 1) relating the source spectrum to the observed cosmic ray spectrum; 2) quantifying the production of light elements by spallation; 3) predicting the anisotropy as a function of energy.  ", "human_text": "  We present the results of a numerical simulation of propagation of cosmic rays with energy above $10^{15}$ eV in a complex magnetic field, made in general of a large scale component and a turbulent component. Several configurations are investigated that may represent specific aspects of a realistic magnetic field of the Galaxy, though the main purpose of this investigation is not to achieve a realistic description of the propagation in the Galaxy, but rather to assess the role of several effects that define the complex problem of propagation. Our simulations of Cosmic Rays in the Galaxy will be presented in Paper II. We identified several effects that are difficult to interpret in a purely diffusive approach and that play a crucial role in the propagation of cosmic rays in the complex magnetic field of the Galaxy. We discuss at length the problem of the extrapolation of our results to much lower energies where data are available on the confinement time of cosmic rays in the Galaxy. The confinement time and its dependence on particles' rigidity are crucial ingredients for 1) relating the source spectrum to the observed cosmic ray spectrum; 2) quantifying the production of light elements by spallation; 3) predicting the anisotropy as a function of energy. ", "machine_text": " In this paper, we discuss the numerical simulation of high energy cosmic ray (above $10^{15}$ eV) propagation through a complex magnetic field composed of a large-scale component and a turbulent component in order to explore potential relevant effects to the problem. We identify a number of effects that are difficult to interpret in a diffusive approach while making an important contribution to Cosmic Ray diffusion in the complex field of the Galaxy. We further assess the effect of this simulation on confinement time of cosmic rays and its dependence on particle rigidity, which is integral in determining source spectra, light element production by spallation, and anisotropy in cosmic ray propagation. These results will be presented and discussed in detail in subsequent paper.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1972}
{"prompt": "Rephrase the abstract of an article with title 'The Unique Type Ib Supernova 2005bf at Nebular Phases: A Possible Birth   Event of A Strongly Magnetized Neutron Star'.   Late phase nebular spectra and photometry of Type Ib Supernova (SN) 2005bf taken by the Subaru telescope at ~ 270 and ~ 310 days since the explosion are presented. Emission lines ([OI]6300, 6363, [CaII]7291, 7324, [FeII]7155) show the blueshift of ~ 1,500 - 2,000 km s-1. The [OI] doublet shows a doubly-peaked profile. The line luminosities can be interpreted as coming from a blob or jet containing only ~ 0.1 - 0.4 Msun, in which ~ 0.02 - 0.06 Msun is 56Ni synthesized at the explosion. To explain the blueshift, the blob should either be of unipolar moving at the center-of-mass velocity v ~ 2,000 - 5,000 km s-1, or suffer from self-absorption within the ejecta as seen in SN 1990I. In both interpretations, the low-mass blob component dominates the optical output both at the first peak (~ 20 days) and at the late phase (~ 300 days). The low luminosity at the late phase (the absolute R magnitude M_R ~ -10.2 mag at ~ 270 days) sets the upper limit for the mass of 56Ni < ~ 0.08 Msun, which is in contradiction to the value necessary to explain the second, main peak luminosity (M_R ~ -18.3 mag at ~ 40 days). Encountered by this difficulty in the 56Ni heating model, we suggest an alternative scenario in which the heating source is a newly born, strongly magnetized neutron star (a magnetar) with the surface magnetic field Bmag ~ 10^{14-15} gauss and the initial spin period P0 ~ 10 ms. Then, SN 2005bf could be a link between normal SNe Ib/c and an X-Ray Flash associated SN 2006aj, connected in terms of Bmag and/or P0.  ", "human_text": "  Late phase nebular spectra and photometry of Type Ib Supernova (SN) 2005bf taken by the Subaru telescope at ~ 270 and ~ 310 days since the explosion are presented. Emission lines ([OI]6300, 6363, [CaII]7291, 7324, [FeII]7155) show the blueshift of ~ 1,500 - 2,000 km s-1. The [OI] doublet shows a doubly-peaked profile. The line luminosities can be interpreted as coming from a blob or jet containing only ~ 0.1 - 0.4 Msun, in which ~ 0.02 - 0.06 Msun is 56Ni synthesized at the explosion. To explain the blueshift, the blob should either be of unipolar moving at the center-of-mass velocity v ~ 2,000 - 5,000 km s-1, or suffer from self-absorption within the ejecta as seen in SN 1990I. In both interpretations, the low-mass blob component dominates the optical output both at the first peak (~ 20 days) and at the late phase (~ 300 days). The low luminosity at the late phase (the absolute R magnitude M_R ~ -10.2 mag at ~ 270 days) sets the upper limit for the mass of 56Ni < ~ 0.08 Msun, which is in contradiction to the value necessary to explain the second, main peak luminosity (M_R ~ -18.3 mag at ~ 40 days). Encountered by this difficulty in the 56Ni heating model, we suggest an alternative scenario in which the heating source is a newly born, strongly magnetized neutron star (a magnetar) with the surface magnetic field Bmag ~ 10^{14-15} gauss and the initial spin period P0 ~ 10 ms. Then, SN 2005bf could be a link between normal SNe Ib/c and an X-Ray Flash associated SN 2006aj, connected in terms of Bmag and/or P0. ", "machine_text": " This article presents late phase spectroscopic and photometric observations of the Type Ib supernova (SN) 2005bf made with the Subaru telescope. Emission lines have been detected with blueshifts of 1,500-2,000 km/s. The line luminosities suggest that a blob or jet containing ~ 0.1-0.4 M_sun of material was driven out near the center-of-mass velocity of ~2,000-5,000 km/s. This, combined with the low optical output at the late phase of these observations would limit the amount of synthesized 56Ni to ~0.08 M_sun. This value contradicts the amount needed to explain the main peak luminosity. An alternative scenario is then proposed to explain the late phase observations; a newly born, strongly magnetized neutron star (magnetar) with a surface magnetic field of ~10^14-15 gauss and an initial spin period of ~10 ms could serve as the heating source. This would link SN 2005bf to seemingly unrelated X-ray Flash events such as SN 2006aj.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2713}
{"prompt": "Rephrase the abstract of an article with title 'A New Tool for Seismology--the Cumulative Spectral Power'.   The power spectral density (PSD) function is commonly used to specify seismometer performance. It is derived from the FFT of acceleration and correction is made for the transfer function of the instrument that generated the data. As with any such spectrum of density (`per Hz') type, the noise inherent to a PSD is large. This article illustrates the value of a function that is derived from the PSD and for which the influence of noise is significantly reduced. Called the cumulative spectral power (CSP), it is obtained from the PSD through the noise-reducing process of integration. The maximum of the CSP (corresponding to the longest graphed value of the period) provides a means for estimating the total vibrational power of the earth. The present author has significantly simplified the process of PSD generation. Thus routine graphing is straightforwared-of first the FFT, followed by the generation of both a PSD and its associated CSP. The unique properties of the CSP make it valuable for the study of a variety of earth dynamics. For example, the strking simplicity of a CSP graph generated from a record containing a strong teleseismic earthquake is undoubtedly important to the development and refinement of any viable theory of earthquake dynamics.  ", "human_text": "  The power spectral density (PSD) function is commonly used to specify seismometer performance. It is derived from the FFT of acceleration and correction is made for the transfer function of the instrument that generated the data. As with any such spectrum of density (`per Hz') type, the noise inherent to a PSD is large. This article illustrates the value of a function that is derived from the PSD and for which the influence of noise is significantly reduced. Called the cumulative spectral power (CSP), it is obtained from the PSD through the noise-reducing process of integration. The maximum of the CSP (corresponding to the longest graphed value of the period) provides a means for estimating the total vibrational power of the earth. The present author has significantly simplified the process of PSD generation. Thus routine graphing is straightforwared-of first the FFT, followed by the generation of both a PSD and its associated CSP. The unique properties of the CSP make it valuable for the study of a variety of earth dynamics. For example, the strking simplicity of a CSP graph generated from a record containing a strong teleseismic earthquake is undoubtedly important to the development and refinement of any viable theory of earthquake dynamics. ", "machine_text": "  This article explores the benefits of a new approach to understanding seismic activity that can reduce the noise inherent to Power Spectral Density (PSD) functions. Called the Cumulative Spectral Power (CSP), it utilizes an integration process that reduces the impact of noise on the data. Its maximum value (corresponding to the longest graphed period) provides an estimate of the level of earth vibrations. This author has streamlined the process of PSD generation, making it easy to graph both PSD and CSP. Furthermore, CSP graphing is useful for examining diverse earth dynamics such as teleseismic earthquakes, and its simplicity is a beneficial tool for refining the relevant theories.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.11}
{"prompt": "Rephrase the abstract of an article with title 'Linkage between Accretion Disks and Blazars'.   The magnetic field in an accretion disk is estimated assuming that all of the angular momentum within prescribed accretion disk radii is removed by a jet. The magnetic field estimated at the base of the jet is extrapolated to the blazar emission region using a model for a relativistic axisymmetric jet combined with some simplifying assumptions based on the relativistic nature of the flow. The extrapolated magnetic field is compared with estimates based upon the synchrotron and inverse Compton emission from three blazars, MKN 501, MKN 421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self- Compton models are inconsistent with the magnetic fields extrapolated in this way. However, in two cases inverse Compton models in which a substantial part of the soft photon field is generated locally agree well, mainly because these models imply magnetic field strengths which are closer to being consistent with Poynting flux dominated jets. This comparison is based on estimating the mass accretion rate from the jet energy flux. Further comparisons along these lines will be facilitated by independent estimates of the mass accretion rate in blazars and by more detailed models for jet propagation near the black hole.  ", "human_text": "  The magnetic field in an accretion disk is estimated assuming that all of the angular momentum within prescribed accretion disk radii is removed by a jet. The magnetic field estimated at the base of the jet is extrapolated to the blazar emission region using a model for a relativistic axisymmetric jet combined with some simplifying assumptions based on the relativistic nature of the flow. The extrapolated magnetic field is compared with estimates based upon the synchrotron and inverse Compton emission from three blazars, MKN 501, MKN 421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self- Compton models are inconsistent with the magnetic fields extrapolated in this way. However, in two cases inverse Compton models in which a substantial part of the soft photon field is generated locally agree well, mainly because these models imply magnetic field strengths which are closer to being consistent with Poynting flux dominated jets. This comparison is based on estimating the mass accretion rate from the jet energy flux. Further comparisons along these lines will be facilitated by independent estimates of the mass accretion rate in blazars and by more detailed models for jet propagation near the black hole. ", "machine_text": " This article examines the relationship between accretion disks and blazars. Magnetic field strength is calculated at the base of the jet and extrapolated to the blazar emission area, based on a relativistic axisymmetric jet model and some relativistic flow assumptions. This extrapolated magnetic field is then compared to the estimated fields formed by synchrotron self-Compton and inverse Compton models. The energy flux of the jet is used to estimate the mass accretion rate, and it is found with pure synchrotron self-Compton models that the field strengths are inconsistent. However, with models incorporating local production of soft photons, a closer agreement is found, primarily due to the fact that these models imply magnetic field strengths that are more similar to those with Poynting flux dominated jets. To further analyze the link between accretion disks and blazars, more detailed models for jet propagation and independent estimation of the mass accretion rate will be required.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2636}
{"prompt": "Rephrase the abstract of an article with title 'Charge and spin stripe in La$_{2-x}$Sr$_{x}$NiO$_{4}$ (x=1/3,1/2)'.   Electronic structure of stripe ordered La$_{2-x}$Sr$_{x}$NiO$_{4}$ is investigated. The system with x=1/3 is insulator, in LSDA+U calculations, and shows charge and spin stripe, consistent with the experimental results. Highly correlated system of x=1/2 is studied by using exact diagonalization of multi-orbital many body Hamiltonian derived from LDA calculations and including on-site and inter-site Coulomb interactions. The fluctuation of the residual spin on Ni$^{3+}$ (hole) site couples with the charge fluctuation between Ni$^{3+}$ and Ni$^{2+}$ states and this correlation lowers the total energy. The resultant ground state is insulator with charge and spin stripe of the energy gap 0.9eV, consistent with observed one. The on-site Coulomb interaction stabilizes integral valency of each Ni ion (Ni$^{3+}$ and Ni$^{2+}$), but does not induce the charge order. Two quantities, inter-site Coulomb interaction and anisotropy of hopping integrals, play an important role to form the charge and spin stripe order in a system of x=1/2.  ", "human_text": "  Electronic structure of stripe ordered La$_{2-x}$Sr$_{x}$NiO$_{4}$ is investigated. The system with x=1/3 is insulator, in LSDA+U calculations, and shows charge and spin stripe, consistent with the experimental results. Highly correlated system of x=1/2 is studied by using exact diagonalization of multi-orbital many body Hamiltonian derived from LDA calculations and including on-site and inter-site Coulomb interactions. The fluctuation of the residual spin on Ni$^{3+}$ (hole) site couples with the charge fluctuation between Ni$^{3+}$ and Ni$^{2+}$ states and this correlation lowers the total energy. The resultant ground state is insulator with charge and spin stripe of the energy gap 0.9eV, consistent with observed one. The on-site Coulomb interaction stabilizes integral valency of each Ni ion (Ni$^{3+}$ and Ni$^{2+}$), but does not induce the charge order. Two quantities, inter-site Coulomb interaction and anisotropy of hopping integrals, play an important role to form the charge and spin stripe order in a system of x=1/2. ", "machine_text": " The electronic structure of La$_{2-x}$Sr$_{x}$NiO$_{4}$ with x=1/3 and 1/2 has been studied to investigate the charge and spin stripe order. For x=1/3, the results from LSDA+U calculations show that the system is an insulator and has both the charge and spin stripe structure, consistent with experimental findings. With x=1/2, an exact diagonalization of a multi-orbital many body Hamiltonian derived from LDA, including on-site and inter-site Coulomb interactions, yields a ground state of an insulator with an energy gap of 0.9eV and charge and spin stripe order. It was found that the on-site Coulomb interaction is essential to ensure integral valency of each Ni ion, though it does not directly trigger the charge order. Instead, the inter-site Coulomb interaction and the anisotropy of hopping integrals are both pertinent to the structure of charge and spin stripe order in the system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3323}
{"prompt": "Rephrase the abstract of an article with title 'Projectile Fragmentation of $^{86}$Kr at 64 MeV/nucleon'.   We measured fragmentation cross sections produced using the primary beam of $^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross sections were obtained by integrating the momentum distributions of isotopes with 25<Z<36 measured using the RIPS fragment separator at RIKEN. The cross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend on the fragment masses, contrary to the simple geometrical models. We compared the extracted cross sections to EPAX; an empirical parameterization of fragmentation cross sections. Predictions from current EPAX parameterization severely overestimate the production cross sections of very neutron-rich isotopes. Attempts to obtain another set of EPAX parameters specific to the reaction studied here, to extrapolate the neutron-rich nuclei more accurately have not been very successful, suggesting that accurate predictions of production cross sections of nuclei far from the valley of stability require information of nuclear properties which are not present in EPAX.  ", "human_text": "  We measured fragmentation cross sections produced using the primary beam of $^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross sections were obtained by integrating the momentum distributions of isotopes with 25<Z<36 measured using the RIPS fragment separator at RIKEN. The cross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend on the fragment masses, contrary to the simple geometrical models. We compared the extracted cross sections to EPAX; an empirical parameterization of fragmentation cross sections. Predictions from current EPAX parameterization severely overestimate the production cross sections of very neutron-rich isotopes. Attempts to obtain another set of EPAX parameters specific to the reaction studied here, to extrapolate the neutron-rich nuclei more accurately have not been very successful, suggesting that accurate predictions of production cross sections of nuclei far from the valley of stability require information of nuclear properties which are not present in EPAX. ", "machine_text": " We conducted an experiment to measure the fragmentation cross sections created by a 64 MeV/nucleon primary beam of $^{86}$Kr nuclei, when impacting upon a $^9$Be and $^{181}$Ta target. We collected data on isotopes in the range 25<Z<36, using the RIPS fragment separator at RIKEN. Our results showed a discrepancy between geometrical predictions and the actual cross-section ratios, and were compared with EPAX; an empirical parameterization for fragmentation cross sections. This comparison suggested that present EPAX formulations tend to overestimate cross sections for highly neutron-rich isotopes. Further analysis via an alternative EPAX parameterization proved unsuccessful, suggesting that accurate predictions for these cross sections require data that EPAX does not supply.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4313}
{"prompt": "Rephrase the abstract of an article with title 'The Nonperiodic Anyon Model and the Fractional Quantum Hall Effect'.   The lowest-Landau-level anyon model becomes nonperiodic in the statistics parameter when the finite size of the attached flux tubes is taken into account. The finite-size effects cause the inverse proportional relation between the critical filling factor and the statistics parameter to be nonperiodically continued in the screening regime, where the fluxes are anti-parallel to the external magnetic field -- at critical filling, the external magnetic field is entirely screened by the mean magnetic field associated with the flux tubes. A clustering argument is proposed to select particular values of the statistics parameter. In this way, IQHE and FQHE fillings are obtained in terms of gapped nondegenerate LLL-anyonic wave functions. Jain's series are reproduced without the need to populate higher Landau levels. New FQHE series are proposed, like, in particular, the particle-hole complementary series of the Laughlin one. For fast-rotating Bose-Einstein condensates, a corresponding clustering argument yields particular fractional filling series.  ", "human_text": "  The lowest-Landau-level anyon model becomes nonperiodic in the statistics parameter when the finite size of the attached flux tubes is taken into account. The finite-size effects cause the inverse proportional relation between the critical filling factor and the statistics parameter to be nonperiodically continued in the screening regime, where the fluxes are anti-parallel to the external magnetic field -- at critical filling, the external magnetic field is entirely screened by the mean magnetic field associated with the flux tubes. A clustering argument is proposed to select particular values of the statistics parameter. In this way, IQHE and FQHE fillings are obtained in terms of gapped nondegenerate LLL-anyonic wave functions. Jain's series are reproduced without the need to populate higher Landau levels. New FQHE series are proposed, like, in particular, the particle-hole complementary series of the Laughlin one. For fast-rotating Bose-Einstein condensates, a corresponding clustering argument yields particular fractional filling series. ", "machine_text": " The Nonperiodic Anyon Model is examined to explain the Fractional Quantum Hall Effect (FQHE) in terms of LLL-anyonic wave functions. Taking into account the finite size of flux tubes, the model establishes an inverse proportional relation between the critical filling factor and the parameter of statistical exchange. When the fluxes are anti-parallel to the external magnetic field and critical filling is achieved, the external magnetic field is completely shielded by the mean magnetic field associated with the flux tubes. Utilizing the clustering argument, values for the statistical parameter can be chosen to ensure the fillings match those proposed by Jain's series, as well as new FQHE series like the particle-hole complementary to the Laughlin one. This same clustering argument can be used to produce particular fractional filling series in fast-rotating Bose-Einstein condensates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2474}
{"prompt": "Rephrase the abstract of an article with title 'Results of the IGEC-2 search for gravitational wave bursts during 2005'.   The network of resonant bar detectors of gravitational waves resumed coordinated observations within the International Gravitational Event Collaboration (IGEC-2). Four detectors are taking part in this collaboration: ALLEGRO, AURIGA, EXPLORER and NAUTILUS. We present here the results of the search for gravitational wave bursts over 6 months during 2005, when IGEC-2 was the only gravitational wave observatory in operation. The network data analysis implemented is based on a time coincidence search among AURIGA, EXPLORER and NAUTILUS, keeping the data from ALLEGRO for follow-up studies. With respect to the previous IGEC 1997-2000 observations, the amplitude sensitivity of the detectors to bursts improved by a factor about 3 and the sensitivity bandwidths are wider, so that the data analysis was tuned considering a larger class of detectable waveforms. Thanks to the higher duty cycles of the single detectors, we decided to focus the analysis on three-fold observation, so to ensure the identification of any single candidate of gravitational waves (gw) with high statistical confidence. The achieved false detection rate is as low as 1 per century. No candidates were found.  ", "human_text": "  The network of resonant bar detectors of gravitational waves resumed coordinated observations within the International Gravitational Event Collaboration (IGEC-2). Four detectors are taking part in this collaboration: ALLEGRO, AURIGA, EXPLORER and NAUTILUS. We present here the results of the search for gravitational wave bursts over 6 months during 2005, when IGEC-2 was the only gravitational wave observatory in operation. The network data analysis implemented is based on a time coincidence search among AURIGA, EXPLORER and NAUTILUS, keeping the data from ALLEGRO for follow-up studies. With respect to the previous IGEC 1997-2000 observations, the amplitude sensitivity of the detectors to bursts improved by a factor about 3 and the sensitivity bandwidths are wider, so that the data analysis was tuned considering a larger class of detectable waveforms. Thanks to the higher duty cycles of the single detectors, we decided to focus the analysis on three-fold observation, so to ensure the identification of any single candidate of gravitational waves (gw) with high statistical confidence. The achieved false detection rate is as low as 1 per century. No candidates were found. ", "machine_text": " The International Gravitational Event Collaboration (IGEC-2) utilized the internationally recognized network of resonant bar detectors to coordinate observations of gravitational wave bursts over a 6-month period in 2005. These four detectors - ALLEGRO, AURIGA, EXPLORER and NAUTILUS - had improved sensitivities over IGEC 1997-2000 observations, due to enhanced duty cycles and wider bandwidths. The data analysis focused on threefold observation to ensure a strong statistical confidence if a candidate of gravitational waves were to be found. A false detection rate of 1 per century was achieved, yet no candidate events were located.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0688}
{"prompt": "Rephrase the abstract of an article with title 'The power of quantum systems on a line'.   We study the computational strength of quantum particles (each of finite dimensionality) arranged on a line. First, we prove that it is possible to perform universal adiabatic quantum computation using a one-dimensional quantum system (with 9 states per particle). This might have practical implications for experimentalists interested in constructing an adiabatic quantum computer. Building on the same construction, but with some additional technical effort and 12 states per particle, we show that the problem of approximating the ground state energy of a system composed of a line of quantum particles is QMA-complete; QMA is a quantum analogue of NP. This is in striking contrast to the fact that the analogous classical problem, namely, one-dimensional MAX-2-SAT with nearest neighbor constraints, is in P. The proof of the QMA-completeness result requires an additional idea beyond the usual techniques in the area: Not all illegal configurations can be ruled out by local checks, so instead we rule out such illegal configurations because they would, in the future, evolve into a state which can be seen locally to be illegal. Our construction implies (assuming the quantum Church-Turing thesis and that quantum computers cannot efficiently solve QMA-complete problems) that there are one-dimensional systems which take an exponential time to relax to their ground states at any temperature, making them candidates for being one-dimensional spin glasses.  ", "human_text": "  We study the computational strength of quantum particles (each of finite dimensionality) arranged on a line. First, we prove that it is possible to perform universal adiabatic quantum computation using a one-dimensional quantum system (with 9 states per particle). This might have practical implications for experimentalists interested in constructing an adiabatic quantum computer. Building on the same construction, but with some additional technical effort and 12 states per particle, we show that the problem of approximating the ground state energy of a system composed of a line of quantum particles is QMA-complete; QMA is a quantum analogue of NP. This is in striking contrast to the fact that the analogous classical problem, namely, one-dimensional MAX-2-SAT with nearest neighbor constraints, is in P. The proof of the QMA-completeness result requires an additional idea beyond the usual techniques in the area: Not all illegal configurations can be ruled out by local checks, so instead we rule out such illegal configurations because they would, in the future, evolve into a state which can be seen locally to be illegal. Our construction implies (assuming the quantum Church-Turing thesis and that quantum computers cannot efficiently solve QMA-complete problems) that there are one-dimensional systems which take an exponential time to relax to their ground states at any temperature, making them candidates for being one-dimensional spin glasses. ", "machine_text": " We investigate the potential of quantum particles arranged in a line to perform universal adiabatic quantum computing. With nine states per particle, we prove this to be possible. This finding has possible applications for those looking to build adiabatic quantum computers. By adding some more technical effort and increasing the number of states to twelve, we demonstrate that state energy approximation becomes QMA-complete. This is in stark comparison to the analogous classical problem, which is contained in P. To prove this, the usual methods are not sufficient and so we had to find an additional way - ruling out all illegal configurations by accounting for how they will evolve in the future. Our results show that, if the quantum Church-Turing thesis is accepted and quantum computers cannot efficiently solve QMA-complete problems, one-dimensional systems that take exponential time to reach their ground state may appear as one-dimensional spin glasses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4077}
{"prompt": "Rephrase the abstract of an article with title 'Host Galaxy Bulge Predictors of Supermassive Black Hole Mass'.   A variety of host galaxy (bulge) parameters are examined in order to determine their predictive power in ascertaining the masses of the supermassive black holes (SMBH) at the centers of the galaxies. Based on a sample of 23 nearby galaxies, comprised of both elliptical galaxies and spiral/lenticular bulges, we identify a strong correlation between the bulge gravitational binding energy ($E_g$), as traced by the stellar light profile, and the SMBH mass ($M_{\\bullet}$), such that $M_{\\bullet} \\propto E_g^{0.6}$. The scatter about the relationship indicates that this is as strong a predictor of $M_{\\bullet}$ as the velocity dispersion ($\\sigma$), for the elliptical galaxy subsample. Improved mass-to-light ratios, obtained with IFU spectroscopy and I-band photometry by the SAURON group, were used for those sample galaxies where available, resulting in an energy predictor with the same slope, but with reduced scatter. Alternative $M_{\\bullet}$ predictors such as the gravitational potential and the bulge mass are also explored, but these are found to be inferior when compared with both the bulge gravitational binding energy and bulge velocity dispersion predictors, for the full galaxy sample.  ", "human_text": "  A variety of host galaxy (bulge) parameters are examined in order to determine their predictive power in ascertaining the masses of the supermassive black holes (SMBH) at the centers of the galaxies. Based on a sample of 23 nearby galaxies, comprised of both elliptical galaxies and spiral/lenticular bulges, we identify a strong correlation between the bulge gravitational binding energy ($E_g$), as traced by the stellar light profile, and the SMBH mass ($M_{\\bullet}$), such that $M_{\\bullet} \\propto E_g^{0.6}$. The scatter about the relationship indicates that this is as strong a predictor of $M_{\\bullet}$ as the velocity dispersion ($\\sigma$), for the elliptical galaxy subsample. Improved mass-to-light ratios, obtained with IFU spectroscopy and I-band photometry by the SAURON group, were used for those sample galaxies where available, resulting in an energy predictor with the same slope, but with reduced scatter. Alternative $M_{\\bullet}$ predictors such as the gravitational potential and the bulge mass are also explored, but these are found to be inferior when compared with both the bulge gravitational binding energy and bulge velocity dispersion predictors, for the full galaxy sample. ", "machine_text": " By using a sample of 23 nearby elliptical galaxies and spiral/lenticular bulges, it has been found that there is an influential correlation between the mass of the supermassive black hole (SMBH) and the gravitational binding energy of the bulge, as measured by the stellar light profiles. It was revealed that $M_{\\bullet}$ corresponds directly to $E_g^{0.6}$, with a scatter that suggests this is as reliable a predictor as the bulge's velocity dispersion, at least in the case of ellipticals. Even so, alternative $M_{\\bullet}$ predictors such as the gravitational potential and the bulge mass were observed to be weaker when comparing across the entire sample population. With the aid of IFU spectroscopy and I-band photometry by the SAURON group, new mass-to-light ratios were used for some of the galaxies, leading to an energy predictor with an identical slope but with reduced deviation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1165}
{"prompt": "Rephrase the abstract of an article with title 'Direct determination of the epicycle frequency in the galactic disk, and   the derived rotation velocity V0'.   We present a method which allows a direct measurement of the epicycle frequency $\\kappa$ in the galactic disk, using the large database on open clusters completed by our group. The observed velocity vector (amplitude and direction) of the clusters in the galactic plane is derived from the catalog data. In the epicycle approximation, this velocity is the sum of the circular velocity, described by the galactic rotation curve, and of a residual velocity, which has a direction that rotates with the frequency $\\kappa$. If for some reason the clusters are formed with non-random initial perturbation velocity direction (measured for instance with respect to the direction of circular rotation), then a plot of the orientation angle of the residual velocity as a function of age reveals the epicycle frequency. The data analysis confirms that this is the case; due to the non-random initial velocities, it is possible to measure $\\kappa$ for different galactic radii. Our analysis considers that the effect of the arms on the stellar orbits is small (the Galactic potential is mainly axis-symmetric); in this sense our results do not depend on any specific model of the spiral structure, like the existence of a given number of spiral arms, or on a particular choice of the radius of corotation. The values of $\\kappa$ provide constraints on the rotation velocity of the disk and on its minimum beyond the solar radius; in particular, $V_0$ is found to be 226 $\\pm$ 15 kms$^{-1}$ even if the short scale (R$_0$ = 7.5 kpc) of the galaxy is adopted. The mesured $\\kappa$ at the solar radius is 42$\\pm$4 kms$^{-1}$kpc$^{-1}$.  ", "human_text": "  We present a method which allows a direct measurement of the epicycle frequency $\\kappa$ in the galactic disk, using the large database on open clusters completed by our group. The observed velocity vector (amplitude and direction) of the clusters in the galactic plane is derived from the catalog data. In the epicycle approximation, this velocity is the sum of the circular velocity, described by the galactic rotation curve, and of a residual velocity, which has a direction that rotates with the frequency $\\kappa$. If for some reason the clusters are formed with non-random initial perturbation velocity direction (measured for instance with respect to the direction of circular rotation), then a plot of the orientation angle of the residual velocity as a function of age reveals the epicycle frequency. The data analysis confirms that this is the case; due to the non-random initial velocities, it is possible to measure $\\kappa$ for different galactic radii. Our analysis considers that the effect of the arms on the stellar orbits is small (the Galactic potential is mainly axis-symmetric); in this sense our results do not depend on any specific model of the spiral structure, like the existence of a given number of spiral arms, or on a particular choice of the radius of corotation. The values of $\\kappa$ provide constraints on the rotation velocity of the disk and on its minimum beyond the solar radius; in particular, $V_0$ is found to be 226 $\\pm$ 15 kms$^{-1}$ even if the short scale (R$_0$ = 7.5 kpc) of the galaxy is adopted. The mesured $\\kappa$ at the solar radius is 42$\\pm$4 kms$^{-1}$kpc$^{-1}$. ", "machine_text": " We have developed a technique for direct determination of the epicycle frequency $\\kappa$ in the galactic disk from a large database of open clusters. From the catalog data, we evaluated the observed velocity vector (direction and magnitude) of the clusters in the galactic plane. For large-scale asymmetric structures as galaxies, the residual velocity in the disk has a direction rotating with the frequency $\\kappa$ and the circular velocity is in determined by the galactic rotation curve. By observing any non-random initial velocities in the clusters, plot of the orientation angle of the velocity as a function of age reveals the epicycle frequency. Analysis of the data confirmed this non-random direction and enabled us to measure $\\kappa$ for different galactic radii. Our results are independent of Galactic arm models, such as the number of spiral arms or the particular choice of the radius of corotation. We obtained results indicating a minimum rotation velocity beyond the solar radius of 226 $\\pm$ 15 kms$^{-1}$ and a $\\kappa$ of 42 $\\pm$ 4 kms$^{-1}$kpc$^{-1}$ at the solar radius.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1811}
{"prompt": "Rephrase the abstract of an article with title 'Molecular opacities for low-mass metal-poor AGB stars undergoing the   Third Dredge Up'.   The concomitant overabundances of C, N and s-process elements are commonly ascribed to the complex interplay of nucleosynthesis, mixing and mass loss taking place in Asymptotic Giant Branch stars. At low metallicity, the enhancement of C and/or N may be up to 1000 times larger than the original iron content and significantly affects the stellar structure and its evolution. For this reason, the interpretation of the already available and still growing amount of data concerning C-rich metal-poor stars belonging to our Galaxy as well as to dwarf spheroidal galaxies would require reliable AGB stellar models for low and very low metallicities. In this paper we address the question of calculation and use of appropriate opacity coefficients, which take into account the C enhancement caused by the third dredge up. A possible N enhancement, caused by the cool bottom process or by the engulfment of protons into the convective zone generated by a thermal pulse and the subsequent huge third dredge up, is also considered. Basing on up-to-date stellar models, we illustrate the changes induced by the use of these opacity on the physical and chemical properties expected for these stars.  ", "human_text": "  The concomitant overabundances of C, N and s-process elements are commonly ascribed to the complex interplay of nucleosynthesis, mixing and mass loss taking place in Asymptotic Giant Branch stars. At low metallicity, the enhancement of C and/or N may be up to 1000 times larger than the original iron content and significantly affects the stellar structure and its evolution. For this reason, the interpretation of the already available and still growing amount of data concerning C-rich metal-poor stars belonging to our Galaxy as well as to dwarf spheroidal galaxies would require reliable AGB stellar models for low and very low metallicities. In this paper we address the question of calculation and use of appropriate opacity coefficients, which take into account the C enhancement caused by the third dredge up. A possible N enhancement, caused by the cool bottom process or by the engulfment of protons into the convective zone generated by a thermal pulse and the subsequent huge third dredge up, is also considered. Basing on up-to-date stellar models, we illustrate the changes induced by the use of these opacity on the physical and chemical properties expected for these stars. ", "machine_text": "This article examines the effect of C and/or N enhancement on the stellar structure and evolution of low-metallicity stars in the Asymptotic Giant Branch phase. In particular, we focus on the usage of appropriate opacity coefficients, to account for the potential C enrichment caused by the third dredge up, and the possible N enrichment due to a cool bottom process or by the ingestion of protons into the convective zone post-thermal pulse. Through calculation of up-to-date stellar models, our paper illustrates the changes manifested in the physical and chemical characteristics of these stars due to the adjusted opacities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.21}
{"prompt": "Rephrase the abstract of an article with title 'Virtual Photon Emission from Quark-Gluon Plasma'.   We recently proposed an empirical approach for the Landau-Pomeranchuk-Migdal (LPM) effects in photon emission from the quark gluon plasma as a function of photon mass. This approach was based on Generalized Emission Functions (GEF) for photon emission, derived at a fixed temperature and strong coupling constant. In the present work, we have extended the LPM calculations for several temperatures and strong coupling strengths. The integral equations for (${\\bf \\tilde{f}(\\tilde{p}_\\perp)}$) and ($\\tilde{g}({\\bf \\tilde{p}_\\perp})$) are solved by the iterations method for the variable set \\{$p_0,q_0,Q^2,T,\\alpha_s$\\}, considering bremsstrahlung and $\\bf aws$ processes. We generalize the dynamical scaling variables, $x_T$, $x_L$, for bremsstrahlung and {\\bf aws} processes which are now functions of variables $p_0,q_0,Q^2,T,\\alpha_s$. The GEF introduced earlier, $g^b_T$, $g^a_T$, $g^b_L$, $g^a_L$, are also generalized for any temperatures and coupling strengths. From this, the imaginary part of the photon polarization tensor as a function of photon mass and energy can be calculated as a one dimensional integral over these GEF and parton distribution functions in the plasma. However, for phenomenological studies of experimental data, one needs a simple empirical formula without involving parton momentum integrations. Therefore, we present a phenomenological formula for imaginary photon polarization tensor as a function of \\{$q_0,Q^2,T,\\alpha_s$\\} that includes bremsstrahlung and $\\bf aws$ mechanisms along with LPM effects.  ", "human_text": "  We recently proposed an empirical approach for the Landau-Pomeranchuk-Migdal (LPM) effects in photon emission from the quark gluon plasma as a function of photon mass. This approach was based on Generalized Emission Functions (GEF) for photon emission, derived at a fixed temperature and strong coupling constant. In the present work, we have extended the LPM calculations for several temperatures and strong coupling strengths. The integral equations for (${\\bf \\tilde{f}(\\tilde{p}_\\perp)}$) and ($\\tilde{g}({\\bf \\tilde{p}_\\perp})$) are solved by the iterations method for the variable set \\{$p_0,q_0,Q^2,T,\\alpha_s$\\}, considering bremsstrahlung and $\\bf aws$ processes. We generalize the dynamical scaling variables, $x_T$, $x_L$, for bremsstrahlung and {\\bf aws} processes which are now functions of variables $p_0,q_0,Q^2,T,\\alpha_s$. The GEF introduced earlier, $g^b_T$, $g^a_T$, $g^b_L$, $g^a_L$, are also generalized for any temperatures and coupling strengths. From this, the imaginary part of the photon polarization tensor as a function of photon mass and energy can be calculated as a one dimensional integral over these GEF and parton distribution functions in the plasma. However, for phenomenological studies of experimental data, one needs a simple empirical formula without involving parton momentum integrations. Therefore, we present a phenomenological formula for imaginary photon polarization tensor as a function of \\{$q_0,Q^2,T,\\alpha_s$\\} that includes bremsstrahlung and $\\bf aws$ mechanisms along with LPM effects. ", "machine_text": " We have developed a novel empirical approach for calculating the Landau-Pomeranchuk-Migdal (LPM) effects on virtual photon emission from quark-gluon plasma. To do this, we have extended the original model of generalized emission functions (GEF) to account for different temperatures and strong coupling strengths. In addition, the dynamical scaling variable $x_T$ and $x_L$ have been generalized to include the parameters $p_0, q_0, Q^2, T,   \\alpha_s$. Moreover, the GEF, $g^b_T, g^a_T, g^b_L, g^a_L$, have also been adapted for varying temperatures and couplings. This allows us to calculate the imaginary part of the photon polarization tensor as a function of photon mass and energy. To which end, we have put forth a phenomenological formula for the imaginary photon polarization tensor as a function of \\{$q_0, Q^2, T, \\alpha_s$\\}, to simplify experimental investigations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3676}
{"prompt": "Rephrase the abstract of an article with title 'Matched Filtering of Numerical Relativity Templates of Spinning Binary   Black Holes'.   Tremendous progress has been made towards the solution of the binary-black-hole problem in numerical relativity. The waveforms produced by numerical relativity will play a role in gravitational wave detection as either test-beds for analytic template banks or as template banks themselves. As the parameter space explored by numerical relativity expands, the importance of quantifying the effect that each parameter has on first the detection of gravitational waves and then the parameter estimation of their sources increases. In light of this, we present a study of equal-mass, spinning binary-black-hole evolutions through matched filtering techniques commonly used in data analysis. We study how the match between two numerical waveforms varies with numerical resolution, initial angular momentum of the black holes and the inclination angle between the source and the detector. This study is limited by the fact that the spinning black-hole-binaries are oriented axially and the waveforms only contain approximately two and a half orbits before merger. We find that for detection purposes, spinning black holes require the inclusion of the higher harmonics in addition to the dominant mode, a condition that becomes more important as the black-hole-spins increase. In addition, we conduct a preliminary investigation of how well a template of fixed spin and inclination angle can detect target templates of arbitrary spin and inclination for the axial case considered here.  ", "human_text": "  Tremendous progress has been made towards the solution of the binary-black-hole problem in numerical relativity. The waveforms produced by numerical relativity will play a role in gravitational wave detection as either test-beds for analytic template banks or as template banks themselves. As the parameter space explored by numerical relativity expands, the importance of quantifying the effect that each parameter has on first the detection of gravitational waves and then the parameter estimation of their sources increases. In light of this, we present a study of equal-mass, spinning binary-black-hole evolutions through matched filtering techniques commonly used in data analysis. We study how the match between two numerical waveforms varies with numerical resolution, initial angular momentum of the black holes and the inclination angle between the source and the detector. This study is limited by the fact that the spinning black-hole-binaries are oriented axially and the waveforms only contain approximately two and a half orbits before merger. We find that for detection purposes, spinning black holes require the inclusion of the higher harmonics in addition to the dominant mode, a condition that becomes more important as the black-hole-spins increase. In addition, we conduct a preliminary investigation of how well a template of fixed spin and inclination angle can detect target templates of arbitrary spin and inclination for the axial case considered here. ", "machine_text": " This paper carries out a detailed investigation into the effects of numerical resolution, black hole spin, and inclination angle on the detectability of equal-mass, spinning binary black holes using matched filtering techniques, commonly employed in data analysis. Results from our study suggest that higher harmonics are necessary for accurate detection of spinning binary black holes and can become increasingly important as their spins increase. We also present a preliminary analysis on how well a template of fixed spin and inclination can detect signals of arbitrary spin and inclination by sticking to the axial case scanned in this research. Our findings demonstrate the importance of the parameter space explored by numerical relativity and its implications for the detection of gravitational waves and the subsequent parameter estimation of their sources.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3829}
{"prompt": "Rephrase the abstract of an article with title 'Reexamining the Einstein-Podolsky-Rosen experiment, photon correlation   and Bell's inequality'.   The purpose of this article is to show that the introduction of hidden variables to describe individual events is fully consistent with the statistical predictions of quantum theory. We illustrate the validity of this assertion by discussing two fundamental experiments on correlated photons which are believed to behave ``violently non-classical''. Our considerations carry over to correlated pairs of neutral particles of spin one-half in a singlet state. Much in the spirit of Einstein's conviction we come to the conclusion that the state vector of a system does not provide an exhaustive description of the individual physical system. We also briefly discuss an experiment on ``quantum teleportation'' and demonstrate that our completely local approach leads to a full understanding of the experiment indicating the absence of any teleportation phenomenon. We caution that the indiscriminated use of the term ``Quantum Theory'' tends to obscure distinct differences between the quantum mechanics of massive particles and the propagation of photons. It is emphasized that the properties of polarizers, beam splitters, halfwave plates etc. used in photon-correlation experiments are defined by the laws of classical optics. Hence, understanding the outcome of those experiments requires a well-founded interconnection between classical and quantum electrodynamics free from unnecessary hypotheses.  ", "human_text": "  The purpose of this article is to show that the introduction of hidden variables to describe individual events is fully consistent with the statistical predictions of quantum theory. We illustrate the validity of this assertion by discussing two fundamental experiments on correlated photons which are believed to behave ``violently non-classical''. Our considerations carry over to correlated pairs of neutral particles of spin one-half in a singlet state. Much in the spirit of Einstein's conviction we come to the conclusion that the state vector of a system does not provide an exhaustive description of the individual physical system. We also briefly discuss an experiment on ``quantum teleportation'' and demonstrate that our completely local approach leads to a full understanding of the experiment indicating the absence of any teleportation phenomenon. We caution that the indiscriminated use of the term ``Quantum Theory'' tends to obscure distinct differences between the quantum mechanics of massive particles and the propagation of photons. It is emphasized that the properties of polarizers, beam splitters, halfwave plates etc. used in photon-correlation experiments are defined by the laws of classical optics. Hence, understanding the outcome of those experiments requires a well-founded interconnection between classical and quantum electrodynamics free from unnecessary hypotheses. ", "machine_text": " This article explores the notion that introducing hidden variables can still abide by the statistical predictions of quantum theory. This is shown by two pivotal experiments with correlated photons, where their behavior is deemed 'violently non-classical'. The conclusion reached is similar to Einstein's persuasion - that the expression of a system's state is not a sufficient explanation of its physical state. The experiment of quantum teleportation is then briefly looked into, and it is concluded that a classical approach can be a complete understanding of the outcome, where no teleportation has occurred. Attention is also drawn to the potential of overlooking the differences between quantum mechanics for massive particles, and the behavior of photons. Classical electrodynamics is looked to as the answer, and this requires a link between the two ideas without any speculative ideas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2568}
{"prompt": "Rephrase the abstract of an article with title 'Chemical and Dynamical Properties of the Stellar Halo'.   The difference in density profiles of the contributions from different density peaks to dark matter halos results in certain expectations about the Milky Way's stellar halo. We cut our simulated halo stars into two populations: those forming before/during the last major merger, and those accreted after the last major merger. The former population are more centrally located at z=0, while stars forming in low mass late forming proto-galaxies are spread through the halo. A difference in observed binding energy distinguishes these two populations. We look at possible chemical abundance signatures of the two populations. We also show that galaxies forming in isolated low sigma peaks will form from primordial material. Thus, even though the oldest stars are centrally concentrated as they originated in the early collapsing, densest regions, primordial stars would be found distributed throughout the halo. Thus, the lack of observed metal free stars can be taken as directly constraining the Population III IMF, and the lowest metallicity observed stars can be interpreted as holding clues to the chemical yields of Pop III stars.  ", "human_text": "  The difference in density profiles of the contributions from different density peaks to dark matter halos results in certain expectations about the Milky Way's stellar halo. We cut our simulated halo stars into two populations: those forming before/during the last major merger, and those accreted after the last major merger. The former population are more centrally located at z=0, while stars forming in low mass late forming proto-galaxies are spread through the halo. A difference in observed binding energy distinguishes these two populations. We look at possible chemical abundance signatures of the two populations. We also show that galaxies forming in isolated low sigma peaks will form from primordial material. Thus, even though the oldest stars are centrally concentrated as they originated in the early collapsing, densest regions, primordial stars would be found distributed throughout the halo. Thus, the lack of observed metal free stars can be taken as directly constraining the Population III IMF, and the lowest metallicity observed stars can be interpreted as holding clues to the chemical yields of Pop III stars. ", "machine_text": " This study investigates the chemical signatures and dynamical properties of the Milky Way's stellar halo. We analyze simulated halo stars divided into two different populations: those that formed before/during the last major merger, and those that came from accretion of substructures after that event. Comparing the binding energy of stars within the two groups shows that the former are mainly located closer to the center at z=0, whereas those originating in small scale merging structures are spread through the halo. We also explore what possible chemical abundance signatures these two populations may exhibit. Additionally, it is predicted that primordial stars are spread throughout the halo, while the oldest stars are still mainly situated in the early collapsing, densest regions. Our findings lend support to the notion that the lack of metal-free stars indicates a constraint on the Population III initial mass function, and that the lowest metallicity stars may hold clues to the chemical yields of Population III stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0347}
{"prompt": "Rephrase the abstract of an article with title 'Massive gravity and structure formation'.   We study the growth of cosmological perturbations in the model of Lorentz-violating massive gravity. The Friedman equation in this model acquires an unconventional term due to the Lorentz-breaking condensates which has the equation of state w = -1 / (3 gamma) with gamma being a free parameter taking values outside of the range [0,1/3]. Apart from the standard contributions, the perturbations above the Friedmann background contain an extra piece which is proportional to an arbitrary function theta(x) of the space coordinates. This function appears as an integration constant and corresponds to a non-propagating scalar mode which may, however, become dynamical with the account of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1 the ``anomalous'' perturbations grow slower than the standard ones and thus the model is compatible with observations. Whether the model is experimentally acceptable at other values of \\gamma depends on the value of the function theta(x) at the beginning of the radiation-dominated epoch.  ", "human_text": "  We study the growth of cosmological perturbations in the model of Lorentz-violating massive gravity. The Friedman equation in this model acquires an unconventional term due to the Lorentz-breaking condensates which has the equation of state w = -1 / (3 gamma) with gamma being a free parameter taking values outside of the range [0,1/3]. Apart from the standard contributions, the perturbations above the Friedmann background contain an extra piece which is proportional to an arbitrary function theta(x) of the space coordinates. This function appears as an integration constant and corresponds to a non-propagating scalar mode which may, however, become dynamical with the account of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1 the ``anomalous'' perturbations grow slower than the standard ones and thus the model is compatible with observations. Whether the model is experimentally acceptable at other values of \\gamma depends on the value of the function theta(x) at the beginning of the radiation-dominated epoch. ", "machine_text": "We investigate structure formation in the context of massive gravity which violates Lorentz symmetry. The equations governing this system produce an unusual term with an equation of state w = -1 / (3 gamma) for the Friedman equation. Additionally, perturbations above the Friedmann background contain an extra contribution that is proportional to a non-propagating scalar mode. Depending on the value of gamma, this mode may or may not be dynamical. For gamma between -1 and 0, the extra terms produce perturbations that grow slower than expected, making the model compatible with observations. To fully elucidate whether this model is experimentally viable, the values of the scalar mode theta(x) must be evaluated at the beginning of the radiation-dominated epoch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1301}
{"prompt": "Rephrase the abstract of an article with title 'A possible explanation why the Theta+ is seen in some experiments and   not in others'.   To understand the whole set of positive and null data on the Theta+(1530)-production, we suggest the hypothesis that multiquark hadrons are mainly generated from many-quark states, which emerge either as short-term hadron fluctuations, or as hadron remnants in hard processes. This approach allows us to describe both non-observation of the Theta+ in current null experiments and peculiar features of its production in positive experiments. Further, we are able to propose new experiments that might be decisive for the problem of the Theta+ existence. Distributions of the Theta+ in such experiments can give important information both on higher Fock components of conventional hadrons and about structure and hadronization properties of hadron remnants produced in hard processes. We also explain that description of multiquark hadrons may require a modified form of the constituent quark model, with quark masses and couplings being intermediate between their values for the familiar constituent quarks and the current ones.  ", "human_text": "  To understand the whole set of positive and null data on the Theta+(1530)-production, we suggest the hypothesis that multiquark hadrons are mainly generated from many-quark states, which emerge either as short-term hadron fluctuations, or as hadron remnants in hard processes. This approach allows us to describe both non-observation of the Theta+ in current null experiments and peculiar features of its production in positive experiments. Further, we are able to propose new experiments that might be decisive for the problem of the Theta+ existence. Distributions of the Theta+ in such experiments can give important information both on higher Fock components of conventional hadrons and about structure and hadronization properties of hadron remnants produced in hard processes. We also explain that description of multiquark hadrons may require a modified form of the constituent quark model, with quark masses and couplings being intermediate between their values for the familiar constituent quarks and the current ones. ", "machine_text": " This article attempts to explain the mixed results on the Theta+(1530) detected in some experiments, while not seen in others. We suggest that multiquark hadrons are formed by many different quark states, and could be present in short-lived fluctuations or left over as remnants of hard processes. This notion can account for the inconsistencies between both outcomes. Moreover, new experiments which might be decisive in understanding the Theta+ can be proposed focusing on its distributions within them. Additionally, understanding multiquark hadrons might necessitate modifications of the traditional quark model with updated couplings and masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3045}
{"prompt": "Rephrase the abstract of an article with title 'A very massive runaway star from Cygnus OB2'.   Aims: We analyze the available information on the star BD+43 3654 to investigate the possibility that it may have had its origin in the massive OB association Cygnus OB2.   Methods: We present new spectroscopic observations allowing a reliable spectral classification of the star, and discuss existing MSX observations of its associated bow shock and astrometric information not previously studied.   Results: Our observations reveal that BD+43 3654 is a very early and luminous star of spectral type O4If, with an estimated mass of (70 +/- 15) solar masses and an age of about 1.6 Myr. The high spatial resolution of the MSX observations allows us to determine its direction of motion in the plane of the sky by means of the symmetry axis of the well-defined bow shock, which matches well the orientation expected from the proper motion. Tracing back its path across the sky we find that BD+43 3654 was located near the central, densest region of Cygnus OB2 at a time in the past similar to its estimated age.   Conclusions: BD+43 3654 turns out to be one of the three most massive runaway stars known, and it most likely formed in the central region of Cygnus OB2. A runaway formation mechanism by means of dynamical ejection is consistent with our results.  ", "human_text": "  Aims: We analyze the available information on the star BD+43 3654 to investigate the possibility that it may have had its origin in the massive OB association Cygnus OB2.   Methods: We present new spectroscopic observations allowing a reliable spectral classification of the star, and discuss existing MSX observations of its associated bow shock and astrometric information not previously studied.   Results: Our observations reveal that BD+43 3654 is a very early and luminous star of spectral type O4If, with an estimated mass of (70 +/- 15) solar masses and an age of about 1.6 Myr. The high spatial resolution of the MSX observations allows us to determine its direction of motion in the plane of the sky by means of the symmetry axis of the well-defined bow shock, which matches well the orientation expected from the proper motion. Tracing back its path across the sky we find that BD+43 3654 was located near the central, densest region of Cygnus OB2 at a time in the past similar to its estimated age.   Conclusions: BD+43 3654 turns out to be one of the three most massive runaway stars known, and it most likely formed in the central region of Cygnus OB2. A runaway formation mechanism by means of dynamical ejection is consistent with our results. ", "machine_text": " This paper presents new spectroscopic and existing MSX observations of the massive runaway star BD+43 3654. Our observations reveal that it is an O4If star with an estimated mass of 70 (+/- 15) solar masses and an age of about 1.6 million years. Its well-defined bow shock, seen in MSX observations, reveals an orientation in the plane of the sky that is concordant with its proper motion. Backtracking its path across the sky, its origins can be traced to the densest region of the Cygnus OB2 association at a time similar to its estimated age. BD+43 3654 is thus one of the three most massive runaway stars known and its formation could have been caused by dynamical ejection.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0676}
{"prompt": "Rephrase the abstract of an article with title 'Progenitors of Long Gamma-ray Bursts'.   Pinpointing the progenitors of long duration gamma-ray bursts (LGRBs) remains an extremely important question, although it is now clear that at least a fraction of LGRBs originate in the core collapse of massive stars in type Ic supernovae, the pathways to the production of these stars, and their initial masses, remain uncertain. Rotation is thought to be vital in the creation of LGRBs, and it is likely that black hole creation is also necessary. We suggest that these two constraints can be met if the GRB progenitors are very massive stars (>20 solar masses) and are formed in tight binary systems. Using simple models we compare the predictions of this scenario with observations and find that the location of GRBs on their host galaxies are suggestive of main-sequence masses in excess of 20 solar masses, while 50% of the known compact binary systems may have been sufficiently close to have had the necessary rotation rates for GRB creation. Thus, massive stars in compact binaries are a likely channel for at least some fraction of LGRBs.  ", "human_text": "  Pinpointing the progenitors of long duration gamma-ray bursts (LGRBs) remains an extremely important question, although it is now clear that at least a fraction of LGRBs originate in the core collapse of massive stars in type Ic supernovae, the pathways to the production of these stars, and their initial masses, remain uncertain. Rotation is thought to be vital in the creation of LGRBs, and it is likely that black hole creation is also necessary. We suggest that these two constraints can be met if the GRB progenitors are very massive stars (>20 solar masses) and are formed in tight binary systems. Using simple models we compare the predictions of this scenario with observations and find that the location of GRBs on their host galaxies are suggestive of main-sequence masses in excess of 20 solar masses, while 50% of the known compact binary systems may have been sufficiently close to have had the necessary rotation rates for GRB creation. Thus, massive stars in compact binaries are a likely channel for at least some fraction of LGRBs. ", "machine_text": " The elusive nature of the progenitors of long duration gamma-ray bursts (LGRBs) has been an intriguing mystery for some time. Much of the current thinking suggests that these blasts originate from the core collapse of massive stars in type Ic supernovae, but the details of their formation, initial masses and pathways remain unknown. Experts believe that, in order for LGRBs to be produced, rapid rotation and the formation of a black hole are both necessary. Therefore, this paper proposes that progenitors of this type of gamma-ray burst could be composed of very massive stars (>20 solar masses) within tight binary systems. Through the use of simple models, this hypothesis is compared to observations and it appears that the GRB locations on their host galaxies are indicative of main-sequence masses that surpass 20 solar masses, while up to 50% of binary systems were thought to have close enough proximity to have the appropriate velocity for GRB production. Consequently, massive stars in binary systems are believed to be a primary publisher of at least a portion of LGRBs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1899}
{"prompt": "Rephrase the abstract of an article with title 'Discovery of Two Spectroscopically Peculiar, Low-Luminosity Quasars at   z~4'.   We report the discovery of two low-luminosity quasars at z~4, both of which show prominent N IV] 1486A emission. This line is extremely rare in quasar spectra at any redshift; detecting it in two out of a sample of 23 objects (i.e., ~ 9% of the sample) is intriguing and is likely due to the low-luminosity, high-redshift quasar sample we are studying. This is still a poorly explored regime, where contributions from associated, early starbursts may be significant. One interpretation of this line posits photoionization by very massive young stars. Seeing N IV] 1486A emission in a high-redshift quasar may thus be understood in the context of co-formation and early co-evolution of galaxies and their supermassive black holes. Alternatively, we may be seeing a phenomenon related to the early evolution of quasar broad emission line regions. The non-detection (and possibly even broad absorption) of N V 1240A line in the spectrum of one of these quasars may support that interpretation. These two objects may signal a new faint quasar population or an early AGN evolutionary stage at high redshifts.  ", "human_text": "  We report the discovery of two low-luminosity quasars at z~4, both of which show prominent N IV] 1486A emission. This line is extremely rare in quasar spectra at any redshift; detecting it in two out of a sample of 23 objects (i.e., ~ 9% of the sample) is intriguing and is likely due to the low-luminosity, high-redshift quasar sample we are studying. This is still a poorly explored regime, where contributions from associated, early starbursts may be significant. One interpretation of this line posits photoionization by very massive young stars. Seeing N IV] 1486A emission in a high-redshift quasar may thus be understood in the context of co-formation and early co-evolution of galaxies and their supermassive black holes. Alternatively, we may be seeing a phenomenon related to the early evolution of quasar broad emission line regions. The non-detection (and possibly even broad absorption) of N V 1240A line in the spectrum of one of these quasars may support that interpretation. These two objects may signal a new faint quasar population or an early AGN evolutionary stage at high redshifts. ", "machine_text": " We present the discovery of two unusual, low-luminosity quasars at redshift z~4 which show a prominent N IV] 1486A emission line. Finding such a feature in two out of 23 objects in our sample (8.6%) is particularly remarkable as this line is ordinarily rarely seen in quasar spectra regardless of redshift. This uncommon observation may be indicative of starbursts in associated, early galaxies. Alternatively, we may be witnessing the early stages of quasar broad emission line region evolution. The finding of no N V 1240A line in one of these quasars may provide evidence for the latter. Together, these objects could point to either a new population of faint quasars or to an AGN evolutionary phase in its infancy at high redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3638}
{"prompt": "Rephrase the abstract of an article with title 'Vortex trapping in suddenly connected Bose-Josephson junctions'.   We investigate the problem of vortex trapping in cyclically coupled Bose-Josephson junctions. Starting with $N$ independent BECs we couple the condensates through Josephson links and allow the system to reach a stable circulation by adding a dissipative term in our semiclassical equations of motion. The central question we address is what is the probability to trap a vortex with winding number $m$. Our numerical simulations reveal that the final distribution of winding numbers is narrower than the initial distribution of total phases, indicating an increased probability for no-vortex configurations. Further, the nonlinearity of the problem manifests itself in the somewhat counter-intuitive result that it is possible to obtain a non-zero circulation starting with zero total phase around the loop. The final width of the distribution of winding numbers for $N$ sites scales as $\\lambda N^{\\alpha}$, where $\\alpha=0.47\\pm 0.01$ and $\\lambda <0.67$ (value predicted for the initial distribution) indicating a shrinking of the final distribution. The actual value of $\\lambda$ is found to depend on the strength of dissipation.  ", "human_text": "  We investigate the problem of vortex trapping in cyclically coupled Bose-Josephson junctions. Starting with $N$ independent BECs we couple the condensates through Josephson links and allow the system to reach a stable circulation by adding a dissipative term in our semiclassical equations of motion. The central question we address is what is the probability to trap a vortex with winding number $m$. Our numerical simulations reveal that the final distribution of winding numbers is narrower than the initial distribution of total phases, indicating an increased probability for no-vortex configurations. Further, the nonlinearity of the problem manifests itself in the somewhat counter-intuitive result that it is possible to obtain a non-zero circulation starting with zero total phase around the loop. The final width of the distribution of winding numbers for $N$ sites scales as $\\lambda N^{\\alpha}$, where $\\alpha=0.47\\pm 0.01$ and $\\lambda <0.67$ (value predicted for the initial distribution) indicating a shrinking of the final distribution. The actual value of $\\lambda$ is found to depend on the strength of dissipation. ", "machine_text": " We investigate the behaviour of trapping vortices in the junctions of Bose-Josephson systems which have been suddenly connected. We study this by designing a semiclassical model consisting of independently evolved $N$ BECs which are coupled together in loops by Josephson junctions and a dissipative term. This model is then used to calculate the probability of having a vortex of winding number $m$ present in the final state. Our simulations suggest that the final winding numbers are more restricted than the initial total phases, making an absence of vortices more likely. Counter-intuitively, non-zero circulation can occur even when the initial total phase is zero. Furthermore, the width of the final distribution of winding numbers appears to scale as $\\lambda N^{\\alpha}$ with $\\alpha=0.47\\pm 0.01$ and $\\lambda <0.67$ (the predicted value of the initial distribution), showing that the sizes of the distribution tend to shrink. It was observed that the value of $\\lambda$ is dependent on the strength of the dissipation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2431}
{"prompt": "Rephrase the abstract of an article with title 'Chromohydrodynamical instabilities induced by relativistic jets'.   We study the properties of the chromohydrodynamical instabilities induced by a relativistic jet that crosses the quark-gluon plasma. Assuming that the jet of particles and the plasma can be described using a hydrodynamical approach, we derive and discuss the dispersion laws for the unstable collective modes. In our analysis the chromohydrodynamical equations for the collective modes are tackled in the linear response approximation. Such an approximation, valid for short time scales, allows to study in a straightforward way the dependence of the dispersion laws of the collective modes on the velocity of the jet, on the magnitude of the momentum of the collective mode and on the angle between these two quantities. We find that unstable modes arise for velocity of the jet larger than the speed of the sound of the plasma and only modes with momenta smaller than a certain values are unstable. Moreover, for ultrarelativistic velocities of the jet the longitudinal mode becomes stable and the most unstable modes correspond to relative angles between the velocity of the jet and momentum of the collective mode larger than $\\sim \\pi/8$. Our results suggest an alternative mechanism for the description of the jet quenching phenomenon, where the jet crossing the plasma loses energy exciting colored unstable modes.  ", "human_text": "  We study the properties of the chromohydrodynamical instabilities induced by a relativistic jet that crosses the quark-gluon plasma. Assuming that the jet of particles and the plasma can be described using a hydrodynamical approach, we derive and discuss the dispersion laws for the unstable collective modes. In our analysis the chromohydrodynamical equations for the collective modes are tackled in the linear response approximation. Such an approximation, valid for short time scales, allows to study in a straightforward way the dependence of the dispersion laws of the collective modes on the velocity of the jet, on the magnitude of the momentum of the collective mode and on the angle between these two quantities. We find that unstable modes arise for velocity of the jet larger than the speed of the sound of the plasma and only modes with momenta smaller than a certain values are unstable. Moreover, for ultrarelativistic velocities of the jet the longitudinal mode becomes stable and the most unstable modes correspond to relative angles between the velocity of the jet and momentum of the collective mode larger than $\\sim \\pi/8$. Our results suggest an alternative mechanism for the description of the jet quenching phenomenon, where the jet crossing the plasma loses energy exciting colored unstable modes. ", "machine_text": " We investigate the effects of a relativistic jet crossing quark-gluon plasma on the chromohydrodynamics instabilities. We examine this issue by looking into the hydrodynamic equations describing the jet and the plasma, in the linear response approximation. This is valid over short time scales, and allows us to investigate how the velocity of the jet, magnitude of the collective mode momentum, and the angle between them, changes the dispersion laws. We find that for jet velocities larger than the sound speed of the plasma, and for momenta smaller than a certain value, instabilities arise. Additionally, in the case of ultrarelativistic jet velocity, longitudinal modes become stable, and the most unstable modes have an angle between the jet velocity and its momentum greater than around $\\pi/8$. Our results hint at a novel method to explain jet quenching, in which the jet would lose energy exciting colored instabilities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1047}
{"prompt": "Rephrase the abstract of an article with title 'Physical Properties of Weak MgII Absorbers at z~2'.   We present the results of photoionization modeling of nine weak MgII (W_r<0.3 Ang) quasar absorption line systems with redshifts 1.4<z<2.4 obtained with the Ultraviolet and Visual Echelle Spectrograph on the Very Large Telescope. These systems have been chosen because they provide access to a regime of red-shift space that previous weak MgII studies have not looked at. The densities, metallicities, Doppler parameters, and column densities of these systems are compared to those of other weak MgII systems at lower redshift. There is no significant statistical variation in the properties of the absorbers over the redshift range 0.4<z<2.4. The number density per unit redshift is known to decrease for weak MgII absorbers between z~1 and z~2 by a greater amount than predicted from cosmological effects and changes in the extragalactic ionizing background alone. We suggest that, because the physical properties of the absorber population are not seen to change significantly across this range, that the evolution in dN/dz is due to a decrease in the activity that gives rise to weak MgII absorption, and not due to a change in the processes that form weak MgII absorbers. The presence of separate, but aligned (in velocity) low and high density clouds in all single cloud weak MgII absorbers provides an important diagnostic of their geometry. We discuss possible origins in dwarf galaxies and in extragalactic analogs to high velocity clouds.  ", "human_text": "  We present the results of photoionization modeling of nine weak MgII (W_r<0.3 Ang) quasar absorption line systems with redshifts 1.4<z<2.4 obtained with the Ultraviolet and Visual Echelle Spectrograph on the Very Large Telescope. These systems have been chosen because they provide access to a regime of red-shift space that previous weak MgII studies have not looked at. The densities, metallicities, Doppler parameters, and column densities of these systems are compared to those of other weak MgII systems at lower redshift. There is no significant statistical variation in the properties of the absorbers over the redshift range 0.4<z<2.4. The number density per unit redshift is known to decrease for weak MgII absorbers between z~1 and z~2 by a greater amount than predicted from cosmological effects and changes in the extragalactic ionizing background alone. We suggest that, because the physical properties of the absorber population are not seen to change significantly across this range, that the evolution in dN/dz is due to a decrease in the activity that gives rise to weak MgII absorption, and not due to a change in the processes that form weak MgII absorbers. The presence of separate, but aligned (in velocity) low and high density clouds in all single cloud weak MgII absorbers provides an important diagnostic of their geometry. We discuss possible origins in dwarf galaxies and in extragalactic analogs to high velocity clouds. ", "machine_text": " By studying nine weak MgII quasar absorption line systems at redshifts of 1.4-2.4 with the Ultraviolet and Visual Echelle Spectrograph on the Very Large Telescope, we investigate whether there are differences in the physical properties of weak MgII absorbers at varying redshifts. Our results show that the densities, metallicities, Doppler parameters, and column densities remain the same across redshifts 0.4-2.4. The number of weak MgII absorbers decreases from z~1 to z~2, however, because the physical properties do not change significantly, the decrease may be attributed to a decrease in activity rather than a change in formation process. We find evidence for multiple, velocity aligned clouds in single cloud weak MgII absorbers, which could be of extragalactic origin, such as dwarf galaxies or high velocity clouds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2036}
{"prompt": "Rephrase the abstract of an article with title 'Accurate QCD predictions for heavy-quark jets at the Tevatron and LHC'.   Heavy-quark jets are important in many of today's collider studies and searches, yet predictions for them are subject to much larger uncertainties than for light jets. This is because of strong enhancements in higher orders from large logarithms, ln(p_t/m_Q). We propose a new definition of heavy-quark jets, which is free of final-state logarithms to all orders and such that all initial-state collinear logarithms can be resummed into the heavy-quark parton distributions. Heavy-jet spectra can then be calculated in the massless approximation, which is simpler than a massive calculation and reduces the theoretical uncertainties by a factor of three. This provides the first ever accurate predictions for inclusive b- and c-jets, and the latter have significant discriminatory power for the intrinsic charm content of the proton. The techniques introduced here could be used to obtain heavy-flavour jet results from existing massless next-to-leading order calculations for a wide range of processes. We also discuss the experimental applicability of our flavoured jet definition.  ", "human_text": "  Heavy-quark jets are important in many of today's collider studies and searches, yet predictions for them are subject to much larger uncertainties than for light jets. This is because of strong enhancements in higher orders from large logarithms, ln(p_t/m_Q). We propose a new definition of heavy-quark jets, which is free of final-state logarithms to all orders and such that all initial-state collinear logarithms can be resummed into the heavy-quark parton distributions. Heavy-jet spectra can then be calculated in the massless approximation, which is simpler than a massive calculation and reduces the theoretical uncertainties by a factor of three. This provides the first ever accurate predictions for inclusive b- and c-jets, and the latter have significant discriminatory power for the intrinsic charm content of the proton. The techniques introduced here could be used to obtain heavy-flavour jet results from existing massless next-to-leading order calculations for a wide range of processes. We also discuss the experimental applicability of our flavoured jet definition. ", "machine_text": "This article presents a new definition of heavy-quark jets which eliminates large logarithmic uncertainties in their predictions, as well as simplifying calculations. We have demonstrated that this gives better accuracy and uncertainty estimates for b- and c-jets. Methods arising from this work have applications in a range of processes and could have exciting implications for gauging the intrinsic charm content of the proton. Additionally, we have covered the practical uses of this flavoured jet definition in an experimental setting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2999}
{"prompt": "Rephrase the abstract of an article with title 'Les espaces de Berkovich sont excellents'.   In this paper, we first study the local rings of a Berkovich analytic space from the point of view of commutative algebra. We show that those rings are excellent ; we introduce the notion of a an analytically separable extension of non-archimedean complete fields (it includes the case of the finite separable extensions, and also the case of any complete extension of a perfect complete non-archimedean field) and show that the usual commutative algebra properties (Rm, Sm, Gorenstein, Cohen-Macaulay, Complete Intersection) are stable under analytically separable ground field extensions; we also establish a GAGA principle with respect to those properties for any finitely generated scheme over an affinoid algebra.   A second part of the paper deals with more global geometric notions : we define, show the existence and establish basic properties of the irreducible components of analytic space ; we define, show the existence and establish basic properties of its normalization ; and we study the behaviour of connectedness and irreducibility with respect to base change.  ", "human_text": "  In this paper, we first study the local rings of a Berkovich analytic space from the point of view of commutative algebra. We show that those rings are excellent ; we introduce the notion of a an analytically separable extension of non-archimedean complete fields (it includes the case of the finite separable extensions, and also the case of any complete extension of a perfect complete non-archimedean field) and show that the usual commutative algebra properties (Rm, Sm, Gorenstein, Cohen-Macaulay, Complete Intersection) are stable under analytically separable ground field extensions; we also establish a GAGA principle with respect to those properties for any finitely generated scheme over an affinoid algebra.   A second part of the paper deals with more global geometric notions : we define, show the existence and establish basic properties of the irreducible components of analytic space ; we define, show the existence and establish basic properties of its normalization ; and we study the behaviour of connectedness and irreducibility with respect to base change. ", "machine_text": "This article examines Berkovich spaces with respect to commutative algebra and local rings. It is demonstrated that these rings are excellent and we introduce and investigate the concept of analytically separable extensions, which includes finite separable extensions as well as complete extensions of perfect fields. Properties such as Rm, Sm, Gorenstein, Cohen-Macaulay, and Complete Intersection are discussed, alongside a GAGA principle applied to finitely generated schemes over an affinoid algebra. Additionally, the global geometric notions of irreducible components of an analytic space and its normalization are explored, along with their connections to base change in terms of connectedness and irreducibility. In summary, the results obtained demonstrate that Berkovich spaces are indeed excellent.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0666}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of Newtonian fluid slip using a torsional ultrasonic   oscillator'.   The composite torsional ultrasonic oscillator, a versatile experimental system, can be used to investigate slip of Newtonian fluid at a smooth surface. A rigorous analysis of slip-dependent damping for the oscillator is presented. Initially, the phenomenon of finite surface slip and the slip length are considered for a half-space of Newtonian fluid in contact with a smooth, oscillating solid surface. Definitions are revisited and clarified in light of inconsistencies in the literature. We point out that, in general oscillating flows, Navier's slip length b is a complex number. An intuitive velocity discontinuity parameter of unrestricted phase is used to describe the effect of slip on measurement of viscous shear damping. The analysis is applied to the composite oscillator and preliminary experimental work for a 40 kHz oscillator is presented. The Non-Slip Boundary Condition (NSBC) has been verified for a hydrophobic surface in water to within ~60 nm of |b|=0 nm. Experiments were carried out at shear rate amplitudes between 230 and 6800 /s, corresponding to linear displacement amplitudes between 3.2 and 96 nm.  ", "human_text": "  The composite torsional ultrasonic oscillator, a versatile experimental system, can be used to investigate slip of Newtonian fluid at a smooth surface. A rigorous analysis of slip-dependent damping for the oscillator is presented. Initially, the phenomenon of finite surface slip and the slip length are considered for a half-space of Newtonian fluid in contact with a smooth, oscillating solid surface. Definitions are revisited and clarified in light of inconsistencies in the literature. We point out that, in general oscillating flows, Navier's slip length b is a complex number. An intuitive velocity discontinuity parameter of unrestricted phase is used to describe the effect of slip on measurement of viscous shear damping. The analysis is applied to the composite oscillator and preliminary experimental work for a 40 kHz oscillator is presented. The Non-Slip Boundary Condition (NSBC) has been verified for a hydrophobic surface in water to within ~60 nm of |b|=0 nm. Experiments were carried out at shear rate amplitudes between 230 and 6800 /s, corresponding to linear displacement amplitudes between 3.2 and 96 nm. ", "machine_text": " Using the efficient and convenient torsional ultrasonic oscillator, this article provides an in-depth assessment of Newtonian fluid slips across a smooth surface. An updated examination of the Navier's slip length is undertaken, revealing the complexity of this phenomenon across oscillating flows. The Non-Slip Boundary Condition (NSBC) is explored through experiments with a 40 kHz oscillator and a hydrophobic surface in water, with results demonstrating slips within 60 nm of |b|=0 nm. Shear rate amplitudes between 230 and 6800 /s, revealing linear displacement amplitudes between 3.2 and 96 nm, further give insight into Newtonian fluid slip.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3498}
{"prompt": "Rephrase the abstract of an article with title 'Scalability and Optimisation of a Committee of Agents Using Genetic   Algorithm'.   A population of committees of agents that learn by using neural networks is implemented to simulate the stock market. Each committee of agents, which is regarded as a player in a game, is optimised by continually adapting the architecture of the agents using genetic algorithms. The committees of agents buy and sell stocks by following this procedure: (1) obtain the current price of stocks; (2) predict the future price of stocks; (3) and for a given price trade until all the players are mutually satisfied. The trading of stocks is conducted by following these rules: (1) if a player expects an increase in price then it tries to buy the stock; (2) else if it expects a drop in the price, it sells the stock; (3)and the order in which a player participates in the game is random. The proposed procedure is implemented to simulate trading of three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear relationship between the number of players and agents versus the computational time to run the complete simulation is observed. It is also found that no player has a monopolistic advantage.  ", "human_text": "  A population of committees of agents that learn by using neural networks is implemented to simulate the stock market. Each committee of agents, which is regarded as a player in a game, is optimised by continually adapting the architecture of the agents using genetic algorithms. The committees of agents buy and sell stocks by following this procedure: (1) obtain the current price of stocks; (2) predict the future price of stocks; (3) and for a given price trade until all the players are mutually satisfied. The trading of stocks is conducted by following these rules: (1) if a player expects an increase in price then it tries to buy the stock; (2) else if it expects a drop in the price, it sells the stock; (3)and the order in which a player participates in the game is random. The proposed procedure is implemented to simulate trading of three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear relationship between the number of players and agents versus the computational time to run the complete simulation is observed. It is also found that no player has a monopolistic advantage. ", "machine_text": "This study presents an algorithm for scalability and optimisation of a committee of agents through the use of a genetic algorithm. Neural networks are used to teach the population of agents to simulate the stock market. This study focuses on testing the trading of certain stocks and its agents as they try to purchase or sell stocks following three principles: obtaining the current stock price, predicting the future stock price and trading until both parties are mutually satisfied. In a research experiment, it was found that the number of players and agents had a linear relationship with the time needed to run the simulation and that none of the players had an unfair advantage.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1757}
{"prompt": "Rephrase the abstract of an article with title 'The LuckyCam Survey for Very Low Mass Binaries II: 13 new M4.5-M6.0   Binaries'.   We present results from a high-angular-resolution survey of 78 very low mass (VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15 arcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new binary systems range in separation between 0.18 arcsec and 1.3 arcsec. The distance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with previous results. 9 of the new binary systems have orbital radii > 10 AU, including a new wide VLM binary with 27 AU projected orbital separation. One of the new systems forms two components of a 2300 AU separation triple system. We find that the orbital radius distribution of the binaries with V-K < 6.5 in this survey appears to be different from that of redder (lower-mass) objects, suggesting a possible rapid change in the orbital radius distribution at around the M5 spectral type. The target sample was also selected to investigate X-ray activity among VLM binaries. There is no detectable correlation between excess X-Ray emission and the frequency and binary properties of the VLM systems.  ", "human_text": "  We present results from a high-angular-resolution survey of 78 very low mass (VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15 arcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new binary systems range in separation between 0.18 arcsec and 1.3 arcsec. The distance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with previous results. 9 of the new binary systems have orbital radii > 10 AU, including a new wide VLM binary with 27 AU projected orbital separation. One of the new systems forms two components of a 2300 AU separation triple system. We find that the orbital radius distribution of the binaries with V-K < 6.5 in this survey appears to be different from that of redder (lower-mass) objects, suggesting a possible rapid change in the orbital radius distribution at around the M5 spectral type. The target sample was also selected to investigate X-ray activity among VLM binaries. There is no detectable correlation between excess X-Ray emission and the frequency and binary properties of the VLM systems. ", "machine_text": " This survey of 78 VLM binary systems has uncovered 21 binary systems, 13 of which are new discoveries. The new binaries have separations ranging from 0.18 arcsec to 1.3 arcsec after correcting for distance. The resulting binary fraction is 13.5%, which is in agreement with prior work. Notably, 9 of these newly discovered binaries have orbital radii > 10 AU, including one system that has a projected 27 AU separation. Furthermore, the orbital radius distribution of binaries with V-K < 6.5 appears to differ from that of lower-mass systems, suggesting a dramatic change at the M5 spectral type. Finally, there was no correlation found between X-ray emission and the frequency and parameters of the VLM systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1812}
{"prompt": "Rephrase the abstract of an article with title 'The Dynamics-Based Approach to Studying Terrestrial Exoplanets'.   One of the great quests of astronomy is to obtain the spectrum of a terrestrial planet orbiting within the habitable zone of its star, and the dominant challenge in doing so is to isolate the light of the planet from that of the star. Dynamics-based methods separate these signals temporally, whereas imaging techniques do so spatially. In light of the overwhelming dominance of dynamics-based methods over the past decade, we challenge the notion that spectra of terrestrial planets necessarily require extreme imaging methods. We advocate that some resources be committed to refining the proven technologies of radial-velocity measurements, transit photometry, and occultation spectroscopy (i.e. emergent infrared spectra obtained at secondary eclipse). We see a particularly attractive opportunity in M-dwarfs, for which the habitable zone is close to the star, increasing the probability and frequency of transits, and the amplitude of the induced radial-velocity variation. Such planets could be discovered by a dedicated ground-based transit survey of the 10,000 nearest M-dwarfs. The favorable planet-star contrast ratio would make these planets ideal targets for the study of their atmospheres with the technique of occultation spectroscopy.  ", "human_text": "  One of the great quests of astronomy is to obtain the spectrum of a terrestrial planet orbiting within the habitable zone of its star, and the dominant challenge in doing so is to isolate the light of the planet from that of the star. Dynamics-based methods separate these signals temporally, whereas imaging techniques do so spatially. In light of the overwhelming dominance of dynamics-based methods over the past decade, we challenge the notion that spectra of terrestrial planets necessarily require extreme imaging methods. We advocate that some resources be committed to refining the proven technologies of radial-velocity measurements, transit photometry, and occultation spectroscopy (i.e. emergent infrared spectra obtained at secondary eclipse). We see a particularly attractive opportunity in M-dwarfs, for which the habitable zone is close to the star, increasing the probability and frequency of transits, and the amplitude of the induced radial-velocity variation. Such planets could be discovered by a dedicated ground-based transit survey of the 10,000 nearest M-dwarfs. The favorable planet-star contrast ratio would make these planets ideal targets for the study of their atmospheres with the technique of occultation spectroscopy. ", "machine_text": " Exoplanets are of particular fascination to astronomers due to the possibility of them being habitable. To obtain the spectrum of a terrestrial planet orbiting in the habitable zone of its star is a great feat, however the challenge of isolating the light of the planet from that of its star still persists. In the last decade, dynamics-based methods, as opposed to imaging techniques, have facilitated this endeavor significantly. We propose that more focused efforts be given to technologies such as radial-velocity measurements, transit photometry, and occultation spectroscopy in order to obtain spectra of exoplanets. M-dwarfs, which have a habitable zone close to their star, have seen a rise in transits and radial-velocity variations, making them prime candidates for studying the atmospheres of terrestrial planets with occultation spectroscopy. A dedicated ground-based transit survey of the 10,000 nearest M-dwarfs, with their favorable planet-star contrast ratio, could consequently fulfill this quest.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1047}
{"prompt": "Rephrase the abstract of an article with title 'Coronal ion-cyclotron beam instabilities within the multi-fluid   description'.   Spectroscopic observations and theoretical models suggest resonant wave-particle interactions, involving high-frequency ion-cyclotron waves, as the principal mechanism for heating and accelerating ions in the open coronal holes. However, the mechanism responsible for the generation of the ion-cyclotron waves remains unclear. One possible scenario is that ion beams originating from small-scale reconnection events can drive micro-instabilities that constitute a possible source for the excitation of ion-cyclotron waves. In order to study ion beam-driven electromagnetic instabilities, the multi-fluid model in the low-beta coronal plasma is used. While neglecting the electron inertia this model allows one to take into account ion-cyclotron wave effects that are absent from the one-fluid MHD model. Realistic models of density and temperature as well as a 2-D analytical magnetic field model are used to define the background plasma in the open-field funnel region of a polar coronal hole. Considering the WKB approximation, a Fourier plane-wave linear mode analysis is employed in order to derive the dispersion relation. Ray-tracing theory is used to compute the ray path of the unstable wave as well as the evolution of the growth rate of the wave while propagating in the coronal funnel. We demonstrate that, in typical coronal holes conditions and assuming realistic values of the beam velocity, the free energy provided by the ion beam propagating parallel the ambient field can drive micro-instabilities through resonant ion-cyclotron excitation.  ", "human_text": "  Spectroscopic observations and theoretical models suggest resonant wave-particle interactions, involving high-frequency ion-cyclotron waves, as the principal mechanism for heating and accelerating ions in the open coronal holes. However, the mechanism responsible for the generation of the ion-cyclotron waves remains unclear. One possible scenario is that ion beams originating from small-scale reconnection events can drive micro-instabilities that constitute a possible source for the excitation of ion-cyclotron waves. In order to study ion beam-driven electromagnetic instabilities, the multi-fluid model in the low-beta coronal plasma is used. While neglecting the electron inertia this model allows one to take into account ion-cyclotron wave effects that are absent from the one-fluid MHD model. Realistic models of density and temperature as well as a 2-D analytical magnetic field model are used to define the background plasma in the open-field funnel region of a polar coronal hole. Considering the WKB approximation, a Fourier plane-wave linear mode analysis is employed in order to derive the dispersion relation. Ray-tracing theory is used to compute the ray path of the unstable wave as well as the evolution of the growth rate of the wave while propagating in the coronal funnel. We demonstrate that, in typical coronal holes conditions and assuming realistic values of the beam velocity, the free energy provided by the ion beam propagating parallel the ambient field can drive micro-instabilities through resonant ion-cyclotron excitation. ", "machine_text": " This article investigates the effect of ion-cyclotron micro-instabilities, caused by the resonance between ion-cyclotron waves and high-energy ion beams originating from small-scale reconnection events, on the open-field region of a polar coronal hole. Using the multi-fluid model, the WKB Fourier plane-wave linear mode analysis, and ray-tracing theory, this study is able to demonstrate that the free energy of the propagating ion beams is a potential source of ion-cyclotron waves in coronal holes under typical conditions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0752}
{"prompt": "Rephrase the abstract of an article with title 'Some Comments around The Examples against The Generalized Jacobian   Conjecture'.   We have studied a faded problem, the Jacobian Conjecture ~:   \\noindent   {\\sf The Jacobian Conjecture $(JC_n)$}~:   If $f_1, \\cdots, f_n$ are elements in a polynomial ring $k[X_1, \\cdots, X_n]$ over a field $k$ of characteristic $0$ such that the Jacobian $\\det(\\partial f_i/ \\partial X_j) $ is a nonzero constant, then $k[f_1, \\cdots, f_n] = k[X_1, \\cdots, X_n]$.   For this purpose, we generalize it to the following form~:   \\noindent   {\\sf The Generalized Jacobian Conjecture $(GJC)$}~:   {\\it Let $\\varphi : S \\rightarrow T$ be an unramified homomorphism of Noetherian domains with $T^\\times = \\varphi(S^\\times)$. Assume that $T$ is a factorial domain and that $S$ is a simply connected normal domain. Then $\\varphi$ is an isomorphism. }   For the consistency of our discussion, we raise some serious (or idiot) questions and some comments concerning the examples appeared in the papers published by the certain excellent mathematicians (though we are unwilling to deal with them). Since the existence of such examples would be against our original target Conjecture$(GJC)$, we have to dispute their arguments about the existence of their respective (so called) counter-examples. Our conclusion is that they are not perfect counter-examples as are shown explicitly.  ", "human_text": "  We have studied a faded problem, the Jacobian Conjecture ~:   \\noindent   {\\sf The Jacobian Conjecture $(JC_n)$}~:   If $f_1, \\cdots, f_n$ are elements in a polynomial ring $k[X_1, \\cdots, X_n]$ over a field $k$ of characteristic $0$ such that the Jacobian $\\det(\\partial f_i/ \\partial X_j) $ is a nonzero constant, then $k[f_1, \\cdots, f_n] = k[X_1, \\cdots, X_n]$.   For this purpose, we generalize it to the following form~:   \\noindent   {\\sf The Generalized Jacobian Conjecture $(GJC)$}~:   {\\it Let $\\varphi : S \\rightarrow T$ be an unramified homomorphism of Noetherian domains with $T^\\times = \\varphi(S^\\times)$. Assume that $T$ is a factorial domain and that $S$ is a simply connected normal domain. Then $\\varphi$ is an isomorphism. }   For the consistency of our discussion, we raise some serious (or idiot) questions and some comments concerning the examples appeared in the papers published by the certain excellent mathematicians (though we are unwilling to deal with them). Since the existence of such examples would be against our original target Conjecture$(GJC)$, we have to dispute their arguments about the existence of their respective (so called) counter-examples. Our conclusion is that they are not perfect counter-examples as are shown explicitly. ", "machine_text": " We have studied the Jacobian Conjecture, which states that if $f_1, \\cdots, f_n$ are elements in a polynomial ring $k[X_1, \\cdots, X_n]$ over a field $k$ of characteristic $0$ such that the Jacobian $\\det(\\partial f_i/ \\partial X_j) $ is a nonzero constant, then $k[f_1, \\cdots, f_n] = k[X_1, \\cdots, X_n]$. In addition, to further investigate it, we generalized the ground problem to the Generalized Jacobian Conjecture. This conjecture states that any unramified homomorphism of Noetherian domains, where the domain $T$ is factorial and $S$ is simply connected and normal, is an isomorphism. In light of this, we brought up some questions and comments regarding the presented counter-examples. After examining them closely, we have come to the conclusion that these examples are not valid counter-examples to the Generalized Jacobian Conjecture.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1138}
{"prompt": "Rephrase the abstract of an article with title 'QCD in One Dimension at Nonzero Chemical Potential'.   Using an integration formula recently derived by Conrey, Farmer and Zirnbauer, we calculate the expectation value of the phase factor of the fermion determinant for the staggered lattice QCD action in one dimension. We show that the chemical potential can be absorbed into the quark masses; the theory is in the same chiral symmetry class as QCD in three dimensions at zero chemical potential. In the limit of a large number of colors and fixed number of lattice points, chiral symmetry is broken spontaneously, and our results are in agreement with expressions based on a chiral Lagrangian. In this limit, the eigenvalues of the Dirac operator are correlated according to random matrix theory for QCD in three dimensions. The discontinuity of the chiral condensate is due to an alternative to the Banks-Casher formula recently discovered for QCD in four dimensions at nonzero chemical potential. The effect of temperature on the average phase factor is discussed in a schematic random matrix model.  ", "human_text": "  Using an integration formula recently derived by Conrey, Farmer and Zirnbauer, we calculate the expectation value of the phase factor of the fermion determinant for the staggered lattice QCD action in one dimension. We show that the chemical potential can be absorbed into the quark masses; the theory is in the same chiral symmetry class as QCD in three dimensions at zero chemical potential. In the limit of a large number of colors and fixed number of lattice points, chiral symmetry is broken spontaneously, and our results are in agreement with expressions based on a chiral Lagrangian. In this limit, the eigenvalues of the Dirac operator are correlated according to random matrix theory for QCD in three dimensions. The discontinuity of the chiral condensate is due to an alternative to the Banks-Casher formula recently discovered for QCD in four dimensions at nonzero chemical potential. The effect of temperature on the average phase factor is discussed in a schematic random matrix model. ", "machine_text": " We utilize a recently established integration formula by Conrey, Farmer and Zirnbauer to estimate the expectation value of the phase factor of the staggered lattice QCD action in one dimension when a chemical potential is present. We determine that it is possible to incorporate the chemical potential into the quark masses in the same manner as for the QCD in three dimensions when the chemical potential is zero. At higher numbers of colors and a constant number of lattice points, chiral symmetry is spontaneously broken and the results are found to coincide with the effects related to a chiral Lagrangian. The eigenvalues of the Dirac operator are found to obey the random matrix theory for the QCD in three dimensions too. The discontinuity in the chiral condensate is a consequence of an alternative to the Banks-Casher formula which was recently found to pertain to QCD in four dimensions and a nonzero chemical potential. The influence of temperature on the average phase factor is explored in a schematic random matrix model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1111}
{"prompt": "Rephrase the abstract of an article with title 'Analysis of random Boolean networks using the average sensitivity'.   In this work we consider random Boolean networks that provide a general model for genetic regulatory networks. We extend the analysis of James Lynch who was able to proof Kauffman's conjecture that in the ordered phase of random networks, the number of ineffective and freezing gates is large, where as in the disordered phase their number is small. Lynch proved the conjecture only for networks with connectivity two and non-uniform probabilities for the Boolean functions. We show how to apply the proof to networks with arbitrary connectivity $K$ and to random networks with biased Boolean functions. It turns out that in these cases Lynch's parameter $\\lambda$ is equivalent to the expectation of average sensitivity of the Boolean functions used to construct the network. Hence we can apply a known theorem for the expectation of the average sensitivity. In order to prove the results for networks with biased functions, we deduct the expectation of the average sensitivity when only functions with specific connectivity and specific bias are chosen at random.  ", "human_text": "  In this work we consider random Boolean networks that provide a general model for genetic regulatory networks. We extend the analysis of James Lynch who was able to proof Kauffman's conjecture that in the ordered phase of random networks, the number of ineffective and freezing gates is large, where as in the disordered phase their number is small. Lynch proved the conjecture only for networks with connectivity two and non-uniform probabilities for the Boolean functions. We show how to apply the proof to networks with arbitrary connectivity $K$ and to random networks with biased Boolean functions. It turns out that in these cases Lynch's parameter $\\lambda$ is equivalent to the expectation of average sensitivity of the Boolean functions used to construct the network. Hence we can apply a known theorem for the expectation of the average sensitivity. In order to prove the results for networks with biased functions, we deduct the expectation of the average sensitivity when only functions with specific connectivity and specific bias are chosen at random. ", "machine_text": "This article examines the use of average sensitivity to analyze random Boolean networks. This extends upon prior work by James Lynch to prove Kauffman's conjecture; that in random networks, few ineffective and freezing gates exist in the ordered phase, and many in the disordered phase. Setting $\\lambda$ as the expectation of average sensitivity, we use Lynch's proof to analyze networks with arbitrary connectivity and biased Boolean functions. We further deduce the expectation of average sensitivity when a specific connectivity and bias of functions are randomly chosen.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0197}
{"prompt": "Rephrase the abstract of an article with title 'Geometry of Time, Axiom of Choice and Neuro-Biological Quantum Zeno   Effect'.   Role of axiom of choice in quantum measurement is highlighted by suggesting that the conscious observer chooses the outcome from a mixed state. Further, in a periodically repeating universe, these outcomes must be pre-recorded within the non-physical conscious observers, which precludes free will. Free will however exists in a universe with open time, It is suggested that psychology's binding problem is connected with Cantor's original definition of set. Influence of consciousness on material outcome through quantum processes is discussed and interesting constraints derived. For example, it is predicted that quantum mechanical brain states should get frozen if monitored at sufficiently small space-time intervals - a neuro-biological version of the so called quantum zeno effect, which has been verified in domain of micro-physics. Existence of a very small micro-mini-black-hole in brain is predicted as a space-time structural interface between consciousness and brain, whose vaporization explains mass-loss reported in weighing experiments, conducting during the moments of death.  ", "human_text": "  Role of axiom of choice in quantum measurement is highlighted by suggesting that the conscious observer chooses the outcome from a mixed state. Further, in a periodically repeating universe, these outcomes must be pre-recorded within the non-physical conscious observers, which precludes free will. Free will however exists in a universe with open time, It is suggested that psychology's binding problem is connected with Cantor's original definition of set. Influence of consciousness on material outcome through quantum processes is discussed and interesting constraints derived. For example, it is predicted that quantum mechanical brain states should get frozen if monitored at sufficiently small space-time intervals - a neuro-biological version of the so called quantum zeno effect, which has been verified in domain of micro-physics. Existence of a very small micro-mini-black-hole in brain is predicted as a space-time structural interface between consciousness and brain, whose vaporization explains mass-loss reported in weighing experiments, conducting during the moments of death. ", "machine_text": "This article discusses the role of the axiom of choice in quantum measurement, proposing that conscious observers select the outcome from a mixed state. Furthermore, the implications for a periodically repeating universe and notions of free will are proposed. In addition, a connection is proposed between Cantor's original definition of a set and the psychology binding problem. The article also examines the effect of consciousness on material outcomes through quantum processes, deriving interesting constraints, including the potential for a neuro-biological version of the quantum zeno effect. Lastly, the article suggests a hypothesis wherein a micro-mini black hole in the brain acts as a space-time interface between consciousness and the brain and is the source of mass-loss in the moment of death.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1054}
{"prompt": "Rephrase the abstract of an article with title 'Aromatic emission from the ionised mane of the Horsehead nebula'.   We study the evolution of the Aromatic Infrared Bands (AIBs) emitters across the illuminated edge of the Horsehead nebula and especially their survival and properties in the HII region. We present spectral mapping observations taken with the Infrared Spectrograph (IRS) at wavelengths 5.2-38 microns. A strong AIB at 11.3 microns is detected in the HII region, relative to the other AIBs at 6.2, 7.7 and 8.6 microns. The intensity of this band appears to be correlated with the intensity of the [NeII] at 12.8 microns and of Halpha, which shows that the emitters of the 11.3 microns band are located in the ionised gas. The survival of PAHs in the HII region could be due to the moderate intensity of the radiation field (G0 about 100) and the lack of photons with energy above about 25eV. The enhancement of the intensity of the 11.3 microns band in the HII region, relative to the other AIBs can be explained by the presence of neutral PAHs. Our observations highlight a transition region between ionised and neutral PAHs observed with ideal conditions in our Galaxy. A scenario where PAHs can survive in HII regions and be significantly neutral could explain the detection of a prominent 11.3 microns band in other Spitzer observations.  ", "human_text": "  We study the evolution of the Aromatic Infrared Bands (AIBs) emitters across the illuminated edge of the Horsehead nebula and especially their survival and properties in the HII region. We present spectral mapping observations taken with the Infrared Spectrograph (IRS) at wavelengths 5.2-38 microns. A strong AIB at 11.3 microns is detected in the HII region, relative to the other AIBs at 6.2, 7.7 and 8.6 microns. The intensity of this band appears to be correlated with the intensity of the [NeII] at 12.8 microns and of Halpha, which shows that the emitters of the 11.3 microns band are located in the ionised gas. The survival of PAHs in the HII region could be due to the moderate intensity of the radiation field (G0 about 100) and the lack of photons with energy above about 25eV. The enhancement of the intensity of the 11.3 microns band in the HII region, relative to the other AIBs can be explained by the presence of neutral PAHs. Our observations highlight a transition region between ionised and neutral PAHs observed with ideal conditions in our Galaxy. A scenario where PAHs can survive in HII regions and be significantly neutral could explain the detection of a prominent 11.3 microns band in other Spitzer observations. ", "machine_text": " We explore the emission of Aromatic Infrared Bands (AIBs) across the illuminated edge of the Horsehead nebula, especially their existence and characteristics in the HII region. Our study includes spectral mapping conducted with the Infrared Spectrograph at wavelengths of 5.2 - 38 microns. An intense AIB of 11.3 microns is detected in the HII region compared to the other AIBs at 6.2, 7.7, and 8.6 microns. The intensity of this particular band appears to correlate with the intensity of [NeII] at 12.8 microns and Halpha, which implies the emitter of the 11.3 micron band is located within the ionised gas. This finding could be accounted for by the average-intensity radiation field (G0 about 100) and little photons of energy over 25eV. We reason the intensification of the 11.3 micron band in the HII region relative to the other AIBs could stem from the availability of neutral PAHs. Our observations highlight a transitory area between ionised and neutral PAHs witnessed in our Galaxy under proper conditions. A scenario in which PAHs can survive in HII regions and substantially remain neutral could explain the noticeable 11.3 micron band noticed in many other Spitzer observations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.151}
{"prompt": "Rephrase the abstract of an article with title 'Principal Component Analysis and Automatic Relevance Determination in   Damage Identification'.   This paper compares two neural network input selection schemes, the Principal Component Analysis (PCA) and the Automatic Relevance Determination (ARD) based on Mac-Kay's evidence framework. The PCA takes all the input data and projects it onto a lower dimension space, thereby reduc-ing the dimension of the input space. This input reduction method often results with parameters that have significant influence on the dynamics of the data being diluted by those that do not influence the dynamics of the data. The ARD selects the most relevant input parameters and discards those that do not contribute significantly to the dynamics of the data being modelled. The ARD sometimes results with important input parameters being discarded thereby compromising the dynamics of the data. The PCA and ARD methods are implemented together with a Multi-Layer-Perceptron (MLP) network for fault identification in structures and the performance of the two methods is as-sessed. It is observed that ARD and PCA give similar accu-racy levels when used as input-selection schemes. There-fore, the choice of input-selection scheme is dependent on the nature of the data being processed.  ", "human_text": "  This paper compares two neural network input selection schemes, the Principal Component Analysis (PCA) and the Automatic Relevance Determination (ARD) based on Mac-Kay's evidence framework. The PCA takes all the input data and projects it onto a lower dimension space, thereby reduc-ing the dimension of the input space. This input reduction method often results with parameters that have significant influence on the dynamics of the data being diluted by those that do not influence the dynamics of the data. The ARD selects the most relevant input parameters and discards those that do not contribute significantly to the dynamics of the data being modelled. The ARD sometimes results with important input parameters being discarded thereby compromising the dynamics of the data. The PCA and ARD methods are implemented together with a Multi-Layer-Perceptron (MLP) network for fault identification in structures and the performance of the two methods is as-sessed. It is observed that ARD and PCA give similar accu-racy levels when used as input-selection schemes. There-fore, the choice of input-selection scheme is dependent on the nature of the data being processed. ", "machine_text": " This research examines the performance of Principal Component Analysis (PCA) and Automatic Relevance Determination (ARD) when utilized in combination with a Multi-Layer-Perceptron (MLP) network for determining damage in a structure. PCA offers reduction of input data dimension by projecting it to a lower dimension space, which could lead to important influencing parameters being diluted by those that don't effect the data's dynamics. Conversely, ARD selects the most relevant input parameters while limiting the effect of parameters that don't notably influence the dynamics. It was observed the ARD and PCA provided similar accuracy levels, meaning the choice of which scheme to use is dependent on the data's nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1672}
{"prompt": "Rephrase the abstract of an article with title 'Ray-tracing and physical-optics analysis of the aperture efficiency in a   radio telescope'.   The performance of telescope systems working at microwave or visible/IR wavelengths is typically described in terms of different parameters according to the wavelength range. Most commercial ray tracing packages have been specifically designed for use with visible/IR systems and thus, though very flexible and sophisticated, do not provide the appropriate parameters to fully describe microwave antennas, and thus to compare with specifications. In this work we demonstrate that the Strehl ratio is equal to the phase efficiency when the apodization factor is taken into account. The phase efficiency is the most critical contribution to the aperture efficiency of an antenna, and the most difficult parameter to optimize during the telescope design. The equivalence between the Strehl ratio and the phase efficiency gives the designer/user of the telescope the opportunity to use the faster commercial ray-tracing software to optimize the design. We also discuss the results of several tests performed to check the validity of this relationship that we carried out using a ray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3, applied to three different telescope designs that span a factor of $\\simeq 10 in terms of D/lambda. The maximum measured discrepancy between phase efficiency and Strehl ratio varies between $\\simeq 0.4 and 1.9 up to an offset angle of >40 beams, depending on the optical configuration, but it is always less than 0.5 where the Strehl ratio is >0.95.  ", "human_text": "  The performance of telescope systems working at microwave or visible/IR wavelengths is typically described in terms of different parameters according to the wavelength range. Most commercial ray tracing packages have been specifically designed for use with visible/IR systems and thus, though very flexible and sophisticated, do not provide the appropriate parameters to fully describe microwave antennas, and thus to compare with specifications. In this work we demonstrate that the Strehl ratio is equal to the phase efficiency when the apodization factor is taken into account. The phase efficiency is the most critical contribution to the aperture efficiency of an antenna, and the most difficult parameter to optimize during the telescope design. The equivalence between the Strehl ratio and the phase efficiency gives the designer/user of the telescope the opportunity to use the faster commercial ray-tracing software to optimize the design. We also discuss the results of several tests performed to check the validity of this relationship that we carried out using a ray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3, applied to three different telescope designs that span a factor of $\\simeq 10 in terms of D/lambda. The maximum measured discrepancy between phase efficiency and Strehl ratio varies between $\\simeq 0.4 and 1.9 up to an offset angle of >40 beams, depending on the optical configuration, but it is always less than 0.5 where the Strehl ratio is >0.95. ", "machine_text": " This paper investigates the relationship between aperture efficiency, obtained from the Strehl ratio and the phase efficiency in different radio telescope designs. The idea being that a commercial ray-tracing software can be used to optimize the design. To test this proposition, different tunnel designs spanning a factor of $\\simeq 10 in terms of D/lambda were simulated with ZEMAX and GRASP9.3. Results indicate that there is a difference between phase efficiency and Strehl ratio of approximately 0.4 to 1.9 up to an offset angle of 40 beams, depending on the design specifics. Notwithstanding this, discrepancies between Strehl ratio and phase efficiency were always less than 0.5 when Strehl ratio was greater than 0.95.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3379}
{"prompt": "Rephrase the abstract of an article with title 'A unified projection formalism for the Al-Pd-Mn quasicrystal   Xi-approximants and their metadislocations'.   The approximants xi, xi' and xi'_n of the quasicrystal Al-Mn-Pd display most interesting plastic properties as for example phason-induced deformation processes (Klein, H., Audier, M., Boudard, M., de Boissieu, M., Beraha, L., and Duneau, M., 1996, Phil. Mag. A, 73, 309.) or metadislocations (Klein, H., Feuerbacher, M., Schall, P., and Urban, K., 1999, Phys. Rev. Lett., 82, 3468.). Here we demonstrate that the phases and their deformed or defected states can be described by a simple projection formalism in three-dimensional space - not as usual in four to six dimensions. With the method we can interpret microstructures observed with electron microscopy as phasonic phase boundaries. Furthermore we determine the metadislocations of lowest energy and relate them uniquely to experimentally observed ones. Since moving metadislocations in the xi'-phase can create new phason-planes, we suggest a dislocation induced phase transition from xi' to xi'_n. The methods developed in this paper can as well be used for various other complex metallic alloys.  ", "human_text": "  The approximants xi, xi' and xi'_n of the quasicrystal Al-Mn-Pd display most interesting plastic properties as for example phason-induced deformation processes (Klein, H., Audier, M., Boudard, M., de Boissieu, M., Beraha, L., and Duneau, M., 1996, Phil. Mag. A, 73, 309.) or metadislocations (Klein, H., Feuerbacher, M., Schall, P., and Urban, K., 1999, Phys. Rev. Lett., 82, 3468.). Here we demonstrate that the phases and their deformed or defected states can be described by a simple projection formalism in three-dimensional space - not as usual in four to six dimensions. With the method we can interpret microstructures observed with electron microscopy as phasonic phase boundaries. Furthermore we determine the metadislocations of lowest energy and relate them uniquely to experimentally observed ones. Since moving metadislocations in the xi'-phase can create new phason-planes, we suggest a dislocation induced phase transition from xi' to xi'_n. The methods developed in this paper can as well be used for various other complex metallic alloys. ", "machine_text": "This study examines the plastic properties of Al-Mn-Pd approximants xi, xi' and xi'_n of the quasicrystal. It is demonstrated that these phases, as well as their deformed or defected states, can be understood using a projection formalism in three-dimensional space, unlike previously used four to six-dimensional methods. This formalism is then used to explain microstructures observed in electron microscopy, and to determine the most energetically favorable metadislocations in relation to experimentally observed ones. In addition, the notion of a dislocation-induced phase transition from xi' to xi'n is proposed. Lastly, the methods employed in this article can be applied to study other complex metallic alloys.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1428}
{"prompt": "Rephrase the abstract of an article with title 'Annotations to a certain passage of Descartes for finding the quadrature   of the circle'.   Translation from the Latin of \"Annotationes in locum quendam Cartesii ad circuli quadraturam spectantem\" (1763).   The passage Euler is referring to is the \"Excerpta\" in part 6, p. 6 of Descartes' 1701 \"Opuscula posthuma\".   Before reading this paper I had not heard of the \"quadratrix\" before, and I recommend learning a bit about it before reading this. I found Thomas Heath, \"A history of Greek mathematics\", vol. I, chapter VII to be helpful, in particular pp. 226-230. The quadratrix is a \"mechanical curve\" that can be used to rectify the circle. The usual problem of squaring the circle is to construct a square with the same area (or perimeter) as a given circle, in a finite number of steps using compass and straightedge. Descartes worked in the reverse direction: from a given square he constructed the radius of a circle with the same perimeter, but in an infinite number of steps.   In this paper Euler reconstructs Descartes' argument and develops some consequences of it. Euler finds that \\[ \\sum_{n=0}^\\infty \\frac{1}{2^n} \\tan \\frac{1}{2^n}\\phi = \\frac{1}{\\phi} - 2\\cot 2\\phi. \\] Integrating this yields \\[ \\prod_{n=1}^\\infty \\sec \\frac{1}{2^n} \\phi = \\frac{2\\phi}{\\sin 2\\phi}. \\]   I'd like to thank Davide Crippa from the University of Paris 7 for some helpful back and forth about this paper.   One of the only citations to this paper that I have found is in Pietro Ferroni, De calculo integralium exercitatio mathematica, Allegrini, Florence, 1792, pp. xxi--xxiii. The full text of it is available on Google Books.  ", "human_text": "  Translation from the Latin of \"Annotationes in locum quendam Cartesii ad circuli quadraturam spectantem\" (1763).   The passage Euler is referring to is the \"Excerpta\" in part 6, p. 6 of Descartes' 1701 \"Opuscula posthuma\".   Before reading this paper I had not heard of the \"quadratrix\" before, and I recommend learning a bit about it before reading this. I found Thomas Heath, \"A history of Greek mathematics\", vol. I, chapter VII to be helpful, in particular pp. 226-230. The quadratrix is a \"mechanical curve\" that can be used to rectify the circle. The usual problem of squaring the circle is to construct a square with the same area (or perimeter) as a given circle, in a finite number of steps using compass and straightedge. Descartes worked in the reverse direction: from a given square he constructed the radius of a circle with the same perimeter, but in an infinite number of steps.   In this paper Euler reconstructs Descartes' argument and develops some consequences of it. Euler finds that \\[ \\sum_{n=0}^\\infty \\frac{1}{2^n} \\tan \\frac{1}{2^n}\\phi = \\frac{1}{\\phi} - 2\\cot 2\\phi. \\] Integrating this yields \\[ \\prod_{n=1}^\\infty \\sec \\frac{1}{2^n} \\phi = \\frac{2\\phi}{\\sin 2\\phi}. \\]   I'd like to thank Davide Crippa from the University of Paris 7 for some helpful back and forth about this paper.   One of the only citations to this paper that I have found is in Pietro Ferroni, De calculo integralium exercitatio mathematica, Allegrini, Florence, 1792, pp. xxi--xxiii. The full text of it is available on Google Books. ", "machine_text": "This paper examines the Latin \u201cAnnotationes in locum quendam Cartesii ad circuli quadraturam spectantem\u201d by Leonhard Euler, originally published in 1763. It reviews a passage from Descartes\u2019 \u201cOpuscula posthuma\u201d, in which he utilizes the \u201cquadratrix\u201d, a \u201cmechanical curve\u201d, to rectify the circle. He reverses the traditional problem of squaring the circle \u2013 instead of constructing a square with the same area or perimeter of a given circle in a finite number of steps, he is attempting to construct the radius of a circle with the same perimeter using an infinite number of steps. Euler reconstructs Descartes' argument, ultimately deducing two equations, one of which when integrated, yields a formula derived from said argument. The bibliographic reference of this paper is Pietro Ferroni\u2019s \u201cDe calculo integralium exercitatio mathematica\u201d, published in 1792.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3423}
{"prompt": "Rephrase the abstract of an article with title 'A Covariant Holographic Entanglement Entropy Proposal'.   With an aim towards understanding the time-dependence of entanglement entropy in generic quantum field theories, we propose a covariant generalization of the holographic entanglement entropy proposal of hep-th/0603001. Apart from providing several examples of possible covariant generalizations, we study a particular construction based on light-sheets, motivated in similar spirit to the covariant entropy bound underlying the holographic principle. In particular, we argue that the entanglement entropy associated with a specified region on the boundary in the context of the AdS/CFT correspondence is given by the area of a co-dimension two bulk surface with vanishing expansions of null geodesics. We demonstrate our construction with several examples to illustrate its reduction to the holographic entanglement entropy proposal in static spacetimes. We further show how this proposal may be used to understand the time evolution of entanglement entropy in a time varying QFT state dual to a collapsing black hole background. Finally, we use our proposal to argue that the Euclidean wormhole geometries with multiple boundaries should be regarded as states in a non-interacting but entangled set of QFTs, one associated to each boundary.  ", "human_text": "  With an aim towards understanding the time-dependence of entanglement entropy in generic quantum field theories, we propose a covariant generalization of the holographic entanglement entropy proposal of hep-th/0603001. Apart from providing several examples of possible covariant generalizations, we study a particular construction based on light-sheets, motivated in similar spirit to the covariant entropy bound underlying the holographic principle. In particular, we argue that the entanglement entropy associated with a specified region on the boundary in the context of the AdS/CFT correspondence is given by the area of a co-dimension two bulk surface with vanishing expansions of null geodesics. We demonstrate our construction with several examples to illustrate its reduction to the holographic entanglement entropy proposal in static spacetimes. We further show how this proposal may be used to understand the time evolution of entanglement entropy in a time varying QFT state dual to a collapsing black hole background. Finally, we use our proposal to argue that the Euclidean wormhole geometries with multiple boundaries should be regarded as states in a non-interacting but entangled set of QFTs, one associated to each boundary. ", "machine_text": " This work provides a framework for analyzing the time-dependent entanglement entropy in generic quantum field theories. In line with the underlying covariant entropy bound behind the holographic principle, our proposal contains several covariant generalizations meant to evaluate the entanglement entropy associated with a certain boundary region. Specifically, we provide a construction which involves the area of a co-dimension two bulk surface with vanishing expansions of null geodesics, in accordance with the AdS/CFT correspondence. Through examples, we illustrate how this covarientized version of the holographic entanglement entropy proposal works in static spacetimes, as well as in a collapsing black hole background. Additionally, we comment on the idea of considering Euclidean wormhole geometries with multiple boundaries as states induced by a set of non-interacting but entangled QFTs, each corresponding to one of the boundaries.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0016}
{"prompt": "Rephrase the abstract of an article with title 'The scalar wave equation in a non-commutative spherically symmetric   space-time'.   Recent work in the literature has studied a version of non-commutative Schwarzschild black holes where the effects of non-commutativity are described by a mass function depending on both the radial variable r and a non-commutativity parameter theta. The present paper studies the asymptotic behaviour of solutions of the zero-rest-mass scalar wave equation in such a modified Schwarzschild space-time in a neighbourhood of spatial infinity. The analysis is eventually reduced to finding solutions of an inhomogeneous Euler--Poisson--Darboux equation, where the parameter theta affects explicitly the functional form of the source term. Interestingly, for finite values of theta, there is full qualitative agreement with general relativity: the conformal singularity at spacelike infinity reduces in a considerable way the differentiability class of scalar fields at future null infinity. In the physical space-time, this means that the scalar field has an asymptotic behaviour with a fall-off going on rather more slowly than in flat space-time.  ", "human_text": "  Recent work in the literature has studied a version of non-commutative Schwarzschild black holes where the effects of non-commutativity are described by a mass function depending on both the radial variable r and a non-commutativity parameter theta. The present paper studies the asymptotic behaviour of solutions of the zero-rest-mass scalar wave equation in such a modified Schwarzschild space-time in a neighbourhood of spatial infinity. The analysis is eventually reduced to finding solutions of an inhomogeneous Euler--Poisson--Darboux equation, where the parameter theta affects explicitly the functional form of the source term. Interestingly, for finite values of theta, there is full qualitative agreement with general relativity: the conformal singularity at spacelike infinity reduces in a considerable way the differentiability class of scalar fields at future null infinity. In the physical space-time, this means that the scalar field has an asymptotic behaviour with a fall-off going on rather more slowly than in flat space-time. ", "machine_text": "This article investigates the relationship between the scalar wave equation and a modified Schwarzschild space-time in a non-commutative geometry. Solutions to the equation are analyzed near spatial infinity, and the investigation concludes that if theta is finite, then the field's asymptotic behavior is reduced in class due to the conformal singularity at spacelike infinity, resulting in a slower fall-off than what is seen in flat space-time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0242}
{"prompt": "Rephrase the abstract of an article with title '2-Frame flow dynamics and hyperbolic rank rigidity in nonpositive   curvature'.   This paper presents hyperbolic rank rigidity results for rank 1, nonpositively curved spaces. Let $M$ be a compact, rank 1 manifold with nonpositive sectional curvature and suppose that along every geodesic in $M$ there is a parallel vector field making curvature $-a^2$ with the geodesic direction. We prove that $M$ has constant curvature equal to $-a^2$ if $M$ is odd dimensional, or if $M$ is even dimensional and has sectional curvature pinched as follows: $-\\Lambda^2 < K < -\\lambda^2$ where $\\lambda/\\Lambda > >.93$. When $-a^2$ is the upper curvature bound this gives a shorter proof of the hyperbolic rank rigidity theorem of Hamenst\\\"{a}dt, subject to the pinching condition in even dimension; in all other cases it is a new result. We also present a rigidity result using only an assumption on maximal Lyapunov exponents in direct analogy with work done by Connell. The proof of the main theorem is simplified considerably by assuming strict negative curvature; in fact, in all dimensions but 7 and 8 it is then an immediate consequence of ergodicity of the $(dim(M)-1)$-frame flow. In these exceptional dimensions, recourse to the dynamics of the 2-frame flow must be made and the scheme of proof developed there can be generalized to deal with rank 1, nonpositively curved spaces.  ", "human_text": "  This paper presents hyperbolic rank rigidity results for rank 1, nonpositively curved spaces. Let $M$ be a compact, rank 1 manifold with nonpositive sectional curvature and suppose that along every geodesic in $M$ there is a parallel vector field making curvature $-a^2$ with the geodesic direction. We prove that $M$ has constant curvature equal to $-a^2$ if $M$ is odd dimensional, or if $M$ is even dimensional and has sectional curvature pinched as follows: $-\\Lambda^2 < K < -\\lambda^2$ where $\\lambda/\\Lambda > >.93$. When $-a^2$ is the upper curvature bound this gives a shorter proof of the hyperbolic rank rigidity theorem of Hamenst\\\"{a}dt, subject to the pinching condition in even dimension; in all other cases it is a new result. We also present a rigidity result using only an assumption on maximal Lyapunov exponents in direct analogy with work done by Connell. The proof of the main theorem is simplified considerably by assuming strict negative curvature; in fact, in all dimensions but 7 and 8 it is then an immediate consequence of ergodicity of the $(dim(M)-1)$-frame flow. In these exceptional dimensions, recourse to the dynamics of the 2-frame flow must be made and the scheme of proof developed there can be generalized to deal with rank 1, nonpositively curved spaces. ", "machine_text": " This paper investigates rank 1, nonpositively curved spaces by exploring hyperbolic rank rigidity results. We assume that along each geodesic in the compact, rank 1 manifold $M$ with nonpositive sectional curvature there is a parallel vector field that causes curvature to equal $-a^2$ in the direction of the geodesic. The results of this paper indicate that if $M$ is of odd dimension, or if it is even and the sectional curvature is pinched to be between -$\\Lambda^2$ and -$\\lambda^2$ (where $\\lambda / \\Lambda > 0.93$), the curvature of $M$ will be constant and equal to $-a^2$. This research confirms the result of Hyperbolic Rank Rigidity Theorem by Hamenst\\\"{a}dt when bounded from above by $-a^2$, and also provides a new result in other scenarios. We provide a rigidity result with only an assumption on maximal Lyapunov exponents similar to a previous work by Connell. The proof of the major theorem is simplified by assuming negative curvature, and outside of dimensions 7 and 8 the proof relies solely on ergodicity of the $(dim(M)-1)$-frame flow. For these 2 exceptional dimensions the 2-frame flow is used instead to develop a scheme for generalizing the result.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1853}
{"prompt": "Rephrase the abstract of an article with title 'Role of Dynamical Research in the Detection and Characterization of   Exoplanets'.   (Abridged) The discovery of extrasolar planetary systems revealed an unexpected diversity of planetary systems that has revolutionized planet formation theory. A strong program of theoretical research is essential to maximize both the discovery potential and the scientific returns of future observational programs, so as to achieve a deeper understanding of the formation and evolution of planetary systems. We outline three broad categories of theoretical research: detailed studies of specific planetary systems, testing planet formation models by comparing their predictions to the observed exoplanet population, and detailed modeling of specific physical processes. We describe how such theoretical research plays an important role in analyzing observations for a wide range detection methods and contributes to understanding the Earth's place in the universe and the potential for Earth-like life beyond our solar system. In this white paper, we suggest how to maximize the scientific return of future exoplanet observations. Our recommendations include a strong theory program, support for multiple observational programs that will study a diverse set of planets and stars, significant observing time devoted to follow-up observations, and healthy collaboration between observers and theorists.  ", "human_text": "  (Abridged) The discovery of extrasolar planetary systems revealed an unexpected diversity of planetary systems that has revolutionized planet formation theory. A strong program of theoretical research is essential to maximize both the discovery potential and the scientific returns of future observational programs, so as to achieve a deeper understanding of the formation and evolution of planetary systems. We outline three broad categories of theoretical research: detailed studies of specific planetary systems, testing planet formation models by comparing their predictions to the observed exoplanet population, and detailed modeling of specific physical processes. We describe how such theoretical research plays an important role in analyzing observations for a wide range detection methods and contributes to understanding the Earth's place in the universe and the potential for Earth-like life beyond our solar system. In this white paper, we suggest how to maximize the scientific return of future exoplanet observations. Our recommendations include a strong theory program, support for multiple observational programs that will study a diverse set of planets and stars, significant observing time devoted to follow-up observations, and healthy collaboration between observers and theorists. ", "machine_text": "This paper examines the role of dynamical research in detection and characterization of exoplanets. The discovery of planetary systems outside our Solar System has ushered a new era of planet formation theory. To maximize discovery potential and the scientific returns of observational programs, dynamical research should be incorporated. The three main categories of theoretical research discussed here are studies of individual planetary systems, testing of planet formation models, and modeling of physical processes. The paper also discusses the advantages of incorporating dynamical research in locating life-bearing exoplanets, and how this can be achieved through support for multiple observational programs, follow-up observations, and collaboration between observers and theorists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2781}
{"prompt": "Rephrase the abstract of an article with title 'Optimal Occulter Design for Finding Extrasolar Planets'.   One proposed method for finding terrestrial planets around nearby stars is to use two spacecraft--a telescope and a specially shaped occulter that is specifically designed to prevent all but a tiny fraction of the starlight from diffracting into the telescope. As the cost and observing cadence for such a mission will be driven largely by the separation between the two spacecraft, it is critically important to design an occulter that can meet the observing goals while flying as close to the telescope as possible. In this paper, we explore this tradeoff between separation and occulter diameter. More specifically, we present a method for designing the shape of the outer edge of an occulter that is as small as possible and gives a shadow that is deep enough and large enough for a 4m telescope to survey the habitable zones of many stars for Earth-like planets. In particular, we show that in order for a 4m telescope to detect in broadband visible light a planet 0.06 arcseconds from a star shining $10^{10}$ times brighter than the planet requires a specially-shaped occulter 50m in diameter positioned about $72,000$ km in front of the telescope.  ", "human_text": "  One proposed method for finding terrestrial planets around nearby stars is to use two spacecraft--a telescope and a specially shaped occulter that is specifically designed to prevent all but a tiny fraction of the starlight from diffracting into the telescope. As the cost and observing cadence for such a mission will be driven largely by the separation between the two spacecraft, it is critically important to design an occulter that can meet the observing goals while flying as close to the telescope as possible. In this paper, we explore this tradeoff between separation and occulter diameter. More specifically, we present a method for designing the shape of the outer edge of an occulter that is as small as possible and gives a shadow that is deep enough and large enough for a 4m telescope to survey the habitable zones of many stars for Earth-like planets. In particular, we show that in order for a 4m telescope to detect in broadband visible light a planet 0.06 arcseconds from a star shining $10^{10}$ times brighter than the planet requires a specially-shaped occulter 50m in diameter positioned about $72,000$ km in front of the telescope. ", "machine_text": " This paper focuses on an optimized design of an occulter that would enable a 4m telescope to search the habitable zones of numerous stars for Earth-like exoplanets. A key factor in the cost and success of this kind of mission will be the separation between the telescope and the occulter, meaning it is essential to devise an occulter that is small enough to be positioned close to the telescope yet deep and broad enough to effectively block starlight. We show that in order to detect a planet 0.06 arcseconds away from a star of 10 billion times brighter, the occulter requires a shape tailored for this size, 50 meters in diameter, and would have to fly around 72,000 km from the telescope.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3488}
{"prompt": "Rephrase the abstract of an article with title 'Metal Cooling in Simulations of Cosmic Structure Formation'.   The addition of metals to any gas can significantly alter its evolution by increasing the rate of radiative cooling. In star-forming environments, enhanced cooling can potentially lead to fragmentation and the formation of low-mass stars, where metal-free gas-clouds have been shown not to fragment. Adding metal cooling to numerical simulations has traditionally required a choice between speed and accuracy. We introduce a method that uses the sophisticated chemical network of the photoionization software, Cloudy, to include radiative cooling from a complete set of metals up to atomic number 30 (Zn) that can be used with large-scale three-dimensional hydrodynamic simulations. Our method is valid over an extremely large temperature range (10 K < T < 10^8 K), up to hydrogen number densities of 10^12 cm^-3. At this density, a sphere of 1 Msun has a radius of roughly 40 AU. We implement our method in the adaptive mesh refinement (AMR) hydrodynamic/N-body code, Enzo. Using cooling rates generated with this method, we study the physical conditions that led to the transition from Population III to Population II star formation. While C, O, Fe, and Si have been previously shown to make the strongest contribution to the cooling in low-metallicity gas, we find that up to 40% of the metal cooling comes from fine-structure emission by S, when solar abundance patterns are present. At metallicities, Z > 10^-4 Zsun, regions of density and temperature exist where gas is both thermally unstable and has a cooling time less than its dynamical time. We identify these doubly unstable regions as the most inducive to fragmentation. At high redshifts, the CMB inhibits efficient cooling at low temperatures and, thus, reduces the size of the doubly unstable regions, making fragmentation more difficult.  ", "human_text": "  The addition of metals to any gas can significantly alter its evolution by increasing the rate of radiative cooling. In star-forming environments, enhanced cooling can potentially lead to fragmentation and the formation of low-mass stars, where metal-free gas-clouds have been shown not to fragment. Adding metal cooling to numerical simulations has traditionally required a choice between speed and accuracy. We introduce a method that uses the sophisticated chemical network of the photoionization software, Cloudy, to include radiative cooling from a complete set of metals up to atomic number 30 (Zn) that can be used with large-scale three-dimensional hydrodynamic simulations. Our method is valid over an extremely large temperature range (10 K < T < 10^8 K), up to hydrogen number densities of 10^12 cm^-3. At this density, a sphere of 1 Msun has a radius of roughly 40 AU. We implement our method in the adaptive mesh refinement (AMR) hydrodynamic/N-body code, Enzo. Using cooling rates generated with this method, we study the physical conditions that led to the transition from Population III to Population II star formation. While C, O, Fe, and Si have been previously shown to make the strongest contribution to the cooling in low-metallicity gas, we find that up to 40% of the metal cooling comes from fine-structure emission by S, when solar abundance patterns are present. At metallicities, Z > 10^-4 Zsun, regions of density and temperature exist where gas is both thermally unstable and has a cooling time less than its dynamical time. We identify these doubly unstable regions as the most inducive to fragmentation. At high redshifts, the CMB inhibits efficient cooling at low temperatures and, thus, reduces the size of the doubly unstable regions, making fragmentation more difficult. ", "machine_text": "This paper presents a method to incorporate metal cooling into numerical simulations of cosmic structure formation. Leveraging the sophisticated chemical network of the photoionization software Cloudy, cooling rates are generated across a temperature range of 10 K to 10^8 K and up to a hydrogen number density of 10^12 cm^-3. When implementing these rates in the adaptive mesh refinement (AMR) hydrodynamic/N-body code Enzo, the authors investigate physical conditions that led to the transition from Population III to Population II star formation. Results show that including metals up to a certain atomic number (Zn) increases the rate of radiative cooling and can potentially lead to fragmentation and the formation of low-mass stars from regions of certain density and temperature. In addition, up to 40% of the cooling can come from fine-structure emission by S when solar abundance patterns are present. The CMB inhibits efficient cooling at high redshifts, making fragmentation more difficult in doubly unstable regions than at lower redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0754}
{"prompt": "Rephrase the abstract of an article with title 'Parametrized Post-Newtonian Expansion of Chern-Simons Gravity'.   We investigate the weak-field, post-Newtonian expansion to the solution of the field equations in Chern-Simons gravity with a perfect fluid source. In particular, we study the mapping of this solution to the parameterized post-Newtonian formalism to 1 PN order in the metric. We find that the PPN parameters of Chern-Simons gravity are identical to those of general relativity, with the exception of the inclusion of a new term that is proportional to the Chern-Simons coupling parameter and the curl of the PPN vector potentials. We also find that the new term is naturally enhanced by the non-linearity of spacetime and we provide a physical interpretation for it. By mapping this correction to the gravito-electro-magnetic framework, we study the corrections that this new term introduces to the acceleration of point particles and the frame-dragging effect in gyroscopic precession. We find that the Chern-Simons correction to these classical predictions could be used by current and future experiments to place bounds on intrinsic parameters of Chern-Simons gravity and, thus, string theory.  ", "human_text": "  We investigate the weak-field, post-Newtonian expansion to the solution of the field equations in Chern-Simons gravity with a perfect fluid source. In particular, we study the mapping of this solution to the parameterized post-Newtonian formalism to 1 PN order in the metric. We find that the PPN parameters of Chern-Simons gravity are identical to those of general relativity, with the exception of the inclusion of a new term that is proportional to the Chern-Simons coupling parameter and the curl of the PPN vector potentials. We also find that the new term is naturally enhanced by the non-linearity of spacetime and we provide a physical interpretation for it. By mapping this correction to the gravito-electro-magnetic framework, we study the corrections that this new term introduces to the acceleration of point particles and the frame-dragging effect in gyroscopic precession. We find that the Chern-Simons correction to these classical predictions could be used by current and future experiments to place bounds on intrinsic parameters of Chern-Simons gravity and, thus, string theory. ", "machine_text": " We examine the weak field, post-Newtonian expansion of Chern-Simons gravity, allowing interactions with a perfect fluid source. In particular, we analyze the mapping of this solution to the Parameterized Post-Newtonian (PPN) formalism to 1 PN order on the metric. Our results demonstrate that the PPN parameters of Chern-Simons gravity are identical to those of general relativity, with the exception of a new term introduced by the Chern-Simons coupling parameter and the curl of the PPN vector potentials. This new term is further enhanced by the nonlinearity of spacetime. Connecting this correction to the gravito-electromagnetic framework, we explore how it modifies the acceleration of point particles and the frame dragging effect in gyroscopic precession. Our findings suggest that modern and future experiments have the capability to detect these corrections and, as a result, place constraints on intrinsic Chern-Simons parameters and string theory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0299}
{"prompt": "Rephrase the abstract of an article with title 'Exploring the Variable Sky with the Sloan Digital Sky Survey'.   We quantify the variability of faint unresolved optical sources using a catalog based on multiple SDSS imaging observations. The catalog covers SDSS Stripe 82, and contains 58 million photometric observations in the SDSS ugriz system for 1.4 million unresolved sources. In each photometric bandpass we compute various low-order lightcurve statistics and use them to select and study variable sources. We find that 2% of unresolved optical sources brighter than g=20.5 appear variable at the 0.05 mag level (rms) simultaneously in the g and r bands. The majority (2/3) of these variable sources are low-redshift (<2) quasars, although they represent only 2% of all sources in the adopted flux-limited sample. We find that at least 90% of quasars are variable at the 0.03 mag level (rms) and confirm that variability is as good a method for finding low-redshift quasars as is the UV excess color selection (at high Galactic latitudes). We analyze the distribution of lightcurve skewness for quasars and find that is centered on zero. We find that about 1/4 of the variable stars are RR Lyrae stars, and that only 0.5% of stars from the main stellar locus are variable at the 0.05 mag level. The distribution of lightcurve skewness in the g-r vs. u-g color-color diagram on the main stellar locus is found to be bimodal (with one mode consistent with Algol-like behavior). Using over six hundred RR Lyrae stars, we demonstrate rich halo substructure out to distances of 100 kpc. We extrapolate these results to expected performance by the Large Synoptic Survey Telescope and estimate that it will obtain well-sampled 2% accurate, multi-color lightcurves for ~2 million low-redshift quasars, and will discover at least 50 million variable stars.  ", "human_text": "  We quantify the variability of faint unresolved optical sources using a catalog based on multiple SDSS imaging observations. The catalog covers SDSS Stripe 82, and contains 58 million photometric observations in the SDSS ugriz system for 1.4 million unresolved sources. In each photometric bandpass we compute various low-order lightcurve statistics and use them to select and study variable sources. We find that 2% of unresolved optical sources brighter than g=20.5 appear variable at the 0.05 mag level (rms) simultaneously in the g and r bands. The majority (2/3) of these variable sources are low-redshift (<2) quasars, although they represent only 2% of all sources in the adopted flux-limited sample. We find that at least 90% of quasars are variable at the 0.03 mag level (rms) and confirm that variability is as good a method for finding low-redshift quasars as is the UV excess color selection (at high Galactic latitudes). We analyze the distribution of lightcurve skewness for quasars and find that is centered on zero. We find that about 1/4 of the variable stars are RR Lyrae stars, and that only 0.5% of stars from the main stellar locus are variable at the 0.05 mag level. The distribution of lightcurve skewness in the g-r vs. u-g color-color diagram on the main stellar locus is found to be bimodal (with one mode consistent with Algol-like behavior). Using over six hundred RR Lyrae stars, we demonstrate rich halo substructure out to distances of 100 kpc. We extrapolate these results to expected performance by the Large Synoptic Survey Telescope and estimate that it will obtain well-sampled 2% accurate, multi-color lightcurves for ~2 million low-redshift quasars, and will discover at least 50 million variable stars. ", "machine_text": " We analyze the changes in flux of faint, unresolved optical sources in the SDSS Stripe 82 by monitoring their photometric brightness across the SDSS ugriz bands. Our catalog collected 1.4 million observations and identified that 2% of these sources brighter than g=20.5 demonstrated a 0.05 mag (rms) variation simultaneously in both the g and r bands. Of these sources, two-thirds were found to be low-redshift quasars, although they only constitute 2% of all sources in the flux-limited sample. We establish that, at the 0.03 mag level, over 90% of quasars are variable and thus variability serves as a viable indicator for the selection of low-redshift quasars at high galactic latitudes. Further examinations of the quasar lightcurve skewness prove it is centered at zero. We also observe that roughly a quarter of the variable stars are RR Lyrae stars, and that only 0.5% of the sources in the main stellar locus demonstrate 0.05 mag of variability. Using over 600 RR Lyrae stars, we have detected halo substructures out to distances of 100 kpc. Predictions made by the Large Synoptic Survey Telescope estimate it will detect 2 million low-redshift quasars that display 0.02 mag (rms) variability, in addition to a total of 50 million variable stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0655}
{"prompt": "Rephrase the abstract of an article with title 'The infrared environments of masers associated with star formation'.   The near infrared (1-2um) and the thermal infrared (3-25um) trace many of the environments in which masers are thought to reside, including shocks, outflows, accretion disks, and the dense medium near protostars. After a number of recent surveys it has been found that there is a higher detection rate of mid-IR emission towards masers than cm radio continuum emission from UC HII regions, and that the mid-IR emission is actually more closely cospatial to the maser locations. A high percentage of water and methanol masers that are not coincident with the UC HII regions in massive star forming regions are likely to be tracing outflows and extremely young high mass stars before the onset of the UC HII region phase. After a decade of groundwork supporting the hypothesis that linarly distributed class II methanol masers may generally trace accretion disks around young massive stars, compelling evidence is mounting that these masers may generally be associated with outflows instead. Substantiation of this claim comes from recent outflow surveys and high angular resolution mid-IR imaging of the maser environments.  ", "human_text": "  The near infrared (1-2um) and the thermal infrared (3-25um) trace many of the environments in which masers are thought to reside, including shocks, outflows, accretion disks, and the dense medium near protostars. After a number of recent surveys it has been found that there is a higher detection rate of mid-IR emission towards masers than cm radio continuum emission from UC HII regions, and that the mid-IR emission is actually more closely cospatial to the maser locations. A high percentage of water and methanol masers that are not coincident with the UC HII regions in massive star forming regions are likely to be tracing outflows and extremely young high mass stars before the onset of the UC HII region phase. After a decade of groundwork supporting the hypothesis that linarly distributed class II methanol masers may generally trace accretion disks around young massive stars, compelling evidence is mounting that these masers may generally be associated with outflows instead. Substantiation of this claim comes from recent outflow surveys and high angular resolution mid-IR imaging of the maser environments. ", "machine_text": "This article explores the relationships between interstellar masers and the infrared emission coming from star formation regions. Recent surveys have found that mid-IR emission is more likely to be detected in association with masers than cm radio continuum emission from UC HII regions. Additionally, a high percentage of water and methanol masers coincident with massive star forming regions are likely to trace outflows and very young high-mass stars before the UC HII region phase. This hypothesis is supported by outflow surveys and mid-IR imaging with high angular resolution of maser environments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.39}
{"prompt": "Rephrase the abstract of an article with title 'Sulphur abundances from the SI near-infrared triplet at 1045 nm'.   context : Unlike silicon and calcium, sulphur is an alpha-element which does not form dust. Some of the available observations of the evolution of sulphur with metallicity indicate an increased scatter of sulphur to iron ratios at low metallicities or even a bimodal distribution, with some stars showing constant S/Fe at all metallicities and others showing an increasing S/Fe ratio with decreasing metallicity. In metal-poor stars SI lines of Multiplet 1 at 920 nm are not yet too weak to permit to measure the sulphur abundance A(S), however in ground-based observations they are severely affected by telluric lines. aims : We investigate the possibility to measure sulphur abundances from SI Mult. 3 at 1045 nm lines, which lie in the near infra-red. These are slightly weaker than those of Mult. 1, but lie in a range not affected by telluric lines. method We investigate the lines of Mult.3 in the Sun (G2V), Procyon (F5V), HD 33256 (F5V), HD 25069 (G9V) and epsilon Eri (HD 22049, K2V). For the Sun and Procyon the analysis has been performed with CO5BOLD 3D hydrodynamical model atmospheres, for the other three stars, for which hydrodynamical simulations are not available, the analysis has been performed using 1D model atmospheres. results For our sample of stars we find a global agreement of A(S) from lines of different multiplets. conclusions : Our results suggest that the infrared lines of Mult. 3 are a viable indicator of the sulphur abundance which, because of the intrinsic strength of this multiplet, should be suitable to study the trend of [S/Fe] at low metallicities.  ", "human_text": "  context : Unlike silicon and calcium, sulphur is an alpha-element which does not form dust. Some of the available observations of the evolution of sulphur with metallicity indicate an increased scatter of sulphur to iron ratios at low metallicities or even a bimodal distribution, with some stars showing constant S/Fe at all metallicities and others showing an increasing S/Fe ratio with decreasing metallicity. In metal-poor stars SI lines of Multiplet 1 at 920 nm are not yet too weak to permit to measure the sulphur abundance A(S), however in ground-based observations they are severely affected by telluric lines. aims : We investigate the possibility to measure sulphur abundances from SI Mult. 3 at 1045 nm lines, which lie in the near infra-red. These are slightly weaker than those of Mult. 1, but lie in a range not affected by telluric lines. method We investigate the lines of Mult.3 in the Sun (G2V), Procyon (F5V), HD 33256 (F5V), HD 25069 (G9V) and epsilon Eri (HD 22049, K2V). For the Sun and Procyon the analysis has been performed with CO5BOLD 3D hydrodynamical model atmospheres, for the other three stars, for which hydrodynamical simulations are not available, the analysis has been performed using 1D model atmospheres. results For our sample of stars we find a global agreement of A(S) from lines of different multiplets. conclusions : Our results suggest that the infrared lines of Mult. 3 are a viable indicator of the sulphur abundance which, because of the intrinsic strength of this multiplet, should be suitable to study the trend of [S/Fe] at low metallicities. ", "machine_text": " In this study, we analyse the possibility of measuring sulphur abundance (A(S)) from the near-infrared triplet of Silicon (SI) at 1045 nm. Unlike Silicon and Calcium, sulphur does not form dust, which results in an increased scatter of sulphur-to-iron ratios seen in observations of low metallicities or a bimodal distribution seen in some stars. Given that the lines of Multiplet 1 at 920 nm are affected by telluric lines when observed from the ground, Multiplet 3 at 1045 nm, which is located in a range that is clear from such contamination, is considered here. Our sample is composed of the Sun (G2V), Procyon (F5V), HD 33256 (F5V), HD 25069 (G9V) and epsilon Eri (HD 22049, K2V). For the Sun and Procyon, the analysis is conducted with CO5BOLD 3D hydrodynamical model atmospheres, while for the other three stars, 1D models are employed. Ultimately, we discover that the infrared lines of Mult.3 are a reliable instrument of A(S) measurement and can be useful in analysing the evolution of [S/Fe] at low metallicities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2335}
{"prompt": "Rephrase the abstract of an article with title 'Derivations and skew derivations of the Grassmann algebras'.   Surprisingly, skew derivations rather than ordinary derivations are more basic (important) object in study of the Grassmann algebras. Let $\\L_n = K\\lfloor x_1, ..., x_n\\rfloor$ be the Grassmann algebra over a commutative ring $K$ with ${1/2}\\in K$, and $\\d$ be a skew $K$-derivation of $\\L_n$. It is proved that $\\d$ is a unique sum $\\d = \\d^{ev} +\\d^{od}$ of an even and odd skew derivation. Explicit formulae are given for $\\d^{ev}$ and $\\d^{od}$ via the elements $\\d (x_1), ..., \\d (x_n)$. It is proved that the set of all even skew derivations of $\\L_n$ coincides with the set of all the inner skew derivations. Similar results are proved for derivations of $\\L_n$. In particular, $\\Der_K(\\L_n)$ is a faithful but not simple $\\Aut_K(\\L_n)$-module (where $K$ is reduced and $n\\geq 2$). All differential and skew differential ideals of $\\L_n$ are found. It is proved that the set of generic normal elements of $\\L_n$ that are not units forms a single $\\Aut_K(\\L_n)$-orbit (namely, $\\Aut_K(\\L_n)x_1$) if $n$ is even and two orbits (namely, $\\Aut_K(\\L_n)x_1$ and $\\Aut_K(\\L_n)(x_1+x_2... x_n)$) if $n$ is odd.  ", "human_text": "  Surprisingly, skew derivations rather than ordinary derivations are more basic (important) object in study of the Grassmann algebras. Let $\\L_n = K\\lfloor x_1, ..., x_n\\rfloor$ be the Grassmann algebra over a commutative ring $K$ with ${1/2}\\in K$, and $\\d$ be a skew $K$-derivation of $\\L_n$. It is proved that $\\d$ is a unique sum $\\d = \\d^{ev} +\\d^{od}$ of an even and odd skew derivation. Explicit formulae are given for $\\d^{ev}$ and $\\d^{od}$ via the elements $\\d (x_1), ..., \\d (x_n)$. It is proved that the set of all even skew derivations of $\\L_n$ coincides with the set of all the inner skew derivations. Similar results are proved for derivations of $\\L_n$. In particular, $\\Der_K(\\L_n)$ is a faithful but not simple $\\Aut_K(\\L_n)$-module (where $K$ is reduced and $n\\geq 2$). All differential and skew differential ideals of $\\L_n$ are found. It is proved that the set of generic normal elements of $\\L_n$ that are not units forms a single $\\Aut_K(\\L_n)$-orbit (namely, $\\Aut_K(\\L_n)x_1$) if $n$ is even and two orbits (namely, $\\Aut_K(\\L_n)x_1$ and $\\Aut_K(\\L_n)(x_1+x_2... x_n)$) if $n$ is odd. ", "machine_text": "The study of Grassmann Algebras has revealed the fundamental nature of skew derivations over ordinary derivations. Taking $\\mathcal{L}_n = K \\langle x_1,\\cdots,x_n \\rangle$ as a Grassmann Algebra over a commutative ring $K$ where $\\frac{1}{2} \\in K$, and any skew $K$-derivation $\\delta$ being the sum $\\delta = \\delta^{ev} + \\delta^{od}$ of an even and odd skew derivation, formulae are given to find $\\delta_{ev}$ and $\\delta_{od}$ to in terms of $\\delta (x_1),\\cdots,\\delta (x_n)$. Furthermore, it has been deduced that the set of all even skew derivations of $\\mathcal{L}_n$ coincide with the set of inner skew derivations. Results analogous to this have been found for derivations of $\\mathcal{L}_n$. Additionally, all differential and skew differential ideals of $\\mathcal{L}_n$ have been discovered. Finally, it has been elucidated that the set of all generic normal non-unit elements in $\\mathcal{L}_n$ forms a single orbit when $n$ is even, or two orbits when $n$ is odd.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.385}
{"prompt": "Rephrase the abstract of an article with title 'Antiferromagnetic Spin Fluctuations in the Metallic Phase of   Quasi-Two-Dimensional Organic Superconductors'.   We give a quantitative analysis of the previously published nuclear magnetic resonance (NMR) experiments in the k-(ET)2X family of organic charge transfer salts by using the phenomenological spin fluctuation model of Moriya, and Millis, Monien and Pines (M-MMP). For temperatures above T_nmr ~ 50 K, the model gives a good quantitative description of the data in the metallic phases of several k-(ET)2X materials. These materials display antiferromagnetic correlation lengths which increase with decreasing temperature and grow to several lattice constants by T_nmr. It is shown that the fact that the dimensionless Korringa ratio is much larger than unity is inconsistent with a broad class of theoretical models (such as dynamical mean-field theory) which neglects spatial correlations and/or vertex corrections. For materials close to the Mott insulating phase the nuclear spin relaxation rate, the Knight shift and the Korringa ratio all decrease significantly with decreasing temperature below T_nmr. This cannot be described by the M-MMP model and the most natural explanation is that a pseudogap, similar to that observed in the underdoped cuprate superconductors, opens up in the density of states below T_nmr. Such a pseudogap has recently been predicted to occur in the dimerised organic charge transfer salts materials by the resonating valence bond (RVB) theory. We propose specific new experiments on organic superconductors to elucidate these issues. For example, measurements to see if high magnetic fields or high pressures can be used to close the pseudogap would be extremely valuable.  ", "human_text": "  We give a quantitative analysis of the previously published nuclear magnetic resonance (NMR) experiments in the k-(ET)2X family of organic charge transfer salts by using the phenomenological spin fluctuation model of Moriya, and Millis, Monien and Pines (M-MMP). For temperatures above T_nmr ~ 50 K, the model gives a good quantitative description of the data in the metallic phases of several k-(ET)2X materials. These materials display antiferromagnetic correlation lengths which increase with decreasing temperature and grow to several lattice constants by T_nmr. It is shown that the fact that the dimensionless Korringa ratio is much larger than unity is inconsistent with a broad class of theoretical models (such as dynamical mean-field theory) which neglects spatial correlations and/or vertex corrections. For materials close to the Mott insulating phase the nuclear spin relaxation rate, the Knight shift and the Korringa ratio all decrease significantly with decreasing temperature below T_nmr. This cannot be described by the M-MMP model and the most natural explanation is that a pseudogap, similar to that observed in the underdoped cuprate superconductors, opens up in the density of states below T_nmr. Such a pseudogap has recently been predicted to occur in the dimerised organic charge transfer salts materials by the resonating valence bond (RVB) theory. We propose specific new experiments on organic superconductors to elucidate these issues. For example, measurements to see if high magnetic fields or high pressures can be used to close the pseudogap would be extremely valuable. ", "machine_text": "We examine the NMR experiments done on the k-(ET)2X organic materials and demonstrate that above temperatures of 50 K, the antiferromagnetic spin fluctuations are present and the M-MMP phenomenological spin fluctuation model describes the data well. Near the Mott insulating phase, the Korringa ratio becomes much greater than one and suggests vertex corrections or spatial correlations are being neglected. Below 50 K, the Knight shift and Korringa ratio decline, signaling the opening of a pseudogap akin to that observed in the underdoped cuprate superconductors. We suggest experiments to prove the presence of a pseudogap and explore potential methods of closing it altogether.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1382}
{"prompt": "Rephrase the abstract of an article with title 'The Average Kinetic Energy of the Heavy Quark in $\\Lambda_b$ in the   Bethe-Salpeter Equation Approach'.   In the previous paper, based on the $SU(2)_{f}\\times SU(2)_{s}$ heavy quark symmetries of the QCD Lagrangian in the heavy quark limit, the Bethe-Salpeter equation for the heavy baryon $\\Lambda_b$ was established with the picture that $\\Lambda_b$ is composed of a heavy quark and a scalar light diquark. In the present work, we apply this model to calculate $\\mu_\\pi^2$ for $\\Lambda_b$, the average kinetic energy of the heavy quark inside $\\Lambda_{b}$. This quantity is particularly interesting since it can be measured in experiments and since it contributes to the inclusive semileptonic decays of $\\Lambda_b$ when contributions from higher order terms in $1/M_b$ expansions are taken into account and consequently influences the determination of the Cabibbo-Kobayashi-Maskawa matrix elements $V_{ub}$ and $V_{cb}$. We find that $\\mu_\\pi^2$ for $\\Lambda_b$ is $0.25GeV^2$ $\\sim$ $0.95GeV^2$, depending on the parameters in the model including the light diquark mass and the interaction strength between the heavy quark and the light diquark in the kernel of the BS equation. We also find that this result is consistent with the value of $\\mu_\\pi^2$ for $\\Lambda_b$ which is derived from the experimental value of $\\mu_\\pi^2$ for the $B$ meson with the aid of the heavy quark effective theory.  ", "human_text": "  In the previous paper, based on the $SU(2)_{f}\\times SU(2)_{s}$ heavy quark symmetries of the QCD Lagrangian in the heavy quark limit, the Bethe-Salpeter equation for the heavy baryon $\\Lambda_b$ was established with the picture that $\\Lambda_b$ is composed of a heavy quark and a scalar light diquark. In the present work, we apply this model to calculate $\\mu_\\pi^2$ for $\\Lambda_b$, the average kinetic energy of the heavy quark inside $\\Lambda_{b}$. This quantity is particularly interesting since it can be measured in experiments and since it contributes to the inclusive semileptonic decays of $\\Lambda_b$ when contributions from higher order terms in $1/M_b$ expansions are taken into account and consequently influences the determination of the Cabibbo-Kobayashi-Maskawa matrix elements $V_{ub}$ and $V_{cb}$. We find that $\\mu_\\pi^2$ for $\\Lambda_b$ is $0.25GeV^2$ $\\sim$ $0.95GeV^2$, depending on the parameters in the model including the light diquark mass and the interaction strength between the heavy quark and the light diquark in the kernel of the BS equation. We also find that this result is consistent with the value of $\\mu_\\pi^2$ for $\\Lambda_b$ which is derived from the experimental value of $\\mu_\\pi^2$ for the $B$ meson with the aid of the heavy quark effective theory. ", "machine_text": "  This study focuses on the average kinetic energy of the heavy quark within the context of the $\\Lambda_b$ baryon, as determined by the Bethe-Salpeter equation formulated in the framework of the $SU(2)_{f} \\times SU(2)_{s}$ heavy quark symmetries of QCD. This quantity, $\\mu_\\pi^2$, can be extracted from experimental data and is important since it contributes to the inclusive semileptonic decays of $\\Lambda_b$ in the calculation of Cabibbo-Kobayashi-Maskawa matrix elements $V_{ub}$ and $V_{cb}$. Through our research, we conclude that $\\mu_\\pi^2$ for $\\Lambda_b$ ranges between $0.25-0.95GeV^2$, all depending on the light diquark mass and the interactions between the heavy quark and the light diquark. This result is consistent with the value of $\\mu_\\pi^2$ for $\\Lambda_b$ derived through the heavy quark effective theory from the experimental value of $\\mu_\\pi^2$ for the $B$ meson.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1379}
{"prompt": "Rephrase the abstract of an article with title 'Non-topological solitons in field theories with kinetic self-coupling'.   We investigate some fundamental features of a class of non-linear relativistic lagrangian field theories with kinetic self-coupling. We focus our attention upon theories admitting static, spherically symmetric solutions in three space dimensions which are finite-energy and stable. We determine general conditions for the existence and stability of these non-topological soliton solutions. In particular, we perform a linear stability analysis that goes beyond the usual Derrick-like criteria. On the basis of these considerations we obtain a complete characterization of the soliton-supporting members of the aforementioned class of non-linear field theories. We then classify the family of soliton-supporting theories according to the central and asymptotic behaviors of the soliton field, and provide illustrative explicit examples of models belonging to each of the corresponding sub-families. In the present work we restrict most of our considerations to one and many-components scalar models. We show that in these cases the finite-energy static spherically symmetric solutions are stable against charge-preserving perturbations, provided that the vacuum energy of the model vanishes and the energy density is positive definite. We also discuss briefly the extension of the present approach to models involving other types of fields, but a detailed study of this more general scenario will be addressed in a separate publication.  ", "human_text": "  We investigate some fundamental features of a class of non-linear relativistic lagrangian field theories with kinetic self-coupling. We focus our attention upon theories admitting static, spherically symmetric solutions in three space dimensions which are finite-energy and stable. We determine general conditions for the existence and stability of these non-topological soliton solutions. In particular, we perform a linear stability analysis that goes beyond the usual Derrick-like criteria. On the basis of these considerations we obtain a complete characterization of the soliton-supporting members of the aforementioned class of non-linear field theories. We then classify the family of soliton-supporting theories according to the central and asymptotic behaviors of the soliton field, and provide illustrative explicit examples of models belonging to each of the corresponding sub-families. In the present work we restrict most of our considerations to one and many-components scalar models. We show that in these cases the finite-energy static spherically symmetric solutions are stable against charge-preserving perturbations, provided that the vacuum energy of the model vanishes and the energy density is positive definite. We also discuss briefly the extension of the present approach to models involving other types of fields, but a detailed study of this more general scenario will be addressed in a separate publication. ", "machine_text": " In this work, we study the properties of a class of relativistic lagrangian field  theories with kinetic self-coupling that hosts spherically symmetric, finite-energy  non-topological soliton solutions in three space dimensions and analyze their stability. We first derive conditions required for such solitons to exist and be stable, going beyond standard Derrick-like criteria. Following this, we classify these solutions by the central and asymptotic behaviors of the field and provide examples of the various sub-families. In particular, we discuss the stability of one- and multi-component scalar models with a vanishing vacuum energy and a  positive definite energy density against charge-preserving perturbations. A more  in-depth analysis of the general case is provided in a future publication.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0112}
{"prompt": "Rephrase the abstract of an article with title 'Kinematics of hypervelocity stars in the triaxial halo of the Milky Way'.   Hypervelocity stars (HVSs) ejected by the massive black hole at the Galactic center have unique kinematic properties compared to other halo stars. Their trajectories will deviate from being exactly radial because of the asymmetry of the Milky Way potential produced by the flattened disk and the triaxial dark matter halo, causing a change of angular momentum that can be much larger than the initial small value at injection. We study the kinematics of HVSs and propose an estimator of dark halo triaxiality that is determined only by instantaneous position and velocity vectors of HVSs at large Galactocentric distances (r>~50kpc). We show that, in the case of a substantially triaxial halo, the distribution of deflection angles (the angle between the stellar position and velocity vector) for HVSs on bound orbits is spread uniformly over the range 10--180deg. Future astrometric and deep wide-field surveys should measure the positions and velocities of a significant number of HVSs, and provide useful constraints on the shape of the Galactic dark matter halo.  ", "human_text": "  Hypervelocity stars (HVSs) ejected by the massive black hole at the Galactic center have unique kinematic properties compared to other halo stars. Their trajectories will deviate from being exactly radial because of the asymmetry of the Milky Way potential produced by the flattened disk and the triaxial dark matter halo, causing a change of angular momentum that can be much larger than the initial small value at injection. We study the kinematics of HVSs and propose an estimator of dark halo triaxiality that is determined only by instantaneous position and velocity vectors of HVSs at large Galactocentric distances (r>~50kpc). We show that, in the case of a substantially triaxial halo, the distribution of deflection angles (the angle between the stellar position and velocity vector) for HVSs on bound orbits is spread uniformly over the range 10--180deg. Future astrometric and deep wide-field surveys should measure the positions and velocities of a significant number of HVSs, and provide useful constraints on the shape of the Galactic dark matter halo. ", "machine_text": " The instantaneous positions and velocities of Hypervelocity Stars (HVSs) ejected from the Galactic Center provide insight into the asymmetrical potential of the Milky Way, and allow us to estimate the triaxiality of its dark matter halo. By studying the trajectories of these stars at large Galactocentric distances (r>~50kpc) and their deviation from being radial, we can measure the magnitude of the change in angular momentum caused by the asymmetry of the Milky Way's flattened disk and triaxial dark matter halo. We propose an estimator of dark halo triaxiality based on the deflection angles (the angle between the star's position and velocity vector) of HVSs on bound orbits. Our findings indicate that, in the case of a triaxial halo, the distribution of these angles is spread uniformly between 10 and 180 degrees. Future surveys with precise astrometric and wide-field measurements of the positions and velocities of HVSs will provide important constraints for the shape of the Galactic dark halo.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3514}
{"prompt": "Rephrase the abstract of an article with title 'On the freezing of variables in random constraint satisfaction problems'.   The set of solutions of random constraint satisfaction problems (zero energy groundstates of mean-field diluted spin glasses) undergoes several structural phase transitions as the amount of constraints is increased. This set first breaks down into a large number of well separated clusters. At the freezing transition, which is in general distinct from the clustering one, some variables (spins) take the same value in all solutions of a given cluster. In this paper we study the critical behavior around the freezing transition, which appears in the unfrozen phase as the divergence of the sizes of the rearrangements induced in response to the modification of a variable. The formalism is developed on generic constraint satisfaction problems and applied in particular to the random satisfiability of boolean formulas and to the coloring of random graphs. The computation is first performed in random tree ensembles, for which we underline a connection with percolation models and with the reconstruction problem of information theory. The validity of these results for the original random ensembles is then discussed in the framework of the cavity method.  ", "human_text": "  The set of solutions of random constraint satisfaction problems (zero energy groundstates of mean-field diluted spin glasses) undergoes several structural phase transitions as the amount of constraints is increased. This set first breaks down into a large number of well separated clusters. At the freezing transition, which is in general distinct from the clustering one, some variables (spins) take the same value in all solutions of a given cluster. In this paper we study the critical behavior around the freezing transition, which appears in the unfrozen phase as the divergence of the sizes of the rearrangements induced in response to the modification of a variable. The formalism is developed on generic constraint satisfaction problems and applied in particular to the random satisfiability of boolean formulas and to the coloring of random graphs. The computation is first performed in random tree ensembles, for which we underline a connection with percolation models and with the reconstruction problem of information theory. The validity of these results for the original random ensembles is then discussed in the framework of the cavity method. ", "machine_text": " This paper examines the structural modifications in the set of solutions of random constraint satisfaction problems as the amount of constraints increases. In particular, it looks at the behavior around the freezing transition, where variables take the same value in the different clusters of a given solution. This is compared with percolation models and the reconstruction problem of information theory. An analysis is done of the random tree ensembles, and then the validity of these results for the original random constraint satisfaction problem is discussed by using the cavity method.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2147}
{"prompt": "Rephrase the abstract of an article with title 'Geodesics for Efficient Creation and Propagation of Order along Ising   Spin Chains'.   Experiments in coherent nuclear and electron magnetic resonance, and optical spectroscopy correspond to control of quantum mechanical ensembles, guiding them from initial to final target states by unitary transformations. The control inputs (pulse sequences) that accomplish these unitary transformations should take as little time as possible so as to minimize the effects of relaxation and decoherence and to optimize the sensitivity of the experiments. Here we give efficient syntheses of various unitary transformations on Ising spin chains of arbitrary length. The efficient realization of the unitary transformations presented here is obtained by computing geodesics on a sphere under a special metric. We show that contrary to the conventional belief, it is possible to propagate a spin order along an Ising spin chain with coupling strength J (in units of Hz), significantly faster than 1/(2J) per step. The methods presented here are expected to be useful for immediate and future applications involving control of spin dynamics in coherent spectroscopy and quantum information processing.  ", "human_text": "  Experiments in coherent nuclear and electron magnetic resonance, and optical spectroscopy correspond to control of quantum mechanical ensembles, guiding them from initial to final target states by unitary transformations. The control inputs (pulse sequences) that accomplish these unitary transformations should take as little time as possible so as to minimize the effects of relaxation and decoherence and to optimize the sensitivity of the experiments. Here we give efficient syntheses of various unitary transformations on Ising spin chains of arbitrary length. The efficient realization of the unitary transformations presented here is obtained by computing geodesics on a sphere under a special metric. We show that contrary to the conventional belief, it is possible to propagate a spin order along an Ising spin chain with coupling strength J (in units of Hz), significantly faster than 1/(2J) per step. The methods presented here are expected to be useful for immediate and future applications involving control of spin dynamics in coherent spectroscopy and quantum information processing. ", "machine_text": " The current study looks at creating and propagating order along Ising spin chains using geodesics, affording the possibility of ultra-fast control over quantum mechanical ensembles by reducing the time it takes for unitary transformations. Results suggest that it is possible to spread a spin order along an Ising spin chain at speeds much faster than initially thought -- 1/2J Hz per step -- opening up new possibilities for controlling spin dynamics in coherent spectroscopy and quantum information processing. Experiments demonstrate the efficacy of the synthesized unitary transformations and these methods are expected to lead to further applications.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0378}
{"prompt": "Rephrase the abstract of an article with title 'Metal and molecule cooling in simulations of structure formation'.   Cooling is the main process leading to the condensation of gas in the dark matter potential wells and consequently to star and structure formation. In a metal-free environment, the main available coolants are H, He, H$_2$ and HD; once the gas is enriched with metals, these also become important in defining the cooling properties of the gas. We discuss the implementation in Gadget-2 of molecular and metal cooling at temperatures lower that $\\rm10^4 K$, following the time dependent properties of the gas and pollution from stellar evolution. We have checked the validity of our scheme comparing the results of some test runs with previous calculations of cosmic abundance evolution and structure formation, finding excellent agreement. We have also investigated the relevance of molecule and metal cooling in some specific cases, finding that inclusion of HD cooling results in a higher clumping factor of the gas at high redshifts, while metal cooling at low temperatures can have a significant impact on the formation and evolution of cold objects.  ", "human_text": "  Cooling is the main process leading to the condensation of gas in the dark matter potential wells and consequently to star and structure formation. In a metal-free environment, the main available coolants are H, He, H$_2$ and HD; once the gas is enriched with metals, these also become important in defining the cooling properties of the gas. We discuss the implementation in Gadget-2 of molecular and metal cooling at temperatures lower that $\\rm10^4 K$, following the time dependent properties of the gas and pollution from stellar evolution. We have checked the validity of our scheme comparing the results of some test runs with previous calculations of cosmic abundance evolution and structure formation, finding excellent agreement. We have also investigated the relevance of molecule and metal cooling in some specific cases, finding that inclusion of HD cooling results in a higher clumping factor of the gas at high redshifts, while metal cooling at low temperatures can have a significant impact on the formation and evolution of cold objects. ", "machine_text": " This article explores the role of metal and molecular cooling in simulations of structure formation. We present an implementation in the Gadget-2 code of cooling from these two sources at temperatures lower than 10,000 K, taking into account the processing of the gas due to stellar evolution. The results of our scheme are compared with past results from cosmic abundance evolution and structure formation, finding a strong correlation. Additionally, we investigate the effects of HD cooling on the clumping of gas at high redshifts and the impact of metal cooling on the formation and evolution of cold objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2182}
{"prompt": "Rephrase the abstract of an article with title 'Matrix Exponential-Based Closures for the Turbulent Subgrid-Scale Stress   Tensor'.   Two approaches for closing the turbulence subgrid-scale stress tensor in terms of matrix exponentials are introduced and compared. The first approach is based on a formal solution of the stress transport equation in which the production terms can be integrated exactly in terms of matrix exponentials. This formal solution of the subgrid-scale stress transport equation is shown to be useful to explore special cases, such as the response to constant velocity gradient, but neglecting pressure-strain correlations and diffusion effects. The second approach is based on an Eulerian-Lagrangian change of variables, combined with the assumption of isotropy for the conditionally averaged Lagrangian velocity gradient tensor and with the `Recent Fluid Deformation' (RFD) approximation. It is shown that both approaches lead to the same basic closure in which the stress tensor is expressed as the product of the matrix exponential of the resolved velocity gradient tensor multiplied by its transpose. Short-time expansions of the matrix exponentials are shown to provide an eddy-viscosity term and particular quadratic terms, and thus allow a reinterpretation of traditional eddy-viscosity and nonlinear stress closures. The basic feasibility of the matrix-exponential closure is illustrated by implementing it successfully in Large Eddy Simulation of forced isotropic turbulence. The matrix-exponential closure employs the drastic approximation of entirely omitting the pressure-strain correlation and other `nonlinear scrambling' terms. But unlike eddy-viscosity closures, the matrix exponential approach provides a simple and local closure that can be derived directly from the stress transport equation with the production term, and using physically motivated assumptions about Lagrangian decorrelation and upstream isotropy.  ", "human_text": "  Two approaches for closing the turbulence subgrid-scale stress tensor in terms of matrix exponentials are introduced and compared. The first approach is based on a formal solution of the stress transport equation in which the production terms can be integrated exactly in terms of matrix exponentials. This formal solution of the subgrid-scale stress transport equation is shown to be useful to explore special cases, such as the response to constant velocity gradient, but neglecting pressure-strain correlations and diffusion effects. The second approach is based on an Eulerian-Lagrangian change of variables, combined with the assumption of isotropy for the conditionally averaged Lagrangian velocity gradient tensor and with the `Recent Fluid Deformation' (RFD) approximation. It is shown that both approaches lead to the same basic closure in which the stress tensor is expressed as the product of the matrix exponential of the resolved velocity gradient tensor multiplied by its transpose. Short-time expansions of the matrix exponentials are shown to provide an eddy-viscosity term and particular quadratic terms, and thus allow a reinterpretation of traditional eddy-viscosity and nonlinear stress closures. The basic feasibility of the matrix-exponential closure is illustrated by implementing it successfully in Large Eddy Simulation of forced isotropic turbulence. The matrix-exponential closure employs the drastic approximation of entirely omitting the pressure-strain correlation and other `nonlinear scrambling' terms. But unlike eddy-viscosity closures, the matrix exponential approach provides a simple and local closure that can be derived directly from the stress transport equation with the production term, and using physically motivated assumptions about Lagrangian decorrelation and upstream isotropy. ", "machine_text": "This article presents two approaches for deriving the closure of the turbulent subgrid-scale stress tensor in terms of matrix exponentials. The first approach employs a formal solution of the stress transport equation, integrating the production terms exactly as matrix exponentials. While this method enables exploring special cases, it fails to account for pressure-strain correlations or diffusion effects. The second approach is based on an Eulerian-Lagrangian analysis, assuming isotropy of the conditionally averaged Lagrangian velocity gradient tensor and using the RFD approximation. Results for both approaches manifest as the product of the matrix exponential of the resolved velocity gradient tensor and its transpose. Short-time expansions of the matrix exponentials allow for the interpretative reexpression of traditional eddy-viscosity and nonlinear stress closures. An implementation of the matrix-exponential closure was successful in Large Eddy Simulations of forced isotropic turbulence, though this method drastically omits the pressure-strain correlation as well as other nonlinear scrambling terms. The matrix-exponential closure provides a local and physically motivated solution of the subgrid-scale stress transport equation, derived directly from its production term.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3781}
{"prompt": "Rephrase the abstract of an article with title 'Integrable systems and complex geometry'.   In this paper, we discuss an interaction between complex geometry and integrable systems. Section 1 reviews the classical results on integrable systems. New examples of integrable systems, which have been discovered, are based on the Lax representation of the equations of motion. These systems can be realized as straight line motions on a Jacobi variety of a so-called spectral curve. In section 2, we study a Lie algebra theoretical method leading to integrable systems and we apply the method to several problems. In section 3, we discuss the concept of the algebraic complete integrability (a.c.i.) of hamiltonian systems. Algebraic integrability means that the system is completely integrable in the sens of the phase space being folited by tori, which in addition are real parts of a complex algebraic tori (abelian varieties). The method is devoted to illustrate how to decide about the a.c.i. of hamiltonian systems and is applied to some examples. Finally, in section 4 we study an a.c.i. in the generalized sense which appears as covering of a.c.i. system. The manifold invariant by the complex flow is covering of abelian variety.  ", "human_text": "  In this paper, we discuss an interaction between complex geometry and integrable systems. Section 1 reviews the classical results on integrable systems. New examples of integrable systems, which have been discovered, are based on the Lax representation of the equations of motion. These systems can be realized as straight line motions on a Jacobi variety of a so-called spectral curve. In section 2, we study a Lie algebra theoretical method leading to integrable systems and we apply the method to several problems. In section 3, we discuss the concept of the algebraic complete integrability (a.c.i.) of hamiltonian systems. Algebraic integrability means that the system is completely integrable in the sens of the phase space being folited by tori, which in addition are real parts of a complex algebraic tori (abelian varieties). The method is devoted to illustrate how to decide about the a.c.i. of hamiltonian systems and is applied to some examples. Finally, in section 4 we study an a.c.i. in the generalized sense which appears as covering of a.c.i. system. The manifold invariant by the complex flow is covering of abelian variety. ", "machine_text": " This article explores the interplay between integrable systems and complex geometry. We begin by revising classical findings about integrable systems and explicating the Lax representation which describes them. Subsequently, a Lie algebra theoretical approach to integration of systems is applied to various problems. Following this, the concept of algebraic complete integrability (a.c.i.) of hamiltonian systems is discussed. Through this, it is explained how to determine the a.c.i. of a system and representative examples are presented. Lastly, a generalised a.c.i. that forms a covering of abelian varieties is analysed. The related complex flows are then examined in terms of the resulting invariant manifold.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1579}
{"prompt": "Rephrase the abstract of an article with title 'Extrasolar planet taxonomy: a new statistical approach'.   In this paper we present the guidelines for an extrasolar planet taxonomy. The discovery of an increasing number of extrasolar planets showing a vast variety of planetary parameters, like Keplerian orbital elements and environmental parameters, like stellar masses, spectral types, metallicity etc., prompts the development of a planetary taxonomy. In this work via principal component analysis followed by hierarchical clustering analysis, we report the definition of five robust groups of planets. We also discuss the physical relevance of such analysis, which may provide a valid basis for disentangling the role of the several physical parameters involved in the processes of planet formation and subsequent evolution. For instance, we were able to divide the hot Jupiters into two main groups on the basis of their stellar masses and metallicities. Moreover, for some groups, we find strong correlations between metallicity, semi-major axis and eccentricity. The implications of these findings are discussed.  ", "human_text": "  In this paper we present the guidelines for an extrasolar planet taxonomy. The discovery of an increasing number of extrasolar planets showing a vast variety of planetary parameters, like Keplerian orbital elements and environmental parameters, like stellar masses, spectral types, metallicity etc., prompts the development of a planetary taxonomy. In this work via principal component analysis followed by hierarchical clustering analysis, we report the definition of five robust groups of planets. We also discuss the physical relevance of such analysis, which may provide a valid basis for disentangling the role of the several physical parameters involved in the processes of planet formation and subsequent evolution. For instance, we were able to divide the hot Jupiters into two main groups on the basis of their stellar masses and metallicities. Moreover, for some groups, we find strong correlations between metallicity, semi-major axis and eccentricity. The implications of these findings are discussed. ", "machine_text": " This research provides a new statistical approach for classifying extrasolar planets. By utilizing principal component analysis and hierarchical clustering, we have managed to find five distinct groups of planets. We can see the importance of environmental parameters such as stellar masses and gas composition on the classification of these groups. Furthermore, we discovered strong correlations between properties such as density, semi-major axis, and eccentricity. These correlations and their effects on the formation and evolution of these planets will be discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.091}
{"prompt": "Rephrase the abstract of an article with title 'The Mira variable S Ori: Relationships between the photosphere,   molecular layer, dust shell, and SiO maser shell at 4 epochs'.   We present the first multi-epoch study that includes concurrent mid-infrared and radio interferometry of an oxygen-rich Mira star. We obtained mid-infrared interferometry of S Ori with VLTI/MIDI at four epochs between December 2004 and December 2005. We concurrently observed v=1, J=1-0 (43.1 GHz), and v=2, J=1-0 (42.8 GHz) SiO maser emission toward S Ori with the VLBA at three epochs. The MIDI data are analyzed using self-excited dynamic model atmospheres including molecular layers, complemented by a radiative transfer model of the circumstellar dust shell. The VLBA data are reduced to the spatial structure and kinematics of the maser spots. The modeling of our MIDI data results in phase-dependent continuum photospheric angular diameters between about 7.9 mas (Phase 0.55) and 9.7 mas (Phase 1.16). The dust shell can best be modeled with Al2O3 grains using phase-dependent inner boundary radii between 1.8 and 2.4 photospheric radii. The dust shell appears to be more compact with greater optical depth near visual minimum, and more extended with lower optical depth after visual maximum. The ratios of the SiO maser ring radii to the photospheric radii are between about 1.9 and 2.4. The maser spots mark the region of the molecular atmospheric layers just beyond the steepest decrease in the mid-infrared model intensity profile. Their velocity structure indicates a radial gas expansion. Al2O3 dust grains and SiO maser spots form at relatively small radii of 1.8-2.4 photospheric radii. Our results suggest increased mass loss and dust formation close to the surface near the minimum visual phase, when Al2O3 dust grains are co-located with the molecular gas and the SiO maser shells, and a more expanded dust shell after visual maximum. Silicon does not appear to be bound in dust, as our data show no sign of silicate grains.  ", "human_text": "  We present the first multi-epoch study that includes concurrent mid-infrared and radio interferometry of an oxygen-rich Mira star. We obtained mid-infrared interferometry of S Ori with VLTI/MIDI at four epochs between December 2004 and December 2005. We concurrently observed v=1, J=1-0 (43.1 GHz), and v=2, J=1-0 (42.8 GHz) SiO maser emission toward S Ori with the VLBA at three epochs. The MIDI data are analyzed using self-excited dynamic model atmospheres including molecular layers, complemented by a radiative transfer model of the circumstellar dust shell. The VLBA data are reduced to the spatial structure and kinematics of the maser spots. The modeling of our MIDI data results in phase-dependent continuum photospheric angular diameters between about 7.9 mas (Phase 0.55) and 9.7 mas (Phase 1.16). The dust shell can best be modeled with Al2O3 grains using phase-dependent inner boundary radii between 1.8 and 2.4 photospheric radii. The dust shell appears to be more compact with greater optical depth near visual minimum, and more extended with lower optical depth after visual maximum. The ratios of the SiO maser ring radii to the photospheric radii are between about 1.9 and 2.4. The maser spots mark the region of the molecular atmospheric layers just beyond the steepest decrease in the mid-infrared model intensity profile. Their velocity structure indicates a radial gas expansion. Al2O3 dust grains and SiO maser spots form at relatively small radii of 1.8-2.4 photospheric radii. Our results suggest increased mass loss and dust formation close to the surface near the minimum visual phase, when Al2O3 dust grains are co-located with the molecular gas and the SiO maser shells, and a more expanded dust shell after visual maximum. Silicon does not appear to be bound in dust, as our data show no sign of silicate grains. ", "machine_text": "This work presents a comprehensive, four-epoch study of the red giant oxygen-rich star, S Ori, employing mid-infrared interferometry with VLTI/MIDI and radio interferometry with the VLBA to measure the photospheric, molecular layer, dust shell, and SiO maser shell properties. Our results suggest a large increase in mass loss and dust formation close to the photospheric surface near the minimum visual phase, with Al2O3 dust grains co-located with the molecular gas and SiO maser shells, and a more expanded dust shell after visual maximum. While silicon appears to be mostly in a gaseous form, we find no evidence of silicate grains.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4614}
{"prompt": "Rephrase the abstract of an article with title 'The Angular-Diameter-Distance-Maximum and Its Redshift as Constraints on   $\\Lambda \\neq 0$ FLRW Models'.   The plethora of recent cosmologically relevant data has indicated that our universe is very well fit by a standard Friedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) model, with $\\Omega_{M} \\approx 0.27$ and $\\Omega_{\\Lambda} \\approx 0.73$ -- or, more generally, by nearly flat FLRW models with parameters close to these values. Additional independent cosmological information, particularly the maximum of the angular-diameter (observer-area) distance and the redshift at which it occurs, would improve and confirm these results, once sufficient precise Supernovae Ia data in the range $1.5 < z < 1.8$ become available. We obtain characteristic FLRW closed functional forms for $C = C(z)$ and $\\hat{M}_0 = \\hat{M}_0(z)$, the angular-diameter distance and the density per source counted, respectively, when $\\Lambda \\neq 0$, analogous to those we have for $\\Lambda = 0$. More importantly, we verify that for flat FLRW models $z_{max}$ -- as is already known but rarely recognized -- the redshift of $C_{max}$, the maximum of the angular-diameter-distance, uniquely gives $\\Omega_{\\Lambda}$, the amount of vacuum energy in the universe, independently of $H_0$, the Hubble parameter. For non-flat models determination of both $z_{max}$ and $C_{max}$ gives both $\\Omega_{\\Lambda}$ and $\\Omega_M$, the amount of matter in the universe, as long as we know $H_0$ independently. Finally, determination of $C_{max}$ automatically gives a very simple observational criterion for whether or not the universe is flat -- presuming that it is FLRW.  ", "human_text": "  The plethora of recent cosmologically relevant data has indicated that our universe is very well fit by a standard Friedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) model, with $\\Omega_{M} \\approx 0.27$ and $\\Omega_{\\Lambda} \\approx 0.73$ -- or, more generally, by nearly flat FLRW models with parameters close to these values. Additional independent cosmological information, particularly the maximum of the angular-diameter (observer-area) distance and the redshift at which it occurs, would improve and confirm these results, once sufficient precise Supernovae Ia data in the range $1.5 < z < 1.8$ become available. We obtain characteristic FLRW closed functional forms for $C = C(z)$ and $\\hat{M}_0 = \\hat{M}_0(z)$, the angular-diameter distance and the density per source counted, respectively, when $\\Lambda \\neq 0$, analogous to those we have for $\\Lambda = 0$. More importantly, we verify that for flat FLRW models $z_{max}$ -- as is already known but rarely recognized -- the redshift of $C_{max}$, the maximum of the angular-diameter-distance, uniquely gives $\\Omega_{\\Lambda}$, the amount of vacuum energy in the universe, independently of $H_0$, the Hubble parameter. For non-flat models determination of both $z_{max}$ and $C_{max}$ gives both $\\Omega_{\\Lambda}$ and $\\Omega_M$, the amount of matter in the universe, as long as we know $H_0$ independently. Finally, determination of $C_{max}$ automatically gives a very simple observational criterion for whether or not the universe is flat -- presuming that it is FLRW. ", "machine_text": "Recent research has investigated the universe as a Friedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) model, supported by a wealth of cosmologically significant data. This model strongly indicates a flat FLRW universe nearly equal parts matter and vacuum energy -- $\\Omega_{M} \\approx 0.27$, $\\Omega_{\\Lambda} \\approx 0.73$. While more precise data from Supernovae Ia in the range $1.5 < z < 1.8$ would support these findings, another independent cosmological metric also offers potential benefits. Determining the maximum value of the angular-diameter-distance -- its value for $\\Lambda \\neq 0$ or $\\Lambda = 0$ -- and the redshift at which this occurs has been identified as an appropriate measure. When $\\Lambda = 0$ and the FLRW model is flat, the redshift of maximum angular-diameter-distance gives a unique value for $\\Omega_{\\Lambda}$ without the need to factor in the Hubble parameter. By including the redshift, this measure can also determine values for $\\Omega_M$ and $\\Omega_{\\Lambda}$ for non-flat FLRW models provided the value for the Hubble parameter is determined independently. Ultimately, with an understanding of the maximum angular-diameter-distance and its redshift, it is possible to determine the flatness of the universe given a Friedmann-Lema\\^{i}tre-Robertson-Walker model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1846}
{"prompt": "Rephrase the abstract of an article with title 'Relativistic Effects in Extreme Mass Ratio Gravitational Wave Bursts'.   Extreme mass ratio bursts (EMRBs) have been proposed as a possible source for future space-borne gravitational wave detectors, such as the Laser Interferometer Space Antenna (LISA). These events are characterized by long-period, nearly-radial orbits of compact objects around a central massive black hole. The gravitational radiation emitted during such events consists of a short burst, corresponding to periapse passage, followed by a longer, silent interval. In this paper we investigate the impact of including relativistic corrections to the description of the compact object's trajectory via a geodesic treatment, as well as including higher-order multipole corrections in the waveform calculation. The degree to which the relativistic corrections are important depends on the EMRB's orbital parameters. We find that relativistic EMRBs (v_{max}}/c > 0.25) are not rare and actually account for approximately half of the events in our astrophysical model. The relativistic corrections tend to significantly change the waveform amplitude and phase relative to a Newtonian description, although some of this dephasing could be mimicked by parameter errors. The dephasing over several bursts could be of particular importance not only to gravitational wave detection, but also to parameter estimation, since it is highly correlated to the spin of the massive black hole. Consequently, we postulate that if a relativistic EMRB is detected, such dephasing might be used to probe the relativistic character of the massive black hole and obtain information about its spin.  ", "human_text": "  Extreme mass ratio bursts (EMRBs) have been proposed as a possible source for future space-borne gravitational wave detectors, such as the Laser Interferometer Space Antenna (LISA). These events are characterized by long-period, nearly-radial orbits of compact objects around a central massive black hole. The gravitational radiation emitted during such events consists of a short burst, corresponding to periapse passage, followed by a longer, silent interval. In this paper we investigate the impact of including relativistic corrections to the description of the compact object's trajectory via a geodesic treatment, as well as including higher-order multipole corrections in the waveform calculation. The degree to which the relativistic corrections are important depends on the EMRB's orbital parameters. We find that relativistic EMRBs (v_{max}}/c > 0.25) are not rare and actually account for approximately half of the events in our astrophysical model. The relativistic corrections tend to significantly change the waveform amplitude and phase relative to a Newtonian description, although some of this dephasing could be mimicked by parameter errors. The dephasing over several bursts could be of particular importance not only to gravitational wave detection, but also to parameter estimation, since it is highly correlated to the spin of the massive black hole. Consequently, we postulate that if a relativistic EMRB is detected, such dephasing might be used to probe the relativistic character of the massive black hole and obtain information about its spin. ", "machine_text": "This study investigates the influence of relativistic corrections when describing extreme mass ratio bursts (EMRBs) that can be observed by future space-borne gravitational wave detectors, such as the Laser Interferometer Space Antenna (LISA). We found that the relativistic effects can drastically alter the amplitude and phase of the waveforms in contrast to those of a Newtonian description. We also propose that identifying and measuring the dephasing across multiple EMRBs could be used to measure the spin of the central massive black hole, allowing us to probe its relativistic character.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2612}
{"prompt": "Rephrase the abstract of an article with title 'A novel quasi-exactly solvable spin chain with nearest-neighbors   interactions'.   In this paper we study a novel spin chain with nearest-neighbors interactions depending on the sites coordinates, which in some sense is intermediate between the Heisenberg chain and the spin chains of Haldane-Shastry type. We show that when the number of spins is sufficiently large both the density of sites and the strength of the interaction between consecutive spins follow the Gaussian law. We develop an extension of the standard freezing trick argument that enables us to exactly compute a certain number of eigenvalues and their corresponding eigenfunctions. The eigenvalues thus computed are all integers, and in fact our numerical studies evidence that these are the only integer eigenvalues of the chain under consideration. This fact suggests that this chain can be regarded as a finite-dimensional analog of the class of quasi-exactly solvable Schroedinger operators, which has been extensively studied in the last two decades. We have applied the method of moments to study some statistical properties of the chain's spectrum, showing in particular that the density of eigenvalues follows a Wigner-like law. Finally, we emphasize that, unlike the original freezing trick, the extension thereof developed in this paper can be applied to spin chains whose associated dynamical spin model is only quasi-exactly solvable.  ", "human_text": "  In this paper we study a novel spin chain with nearest-neighbors interactions depending on the sites coordinates, which in some sense is intermediate between the Heisenberg chain and the spin chains of Haldane-Shastry type. We show that when the number of spins is sufficiently large both the density of sites and the strength of the interaction between consecutive spins follow the Gaussian law. We develop an extension of the standard freezing trick argument that enables us to exactly compute a certain number of eigenvalues and their corresponding eigenfunctions. The eigenvalues thus computed are all integers, and in fact our numerical studies evidence that these are the only integer eigenvalues of the chain under consideration. This fact suggests that this chain can be regarded as a finite-dimensional analog of the class of quasi-exactly solvable Schroedinger operators, which has been extensively studied in the last two decades. We have applied the method of moments to study some statistical properties of the chain's spectrum, showing in particular that the density of eigenvalues follows a Wigner-like law. Finally, we emphasize that, unlike the original freezing trick, the extension thereof developed in this paper can be applied to spin chains whose associated dynamical spin model is only quasi-exactly solvable. ", "machine_text": "In this article, we look at a novel spin chain with nearest-neighbor interactions that falls between Heisenberg's chain and the spin chains of the Haldane-Shastry type. We demonstrate that when the number of spins is large enough, the locations of the sites and the interaction strengths can follow a Gaussian distribution. We introduce an advanced version of the freezing trick technique which helps us to precisely ascertain an array of eigenvalues and connected eigenfunctions. This is remarkable since the resultant eigenvalues are integers, hinting at the possibility of this chain being a finite-dimensional variant of the quasi-exactly solvable Schroedinger operators. Furthermore, we apply the method of moments to learn some of the statistical properties of the chain's spectrum, particularly showing that the eigenvalues follow a Wigner-type law. Finally, we emphasize that different from the original freezing trick, the improved approach developed here can be applied to spin chains whose dynamics only offer a quasi-exact solvability.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3046}
{"prompt": "Rephrase the abstract of an article with title 'Very High Energy Gamma-ray Radiation from the Stellar-mass Black Hole   Cygnus X-1'.   We report on the results from the observations in very high energy band (VHE, E_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The observations were performed with the MAGIC telescope, for a total of 40 hours during 26 nights, spanning the period between June and November 2006. Searches for steady gamma-ray signals yielded no positive result and upper limits to the integral flux ranging between 1 and 2% of the Crab nebula flux, depending on the energy, have been established. We also analyzed each observation night independently, obtaining evidence of gamma-ray signals at the 4.0 standard deviations (sigma) significance level (3.2 sigma after trial correction) for 154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41 UTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search for faster-varying signals within a night resulted in an excess with a significance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT between 22h17 and 23h41 UTC. The measured excess is compatible with a point-like source at the position of Cygnus X-1, and excludes the nearby radio nebula powered by its relativistic jet. The differential energy spectrum is well fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x 10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of VHE emission from a stellar-mass black hole, and therefore from a confirmed accreting X-ray binary.  ", "human_text": "  We report on the results from the observations in very high energy band (VHE, E_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The observations were performed with the MAGIC telescope, for a total of 40 hours during 26 nights, spanning the period between June and November 2006. Searches for steady gamma-ray signals yielded no positive result and upper limits to the integral flux ranging between 1 and 2% of the Crab nebula flux, depending on the energy, have been established. We also analyzed each observation night independently, obtaining evidence of gamma-ray signals at the 4.0 standard deviations (sigma) significance level (3.2 sigma after trial correction) for 154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41 UTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search for faster-varying signals within a night resulted in an excess with a significance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT between 22h17 and 23h41 UTC. The measured excess is compatible with a point-like source at the position of Cygnus X-1, and excludes the nearby radio nebula powered by its relativistic jet. The differential energy spectrum is well fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x 10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of VHE emission from a stellar-mass black hole, and therefore from a confirmed accreting X-ray binary. ", "machine_text": " In this paper, we present the results of the observations of the stellar-mass black hole Cygnus X-1 in the very high energy (VHE, E_gamma > 100 GeV) gamma-ray band. The observations were conducted with the MAGIC telescope over 26 nights between June and November 2006 for a total of 40 hours. Although overall no significant gamma-ray signals were identified, a 4.0 standard deviations (sigma) significance level (3.2 sigma after trial correction) for 154 minutes effective on-time (EOT) was observed on September 24th between 20h58 and 23h41 UTC, coinciding with an X-ray flare documented by RXTE, Swift and INTEGRAL. Furthermore, 79 minutes EOT during this period provided excess with a significance of 4.9 sigma (4.1 sigma after trial correction). The measured excess matches a point-like source at the position of Cygnus X-1, indicating a potential emission of VHE radiation from this stellar-mass black hole system. The differential energy spectrum agrees with an unbroken power-law with a rate of dN/(dA dt dE) = (2.3+- 0.6) x 10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. These findings provide the first evidence of VHE gamma-rays from a confirmed accreting X-ray binary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1505}
{"prompt": "Rephrase the abstract of an article with title 'Detailed Spectral Analysis of the Type Ib Supernova 1999dn. Paper I:   Hydrogen-free Models'.   We present spectral fits to five epochs of the typical Type Ib supernova 1999dn using the generalized, non-LTE, stellar atmospheres code PHOENIX. Our goal is threefold: to determine basic physical properties of the supernova ejecta, such as velocity, temperature, and density gradients; to reproduce He I absorption lines by invoking non-thermal excitation; and, to investigate possible spectral signatures of hydrogen, especially a feature around 6200 Angstrom, which has been attributed to high velocity $H_\\alpha$. Our models assume an atmosphere with uniform composition devoid of any hydrogen. Our model spectra fit the observed spectra well, successfully reproducing most of the features, including the prominent He I absorptions. The most plausible alternative to $H_\\alpha$ as the source of the 6200 Angstrom feature is a blend of Fe II and Si II lines, which can be made stronger to fit the observed feature better by increasing the metallicity of the ejecta. High-metallicity models fit well at early epochs, but not as well as solar-metallicity models after maximum light. While this blend of metal lines is a reasonable explanation of the source of the 6200 Angstrom feature, it is still important to investigate hydrogen as the source; therefore, a second paper will present models that include a thin shell of hydrogen around the main composition structure.  ", "human_text": "  We present spectral fits to five epochs of the typical Type Ib supernova 1999dn using the generalized, non-LTE, stellar atmospheres code PHOENIX. Our goal is threefold: to determine basic physical properties of the supernova ejecta, such as velocity, temperature, and density gradients; to reproduce He I absorption lines by invoking non-thermal excitation; and, to investigate possible spectral signatures of hydrogen, especially a feature around 6200 Angstrom, which has been attributed to high velocity $H_\\alpha$. Our models assume an atmosphere with uniform composition devoid of any hydrogen. Our model spectra fit the observed spectra well, successfully reproducing most of the features, including the prominent He I absorptions. The most plausible alternative to $H_\\alpha$ as the source of the 6200 Angstrom feature is a blend of Fe II and Si II lines, which can be made stronger to fit the observed feature better by increasing the metallicity of the ejecta. High-metallicity models fit well at early epochs, but not as well as solar-metallicity models after maximum light. While this blend of metal lines is a reasonable explanation of the source of the 6200 Angstrom feature, it is still important to investigate hydrogen as the source; therefore, a second paper will present models that include a thin shell of hydrogen around the main composition structure. ", "machine_text": " We present the analysis of the Type Ib supernova 1999dn in five epochs through non-LTE stellar atmosphere spectra based on PHOENIX. The objective of this study is threefold: to compute the ejecta physical parameters such as temperature, density, and velocity; to reproduce the He I absorption lines by non-thermal excitation; and to explore the possible presence of hydrogen, primarily through a feature around 6200 Angstrom that has been attributed to high velocity H$_\\alpha$. All models have a uniform composition with no hydrogen. The results show our models fit the observations, accurately reproducing most of the features including He I absorptions. We consider the combination of Fe II and Si II lines as a stronger substitute for H$_\\alpha$ as a source for the 6200 Angstrom feature, which we can achieve by increasing the metallicity viewpoint. High metallicity models match early epochs, though not as optimal than solar metallicity models after the maximum brightness is attained. In addition, a further investigation of hydrogen as a potential source of the 6200 Angstrom feature will be addressed in our second paper with models involving a thin shell of hydrogen surrounding the main composition.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4086}
{"prompt": "Rephrase the abstract of an article with title 'Impact of Ion Clearing Electrodes on Beam Dynamics in DAFNE'.   Presently clearing electrodes are being considered as a possible cure of e-cloud driven problems in existing and future colliders. 'Invisible' electrodes, made of a thin highly resistive layer pasted on a dielectric plate, have been proposed as one of design solutions for the e-cloud clearing. For the first time such electrodes were successfully used in the electron-positron accumulator (EPA) of LEP. Similar electrodes had been using for a long time for ion clearing purposes in the DAFNE electron ring. Theoretical considerations and experimental measurements at DAFNE have revealed a substantial contribution of the ion clearing electrodes (ICE) to the machine broad-band impedance giving rise to several harmful effects degrading the collider performance. In this paper we discuss the impact of the electrodes on DAFNE beam dynamics, show the results of ICE wake field and impedance calculations and compare them with available experimental data. We also describe the procedure of ICE removal from the wiggler sections of the electron ring that has resulted in remarkable improvements in terms of beam dynamics and geometric luminosity.  ", "human_text": "  Presently clearing electrodes are being considered as a possible cure of e-cloud driven problems in existing and future colliders. 'Invisible' electrodes, made of a thin highly resistive layer pasted on a dielectric plate, have been proposed as one of design solutions for the e-cloud clearing. For the first time such electrodes were successfully used in the electron-positron accumulator (EPA) of LEP. Similar electrodes had been using for a long time for ion clearing purposes in the DAFNE electron ring. Theoretical considerations and experimental measurements at DAFNE have revealed a substantial contribution of the ion clearing electrodes (ICE) to the machine broad-band impedance giving rise to several harmful effects degrading the collider performance. In this paper we discuss the impact of the electrodes on DAFNE beam dynamics, show the results of ICE wake field and impedance calculations and compare them with available experimental data. We also describe the procedure of ICE removal from the wiggler sections of the electron ring that has resulted in remarkable improvements in terms of beam dynamics and geometric luminosity. ", "machine_text": "This paper examines the effect of the ion clearing electrodes in the DAFNE electron ring. We analyze the theoretical models and the experimental data concerning the contribution of ICE to the machine broad-band impedance. We observe that these electrodes lead to several negative consequences for the overall performance of the collider. We report on our investigation of the ICE wake field and impedance calculations, as well as on the effects of the ICE removal from the electron's wiggler sections. This resulted in an improvement of the beam dynamics, luminosity and overall performance of the collider.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1223}
{"prompt": "Rephrase the abstract of an article with title 'Room temperature spin polarized magnetic semiconductor'.   Alternating layers of granular Iron (Fe) and Titanium dioxide (TiO$_{2-\\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$) substrates in low oxygen chamber pressure using a controlled pulsed laser ablation deposition technique. The total thickness of the film was about 200 nm. The films show ferromagnetic behavior for temperatures ranging from 4 to $400 ^oK$. The layered film structure was characterized as p-type magnetic semiconductor at $300 ^oK$ with a carrier density of the order of $10^{20} /cm^3$. The undoped pure TiO$_{2-\\delta}$ film was characterized as an n-type magnetic semiconductor. The hole carriers were excited at the interface between the granular Fe and TiO$_{2-\\delta}$ layers similar to holes excited in the metal/n-type semiconductor interface commonly observed in Metal-Oxide-Semiconductor (MOS) devices. The holes at the interface were polarized in an applied magnetic field raising the possibility that these granular MOS structures can be utilized for practical spintronic device applications.  ", "human_text": "  Alternating layers of granular Iron (Fe) and Titanium dioxide (TiO$_{2-\\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$) substrates in low oxygen chamber pressure using a controlled pulsed laser ablation deposition technique. The total thickness of the film was about 200 nm. The films show ferromagnetic behavior for temperatures ranging from 4 to $400 ^oK$. The layered film structure was characterized as p-type magnetic semiconductor at $300 ^oK$ with a carrier density of the order of $10^{20} /cm^3$. The undoped pure TiO$_{2-\\delta}$ film was characterized as an n-type magnetic semiconductor. The hole carriers were excited at the interface between the granular Fe and TiO$_{2-\\delta}$ layers similar to holes excited in the metal/n-type semiconductor interface commonly observed in Metal-Oxide-Semiconductor (MOS) devices. The holes at the interface were polarized in an applied magnetic field raising the possibility that these granular MOS structures can be utilized for practical spintronic device applications. ", "machine_text": " This paper details a method of pulsed laser ablation deposition utilized to construct an alternating layer thickness of granular Iron and Titanium dioxide on a Lanthanum aluminate substrate, yielding a total thickness of approximately 200 nm. Upon analysis, the composed film structure was classified as a p-type magnetic semiconductor at 300 K, demonstrating ferromagnetic behaviour from 4 to 400 K, and with a carrier density of 10$^{20}$/cm$^3$. The undoped Titanium dioxide film showed characteristics of an n-type magnetic semiconductor. The holes present at the interface between the Iron and Titanium dioxide layers reacted to an applied magnetic field, implying the potential for spintronic applications.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2993}
{"prompt": "Rephrase the abstract of an article with title 'Dimer Models, Free Fermions and Super Quantum Mechanics'.   This note relates topics in statistical mechanics, graph theory and combinatorics, lattice quantum field theory, super quantum mechanics and string theory. We give a precise relation between the dimer model on a graph embedded on a torus and the massless free Majorana fermion living on the same lattice. A loop expansion of the fermion determinant is performed, where the loops turn out to be compositions of two perfect matchings. These loop states are sorted into co-chain groups using categorification techniques similar to the ones used for categorifying knot polynomials. The Euler characteristic of the resulting co-chain complex recovers the Newton polynomial of the dimer model. We re-interpret this system as supersymmetric quantum mechanics, where configurations with vanishing net winding number form the ground states. Finally, we make use of the quiver gauge theory - dimer model correspondence to obtain an interpretation of the loops in terms of the physics of D-branes probing a toric Calabi-Yau singularity.  ", "human_text": "  This note relates topics in statistical mechanics, graph theory and combinatorics, lattice quantum field theory, super quantum mechanics and string theory. We give a precise relation between the dimer model on a graph embedded on a torus and the massless free Majorana fermion living on the same lattice. A loop expansion of the fermion determinant is performed, where the loops turn out to be compositions of two perfect matchings. These loop states are sorted into co-chain groups using categorification techniques similar to the ones used for categorifying knot polynomials. The Euler characteristic of the resulting co-chain complex recovers the Newton polynomial of the dimer model. We re-interpret this system as supersymmetric quantum mechanics, where configurations with vanishing net winding number form the ground states. Finally, we make use of the quiver gauge theory - dimer model correspondence to obtain an interpretation of the loops in terms of the physics of D-branes probing a toric Calabi-Yau singularity. ", "machine_text": " This article examines the overlapping intersections between statistical mechanics, graph theory and combinatorics, lattice quantum field theory, super quantum mechanics and string theory. Using the dimer model on a graph embedded on a torus and the massless, free Majorana fermion living on the same lattice, a loop expansion of the fermion determinant is determined. The loops are then classified into co-chain groups through categorification, with the Euler characteristic of the resulting co-chain complex being identical to the Newton polynomial of the dimer model. Exploring the same system further, configuration with vanishing net winding number were found to form the ground states suggesting a connection to supersymmetric quantum mechanics. With the use of the quiver gauge theory - dimer model correspondence, furthermore, this article reveals how the loops are in fact related to the physics of the D-branes probing a toric Calabi-Yau singularity.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1645}
{"prompt": "Rephrase the abstract of an article with title 'Diversity-Multiplexing Tradeoff via Asymptotic Analysis of Large MIMO   Systems'.   Diversity-multiplexing tradeoff (DMT) presents a compact framework to compare various MIMO systems and channels in terms of the two main advantages they provide (i.e. high data rate and/or low error rate). This tradeoff was characterized asymptotically (SNR-> infinity) for i.i.d. Rayleigh fading channel by Zheng and Tse [1]. The asymptotic DMT overestimates the finite-SNR one [2]. In this paper, using the recent results on the asymptotic (in the number of antennas) outage capacity distribution, we derive and analyze the finite-SNR DMT for a broad class of channels (not necessarily Rayleigh fading). Based on this, we give the convergence conditions for the asymptotic DMT to be approached by the finite-SNR one. The multiplexing gain definition is shown to affect critically the convergence point: when the multiplexing gain is defined via the mean (ergodic) capacity, the convergence takes place at realistic SNR values. Furthermore, in this case the diversity gain can also be used to estimate the outage probability with reasonable accuracy. The multiplexing gain definition via the high-SNR asymptote of the mean capacity (as in [1]) results in very slow convergence for moderate to large systems (as 1/ln(SNR)^2) and, hence, the asymptotic DMT cannot be used at realistic SNR values. For this definition, the high-SNR threshold increases exponentially in the number of antennas and in the multiplexing gain. For correlated keyhole channel, the diversity gain is shown to decrease with correlation and power imbalance of the channel. While the SNR-asymptotic DMT of Zheng and Tse does not capture this effect, the size-asymptotic DMT does.  ", "human_text": "  Diversity-multiplexing tradeoff (DMT) presents a compact framework to compare various MIMO systems and channels in terms of the two main advantages they provide (i.e. high data rate and/or low error rate). This tradeoff was characterized asymptotically (SNR-> infinity) for i.i.d. Rayleigh fading channel by Zheng and Tse [1]. The asymptotic DMT overestimates the finite-SNR one [2]. In this paper, using the recent results on the asymptotic (in the number of antennas) outage capacity distribution, we derive and analyze the finite-SNR DMT for a broad class of channels (not necessarily Rayleigh fading). Based on this, we give the convergence conditions for the asymptotic DMT to be approached by the finite-SNR one. The multiplexing gain definition is shown to affect critically the convergence point: when the multiplexing gain is defined via the mean (ergodic) capacity, the convergence takes place at realistic SNR values. Furthermore, in this case the diversity gain can also be used to estimate the outage probability with reasonable accuracy. The multiplexing gain definition via the high-SNR asymptote of the mean capacity (as in [1]) results in very slow convergence for moderate to large systems (as 1/ln(SNR)^2) and, hence, the asymptotic DMT cannot be used at realistic SNR values. For this definition, the high-SNR threshold increases exponentially in the number of antennas and in the multiplexing gain. For correlated keyhole channel, the diversity gain is shown to decrease with correlation and power imbalance of the channel. While the SNR-asymptotic DMT of Zheng and Tse does not capture this effect, the size-asymptotic DMT does. ", "machine_text": " The tradeoff between data rate and error rate is encapsulated in the concept of diversity-multiplexing tradeoff (DMT). While this tradeoff has been characterized asymptotically (in SNR) for Independent and Identically Distributed (i.i.d.) Rayleigh fading channel by Zheng and Tse [1], this paper makes an effort to extend the asymptotic analysis to a broad class of channels, including those which are not necessarily Rayleigh fading. Using the existing results of the asymptotic outage capacity distributions,this paper explores the finite SNR DMT which is expected to be a more accurate representation than its asymptotic counterpart. Moreover, the definition of multiplexing gain affects the speed of convergence of the finite SNR DMT to its asymptotic version. The outline of conditions under which the asymptotic DMT converges to the finite SNR one are especially useful when the multiplexing gain is defined via the mean (ergodic) capacity, converging at feasible SNR values. Furthermore, this paper highlights the effects of scenarios such as correlation and power imbalance, which are expected to reduce the diversity gain for correlated keyhole channels. All these scenarios are not captured by the SNR-asymptotic DMT of Zheng and Tse but are elucidated by the size-asymptotic DMT.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1336}
{"prompt": "Rephrase the abstract of an article with title 'Super Star Cluster NGC1705-1: A Local Analogue to the Birthsite of   Long-duration Gamma-ray Bursts'.   Recent observations suggest that global properties of the host galaxies for long-duration gamma-ray bursts (GRBs) are particularly well-suited for creating the massive star progenitors of these GRBs. Motivated by the hypothesis that massive young star clusters located in metal-poor, low-metallicity galaxies are a natural birthsite for GRB progenitors, we present a comparison study of the ISM properties along the sightline toward the super star cluster, NGC1705-1, and those in distant GRB hosts. Using the same set of metal transitions in the UV and applying known ISM structures in NGC1705, we find that NGC1705-1 resembles distant GRB host galaxies in its high neutral gas column, low molecular gas fraction, low metallicity, alpha-element enhancement,and low dust depletion. The lack of molecular gas is due to the enhanced UV radiation field in the starburst environment, consistent with the expectations for GRB progenitors. In addition, the known presence of dense neutral gas clouds at r<500 pc from NGC1705-1 provides a natural reservoir of C^+, Si^+, and Fe^+ ions that may be subsequently excited by the afterglow UV radiation field to produce excited lines commonly seen in GRB host ISM. We further argue that the apparent offset in the velocity profiles of low- and high-ionization transitions from absorption-line observations alone already offers important clues for related starburst episodes in GRB host galaxies. Our study shows that a statistical comparison between the ISM around star clusters and high-redshift GRB progenitors is important for identifying the key physical parameters that facilitate the formation of GRBs.  ", "human_text": "  Recent observations suggest that global properties of the host galaxies for long-duration gamma-ray bursts (GRBs) are particularly well-suited for creating the massive star progenitors of these GRBs. Motivated by the hypothesis that massive young star clusters located in metal-poor, low-metallicity galaxies are a natural birthsite for GRB progenitors, we present a comparison study of the ISM properties along the sightline toward the super star cluster, NGC1705-1, and those in distant GRB hosts. Using the same set of metal transitions in the UV and applying known ISM structures in NGC1705, we find that NGC1705-1 resembles distant GRB host galaxies in its high neutral gas column, low molecular gas fraction, low metallicity, alpha-element enhancement,and low dust depletion. The lack of molecular gas is due to the enhanced UV radiation field in the starburst environment, consistent with the expectations for GRB progenitors. In addition, the known presence of dense neutral gas clouds at r<500 pc from NGC1705-1 provides a natural reservoir of C^+, Si^+, and Fe^+ ions that may be subsequently excited by the afterglow UV radiation field to produce excited lines commonly seen in GRB host ISM. We further argue that the apparent offset in the velocity profiles of low- and high-ionization transitions from absorption-line observations alone already offers important clues for related starburst episodes in GRB host galaxies. Our study shows that a statistical comparison between the ISM around star clusters and high-redshift GRB progenitors is important for identifying the key physical parameters that facilitate the formation of GRBs. ", "machine_text": " Recent findings demonstrate that the galaxies which host long-duration gamma-ray bursts (GRBs) are highly suitable for the formation of massive stars which give rise to the GRBs. To find out how well the interstellar medium (ISM) characteristics along the line of sight of the Super Star Cluster, NGC1705-1, aligns with that of distant GRB hosts, we conducted a comparison study. We looked at the same set of metal transitions in the UV and used related ISM structures in NGC1705-1. We noted that the UV radiation field in the starburst environment is the cause of lack of molecular gas and the other ISM traits in NGC1705-1 resemble that of distant GRB hosts with high neutral gas column, low molecular gas fraction, low metallicity, alpha-element enhancement as well as low dust depletion. Furthermore, we concurred that the afterglow UV radiation from the GRB excites C^+, Si^+ and Fe^+ ions in the neutral gas clouds located at a distance of 500 pc from NGC1705-1, producing excited lines commonly observed in GRB host ISM. We concluded that a comparative assessment of star clusters and high-redshift GRB progenitors is a promising method to identify the eminent physical properties essential to the GRB\u2019s emergence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2364}
{"prompt": "Rephrase the abstract of an article with title 'Dark Energy and Gravity'.   I review the problem of dark energy focusing on the cosmological constant as the candidate and discuss its implications for the nature of gravity. Part 1 briefly overviews the currently popular `concordance cosmology' and summarises the evidence for dark energy. It also provides the observational and theoretical arguments in favour of the cosmological constant as the candidate and emphasises why no other approach really solves the conceptual problems usually attributed to the cosmological constant. Part 2 describes some of the approaches to understand the nature of the cosmological constant and attempts to extract the key ingredients which must be present in any viable solution. I argue that (i)the cosmological constant problem cannot be satisfactorily solved until gravitational action is made invariant under the shift of the matter lagrangian by a constant and (ii) this cannot happen if the metric is the dynamical variable. Hence the cosmological constant problem essentially has to do with our (mis)understanding of the nature of gravity. Part 3 discusses an alternative perspective on gravity in which the action is explicitly invariant under the above transformation. Extremizing this action leads to an equation determining the background geometry which gives Einstein's theory at the lowest order with Lanczos-Lovelock type corrections. (Condensed abstract).  ", "human_text": "  I review the problem of dark energy focusing on the cosmological constant as the candidate and discuss its implications for the nature of gravity. Part 1 briefly overviews the currently popular `concordance cosmology' and summarises the evidence for dark energy. It also provides the observational and theoretical arguments in favour of the cosmological constant as the candidate and emphasises why no other approach really solves the conceptual problems usually attributed to the cosmological constant. Part 2 describes some of the approaches to understand the nature of the cosmological constant and attempts to extract the key ingredients which must be present in any viable solution. I argue that (i)the cosmological constant problem cannot be satisfactorily solved until gravitational action is made invariant under the shift of the matter lagrangian by a constant and (ii) this cannot happen if the metric is the dynamical variable. Hence the cosmological constant problem essentially has to do with our (mis)understanding of the nature of gravity. Part 3 discusses an alternative perspective on gravity in which the action is explicitly invariant under the above transformation. Extremizing this action leads to an equation determining the background geometry which gives Einstein's theory at the lowest order with Lanczos-Lovelock type corrections. (Condensed abstract). ", "machine_text": " This article reviews the problem of dark energy and its implications for the nature of gravity, with the cosmological constant as the leading candidate. We first explore the concordance cosmology, and review the evidence for dark energy as well as the theoretical and observational arguments in favor of the cosmological constant. We then outline some possible approaches towards understanding the nature of the cosmological constant and extracting the key ingredients that must be incorporated in a viable solution. Finally, we discuss an alternative perspective on gravity in which the action is efficiently invariant under the shift of the matter lagrangian. This leads to a background equation. Evaluating this equation leads to Einstein's theory at the lowest order, with Lanczos-Lovelock type corrections.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2533}
{"prompt": "Rephrase the abstract of an article with title 'A Close Look at Star Formation around Active Galactic Nuclei'.   We analyse star formation in the nuclei of 9 Seyfert galaxies at spatial resolutions down to 0.085arcsec, corresponding to length scales of less than 10pc in some objects. Our data were taken mostly with the near infrared adaptive optics integral field spectrograph SINFONI. The stellar light profiles typically have size scales of a few tens of parsecs. In two cases there is unambiguous kinematic evidence for stellar disks on these scales. In the nuclear regions there appear to have been recent - but no longer active - starbursts in the last 10-300Myr. The stellar luminosity is less than a few percent of the AGN in the central 10pc, whereas on kiloparsec scales the luminosities are comparable. The surface stellar luminosity density follows a similar trend in all the objects, increasing steadily at smaller radii up to 10^{13}L_sun/kpc^2 in the central few parsecs, where the mass surface density exceeds 10^4M_sun/pc^2. The intense starbursts were probably Eddington limited and hence inevitably short-lived, implying that the starbursts occur in multiple short bursts. The data hint at a delay of 50--100Myr between the onset of star formation and subsequent fuelling of the black hole. We discuss whether this may be a consequence of the role that stellar ejecta could play in fuelling the black hole. While a significant mass is ejected by OB winds and supernovae, their high velocity means that very little of it can be accreted. On the other hand winds from AGB stars ultimately dominate the total mass loss, and they can also be accreted very efficiently because of their slow speeds.  ", "human_text": "  We analyse star formation in the nuclei of 9 Seyfert galaxies at spatial resolutions down to 0.085arcsec, corresponding to length scales of less than 10pc in some objects. Our data were taken mostly with the near infrared adaptive optics integral field spectrograph SINFONI. The stellar light profiles typically have size scales of a few tens of parsecs. In two cases there is unambiguous kinematic evidence for stellar disks on these scales. In the nuclear regions there appear to have been recent - but no longer active - starbursts in the last 10-300Myr. The stellar luminosity is less than a few percent of the AGN in the central 10pc, whereas on kiloparsec scales the luminosities are comparable. The surface stellar luminosity density follows a similar trend in all the objects, increasing steadily at smaller radii up to 10^{13}L_sun/kpc^2 in the central few parsecs, where the mass surface density exceeds 10^4M_sun/pc^2. The intense starbursts were probably Eddington limited and hence inevitably short-lived, implying that the starbursts occur in multiple short bursts. The data hint at a delay of 50--100Myr between the onset of star formation and subsequent fuelling of the black hole. We discuss whether this may be a consequence of the role that stellar ejecta could play in fuelling the black hole. While a significant mass is ejected by OB winds and supernovae, their high velocity means that very little of it can be accreted. On the other hand winds from AGB stars ultimately dominate the total mass loss, and they can also be accreted very efficiently because of their slow speeds. ", "machine_text": " We have conducted an extensive study of star formation around Active Galactic Nuclei with data taken from the near infrared adaptive optics integral field spectrograph SINFONI. Our results show stellar light profiles of a few tens of parsecs with evidence for recent but inactive starbursts 10-300 million years ago. The stellar luminosity in the central 10pc is much lower than the AGN, but comparable on larger scales. Our analysis reveals a steadily increasing surface stellar luminosity density of up to 10^13L_sun/kpc^2 in the central few parsecs and a mass surface density of 10^4M_sun/pc^2. We postulate that the starbursts were likely Eddington limited and hence had relatively short lifespans, with a possible delay of 50-100 million years between the onset of star formation and subsequent fuelling of the black hole. The role of stellar ejecta in this process is discussed, suggesting that while a significant mass is ejected from OB winds and supernovae, AGB stars provide the largest mass loss at a slow enough speed to be accreted efficiently.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1374}
{"prompt": "Rephrase the abstract of an article with title 'Daemons and DAMA: Their Celestial-Mechanics Interrelations'.   The assumption of the capture by the Solar System of the electrically charged Planckian DM objects (daemons) from the galactic disk is confirmed not only by the St.Petersburg (SPb) experiments detecting particles with V<30 km/s. Here the daemon approach is analyzed considering the positive model independent result of the DAMA/NaI experiment. We explain the maximum in DAMA signals observed in the May-June period to be associated with the formation behind the Sun of a trail of daemons that the Sun captures into elongated orbits as it moves to the apex. The range of significant 2-6-keV DAMA signals fits well the iodine nuclei elastically knocked out of the NaI(Tl) scintillator by particles falling on the Earth with V=30-50 km/s from strongly elongated heliocentric orbits. The half-year periodicity of the slower daemons observed in SPb originates from the transfer of particles that are deflected through ~90 deg into near-Earth orbits each time the particles cross the outer reaches of the Sun which had captured them. Their multi-loop (cross-like) trajectories traverse many times the Earth's orbit in March and September, which increases the probability for the particles to enter near-Earth orbits during this time. Corroboration of celestial mechanics calculations with observations yields ~1e-19 cm2 for the cross section of daemon interaction with the solar matter.  ", "human_text": "  The assumption of the capture by the Solar System of the electrically charged Planckian DM objects (daemons) from the galactic disk is confirmed not only by the St.Petersburg (SPb) experiments detecting particles with V<30 km/s. Here the daemon approach is analyzed considering the positive model independent result of the DAMA/NaI experiment. We explain the maximum in DAMA signals observed in the May-June period to be associated with the formation behind the Sun of a trail of daemons that the Sun captures into elongated orbits as it moves to the apex. The range of significant 2-6-keV DAMA signals fits well the iodine nuclei elastically knocked out of the NaI(Tl) scintillator by particles falling on the Earth with V=30-50 km/s from strongly elongated heliocentric orbits. The half-year periodicity of the slower daemons observed in SPb originates from the transfer of particles that are deflected through ~90 deg into near-Earth orbits each time the particles cross the outer reaches of the Sun which had captured them. Their multi-loop (cross-like) trajectories traverse many times the Earth's orbit in March and September, which increases the probability for the particles to enter near-Earth orbits during this time. Corroboration of celestial mechanics calculations with observations yields ~1e-19 cm2 for the cross section of daemon interaction with the solar matter. ", "machine_text": "This article discusses the relationship between daemons and celestial mechanics as it pertains to the DAMA/NaI experiment which observed the maximum signal in the May-June period. It suggests that this maximum is caused by a trail of daemons that become elongated orbits as the Sun moves, falling on the Earth with a velocity of 30-50 km/s. These daemons are observed in the St. Petersburg experiment and their half-year periodicity is caused by their crossing of the outer reaches of the Sun which capture them. Consequently, celestial mechanics calculations corroborated with observations have produced a cross-section of daemon interaction with the solar matter to be ~1e-19 cm2.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0982}
{"prompt": "Rephrase the abstract of an article with title 'Electronic structure of barium titanate : an abinitio DFT study'.   First principle calculations were performed to study the ground state electronic properties of Barium titanate within the density functional theory (DFT). In our DFT computations, we used Vosko-Wilk-Nusair correlation energy functional and generalized gradient approximation (GGA) exchange and correlation energy functional as suggested by Perdew and Wang (PWGGA). The band structure, total density of states (DOS) and partial DOS have been systematically conducted to investigate the electronic configuration of this prototype ferroelectric perovskits compound. The band gap was 1.92 eV within our approach, and the quasi-flat band at -17 eV and -10 eV were attributed to the O 2s and Ba 5p states respectively, which was in good agreement with the corresponding total DOS and partial DOS. From the DOS investigation, it can be seen that the Ti eg state intended to interact with the oxygen octahedral orbitals to form the p-d hybridization. Moreover the strong p-d overlap and bonding can be observed in the electronic density redistribution along the different crystalline planes with respect to the corresponding space group, and the electronic isodense have been shown along the (001), (100), (110) and (111) crystal planes. From these electronic density maps, the strong bonding between Ti and O atoms can even be observed in the (111) crystalline plane.  ", "human_text": "  First principle calculations were performed to study the ground state electronic properties of Barium titanate within the density functional theory (DFT). In our DFT computations, we used Vosko-Wilk-Nusair correlation energy functional and generalized gradient approximation (GGA) exchange and correlation energy functional as suggested by Perdew and Wang (PWGGA). The band structure, total density of states (DOS) and partial DOS have been systematically conducted to investigate the electronic configuration of this prototype ferroelectric perovskits compound. The band gap was 1.92 eV within our approach, and the quasi-flat band at -17 eV and -10 eV were attributed to the O 2s and Ba 5p states respectively, which was in good agreement with the corresponding total DOS and partial DOS. From the DOS investigation, it can be seen that the Ti eg state intended to interact with the oxygen octahedral orbitals to form the p-d hybridization. Moreover the strong p-d overlap and bonding can be observed in the electronic density redistribution along the different crystalline planes with respect to the corresponding space group, and the electronic isodense have been shown along the (001), (100), (110) and (111) crystal planes. From these electronic density maps, the strong bonding between Ti and O atoms can even be observed in the (111) crystalline plane. ", "machine_text": " A theoretical density functional theory study was conducted to gain further insights into the electronic configuration of Barium titanate. The Vosko-Wilk-Nusair correlation energy functional combined with a generalized gradient approximation (GGA) exchange and correlation energy functional was used for the computations. The results obtained showed a band gap of 1.92 eV, along with quasi-flat bands at -17 eV and -10 eV due to the O 2s and Ba 5p states, respectively. Further, a p-d hybridization between Ti eg and oxygen octahedral orbitals was observed from the total density of states (DOS) and partial DOS analysis. Additionally, the electronic density redistribution along the different crystalline planes was used to show strong p-d overlap and bonding, and even strong bonding between the Ti and O atoms in the (111) crystalline plane was observed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2695}
{"prompt": "Rephrase the abstract of an article with title 'X-ray source counts in the COSMOS field'.   We present the analysis of the source counts in the XMM-COSMOS survey using data of the first year of XMM-Newton observations. The survey covers ~2 deg^2 within the region of sky bounded by 9^h57.5^m<R.A.<10^h03.5^m; 1^d27.5^m<DEC<2^d57.5^m with a total net integration time of 504 ks. Using a maximum likelihood algorithm we detected a total of 1390 sources at least in one band. Using Monte Carlo simulations to estimate the sky coverage we produced the logN-logS relations. These relations have been then derived in the 0.5--2 keV, 2--10 keV and 5--10 keV energy bands, down to flux limits of 7.2x10^-16 erg cm^-2 s^-1, 4.0x10^-15 erg cm^-2 s^-1 and 9.7x10^-15 erg cm^-2 s^-1, respectively. These relations have been compared to previous X-ray survey and to the most recent X-ray background model finding an excellent agreement. The slightly different normalizations observed in the source counts of COSMOS and previous surveys can be largely explained as a combination of low counting statistics and cosmic variance introduced by the large scale structure.  ", "human_text": "  We present the analysis of the source counts in the XMM-COSMOS survey using data of the first year of XMM-Newton observations. The survey covers ~2 deg^2 within the region of sky bounded by 9^h57.5^m<R.A.<10^h03.5^m; 1^d27.5^m<DEC<2^d57.5^m with a total net integration time of 504 ks. Using a maximum likelihood algorithm we detected a total of 1390 sources at least in one band. Using Monte Carlo simulations to estimate the sky coverage we produced the logN-logS relations. These relations have been then derived in the 0.5--2 keV, 2--10 keV and 5--10 keV energy bands, down to flux limits of 7.2x10^-16 erg cm^-2 s^-1, 4.0x10^-15 erg cm^-2 s^-1 and 9.7x10^-15 erg cm^-2 s^-1, respectively. These relations have been compared to previous X-ray survey and to the most recent X-ray background model finding an excellent agreement. The slightly different normalizations observed in the source counts of COSMOS and previous surveys can be largely explained as a combination of low counting statistics and cosmic variance introduced by the large scale structure. ", "machine_text": " The results of an XMM-Newton survey of the COSMOS field, measuring X-ray source counts, are presented in this article. This survey covers a ~2 deg^2 region of the sky over a total integration time of 504 ks and identified a total of 1390 sources. A Monte Carlo simulation was used to construct the logN-logS relations in the 0.5-2, 2-10 and 5-10 keV energy bands, with corresponding flux limits of 7.2x10^-16, 4.0x10^-15, and 9.7x10^-15 erg cm^-2 s^-1, respectively. The resulting counts were found to be consistent with previous X-ray surveys and the latest X-ray background modeling. The discrepancy between the source counts in COSMOS and those in the previously conducted surveys is likely the result of the combination of low-counting statistics and effects of cosmic variance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2293}
{"prompt": "Rephrase the abstract of an article with title 'Plasma effects in a micromachined floating-gate high-electron-mobility   transistor'.   We study plasma effects in a micromachined high-electron mobility transistor (HEMT) with the microcantilever serving as the gate using the developed a model. The model accounts for mechanical motion of the microcantilever and spatio-temporal variations (plasma effects) of the two-dimensional electron gas(2DEG) system in the transistor channel. The microcantilever mechanical motion is described in the point-mass approximation. The hydrodynamic electron transport model is used to describe distributed electron plasma phenomena in the 2DEG system. Using the developed model, we calculated the response function characterizing the amplitude microcantilever oscillations and the output electric signal as functions of the signal frequency and the bias voltage for the devices with different parameters. We find the voltage dependences of the frequency of the mechanical resonance and its damping. In particular, it is demonstrated that the amplitudes of the mechanical oscillations and output electric signal exhibit pronounced maxima at the bias voltages close to the voltage of the 2DEG channel depletion followed by a steep drop with further increase in the bias voltage.  ", "human_text": "  We study plasma effects in a micromachined high-electron mobility transistor (HEMT) with the microcantilever serving as the gate using the developed a model. The model accounts for mechanical motion of the microcantilever and spatio-temporal variations (plasma effects) of the two-dimensional electron gas(2DEG) system in the transistor channel. The microcantilever mechanical motion is described in the point-mass approximation. The hydrodynamic electron transport model is used to describe distributed electron plasma phenomena in the 2DEG system. Using the developed model, we calculated the response function characterizing the amplitude microcantilever oscillations and the output electric signal as functions of the signal frequency and the bias voltage for the devices with different parameters. We find the voltage dependences of the frequency of the mechanical resonance and its damping. In particular, it is demonstrated that the amplitudes of the mechanical oscillations and output electric signal exhibit pronounced maxima at the bias voltages close to the voltage of the 2DEG channel depletion followed by a steep drop with further increase in the bias voltage. ", "machine_text": " In this article, we have developed a model to understand plasma effects in a micromachined High Electron Mobility Transistor (HEMT) with a microcantilever serving as the gate. The model takes into consideration the mechanical movement of the microcantilever, as well as the spatial and temporal variations of the Two-Dimensional Electron Gas (2DEG) system present in the transistor channel. To describe the microcantilever motion, the point-mass approximation was adopted. A hydrodynamic electron transport model was used to mimic plasma phenomena in the 2DEG. Using the model, we studied the response of the microcantilever oscillations and output signal as functions of signal frequency and bias voltage for various device parameters. We also analyzed voltage dependences of resonance frequency and its damping. We found that the signal amplitudes and microcantilever oscillations exhibit maxima at voltages close to the depletion voltage, followed by a steep drop as the bias voltage increases.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2082}
{"prompt": "Rephrase the abstract of an article with title 'The Clusters AgeS Experiment (CASE). I. V209 omega Cen - An Eclipsing   Post-Common Envelope Binary in the Globular Cluster omega Cen'.   We use photometric and spectroscopic observations of the detached eclipsing binary V209 omega Cen to derive the masses, radii, and luminosities of the component stars. The system exhibits total eclipses and, based on the measured systemic velocity and the derived distance, is a member of the globular cluster omega Cen. We obtain 0.945 +/- 0.043 Msun, 0.983 +/- 0.015 Rsun and 6.68 +/- 0.88 Lsun for the cooler, but larger and more luminous primary component. The secondary component has 0.144 +/- 0.008 Msun, 0.425 +/- 0.008 Rsun and 2.26 +/- 0.28 Lsun. The effective temperatures are estimated at 9370 K for the primary and at 10866 K for the secondary. On the color-magnitude diagram of the cluster, the primary component occupies a position between the tip of the blue straggler region and the extended horizontal branch while the secondary component is located close to the red border of the area occupied by hot subdwarfs. However, its radius is too large and its effective temperature is too low for it to be an sdB star. We propose a scenario leading to the formation of a system with such unusual properties with the primary component ``re-born'' from a former white dwarf which accreted a new envelope through mass transfer from its companion. The secondary star has lost most of its envelope while starting its ascent onto the sub-giant branch. It failed to ignite helium in its core and is currently powered by a hydrogen burning shell.  ", "human_text": "  We use photometric and spectroscopic observations of the detached eclipsing binary V209 omega Cen to derive the masses, radii, and luminosities of the component stars. The system exhibits total eclipses and, based on the measured systemic velocity and the derived distance, is a member of the globular cluster omega Cen. We obtain 0.945 +/- 0.043 Msun, 0.983 +/- 0.015 Rsun and 6.68 +/- 0.88 Lsun for the cooler, but larger and more luminous primary component. The secondary component has 0.144 +/- 0.008 Msun, 0.425 +/- 0.008 Rsun and 2.26 +/- 0.28 Lsun. The effective temperatures are estimated at 9370 K for the primary and at 10866 K for the secondary. On the color-magnitude diagram of the cluster, the primary component occupies a position between the tip of the blue straggler region and the extended horizontal branch while the secondary component is located close to the red border of the area occupied by hot subdwarfs. However, its radius is too large and its effective temperature is too low for it to be an sdB star. We propose a scenario leading to the formation of a system with such unusual properties with the primary component ``re-born'' from a former white dwarf which accreted a new envelope through mass transfer from its companion. The secondary star has lost most of its envelope while starting its ascent onto the sub-giant branch. It failed to ignite helium in its core and is currently powered by a hydrogen burning shell. ", "machine_text": " In this study, photometric and spectroscopic observations were conducted on V209 omega Cen, an eclipsing binary system in the globular cluster omega Cen. By analyzing the results, it was determined that both component stars possess masses of 0.945 +/- 0.043 Msun and 0.144 +/- 0.008 Msun, radii of 0.983 +/- 0.015 Rsun and 0.425 +/- 0.008 Rsun, and luminosities of 6.68 +/- 0.88 Lsun and 2.26 +/- 0.28 Lsun, respectively. Additionally, the cooler primary component has an effective temperature measurement of 9370 K, and the hotter secondary component has 10866 K. The positions of both stars within the cluster's colour-magnitude diagram are discussed. We then propose an alternative explanation for the unusual properties of the binary system, postulating that the primary star was previously a white dwarf that gained an additional envelope from the secondary star and then ``re-birthed'' with the secondary star losing majority of its own envelope while it started its climb up the subgiant branch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3507}
{"prompt": "Rephrase the abstract of an article with title 'Effective Theory for Trapped Few-Fermion Systems'.   We apply the general principles of effective field theories to the construction of effective interactions suitable for few- and many-body calculations in a no-core shell model framework. We calculate the spectrum of systems with three and four two-component fermions in a harmonic trap. In the unitary limit, we find that three-particle results are within 10% of known semi-analytical values even in small model spaces. The method is very general, and can be readily extended to other regimes, more particles, different species (e.g., protons and neutrons in nuclear physics), or more-component fermions (as well as bosons). As an illustration, we present calculations of the lowest-energy three-fermion states away from the unitary limit and find a possible inversion of parity in the ground state in the limit of trap size large compared to the scattering length. Furthermore, we investigate the lowest positive-parity states for four fermions, although we are limited by the dimensions we can currently handle in this case.  ", "human_text": "  We apply the general principles of effective field theories to the construction of effective interactions suitable for few- and many-body calculations in a no-core shell model framework. We calculate the spectrum of systems with three and four two-component fermions in a harmonic trap. In the unitary limit, we find that three-particle results are within 10% of known semi-analytical values even in small model spaces. The method is very general, and can be readily extended to other regimes, more particles, different species (e.g., protons and neutrons in nuclear physics), or more-component fermions (as well as bosons). As an illustration, we present calculations of the lowest-energy three-fermion states away from the unitary limit and find a possible inversion of parity in the ground state in the limit of trap size large compared to the scattering length. Furthermore, we investigate the lowest positive-parity states for four fermions, although we are limited by the dimensions we can currently handle in this case. ", "machine_text": "We present a theory for the trapped few-fermion systems that successfully constructs effective interactions in order to carry out few- and many-body calculations. We analyze the spectrum of three- and four-particle systems in a confinement, finding agreement with known semi-analytical values in the unitary limit. We extend this method to other scenarios, with different species and more components, as demonstrated by calculations of low-energy states away from the unitary limit and the possible inversion of parity in the ground state. Additionally, we explore the lowest positive-parity states of four fermions, although this may be limited by current computational dimensions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4335}
{"prompt": "Rephrase the abstract of an article with title 'Orbifoldes speciales et classification bimeromorphe des varietes   kaehleriennes compactes'.   This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\\it category} of geometric orbifolds. These interpolate between (compact K\\\" ahler) manifolds and such manifolds with logarithmic structure. These geometric orbifolds are considered from the point of view of their geometry, and thus equipped with the usual invariants of varieties: morphisms and bimeromorphic maps, differential forms, fundamental groups and universal covers, fields of definition and rational points. The most elementary properties, directly adapted from the case of varieties without orbifold structure, are established here. The arguments of [Ca01] can then be directly adapted to extend the main structure results to this orbifold category. We hope to come back to deeper aspects later. The motivation is that the natural frame for the theory of classification of compact K\\\" ahler (and complex projective) manifolds includes at least the category of orbifolds, as shown in [Ca01] by the fonctorial decomposition of {\\it special} manifolds as tower of orbifolds with either $\\kappa_+=-\\infty$ or $\\kappa=0$, and also, seemingly, by the minimal model program, in which most proofs work only after the adjunction of a \"boundary\".   Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds extension properties not satisfied in the category of varieties without orbifold structure, permitting to express invariants of the total space from those of the generic fibre and of the base. For example, the natural sequence of fundamental groups is exact there; also the total space is special if so are the generic fibre and the base. This makes this category suitable to lift properties from orbifolds having either $\\kappa_+=-\\infty$ or $\\kappa=0$ to those which are special.  ", "human_text": "  This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\\it category} of geometric orbifolds. These interpolate between (compact K\\\" ahler) manifolds and such manifolds with logarithmic structure. These geometric orbifolds are considered from the point of view of their geometry, and thus equipped with the usual invariants of varieties: morphisms and bimeromorphic maps, differential forms, fundamental groups and universal covers, fields of definition and rational points. The most elementary properties, directly adapted from the case of varieties without orbifold structure, are established here. The arguments of [Ca01] can then be directly adapted to extend the main structure results to this orbifold category. We hope to come back to deeper aspects later. The motivation is that the natural frame for the theory of classification of compact K\\\" ahler (and complex projective) manifolds includes at least the category of orbifolds, as shown in [Ca01] by the fonctorial decomposition of {\\it special} manifolds as tower of orbifolds with either $\\kappa_+=-\\infty$ or $\\kappa=0$, and also, seemingly, by the minimal model program, in which most proofs work only after the adjunction of a \"boundary\".   Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds extension properties not satisfied in the category of varieties without orbifold structure, permitting to express invariants of the total space from those of the generic fibre and of the base. For example, the natural sequence of fundamental groups is exact there; also the total space is special if so are the generic fibre and the base. This makes this category suitable to lift properties from orbifolds having either $\\kappa_+=-\\infty$ or $\\kappa=0$ to those which are special. ", "machine_text": "In this article, we present a study of special geometric orbifolds, and the classification of compact K\\\" ahler varieties within this orbifold category. We define the bimeromorphic category of such orbifolds, along with their invariants, such as morphisms, differential forms, fundamental groups and universal covers, fields of definition, and rational points. Additionally, we discuss how properties of these orbifolds can be extended from those without orbifold structure, and review the concept of special manifolds being composed as towers of orbifolds. We then provide a classification of compact K\\\" ahler varieties through this bimeromorphic category of geometric orbifolds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0737}
{"prompt": "Rephrase the abstract of an article with title 'A Panchromatic Study of the Globular Cluster NGC 1904. I: The Blue   Straggler Population'.   By combining high-resolution (HST-WFPC2) and wide-field ground based (2.2m ESO-WFI) and space (GALEX) observations, we have collected a multi-wavelength photometric data base (ranging from the far UV to the near infrared) of the galactic globular cluster NGC1904 (M79). The sample covers the entire cluster extension, from the very central regions up to the tidal radius. In the present paper such a data set is used to study the BSS population and its radial distribution. A total number of 39 bright ($m_{218}\\le 19.5$) BSS has been detected, and they have been found to be highly segregated in the cluster core. No significant upturn in the BSS frequency has been observed in the outskirts of NGC 1904, in contrast to other clusters (M 3, 47 Tuc, NGC 6752, M 5) studied with the same technique. Such evidences, coupled with the large radius of avoidance estimated for NGC 1904 ($r_{avoid}\\sim 30$ core radii), indicate that the vast majority of the cluster heavy stars (binaries) has already sunk to the core. Accordingly, extensive dynamical simulations suggest that BSS formed by mass transfer activity in primordial binaries evolving in isolation in the cluster outskirts represent only a negligible (0--10%) fraction of the overall population.  ", "human_text": "  By combining high-resolution (HST-WFPC2) and wide-field ground based (2.2m ESO-WFI) and space (GALEX) observations, we have collected a multi-wavelength photometric data base (ranging from the far UV to the near infrared) of the galactic globular cluster NGC1904 (M79). The sample covers the entire cluster extension, from the very central regions up to the tidal radius. In the present paper such a data set is used to study the BSS population and its radial distribution. A total number of 39 bright ($m_{218}\\le 19.5$) BSS has been detected, and they have been found to be highly segregated in the cluster core. No significant upturn in the BSS frequency has been observed in the outskirts of NGC 1904, in contrast to other clusters (M 3, 47 Tuc, NGC 6752, M 5) studied with the same technique. Such evidences, coupled with the large radius of avoidance estimated for NGC 1904 ($r_{avoid}\\sim 30$ core radii), indicate that the vast majority of the cluster heavy stars (binaries) has already sunk to the core. Accordingly, extensive dynamical simulations suggest that BSS formed by mass transfer activity in primordial binaries evolving in isolation in the cluster outskirts represent only a negligible (0--10%) fraction of the overall population. ", "machine_text": " This study examines the blue straggler population of the globular cluster NGC 1904 (M79) using a multifaceted data collection. The photometric data - ranging from ultraviolet to near infrared - was sourced from both high resolution HST-WFPC2 and ground/space based 2.2m ESO-WFI and GALEX instruments. After analysing the entire cluster in this way, a total of 39 notably bright blue stragglers ($m_{218}\\le 19.5$) have been distinguished with a highly concentrated distribution in the core region. Contrary to other globular clusters (M 3, 47 Tuc, NGC 6752, M 5) that have been studied with the same method, no major increase in the frequency of blue stragglers in the outer regions of NGC 1904 was observed. This, combined with a comparatively large radius of avoidance ($r_{avoid}\\sim 30$ core radii), leads to the conclusion that dynamic processes of a primordial binary system only make up a minuscule (0-10%) proportion of the overall blue straggler population of NGC 1904.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1393}
{"prompt": "Rephrase the abstract of an article with title 'Bond breaking with auxiliary-field quantum Monte Carlo'.   Bond stretching mimics different levels of electron correlation and provides a challenging testbed for approximate many-body computational methods. Using the recently developed phaseless auxiliary-field quantum Monte Carlo (AF QMC) method, we examine bond stretching in the well-studied molecules BH and N$_2$, and in the H$_{50}$ chain. To control the sign/phase problem, the phaseless AF QMC method constrains the paths in the auxiliary-field path integrals with an approximate phase condition that depends on a trial wave function. With single Slater determinants from unrestricted Hartree-Fock (UHF) as trial wave function, the phaseless AF QMC method generally gives better overall accuracy and a more uniform behavior than the coupled cluster CCSD(T) method in mapping the potential-energy curve. In both BH and N$_2$, we also study the use of multiple-determinant trial wave functions from multi-configuration self-consistent-field (MCSCF) calculations. The increase in computational cost versus the gain in statistical and systematic accuracy are examined. With such trial wave functions, excellent results are obtained across the entire region between equilibrium and the dissociation limit.  ", "human_text": "  Bond stretching mimics different levels of electron correlation and provides a challenging testbed for approximate many-body computational methods. Using the recently developed phaseless auxiliary-field quantum Monte Carlo (AF QMC) method, we examine bond stretching in the well-studied molecules BH and N$_2$, and in the H$_{50}$ chain. To control the sign/phase problem, the phaseless AF QMC method constrains the paths in the auxiliary-field path integrals with an approximate phase condition that depends on a trial wave function. With single Slater determinants from unrestricted Hartree-Fock (UHF) as trial wave function, the phaseless AF QMC method generally gives better overall accuracy and a more uniform behavior than the coupled cluster CCSD(T) method in mapping the potential-energy curve. In both BH and N$_2$, we also study the use of multiple-determinant trial wave functions from multi-configuration self-consistent-field (MCSCF) calculations. The increase in computational cost versus the gain in statistical and systematic accuracy are examined. With such trial wave functions, excellent results are obtained across the entire region between equilibrium and the dissociation limit. ", "machine_text": " The bond breaking process has been tested using the auxiliary-field quantum Monte Carlo method, where paths in the path integrals are controlled with an approximate phase condition based on a trial wave function. Single Slater determinants from unrestricted Hartree-Fock calculations and multiple-determinant trial wave functions from multi-configuration self-consistent-field method were used to provide an assessment of the accuracy improvement with the increase of computational cost. This was tested using BH and N$_{2}$ molecules and the H$_{50}$ chain as examples. Ultimately it was found that these trial wave functions yielded excellent results across the entire period from the equilibrium point to the dissociation limit.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2827}
{"prompt": "Rephrase the abstract of an article with title 'Origin of magnetoelectric behavior in BiFeO$_3$'.   The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of accurate density functional calculations. The structural, electronic, magnetic, and ferroelectric properties of BiFeO$_3$ are predicted correctly without including strong correlation effect in the calculation. Moreover, the experimentally-observed elongation of cubic perovskite-like lattice along the [111] direction is correctly reproduced. At high pressure we predicted a pressure-induced structural transition and the total energy calculations at expanded lattice show two lower energy ferroelectric phases, closer in energy to the ground state phase. Band-structure calculations show that BiFeO$_3$ will be an insulator in A- and G-type antiferromagnetic phases and a metal in other magnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using various tools and electron localization function analysis shows that stereochemically active lone-pair electrons at the Bi sites are responsible for displacements of the Bi atoms from the centro-symmetric to the noncentrosymmetric structure and hence the ferroelectricity. A large ferroelectric polarization (88.7 $\\mu$C/cm$^{2}$) is predicted in accordance with recent experimental findings. The net polarization is found to mainly ($>$ 98%) originate from Bi atoms. Moreover the large scatter in experimentally reported polarization values is due to the large anisotropy in the spontaneous polarization.  ", "human_text": "  The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of accurate density functional calculations. The structural, electronic, magnetic, and ferroelectric properties of BiFeO$_3$ are predicted correctly without including strong correlation effect in the calculation. Moreover, the experimentally-observed elongation of cubic perovskite-like lattice along the [111] direction is correctly reproduced. At high pressure we predicted a pressure-induced structural transition and the total energy calculations at expanded lattice show two lower energy ferroelectric phases, closer in energy to the ground state phase. Band-structure calculations show that BiFeO$_3$ will be an insulator in A- and G-type antiferromagnetic phases and a metal in other magnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using various tools and electron localization function analysis shows that stereochemically active lone-pair electrons at the Bi sites are responsible for displacements of the Bi atoms from the centro-symmetric to the noncentrosymmetric structure and hence the ferroelectricity. A large ferroelectric polarization (88.7 $\\mu$C/cm$^{2}$) is predicted in accordance with recent experimental findings. The net polarization is found to mainly ($>$ 98%) originate from Bi atoms. Moreover the large scatter in experimentally reported polarization values is due to the large anisotropy in the spontaneous polarization. ", "machine_text": " This paper aims to reveal the source of magnetoelectric behavior in BiFeO$_3$ by investigating the structural, electronic, magnetic, and ferroelectric properties of this material. Accurate density functional calculations without strong correlation effects are used to reproduce the observed cuboctahedral lattice expansion in the [111] direction, as well as a pressure-induced structural transition. Band-structure calculations predict that BiFeO$_3$ is an insulator in an A- and G-type antiferromagnetic phase and a metal in other magnetic configurations. Results from the electron localization function analysis indicate that the ferroelectricity is caused by sterically active lone-pair electrons at the Bi sites. A large ferroelectric polarization of 88.7 $\\mu$C/cm$^{2}$ is expected from this research, which is in agreement with recent experimental findings. Moreover, the large variations in the ferroelectric polarization are due to the anisotropy in the spontaneous polarization.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.046}
{"prompt": "Rephrase the abstract of an article with title 'Polarizabilities of Intermediate Sized Lithium Clusters From   Density-Functional Theory'.   We present a detailed investigation of static dipole polarizability of lithium clusters containing up to 22 atoms. We first build a database of lithium clusters by optimizing several candidate structures for the ground state geometry for each size. The full polarizability tensor is determined for about 5-6 isomers of each cluster size using the finite-field method. All calculations are performed using large Gaussian basis sets, and within the generalized gradient approximation to the density functional theory, as implemented in the NRLMOL suite of codes. The average polarizability per atom varies from 11 to 9 Angstrom^3, within the 8-22 size range and show smoother decrease with increase in cluster size than the experimental values. While the average polarizability exhibits a relatively weak dependence on cluster conformation, significant changes in the degree of anisotropy of the polarizability tensor are observed. Interestingly, in addition to the expected even odd (0 and 1 $\\mu_B$) magnetic states, our results show several cases where clusters with an odd number of Li atoms exhibit elevated spin states (e.g. 3 $\\mu_B$).  ", "human_text": "  We present a detailed investigation of static dipole polarizability of lithium clusters containing up to 22 atoms. We first build a database of lithium clusters by optimizing several candidate structures for the ground state geometry for each size. The full polarizability tensor is determined for about 5-6 isomers of each cluster size using the finite-field method. All calculations are performed using large Gaussian basis sets, and within the generalized gradient approximation to the density functional theory, as implemented in the NRLMOL suite of codes. The average polarizability per atom varies from 11 to 9 Angstrom^3, within the 8-22 size range and show smoother decrease with increase in cluster size than the experimental values. While the average polarizability exhibits a relatively weak dependence on cluster conformation, significant changes in the degree of anisotropy of the polarizability tensor are observed. Interestingly, in addition to the expected even odd (0 and 1 $\\mu_B$) magnetic states, our results show several cases where clusters with an odd number of Li atoms exhibit elevated spin states (e.g. 3 $\\mu_B$). ", "machine_text": "This article delves into the analysis of the polarizability of lithium clusters with up to 22 atoms. A database of geometrical structures was created and the finite-field method was applied to determine the full polarizability tensor for each size. The results from density functional theory (in the form of Gaussian basis sets and the NRLMOL suite of codes) show that the average polarizability per atom declines from 11 to 9 Angstrom^3 in the 8-22 size range and is smoother than the experimentally obtained values. Additionally, changes in the degree of anisotropy of the polarizability in different conformations were observed while some cases with an odd atom number show elevated spin states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0555}
{"prompt": "Rephrase the abstract of an article with title 'Quasi-periodic oscillations, charge and the gravitomagnetic theory'.   A new model for the explanation of the high frequency quasi-periodic oscillations (QPOs) in pulsars, black holes and white dwarfs is presented. Three circular tori are assumed to be present around the star: an inner torus with charge $Q_i$, an outer torus with charge $Q_o$ and a torus with electrically neutral mass $m_m$ in the middle, whereas the star bears a charge $Q_s$ ($Q_o$ and $Q_s$ have the same sign, $Q_i$ the opposite one). The frequency $\\nu_m$ of the mass current is approximately given by the Kepler frequency, whereas the frequencies of $Q_i$ and $Q_o$, $\\nu_i$ and $\\nu_o$, respectively, are calculated from classical mechanics and Coulomb's law.   For the explanation of the low frequency QPOs in pulsars and black holes a special interpretation of the gravitomagnetic theory may be essential. From the latter theory four new gravitomagnetic precession frequencies are deduced, which may be identified with the observed low frequency QPOs.   Predictions of the presented model are compared with observed high frequency and low frequency QPOs of the pulsars SAX J1808.4--3658, XTE J1807--294, IGR J00291+5934, SGR 1806--20 and the black hole XTE J1550--564. In addition, charge flow near the pole of pulsars may explain frequency drift of burst oscillations. Moreover, charge flow at the equator of SAX J1808.4--3658 may be the cause of the enigmatic 410 kHz QPO. Furthermore, the Lense-Thirring frequency is discussed and a modified formula is compared with data of the pulsars.   Contrary to pulsars and black holes, the low frequency QPOs of white dwarfs might be attributed to electromagnetic precession frequencies, deduced in this work. Predictions are compared with data of the dwarf nova VW Hyi.  ", "human_text": "  A new model for the explanation of the high frequency quasi-periodic oscillations (QPOs) in pulsars, black holes and white dwarfs is presented. Three circular tori are assumed to be present around the star: an inner torus with charge $Q_i$, an outer torus with charge $Q_o$ and a torus with electrically neutral mass $m_m$ in the middle, whereas the star bears a charge $Q_s$ ($Q_o$ and $Q_s$ have the same sign, $Q_i$ the opposite one). The frequency $\\nu_m$ of the mass current is approximately given by the Kepler frequency, whereas the frequencies of $Q_i$ and $Q_o$, $\\nu_i$ and $\\nu_o$, respectively, are calculated from classical mechanics and Coulomb's law.   For the explanation of the low frequency QPOs in pulsars and black holes a special interpretation of the gravitomagnetic theory may be essential. From the latter theory four new gravitomagnetic precession frequencies are deduced, which may be identified with the observed low frequency QPOs.   Predictions of the presented model are compared with observed high frequency and low frequency QPOs of the pulsars SAX J1808.4--3658, XTE J1807--294, IGR J00291+5934, SGR 1806--20 and the black hole XTE J1550--564. In addition, charge flow near the pole of pulsars may explain frequency drift of burst oscillations. Moreover, charge flow at the equator of SAX J1808.4--3658 may be the cause of the enigmatic 410 kHz QPO. Furthermore, the Lense-Thirring frequency is discussed and a modified formula is compared with data of the pulsars.   Contrary to pulsars and black holes, the low frequency QPOs of white dwarfs might be attributed to electromagnetic precession frequencies, deduced in this work. Predictions are compared with data of the dwarf nova VW Hyi. ", "machine_text": " This paper presents a theoretical model for explaining the high frequency quasi-periodic oscillations (QPOs) in pulsars, black holes and white dwarfs. The model incorporates three circular tori around the star, where two carry charge and the third houses an electrically neutral mass. The given theory also proposes a new interpretation to the gravitomagnetic theory in order to explain low-frequency QPOs in pulsars and black holes. Furthermore, the effect of charge flow is contemplated to explain the frequency drifts of burst oscillations and the 410 kHz QPO in the pulsar SAX J1808.4--3658. In addition, the Lense-Thirring frequency and a modified formula derived from it are compared with data from pulsars. Lastly, for white dwarf stars, low frequency QPOs are suggested to stem from electromagnetic precession frequencies developed in the theory. Predictions from the model are compared to the data from the dwarf nova VW Hyi.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0313}
{"prompt": "Rephrase the abstract of an article with title 'Radiatively broken symmetries of nonhierarchical neutrinos'.   Symmetry-based ideas, such as the quark-lepton complementarity (QLC) principle and the tri-bimaximal mixing (TBM) scheme, have been proposed to explain the observed mixing pattern of neutrinos. We argue that such symmetry relations need to be imposed at a high scale $\\Lambda \\sim 10^{12}$ GeV characterizing the large masses of right-handed neutrinos required to implement the seesaw mechanism. For nonhierarchical neutrinos, renormalisation group evolution down to a laboratory energy scale $\\lambda \\sim 10^3$ GeV tends to radiatively break these symmetries at a significant level and spoil the mixing pattern predicted by them. However, for Majorana neutrinos, suitable constraints on the extra phases $\\alpha_{2,3}$ enable the retention of those high scale mixing patterns at laboratory energies. We examine this issue within the Minimal Supersymmetric Standard Model (MSSM) and demonstrate the fact posited above for two versions of QLC and two versions of TBM. The appropriate constraints are worked out for all these four cases. Specifically, a preference for $\\alpha_2 \\approx \\pi$ (i.e. $m_1 \\approx -m_2$) emerges in each case. We also show how a future accurate measurement of $\\theta_{13}$ may enable some discrimination among these four cases in spite of renormalization group evolution.  ", "human_text": "  Symmetry-based ideas, such as the quark-lepton complementarity (QLC) principle and the tri-bimaximal mixing (TBM) scheme, have been proposed to explain the observed mixing pattern of neutrinos. We argue that such symmetry relations need to be imposed at a high scale $\\Lambda \\sim 10^{12}$ GeV characterizing the large masses of right-handed neutrinos required to implement the seesaw mechanism. For nonhierarchical neutrinos, renormalisation group evolution down to a laboratory energy scale $\\lambda \\sim 10^3$ GeV tends to radiatively break these symmetries at a significant level and spoil the mixing pattern predicted by them. However, for Majorana neutrinos, suitable constraints on the extra phases $\\alpha_{2,3}$ enable the retention of those high scale mixing patterns at laboratory energies. We examine this issue within the Minimal Supersymmetric Standard Model (MSSM) and demonstrate the fact posited above for two versions of QLC and two versions of TBM. The appropriate constraints are worked out for all these four cases. Specifically, a preference for $\\alpha_2 \\approx \\pi$ (i.e. $m_1 \\approx -m_2$) emerges in each case. We also show how a future accurate measurement of $\\theta_{13}$ may enable some discrimination among these four cases in spite of renormalization group evolution. ", "machine_text": " We examine the issue of how radiative corrections at low energy scales may cause breaking of symmetries, such as the quark-lepton complementarity (QLC) and the tri-bimaximal mixing (TBM), that are proposed to explain the observed mixing pattern of neutrinos. Our investigation is conducted within the context of the Minimal Supersymmetric Standard Model (MSSM) for nonhierarchical neutrinos. We find that the appropriate choice of extra phases $\\alpha_{2,3}$ can retain the high scale mixing patterns which would otherwise be spoiled by the radiative corrections. Further, measuring the angle $\\theta_{13}$ at a future point in time may enable distinction between the different symmetry-based models even after the radiative breaking of the symmetries.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3735}
{"prompt": "Rephrase the abstract of an article with title 'A Pair of Bootes: A New Milky Way Satellite'.   As part of preparations for a southern sky search for faint Milky Way dwarf galaxy satellites, we report the discovery of a stellar overdensity in the Sloan Digital Sky Survey Data Release 5, lying at an angular distance of only 1.5 degrees from the recently discovered Bo{\\\"o}tes dwarf. The overdensity was detected well above statistical noise by employing a sophisticated data mining algorithm and does not correspond to any catalogued object. Overlaid isochrones using stellar population synthesis models show that the color-magnitude diagram of that region has the signature of an old (12 Gyr), metal-poor (${\\rm Fe/H}\\approx-2.0$) stellar population at a tentative distance of 60 kpc, evidently the same heliocentric distance as the Bo\\\"otes dwarf. We estimate the new object to have a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a half-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc) placing it in an apparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies, occupied only by another recently discovered Milky Way Satellite, Coma Berenices.  ", "human_text": "  As part of preparations for a southern sky search for faint Milky Way dwarf galaxy satellites, we report the discovery of a stellar overdensity in the Sloan Digital Sky Survey Data Release 5, lying at an angular distance of only 1.5 degrees from the recently discovered Bo{\\\"o}tes dwarf. The overdensity was detected well above statistical noise by employing a sophisticated data mining algorithm and does not correspond to any catalogued object. Overlaid isochrones using stellar population synthesis models show that the color-magnitude diagram of that region has the signature of an old (12 Gyr), metal-poor (${\\rm Fe/H}\\approx-2.0$) stellar population at a tentative distance of 60 kpc, evidently the same heliocentric distance as the Bo\\\"otes dwarf. We estimate the new object to have a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a half-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc) placing it in an apparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies, occupied only by another recently discovered Milky Way Satellite, Coma Berenices. ", "machine_text": " We have uncovered a new Milky Way satellite, located within 1.5 degrees of the existing Bo{\\\"o}tes dwarf, during a survey of the southern sky for faint galaxy satellites. A sophisticated data mining algorithm was used to detect the stellar overdensity and verify that it does not correspond to any previously catalogued object. Analysis of the color-magnitude diagram for the region with stellar population synthesis models suggests that the new object has a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a half-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc). This places it in a previously empty forty to one-hundred parsec void between globular clusters and dwarf galaxies, occupied by only one other Milky Way satellite- Coma Berenices.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1378}
{"prompt": "Rephrase the abstract of an article with title 'Sample eigenvalue based detection of high dimensional signals in white   noise using relatively few samples'.   We present a mathematically justifiable, computationally simple, sample eigenvalue based procedure for estimating the number of high-dimensional signals in white noise using relatively few samples. The main motivation for considering a sample eigenvalue based scheme is the computational simplicity and the robustness to eigenvector modelling errors which are can adversely impact the performance of estimators that exploit information in the sample eigenvectors.   There is, however, a price we pay by discarding the information in the sample eigenvectors; we highlight a fundamental asymptotic limit of sample eigenvalue based detection of weak/closely spaced high-dimensional signals from a limited sample size. This motivates our heuristic definition of the effective number of identifiable signals which is equal to the number of \"signal\" eigenvalues of the population covariance matrix which exceed the noise variance by a factor strictly greater than 1+sqrt(Dimensionality of the system/Sample size). The fundamental asymptotic limit brings into sharp focus why, when there are too few samples available so that the effective number of signals is less than the actual number of signals, underestimation of the model order is unavoidable (in an asymptotic sense) when using any sample eigenvalue based detection scheme, including the one proposed herein. The analysis reveals why adding more sensors can only exacerbate the situation. Numerical simulations are used to demonstrate that the proposed estimator consistently estimates the true number of signals in the dimension fixed, large sample size limit and the effective number of identifiable signals in the large dimension, large sample size limit.  ", "human_text": "  We present a mathematically justifiable, computationally simple, sample eigenvalue based procedure for estimating the number of high-dimensional signals in white noise using relatively few samples. The main motivation for considering a sample eigenvalue based scheme is the computational simplicity and the robustness to eigenvector modelling errors which are can adversely impact the performance of estimators that exploit information in the sample eigenvectors.   There is, however, a price we pay by discarding the information in the sample eigenvectors; we highlight a fundamental asymptotic limit of sample eigenvalue based detection of weak/closely spaced high-dimensional signals from a limited sample size. This motivates our heuristic definition of the effective number of identifiable signals which is equal to the number of \"signal\" eigenvalues of the population covariance matrix which exceed the noise variance by a factor strictly greater than 1+sqrt(Dimensionality of the system/Sample size). The fundamental asymptotic limit brings into sharp focus why, when there are too few samples available so that the effective number of signals is less than the actual number of signals, underestimation of the model order is unavoidable (in an asymptotic sense) when using any sample eigenvalue based detection scheme, including the one proposed herein. The analysis reveals why adding more sensors can only exacerbate the situation. Numerical simulations are used to demonstrate that the proposed estimator consistently estimates the true number of signals in the dimension fixed, large sample size limit and the effective number of identifiable signals in the large dimension, large sample size limit. ", "machine_text": " We explore the feasibility of a mathematically sound and computationally simple eigenvalue based method for estimating the number of high-dimensional signals present in an additive white noise environment, when the number of available samples is relatively low. This procedure exploits eigenvalues from the population covariance matrix as an indicator of signal presence, as a way to overcome potential errors which could arise from eigenvector modelling. However, a fundamental limit is uncovered with the estimator, due to its incapacity to detect weak signals or close signals in the same frequency range. We define the effective number of identifiable signals equal to the 'signal' eigenvalues which surpass the noise variance multiplied by a factor greater than 1+\u221a(Dimensionality of system/Sample size). Numerical experiments validate that the estimator correctly presents the true patterns of signal presence when in a large sample size/dimensionality scenario and the effective number of signals in a large dimension/sample size environment.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2605}
{"prompt": "Rephrase the abstract of an article with title 'Relating two standard notions of secrecy'.   Two styles of definitions are usually considered to express that a security protocol preserves the confidentiality of a data s. Reachability-based secrecy means that s should never be disclosed while equivalence-based secrecy states that two executions of a protocol with distinct instances for s should be indistinguishable to an attacker. Although the second formulation ensures a higher level of security and is closer to cryptographic notions of secrecy, decidability results and automatic tools have mainly focused on the first definition so far.   This paper initiates a systematic investigation of the situations where syntactic secrecy entails strong secrecy. We show that in the passive case, reachability-based secrecy actually implies equivalence-based secrecy for digital signatures, symmetric and asymmetric encryption provided that the primitives are probabilistic. For active adversaries, we provide sufficient (and rather tight) conditions on the protocol for this implication to hold.  ", "human_text": "  Two styles of definitions are usually considered to express that a security protocol preserves the confidentiality of a data s. Reachability-based secrecy means that s should never be disclosed while equivalence-based secrecy states that two executions of a protocol with distinct instances for s should be indistinguishable to an attacker. Although the second formulation ensures a higher level of security and is closer to cryptographic notions of secrecy, decidability results and automatic tools have mainly focused on the first definition so far.   This paper initiates a systematic investigation of the situations where syntactic secrecy entails strong secrecy. We show that in the passive case, reachability-based secrecy actually implies equivalence-based secrecy for digital signatures, symmetric and asymmetric encryption provided that the primitives are probabilistic. For active adversaries, we provide sufficient (and rather tight) conditions on the protocol for this implication to hold. ", "machine_text": " This paper investigates the way in which reachability-based secrecy may be related to equivalence-based secrecy. It is determined that reachability-based secrecy implies equivalence-based secrecy for digital signatures, symmetric and asymmetric encryption, when the primitives used are probabilistic. Additionally, for active adversaries, there are sufficient conditions that help reach the same result. The study focuses on the ways in which reachability-based secrecy can ensure strong security, and provides decidability results and automatic tools to help.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0502}
{"prompt": "Rephrase the abstract of an article with title 'The Millennium Galaxy Catalogue: the B-band attenuation of bulge and   disc light and the implied cosmic dust and stellar mass densities'.   Based on our sample of 10095 galaxies with bulge-disc decompositions we derive the empirical B-band internal attenuation--inclination relation for galaxy discs and their associated central bulges. Our results agree well with the independently derived dust models of Tuffs et al., leading to a direct constraint on the mean opacity of spiral discs of Tau_B^f = 3.8 +/- 0.7 (central face-on B-band opacity). Depending on inclination, the B-band attenuation correction varies from 0.2 -- 1.1 mag for discs and from 0.8 -- 2.6 mag for bulges. We find that, overall, 37 per cent of all B-band photons produced in discs in the nearby universe are absorbed by dust, a figure that rises to 71 per cent for bulge photons. The severity of internal dust extinction is such that one must incorporate internal dust corrections in all optical studies of large galaxy samples. This is particularly pertinent for optical HST comparative evolutionary studies as the dust properties will also be evolving. We use the new results to revise our recent estimates of the spheroid and disc luminosity functions. From our best fitting dust models we derive a redshift zero cosmic dust density of rho_{dust} ~ (5.3 +/- 1.7) x 10^5, h M_{odot} Mpc^-3. This implies that (0.0083 +/- 0.0027), h per cent of the baryons in the Universe are in the form of dust and (11.9 +/- 1.7), h per cent (Salpeter-`lite' IMF) are in the form of stars (~58 per cent reside in galaxy discs, ~10 per cent in red elliptical galaxies, ~29 per cent in classical galaxy bulges and the remainder in low luminosity blue spheroid systems/components). [Abridged]  ", "human_text": "  Based on our sample of 10095 galaxies with bulge-disc decompositions we derive the empirical B-band internal attenuation--inclination relation for galaxy discs and their associated central bulges. Our results agree well with the independently derived dust models of Tuffs et al., leading to a direct constraint on the mean opacity of spiral discs of Tau_B^f = 3.8 +/- 0.7 (central face-on B-band opacity). Depending on inclination, the B-band attenuation correction varies from 0.2 -- 1.1 mag for discs and from 0.8 -- 2.6 mag for bulges. We find that, overall, 37 per cent of all B-band photons produced in discs in the nearby universe are absorbed by dust, a figure that rises to 71 per cent for bulge photons. The severity of internal dust extinction is such that one must incorporate internal dust corrections in all optical studies of large galaxy samples. This is particularly pertinent for optical HST comparative evolutionary studies as the dust properties will also be evolving. We use the new results to revise our recent estimates of the spheroid and disc luminosity functions. From our best fitting dust models we derive a redshift zero cosmic dust density of rho_{dust} ~ (5.3 +/- 1.7) x 10^5, h M_{odot} Mpc^-3. This implies that (0.0083 +/- 0.0027), h per cent of the baryons in the Universe are in the form of dust and (11.9 +/- 1.7), h per cent (Salpeter-`lite' IMF) are in the form of stars (~58 per cent reside in galaxy discs, ~10 per cent in red elliptical galaxies, ~29 per cent in classical galaxy bulges and the remainder in low luminosity blue spheroid systems/components). [Abridged] ", "machine_text": " By analyzing 10095 galaxies with bulge and disc components, this investigation offers an empirical correlation between the internal B-band attenuation and inclination of a galaxy. Aligning well with the dust models of Tuffs et al., this connection leads to a reliable estimate of the face-on opacity of spiral discs (Tau_B^f = 3.8 +/- 0.7). The attenuation varies significantly from disc to disc, ranging from 0.2 - 1.1 mag, and from 0.8 - 2.6 mag for the bulges. It is found that an astonishing 37% of all B-band photons produced in discs are absorbed by dust, increasing to 71% for photons originating from bulges. Consequently, studies of large galaxy samples must all incorporate internal dust models. Applying the new findings, the redshift 0 cosmic dust density is calculated, revealing that 0.0083 +/- 0.0027 of baryons in the universe are in the form of dust. Similarly, the data provides an exact amount of stellar matter in any form, with 11.9 +/- 1.7% being attributed to stars, the majority of which reside in galaxy discs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.214}
{"prompt": "Rephrase the abstract of an article with title 'Magnetically-driven explosions of rapidly-rotating white dwarfs   following Accretion-Induced Collapse'.   We present 2D multi-group flux-limited diffusion magnetohydrodynamics (MHD) simulations of the Accretion-Induced Collapse (AIC) of a rapidly-rotating white dwarf. We focus on the dynamical role of MHD processes after the formation of a millisecond-period protoneutron star. We find that including magnetic fields and stresses can lead to a powerful explosion with an energy of a few Bethe, rather than a weak one of at most 0.1 Bethe, with an associated ejecta mass of ~0.1Msun, instead of a few 0.001Msun. The core is spun down by ~30% within 500ms after bounce, and the rotational energy extracted from the core is channeled into magnetic energy that generates a strong magnetically-driven wind, rather than a weak neutrino-driven wind. Baryon loading of the ejecta, while this wind prevails, precludes it from becoming relativistic. This suggests that a GRB is not expected to emerge from such AICs during the early protoneutron star phase, except in the unlikely event that the massive white dwarf has sufficient mass to lead to black hole formation. In addition, we predict both negligible 56Ni-production (that should result in an optically-dark, adiabatically-cooled explosion) and the ejection of 0.1Msun of material with an electron fraction of 0.1-0.2. Such pollution by neutron-rich nuclei puts strong constraints on the possible rate of such AICs. Moreover, being free from ``fallback,'' such highly-magnetized millisecond-period protoneutron stars may later become magnetars, and the magnetically-driven winds may later transition to Poynting-flux-dominated, relativistic winds, eventually detectable as GRBs at cosmological distances. However, the low expected event rate of AICs will constrain them to be, at best, a small subset of GRB and/or magnetar progenitors.  ", "human_text": "  We present 2D multi-group flux-limited diffusion magnetohydrodynamics (MHD) simulations of the Accretion-Induced Collapse (AIC) of a rapidly-rotating white dwarf. We focus on the dynamical role of MHD processes after the formation of a millisecond-period protoneutron star. We find that including magnetic fields and stresses can lead to a powerful explosion with an energy of a few Bethe, rather than a weak one of at most 0.1 Bethe, with an associated ejecta mass of ~0.1Msun, instead of a few 0.001Msun. The core is spun down by ~30% within 500ms after bounce, and the rotational energy extracted from the core is channeled into magnetic energy that generates a strong magnetically-driven wind, rather than a weak neutrino-driven wind. Baryon loading of the ejecta, while this wind prevails, precludes it from becoming relativistic. This suggests that a GRB is not expected to emerge from such AICs during the early protoneutron star phase, except in the unlikely event that the massive white dwarf has sufficient mass to lead to black hole formation. In addition, we predict both negligible 56Ni-production (that should result in an optically-dark, adiabatically-cooled explosion) and the ejection of 0.1Msun of material with an electron fraction of 0.1-0.2. Such pollution by neutron-rich nuclei puts strong constraints on the possible rate of such AICs. Moreover, being free from ``fallback,'' such highly-magnetized millisecond-period protoneutron stars may later become magnetars, and the magnetically-driven winds may later transition to Poynting-flux-dominated, relativistic winds, eventually detectable as GRBs at cosmological distances. However, the low expected event rate of AICs will constrain them to be, at best, a small subset of GRB and/or magnetar progenitors. ", "machine_text": " This research examines the power of magnetohydrodynamics (MHD) when applied to rapidly-rotating white dwarf stars going through Accretion-Induced Collapse (AIC). Our simulations, using 2D multi-group flux-limited diffusion MHD, find that including MHD processes can create an explosion with a power of a few Bethe - up from a mere 0.1Bethe - and an ejecta mass of ~0.1Msun, compared to 0.001Msun without the addition of magnetic fields and stresses. The core is substantially spun down and the rotational energy is channeled into magnetic energy, producing a strong magnetically-driven wind instead of a weak one driven by neutrinos. This wind has too much baryon load to become relativistic, suggesting an unlikely GRB event to emerge. Our study also predicts low production of 56Ni, likely making this an optically-dark, adiabatically-cooled explosion, as well as an ejection of neutron-rich nuclei. We suggest that such highly-magnetized millisecond-period protoneutron stars may later form into magnetars, and that their magnetically-driven winds may transition to Poynting-flux-dominated, potentially detectable GRBs at cosmological distances. Nevertheless, the expectation of a low rate of AICs will limit them to a miniscule subset of GRB and/or magnetar progenitors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3678}
{"prompt": "Rephrase the abstract of an article with title 'Characterization of open cluster remnants'.   Despite progress in the theoretical knowledge of open cluster remnants and the growing search for observational identifications in recent years, open questions still remain. The methods used to analyze open cluster remnants and criteria to define them as physical systems are not homogeneous. In this work we present a systematic method for studying these objects that provides a view of their properties and allows their characterization. Eighteen remnant candidates are analyzed by means of photometric and proper motion data. These data provide information on objects and their fields. We establish criteria for characterizing open cluster remnants, taking observational uncertainties into account. 2MASS J and H photometry is employed (i) to study structural properties of the objects by means of radial stellar density profiles, (ii) to test for any similarity between objects and fields with a statistical comparison method applied to the distributions of stars in the CMDs, and (iii) to obtain ages, reddening values, and distances from the CMD, taking an index of isochrone fit into account. The UCAC2 proper motions allowed an objective comparison between objects and large solid angle offset fields. The objective analysis based on the present methods indicates 13 open-cluster remnants in the sample. Evidence of the presence of binary stars is found, as expected for dynamically evolved systems. Finally, we infer possible evolutionary stages among remnants from the structure, proper motion, and CMD distributions. The low stellar statistics for individual objects is overcome by means of the construction of composite proper motion and CMD diagrams. The distributions of remnants in the composite diagrams resemble the single-star and unresolved binary star distributions of open clusters.  ", "human_text": "  Despite progress in the theoretical knowledge of open cluster remnants and the growing search for observational identifications in recent years, open questions still remain. The methods used to analyze open cluster remnants and criteria to define them as physical systems are not homogeneous. In this work we present a systematic method for studying these objects that provides a view of their properties and allows their characterization. Eighteen remnant candidates are analyzed by means of photometric and proper motion data. These data provide information on objects and their fields. We establish criteria for characterizing open cluster remnants, taking observational uncertainties into account. 2MASS J and H photometry is employed (i) to study structural properties of the objects by means of radial stellar density profiles, (ii) to test for any similarity between objects and fields with a statistical comparison method applied to the distributions of stars in the CMDs, and (iii) to obtain ages, reddening values, and distances from the CMD, taking an index of isochrone fit into account. The UCAC2 proper motions allowed an objective comparison between objects and large solid angle offset fields. The objective analysis based on the present methods indicates 13 open-cluster remnants in the sample. Evidence of the presence of binary stars is found, as expected for dynamically evolved systems. Finally, we infer possible evolutionary stages among remnants from the structure, proper motion, and CMD distributions. The low stellar statistics for individual objects is overcome by means of the construction of composite proper motion and CMD diagrams. The distributions of remnants in the composite diagrams resemble the single-star and unresolved binary star distributions of open clusters. ", "machine_text": "This article presents a systematic characterization of open cluster remnants. Photometric and proper motion data are used to obtain structural properties, ages, reddening values and distances, as well as evidence for the presence of binary stars. Criteria for defining these objects as physical systems are established. These analyses shed light on potential evolutionary stages of open clusters and enable the detection of thirteen searchable open cluster remnants. Statistical comparison and composite diagrams are used to overcome the limitations of small stellar samples. These diagrams resemble the distributions of single-star and unresolved binary star systems in open clusters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1159}
{"prompt": "Rephrase the abstract of an article with title 'Atomic Electric Dipole Moments: The Schiff Theorem and Its Corrections'.   Searches for the permanent electric dipole moments (EDMs) of diamagnetic atoms provide powerful probes of CP-violating hadronic and semileptonic interactions. The theoretical interpretation of such experiments, however, requires careful implementation of a well-known theorem by Schiff that implies a vanishing net EDM for an atom built entirely from point-like, nonrelativistic constituents that interact only electrostatically. Any experimental observation of a nonzero atomic EDM would result from corrections to the point-like, nonrelativistic, electrostatic assumption. We reformulate Schiff's theorem at the operator level and delineate the electronic and nuclear operators whose atomic matrix elements generate corrections to \"Schiff screening\". We obtain a form for the operator responsible for the leading correction associated with finite nuclear size -- the so-called \"Schiff moment\" operator -- and observe that it differs from the corresponding operator used in previous Schiff moment computations. We show that the more general Schiff moment operator reduces to the previously employed operator only under certain approximations that are not generally justified. We also identify other corrections to Schiff screening that may not be included properly in previous theoretical treatments. We discuss practical considerations for obtaining a complete computation of corrections to Schiff screening in atomic EDM calculations.  ", "human_text": "  Searches for the permanent electric dipole moments (EDMs) of diamagnetic atoms provide powerful probes of CP-violating hadronic and semileptonic interactions. The theoretical interpretation of such experiments, however, requires careful implementation of a well-known theorem by Schiff that implies a vanishing net EDM for an atom built entirely from point-like, nonrelativistic constituents that interact only electrostatically. Any experimental observation of a nonzero atomic EDM would result from corrections to the point-like, nonrelativistic, electrostatic assumption. We reformulate Schiff's theorem at the operator level and delineate the electronic and nuclear operators whose atomic matrix elements generate corrections to \"Schiff screening\". We obtain a form for the operator responsible for the leading correction associated with finite nuclear size -- the so-called \"Schiff moment\" operator -- and observe that it differs from the corresponding operator used in previous Schiff moment computations. We show that the more general Schiff moment operator reduces to the previously employed operator only under certain approximations that are not generally justified. We also identify other corrections to Schiff screening that may not be included properly in previous theoretical treatments. We discuss practical considerations for obtaining a complete computation of corrections to Schiff screening in atomic EDM calculations. ", "machine_text": " Investigations into the longevity of electric dipole moments (EDMs) of diamagnetic atoms prove as dependable measures of CP-violating hadronic and semi-leptonic interactions. As such, interpretation of the results of these experiments necessitate cautious enforcement of the widely observed theorem devised by Schiff, postulating a lack of a permanent EDM in an atom made entirely of point- like non- relativistic constituents interacting only electrostatically. Conversely, any perceived non-zero atomic EDM would trace back to deviations in the point-like, non-relativistic, electrostatic theory. We herein restate Schiff's theorem on the operator level and compile a distribution of atomic matrix elements from both electronic and nuclear operators tending to invalidate the suggestive \"Schiff screening\". We also enunciate a pattern for the frontrunner of such deviations -- the \"Schiff moment\" operator, which varies in contrast to the already utilized operators in earlier Schiff moment estimations. We demonstrate that the more general Schiff moment operator defaults to prior use operators only under certain tolerances that are often not reasonable. Additionally, we distinguish other alterations to Schiff screening that may not have been previously involved in theoretical dealings. We further intend to decorate a comprehensive analysis of corrections to Schiff screening in atomic EDM estimations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1681}
{"prompt": "Rephrase the abstract of an article with title 'Sterile neutrino oscillations after first MiniBooNE results'.   In view of the recent results from the MiniBooNE experiment we revisit the global neutrino oscillation fit to short-baseline neutrino data by adding one or two sterile neutrinos with eV-scale masses to the three Standard Model neutrinos, and for the first time we consider also the global fit with three sterile neutrinos. Four-neutrino oscillations of the (3+1) type have been only marginally allowed before the recent MiniBooNE results, and become even more disfavored with the new data (at the level of $4\\sigma$). In the framework of so-called (3+2) five-neutrino mass schemes we find severe tension between appearance and disappearance experiments at the level of more than $3\\sigma$, and hence no satistfactory fit to the global data is possible in (3+2) schemes. This tension remains also when a third sterile neutrino is added, and the quality of the global fit does not improve significantly in a (3+3) scheme. It should be noted, however, that in models with more than one sterile neutrino the MiniBooNE results are in perfect agreement with the LSND appearance evidence, thanks to the possibility of CP violation available in such oscillation schemes. Furthermore, if disappearance data are not taken into account (3+2) oscillations provide an excellent fit to the full MiniBooNE spectrum including the event excess at low energies.  ", "human_text": "  In view of the recent results from the MiniBooNE experiment we revisit the global neutrino oscillation fit to short-baseline neutrino data by adding one or two sterile neutrinos with eV-scale masses to the three Standard Model neutrinos, and for the first time we consider also the global fit with three sterile neutrinos. Four-neutrino oscillations of the (3+1) type have been only marginally allowed before the recent MiniBooNE results, and become even more disfavored with the new data (at the level of $4\\sigma$). In the framework of so-called (3+2) five-neutrino mass schemes we find severe tension between appearance and disappearance experiments at the level of more than $3\\sigma$, and hence no satistfactory fit to the global data is possible in (3+2) schemes. This tension remains also when a third sterile neutrino is added, and the quality of the global fit does not improve significantly in a (3+3) scheme. It should be noted, however, that in models with more than one sterile neutrino the MiniBooNE results are in perfect agreement with the LSND appearance evidence, thanks to the possibility of CP violation available in such oscillation schemes. Furthermore, if disappearance data are not taken into account (3+2) oscillations provide an excellent fit to the full MiniBooNE spectrum including the event excess at low energies. ", "machine_text": "In light of recent outcomes from the MiniBooNE endeavor, we reexamine the worldwide neutrino oscillation fit of short-range neutrino information by including one or two sterile neutrinos with eV-scale masses to the three Standard Model neutrinos, and furthermore, consider the global fit with three sterile neutrinos for the first time. Prior to the currentMiniBooNE results, four-neutrino oscillations of the (3+1) type had just been slightly approved, and become much less desirable with the new data (at a 4-sigma level). In the setting of so-called (3+2) five-neutrino mass models we observe an extreme discrepancy between perceived and vanishing trials at a sum of 3-sigma or better, correspondingly, no satisfactory fit to the total information can be accomplished in (3+2) frames. This pressure stays unaltered when a third sterile neutrino is incorporated and the nature of the overall fit does not noticeable improve in a(3+3) plan. In any case, it should be noticed that in models with in excess of one sterile neutrino the MiniBooNE outcomes coordinate perfectly with the LSND appearance proof, because of the presence of CP violation accessible in such oscillation plans. Moreover, if vanishing information isn't thought about,(3+2) oscillations give a superb fit to the complete MiniBooNE range including the occasion abundance at low energies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0107}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological perturbations in Palatini modified gravity'.   Two approaches to the study of cosmological density perturbations in modified theories of Palatini gravity have recently been discussed. These utilise, respectively, a generalisation of Birkhoff's theorem and a direct linearization of the gravitational field equations. In this paper these approaches are compared and contrasted. The general form of the gravitational lagrangian for which the two frameworks yield identical results in the long-wavelength limit is derived. This class of models includes the case where the lagrangian is a power-law of the Ricci curvature scalar. The evolution of density perturbations in theories of the type $f(R)=R-c /R^ b$ is investigated numerically. It is found that the results obtained by the two methods are in good agreement on sufficiently large scales when the values of the parameters (b,c) are consistent with current observational constraints. However, this agreement becomes progressively poorer for models that differ significantly from the standard concordance model and as smaller scales are considered.  ", "human_text": "  Two approaches to the study of cosmological density perturbations in modified theories of Palatini gravity have recently been discussed. These utilise, respectively, a generalisation of Birkhoff's theorem and a direct linearization of the gravitational field equations. In this paper these approaches are compared and contrasted. The general form of the gravitational lagrangian for which the two frameworks yield identical results in the long-wavelength limit is derived. This class of models includes the case where the lagrangian is a power-law of the Ricci curvature scalar. The evolution of density perturbations in theories of the type $f(R)=R-c /R^ b$ is investigated numerically. It is found that the results obtained by the two methods are in good agreement on sufficiently large scales when the values of the parameters (b,c) are consistent with current observational constraints. However, this agreement becomes progressively poorer for models that differ significantly from the standard concordance model and as smaller scales are considered. ", "machine_text": " This paper provides a comparison of two different ways to understand cosmological density perturbations in Palatini modified gravity. The first involves a generalization of Birkhoff's theorem and the second is through a linearization of the gravitational field equations. The findings are used to determine a general form for the gravitational lagrangian that produces the same results for the long wave limit. Additionally, the perturbation evolution for a certain type of lagrangian (with parameters b and c) is calculated, with results that match up to the observational data. It is also noted that these results don't hold up for models deviating greatly from the standard concordance model and on increasingly smaller scales.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0232}
{"prompt": "Rephrase the abstract of an article with title 'Systematic analysis of a spin-susceptibility representation of the   pairing interaction in the 2D Hubbard model'.   A dynamic cluster quantum Monte Carlo algorithm is used to study a spin susceptibility representation of the pairing interaction for the two-dimensional Hubbard model with an on-site Coulomb interaction equal to the bandwidth for various doping levels. We find that the pairing interaction is well approximated by ${3/2}\\Ub(T)^2\\chi(K-K')$ with an effective temperature and doping dependent coupling $\\Ub(T)$ and the numerically calculated spin susceptibility $\\chi(K-K')$. We show that at low temperatures, $\\Ub$ may be accurately determined from a corresponding spin susceptibility based calculation of the single-particle self-energy. We conclude that the strength of the d-wave pairing interaction, characterized by the mean-field transition temperature, can be determined from a knowledge of the dressed spin susceptibility and the nodal quasiparticle spectral weight. This has important implications with respect to the questions of whether spin fluctuations are responsible for pairing in the high-T$_c$ cuprates.  ", "human_text": "  A dynamic cluster quantum Monte Carlo algorithm is used to study a spin susceptibility representation of the pairing interaction for the two-dimensional Hubbard model with an on-site Coulomb interaction equal to the bandwidth for various doping levels. We find that the pairing interaction is well approximated by ${3/2}\\Ub(T)^2\\chi(K-K')$ with an effective temperature and doping dependent coupling $\\Ub(T)$ and the numerically calculated spin susceptibility $\\chi(K-K')$. We show that at low temperatures, $\\Ub$ may be accurately determined from a corresponding spin susceptibility based calculation of the single-particle self-energy. We conclude that the strength of the d-wave pairing interaction, characterized by the mean-field transition temperature, can be determined from a knowledge of the dressed spin susceptibility and the nodal quasiparticle spectral weight. This has important implications with respect to the questions of whether spin fluctuations are responsible for pairing in the high-T$_c$ cuprates. ", "machine_text": "  This work utilizes a dynamic cluster quantum Monte Carlo algorithm to analyze the spin susceptibility representation of the pairing interaction in the two-dimensional Hubbard model with an on-site Coulomb interaction equal to the bandwidth for different doping levels. It was determined that the pairing interaction is approximately ${3/2}\\Ub(T)^2\\chi(K-K')$ with a temperature and doping dependent coupling $\\Ub(T)$ and the numerically calculated spin susceptibility $\\chi(K-K')$. Low temperatures were found to be accurately expressed in terms of the single-particle self-energy when the spin susceptibility was incorporated. Our findings suggest that the strength of d-wave pairing, which is marked by the mean-field transition temperature, can be established through the use of dressed spin susceptibility and the nodal quasiparticle spectral weight. As a result, these studies have crucial implications in regards to the question of whether spin fluctuations are responsible for pairing in the high-T$_c$ cuprates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0241}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic rays and the primordial gas'.   One of the most outstanding problems in the gravitational collapse scenario of early structure formation is the cooling of primordial gas to allow for small mass objects to form. As the neutral primordial gas is a poor radiator at temperatures (T\\le10^4\\unit{K}), molecular hydrogen is needed for further cooling down to temperatures (T\\sim100\\unit{K}). The formation of molecular hydrogen is catalyzed by the presence of free electrons, which could be provided by the ionization due to an early population of cosmic rays. In order to investigate this possibility we developed a code to study the effects of ionizing cosmic rays on the thermal and chemical evolution of primordial gas. We found that cosmic rays can provide enough free electrons needed for the formation of molecular hydrogen, and therefore can increase the cooling ability of such primordial gas under following conditions: A dissociating photon flux with (F<10^{-18}\\unit{erg cm^{-2} Hz^{-1} s^{-1}}), initial temperature of the gas (\\sim10^{3}\\unit{K}), total gas number densities (n\\ge1\\unit{cm^{-3}}), Cosmic ray sources with (\\dot{\\epsilon}_{CR}>10^{-33}\\unit{erg cm^{-3} s^{-1}}).  ", "human_text": "  One of the most outstanding problems in the gravitational collapse scenario of early structure formation is the cooling of primordial gas to allow for small mass objects to form. As the neutral primordial gas is a poor radiator at temperatures (T\\le10^4\\unit{K}), molecular hydrogen is needed for further cooling down to temperatures (T\\sim100\\unit{K}). The formation of molecular hydrogen is catalyzed by the presence of free electrons, which could be provided by the ionization due to an early population of cosmic rays. In order to investigate this possibility we developed a code to study the effects of ionizing cosmic rays on the thermal and chemical evolution of primordial gas. We found that cosmic rays can provide enough free electrons needed for the formation of molecular hydrogen, and therefore can increase the cooling ability of such primordial gas under following conditions: A dissociating photon flux with (F<10^{-18}\\unit{erg cm^{-2} Hz^{-1} s^{-1}}), initial temperature of the gas (\\sim10^{3}\\unit{K}), total gas number densities (n\\ge1\\unit{cm^{-3}}), Cosmic ray sources with (\\dot{\\epsilon}_{CR}>10^{-33}\\unit{erg cm^{-3} s^{-1}}). ", "machine_text": " This study examines the possible role of cosmic rays in the thermal and chemical evolution of primordial gas. It is proposed that an early population of cosmic rays may introduce enough free electrons to enable the formation of molecular hydrogen, therefore cooling the gas to temperatures as low as 100K. A code was developed to simulate these effects, with findings that cosmic rays can help with cooling under specific conditions, for example an intensity of dissociating photons less than 10^(-18)erg cm^(-2) s^(-1), an initial temperature of ~ 10^3 K, number densities greater than or equal to 1 cm^(-3) and cosmic ray sources producing a rate greater than 10^(-33) erg cm^(-3) s^(-1).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4541}
{"prompt": "Rephrase the abstract of an article with title 'Yield design formulation for porous media subjected to flow, using   approximate pressure field. Calcul \\`a la rupture en pr\\'esence d'un   \\'ecoulement : formulation cin\\'ematique avec un champ de pression approch\\'e'.   Yield design formulation for porous media subjected to flow, using approximate pressure field. We attempt here to use the kinematic method of yield design in the case of a porous medium subjected to flow (with or without free surface), without looking for the exact solution of the pressure field. The method proposed here is based on the use of approximate pressure fields. In this paper, we show how, under different conditions concerning the yield criterion and the velocity field, the use of such approximate fields allows to obtain a necessary condition for stability without having to find the real pressure field. Nous cherchons ici \\`a utiliser la m\\'ethode cin\\'ematique du calcul \\`a la rupture dans le cas d'un milieu poreux soumis \\`a un \\'ecoulement avec ou sans surface libre sans conna\\^itre la solution exacte du champ de pression. La m\\'ethode propos\\'ee ici repose sur l'utilisation de champs de pression approch\\'es par d\\'efaut. Nous montrerons comment sous certaines conditions portant sur le crit\\`ere de r\\'esistance et sur le champ de vitesse utilis\\'e, l'utilisation de tels champs de pression approch\\'es permet d'obtenir une condition n\\'ecessaire de stabilit\\'e sans avoir \\`a d\\'eterminer exactement l'\\'ecoulement.  ", "human_text": "  Yield design formulation for porous media subjected to flow, using approximate pressure field. We attempt here to use the kinematic method of yield design in the case of a porous medium subjected to flow (with or without free surface), without looking for the exact solution of the pressure field. The method proposed here is based on the use of approximate pressure fields. In this paper, we show how, under different conditions concerning the yield criterion and the velocity field, the use of such approximate fields allows to obtain a necessary condition for stability without having to find the real pressure field. Nous cherchons ici \\`a utiliser la m\\'ethode cin\\'ematique du calcul \\`a la rupture dans le cas d'un milieu poreux soumis \\`a un \\'ecoulement avec ou sans surface libre sans conna\\^itre la solution exacte du champ de pression. La m\\'ethode propos\\'ee ici repose sur l'utilisation de champs de pression approch\\'es par d\\'efaut. Nous montrerons comment sous certaines conditions portant sur le crit\\`ere de r\\'esistance et sur le champ de vitesse utilis\\'e, l'utilisation de tels champs de pression approch\\'es permet d'obtenir une condition n\\'ecessaire de stabilit\\'e sans avoir \\`a d\\'eterminer exactement l'\\'ecoulement. ", "machine_text": "This paper presents a yield design formulation for porous media subjected to flow, using approximate pressure field instead of the exact pressure field.  We describe how under certain conditions concerning the yield criterion and the velocity field, the approximate fields enable to obtain a necessary condition for stability. This kinematic method allows us a better understanding of different aspect of the flow in such porous media.   Ce document pr\\'esente une formulation du calcul \\`a la rupture pour un milieu poreux soumis \\`a un \\'ecoulement, en utilisant un champ de pression approch\\'e au lieu du champ de pression exact.  Nous expliquons comment dans certaines conditions concernant le crit\\`ere de r\\'esistance et le champ de vitesse, les champs de pression approximatifs permettent d'obtenir une condition n\\'ecessaire de stabilit\\'e. Cette m\\'ethode cin\\'ematique nous offre une meilleure compr\\'ehension des diff\\'erents aspects de l'\\'ecoulement dans un milieu poreux.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2364}
{"prompt": "Rephrase the abstract of an article with title 'Precision measurements of large scale structure with future type Ia   supernova surveys'.   Type Ia supernovae are currently the best known standard candles at cosmological distances. In addition to providing a powerful probe of dark energy they are an ideal source of information about the peculiar velocity field of the local universe. Even with the very small number of supernovae presently available it has been possible to measure the dipole and quadrupole of the local velocity field out to z~0.025. With future continuous all-sky surveys like the LSST project the luminosity distances of tens of thousands of nearby supernovae will be measured accurately. This will allow for a determination of the local velocity structure of the universe as a function of redshift with unprecedented accuracy, provided the redshifts of the host galaxies are known. Using catalogues of mock surveys we estimate that future low redshift supernova surveys will be able to probe sigma-8 to a precision of roughly 5% at 95% C.L. This is comparable to the precision in future galaxy and weak lensing surveys and with a relatively modest observational effort it will provide a crucial cross-check on future measurements of the matter power spectrum.  ", "human_text": "  Type Ia supernovae are currently the best known standard candles at cosmological distances. In addition to providing a powerful probe of dark energy they are an ideal source of information about the peculiar velocity field of the local universe. Even with the very small number of supernovae presently available it has been possible to measure the dipole and quadrupole of the local velocity field out to z~0.025. With future continuous all-sky surveys like the LSST project the luminosity distances of tens of thousands of nearby supernovae will be measured accurately. This will allow for a determination of the local velocity structure of the universe as a function of redshift with unprecedented accuracy, provided the redshifts of the host galaxies are known. Using catalogues of mock surveys we estimate that future low redshift supernova surveys will be able to probe sigma-8 to a precision of roughly 5% at 95% C.L. This is comparable to the precision in future galaxy and weak lensing surveys and with a relatively modest observational effort it will provide a crucial cross-check on future measurements of the matter power spectrum. ", "machine_text": " The rigorous determination of cosmological parameters such as dark energy and the measurement of large-scale structure quantities like sigma-8 require highly accurate probes of peculiar velocities in the universe. Type Ia supernova surveys promise to provide just such results. Based on a small number of supernovae presently available, it is already possible to measure the dipole and quadrupole of the local velocity field out to z ~ 0.025. With an upcoming continuous all-sky survey like the Large Synoptic Survey Telescope (LSST), various luminosity distances of the surrounding supernovae can be accurately recorded. This will allow for higher precision characterizations of local velocity fields of the universe, given that the host galaxy's redshifts are known. Utilizing mock catalogues from survey projections, it can be estimated that a future supernova survey has the ability to measure sigma-8 with a roughly 5% precision at 95%C.L. This level of performance is nearly comparable to upcoming galaxy and weak lensing surveys, requiring relatively little observation effort for such a major confirmation of the matter power spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0979}
{"prompt": "Rephrase the abstract of an article with title 'Notes on Liouville Theory at c<=1'.   The continuation of the Liouville conformal field theory to c<=1 is considered. The viability of an interpretation involving a timelike boson which is the conformal factor for two-dimensional asymptotically de Sitter geometries is examined. The conformal bootstrap leads to a three-point function with a unique analytic factor which is the same as that which appears along with the fusion coefficients in the minimal models. A corresponding non-analytic factor produces a well-defined metric on fields only when the central charge is restricted to those of the topological minimal models, and when the conformal dimensions satisfy h>(c-1)/24. However, the theories considered here have a continuous spectrum which excludes the degenerate representations appearing in the minimal models. The c=1 theory has been investigated previously using similar techniques, and is identical to a non-rational CFT which arises as a limit of unitary minimal models. When coupled to unitary matter fields, the non-unitary theories with c<=-2 produce string amplitudes which are similar to those of the minimal string.  ", "human_text": "  The continuation of the Liouville conformal field theory to c<=1 is considered. The viability of an interpretation involving a timelike boson which is the conformal factor for two-dimensional asymptotically de Sitter geometries is examined. The conformal bootstrap leads to a three-point function with a unique analytic factor which is the same as that which appears along with the fusion coefficients in the minimal models. A corresponding non-analytic factor produces a well-defined metric on fields only when the central charge is restricted to those of the topological minimal models, and when the conformal dimensions satisfy h>(c-1)/24. However, the theories considered here have a continuous spectrum which excludes the degenerate representations appearing in the minimal models. The c=1 theory has been investigated previously using similar techniques, and is identical to a non-rational CFT which arises as a limit of unitary minimal models. When coupled to unitary matter fields, the non-unitary theories with c<=-2 produce string amplitudes which are similar to those of the minimal string. ", "machine_text": "In this article, the aspects of Liouville Theory in relation to c<=1 are discussed. The analysis includes an examination of whether an interpretation with a timelike boson coincides with two-dimensional de Sitter asymptotic geometry. The conformal bootstrap further leads to a singular three-point function. Adding a metric on fields brings the conformal charge to the degenerate values of the topological minimal models. Regarding the continuous spectrum, the methods employed here differ compared to those of the minimal models. Prior studies of c=1 theory have demonstrted that it is analogous to a non-rational CFT, which arises in the limit of the unitary minimal models. Additionally, coupling the non-unitary theories with c<=-2 to unitary matter fields have resulted in string amplitudes reminiscent of the minimal strings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0365}
{"prompt": "Rephrase the abstract of an article with title 'A Finite Element framework for computation of protein normal modes and   mechanical response'.   A coarse-grained computational procedure based on the Finite Element Method is proposed to calculate the normal modes and mechanical response of proteins and their supramolecular assemblies. Motivated by the elastic network model, proteins are modeled as homogeneous isotropic elastic solids with volume defined by their solvent-excluded surface. The discretized Finite Element representation is obtained using a surface simplification algorithm that facilitates the generation of models of arbitrary prescribed spatial resolution. The procedure is applied to compute the normal modes of a mutant of T4 phage lysozyme and of filamentous actin, as well as the critical Euler buckling load of the latter when subject to axial compression. Results compare favorably with all-atom normal mode analysis, the Rotation Translation Blocks procedure, and experiment. The proposed methodology establishes a computational framework for the calculation of protein mechanical response that facilitates the incorporation of specific atomic-level interactions into the model, including aqueous-electrolyte-mediated electrostatic effects. The procedure is equally applicable to proteins with known atomic coordinates as it is to electron density maps of proteins, protein complexes, and supramolecular assemblies of unknown atomic structure.  ", "human_text": "  A coarse-grained computational procedure based on the Finite Element Method is proposed to calculate the normal modes and mechanical response of proteins and their supramolecular assemblies. Motivated by the elastic network model, proteins are modeled as homogeneous isotropic elastic solids with volume defined by their solvent-excluded surface. The discretized Finite Element representation is obtained using a surface simplification algorithm that facilitates the generation of models of arbitrary prescribed spatial resolution. The procedure is applied to compute the normal modes of a mutant of T4 phage lysozyme and of filamentous actin, as well as the critical Euler buckling load of the latter when subject to axial compression. Results compare favorably with all-atom normal mode analysis, the Rotation Translation Blocks procedure, and experiment. The proposed methodology establishes a computational framework for the calculation of protein mechanical response that facilitates the incorporation of specific atomic-level interactions into the model, including aqueous-electrolyte-mediated electrostatic effects. The procedure is equally applicable to proteins with known atomic coordinates as it is to electron density maps of proteins, protein complexes, and supramolecular assemblies of unknown atomic structure. ", "machine_text": "This article presents a Finite Element framework for obtaining the normal modes and mechanical responses of proteins and assemblies of proteins. Motivated by the Elastic Network model, these proteins are modeled as uniform and anisotropic elastic solids with volume defined by their solvent-excluded surface. A surface simplification algorithm is used to represent the Finite Element structure which aids in generating models of various spatial resolutions. The procedure is applied to a T4 phage lysozyme mutant and a filamentous actin to determine their normal modes as well as the critical Euler buckling load when subject to axial compression. The results of this method favorably compare with experimental data, Rotation Translation Blocks and all-atom normal mode analyses. This procedure can incorporate atomic-level interactions, such as aqueous-electrolyte-mediated electrostatics, and can be usedon proteins with or without known atomic coordinates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0634}
{"prompt": "Rephrase the abstract of an article with title 'The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The   Serpens YSO Population As Observed With IRAC and MIPS'.   We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy observations of the Serpens star-forming region. In particular we present a set of criteria for isolating bona fide young stellar objects, YSO's, from the extensive background contamination by extra-galactic objects. We then discuss the properties of the resulting high confidence set of YSO's. We find 235 such objects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An additional set of 51 lower confidence YSO's outside this area is identified from the MIPS data combined with 2MASS photometry. We describe two sets of results, color-color diagrams to compare our observed source properties with those of theoretical models for star/disk/envelope systems and our own modeling of the subset of our objects that appear to be star+disks. These objects exhibit a very wide range of disk properties, from many that can be fit with actively accreting disks to some with both passive disks and even possibly debris disks. We find that the luminosity function of YSO's in Serpens extends down to at least a few x .001 Lsun or lower for an assumed distance of 260 pc. The lower limit may be set by our inability to distinguish YSO's from extra-galactic sources more than by the lack of YSO's at very low luminosities. A spatial clustering analysis shows that the nominally less-evolved YSO's are more highly clustered than the later stages and that the background extra-galactic population can be fit by the same two-point correlation function as seen in other extra-galactic studies. We also present a table of matches between several previous infrared and X-ray studies of the Serpens YSO population and our Spitzer data set.  ", "human_text": "  We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy observations of the Serpens star-forming region. In particular we present a set of criteria for isolating bona fide young stellar objects, YSO's, from the extensive background contamination by extra-galactic objects. We then discuss the properties of the resulting high confidence set of YSO's. We find 235 such objects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An additional set of 51 lower confidence YSO's outside this area is identified from the MIPS data combined with 2MASS photometry. We describe two sets of results, color-color diagrams to compare our observed source properties with those of theoretical models for star/disk/envelope systems and our own modeling of the subset of our objects that appear to be star+disks. These objects exhibit a very wide range of disk properties, from many that can be fit with actively accreting disks to some with both passive disks and even possibly debris disks. We find that the luminosity function of YSO's in Serpens extends down to at least a few x .001 Lsun or lower for an assumed distance of 260 pc. The lower limit may be set by our inability to distinguish YSO's from extra-galactic sources more than by the lack of YSO's at very low luminosities. A spatial clustering analysis shows that the nominally less-evolved YSO's are more highly clustered than the later stages and that the background extra-galactic population can be fit by the same two-point correlation function as seen in other extra-galactic studies. We also present a table of matches between several previous infrared and X-ray studies of the Serpens YSO population and our Spitzer data set. ", "machine_text": " This work presents an analysis of the c2d Spitzer Legacy observations of the star-forming region of Serpens. We propose criteria to distinguish genuine young stellar objects, YSOs, from the contamination by extra-galactic sources. Using these criteria, we record 286 YSOs in total, 7.5% of which have been identified by previous infrared and X-ray studies. We further analyse the colors of the observed sources and compare them with those of theoretical star/disk/envelope models. Objects that appear to be stars plus disks, to the extent of our observational capacity, demonstrate a diverse range of disk properties from active disks to passive disks and even debris disks. We also observe that the luminosity function of YSOs in Serpens extends at least to 0.001 Lsun or lower for a 260-pc distance. Additionally, we observe that less evolved YSOs tend to be more clustered from a spatial correlation analysis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0009}
{"prompt": "Rephrase the abstract of an article with title 'Red Sequence Cluster Finding in the Millennium Simulation'.   We investigate halo mass selection properties of red-sequence cluster finders using galaxy populations of the Millennium Simulation (MS). A clear red sequence exists for MS galaxies in massive halos at redshifts z < 1, and we use this knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h projections of the simulated volume. At low redshift (z=0.4), we find that 90% of the clusters found have galaxy membership dominated by a single, real-space halo, and that 10% are blended systems for which no single halo contributes a majority of a cluster's membership. At z=1, the fraction of blends increases to 22%, as weaker redshift evolution in observed color extends the comoving length probed by a fixed range of color. Other factors contributing to the increased blending at high-z include broadening of the red sequence and confusion from a larger number of intermediate mass halos hosting bright red galaxies of magnitude similar to those in higher mass halos. Our method produces catalogs of cluster candidates whose halo mass selection function, p(M|\\Ngal,z), is characterized by a bimodal log-normal model with a dominant component that reproduces well the real-space distribution, and a redshift-dependent tail that is broader and displaced by a factor ~2 lower in mass. We discuss implications for X-ray properties of optically selected clusters and offer ideas for improving both mock catalogs and cluster-finding in future surveys.  ", "human_text": "  We investigate halo mass selection properties of red-sequence cluster finders using galaxy populations of the Millennium Simulation (MS). A clear red sequence exists for MS galaxies in massive halos at redshifts z < 1, and we use this knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h projections of the simulated volume. At low redshift (z=0.4), we find that 90% of the clusters found have galaxy membership dominated by a single, real-space halo, and that 10% are blended systems for which no single halo contributes a majority of a cluster's membership. At z=1, the fraction of blends increases to 22%, as weaker redshift evolution in observed color extends the comoving length probed by a fixed range of color. Other factors contributing to the increased blending at high-z include broadening of the red sequence and confusion from a larger number of intermediate mass halos hosting bright red galaxies of magnitude similar to those in higher mass halos. Our method produces catalogs of cluster candidates whose halo mass selection function, p(M|\\Ngal,z), is characterized by a bimodal log-normal model with a dominant component that reproduces well the real-space distribution, and a redshift-dependent tail that is broader and displaced by a factor ~2 lower in mass. We discuss implications for X-ray properties of optically selected clusters and offer ideas for improving both mock catalogs and cluster-finding in future surveys. ", "machine_text": " We analyze the power of red sequence cluster finders on an array of galaxies from the Millennium Simulation (MS). We find that for low redshifts (z=0.4) the majority of clusters identified had a single halo with the remaining 10% questioning whether any single halo had credit for majority of the cluster's membership. Far with redshift (z=1), this increased to 22%, thus more challenging the red sequence cluster finder. This was mainly due to weaker red shift evolution of color and further confusion due to larger number of intermediate halos with bright red galaxies of magnitude similar to those in higher mass halos. We then developed a model that would describe a bimodal log-normal shaped mass selection function (p(M|\\Ngal,z)) which reproduced the real space distribution. We also investigated the effect on X-ray properties of optically selected clusters and suggest approaches to better improve the current mock catalogs being used.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0211}
{"prompt": "Rephrase the abstract of an article with title 'Phase resolved measurements of stimulated emission'.   The development of the semiconductor quantum cascade laser (QCL) [1] has enabled bright coherent sources operating at frequencies between the optical (>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for fundamental science investigations [2-5] as well as for applications [6]. However, detailed information about the internal processes in QCLs and their ultrafast dynamics are needed for their further development towards high output power, longer wavelengths and stable pulsed operation. We introduce a novel approach to study the gain and dynamics of a terahertz (THz) QCL [7] using phase resolved measurements of the stimulated emission. This is enabled by direct recording of the emitted electric field with <100 fs time resolution. For the case of the THz QCL we demonstrate the validity of the quantum mechanical description of the laser. We show for the first time the real bandwidth of the terahertz gain medium, the current dependence of this gain, and the losses associated with the wave propagation in the laser waveguide.  ", "human_text": "  The development of the semiconductor quantum cascade laser (QCL) [1] has enabled bright coherent sources operating at frequencies between the optical (>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for fundamental science investigations [2-5] as well as for applications [6]. However, detailed information about the internal processes in QCLs and their ultrafast dynamics are needed for their further development towards high output power, longer wavelengths and stable pulsed operation. We introduce a novel approach to study the gain and dynamics of a terahertz (THz) QCL [7] using phase resolved measurements of the stimulated emission. This is enabled by direct recording of the emitted electric field with <100 fs time resolution. For the case of the THz QCL we demonstrate the validity of the quantum mechanical description of the laser. We show for the first time the real bandwidth of the terahertz gain medium, the current dependence of this gain, and the losses associated with the wave propagation in the laser waveguide. ", "machine_text": "This study presents a novel phase-resolved measurements technique for the understanding of THz quantum cascade lasers. It provides detailed knowledge of the gain and dynamics of these lasers, linked to their ultrafast responses and internal processes. By recording the emitted electric fields with less than 100 femtoseconds resolution, information is gathered on the bandwidth of the THz laser\u2019s gain medium, its current dependence of the gain, and the waveguide losses associated. This research is expected to benefit the further development of these lasers towards improved output power, extended wavelengths and more reliable pulsed operations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2296}
{"prompt": "Rephrase the abstract of an article with title 'Multi-Color Photometry of the Galactic Globular Cluster M75 = NGC 6864.   A New Sensitive Metallicity Indicator and the Position of the Horizontal   Branch in UV'.   We carry out and analyze new multi-color photometry of the Galactic globular cluster (GC) M75 in UBVI and focus on the brighter sequences of the color- magnitude diagram (CMD), with particular emphasis on their location in U-based CMD. Specifically, we study the level both of the horizontal (HB) and red giant branches (RGB) relative to the main-sequence turnoff (TO) in the U magnitude. Along with the presented photometry of M75, we use our collection of photometric data on GCs belonging to the metal-poor range, [Fe/H]zw<-1.1 dex, obtained from observations with different equipment, but calibrated by standard stars situated in the observed cluster fields. We confirm our earlier finding, and extend it to a larger magnitude range.We demonstrate that DeltaU_{TO}^{BHB} expressing the difference in U magnitude between the TO point and the level of the blue HB, near its red boundary, of the metal-poor GCs observed with the EMMI camera of the NTT/ESO telescope is about 0.4-0.5 mag smaller as compared to GCs observed with the 100\" telescope and 1.3 m Warsaw telescope of the Las Campanas Observatory. At the same time, Delta U_{TO}^{RGB}, the difference in U magnitude between the TO and RGB inflection (brightest) points, does not show such an apparent dependence on the characteristics of U filters used, but it depends on cluster metallicity. We have shown, for the first time, the dependence of the parameter DeltaU_{TO}^{RGB} on [Fe/H] and have estimated its analytical expression, by assuming a linear relation between the parameter and metallicity. Its slope, Delta U_{TO}^{RGB}/Delta [Fe/H]~1.2 mag/dex, is approx. a factor of two steeper than that of the dependence of the RGB bump position in the V magnitude on metallicity. The asymptotic giant branch (AGB) clump and features of the RGB luminosity function (LF) of M75 are also discussed.  ", "human_text": "  We carry out and analyze new multi-color photometry of the Galactic globular cluster (GC) M75 in UBVI and focus on the brighter sequences of the color- magnitude diagram (CMD), with particular emphasis on their location in U-based CMD. Specifically, we study the level both of the horizontal (HB) and red giant branches (RGB) relative to the main-sequence turnoff (TO) in the U magnitude. Along with the presented photometry of M75, we use our collection of photometric data on GCs belonging to the metal-poor range, [Fe/H]zw<-1.1 dex, obtained from observations with different equipment, but calibrated by standard stars situated in the observed cluster fields. We confirm our earlier finding, and extend it to a larger magnitude range.We demonstrate that DeltaU_{TO}^{BHB} expressing the difference in U magnitude between the TO point and the level of the blue HB, near its red boundary, of the metal-poor GCs observed with the EMMI camera of the NTT/ESO telescope is about 0.4-0.5 mag smaller as compared to GCs observed with the 100\" telescope and 1.3 m Warsaw telescope of the Las Campanas Observatory. At the same time, Delta U_{TO}^{RGB}, the difference in U magnitude between the TO and RGB inflection (brightest) points, does not show such an apparent dependence on the characteristics of U filters used, but it depends on cluster metallicity. We have shown, for the first time, the dependence of the parameter DeltaU_{TO}^{RGB} on [Fe/H] and have estimated its analytical expression, by assuming a linear relation between the parameter and metallicity. Its slope, Delta U_{TO}^{RGB}/Delta [Fe/H]~1.2 mag/dex, is approx. a factor of two steeper than that of the dependence of the RGB bump position in the V magnitude on metallicity. The asymptotic giant branch (AGB) clump and features of the RGB luminosity function (LF) of M75 are also discussed. ", "machine_text": " We present a comprehensive analysis of multi-color photometry of the Galactic globular cluster (GC) M75, with a focus on the brighter sequences of the color-magnitude diagram (CMD) in U-based CMD. We use our own photometric data on GCs of [Fe/H]zw<-1.1 dex observed with different equipment, as well as present the new photometry results of M75. We demonstrate that Delta U_{TO}^{BHB} - the difference in U magnitude between the Turnoff point and the level of the blue Horizontal Branch near its red boundary - is about 0.4-0.5 mag smaller when observed with the EMMI camera of the NTT/ESO telescope than when observed with the 100\" telescope and 1.3 m Warsaw telescope of the Las Campanas Observatory. We also show, for the first time, the dependence between metallicity of the cluster and the parameter DeltaU_{TO}^{RGB}, the difference in U magnitude between the TO and RGB inflection points, with a slope of 1.2 mag/dex. Additionally, the asymptotic giant branch (AGB) clump and features of the RGB luminosity function (LF) of M75 are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2445}
{"prompt": "Rephrase the abstract of an article with title 'Dynamics of Baryons from String Theory and Vector Dominance'.   We consider a holographic model of QCD from string theory, a la Sakai and Sugimoto, and study baryons. In this model, mesons are collectively realized as a five-dimensional \\$U(N_F)=U(1)\\times SU(N_F)$ Yang-Mills field and baryons are classically identified as $SU(N_F)$ solitons with a unit Pontryagin number and $N_c$ electric charges. The soliton is shown to be very small in the large 't Hooft coupling limit, allowing us to introduce an effective field ${\\cal B}$. Its coupling to the mesons are dictated by the soliton structure, and consists of a direct magnetic coupling to the $SU(N_F)$ field strength as well as a minimal coupling to the $U(N_F)$ gauge field. Upon the dimensional reduction, this effective action reproduces all interaction terms between nucleons and an infinite tower of mesons in a manner consistent with the large $N_c$ expansion. We further find that all electromagnetic interactions, as inferred from the same effective action via a holographic prescription, are mediated by an infinite tower of vector mesons, rendering the baryon electromagnetic form factors completely vector-dominated as well. We estimate nucleon-meson couplings and also the anomalous magnetic moments, which compare well with nature.  ", "human_text": "  We consider a holographic model of QCD from string theory, a la Sakai and Sugimoto, and study baryons. In this model, mesons are collectively realized as a five-dimensional \\$U(N_F)=U(1)\\times SU(N_F)$ Yang-Mills field and baryons are classically identified as $SU(N_F)$ solitons with a unit Pontryagin number and $N_c$ electric charges. The soliton is shown to be very small in the large 't Hooft coupling limit, allowing us to introduce an effective field ${\\cal B}$. Its coupling to the mesons are dictated by the soliton structure, and consists of a direct magnetic coupling to the $SU(N_F)$ field strength as well as a minimal coupling to the $U(N_F)$ gauge field. Upon the dimensional reduction, this effective action reproduces all interaction terms between nucleons and an infinite tower of mesons in a manner consistent with the large $N_c$ expansion. We further find that all electromagnetic interactions, as inferred from the same effective action via a holographic prescription, are mediated by an infinite tower of vector mesons, rendering the baryon electromagnetic form factors completely vector-dominated as well. We estimate nucleon-meson couplings and also the anomalous magnetic moments, which compare well with nature. ", "machine_text": " In this research article, we examine baryonic behavior in a model of QCD from string theory created by Sakai and Sugimoto. We discover that mesons can form a unit five-dimensional \\$U(N_F) = U(1) \\times SU(N_F)$ Yang-Mills field, and baryons are classically represented as solitons with one Pontryagin number and electric charges that are equivalent to $N_c$. In the large 't Hooft coupling limit, the soliton is found to be quite small, allowing us to introduce an effective field $\\cal{B}$. This effective field connects to the mesons based on the structure of the soliton, and comes in the form of a direct magnetic connection to the $SU(N_F)$ power and a minimal connection to the $U(N_F)$ guide field. After dimension reduction, this analytic equation matches with all interaction terms between nucleons and an infinite amount of mesons in a way that is consistent with a large $N_c$ growth. Additionally, we found that all electromagnetic connections, resolved from the effective action with a holographic formula, are conveyed by an infinite number of vector mesons, which makes the baryon electromagnetic field factors completely vector-dominated. We estimate nucleon-meson attachments and anomalous magnetic moments, compared to nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2632}
{"prompt": "Rephrase the abstract of an article with title 'RNA polymerase motors on DNA track: effects of traffic congestion on RNA   synthesis'.   RNA polymerase (RNAP) is an enzyme that synthesizes a messenger RNA (mRNA) strand which is complementary to a single-stranded DNA template. From the perspective of physicists, an RNAP is a molecular motor that utilizes chemical energy input to move along the track formed by a ssDNA. In some circumstances, which are described in this paper, a large number of RNAPs move simultaneously along the same track. We refer to such collective movements of the RNAPs as RNAP traffic because of the similarities between the collective dynamics of the RNAPs on ssDNA track and that of vehicles in highway traffic. In this paper we develop a theoretical model for RNAP traffic by incorporating the steric interactions between RNAPs as well as the mechano-chemical cycle of individual RNAPs during the elongation of the mRNA. By a combination of analytical and numerical techniques, we calculate the rates of mRNA synthesis and the average density profile of the RNAPs on the ssDNA track. We also suggest novel experiments for testing our theoretical predictions.  ", "human_text": "  RNA polymerase (RNAP) is an enzyme that synthesizes a messenger RNA (mRNA) strand which is complementary to a single-stranded DNA template. From the perspective of physicists, an RNAP is a molecular motor that utilizes chemical energy input to move along the track formed by a ssDNA. In some circumstances, which are described in this paper, a large number of RNAPs move simultaneously along the same track. We refer to such collective movements of the RNAPs as RNAP traffic because of the similarities between the collective dynamics of the RNAPs on ssDNA track and that of vehicles in highway traffic. In this paper we develop a theoretical model for RNAP traffic by incorporating the steric interactions between RNAPs as well as the mechano-chemical cycle of individual RNAPs during the elongation of the mRNA. By a combination of analytical and numerical techniques, we calculate the rates of mRNA synthesis and the average density profile of the RNAPs on the ssDNA track. We also suggest novel experiments for testing our theoretical predictions. ", "machine_text": " This study investigates the behaviour of an ensemble of RNA polymerase enzymes that move along a single-stranded DNA template. Drawing parallels between the collective dynamics of the enzymes and highway traffic, we refer to this collective movement of the enzymes as 'RNAP traffic'. To elucidate the effects of crowded flows on RNA synthesis, we construct a theoretical model that incorporates steric interactions between the enzymes as well as individual motor cycles. Using analytical and numerical tools, our investigations analyze the rate of mRNA synthesis and average density profile of these enzymes, on the DNA track, as well as suggest experiments for testing the theoretical predictions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2115}
{"prompt": "Rephrase the abstract of an article with title 'Unicast and Multicast Qos Routing with Soft Constraint Logic Programming'.   We present a formal model to represent and solve the unicast/multicast routing problem in networks with Quality of Service (QoS) requirements. To attain this, first we translate the network adapting it to a weighted graph (unicast) or and-or graph (multicast), where the weight on a connector corresponds to the multidimensional cost of sending a packet on the related network link: each component of the weights vector represents a different QoS metric value (e.g. bandwidth, cost, delay, packet loss). The second step consists in writing this graph as a program in Soft Constraint Logic Programming (SCLP): the engine of this framework is then able to find the best paths/trees by optimizing their costs and solving the constraints imposed on them (e.g. delay < 40msec), thus finding a solution to QoS routing problems. Moreover, c-semiring structures are a convenient tool to model QoS metrics. At last, we provide an implementation of the framework over scale-free networks and we suggest how the performance can be improved.  ", "human_text": "  We present a formal model to represent and solve the unicast/multicast routing problem in networks with Quality of Service (QoS) requirements. To attain this, first we translate the network adapting it to a weighted graph (unicast) or and-or graph (multicast), where the weight on a connector corresponds to the multidimensional cost of sending a packet on the related network link: each component of the weights vector represents a different QoS metric value (e.g. bandwidth, cost, delay, packet loss). The second step consists in writing this graph as a program in Soft Constraint Logic Programming (SCLP): the engine of this framework is then able to find the best paths/trees by optimizing their costs and solving the constraints imposed on them (e.g. delay < 40msec), thus finding a solution to QoS routing problems. Moreover, c-semiring structures are a convenient tool to model QoS metrics. At last, we provide an implementation of the framework over scale-free networks and we suggest how the performance can be improved. ", "machine_text": " In this article, we develop a formal model for unicast and multicast routing of Quality of Service (QoS) requirements. To accomplish our goal, we first translate the network into a weighted graph or and-or graph, depending on whether it is a unicast or multicast. The weights of the connectors represent the multi-dimensional costs associated with each network link in terms of QoS metrics such as bandwidth, cost, and packet loss. We represent this graph using Soft Constraint Logic Programming (SCLP) and use the built-in engine to find the best paths/trees by optimizing their associated costs and fulfilling the imposed constraints. Additionally, we make use of c-semiring structures, enabling us to model the QoS metrics accurately. Finally, we provide an implementation for scale-free networks  and offer suggestions for improving performance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1783}
{"prompt": "Rephrase the abstract of an article with title 'Confining ensemble of dyons'.   We construct the integration measure over the moduli space of an arbitrary number of N kinds of dyons of the pure SU(N) gauge theory at finite temperatures. The ensemble of dyons governed by the measure is mathematically described by a (supersymmetric) quantum field theory that is exactly solvable and is remarkable for a number of striking features: 1) The free energy has the minimum corresponding to the zero average Polyakov line, as expected in the confining phase; 2)The correlation function of two Polyakov lines exhibits a linear potential between static quarks in any N-ality non-zero representation, with a calculable string tension roughly independent of temperature; 3) The average spatial Wilson loop falls off exponentially with its area and the same string tension; 4) At a critical temperature the ensemble of dyons rearranges and de-confines; 5)The estimated ratio of the critical temperature to the square root of the string tension is in excellent agreement with the lattice data.  ", "human_text": "  We construct the integration measure over the moduli space of an arbitrary number of N kinds of dyons of the pure SU(N) gauge theory at finite temperatures. The ensemble of dyons governed by the measure is mathematically described by a (supersymmetric) quantum field theory that is exactly solvable and is remarkable for a number of striking features: 1) The free energy has the minimum corresponding to the zero average Polyakov line, as expected in the confining phase; 2)The correlation function of two Polyakov lines exhibits a linear potential between static quarks in any N-ality non-zero representation, with a calculable string tension roughly independent of temperature; 3) The average spatial Wilson loop falls off exponentially with its area and the same string tension; 4) At a critical temperature the ensemble of dyons rearranges and de-confines; 5)The estimated ratio of the critical temperature to the square root of the string tension is in excellent agreement with the lattice data. ", "machine_text": " We present the integration measure over the moduli space of various sorts of dyons in a pure SU(N) gauge theory at finite temperatures. This ensemble of dyons is mathematically described by a (supersymmetric) quantum field theory that can be solved exactly. We observe several remarkable characteristics: one, the free energy has a minimum corresponding to the average Polyakov line as expected in the confining phase; two, the correlation between two Polyakov lines exhibits a linear potential between static quarks in any N-ality non-zero representation with a calculable string tension largely independent of the temperature; three, the average spatial Wilson loop falls off exponentially with the area and the same string tension; four, at a critical temperature the dyons rearrange and disconfine; five, the relative ratio of the critical temperature to the square root of the string tension is in high agreement with lattice data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3181}
{"prompt": "Rephrase the abstract of an article with title 'Modules over operads and functors'.   In the theory of operads we consider functors of generalized symmetric powers defined by sums of coinvariant modules under actions of symmetric groups. One observes classically that the construction of symmetric functors provides an isomorphism from the category of symmetric modules to a subcategory of the category of functors on the base category. The purpose of this book is to obtain a similar relationship for functors on a category of algebras over an operad.   We observe that right modules over operads, symmetric modules equipped with a right operad action, give rise to functors on categories of algebras and we prove that this construction yields an embedding of categories. Then we check that right modules over operads form a model category. In addition we prove that weak-equivalences of right modules correspond to pointwise weak-equivalences at the functor level. As a conclusion, we obtain that right modules over operads supply good models for the homotopy of associated functors on algebras over operads.  ", "human_text": "  In the theory of operads we consider functors of generalized symmetric powers defined by sums of coinvariant modules under actions of symmetric groups. One observes classically that the construction of symmetric functors provides an isomorphism from the category of symmetric modules to a subcategory of the category of functors on the base category. The purpose of this book is to obtain a similar relationship for functors on a category of algebras over an operad.   We observe that right modules over operads, symmetric modules equipped with a right operad action, give rise to functors on categories of algebras and we prove that this construction yields an embedding of categories. Then we check that right modules over operads form a model category. In addition we prove that weak-equivalences of right modules correspond to pointwise weak-equivalences at the functor level. As a conclusion, we obtain that right modules over operads supply good models for the homotopy of associated functors on algebras over operads. ", "machine_text": " This paper is devoted to investigating the relationships between functors on categories of algebras over operads and right modules over operads. We start by proving that right modules over operads give rise to functors on categories of algebras, and we demonstrate that this construction yields an embedding of categories. We then go further and show that right modules over operads form a model category. This notion allows us to investigate the correspondence between weak-equivalences of right modules and point-wise weak-equivalences at the functor level. We ultimately conclude that right modules over operads supply accurate models for the homotopy of their associated functors on algebras over operads.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.309}
{"prompt": "Rephrase the abstract of an article with title 'Entanglement transformations using separable operations'.   We study conditions for the deterministic transformation $\\ket{\\psi}\\longrightarrow\\ket{\\phi}$ of a bipartite entangled state by a separable operation. If the separable operation is a local operation with classical communication (LOCC), Nielsen's majorization theorem provides necessary and sufficient conditions. For the general case we derive a necessary condition in terms of products of Schmidt coefficients, which is equivalent to the Nielsen condition when either of the two factor spaces is of dimension 2, but is otherwise weaker. One implication is that no separable operation can reverse a deterministic map produced by another separable operation, if one excludes the case where the Schmidt coefficients of $\\ket{\\psi}$ and are the same as those of $\\ket{\\phi}$. The question of sufficient conditions in the general separable case remains open. When the Schmidt coefficients of $\\ket{\\psi}$ are the same as those of $\\ket{\\phi}$, we show that the Kraus operators of the separable transformation restricted to the supports of $\\ket{\\psi}$ on the factor spaces are proportional to unitaries. When that proportionality holds and the factor spaces have equal dimension, we find conditions for the deterministic transformation of a collection of several full Schmidt rank pure states $\\ket{\\psi_j}$ to pure states $\\ket{\\phi_j}$.  ", "human_text": "  We study conditions for the deterministic transformation $\\ket{\\psi}\\longrightarrow\\ket{\\phi}$ of a bipartite entangled state by a separable operation. If the separable operation is a local operation with classical communication (LOCC), Nielsen's majorization theorem provides necessary and sufficient conditions. For the general case we derive a necessary condition in terms of products of Schmidt coefficients, which is equivalent to the Nielsen condition when either of the two factor spaces is of dimension 2, but is otherwise weaker. One implication is that no separable operation can reverse a deterministic map produced by another separable operation, if one excludes the case where the Schmidt coefficients of $\\ket{\\psi}$ and are the same as those of $\\ket{\\phi}$. The question of sufficient conditions in the general separable case remains open. When the Schmidt coefficients of $\\ket{\\psi}$ are the same as those of $\\ket{\\phi}$, we show that the Kraus operators of the separable transformation restricted to the supports of $\\ket{\\psi}$ on the factor spaces are proportional to unitaries. When that proportionality holds and the factor spaces have equal dimension, we find conditions for the deterministic transformation of a collection of several full Schmidt rank pure states $\\ket{\\psi_j}$ to pure states $\\ket{\\phi_j}$. ", "machine_text": " This paper explores the possibility of using separable operations to transform one bipartite entangled state $\\ket{\\psi}$ into another $\\ket{\\phi}$. If the separable operation is a local operation with classical communication (LOCC), Nielsen's theorem states the necessary and sufficient conditions for the transformation to occur. When this isn't the case, we show that at least one necessary condition requires that products of the Schmidt coefficients of $\\ket{\\psi}$ and $\\ket{\\phi}$ be equal. As a result, it is not possible to use separable operations to reverse the transformation by another separable operation unless the Schmidt coefficients of $\\ket{\\psi}$ and $\\ket{\\phi}$ are the same. Furthermore, we examine the situation when the Schmidt coefficients are equal, deriving conditions for the deterministic transformation of a collection of several full Schmidt rank pure states $\\ket{\\psi_j}$ to pure states $\\ket{\\phi_j}$. Finally, we also present sufficient conditions for the general separable transformation, although further research is still necessary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0369}
{"prompt": "Rephrase the abstract of an article with title 'Equivalence of three-dimensional spacetimes'.   A solution to the equivalence problem in three-dimensional gravity is given and a practically useful method to obtain a coordinate invariant description of local geometry is presented. The method is a nontrivial adaptation of Karlhede invariant classification of spacetimes of general relativity. The local geometry is completely determined by the curvature tensor and a finite number of its covariant derivatives in a frame where the components of the metric are constants. The results are presented in the framework of real two-component spinors in three-dimensional spacetimes, where the algebraic classifications of the Ricci and Cotton-York spinors are given and their isotropy groups and canonical forms are determined. As an application we discuss Goedel-type spacetimes in three-dimensional General Relativity. The conditions for local space and time homogeneity are derived and the equivalence of three-dimensional Goedel-type spacetimes is studied and the results are compared with previous works on four-dimensional Goedel-type spacetimes.  ", "human_text": "  A solution to the equivalence problem in three-dimensional gravity is given and a practically useful method to obtain a coordinate invariant description of local geometry is presented. The method is a nontrivial adaptation of Karlhede invariant classification of spacetimes of general relativity. The local geometry is completely determined by the curvature tensor and a finite number of its covariant derivatives in a frame where the components of the metric are constants. The results are presented in the framework of real two-component spinors in three-dimensional spacetimes, where the algebraic classifications of the Ricci and Cotton-York spinors are given and their isotropy groups and canonical forms are determined. As an application we discuss Goedel-type spacetimes in three-dimensional General Relativity. The conditions for local space and time homogeneity are derived and the equivalence of three-dimensional Goedel-type spacetimes is studied and the results are compared with previous works on four-dimensional Goedel-type spacetimes. ", "machine_text": "This paper examines the equivalency problem concerning three-dimensional spacetimes. We provide a workable, coordinate-invariant approach to delineate the local structure of a given space. Our approach is based on Karlhede's invariant characterization of spacetime, the curvature tensor, and the Cotton-York spinors; the algebraic classification of these elements being integral to the formulation. We discuss a particular type of spacetime, Goedel-type, in the context of three-dimensional General Relativity, with the view of determining homogeneity in both space and time. These results are then contrasted with similar studies of four-dimensional Goedel-type spacetimes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0758}
{"prompt": "Rephrase the abstract of an article with title 'The Blazhko behaviour of RR Geminorum II -- long-term photometric   results'.   Context. RR Gem is one of the few Blazhko RR Lyrae that has photometric observations available extended enough to study the long-term courses of its pulsation and modulation properties in detail.   Aims. We investigate the pulsation and modulation properties and the relations between them in RR Gem using photometric observations from the past 70 years in order to gain further insight into the nature of the Blazhko modulation.   Methods. We studied the photographic, photoelectric, and CCD light curves obtained at the Konkoly Observatory and other authors' published maxima observations. Detailed analysis of the light curves, maximum brightness, and O-C data are carried out.   Results. RR Gem showed modulation most of the time it was observed. The modulation amplitude showed strong variations from the undetectable level (less than 0.04 mag in maximum brightness) to about 0.20 mag. The amplitudes of the amplitude and phase modulations showed parallel changes, thus the total 'power' of the modulation have changed during the past 70 years. Parallel changes in the pulsation and modulation periods occur with a d P_mod / d P_puls = 1.6 +/- 0.8 * 10^3 ratio. We also detected 0.05-0.1 mag changes in the mean maximum brightness and mean pulsation amplitude.  ", "human_text": "  Context. RR Gem is one of the few Blazhko RR Lyrae that has photometric observations available extended enough to study the long-term courses of its pulsation and modulation properties in detail.   Aims. We investigate the pulsation and modulation properties and the relations between them in RR Gem using photometric observations from the past 70 years in order to gain further insight into the nature of the Blazhko modulation.   Methods. We studied the photographic, photoelectric, and CCD light curves obtained at the Konkoly Observatory and other authors' published maxima observations. Detailed analysis of the light curves, maximum brightness, and O-C data are carried out.   Results. RR Gem showed modulation most of the time it was observed. The modulation amplitude showed strong variations from the undetectable level (less than 0.04 mag in maximum brightness) to about 0.20 mag. The amplitudes of the amplitude and phase modulations showed parallel changes, thus the total 'power' of the modulation have changed during the past 70 years. Parallel changes in the pulsation and modulation periods occur with a d P_mod / d P_puls = 1.6 +/- 0.8 * 10^3 ratio. We also detected 0.05-0.1 mag changes in the mean maximum brightness and mean pulsation amplitude. ", "machine_text": " The study explored the pulsation and modulation properties as well as the connection between them in RR Gem over a timespan of 70 years. A detailed analysis of the light curves, maximum brightness and O-C data was conducted. It was found that RR Gem was mostly modulated, with the total 'power' of the modulation changing over the observed time period. Changes in the modulation and pulsation periods were also observed and displayed a ratio of 1.6 +/- 0.8 * 10^3. As well as this, small changes in the mean maximum brightness and pulsation amplitude were detected.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3337}
{"prompt": "Rephrase the abstract of an article with title 'The impact of radio feedback from active galactic nuclei in cosmological   simulations: Formation of disk galaxies'.   In this paper, we present a new implementation of feedback due to active galactic nuclei (AGN) in cosmological simulations of galaxy formation. We assume that a fraction of jet energy, which is generated by an AGN, is transferred to the surrounding gas as thermal energy. Combining a theoretical model of mass accretion onto black holes with a multiphase description of star-forming gas, we self-consistently follow evolution of both galaxies and their central black holes. The novelty in our model is that we consider two distinct accretion modes: standard radiatively efficient thin accretion disks and radiatively inefficient accretion flows which we will generically refer to as RIAFs; motivated by theoretical models for jet production in accretion disks, we assume that only the RIAF is responsible for the AGN feedback. We find that, after an initial episode of bursting star formation, the accretion rate onto the central black hole drops so that the accretion disk switches to a RIAF structure. At this point, the feedback from the AGN becomes efficient and slightly suppresses star formation in the galactic disk and almost completely halts star formation in the bulge. As a result, the nucleus becomes a stochastically fuelled low-luminosity AGN (Seyfert galaxy) with recurrent short-lived episodes of activity after the star bursts. Our model predicts several properties of the low-luminosity AGN including the bolometric luminosity, jet powers, the effect on kpc-scale of the radio jet and the AGN lifetime, which are in broad agreement with observations of Seyfert galaxies and their radio activity. We also find that the mass ratios between the central black hole and the the host spheroid at z = 0 are ~10^{-3} regardless of the strength of either supernova feedback or AGN feedback. (abridged)  ", "human_text": "  In this paper, we present a new implementation of feedback due to active galactic nuclei (AGN) in cosmological simulations of galaxy formation. We assume that a fraction of jet energy, which is generated by an AGN, is transferred to the surrounding gas as thermal energy. Combining a theoretical model of mass accretion onto black holes with a multiphase description of star-forming gas, we self-consistently follow evolution of both galaxies and their central black holes. The novelty in our model is that we consider two distinct accretion modes: standard radiatively efficient thin accretion disks and radiatively inefficient accretion flows which we will generically refer to as RIAFs; motivated by theoretical models for jet production in accretion disks, we assume that only the RIAF is responsible for the AGN feedback. We find that, after an initial episode of bursting star formation, the accretion rate onto the central black hole drops so that the accretion disk switches to a RIAF structure. At this point, the feedback from the AGN becomes efficient and slightly suppresses star formation in the galactic disk and almost completely halts star formation in the bulge. As a result, the nucleus becomes a stochastically fuelled low-luminosity AGN (Seyfert galaxy) with recurrent short-lived episodes of activity after the star bursts. Our model predicts several properties of the low-luminosity AGN including the bolometric luminosity, jet powers, the effect on kpc-scale of the radio jet and the AGN lifetime, which are in broad agreement with observations of Seyfert galaxies and their radio activity. We also find that the mass ratios between the central black hole and the the host spheroid at z = 0 are ~10^{-3} regardless of the strength of either supernova feedback or AGN feedback. (abridged) ", "machine_text": " This paper investigates the impacts of feedback from active galactic nuclei (AGNs) in cosmological simulations of galaxy formation. We present a model which takes into account the mass-accretion into central black holes as well as multi-phase star formation within the gas to describe the evolution of both galaxies and the said black holes. A novel component of the model is that it acknowledges two modes of accretion: the usual thin, radiatively-efficient flows and alternatively, radiatively-inefficient flows referred to as RIAFs. It is assumed that only the latter produces the AGN feedback. Results show that subsequent to a burst of star formation, the rate of mass accretion declines and the flow of accretion transitions to a RIAF. This coincides with when the AGN feedback starts to diminish star formation in the galactic disks and brings star formation in the bulge almost to a halt. Our model predicts certain attributes of low-luminosity AGNs which match observations of Seyfert galaxies, such as bolometric luminosities and jet powers. Interestingly, an examination of the mass ratio of central black holes to the parent spheroid indicates that the ratio is almost the same regardless of the presence of either supernova feedback or AGN feedback.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1218}
{"prompt": "Rephrase the abstract of an article with title 'Weak decays of 4He-Lambda'.   We measured the lifetime and the mesonic and non-mesonic decay rates of the 4He-Lambda hypernucleus. The hypernuclei were created using a 750 MeV/c momentum K- beam on a liquid 4He target by the reaction 4He(K-,pi-)4He-Lambda. The 4He-Lambda lifetime was directly measured using protons from Lambda p -> n p non-mesonic decay (also referred to as proton-stimulated decay) and was found to have a value of tau = 245 +/- 24 ps. The mesonic decay rates were determined from the observed numbers of pi-'s and pi0's as Gamma_pi-/Gamma_tot = 0.270 +/- 0.024 and Gamma_pi0/Gamma_tot = 0.564 +/- 0.036, respectively, and the values of the proton- and neutron-stimulated decay rates were extracted as Gamma_p/Gamma_tot = 0.169 +/- 0.019 and Gamma_n/Gamma_tot <= 0.032 (95% CL), respectively. The effects of final-state interactions and possible 3-body Lambda N N decay contributions were studied in the context of a simple model of nucleon-stimulated decay. Nucleon-nucleon coincidence events were observed and were used in the determination of the non-mesonic branching fractions. The implications of the results of this analysis were considered for the empirical Delta I = 1/2 rule and the decay rates of the 4H-Lambda hypernucleus.  ", "human_text": "  We measured the lifetime and the mesonic and non-mesonic decay rates of the 4He-Lambda hypernucleus. The hypernuclei were created using a 750 MeV/c momentum K- beam on a liquid 4He target by the reaction 4He(K-,pi-)4He-Lambda. The 4He-Lambda lifetime was directly measured using protons from Lambda p -> n p non-mesonic decay (also referred to as proton-stimulated decay) and was found to have a value of tau = 245 +/- 24 ps. The mesonic decay rates were determined from the observed numbers of pi-'s and pi0's as Gamma_pi-/Gamma_tot = 0.270 +/- 0.024 and Gamma_pi0/Gamma_tot = 0.564 +/- 0.036, respectively, and the values of the proton- and neutron-stimulated decay rates were extracted as Gamma_p/Gamma_tot = 0.169 +/- 0.019 and Gamma_n/Gamma_tot <= 0.032 (95% CL), respectively. The effects of final-state interactions and possible 3-body Lambda N N decay contributions were studied in the context of a simple model of nucleon-stimulated decay. Nucleon-nucleon coincidence events were observed and were used in the determination of the non-mesonic branching fractions. The implications of the results of this analysis were considered for the empirical Delta I = 1/2 rule and the decay rates of the 4H-Lambda hypernucleus. ", "machine_text": " In this work, we quantified the lifetime and the mesonic and non-mesonic decay rates of 4He-Lambda hypernuclei. These hypernuclei were created through the reaction 4He(K-,\u03c0-)4He-Lambda at 750 MeV/c momentum. The lifetime of the 4He-Lambda hypernucleus was measured directly, given a value of \u03c4 = 245 \u00b1 24 ps. Further, the mesonic decay rates were quantified based on the number of pions and pion-zeros collected in the data, producing Gamma_\u03c0-/Gamma_tot = 0.270 \u00b1 0.024 and Gamma_\u03c00 / Gamma_tot = 0.564 \u00b1 0.036 respectively. The proton- and neutron-stimulated decay rates were further calculated from the data as Gamma_p / Gamma_tot = 0.169 \u00b1 0.019 and Gamma_n / Gamma_tot \u2264 0.032 (95% CL) respectively. The effects of the final-state interactions and possible three-body Lambda N N decay contributions are studied using a model of nucleon-stimulated decay. Furthermore, nucleon-nucleon coincidence events observed were used to draw inferences on the non-mesonic branching fractions. We also consider the implications of this study on the empirical Delta I = 1/2 rule and the decay rates of 4H-Lambda hypernucleus.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3311}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of Dust in Primordial Supernova Remnants: Can Dust Grains   Formed in the Ejecta Survive and be Injected into the Early Interstellar   Medium?'.   We investigate the evolution of dust that formed at Population III supernova (SN) explosions and its processing through the collisions with the reverse shocks resulting from the interaction of the SN ejecta with the ambient medium. In particular, we investigate the transport of the shocked dust within the SN remnant (SNR), and its effect on the chemical composition, the size distribution, and the total mass of dust surviving in SNR. We find that the evolution of the reverse shock, and hence its effect on the processing of the dust depends on the thickness of the envelope retained by the progenitor star. Furthermore, the transport and survival of the dust grains depend on their initial radius, a_{ini}, and composition: For Type II SNRs expanding into the interstellar medium (ISM) with a density of n_{H,0}=1 cm^{-3}, small grains with a_{ini} < ~ 0.05 micron are completely destroyed by sputtering in the postshock flow, while grains with a_{ini}= 0.05--0.2 micron are trapped into the dense shell behind the forward shock. Very large grains of a_{ini} > ~ 0.2 micron are ejected into the ISM without decreasing their sizes significantly. We find that the total mass fraction of dust that is destroyed by the reverse shock ranges from 0.2 to 1.0, depending on the energy of the explosion and the density of the ambient ISM. The results of our calculations have significant impact on the abundance pattern of subsequent generation of stars that form in the dense shell of primordial SNRs.  ", "human_text": "  We investigate the evolution of dust that formed at Population III supernova (SN) explosions and its processing through the collisions with the reverse shocks resulting from the interaction of the SN ejecta with the ambient medium. In particular, we investigate the transport of the shocked dust within the SN remnant (SNR), and its effect on the chemical composition, the size distribution, and the total mass of dust surviving in SNR. We find that the evolution of the reverse shock, and hence its effect on the processing of the dust depends on the thickness of the envelope retained by the progenitor star. Furthermore, the transport and survival of the dust grains depend on their initial radius, a_{ini}, and composition: For Type II SNRs expanding into the interstellar medium (ISM) with a density of n_{H,0}=1 cm^{-3}, small grains with a_{ini} < ~ 0.05 micron are completely destroyed by sputtering in the postshock flow, while grains with a_{ini}= 0.05--0.2 micron are trapped into the dense shell behind the forward shock. Very large grains of a_{ini} > ~ 0.2 micron are ejected into the ISM without decreasing their sizes significantly. We find that the total mass fraction of dust that is destroyed by the reverse shock ranges from 0.2 to 1.0, depending on the energy of the explosion and the density of the ambient ISM. The results of our calculations have significant impact on the abundance pattern of subsequent generation of stars that form in the dense shell of primordial SNRs. ", "machine_text": " We explore the fate of the dust that is produced through Population III supernova (SN) explosions in addition to its processing by reverse shocks from the SN ejecta's interaction with the ambient environment. We focus on the transport of the dust within the SN remnant (SNR), its effects on the composition, size and total mass that survives within the SNR. We observe changes in the reverse shock based on the thickness of the progenitor star's envelope, with the transport and endurance of the dust grains depending on their initial size and composition. Our research shows that small grains with an initial size of under 0.05 microns are obliterated in the postshock flow while grains with a size between 0.05-0.2 microns are caught in the dense layer behind the forward shock. Very large grains with an initial size of 0.2 microns or above are released into the interstellar medium (ISM) without a dramatic decrease in size. We compute the total mass fraction of dust that is destroyed by the reverse shock, varying between 0.2 and 1.0, contingent on the energy of the explosion and ISM density. Our findings could have a considerable effect on the abundance pattern of the stars formed in primordial SNRs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0383}
{"prompt": "Rephrase the abstract of an article with title 'Displacement of the Sun from the Galactic Plane'.   We have carried out a comparative statistical study for the displacement of the Sun from the Galactic plane (z_\\odot) following three different methods. The study has been done using a sample of 537 young open clusters (YOCs) with log(Age) < 8.5 lying within a heliocentric distance of 4 kpc and 2030 OB stars observed up to a distance of 1200 pc, all of them have distance information. We decompose the Gould Belt's member in a statistical sense before investigating the variation in the z_\\odot estimation with different upper cut-off limits in the heliocentric distance and distance perpendicular to the Galactic plane. We found z_\\odot varies in a range of ~ 13 - 20 pc from the analys is of YOCs and ~ 6 - 18 pc from the OB stars. A significant scatter in the z_\\odot obtained due to different cut-off values is noticed for the OB stars although no such deviation is seen for the YOCs. We also determined scale heights of 56.9(+3.8)(-3.4} and 61.4(+2.7)(-2.4) pc for the distribution of YOCs and OB stars respectively.  ", "human_text": "  We have carried out a comparative statistical study for the displacement of the Sun from the Galactic plane (z_\\odot) following three different methods. The study has been done using a sample of 537 young open clusters (YOCs) with log(Age) < 8.5 lying within a heliocentric distance of 4 kpc and 2030 OB stars observed up to a distance of 1200 pc, all of them have distance information. We decompose the Gould Belt's member in a statistical sense before investigating the variation in the z_\\odot estimation with different upper cut-off limits in the heliocentric distance and distance perpendicular to the Galactic plane. We found z_\\odot varies in a range of ~ 13 - 20 pc from the analys is of YOCs and ~ 6 - 18 pc from the OB stars. A significant scatter in the z_\\odot obtained due to different cut-off values is noticed for the OB stars although no such deviation is seen for the YOCs. We also determined scale heights of 56.9(+3.8)(-3.4} and 61.4(+2.7)(-2.4) pc for the distribution of YOCs and OB stars respectively. ", "machine_text": " We conducted an empirical study examining the Sun's displacement from the Galactic plane (z_\\odot) using three analytical methods. Our sample comprised of 537 young open clusters (YOCs) with an age logarithm of less than 8.5 and located within a heliocentric distance of 4 kpc, as well as 2030 OB stars observed up to a distance of 1200 pc and possessing distance information. We split the members of the Gould Belt into statistical subsections before analyzing z_\\odot for variation in line with different maximum values in the heliocentric distance and perpendicular distance to the Galactic plane. The z_\\odot for YOCs averaged between 13 and 20 pc, whilst for OB stars it fluctuated between 6 and 18 pc. There was a conspicuous inconsistency in the z_\\odot from the OB star analysis due to different limit values, while no such effect was noticed utilizing YOCs. Additionally, we identified scale heights of 56.9(+3.8)(-3.4) pc and 61.4(+2.7)(-2.4) pc for the distributions of YOCs and OB stars respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.095}
{"prompt": "Rephrase the abstract of an article with title 'Non-Parametric Field Estimation using Randomly Deployed, Noisy, Binary   Sensors'.   The reconstruction of a deterministic data field from binary-quantized noisy observations of sensors which are randomly deployed over the field domain is studied. The study focuses on the extremes of lack of deterministic control in the sensor deployment, lack of knowledge of the noise distribution, and lack of sensing precision and reliability. Such adverse conditions are motivated by possible real-world scenarios where a large collection of low-cost, crudely manufactured sensors are mass-deployed in an environment where little can be assumed about the ambient noise. A simple estimator that reconstructs the entire data field from these unreliable, binary-quantized, noisy observations is proposed. Technical conditions for the almost sure and integrated mean squared error (MSE) convergence of the estimate to the data field, as the number of sensors tends to infinity, are derived and their implications are discussed. For finite-dimensional, bounded-variation, and Sobolev-differentiable function classes, specific integrated MSE decay rates are derived. For the first and third function classes these rates are found to be minimax order optimal with respect to infinite precision sensing and known noise distribution.  ", "human_text": "  The reconstruction of a deterministic data field from binary-quantized noisy observations of sensors which are randomly deployed over the field domain is studied. The study focuses on the extremes of lack of deterministic control in the sensor deployment, lack of knowledge of the noise distribution, and lack of sensing precision and reliability. Such adverse conditions are motivated by possible real-world scenarios where a large collection of low-cost, crudely manufactured sensors are mass-deployed in an environment where little can be assumed about the ambient noise. A simple estimator that reconstructs the entire data field from these unreliable, binary-quantized, noisy observations is proposed. Technical conditions for the almost sure and integrated mean squared error (MSE) convergence of the estimate to the data field, as the number of sensors tends to infinity, are derived and their implications are discussed. For finite-dimensional, bounded-variation, and Sobolev-differentiable function classes, specific integrated MSE decay rates are derived. For the first and third function classes these rates are found to be minimax order optimal with respect to infinite precision sensing and known noise distribution. ", "machine_text": " This investigation examines the capability of estimating a deterministic field given unreliable, noisily-quantized, binary observations obtained from randomly deployed sensors. The primary focus is on strict conditions which make it impossible to know the noise distribution and guarantee the accuracy of the sensing precision and reliability. Real-world applications may involve deploying a wide array of economical, crudely produced sensors in environments with minimal to no data on the surrounding noise. This paper presents a simple way to reconstruct the entire data field from the aforementioned conditions. Among the details discussed are the strong convergence parameters of the estimator when the number of sensors is large, and integrated MSE decay rates for certain function classes. Additionally, for two of these classes, the decay rates are found to be optimally optimal with respect to known noise and infinite accuracy sensing.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0685}
{"prompt": "Rephrase the abstract of an article with title 'Path Integral Methods in the Su-Schrieffer-Heeger Polaron Problem'.   I propose a path integral description of the Su-Schrieffer-Heeger Hamiltonian, both in one and two dimensions, after mapping the real space model onto the time scale. While the lattice degrees of freedom are classical functions of time and are integrated out exactly, the electron particle paths are treated quantum mechanically. The method accounts for the variable range of the electronic hopping processes. The free energy of the system and its temperature derivatives are computed by summing at any $T$ over the ensemble of relevant particle paths which mainly contribute to the total partition function. In the low $T$ regime, the {\\it heat capacity over T} ratio shows un upturn peculiar to a glass-like behavior. This feature is more sizeable in the square lattice than in the linear chain as the overall hopping potential contribution to the total action is larger in higher dimensionality. The effects of the electron-phonon anharmonic interactions on the phonon subsystem are studied by the path integral cumulant expansion method.  ", "human_text": "  I propose a path integral description of the Su-Schrieffer-Heeger Hamiltonian, both in one and two dimensions, after mapping the real space model onto the time scale. While the lattice degrees of freedom are classical functions of time and are integrated out exactly, the electron particle paths are treated quantum mechanically. The method accounts for the variable range of the electronic hopping processes. The free energy of the system and its temperature derivatives are computed by summing at any $T$ over the ensemble of relevant particle paths which mainly contribute to the total partition function. In the low $T$ regime, the {\\it heat capacity over T} ratio shows un upturn peculiar to a glass-like behavior. This feature is more sizeable in the square lattice than in the linear chain as the overall hopping potential contribution to the total action is larger in higher dimensionality. The effects of the electron-phonon anharmonic interactions on the phonon subsystem are studied by the path integral cumulant expansion method. ", "machine_text": " The goal of this article is to employ path integral methods to study the Su-Schrieffer-Heeger polaron problem. The time and real space components of the Hamiltonian are both taken into account, with the electron particle paths being treated quantum mechanically and the lattice degrees of freedom integrated out exactly. By summing over a range of relevant particle paths which form the total partition function, the free energy and its temperature derivatives can be calculated. At low temperatures, the heat capacity over T ratio displays a growth pattern characteristic of glass-like behaviour, with the effects of electron-phonon anharmonic interactions explored by the cumulant expansion method. The square lattice, due to its larger overall hopping potential contribution, is found to show the strongest glass-like behaviour.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1428}
{"prompt": "Rephrase the abstract of an article with title 'Asymptotic Behavior of Total Times For Jobs That Must Start Over If a   Failure Occurs'.   Many processes must complete in the presence of failures. Different systems respond to task failure in different ways. The system may resume a failed task from the failure point (or a saved checkpoint shortly before the failure point), it may give up on the task and select a replacement task from the ready queue, or it may restart the task. The behavior of systems under the first two scenarios is well documented, but the third ({\\em RESTART}) has resisted detailed analysis. In this paper we derive tight asymptotic relations between the distribution of {\\em task times} without failures to the {\\em total time} when including failures, for any failure distribution. In particular, we show that if the task time distribution has an unbounded support then the total time distribution $H$ is always heavy-tailed. Asymptotic expressions are given for the tail of $H$ in various scenarios. The key ingredients of the analysis are the Cram\\'er--Lundberg asymptotics for geometric sums and integral asymptotics, that in some cases are obtained via Tauberian theorems and in some cases by bare-hand calculations.  ", "human_text": "  Many processes must complete in the presence of failures. Different systems respond to task failure in different ways. The system may resume a failed task from the failure point (or a saved checkpoint shortly before the failure point), it may give up on the task and select a replacement task from the ready queue, or it may restart the task. The behavior of systems under the first two scenarios is well documented, but the third ({\\em RESTART}) has resisted detailed analysis. In this paper we derive tight asymptotic relations between the distribution of {\\em task times} without failures to the {\\em total time} when including failures, for any failure distribution. In particular, we show that if the task time distribution has an unbounded support then the total time distribution $H$ is always heavy-tailed. Asymptotic expressions are given for the tail of $H$ in various scenarios. The key ingredients of the analysis are the Cram\\'er--Lundberg asymptotics for geometric sums and integral asymptotics, that in some cases are obtained via Tauberian theorems and in some cases by bare-hand calculations. ", "machine_text": " This paper examines the asymptotic behavior of total time when taking into account task failures. Two common ways of responding to failed tasks, resuming from a failure point or selecting a replacement task, are extensively documented. However, the paper focuses on a third alternative, referred to as RESTART, which has resisted detailed analysis until now. This work provides new insights into task time distributions, with heavy-tailed distributions observed when the initial task time has an unbounded support. The analysis combines Cram\u00e9r-Lundberg asymptotics with integral asymptotics, which sometimes requires the use of Tauberian theorems or direct calculations. Results are included for various scenarios.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0403}
{"prompt": "Rephrase the abstract of an article with title '$2\\times250$ GeV CLIC $\\gamma\\gamma$ Collider Based on its Drive Beam   FEL'.   CLIC is a linear $e^+e^-$ ($\\gamma\\gamma$) collider project which uses a drive beam to accelerate the main beam. The drive beam provides RF power for each corresponding unit of the main linac through energy extracting RF structures. CLIC has a wide range of center-of-mass energy options from 150 GeV to 3 TeV. The present paper contains optimization of Free Electron Laser (FEL) using one bunch of CLIC drive beam in order to provide polarized light amplification using appropriate wiggler and luminosity spectrum of $\\gamma\\gamma$ collider for $E_{cm}$=0.5 TeV. Then amplified laser can be converted to a polarized high-energy $\\gamma$ beam at the Conversion point (CP-prior to electron positron interaction point) in the process of Compton backscattering. At the CP a powerful laser pulse (FEL) focused to main linac electrons (positrons). Here this scheme described and it is show that CLIC drive beam parameters satisfy the requirement of FEL additionally essential undulator parameters has been defined. Achievable $\\gamma\\gamma$ luminosity is above $10^{34}$.  ", "human_text": "  CLIC is a linear $e^+e^-$ ($\\gamma\\gamma$) collider project which uses a drive beam to accelerate the main beam. The drive beam provides RF power for each corresponding unit of the main linac through energy extracting RF structures. CLIC has a wide range of center-of-mass energy options from 150 GeV to 3 TeV. The present paper contains optimization of Free Electron Laser (FEL) using one bunch of CLIC drive beam in order to provide polarized light amplification using appropriate wiggler and luminosity spectrum of $\\gamma\\gamma$ collider for $E_{cm}$=0.5 TeV. Then amplified laser can be converted to a polarized high-energy $\\gamma$ beam at the Conversion point (CP-prior to electron positron interaction point) in the process of Compton backscattering. At the CP a powerful laser pulse (FEL) focused to main linac electrons (positrons). Here this scheme described and it is show that CLIC drive beam parameters satisfy the requirement of FEL additionally essential undulator parameters has been defined. Achievable $\\gamma\\gamma$ luminosity is above $10^{34}$. ", "machine_text": " This paper investigates the feasibility of using the CLIC Drive Beam FEL to realize a $2\\times250$ GeV centre-of-mass energy $\\gamma\\gamma$ collider. By using one bunch of the CLIC drive beam, the authors optimize a Free Electron Laser (FEL) to provide polarized light amplification. An appropriate wiggler and luminosity spectrum is obtained for a 0.5 TeV collision energy. The amplified laser can then be converted to a polarized high-energy $\\gamma$ beam at the Conversion point, prior to the electron-positron interaction point, via Compton backscattering. This paper identifies the essential CLIC Drive Beam and undulator parameters, and goes on to demonstrate that the CLIC Drive Beam parameters meet the demands of the FEL. An envisaged $\\gamma\\gamma$ luminosity of greater than $10^{34}$ can be achieved.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2583}
{"prompt": "Rephrase the abstract of an article with title 'Wide Field Surveys and Astronomical Discovery Space'.   I review the status of science with wide field surveys. For many decades surveys have been the backbone of astronomy, and the main engine of discovery, as we have mapped the sky at every possible wavelength. Surveys are an efficient use of resources. They are important as a fundamental resource; to map intrinsically large structures; to gain the necessary statistics to address some problems; and to find very rare objects. I summarise major recent wide field surveys - 2MASS, SDSS, 2dfGRS, and UKIDSS - and look at examples of the exciting science they have produced, covering the structure of the Milky Way, the measurement of cosmological parameters, the creation of a new field studying substellar objects, and the ionisation history of the Universe. I then look briefly at upcoming projects in the optical-IR survey arena - VISTA, PanSTARRS, WISE, and LSST. Finally I ask, now we have opened up essentially all wavelength windows, whether the exploration of survey discovery space is ended. I examine other possible axes of discovery space, and find them mostly to be too expensive to explore or otherwise unfruitful, with two exceptions : the first is the time axis, which we have only just begun to explore properly; and the second is the possibility of neutrino astrophysics.  ", "human_text": "  I review the status of science with wide field surveys. For many decades surveys have been the backbone of astronomy, and the main engine of discovery, as we have mapped the sky at every possible wavelength. Surveys are an efficient use of resources. They are important as a fundamental resource; to map intrinsically large structures; to gain the necessary statistics to address some problems; and to find very rare objects. I summarise major recent wide field surveys - 2MASS, SDSS, 2dfGRS, and UKIDSS - and look at examples of the exciting science they have produced, covering the structure of the Milky Way, the measurement of cosmological parameters, the creation of a new field studying substellar objects, and the ionisation history of the Universe. I then look briefly at upcoming projects in the optical-IR survey arena - VISTA, PanSTARRS, WISE, and LSST. Finally I ask, now we have opened up essentially all wavelength windows, whether the exploration of survey discovery space is ended. I examine other possible axes of discovery space, and find them mostly to be too expensive to explore or otherwise unfruitful, with two exceptions : the first is the time axis, which we have only just begun to explore properly; and the second is the possibility of neutrino astrophysics. ", "machine_text": "This article reviews the progress of wide field surveys in astronomy and their use as the primary engine of discovery in mapping the sky. I review the major wide field surveys of the past two decades - 2MASS, SDSS, 2dfGRS, and UKIDSS - and the science they've allowed us to explore. I then look at upcoming projects that may contribute to future astronomical discoveries. Finally, I consider whether the exploration of survey discovery space has ended and assess other possible ways to extend astronomical discovery, including the use of time and the possibility of neutrino astrophysics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0809}
{"prompt": "Rephrase the abstract of an article with title 'Ground-state long-range order in quasi-one-dimensional Heisenberg   quantum antiferromagnets: High-order coupled-cluster calculations'.   We investigate the ground-state magnetic long-range order of quasi-one-dimensional quantum Heisenberg antiferromagnets for spin quantum numbers s=1/2 and s=1. We use the coupled cluster method to calculate the sublattice magnetization in dependence on the inter-chain coupling. We find that for the unfrustrated spin-1/2 system an infinitesimal inter-chain coupling is sufficient to stabilize magnetic long-range order, which is in agreement with results obtained by some other methods. For s=1 we find that a finite inter-chain coupling of about 10% of the in-chain coupling is necessary to stabilize magnetic long-range order. Furthermore, we consider a quasi one-dimensional spin-1/2 system, where a frustrating next-nearest neighbor in-chain coupling is included. We find that for stronger frustration also a finite inter-chain coupling is necessary to have magnetic long-range order in the ground state, where the strength of the inter-chain coupling necessary to establish magnetic long-range order is related to the size of the spin gap of the isolated chain.  ", "human_text": "  We investigate the ground-state magnetic long-range order of quasi-one-dimensional quantum Heisenberg antiferromagnets for spin quantum numbers s=1/2 and s=1. We use the coupled cluster method to calculate the sublattice magnetization in dependence on the inter-chain coupling. We find that for the unfrustrated spin-1/2 system an infinitesimal inter-chain coupling is sufficient to stabilize magnetic long-range order, which is in agreement with results obtained by some other methods. For s=1 we find that a finite inter-chain coupling of about 10% of the in-chain coupling is necessary to stabilize magnetic long-range order. Furthermore, we consider a quasi one-dimensional spin-1/2 system, where a frustrating next-nearest neighbor in-chain coupling is included. We find that for stronger frustration also a finite inter-chain coupling is necessary to have magnetic long-range order in the ground state, where the strength of the inter-chain coupling necessary to establish magnetic long-range order is related to the size of the spin gap of the isolated chain. ", "machine_text": "We present research focusing on the magnetic long-range order at the ground-state of quasi-one-dimensional quantum Heisenberg antiferromagnets for spin quantum numbers s=1/2 and s=1. Using the coupled cluster method, we determine the sublattice magnetization in function of the inter-chain coupling. Results show that an enormously small inter-chain coupling is effective in establishing long-range order for the unfrustrated spin-1/2 system. For spin s=1, however, an inter-chain coupling of 10% of the in-chain coupling is necessary to give stability to the magnetic order. Moreover, we consider the case of a quasi one-dimensional spin-1/2 system where a frustrating next-nearest neighbor in-chain coupling is also included. We observe that for stronger frustration, a finite inter-chain coupling is needed for magnetic long-range order; this amounts to the spin gap of the isolated chain.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3582}
{"prompt": "Rephrase the abstract of an article with title 'Particle Motion in Rapidly Oscillating Potentials: The Role of the   Potential's Initial Phase'.   Rapidly oscillating potentials with a vanishing time average have been used for a long time to trap charged particles in source-free regions. It has been argued that the motion of a particle in such a potential can be approximately described by a time independent effective potential, which does not depend upon the initial phase of the oscillating potential. However, here we show that the motion of a particle and its trapping condition significantly depend upon this initial phase for arbitrarily high frequencies of the potential's oscillation. We explain this novel phenomenon by showing that the motion of a particle is determined by the effective potential stated in the literature only if its initial conditions are transformed according to a transformation which we show to significantly depend on the potential's initial phase for arbitrarily high frequencies. We confirm our theoretical findings by numerical simulations. Further, we demonstrate that the found phenomenon offers new ways to manipulate the dynamics of particles which are trapped by rapidly oscillating potentials. Finally, we propose a simple experiment to verify the theoretical findings of this work.  ", "human_text": "  Rapidly oscillating potentials with a vanishing time average have been used for a long time to trap charged particles in source-free regions. It has been argued that the motion of a particle in such a potential can be approximately described by a time independent effective potential, which does not depend upon the initial phase of the oscillating potential. However, here we show that the motion of a particle and its trapping condition significantly depend upon this initial phase for arbitrarily high frequencies of the potential's oscillation. We explain this novel phenomenon by showing that the motion of a particle is determined by the effective potential stated in the literature only if its initial conditions are transformed according to a transformation which we show to significantly depend on the potential's initial phase for arbitrarily high frequencies. We confirm our theoretical findings by numerical simulations. Further, we demonstrate that the found phenomenon offers new ways to manipulate the dynamics of particles which are trapped by rapidly oscillating potentials. Finally, we propose a simple experiment to verify the theoretical findings of this work. ", "machine_text": " Studies of rapid oscillations in source-free areas often utilise a vanishing time average potential to capture charged particles. It has been hypothesised that a particle's motion in such circumstances can be predicted from a static, phase-insensitive effective potential. This study unveils a new phenomenon and reveals that a particle's motion and trapping conditions are in fact very dependent on their initial phase, even for very high frequencies. We explain this through a transformation according to the potential's initial phase, which has not previously been considered. Our theory is backed up with numerical simulations, as well as suggesting a simple experiment to test our claims. This finding could lead to innovative ways of manipulating the dynamics of particles subject to intense oscillations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2737}
{"prompt": "Rephrase the abstract of an article with title 'Central limit theorems in linear structural error-in-variables models   with explanatory variables in the domain of attraction of the normal law'.   Linear structural error-in-variables models with univariate observations are revisited for studying modified least squares estimators of the slope and intercept. New marginal central limit theorems (CLT's) are established for these estimators, assuming the existence of four moments for the measurement errors and that the explanatory variables are in the domain of attraction of the normal law. The latter condition for the explanatory variables is used the first time, and is so far the most general in this context. It is also optimal, or nearly optimal, for our CLT's. Moreover, due to the obtained CLT's being in Studentized and self-normalized forms to begin with, they are a priori nearly, or completely, data-based, and free of unknown parameters of the joint distribution of the error and explanatory variables. Consequently, they lead to a variety of readily available, or easily derivable, large-sample approximate confidence intervals (CI's) for the slope and intercept. In contrast, in related CLT's in the literature so far, the variances of the limiting normal distributions, in general, are complicated and depend on various, typically unknown, moments of the error and explanatory variables. Thus, the corresponding CI's for the slope and intercept in the literature, unlike those of the present paper, are available only under some additional model assumptions.  ", "human_text": "  Linear structural error-in-variables models with univariate observations are revisited for studying modified least squares estimators of the slope and intercept. New marginal central limit theorems (CLT's) are established for these estimators, assuming the existence of four moments for the measurement errors and that the explanatory variables are in the domain of attraction of the normal law. The latter condition for the explanatory variables is used the first time, and is so far the most general in this context. It is also optimal, or nearly optimal, for our CLT's. Moreover, due to the obtained CLT's being in Studentized and self-normalized forms to begin with, they are a priori nearly, or completely, data-based, and free of unknown parameters of the joint distribution of the error and explanatory variables. Consequently, they lead to a variety of readily available, or easily derivable, large-sample approximate confidence intervals (CI's) for the slope and intercept. In contrast, in related CLT's in the literature so far, the variances of the limiting normal distributions, in general, are complicated and depend on various, typically unknown, moments of the error and explanatory variables. Thus, the corresponding CI's for the slope and intercept in the literature, unlike those of the present paper, are available only under some additional model assumptions. ", "machine_text": "This article examines the modified least squares estimators of the slope and intercept in linear structural error-in-variables models with univariate observations. Central limit theorems are established, assuming the measurement errors have four moments and the explanatory variables are in the domain of attraction of the normal law. The CLT's are already in the forms of a Studentized and self-normalized distribution and provide a range of efficient, data-based approximate confidence intervals for the slope and intercept, free of unknown parameters of the joint distribution of the error and explanatory variables. As such, these CI's are an improvement on the related CLT's in the literature which depend on various, unknown, moments of the errors and the explanatory variables.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0826}
{"prompt": "Rephrase the abstract of an article with title 'An invariance principle for semimartingale reflecting Brownian motions   in domains with piecewise smooth boundaries'.   Semimartingale reflecting Brownian motions (SRBMs) living in the closures of domains with piecewise smooth boundaries are of interest in applied probability because of their role as heavy traffic approximations for some stochastic networks. In this paper, assuming certain conditions on the domains and directions of reflection, a perturbation result, or invariance principle, for SRBMs is proved. This provides sufficient conditions for a process that satisfies the definition of an SRBM, except for small random perturbations in the defining conditions, to be close in distribution to an SRBM. A crucial ingredient in the proof of this result is an oscillation inequality for solutions of a perturbed Skorokhod problem. We use the invariance principle to show weak existence of SRBMs under mild conditions. We also use the invariance principle, in conjunction with known uniqueness results for SRBMs, to give some sufficient conditions for validating approximations involving (i) SRBMs in convex polyhedrons with a constant reflection vector field on each face of the polyhedron, and (ii) SRBMs in bounded domains with piecewise smooth boundaries and possibly nonconstant reflection vector fields on the boundary surfaces.  ", "human_text": "  Semimartingale reflecting Brownian motions (SRBMs) living in the closures of domains with piecewise smooth boundaries are of interest in applied probability because of their role as heavy traffic approximations for some stochastic networks. In this paper, assuming certain conditions on the domains and directions of reflection, a perturbation result, or invariance principle, for SRBMs is proved. This provides sufficient conditions for a process that satisfies the definition of an SRBM, except for small random perturbations in the defining conditions, to be close in distribution to an SRBM. A crucial ingredient in the proof of this result is an oscillation inequality for solutions of a perturbed Skorokhod problem. We use the invariance principle to show weak existence of SRBMs under mild conditions. We also use the invariance principle, in conjunction with known uniqueness results for SRBMs, to give some sufficient conditions for validating approximations involving (i) SRBMs in convex polyhedrons with a constant reflection vector field on each face of the polyhedron, and (ii) SRBMs in bounded domains with piecewise smooth boundaries and possibly nonconstant reflection vector fields on the boundary surfaces. ", "machine_text": "This article examines the features of semimartingale reflecting Brownian motions (SRBMs) that exist within the boundaries of domains with piecewise smooth edges. An invariance principle is presented which can be applied to ensure adequate conditions for SRBMs, with the exception of small random variations in the defining parameters. This perturbation result is used to assess the existence of SRBMs under certain conditions, as well as for validating approximations with either SRBMs in convex polyhedrons or in bounded domains with piecewise smooth boundaries. An important factor in the proof of the invariance principle is a type of oscillation inequality associated with the perturbed Skorokhod problem.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0405}
{"prompt": "Rephrase the abstract of an article with title 'Evidence for a jet contribution to the optical/infrared light of neutron   star X-ray binaries'.   Optical/near-infrared (optical/NIR; OIR) light from low-mass neutron star X-ray binaries (NSXBs) in outburst is traditionally thought to be thermal emission from the accretion disc. Here we present a comprehensive collection of quasi-simultaneous OIR and X-ray data from 19 low-magnetic field NSXBs, including new observations of three sources: 4U 0614+09, LMC X-2 and GX 349+2. The average radio-OIR spectrum for NSXBs is alpha ~ +0.2 (where L_nu propto nu^alpha) at least at high luminosities when the radio jet is detected. This is comparable to, but slightly more inverted than the alpha ~ 0.0 found for black hole X-ray binaries. The OIR spectra and relations between OIR and X-ray fluxes are compared to those expected if the OIR emission is dominated by thermal emission from an X-ray or viscously heated disc, or synchrotron emission from the inner regions of the jets. We find that thermal emission due to X-ray reprocessing can explain all the data except at high luminosities for some NSXBs, namely the atolls and millisecond X-ray pulsars (MSXPs). Optically thin synchrotron emission from the jets (with an observed OIR spectral index of alpha_thin < 0) dominate the NIR light above L_x ~ 10^36 erg/s and the optical above L_x ~ 10^37 erg/s in these systems. For NSXB Z-sources, the OIR observations can be explained by X-ray reprocessing alone, although synchrotron emission may make a low level contribution to the NIR, and could dominate the OIR in one or two cases.  ", "human_text": "  Optical/near-infrared (optical/NIR; OIR) light from low-mass neutron star X-ray binaries (NSXBs) in outburst is traditionally thought to be thermal emission from the accretion disc. Here we present a comprehensive collection of quasi-simultaneous OIR and X-ray data from 19 low-magnetic field NSXBs, including new observations of three sources: 4U 0614+09, LMC X-2 and GX 349+2. The average radio-OIR spectrum for NSXBs is alpha ~ +0.2 (where L_nu propto nu^alpha) at least at high luminosities when the radio jet is detected. This is comparable to, but slightly more inverted than the alpha ~ 0.0 found for black hole X-ray binaries. The OIR spectra and relations between OIR and X-ray fluxes are compared to those expected if the OIR emission is dominated by thermal emission from an X-ray or viscously heated disc, or synchrotron emission from the inner regions of the jets. We find that thermal emission due to X-ray reprocessing can explain all the data except at high luminosities for some NSXBs, namely the atolls and millisecond X-ray pulsars (MSXPs). Optically thin synchrotron emission from the jets (with an observed OIR spectral index of alpha_thin < 0) dominate the NIR light above L_x ~ 10^36 erg/s and the optical above L_x ~ 10^37 erg/s in these systems. For NSXB Z-sources, the OIR observations can be explained by X-ray reprocessing alone, although synchrotron emission may make a low level contribution to the NIR, and could dominate the OIR in one or two cases. ", "machine_text": "This article provides evidence for a contribution from jets to the OIR light of low-magnetic field neutron star X-ray binaries. By analyzing quasi-simultaneous OIR and X-ray data from 19 different sources, we found that the radio-OIR spectrum for NSXBs is alpha ~ +0.2, even at high luminosities where the radio jet is detected. Optically thin synchrotron emission from the jets dominates the NIR light above L_x ~ 10^36 erg/s and the optical above L_x ~ 10^37 erg/s from atolls and millisecond X-ray pulsars, while X-ray reprocessing is the only source of OIR emission in Z-sources, with synchrotron emission potentially making a low level contribution to the NIR.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3611}
{"prompt": "Rephrase the abstract of an article with title 'El universo de Einstein: 1905 - annus mirabilis - 2005'.   Year 2005 was the World Year of Physics, and it was commemorated worldwide as the 100th anniversary of Albert Einstein's legendary works in which the foundations of at least three areas of modern physics were laid: statistical mechanics, quantum mechanics and special relativity. These works turned year 1905 in what deservedly was called the \"miraculous year\" (annus mirabilis) of Einstein. However, the influence of this great mind was not limited to science. As it is well known, his fingerprint remains engraved in many aspects of our daily life. Because of that, in this work we have tried to cover almost all the subjects in which Einstein was involved during the last century and, of course, try and reveal the future projection his actions will have in this new century that has just begun. Among the subjects covered in the volume one can find the possible connection between Einstein and the artistic vanguard movement, his religiosity, his days in Argentina, the Nobel Prize, the Einstein-Freud correspondence, his pacifism and the nuclear energy, science and politics under the Second Empire and the Weimar Republic, and even a description of his patents and experiments, the studies performed to search for \"built-in\" features in his brain and the doubts many had regarding whether Einstein was a genius or a crank. Also included are essays on Einstein and Borges, philosophy and relativity, Mach's principle, the relation among science, arts and humanities, and, closer to Einstein's own theoretical research, the twin paradox, chance and quantum mechanics, the arrow of time, gravitational lenses, string theory, holography and black holes, gravitomagnetism, superconductivity, gravitational waves, the photoelectric effect and the alternative theories for gravitation.  ", "human_text": "  Year 2005 was the World Year of Physics, and it was commemorated worldwide as the 100th anniversary of Albert Einstein's legendary works in which the foundations of at least three areas of modern physics were laid: statistical mechanics, quantum mechanics and special relativity. These works turned year 1905 in what deservedly was called the \"miraculous year\" (annus mirabilis) of Einstein. However, the influence of this great mind was not limited to science. As it is well known, his fingerprint remains engraved in many aspects of our daily life. Because of that, in this work we have tried to cover almost all the subjects in which Einstein was involved during the last century and, of course, try and reveal the future projection his actions will have in this new century that has just begun. Among the subjects covered in the volume one can find the possible connection between Einstein and the artistic vanguard movement, his religiosity, his days in Argentina, the Nobel Prize, the Einstein-Freud correspondence, his pacifism and the nuclear energy, science and politics under the Second Empire and the Weimar Republic, and even a description of his patents and experiments, the studies performed to search for \"built-in\" features in his brain and the doubts many had regarding whether Einstein was a genius or a crank. Also included are essays on Einstein and Borges, philosophy and relativity, Mach's principle, the relation among science, arts and humanities, and, closer to Einstein's own theoretical research, the twin paradox, chance and quantum mechanics, the arrow of time, gravitational lenses, string theory, holography and black holes, gravitomagnetism, superconductivity, gravitational waves, the photoelectric effect and the alternative theories for gravitation. ", "machine_text": " This year marks the 100th anniversary of the exceptional contributions of Albert Einstein to modern physics, specifically statistical mechanics, quantum mechanics, and special relativity. His accomplishments have been rightfully dubbed the 'miraculous year' of Einstein. His influence has extended beyond science, and this work is intended to explore his influence and legacy throughout the last century as well as hint at the future projection of his impact into this new century. Examining a variety of topics such as Einstein and the artistic vanguard movement, his religiosity, his time spent in Argentina, the Nobel Prize, the Einstein-Freud correspondence, his pacifism, nuclear energy, and many of his experimental studies, the differences between genius and crank, Einstein and Borges, philosophy and relativity, Mach\u2019s principle, the relation between science, arts, and humanities, and more, this work illuminates a comprehensive view of the universe of Einstein.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4266}
{"prompt": "Rephrase the abstract of an article with title 'A Symplectic Test of the L-Functions Ratios Conjecture'.   Recently Conrey, Farmer and Zirnbauer conjectured formulas for the averages over a family of ratios of products of shifted L-functions. Their L-functions Ratios Conjecture predicts both the main and lower order terms for many problems, ranging from n-level correlations and densities to mollifiers and moments to vanishing at the central point. There are now many results showing agreement between the main terms of number theory and random matrix theory; however, there are very few families where the lower order terms are known. These terms often depend on subtle arithmetic properties of the family, and provide a way to break the universality of behavior. The L-functions Ratios Conjecture provides a powerful and tractable way to predict these terms. We test a specific case here, that of the 1-level density for the symplectic family of quadratic Dirichlet characters arising from even fundamental discriminants d \\le X. For test functions supported in (-1/3, 1/3) we calculate all the lower order terms up to size O(X^{-1/2+epsilon}) and observe perfect agreement with the conjecture (for test functions supported in (-1, 1) we show agreement up to errors of size O(X^{-epsilon}) for any epsilon). Thus for this family and suitably restricted test functions, we completely verify the Ratios Conjecture's prediction for the 1-level density.  ", "human_text": "  Recently Conrey, Farmer and Zirnbauer conjectured formulas for the averages over a family of ratios of products of shifted L-functions. Their L-functions Ratios Conjecture predicts both the main and lower order terms for many problems, ranging from n-level correlations and densities to mollifiers and moments to vanishing at the central point. There are now many results showing agreement between the main terms of number theory and random matrix theory; however, there are very few families where the lower order terms are known. These terms often depend on subtle arithmetic properties of the family, and provide a way to break the universality of behavior. The L-functions Ratios Conjecture provides a powerful and tractable way to predict these terms. We test a specific case here, that of the 1-level density for the symplectic family of quadratic Dirichlet characters arising from even fundamental discriminants d \\le X. For test functions supported in (-1/3, 1/3) we calculate all the lower order terms up to size O(X^{-1/2+epsilon}) and observe perfect agreement with the conjecture (for test functions supported in (-1, 1) we show agreement up to errors of size O(X^{-epsilon}) for any epsilon). Thus for this family and suitably restricted test functions, we completely verify the Ratios Conjecture's prediction for the 1-level density. ", "machine_text": " This article assesses the validity of the L-functions Ratios Conjecture concerning the 1-level density of the symplectic family of quadratic Dirichlet characters from even discriminants d, each of which is less than or equal to X. We calculate the lower order terms up to size O(X^{-1/2 + epsilon}) and observe perfect agreement with the Conjecture for test functions supported in [-1/3, 1/3]. Regarding test functions supported in [-1, 1], we demonstrate agreement with the Conjecture up to O(X^{-epsilon}), where epsilon is an arbitrarily small value. Our results suggest that the Ratios Conjecture effectively predicts the lower order terms of the 1-level density in this case, and thereby affirms the universality of behavior.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0927}
{"prompt": "Rephrase the abstract of an article with title 'Strange Nucleon Form Factors from $ep$ and $\\nu p$ Elastic Scattering'.   The recent parity-violating $ep$ forward-scattering elastic asymmetry data from Jefferson Lab (HAPPEx and G0), when combined with the $\\nu p$ elastic cross section data from Brookhaven (E734), permit an extraction of the strangeness contribution to the vector and axial nucleon form factors for momentum transfers in the range $0.45 < Q^2 < 1.0$ GeV$^2$. These results, combined with the recent determination of the strange vector form factors at $Q^2 = 0.1$ GeV$^2$ (SAMPLE, HAPPEx, PVA4, G0) have been interpreted in terms of $uuds\\bar{s}$ configurations very different from the kaon-loop configurations usually associated with strangeness in the nucleon. New experiments are being proposed to improve the state of our knowledge of the $\\nu p$ elastic cross section -- these new experiments will push the range of $Q^2$ to much lower values, and greatly increase the precision of the $\\nu p$ elastic data. One outcome of this can be a measurement of the strangeness contribution to the nucleon spin, $\\Delta s$. Nuclear targets (e.g. C or Ar) are to be used in these neutrino experiments, and so a deep understanding of the nuclear physics, particularly in regard to final state effects, is needed before the potential of these precision experiments can be fully realized.  ", "human_text": "  The recent parity-violating $ep$ forward-scattering elastic asymmetry data from Jefferson Lab (HAPPEx and G0), when combined with the $\\nu p$ elastic cross section data from Brookhaven (E734), permit an extraction of the strangeness contribution to the vector and axial nucleon form factors for momentum transfers in the range $0.45 < Q^2 < 1.0$ GeV$^2$. These results, combined with the recent determination of the strange vector form factors at $Q^2 = 0.1$ GeV$^2$ (SAMPLE, HAPPEx, PVA4, G0) have been interpreted in terms of $uuds\\bar{s}$ configurations very different from the kaon-loop configurations usually associated with strangeness in the nucleon. New experiments are being proposed to improve the state of our knowledge of the $\\nu p$ elastic cross section -- these new experiments will push the range of $Q^2$ to much lower values, and greatly increase the precision of the $\\nu p$ elastic data. One outcome of this can be a measurement of the strangeness contribution to the nucleon spin, $\\Delta s$. Nuclear targets (e.g. C or Ar) are to be used in these neutrino experiments, and so a deep understanding of the nuclear physics, particularly in regard to final state effects, is needed before the potential of these precision experiments can be fully realized. ", "machine_text": " Evidence from Jefferson Lab's proton-electron (HAPPEx and G0) parity-violating forward-scattering asymmetry measurements, in conjunction with neutrino-proton elastic cross section observation from Brookhaven's E734 project, has offered the opportunity to assess the strangeness contribution of the nucleon vector and axial form factors in the range of 0.45 to 1.0 GeV$^2$. These results, combined with the strange vector form factors found from other studies (SAMPLE, HAPPEx, PVA4 and G0) have reportedly been established by configurations of the $uuds\\bar{s}$ variety that are unlike the typical kaon-loop configurations linked to nucleon strangeness. To advance our knowledge of the $\\nu p$ elastic cross section, new experiments targeting lower $Q^2$ values with heightened precision are in the works. If successful, they will bring the ability to measure the strangeness fraction of nucleon spins, $\\Delta s$. Understanding how the quantities in the nucleus interact and affect the final state is paramount to maximize output of said experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1115}
{"prompt": "Rephrase the abstract of an article with title 'Influence of an external magnetic field on the decoherence of a central   spin coupled to an antiferromagnetic environment'.   Using the spin wave approximation, we study the decoherence dynamics of a central spin coupled to an antiferromagnetic environment under the application of an external global magnetic field. The external magnetic field affects the decoherence process through its effect on the antiferromagnetic environment. It is shown explicitly that the decoherence factor which displays a Gaussian decay with time depends on the strength of the external magnetic field and the crystal anisotropy field in the antiferromagnetic environment. When the values of the external magnetic field is increased to the critical field point at which the spin-flop transition (a first-order quantum phase transition) happens in the antiferromagnetic environment, the decoherence of the central spin reaches its highest point. This result is consistent with several recent quantum phase transition witness studies. The influences of the environmental temperature on the decoherence behavior of the central spin are also investigated.  ", "human_text": "  Using the spin wave approximation, we study the decoherence dynamics of a central spin coupled to an antiferromagnetic environment under the application of an external global magnetic field. The external magnetic field affects the decoherence process through its effect on the antiferromagnetic environment. It is shown explicitly that the decoherence factor which displays a Gaussian decay with time depends on the strength of the external magnetic field and the crystal anisotropy field in the antiferromagnetic environment. When the values of the external magnetic field is increased to the critical field point at which the spin-flop transition (a first-order quantum phase transition) happens in the antiferromagnetic environment, the decoherence of the central spin reaches its highest point. This result is consistent with several recent quantum phase transition witness studies. The influences of the environmental temperature on the decoherence behavior of the central spin are also investigated. ", "machine_text": " We explore the effects of an external global magnetic field on the decoherence dynamics of a spin located in an antiferromagnetic environment. Our calculations, based on the spin wave approximation, reveal that the decoherence rate, quantified through a Gaussian decay function, is influenced by both the field strength and the anisotropy of the antiferromagnetic environment. The critical field strength at which the spin-flop transition in the antiferromagnetic environment occurs marks the peak of the central spin decoherence, providing results that corroborate recent quantum phase transition witness studies. We additionally consider the impact of temperature on the decoherence of the central spin.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0934}
{"prompt": "Rephrase the abstract of an article with title 'Asymmetric superconductivity in metallic systems'.   Different types of superfluid ground states have been investigated in systems of two species of fermions with Fermi surfaces that do not match. This study is relevant for cold atomic systems, condensed matter physics and quark matter. In this paper we consider this problem in the case the fermionic quasi-particles can transmute into one another and only their total number is conserved. We use a BCS approximation to study superconductivity in two-band metallic systems with inter and intra-band interactions. Tuning the hybridization between the bands varies the mismatch of the Fermi surfaces and produces different instabilities. For inter-band attractive interactions we find a first order normal-superconductor and a homogeneous metastable phase with gapless excitations. In the case of intra-band interactions, the transition from the superconductor to the normal state as hybridization increases is continuous and associated with a quantum critical point. The case when both interactions are present is also considered.  ", "human_text": "  Different types of superfluid ground states have been investigated in systems of two species of fermions with Fermi surfaces that do not match. This study is relevant for cold atomic systems, condensed matter physics and quark matter. In this paper we consider this problem in the case the fermionic quasi-particles can transmute into one another and only their total number is conserved. We use a BCS approximation to study superconductivity in two-band metallic systems with inter and intra-band interactions. Tuning the hybridization between the bands varies the mismatch of the Fermi surfaces and produces different instabilities. For inter-band attractive interactions we find a first order normal-superconductor and a homogeneous metastable phase with gapless excitations. In the case of intra-band interactions, the transition from the superconductor to the normal state as hybridization increases is continuous and associated with a quantum critical point. The case when both interactions are present is also considered. ", "machine_text": "This article explores the science of asymmetric superconductivity in metallic systems using a BCS approximation. We consider a two-band system of fermions with interactions between intra- and inter-bands. The hybridization between the bands is varied and we investigate the instabilities it produces. We find that for inter-band attractive interactions, a normal-superconductor transition is present, as well as a homogenous metastable phase with gapless excitations. In the case of intra-band interactions, the transition from the superconductor to the normal state is continuous, related to a quantum critical point. Results are presented for the situation in which both intra- and inter-band interactions are present.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1201}
{"prompt": "Rephrase the abstract of an article with title 'Analytic models of plausible gravitational lens potentials'.   Gravitational lenses on galaxy scales are plausibly modelled as having ellipsoidal symmetry and a universal dark matter density profile, with a Sersic profile to describe the distribution of baryonic matter. Predicting all lensing effects requires knowledge of the total lens potential: in this work we give analytic forms for that of the above hybrid model. Emphasising that complex lens potentials can be constructed from simpler components in linear combination, we provide a recipe for attaining elliptical symmetry in either projected mass or lens potential. We also provide analytic formulae for the lens potentials of Sersic profiles for integer and half-integer index. We then present formulae describing the gravitational lensing effects due to smoothly-truncated universal density profiles in cold dark matter model. For our isolated haloes the density profile falls off as radius to the minus fifth or seventh power beyond the tidal radius, functional forms that allow all orders of lens potential derivatives to be calculated analytically, while ensuring a non-divergent total mass. We show how the observables predicted by this profile differ from that of the original infinite-mass NFW profile. Expressions for the gravitational flexion are highlighted. We show how decreasing the tidal radius allows stripped haloes to be modelled, providing a framework for a fuller investigation of dark matter substructure in galaxies and clusters. Finally we remark on the need for finite mass halo profiles when doing cosmological ray-tracing simulations, and the need for readily-calculable higher order derivatives of the lens potential when studying catastrophes in strong lenses.  ", "human_text": "  Gravitational lenses on galaxy scales are plausibly modelled as having ellipsoidal symmetry and a universal dark matter density profile, with a Sersic profile to describe the distribution of baryonic matter. Predicting all lensing effects requires knowledge of the total lens potential: in this work we give analytic forms for that of the above hybrid model. Emphasising that complex lens potentials can be constructed from simpler components in linear combination, we provide a recipe for attaining elliptical symmetry in either projected mass or lens potential. We also provide analytic formulae for the lens potentials of Sersic profiles for integer and half-integer index. We then present formulae describing the gravitational lensing effects due to smoothly-truncated universal density profiles in cold dark matter model. For our isolated haloes the density profile falls off as radius to the minus fifth or seventh power beyond the tidal radius, functional forms that allow all orders of lens potential derivatives to be calculated analytically, while ensuring a non-divergent total mass. We show how the observables predicted by this profile differ from that of the original infinite-mass NFW profile. Expressions for the gravitational flexion are highlighted. We show how decreasing the tidal radius allows stripped haloes to be modelled, providing a framework for a fuller investigation of dark matter substructure in galaxies and clusters. Finally we remark on the need for finite mass halo profiles when doing cosmological ray-tracing simulations, and the need for readily-calculable higher order derivatives of the lens potential when studying catastrophes in strong lenses. ", "machine_text": " This study explores the potential of elliptic, hybrid models of galactic gravitational lensing that combine a universal dark matter density profile with a Sersic profile for the baryonic matter distribution. To this end, analytic forms for the lens potentials of these models are derived, and a recipe for elliptic symmetry in either the projected mass or lens potential is developed. Additionally formulae describing the gravitational lensing effects of differently truncated universal cold dark matter are provided and taken compared to the infinite-mass NFW profile. Furthermore, the application of these models to stripped halo profiles and their implications for cosmological ray-tracing simulations and investigating catastrophic lensing effects are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0682}
{"prompt": "Rephrase the abstract of an article with title 'Discrete Thermodynamics of Lasers'.   The paper offers a discrete thermodynamic model of lasers. Laser is an open system; its equilibrium is based on a balance of two thermodynamic forces, one related to the incoming pumping power and another to the emitted light. The basic expression for such equilibrium is a logistic map, graphical solutions to which are pitchfork bifurcation diagrams. As pumping force increases, the relative populations on the ground and lasing branches tend to zero and unity correspondingly. An interesting feature of this model is the line spectrum of the up and down transitions between the branches beyond bifurcation point. Even in a simple case of 2-level laser with only 2 possible transition types (up and down), the spectra look like sets of the line packets, starting well before the population inversion. This effect is an independent confirmation of the Einstein's prohibition on practical realization of 2-level laser. Multilevel lasers may be approached by employing the idea of thermodynamic activity for the emitting atoms. Considering coefficient of thermodynamic activity of the lasing level atoms to be proportional to the ratio of life times on the upper and lasing (the 3d) levels, one can derive a new basic map for the multilevel laser system. For a modest ratio only of 0.01, spontaneous transitions between levels are pushed to the area beyond population inversion, opening a space for the functioning of laser.  ", "human_text": "  The paper offers a discrete thermodynamic model of lasers. Laser is an open system; its equilibrium is based on a balance of two thermodynamic forces, one related to the incoming pumping power and another to the emitted light. The basic expression for such equilibrium is a logistic map, graphical solutions to which are pitchfork bifurcation diagrams. As pumping force increases, the relative populations on the ground and lasing branches tend to zero and unity correspondingly. An interesting feature of this model is the line spectrum of the up and down transitions between the branches beyond bifurcation point. Even in a simple case of 2-level laser with only 2 possible transition types (up and down), the spectra look like sets of the line packets, starting well before the population inversion. This effect is an independent confirmation of the Einstein's prohibition on practical realization of 2-level laser. Multilevel lasers may be approached by employing the idea of thermodynamic activity for the emitting atoms. Considering coefficient of thermodynamic activity of the lasing level atoms to be proportional to the ratio of life times on the upper and lasing (the 3d) levels, one can derive a new basic map for the multilevel laser system. For a modest ratio only of 0.01, spontaneous transitions between levels are pushed to the area beyond population inversion, opening a space for the functioning of laser. ", "machine_text": "This article studies the thermodynamic aspects of lasers. The equilibrium of the open system is determined by two thermodynamic forces, the incoming pumping power and the emitted light. The logistic map is used to express this equilibrium, which reveals pitchfork bifurcation diagrams when graphed. As the pumping force increases, there is a corresponding decrease in the relative populations of the ground levels and the lasing branches. An interesting observation of this model is the spectrum of up and down transitions between the branches beyond the bifurcation point. With just two transition types (up and down) of two-level lasers, it is impossible to practically bring into effect. Multilevel lasers are discussed by introducing the concept of thermodynamic activity to the emitting atoms. By doing so, the concept of population inversion is pushed beyond the scope of spontaneous transitions between levels, which creates a chance for the system to function as a laser.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1289}
{"prompt": "Rephrase the abstract of an article with title 'Probing the Impact of Stellar Duplicity on Planet Occurrence with   Spectroscopic and Imaging Observations'.   Although it is commonly agreed that the presence of a close stellar companion is likely to affect planet formation and evolution, the precise effects and their actual impact on planet occurrence and properties are still debated. In particular, observational constraints are sparse, a consequence of the discrimination against close binaries in Doppler planet searches. To bring observational constraints on the occurrence and properties of planets in binaries and multiple stars, we have been conducting two dedicated observing programs using both adaptive optics imaging and radial-velocity monitoring. In this chapter we explain our approach and present preliminary results from these two programs. A simplified statistical analysis of the data from our VLT/NACO imaging survey brings the first observational evidence that the occurrence of planets is reduced in binaries closer than ~120 AU. On the radial-velocity side, current results confirm that the use of two-dimensional correlation allows to search for circumprimary giant planets in many types of spectroscopic binaries. Definitive results from our ongoing planet search in spectroscopic binaries should yield important constraints on the closest binaries susceptible of hosting circumprimary giant planets.  ", "human_text": "  Although it is commonly agreed that the presence of a close stellar companion is likely to affect planet formation and evolution, the precise effects and their actual impact on planet occurrence and properties are still debated. In particular, observational constraints are sparse, a consequence of the discrimination against close binaries in Doppler planet searches. To bring observational constraints on the occurrence and properties of planets in binaries and multiple stars, we have been conducting two dedicated observing programs using both adaptive optics imaging and radial-velocity monitoring. In this chapter we explain our approach and present preliminary results from these two programs. A simplified statistical analysis of the data from our VLT/NACO imaging survey brings the first observational evidence that the occurrence of planets is reduced in binaries closer than ~120 AU. On the radial-velocity side, current results confirm that the use of two-dimensional correlation allows to search for circumprimary giant planets in many types of spectroscopic binaries. Definitive results from our ongoing planet search in spectroscopic binaries should yield important constraints on the closest binaries susceptible of hosting circumprimary giant planets. ", "machine_text": " Investigations into the influence of stellar multiplicity on planet presence and characteristics have been marred by a lack of observational data. In an effort to bring observational evidence to this field, two programs utilizing adaptive optics imaging and radial-velocity monitoring have been initiated. In this chapter, the restructuring of the approach and the preliminary outcomes of these two projects are reported. Analysis of the findings from VLT/NACO imaging survey offer the first individual proof that the existence of planets is lessened in binaries closer than ~120 AU. Additionally, on the radial-velocity side, recent results underscore the use of two-dimensional correlation to search for planets orbiting the primary star in various forms of spectroscopic binaries. The pursuing conclusion of the survey of planets in spectroscopic binaries is set to bring crucial information on the closest binaries capable of holding circumprimary giant planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3173}
{"prompt": "Rephrase the abstract of an article with title 'Three Particle Correlations from STAR'.   Two-particle correlations have shown modification to the away-side shape in central Au+Au collisions relative to $pp$, d+Au and peripheral Au+Au collisions. Different scenarios can explain this modification including: large angle gluon radiation, jets deflected by transverse flow, path length dependent energy loss, Cerenkov gluon radiation of fast moving particles, and conical flow generated by hydrodynamic Mach-cone shock-waves. Three-particle correlations have the power to distinguish the scenarios with conical emission, conical flow and Cerenkov radiation, from other scenarios. In addition, the dependence of the observed shapes on the $p_T$ of the associated particles can be used to distinguish conical emission from a sonic boom (Mach-cone) and from QCD-Cerenkov radiation. We present results from STAR on 3-particle azimuthal correlations for a high $p_T$ trigger particle with two softer particles. Results are shown for $pp$, d+Au and high statistics Au+Au collisions at $\\sqrt{s_{NN}}$=200 GeV. An important aspect of the analysis is the subtraction of combinatorial backgrounds. Systematic uncertainties due to this subtraction and the flow harmonics v2 and v4 are investigated in detail. The implications of the results for the presence or absence of conical flow from Mach-cones are discussed.  ", "human_text": "  Two-particle correlations have shown modification to the away-side shape in central Au+Au collisions relative to $pp$, d+Au and peripheral Au+Au collisions. Different scenarios can explain this modification including: large angle gluon radiation, jets deflected by transverse flow, path length dependent energy loss, Cerenkov gluon radiation of fast moving particles, and conical flow generated by hydrodynamic Mach-cone shock-waves. Three-particle correlations have the power to distinguish the scenarios with conical emission, conical flow and Cerenkov radiation, from other scenarios. In addition, the dependence of the observed shapes on the $p_T$ of the associated particles can be used to distinguish conical emission from a sonic boom (Mach-cone) and from QCD-Cerenkov radiation. We present results from STAR on 3-particle azimuthal correlations for a high $p_T$ trigger particle with two softer particles. Results are shown for $pp$, d+Au and high statistics Au+Au collisions at $\\sqrt{s_{NN}}$=200 GeV. An important aspect of the analysis is the subtraction of combinatorial backgrounds. Systematic uncertainties due to this subtraction and the flow harmonics v2 and v4 are investigated in detail. The implications of the results for the presence or absence of conical flow from Mach-cones are discussed. ", "machine_text": " Results from the STAR experiment on 3-particle correlations in $pp$, d+Au and Au+Au collisions at $\\sqrt{s_{NN}}$=200 GeV are discussed. Through comparison of the away-side shape in central Au+Au, relative to $pp$, d+Au and peripheral Au+Au collisions, several scenarios are proposed to explain the modification of two-particle correlations including: gluon radiation, jet deflection, energy loss, and conical flow. Three-particle correlations are used to differentiate these scenarios to determine if a Mach-cone conical flow is present. The $p_T$ dependence of the observed shapes is used to distinguish conical emission from sonic booms and Cerenkov radiation. The combinatorial backgrounds and flow harmonics v2 and v4 are studied in detail, with the implications of the results for the presence of conical flow discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.022}
{"prompt": "Rephrase the abstract of an article with title 'New Integral Representations of Whittaker Functions for Classical Lie   Groups'.   We propose integral representations of the Whittaker functions for the classical Lie algebras sp(2l), so(2l) and so(2l+1). These integral representations generalize the integral representation of gl(l+1)-Whittaker functions first introduced by Givental. One of the salient features of the Givental representation is its recursive structure with respect to the rank of the Lie algebra gl(l+1). The proposed generalization of the Givental representation to the classical Lie algebras retains this property. It was shown elsewhere that the integral recursion operator for gl(l+1)-Whittaker function in the Givental representation coincides with a degeneration of the Baxter Q-operator for $\\hat{gl(l+1)}$-Toda chains. We construct Q-operator for affine Lie algebras $\\hat{so(2l)}$, $\\hat{so(2l+1)}$ and a twisted form of $\\hat{gl(2l)}$. We demonstrate that the relation between recursion integral operators of the generalized Givental representation and degenerate Q-operators remains valid for all classical Lie algebras.  ", "human_text": "  We propose integral representations of the Whittaker functions for the classical Lie algebras sp(2l), so(2l) and so(2l+1). These integral representations generalize the integral representation of gl(l+1)-Whittaker functions first introduced by Givental. One of the salient features of the Givental representation is its recursive structure with respect to the rank of the Lie algebra gl(l+1). The proposed generalization of the Givental representation to the classical Lie algebras retains this property. It was shown elsewhere that the integral recursion operator for gl(l+1)-Whittaker function in the Givental representation coincides with a degeneration of the Baxter Q-operator for $\\hat{gl(l+1)}$-Toda chains. We construct Q-operator for affine Lie algebras $\\hat{so(2l)}$, $\\hat{so(2l+1)}$ and a twisted form of $\\hat{gl(2l)}$. We demonstrate that the relation between recursion integral operators of the generalized Givental representation and degenerate Q-operators remains valid for all classical Lie algebras. ", "machine_text": " This article introduces integral representations of Whittaker functions for the classical Lie algebras sp(2l), so(2l) and so(2l+1). These representations are an extension of Givental's integral representation of gl(l+1)-Whittaker functions that has the special property of being recursive in nature. It was previously shown that the gl(l+1) integral recursion operator is connected to the Baxter Q-operator of the corresponding affine Lie algebra. We demonstrate this connection by constructing Q-operators for $\\hat{so(2l)}$, $\\hat{so(2l+1)}$ and a twisted version of $\\hat{gl(2l)}$. Our results suggest that the link between recursion integral operators and degenerated Q-operators for classical Lie algebras is generalizable.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2886}
{"prompt": "Rephrase the abstract of an article with title 'Detection of Emission from the CN Radical in the Cloverleaf Quasar at   z=2.56'.   We report the detection of CN(N=3-2) emission towards the Cloverleaf quasar (z=2.56) based on observations with the IRAM Plateau de Bure Interferometer. This is the first clear detection of emission from this radical at high redshift. CN emission is a tracer of dense molecular hydrogen gas (n(H2) > 10^4 cm^{-3}) within star-forming molecular clouds, in particular in regions where the clouds are affected by UV radiation. The HCN/CN intensity ratio can be used as a diagnostic for the relative importance of photodissociation regions (PDRs) in a source, and as a sensitive probe of optical depth, the radiation field, and photochemical processes. We derive a lensing-corrected CN(N=3-2) line luminosity of L'(CN(3-2) = (4.5 +/- 0.5) x 10^9 K km/s pc^2. The ratio between CN luminosity and far-infrared luminosity falls within the scatter of the same relationship found for low-z (ultra-) luminous infrared galaxies. Combining our new results with CO(J=3-2) and HCN(J=1-0) measurements from the literature and assuming thermal excitation for all transitions, we find a CO/CN luminosity ratio of 9.3 +/- 1.9 and a HCN/CN luminosity ratio of 0.95 +/- 0.15. However, we find that the CN(N=3-2) line is likely only subthermally excited, implying that those ratios may only provide upper limits for the intrinsic 1-0 line luminosity ratios. We conclude that, in combination with other molecular gas tracers like CO, HCN, and HCO+, CN is an important probe of the physical conditions and chemical composition of dense molecular environments at high redshift.  ", "human_text": "  We report the detection of CN(N=3-2) emission towards the Cloverleaf quasar (z=2.56) based on observations with the IRAM Plateau de Bure Interferometer. This is the first clear detection of emission from this radical at high redshift. CN emission is a tracer of dense molecular hydrogen gas (n(H2) > 10^4 cm^{-3}) within star-forming molecular clouds, in particular in regions where the clouds are affected by UV radiation. The HCN/CN intensity ratio can be used as a diagnostic for the relative importance of photodissociation regions (PDRs) in a source, and as a sensitive probe of optical depth, the radiation field, and photochemical processes. We derive a lensing-corrected CN(N=3-2) line luminosity of L'(CN(3-2) = (4.5 +/- 0.5) x 10^9 K km/s pc^2. The ratio between CN luminosity and far-infrared luminosity falls within the scatter of the same relationship found for low-z (ultra-) luminous infrared galaxies. Combining our new results with CO(J=3-2) and HCN(J=1-0) measurements from the literature and assuming thermal excitation for all transitions, we find a CO/CN luminosity ratio of 9.3 +/- 1.9 and a HCN/CN luminosity ratio of 0.95 +/- 0.15. However, we find that the CN(N=3-2) line is likely only subthermally excited, implying that those ratios may only provide upper limits for the intrinsic 1-0 line luminosity ratios. We conclude that, in combination with other molecular gas tracers like CO, HCN, and HCO+, CN is an important probe of the physical conditions and chemical composition of dense molecular environments at high redshift. ", "machine_text": " We have detected the presence of CN(N=3-2) emission from the Cloverleaf quasar (z=2.56) for the first time, by utilizing the IRAM Plateau de Bure Interferometer. This emission is a tracer of high density molecular hydrogen clouds, in particular those affected by UV radiation. We can therefore assess the importance of photodissociation regions, radiation field strength and photochemical processes by investigating the HCN/CN intensity ratio. Our findings suggest a CN(N=3-2) line luminosity of L'(CN(3-2) = (4.5 +/- 0.5) x 10^9 K km/s pc^2 when accounting for lensing. This ratio lies within the range of those observed for low-z (ultra-luminous) infrared galaxies. Combining our results with other indicators, such as CO(J=3-2), HCN(J=1-0) etc, indicates a CO/CN luminosity ratio of 9.3 +/- 1.9 and HCN/CN luminosity ratio of 0.95 +/- 0.15. We hypothesize that the CN(N=3-2) line is mostly sub-thermally excited, thus implying these ratios could be significantly higher than found in this analysis. Overall, CN is a sensitive tool to study the physical conditions and chemical compositions of dense molecular environments at high redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3338}
{"prompt": "Rephrase the abstract of an article with title 'Computer simulation of model cohesive powders: influence of assembling   procedure and contact laws on low consolidation states'.   The structure and mechanical properties of a simple two-dimensional model of a cohesive powder are investigated by molecular dynamics simulations. Micromechanical ingredients involve elasticity, friction, a short range attraction and, possibly, rolling resistance (RR) in contacts. The microstructure of the cohesive packing varies according to the assembling procedure, from rather densely packed if isolated particles are directly compressed to much looser if the formation of large aggregates is allowed prior to compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure P, acting on grains of diameter $a$, to maximum tensile contact force F0. At low P* the final structure depends on the level of velocity fluctuations at the early stages of cluster aggregation. With RR the coordination number approaches 2 in the limit of low initial velocities or large rolling friction. The force network generally comprises small hyperstatic clusters with forces of the order of F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly rearranges into force chain-like patterns. Density correlations witness a fractal structure, with dimension Df, up to some density-dependent blob size. WIth RR Df coincides with the ballistic aggregation result, despite a possibly different connectivity. Possible effects of some parameters on material strength are evoked.  ", "human_text": "  The structure and mechanical properties of a simple two-dimensional model of a cohesive powder are investigated by molecular dynamics simulations. Micromechanical ingredients involve elasticity, friction, a short range attraction and, possibly, rolling resistance (RR) in contacts. The microstructure of the cohesive packing varies according to the assembling procedure, from rather densely packed if isolated particles are directly compressed to much looser if the formation of large aggregates is allowed prior to compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure P, acting on grains of diameter $a$, to maximum tensile contact force F0. At low P* the final structure depends on the level of velocity fluctuations at the early stages of cluster aggregation. With RR the coordination number approaches 2 in the limit of low initial velocities or large rolling friction. The force network generally comprises small hyperstatic clusters with forces of the order of F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly rearranges into force chain-like patterns. Density correlations witness a fractal structure, with dimension Df, up to some density-dependent blob size. WIth RR Df coincides with the ballistic aggregation result, despite a possibly different connectivity. Possible effects of some parameters on material strength are evoked. ", "machine_text": " Molecular dynamics simulations are used to study the composition and mechanical properties of a simplified two-dimensional model of a cohesive powder. The characteristics of the cohesive packaging depend on the particular procedure used for assembly, from denser structures when isolated particles are compressed to looser ones when large aggregates are combined prior to pressing. Essential in governing the behavior of the microstructure is the ratio of applied pressure acting on the grains of size $ a$ to the maximum tension of the contact force, given as ($P^*=F_a/F_0$). At lower $P^*$, the velocity fluctuations during the early phases of cluster aggregation determines how the microstructure develops. If rolling resistance is accounted for the final coordination number adapts to two when initial velocity is low or there is a considerable rolling friction. The pattern of contact forces shows small hyperstatic clusters linked by unstressed arms. As $P^*$ is increased, there is a restructuring towards force chain-like architecture. The density of the material presents fractal behavior which is determined by the density and blob size. The effects of some parameters on the strength of the cohesive material are also studied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3295}
{"prompt": "Rephrase the abstract of an article with title 'Reply to comment on \"Essence of intrinsic tunnelling: Distinguishing   intrinsic features from artefacts'.   The recent PRB, henceforth referred as Ref.[1], experimentally resolves the intrinsic shape of the c-axis current-voltage characteristics (IVC) of HTSC and demonstrates that at sufficiently high heat loads the heating-induced IVC nonlinearities exceed the intrinsic ones so radically that the latter might be safely ignored.   The author of the comment fails to take account of the experimental findings by Ref.[1] and seeks to cast doubt on all its conclusions through reference to a brush-like IVC, which is claimed to be free of heating. I will show that this claim lacks substantiation; indeed it can be stated with certainty that the IVC is not free from heating. I will further show that the data selected for this comment make it possible to explore for the first time the effect of temperature on a range of loads where the genuine response is not hidden by heating and to demonstrate for the first time that $R(T)$ of the same sample is responsible for a rich variety of IVC behaviours taken above and below $T_c$ at bath temperatures spanned over 180K. Thus these data in fact provide strong novel evidence in favour of the major conclusions by Ref.[1], in particular the extrinsic cause of the key findings by intrinsic tunnelling spectroscopy.  ", "human_text": "  The recent PRB, henceforth referred as Ref.[1], experimentally resolves the intrinsic shape of the c-axis current-voltage characteristics (IVC) of HTSC and demonstrates that at sufficiently high heat loads the heating-induced IVC nonlinearities exceed the intrinsic ones so radically that the latter might be safely ignored.   The author of the comment fails to take account of the experimental findings by Ref.[1] and seeks to cast doubt on all its conclusions through reference to a brush-like IVC, which is claimed to be free of heating. I will show that this claim lacks substantiation; indeed it can be stated with certainty that the IVC is not free from heating. I will further show that the data selected for this comment make it possible to explore for the first time the effect of temperature on a range of loads where the genuine response is not hidden by heating and to demonstrate for the first time that $R(T)$ of the same sample is responsible for a rich variety of IVC behaviours taken above and below $T_c$ at bath temperatures spanned over 180K. Thus these data in fact provide strong novel evidence in favour of the major conclusions by Ref.[1], in particular the extrinsic cause of the key findings by intrinsic tunnelling spectroscopy. ", "machine_text": " In this article, the author refutes a comment on an earlier PRB paper (Ref.[1]) which argued for the existence of intrinsic features of the c-axis current-voltage characteristics (IVC) of high-temperature superconducting (HTSC) materials at high heat loads, which Ref.[1] had suggested to be negligible. The author will demonstrate that the comment's IVC shape was indeed caused by heating, disproving the claim that it is intrinsic, and will present data which establishes that temperature has a strong effect on the range of loads which cannot be masked by heating, thus providing evidence to support Ref.[1]'s major conclusions. This data will therefore further the understandings of intrinsic tunnelling spectroscopy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0594}
{"prompt": "Rephrase the abstract of an article with title 'Ab initio wavefunction based methods for excited states in solids:   correlation corrections to the band structure of ionic oxides'.   Ab initio wavefunction based methods are applied to the study of electron correlation effects on the band structure of oxide systems. We choose MgO as a prototype closed-shell ionic oxide. Our analysis is based on a local Hamiltonian approach and performed on finite fragments cut from the infinite solid. Localized Wannier functions and embedding potentials are obtained from prior periodic Hartree-Fock (HF) calculations. We investigate the role of various electron correlation effects in reducing the HF band gap and modifying the band widths. On-site and nearest-neighbor charge relaxation as well as long-range polarization effects are calculated. Whereas correlation effects are essential for computing accurate band gaps, we found that they produce smaller changes on the HF band widths, at least for this material. Surprisingly, a broadening effect is obtained for the O 2p valence bands. The ab initio data are in good agreement with the energy gap and band width derived from thermoreflectance and x-ray photoemission experiments. The results show that the wavefunction based approach applied here allows for well controlled approximations and a transparent identification of the microscopic processes which determine the electronic band structure.  ", "human_text": "  Ab initio wavefunction based methods are applied to the study of electron correlation effects on the band structure of oxide systems. We choose MgO as a prototype closed-shell ionic oxide. Our analysis is based on a local Hamiltonian approach and performed on finite fragments cut from the infinite solid. Localized Wannier functions and embedding potentials are obtained from prior periodic Hartree-Fock (HF) calculations. We investigate the role of various electron correlation effects in reducing the HF band gap and modifying the band widths. On-site and nearest-neighbor charge relaxation as well as long-range polarization effects are calculated. Whereas correlation effects are essential for computing accurate band gaps, we found that they produce smaller changes on the HF band widths, at least for this material. Surprisingly, a broadening effect is obtained for the O 2p valence bands. The ab initio data are in good agreement with the energy gap and band width derived from thermoreflectance and x-ray photoemission experiments. The results show that the wavefunction based approach applied here allows for well controlled approximations and a transparent identification of the microscopic processes which determine the electronic band structure. ", "machine_text": " We explore the role of electron correlation effects on the band structure of oxide systems, namely MgO, through applying ab initio wavefunction based methods. Our approach consists of a local Hamiltonian approach and is performed on finite fragments cut from the infinite solid. Through using localized Wannier functions and embedding potentials obtained from prior periodic Hartree-Fock (HF) calculations, we calculate on-site, nearest-neighbor charge relaxation, and long-range polarization effects in order to examine their impact on diminishing the HF band gap and modifying the band widths. We find that correlation effects are essential for obtaining accurate band gap data, but make less of an impact on HF band widths. Intriguingly, we observe a broadening effect for O 2p valence bands. Our data align with energy gap and band width measurements through thermoreflectance and x-ray photoemission experiments, implying wavefunction based methods are capable of accurately approximating the electronic band structure while identifying its determining processes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1906}
{"prompt": "Rephrase the abstract of an article with title 'Spatially resolved kinematics and stellar populations of brightest   cluster and group galaxies'.   We present an examination of the kinematics and stellar populations of a sample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies (BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise Gemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these galaxies and use Lick indices to determine ages, metallicities and alpha-element abundance ratios out to at least their effective radii. We find that the BGGs and BCGs have very uniform masses, central ages and central metallicities. Examining the radial dependence of their stellar populations, we find no significant velocity dispersion, age, or alpha-enhancement gradients. However, we find a wide range of metallicity gradients, suggesting a variety of formation mechanisms. The range of metallicity gradients observed is surprising given the homogeneous environment these galaxies probe and their uniform central stellar populations. However, our results are inconsistent with any single model of galaxy formation and emphasize the need for more theoretical understanding of both the origins of metallicity gradients and galaxy formation itself. We postulate two possible physical causes for the different formation mechanisms.  ", "human_text": "  We present an examination of the kinematics and stellar populations of a sample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies (BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise Gemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these galaxies and use Lick indices to determine ages, metallicities and alpha-element abundance ratios out to at least their effective radii. We find that the BGGs and BCGs have very uniform masses, central ages and central metallicities. Examining the radial dependence of their stellar populations, we find no significant velocity dispersion, age, or alpha-enhancement gradients. However, we find a wide range of metallicity gradients, suggesting a variety of formation mechanisms. The range of metallicity gradients observed is surprising given the homogeneous environment these galaxies probe and their uniform central stellar populations. However, our results are inconsistent with any single model of galaxy formation and emphasize the need for more theoretical understanding of both the origins of metallicity gradients and galaxy formation itself. We postulate two possible physical causes for the different formation mechanisms. ", "machine_text": " This study examines the kinematics and stellar characteristics of a collection of three Brightest Group Galaxies (BGGs) and three Brightest Cluster Galaxies (BCGs) that are located in X-ray emitting clusters and groups. Applying high signal-to-noise spectra originating from the Gemini/GMOS, we compute the ages, metallicities, and abundance ratios of the sample galaxies up to their effective radii. We find that the BGGs and BCGs share similar bodies in terms of mass, central ages, and central levels of metallicity. By analyzing the variation of stellar elements over the radial parameter, we detect no substantial changes in velocity, age, or alpha-enhanced concentrations. Yet, the metallicity displayed significant scale difference, pointing to an assortment of formation mechanisms. This range of metallicity gradients opposes the unified state of the surveyed galaxies, indicating a need for more theories that would explain the origins of metallicity gradients and the general concept of galaxy formation. Ultimately, we introduce two prospective causes for the various formations mechanisms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3097}
{"prompt": "Rephrase the abstract of an article with title 'The Distance Geometry of Music'.   We demonstrate relationships between the classic Euclidean algorithm and many other fields of study, particularly in the context of music and distance geometry. Specifically, we show how the structure of the Euclidean algorithm defines a family of rhythms which encompass over forty timelines (\\emph{ostinatos}) from traditional world music. We prove that these \\emph{Euclidean rhythms} have the mathematical property that their onset patterns are distributed as evenly as possible: they maximize the sum of the Euclidean distances between all pairs of onsets, viewing onsets as points on a circle. Indeed, Euclidean rhythms are the unique rhythms that maximize this notion of \\emph{evenness}. We also show that essentially all Euclidean rhythms are \\emph{deep}: each distinct distance between onsets occurs with a unique multiplicity, and these multiplicies form an interval $1,2,...,k-1$. Finally, we characterize all deep rhythms, showing that they form a subclass of generated rhythms, which in turn proves a useful property called shelling. All of our results for musical rhythms apply equally well to musical scales. In addition, many of the problems we explore are interesting in their own right as distance geometry problems on the circle; some of the same problems were explored by Erd\\H{o}s in the plane.  ", "human_text": "  We demonstrate relationships between the classic Euclidean algorithm and many other fields of study, particularly in the context of music and distance geometry. Specifically, we show how the structure of the Euclidean algorithm defines a family of rhythms which encompass over forty timelines (\\emph{ostinatos}) from traditional world music. We prove that these \\emph{Euclidean rhythms} have the mathematical property that their onset patterns are distributed as evenly as possible: they maximize the sum of the Euclidean distances between all pairs of onsets, viewing onsets as points on a circle. Indeed, Euclidean rhythms are the unique rhythms that maximize this notion of \\emph{evenness}. We also show that essentially all Euclidean rhythms are \\emph{deep}: each distinct distance between onsets occurs with a unique multiplicity, and these multiplicies form an interval $1,2,...,k-1$. Finally, we characterize all deep rhythms, showing that they form a subclass of generated rhythms, which in turn proves a useful property called shelling. All of our results for musical rhythms apply equally well to musical scales. In addition, many of the problems we explore are interesting in their own right as distance geometry problems on the circle; some of the same problems were explored by Erd\\H{o}s in the plane. ", "machine_text": " We explore the relationship between Euclidean algorithms, music, and distance geometry. Specifically, we show how Euclidean algorithms can be used to create a family of rhythmic timelines, called Euclidean rhythms, that have the mathematical property of evenly distributed beat onsets. Evenness is defined as maximizing the sum of Euclidean distances between all pairs of onsets, treating onsets as points on a circle. In addition, Euclidean rhythms are shown to be deep - each distinct distance between onsets occurs with a unique multiplicity. We also characterize all deep rhythms, proving that they form a subclass of generated rhythms and demonstrating a useful property called shelling. Furthermore, many of the problems we explore are interesting from a distance geometry point of view, having been previously investigated by Erd\\H{o}s. These results can be applied to musical scales as well as rhythms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4085}
{"prompt": "Rephrase the abstract of an article with title 'Evaporation of buffer gas-thermalized anions out of a multipole rf ion   trap'.   We identify plain evaporation of ions as the fundamental loss mechanism out of a multipole ion trap. Using thermalized negative Cl- ions we find that the evaporative loss rate is proportional to a Boltzmann factor. This thermodynamic description sheds new light on the dynamics of particles in time-varying confining potentials. It specifically allows us to extract the effective depth of the ion trap as the activation energy for evaporation. As a function of the rf amplitude we find two distinct regimes related to the stability of motion of the trapped ions. For low amplitudes the entire trap allows for stable motion and the trap depth increases with the rf field. For larger rf amplitudes, however, rapid energy transfer from the field to the ion motion can occur at large trap radii, which leads to a reduction of the effective trapping volume. In this regime the trap depth decreases again with increasing rf amplitude. We give an analytical parameterization of the trap depth for various multipole traps that allows predictions of the most favorable trapping conditions.  ", "human_text": "  We identify plain evaporation of ions as the fundamental loss mechanism out of a multipole ion trap. Using thermalized negative Cl- ions we find that the evaporative loss rate is proportional to a Boltzmann factor. This thermodynamic description sheds new light on the dynamics of particles in time-varying confining potentials. It specifically allows us to extract the effective depth of the ion trap as the activation energy for evaporation. As a function of the rf amplitude we find two distinct regimes related to the stability of motion of the trapped ions. For low amplitudes the entire trap allows for stable motion and the trap depth increases with the rf field. For larger rf amplitudes, however, rapid energy transfer from the field to the ion motion can occur at large trap radii, which leads to a reduction of the effective trapping volume. In this regime the trap depth decreases again with increasing rf amplitude. We give an analytical parameterization of the trap depth for various multipole traps that allows predictions of the most favorable trapping conditions. ", "machine_text": "This investigation reveals the source and nature of thermal ion evaporation out of a multipole ion trap. Results indicate that the evaporation rate is connected to a Boltzmann factor, with an activation energy as an adjustable trap parameter. A dependence of the effective trap volume on the amplitude of the applied rf trapping field and an analytical parametersation of the trap depth are also outlined, thus aiding in determining the most favorable trapping conditions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0224}
{"prompt": "Rephrase the abstract of an article with title 'Almost Product Evaluation of Hankel Determinants'.   An extensive literature exists describing various techniques for the evaluation of Hankel determinants. The prevailing methods such as Dodgson condensation, continued fraction expansion, LU decomposition, all produce product formulas when they are applicable. We mention the classic case of the Hankel determinants with binomial entries ${3k+2 \\choose k}$ and those with entries ${3k \\choose k}$; both of these classes of Hankel determinants have product form evaluations. The intermediate case, ${3k+1 \\choose k}$ has not been evaluated. There is a good reason for this: these latter determinants do not have product form evaluations.   In this paper we evaluate the Hankel determinant of ${3k+1 \\choose k}$. The evaluation is a sum of a small number of products, an almost product.   The method actually provides more, and as applications, we present the salient points for the evaluation of a number of other Hankel determinants with polynomial entries, along with product and almost product form evaluations at special points.  ", "human_text": "  An extensive literature exists describing various techniques for the evaluation of Hankel determinants. The prevailing methods such as Dodgson condensation, continued fraction expansion, LU decomposition, all produce product formulas when they are applicable. We mention the classic case of the Hankel determinants with binomial entries ${3k+2 \\choose k}$ and those with entries ${3k \\choose k}$; both of these classes of Hankel determinants have product form evaluations. The intermediate case, ${3k+1 \\choose k}$ has not been evaluated. There is a good reason for this: these latter determinants do not have product form evaluations.   In this paper we evaluate the Hankel determinant of ${3k+1 \\choose k}$. The evaluation is a sum of a small number of products, an almost product.   The method actually provides more, and as applications, we present the salient points for the evaluation of a number of other Hankel determinants with polynomial entries, along with product and almost product form evaluations at special points. ", "machine_text": "This paper examines the almost product evaluation of Hankel determinants in order to find a product form evaluation for the intermediate case of ${3k+1 \\choose k}$. This Hankel determinant has not yet been evaluated due to its lack of product form evaluations. The method used in this paper offers a sum of a small number of products, referred to as an almost product, and thus provides an evaluation. Furthermore, the method demonstrates the salient points for the evaluation of other Hankel determinants with polynomial entries, as well as product and almost product form evaluations at special points.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3398}
{"prompt": "Rephrase the abstract of an article with title 'Deformed Wigner crystal in a one-dimensional quantum dot'.   The spatial Fourier spectrum of the electron density distribution in a finite 1D system and the distribution function of electrons over single-particle states are studied in detail to show that there are two universal features in their behavior, which characterize the electron ordering and the deformation of Wigner crystal by boundaries. The distribution function has a $\\delta$-like singularity at the Fermi momentum $k_F$. The Fourier spectrum of the density has a step-like form at the wavevector $2k_F$, with the harmonics being absent or vanishing above this threshold. These features are found by calculations using exact diagonalization method. They are shown to be caused by Wigner ordering of electrons, affected by the boundaries. However the common Luttinger liquid model with open boundaries fails to capture these features, because it overestimates the deformation of the Wigner crystal. An improvement of the Luttinger liquid model is proposed which allows one to describe the above features correctly. It is based on the corrected form of the density operator conserving the particle number.  ", "human_text": "  The spatial Fourier spectrum of the electron density distribution in a finite 1D system and the distribution function of electrons over single-particle states are studied in detail to show that there are two universal features in their behavior, which characterize the electron ordering and the deformation of Wigner crystal by boundaries. The distribution function has a $\\delta$-like singularity at the Fermi momentum $k_F$. The Fourier spectrum of the density has a step-like form at the wavevector $2k_F$, with the harmonics being absent or vanishing above this threshold. These features are found by calculations using exact diagonalization method. They are shown to be caused by Wigner ordering of electrons, affected by the boundaries. However the common Luttinger liquid model with open boundaries fails to capture these features, because it overestimates the deformation of the Wigner crystal. An improvement of the Luttinger liquid model is proposed which allows one to describe the above features correctly. It is based on the corrected form of the density operator conserving the particle number. ", "machine_text": "A study of the electron ordering and deformation of the Wigner crystal in a one-dimensional quantum dot is presented. By examining the spatial Fourier spectrum of the electron density distribution and the distribution function of electrons across single-particle states, two distinct features of the system are determined. These include a $\\delta$-like singularity at the Fermi momentum $k_F$ in the distribution function and a step-like form at the wavevector $2k_F$, with final harmonics being completely absent or vanishing. These features are established via calculations generated from a exact diagonalization method. It is emphasized that their presence arises from the Wigner ordering of electrons, which is influenced by the boundaries. A modification of the Luttinger liquid model that incorporates a corrected version of the density operator preserving particle number is proposed. This refinement enables one to accurately account for the two dynamic characteristics associated with the system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1445}
{"prompt": "Rephrase the abstract of an article with title 'TrES-3: A Nearby, Massive, Transiting Hot Jupiter in a 31-Hour Orbit'.   We describe the discovery of a massive transiting hot Jupiter with a very short orbital period (1.30619 d), which we name TrES-3. From spectroscopy of the host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +- 0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We estimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal variation of our high-precision radial velocity measurements. This variation has a period and phase consistent with our transit photometry. Our spectra show no evidence of line bisector variations that would indicate a blended eclipsing binary star. From detailed modeling of our B and z photometry of the 2.5%-deep transits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary radius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of the known transiting exoplanets, facilitating studies of orbital decay and mass loss due to evaporation, and making it an excellent target for future studies of infrared emission and reflected starlight.  ", "human_text": "  We describe the discovery of a massive transiting hot Jupiter with a very short orbital period (1.30619 d), which we name TrES-3. From spectroscopy of the host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +- 0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We estimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal variation of our high-precision radial velocity measurements. This variation has a period and phase consistent with our transit photometry. Our spectra show no evidence of line bisector variations that would indicate a blended eclipsing binary star. From detailed modeling of our B and z photometry of the 2.5%-deep transits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary radius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of the known transiting exoplanets, facilitating studies of orbital decay and mass loss due to evaporation, and making it an excellent target for future studies of infrared emission and reflected starlight. ", "machine_text": " This paper presents the discovery of TrES-3, a close, massive hot Jupiter with an orbit that completes one rotation every 31 hours. We have conducted spectroscopy of the star GSC 03089-00929 to determine its properties, including an effective temperature of 5720 +/- 150 K, a stellar logg of 4.6 +/- 0.3 and a rotational velocity of less than 2 km/s. Our radial velocity measurements indicate a planetary mass of 1.92 +/- 0.23 Jupiter masses. Our photometric analysis of the 2.5%-deep transits reveals a stellar radius of 0.802 +/- 0.046 solar radii and a planetary radius of 1.295 +/- 0.081 Jupiter radii. The short orbital period of the planet presents new opportunities for investigating orbital decay and evaporation, as well as infrared emission and reflected starlight.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2004}
{"prompt": "Rephrase the abstract of an article with title 'Fractal dimension of domain walls in two-dimensional Ising spin glasses'.   We study domain walls in 2d Ising spin glasses in terms of a minimum-weight path problem. Using this approach, large systems can be treated exactly. Our focus is on the fractal dimension $d_f$ of domain walls, which describes via $<\\ell >\\simL^{d_f}$ the growth of the average domain-wall length with %% systems size $L\\times L$. %% 20.07.07 OM %% Exploring systems up to L=320 we yield $d_f=1.274(2)$ for the case of Gaussian disorder, i.e. a much higher accuracy compared to previous studies. For the case of bimodal disorder, where many equivalent domain walls exist due to the degeneracy of this model, we obtain a true lower bound $d_f=1.095(2)$ and a (lower) estimate $d_f=1.395(3)$ as upper bound. Furthermore, we study the distributions of the domain-wall lengths. Their scaling with system size can be described also only by the exponent $d_f$, i.e. the distributions are monofractal. Finally, we investigate the growth of the domain-wall width with system size (``roughness'') and find a linear behavior.  ", "human_text": "  We study domain walls in 2d Ising spin glasses in terms of a minimum-weight path problem. Using this approach, large systems can be treated exactly. Our focus is on the fractal dimension $d_f$ of domain walls, which describes via $<\\ell >\\simL^{d_f}$ the growth of the average domain-wall length with %% systems size $L\\times L$. %% 20.07.07 OM %% Exploring systems up to L=320 we yield $d_f=1.274(2)$ for the case of Gaussian disorder, i.e. a much higher accuracy compared to previous studies. For the case of bimodal disorder, where many equivalent domain walls exist due to the degeneracy of this model, we obtain a true lower bound $d_f=1.095(2)$ and a (lower) estimate $d_f=1.395(3)$ as upper bound. Furthermore, we study the distributions of the domain-wall lengths. Their scaling with system size can be described also only by the exponent $d_f$, i.e. the distributions are monofractal. Finally, we investigate the growth of the domain-wall width with system size (``roughness'') and find a linear behavior. ", "machine_text": " We investigate the properties of domain walls in two-dimensional Ising spin glasses by implementing minimum-weight path approaches to analyse systems of up to 320 sizes. The fractal dimension of these domain walls is reported as $d_f=1.274(2)$ for the cases of Gaussian disorder and $d_f=1.095(2)$ for the bimodal disorder. Moreover, the distribution of domain-wall lengths show scaling with system size and can be explained by the same fractal exponent $d_f$, pointing to a monofractal nature. Furthermore, the growth of the domain-wall width with the system size is linear.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2004}
{"prompt": "Rephrase the abstract of an article with title 'Link concordance, homology cobordism, and Hirzebruch-type defects from   iterated p-covers'.   We obtain new invariants of topological link concordance and homology cobordism of 3-manifolds from Hirzebruch-type intersection form defects of towers of iterated p-covers. Our invariants can extract geometric information from an arbitrary depth of the derived series of the fundamental group, and can detect torsion which is invisible via signature invariants. Applications illustrating these features include the following: (1) There are infinitely many homology equivalent rational 3-spheres which are indistinguishable via multisignatures, eta-invariants, and L2-signatures but have distinct homology cobordism types. (2) There is an infinite family of 2-torsion (amphichiral) knots, including the figure eight knot, with non-slice iterated Bing doubles; as a special case, we give the first proof of the conjecture that the Bing double of the figure eight knot is not slice. (3) There exist infinitely many torsion elements at any depth of the Cochran-Orr-Teichner filtration of link concordance.  ", "human_text": "  We obtain new invariants of topological link concordance and homology cobordism of 3-manifolds from Hirzebruch-type intersection form defects of towers of iterated p-covers. Our invariants can extract geometric information from an arbitrary depth of the derived series of the fundamental group, and can detect torsion which is invisible via signature invariants. Applications illustrating these features include the following: (1) There are infinitely many homology equivalent rational 3-spheres which are indistinguishable via multisignatures, eta-invariants, and L2-signatures but have distinct homology cobordism types. (2) There is an infinite family of 2-torsion (amphichiral) knots, including the figure eight knot, with non-slice iterated Bing doubles; as a special case, we give the first proof of the conjecture that the Bing double of the figure eight knot is not slice. (3) There exist infinitely many torsion elements at any depth of the Cochran-Orr-Teichner filtration of link concordance. ", "machine_text": "This article examines new methods for determining the link concordance, homology cobordism, and Hirzebruch-type intersection form defects of towers of iterated p-covers. We illustrate our methods to show that there is a vast range of results, including detection of infinitely many homology equivalent rational 3-spheres which are indistinguishable through multisignatures, eta-invariants, and L2-signatures, and the proof of the conjecture that the Bing double of the figure eight knot is not slice. In addition, our invariants are able to detect torsion which is not visible through signature invariants, illustrating the presence of infinitely many torsion elements at any depth of the Cochran-Orr-Teichner filtration of link concordance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0088}
{"prompt": "Rephrase the abstract of an article with title 'Spin 1/2 Fermions in the Unitary Limit.I'.   This report concerns the energy of a zero-temperature many-body system of spin 1/2 fermions interacting via a two-body potential with a free space infinite scattering length and zero effective range; the Unitary limit. Given the corresponding phase-shift $\\delta(k)=\\pi/2$ a one-term separable potential is obtained by inverse scattering assuming a momentum cut-off $\\Lambda$ such that $\\delta(k)=0$ for $k>\\Lambda$. The \\it effective \\rm interaction in the many-body system is calculated in a pp-ladder approximation with Pauli-blocking but neglecting mean-field (dispersion) corrections; effective mass $m^{*}=1$. Using only the zero relative momentum component of this interaction the total energy is $\\xi=4/9$ (in units of the fermigas), a result reported by several previous authors. Integrating the momentum dependent interaction over the Fermi sea this energy is revised to $\\xi=0.24.$ This result is independent of density and of the cut-off $\\Lambda$ if $\\Lambda > \\sim 3k_{f}$.   With $m^{*}\\neq 1$ there is however a strong dependence on this cut-off.   Including hh-ladders estimates give $\\xi=0.4\\leftrightarrow 0.6$, but a reliable result would in this case require a Green's function calculation.  ", "human_text": "  This report concerns the energy of a zero-temperature many-body system of spin 1/2 fermions interacting via a two-body potential with a free space infinite scattering length and zero effective range; the Unitary limit. Given the corresponding phase-shift $\\delta(k)=\\pi/2$ a one-term separable potential is obtained by inverse scattering assuming a momentum cut-off $\\Lambda$ such that $\\delta(k)=0$ for $k>\\Lambda$. The \\it effective \\rm interaction in the many-body system is calculated in a pp-ladder approximation with Pauli-blocking but neglecting mean-field (dispersion) corrections; effective mass $m^{*}=1$. Using only the zero relative momentum component of this interaction the total energy is $\\xi=4/9$ (in units of the fermigas), a result reported by several previous authors. Integrating the momentum dependent interaction over the Fermi sea this energy is revised to $\\xi=0.24.$ This result is independent of density and of the cut-off $\\Lambda$ if $\\Lambda > \\sim 3k_{f}$.   With $m^{*}\\neq 1$ there is however a strong dependence on this cut-off.   Including hh-ladders estimates give $\\xi=0.4\\leftrightarrow 0.6$, but a reliable result would in this case require a Green's function calculation. ", "machine_text": "  This article reviews the energy levels of spin-1/2 fermions when interacting through a two-body potential with an infinite scattering length and zero effective range, otherwise known as the Unitary limit. Using a single term separable potential with a momentum cut-off of $\\Lambda$, the many-body system is calculated with Pauli blocking, neglecting any mean-field corrections or changes in mass. The energy is reported as $\\xi = 4/9$, a result independently offered by previous work, but revised to $\\xi = 0.24$ when integrating the momentum dependent interaction with the Fermi sea. Additionally, consideration of hh-ladders provide suggested energy estimates of $\\xi = 0.4$ to 0.6, though a Green's function calculation would be required for a successful and reliable outcome.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0944}
{"prompt": "Rephrase the abstract of an article with title 'Casimir effect in a 6D warped flux compactification model'.   We discuss Casimir effect of a massless, minimally coupled scalar field in a 6D warped flux compactification model and its implications for the hierarchy and cosmological constant problems, which are longstanding puzzles in phenomenology and cosmology. Due to the scale invariance of the background theory, the 4D effective theory contains a volume modulus. To stabilize the modulus, we consider one-loop corrections to the effective potential by the Casimir effect. The one-loop effective potential for the volume modulus has a form which is very similar to Coleman-Weinberg potential. We evaluate coefficients appearing in the effective potential by employing zeta function regularization and heat kernel analysis. The volume modulus is stabilized for smaller degrees of warping, below a critical value, which depends on deficit angle of the reference brane. After stabilizing the modulus, it is possible to obtain observed values of the mass ratio between the fundamental energy scales and a tiny effective cosmological constant (though its sign is negative). The degree of warping should be tuned to be close to the critical value, not as severely as the original fine-tuning.  ", "human_text": "  We discuss Casimir effect of a massless, minimally coupled scalar field in a 6D warped flux compactification model and its implications for the hierarchy and cosmological constant problems, which are longstanding puzzles in phenomenology and cosmology. Due to the scale invariance of the background theory, the 4D effective theory contains a volume modulus. To stabilize the modulus, we consider one-loop corrections to the effective potential by the Casimir effect. The one-loop effective potential for the volume modulus has a form which is very similar to Coleman-Weinberg potential. We evaluate coefficients appearing in the effective potential by employing zeta function regularization and heat kernel analysis. The volume modulus is stabilized for smaller degrees of warping, below a critical value, which depends on deficit angle of the reference brane. After stabilizing the modulus, it is possible to obtain observed values of the mass ratio between the fundamental energy scales and a tiny effective cosmological constant (though its sign is negative). The degree of warping should be tuned to be close to the critical value, not as severely as the original fine-tuning. ", "machine_text": " This paper examines the Casimir effect for a 6D warped flux compactification model and its possible resolution to some long-standing problems. Specifically, the massless and minimally coupled scalar field is conceptually consistent with a 4D effective theory, which has a volume modulus that must be stabilised. We use a combination of zeta function regularisation and heat-kernel calculations to evaluate the one-loop effective potential of the modulus and find that it is analogous to Coleman-Weinberg potential. When the tuning of the degree of warping is close to the critical value, we can observe the desired mass ratio between two basic energies and a small, but negative, effective cosmological constant. This situation is a much less stringent fine-tuning than earlier models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3623}
{"prompt": "Rephrase the abstract of an article with title 'High Sensitivity Array Observations of the $z = 4.4$ QSO BRI 1335-0417'.   We present sensitive phase-referenced VLBI results on the radio continuum emission from the $z=4.4$ QSO BRI 1335--0417. The observations were carried out at 1.4 GHz using the High Sensitivity Array (HSA). Our sensitive VLBI image at $189 \\times 113$ mas ($1.25 \\times 0.75$ kpc) resolution shows continuum emission in BRI 1335--0417 with a total flux density of $208 \\pm 46 \\mu$Jy, consistent with the flux density measured with the VLA. The size of the source at FWHM is $255 \\times 138$ mas ($1.7 \\times 0.9$ kpc) and the derived intrinsic brightness temperature is $\\sim 3.5\\times 10^4$ K. No continuum emission is detected at the full VLBI resolution ($32 \\times 7$ mas, $211 \\times 46$ pc), with a 4$\\sigma$ point source upper limit of 34 $\\mu$Jy beam$^{-1}$, or an upper limit to the intrinsic brightness temperature of $5.6\\times 10^5$ K. The highest angular resolution with at least a 4.5$\\sigma$ detection of the radio continuum emission is $53 \\times 27$ mas ($0.35 \\times 0.18$ kpc). At this resolution, the image shows a continuum feature in BRI 1335--0417 with a size of $64 \\times 35$ mas ($0.42 \\times 0.23$ kpc) at FWHM, and intrinsic brightness temperature of $\\sim 2\\times 10^5$ K. The extent of the observed continuum sources at 1.4 GHz and the derived brightness temperatures show that the radio emission (and thus presumably the far-infrared emission) in BRI 1335--0417 is powered by a major starburst, with a massive star formation rate of order a few thousand M_{\\odot} {\\rm yr}^{-1}$. Moreover, the absence of any compact high-brightness temperature source suggests that there is no radio-loud AGN in this $z=4.4$ QSO.  ", "human_text": "  We present sensitive phase-referenced VLBI results on the radio continuum emission from the $z=4.4$ QSO BRI 1335--0417. The observations were carried out at 1.4 GHz using the High Sensitivity Array (HSA). Our sensitive VLBI image at $189 \\times 113$ mas ($1.25 \\times 0.75$ kpc) resolution shows continuum emission in BRI 1335--0417 with a total flux density of $208 \\pm 46 \\mu$Jy, consistent with the flux density measured with the VLA. The size of the source at FWHM is $255 \\times 138$ mas ($1.7 \\times 0.9$ kpc) and the derived intrinsic brightness temperature is $\\sim 3.5\\times 10^4$ K. No continuum emission is detected at the full VLBI resolution ($32 \\times 7$ mas, $211 \\times 46$ pc), with a 4$\\sigma$ point source upper limit of 34 $\\mu$Jy beam$^{-1}$, or an upper limit to the intrinsic brightness temperature of $5.6\\times 10^5$ K. The highest angular resolution with at least a 4.5$\\sigma$ detection of the radio continuum emission is $53 \\times 27$ mas ($0.35 \\times 0.18$ kpc). At this resolution, the image shows a continuum feature in BRI 1335--0417 with a size of $64 \\times 35$ mas ($0.42 \\times 0.23$ kpc) at FWHM, and intrinsic brightness temperature of $\\sim 2\\times 10^5$ K. The extent of the observed continuum sources at 1.4 GHz and the derived brightness temperatures show that the radio emission (and thus presumably the far-infrared emission) in BRI 1335--0417 is powered by a major starburst, with a massive star formation rate of order a few thousand M_{\\odot} {\\rm yr}^{-1}$. Moreover, the absence of any compact high-brightness temperature source suggests that there is no radio-loud AGN in this $z=4.4$ QSO. ", "machine_text": " Using the High Sensitivity Array (HSA) at 1.4 GHz, we conducted highly-sensitive phase-referenced VLBI observations of the $z = 4.4$ QSO BRI 1335-0417. Our results revealed a total recorded flux density of $208 \\pm 46 \\mu$Jy and source size at the FWHM measure of $255 \\times 138$ mas ($1.7 \\times 0.9$ kpc). Through the image at the highest angular resolution, the detected continuum source's size was measured to be $64 \\times 35$ mas ($0.42 \\times 0.23$ kpc) with an intrinsic brightness temperature of $\\sim 2\\times 10^5$ K. As the radio emission was found to have no high-brightness temperature source, it is believed that this $z=4.4$ QSO has no radio-loud AGN and is instead being powered by a starburst with a star formation rate of a few thousand M_{\\odot} yr$^{-1}$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0899}
{"prompt": "Rephrase the abstract of an article with title 'Orbital magnetization and its effects in spin-chiral ferromagnetic   Kagome lattice'.   Recently, Berry phase in the semiclassical dynamical of Bloch electrons has been found to make a correction to the phase-space density of states and a general multi-band formula for finite-temperature orbital magnetization has been given [Phys. Rev. Lett. \\textbf{97}, 026603 (2006)], where the orbital magnetization $\\mathcal{M}$ consists of two parts, i.e., the conventional part $M_{c}$ and the Berry-phase correction part $M_{\\Omega}$. Using this general formula, we theoretically investigate the orbital magnetization and its effects on thermoelectric transport and magnetic susceptibility properties of the two-dimensional \\textit{kagom\\'{e}} lattice with spin anisotropies included. The study in this paper is highly interesting by the occurrence of nonzero Chern number in the lattice. The spin chirality parameter $\\phi$ (see text) results in profound effects on the orbital magnetization properties. It is found that the two parts in orbital magnetization opposite each other. In particular, we show that $M_{c}$ and $M_{\\Omega}$ yield the paramagnetic and diamagnetic responses, respectively. It is further shown that the orbital magnetization displays fully different behavior in the metallic and insulating regions, which is due to the different roles $M_{c}$ and $M_{\\Omega}$ play in these two regions. The anomalous Nernst conductivity is also calculated, which displays a peak-valley structure as a function of the electron Fermi energy.  ", "human_text": "  Recently, Berry phase in the semiclassical dynamical of Bloch electrons has been found to make a correction to the phase-space density of states and a general multi-band formula for finite-temperature orbital magnetization has been given [Phys. Rev. Lett. \\textbf{97}, 026603 (2006)], where the orbital magnetization $\\mathcal{M}$ consists of two parts, i.e., the conventional part $M_{c}$ and the Berry-phase correction part $M_{\\Omega}$. Using this general formula, we theoretically investigate the orbital magnetization and its effects on thermoelectric transport and magnetic susceptibility properties of the two-dimensional \\textit{kagom\\'{e}} lattice with spin anisotropies included. The study in this paper is highly interesting by the occurrence of nonzero Chern number in the lattice. The spin chirality parameter $\\phi$ (see text) results in profound effects on the orbital magnetization properties. It is found that the two parts in orbital magnetization opposite each other. In particular, we show that $M_{c}$ and $M_{\\Omega}$ yield the paramagnetic and diamagnetic responses, respectively. It is further shown that the orbital magnetization displays fully different behavior in the metallic and insulating regions, which is due to the different roles $M_{c}$ and $M_{\\Omega}$ play in these two regions. The anomalous Nernst conductivity is also calculated, which displays a peak-valley structure as a function of the electron Fermi energy. ", "machine_text": " This paper examines the orbital magnetization and its consequences on the thermoelectric transport and magnetization features of a two-dimensional Kagome lattice with spin anisotropy present. In addition to a conventional term, the orbital magnetization consists of a correction made by a Berry phase in the Bloch electrons' semi-classical dynamics. We demonstrate that there is an opposition in behavior between the two orbital magnetization pieces; $M_{c}$ and $M_{\\Omega}$ displaying a paramagnetic and diamagnetic response respectively. We also show that change in the spin chirality parameter $\\phi$ has a profound effect on the orbital magnetization property, further demonstrating the peculiarity of its behavior depending on whether the system is in a metallic or insulating region. Finally, the anomalous Nernst conductivity is computed and gives distinct peak-valley structure when the electron Fermi energy is changed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3305}
{"prompt": "Rephrase the abstract of an article with title 'Stability of the superconducting state in YBa_2Cu_3O_7'.   The nonadiabatic Heisenberg model (NHM) proposed as an extension of the Heisenberg model makes a contribution to the eigenstate problem of superconductivity. The Hamiltonian H^n derived within this group-theoretical model has superconducting eigenstates if and only if the considered material possesses a narrow, roughly half-filled \"superconducting\" energy band of special symmetry in its band structure. This paper shows that the high-temperature superconductor YBa_2Cu_3O_7 possesses such a superconducting band. This new result together with previous observations about other superconductors and non-superconductors corroborates the theoretical evidence within the NHM that stable superconducting states are connected with superconducting bands. It is proposed that the type of superconductivity, i.e., whether the material is a conventional low-T_c or a high-T_c superconductor, is determined by the energetically lowest boson excitations that carry the crystal spin 1*hbar and are sufficiently stable to transport this crystal spin-angular momentum through the crystal. This mechanism provides the electron-phonon mechanism that enters the BCS theory in conventional superconductors.  ", "human_text": "  The nonadiabatic Heisenberg model (NHM) proposed as an extension of the Heisenberg model makes a contribution to the eigenstate problem of superconductivity. The Hamiltonian H^n derived within this group-theoretical model has superconducting eigenstates if and only if the considered material possesses a narrow, roughly half-filled \"superconducting\" energy band of special symmetry in its band structure. This paper shows that the high-temperature superconductor YBa_2Cu_3O_7 possesses such a superconducting band. This new result together with previous observations about other superconductors and non-superconductors corroborates the theoretical evidence within the NHM that stable superconducting states are connected with superconducting bands. It is proposed that the type of superconductivity, i.e., whether the material is a conventional low-T_c or a high-T_c superconductor, is determined by the energetically lowest boson excitations that carry the crystal spin 1*hbar and are sufficiently stable to transport this crystal spin-angular momentum through the crystal. This mechanism provides the electron-phonon mechanism that enters the BCS theory in conventional superconductors. ", "machine_text": "This paper examines the stability of the superconducting state in YBa_2Cu_3O_7. It is shown that the material possesses a narrow, roughly half-filled energy band of special symmetry. Through the nonadiabatic Heisenberg model and its ensuing Hamiltonian, this band is identified with the eigenstate problem of superconductivity. This discovery establishes that the symmetrical nature of the energy band is a prerequisite for stable superconducting states. The proposed mechanism for superconductivity suggests that the type of superconductivity, as well as its critical temperature, is determined by the energetically lowest excitations that transport crystal spin-angular momentum. This provides a framework for the electron-phonon mechanism central to the BCS theory of conventional superconductors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.211}
{"prompt": "Rephrase the abstract of an article with title 'Fifteen Years of High-Resolution Radio Imaging of Supernova 1987A'.   Supernova 1987A in the Large Magellanic Cloud provides a spectacularly detailed view of the aftermath of a core-collapse explosion. The supernova ejecta initially coasted outward at more than 10% of the speed of light, but in 1990 were observed to decelerate rapidly as they began to encounter dense circumstellar material expelled by the progenitor star. The resulting shock has subsequently produced steadily brightening radio synchrotron emission, which is resolved by the Australia Telescope Compact Array (ATCA) into an expanding limb-brightened shell. Here we present 15 years of ATCA imaging of Supernova 1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio remnant has accelerated in its expansion over this period, from approx 3600 km/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of the evolving X-ray shell have been ~15% smaller than the corresponding radio values, but a simultaneous Fourier analysis of both radio and X-ray data eliminates this discrepancy, and yields a current diameter for the shell in both wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is seen in radio images at all ATCA epochs: the eastern and western rims have higher fluxes than the northern and southern regions, indicating that most of the radio emission comes from the equatorial plane of the system, where the progenitor star's circumstellar wind is thought to be densest. The eastern lobe is brighter than and further from the supernova site than the western lobe, suggesting an additional asymmetry in the initial distribution of supernova ejecta.  ", "human_text": "  Supernova 1987A in the Large Magellanic Cloud provides a spectacularly detailed view of the aftermath of a core-collapse explosion. The supernova ejecta initially coasted outward at more than 10% of the speed of light, but in 1990 were observed to decelerate rapidly as they began to encounter dense circumstellar material expelled by the progenitor star. The resulting shock has subsequently produced steadily brightening radio synchrotron emission, which is resolved by the Australia Telescope Compact Array (ATCA) into an expanding limb-brightened shell. Here we present 15 years of ATCA imaging of Supernova 1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio remnant has accelerated in its expansion over this period, from approx 3600 km/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of the evolving X-ray shell have been ~15% smaller than the corresponding radio values, but a simultaneous Fourier analysis of both radio and X-ray data eliminates this discrepancy, and yields a current diameter for the shell in both wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is seen in radio images at all ATCA epochs: the eastern and western rims have higher fluxes than the northern and southern regions, indicating that most of the radio emission comes from the equatorial plane of the system, where the progenitor star's circumstellar wind is thought to be densest. The eastern lobe is brighter than and further from the supernova site than the western lobe, suggesting an additional asymmetry in the initial distribution of supernova ejecta. ", "machine_text": " For the past 15 years, the Australia Telescope Compact Array has observed the aftermath of Supernova 1987A located in the Large Magellanic Cloud, by making high-resolution radio imaging of this spectacular core-collapse explosion. The initial expansion of the ejecta was exceptionally high and fast, but in 1990 the deceleration began due to dense circumstellar material expelled from the progenitor star, resulting in brightening radio synchrotron emission, discernable by the ATCA. We discuss that the remnant has been accelerating in its expansion, from about 3600 km/s in 1992 to about 5200 km/s by the end of 2006, the X-ray shell printed 15% smaller than the corresponding radio values, but a Fourier analysis of both reveals a diameter of 1.7 arcsec. An asymmetric brightness distribution occurred in the images at all ATCA epochs, where the eastern rim is brighter and further from the supernova site than the western lobe, indicating an uneven initial distribution of the supernova ejecta.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0057}
{"prompt": "Rephrase the abstract of an article with title 'A multi band study of the optically dark GRB 051028'.   Observations were made of the optical afterglow of GRB 051028 with the Lulin observatory's 1.0 m telescope and the WIDGET robotic telescope system. R band photometric data points were obtained on 2005 October 28 (UT), or 0.095-0.180 days after the burst. There is a possible plateau in the optical light curve around 0.1 days after the burst; the light curve resembles optically bright afterglows (e.g. GRB 041006, GRB 050319, GRB060605) in shape of the light curve but not in brightness. The brightness of the GRB 051028 afterglow is 3 magnitudes fainter than that of one of the dark events, GRB 020124. Optically dark GRBs have been attributed to dust extinction within the host galaxy or high redshift. However, the spectrum analysis of the X-rays implies that there is no significant absorption by the host galaxy. Furthermore, according to the model theoretical calculation of the Ly$\\alpha$ absorption to find the limit of GRB 051028's redshift, the expected $R$ band absorption is not high enough to explain the darkness of the afterglow. While the present results disfavor either the high-redshift hypothesis or the high extinction scenario for optically dark bursts, they are consistent with the possibility that the brightness of the optical afterglow, intrinsically dark.  ", "human_text": "  Observations were made of the optical afterglow of GRB 051028 with the Lulin observatory's 1.0 m telescope and the WIDGET robotic telescope system. R band photometric data points were obtained on 2005 October 28 (UT), or 0.095-0.180 days after the burst. There is a possible plateau in the optical light curve around 0.1 days after the burst; the light curve resembles optically bright afterglows (e.g. GRB 041006, GRB 050319, GRB060605) in shape of the light curve but not in brightness. The brightness of the GRB 051028 afterglow is 3 magnitudes fainter than that of one of the dark events, GRB 020124. Optically dark GRBs have been attributed to dust extinction within the host galaxy or high redshift. However, the spectrum analysis of the X-rays implies that there is no significant absorption by the host galaxy. Furthermore, according to the model theoretical calculation of the Ly$\\alpha$ absorption to find the limit of GRB 051028's redshift, the expected $R$ band absorption is not high enough to explain the darkness of the afterglow. While the present results disfavor either the high-redshift hypothesis or the high extinction scenario for optically dark bursts, they are consistent with the possibility that the brightness of the optical afterglow, intrinsically dark. ", "machine_text": "This article presents a multi-band analysis of GRB 051028's optically dark afterglow, utilizing the Lulin observatory's 1.0m telescope and the WIDGET robotic telescope system. Upon measuring R-band photometric data points on zero-point-nine-five and one-point-eight days after the burst, a plateau in the optical light curve was identified. While its shape was reminiscent of optically bright afterglows, the magnitude was three magnitudes fainter than that of GRB 020124. Examining the spectrum analysis of X-rays, no significant host-galaxy absorption was inferred. Further computational modelling of the Ly$\\alpha$ absorption could not confirm a high redshift. These results dispelled both the high-redshift and the high-extinction hypotheses on the optically dark burst, leading to the conclusion that the afterglow was, intrinsically, dim.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0561}
{"prompt": "Rephrase the abstract of an article with title 'Spectrum of cosmic rays, produced in supernova remnants'.   Nonlinear kinetic theory of cosmic ray (CR) acceleration in supernova remnants is employed to calculate CR spectra. The magnetic field in SNRs is assumed to be significantly amplified by the efficiently accelerating nuclear CR component. It is shown that the calculated CR spectra agree in a satisfactory way with the existing measurements up to the energy $10^{17}$ eV. The power law spectrum of protons extends up to the energy $3\\times 10^{15}$ eV with a subsequent exponential cutoff. It gives a natural explanation for the observed knee in the Galactic CR spectrum. The maximum energy of the accelerated nuclei is proportional to their charge number $Z$. Therefore the break in the Galactic CR spectrum is the result of the contribution of progressively heavier species in the overall CR spectrum so that at $10^{17}$ eV the CR spectrum is dominated by iron group nuclei. It is shown that this component plus a suitably chosen extragalactic CR component can give a consistent description for the entire Galactic CR spectrum.  ", "human_text": "  Nonlinear kinetic theory of cosmic ray (CR) acceleration in supernova remnants is employed to calculate CR spectra. The magnetic field in SNRs is assumed to be significantly amplified by the efficiently accelerating nuclear CR component. It is shown that the calculated CR spectra agree in a satisfactory way with the existing measurements up to the energy $10^{17}$ eV. The power law spectrum of protons extends up to the energy $3\\times 10^{15}$ eV with a subsequent exponential cutoff. It gives a natural explanation for the observed knee in the Galactic CR spectrum. The maximum energy of the accelerated nuclei is proportional to their charge number $Z$. Therefore the break in the Galactic CR spectrum is the result of the contribution of progressively heavier species in the overall CR spectrum so that at $10^{17}$ eV the CR spectrum is dominated by iron group nuclei. It is shown that this component plus a suitably chosen extragalactic CR component can give a consistent description for the entire Galactic CR spectrum. ", "machine_text": " An analysis of nonlinear kinetic theory and observations of cosmic rays (CRs) reveals the behavior of CRs produced by supernova remnants. The magnetic field in the supernova remnants is believed to be amplified by the accelerated nuclear CR component, allowing for calculations that result in CR spectra that are consistent with existing energy measurements of up to $10^{17}$ eV. The observational components consist of a power law spectrum of protons extending up to $3\\times 10^{15}$ eV, providing gravitational evidence for the 'knee' in the Galactic CR spectrum. Additionally, the maximum energy of the accelerated nuclei is proportional to their charge number, exhibiting a break in the Galactic CR spectrum from the contribution of more massive species. Combining these components with an appropriate extragalactic CR component can enable a comprehensive description of the overall Galactic CR spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1715}
{"prompt": "Rephrase the abstract of an article with title 'Orbital liquid in ferromagnetic manganites: The orbital Hubbard model   for $e_g$ electrons'.   We have analyzed the symmetry properties and the ground state of an orbital Hubbard model with two orbital flavors, describing a partly filled spin-polarized $e_g$ band on a cubic lattice, as in ferromagnetic manganites. We demonstrate that the off-diagonal hopping responsible for transitions between $x^2-y^2$ and $3z^2-r^2$ orbitals, and the absence of SU(2) invariance in orbital space, have important implications. One finds that superexchange contributes in all orbital ordered states, the Nagaoka theorem does not apply, and the kinetic energy is much enhanced as compared with the spin case. Therefore, orbital ordered states are harder to stabilize in the Hartree-Fock approximation (HFA), and the onset of a uniform ferro-orbital polarization and antiferro-orbital instability are similar to each other, unlike in spin case. Next we formulate a cubic (gauge) invariant slave boson approach using the orbitals with complex coefficients. In the mean-field approximation it leads to the renormalization of the kinetic energy, and provides a reliable estimate for the ground state energy of the disordered state. Using this approach one finds that the HFA fails qualitatively in the regime of large Coulomb repulsion $U\\to\\infty$ -- the orbital order is unstable, and instead a strongly correlated orbital liquid with disordered orbitals is realized at any electron filling.  ", "human_text": "  We have analyzed the symmetry properties and the ground state of an orbital Hubbard model with two orbital flavors, describing a partly filled spin-polarized $e_g$ band on a cubic lattice, as in ferromagnetic manganites. We demonstrate that the off-diagonal hopping responsible for transitions between $x^2-y^2$ and $3z^2-r^2$ orbitals, and the absence of SU(2) invariance in orbital space, have important implications. One finds that superexchange contributes in all orbital ordered states, the Nagaoka theorem does not apply, and the kinetic energy is much enhanced as compared with the spin case. Therefore, orbital ordered states are harder to stabilize in the Hartree-Fock approximation (HFA), and the onset of a uniform ferro-orbital polarization and antiferro-orbital instability are similar to each other, unlike in spin case. Next we formulate a cubic (gauge) invariant slave boson approach using the orbitals with complex coefficients. In the mean-field approximation it leads to the renormalization of the kinetic energy, and provides a reliable estimate for the ground state energy of the disordered state. Using this approach one finds that the HFA fails qualitatively in the regime of large Coulomb repulsion $U\\to\\infty$ -- the orbital order is unstable, and instead a strongly correlated orbital liquid with disordered orbitals is realized at any electron filling. ", "machine_text": " An investigation was conducted examining the symmetry properties and the ground state of an orbital Hubbard model consisting of two orbitals partly filled with spin-polarized electrons on a cubic lattice, similar to ferromagnetic manganites. Found that due to the off-diagonal hopping for transitions between $x^2-y^2$ and $3z^2-r^2$ orbitals and the lack of SU(2) invariance in orbital space, superexchange contributes to all orbital ordered states, the Nagaoka theorem does not apply, and the kinetic energy is enhanced in comparison to the spin case. This makes orbital ordered states harder to stabilize in the Hartree-Fock approximation and the onset of ferro-orbital and antiferro-orbital polarizations are alike, unlike in spin cases. Subsequently, a cubic-gauge invariant slave boson approach is formulated with orbitals containing complex coefficients in mean-field approximation which gives accurate estimates of the ground-state energy of disordered states. Results show that in the regime of high Coulomb repulsion the orbital order is unstable, leading instead to a highly correlated orbital liquid with random orbitals at any electron filling.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1766}
{"prompt": "Rephrase the abstract of an article with title 'Emergence of spatiotemporal chaos driven by far-field breakup of spiral   waves in the plankton ecological systems'.   Alexander B. Medvinsky \\emph{et al} [A. B. Medvinsky, I. A. Tikhonova, R. R. Aliev, B.-L. Li, Z.-S. Lin, and H. Malchow, Phys. Rev. E \\textbf{64}, 021915 (2001)] and Marcus R. Garvie \\emph{et al} [M. R. Garvie and C. Trenchea, SIAM J. Control. Optim. \\textbf{46}, 775-791 (2007)] shown that the minimal spatially extended reaction-diffusion model of phytoplankton-zooplankton can exhibit both regular, chaotic behavior, and spatiotemporal patterns in a patchy environment. Based on that, the spatial plankton model is furtherly investigated by means of computer simulations and theoretical analysis in the present paper when its parameters would be expected in the case of mixed Turing-Hopf bifurcation region. Our results show that the spiral waves exist in that region and the spatiotemporal chaos emerge, which arise from the far-field breakup of the spiral waves over large ranges of diffusion coefficients of phytoplankton and zooplankton. Moreover, the spatiotemporal chaos arising from the far-field breakup of spiral waves does not gradually involve the whole space within that region. Our results are confirmed by means of computation spectra and nonlinear bifurcation of wave trains. Finally, we give some explanations about the spatially structured patterns from the community level.  ", "human_text": "  Alexander B. Medvinsky \\emph{et al} [A. B. Medvinsky, I. A. Tikhonova, R. R. Aliev, B.-L. Li, Z.-S. Lin, and H. Malchow, Phys. Rev. E \\textbf{64}, 021915 (2001)] and Marcus R. Garvie \\emph{et al} [M. R. Garvie and C. Trenchea, SIAM J. Control. Optim. \\textbf{46}, 775-791 (2007)] shown that the minimal spatially extended reaction-diffusion model of phytoplankton-zooplankton can exhibit both regular, chaotic behavior, and spatiotemporal patterns in a patchy environment. Based on that, the spatial plankton model is furtherly investigated by means of computer simulations and theoretical analysis in the present paper when its parameters would be expected in the case of mixed Turing-Hopf bifurcation region. Our results show that the spiral waves exist in that region and the spatiotemporal chaos emerge, which arise from the far-field breakup of the spiral waves over large ranges of diffusion coefficients of phytoplankton and zooplankton. Moreover, the spatiotemporal chaos arising from the far-field breakup of spiral waves does not gradually involve the whole space within that region. Our results are confirmed by means of computation spectra and nonlinear bifurcation of wave trains. Finally, we give some explanations about the spatially structured patterns from the community level. ", "machine_text": "This paper investigates the emergence of spatiotemporal chaos driven by far-field breakup of spiral waves in a reaction-diffusion plankton model. Through computer simulations and theoretical analysis, the authors show that this model can exhibit both regular and chaotic behavior, as well as spatiotemporal patterns, in the case of mixed Turing-Hopf bifurcation. The results suggest that spatiotemporal chaos arising from the far-field breakup of spiral waves does not involve the entire region, and confirm this notion by means of computation spectra and nonlinear bifurcation of wave trains. Finally, explanations for the spatially structured patterns from a community level are also given.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0322}
{"prompt": "Rephrase the abstract of an article with title 'Planetary embryos and planetesimals residing in thin debris disks'.   We consider constraints on the planetesimal population residing in the disks of AU Microscopii, Beta Pictoris and Fomalhaut taking into account their observed thicknesses and normal disk opacities. We estimate that bodies of radius 5, 180 and 70 km are responsible for initiating the collisional cascade accounting for the dust production for AU-Mic, Beta-Pic and Fomalhaut's disks, respectively, at break radii from the star where their surface brightness profiles change slope. Larger bodies, of radius 1000km and with surface density of order 0.01 g/cm^2, are required to explain the thickness of these disks assuming that they are heated by gravitational stirring. A comparison between the densities of the two sizes suggests the size distribution in the largest bodies is flatter than that observed in the Kuiper belt. AU Mic's disk requires the shallowest size distribution for bodies with radius greater than 10km suggesting that the disk contains planetary embryos experiencing a stage of runaway growth.  ", "human_text": "  We consider constraints on the planetesimal population residing in the disks of AU Microscopii, Beta Pictoris and Fomalhaut taking into account their observed thicknesses and normal disk opacities. We estimate that bodies of radius 5, 180 and 70 km are responsible for initiating the collisional cascade accounting for the dust production for AU-Mic, Beta-Pic and Fomalhaut's disks, respectively, at break radii from the star where their surface brightness profiles change slope. Larger bodies, of radius 1000km and with surface density of order 0.01 g/cm^2, are required to explain the thickness of these disks assuming that they are heated by gravitational stirring. A comparison between the densities of the two sizes suggests the size distribution in the largest bodies is flatter than that observed in the Kuiper belt. AU Mic's disk requires the shallowest size distribution for bodies with radius greater than 10km suggesting that the disk contains planetary embryos experiencing a stage of runaway growth. ", "machine_text": " The present study investigates the nature and characteristics of large planetary embryos and planetesimals present in thin debris disks found around three sources (AU Microscopii, Beta Pictoris and Fomalhaut). We analyse the opacity and thickness of the disks, the surface brightness profiles, and the requirements for the size of the largest bodies these disks contain. It is determined that the maximum radius of these particles appears to be 5, 180, and 70 km respectively for the three disks, and that bodies with radius of 1000km and with surface density of 0.01 g/cm^2 would be necessary to explain the thickness of the disks assuming that they are heated by gravitational stirring. Further comparison of the densities of the two sizes implicates that the size distribution amongst the bodies with radius more than 10km is flatter than the one observed in the Kuiper belt. For AU Mic's disk, the shallowest size distribution for the bodies with highest radius is suggested, indicating that the planet may contain embryos resulting from runaway growth.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1325}
{"prompt": "Rephrase the abstract of an article with title 'The Dynamical State fo the Starless Dense Core FeSt 1-457: A Pulsating   Globule?'.   High resolution molecular line observations of CS, HCO+, C18O and N2H+ were obtained toward the starless globule FeSt 1-457 in order to investigate its kinematics and chemistry. The HCO+ and CS spectra show clear self-reversed and asymmetric profiles across the face of the globule. The sense of the observed asymmetry is indicative of the global presence of expansion motions in the outer layers of the globule. These motions appear to be subsonic and significantly below the escape velocity of the globule. Comparison of our observations with near-infrared extinction data indicate that the globule is gravitationally bound. Taken together these considerations lead us to suggest that the observed expansion has its origin in an oscillatory motion of the outer layers of the globule which itself is likely in a quasi-stable state near hydrostatic equilibrium. Analysis of the observed linewidths of CO and N2H+ confirm that thermal pressure is the dominant component of the cloud's internal support. A simple calculation suggests that the dominant mode of pulsation would be an l = 2 mode with a period of 0.3 Myr. Deformation of the globule due to the large amplitude l = 2 oscillation may be responsible for the double-peaked structure of the core detected in high resolution extinction maps. Detailed comparison of the molecular-line observations and extinction data provides evidence for significant depletion of C18O and perhaps HCO+ while N2H+ may be undepleted to a cloud depth of about 40 magnitudes of visual extinction.  ", "human_text": "  High resolution molecular line observations of CS, HCO+, C18O and N2H+ were obtained toward the starless globule FeSt 1-457 in order to investigate its kinematics and chemistry. The HCO+ and CS spectra show clear self-reversed and asymmetric profiles across the face of the globule. The sense of the observed asymmetry is indicative of the global presence of expansion motions in the outer layers of the globule. These motions appear to be subsonic and significantly below the escape velocity of the globule. Comparison of our observations with near-infrared extinction data indicate that the globule is gravitationally bound. Taken together these considerations lead us to suggest that the observed expansion has its origin in an oscillatory motion of the outer layers of the globule which itself is likely in a quasi-stable state near hydrostatic equilibrium. Analysis of the observed linewidths of CO and N2H+ confirm that thermal pressure is the dominant component of the cloud's internal support. A simple calculation suggests that the dominant mode of pulsation would be an l = 2 mode with a period of 0.3 Myr. Deformation of the globule due to the large amplitude l = 2 oscillation may be responsible for the double-peaked structure of the core detected in high resolution extinction maps. Detailed comparison of the molecular-line observations and extinction data provides evidence for significant depletion of C18O and perhaps HCO+ while N2H+ may be undepleted to a cloud depth of about 40 magnitudes of visual extinction. ", "machine_text": " Researchers conducted molecular line observations of the starless globule FeSt 1-457 in order to analyze its kinematics and chemical properties. The self-reversed and asymmetric profiles of the HCO+ and CS spectra across the face of the globule were noticed, suggesting the presence of expansion motions in the globule's outer layers. It was also determined that these motions were subsonic and below the escape velocity, indicating that the globule is gravitationally bound. After comparing the observations to near-infrared extinction data, it was suggested that the observed expansion has its roots in an oscillatory motion amd the globule is in a quasi-stable state near hydrostatic equilibrium. The analysis of the observed linewidths concluded that thermal pressure is the primary internal support mechanism of the cloud. A calculation suggested that the dominant oscillation period is around 0.3 Myr, potentially accounting for the double-peaked structure of the core in the high resolution extinction maps. Lastly, comparisons between the molecular-line observations and extinction data have revealed potential evidence for depletion of C18O and HCO+, and possibly no depletion for N2H+ up to 40 magnitudes of visual extinction.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0328}
{"prompt": "Rephrase the abstract of an article with title 'Gravitational waves from galaxy encounters'.   We discuss the emission of gravitational radiation produced in encounters of dark matter galactic halos. To this aim we perform a number of numerical simulations of typical galaxy mergers, computing the associated gravitational radiation waveforms as well as the energy released in the processes. Our simulations yield dimensionless gravitational wave amplitudes of the order of $10^{-13}$ and gravitational wave frequencies of the order of $10^{-16}$ Hz, when the galaxies are located at a distance of 10 Mpc. These values are of the same order as those arising in the gravitational radiation originated by strong variations of the gravitational field in the early Universe, and therefore, such gravitational waves cannot be directly observed by ground-based detectors. We discuss the feasibility of an indirect detection by means of the B-mode polarization of the Cosmic Microwave Background (CMB) induced by such waves. Our results show that the gravitational waves from encounters of dark matter galactic halos leave much too small an imprint on the CMB polarization to be actually observed with ongoing and future missions.  ", "human_text": "  We discuss the emission of gravitational radiation produced in encounters of dark matter galactic halos. To this aim we perform a number of numerical simulations of typical galaxy mergers, computing the associated gravitational radiation waveforms as well as the energy released in the processes. Our simulations yield dimensionless gravitational wave amplitudes of the order of $10^{-13}$ and gravitational wave frequencies of the order of $10^{-16}$ Hz, when the galaxies are located at a distance of 10 Mpc. These values are of the same order as those arising in the gravitational radiation originated by strong variations of the gravitational field in the early Universe, and therefore, such gravitational waves cannot be directly observed by ground-based detectors. We discuss the feasibility of an indirect detection by means of the B-mode polarization of the Cosmic Microwave Background (CMB) induced by such waves. Our results show that the gravitational waves from encounters of dark matter galactic halos leave much too small an imprint on the CMB polarization to be actually observed with ongoing and future missions. ", "machine_text": " We investigate the gravitational waves produced in collisions of dark matter-filled galactic halos. Our numerical simulations investigate the energy output and associated gravitational radiation waveforms. We observe that, for galaxies located 10 Mpc away, the amplitudes of the gravitational waves range from around $10^{-13}$ and the frequencies from around $10^{-16}$ Hz, values similar to those theorized for the waves spawned in the primordial universe. As such, the waves cannot be recorded directly by terrestrial detectors. We explore the possibility of an indirect detection via the B-mode polarization of the Cosmic Microwave Background triggered by the waves. Ultimately, our results show that the imprint of gravitational waves from galaxy encounters is too weak to be observed by ongoing or upcoming missions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3009}
{"prompt": "Rephrase the abstract of an article with title 'Efficient method for detection of periodic orbits in chaotic maps and   flows'.   An algorithm for detecting unstable periodic orbits in chaotic systems [Phys. Rev. E, 60 (1999), pp. 6172-6175] which combines the set of stabilising transformations proposed by Schmelcher and Diakonos [Phys. Rev. Lett., 78 (1997), pp. 4733-4736] with a modified semi-implicit Euler iterative scheme and seeding with periodic orbits of neighbouring periods, has been shown to be highly efficient when applied to low-dimensional system. The difficulty in applying the algorithm to higher dimensional systems is mainly due to the fact that the number of stabilising transformations grows extremely fast with increasing system dimension. In this thesis, we construct stabilising transformations based on the knowledge of the stability matrices of already detected periodic orbits (used as seeds). The advantage of our approach is in a substantial reduction of the number of transformations, which increases the efficiency of the detection algorithm, especially in the case of high-dimensional systems. The performance of the new approach is illustrated by its application to the four-dimensional kicked double rotor map, a six-dimensional system of three coupled H\\'enon maps and to the Kuramoto-Sivashinsky system in the weakly turbulent regime.  ", "human_text": "  An algorithm for detecting unstable periodic orbits in chaotic systems [Phys. Rev. E, 60 (1999), pp. 6172-6175] which combines the set of stabilising transformations proposed by Schmelcher and Diakonos [Phys. Rev. Lett., 78 (1997), pp. 4733-4736] with a modified semi-implicit Euler iterative scheme and seeding with periodic orbits of neighbouring periods, has been shown to be highly efficient when applied to low-dimensional system. The difficulty in applying the algorithm to higher dimensional systems is mainly due to the fact that the number of stabilising transformations grows extremely fast with increasing system dimension. In this thesis, we construct stabilising transformations based on the knowledge of the stability matrices of already detected periodic orbits (used as seeds). The advantage of our approach is in a substantial reduction of the number of transformations, which increases the efficiency of the detection algorithm, especially in the case of high-dimensional systems. The performance of the new approach is illustrated by its application to the four-dimensional kicked double rotor map, a six-dimensional system of three coupled H\\'enon maps and to the Kuramoto-Sivashinsky system in the weakly turbulent regime. ", "machine_text": "This thesis presents an improved method for detecting periodic orbits in chaotic maps and flows. It combines the stabilising transformations proposed by Schmelcher and Diakonos with a modified semi-implicit Euler iterative scheme and seeding with periodic orbits of neighbouring periods. This technique is highly efficient when applied to low-dimensional systems, but can be difficult to apply to higher-dimensional systems due to the rapid growth of the number of required stabilising transformations. To address this challenge, the thesis introduces a novel approach which relies on the knowledge of stability matrices of already-detected periodic orbits to reduce the number of transformations and increase the efficiency of the detection algorithm. The efficacy of this approach is demonstrated by its application to a four-dimensional kicked double rotor map, a six-dimensional system of three coupled H\u00e9non maps, and the Kuramoto-Sivashinsky system in a weakly turbulent regime.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.194}
{"prompt": "Rephrase the abstract of an article with title 'Optimizing future imaging survey of galaxies to confront dark energy and   modified gravity models'.   We consider the extent to which future imaging surveys of galaxies can distinguish between dark energy and modified gravity models for the origin of the cosmic acceleration. Dynamical dark energy models may have similar expansion rates as models of modified gravity, yet predict different growth of structure histories. We parameterize the cosmic expansion by the two parameters, $w_0$ and $w_a$, and the linear growth rate of density fluctuations by Linder's $\\gamma$, independently. Dark energy models generically predict $\\gamma \\approx 0.55$, while the DGP model $\\gamma \\approx 0.68$. To determine if future imaging surveys can constrain $\\gamma$ within 20 percent (or $\\Delta\\gamma<0.1$), we perform the Fisher matrix analysis for a weak lensing survey such as the on-going Hyper Suprime-Cam (HSC) project. Under the condition that the total observation time is fixed, we compute the Figure of Merit (FoM) as a function of the exposure time $\\texp$. We find that the tomography technique effectively improves the FoM, which has a broad peak around $\\texp\\simeq {\\rm several}\\sim 10$ minutes; a shallow and wide survey is preferred to constrain the $\\gamma$ parameter. While $\\Delta\\gamma < 0.1$ cannot be achieved by the HSC weak-lensing survey alone, one can improve the constraints by combining with a follow-up spectroscopic survey like WFMOS and/or future CMB observations.  ", "human_text": "  We consider the extent to which future imaging surveys of galaxies can distinguish between dark energy and modified gravity models for the origin of the cosmic acceleration. Dynamical dark energy models may have similar expansion rates as models of modified gravity, yet predict different growth of structure histories. We parameterize the cosmic expansion by the two parameters, $w_0$ and $w_a$, and the linear growth rate of density fluctuations by Linder's $\\gamma$, independently. Dark energy models generically predict $\\gamma \\approx 0.55$, while the DGP model $\\gamma \\approx 0.68$. To determine if future imaging surveys can constrain $\\gamma$ within 20 percent (or $\\Delta\\gamma<0.1$), we perform the Fisher matrix analysis for a weak lensing survey such as the on-going Hyper Suprime-Cam (HSC) project. Under the condition that the total observation time is fixed, we compute the Figure of Merit (FoM) as a function of the exposure time $\\texp$. We find that the tomography technique effectively improves the FoM, which has a broad peak around $\\texp\\simeq {\\rm several}\\sim 10$ minutes; a shallow and wide survey is preferred to constrain the $\\gamma$ parameter. While $\\Delta\\gamma < 0.1$ cannot be achieved by the HSC weak-lensing survey alone, one can improve the constraints by combining with a follow-up spectroscopic survey like WFMOS and/or future CMB observations. ", "machine_text": " The objective of this research is to analyze the capability of imaging surveys of galaxies in distinguishing between dark energy and modified gravity explanations for the emergence of cosmic acceleration. We divide properties of the universe's evolutionary history into two parameters, $w_0$ and $w_a$, and the rate of growth of density disparities by Linder's $\\gamma$. Dark energy models generally show $\\gamma \\approx 0.55$ and the DGP model is signified by $\\gamma \\approx 0.68$. We utilize the Fisher Matrix technique to assess a survey such as the Hyper Suprime-Cam (HSC) project to determine if its observations of $\\gamma$ can be constrained to within 20%. Results from tomography help to raise the FoM, and its peak is at an exposure time of several minutes for a wide and shallow survey. In order to reach $\\Delta\\gamma < 0.1$ it is necessary to employ additional surveys such as WFMOS or upcoming CMB studies in combination with the HSC survey.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2949}
{"prompt": "Rephrase the abstract of an article with title 'Ramsey interferometry with a two-level Tonks-Girardeau gas'.   We propose a generalization of the Tonks-Girardeau model that describes a coherent gas of cold two-level Bosons which interact with two external fields in a Ramsey interferometer. They also interact among themselves by contact collisions with interchange of momentum and internal state. We study the corresponding Ramsey fringes and the quantum projection noise which, essentially unaffected by the interactions, remains that for ideal Bosons. The dual system of this gas, an ideal gas of two-level Fermions coupled by the interaction with the separated fields, produces the same fringes and noise fluctuations. The cases of time-separated and spatially-separated fields are studied. For spatially separated fields the fringes may be broadened slightly by increasing the number of particles, but only for large particle numbers far from present experiments with Tonks-Girardeau gases. The uncertainty in the determination of the atomic transition frequency diminishes, essentially with the inverse root of the particle number.  ", "human_text": "  We propose a generalization of the Tonks-Girardeau model that describes a coherent gas of cold two-level Bosons which interact with two external fields in a Ramsey interferometer. They also interact among themselves by contact collisions with interchange of momentum and internal state. We study the corresponding Ramsey fringes and the quantum projection noise which, essentially unaffected by the interactions, remains that for ideal Bosons. The dual system of this gas, an ideal gas of two-level Fermions coupled by the interaction with the separated fields, produces the same fringes and noise fluctuations. The cases of time-separated and spatially-separated fields are studied. For spatially separated fields the fringes may be broadened slightly by increasing the number of particles, but only for large particle numbers far from present experiments with Tonks-Girardeau gases. The uncertainty in the determination of the atomic transition frequency diminishes, essentially with the inverse root of the particle number. ", "machine_text": "This article presents a new, generalized model of the Tonks-Girardeau gas, which consists of cold two-level Bosons interacting with external fields and among themselves in a Ramsey interferometer. We analyze the quantum effects and resulting Ramsey fringes and quantum projection noise, showing that these effects remain largely unaltered in the presence of interactions. Additionally, we examine the behavior of the dual system - an ideal gas of two-level Fermions interacting with fields - and empirically deduce that the number of particles generally does not have a great impact on the broadening of fringes. Lastly, we demonstrate that precision in the measurement of atomic transition frequency increases with the inverse root of the number of particles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3746}
{"prompt": "Rephrase the abstract of an article with title 'Spitzer Mid-to-Far-Infrared Flux Densities of Distant Galaxies'.   We study the infrared (IR) properties of high-redshift galaxies using deep Spitzer 24, 70, and 160 micron data. Our primary interest is to improve the constraints on the total IR luminosities, L(IR), of these galaxies. We combine the Spitzer data in the southern Extended Chandra Deep Field with a K-band-selected galaxy sample and photometric redshifts from the Multiwavelength Survey by Yale-Chile. We used a stacking analysis to measure the average 70 and 160 micron flux densities of 1.5 < z < 2.5 galaxies as a function of 24 micron flux density, X-ray activity, and rest-frame near-IR color. Galaxies with 1.5 < z < 2.5 and S(24)=53-250 micro-Jy have L(IR) derived from their average 24-160 micron flux densities within factors of 2-3 of those derived from the 24 micron flux densities only. However, L(IR) derived from the average 24-160 micron flux densities for galaxies with S(24) > 250 micro-Jy and 1.5 < z < 2.5 are lower than those derived using only the 24 micron flux density by factors of 2-10. Galaxies with S(24) > 250 micro-Jy have S(70)/S(24) flux ratios comparable to sources with X-ray detections or red rest-frame IR colors, suggesting that warm dust possibly heated by AGN may contribute to the high 24 micron emission. Based on the average 24-160 micron flux densities, nearly all 24 micron-selected galaxies at 1.5 < z < 2.5 have L(IR) < 6 x 10^12 solar luminosities, which if attributed to star formation corresponds to < 1000 solar masses per year. This suggests that high redshift galaxies may have similar star formation efficiencies and feedback processes as local analogs. Objects with L(IR) > 6 x 10^12 solar luminosities are quite rare, with a surface density ~ 30 +/- 10 per sq. deg, corresponding to ~ 2 +/- 1 x 10^-6 Mpc^-3 over 1.5 < z < 2.5.  ", "human_text": "  We study the infrared (IR) properties of high-redshift galaxies using deep Spitzer 24, 70, and 160 micron data. Our primary interest is to improve the constraints on the total IR luminosities, L(IR), of these galaxies. We combine the Spitzer data in the southern Extended Chandra Deep Field with a K-band-selected galaxy sample and photometric redshifts from the Multiwavelength Survey by Yale-Chile. We used a stacking analysis to measure the average 70 and 160 micron flux densities of 1.5 < z < 2.5 galaxies as a function of 24 micron flux density, X-ray activity, and rest-frame near-IR color. Galaxies with 1.5 < z < 2.5 and S(24)=53-250 micro-Jy have L(IR) derived from their average 24-160 micron flux densities within factors of 2-3 of those derived from the 24 micron flux densities only. However, L(IR) derived from the average 24-160 micron flux densities for galaxies with S(24) > 250 micro-Jy and 1.5 < z < 2.5 are lower than those derived using only the 24 micron flux density by factors of 2-10. Galaxies with S(24) > 250 micro-Jy have S(70)/S(24) flux ratios comparable to sources with X-ray detections or red rest-frame IR colors, suggesting that warm dust possibly heated by AGN may contribute to the high 24 micron emission. Based on the average 24-160 micron flux densities, nearly all 24 micron-selected galaxies at 1.5 < z < 2.5 have L(IR) < 6 x 10^12 solar luminosities, which if attributed to star formation corresponds to < 1000 solar masses per year. This suggests that high redshift galaxies may have similar star formation efficiencies and feedback processes as local analogs. Objects with L(IR) > 6 x 10^12 solar luminosities are quite rare, with a surface density ~ 30 +/- 10 per sq. deg, corresponding to ~ 2 +/- 1 x 10^-6 Mpc^-3 over 1.5 < z < 2.5. ", "machine_text": " Using data from Spitzer's 24, 70 and 160 micron bands, we studied the infrared characteristics of high-redshift galaxies in the southern Extended Chandra Deep Field in connection with K-band-selected galaxies, Multiwavelength Survey by Yale-Chile photometric redshift data, and X-ray activity. Through stacking analysis, we determined the average 70 and 160 micron flux densities for galaxies with 1.5 < z < 2.5, both with respect to the 24 micron flux density and for red rest-frame infrared colours and X-ray detections. Our results indicate that galaxies in this redshift range with S(24) = 0.053-0.250 micro-Jy showed L(IR) values similar to those of 24 micron flux densities. However, those with S(24) > 0.250 micro-Jy had higher S(70)/S(24) flux ratios, possibly due to emission from hot dust heated by AGN. Lastly, our analysis suggests that star-forming galaxies have star-formation efficiencies and feedback mechanisms comparable to our galaxy's local counterparts, with L(IR) < 6 x 10^12 solar luminosities corresponding to <1000 solar masses per year. Such galaxies appear to be rare, at surface densities approximately 30 +/- 10 per square degree and a volume density of ~2 +/- 1 x 10^-6 Mpc^-3 over 1.5 < z < 2.5.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2164}
{"prompt": "Rephrase the abstract of an article with title 'The Equivariant cohomology theory of twisted generalized complex   manifolds'.   It has been shown recently by Kapustin and Tomasiello that the mathematical notion of Hamiltonian actions on twisted generalized K\\\"ahler manifolds is in perfect agreement with the physical notion of general $(2,2)$ gauged sigma models with three-form fluxes. In this article, we study the twisted equivariant cohomology theory of Hamiltonian actions on $H$-twisted generalized complex manifolds. If the manifold satisfies the $\\bar{\\partial}\\partial$-lemma, we establish the equivariant formality theorem. If in addition, the manifold satisfies the generalized K\\\"ahler condition, we prove the Kirwan injectivity in this setting. We then consider the Hamiltonian action of a torus on an $H$-twisted generalized Calabi-Yau manifold and extend to this case the Duistermaat-Heckman theorem for the push-forward measure.   As a side result, we show in this paper that the generalized K\\\"ahler quotient of a generalized K\\\"ahler vector space can never have a (cohomologically) non-trivial twisting. This gives a negative answer to a question asked by physicists whether one can construct $(2,2)$ gauged linear sigma models with non-trivial fluxes.  ", "human_text": "  It has been shown recently by Kapustin and Tomasiello that the mathematical notion of Hamiltonian actions on twisted generalized K\\\"ahler manifolds is in perfect agreement with the physical notion of general $(2,2)$ gauged sigma models with three-form fluxes. In this article, we study the twisted equivariant cohomology theory of Hamiltonian actions on $H$-twisted generalized complex manifolds. If the manifold satisfies the $\\bar{\\partial}\\partial$-lemma, we establish the equivariant formality theorem. If in addition, the manifold satisfies the generalized K\\\"ahler condition, we prove the Kirwan injectivity in this setting. We then consider the Hamiltonian action of a torus on an $H$-twisted generalized Calabi-Yau manifold and extend to this case the Duistermaat-Heckman theorem for the push-forward measure.   As a side result, we show in this paper that the generalized K\\\"ahler quotient of a generalized K\\\"ahler vector space can never have a (cohomologically) non-trivial twisting. This gives a negative answer to a question asked by physicists whether one can construct $(2,2)$ gauged linear sigma models with non-trivial fluxes. ", "machine_text": " In this paper, we analyze the equivariant cohomology of twisted generalized complex manifolds subjected to Hamiltonian actions - a notion compatible with the physical theory of $(2,2)$ gauged sigma models with three-form fluxes according to Kapustin and Tomasiello. We establish an equivariant formality theorem and Kirwan Injectivity if the manifold satisfies the $\\bar{\\partial}\\partial$-lemma, and the generalized K\\\"ahler condition, respectively. Furthermore, we extend the Duistermaat-Heckman theorem to the case of an $H$-twisted generalized Calabi-Yau manifold acted upon by a torus. As a secondary outcome of this, we prove that the generalized K\\\"ahler quotient of a generalized K\\\"ahler vector space does not have a (cohomologically) non-trivial twisting, yielding a negative answer to a query about gauged linear sigma models with non-trivial fluxes voiced by physicists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2804}
{"prompt": "Rephrase the abstract of an article with title 'Star formation in Perseus: III. Outflows'.   We present a search for outflows towards 51 submillimetre cores in Perseus. With consistently derived outflow properties from a large homogeneous dataset within one molecular cloud we can investigate further the mass dependence and time evolution of protostellar mass loss. Of the 51 cores, 37 show broad linewings indicative of molecular outflows. In 13 cases, the linewings could be due to confusion with neighbouring flows but 9 of those sources also have near-infrared detections confirming their protostellar nature. The total fraction of protostars in our sample is 65%. All but four outflow detections are confirmed as protostellar by Spitzer IR detections and only one Spitzer source has no outflow, showing that outflow maps at this sensitivity are equally good at identifying protostars as Spitzer. Outflow momentum flux correlates both with source luminosity and with core mass but there is considerable scatter even within this one cloud despite the homogeneous dataset. We fail to confirm the result of Bontemps et al. (1996) that Class I sources show lower momentum fluxes on average than Class 0 sources, with a KS test showing a significant probability that the momentum fluxes for both Class 0s and Class Is are drawn from the same distribution. We find that outflow power may not show a simple decline between the Class 0 to Class I stages. Our sample includes low momentum flux, low-luminosity Class 0 sources, possibly at a very early evolutionary stage. If the only mass loss from the core were due to outflows, cores would last for 10^5-10^8 years, longer than current estimates of 1.5-4 x 10^5 years for the mean lifetime for the embedded phase. Additional mechanisms for removing mass from protostellar cores may be necessary.  ", "human_text": "  We present a search for outflows towards 51 submillimetre cores in Perseus. With consistently derived outflow properties from a large homogeneous dataset within one molecular cloud we can investigate further the mass dependence and time evolution of protostellar mass loss. Of the 51 cores, 37 show broad linewings indicative of molecular outflows. In 13 cases, the linewings could be due to confusion with neighbouring flows but 9 of those sources also have near-infrared detections confirming their protostellar nature. The total fraction of protostars in our sample is 65%. All but four outflow detections are confirmed as protostellar by Spitzer IR detections and only one Spitzer source has no outflow, showing that outflow maps at this sensitivity are equally good at identifying protostars as Spitzer. Outflow momentum flux correlates both with source luminosity and with core mass but there is considerable scatter even within this one cloud despite the homogeneous dataset. We fail to confirm the result of Bontemps et al. (1996) that Class I sources show lower momentum fluxes on average than Class 0 sources, with a KS test showing a significant probability that the momentum fluxes for both Class 0s and Class Is are drawn from the same distribution. We find that outflow power may not show a simple decline between the Class 0 to Class I stages. Our sample includes low momentum flux, low-luminosity Class 0 sources, possibly at a very early evolutionary stage. If the only mass loss from the core were due to outflows, cores would last for 10^5-10^8 years, longer than current estimates of 1.5-4 x 10^5 years for the mean lifetime for the embedded phase. Additional mechanisms for removing mass from protostellar cores may be necessary. ", "machine_text": " In this paper, we explore the mass dependence, time evolution, and degree of outflows associated with star formation in the Perseus molecular cloud. We surveyed 51 submillimetre cores and 37 of those showed evidence of protostellar outflows in their broad linewings - with 13 of those potentially being false positives due to confusion with neighbouring flows. Near-infrared detections further confirmed that 65 percent of the cores are protostars. Comparing our results to Spitzer infrared detections, outflow maps at this same sensitivity were found to be just as good as Spitzer in identifying protostars. Outflow momentum flux displays correlations with core mass and source luminosity, but with a large degree of scatter. Furthermore, our results did not provide strong evidence for the Bontemps et al. (1996) assertion of lower momentum fluxes for Class I sources in comparison to Class 0 sources. Lastly, our sample also included low momentum flux, low-luminosity Class 0 sources potentially signifying an early stage of star formation - a stage that may last longer than the current lifetime estimates for the embedded phase. Our findings suggest that additional mechanisms may be necessary for the removal of mass from protostellar cores.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1724}
{"prompt": "Rephrase the abstract of an article with title '3D Radiative Hydrodynamics for Disk Stability Simulations: A Proposed   Testing Standard and New Results'.   Recent three-dimensional radiative hydrodynamics simulations of protoplanetary disks report disparate disk behaviors, and these differences involve the importance of convection to disk cooling, the dependence of disk cooling on metallicity, and the stability of disks against fragmentation and clump formation. To guarantee trustworthy results, a radiative physics algorithm must demonstrate the capability to handle both the high and low optical depth regimes. We develop a test suite that can be used to demonstrate an algorithm's ability to relax to known analytic flux and temperature distributions, to follow a contracting slab, and to inhibit or permit convection appropriately. We then show that the radiative algorithm employed by Meji\\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al. (2006) and Cai et al. (2007, in prep.) pass these tests with reasonable accuracy. In addition, we discuss a new algorithm that couples flux-limited diffusion with vertical rays, we apply the test suite, and we discuss the results of evolving the Boley et al. (2006) disk with this new routine. Although the outcome is significantly different in detail with the new algorithm, we obtain the same qualitative answers. Our disk does not cool fast due to convection, and it is stable to fragmentation. We find an effective $\\alpha\\approx 10^{-2}$. In addition, transport is dominated by low-order modes.  ", "human_text": "  Recent three-dimensional radiative hydrodynamics simulations of protoplanetary disks report disparate disk behaviors, and these differences involve the importance of convection to disk cooling, the dependence of disk cooling on metallicity, and the stability of disks against fragmentation and clump formation. To guarantee trustworthy results, a radiative physics algorithm must demonstrate the capability to handle both the high and low optical depth regimes. We develop a test suite that can be used to demonstrate an algorithm's ability to relax to known analytic flux and temperature distributions, to follow a contracting slab, and to inhibit or permit convection appropriately. We then show that the radiative algorithm employed by Meji\\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al. (2006) and Cai et al. (2007, in prep.) pass these tests with reasonable accuracy. In addition, we discuss a new algorithm that couples flux-limited diffusion with vertical rays, we apply the test suite, and we discuss the results of evolving the Boley et al. (2006) disk with this new routine. Although the outcome is significantly different in detail with the new algorithm, we obtain the same qualitative answers. Our disk does not cool fast due to convection, and it is stable to fragmentation. We find an effective $\\alpha\\approx 10^{-2}$. In addition, transport is dominated by low-order modes. ", "machine_text": " The results of three-dimensional radiative hydrodynamics simulations of protoplanetary disks show various disparate disk behaviors, producing varying results on the role of convection in cooling, the disk's metal content and its stability against clump formation and fragmentation. To ensure valid outcomes, a radiative physics algorithm is proposed and tested to demonstrate the capacity to produce expected flux and temperature distributions, follow a contracting slab of material and either facilitate or inhibit convection as required. Using the test results, we evaluate two distinct radiative algorithms from Meji\\'a (2004) and Boley et al. (2006), and Cai et al. (2006) and Cai et al. (2007, in prep.), and present a new algorithm combining flux-limited diffusion and vertical rays. We show that the new algorithm produces qualitatively similar results - that convection does not play a major part in cooling and the disk is stable - but with some different quantitative details. This supports an effective $\\alpha\\approx 10^{-2}$ for the disk, with transport mainly dominated by low-order modes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2532}
{"prompt": "Rephrase the abstract of an article with title 'Deaconstructing Functions on Quadratic Surfaces into Multipoles'.   Any homogeneous polynomial $P(x, y, z)$ of degree $d$, being restricted to a unit sphere $S^2$, admits essentially a unique representation of the form $\\lambda + \\sum_{k = 1}^d [\\prod_{j = 1}^k L_{kj}]$, where $L_{kj}$'s are linear forms in $x, y$ and $z$ and $\\lambda$ is a real number. The coefficients of these linear forms, viewed as 3D vectors, are called \\emph{multipole} vectors of $P$. In this paper we consider similar multipole representations of polynomial and analytic functions on other quadratic surfaces $Q(x, y, z) = c$, real and complex. Over the complex numbers, the above representation is not unique, although the ambiguity is essentially finite. We investigate the combinatorics that depicts this ambiguity. We link these results with some classical theorems of harmonic analysis, theorems that describe decompositions of functions into sums of spherical harmonics. We extend these classical theorems (which rely on our understanding of the Laplace operator $\\Delta_{S^2}$) to more general differential operators $\\Delta_Q$ that are constructed with the help of the quadratic form $Q(x, y, z)$. Then we introduce modular spaces of multipoles. We study their intricate geometry and topology using methods of algebraic geometry and singularity theory. The multipole spaces are ramified over vector or projective spaces, and the compliments to the ramification sets give rise to a rich family of $K(\\pi, 1)$-spaces, where $\\pi$ runs over a variety of modified braid groups.  ", "human_text": "  Any homogeneous polynomial $P(x, y, z)$ of degree $d$, being restricted to a unit sphere $S^2$, admits essentially a unique representation of the form $\\lambda + \\sum_{k = 1}^d [\\prod_{j = 1}^k L_{kj}]$, where $L_{kj}$'s are linear forms in $x, y$ and $z$ and $\\lambda$ is a real number. The coefficients of these linear forms, viewed as 3D vectors, are called \\emph{multipole} vectors of $P$. In this paper we consider similar multipole representations of polynomial and analytic functions on other quadratic surfaces $Q(x, y, z) = c$, real and complex. Over the complex numbers, the above representation is not unique, although the ambiguity is essentially finite. We investigate the combinatorics that depicts this ambiguity. We link these results with some classical theorems of harmonic analysis, theorems that describe decompositions of functions into sums of spherical harmonics. We extend these classical theorems (which rely on our understanding of the Laplace operator $\\Delta_{S^2}$) to more general differential operators $\\Delta_Q$ that are constructed with the help of the quadratic form $Q(x, y, z)$. Then we introduce modular spaces of multipoles. We study their intricate geometry and topology using methods of algebraic geometry and singularity theory. The multipole spaces are ramified over vector or projective spaces, and the compliments to the ramification sets give rise to a rich family of $K(\\pi, 1)$-spaces, where $\\pi$ runs over a variety of modified braid groups. ", "machine_text": "This paper explores the idea of breaking down homogeneous polynomial and analytic functions defined on quadratic surfaces into their multipole vector components. We discuss how this approach relates to classical harmonic analysis and the associated Laplace operator and more general differential operators related to the shape of the quadratic surface. Investigating the geometry and topology of the multipole spaces, we employ analytic geometry and singularity theory to delve further into these spaces which feature a variety of modified braid groups.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1174}
{"prompt": "Rephrase the abstract of an article with title 'A novel method for evaluating the critical nucleus and the surface   tension in systems with first order phase transition'.   We introduce a novel method for calculating the size of the critical nucleus and the value of the surface tension in systems with first order phase transition. The method is based on classical nucleation theory, and it consists in studying the thermodynamics of a sphere of given radius embedded in a frozen metastable surrounding. The frozen configuration creates a pinning field on the surface of the free sphere. The pinning field forces the sphere to stay in the metastable phase as long as its size is smaller than the critical nucleus. We test our method in two first-order systems, both on a two-dimensional lattice: a system where the parameter tuning the transition is the magnetic field, and a second system where the tuning parameter is the temperature. In both cases the results are satisfying. Unlike previous techniques, our method does not require an infinite volume limit to compute the surface tension, and it therefore gives reliable estimates even by using relatively small systems. However, our method cannot be used at, or close to, the critical point, i.e. at coexistence, where the critical nucleus becomes infinitely large.  ", "human_text": "  We introduce a novel method for calculating the size of the critical nucleus and the value of the surface tension in systems with first order phase transition. The method is based on classical nucleation theory, and it consists in studying the thermodynamics of a sphere of given radius embedded in a frozen metastable surrounding. The frozen configuration creates a pinning field on the surface of the free sphere. The pinning field forces the sphere to stay in the metastable phase as long as its size is smaller than the critical nucleus. We test our method in two first-order systems, both on a two-dimensional lattice: a system where the parameter tuning the transition is the magnetic field, and a second system where the tuning parameter is the temperature. In both cases the results are satisfying. Unlike previous techniques, our method does not require an infinite volume limit to compute the surface tension, and it therefore gives reliable estimates even by using relatively small systems. However, our method cannot be used at, or close to, the critical point, i.e. at coexistence, where the critical nucleus becomes infinitely large. ", "machine_text": "This paper presents a novel approach for evaluating the size of the critical nucleus and the surface tension in systems that exhibit a first order phase transition. Our technique is based on the thermodynamics of a sphere of given radius encapsulated in a frozen metastable surrounding, and the exterior pinning field that it creates remains until the radius of the sphere is larger than the critical nucleus' size. We have tested our method in two systems under two different parameters - the magnetic field and temperature, both in a two-dimensional lattice - where we obtained satisfactory results. One advantage of our method is that it does not need an infinite volume limit to be accurate, since it obtains reliable results even in relatively small systems. On the contrary, it cannot be used at or close to the critical point, since the critical nucleus would become infinitely large at this stage.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1519}
{"prompt": "Rephrase the abstract of an article with title 'The Stueckelberg Extension and Milli Weak and Milli Charge Dark Matter'.   A overview is given of the recent developments in the $U(1)_X$ Stueckelberg extensions of the Standard Model and of MSSM where all the Standard Model particles are neutral under the $U(1)_X$ but an axion which is absorbed is charged under both $U(1)_X$ and $U(1)_Y$ and acts as the connector field coupling the Standard Model sector with the Stueckelberg sector. Coupled with the usual Higgs mechanism that breaks the $SU(2)_L\\times U(1)_Y$ gauge symmetry, this scenario produces mixings in the neutral gauge boson sector generating an extra $Z'$ boson. The couplings of the extra $Z'$ to the Standard Model particles are milli weak but its couplings to the hidden sector matter, defined as matter that couples only to the gauge field of $U(1)_X$, can be of normal electro-weak strength. It is shown that such extensions, aside from the possibility of leading to a sharp $Z' $ resonance, lead to two new types of dark matter: milli weak (or extra weak) and milli charged. An analysis of the relic density shows that the WMAP-3 constraints can be satisfied for either of these scenarios. The types of models discussed could arise as possible field point limit of certain Type IIB orientifold string models.  ", "human_text": "  A overview is given of the recent developments in the $U(1)_X$ Stueckelberg extensions of the Standard Model and of MSSM where all the Standard Model particles are neutral under the $U(1)_X$ but an axion which is absorbed is charged under both $U(1)_X$ and $U(1)_Y$ and acts as the connector field coupling the Standard Model sector with the Stueckelberg sector. Coupled with the usual Higgs mechanism that breaks the $SU(2)_L\\times U(1)_Y$ gauge symmetry, this scenario produces mixings in the neutral gauge boson sector generating an extra $Z'$ boson. The couplings of the extra $Z'$ to the Standard Model particles are milli weak but its couplings to the hidden sector matter, defined as matter that couples only to the gauge field of $U(1)_X$, can be of normal electro-weak strength. It is shown that such extensions, aside from the possibility of leading to a sharp $Z' $ resonance, lead to two new types of dark matter: milli weak (or extra weak) and milli charged. An analysis of the relic density shows that the WMAP-3 constraints can be satisfied for either of these scenarios. The types of models discussed could arise as possible field point limit of certain Type IIB orientifold string models. ", "machine_text": "This article explores the Stueckelberg extension of the Standard Model and MSSM, which includes an axion connecting the Standard Model and Stueckelberg sectors when combined with the usual Higgs mechanism. As a result, an extra $Z'$ boson is created with interactions that are a fraction weaker than the Standard Model's, yet of regular electro-weak strength with hidden sector matter. It is demonstrated how this structure can satisfy WMAP-3 constraints and lead to two distinct dark matter forms: milli weak and milli charged. Furthermore, this could arise as the field point limit of certain Type IIB orientifold string models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2924}
{"prompt": "Rephrase the abstract of an article with title 'The continuum radio emission from the Sy 1.5 galaxy NGC 5033'.   We present new continuum VLA observations of the nearby Sy 1.5 galaxy NGC 5033, made at 4.9 and 8.4 GHz on 8 April 2003. Combined with VLA archival observations at 1.4 and 4.9 GHz made on 7 August 1993, 29 August 1999, and 31 October 1999, we sample the galaxy radio emission at scales ranging from the nuclear regions (<~ 100 pc) to the outer regions of the disk (~ 40 kpc). The high-resolution VLA images show a core-jet structure for the Sy 1.5 nucleus. While the core has a moderately steep non-thermal radio spectrum (S_\\nu ~ \\nu^\\alpha; \\alpha_{1.5}^{4.9} \\approx -0.4), the inner kpc region shows a steeper spectrum (\\alpha_{1.5}^{8.4} \\approx -0.9). This latter spectrum is typical of galaxies where energy losses are high, indicating that the escape rate of cosmic ray electrons in NGC 5033 is low. The nucleus contributes little to the total 1.4 GHz radio power of NGC 5033 and, based on the radio to far-infrared (FIR) relation, it appears that the radio and far-infrared emission from NGC 5033 are dominated by a starburst that during the last 10 Myr produced stars at a rate of ~2.8 M_sun/yr, yielding a supernova (type Ib/c and II) rate of 0.045 #/yr. This supernova rate corresponds to about 1 SN event every 22 yr. Finally, from our deep 8.4 GHz VLA-D image, we suggest the existence of a radio spur in NGC 5033, which could have been due to a hot superbubble formed as a consequence of sequential supernova explosions occurring during the lifetime of a giant molecular cloud.  ", "human_text": "  We present new continuum VLA observations of the nearby Sy 1.5 galaxy NGC 5033, made at 4.9 and 8.4 GHz on 8 April 2003. Combined with VLA archival observations at 1.4 and 4.9 GHz made on 7 August 1993, 29 August 1999, and 31 October 1999, we sample the galaxy radio emission at scales ranging from the nuclear regions (<~ 100 pc) to the outer regions of the disk (~ 40 kpc). The high-resolution VLA images show a core-jet structure for the Sy 1.5 nucleus. While the core has a moderately steep non-thermal radio spectrum (S_\\nu ~ \\nu^\\alpha; \\alpha_{1.5}^{4.9} \\approx -0.4), the inner kpc region shows a steeper spectrum (\\alpha_{1.5}^{8.4} \\approx -0.9). This latter spectrum is typical of galaxies where energy losses are high, indicating that the escape rate of cosmic ray electrons in NGC 5033 is low. The nucleus contributes little to the total 1.4 GHz radio power of NGC 5033 and, based on the radio to far-infrared (FIR) relation, it appears that the radio and far-infrared emission from NGC 5033 are dominated by a starburst that during the last 10 Myr produced stars at a rate of ~2.8 M_sun/yr, yielding a supernova (type Ib/c and II) rate of 0.045 #/yr. This supernova rate corresponds to about 1 SN event every 22 yr. Finally, from our deep 8.4 GHz VLA-D image, we suggest the existence of a radio spur in NGC 5033, which could have been due to a hot superbubble formed as a consequence of sequential supernova explosions occurring during the lifetime of a giant molecular cloud. ", "machine_text": " Observations made using the Very Large Array at 1.4 and 4.9 GHz on 8 April 2003 and 7 August 1993, 29 August 1999, and 31 October 1999 indicate the presence of a core-jet structure in the Sy 1.5 galaxy NGC 5033. At the nucleus, the radio spectrum is moderately steep. Further away, in the inner kpc region, a steeper spectrum was detected, which is typical of galaxies where high energy losses are experienced. This suggests that the escape rate of cosmic ray electrons from NGC 5033 may be low. An analysis of the radio to far infrared relation revealed that the radio and far infrared emission from NGC 5033 are likely driven by a starburst event over the past 10 million years, with a supernova type Ib/c and II rate of 0.045 per year. A deep 8.4 GHz VLA-D image also pointed to the possible existence of a radio spur in NGC 5033, possibly as a result of hot superbubbles caused by successive supernovae in a giant molecular cloud.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0918}
{"prompt": "Rephrase the abstract of an article with title 'Spectral analysis of Swift long GRBs with known redshift'.   We study the spectral and energetics properties of 47 long-duration gamma-ray bursts (GRBs) with known redshift, all of them detected by the Swift satellite. Due to the narrow energy range (15-150 keV) of the Swift-BAT detector, the spectral fitting is reliable only for fitting models with 2 or 3 parameters. As high uncertainty and correlation among the errors is expected, a careful analysis of the errors is necessary. We fit both the power law (PL, 2 parameters) and cut--off power law (CPL, 3 parameters) models to the time-integrated spectra of the 47 bursts, and present the corresponding parameters, their uncertainties, and the correlations among the uncertainties. The CPL model is reliable only for 29 bursts for which we estimate the nuf_nu peak energy Epk. For these GRBs, we calculate the energy fluence and the rest- frame isotropic-equivalent radiated energy, Eiso, as well as the propagated uncertainties and correlations among them. We explore the distribution of our homogeneous sample of GRBs on the rest-frame diagram E'pk vs Eiso. We confirm a significant correlation between these two quantities (the \"Amati\" relation) and we verify that, within the uncertainty limits, no outliers are present. We also fit the spectra to a Band model with the high energy power law index frozen to -2.3, obtaining a rather good agreement with the \"Amati\" relation of non-Swift GRBs.  ", "human_text": "  We study the spectral and energetics properties of 47 long-duration gamma-ray bursts (GRBs) with known redshift, all of them detected by the Swift satellite. Due to the narrow energy range (15-150 keV) of the Swift-BAT detector, the spectral fitting is reliable only for fitting models with 2 or 3 parameters. As high uncertainty and correlation among the errors is expected, a careful analysis of the errors is necessary. We fit both the power law (PL, 2 parameters) and cut--off power law (CPL, 3 parameters) models to the time-integrated spectra of the 47 bursts, and present the corresponding parameters, their uncertainties, and the correlations among the uncertainties. The CPL model is reliable only for 29 bursts for which we estimate the nuf_nu peak energy Epk. For these GRBs, we calculate the energy fluence and the rest- frame isotropic-equivalent radiated energy, Eiso, as well as the propagated uncertainties and correlations among them. We explore the distribution of our homogeneous sample of GRBs on the rest-frame diagram E'pk vs Eiso. We confirm a significant correlation between these two quantities (the \"Amati\" relation) and we verify that, within the uncertainty limits, no outliers are present. We also fit the spectra to a Band model with the high energy power law index frozen to -2.3, obtaining a rather good agreement with the \"Amati\" relation of non-Swift GRBs. ", "machine_text": " In this study, 47 gamma-ray bursts (GRBs) that were observed by Swift were analyzed spectrally and energetically. These GRBs all had redshift known, granting better insight into the details of their composition. To begin, models with two and three parameters were used to fit the narrow-range Swift-BAT 15-150 keV detected spectra. A careful analysis of errors and their correlations was done. Further, results from both the power law and cut-off power law models were studied. In addition, energies and their fluences in the rest-frame were calculated for those with the CPL model. This homogeneous sample was compared to the \u201cAmati\u201d relation among non-Swift GRBs, which showed significant correlation between the peak energy E'pk and the radiated energy Eiso. Lastly, a band model with power law index frozen to -2.3 fit was used to further compare to the \u201cAmati\u201d relation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0791}
{"prompt": "Rephrase the abstract of an article with title 'Detection of a 1258 Hz high-amplitude kilohertz quasi-periodic   oscillation in the ultra-compact X-ray binary 1A 1246-588'.   We have observed the ultra-compact low-mass X-ray binary (LMXB) 1A 1246-588 with the Rossi X-ray Timing Explorer (RXTE). In this manuscript we report the discovery of a kilohertz quasi-periodic oscillation (QPO) in 1A 1246-588. The kilohertz QPO was only detected when the source was in a soft high-flux state reminiscent of the lower banana branch in atoll sources. Only one kilohertz QPO peak is detected at a relatively high frequency of 1258+-2 Hz and at a single trial significance of more than 7 sigma. Kilohertz QPOs with a higher frequency have only been found on two occasions in 4U 0614+09. Furthermore, the frequency is higher than that found for the lower kilohertz QPO in any source, strongly suggesting that the QPO is the upper of the kilohertz QPO pair often found in LMXBs. The full-width at half maximum is 25+-4 Hz, making the coherence the highest found for an upper kilohertz QPO. From a distance estimate of ~6 kpc from a radius expansion burst we derive that 1A 1246-588 is at a persistent flux of ~0.2-0.3 per cent of the Eddington flux, hence 1A 1246-588 is one of the weakest LMXBs for which a kilohertz QPO has been detected. The root-mean-square (rms) amplitude in the 5-60 keV band is 27+-3 per cent, this is the highest for any kilohertz QPO source so far, in line with the general anti-correlation between source luminosity and rms amplitude of the kilohertz QPO peak identified before. Using the X-ray spectral information we produce a colour-colour diagram. The source behaviour in this diagram provides further evidence for the atoll nature of the source.  ", "human_text": "  We have observed the ultra-compact low-mass X-ray binary (LMXB) 1A 1246-588 with the Rossi X-ray Timing Explorer (RXTE). In this manuscript we report the discovery of a kilohertz quasi-periodic oscillation (QPO) in 1A 1246-588. The kilohertz QPO was only detected when the source was in a soft high-flux state reminiscent of the lower banana branch in atoll sources. Only one kilohertz QPO peak is detected at a relatively high frequency of 1258+-2 Hz and at a single trial significance of more than 7 sigma. Kilohertz QPOs with a higher frequency have only been found on two occasions in 4U 0614+09. Furthermore, the frequency is higher than that found for the lower kilohertz QPO in any source, strongly suggesting that the QPO is the upper of the kilohertz QPO pair often found in LMXBs. The full-width at half maximum is 25+-4 Hz, making the coherence the highest found for an upper kilohertz QPO. From a distance estimate of ~6 kpc from a radius expansion burst we derive that 1A 1246-588 is at a persistent flux of ~0.2-0.3 per cent of the Eddington flux, hence 1A 1246-588 is one of the weakest LMXBs for which a kilohertz QPO has been detected. The root-mean-square (rms) amplitude in the 5-60 keV band is 27+-3 per cent, this is the highest for any kilohertz QPO source so far, in line with the general anti-correlation between source luminosity and rms amplitude of the kilohertz QPO peak identified before. Using the X-ray spectral information we produce a colour-colour diagram. The source behaviour in this diagram provides further evidence for the atoll nature of the source. ", "machine_text": "We report the detection of a high-amplitude kilohertz quasi-periodic oscillation (QPO) from the ulta-compact low-mass X-ray binary (LMXB) 1A 1246-588. This QPO was detected when the source was in a soft, high-flux state and had a peak frequency of 1258+-2 Hz and a single trial significance of more than 7 sigma. The coherence and amplitude of this QPO is also higher than has been seen in any other source, suggesting that this is the upper QPO of a kilohertz pair. We estimate that the persistent flux of 1A 1246-588 is ~0.2-0.3 percent of the Eddington flux, making it one of the weakest LMXBs in which a kilohertz QPO has been detected. The root-mean-square (rms) amplitude is extremely high at 27+-3 percent. The colour-colour diagram of the source provides further evidence for its atoll nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1741}
{"prompt": "Rephrase the abstract of an article with title 'Sparticle Spectra and LHC Signatures for Large Volume String   Compactifications'.   We study the supersymmetric particle spectra and LHC collider observables for the large-volume string models with a fundamental scale of 10^{11} GeV that arise in moduli-fixed string compactifications with branes and fluxes. The presence of magnetic fluxes on the brane world volume, required for chirality, perturb the soft terms away from those previously computed in the dilute-flux limit. We use the difference in high-scale gauge couplings to estimate the magnitude of this perturbation and study the potential effects of the magnetic fluxes by generating many random spectra with the soft terms perturbed around the dilute flux limit. Even with a 40% variation in the high-scale soft terms the low-energy spectra take a clear and predictive form. The resulting spectra are broadly similar to those arising on the SPS1a slope, but more degenerate. In their minimal version the models predict the ratios of gaugino masses to be M_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage mediation. Among the scalars, the squarks tend to be lighter and the sleptons heavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC data for the random spectra in order to study the range of collider phenomenology that can occur. We perform a detailed mass reconstruction on one example large-volume string model spectrum. 100 fb^{-1} of integrated luminosity is sufficient to discriminate the model from mSUGRA and aspects of the sparticle spectrum can be accurately reconstructed.  ", "human_text": "  We study the supersymmetric particle spectra and LHC collider observables for the large-volume string models with a fundamental scale of 10^{11} GeV that arise in moduli-fixed string compactifications with branes and fluxes. The presence of magnetic fluxes on the brane world volume, required for chirality, perturb the soft terms away from those previously computed in the dilute-flux limit. We use the difference in high-scale gauge couplings to estimate the magnitude of this perturbation and study the potential effects of the magnetic fluxes by generating many random spectra with the soft terms perturbed around the dilute flux limit. Even with a 40% variation in the high-scale soft terms the low-energy spectra take a clear and predictive form. The resulting spectra are broadly similar to those arising on the SPS1a slope, but more degenerate. In their minimal version the models predict the ratios of gaugino masses to be M_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage mediation. Among the scalars, the squarks tend to be lighter and the sleptons heavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC data for the random spectra in order to study the range of collider phenomenology that can occur. We perform a detailed mass reconstruction on one example large-volume string model spectrum. 100 fb^{-1} of integrated luminosity is sufficient to discriminate the model from mSUGRA and aspects of the sparticle spectrum can be accurately reconstructed. ", "machine_text": " We explore the superparticle spectra and LHC signature outputs for large-scale string models in moduli-fixed string compactifications with branes and fluxes, with a cutting-edge laboratory energy level of 10^{11} GeV. Magnetic fluxes on the brane plane perturb the soft terms away from what was previously computed in the dilute-flux limit. Through an analysis of high-scale gauge couplings, we gauge the active impact of the magnetic fluxes and generate an abundance of random spectra with the soft terms adjusted around the dilute-flux limit. Despite the presence of a 40% variation in the high-scale soft terms, the low-energy spectra exhibit a clear and uniform pattern. The minimal models predict ratios of gaugino masses to be M_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, differing from both mSUGRA and mirage mediation. Squark scalars are lighter and the sleptons heavier than comparable mSUGRA models. We create 10 fb^{-1} of simulated data from the random spectra with which to study the scope of the collider phenomenology, with the example large-volume string model spectrum subjected to a detailed mass reconstruction. With a mere 100 fb^{-1} of integrated luminosity, the model is distinguishable from mSUGRA, and certain aspects of the sparticle spectrum can be accurately reconstructed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3403}
{"prompt": "Rephrase the abstract of an article with title 'A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA   Networks with Delay Constraints'.   A game-theoretic framework is used to study the effect of constellation size on the energy efficiency of wireless networks for M-QAM modulation. A non-cooperative game is proposed in which each user seeks to choose its transmit power (and possibly transmit symbol rate) as well as the constellation size in order to maximize its own utility while satisfying its delay quality-of-service (QoS) constraint. The utility function used here measures the number of reliable bits transmitted per joule of energy consumed, and is particularly suitable for energy-constrained networks. The best-response strategies and Nash equilibrium solution for the proposed game are derived. It is shown that in order to maximize its utility (in bits per joule), a user must choose the lowest constellation size that can accommodate the user's delay constraint. Using this framework, the tradeoffs among energy efficiency, delay, throughput and constellation size are also studied and quantified. The effect of trellis-coded modulation on energy efficiency is also discussed.  ", "human_text": "  A game-theoretic framework is used to study the effect of constellation size on the energy efficiency of wireless networks for M-QAM modulation. A non-cooperative game is proposed in which each user seeks to choose its transmit power (and possibly transmit symbol rate) as well as the constellation size in order to maximize its own utility while satisfying its delay quality-of-service (QoS) constraint. The utility function used here measures the number of reliable bits transmitted per joule of energy consumed, and is particularly suitable for energy-constrained networks. The best-response strategies and Nash equilibrium solution for the proposed game are derived. It is shown that in order to maximize its utility (in bits per joule), a user must choose the lowest constellation size that can accommodate the user's delay constraint. Using this framework, the tradeoffs among energy efficiency, delay, throughput and constellation size are also studied and quantified. The effect of trellis-coded modulation on energy efficiency is also discussed. ", "machine_text": "A game-theoretic perspective is applied to evaluate the influence of the size of a transmission constellation on the energy efficiency of M-QAM modulation in CDMA networks with time-delay specifications. A non-cooperative game provides an environment wherein each user can select the transmission power and possible symbol rate, as well as the constellation size that maximizes their own utility, as long as their Quality-of-Service (QoS) delay requirements are fulfilled. This utility is calculated in terms of reliable bits per energy joule used and makes the framework appropriate for energy-tight networks. The advantageousness of a constellation and the Nash equilibrium, along with best-response strategies, were all determined. Results suggested that the user should choose the smallest constellation that can meet their delay instruction if they want to maximize the utility (bits per joule). This framework also allows for an examination of the relations between energy efficiency, delay, constellation size and throughput and provides understanding for the effect of trellis-coded modulation on energy efficiency.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3878}
{"prompt": "Rephrase the abstract of an article with title 'Ordering phenomena in quasi one-dimensional organic conductors'.   Low-dimensional organic conductors could establish themselves as model systems for the investigation of the physics in reduced dimensions. In the metallic state of a one-dimensional solid, Fermi-liquid theory breaks down and spin and charge degrees of freedom become separated. But the metallic phase is not stable in one dimension: as the temperature is reduced, the electronic charge and spin tend to arrange themselves in an ordered fashion due to strong correlations. The competition of the different interactions is responsible for which broken-symmetry ground state is eventually realized in a specific compound and which drives the system towards an insulating state.   Here we review the various ordering phenomena and how they can be identified by optic and magnetic measurements. While the final results might look very similar in the case of a charge density wave and a charge-ordered metal, for instance, the physical cause is completely different. When density waves form, a gap opens in the density of states at the Fermi energy due to nesting of the one-dimension Fermi surface sheets. When a one-dimensional metal becomes a charge-ordered Mott insulator, on the other hand, the short-range Coulomb repulsion localizes the charge on the lattice sites and even causes certain charge patterns.   We try to point out the similarities and conceptional differences of these phenomena and give an example for each of them. Particular emphasis will be put on collective phenomena which are inherently present as soon as ordering breaks the symmetry of the system.  ", "human_text": "  Low-dimensional organic conductors could establish themselves as model systems for the investigation of the physics in reduced dimensions. In the metallic state of a one-dimensional solid, Fermi-liquid theory breaks down and spin and charge degrees of freedom become separated. But the metallic phase is not stable in one dimension: as the temperature is reduced, the electronic charge and spin tend to arrange themselves in an ordered fashion due to strong correlations. The competition of the different interactions is responsible for which broken-symmetry ground state is eventually realized in a specific compound and which drives the system towards an insulating state.   Here we review the various ordering phenomena and how they can be identified by optic and magnetic measurements. While the final results might look very similar in the case of a charge density wave and a charge-ordered metal, for instance, the physical cause is completely different. When density waves form, a gap opens in the density of states at the Fermi energy due to nesting of the one-dimension Fermi surface sheets. When a one-dimensional metal becomes a charge-ordered Mott insulator, on the other hand, the short-range Coulomb repulsion localizes the charge on the lattice sites and even causes certain charge patterns.   We try to point out the similarities and conceptional differences of these phenomena and give an example for each of them. Particular emphasis will be put on collective phenomena which are inherently present as soon as ordering breaks the symmetry of the system. ", "machine_text": "  This review provides an overview of the ordering phenomena in quasi one-dimensional organic conductors and how they can be identified through optical and magnetic measurements. It focuses on the differences between charge density waves and charge-ordered metal and gives an example of each type. It also emphasizes the collective effects that arise when the symmetry of a system is broken by ordering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2135}
{"prompt": "Rephrase the abstract of an article with title 'Affine Structures on a Ringed Space and Schemes'.   In this paper we will first introduce the notion of affine structures on a ringed space and then obtain several properties. Affine structures on a ringed space, arising mainly from complex analytical spaces of algebraic schemes over number fields, behave like differential structures on a smooth manifold.   As one does for differential manifolds, we will use pseudogroups of affine transformations to define affine atlases on a ringed space. An atlas on a space is said to be an affine structure if it is maximal. An affine structure is admissible if there is a sheaf on the underlying space such that they are coincide on all affine charts, which are in deed affine open sets of a scheme. In a rigour manner, a scheme is defined to be a ringed space with a specified affine structure if the affine structures are in action in some special cases such as analytical spaces of algebraic schemes. Particularly, by the whole of affine structures on a space, we will obtain respectively necessary and sufficient conditions that two spaces are homeomorphic and that two schemes are isomorphic, which are the two main theorems of the paper. It follows that the whole of affine structures on a space and a scheme, as local data, encode and reflect the global properties of the space and the scheme, respectively.  ", "human_text": "  In this paper we will first introduce the notion of affine structures on a ringed space and then obtain several properties. Affine structures on a ringed space, arising mainly from complex analytical spaces of algebraic schemes over number fields, behave like differential structures on a smooth manifold.   As one does for differential manifolds, we will use pseudogroups of affine transformations to define affine atlases on a ringed space. An atlas on a space is said to be an affine structure if it is maximal. An affine structure is admissible if there is a sheaf on the underlying space such that they are coincide on all affine charts, which are in deed affine open sets of a scheme. In a rigour manner, a scheme is defined to be a ringed space with a specified affine structure if the affine structures are in action in some special cases such as analytical spaces of algebraic schemes. Particularly, by the whole of affine structures on a space, we will obtain respectively necessary and sufficient conditions that two spaces are homeomorphic and that two schemes are isomorphic, which are the two main theorems of the paper. It follows that the whole of affine structures on a space and a scheme, as local data, encode and reflect the global properties of the space and the scheme, respectively. ", "machine_text": "  In this article, we investigate affine structures on a ringed space and schemes. We explore the behavior of affine structures on a space resulting from analytical spaces of algebraic schemes over number fields. Pseudogroups of affine transformations are utilized to define affine atlases on a space, and maximal atlas will determine an affine structure. Admissible affine structures can be recognized by the coincidence of a sheaf on the underlying space. We give necessary and sufficient conditions for two spaces to be homeomorphic and two schemes to be isomorphic using the affine structures as local data. The global properties of the space and the scheme are encoded and reflected through their respective affine structures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0579}
{"prompt": "Rephrase the abstract of an article with title 'Chaos and Symmetry in String Cosmology'.   We review the recently discovered interplay between chaos and symmetry in the general inhomogeneous solution of many string-related Einstein-matter systems in the vicinity of a cosmological singularity. The Belinsky-Khalatnikov-Lifshitz-type chaotic behaviour is found, for many Einstein-matter models (notably those related to the low-energy limit of superstring theory and M-theory), to be connected with certain (infinite-dimensional) hyperbolic Kac-Moody algebras. In particular, the billiard chambers describing the asymptotic cosmological behaviour of pure Einstein gravity in spacetime dimension d+1, or the metric-three-form system of 11-dimensional supergravity, are found to be identical to the Weyl chambers of the Lorentzian Kac-Moody algebras AE_d, or E_{10}, respectively. This suggests that these Kac-Moody algebras are hidden symmetries of the corresponding models. There even exists some evidence of a hidden equivalence between the general solution of the Einstein-three-form system and a null geodesic in the infinite dimensional coset space E_{10} / K(E_{10}), where K(E_{10}) is the maximal compact subgroup of E_{10}.  ", "human_text": "  We review the recently discovered interplay between chaos and symmetry in the general inhomogeneous solution of many string-related Einstein-matter systems in the vicinity of a cosmological singularity. The Belinsky-Khalatnikov-Lifshitz-type chaotic behaviour is found, for many Einstein-matter models (notably those related to the low-energy limit of superstring theory and M-theory), to be connected with certain (infinite-dimensional) hyperbolic Kac-Moody algebras. In particular, the billiard chambers describing the asymptotic cosmological behaviour of pure Einstein gravity in spacetime dimension d+1, or the metric-three-form system of 11-dimensional supergravity, are found to be identical to the Weyl chambers of the Lorentzian Kac-Moody algebras AE_d, or E_{10}, respectively. This suggests that these Kac-Moody algebras are hidden symmetries of the corresponding models. There even exists some evidence of a hidden equivalence between the general solution of the Einstein-three-form system and a null geodesic in the infinite dimensional coset space E_{10} / K(E_{10}), where K(E_{10}) is the maximal compact subgroup of E_{10}. ", "machine_text": "  In this article, we examine the intricate relationship between chaos and symmetry demonstrated by the inhomogeneous solutions of Einstein-matter systems associated with string theory and M-theory. Using the Belinsky-Khalatnikov-Lifshitz framework, we determine the extent of the chaotic behavior of these systems near the cosmological singularity. Our analysis reveals a connection between the chaotic settings arising from the respective systems and certain infinite-dimensional hyperbolic Kac-Moody algebras. We find that the billiard chambers describing the asymptotic cosmological behavior of Einstein gravity in d+1 dimensions and the metric-three-form system of 11-dimensional supergravity are the same as the Weyl chambers of the Lorentzian Kac-Moody algebras AE_d and E_{10}, respectively. This bolsters the idea that these Kac-Moody algebras serve as hidden symmetries of the corresponding models. Moreover, there is some evidence of a hidden similarity between the general solution of the Einstein-three-form system and a null geodesic in the infinite dimensional E_{10} / K(E_{10}) coset space.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1457}
{"prompt": "Rephrase the abstract of an article with title 'Applicability of layered sine-Gordon models to layered superconductors:   II. The case of magnetic coupling'.   In this paper, we propose a quantum field theoretical renormalization group approach to the vortex dynamics of magnetically coupled layered superconductors, to supplement our earlier investigations on the Josephson-coupled case. We construct a two-dimensional multi-layer sine-Gordon type model which we map onto a gas of topological excitations. With a special choice of the mass matrix for our field theoretical model, vortex dominated properties of magnetically coupled layered superconductors can be described. The well known interaction potentials of fractional flux vortices are consistently obtained from our field-theoretical analysis, and the physical parameters (vortex fugacity and temperature parameter) are also identified. We analyse the phase structure of the multi-layer sine--Gordon model by a differential renormalization group method for the magnetically coupled case from first principles. The dependence of the transition temperature on the number of layers is found to be in agreement with known results based on other methods.  ", "human_text": "  In this paper, we propose a quantum field theoretical renormalization group approach to the vortex dynamics of magnetically coupled layered superconductors, to supplement our earlier investigations on the Josephson-coupled case. We construct a two-dimensional multi-layer sine-Gordon type model which we map onto a gas of topological excitations. With a special choice of the mass matrix for our field theoretical model, vortex dominated properties of magnetically coupled layered superconductors can be described. The well known interaction potentials of fractional flux vortices are consistently obtained from our field-theoretical analysis, and the physical parameters (vortex fugacity and temperature parameter) are also identified. We analyse the phase structure of the multi-layer sine--Gordon model by a differential renormalization group method for the magnetically coupled case from first principles. The dependence of the transition temperature on the number of layers is found to be in agreement with known results based on other methods. ", "machine_text": " This paper examines the feasibility of a two-dimensional multi-layer sine-Gordon model to describe the vortex dynamics of magnetically coupled layered superconductors. We apply a quantum field theoretical renormalization group approach to study the phase structure of the model, with parameters that include the vortex fugacity and temperature. Results from this analysis correspond to the interaction potentials and transition temperatures expected for fractional flux vortices, and agree with previously established theoretical evidence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0578}
{"prompt": "Rephrase the abstract of an article with title 'Spitzer Quasar and ULIRG Evolution Study (QUEST): II. The Spectral   Energy Distributions of Palomar-Green Quasars'.   This is the second paper studying the QSOs in the spitzer QUEST sample. Previously we presented new PAH measurements and argued that most of the observed far infrared (FIR) radiation is due to star-forming activity. Here we present spectral energy distributions (SEDs) by supplementing our data with optical, NIR and FIR observations. We define two sub-groups of ``weak FIR'' and ``strong FIR'' QSOs, and a third group of FIR non-detections. Assuming a starburst origin for the FIR, we obtain ``intrinsic'' AGN SEDs by subtracting a starburst template from the mean SEDs. The resulting SEDs are remarkably similar for all groups. They show three distinct peaks corresponding to two silicate emission features and a 3mic bump that we interpret as the signature of the hottest AGN dust. They also display drops beyond 20mic that we interpret as the signature of the minimum temperature (about 200K) dust. This component must be optically thin to explain the silicate emission and the slope of the long wavelength continuum. We discuss the merits of an alternative model where most of the FIR emission is due to AGN heating. Such models are unlikely to explain the properties of our QSOs but they cannot be ruled out for more luminous objects. We also find correlations between the luminosity at 5100A and two infrared starburst indicators: L(60mic) and L(PAH 7.7mic). The correlation of L(5100A) with L(60mic) can be used to measure the relative growth rates and lifetimes of the black hole and the new stars.  ", "human_text": "  This is the second paper studying the QSOs in the spitzer QUEST sample. Previously we presented new PAH measurements and argued that most of the observed far infrared (FIR) radiation is due to star-forming activity. Here we present spectral energy distributions (SEDs) by supplementing our data with optical, NIR and FIR observations. We define two sub-groups of ``weak FIR'' and ``strong FIR'' QSOs, and a third group of FIR non-detections. Assuming a starburst origin for the FIR, we obtain ``intrinsic'' AGN SEDs by subtracting a starburst template from the mean SEDs. The resulting SEDs are remarkably similar for all groups. They show three distinct peaks corresponding to two silicate emission features and a 3mic bump that we interpret as the signature of the hottest AGN dust. They also display drops beyond 20mic that we interpret as the signature of the minimum temperature (about 200K) dust. This component must be optically thin to explain the silicate emission and the slope of the long wavelength continuum. We discuss the merits of an alternative model where most of the FIR emission is due to AGN heating. Such models are unlikely to explain the properties of our QSOs but they cannot be ruled out for more luminous objects. We also find correlations between the luminosity at 5100A and two infrared starburst indicators: L(60mic) and L(PAH 7.7mic). The correlation of L(5100A) with L(60mic) can be used to measure the relative growth rates and lifetimes of the black hole and the new stars. ", "machine_text": " In this second paper on the QUEST sample of Quasars (QSOs), we focus on their Spectral Energy Distributions (SEDs). We supplement our data with observations in optical, NIR and FIR. We identify two categories of QSOs as \u201cweak FIR\u201d and \u201cstrong FIR\u201d and a third category of QSOs without FIR detections. We assume the far infrared (FIR) emission is primarily due to star-forming activity and are able to remove a starburst template from the mean SED to obtain an \u201cintrinsic\u201d SED for the AGNs. The resulting SEDs for all 3 groups show the same three distinct peaks, two silicate emission features and a 3mic bump. We interpret these as the signature of the hottest AGN dust. Additionally, drops beyond 20mic are observed, which we interpret as the signature of the minimum temperature (approximately 200K) dust. We analyze the merits of an alternative model where most of the FIR is due to AGN heating and discuss the correlations between luminosity at 5100A and two infrared starburst indicators: L(60mic) and L(PAH 7.7mic).  This can be used to measure the relative growth rates and lifetimes of the black hole and the new stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0818}
{"prompt": "Rephrase the abstract of an article with title 'A Catalog of Star Cluster Candidates in M33'.   We present a new catalog of star cluster candidates in the nearby spiral galaxy M33. It is based on eight existing catalogs wherein we have cross-referenced identifications and endeavored to resolve inconsistencies between them. Our catalog contains 451 candidates of which 255 are confirmed clusters based on HST and high resolution ground-based imaging. The catalog contains precise cluster positions (RA and Dec), magnitudes and colors in the UBVRIJHKs filters, metallicities, radial velocities, masses and ages, where available, and galactocentric distances for each cluster. The color distribution of the M33 clusters appears to be similar to those in the Large Magellanic Cloud with major peaks at (B-V)o~0.15, and (B-V)o~0.65. The intrinsic colors are correlated with cluster ages, which range from 10^{7.5} to 10^{10.3} years. The age distribution of the star clusters supports the notion of rapid cluster disruption with a slope of alpha=-1.09 +/- 0.07 in the dN_{cluster}/dt ~ t^{alpha} relation. In addition, comparison to theoretical single stellar population models suggests the presence of an age-metallicity relation among these clusters with younger clusters being more metal-rich. Analysis of the radial distribution of the clusters yields some evidence that younger clusters (age <~ 1 Gyr) may be more concentrated toward the center of M33 than older ones. A similar comparison with the radial profile of the M33 field stars shows the clusters to be more centrally concentrated at the greater than 99.9% confidence level. Possible reasons for this are presented and discussed; however, the overwhelming conclusion seems to be that a more complete and thorough cluster search is needed covering at least 4 square degrees centered on M33.  ", "human_text": "  We present a new catalog of star cluster candidates in the nearby spiral galaxy M33. It is based on eight existing catalogs wherein we have cross-referenced identifications and endeavored to resolve inconsistencies between them. Our catalog contains 451 candidates of which 255 are confirmed clusters based on HST and high resolution ground-based imaging. The catalog contains precise cluster positions (RA and Dec), magnitudes and colors in the UBVRIJHKs filters, metallicities, radial velocities, masses and ages, where available, and galactocentric distances for each cluster. The color distribution of the M33 clusters appears to be similar to those in the Large Magellanic Cloud with major peaks at (B-V)o~0.15, and (B-V)o~0.65. The intrinsic colors are correlated with cluster ages, which range from 10^{7.5} to 10^{10.3} years. The age distribution of the star clusters supports the notion of rapid cluster disruption with a slope of alpha=-1.09 +/- 0.07 in the dN_{cluster}/dt ~ t^{alpha} relation. In addition, comparison to theoretical single stellar population models suggests the presence of an age-metallicity relation among these clusters with younger clusters being more metal-rich. Analysis of the radial distribution of the clusters yields some evidence that younger clusters (age <~ 1 Gyr) may be more concentrated toward the center of M33 than older ones. A similar comparison with the radial profile of the M33 field stars shows the clusters to be more centrally concentrated at the greater than 99.9% confidence level. Possible reasons for this are presented and discussed; however, the overwhelming conclusion seems to be that a more complete and thorough cluster search is needed covering at least 4 square degrees centered on M33. ", "machine_text": " This paper presents a catalog of 451 star cluster candidates in M33, 255 of which have been confirmed through HST and high resolution ground-based imaging. Our catalog includes precise data for each cluster such as positions, magnitudes and colors, metallicities, radial velocities, masses and ages, and galactocentric distances. The color distribution of the M33 clusters appears similar to those of the large Magellanic Cloud, where major peaks are located at B-V of 0.15 and 0.65. Additionally, results from this analysis indicate a correlation between the clusters' ages and intrinsic colors with younger clusters tending to be more metal-rich. The radial profile of the M33 clusters is also more concentrated than that of the field stars, suggesting that a more comprehensive search of the area is needed; we discuss potential reasons for this conclusion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1576}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical models with a general anisotropy profile'.   Both numerical simulations and observational evidence indicate that the outer regions of galaxies and dark matter haloes are typically mildly to significantly radially anisotropic. The inner regions can be significantly non-isotropic, depending on the dynamical formation and evolution processes. In an attempt to break the lack of simple dynamical models that can reproduce this behaviour, we explore a technique to construct dynamical models with an arbitrary density and an arbitrary anisotropy profile. We outline a general construction method and propose a more practical approach based on a parameterized anisotropy profile. This approach consists of fitting the density of the model with a set of dynamical components, each of which have the same anisotropy profile. Using this approach we avoid the delicate fine-tuning difficulties other fitting techniques typically encounter when constructing radially anisotropic models. We present a model anisotropy profile that generalizes the Osipkov-Merritt profile, and that can represent any smooth monotonic anisotropy profile. Based on this model anisotropy profile, we construct a very general seven-parameter set of dynamical components for which the most important dynamical properties can be calculated analytically. We use the results to look for simple one-component dynamical models that generate simple potential-density pairs while still supporting a flexible anisotropy profile. We present families of Plummer and Hernquist models in which the anisotropy at small and large radii can be chosen as free parameters. We also generalize these two families to a three-parameter family that self-consistently generates the set of Veltmann potential-density pairs. (Abridged...)  ", "human_text": "  Both numerical simulations and observational evidence indicate that the outer regions of galaxies and dark matter haloes are typically mildly to significantly radially anisotropic. The inner regions can be significantly non-isotropic, depending on the dynamical formation and evolution processes. In an attempt to break the lack of simple dynamical models that can reproduce this behaviour, we explore a technique to construct dynamical models with an arbitrary density and an arbitrary anisotropy profile. We outline a general construction method and propose a more practical approach based on a parameterized anisotropy profile. This approach consists of fitting the density of the model with a set of dynamical components, each of which have the same anisotropy profile. Using this approach we avoid the delicate fine-tuning difficulties other fitting techniques typically encounter when constructing radially anisotropic models. We present a model anisotropy profile that generalizes the Osipkov-Merritt profile, and that can represent any smooth monotonic anisotropy profile. Based on this model anisotropy profile, we construct a very general seven-parameter set of dynamical components for which the most important dynamical properties can be calculated analytically. We use the results to look for simple one-component dynamical models that generate simple potential-density pairs while still supporting a flexible anisotropy profile. We present families of Plummer and Hernquist models in which the anisotropy at small and large radii can be chosen as free parameters. We also generalize these two families to a three-parameter family that self-consistently generates the set of Veltmann potential-density pairs. (Abridged...) ", "machine_text": " We present a method of constructing dynamical models with an arbitrary density and anisotropy profile in order to reproduce observed radial anisotropy in galaxies and dark matter haloes. A parameterized anisotropy profile is proposed, which generalizes the Osipkov-Merritt profile and can represent any smooth monotonic anisotropy profile. Using the proposed model, a seven-parameter set of dynamical components can be constructed and dynamical properties can be calculated analytically. Through the study of simple one-component dynamical models, we construct families of Plummer and Hernquist models which include flexible anisotropy profiles of small and large radii as potntial parameters. In addition, a three-parameter family generalizes these models, generating Veltmann potential-density pairs self-consistently.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4109}
{"prompt": "Rephrase the abstract of an article with title 'Two branches of neutron stars - reconciling a 2M_sun pulsar and SN1987A'.   The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the maximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max, due to a kaon condensation in the stellar core, implies collapse of a too massive deleptonized protoneutron star into a black hole. This would naturally explain the lack of a neutron star in the SN1987A remnant. On the other hand, recent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This contradicts the original Bethe-Brown model, but can be reconciled within scenarios proposed in the present Letter. We consider two types of dense matter models with high-density softening, due to a transition from a non-strange N-phase of matter to a strangeness carrying phase S: kaon condensation and deconfinement of quarks. Two scenarios of neutron star formation in stellar core collapse are considered. In the first scenario, realized in sufficiently hot and dense supernova cores, nucleation of an S-phase is sufficiently rapid so as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the second scenario, nucleation of the S-phase at neutron star birth is too slow to materialize, and the star becomes cold without forming an S-phase core. Then, stellar mass can increase via accretion, until central density \\rho_crit is reached, and the S phase forms. This N branch of neutron stars ends at M=M_crit. We select several models of N-phase satifying the necessary condition M^N_max > 2M_sun and combine them with models of kaon condensation and quark deconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun, which is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark deconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and PSR J0751+1807.  ", "human_text": "  The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the maximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max, due to a kaon condensation in the stellar core, implies collapse of a too massive deleptonized protoneutron star into a black hole. This would naturally explain the lack of a neutron star in the SN1987A remnant. On the other hand, recent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This contradicts the original Bethe-Brown model, but can be reconciled within scenarios proposed in the present Letter. We consider two types of dense matter models with high-density softening, due to a transition from a non-strange N-phase of matter to a strangeness carrying phase S: kaon condensation and deconfinement of quarks. Two scenarios of neutron star formation in stellar core collapse are considered. In the first scenario, realized in sufficiently hot and dense supernova cores, nucleation of an S-phase is sufficiently rapid so as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the second scenario, nucleation of the S-phase at neutron star birth is too slow to materialize, and the star becomes cold without forming an S-phase core. Then, stellar mass can increase via accretion, until central density \\rho_crit is reached, and the S phase forms. This N branch of neutron stars ends at M=M_crit. We select several models of N-phase satifying the necessary condition M^N_max > 2M_sun and combine them with models of kaon condensation and quark deconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun, which is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark deconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and PSR J0751+1807. ", "machine_text": " This study examines the discord between SN1987A and the confirmed pulsar PSR J0751+1807, which suggests a maximum mass of cold neutron stars of 1.5M_sun due to kaon condensing in the stellar core. In contrast, the evaluation of PSR J0751+1807 gives a value greater than 2M_sun. Through evaluation of two models of dense matter with high-density softening, kaon condensation and deconfinement of quarks, this research proposes two scenarios of neutron star formation. In the first, the S-phase forms rapidly in the supernova core, giving a maximum mass of 1.5M_sun, which is invalidated by PSR J0751+1807. In the second, nucleation of the S-phase at neutron star birth is too slow and it remains a non-strange N-phase. Consequently, stellar mass can increase beyond the critical value of 2M_sun via accretion. This N-phase model reconciles SN1987A and PSR J0751+1807, resolving the existing conflict between the two.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4594}
{"prompt": "Rephrase the abstract of an article with title 'Construction of type ${\\rm II_1}$ factors with prescribed countable   fundamental group'.   In the context of Free Probability Theory, we study two different constructions that provide new examples of factors of type ${\\rm II_1}$ with prescribed fundamental group. First we investigate state-preserving group actions on the almost periodic free Araki-Woods factors satisfying both a condition of mixing and a condition of free malleability in the sense of Popa. Typical examples are given by the free Bogoliubov shifts. Take an ICC $w$-rigid group $G$ such that $\\mathcal{F}(L(G)) = \\{1\\}$ (e.g. $G = \\Z^2 \\rtimes \\SL(2, \\Z)$). For any countable subgroup $S \\subset \\R^*_+$, we show that there exists an action of $G$ on $L(\\F_\\infty)$ such that $L(\\F_\\infty) \\rtimes G$ is a type ${\\rm II_1}$ factor and its fundamental group is $S$. The second construction is based on a free product. Take $(B(H), \\psi)$ any factor of type ${\\rm I}$ endowed with a faithful normal state and denote by $\\Gamma \\subset \\R^*_+$ the subgroup generated by the point spectrum of $\\psi$. We show that the centralizer $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ is a type ${\\rm II_1}$ factor and its fundamental group is $\\Gamma$. Our proofs rely on Popa's deformation/rigidity strategy using his intertwining-by-bimodules technique.  ", "human_text": "  In the context of Free Probability Theory, we study two different constructions that provide new examples of factors of type ${\\rm II_1}$ with prescribed fundamental group. First we investigate state-preserving group actions on the almost periodic free Araki-Woods factors satisfying both a condition of mixing and a condition of free malleability in the sense of Popa. Typical examples are given by the free Bogoliubov shifts. Take an ICC $w$-rigid group $G$ such that $\\mathcal{F}(L(G)) = \\{1\\}$ (e.g. $G = \\Z^2 \\rtimes \\SL(2, \\Z)$). For any countable subgroup $S \\subset \\R^*_+$, we show that there exists an action of $G$ on $L(\\F_\\infty)$ such that $L(\\F_\\infty) \\rtimes G$ is a type ${\\rm II_1}$ factor and its fundamental group is $S$. The second construction is based on a free product. Take $(B(H), \\psi)$ any factor of type ${\\rm I}$ endowed with a faithful normal state and denote by $\\Gamma \\subset \\R^*_+$ the subgroup generated by the point spectrum of $\\psi$. We show that the centralizer $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ is a type ${\\rm II_1}$ factor and its fundamental group is $\\Gamma$. Our proofs rely on Popa's deformation/rigidity strategy using his intertwining-by-bimodules technique. ", "machine_text": " This article explores two separate constructions of type ${\\rm II_1}$ factors having a prescribed countable fundamental group. The first involves group actions on almost periodic free Araki-Woods factors that meet two conditions: mixing and free malleability, as defined by Popa. When the group $G$ chosen is an ICC $w$-rigid group with trivial centralizer (e.g. $G = \\Z^2 \\rtimes \\SL(2,\\Z)$), there will be an action on $L(\\F_\\infty)$ that forms a type ${\\rm II_1}$ factor with fundamental group $S$, where $S$ is an arbitrary countable subgroup of $\\R^*_+$. The other construction involves a free product of factors, such that for a factor $B(H)$ of type ${\\rm I}$ with a normal faithful state $\\psi$, the centralizer of the free product $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ turns out to be a type ${\\rm II_1}$ factor with fundamental group $\\Gamma$, which is the subgroup of $\\R^*_+$ generated by the point spectrum of $\\psi$. The techniques of Popa's deformation/rigidity strategy and intertwining- by -bimodules are the main instruments for the proof.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3502}
{"prompt": "Rephrase the abstract of an article with title 'INTEGRAL high energy monitoring of the X-ray burster KS 1741-293'.   KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module of the Mir space station and identified as an X-ray burster, has not been detected in the hard X band until the advent of the INTEGRAL observatory. Moreover this source has been recently object of scientific discussion, being also associated to a nearby extended radio source that in principle could be the supernova remnant produced by the accretion induced collapse in the binary system. Our long term monitoring with INTEGRAL, covering the period from February 2003 to May 2005, confirms that KS 1741-293 is transient in soft and hard X band. When the source is active, from a simultaneous JEM-X and IBIS data analysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by a two component model, a multiple blackbody for the soft emission and a Comptonized or a cut-off power law model for the hard component. Finally, by the detection of two X-ray bursters with JEM-X, we confirm the bursting nature of KS 1741-293, including this source in the class of the hard tailed X-ray bursters.  ", "human_text": "  KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module of the Mir space station and identified as an X-ray burster, has not been detected in the hard X band until the advent of the INTEGRAL observatory. Moreover this source has been recently object of scientific discussion, being also associated to a nearby extended radio source that in principle could be the supernova remnant produced by the accretion induced collapse in the binary system. Our long term monitoring with INTEGRAL, covering the period from February 2003 to May 2005, confirms that KS 1741-293 is transient in soft and hard X band. When the source is active, from a simultaneous JEM-X and IBIS data analysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by a two component model, a multiple blackbody for the soft emission and a Comptonized or a cut-off power law model for the hard component. Finally, by the detection of two X-ray bursters with JEM-X, we confirm the bursting nature of KS 1741-293, including this source in the class of the hard tailed X-ray bursters. ", "machine_text": " The INTEGRAL observatory's high-energy monitoring of the X-ray burster KS 1741-293 has revealed that this source is transient in the soft and hard X bands. The time period examined being February 2003 - May 2005, a two component model has successfully fit the JEM-X and IBIS data from 5 - 100 keV. This includes a multiple blackbody for the soft emission and a cut-off power law model for the hard component. The data has contributed to a new classification for KS 1741-293, confirming its identity as a hard-tailed X-ray burster.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0832}
{"prompt": "Rephrase the abstract of an article with title 'c2d Spitzer IRS Spectra of Disks around T Tauri Stars. III. [Ne II], [Fe   I], and H_2 gas-phase lines'.   We present a survey of mid-infrared gas-phase lines toward a sample of 76 circumstellar disks around low mass pre-main sequence stars from the Spitzer \"Cores to Disks\" legacy program. We report the first detections of [Ne II] and [Fe I] toward classical T Tauri stars in ~20% respectively ~9% of our sources. The observed [Ne II] line fluxes and upper limits are consistent with [Ne II] excitation in an X-ray irradiated disk around stars with X-ray luminosities L_X=10^{29}-10^{31} erg s^{-1}. [Fe I] is detected at ~10^-5-10^-4 L_Sun, but no [S I] or [Fe II] is detected down to ~10^{-6} L_Sun. The [Fe I] detections indicate the presence of gas-rich disks with masses of >~0.1 M_J. No H_2 0-0 S(0) and S(1) disk emission is detected, except for S(1) toward one source. These data give upper limits on the warm (T~100-200K) gas mass of a few Jovian masses, consistent with recent T Tauri disk models which include gas heating by stellar radiation. Compact disk emission of hot (T>~500K) gas is observed through the H_2 0-0 S(2) and/or S(3) lines toward ~8% of our sources. The line fluxes are, however, higher by more than an order of magnitude than those predicted by recent disk models, even when X-ray and excess UV radiation are included. Similarly the [Ne II]/H_2 0-0 S(2) ratios for these sources are lower than predicted, consistent with the presence of an additional hot molecular gas component not included in current disk models. Oblique shocks of stellar winds interacting with the disk can explain many aspects of the hot gas emission, but are inconsistent with the non-detection of [S I] and [Fe II] lines.  ", "human_text": "  We present a survey of mid-infrared gas-phase lines toward a sample of 76 circumstellar disks around low mass pre-main sequence stars from the Spitzer \"Cores to Disks\" legacy program. We report the first detections of [Ne II] and [Fe I] toward classical T Tauri stars in ~20% respectively ~9% of our sources. The observed [Ne II] line fluxes and upper limits are consistent with [Ne II] excitation in an X-ray irradiated disk around stars with X-ray luminosities L_X=10^{29}-10^{31} erg s^{-1}. [Fe I] is detected at ~10^-5-10^-4 L_Sun, but no [S I] or [Fe II] is detected down to ~10^{-6} L_Sun. The [Fe I] detections indicate the presence of gas-rich disks with masses of >~0.1 M_J. No H_2 0-0 S(0) and S(1) disk emission is detected, except for S(1) toward one source. These data give upper limits on the warm (T~100-200K) gas mass of a few Jovian masses, consistent with recent T Tauri disk models which include gas heating by stellar radiation. Compact disk emission of hot (T>~500K) gas is observed through the H_2 0-0 S(2) and/or S(3) lines toward ~8% of our sources. The line fluxes are, however, higher by more than an order of magnitude than those predicted by recent disk models, even when X-ray and excess UV radiation are included. Similarly the [Ne II]/H_2 0-0 S(2) ratios for these sources are lower than predicted, consistent with the presence of an additional hot molecular gas component not included in current disk models. Oblique shocks of stellar winds interacting with the disk can explain many aspects of the hot gas emission, but are inconsistent with the non-detection of [S I] and [Fe II] lines. ", "machine_text": " In this study, we have surveyed mid-infrared gas-phase lines in 76 circumstellar disks of low-mass pre-main sequence stars as part of the Spitzer \"Cores to Disks\" program. This is the first detection of [Ne II] and [Fe I] in ~20% and ~9% of these systems, respectively. The [Ne II] line emission suggests that these disks are x-ray-irradiated and the [Fe I] fluxes imply the presence of gas-rich disks with masses > 0.1 M_J. Additionally, H_2 0-0 S(2) and S(3) lines were detected from a few sources at much higher intensities than predicted by current disk models. To explain this emission, we suggest the presence of interceding shocks from a stellar wind is required and cannot be explained by the non-detections of [S I] and [Fe II] lines.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2305}
{"prompt": "Rephrase the abstract of an article with title 'A Cross-disciplinary Framework for the Description of Contextually   Mediated Change'.   We present a mathematical framework (referred to as Context-driven Actualization of Potential, or CAP) for describing how entities change over time under the influence of a context. The approach facilitates comparison of change of state of entities studied in different disciplines. Processes are seen to differ according to the degree of nondeterminism, and the degree to which they are sensitive to, internalize, and depend upon a particular context. Our analysis suggests that the dynamical evolution of a quantum entity described by the Schrodinger equation is not fundamentally different from change provoked by a measurement often referred to as collapse, but a limiting case, with only one way to collapse. The biological transition to coded replication is seen as a means of preserving structure in the fact of context-driven change, and sextual replication as a means of increasing potentiality thus enhancing diversity through interaction with context. The framework sheds light on concepts like selection and fitness, reveals how exceptional Darwinian evolution is as a means of 'change of state', and clarifies in what sense culture, and the creative process underlying it, are Darwinian.  ", "human_text": "  We present a mathematical framework (referred to as Context-driven Actualization of Potential, or CAP) for describing how entities change over time under the influence of a context. The approach facilitates comparison of change of state of entities studied in different disciplines. Processes are seen to differ according to the degree of nondeterminism, and the degree to which they are sensitive to, internalize, and depend upon a particular context. Our analysis suggests that the dynamical evolution of a quantum entity described by the Schrodinger equation is not fundamentally different from change provoked by a measurement often referred to as collapse, but a limiting case, with only one way to collapse. The biological transition to coded replication is seen as a means of preserving structure in the fact of context-driven change, and sextual replication as a means of increasing potentiality thus enhancing diversity through interaction with context. The framework sheds light on concepts like selection and fitness, reveals how exceptional Darwinian evolution is as a means of 'change of state', and clarifies in what sense culture, and the creative process underlying it, are Darwinian. ", "machine_text": "This article presents a framework for examining how entities change over time based on their respective contexts. We refer to this approach as Context-driven Actualization of Potential (CAP). This framework facilitates an understanding of the differences in how state-changes occur in different disciplines. For instance, our analysis posits that the dynamical evolution of quantum entities, as described by the Schrodinger equation, is not distinct from the changes by measurement (or, the 'collapse'), but merely a limiting case. Additionally, our framework offers insights into concepts such as selection and fitness, demonstrating how exceptional Darwinian evolution is as a means of state-change. Lastly, it reveals the connections between culture, and the creative processes that embody it, and Darwinian principles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0156}
{"prompt": "Rephrase the abstract of an article with title 'Laplacian spectra of complex networks and random walks on them: Are   scale-free architectures really important?'.   We study the Laplacian operator of an uncorrelated random network and, as an application, consider hopping processes (diffusion, random walks, signal propagation, etc.) on networks. We develop a strict approach to these problems. We derive an exact closed set of integral equations, which provide the averages of the Laplacian operator's resolvent. This enables us to describe the propagation of a signal and random walks on the network. We show that the determining parameter in this problem is the minimum degree $q_m$ of vertices in the network and that the high-degree part of the degree distribution is not that essential. The position of the lower edge of the Laplacian spectrum $\\lambda_c$ appears to be the same as in the regular Bethe lattice with the coordination number $q_m$. Namely, $\\lambda_c>0$ if $q_m>2$, and $\\lambda_c=0$ if $q_m\\leq2$. In both these cases the density of eigenvalues $\\rho(\\lambda)\\to0$ as $\\lambda\\to\\lambda_c+0$, but the limiting behaviors near $\\lambda_c$ are very different. In terms of a distance from a starting vertex, the hopping propagator is a steady moving Gaussian, broadening with time. This picture qualitatively coincides with that for a regular Bethe lattice. Our analytical results include the spectral density $\\rho(\\lambda)$ near $\\lambda_c$ and the long-time asymptotics of the autocorrelator and the propagator.  ", "human_text": "  We study the Laplacian operator of an uncorrelated random network and, as an application, consider hopping processes (diffusion, random walks, signal propagation, etc.) on networks. We develop a strict approach to these problems. We derive an exact closed set of integral equations, which provide the averages of the Laplacian operator's resolvent. This enables us to describe the propagation of a signal and random walks on the network. We show that the determining parameter in this problem is the minimum degree $q_m$ of vertices in the network and that the high-degree part of the degree distribution is not that essential. The position of the lower edge of the Laplacian spectrum $\\lambda_c$ appears to be the same as in the regular Bethe lattice with the coordination number $q_m$. Namely, $\\lambda_c>0$ if $q_m>2$, and $\\lambda_c=0$ if $q_m\\leq2$. In both these cases the density of eigenvalues $\\rho(\\lambda)\\to0$ as $\\lambda\\to\\lambda_c+0$, but the limiting behaviors near $\\lambda_c$ are very different. In terms of a distance from a starting vertex, the hopping propagator is a steady moving Gaussian, broadening with time. This picture qualitatively coincides with that for a regular Bethe lattice. Our analytical results include the spectral density $\\rho(\\lambda)$ near $\\lambda_c$ and the long-time asymptotics of the autocorrelator and the propagator. ", "machine_text": " We investigate the Laplacian spectra and random walks of complex networks by deriving and analyzing a closed set of integral equations which give us averages of the Laplacian operator's resolvent. We examine the integral values and parameters of the network, concluding that the minimum degree of a vertex is a key factor. We find that the lower edge of the Laplacian spectrum is the same as that of a regular Bethe lattice, indicating a steady moving Gaussian of the hopping propagator. Furthermore, the long time asymptotic for the autocorrelator and the propagator are indicated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1176}
{"prompt": "Rephrase the abstract of an article with title 'Space of Quantum Theory Representations of Natural Numbers, Integers,   and Rational Numbers'.   This paper extends earlier work on quantum theory representations of natural numbers N, integers I, and rational numbers Ra to describe a space of these representations and transformations on the space. The space is parameterized by 4-tuple points in a parameter set. Each point, (k,m,h,g), labels a specific representation of X = N, I, Ra as a Fock space F^{X}_{k,m,h} of states of finite length strings of qukits q and a string state basis B^{X}_{k,m,h,g}. The pair (m,h) locates the q string in a square integer lattice I \\times I, k is the q base, and the function g fixes the gauge or basis states for each q. Maps on the parameter set induce transformations on on the representation space. There are two shifts, a base change operator W_{k',k}, and a basis or gauge transformation function U_{k}. The invariance of the axioms and theorems for N, I, and Ra under any transformation is discussed along with the dependence of the properties of W_{k',k} on the prime factors of k' and k. This suggests that one consider prime number q's, q_{2}, q_{3}, q_{5}, etc. as elementary and the base k q's as composites of the prime number q's.  ", "human_text": "  This paper extends earlier work on quantum theory representations of natural numbers N, integers I, and rational numbers Ra to describe a space of these representations and transformations on the space. The space is parameterized by 4-tuple points in a parameter set. Each point, (k,m,h,g), labels a specific representation of X = N, I, Ra as a Fock space F^{X}_{k,m,h} of states of finite length strings of qukits q and a string state basis B^{X}_{k,m,h,g}. The pair (m,h) locates the q string in a square integer lattice I \\times I, k is the q base, and the function g fixes the gauge or basis states for each q. Maps on the parameter set induce transformations on on the representation space. There are two shifts, a base change operator W_{k',k}, and a basis or gauge transformation function U_{k}. The invariance of the axioms and theorems for N, I, and Ra under any transformation is discussed along with the dependence of the properties of W_{k',k} on the prime factors of k' and k. This suggests that one consider prime number q's, q_{2}, q_{3}, q_{5}, etc. as elementary and the base k q's as composites of the prime number q's. ", "machine_text": "This paper presents a space of quantum theory representations of the natural numbers N, integers I and rational numbers Ra. This space is parameterized by parameters denoted by 4-tuple points (k,m,h,g). Each point of the space labels a specific Fock space F^{X}_{k,m,h} of states with finite length strings of qukits q and a string state basis B^{X}_{k,m,h,g}. Maps on the parameter set result in transformations on the representation space, consisting of shifts, a base change operator W_{k',k}, and a basis or gauge transformation function U_{k}. The invariance of the properties of the natural, integer and rational numbers under any of these transformations is discussed, with an emphasis on the effect of prime factors on the operation of W_{k',k}. Under this light, the paper suggests that one should consider the prime number q's (e.g., q_{2}, q_{3}, q_{5}) as elemental and k q's as composites of these primes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3574}
{"prompt": "Rephrase the abstract of an article with title 'Geometry of PT-symmetric quantum mechanics'.   Recently, much research has been carried out on Hamiltonians that are not Hermitian but are symmetric under space-time reflection, that is, Hamiltonians that exhibit PT symmetry. Investigations of the Sturm-Liouville eigenvalue problem associated with such Hamiltonians have shown that in many cases the entire energy spectrum is real and positive and that the eigenfunctions form an orthogonal and complete basis. Furthermore, the quantum theories determined by such Hamiltonians have been shown to be consistent in the sense that the probabilities are positive and the dynamical trajectories are unitary. However, the geometrical structures that underlie quantum theories formulated in terms of such Hamiltonians have hitherto not been fully understood. This paper studies in detail the geometric properties of a Hilbert space endowed with a parity structure and analyses the characteristics of a PT-symmetric Hamiltonian and its eigenstates. A canonical relationship between a PT-symmetric operator and a Hermitian operator is established. It is shown that the quadratic form corresponding to the parity operator, in particular, gives rise to a natural partition of the Hilbert space into two halves corresponding to states having positive and negative PT norm. The indefiniteness of the norm can be circumvented by introducing a symmetry operator C that defines a positive definite inner product by means of a CPT conjugation operation.  ", "human_text": "  Recently, much research has been carried out on Hamiltonians that are not Hermitian but are symmetric under space-time reflection, that is, Hamiltonians that exhibit PT symmetry. Investigations of the Sturm-Liouville eigenvalue problem associated with such Hamiltonians have shown that in many cases the entire energy spectrum is real and positive and that the eigenfunctions form an orthogonal and complete basis. Furthermore, the quantum theories determined by such Hamiltonians have been shown to be consistent in the sense that the probabilities are positive and the dynamical trajectories are unitary. However, the geometrical structures that underlie quantum theories formulated in terms of such Hamiltonians have hitherto not been fully understood. This paper studies in detail the geometric properties of a Hilbert space endowed with a parity structure and analyses the characteristics of a PT-symmetric Hamiltonian and its eigenstates. A canonical relationship between a PT-symmetric operator and a Hermitian operator is established. It is shown that the quadratic form corresponding to the parity operator, in particular, gives rise to a natural partition of the Hilbert space into two halves corresponding to states having positive and negative PT norm. The indefiniteness of the norm can be circumvented by introducing a symmetry operator C that defines a positive definite inner product by means of a CPT conjugation operation. ", "machine_text": "This article analyzes the geometrical aspects of quantum mechanics when the Hamiltonian is not Hermitian, yet symmetric under space-time reflection, i.e. PT-symmetric. The spectrum of associated eigenvalues of the Sturm-Liouville problem have been shown to have only real and positive energies and the basis of these eigenfunctions form an orthogonal and full set. Consequently, the probability of these quantum theories are positive and the dynamical trajectories remain unitary. This paper studies the properties of a Hilbert space consisting of a parity structure and examines the features of the PT-symmetric Hamiltonian and its eigenstates. Results indicate a connection between the PT-symmetric operator and a Hermitian operator, and how the quadratic form of the parity operator divides the Hilbert space into two halves according to states having a positive or negative PT norm. This can be solved by using a symmetry operator C in order to introduce a positive definite inner product through a CPT conjugation operation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2959}
{"prompt": "Rephrase the abstract of an article with title 'Growth window and possible mechanism of millimeter-thick single-walled   carbon nanotube forests'.   Our group recently reproduced the water-assisted growth method, so-called \"super growth\", of millimeter-thick single-walled carbon nanotube (SWNT) forests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this current work, a parametric study was carried out on both reaction and catalyst conditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm) yielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3 support enhanced the activity of Fe, Co, and Ni catalysts. The growth window for the rapid SWNT growth was narrow, however. Optimum amount of added H2O increased the SWNT growth rate but further addition of H2O degraded both the SWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT growth, but again, further addition decreased both the SWNT growth rate and quality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly enhances the SWNT growth rate by supplying the carbon source to the catalyst nanoparticles. The origin of the narrow window for rapid SWNT growth will also be discussed.  ", "human_text": "  Our group recently reproduced the water-assisted growth method, so-called \"super growth\", of millimeter-thick single-walled carbon nanotube (SWNT) forests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this current work, a parametric study was carried out on both reaction and catalyst conditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm) yielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3 support enhanced the activity of Fe, Co, and Ni catalysts. The growth window for the rapid SWNT growth was narrow, however. Optimum amount of added H2O increased the SWNT growth rate but further addition of H2O degraded both the SWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT growth, but again, further addition decreased both the SWNT growth rate and quality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly enhances the SWNT growth rate by supplying the carbon source to the catalyst nanoparticles. The origin of the narrow window for rapid SWNT growth will also be discussed. ", "machine_text": " A recent study explored the optimal parameters for the successful growth of millimeter-thick single-walled carbon nanotube (SWNT) forests using C2H4/ H2/ H2O/ Ar reactant gas and a Fe/ Al2O3 catalyst. Results from this study determined that SWNTs grow best with a thin layer of Fe catalyst when the catalyst is supported on Al2O3, pointing to Al2O3 support as a means to boost the activity of Fe, Co, and Ni catalysts. However, the parameters to achieve a rapid growth rate of SWNTs were found to be narrow. Increasing the amount of added H2O can increase the SWNT growth rate, but its quality suffers when increased beyond optimal amounts. Similarly, H2 is essential for rapid growth, but its addition has the same negative effects as H2O once an optimal threshold is exceeded. Al2O3 was speculated to boost the SWNT growth rate by providing the carbon source for the catalyst nanoparticles. Additionally, the mechanisms responsible for the narrow growth window for SWNTs were addressed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1903}
{"prompt": "Rephrase the abstract of an article with title 'k-dependent SU(4) model of high-temperature superconductivity and its   coherent-state solutions'.   We extend the SU(4) model [1-5] for high-Tc superconductivity to an SU(4)k model that permits explicit momentum (k) dependence in predicted observables. We derive and solve gap equations that depend on k, temperature, and doping from the SU(4)k coherent states, and show that the new SU(4)k model reduces to the original SU(4) model for observables that do not depend explicitly on momentum. The results of the SU(4)k model are relevant for experiments such as ARPES that detect explicitly k-dependent properties. The present SU(4)k model describes quantitatively the pseudogap temperature scale and may explain why the ARPES-measured T* along the anti-nodal direction is larger than other measurements that do not resolve momentum. It also provides an immediate microscopic explanation for Fermi arcs observed in the pseudogap region. In addition, the model leads to a prediction that even in the underdoped regime, there exist doping-dependent windows around nodal points in the k-space, where antiferromagnetism may be completely suppressed for all doping fractions, permitting pure superconducting states to exist.  ", "human_text": "  We extend the SU(4) model [1-5] for high-Tc superconductivity to an SU(4)k model that permits explicit momentum (k) dependence in predicted observables. We derive and solve gap equations that depend on k, temperature, and doping from the SU(4)k coherent states, and show that the new SU(4)k model reduces to the original SU(4) model for observables that do not depend explicitly on momentum. The results of the SU(4)k model are relevant for experiments such as ARPES that detect explicitly k-dependent properties. The present SU(4)k model describes quantitatively the pseudogap temperature scale and may explain why the ARPES-measured T* along the anti-nodal direction is larger than other measurements that do not resolve momentum. It also provides an immediate microscopic explanation for Fermi arcs observed in the pseudogap region. In addition, the model leads to a prediction that even in the underdoped regime, there exist doping-dependent windows around nodal points in the k-space, where antiferromagnetism may be completely suppressed for all doping fractions, permitting pure superconducting states to exist. ", "machine_text": "This paper presents an extended SU(4) model for high-temperature superconductivity which considers the momentum (k)-dependence of the model's predicted observables. We solve for gap equations that depend on k, temperature, and doping using SU(4)k coherent states and show that the new model reduces to the original model for non-k-dependent observables. Our results have relevance for experiments such as ARPES that measure k-dependent properties. Furthermore, the model quantitatively describes the pseudogap temperature scale and might explain why the temperature T* of ARPES-measured values along the anti-nodal direction is higher than other non-momentum-resolving measurements. Additionally, the model proposes that in underdoped regions, there exist doping-related windows around nodal points in the k-space that might enable the complete suppression of antiferromagnetism, to form purely superconducting states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0818}
{"prompt": "Rephrase the abstract of an article with title 'The Detection and Characterization of cm Radio Continuum Emission from   the Low-mass Protostar L1014-IRS'.   Observations by the Cores to Disk Legacy Team with the Spitzer Space Telescope have identified a low luminosity, mid-infrared source within the dense core, Lynds 1014, which was previously thought to harbor no internal source. Followup near-infrared and submillimeter interferometric observations have confirmed the protostellar nature of this source by detecting scattered light from an outflow cavity and a weak molecular outflow. In this paper, we report the detection of cm continuum emission with the VLA. The emission is characterized by a quiescent, unresolved 90 uJy 6 cm source within 0.2\" of the Spitzer source. The spectral index of the quiescent component is $\\alpha = 0.37\\pm 0.34$ between 6 cm and 3.6 cm. A factor of two increase in 6 cm emission was detected during one epoch and circular polarization was marginally detected at the $5\\sigma$ level with Stokes {V/I} $= 48 \\pm 16$% . We have searched for 22 GHz H2O maser emission toward L1014-IRS, but no masers were detected during 7 epochs of observations between June 2004 and December 2006. L1014-IRS appears to be a low-mass, accreting protostar which exhibits cm emission from a thermal jet or a wind, with a variable non-thermal emission component. The quiescent cm radio emission is noticeably above the correlation of 3.6 cm and 6 cm luminosity versus bolometric luminosity, indicating more radio emission than expected. We characterize the cm continuum emission in terms of observations of other low-mass protostars, including updated correlations of centimeter continuum emission with bolometric luminosity and outflow force, and discuss the implications of recent larger distance estimates on the physical attributes of the protostar and dense molecular core.  ", "human_text": "  Observations by the Cores to Disk Legacy Team with the Spitzer Space Telescope have identified a low luminosity, mid-infrared source within the dense core, Lynds 1014, which was previously thought to harbor no internal source. Followup near-infrared and submillimeter interferometric observations have confirmed the protostellar nature of this source by detecting scattered light from an outflow cavity and a weak molecular outflow. In this paper, we report the detection of cm continuum emission with the VLA. The emission is characterized by a quiescent, unresolved 90 uJy 6 cm source within 0.2\" of the Spitzer source. The spectral index of the quiescent component is $\\alpha = 0.37\\pm 0.34$ between 6 cm and 3.6 cm. A factor of two increase in 6 cm emission was detected during one epoch and circular polarization was marginally detected at the $5\\sigma$ level with Stokes {V/I} $= 48 \\pm 16$% . We have searched for 22 GHz H2O maser emission toward L1014-IRS, but no masers were detected during 7 epochs of observations between June 2004 and December 2006. L1014-IRS appears to be a low-mass, accreting protostar which exhibits cm emission from a thermal jet or a wind, with a variable non-thermal emission component. The quiescent cm radio emission is noticeably above the correlation of 3.6 cm and 6 cm luminosity versus bolometric luminosity, indicating more radio emission than expected. We characterize the cm continuum emission in terms of observations of other low-mass protostars, including updated correlations of centimeter continuum emission with bolometric luminosity and outflow force, and discuss the implications of recent larger distance estimates on the physical attributes of the protostar and dense molecular core. ", "machine_text": "In this paper, we present the findings of an investigation using the VLA and Spitzer Space Telescope to characterize cm radio continuum emission from the low-luminosity, mid-infrared protostar located within the Lynds 1014 dense core. The emission is comprised of a quiescent, unresolved component with a spectral index of $\\alpha = 0.37\\pm 0.34$ between the 6 cm and 3.6 cm bands, and a component that has been found to increase in strength in the 6 cm band during one epoch of observation. Circular polarization was also detected at a 5$\\sigma$ level. Despite no 22 GHz H2O maser emission being detected, the cm radio emission from L1014-IRS exceeds expectations according to established 3.6 cm and 6 cm luminosity versus bolometric luminosity correlations. We compare the emission from L1014-IRS with other low-mass protostars, and discuss the implications of the updated distance measurements on the core and protostar.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1747}
{"prompt": "Rephrase the abstract of an article with title 'Monoid generalizations of the Richard Thompson groups'.   The groups G_{k,1} of Richard Thompson and Graham Higman can be generalized in a natural way to monoids, that we call M_{k,1}, and to inverse monoids, called Inv_{k,1}; this is done by simply generalizing bijections to partial functions or partial injective functions. The monoids M_{k,1} have connections with circuit complexity (studied in another paper). Here we prove that M_{k,1} and Inv_{k,1} are congruence-simple for all k. Their Green relations J and D are characterized: M_{k,1} and Inv_{k,1} are J-0-simple, and they have k-1 non-zero D-classes. They are submonoids of the multiplicative part of the Cuntz algebra O_k. They are finitely generated, and their word problem over any finite generating set is in P. Their word problem is coNP-complete over certain infinite generating sets.   Changes in this version: Section 4 has been thoroughly revised, and errors have been corrected; however, the main results of Section 4 do not change. Sections 1, 2, and 3 are unchanged, except for the proof of Theorem 2.3, which was incomplete; a complete proof was published in the Appendix of reference [6], and is also given here.  ", "human_text": "  The groups G_{k,1} of Richard Thompson and Graham Higman can be generalized in a natural way to monoids, that we call M_{k,1}, and to inverse monoids, called Inv_{k,1}; this is done by simply generalizing bijections to partial functions or partial injective functions. The monoids M_{k,1} have connections with circuit complexity (studied in another paper). Here we prove that M_{k,1} and Inv_{k,1} are congruence-simple for all k. Their Green relations J and D are characterized: M_{k,1} and Inv_{k,1} are J-0-simple, and they have k-1 non-zero D-classes. They are submonoids of the multiplicative part of the Cuntz algebra O_k. They are finitely generated, and their word problem over any finite generating set is in P. Their word problem is coNP-complete over certain infinite generating sets.   Changes in this version: Section 4 has been thoroughly revised, and errors have been corrected; however, the main results of Section 4 do not change. Sections 1, 2, and 3 are unchanged, except for the proof of Theorem 2.3, which was incomplete; a complete proof was published in the Appendix of reference [6], and is also given here. ", "machine_text": " This work investigates the natural generalization of the groups G_{k,1} of Richard Thompson and Graham Higman to monoids, called M_{k,1}, and to inverse monoids, called Inv_{k,1}. This research shows that these monoids and inverse monoids are both congruence-simple and J-0-simple when all k are considered. Furthermore, they possess k-1 nontrivial D-classes. Connections to the multiplicative part of the Cuntz algebra O_k, as well as finite and infinite generating sets, are explored. Results show that the word problem for M_{k,1} and Inv_{k,1} is decidable for any finite generating set, and for certain infinite sets is coNP-complete. Revised Section 4 of the paper is included, correcting errors, though the main results for this section remain unchanged, as does Sections 1, 2 and 3 with the exception of Theorem 2.3, which has been revised to the proof included in reference [6].", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0189}
{"prompt": "Rephrase the abstract of an article with title 'Ionized nebulae surrounding brightest cluster galaxies'.   We present IFU observations of six emission-line nebulae that surround the central galaxy of cool core clusters. Qualitatively similar nebulae are observed in cool core clusters even when the dynamics and possibly formation and excitation source are different. Evidence for a nearby secondary galaxy disturbing a nebula, as well as AGN and starburst driven outflows are presented as possible formation mechanisms. One nebula has a rotation velocity of the same amplitude as the underlying molecular reservoir, which implies that the excitation or formation of a nebula does not require any disturbance of the molecular reservoir within the central galaxy. Bulk flows and velocity shears of a few hundred km/s are seen across all nebulae. The majority lack any ordered rotation, their configurations are not stable so the nebulae must be constantly reshaping, dispersing and reforming. The dimmer nebulae are co-spatial with dust features whilst the more luminous are not. Significant variation in the ionization state of the gas is seen in all nebulae through the non-uniform [NII]/H_alpha ratio. There is no correlation between the line ratio and H_alpha surface brightness, but regions with excess blue or UV light have lower line ratios. This implies that UV from massive, young stars act in combination with an underlying heating source that produces the observed low-ionization spectra.  ", "human_text": "  We present IFU observations of six emission-line nebulae that surround the central galaxy of cool core clusters. Qualitatively similar nebulae are observed in cool core clusters even when the dynamics and possibly formation and excitation source are different. Evidence for a nearby secondary galaxy disturbing a nebula, as well as AGN and starburst driven outflows are presented as possible formation mechanisms. One nebula has a rotation velocity of the same amplitude as the underlying molecular reservoir, which implies that the excitation or formation of a nebula does not require any disturbance of the molecular reservoir within the central galaxy. Bulk flows and velocity shears of a few hundred km/s are seen across all nebulae. The majority lack any ordered rotation, their configurations are not stable so the nebulae must be constantly reshaping, dispersing and reforming. The dimmer nebulae are co-spatial with dust features whilst the more luminous are not. Significant variation in the ionization state of the gas is seen in all nebulae through the non-uniform [NII]/H_alpha ratio. There is no correlation between the line ratio and H_alpha surface brightness, but regions with excess blue or UV light have lower line ratios. This implies that UV from massive, young stars act in combination with an underlying heating source that produces the observed low-ionization spectra. ", "machine_text": " Our IFU observations of emission-line nebulae that encircle the central galaxy of cooler core clusters suggest that several different phenomena may be at work in their formation. Such nebulae can develop due to AGN and starburst-powered outflows, with the presence of a neighboring galaxy to provide disruption. We have also established that rotation of the same amplitude as the underlying molecular reservoir might cause the excitation or formation of one of the nebulae, implying lack of disturbance of the central galaxy. The nebulae also demonstrate bulk flows and velocity shears up to several hundred km/s, and are likely constantly being reshaped and reformed due to their unsteady configurational states. Moreover, our results suggest that the varying ionization states of gas in the nebulae, particularly their [NII]/H_alpha ratios, are likely caused by a combination of UV from massive, young stars, in conjunction with an underlying heating source.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0661}
{"prompt": "Rephrase the abstract of an article with title 'Dark energy constraints from cosmic shear power spectra: impact of   intrinsic alignments on photometric redshift requirements'.   Cosmic shear constrains cosmology by exploiting the apparent alignments of pairs of galaxies due to gravitational lensing by intervening mass clumps. However galaxies may become (intrinsically) aligned with each other, and with nearby mass clumps, during their formation. This effect needs to be disentangled from the cosmic shear signal to place constraints on cosmology. We use the linear intrinsic alignment model as a base and compare it to an alternative model and data. If intrinsic alignments are ignored then the dark energy equation of state is biased by ~50 per cent. We examine how the number of tomographic redshift bins affects uncertainties on cosmological parameters and find that when intrinsic alignments are included two or more times as many bins are required to obtain 80 per cent of the available information. We investigate how the degradation in the dark energy figure of merit depends on the photometric redshift scatter. Previous studies have shown that lensing does not place stringent requirements on the photometric redshift uncertainty, so long as the uncertainty is well known. However, if intrinsic alignments are included the requirements become a factor of three tighter. These results are quite insensitive to the fraction of catastrophic outliers, assuming that this fraction is well known. We show the effect of uncertainties in photometric redshift bias and scatter. Finally we quantify how priors on the intrinsic alignment model would improve dark energy constraints.  ", "human_text": "  Cosmic shear constrains cosmology by exploiting the apparent alignments of pairs of galaxies due to gravitational lensing by intervening mass clumps. However galaxies may become (intrinsically) aligned with each other, and with nearby mass clumps, during their formation. This effect needs to be disentangled from the cosmic shear signal to place constraints on cosmology. We use the linear intrinsic alignment model as a base and compare it to an alternative model and data. If intrinsic alignments are ignored then the dark energy equation of state is biased by ~50 per cent. We examine how the number of tomographic redshift bins affects uncertainties on cosmological parameters and find that when intrinsic alignments are included two or more times as many bins are required to obtain 80 per cent of the available information. We investigate how the degradation in the dark energy figure of merit depends on the photometric redshift scatter. Previous studies have shown that lensing does not place stringent requirements on the photometric redshift uncertainty, so long as the uncertainty is well known. However, if intrinsic alignments are included the requirements become a factor of three tighter. These results are quite insensitive to the fraction of catastrophic outliers, assuming that this fraction is well known. We show the effect of uncertainties in photometric redshift bias and scatter. Finally we quantify how priors on the intrinsic alignment model would improve dark energy constraints. ", "machine_text": " The gravitational lensing effect of intervening spots of mass can be discerned by observing the alignment of far-flung galaxies. However, this cosmic shear signal may be contaminated by the alignment of the galaxies themselves, which needs to be factored out in order to place certain constrictions on our cosmology. We discuss two models in this area and investigate the impact of intrinsic alignments on the number of necessary tomographic redshift bins and the robustness of dark energy constraints. With the inclusion of intrinsic alignments, dark energy biases can reach as high as 50 percent. Furthermore, we find that unless the photometric redshift uncertainty is increased by a factor of three, the dark energy figure of merit will decline. Lastly, we analyze how prior knowledge of the intrinsic alignment model may improve the accuracy of the final result.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0166}
{"prompt": "Rephrase the abstract of an article with title 'A Class of LDPC Erasure Distributions with Closed-Form Threshold   Expression'.   In this paper, a family of low-density parity-check (LDPC) degree distributions, whose decoding threshold on the binary erasure channel (BEC) admits a simple closed form, is presented. These degree distributions are a subset of the check regular distributions (i.e. all the check nodes have the same degree), and are referred to as $p$-positive distributions. It is given proof that the threshold for a $p$-positive distribution is simply expressed by $[\\lambda'(0)\\rho'(1)]^{-1}$. Besides this closed form threshold expression, the $p$-positive distributions exhibit three additional properties. First, for given code rate, check degree and maximum variable degree, they are in some cases characterized by a threshold which is extremely close to that of the best known check regular distributions, under the same set of constraints. Second, the threshold optimization problem within the $p$-positive class can be solved in some cases with analytic methods, without using any numerical optimization tool. Third, these distributions can achieve the BEC capacity. The last property is shown by proving that the well-known binomial degree distributions belong to the $p$-positive family.  ", "human_text": "  In this paper, a family of low-density parity-check (LDPC) degree distributions, whose decoding threshold on the binary erasure channel (BEC) admits a simple closed form, is presented. These degree distributions are a subset of the check regular distributions (i.e. all the check nodes have the same degree), and are referred to as $p$-positive distributions. It is given proof that the threshold for a $p$-positive distribution is simply expressed by $[\\lambda'(0)\\rho'(1)]^{-1}$. Besides this closed form threshold expression, the $p$-positive distributions exhibit three additional properties. First, for given code rate, check degree and maximum variable degree, they are in some cases characterized by a threshold which is extremely close to that of the best known check regular distributions, under the same set of constraints. Second, the threshold optimization problem within the $p$-positive class can be solved in some cases with analytic methods, without using any numerical optimization tool. Third, these distributions can achieve the BEC capacity. The last property is shown by proving that the well-known binomial degree distributions belong to the $p$-positive family. ", "machine_text": "This paper presents a particular class of low-density parity-check (LDPC) degree distributions, referred to as $p$-positive distributions, for which the decoding threshold on the binary erasure channel (BEC) admits a simple closed-form expression. It is demonstrated that $[\\lambda'(0)\\rho'(1)]^{-1}$ viz. the expression of the threshold for a $p$-positive distribution. The $p$-positive distributions also possess a number of desirable properties i.e. a threshold close to best known check regular distributions in certain cases, optimization of threshold within the class using analytic methods, and the capacity-achievability property, which is established by including the well-known binomial degree distributions in the $p$-positive family.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1612}
{"prompt": "Rephrase the abstract of an article with title 'Scaling Laws of Cognitive Networks'.   We consider a cognitive network consisting of n random pairs of cognitive transmitters and receivers communicating simultaneously in the presence of multiple primary users. Of interest is how the maximum throughput achieved by the cognitive users scales with n. Furthermore, how far these users must be from a primary user to guarantee a given primary outage. Two scenarios are considered for the network scaling law: (i) when each cognitive transmitter uses constant power to communicate with a cognitive receiver at a bounded distance away, and (ii) when each cognitive transmitter scales its power according to the distance to a considered primary user, allowing the cognitive transmitter-receiver distances to grow. Using single-hop transmission, suitable for cognitive devices of opportunistic nature, we show that, in both scenarios, with path loss larger than 2, the cognitive network throughput scales linearly with the number of cognitive users. We then explore the radius of a primary exclusive region void of cognitive transmitters. We obtain bounds on this radius for a given primary outage constraint. These bounds can help in the design of a primary network with exclusive regions, outside of which cognitive users may transmit freely. Our results show that opportunistic secondary spectrum access using single-hop transmission is promising.  ", "human_text": "  We consider a cognitive network consisting of n random pairs of cognitive transmitters and receivers communicating simultaneously in the presence of multiple primary users. Of interest is how the maximum throughput achieved by the cognitive users scales with n. Furthermore, how far these users must be from a primary user to guarantee a given primary outage. Two scenarios are considered for the network scaling law: (i) when each cognitive transmitter uses constant power to communicate with a cognitive receiver at a bounded distance away, and (ii) when each cognitive transmitter scales its power according to the distance to a considered primary user, allowing the cognitive transmitter-receiver distances to grow. Using single-hop transmission, suitable for cognitive devices of opportunistic nature, we show that, in both scenarios, with path loss larger than 2, the cognitive network throughput scales linearly with the number of cognitive users. We then explore the radius of a primary exclusive region void of cognitive transmitters. We obtain bounds on this radius for a given primary outage constraint. These bounds can help in the design of a primary network with exclusive regions, outside of which cognitive users may transmit freely. Our results show that opportunistic secondary spectrum access using single-hop transmission is promising. ", "machine_text": " In this paper, we investigate the scaling laws of a cognitive network with n simultaneous pairs of cognitive transmitters and receivers in the presence of multiple primary users. Specifically, we consider how the network throughput, as well as the radius of a primary exclusive region outside of which cognitive users can avoid causing interference, vary with the number of cognitive users. We analyze two scenarios, with either a static or a scaled power, and show that, with a path-loss larger than 2, the throughput scales linearly and can be guaranteed with a minimum distance to primary users at a given outage constraint. The results suggest that single-hop transmission can be used to provide an efficient and feasible means of secondary spectrum access.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2353}
{"prompt": "Rephrase the abstract of an article with title 'Algebraic charge liquids'.   High temperature superconductivity emerges in the cuprate compounds upon changing the electron density of an insulator in which the electron spins are antiferromagnetically ordered. A key characteristic of the superconductor is that electrons can be extracted from them at zero energy only if their momenta take one of four specific values (the `nodal points'). A central enigma has been the evolution of the zero energy electrons in the metallic state between the antiferromagnet and the superconductor, and recent experiments yield apparently contradictory results. The oscillation of the resistance in this metal as a function of magnetic field indicate that the zero energy electrons carry momenta which lie on elliptical `Fermi pockets', while ejection of electrons by high intensity light indicates that the zero energy electrons have momenta only along arc-like regions. We present a theory of new states of matter, which we call `algebraic charge liquids', which arise naturally between the antiferromagnet and the superconductor, and reconcile these observations. Our theory also explains a puzzling dependence of the density of superconducting electrons on the total electron density, and makes a number of unique predictions for future experiments.  ", "human_text": "  High temperature superconductivity emerges in the cuprate compounds upon changing the electron density of an insulator in which the electron spins are antiferromagnetically ordered. A key characteristic of the superconductor is that electrons can be extracted from them at zero energy only if their momenta take one of four specific values (the `nodal points'). A central enigma has been the evolution of the zero energy electrons in the metallic state between the antiferromagnet and the superconductor, and recent experiments yield apparently contradictory results. The oscillation of the resistance in this metal as a function of magnetic field indicate that the zero energy electrons carry momenta which lie on elliptical `Fermi pockets', while ejection of electrons by high intensity light indicates that the zero energy electrons have momenta only along arc-like regions. We present a theory of new states of matter, which we call `algebraic charge liquids', which arise naturally between the antiferromagnet and the superconductor, and reconcile these observations. Our theory also explains a puzzling dependence of the density of superconducting electrons on the total electron density, and makes a number of unique predictions for future experiments. ", "machine_text": "Recent experiments on the high temperature cuprate superconductors have uncovered apparently contradictory results regarding the charge and momentum of the zero energy electrons in the metallic state between the antiferromagnet and the superconductor. This paper introduces a theory of novel states of matter, called 'algebraic charge liquids', which explain these discrepancies and explore the dependence of the density of the superconducting electrons on the total electron density. We identify a number of unique predictions for further experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2187}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical models and the phase ordering kinetics of the s=1 spinor   condensate'.   The $s=1$ spinor Bose condensate at zero temperature supports ferromagnetic and polar phases that combine magnetic and superfluid ordering. We investigate the formation of magnetic domains at finite temperature and magnetic field in two dimensions in an optical trap. We study the general ground state phase diagram of a spin-1 system and focus on a phase that has a magnetic Ising order parameter and numerically determine the nature of the finite temperature superfluid and magnetic phase transitions. We then study three different dynamical models: model A, which has no conserved quantities, model F, which has a conserved second sound mode and the Gross-Pitaevskii (GP) equation which has a conserved density and magnetization. We find the dynamic critical exponent to be the same for models A and F ($z=2$) but different for GP ($z \\approx 3$). Externally imposed magnetization conservation in models A and F yields the value $z \\approx 3$, which demonstrates that the only conserved density relevant to domain formation is the magnetization density.  ", "human_text": "  The $s=1$ spinor Bose condensate at zero temperature supports ferromagnetic and polar phases that combine magnetic and superfluid ordering. We investigate the formation of magnetic domains at finite temperature and magnetic field in two dimensions in an optical trap. We study the general ground state phase diagram of a spin-1 system and focus on a phase that has a magnetic Ising order parameter and numerically determine the nature of the finite temperature superfluid and magnetic phase transitions. We then study three different dynamical models: model A, which has no conserved quantities, model F, which has a conserved second sound mode and the Gross-Pitaevskii (GP) equation which has a conserved density and magnetization. We find the dynamic critical exponent to be the same for models A and F ($z=2$) but different for GP ($z \\approx 3$). Externally imposed magnetization conservation in models A and F yields the value $z \\approx 3$, which demonstrates that the only conserved density relevant to domain formation is the magnetization density. ", "machine_text": " This article explores the process of domain formation at finite temperature and magnetic field in two-dimensional optical traps of $s=1$ spinor Bose condensates. Through researching the fundamental ground state phase diagrams and modeling through three different approaches, we investigate the role of different conserved quantities. We find that the dynamic critical exponent for model A and F is equal to $z=2$, but differs for GP with $z \\approx 3$. An inclusion of externally imposed magnetization conservation for models A and F yields the same value of $z \\approx 3$, suggesting that magnetization density is the only conserved quantity relevant to domain formation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.344}
{"prompt": "Rephrase the abstract of an article with title 'Dark Matter in Gauge Mediation from Emergent Supersymmetry'.   We investigated the viability of neutralino dark matter in the gauge mediation from emergent supersymmetry proposal. In this proposal, supersymmetry is broken at Planck scale and consequently, the gravitino is superheavy and completely decouples from the low energy theory. Squarks and sleptons obtain their soft masses dominantly through gauge mediation with other mechanisms highly suppressed. The lightest supersymmetric partner, in contrast to traditional gauge mediation, is a neutralino which is also a dark matter candidate. By explicit calculation of the low energy spectra, the parameter space was constrained using the WMAP observed relic density of dark matter, LEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic B-meson decays. We found that the model has intriguing hybrid features such as a nearly gauge-mediated spectrum (the exception being the superheavy gravitino) but with a dominant mSUGRA-like bino-stau coannihilation channel and at large $\\tan \\beta$, A-resonance-like annihilation.  ", "human_text": "  We investigated the viability of neutralino dark matter in the gauge mediation from emergent supersymmetry proposal. In this proposal, supersymmetry is broken at Planck scale and consequently, the gravitino is superheavy and completely decouples from the low energy theory. Squarks and sleptons obtain their soft masses dominantly through gauge mediation with other mechanisms highly suppressed. The lightest supersymmetric partner, in contrast to traditional gauge mediation, is a neutralino which is also a dark matter candidate. By explicit calculation of the low energy spectra, the parameter space was constrained using the WMAP observed relic density of dark matter, LEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic B-meson decays. We found that the model has intriguing hybrid features such as a nearly gauge-mediated spectrum (the exception being the superheavy gravitino) but with a dominant mSUGRA-like bino-stau coannihilation channel and at large $\\tan \\beta$, A-resonance-like annihilation. ", "machine_text": " In this article, we explored the feasibility of a dark matter candidate, the neutralino, through the gauge mediation derived from the emergence of supersymmetry. This approach dictated that the gravitino was incredibly massive and therefore decoupled the low energy theory. The soft masses are primarily derived from gauge mediation, and not other means, creating an interesting hybrid of features including a nearly gauge-mediated spectrum with a large mSUGRA-like bino-stau coannihilation channel, and also with a possible A-resonance-like annihilation near large $\\tan \\beta$. We constrained our parameter space using WMAP dark matter relic density data, LEP2 Higgs mass bound, and a number of collider and exotic B-meson decay bounds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2258}
{"prompt": "Rephrase the abstract of an article with title 'Novel technique for monitoring the performance of the LAT instrument on   board the GLAST satellite'.   The Gamma-ray Large Area Space Telescope (GLAST) is an observatory designed to perform gamma-ray astronomy in the energy range 20 MeV to 300 GeV, with supporting measurements for gamma-ray bursts from 10 keV to 25 MeV. GLAST will be launched at the end of 2007, opening a new and important window on a wide variety of high energy astrophysical phenomena . The main instrument of GLAST is the Large Area Telescope (LAT), which provides break-through high-energy measurements using techniques typically used in particle detectors for collider experiments. The LAT consists of 16 identical towers in a four-by-four grid, each one containing a pair conversion tracker and a hodoscopic crystal calorimeter, all covered by a segmented plastic scintillator anti-coincidence shield. The scientific return of the instrument depends very much on how accurately we know its performance, and how well we can monitor it and correct potential problems promptly. We report on a novel technique that we are developing to help in the characterization and monitoring of LAT by using the power of classification trees to pinpoint in a short time potential problems in the recorded data. The same technique could also be used to evaluate the effect on the overall LAT performance produced by potential instrumental problems.  ", "human_text": "  The Gamma-ray Large Area Space Telescope (GLAST) is an observatory designed to perform gamma-ray astronomy in the energy range 20 MeV to 300 GeV, with supporting measurements for gamma-ray bursts from 10 keV to 25 MeV. GLAST will be launched at the end of 2007, opening a new and important window on a wide variety of high energy astrophysical phenomena . The main instrument of GLAST is the Large Area Telescope (LAT), which provides break-through high-energy measurements using techniques typically used in particle detectors for collider experiments. The LAT consists of 16 identical towers in a four-by-four grid, each one containing a pair conversion tracker and a hodoscopic crystal calorimeter, all covered by a segmented plastic scintillator anti-coincidence shield. The scientific return of the instrument depends very much on how accurately we know its performance, and how well we can monitor it and correct potential problems promptly. We report on a novel technique that we are developing to help in the characterization and monitoring of LAT by using the power of classification trees to pinpoint in a short time potential problems in the recorded data. The same technique could also be used to evaluate the effect on the overall LAT performance produced by potential instrumental problems. ", "machine_text": "This paper describes a new technique for monitoring the performance of the Large Area Telescope (LAT) instrument on board the Gamma-ray Large Area Space Telescope (GLAST) satellite. The LAT instrument consists of 16 towers in a four-by-four grid containing a pair conversion tracker, a hodoscopic crystal calorimeter, and a segmented plastic scintillator anti-coincidence shield. In order to ensure that the LAT performs optimally and that any potential problems with the instrument can be promptly located and addressed, this paper outlines a method using the power of classification trees to accurately identify any potential issues with the recorded data. The technique described in this article also provides insight into the effect of potential instrumental problems on the overall LAT performance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1544}
{"prompt": "Rephrase the abstract of an article with title 'Synergistic Effects of MoDTC and ZDTP on Frictional Behaviour of   Tribofilms at the Nanometer Scale'.   The layered structure and the rheological properties of anti-wear films, generated in a rolling/sliding contact from lubricants containing zinc dialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC) additives, have been studied by dynamic nanoindentation experiments coupled with a simple modelling of the stiffness measurements. Local nano-friction experiments were conducted with the same device in order to determine the evolution of the friction coefficient as a function of the applied pressure for the different lubricant formulations. For the MoDTC film, the applied pressure in the friction test remains low (<0.5 GPa) and the apparent friction coefficient is high ($\\mu$ > 0.4). For the tribofilms containing MoDTC together with ZDTP, which permits the applied pressure to increase up to a few GPa through some accommodation process, a very low friction domain appears (0.01 < $\\mu$ < 0.05), located a few nanometers below the surface of the tribofilm. This low friction coefficient is attributed to the presence of MoS2 planes sliding over each other in a favourable configuration obtained when the pressure is sufficiently high, which is made possible by the presence of ZDTP.  ", "human_text": "  The layered structure and the rheological properties of anti-wear films, generated in a rolling/sliding contact from lubricants containing zinc dialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC) additives, have been studied by dynamic nanoindentation experiments coupled with a simple modelling of the stiffness measurements. Local nano-friction experiments were conducted with the same device in order to determine the evolution of the friction coefficient as a function of the applied pressure for the different lubricant formulations. For the MoDTC film, the applied pressure in the friction test remains low (<0.5 GPa) and the apparent friction coefficient is high ($\\mu$ > 0.4). For the tribofilms containing MoDTC together with ZDTP, which permits the applied pressure to increase up to a few GPa through some accommodation process, a very low friction domain appears (0.01 < $\\mu$ < 0.05), located a few nanometers below the surface of the tribofilm. This low friction coefficient is attributed to the presence of MoS2 planes sliding over each other in a favourable configuration obtained when the pressure is sufficiently high, which is made possible by the presence of ZDTP. ", "machine_text": " The interactions between the components in lubricants containing zinc dialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC) that create anti-wear films were evaluated using dynamic nanoindentation and friction tests in the nanometer scale. Results showed that a low friction coefficient (0.01 < $\\mu$ < 0.05) is obtained when the two additives are present. This is due to the favourable configuration of MoS2 planes sliding over each other when the pressure is sufficiently high, which is enabled by the presence of ZDTP. Through nanoindentation experiments and a simple stiffness measurement model, the layered structure and rheological properties can also be observed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0338}
{"prompt": "Rephrase the abstract of an article with title 'On the geometry of generalized Gaussian distributions'.   In this paper we consider the space of those probability distributions which maximize the $q$-R\\'enyi entropy. These distributions have the same parameter space for every $q$, and in the $q=1$ case these are the normal distributions. Some methods to endow this parameter space with Riemannian metric is presented: the second derivative of the $q$-R\\'enyi entropy, Tsallis-entropy and the relative entropy give rise to a Riemannian metric, the Fisher-information matrix is a natural Riemannian metric, and there are some geometrically motivated metrics which were studied by Siegel, Calvo and Oller, Lovri\\'c, Min-Oo and Ruh. These metrics are different therefore our differential geometrical calculations based on a unified metric, which covers all the above mentioned metrics among others. We also compute the geometrical properties of this metric, the equation of the geodesic line with some special solutions, the Riemann and Ricci curvature tensors and scalar curvature. Using the correspondence between the volume of the geodesic ball and the scalar curvature we show how the parameter $q$ modulates the statistical distinguishability of close points. We show that some frequently used metric in quantum information geometry can be easily recovered from classical metrics.  ", "human_text": "  In this paper we consider the space of those probability distributions which maximize the $q$-R\\'enyi entropy. These distributions have the same parameter space for every $q$, and in the $q=1$ case these are the normal distributions. Some methods to endow this parameter space with Riemannian metric is presented: the second derivative of the $q$-R\\'enyi entropy, Tsallis-entropy and the relative entropy give rise to a Riemannian metric, the Fisher-information matrix is a natural Riemannian metric, and there are some geometrically motivated metrics which were studied by Siegel, Calvo and Oller, Lovri\\'c, Min-Oo and Ruh. These metrics are different therefore our differential geometrical calculations based on a unified metric, which covers all the above mentioned metrics among others. We also compute the geometrical properties of this metric, the equation of the geodesic line with some special solutions, the Riemann and Ricci curvature tensors and scalar curvature. Using the correspondence between the volume of the geodesic ball and the scalar curvature we show how the parameter $q$ modulates the statistical distinguishability of close points. We show that some frequently used metric in quantum information geometry can be easily recovered from classical metrics. ", "machine_text": "This paper examines the geometrical properties of probability distributions that maximize the $q$-R\\'enyi entropy. Such distributions contain the normal distributions as a special case ($q=1$). We provide methods to equip the parameter space of these distributions with a Riemannian metric, which includes the second derivative of the $q$-R\\'enyi entropy, Tsallis-entropy, the relative entropy, the Fisher-information matrix, and geometrically motivated metrics studied by Siegel, Calvo and Oller, Lovri\\'c, Min-Oo, and Ruh. We calculate the geometrical features of this unified metric, including the equation of its geodesic lines and the Riemann and Ricci curvature tensors and scalar curvature. Then we demonstrate how these calculations can be used to show how the parameter $q$ affects the statistical distinguishability of nearby points. Furthermore, we reveal the relationship between the classical metrics and the metrics used in the field of quantum information geometry.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0606}
{"prompt": "Rephrase the abstract of an article with title 'Relaxation dynamics in fluids of platelike colloidal particles'.   The relaxation dynamics of a model fluid of platelike colloidal particles is investigated by means of a phenomenological dynamic density functional theory. The model fluid approximates the particles within the Zwanzig model of restricted orientations. The driving force for time-dependence is expressed completely by gradients of the local chemical potential which in turn is derived from a density functional -- hydrodynamic interactions are not taken into account. These approximations are expected to lead to qualitatively reliable results for low densities as those within the isotropic-nematic two-phase region. The formalism is applied to model an initially spatially homogeneous stable or metastable isotropic fluid which is perturbed by switching a two-dimensional array of Gaussian laser beams. Switching on the laser beams leads to an accumulation of colloidal particles in the beam centers. If the initial chemical potential and the laser power are large enough a preferred orientation of particles occurs breaking the symmetry of the laser potential. After switching off the laser beams again the system can follow different relaxation paths: It either relaxes back to the homogeneous isotropic state or it forms an approximately elliptical high-density core which is elongated perpendicular to the dominating orientation in order to minimize the surface free energy. For large supersaturations of the initial isotropic fluid the high-density cores of neighboring laser beams of the two-dimensional array merge into complex superstructures.  ", "human_text": "  The relaxation dynamics of a model fluid of platelike colloidal particles is investigated by means of a phenomenological dynamic density functional theory. The model fluid approximates the particles within the Zwanzig model of restricted orientations. The driving force for time-dependence is expressed completely by gradients of the local chemical potential which in turn is derived from a density functional -- hydrodynamic interactions are not taken into account. These approximations are expected to lead to qualitatively reliable results for low densities as those within the isotropic-nematic two-phase region. The formalism is applied to model an initially spatially homogeneous stable or metastable isotropic fluid which is perturbed by switching a two-dimensional array of Gaussian laser beams. Switching on the laser beams leads to an accumulation of colloidal particles in the beam centers. If the initial chemical potential and the laser power are large enough a preferred orientation of particles occurs breaking the symmetry of the laser potential. After switching off the laser beams again the system can follow different relaxation paths: It either relaxes back to the homogeneous isotropic state or it forms an approximately elliptical high-density core which is elongated perpendicular to the dominating orientation in order to minimize the surface free energy. For large supersaturations of the initial isotropic fluid the high-density cores of neighboring laser beams of the two-dimensional array merge into complex superstructures. ", "machine_text": " This paper explores the fluid dynamics of platelike colloidal particles using a phenomonological dynamic density functional theory. In this model, the driving force behind the time-dependent behavior of the system is based on local chemical potential gradients, while hydrodynamic effects are excluded. Using this approach, this paper looks at how a homogenous and stable isotropic fluid of colloidal particles interacts with a two-dimensional array of beam lasers. The main effects of the laser beams are that the colloidal particles will accumulate in the center of the beam, and that a preferred orientation in the particles breaks the symmetry of the beam. After the laser is switched off, the particles will either relax and return to the initial homogenous state, or form a high-density core that is elongated perpendicular to the dominant orientation to minimize surface free energy. Under certain conditions, high-density cores of neighboring lasers can merge, forming complex superstructures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0104}
{"prompt": "Rephrase the abstract of an article with title 'Network statistics on early English Syntax: Structural criteria'.   This paper includes a reflection on the role of networks in the study of English language acquisition, as well as a collection of practical criteria to annotate free-speech corpora from children utterances. At the theoretical level, the main claim of this paper is that syntactic networks should be interpreted as the outcome of the use of the syntactic machinery. Thus, the intrinsic features of such machinery are not accessible directly from (known) network properties. Rather, what one can see are the global patterns of its use and, thus, a global view of the power and organization of the underlying grammar. Taking a look into more practical issues, the paper examines how to build a net from the projection of syntactic relations. Recall that, as opposed to adult grammars, early-child language has not a well-defined concept of structure. To overcome such difficulty, we develop a set of systematic criteria assuming constituency hierarchy and a grammar based on lexico-thematic relations. At the end, what we obtain is a well defined corpora annotation that enables us i) to perform statistics on the size of structures and ii) to build a network from syntactic relations over which we can perform the standard measures of complexity. We also provide a detailed example.  ", "human_text": "  This paper includes a reflection on the role of networks in the study of English language acquisition, as well as a collection of practical criteria to annotate free-speech corpora from children utterances. At the theoretical level, the main claim of this paper is that syntactic networks should be interpreted as the outcome of the use of the syntactic machinery. Thus, the intrinsic features of such machinery are not accessible directly from (known) network properties. Rather, what one can see are the global patterns of its use and, thus, a global view of the power and organization of the underlying grammar. Taking a look into more practical issues, the paper examines how to build a net from the projection of syntactic relations. Recall that, as opposed to adult grammars, early-child language has not a well-defined concept of structure. To overcome such difficulty, we develop a set of systematic criteria assuming constituency hierarchy and a grammar based on lexico-thematic relations. At the end, what we obtain is a well defined corpora annotation that enables us i) to perform statistics on the size of structures and ii) to build a network from syntactic relations over which we can perform the standard measures of complexity. We also provide a detailed example. ", "machine_text": " This article explores the potential utility of network statistics in exploring early English syntax. With an emphasis on structural criteria, the paper assesses the possibility of using networks to analyze the language production of children. It proposes that networks can capture global patterns of grammatical usage as opposed to intrinsic features of grammar, allowing for the creation and analysis of a corpus of annotated texts. Guidelines are provided for building networks using projections of syntactic relations in early language, along with a methodology for completing the annotation process in a way that equips statisticians to do research on the size of structures, as well as assess the overall complexity presented. An example is given to illustrate the steps taken.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3708}
{"prompt": "Rephrase the abstract of an article with title 'One- and two-component bottle-brush polymers: simulations compared to   theoretical predictions'.   Scaling predictions and results from self-consistent field calculations for bottle-brush polymers with a rigid backbone and flexible side chains under good solvent conditions are summarized and their validity and applicability is assessed by a comparison with Monte Carlo simulations of a simple lattice model. It is shown that under typical conditions, as they are also present in experiments, only a rather weak stretching of the side chains is realized, and then the scaling predictions based on the extension of the Daoud-Cotton blob picture are not applicable.   Also two-component bottle brush polymers are considered, where two types (A,B) of side chains are grafted, assuming that monomers of different kind repel each other. In this case, variable solvent quality is allowed for, such that for poor solvent conditions rather dense cylinder-like structures result. Theories predict ``Janus Cylinder''-type phase separation along the backbone in this case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth method (PERM) then are restricted to rather short side chain length. Nevertheless, evidence is obtained that the phase separation between an A-rich part of the cylindrical molecule and a B-rich part can only occur locally. The correlation length of this microphase separation can be controlled by the solvent quality. This lack of a phase transition is interpreted by an analogy with models for ferromagnets in one space dimension.  ", "human_text": "  Scaling predictions and results from self-consistent field calculations for bottle-brush polymers with a rigid backbone and flexible side chains under good solvent conditions are summarized and their validity and applicability is assessed by a comparison with Monte Carlo simulations of a simple lattice model. It is shown that under typical conditions, as they are also present in experiments, only a rather weak stretching of the side chains is realized, and then the scaling predictions based on the extension of the Daoud-Cotton blob picture are not applicable.   Also two-component bottle brush polymers are considered, where two types (A,B) of side chains are grafted, assuming that monomers of different kind repel each other. In this case, variable solvent quality is allowed for, such that for poor solvent conditions rather dense cylinder-like structures result. Theories predict ``Janus Cylinder''-type phase separation along the backbone in this case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth method (PERM) then are restricted to rather short side chain length. Nevertheless, evidence is obtained that the phase separation between an A-rich part of the cylindrical molecule and a B-rich part can only occur locally. The correlation length of this microphase separation can be controlled by the solvent quality. This lack of a phase transition is interpreted by an analogy with models for ferromagnets in one space dimension. ", "machine_text": " This study looks at the theoretical predictions and scaling predictions regarding bottle-brush polymers with a rigid backbone and flexible side chains in good solvent conditions. Self-consistent field calculations and Monte Carlo simulations of a simple lattice model are used in order to assess the validity and applicability of these predictions. Results show that the predicted stretching of side chains is relatively low and they may not accurately apply in typical experimental conditions. Two-component bottle brush polymers with two types (A,B) of side chains that repel each other are also analyzed. Poor solvent conditions are found to create cylinder-like structures and theories suggest Janus Cylinder-type phase separation in this case. Monte Carlo simulations using the pruned-enriched Rosenbluth method (PERM) suggest the lack of phase transition with correlation length that can be controlled by solvent quality. This is explained through an analogy of one-dimensional ferromagnetic models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1124}
{"prompt": "Rephrase the abstract of an article with title 'The Leo Elliptical NGC 3379: A Metal-Poor Halo Emerges'.   We have used the ACS camera on HST to obtain (V,I) photometry for 5300 red-giant stars in the halo of the dominant Leo-group member NGC 3379, a galaxy usually regarded as a classic normal giant elliptical. We use this sample of stars to derive the metallicity distribution function (MDF) for its outer-halo field stars 33 kpc from the galaxy center. The MDF is distinctly unlike all the other E galaxies for which we have similar data (including the Local Group dwarf ellipticals, the intermediate-luminosity NGC 3377, and the giant NGC 5128). First, the MDF for the NGC 3379 outer halo is broad and flat, with many stars at every interval in [m/H]. Second, we see a metallicity gradient across our ACS field such that in its outermost region the blue, low-metallicity stars ([m/H] < -0.7) are beginning to dominate and the higher-metallicity stars are rapidly diminishing. Our target field is centered at a projected distance about equal to 12 R_e, twice as far out in units of effective radius as in any of the other galaxies that we have surveyed. If NGC 3379 is indeed representative of large E/S0 galaxies, we predict that such galaxies in general will reveal diffuse low-metallicity subpopulations, but that photometry at radii r ~ 10 - 15 R_e will be necessary to see the faint low-metallicity component clearly.  ", "human_text": "  We have used the ACS camera on HST to obtain (V,I) photometry for 5300 red-giant stars in the halo of the dominant Leo-group member NGC 3379, a galaxy usually regarded as a classic normal giant elliptical. We use this sample of stars to derive the metallicity distribution function (MDF) for its outer-halo field stars 33 kpc from the galaxy center. The MDF is distinctly unlike all the other E galaxies for which we have similar data (including the Local Group dwarf ellipticals, the intermediate-luminosity NGC 3377, and the giant NGC 5128). First, the MDF for the NGC 3379 outer halo is broad and flat, with many stars at every interval in [m/H]. Second, we see a metallicity gradient across our ACS field such that in its outermost region the blue, low-metallicity stars ([m/H] < -0.7) are beginning to dominate and the higher-metallicity stars are rapidly diminishing. Our target field is centered at a projected distance about equal to 12 R_e, twice as far out in units of effective radius as in any of the other galaxies that we have surveyed. If NGC 3379 is indeed representative of large E/S0 galaxies, we predict that such galaxies in general will reveal diffuse low-metallicity subpopulations, but that photometry at radii r ~ 10 - 15 R_e will be necessary to see the faint low-metallicity component clearly. ", "machine_text": " Using the ACS camera on the Hubble Space Telescope, photometry of over 5,000 red-giant stars in the outer halo of NGC 3379, a classic normal giant elliptical and member of the Leo-group, was obtained. After compiling the metallicity distribution function (MDF) for the field stars located 33kpc from the galaxy center, distinctive properties of NGC 3379's outer halo emerged. The MDF was broad and flat, with metal-poor stars dominating in the outermost region. With our ACS field centered at a projected distance equivalent to 12 effective radii, we believe that giant E/S0 galaxies in general will have low-metallicity subpopulations, but that in order to observe them more distant photometry will be required.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1995}
{"prompt": "Rephrase the abstract of an article with title 'Search for pulsation among suspected A-type binaries and the new   multiperiodic Delta Scuti star HD217860'.   We have explored a sample of suspected A-type binaries in a systematic way, both spectroscopically and photometrically. Due to their location in the H-R diagram, indications of pulsation and/or chemical peculiarities among these suspected binary (or multiple) systems may be found. High-resolution spectroscopy obtained with the ELODIE and MUSICOS spectrographs was used in combination with a few nights of differential CCD photometry in order to search for pulsation(s). Of the 32 investigated targets, eight are spectroscopic binaries, one of which is a close binary also showing eclipses, and three have been identified as Delta Scuti pulsators with rapid line-profile variations. Among the latter stars, HD 217860 reveals interesting multiperiodic photometric and spectroscopic variations, with up to eight frequencies common to two large photometric data sets. We suggest that at least one radial overtone mode is excited among the two most dominant frequencies. We furthermore found evidence for a strong modulation of the amplitude(s) and/or the (radial) frequency content of this intriguing Delta Scuti star.  ", "human_text": "  We have explored a sample of suspected A-type binaries in a systematic way, both spectroscopically and photometrically. Due to their location in the H-R diagram, indications of pulsation and/or chemical peculiarities among these suspected binary (or multiple) systems may be found. High-resolution spectroscopy obtained with the ELODIE and MUSICOS spectrographs was used in combination with a few nights of differential CCD photometry in order to search for pulsation(s). Of the 32 investigated targets, eight are spectroscopic binaries, one of which is a close binary also showing eclipses, and three have been identified as Delta Scuti pulsators with rapid line-profile variations. Among the latter stars, HD 217860 reveals interesting multiperiodic photometric and spectroscopic variations, with up to eight frequencies common to two large photometric data sets. We suggest that at least one radial overtone mode is excited among the two most dominant frequencies. We furthermore found evidence for a strong modulation of the amplitude(s) and/or the (radial) frequency content of this intriguing Delta Scuti star. ", "machine_text": " This study conducted an extensive investigation of suspected A-type binary systems, using high-resolution spectroscopy from ELODIE and MUSICOS and CCD photometry, to search for pulsations. Out of the 32 objects surveyed, 8 were spectroscopic binaries, one of which is a close binary exhibiting eclipses, and 3 were classified as Delta Scuti pulsators. One star in particular, HD 217860, was found to contain multiple periodic photometric and spectroscopic variations, with up to eight frequencies present in two large photometric datasets. This Delta Scuti star also showed signs of amplitude and/or frequency modulation. It is suspected that radial overtone modes are exciting the two strongest frequencies detected.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4587}
{"prompt": "Rephrase the abstract of an article with title 'And in the Darkness Bind Them: Equatorial Rings, B[e] Supergiants, and   the Waists of Bipolar Nebulae'.   We report the discovery of two new circumstellar ring nebulae in the western Carina Nebula. The brighter object, SBW1, resembles a lidless staring eye and encircles a B1.5 Iab supergiant. Its size is identical to the inner ring around SN1987A, but SBW1's low N abundance indicates that the star didn't pass through a RSG phase. The fainter object, SBW2, is a more distorted ring, is N-rich, and has a central star that seems to be invisible. We discuss these two new nebulae in context with rings around SN1987A, Sher25, HD168625, RY Scuti, WeBo1, SuWt2, and others. The ring bearers fall into two groups: Five rings surround hot supergiants, and all except for the one known binary are carbon copies of the ring around SN1987A. We propose a link between these rings and B[e] supergiants, where the rings derive from the same material in an earlier B[e] phase. The remaining four rings surround evolved intermediate-mass stars; all members of this ring fellowship are close binaries, hinting that binary interactions govern the forging of such rings. We estimate that there may be several thousand more dark rings in the Galaxy, but we are scarcely aware of their existence due to selection effects. The lower-mass objects might be the equatorial density enhancements often invoked to bind the waists of bipolar PNe.  ", "human_text": "  We report the discovery of two new circumstellar ring nebulae in the western Carina Nebula. The brighter object, SBW1, resembles a lidless staring eye and encircles a B1.5 Iab supergiant. Its size is identical to the inner ring around SN1987A, but SBW1's low N abundance indicates that the star didn't pass through a RSG phase. The fainter object, SBW2, is a more distorted ring, is N-rich, and has a central star that seems to be invisible. We discuss these two new nebulae in context with rings around SN1987A, Sher25, HD168625, RY Scuti, WeBo1, SuWt2, and others. The ring bearers fall into two groups: Five rings surround hot supergiants, and all except for the one known binary are carbon copies of the ring around SN1987A. We propose a link between these rings and B[e] supergiants, where the rings derive from the same material in an earlier B[e] phase. The remaining four rings surround evolved intermediate-mass stars; all members of this ring fellowship are close binaries, hinting that binary interactions govern the forging of such rings. We estimate that there may be several thousand more dark rings in the Galaxy, but we are scarcely aware of their existence due to selection effects. The lower-mass objects might be the equatorial density enhancements often invoked to bind the waists of bipolar PNe. ", "machine_text": "In this article, the discovery of two unique circumstellar rings in the western Carina Nebula is reported. These rings, labelled SBW1 and SBW2, differ in composition and age and encircle stars of different mass. Further examination of these two discoveries alongside a sample of other well-known rings reveals two categories: those around hot supergiants, and those around evolved intermediate mass stars in binary systems. The relationship between B[e] supergiants and the former group, as well as the possibility of thousands more dark rings in the Milky Way, is suggested. Finally, the possible connection between these rings and the equatorial density enhancements often invoked to bind the waists of bipolar planetary nebulae is discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3054}
{"prompt": "Rephrase the abstract of an article with title 'Fourier analysis of active-region plage'.   We study the dynamical interaction of the solar chromosphere with the transition region in mossy and non-mossy active-region plage. We carefully align image sequences taken with the Transition Region And Coronal Explorer (TRACE) in the ultraviolet passbands around 1550, 1600, and 1700 A and the extreme ultraviolet passbands at 171 and 195 A. We compute Fourier phase-difference spectra that are spatially averaged separately over mossy and non-mossy plage to study temporal modulations as a function of temporal frequency. The 1550 versus 171 A comparison shows zero phase difference in non-mossy plage. In mossy plage, the phase differences between all UV and EUV passbands show pronounced upward trends with increasing frequency, which abruptly changes into zero phase difference beyond 4-6 mHz. The phase difference between the 171 and 195 A sequences exhibits a shallow dip below 3 mHz and then also turns to zero phase difference beyond this value. We attribute the various similarities between the UV and EUV diagnostics that are evident in the phase-difference diagrams to the contribution of the C IV resonance lines in the 1550 and 1600 A passbands. The strong upward trend at the lower frequencies indicates the presence of upward-traveling disturbances. It points to correspondence between the lower chromosphere and the upper transition region, perhaps by slow-mode magnetosonic disturbances, or by a connection between chromospheric and coronal heating mechanisms. The transition from this upward trend to zero phase difference at higher frequencies is due to the intermittent obscuration by fibrils that occult the foot points of hot loops, which are bright in the EUV and C IV lines, in oscillatory manner.  ", "human_text": "  We study the dynamical interaction of the solar chromosphere with the transition region in mossy and non-mossy active-region plage. We carefully align image sequences taken with the Transition Region And Coronal Explorer (TRACE) in the ultraviolet passbands around 1550, 1600, and 1700 A and the extreme ultraviolet passbands at 171 and 195 A. We compute Fourier phase-difference spectra that are spatially averaged separately over mossy and non-mossy plage to study temporal modulations as a function of temporal frequency. The 1550 versus 171 A comparison shows zero phase difference in non-mossy plage. In mossy plage, the phase differences between all UV and EUV passbands show pronounced upward trends with increasing frequency, which abruptly changes into zero phase difference beyond 4-6 mHz. The phase difference between the 171 and 195 A sequences exhibits a shallow dip below 3 mHz and then also turns to zero phase difference beyond this value. We attribute the various similarities between the UV and EUV diagnostics that are evident in the phase-difference diagrams to the contribution of the C IV resonance lines in the 1550 and 1600 A passbands. The strong upward trend at the lower frequencies indicates the presence of upward-traveling disturbances. It points to correspondence between the lower chromosphere and the upper transition region, perhaps by slow-mode magnetosonic disturbances, or by a connection between chromospheric and coronal heating mechanisms. The transition from this upward trend to zero phase difference at higher frequencies is due to the intermittent obscuration by fibrils that occult the foot points of hot loops, which are bright in the EUV and C IV lines, in oscillatory manner. ", "machine_text": " By applying Fourier analysis, we examine the dynamic relationship between the chromosphere and the transition region of active-region plage, whether it is mossy or non-mossy. We utilize image sequences gathered by the Transition Region And Coronal Explorer (TRACE) in different ultraviolet and extreme ultraviolet passbands. The results of this analysis show that in the non-mossy plage, there is a zero phase difference between 1550 and 171 A. For mossy plage, there is an inclined trend in the phase difference spectra when the frequency rises, with no phase difference beyond the 4-6 mHz rate. The phase difference diagrams between 171 and 195 A is unusually shallow at 3 mHz and then again turns to no phase difference afterwards. We believe that the same resemblance between the UV and EUV bands are credited to the collaboration of the C IV resonance lines in 1550 and 1600 A, whereas the steep incline in the low frequencies make evident the presence of upward-travelling disturbances. This trend turning to zero phase difference at greater frequencies is likely due to the obscuration of the hot loop's foot points by oscillating fibrils in the higher frequencies. With these results, it may be suggested that there is a connection between chromospheric and coronal heating mechanisms that involves the slow-mode magnetosonic disturbance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2014}
{"prompt": "Rephrase the abstract of an article with title 'Charmless B decays to a scalar meson and a vector meson'.   The hadronic charmless B decays into a scalar meson and a vector meson are studied within the framework of QCD factorization. The main results are: (i) The decay rates for the $f_0(980)K^{*-}$ and $f_0(980)\\ov K^{*0}$ modes depend on the $f_0-\\sigma$ mixing angle $\\theta$. The experimental measurements can be accommodated for $\\theta\\approx 20^\\circ$. (ii) If the $a_0(980)$ is a $q\\bar q$ bound state, the predicted branching ratios for the channels $a_0^+\\rho^-$ and $a_0^0\\rho^-$ will be very large, of order $30\\times 10^{-6}$ and $23\\times 10^{-6}$, respectively. If the observation of or the experimental limit on theses two modes is much smaller than the expectation of $\\sim 25\\times 10^{-6}$, this could hint at a four-quark nature for the $a_0(980)$. (iii) For the $a_0(1450)$ channels, $a_0^+(1450)\\rho^-$ and $a_0^0(1450)\\rho^-$ are found to have branching ratios of order $16\\times 10^{-6}$ and $22\\times 10^{-6}$, respectively. A measurement of them at the predicted level will favor the $q\\bar q$ structure for the $a_0(1450)$. (iv) Contrary to the naive expectation that $\\Gamma(B^-\\to a_0^0\\rho^-)\\sim {1\\over 2}\\Gamma(\\bar B^0\\to a_0^+\\rho^-)$, we found that they have comparable rates due to additional contributions to the $a_0\\rho^-$ mode from the $a_0^0$ emission. (v) The predicted central value of $Br(\\bar B^0\\to\\ov K^{*0}_0(1430)\\phi)$ is larger than experiment, though it can be accommodated within theoretical errors. The decays $B\\to K^{*}_0(1430)\\rho$ are expected to have rates substantially larger than that of $B\\to K^{*}_0(1430)\\pi$ owing to the constructive (destructive) interference between the $a_4$ and $a_6$ penguin terms in the former (latter). Experimentally, it is thus important to check if the $B\\to K^{*}_0\\rho$ modes are enhanced relative to the corresponding $K_0^*\\pi$ channels.  ", "human_text": "  The hadronic charmless B decays into a scalar meson and a vector meson are studied within the framework of QCD factorization. The main results are: (i) The decay rates for the $f_0(980)K^{*-}$ and $f_0(980)\\ov K^{*0}$ modes depend on the $f_0-\\sigma$ mixing angle $\\theta$. The experimental measurements can be accommodated for $\\theta\\approx 20^\\circ$. (ii) If the $a_0(980)$ is a $q\\bar q$ bound state, the predicted branching ratios for the channels $a_0^+\\rho^-$ and $a_0^0\\rho^-$ will be very large, of order $30\\times 10^{-6}$ and $23\\times 10^{-6}$, respectively. If the observation of or the experimental limit on theses two modes is much smaller than the expectation of $\\sim 25\\times 10^{-6}$, this could hint at a four-quark nature for the $a_0(980)$. (iii) For the $a_0(1450)$ channels, $a_0^+(1450)\\rho^-$ and $a_0^0(1450)\\rho^-$ are found to have branching ratios of order $16\\times 10^{-6}$ and $22\\times 10^{-6}$, respectively. A measurement of them at the predicted level will favor the $q\\bar q$ structure for the $a_0(1450)$. (iv) Contrary to the naive expectation that $\\Gamma(B^-\\to a_0^0\\rho^-)\\sim {1\\over 2}\\Gamma(\\bar B^0\\to a_0^+\\rho^-)$, we found that they have comparable rates due to additional contributions to the $a_0\\rho^-$ mode from the $a_0^0$ emission. (v) The predicted central value of $Br(\\bar B^0\\to\\ov K^{*0}_0(1430)\\phi)$ is larger than experiment, though it can be accommodated within theoretical errors. The decays $B\\to K^{*}_0(1430)\\rho$ are expected to have rates substantially larger than that of $B\\to K^{*}_0(1430)\\pi$ owing to the constructive (destructive) interference between the $a_4$ and $a_6$ penguin terms in the former (latter). Experimentally, it is thus important to check if the $B\\to K^{*}_0\\rho$ modes are enhanced relative to the corresponding $K_0^*\\pi$ channels. ", "machine_text": "In this work, the decay of charmless B mesons to a scalar meson and a vector meson are analyzed using the QCD factorization approach. It is found that the decays $f_0(980)K^{*-}$ and $f_0(980)\\ov K^{*0}$ depend on the $f_0-\\sigma$ mixing angle, and experimental results suggest $\\theta\\approx 20^\\circ$. Additionally, the $a_0(980)$ could have a four-quark nature if the observed or predicted $a_0^+\\rho^-$ and $a_0^0\\rho^-$ branching ratios, which are estimated to be approximately $30\\times 10^{-6}$ and $23\\times 10^{-6}$ respectively, were found to be much smaller than expected. Moreover, measured decay rates of $a_0^+(1450)\\rho^-$ and $a_0^0(1450)\\rho^-$ of around $16\\times 10^{-6}$ and $22\\times 10^{-6}$, respectively, are expected to support the $q\\bar q$ structure for the $a_0(1450)$. Finally, the $B\\to K^{*}_0(1430)\\rho$ mode is found to have a substantial rate due to constructive interference between the $a_4$ and $a_6$ penguin terms and should be checked against the $B\\to K^{*}_0(1430)\\pi$ channels.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3079}
{"prompt": "Rephrase the abstract of an article with title 'Iron abundances of B-type post-Asymptotic Giant Branch stars in globular   clusters: Barnard 29 in M 13 and ROA 5701 in omega Cen'.   High resolution optical and ultraviolet spectra of two B-type post-Asymptotic Giant Branch (post-AGB) stars in globular clusters, Barnard 29 in M 13 and ROA 5701 in omega Cen, have been analysed using model atmosphere techniques. The optical spectra have been obtained with FEROS on the ESO 2.2-m telescope and the 2d-Coud\\'e spectrograph on the 2.7-m McDonald telescope, while the ultraviolet observations are from the GHRS on the HST. Abundances of light elements (C, N, O, Mg, Al and S) plus Fe have been determined from the optical spectra, while the ultraviolet data provide additional Fe abundance estimates from Fe III absorption lines in the 1875-1900 {\\AA} wavelength region. A general metal underabundance relative to young B-type stars is found for both Barnard 29 and ROA 5701. These results are consistent with the metallicities of the respective clusters, as well as with previous studies of the objects. The derived abundance patterns suggest that the stars have not undergone a gas-dust separation, contrary to previous suggestions, although they may have evolved from the AGB before the onset of the third dredge-up. However, the Fe abundances derived from the HST spectra are lower than those expected from the metallicities of the respective clusters, by 0.5 dex for Barnard 29 and 0.8 dex for ROA 5701. A similar systematic underabundance is also found for other B-type stars in environments of known metallicity, such as the Magellanic Clouds. These results indicate that the Fe III ultraviolet lines may yield abundance values which are systematically too low by typically 0.6 dex and hence such estimates should be treated with caution.  ", "human_text": "  High resolution optical and ultraviolet spectra of two B-type post-Asymptotic Giant Branch (post-AGB) stars in globular clusters, Barnard 29 in M 13 and ROA 5701 in omega Cen, have been analysed using model atmosphere techniques. The optical spectra have been obtained with FEROS on the ESO 2.2-m telescope and the 2d-Coud\\'e spectrograph on the 2.7-m McDonald telescope, while the ultraviolet observations are from the GHRS on the HST. Abundances of light elements (C, N, O, Mg, Al and S) plus Fe have been determined from the optical spectra, while the ultraviolet data provide additional Fe abundance estimates from Fe III absorption lines in the 1875-1900 {\\AA} wavelength region. A general metal underabundance relative to young B-type stars is found for both Barnard 29 and ROA 5701. These results are consistent with the metallicities of the respective clusters, as well as with previous studies of the objects. The derived abundance patterns suggest that the stars have not undergone a gas-dust separation, contrary to previous suggestions, although they may have evolved from the AGB before the onset of the third dredge-up. However, the Fe abundances derived from the HST spectra are lower than those expected from the metallicities of the respective clusters, by 0.5 dex for Barnard 29 and 0.8 dex for ROA 5701. A similar systematic underabundance is also found for other B-type stars in environments of known metallicity, such as the Magellanic Clouds. These results indicate that the Fe III ultraviolet lines may yield abundance values which are systematically too low by typically 0.6 dex and hence such estimates should be treated with caution. ", "machine_text": " High resolution spectroscopic observations of two B-type post-Asymptotic Giant Branch (post-AGB) stars in globular clusters, Barnard 29 in M 13 and ROA 5701 in omega Cen have been made in both the optical and ultraviolet wavelengths. Using model atmosphere techniques, abundances of light element like C, N, O, Mg, Al and S, plus Fe have been determined from the optical spectra, while additional Fe abundance estimates were derived from Fe III absorption lines in the 1875-1900 {\\AA} wavelength range obtained from the GHRS on the HST. Both stars had abundances which were lower than those of young B-type stars, thus in agreement with the metallicity of the two respective clusters. However, the Fe abundances derived from the HST spectra were lower than expected from the clusters' metallicities, by 0.5 dex for Barnard 29 and 0.8 dex for ROA 5701. This same systematic underabundance was also found among other B-type stars, suggesting that the Fe III ultraviolet lines may be yielding values which are too low by circa 0.6 dex and thus must be treated with caution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2196}
{"prompt": "Rephrase the abstract of an article with title 'Symmetric and asymmetric solitons in linearly coupled Bose-Einstein   condensates trapped in optical lattices'.   We study spontaneous symmetry breaking in a system of two parallel quasi-one-dimensional traps, equipped with optical lattices (OLs) and filled with a Bose-Einstein condensate (BEC). The cores are linearly coupled by tunneling. Analysis of the corresponding system of linearly coupled Gross-Pitaevskii equations (GPEs) reveals that spectral bandgaps of the single GPE split into subgaps. Symmetry breaking in two-component BEC solitons is studied in cases of the attractive (AA) and repulsive (RR) nonlinearity in both traps; the mixed situation, with repulsion in one trap and attraction in the other (RA), is considered too. In all the cases, stable asymmetric solitons are found, bifurcating from symmetric or antisymmetric ones (and destabilizing them), in the AA and RR systems, respectively. In either case, bi-stability is predicted, with a nonbifurcating stable branch, either antisymmetric or symmetric, coexisting with asymmetric ones. Solitons destabilized by the bifurcation tend to rearrange themselves into their stable asymmetric counterparts. The impact of a phase mismatch, between the OLs in the two cores is also studied. Also considered is a related model, for a binary BEC in a single-core trap with the OL, assuming that the two species (representing different spin states of the same atom) are coupled by linear interconversion. In that case, the symmetry-breaking bifurcations in the AA and RR models switch their character, if the inter-species nonlinear interaction becomes stronger than the intra-species nonlinearity.  ", "human_text": "  We study spontaneous symmetry breaking in a system of two parallel quasi-one-dimensional traps, equipped with optical lattices (OLs) and filled with a Bose-Einstein condensate (BEC). The cores are linearly coupled by tunneling. Analysis of the corresponding system of linearly coupled Gross-Pitaevskii equations (GPEs) reveals that spectral bandgaps of the single GPE split into subgaps. Symmetry breaking in two-component BEC solitons is studied in cases of the attractive (AA) and repulsive (RR) nonlinearity in both traps; the mixed situation, with repulsion in one trap and attraction in the other (RA), is considered too. In all the cases, stable asymmetric solitons are found, bifurcating from symmetric or antisymmetric ones (and destabilizing them), in the AA and RR systems, respectively. In either case, bi-stability is predicted, with a nonbifurcating stable branch, either antisymmetric or symmetric, coexisting with asymmetric ones. Solitons destabilized by the bifurcation tend to rearrange themselves into their stable asymmetric counterparts. The impact of a phase mismatch, between the OLs in the two cores is also studied. Also considered is a related model, for a binary BEC in a single-core trap with the OL, assuming that the two species (representing different spin states of the same atom) are coupled by linear interconversion. In that case, the symmetry-breaking bifurcations in the AA and RR models switch their character, if the inter-species nonlinear interaction becomes stronger than the intra-species nonlinearity. ", "machine_text": " We analyze the effects of symmetry breaking on solitons in a dual system of linearly coupled traps containing a Bose-Einstein condensate (BEC), which are filled with optical lattices. We use the Gross-Pitaevskii equations to investigate the situation in both cases of attractive and repulsive nonlinearities, as well as for the combination of repulsive and attractive interactions. As a result, stable asymmetric solitons are found in all cases, emerging from symmetric or antisymmetric solitons during the bifurcation process, and coexisting with the formerly stable configuration. Additionally, the impact of a phase mismatch between the optical lattices in the two traps is reviewed. We also consider the relation between binary BECs in a single-core trap, involving transitions between two species within the same atom, and the relative strength of intra- and inter-species nonlinear interactions. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0364}
{"prompt": "Rephrase the abstract of an article with title 'Exciting the Magnetosphere of the Magnetar CXOU J164710.2-455216 in   Westerlund 1'.   We describe XMM-Newton observations taken 4.3 days prior to and 1.5 days subsequent to two remarkable events that were detected with Swift on 2006 September 21 from the candidate magnetar CXOU J164710.2-455216: (1) a 20 ms burst with an energy of 1e37 erg (15-150 keV), and (2) a rapid spin-down (glitch) with a fractionap period change of 1e-4. We find that the luminosity of the pulsar increased by a factor of 100 in the interval between observations, from 1e33 to 1e35 erg/s (0.5-8.0 keV), and that its spectrum hardened. The pulsed count rate increased by a factor of 10 (0.5-8.0 keV), but the fractional rms amplitude of the pulses decreased from 65 to 11 per cent, and their profile changed from being single-peaked to exhibiting three peaks. Similar changes have been observed from other magnetars in response to outbursts, such as that of 1E 2259+586 in 2002 June. We suggest that a plastic deformation of the neutron star's crust induced a very slight twist in the external magnetic field, which in turn generated currents in the magnetosphere that were the direct cause of the X-ray outburst.  ", "human_text": "  We describe XMM-Newton observations taken 4.3 days prior to and 1.5 days subsequent to two remarkable events that were detected with Swift on 2006 September 21 from the candidate magnetar CXOU J164710.2-455216: (1) a 20 ms burst with an energy of 1e37 erg (15-150 keV), and (2) a rapid spin-down (glitch) with a fractionap period change of 1e-4. We find that the luminosity of the pulsar increased by a factor of 100 in the interval between observations, from 1e33 to 1e35 erg/s (0.5-8.0 keV), and that its spectrum hardened. The pulsed count rate increased by a factor of 10 (0.5-8.0 keV), but the fractional rms amplitude of the pulses decreased from 65 to 11 per cent, and their profile changed from being single-peaked to exhibiting three peaks. Similar changes have been observed from other magnetars in response to outbursts, such as that of 1E 2259+586 in 2002 June. We suggest that a plastic deformation of the neutron star's crust induced a very slight twist in the external magnetic field, which in turn generated currents in the magnetosphere that were the direct cause of the X-ray outburst. ", "machine_text": " XMM-Newton observed CXOU J164710.2-455216, a candidate magnetar, in the Westerlund 1 region, four days before and one and a half days after two remarkable events detected by Swift on 2006 September 21. These included a 20 ms burst with an energy of 1e37 erg (15-150 keV), and a rapid spin-down (glitch) with a fractional period change of 1e-4. The pulsar's luminosity increased by a factor of 100 between the two observations, its spectrum hardened, and the count rate of its pulses rose by a factor of 10. Its fractional rms amplitude decreased from 65 to 11 per cent, and its pulse profile went from single-peaked to exhibiting three peaks. This behavior is similar to that of other magnetars in response to outbursts, such as that of 1E 2259+586 in 2002 June. It is suggested that a plastic deformation of the neutron star's crust led to a tiny twist in its external magnetic field, creating currents in the magnetosphere that were the direct cause of the X-ray outburst.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.163}
{"prompt": "Rephrase the abstract of an article with title 'Boutroux curves with external field: equilibrium measures without a   minimization problem'.   The nonlinear steepest descent method for rank-two systems relies on the notion of g-function. The applicability of the method ranges from orthogonal polynomials (and generalizations) to Painleve transcendents, and integrable wave equations (KdV, NonLinear Schroedinger, etc.).   For the case of asymptotics of generalized orthogonal polynomials with respect to varying complex weights we can recast the requirements for the Cauchy-transform of the equilibrium measure into a problem of algebraic geometry and harmonic analysis and completely solve the existence and uniqueness issue without relying on the minimization of a functional. This addresses and solves also the issue of the ``free boundary problem'', determining implicitly the curves where the zeroes of the orthogonal polynomials accumulate in the limit of large degrees and the support of the measure. The relevance to the quasi--linear Stokes phenomenon for Painleve equations is indicated. A numerical algorithm to find these curves in some cases is also explained.   Technical note: the animations included in the file can be viewed using Acrobat Reader 7 or higher. Mac users should also install a QuickTime plugin called Flip4Mac. Linux users can extract the embedded animations and play them with an external program like VLC or MPlayer. All trademarks are owned by the respective companies.  ", "human_text": "  The nonlinear steepest descent method for rank-two systems relies on the notion of g-function. The applicability of the method ranges from orthogonal polynomials (and generalizations) to Painleve transcendents, and integrable wave equations (KdV, NonLinear Schroedinger, etc.).   For the case of asymptotics of generalized orthogonal polynomials with respect to varying complex weights we can recast the requirements for the Cauchy-transform of the equilibrium measure into a problem of algebraic geometry and harmonic analysis and completely solve the existence and uniqueness issue without relying on the minimization of a functional. This addresses and solves also the issue of the ``free boundary problem'', determining implicitly the curves where the zeroes of the orthogonal polynomials accumulate in the limit of large degrees and the support of the measure. The relevance to the quasi--linear Stokes phenomenon for Painleve equations is indicated. A numerical algorithm to find these curves in some cases is also explained.   Technical note: the animations included in the file can be viewed using Acrobat Reader 7 or higher. Mac users should also install a QuickTime plugin called Flip4Mac. Linux users can extract the embedded animations and play them with an external program like VLC or MPlayer. All trademarks are owned by the respective companies. ", "machine_text": " This paper examines the utilization of the nonlinear steepest descent method for rank-two systems in the context of generalized orthogonal polynomials with regard to varying complex weights. By recasting the requirement for the Cauchy-transform of the equilibrium measure into a problem of algebraic geometry and harmonic analysis, a solution for the issue of existence and uniqueness is presented with the elimination of a minimization problem. In addition, this also tackles and solves the issue of the \"free boundary problem\" to discern implicit curves for the zeroes of orthogonal polynomials to accumulate in larger degrees and the support of the measure. Lastly, the relevance of the quasi-linear Stokes phenomenon for Painleve equations is outlined, and a numerical algorithm is provided to locate the curves in some cases. Technical instructions are provided for viewing the associated animations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3062}
{"prompt": "Rephrase the abstract of an article with title 'First study of the gluon-quark-antiquark static potential in SU(3)   Lattice QCD'.   We study the long distance interaction for hybrid hadrons, with a static gluon, a quark and an antiquark with lattice QCD techniques. A Wilson loop adequate to the static hybrid three-body system is developed and, using a 24^3 x 48 periodic lattice with beta=6.2 and a ~ 0.075 fm, two different geometries for the gluon-quark segment and the gluon-antiquark segment are investigated. When these segments are perpendicular, the static potential is compatible with confinement realized with a pair of fundamental strings, one linking the gluon to the quark and another linking the same gluon to the antiquark. When the segments are parallel and superposed, the total string tension is larger and agrees with the Casimir Scaling measured by Bali. This can be interpreted with a type-II superconductor analogy for the confinement in QCD, with repulsion of the fundamental strings and with the string tension of the first topological excitation of the string (the adjoint string) larger than the double of the fundamental string tension.  ", "human_text": "  We study the long distance interaction for hybrid hadrons, with a static gluon, a quark and an antiquark with lattice QCD techniques. A Wilson loop adequate to the static hybrid three-body system is developed and, using a 24^3 x 48 periodic lattice with beta=6.2 and a ~ 0.075 fm, two different geometries for the gluon-quark segment and the gluon-antiquark segment are investigated. When these segments are perpendicular, the static potential is compatible with confinement realized with a pair of fundamental strings, one linking the gluon to the quark and another linking the same gluon to the antiquark. When the segments are parallel and superposed, the total string tension is larger and agrees with the Casimir Scaling measured by Bali. This can be interpreted with a type-II superconductor analogy for the confinement in QCD, with repulsion of the fundamental strings and with the string tension of the first topological excitation of the string (the adjoint string) larger than the double of the fundamental string tension. ", "machine_text": " Using a lattice QCD approach, this is the first study of the static potential of a three-body system made of a gluon, a quark and an antiquark for hybrid hadrons. Through comparing two geometries for the gluon-quark and gluon-antiquark segments, namely when they are perpendicular and when they are parallel and superposed, it is observed that the string tension follows Casimir scaling. Its interpretation suggests the possibility of a type-II superconductor analogy for the confinement in QCD. This indicates a repulsion of the fundamental strings and a string tension for the first topological excitation (adjoint string) higher than twice the fundamental string tension.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2156}
{"prompt": "Rephrase the abstract of an article with title 'Study of Di-Pion Transitions Among Upsilon(3S), Upsilon(2S), and   Upsilon(1S) States'.   We present measurements of decay matrix elements for hadronic transitions of the form Upsilon(nS) -> pi pi Upsilon(mS) where (n, m) = (3, 1), (2, 1), and (3, 2). We reconstruct charged and neutral pion modes with the final state Upsilon decaying to either mu+mu- or e+e-. Dalitz plot distributions for the twelve decay modes are fit individually as well as jointly assuming isospin symmetry, thereby measuring the matrix elements of the decay amplitude. We observe and account for the anomaly previously noted in the di-pion invariant mass distribution for the Upsilon(3S) -> pi pi Upsilon(1S) transition and obtain good descriptions of the dynamics of the decay using the most general decay amplitude allowed by partial conservation of the axial-vector current (PCAC) considerations. The fits further indicate that the Upsilon(2S) -> pi pi Upsilon(1S) and Upsilon(3S) -> pi pi Upsilon(2S) transitions also show the presence of terms in the decay amplitude that were previously ignored, although at a relatively suppressed level.  ", "human_text": "  We present measurements of decay matrix elements for hadronic transitions of the form Upsilon(nS) -> pi pi Upsilon(mS) where (n, m) = (3, 1), (2, 1), and (3, 2). We reconstruct charged and neutral pion modes with the final state Upsilon decaying to either mu+mu- or e+e-. Dalitz plot distributions for the twelve decay modes are fit individually as well as jointly assuming isospin symmetry, thereby measuring the matrix elements of the decay amplitude. We observe and account for the anomaly previously noted in the di-pion invariant mass distribution for the Upsilon(3S) -> pi pi Upsilon(1S) transition and obtain good descriptions of the dynamics of the decay using the most general decay amplitude allowed by partial conservation of the axial-vector current (PCAC) considerations. The fits further indicate that the Upsilon(2S) -> pi pi Upsilon(1S) and Upsilon(3S) -> pi pi Upsilon(2S) transitions also show the presence of terms in the decay amplitude that were previously ignored, although at a relatively suppressed level. ", "machine_text": " In this study, we measure the transition matrix elements of hadronic decays of the form Upsilon(nS) to pi pi Upsilon(mS) for (n, m) = (3, 1), (2, 1), and (3, 2). The decay modes were reconstructed using decay products of mu+mu- and e+e- final states of the Upsilon, and were characterized by separate Dalitz plot distributions for each mode, which were fit both separately and jointly under the assumption of isospin symmetry. These fits revealed the previously observed anomaly in the di-pion invariant mass of the Upsilon(3S) -> pi pi Upsilon(1S) transition and suggest the presence of ignored terms in the Upsilon(2S) -> pi pi Upsilon(1S) and Upsilon(3S) -> pi pi Upsilon(2S) transitions, albeit at a lower level. The expansion of the decay rate was consistent with the conservation principles of the axial-vector current.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2317}
{"prompt": "Rephrase the abstract of an article with title 'Results on axion physics from the CAST Experiment at CERN'.   Axions are expected to be produced in the sun via the Primakoff process. They may be detected through the inverse process in the laboratory, under the influence of a strong magnetic field, giving rise to X-rays of energies in the range of a few keV. Such an Axion detector is the CERN Axion Solar Telescope (CAST), collecting data since 2003. Results have been published, pushing the axion-photon coupling g$_{a\\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at 95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of magnitude lower than previous experimental limits and surpassed for the first time limits set from astrophysical arguments based on the energy-loss concept. The experiment is currently exploring axion masses in the range of 0.02 eV $< m_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass explored will be extended up to the limit of 1.1 eV, testing for the first time the region of theoretical axion models with the axion helioscope method.  ", "human_text": "  Axions are expected to be produced in the sun via the Primakoff process. They may be detected through the inverse process in the laboratory, under the influence of a strong magnetic field, giving rise to X-rays of energies in the range of a few keV. Such an Axion detector is the CERN Axion Solar Telescope (CAST), collecting data since 2003. Results have been published, pushing the axion-photon coupling g$_{a\\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at 95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of magnitude lower than previous experimental limits and surpassed for the first time limits set from astrophysical arguments based on the energy-loss concept. The experiment is currently exploring axion masses in the range of 0.02 eV $< m_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass explored will be extended up to the limit of 1.1 eV, testing for the first time the region of theoretical axion models with the axion helioscope method. ", "machine_text": " The CERN Axion Solar Telescope (CAST) is an Axion detector that has been in operation since 2003, seeking to detect Axions produced in the sun via the Primakoff process. Results from CAST have since been published, revealing a limit of 10$^{-10}$ GeV$^{-1}$ on the axion-photon coupling g$_{a\\gamma}$ at 95% CL, for axion masses up to 0.02 eV. This surpasses all prior experiments, as well as astrophysical limits based on energy-loss concept by nearly a magnitude. The next run of the experiment, currently in preparation, will expand the search up to 1.1 eV, testing theoretical axion models via the axion helioscope method for the first time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0637}
{"prompt": "Rephrase the abstract of an article with title 'Electrical excitation of shock and soliton-like waves in two-dimensional   electron channels'.   We study electrical excitation of nonlinear plasma waves in heterostructures with two-dimensional electron channels and with split gates, and the propagation of these waves using hydrodynamic equations for electron transport coupled with two-dimensional Poisson equation for self-consistent electric potential. The term related to electron collisions with impurities and phonons as well as the term associated with viscosity are included into the hydrodynamic equations. We demonstrate the formation of shock and soliton-like waves as a result of the evolution of strongly nonuniform initial electron density distribution. It is shown that the shock wave front and the shape of soliton-like pulses pronouncedly depend on the coefficient of viscosity, the thickness of the gate layer and the nonuniformity of the donor distribution along the channel. The electron collisions result in damping of the shock and soliton-like waves, while they do not markedly affect the thickness of the shock wave front.  ", "human_text": "  We study electrical excitation of nonlinear plasma waves in heterostructures with two-dimensional electron channels and with split gates, and the propagation of these waves using hydrodynamic equations for electron transport coupled with two-dimensional Poisson equation for self-consistent electric potential. The term related to electron collisions with impurities and phonons as well as the term associated with viscosity are included into the hydrodynamic equations. We demonstrate the formation of shock and soliton-like waves as a result of the evolution of strongly nonuniform initial electron density distribution. It is shown that the shock wave front and the shape of soliton-like pulses pronouncedly depend on the coefficient of viscosity, the thickness of the gate layer and the nonuniformity of the donor distribution along the channel. The electron collisions result in damping of the shock and soliton-like waves, while they do not markedly affect the thickness of the shock wave front. ", "machine_text": "This investigation seeks to gain a better understanding of electrical excitation of electrically driven plasma waves in two-dimensional electron channels and their propagation patterns. Hydrodynamic equations of electron transport are used along with a two-dimensional Poisson equation to predict the behaviour of shock and soliton-like waves resulting from strongly nonuniform initial electron density distributions of the channel. Our findings suggest that the nature of the shock wave front and the shape of the soliton-like pulses depend on certain factors such as the coefficient of viscosity, the thickness of the gate layer, and the nonuniformity of donor distributions along the channel. It is observed that electron collisions with impurities and phonons induce damping of the aforementioned waves, however have only minimal effect on the thickness of the shock wave front.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2111}
{"prompt": "Rephrase the abstract of an article with title 'Instanton Induced Neutrino Majorana Masses in CFT Orientifolds with   MSSM-like spectra'.   Recently it has been shown that string instanton effects may give rise to neutrino Majorana masses in certain classes of semi-realistic string compactifications. In this paper we make a systematic search for supersymmetric MSSM-like Type II Gepner orientifold constructions admitting boundary states associated with instantons giving rise to neutrino Majorana masses and other L- and/or B-violating operators. We analyze the zero mode structure of D-brane instantons on general type II orientifold compactifications, and show that only instantons with O(1) symmetry can have just the two zero modes required to contribute to the 4d superpotential. We however discuss how the addition of fluxes and/or possible non-perturbative extensions of the orientifold compactifications would allow also instantons with $Sp(2)$ and U(1) symmetries to generate such superpotentials. In the context of Gepner orientifolds with MSSM-like spectra, we find no models with O(1) instantons with just the required zero modes to generate a neutrino mass superpotential. On the other hand we find a number of models in one particular orientifold of the Gepner model $(2,4,22,22)$ with $Sp(2)$ instantons with a few extra uncharged non-chiral zero modes which could be easily lifted by the mentioned effects. A few more orientifold examples are also found under less stringent constraints on the zero modes. This class of $Sp(2)$ instantons have the interesting property that R-parity conservation is automatic and the flavour structure of the neutrino Majorana mass matrices has a simple factorized form.  ", "human_text": "  Recently it has been shown that string instanton effects may give rise to neutrino Majorana masses in certain classes of semi-realistic string compactifications. In this paper we make a systematic search for supersymmetric MSSM-like Type II Gepner orientifold constructions admitting boundary states associated with instantons giving rise to neutrino Majorana masses and other L- and/or B-violating operators. We analyze the zero mode structure of D-brane instantons on general type II orientifold compactifications, and show that only instantons with O(1) symmetry can have just the two zero modes required to contribute to the 4d superpotential. We however discuss how the addition of fluxes and/or possible non-perturbative extensions of the orientifold compactifications would allow also instantons with $Sp(2)$ and U(1) symmetries to generate such superpotentials. In the context of Gepner orientifolds with MSSM-like spectra, we find no models with O(1) instantons with just the required zero modes to generate a neutrino mass superpotential. On the other hand we find a number of models in one particular orientifold of the Gepner model $(2,4,22,22)$ with $Sp(2)$ instantons with a few extra uncharged non-chiral zero modes which could be easily lifted by the mentioned effects. A few more orientifold examples are also found under less stringent constraints on the zero modes. This class of $Sp(2)$ instantons have the interesting property that R-parity conservation is automatic and the flavour structure of the neutrino Majorana mass matrices has a simple factorized form. ", "machine_text": " In this article, we explored the possibilities for the emergence of Majorana masses for neutrinos in orientifolds of string theory, with MSSM-like spectra. We conducted a systematic search for supersymmetric type II Gepner orientifold models, admitting such instanton-induced Majorana masses, as well as other lepton- and baryon-violating operators. We investigated zero mode properties of D-brane instantons in general type II orientifold compactifications, and discovered that for the Majorana mass inducing instantons, only those with O(1) symmetry possess the necessary two zero modes. Further developments, such as the addition of fluxes and/or non-perturbative extensions of the orientifolds, may enable instantons with Sp(2) and U(1) symmetries to be incorporated. We investigated orientifolds with MSSM-like spectra, but were unable to identify any models with O(1) instantons that fulfil the zero mode requirements. We did, however, find a number of models with Sp(2) instantons that can induce Majorana masses, in one particular orientifold of the Gepner model $(2,4,22,22)$. This also means that there is an automatic R-parity conservation, as well as a convenient flavour structure in the Majorana mass matrices. In addition, we presented a few more examples of orientifold models when less stringent constraints on the zero modes are applied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1079}
{"prompt": "Rephrase the abstract of an article with title 'The Advantages of Four Dimensions for Composite Higgs Models'.   We examine the relationship between little Higgs and 5d composite models with identical symmetry structures. By performing an \"extreme\" deconstruction, one can reduce any warped composite model to a little Higgs theory on a handful of sites. This allows us to use 4d intuition and the powerful constraints of nonlinear sigma models to elucidate obscure points in the original setup. We find that the finiteness of the Higgs potential in 5d is due to the same collective symmetry breaking as in the little Higgs. We compare a 4d and a 5d model with the same symmetry to the data. Reviewing the constraints on models related to the Minimal Composite Higgs (hep-ph/0412089), we see that it has difficulty in producing acceptable values for S, T, and m_{top} simultaneously. By contrast, in a global analysis, the Minimal Moose with custodial symmetry is viable in a large region of its parameter space and suffers from no numeric tunings. We conjecture that this result is generic for 4d and 5d models with identical symmetries. The data will less strongly constrain the little theory.  ", "human_text": "  We examine the relationship between little Higgs and 5d composite models with identical symmetry structures. By performing an \"extreme\" deconstruction, one can reduce any warped composite model to a little Higgs theory on a handful of sites. This allows us to use 4d intuition and the powerful constraints of nonlinear sigma models to elucidate obscure points in the original setup. We find that the finiteness of the Higgs potential in 5d is due to the same collective symmetry breaking as in the little Higgs. We compare a 4d and a 5d model with the same symmetry to the data. Reviewing the constraints on models related to the Minimal Composite Higgs (hep-ph/0412089), we see that it has difficulty in producing acceptable values for S, T, and m_{top} simultaneously. By contrast, in a global analysis, the Minimal Moose with custodial symmetry is viable in a large region of its parameter space and suffers from no numeric tunings. We conjecture that this result is generic for 4d and 5d models with identical symmetries. The data will less strongly constrain the little theory. ", "machine_text": " In this paper, we examine the connections between the little Higgs and 5d composite models which share identical symmetry structures. We adopt an ''extreme\" deconstruction which helps reduce any warped composite model to a little Higgs theory on a handful of sites. This approach aids in understanding obscure points in the original model setup. Furthermore, we find that the finiteness of the Higgs potential in 5d is generated by the same collective symmetry breaking seen in the little Higgs framework.   We then compare a 4d and a 5d model with the same symmetries to the real-world data. After reviewing the constraints imposed by the Minimal Composite Higgs (hep-ph/0412089), we observe that it has difficulty simultaneously producing acceptable values for S, T and m_{top}. On the other hand, the Minimal Moose with custodial symmetry is viable in a relatively large area of its parameter space, with no numeric tunings required. Our results suggest that this result is generalizable to any 4d or 5d model sharing the same symmetries. This implies that the observational data constrains the theory less tightly when expressed as a little Higgs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.138}
{"prompt": "Rephrase the abstract of an article with title 'National Scientific Facilities and Their Science Impact on   Non-Biomedical Research'.   H-index, proposed by Hirsch is a good indicator of the impact of a scientist's research. When evaluating departments, institutions or labs, the importance of h-index can be further enhanced when properly calibrated for size. Particularly acute is the issue of federally funded facilities whose number of actively publishing scientists frequently dwarfs that of academic departments. Recently Molinari and Molinari developed a methodology that shows the h-index has a universal growth rate for large numbers of papers, allowing for meaningful comparisons between institutions.   An additional challenge when comparing large institutions is that fields have distinct internal cultures, with different typical rates of publication and citation; biology is more highly cited than physics, which is more highly cited than engineering. For this reason, this study has focused on the physical sciences, engineering, and technology, and has excluded bio-medical research. Comparisons between individual disciplines are reported here to provide contextual framework. Generally, it was found that the universal growth rate of Molinari and Molinari holds well across all the categories considered, testifying to the robustness of both their growth law and our results.   The overall goal here is to set the highest standard of comparison for federal investment in science; comparisons are made with the nations preeminent private and public institutions. We find that many among the national facilities compare favorably in research impact with the nations leading universities.  ", "human_text": "  H-index, proposed by Hirsch is a good indicator of the impact of a scientist's research. When evaluating departments, institutions or labs, the importance of h-index can be further enhanced when properly calibrated for size. Particularly acute is the issue of federally funded facilities whose number of actively publishing scientists frequently dwarfs that of academic departments. Recently Molinari and Molinari developed a methodology that shows the h-index has a universal growth rate for large numbers of papers, allowing for meaningful comparisons between institutions.   An additional challenge when comparing large institutions is that fields have distinct internal cultures, with different typical rates of publication and citation; biology is more highly cited than physics, which is more highly cited than engineering. For this reason, this study has focused on the physical sciences, engineering, and technology, and has excluded bio-medical research. Comparisons between individual disciplines are reported here to provide contextual framework. Generally, it was found that the universal growth rate of Molinari and Molinari holds well across all the categories considered, testifying to the robustness of both their growth law and our results.   The overall goal here is to set the highest standard of comparison for federal investment in science; comparisons are made with the nations preeminent private and public institutions. We find that many among the national facilities compare favorably in research impact with the nations leading universities. ", "machine_text": "This study investigates the impact of national scientific facilities on non-biomedical research using the h-index proposed by Hirsch. With the goal of providing the highest standard of comparison for federal investment in science, data from physical sciences, engineering and technology were considered, excluding the biomedicine field. Molinari and Molinari developed a method to allow for meaningful comparisons between institutions and a universal growth rate for large numbers of papers was found to be consistent across all categories. Comparisons between individual disciplines were made and the results showed that many of the national facilities compare favorably with universities in terms of research impact.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1797}
{"prompt": "Rephrase the abstract of an article with title 'A twisted FZZ-like dual for the two-dimensional black hole'.   We review and study the duality between string theory formulated on a curved exact background (the two dimensional black hole) and string theory in flat space with a tachyon-like potential. We generalize previous results in this subject by discussing a twisted version of the Fateev-Zamolodchikov-Zamolodchikov conjecture. This duality is shown to hold at the level of N-point correlation functions on the sphere topology, and connects tree-level string amplitudes in the Euclidean version of the 2D black hole (x time) to correlation functions in a non-linear sigma-model in flat space but in presence of a tachyon wall potential and a linear dilaton. The dual CFT corresponds to the perturbed 2D quantum gravity coupled to c<1 matter (x time), where the operator that describes the tachyon-like potential can be seen as a n=2 momentum mode perturbation, while the usual sine-Liouville operator would correspond to the vortex sector n =1. We show how the sine-Liouville interaction term arises through a twisting of the marginal deformation introduced here, and discuss such 'twisting' as a non-trivial realization of the symmetries of the theory. After briefly reviewing the computation of correlation functions in sine-Liouville CFT, we give a precise prescription for computing correlation functions in the twisted model. To show the new version of the correspondence we make use of a formula recently proven by S. Ribault and J. Teschner, which connects the correlation functions in the Wess-Zumino-Witten theory to correlation functions in the Liouville theory. Conversely, the duality discussed here can be thought of as a free field realization of such remarkable formula.  ", "human_text": "  We review and study the duality between string theory formulated on a curved exact background (the two dimensional black hole) and string theory in flat space with a tachyon-like potential. We generalize previous results in this subject by discussing a twisted version of the Fateev-Zamolodchikov-Zamolodchikov conjecture. This duality is shown to hold at the level of N-point correlation functions on the sphere topology, and connects tree-level string amplitudes in the Euclidean version of the 2D black hole (x time) to correlation functions in a non-linear sigma-model in flat space but in presence of a tachyon wall potential and a linear dilaton. The dual CFT corresponds to the perturbed 2D quantum gravity coupled to c<1 matter (x time), where the operator that describes the tachyon-like potential can be seen as a n=2 momentum mode perturbation, while the usual sine-Liouville operator would correspond to the vortex sector n =1. We show how the sine-Liouville interaction term arises through a twisting of the marginal deformation introduced here, and discuss such 'twisting' as a non-trivial realization of the symmetries of the theory. After briefly reviewing the computation of correlation functions in sine-Liouville CFT, we give a precise prescription for computing correlation functions in the twisted model. To show the new version of the correspondence we make use of a formula recently proven by S. Ribault and J. Teschner, which connects the correlation functions in the Wess-Zumino-Witten theory to correlation functions in the Liouville theory. Conversely, the duality discussed here can be thought of as a free field realization of such remarkable formula. ", "machine_text": " We explore the accepted string theory notion that curved backgrounds and flat space theory with a tachyon-like potential are dual to each other. This duality can be demonstrated at the level of N-point correlation functions on the sphere topology and the equal coupling of tree-level string amplitudes in the Euclidean 2D black hole (x-time) to correlation functions in a non-linear sigma-model in flat space but with a tachyon wall potential and linear dilaton. Furthermore, the dual CFT corresponds to quantum gravity coupled to C<1 matter (x time), where the tachyon-like potential is seen as an n=2 momentum mode perturbation and sine-Liouville operator as an n=1 vortex sector. In order to show how the sine-Liouville interaction arises, twisting of the marginal deformation is carried out. We then display the formula found and proven by S. Ribault and J. Teschner to connect the correlation functions of Wess-Zumino-Witten theory to Liouville theory. This duality that is discussed may be viewed as a free field realization of this formula.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0036}
{"prompt": "Rephrase the abstract of an article with title 'Towards an exact adaptive algorithm for the determinant of a rational   matrix'.   In this paper we propose several strategies for the exact computation of the determinant of a rational matrix. First, we use the Chinese Remaindering Theorem and the rational reconstruction to recover the rational determinant from its modular images. Then we show a preconditioning for the determinant which allows us to skip the rational reconstruction process and reconstruct an integer result. We compare those approaches with matrix preconditioning which allow us to treat integer instead of rational matrices. This allows us to introduce integer determinant algorithms to the rational determinant problem. In particular, we discuss the applicability of the adaptive determinant algorithm of [9] and compare it with the integer Chinese Remaindering scheme. We present an analysis of the complexity of the strategies and evaluate their experimental performance on numerous examples. This experience allows us to develop an adaptive strategy which would choose the best solution at the run time, depending on matrix properties. All strategies have been implemented in LinBox linear algebra library.  ", "human_text": "  In this paper we propose several strategies for the exact computation of the determinant of a rational matrix. First, we use the Chinese Remaindering Theorem and the rational reconstruction to recover the rational determinant from its modular images. Then we show a preconditioning for the determinant which allows us to skip the rational reconstruction process and reconstruct an integer result. We compare those approaches with matrix preconditioning which allow us to treat integer instead of rational matrices. This allows us to introduce integer determinant algorithms to the rational determinant problem. In particular, we discuss the applicability of the adaptive determinant algorithm of [9] and compare it with the integer Chinese Remaindering scheme. We present an analysis of the complexity of the strategies and evaluate their experimental performance on numerous examples. This experience allows us to develop an adaptive strategy which would choose the best solution at the run time, depending on matrix properties. All strategies have been implemented in LinBox linear algebra library. ", "machine_text": " This article presents various techniques to accurately calculate the determinant of a rational matrix, primarily by utilizing the Chinese Remaindering Theorem and the rational reconstruction, as well as matrix preconditioning. We also evaluate the side-by-side performance of the adaptive determinant algorithm with the integer Chinese Remaindering scheme. To gain a better evaluation, complexity analysis and multiple examples are used in order to develop a scheme to efficiently decide which method to use, depending on the properties of the matrix. These techniques have been implemented in the LinBox linear algebra library.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0014}
{"prompt": "Rephrase the abstract of an article with title 'Supersymmetry versus Gauge Symmetry on the Heterotic Landscape'.   One of the goals of the landscape program in string theory is to extract information about the space of string vacua in the form of statistical correlations between phenomenological features that are otherwise uncorrelated in field theory. Such correlations would thus represent predictions of string theory that hold independently of a vacuum-selection principle. In this paper, we study statistical correlations between two features which are likely to be central to any potential description of nature at high energy scales: gauge symmetries and spacetime supersymmetry. We analyze correlations between these two kinds of symmetry within the context of perturbative heterotic string vacua, and find a number of striking features. We find, for example, that the degree of spacetime supersymmetry is strongly correlated with the probabilities of realizing certain gauge groups, with unbroken supersymmetry at the string scale tending to favor gauge-group factors with larger rank. We also find that nearly half of the heterotic landscape is non-supersymmetric and yet tachyon-free at tree level; indeed, less than a quarter of the tree-level heterotic landscape exhibits any supersymmetry at all at the string scale.  ", "human_text": "  One of the goals of the landscape program in string theory is to extract information about the space of string vacua in the form of statistical correlations between phenomenological features that are otherwise uncorrelated in field theory. Such correlations would thus represent predictions of string theory that hold independently of a vacuum-selection principle. In this paper, we study statistical correlations between two features which are likely to be central to any potential description of nature at high energy scales: gauge symmetries and spacetime supersymmetry. We analyze correlations between these two kinds of symmetry within the context of perturbative heterotic string vacua, and find a number of striking features. We find, for example, that the degree of spacetime supersymmetry is strongly correlated with the probabilities of realizing certain gauge groups, with unbroken supersymmetry at the string scale tending to favor gauge-group factors with larger rank. We also find that nearly half of the heterotic landscape is non-supersymmetric and yet tachyon-free at tree level; indeed, less than a quarter of the tree-level heterotic landscape exhibits any supersymmetry at all at the string scale. ", "machine_text": " The aim of the research presented in this paper is to investigate how two significant elements of the string theory landscape \u2013 gauge groups and spacetime supersymmetry \u2013 are connected. By analyzing correlations between the two in the context of perturbative heterotic string vacua, several surprising outcomes have been revealed. For instance, there is a relationship between the amount of supersymmetry and the chance of certain gauge groups being realized, with enhanced supersymmetry tending to result in larger-ranked gauge groups. Additionally, almost half of the heterotic landscape is non-supersymmetric yet tachyon-free at tree level; we found that only a small fraction of the landscape displayed supersymmetry at the string level.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.132}
{"prompt": "Rephrase the abstract of an article with title '(2+1)-Einstein spacetimes of finite type'.   The aim of this survey is to give an overview on the geometry of Einstein maximal globally hyperbolic 2+1 spacetimes of arbitrary curvature, conatining a complete Cauchy surface of finite type. In particular a specialization to the finite type case of the canonicla Wick rotation-rescaling theory, previously developed by the authors, is provided. This includes, for arbitrary curvatures, parameterizations in terms of suitable measured geodesic laminations on open hyperbolic surfaces of finite type. The same geometric objects also parameterize complex projective structures on the surfaces. The coincidence of such parameter space is explained by means of geometric correlations between spacetimes of different curvatures and projective surfaces realized via canonical WR-rescaling along the cosmological times. We also specialize on AdS case mostly referring to recent results achieved by other authors. In particular we describe maximal causal extensions of AdS globally hyperbolic spacetimes and an AdS approach to the theory of earthquakes for hyperbolic surfaces of finite type. A general earthquake theorem is proved for the so called enhanced Teichmuller space. The case of spacetimes with conical timelike singularities is also treated.  ", "human_text": "  The aim of this survey is to give an overview on the geometry of Einstein maximal globally hyperbolic 2+1 spacetimes of arbitrary curvature, conatining a complete Cauchy surface of finite type. In particular a specialization to the finite type case of the canonicla Wick rotation-rescaling theory, previously developed by the authors, is provided. This includes, for arbitrary curvatures, parameterizations in terms of suitable measured geodesic laminations on open hyperbolic surfaces of finite type. The same geometric objects also parameterize complex projective structures on the surfaces. The coincidence of such parameter space is explained by means of geometric correlations between spacetimes of different curvatures and projective surfaces realized via canonical WR-rescaling along the cosmological times. We also specialize on AdS case mostly referring to recent results achieved by other authors. In particular we describe maximal causal extensions of AdS globally hyperbolic spacetimes and an AdS approach to the theory of earthquakes for hyperbolic surfaces of finite type. A general earthquake theorem is proved for the so called enhanced Teichmuller space. The case of spacetimes with conical timelike singularities is also treated. ", "machine_text": "This article provides an overview of the geometry of (2+1)-Einstein maximal globally hyperbolic spacetimes with arbitrary curvature, whose Cauchy surfaces are of finite type. It includes the finite type version of the canonical Wick rotation-rescaling theory that provides parameterizations in terms of measured geodesic laminations on open hyperbolic surfaces of finite type as well as parameterizations that align with the corresponding complex projective structures on the surface. The results are also specialized to the AdS case involving the description of maximal causal extensions of AdS globally hyperbolic spacetimes, an AdS-based theory of earthquakes for the finite type hyperbolic surfaces, and a general earthquake theorem in the enhanced Teichmuller space, as well as the analysis of spacetimes with conical timelike singularities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2152}
{"prompt": "Rephrase the abstract of an article with title 'The Monitor project: JW 380 -- a 0.26, 0.15 Msol pre main sequence   eclipsing binary in the Orion Nebula Cluster'.   We report the discovery of a low-mass (0.26 +/- 0.02, 0.15 +/- 0.01 Msol) pre-main-sequence eclipsing binary with a 5.3 day orbital period. JW 380 was detected as part of a high-cadence time-resolved photometric survey (the Monitor project) using the 2.5m Isaac Newton Telescope and Wide Field Camera for a survey of a single field in the Orion Nebula Cluster (ONC) region in V and i bands. The star is assigned a 99 per cent membership probability from proper motion measurements, and radial velocity observations indicate a systemic velocity within 1 sigma of that of the ONC. Modelling of the combined light and radial velocity curves of the system gave stellar radii of 1.19 +0.04 -0.18 Rsol and 0.90 +0.17 -0.03 Rsol for the primary and secondary, with a significant third light contribution which is also visible as a third peak in the cross-correlation functions used to derive radial velocities. The masses and radii appear to be consistent with stellar models for 2-3 Myr age from several authors, within the present observational errors. These observations probe an important region of mass-radius parameter space, where there are currently only a handful of known pre-main-sequence eclipsing binary systems with precise measurements available in the literature.  ", "human_text": "  We report the discovery of a low-mass (0.26 +/- 0.02, 0.15 +/- 0.01 Msol) pre-main-sequence eclipsing binary with a 5.3 day orbital period. JW 380 was detected as part of a high-cadence time-resolved photometric survey (the Monitor project) using the 2.5m Isaac Newton Telescope and Wide Field Camera for a survey of a single field in the Orion Nebula Cluster (ONC) region in V and i bands. The star is assigned a 99 per cent membership probability from proper motion measurements, and radial velocity observations indicate a systemic velocity within 1 sigma of that of the ONC. Modelling of the combined light and radial velocity curves of the system gave stellar radii of 1.19 +0.04 -0.18 Rsol and 0.90 +0.17 -0.03 Rsol for the primary and secondary, with a significant third light contribution which is also visible as a third peak in the cross-correlation functions used to derive radial velocities. The masses and radii appear to be consistent with stellar models for 2-3 Myr age from several authors, within the present observational errors. These observations probe an important region of mass-radius parameter space, where there are currently only a handful of known pre-main-sequence eclipsing binary systems with precise measurements available in the literature. ", "machine_text": "This investigation presents JW 380, a newly detected binary located within the Orion Nebula Cluster. The system has a combined mass of 0.26 and 0.15 Msol and an orbital period of 5.3 days. The Monitor project was utilized for the discovery of this binary via time-resolved photometry (V and i bands) with the Isaac Newton Telescope and Wide Field Camera. Additionally, radial velocity observations from the cross-correlation functions measured the systemic velocity, which is within 1 sigma of that of the ONC. Modelling of the data showed stellar radii of 1.19 and 0.90 Rsol and gave an age estimate of 2-3 Myr. This study's findings add to the small number of pre-main-sequence eclipsing binaries with precise measurements in the literature by providing additional evidence in the mass-radius parameter space.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2325}
{"prompt": "Rephrase the abstract of an article with title 'Positronium Groundstate in Relativistic Schroedinger Theory'.   The usefulness of the Relativistic Schr\\\"odinger Theory (RST) is studied in the field of atomic physics. As a concrete demonstration, the positronium groundstate is considered in great detail; especially the groundstate energy $E_0$ is worked out in the non-relativistic approximation and under neglection of the magnetic interactions between the positron and the electron. The corresponding RST prediction $(E_0\\simeq -6,48 [eV])$ misses the analogous conventional Schr\\\"odinger result $(E_0\\simeq -6,80 [eV])$ but is closer to the latter than the corresponding Hartree approximation $(-2,65 [eV])$. The missing binding energy of $6,80-6,48=0,32 [eV]$ can be attributed to the approximative use of an SO(3) symmetric interaction potential which in RST, however, is actually only SO(2) invariant against rotations around the z-axis. It is expected that, with the correct use of an anisotropic interaction potential due to the SO(2) symmetry, the RST predictions will come even closer to the conventional Schr\\\"odinger result, where however the mathematical structure of RST relies on exotic (i.e. double-valued) wave functions and on the corresponding unconventional interaction potentials (e.g. Struve-Neumann potential).  ", "human_text": "  The usefulness of the Relativistic Schr\\\"odinger Theory (RST) is studied in the field of atomic physics. As a concrete demonstration, the positronium groundstate is considered in great detail; especially the groundstate energy $E_0$ is worked out in the non-relativistic approximation and under neglection of the magnetic interactions between the positron and the electron. The corresponding RST prediction $(E_0\\simeq -6,48 [eV])$ misses the analogous conventional Schr\\\"odinger result $(E_0\\simeq -6,80 [eV])$ but is closer to the latter than the corresponding Hartree approximation $(-2,65 [eV])$. The missing binding energy of $6,80-6,48=0,32 [eV]$ can be attributed to the approximative use of an SO(3) symmetric interaction potential which in RST, however, is actually only SO(2) invariant against rotations around the z-axis. It is expected that, with the correct use of an anisotropic interaction potential due to the SO(2) symmetry, the RST predictions will come even closer to the conventional Schr\\\"odinger result, where however the mathematical structure of RST relies on exotic (i.e. double-valued) wave functions and on the corresponding unconventional interaction potentials (e.g. Struve-Neumann potential). ", "machine_text": " This research evaluates the effectiveness of the Relativistic Schr\\\"odinger Theory (RST) when applied to atomic physics by analyzing the positronium groundstate. The study neglects any magnetic interactions between the positron and the electron. The RST prediction on the groundstate energy, which approximately equates to -6,48 eV, deviates from the conventional Schr\\\"odinger Theory\u2019s calculation of -6,80 eV by 0.32 eV. This discrepancy is attributed to the use of a SO(3) symmetric interaction potential instead of the anisotropic one due to the SO(2) symmetry which would be more accurate for RST. This suggests that, with the correct and more precise use of the interaction potential, the RST results will likely be closer to the conventional results, taking into account the exotic, double-valued wave functions and the relevant unconventional interaction potentials such as the Struve-Neumann potential.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.381}
{"prompt": "Rephrase the abstract of an article with title 'A fundamental explanation for the tiny value of the cosmological   constant'.   We will look for an implementation of new symmetries in the space-time structure and their cosmological implications. This search will allow us to find a unified vision for electrodynamics and gravitation. We will attempt to develop a heuristic model of the electromagnetic nature of the electron, so that the influence of the gravitational field on the electrodynamics at very large distances leads to a reformulation of our comprehension of the space- time structure at quantum level through the elimination of the classical idea of rest. This will lead us to a modification of the relativistic theory by introducing the idea about a universal minimum limit of speed in the space- time. Such a limit, unattainable by the particles, represents a preferred frame associated with a universal background field (a vacuum energy), enabling a fundamental understanding of the quantum uncertainties. The structure of space-time becomes extended due to such a vacuum energy density, which leads to a negative pressure at the cosmological scales as an anti-gravity, playing the role of the cosmological constant. The tiny values of the vacuum energy density and the cosmological constant will be successfully obtained, being in agreement with current observational results.  ", "human_text": "  We will look for an implementation of new symmetries in the space-time structure and their cosmological implications. This search will allow us to find a unified vision for electrodynamics and gravitation. We will attempt to develop a heuristic model of the electromagnetic nature of the electron, so that the influence of the gravitational field on the electrodynamics at very large distances leads to a reformulation of our comprehension of the space- time structure at quantum level through the elimination of the classical idea of rest. This will lead us to a modification of the relativistic theory by introducing the idea about a universal minimum limit of speed in the space- time. Such a limit, unattainable by the particles, represents a preferred frame associated with a universal background field (a vacuum energy), enabling a fundamental understanding of the quantum uncertainties. The structure of space-time becomes extended due to such a vacuum energy density, which leads to a negative pressure at the cosmological scales as an anti-gravity, playing the role of the cosmological constant. The tiny values of the vacuum energy density and the cosmological constant will be successfully obtained, being in agreement with current observational results. ", "machine_text": " We propose to analyse the influence that the gravitational field has on electrodynamics in extreme distances. Our target is to create a heuristic framework of the electromagnetic character of the electron, in an attempt to substitute the traditional misconception of rest. Such a substitution will necessitate the installment of a correlation of a universal speed constraint in the space-time. This speed cannot be accomplished by any particle, instead supporting a background force, or a vacuum energy, making clear the mutability of quantum discrepancies. The space-time will reposition with the assistance of a vacuum energy density, inducing a negative pressure at the cosmological levels, as a counteracting force to the gravitational action, referred to as the cosmological constant. Finally, we expect that the small sum of the vacuum energy density and the yet lower cosmological constant, will align with the actual observational evidence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4315}
{"prompt": "Rephrase the abstract of an article with title 'Two-loop world-sheet corrections in AdS_5 x S^5 superstring'.   We initiate the computation of the 2-loop quantum AdS_5 x S^5 string corrections on the example of a certain string configuration in S^5 related by an analytic continuation to a folded rotating string in AdS_5 in the ``long string'' limit. The 2-loop term in the energy of the latter should represent the subleading strong-coupling correction to the cusp anomalous dimension and thus provide a further check of recent conjectures about the exact structure of the Bethe ansatz underlying the AdS/CFT duality. We use the conformal gauge and several choices of the \\kappa-symmetry gauge. While we are unable to verify the cancellation of 2d UV divergences we compute the bosonic contribution to the effective action and also determine the non-trivial finite part of the fermionic contribution. Both the bosonic and the fermionic contributions to the string energy happen to be proportional to the Catalan's constant. The resulting value for 2-loop superstring prediction for the subleading coefficient a_2 in the scaling function matches the numerical value found in hep-th/0611135 from the BES equation.  ", "human_text": "  We initiate the computation of the 2-loop quantum AdS_5 x S^5 string corrections on the example of a certain string configuration in S^5 related by an analytic continuation to a folded rotating string in AdS_5 in the ``long string'' limit. The 2-loop term in the energy of the latter should represent the subleading strong-coupling correction to the cusp anomalous dimension and thus provide a further check of recent conjectures about the exact structure of the Bethe ansatz underlying the AdS/CFT duality. We use the conformal gauge and several choices of the \\kappa-symmetry gauge. While we are unable to verify the cancellation of 2d UV divergences we compute the bosonic contribution to the effective action and also determine the non-trivial finite part of the fermionic contribution. Both the bosonic and the fermionic contributions to the string energy happen to be proportional to the Catalan's constant. The resulting value for 2-loop superstring prediction for the subleading coefficient a_2 in the scaling function matches the numerical value found in hep-th/0611135 from the BES equation. ", "machine_text": " We explore two-loop quantum corrections associated with AdS_5 x S^5 superstrings for a particular string configuration, related to a folded rotating string in AdS_5 in the ``long string'' limit. By employing the conformal gauge and various \\kappa-symmetry gauge choices, we ascertain the bosonic contribution to the effective action and the non-zero finite portion of the fermionic contribution. Notably, the bosonic and fermionic contributions to the string energy both amount to the Catalan's constant. The resultant value for the two-loop superstring prediction for the subleading coefficient a_2 in the scaling function aligns with the numerical value determined from the BES equation in hep-th/0611135. This provides further confirmation of the exact structure of the Bethe ansatz underlying AdS/CFT duality.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3638}
{"prompt": "Rephrase the abstract of an article with title 'Surface Structure in an Accretion Disk Annulus with Comparable Radiation   and Gas Pressure'.   We have employed a 3-d energy-conserving radiation MHD code to simulate the vertical structure and thermodynamics of a shearing box whose parameters were chosen so that the radiation and gas pressures would be comparable. The upper layers of this disk segment are magnetically-dominated, creating conditions appropriate for both photon bubble and Parker instabilities. We find little evidence for photon bubbles, even though the simulation has enough spatial resolution to see them and their predicted growth rates are high. On the other hand, there is strong evidence for Parker instabilities, and they appear to dominate the evolution of the magnetically supported surface layers. The disk photosphere is complex, with large density inhomogeneities at both the scattering and effective (thermalization) photospheres of the evolving horizontally-averaged structure. Both the dominant magnetic support and the inhomogeneities are likely to have strong effects on the spectrum and polarization of thermal photons emerging from the disk atmosphere. The inhomogeneities are also large enough to affect models of reflection spectra from the atmospheres of accretion disks.  ", "human_text": "  We have employed a 3-d energy-conserving radiation MHD code to simulate the vertical structure and thermodynamics of a shearing box whose parameters were chosen so that the radiation and gas pressures would be comparable. The upper layers of this disk segment are magnetically-dominated, creating conditions appropriate for both photon bubble and Parker instabilities. We find little evidence for photon bubbles, even though the simulation has enough spatial resolution to see them and their predicted growth rates are high. On the other hand, there is strong evidence for Parker instabilities, and they appear to dominate the evolution of the magnetically supported surface layers. The disk photosphere is complex, with large density inhomogeneities at both the scattering and effective (thermalization) photospheres of the evolving horizontally-averaged structure. Both the dominant magnetic support and the inhomogeneities are likely to have strong effects on the spectrum and polarization of thermal photons emerging from the disk atmosphere. The inhomogeneities are also large enough to affect models of reflection spectra from the atmospheres of accretion disks. ", "machine_text": " We have used a 3-dimensional radiation magnetohydrodynamic code to investigate the vertical structure and thermodynamics of a disk annular segment where both the gas pressure and radiation pressure would be of similar magnitude. Our results indicate strong evidence of Parker instabilities as the dominant magnetic support in the upper layers of the disc, resulting in a complex photosphere with significant density variations at the scattering and thermalization photospheres. Such inhomogeneities could significantly change both the spectrum and polarization of thermal photons emerging from the disk atmosphere, as well as impacting models used to predict their reflection spectra.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0314}
{"prompt": "Rephrase the abstract of an article with title 'Co-orbital Oligarchy'.   We present a systematic examination of the changes in semi-major axis caused by the mutual interactions of a group of massive bodies orbiting a central star in the presence of eccentricity dissipation. For parameters relevant to the oligarchic stage of planet formation, dynamical friction keeps the typical eccentricities small and prevents orbit crossing. Interactions at impact parameters greater than several Hill radii cause the protoplanets to repel each other; if the impact parameter is instead much less than the Hill radius, the protoplanets shift slightly in semi-major axis but remain otherwise unperturbed. If the orbits of two or more protoplanets are separated by less than a Hill radius, they are each pushed towards an equilibrium spacing between their neighbors and can exist as a stable co-orbital system. In the shear-dominated oligarchic phase of planet formation we show that the feeding zones contain several oligarchs instead of only one. Growth of the protoplanets in the oligarchic phase drives the disk to an equilibrium configuration that depends on the mass ratio of protoplanets to planetesimals, $\\Sigma/\\sigma$. Early in the oligarchic phase, when $\\Sigma/\\sigma$ is low, the spacing between rows of co-orbital oligarchs are about 5 Hill radii wide, rather than the 10 Hill radii cited in the literature. It is likely that at the end of oligarchy the average number of co-orbital oligarchs is greater than unity. In the outer solar system this raises the disk mass required to form the ice giants. In the inner solar system this lowers the mass of the final oligarchs and requires more giant impacts than previously estimated. This result provides additional evidence that Mars is not an untouched leftover from the oligarchic phase, but must be composed of several oligarchs assembled through giant impacts.  ", "human_text": "  We present a systematic examination of the changes in semi-major axis caused by the mutual interactions of a group of massive bodies orbiting a central star in the presence of eccentricity dissipation. For parameters relevant to the oligarchic stage of planet formation, dynamical friction keeps the typical eccentricities small and prevents orbit crossing. Interactions at impact parameters greater than several Hill radii cause the protoplanets to repel each other; if the impact parameter is instead much less than the Hill radius, the protoplanets shift slightly in semi-major axis but remain otherwise unperturbed. If the orbits of two or more protoplanets are separated by less than a Hill radius, they are each pushed towards an equilibrium spacing between their neighbors and can exist as a stable co-orbital system. In the shear-dominated oligarchic phase of planet formation we show that the feeding zones contain several oligarchs instead of only one. Growth of the protoplanets in the oligarchic phase drives the disk to an equilibrium configuration that depends on the mass ratio of protoplanets to planetesimals, $\\Sigma/\\sigma$. Early in the oligarchic phase, when $\\Sigma/\\sigma$ is low, the spacing between rows of co-orbital oligarchs are about 5 Hill radii wide, rather than the 10 Hill radii cited in the literature. It is likely that at the end of oligarchy the average number of co-orbital oligarchs is greater than unity. In the outer solar system this raises the disk mass required to form the ice giants. In the inner solar system this lowers the mass of the final oligarchs and requires more giant impacts than previously estimated. This result provides additional evidence that Mars is not an untouched leftover from the oligarchic phase, but must be composed of several oligarchs assembled through giant impacts. ", "machine_text": " This paper examines how mutual interactions of multiple large bodies orbiting a central star, in the presence of eccentricity dissipation, cause changes in the semi-major axis. For the conditions pertinent to the oligarchic stage of planet formation, dynamical friction keeps the eccentricities small, reducing collision risks. If protoplanets move away from each other at a distance much greater than their Hill radius, they should remain relatively unperturbed. When two or more orbits are within a Hill radius from each other, the protoplanets are drawn towards equilibrium spacing between each other, thus creating a stable configuration of co-orbital oligarchs. We demonstrate that during the oligarchic phase of planet formation, each feeding zone contains several oligarchs instead of the single one previously thought. This finding has implications in the outer solar system, increasing the mass of the disk required to form the ice giants. In the inner solar system, this requires more giant impacts than anticipated to form fewer, final oligarchs. This suggests that Mars is not a pristine vestige of the oligarchic phase; it more likely is composed of multiple oligarchs that merged through giant impacts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1079}
{"prompt": "Rephrase the abstract of an article with title 'Fuzzy Extra Dimensions: Dimensional Reduction, Dynamical Generation and   Renormalizability'.   We examine gauge theories defined in higher dimensions where theextra dimensions form a fuzzy (finite matrix) manifold. First we reinterpret these gauge theories as four-dimensional theories with Kaluza-Klein modes and then we perform a generalized \\`a la Forgacs-Manton dimensional reduction. We emphasize some striking features emerging in the later case such as (i) the appearance of non-abelian gauge theories in four dimensions starting from an abelian gauge theory in higher dimensions, (ii) the fact that the spontaneous symmetry breaking of the theory takes place entirely in the extra dimensions and (iii) the renormalizability of the theory both in higher as well as in four dimensions. Then reversing the above approach we present a renormalizable four dimensional SU(N) gauge theory with a suitable multiplet of scalar fields, which via spontaneous symmetry breaking dynamically develops extra dimensions in the form of a fuzzy sphere. We explicitly find the tower of massive Kaluza-Klein modes consistent with an interpretation as gauge theory on $M^4 \\times S^2$, the scalars being interpreted as gauge fields on $S^2$. Depending on the parameters of the model the low-energy gauge group can be of the form $SU(n_1) \\times SU(n_2) \\times U(1)$.  ", "human_text": "  We examine gauge theories defined in higher dimensions where theextra dimensions form a fuzzy (finite matrix) manifold. First we reinterpret these gauge theories as four-dimensional theories with Kaluza-Klein modes and then we perform a generalized \\`a la Forgacs-Manton dimensional reduction. We emphasize some striking features emerging in the later case such as (i) the appearance of non-abelian gauge theories in four dimensions starting from an abelian gauge theory in higher dimensions, (ii) the fact that the spontaneous symmetry breaking of the theory takes place entirely in the extra dimensions and (iii) the renormalizability of the theory both in higher as well as in four dimensions. Then reversing the above approach we present a renormalizable four dimensional SU(N) gauge theory with a suitable multiplet of scalar fields, which via spontaneous symmetry breaking dynamically develops extra dimensions in the form of a fuzzy sphere. We explicitly find the tower of massive Kaluza-Klein modes consistent with an interpretation as gauge theory on $M^4 \\times S^2$, the scalars being interpreted as gauge fields on $S^2$. Depending on the parameters of the model the low-energy gauge group can be of the form $SU(n_1) \\times SU(n_2) \\times U(1)$. ", "machine_text": " This paper looks into the properties of gauge theories defined in more than four dimensions, where the extra dimensions take the form of a fuzzy (finite matrix) manifold. We compare this to the well-known Kaluza-Klein views of lower-dimensional gauge theories, noting multiple key differences. These include effectively non-abelian gauge theories arising from higher-dimensional abelian theories, the emergence of spontaneous symmetry breaking in the extra dimensions, and the renormalizability of both higher- and lower-dimensional theories. Then we explore the inversion of this approach, with a renormalizable four-dimensional $SU(N)$ gauge theory whose symmetry breaking generates a fuzzy sphere of extra dimensions by way of extra scalar fields. This generates a corresponding tower of massive Kaluza-Klein modes, with the scalars themselves representing the gauge fields on the sphere. With suitable parameterization, the resulting low-energy gauge group can become $SU(n_1) \\times SU(n_2) \\times U(1)$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.288}
{"prompt": "Rephrase the abstract of an article with title 'Combining Weak Lensing Tomography with Halo Clustering to Probe Dark   Energy'.   Two methods of constraining the properties of dark energy are weak lensing tomography and cluster counting. Uncertainties in mass calibration of clusters can be reduced by using the properties of halo clustering (the clustering of clusters). However, within a single survey, weak lensing and halo clustering probe the same density fluctuations. We explore the question of whether this information can be used twice -- once in weak lensing and then again in halo clustering to calibrate cluster masses -- or whether the combined dark energy constraints are weaker than the sum of the individual constraints. For a survey like the Dark Energy Survey (DES), we find that the cosmic shearing of source galaxies at high redshifts is indeed highly correlated with halo clustering at lower redshifts. Surprisingly, this correlation does not degrade cosmological constraints for a DES-like survey, and in fact, constraints are marginally improved since the correlations themselves act as additional observables. This considerably simplifies the analysis for a DES-like survey: when weak lensing and halo clustering are treated as independent experiments, the combined dark energy constraints (cluster counts included) are accurate if not slightly conservative. Our findings mirror those of Takada and Bridle, who investigated correlations between the cosmic shear and cluster counts.  ", "human_text": "  Two methods of constraining the properties of dark energy are weak lensing tomography and cluster counting. Uncertainties in mass calibration of clusters can be reduced by using the properties of halo clustering (the clustering of clusters). However, within a single survey, weak lensing and halo clustering probe the same density fluctuations. We explore the question of whether this information can be used twice -- once in weak lensing and then again in halo clustering to calibrate cluster masses -- or whether the combined dark energy constraints are weaker than the sum of the individual constraints. For a survey like the Dark Energy Survey (DES), we find that the cosmic shearing of source galaxies at high redshifts is indeed highly correlated with halo clustering at lower redshifts. Surprisingly, this correlation does not degrade cosmological constraints for a DES-like survey, and in fact, constraints are marginally improved since the correlations themselves act as additional observables. This considerably simplifies the analysis for a DES-like survey: when weak lensing and halo clustering are treated as independent experiments, the combined dark energy constraints (cluster counts included) are accurate if not slightly conservative. Our findings mirror those of Takada and Bridle, who investigated correlations between the cosmic shear and cluster counts. ", "machine_text": " In this article, we investigate if the information from two methods of constraining dark energy - weak lensing tomography and cluster counting - can be used in tandem to refine mass calibration of clusters. We analyze a survey similar to the Dark Energy Survey (DES) to determine if it is possible to combine cosmic shearing of high redshift source galaxies with halo clustering at lower redshifts without degrading cosmological constraints. Surprisingly, our findings show that when weak lensing and halo clustering are treated independently, the combined dark energy constraints are even slightly better than the sum of individual constraints. Our results echo those proposed by Takada and Bridle examining correlations between cosmic shear and cluster counts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2395}
{"prompt": "Rephrase the abstract of an article with title 'The photospheric environment of a solar pore with light bridge'.   Pores are one of the various features forming in the photosphere by the emergence of magnetic field onto the solar surface. They lie at the border between tiny magnetic elements and larger sunspots. Light bridges, in such structures, are bright features separating umbral areas in two or more irregular regions. Commonly, light bridges indicate that a the merging of magnetic regions or, conversely, the breakup of the area is underway. We investigate the velocity structure of a solar pore (AR10812) with light bridge, and of the quiet solar photosphere nearby, analyzing high spatial and spectral resolution images. The pore area has been observed with the Interferometric BI-dimensional Spectrometer (IBIS) at the Dunn Solar Telescope, acquiring monochromatic images in the Ca II 854.2 nm line and in the Fe I 709.0 nm line as well as G-band and broad-band images. We also computed the Line of Sight (LoS) velocity field associated to the Fe I and Fe II photospheric lines. The amplitude of the LoS velocity fluctuations, inside the pore, is smaller than that observed in the quiet granulation near the active region. We computed the azimuthal average LoS velocity and derived its radial profile. The whole pore is characterized by a downward velocity -200 m/s and by an annular downflow structure with an average velocity of -350 m/s with respect to the nearby quiet sun. The light bridge inside the pore, when observed in the broad-band channel of IBIS and in the red wing of Ca II 854.2 nm line, shows an elongated dark structure running along its axis, that we explain with a semi-analytical model. In the highest resolution LoS velocity images the light bridge shows a profile consistent with a convective roll: a weak upflow, 50-100m/s, in correspondence of the dark lane, flanked by a downflow, -(200-300) m/s.  ", "human_text": "  Pores are one of the various features forming in the photosphere by the emergence of magnetic field onto the solar surface. They lie at the border between tiny magnetic elements and larger sunspots. Light bridges, in such structures, are bright features separating umbral areas in two or more irregular regions. Commonly, light bridges indicate that a the merging of magnetic regions or, conversely, the breakup of the area is underway. We investigate the velocity structure of a solar pore (AR10812) with light bridge, and of the quiet solar photosphere nearby, analyzing high spatial and spectral resolution images. The pore area has been observed with the Interferometric BI-dimensional Spectrometer (IBIS) at the Dunn Solar Telescope, acquiring monochromatic images in the Ca II 854.2 nm line and in the Fe I 709.0 nm line as well as G-band and broad-band images. We also computed the Line of Sight (LoS) velocity field associated to the Fe I and Fe II photospheric lines. The amplitude of the LoS velocity fluctuations, inside the pore, is smaller than that observed in the quiet granulation near the active region. We computed the azimuthal average LoS velocity and derived its radial profile. The whole pore is characterized by a downward velocity -200 m/s and by an annular downflow structure with an average velocity of -350 m/s with respect to the nearby quiet sun. The light bridge inside the pore, when observed in the broad-band channel of IBIS and in the red wing of Ca II 854.2 nm line, shows an elongated dark structure running along its axis, that we explain with a semi-analytical model. In the highest resolution LoS velocity images the light bridge shows a profile consistent with a convective roll: a weak upflow, 50-100m/s, in correspondence of the dark lane, flanked by a downflow, -(200-300) m/s. ", "machine_text": " A solar pore with a light bridge, located on the boundary between small magnetic elements and bigger sunspots, was studied using high resolution images from the Interferometric BI-dimensional Spectrometer (IBIS). This area was observed using monochromatic images in the Ca II 854.2 nm line and in the Fe I 709.0 nm line, as well as G-band and broad-band images. The fluctuations in Line of Sight velocity observed inside the pore were smaller than in a quiet photosphere nearby. Azimuthal average LoS velocity was then measured showing a downward velocity of -200 m/s and an annular downward flow of -350 m/s relative to the near quiet sun. Further examination of the light bridge with the broad-band channel of IBIS and the red wing of Ca II 854.2 nm line revealed the presence of an elongated dark structure along its axis, realised as a convective roll representing a weak upflow of 50-100 m/s flanked by a downflow of -(200-300) m/s.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3776}
{"prompt": "Rephrase the abstract of an article with title 'Quantum Fields on the Groenewold-Moyal Plane: C, P, T and CPT'.   We show that despite the inherent non-locality of quantum field theories on the Groenewold-Moyal (GM) plane, one can find a class of ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and ${\\bf CPT}$ invariant theories. In particular, these are theories without gauge fields or with just gauge fields and no matter fields. We also show that in the presence of gauge fields, one can have a field theory where the Hamiltonian is ${\\bf C}$ and ${\\bf T}$ invariant while the $S$-matrix violates ${\\bf P}$ and ${\\bf CPT}$.   In non-abelian gauge theories with matter fields such as the electro-weak and $QCD$ sectors of the standard model of particle physics, ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and the product of any pair of them are broken while ${\\bf CPT}$ remains intact for the case $\\theta^{0i} =0$. (Here $x^{\\mu} \\star x^{\\nu} - x^{\\nu} \\star x^{\\mu} = i \\theta^{\\mu \\nu}$, $x^{\\mu}$: coordinate functions, $\\theta^{\\mu \\nu} = -\\theta^{\\nu \\mu}=$ constant.) When $\\theta^{0i} \\neq 0$, it contributes to breaking also ${\\bf P}$ and ${\\bf CPT}$. It is known that the $S$-matrix in a non-abelian theory depends on $\\theta^{\\mu \\nu}$ only through $\\theta^{0i}$. The $S$-matrix is frame dependent. It breaks (the identity component of the) Lorentz group. All the noncommutative effects vanish if the scattering takes place in the center-of-mass frame, or any frame where $\\theta^{0i}P^{\\textrm{in}}_{i} = 0$, but not otherwise. ${\\bf P}$ and ${\\bf CPT}$ are good symmetries of the theory in this special case.  ", "human_text": "  We show that despite the inherent non-locality of quantum field theories on the Groenewold-Moyal (GM) plane, one can find a class of ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and ${\\bf CPT}$ invariant theories. In particular, these are theories without gauge fields or with just gauge fields and no matter fields. We also show that in the presence of gauge fields, one can have a field theory where the Hamiltonian is ${\\bf C}$ and ${\\bf T}$ invariant while the $S$-matrix violates ${\\bf P}$ and ${\\bf CPT}$.   In non-abelian gauge theories with matter fields such as the electro-weak and $QCD$ sectors of the standard model of particle physics, ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and the product of any pair of them are broken while ${\\bf CPT}$ remains intact for the case $\\theta^{0i} =0$. (Here $x^{\\mu} \\star x^{\\nu} - x^{\\nu} \\star x^{\\mu} = i \\theta^{\\mu \\nu}$, $x^{\\mu}$: coordinate functions, $\\theta^{\\mu \\nu} = -\\theta^{\\nu \\mu}=$ constant.) When $\\theta^{0i} \\neq 0$, it contributes to breaking also ${\\bf P}$ and ${\\bf CPT}$. It is known that the $S$-matrix in a non-abelian theory depends on $\\theta^{\\mu \\nu}$ only through $\\theta^{0i}$. The $S$-matrix is frame dependent. It breaks (the identity component of the) Lorentz group. All the noncommutative effects vanish if the scattering takes place in the center-of-mass frame, or any frame where $\\theta^{0i}P^{\\textrm{in}}_{i} = 0$, but not otherwise. ${\\bf P}$ and ${\\bf CPT}$ are good symmetries of the theory in this special case. ", "machine_text": " This research presents a class of quantum field theories that are invariant under the transformations ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and ${\\bf CPT}$, despite their nonlocal nature when developed on the Groenewold-Moyal (GM) plane. We consider theories that contain either no gauge fields, or contain both gauge fields and no matter fields. We also demonstrate that in the presence of gauge fields, it is possible to have a field theory where the Hamiltonian is symmetric under ${\\bf C}$ and ${\\bf T}$, while the $S$-matrix violates both ${\\bf P}$ and ${\\bf CPT}$. For non-abelian gauge theories with matter fields, such as the electro-weak and $QCD$ sectors of the standard model of particle physics, the ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and any pairs of them are broken, while ${\\bf CPT}$ remains intact in the case of $\\theta^{0i}=0$. When $\\theta^{0i} \\neq 0$, it also contributes to breaking both ${\\bf P} $ and ${\\bf CPT}$. It is known that the $S$-matrix in a non-abelian theory depends solely on $\\theta^{0i}$. Moreover, this $S$-matrix is frame dependent; meaning it breaks the identity component of the Lorentz group. All the noncommutative effects cease to exist when the scattering takes place in the center-of-mass frame, or any other frame where $\\theta^{0i}P^{\\textrm{in}}_{i} = 0$. By contrast, in this special case both ${\\bf P}$ and ${\\bf CPT}$ are seen to be good symmetries of the theory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1259}
{"prompt": "Rephrase the abstract of an article with title 'Diffuse HI Disks in Isolated Galaxies'.   In order to investigate the contribution of diffuse components to their total HI emission, we have obtained high precision HI line flux densities with the 100m Green Bank Telescope for a sample of 100 isolated spiral and irregular galaxies which we have previously observed with the 43m telescope. A comparison of the observed HI line fluxes obtained with the two different telescopes, characterized by half-power beam widths of 9 arcmin and 21 arcmin respectively, exploits a ``beam matching'' technique to yield a statistical determination of the occurrence of diffuse HI components in their disks. A simple model of the HI distribution within a galaxy well describes ~75 % of the sample and accounts for all of the HI line flux density. The remaining galaxies are approximately evenly divided into two categories: ones which appear to possess a significantly more extensive HI distribution than the model predicts, and ones for which the HI distribution is more centrally concentrated than predicted. Examples of both extremes can be found in the literature but little attention has been paid to the centrally concentrated HI systems. Our sample has demonstrated that galaxies do not commonly possess extended regions of low surface brightness HI gas which is not accounted for by our current understanding of the structure of HI disks. Eight HI-rich companions to the target objects are identified, and a set of extragalactic HI line flux density calibrators is presented.  ", "human_text": "  In order to investigate the contribution of diffuse components to their total HI emission, we have obtained high precision HI line flux densities with the 100m Green Bank Telescope for a sample of 100 isolated spiral and irregular galaxies which we have previously observed with the 43m telescope. A comparison of the observed HI line fluxes obtained with the two different telescopes, characterized by half-power beam widths of 9 arcmin and 21 arcmin respectively, exploits a ``beam matching'' technique to yield a statistical determination of the occurrence of diffuse HI components in their disks. A simple model of the HI distribution within a galaxy well describes ~75 % of the sample and accounts for all of the HI line flux density. The remaining galaxies are approximately evenly divided into two categories: ones which appear to possess a significantly more extensive HI distribution than the model predicts, and ones for which the HI distribution is more centrally concentrated than predicted. Examples of both extremes can be found in the literature but little attention has been paid to the centrally concentrated HI systems. Our sample has demonstrated that galaxies do not commonly possess extended regions of low surface brightness HI gas which is not accounted for by our current understanding of the structure of HI disks. Eight HI-rich companions to the target objects are identified, and a set of extragalactic HI line flux density calibrators is presented. ", "machine_text": " By using the 100m Green Bank Telescope and 43m telescope to observe a collection of 100 isolated spiral and irregular galaxies, this study surveys their HI emission to determine the proportion of diffuse components in their disk. Comparing the HI line flux densities obtained by the two telescopes reveals the degree to which galaxies have an extended low surface brightness HI gas that observational models do not take into account. Results show that in ~75% of the sample, current models are appropriate in accurately accounting for HI distributions. The remaining galaxies, however, could have either a significantly greater HI distribution or a more concentrated one than the models prescribe. Additionally, HI-rich companions to the target objects are found and a set of HI line flux density calibrators are established.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2299}
{"prompt": "Rephrase the abstract of an article with title 'Strong atom-field coupling for Bose-Einstein condensates in an optical   cavity on a chip'.   An optical cavity enhances the interaction between atoms and light, and the rate of coherent atom-photon coupling can be made larger than all decoherence rates of the system. For single atoms, this strong coupling regime of cavity quantum electrodynamics (cQED) has been the subject of spectacular experimental advances, and great efforts have been made to control the coupling rate by trapping and cooling the atom towards the motional ground state, which has been achieved in one dimension so far. For N atoms, the three-dimensional ground state of motion is routinely achieved in atomic Bose-Einstein condensates (BECs), but although first experiments combining BECs and optical cavities have been reported recently, coupling BECs to strong-coupling cavities has remained an elusive goal. Here we report such an experiment, which is made possible by combining a new type of fibre-based cavity with atom chip technology. This allows single-atom cQED experiments with a simplified setup and realizes the new situation of N atoms in a cavity each of which is identically and strongly coupled to the cavity mode. Moreover, the BEC can be positioned deterministically anywhere within the cavity and localized entirely within a single antinode of the standing-wave cavity field. This gives rise to a controlled, tunable coupling rate, as we confirm experimentally. We study the heating rate caused by a cavity transmission measurement as a function of the coupling rate and find no measurable heating for strongly coupled BECs. The spectrum of the coupled atoms-cavity system, which we map out over a wide range of atom numbers and cavity-atom detunings, shows vacuum Rabi splittings exceeding 20 gigahertz, as well as an unpredicted additional splitting which we attribute to the atomic hyperfine structure.  ", "human_text": "  An optical cavity enhances the interaction between atoms and light, and the rate of coherent atom-photon coupling can be made larger than all decoherence rates of the system. For single atoms, this strong coupling regime of cavity quantum electrodynamics (cQED) has been the subject of spectacular experimental advances, and great efforts have been made to control the coupling rate by trapping and cooling the atom towards the motional ground state, which has been achieved in one dimension so far. For N atoms, the three-dimensional ground state of motion is routinely achieved in atomic Bose-Einstein condensates (BECs), but although first experiments combining BECs and optical cavities have been reported recently, coupling BECs to strong-coupling cavities has remained an elusive goal. Here we report such an experiment, which is made possible by combining a new type of fibre-based cavity with atom chip technology. This allows single-atom cQED experiments with a simplified setup and realizes the new situation of N atoms in a cavity each of which is identically and strongly coupled to the cavity mode. Moreover, the BEC can be positioned deterministically anywhere within the cavity and localized entirely within a single antinode of the standing-wave cavity field. This gives rise to a controlled, tunable coupling rate, as we confirm experimentally. We study the heating rate caused by a cavity transmission measurement as a function of the coupling rate and find no measurable heating for strongly coupled BECs. The spectrum of the coupled atoms-cavity system, which we map out over a wide range of atom numbers and cavity-atom detunings, shows vacuum Rabi splittings exceeding 20 gigahertz, as well as an unpredicted additional splitting which we attribute to the atomic hyperfine structure. ", "machine_text": " The strong coupling between atoms and light can be achieved with optical cavities, resulting in single atom experiments that exhibit the coherent atom-photon coupling rate exceeding decoherence rates. Making progress on cavity quantum electrodynamics (cQED) in three dimensions has been hindered by the difficulty in trapping and cooling atoms towards the motional ground state, but has been achievable with a Bose-Einstein condensate (BEC). With the pairing of a new fibre-based cavity and atom chip technology, this experiment presents a simpler setup that demonstrates a strong atom-field coupling for BECs in a cavity on a chip, allowing the BEC to be positioned within the cavity and fully localized within a sole antinode of the standing-wave. Through a transmission measurement, no noticeable heating takes place for the BEC at strong coupling. The spectrum of the coupled atoms-cavity system was mapped with a wide range of atom numbers and cavity-atom detunings, demonstrating vacuum Rabi splittings exceeding 20 gigahertz and an unexpected additional splitting attributed to the atomic hyperfine structure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.139}
{"prompt": "Rephrase the abstract of an article with title 'On the generalized Freedman-Townsend model'.   Consistent interactions that can be added to a free, Abelian gauge theory comprising a finite collection of BF models and a finite set of two-form gauge fields (with the Lagrangian action written in first-order form as a sum of Abelian Freedman-Townsend models) are constructed from the deformation of the solution to the master equation based on specific cohomological techniques. Under the hypotheses of smoothness in the coupling constant, locality, Lorentz covariance, and Poincare invariance of the interactions, supplemented with the requirement on the preservation of the number of derivatives on each field with respect to the free theory, we obtain that the deformation procedure modifies the Lagrangian action, the gauge transformations as well as the accompanying algebra. The interacting Lagrangian action contains a generalized version of non-Abelian Freedman-Townsend model. The consistency of interactions to all orders in the coupling constant unfolds certain equations, which are shown to have solutions.  ", "human_text": "  Consistent interactions that can be added to a free, Abelian gauge theory comprising a finite collection of BF models and a finite set of two-form gauge fields (with the Lagrangian action written in first-order form as a sum of Abelian Freedman-Townsend models) are constructed from the deformation of the solution to the master equation based on specific cohomological techniques. Under the hypotheses of smoothness in the coupling constant, locality, Lorentz covariance, and Poincare invariance of the interactions, supplemented with the requirement on the preservation of the number of derivatives on each field with respect to the free theory, we obtain that the deformation procedure modifies the Lagrangian action, the gauge transformations as well as the accompanying algebra. The interacting Lagrangian action contains a generalized version of non-Abelian Freedman-Townsend model. The consistency of interactions to all orders in the coupling constant unfolds certain equations, which are shown to have solutions. ", "machine_text": " This paper explores the construction and effects of consistent interactions added to a free, Abelian gauge theory including a finite number of BF models and two-form gauge fields. Using specific cohomological tools such as the master equation and its solution, the hypothesis of smooth coupling constants, locality, Lorentz covariance, Poincare invariance, and the maintenance of the same amount of derivatives with respect to the free theory allows us to create the resulting generalized non-Abelian Freedman-Townsend model, and thereby generate expressions of the corresponding deformed Lagrangian action, gauge transformations, and related algebra. Additionally, consistency conditions of the interactions in each successive power of the coupling constant are achieved by obtaining solutions to a set of equations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3407}
{"prompt": "Rephrase the abstract of an article with title 'Self-Similar Evolution of Cosmic-Ray-Modified Quasi-Parallel Plane   Shocks'.   Using an improved version of the previously introduced CRASH (Cosmic Ray Acceleration SHock) code, we have calculated the time evolution of cosmic-ray (CR) modified quasi-parallel plane shocks for Bohm-like diffusion, including self-consistent models of Alfven wave drift and dissipation, along with thermal leakage injection of CRs. The new simulations follow evolution of the CR distribution to much higher energies than our previous study, providing a better examination of evolutionary and asymptotic behaviors. The postshock CR pressure becomes constant after quick initial adjustment, since the evolution of the CR partial pressure expressed in terms of a momentum similarity variable is self-similar. The shock precursor, which scales as the diffusion length of the highest energy CRs, subsequently broadens approximately linearly with time, independent of diffusion model, so long as CRs continue to be accelerated to ever-higher energies. This means the nonlinear shock structure can be described approximately in terms of the similarity variable, x/(u_s t), where u_s is the shock speed once the postshock pressure reaches an approximate time asymptotic state. As before, the shock Mach number is the key parameter determining the evolution and the CR acceleration efficiency, although finite Alfven wave drift and wave energy dissipation in the shock precursor reduce the effective velocity change experienced by CRs, so reduce acceleration efficiency noticeably, thus, providing a second important parameter at low and moderate Mach numbers.  ", "human_text": "  Using an improved version of the previously introduced CRASH (Cosmic Ray Acceleration SHock) code, we have calculated the time evolution of cosmic-ray (CR) modified quasi-parallel plane shocks for Bohm-like diffusion, including self-consistent models of Alfven wave drift and dissipation, along with thermal leakage injection of CRs. The new simulations follow evolution of the CR distribution to much higher energies than our previous study, providing a better examination of evolutionary and asymptotic behaviors. The postshock CR pressure becomes constant after quick initial adjustment, since the evolution of the CR partial pressure expressed in terms of a momentum similarity variable is self-similar. The shock precursor, which scales as the diffusion length of the highest energy CRs, subsequently broadens approximately linearly with time, independent of diffusion model, so long as CRs continue to be accelerated to ever-higher energies. This means the nonlinear shock structure can be described approximately in terms of the similarity variable, x/(u_s t), where u_s is the shock speed once the postshock pressure reaches an approximate time asymptotic state. As before, the shock Mach number is the key parameter determining the evolution and the CR acceleration efficiency, although finite Alfven wave drift and wave energy dissipation in the shock precursor reduce the effective velocity change experienced by CRs, so reduce acceleration efficiency noticeably, thus, providing a second important parameter at low and moderate Mach numbers. ", "machine_text": " In this study, an improved version of the Cosmic Ray Acceleration SHock (CRASH) model has been used to investigate the progression of cosmic-ray (CR) affected quasi-parallel plane shocks. This new version entails an incorporated modeling of Alfven wave drift and dissipation, together with thermal leakage injection of CRs and further analysis of the CR distribution unto much higher energies than that of earlier studies. The results revealed that the pressure exerted by the postshock CR reaches a static state after a brief preliminary period of adjustment and the shock precursor expands incrementally over time, with no reliance on the diffusion model employed so long as CRs continue to be propelled up to higher energies. It was also established that the scale of the nonlinear shock structure can be familiarly represented in terms of the similarity variable (x/(u_s t)), which is contingent on the shock speed and with the Mach number serving as the paramount determinant for shock development and acceleration efficiency. The velocity change created by Alfven wave drift and wave energy dissipation in the precursor, however, lessens the CR optimization noticeably.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3274}
{"prompt": "Rephrase the abstract of an article with title 'CCD BV survey of 42 open clusters'.   We present results of a photometric survey whose aim was to derive structural and astrophysical parameters for 42 open clusters. While our sample is definitively not representative of the total open cluster sample in the Galaxy, it does cover a wide range of cluster parameters and is uniform enough to allow for simple statistical considerations. BV wide-field CCD photometry was obtained for open clusters for which photometric, structural, and dynamical evolution parameters were determined. The limiting and core radii were determined by analyzing radial density profiles. The ages, reddenings, and distances were obtained from the solar metallicity isochrone fitting. The mass function was used to study the dynamical state of the systems, mass segregation effect and to estimate the total mass and number of cluster members. This study reports on the first determination of basic parameters for 11 out of 42 observed open clusters. The angular sizes for the majority of the observed clusters appear to be several times larger than the catalogue data indicate. The core and limiting cluster radii are correlated and the latter parameter is 3.2 times larger on average. The limiting radius increases with the cluster's mass, and both the limiting and core radii decrease in the course of dynamical evolution. For dynamically not advanced clusters, the mass function slope is similar to the universal IMF slope. For more evolved systems, the effect of evaporation of low-mass members is clearly visible. The initial mass segregation is present in all the observed young clusters, whereas the dynamical mass segregation appears in clusters older than about log(age)=8. Low-mass stars are deficient in the cores of clusters older than log(age)=8.5 and not younger than one relaxation time.  ", "human_text": "  We present results of a photometric survey whose aim was to derive structural and astrophysical parameters for 42 open clusters. While our sample is definitively not representative of the total open cluster sample in the Galaxy, it does cover a wide range of cluster parameters and is uniform enough to allow for simple statistical considerations. BV wide-field CCD photometry was obtained for open clusters for which photometric, structural, and dynamical evolution parameters were determined. The limiting and core radii were determined by analyzing radial density profiles. The ages, reddenings, and distances were obtained from the solar metallicity isochrone fitting. The mass function was used to study the dynamical state of the systems, mass segregation effect and to estimate the total mass and number of cluster members. This study reports on the first determination of basic parameters for 11 out of 42 observed open clusters. The angular sizes for the majority of the observed clusters appear to be several times larger than the catalogue data indicate. The core and limiting cluster radii are correlated and the latter parameter is 3.2 times larger on average. The limiting radius increases with the cluster's mass, and both the limiting and core radii decrease in the course of dynamical evolution. For dynamically not advanced clusters, the mass function slope is similar to the universal IMF slope. For more evolved systems, the effect of evaporation of low-mass members is clearly visible. The initial mass segregation is present in all the observed young clusters, whereas the dynamical mass segregation appears in clusters older than about log(age)=8. Low-mass stars are deficient in the cores of clusters older than log(age)=8.5 and not younger than one relaxation time. ", "machine_text": " In this study, we examine 42 open clusters by utilizing wide-field CCD photometry in the BV filter to observe their vivid characteristics. To estimate the clusters' structure and astrophysical parameters, we develop radial density profiles, as well as fitting solar metallicity isochrones to determine the age, reddening, and distance of each. Additionally, we examine the mass function in order to analyze any dynamical state effects, mass segregation, and the total mass and membership in the clusters. We report basic findings for 11 of the 42 open clusters, observing that the angular sizes of the majority of the clusters were 3.2 times larger than the catalogue data indicated, as well as a correlation between the core and limiting radii that increased with the cluster's mass. Furthermore, we see evidence of initial mass segregation in all of the young clusters and dynamical mass segregation in clusters older than approximately 8.5 in log(age) after not less than one relaxation time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1364}
{"prompt": "Rephrase the abstract of an article with title 'Low-dimensional Supersymmetric Lattice Models'.   We study and simulate N=2 supersymmetric Wess-Zumino models in one and two dimensions. For any choice of the lattice derivative, the theories can be made manifestly supersymmetric by adding appropriate improvement terms corresponding to discretizations of surface integrals. In one dimension, our simulations show that a model with the Wilson derivative and the Stratonovitch prescription for this discretization leads to far better results at finite lattice spacing than other models with Wilson fermions considered in the literature. In particular, we check that fermionic and bosonic masses coincide and the unbroken Ward identities are fulfilled to high accuracy. Equally good results for the effective masses can be obtained in a model with the SLAC derivative (even without improvement terms).   In two dimensions we introduce a non-standard Wilson term in such a way that the discretization errors of the kinetic terms are only of order O(a^2). Masses extracted from the corresponding manifestly supersymmetric model prove to approach their continuum values much quicker than those from a model containing the standard Wilson term. Again, a comparable enhancement can be achieved in a theory using the SLAC derivative.  ", "human_text": "  We study and simulate N=2 supersymmetric Wess-Zumino models in one and two dimensions. For any choice of the lattice derivative, the theories can be made manifestly supersymmetric by adding appropriate improvement terms corresponding to discretizations of surface integrals. In one dimension, our simulations show that a model with the Wilson derivative and the Stratonovitch prescription for this discretization leads to far better results at finite lattice spacing than other models with Wilson fermions considered in the literature. In particular, we check that fermionic and bosonic masses coincide and the unbroken Ward identities are fulfilled to high accuracy. Equally good results for the effective masses can be obtained in a model with the SLAC derivative (even without improvement terms).   In two dimensions we introduce a non-standard Wilson term in such a way that the discretization errors of the kinetic terms are only of order O(a^2). Masses extracted from the corresponding manifestly supersymmetric model prove to approach their continuum values much quicker than those from a model containing the standard Wilson term. Again, a comparable enhancement can be achieved in a theory using the SLAC derivative. ", "machine_text": " We carry out simulations with N=2 supersymmetric Wess-Zumino models in both one and two dimensions. We employ various lattice derivatives and add improvement terms to maintain supersymmetry. Our simulations in one dimension show that a model with the Wilson derivative and the Stratonovitch discretization gives superior results to any other model with Wilson fermions in the literature. We check that the fermionic and bosonic masses are equal and Ward identities are satisfied. In two dimensions, we introduce a modified Wilson term leading to discretization errors of order O(a^2). Our studies show that the masses gotten from the corresponding supersymmetric model approach their continuum values faster than those from a model with the standard Wilson term. We also observe a comparable increase in performance when employing the SLAC derivative.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2212}
{"prompt": "Rephrase the abstract of an article with title 'Physical properties of the jet in 0836+710 revealed by its transversal   structure'.   Studying the internal structure of extragalactic jets is crucial for understanding their physics. The Japanese-led space VLBI project VSOP has presented an opportunity for such studies, by reaching baseline lengths of up to 36,000 km and resolving structures down to an angular size of $\\approx 0.3$ mas at 5 GHz. VSOP observations of the jet in 0836+710 at 1.6 and 5 GHz have enabled tracing of the radial structure of the flow on scales from 2 mas to 200 mas along the jet and determination of the wavelengths of individual oscillatory modes responsible for the formation of the structure observed. We apply linear stability analysis to identify the oscillatory modes with modes of Kelvin-Helmholtz instability that match the wavelengths of the structures observed. We find that the jet structure in 0836+710 can be reproduced by the helical surface mode and a combination of the helical and elliptic body modes of Kelvin-Helmholtz instability. Our results indicate that the jet is substantially stratified and different modes of the instability grow inside the jet at different distances to the jet axis. The helical surface mode can be driven externally, and we discuss the implications of the driving frequency on the physics of the active nucleus in 0836+710.  ", "human_text": "  Studying the internal structure of extragalactic jets is crucial for understanding their physics. The Japanese-led space VLBI project VSOP has presented an opportunity for such studies, by reaching baseline lengths of up to 36,000 km and resolving structures down to an angular size of $\\approx 0.3$ mas at 5 GHz. VSOP observations of the jet in 0836+710 at 1.6 and 5 GHz have enabled tracing of the radial structure of the flow on scales from 2 mas to 200 mas along the jet and determination of the wavelengths of individual oscillatory modes responsible for the formation of the structure observed. We apply linear stability analysis to identify the oscillatory modes with modes of Kelvin-Helmholtz instability that match the wavelengths of the structures observed. We find that the jet structure in 0836+710 can be reproduced by the helical surface mode and a combination of the helical and elliptic body modes of Kelvin-Helmholtz instability. Our results indicate that the jet is substantially stratified and different modes of the instability grow inside the jet at different distances to the jet axis. The helical surface mode can be driven externally, and we discuss the implications of the driving frequency on the physics of the active nucleus in 0836+710. ", "machine_text": " This study used the Japanese-led VSOP space VLBI project, which extends baseline lengths up to 36,000 km and resolving structures to 0.3 mas, to investigate the transversal structure of extragalactic jet 0836+710 at 1.6 and 5 GHz. A linear stability analysis was applied to the data to identify which of the Kelvin-Helmholtz instabilities could explain the large-scale structures observed in this jet. Our results demonstrate that the stratified jet can be reproduced by both the helical surface and helical/elliptic body modes of instability, with the helical surface mode driving frequency delivering insights into the physics of the active nucleus.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0433}
{"prompt": "Rephrase the abstract of an article with title 'Chromatin Folding in Relation to Human Genome Function'.   Three-dimensional (3D) chromatin structure is closely related to genome function, in particular transcription. However, the folding path of the chromatin fiber in the interphase nucleus is unknown. Here, we systematically measured the 3D physical distance between pairwise labeled genomic positions in gene-dense, highly transcribed domains and gene-poor less active areas on chromosomes 1 and 11 in G1 nuclei of human primary fibroblasts, using fluorescence in situ hybridization. Interpretation of our results and those published by others, based on polymer physics, shows that the folding of the chromatin fiber can be described as a polymer in a globular state (GS), maintained by intra-polymer attractive interactions that counteract self-avoidance forces. The GS polymer model is able to describe chromatin folding in as well the highly expressed domains as the lowly expressed ones, indicating that they differ in Kuhn length and chromatin compaction. Each type of genomic domain constitutes an ensemble of relatively compact globular folding states, resulting in a considerable cellto- cell variation between otherwise identical cells. We present evidence for different polymer folding regimes of the chromatin fiber on the length scale of a few mega base pairs and on that of complete chromosome arms (several tens of Mb). Our results present a novel view on the folding of the chromatin fiber in interphase and open the possibility to explore the nature of the intra-chromatin fiber interactions.  ", "human_text": "  Three-dimensional (3D) chromatin structure is closely related to genome function, in particular transcription. However, the folding path of the chromatin fiber in the interphase nucleus is unknown. Here, we systematically measured the 3D physical distance between pairwise labeled genomic positions in gene-dense, highly transcribed domains and gene-poor less active areas on chromosomes 1 and 11 in G1 nuclei of human primary fibroblasts, using fluorescence in situ hybridization. Interpretation of our results and those published by others, based on polymer physics, shows that the folding of the chromatin fiber can be described as a polymer in a globular state (GS), maintained by intra-polymer attractive interactions that counteract self-avoidance forces. The GS polymer model is able to describe chromatin folding in as well the highly expressed domains as the lowly expressed ones, indicating that they differ in Kuhn length and chromatin compaction. Each type of genomic domain constitutes an ensemble of relatively compact globular folding states, resulting in a considerable cellto- cell variation between otherwise identical cells. We present evidence for different polymer folding regimes of the chromatin fiber on the length scale of a few mega base pairs and on that of complete chromosome arms (several tens of Mb). Our results present a novel view on the folding of the chromatin fiber in interphase and open the possibility to explore the nature of the intra-chromatin fiber interactions. ", "machine_text": " By utilizing fluorescence in situ hybridization, this article measured the 3D physical distance between specified genomic positions on chromosomes 1 and 11 of G1 cell nuclei found in human primary fibroblasts. Results, which are based off of polymer physics, demonstrate that chromatin folding is comparable to a polymer in a globular state. This globular state is regulated by attractive interactions which suppress the self-avoidance force exhibited by the chromatin. It was also determined that highly expressed and lowly expressed genomic domains differ regarding the Kuhn length and their chromatin compaction. This results in a range of compact globular folding states across cells. Furthermore, it was revealed that the folding of chromatin is seen on different length scales and can even apply to entire chromosome arms. Altogether, this article explores the intras chromatin fiber folding and provides novel insight into the folding of the chromatin fiber in interphase.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1656}
{"prompt": "Rephrase the abstract of an article with title 'Un Resultat Gravimetrique pour la Renaissance de la Theorie   Corpusculaire \"An Experimental Gravimetric Result for the Revival of   Corpuscular Theory\"'.   The gravitational phenomenon, founded on the assumption of absorption of a flux of gravitons through the matter, led to a law of attraction comprising a term of attenuation of gravity. The attenuation effect, which depends on the distribution of mass elements into the Sun, was compared with the relativistic effect for the orbital elements of planets. The calculations carried out with our modified law of Newton, lead to a perfect agreement for the advance of the perihelion of planets, and give an interaction cross section with the matter of 3.2x10^-17 m2/kg (approximately 10^-40 cm2/nucleon). The effect of attenuation during a solar eclipse will produce a local reduction in the soli-lunar attraction of 0.13 microgal. This small variation of gravity during the eclipse can lead to distortions of the geoid of about ten millimetres of which effect on gravity, estimated at a few microgals, is compatible with the observed gravitational anomalies. The gravimetric measurements taken in the area of Montreal during the Sun eclipse of May 10, 1994, show the existence of an anomaly of 2.4 microgals that coincides perfectly with the period of the eclipse.  ", "human_text": "  The gravitational phenomenon, founded on the assumption of absorption of a flux of gravitons through the matter, led to a law of attraction comprising a term of attenuation of gravity. The attenuation effect, which depends on the distribution of mass elements into the Sun, was compared with the relativistic effect for the orbital elements of planets. The calculations carried out with our modified law of Newton, lead to a perfect agreement for the advance of the perihelion of planets, and give an interaction cross section with the matter of 3.2x10^-17 m2/kg (approximately 10^-40 cm2/nucleon). The effect of attenuation during a solar eclipse will produce a local reduction in the soli-lunar attraction of 0.13 microgal. This small variation of gravity during the eclipse can lead to distortions of the geoid of about ten millimetres of which effect on gravity, estimated at a few microgals, is compatible with the observed gravitational anomalies. The gravimetric measurements taken in the area of Montreal during the Sun eclipse of May 10, 1994, show the existence of an anomaly of 2.4 microgals that coincides perfectly with the period of the eclipse. ", "machine_text": " By utilizing the moderated version of Newton's Law of Attraction, with an assumption wherein a flux of gravitons pass through matter, a term describing the attenuation of gravity was observed. This permitted a comparison between the relativistic orbital elements of planets and the observed mass distribution of the Sun. Therein, the findings created an interactions cross section of 3.2x10^-17 m2/kg (nearly 10^-40 cm2/ nucleon) and produced a diminutive variation of gravity during a solar eclipse; estimated at 0.13 microgals. Subsequent analysis elucidated the ways in which this minor adjustments could impact the geoid - evidenced by anticipated deformation of the visage of gravity at around ten millimetres. Moreover, the results of measurements taken in the district encompassing Montreal during the Sun eclipse of May 10, 1994, displayed an anomaly of 2.4 microgals that corroborated exactly with the duration of the eclipse. This serves to corroborate the applicability and success of the corpuscular theory postulated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2581}
{"prompt": "Rephrase the abstract of an article with title 'Line and Mean Opacities for Ultracool Dwarfs and Extrasolar Planets'.   Opacities and chemical abundance data are crucial ingredients of ultracool dwarf and extrasolar giant planet atmosphere models. We report here on the detailed sources of molecular opacity data employed by our group for this application. We also present tables of Rosseland and Planck mean opacities which are of use in some studies of the atmospheres, interiors, and evolution of planets and brown dwarfs. For the tables presented here we have included the opacities of important atomic and molecular species, including the alkali elements, pressure induced absorption by hydrogen, and other significant opacity sources but neglect opacity from condensates. We report for each species how we have assembled molecular line data from a combination of public databases, laboratory data that is not yet in the public databases, and our own numerical calculations. We combine these opacities with abundances computed from a chemical equilibrium model using recently revised solar abundances to compute mean opacities. The chemical equilibrium calculation accounts for the settling of condensates in a gravitational field, and is applicable to ultracool dwarf and extrasolar planetary atmospheres, but not circumstellar disks. We find that the inclusion of alkali atomic opacity substantially increases the mean opacities over those currently in the literature at densities relevant to the atmospheres and interiors of giant planets and brown dwarfs. We provide our opacity tables for public use and discuss their limitations.  ", "human_text": "  Opacities and chemical abundance data are crucial ingredients of ultracool dwarf and extrasolar giant planet atmosphere models. We report here on the detailed sources of molecular opacity data employed by our group for this application. We also present tables of Rosseland and Planck mean opacities which are of use in some studies of the atmospheres, interiors, and evolution of planets and brown dwarfs. For the tables presented here we have included the opacities of important atomic and molecular species, including the alkali elements, pressure induced absorption by hydrogen, and other significant opacity sources but neglect opacity from condensates. We report for each species how we have assembled molecular line data from a combination of public databases, laboratory data that is not yet in the public databases, and our own numerical calculations. We combine these opacities with abundances computed from a chemical equilibrium model using recently revised solar abundances to compute mean opacities. The chemical equilibrium calculation accounts for the settling of condensates in a gravitational field, and is applicable to ultracool dwarf and extrasolar planetary atmospheres, but not circumstellar disks. We find that the inclusion of alkali atomic opacity substantially increases the mean opacities over those currently in the literature at densities relevant to the atmospheres and interiors of giant planets and brown dwarfs. We provide our opacity tables for public use and discuss their limitations. ", "machine_text": " In this paper, we examine the sources of molecular line and mean opacity data utilized when modeling ultracool dwarf and extrasolar planet atmospheres. We additionally provide tables containing the Rosseland and Planck mean opacities, which can be useful for studying the atmospheres, interiors, and evolution of these celestial bodies. The molecular opacities for these models are generated from both publicly available databases, laboratory measurements, and computed values, while elemental abundances used in the mean opacity calculation are computed from a chemical equilibrium model with recently updated solar abundances. We also observe that the opacities of atomic and molecular alkali elements boost mean opacities significantly when applicable to densities of planets\u2019 and brown dwarf atmospheres and interiors. Our resulting opacity tables are publicized and their limitations discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2374}
{"prompt": "Rephrase the abstract of an article with title 'The Elongated Structure of the Hercules dSph from Deep LBT Imaging'.   We present a deep, wide-field photometric survey of the newly-discovered Hercules dwarf spheroidal galaxy, based on data from the Large Binocular Telescope. Images in B, V and r were obtained with the Large Binocular Camera covering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This permitted the construction of colour-magnitude diagrams that reach approximately 1.5 magnitudes below the Hercules main sequence turnoff. Three-filter photometry allowed us to preferentially select probable Hercules member stars, and examine the structure of this system at a previously unattained level. We find that the Hercules dwarf is highly elongated (3:1), considerably more so than any other dSph satellite of the Milky Way except the disrupting Sagittarius dwarf. While we cannot rule out that the unusual structure is intrinsic to Hercules as an equilibrium system, our results suggest tidal disruption as a likely cause of this highly elliptical structure. Given the relatively large Galactocentric distance of this system (132 +/- 12 kpc), signs of tidal disruption would require the Hercules dwarf to be on a highly eccentric orbit around the Milky Way.  ", "human_text": "  We present a deep, wide-field photometric survey of the newly-discovered Hercules dwarf spheroidal galaxy, based on data from the Large Binocular Telescope. Images in B, V and r were obtained with the Large Binocular Camera covering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This permitted the construction of colour-magnitude diagrams that reach approximately 1.5 magnitudes below the Hercules main sequence turnoff. Three-filter photometry allowed us to preferentially select probable Hercules member stars, and examine the structure of this system at a previously unattained level. We find that the Hercules dwarf is highly elongated (3:1), considerably more so than any other dSph satellite of the Milky Way except the disrupting Sagittarius dwarf. While we cannot rule out that the unusual structure is intrinsic to Hercules as an equilibrium system, our results suggest tidal disruption as a likely cause of this highly elliptical structure. Given the relatively large Galactocentric distance of this system (132 +/- 12 kpc), signs of tidal disruption would require the Hercules dwarf to be on a highly eccentric orbit around the Milky Way. ", "machine_text": " Using high-quality images from the Large Binocular Telescope, we conducted a deep and wide-field photometric survey of the newly-found Hercules dwarf spheroidal galaxy. By mapping a 23' times 23' field, our three-filter photometry revealed colour-magnitude diagrams that extended down to around 1.5 magnitudes below the main sequence turnoff of the Hercules dwarf. Our analysis allowed us to accurately select likely Hercules members and observe the structure of the system at an unprecedented scale. Strikingly, we discovered that compared to other dwarf spheroidal satellite galaxies of the Milky Way, the Hercules dwarf exhibits an extremely elongated shape (3:1). We suggest that its unusual shape is likely due to tidally disruptive forces, being at a relatively high distance from the centre of the Milky Way. This would indicate that the Hercules dwarf is on an eccentric orbit around the Milky Way.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1669}
{"prompt": "Rephrase the abstract of an article with title 'Search for Heavy Neutral MSSM Higgs Bosons with CMS: Reach and   Higgs-Mass Precision'.   The search for MSSM Higgs bosons will be an important goal at the LHC. We analyze the search reach of the CMS experiment for the heavy neutral MSSM Higgs bosons with an integrated luminosity of 30 or 60 fb^-1. This is done by combining the latest results for the CMS experimental sensitivities based on full simulation studies with state-of-the-art theoretical predictions of MSSM Higgs-boson properties. The results are interpreted in MSSM benchmark scenarios in terms of the parameters tan_beta and the Higgs-boson mass scale, M_A. We study the dependence of the 5 sigma discovery contours in the M_A-tan_beta plane on variations of the other supersymmetric parameters. The largest effects arise from a change in the higgsino mass parameter mu, which enters both via higher-order radiative corrections and via the kinematics of Higgs decays into supersymmetric particles. While the variation of $\\mu$ can shift the prospective discovery reach (and correspondingly the ``LHC wedge'' region) by about Delta tan_beta = 10, we find that the discovery reach is rather stable with respect to the impact of other supersymmetric parameters. Within the discovery region we analyze the accuracy with which the masses of the heavy neutral Higgs bosons can be determined. We find that an accuracy of 1-4% should be achievable, which could make it possible in favourable regions of the MSSM parameter space to experimentally resolve the signals of the two heavy MSSM Higgs bosons at the LHC.  ", "human_text": "  The search for MSSM Higgs bosons will be an important goal at the LHC. We analyze the search reach of the CMS experiment for the heavy neutral MSSM Higgs bosons with an integrated luminosity of 30 or 60 fb^-1. This is done by combining the latest results for the CMS experimental sensitivities based on full simulation studies with state-of-the-art theoretical predictions of MSSM Higgs-boson properties. The results are interpreted in MSSM benchmark scenarios in terms of the parameters tan_beta and the Higgs-boson mass scale, M_A. We study the dependence of the 5 sigma discovery contours in the M_A-tan_beta plane on variations of the other supersymmetric parameters. The largest effects arise from a change in the higgsino mass parameter mu, which enters both via higher-order radiative corrections and via the kinematics of Higgs decays into supersymmetric particles. While the variation of $\\mu$ can shift the prospective discovery reach (and correspondingly the ``LHC wedge'' region) by about Delta tan_beta = 10, we find that the discovery reach is rather stable with respect to the impact of other supersymmetric parameters. Within the discovery region we analyze the accuracy with which the masses of the heavy neutral Higgs bosons can be determined. We find that an accuracy of 1-4% should be achievable, which could make it possible in favourable regions of the MSSM parameter space to experimentally resolve the signals of the two heavy MSSM Higgs bosons at the LHC. ", "machine_text": "  An exploration of MSSM heavy neutral Higgs bosons is presented based on the CMS experiment with integrated luminosity of 30 and 60 fb$^{-1}$. Utilizing both the latest experimental sensitivity studies and theoretical predictions of MSSM Higgs-boson characteristics, the search capability is interpreted in terms of the parameters tan$\\beta$ and M$_A$. Examination of the 5 sigma discovery contours with respect to varying other supersymmetric parameters shows that a change in the higgsino mass parameter $\\mu$ can alter the prospective discovery reach (the \"LHC wedge\" region) by around 10 Delta tan$\\beta$. Furthermore, a high-precision measurement of the heavy neutral Higgs boson masses may be feasible and potentially help detect the signals of the two heavy MSSM Higgs bosons at the LHC in favourable regions of the MSSM parameter space.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0619}
{"prompt": "Rephrase the abstract of an article with title 'A de Haas-van Alphen study of the filled skutterudite compounds   PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$'.   Comprehensive magnetic-field-orientation dependent studies of the susceptibility and de Haas-van Alphen effect have been carried out on single crystals of the filled skutterudites PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$ using magnetic fields of up to 40~T. Several peaks are observed in the low-field susceptibility of PrOs$_4$As$_{12}$, corresponding to cascades of metamagnetic transitions separating the low-field antiferromagnetic and high-field paramagnetic metal (PMM) phases. The de Haas-van Alphen experiments show that the Fermi-surface topologies of PrOs$_4$As$_{12}$ in its PMM phase and LaOs$_4$As$_{12}$ are very similar. In addition, they are in reasonable agreement with the predictions of bandstructure calculations for LaOs$_4$As$_{12}$ on the PrOs$_4$As$_{12}$ lattice. Both observations suggest that the Pr 4$f$ electrons contribute little to the number of itinerant quasiparticles in the PMM phase. However, whilst the properties of LaOs$_4$As$_{12}$ suggest a conventional nonmagnetic Fermi liquid, the effects of direct exchange and electron correlations are detected in the PMM phase of PrOs$_4$As$_{12}$. For example, the quasiparticle effective masses in PrOs$_4$As$_{12}$ are found to decrease with increasing field, probably reflecting the gradual suppression of magnetic fluctuations associated with proximity to the low-temperature, low-field antiferromagnetic state.  ", "human_text": "  Comprehensive magnetic-field-orientation dependent studies of the susceptibility and de Haas-van Alphen effect have been carried out on single crystals of the filled skutterudites PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$ using magnetic fields of up to 40~T. Several peaks are observed in the low-field susceptibility of PrOs$_4$As$_{12}$, corresponding to cascades of metamagnetic transitions separating the low-field antiferromagnetic and high-field paramagnetic metal (PMM) phases. The de Haas-van Alphen experiments show that the Fermi-surface topologies of PrOs$_4$As$_{12}$ in its PMM phase and LaOs$_4$As$_{12}$ are very similar. In addition, they are in reasonable agreement with the predictions of bandstructure calculations for LaOs$_4$As$_{12}$ on the PrOs$_4$As$_{12}$ lattice. Both observations suggest that the Pr 4$f$ electrons contribute little to the number of itinerant quasiparticles in the PMM phase. However, whilst the properties of LaOs$_4$As$_{12}$ suggest a conventional nonmagnetic Fermi liquid, the effects of direct exchange and electron correlations are detected in the PMM phase of PrOs$_4$As$_{12}$. For example, the quasiparticle effective masses in PrOs$_4$As$_{12}$ are found to decrease with increasing field, probably reflecting the gradual suppression of magnetic fluctuations associated with proximity to the low-temperature, low-field antiferromagnetic state. ", "machine_text": " The properties of the filled skutterudite compounds PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$ were investigated by employing magnetic field-orientation dependent susceptibility and de Haas-van Alphen measurements up to 40 T. Distinctive peaks in the susceptibility of PrOs$_4$As$_{12}$, which could be ascribed to metamagnetic transitions, divided the low-field antiferromagnetic and high-field paramagnetic metal phases. The de Haas-van Alphen experiments further indicated a remarkable likeness in Fermi-surface topology between PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}, as well as moderate congruence between measured and bandstructure-calculated values for the lattice of PrOs$_4$As$_{12}. These findings suggest that the 4f electrons of PrOs$_4$As$_{12}$ are not significant to itinerant quasiparticle profile, while LaOs$_4$As$_{12} is more typical of a nonmagnetic Fermi-liquid. Additionally, PrOs$_4$As$_{12} showed specific behaviors of effectual masses, ascribed to the suppression of magnetic fluctuations near its antiferromagnetic behavior.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2767}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical Friction of a Circular-Orbit Perturber in a Gaseous Medium'.   We investigate the gravitational wake due to, and dynamical friction on, a perturber moving on a circular orbit in a uniform gaseous medium using a semi-analytic method. This work is a straightforward extension of Ostriker (1999) who studied the case of a straight-line trajectory. The circular orbit causes the bending of the wake in the background medium along the orbit, forming a long trailing tail. The wake distribution is thus asymmetric, giving rise to the drag forces in both opposite (azimuthal) and lateral (radial) directions to the motion of the perturber, although the latter does not contribute to orbital decay much. For subsonic motion, the density wake with a weak tail is simply a curved version of that in Ostriker and does not exhibit the front-back symmetry. The resulting drag force in the opposite direction is remarkably similar to the finite-time, linear-trajectory counterpart. On the other hand, a supersonic perturber is able to overtake its own wake, possibly multiple times, and develops a very pronounced tail. The supersonic tail surrounds the perturber in a trailing spiral fashion, enhancing the perturbed density at the back as well as far front of the perturber. We provide the fitting formulae for the drag forces as functions of the Mach number, whose azimuthal part is surprisingly in good agreement with the Ostriker's formula, provided Vp t=2 Rp, where Vp and Rp are the velocity and orbital radius of the perturber, respectively.  ", "human_text": "  We investigate the gravitational wake due to, and dynamical friction on, a perturber moving on a circular orbit in a uniform gaseous medium using a semi-analytic method. This work is a straightforward extension of Ostriker (1999) who studied the case of a straight-line trajectory. The circular orbit causes the bending of the wake in the background medium along the orbit, forming a long trailing tail. The wake distribution is thus asymmetric, giving rise to the drag forces in both opposite (azimuthal) and lateral (radial) directions to the motion of the perturber, although the latter does not contribute to orbital decay much. For subsonic motion, the density wake with a weak tail is simply a curved version of that in Ostriker and does not exhibit the front-back symmetry. The resulting drag force in the opposite direction is remarkably similar to the finite-time, linear-trajectory counterpart. On the other hand, a supersonic perturber is able to overtake its own wake, possibly multiple times, and develops a very pronounced tail. The supersonic tail surrounds the perturber in a trailing spiral fashion, enhancing the perturbed density at the back as well as far front of the perturber. We provide the fitting formulae for the drag forces as functions of the Mach number, whose azimuthal part is surprisingly in good agreement with the Ostriker's formula, provided Vp t=2 Rp, where Vp and Rp are the velocity and orbital radius of the perturber, respectively. ", "machine_text": "  We explore the changes that occur to the gravitational wake, and ensuing dynamical friction, of a circular-orbiting perturber when moving through a uniform gaseous medium. This research follows-up on the findings of Ostriker (1999) who studied the motion of a perturber via a straight-line pathway. The dynamic effects of a circular orbit are considerable and manifest in the formation of a trailing tail, caused by the curved wake that is pushed through the gaseous medium. This asymmetry imparts angular forces in both directions of the perturber's motion and, although radial forces are not significant as far as orbital decay, there are still observable effects on the density wake. When experiencing subsonic motions, for example, the density wake takes on a curved shape, unique from Ostriker's findings, and the dynamical friction is nearly identical to that of a linear trajectory. Even more distinct, when the perturber surpasses the speed of sound, it has the potential to overtake the wake multiple times; consequentially forming a trailing spiral around the perturber, and consequently increasing the perturbed density both in the front and back of the perturber. We find a general agreement between the formulas for the drag forces as a function of the Mach number, as well as with Ostriker's model, when Vp t=2 Rp, where Vp and Rp refer to the velocity and orbital radius of the perturber, respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0084}
{"prompt": "Rephrase the abstract of an article with title 'Maximally Supersymmetric Planar Yang-Mills Amplitudes at Five Loops'.   We present an ansatz for the planar five-loop four-point amplitude in maximally supersymmetric Yang-Mills theory in terms of loop integrals. This ansatz exploits the recently observed correspondence between integrals with simple conformal properties and those found in the four-point amplitudes of the theory through four loops. We explain how to identify all such integrals systematically. We make use of generalized unitarity in both four and D dimensions to determine the coefficients of each of these integrals in the amplitude. Maximal cuts, in which we cut all propagators of a given integral, are an especially effective means for determining these coefficients. The set of integrals and coefficients determined here will be useful for computing the five-loop cusp anomalous dimension of the theory which is of interest for non-trivial checks of the AdS/CFT duality conjecture. It will also be useful for checking a conjecture that the amplitudes have an iterative structure allowing for their all-loop resummation, whose link to a recent string-side computation by Alday and Maldacena opens a new venue for quantitative AdS/CFT comparisons.  ", "human_text": "  We present an ansatz for the planar five-loop four-point amplitude in maximally supersymmetric Yang-Mills theory in terms of loop integrals. This ansatz exploits the recently observed correspondence between integrals with simple conformal properties and those found in the four-point amplitudes of the theory through four loops. We explain how to identify all such integrals systematically. We make use of generalized unitarity in both four and D dimensions to determine the coefficients of each of these integrals in the amplitude. Maximal cuts, in which we cut all propagators of a given integral, are an especially effective means for determining these coefficients. The set of integrals and coefficients determined here will be useful for computing the five-loop cusp anomalous dimension of the theory which is of interest for non-trivial checks of the AdS/CFT duality conjecture. It will also be useful for checking a conjecture that the amplitudes have an iterative structure allowing for their all-loop resummation, whose link to a recent string-side computation by Alday and Maldacena opens a new venue for quantitative AdS/CFT comparisons. ", "machine_text": " We provide an estimate of the four-point amplitude in maximally supersymmetric Yang-Mills theory at five loops, making use of the correspondence between integrals of simple conformal properties and the four-point amplitudes from the theory at four loops. Detailed steps to identify the mentioned integrals have been outlined. We employ both four- and D-dimensional generalized unitarity to figure out the coefficients of each integral in the amplitude. Maximal cuts have been utilized effectively to accurately determine the coefficients. This set of integrals and coefficients will help to calculate the cusp anomalous dimension at five-loops, and shall be instrumental in verifying the validity of the AdS/CFT duality conjecture. Moreover, it will support a conjecture that the amplitudes possess an iterative structure which will contribute to the all-loop resummation and facilitate the comparison between the string-side computation by Alday and Maldacena and the amplitudes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1864}
{"prompt": "Rephrase the abstract of an article with title 'Spin relaxation due to the Bir-Aronov-Pikus mechanism in intrinsic and   $p$-type GaAs quantum wells from a fully microscopic approach'.   We study the electron spin relaxation in intrinsic and $p$-type (001) GaAs quantum wells by constructing and numerically solving the kinetic spin Bloch equations. All the relevant scatterings are explicitly included, especially the spin-flip electron-heavy hole exchange scattering which leads to the Bir-Aronov-Pikus spin relaxation. We show that, due to the neglection of the nonlinear terms in the electron-heavy hole exchange scattering in the Fermi-golden-rule approach, the spin relaxation due to the Bir-Aronov-Pikus mechanism is greatly exaggerated at moderately high electron density and low temperature in the literature. We compare the spin relaxation time due to the Bir-Aronov-Pikus mechanism with that due to the D'yakonov-Perel' mechanism which is also calculated from the kinetic spin Bloch equations with all the scatterings, especially the spin-conserving electron-electron and electron-heavy hole scatterings, included. We find that, in intrinsic quantum wells, the effect from the Bir-Aronov-Pikus mechanism is much smaller than that from the D'yakonov-Perel' mechanism at low temperature, and it is smaller by no more than one order of magnitude at high temperature. In $p$-type quantum wells, the spin relaxation due to the Bir-Aronov-Pikus mechanism is also much smaller than the one due to the D'yakonov-Perel' mechanism at low temperature and becomes comparable to each other at higher temperature when the hole density and the width of the quantum well are large enough. We claim that unlike in the bulk samples, the Bir-Aronov-Pikus mechanism hardly dominates the spin relaxation in two-dimensional samples.  ", "human_text": "  We study the electron spin relaxation in intrinsic and $p$-type (001) GaAs quantum wells by constructing and numerically solving the kinetic spin Bloch equations. All the relevant scatterings are explicitly included, especially the spin-flip electron-heavy hole exchange scattering which leads to the Bir-Aronov-Pikus spin relaxation. We show that, due to the neglection of the nonlinear terms in the electron-heavy hole exchange scattering in the Fermi-golden-rule approach, the spin relaxation due to the Bir-Aronov-Pikus mechanism is greatly exaggerated at moderately high electron density and low temperature in the literature. We compare the spin relaxation time due to the Bir-Aronov-Pikus mechanism with that due to the D'yakonov-Perel' mechanism which is also calculated from the kinetic spin Bloch equations with all the scatterings, especially the spin-conserving electron-electron and electron-heavy hole scatterings, included. We find that, in intrinsic quantum wells, the effect from the Bir-Aronov-Pikus mechanism is much smaller than that from the D'yakonov-Perel' mechanism at low temperature, and it is smaller by no more than one order of magnitude at high temperature. In $p$-type quantum wells, the spin relaxation due to the Bir-Aronov-Pikus mechanism is also much smaller than the one due to the D'yakonov-Perel' mechanism at low temperature and becomes comparable to each other at higher temperature when the hole density and the width of the quantum well are large enough. We claim that unlike in the bulk samples, the Bir-Aronov-Pikus mechanism hardly dominates the spin relaxation in two-dimensional samples. ", "machine_text": "We investigate the spin relaxation of electrons in (001) GaAs quantum wells, both intrinsic and $p$-type, by numerically solving the kinetic spin Bloch equations with all the relevant scatterings accounted for. In particular, the electron-heavy hole exchange scattering, which leads to the Bir-Aronov-Pikus spin relaxation, is explicitly included. Our calculations indicate that, if we limit our analyses to the Fermi-golden-rule approach and neglect the nonlinear terms, the spin relaxation due to the Bir-Aronov-Pikus mechanism will be greatly overestimated at moderate electron density and low temperature. We also study the spin relaxation time due to the D'yakonov-Perel' mechanism and compare it with the one arising from the Bir-Aronov-Pikus mechanism. Our results demonstrate that in intrinsic quantum wells, the effect of the Bir-Aronov-Pikus mechanism is much smaller than that of the D'yakonov-Perel' mechanism at low temperature and is no more than one order of magnitude higher at high temperature. In $p$-type quantum wells, the spin relaxation due to Bir-Aronov-Pikus mechanism is much lower than that of the D'yakonov-Perel' mechanism at low temperature, but can become comparable when the hole density and quantum well width are big enough. Thus, contrary to the situation in bulk samples, the Bir-Aronov-Pikus mechanism is not expected to generally dominate the spin relaxation of two-dimensional systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0216}
{"prompt": "Rephrase the abstract of an article with title 'Bond formation and slow heterogeneous dynamics in adhesive spheres with   long--ranged repulsion: Quantitative test of Mode Coupling Theory'.   A colloidal system of spheres interacting with both a deep and narrow attractive potential and a shallow long-ranged barrier exhibits a prepeak in the static structure factor. This peak can be related to an additional mesoscopic length scale of clusters and/or voids in the system. Simulation studies of this system have revealed that it vitrifies upon increasing the attraction into a gel-like solid at intermediate densities. The dynamics at the mesoscopic length scale corresponding to the prepeak represents the slowest mode in the system. Using mode coupling theory with all input directly taken from simulations, we reveal the mechanism for glassy arrest in the system at 40% packing fraction. The effects of the low-q peak and of polydispersity are considered in detail. We demonstrate that the local formation of physical bonds is the process whose slowing down causes arrest.   It remains largely unaffected by the large-scale heterogeneities, and sets the clock for the slow cluster mode. Results from mode-coupling theory without adjustable parameters agree semi-quantitatively with the local density correlators but overestimate the lifetime of the mesoscopic structure (voids).  ", "human_text": "  A colloidal system of spheres interacting with both a deep and narrow attractive potential and a shallow long-ranged barrier exhibits a prepeak in the static structure factor. This peak can be related to an additional mesoscopic length scale of clusters and/or voids in the system. Simulation studies of this system have revealed that it vitrifies upon increasing the attraction into a gel-like solid at intermediate densities. The dynamics at the mesoscopic length scale corresponding to the prepeak represents the slowest mode in the system. Using mode coupling theory with all input directly taken from simulations, we reveal the mechanism for glassy arrest in the system at 40% packing fraction. The effects of the low-q peak and of polydispersity are considered in detail. We demonstrate that the local formation of physical bonds is the process whose slowing down causes arrest.   It remains largely unaffected by the large-scale heterogeneities, and sets the clock for the slow cluster mode. Results from mode-coupling theory without adjustable parameters agree semi-quantitatively with the local density correlators but overestimate the lifetime of the mesoscopic structure (voids). ", "machine_text": " Simulation studies of a colloidal system of spheres interacting with a deep and narrow attractive potential and a shallow long-ranged barrier have uncovered a prepeak in the static structure factor, suggesting the presence of a mesoscopic length scale of clusters and/or voids. Our analysis using mode coupling theory, without adjustable parameters and taking all input directly from simulations, reveals the mechanism of glassy arrest at 40% packing fraction of the system. We found that the local formation of physical bonds determines the slowing down that causes arrest, suggesting an important role of the low-q peak in the glassy transition. Furthermore, our results demonstrate that the lifetime of the mesoscopic structure (voids) is overestimated by mode-coupling theory, remaining largely unaffected by large-scale heterogeneities and setting the clock for the slow cluster mode.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0637}
{"prompt": "Rephrase the abstract of an article with title 'Opposite magnetic polarity of two photospheric lines in single spectrum   of the quiet Sun'.   We study the structure of the photospheric magnetic field of the quiet Sun by investigating weak spectro-polarimetric signals. We took a sequence of Stokes spectra of the Fe I 630.15 nm and 630.25 nm lines in a region of quiet Sun near the disk center, using the POLIS spectro-polarimeter at the German VTT on Tenerife. The line cores of these two lines form at different heights in the atmosphere. The 3$\\sigma$ noise level of the data is about 1.8 $\\times 10^{-3} I_{c}$. We present co-temporal and co-spatial Stokes-$V$ profiles of the Fe I 630 nm line pair, where the two lines show opposite polarities in a single spectrum. We compute synthetic line profiles and reproduce these spectra with a two-component model atmosphere: a non-magnetic component and a magnetic component. The magnetic component consists of two magnetic layers with opposite polarity: the upper one moves upwards while the lower one moves downward. In-between, there is a region of enhanced temperature. The Stokes-$V$ line pair of opposite polarity in a single spectrum can be understood as a magnetic reconnection event in the solar photosphere. We demonstrate that such a scenario is realistic, but the solution may not be unique.  ", "human_text": "  We study the structure of the photospheric magnetic field of the quiet Sun by investigating weak spectro-polarimetric signals. We took a sequence of Stokes spectra of the Fe I 630.15 nm and 630.25 nm lines in a region of quiet Sun near the disk center, using the POLIS spectro-polarimeter at the German VTT on Tenerife. The line cores of these two lines form at different heights in the atmosphere. The 3$\\sigma$ noise level of the data is about 1.8 $\\times 10^{-3} I_{c}$. We present co-temporal and co-spatial Stokes-$V$ profiles of the Fe I 630 nm line pair, where the two lines show opposite polarities in a single spectrum. We compute synthetic line profiles and reproduce these spectra with a two-component model atmosphere: a non-magnetic component and a magnetic component. The magnetic component consists of two magnetic layers with opposite polarity: the upper one moves upwards while the lower one moves downward. In-between, there is a region of enhanced temperature. The Stokes-$V$ line pair of opposite polarity in a single spectrum can be understood as a magnetic reconnection event in the solar photosphere. We demonstrate that such a scenario is realistic, but the solution may not be unique. ", "machine_text": " In this study, we used the POLIS spectro-polarimeter located at the German VTT on Tenerife to analyze the structure of the photospheric magnetic field of a quiet Sun region near the disk center. Through Stokes spectra of the Fe I 630.15 nm and 630.25 nm lines with a 3$\\sigma$ noise level of approximately 1.8 $\\times 10^{-3} I_{c}$, it was observed that the two lines in the same spectrum had opposite polarities. This was theorized to be the result of a magnetic reconnection event occurring in the photosphere, which we confirmed through inference of a two-component model atmosphere containing a non-magnetic component, and a magnetic one containing both a lower and higher magnetic field with opposite polarities surrounded by a region of higher temperature. Although this solution is likely, it may not be the only one.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3135}
{"prompt": "Rephrase the abstract of an article with title 'Phenomenology of the nMSSM from colliders to cosmology'.   Low energy supersymmetric models provide a solution to the hierarchy problem and also have the necessary ingredients to solve two of the most outstanding issues in cosmology: the origin of dark matter and baryonic matter. One of the most attractive features of this framework is that the relevant physical processes are related to interactions at the weak scale and therefore may be tested in collider experiments in the near future. This is true for the Minimal Supersymmetric Standard Model (MSSM) as well as for its extension with the addition of one singlet chiral superfield, the so-called nMSSM. It has been recently shown that within the nMSSM an elegant solution to both the problem of baryogenesis and dark matter may be found, that relies mostly on the mixing of the singlet sector with the Higgs sector of the theory. In this work we review the nMSSM model constraints from cosmology and present the associated collider phenomenology at the LHC and the ILC. We show that the ILC will efficiently probe the neutralino, chargino and Higgs sectors, allowing to confront cosmological observations with computations based on collider measurements. We also investigate the prospects for a direct detection of dark matter and the constraints imposed by the current bounds of the electron electric dipole moment in this model.  ", "human_text": "  Low energy supersymmetric models provide a solution to the hierarchy problem and also have the necessary ingredients to solve two of the most outstanding issues in cosmology: the origin of dark matter and baryonic matter. One of the most attractive features of this framework is that the relevant physical processes are related to interactions at the weak scale and therefore may be tested in collider experiments in the near future. This is true for the Minimal Supersymmetric Standard Model (MSSM) as well as for its extension with the addition of one singlet chiral superfield, the so-called nMSSM. It has been recently shown that within the nMSSM an elegant solution to both the problem of baryogenesis and dark matter may be found, that relies mostly on the mixing of the singlet sector with the Higgs sector of the theory. In this work we review the nMSSM model constraints from cosmology and present the associated collider phenomenology at the LHC and the ILC. We show that the ILC will efficiently probe the neutralino, chargino and Higgs sectors, allowing to confront cosmological observations with computations based on collider measurements. We also investigate the prospects for a direct detection of dark matter and the constraints imposed by the current bounds of the electron electric dipole moment in this model. ", "machine_text": "The physical properties of low energy supersymmetric models provide potential resolutions to both the hierarchy problem and outstanding issues in cosmology, including dark matter and baryonic matter. These theories are testable in near-future collider experiments, such as the Large Hadron Collider (LHC) and International Linear Collider (ILC), due to the weak-scale interaction parameters. Recently, the Minimal Supersymmetric Standard Model (MSSM) was extended with a singlet chiral superfield, ultimately producing a so-called nMSSM, which presents a viable answer to both baryogenesis and dark matter. This paper reflects on the implications of the nMSSM from cosmology and how it is represented in the LHC and ILC. We discuss how the ILC can verify the neutralino, chargino, and Higgs sectors in the theory, compare them with cosmological hypotheses, and examine prospects for detecting dark matter with further experiments. Also included is an assessment of the current understanding of the electron electric dipole moment when applied to the nMSSM.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0431}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological Symmetry Breaking, Pseudo-scale invariance, Dark Energy and   the Standard Model'.   The energy density of the universe today may be dominated by the vacuum energy of a slowly rolling scalar field. Making a quantum expansion around such a time dependent solution is found to break fundamental symmetries of quantum field theory. We call this mechanism cosmological symmetry breaking and argue that it is different from the standard phenomenon of spontaneous symmetry breaking. We illustrate this with a toy scalar field theory, whose action displays a U(1) symmetry. We identify a symmetry, called pseudo-scale invariance, which sets the cosmological constant exactly equal to zero, both in classical and quantum theory. This symmetry is also broken cosmologically and leads to a nonzero vacuum or dark energy. The slow roll condition along with the observed value of dark energy leads to a value of the background scalar field of the order of Planck mass. We also consider a U(1) gauge symmetry model. Cosmological symmetry breaking, in this case, leads to a non zero mass for the vector field. We also show that a cosmologically broken pseudo-scale invariance can generate a wide range of masses.  ", "human_text": "  The energy density of the universe today may be dominated by the vacuum energy of a slowly rolling scalar field. Making a quantum expansion around such a time dependent solution is found to break fundamental symmetries of quantum field theory. We call this mechanism cosmological symmetry breaking and argue that it is different from the standard phenomenon of spontaneous symmetry breaking. We illustrate this with a toy scalar field theory, whose action displays a U(1) symmetry. We identify a symmetry, called pseudo-scale invariance, which sets the cosmological constant exactly equal to zero, both in classical and quantum theory. This symmetry is also broken cosmologically and leads to a nonzero vacuum or dark energy. The slow roll condition along with the observed value of dark energy leads to a value of the background scalar field of the order of Planck mass. We also consider a U(1) gauge symmetry model. Cosmological symmetry breaking, in this case, leads to a non zero mass for the vector field. We also show that a cosmologically broken pseudo-scale invariance can generate a wide range of masses. ", "machine_text": "The cosmological energy density of the present day universe is likely to be dominated by a slowly rolling scalar field, which leads to a breaking of quantum field theory symmetries. We demonstrate this process as 'cosmological symmetry breaking', distinct from the usual spontaneous symmetry breaking. To illustrate our discussion, we consider a scalar field theory with a U(1) symmetry. We identify a 'pseudo-scale invariance' symmetry, which when broken cosmologically, produces a non-zero vacuum or dark energy. Further applying the slow roll condition, we obtain a value of the background field of the order of Planck mass. We also explore a U(1) gauge symmetry model and demonstrate how cosmological symmetry breaking results in a non-zero mass for the vector field. We illustrate how a broken pseudo-scale invariance can generate a wide range of masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2273}
{"prompt": "Rephrase the abstract of an article with title 'Gravitational Wave Signals from Chaotic System: A Point Mass with A Disk'.   We study gravitational waves from a particle moving around a system of a point mass with a disk in Newtonian gravitational theory. A particle motion in this system can be chaotic when the gravitational contribution from a surface density of a disk is comparable with that from a point mass. In such an orbit, we sometimes find that there appears a phase of the orbit in which particle motion becomes to be nearly regular (the so-called ``stagnant motion'') for a finite time interval between more strongly chaotic phases. To study how these different chaotic behaviours affect on observation of gravitational waves, we investigate a correlation of the particle motion and the waves. We find that such a difference in chaotic motions reflects on the wave forms and energy spectra. The character of the waves in the stagnant motion is quite different from that either in a regular motion or in a more strongly chaotic motion. This suggests that we may make a distinction between different chaotic behaviours of the orbit via the gravitational waves.  ", "human_text": "  We study gravitational waves from a particle moving around a system of a point mass with a disk in Newtonian gravitational theory. A particle motion in this system can be chaotic when the gravitational contribution from a surface density of a disk is comparable with that from a point mass. In such an orbit, we sometimes find that there appears a phase of the orbit in which particle motion becomes to be nearly regular (the so-called ``stagnant motion'') for a finite time interval between more strongly chaotic phases. To study how these different chaotic behaviours affect on observation of gravitational waves, we investigate a correlation of the particle motion and the waves. We find that such a difference in chaotic motions reflects on the wave forms and energy spectra. The character of the waves in the stagnant motion is quite different from that either in a regular motion or in a more strongly chaotic motion. This suggests that we may make a distinction between different chaotic behaviours of the orbit via the gravitational waves. ", "machine_text": " In this paper, we study gravitational wave signals originating from a point mass interacting with a disk in a Newtonian gravitational system. The motion of a particle in such a system is likely to be chaotic when the gravitational force of the disk is close to that of the point mass. We observe that in some orbits, the particle motion becomes nearly regular (labelled as 'stagnant motion') for a certain amount of time between each chaotic period. To study the influence chaotic behaviours have on the observation of gravitational waves, we aim to analyse the correlation between the waves and the behaviour of the particle. Our results indicate that each chaotic behaviour involved in the waveforms and energy spectra can be distinguishable. The waveforms generated from the stagnant motion are notably different from that from the more chaotic or regular motion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0719}
{"prompt": "Rephrase the abstract of an article with title 'A Systematic Study of Departures from Chemical Equilibrium in the   Atmospheres of Substellar Mass Objects'.   We present a systematic study of the spectral consequences of departures from chemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler dwarfs. The temperature/pressure profiles of the non-equilibrium models are fully consistent with the non-equilibrium chemistry. Our grid of non-equilibrium models includes spectra for effective temperatures from 200 K to 1800 K, three surface gravities, four possible values of the coefficient of eddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical reaction prescriptions. We find that the non-equilibrium overabundance of CO translates into flux suppressions in the M ($\\sim4-$5 $\\mu$m) band of at most $\\sim$40% between effective temperatures of 600 and 1800 K. The effect is largest around $T_{\\rm eff} \\approx 1100$ K. The underabundance of ammonia due to non-equilibrium chemistry translates into flux enhancements of no more than $\\sim$20% for the $T_{\\rm eff}$ range from 300 to 1800 K, with the largest effects at the lowest values of $T_{\\rm eff}$. The magnitude of the departure from chemical equilibrium increases with decreasing gravity, with increasing eddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$ reaction. Though these effects are modest, they lead to better fits with the measured T dwarf spectra. Furthermore, the suppression in the M band due to non-equilibrium enhancements in the CO abundance disappears below $\\sim$500 K, and is only partial above $\\sim$500 K, preserving the M band flux as a useful diagnostic of cool atmospheres and maintaining its importance for searches for brown dwarfs cooler than T dwarfs.  ", "human_text": "  We present a systematic study of the spectral consequences of departures from chemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler dwarfs. The temperature/pressure profiles of the non-equilibrium models are fully consistent with the non-equilibrium chemistry. Our grid of non-equilibrium models includes spectra for effective temperatures from 200 K to 1800 K, three surface gravities, four possible values of the coefficient of eddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical reaction prescriptions. We find that the non-equilibrium overabundance of CO translates into flux suppressions in the M ($\\sim4-$5 $\\mu$m) band of at most $\\sim$40% between effective temperatures of 600 and 1800 K. The effect is largest around $T_{\\rm eff} \\approx 1100$ K. The underabundance of ammonia due to non-equilibrium chemistry translates into flux enhancements of no more than $\\sim$20% for the $T_{\\rm eff}$ range from 300 to 1800 K, with the largest effects at the lowest values of $T_{\\rm eff}$. The magnitude of the departure from chemical equilibrium increases with decreasing gravity, with increasing eddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$ reaction. Though these effects are modest, they lead to better fits with the measured T dwarf spectra. Furthermore, the suppression in the M band due to non-equilibrium enhancements in the CO abundance disappears below $\\sim$500 K, and is only partial above $\\sim$500 K, preserving the M band flux as a useful diagnostic of cool atmospheres and maintaining its importance for searches for brown dwarfs cooler than T dwarfs. ", "machine_text": " This article examines the spectral shifts due to a departure from chemical equilibrium in the atmospheres of L and T dwarfs, and even cooler temperatures. A grid of non-equilibrium models was created for effective temperatures ranging from 200 K to 1800 K, with three different surface gravities, four values of the coefficient of eddy diffusion, and three prescriptions for the CO/CH$_4$ chemical reaction. We discovered that the overabundance of CO results in a 40% reduction of flux in the M ($\\sim4-$5 $\\mu$m) band between effective temperatures of 600 and 1800 K, with the most significant effect at $T_{\\rm eff} \\approx 1100$ K. When looking at the underabundance of ammonia, this yields a maximum of 20% increase in flux across the range of 300 to 1800 K, with the greatest effects at the lowest values of $T_{\\rm eff}$. The magnitude of departure from chemical equilibrium increases in relation to decreased gravity, increased eddy diffusion coefficient, and slower speed of the CO/CH$_4$ reaction. Though small, these effects create better fitted spectra to T dwarf measurements. Additionally, it was determined that the suppression in the M band resulting from non-equilibrium CO enhancements vanishes below 500 K and is only partial above 500 K, keeping the M band valuable for discovering brown dwarfs cooler than T dwarfs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3922}
{"prompt": "Rephrase the abstract of an article with title 'Dynamic response of Ag monolayers adsorbed on Au(100) upon an   oscillatory variation of the chemical potential: A Monte Carlo simulation   study'.   Based on the fact that the underpotential electrochemical deposition of Ag atoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at well-defined values of the (coexistence) chemical potential ($\\mu_{coex}$), we performed extensive simulations aimed at investigating the hysteretic dynamic behavior of the system close to coexistence upon the application of a periodic signal of the form $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau) $, where $\\mu_{o}$ and $\\tau$ are the amplitude and the period of the sweep, respectively. For relatively short periods and small enough amplitudes the system becomes trapped either at low or high Ag coverage states, as evidenced by recording hysteresis loops. This scenario is identified as dynamically ordered states (DOS), such that the relaxation time $(\\tau_{relax})$ of the corresponding metastable state obeys $\\tau_{relax} > \\tau $. On the other hand, by properly increasing $\\mu_{o}$ or/and $\\tau$, one finds that the $Ag$ coverage gently follows the external drive (here $\\tau_{relax} < \\tau $) and the system is said to enter into dynamically disordered states (DDS), where hysteresis loops show almost symmetric limiting cycles. This symmetry breaking between limiting cycles driven by an external signal is discussed in terms of the concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and DDS, similar to those encountered when a magnetic system is placed in the presence of a variable external magnetic field. However, a careful finite-size scaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system does not exhibit true second-order phase transitions but rather a crossover behavior between states. A diagram showing the location of the ordered and disordered states in the $\\mu$ versus $\\tau$ plane is obtained and discussed.  ", "human_text": "  Based on the fact that the underpotential electrochemical deposition of Ag atoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at well-defined values of the (coexistence) chemical potential ($\\mu_{coex}$), we performed extensive simulations aimed at investigating the hysteretic dynamic behavior of the system close to coexistence upon the application of a periodic signal of the form $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau) $, where $\\mu_{o}$ and $\\tau$ are the amplitude and the period of the sweep, respectively. For relatively short periods and small enough amplitudes the system becomes trapped either at low or high Ag coverage states, as evidenced by recording hysteresis loops. This scenario is identified as dynamically ordered states (DOS), such that the relaxation time $(\\tau_{relax})$ of the corresponding metastable state obeys $\\tau_{relax} > \\tau $. On the other hand, by properly increasing $\\mu_{o}$ or/and $\\tau$, one finds that the $Ag$ coverage gently follows the external drive (here $\\tau_{relax} < \\tau $) and the system is said to enter into dynamically disordered states (DDS), where hysteresis loops show almost symmetric limiting cycles. This symmetry breaking between limiting cycles driven by an external signal is discussed in terms of the concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and DDS, similar to those encountered when a magnetic system is placed in the presence of a variable external magnetic field. However, a careful finite-size scaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system does not exhibit true second-order phase transitions but rather a crossover behavior between states. A diagram showing the location of the ordered and disordered states in the $\\mu$ versus $\\tau$ plane is obtained and discussed. ", "machine_text": "  This study investigated the response of an Ag monolayer on $Au(100)$ to a periodic variation of the chemical potential, $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau)$, with $\\mu_{o}$ and $\\tau$ corresponding to the amplitude and period of the signal sweep, respectively. Using Monte Carlo simulations, the authors discovered that with relatively short $\\tau$ values and low enough $\\mu_{o}$ amplitudes, the system demonstrated a hysteretic behavior that was identified as Dynamically Ordered States (DOS), where the relaxation time of the corresponding metastable state was found to be $\\tau_{relax} > \\tau$. With increasing values of either $\\mu_{o}$ or $\\tau$, however, the Ag coverage gently follows the oscillatory signal which then designates the system to enter the Dynamically Disordered States (DDS) - displaying almost symmetrical limiting cycles. This breaking of symmetry between cycles mediated by the external signal allows us to discuss Dynamic Phase Transitions, analogous to those encountered in magnetic systems placed under changing external magnetic fields. A finite-size scaling analysis revealed the existence of a crossover behavior between DOS and DDS at $T = 300 K$, and the authors produced a diagram showing the location of the two kinds of states in the $(\\mu, \\tau)$ plane.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.447}
{"prompt": "Rephrase the abstract of an article with title 'A remark on the number of steady states in a multiple futile cycle'.   The multisite phosphorylation-dephosphorylation cycle is a motif repeatedly used in cell signaling. This motif itself can generate a variety of dynamic behaviors like bistability and ultrasensitivity without direct positive feedbacks. In this paper, we study the number of positive steady states of a general multisite phosphorylation-dephosphorylation cycle, and how the number of positive steady states varies by changing the biological parameters. We show analytically that (1) for some parameter ranges, there are at least n+1 (if n is even) or n (if n is odd) steady states; (2) there never are more than 2n-1 steady states (in particular, this implies that for n=2, including single levels of MAPK cascades, there are at most three steady states); (3) for parameters near the standard Michaelis-Menten quasi-steady state conditions, there are at most n+1 steady states; and (4) for parameters far from the standard Michaelis-Menten quasi-steady state conditions, there is at most one steady state.  ", "human_text": "  The multisite phosphorylation-dephosphorylation cycle is a motif repeatedly used in cell signaling. This motif itself can generate a variety of dynamic behaviors like bistability and ultrasensitivity without direct positive feedbacks. In this paper, we study the number of positive steady states of a general multisite phosphorylation-dephosphorylation cycle, and how the number of positive steady states varies by changing the biological parameters. We show analytically that (1) for some parameter ranges, there are at least n+1 (if n is even) or n (if n is odd) steady states; (2) there never are more than 2n-1 steady states (in particular, this implies that for n=2, including single levels of MAPK cascades, there are at most three steady states); (3) for parameters near the standard Michaelis-Menten quasi-steady state conditions, there are at most n+1 steady states; and (4) for parameters far from the standard Michaelis-Menten quasi-steady state conditions, there is at most one steady state. ", "machine_text": "This paper analyses the number of steady states present in a general multisite phosphorylation-dephosphorylation cycle, while also exploring how the number of steady states may change under different biological parameters. We show that the number of steady states range from n+1 (if n is even) or n (if n is odd) to a maximum of 2n-1. It is also demonstrated that parameters near the standard Michaelis-Menten quasi-steady state conditions result in a maximum of n+1 steady states, while parameters far from the typical conditions lead to one steady state at most.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0036}
{"prompt": "Rephrase the abstract of an article with title 'High-precision astrometry on the VLT/FORS1 at time scales of few days'.   We investigate the accuracy of astrometric measurements with the VLT/FORS1 camera and consider potential applications. The study is based on two-epoch (2000 and 2002/2003) frame series of observations of a selected Galactic Bulge sky region that were obtained with FORS1 during four consecutive nights each. Reductions were carried out with a novel technique that eliminates atmospheric image motion and does not require a distinction between targets and reference objects. The positional astrometric precision was found to be limited only by the accuracy of the determination of the star photocentre, which is typically 200-300 microarcsec per single measurement for bright unsaturated stars B=18-19. Several statistical tests have shown that at time-scales of 1-4 nights the residual noise in measured positions is essentially a white noise with no systematic instrumental signature and no significant deviation from a Gaussian distribution. Some evidence of a good astrometric quality of the VLT for frames separated by two years has also been found. Our data show that the VLT with FORS1/2 cameras can be effectively used for astrometric observations of planetary microlensing events and other applications where a high accuracy is required, that is expected to reach 30-40 microarcsec for a series of 50 frames (one hours with R filter).  ", "human_text": "  We investigate the accuracy of astrometric measurements with the VLT/FORS1 camera and consider potential applications. The study is based on two-epoch (2000 and 2002/2003) frame series of observations of a selected Galactic Bulge sky region that were obtained with FORS1 during four consecutive nights each. Reductions were carried out with a novel technique that eliminates atmospheric image motion and does not require a distinction between targets and reference objects. The positional astrometric precision was found to be limited only by the accuracy of the determination of the star photocentre, which is typically 200-300 microarcsec per single measurement for bright unsaturated stars B=18-19. Several statistical tests have shown that at time-scales of 1-4 nights the residual noise in measured positions is essentially a white noise with no systematic instrumental signature and no significant deviation from a Gaussian distribution. Some evidence of a good astrometric quality of the VLT for frames separated by two years has also been found. Our data show that the VLT with FORS1/2 cameras can be effectively used for astrometric observations of planetary microlensing events and other applications where a high accuracy is required, that is expected to reach 30-40 microarcsec for a series of 50 frames (one hours with R filter). ", "machine_text": " By conducting a two-epoch observational study of a Galactic Bulge sky region, we analyze the precision of astrometric measurements by FORS1 on the VLT. To make sure the readings are not impacted by atmospheric image motion, we make use of a special technique and utilize bright, unsaturated stars of magnitude between 18 to 19. Statistical testing reveals that the positional astrometric precision is mainly restricted by the ability to determine star photocenters. We find the residual noise of measured positions is essentially a white noise that follows a Gaussian distribution. After analyzing the data for time-scales of 1-4 nights, we also conclude that there is evidence of a good astrometric quality of the VLT that can reach up to 30-50 microarcsec for 50 frames with a R filter over one hour.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3883}
{"prompt": "Rephrase the abstract of an article with title 'The Mass Assembly History of Spheroidal Galaxies: Did Newly-Formed   Systems Arise Via Major Mergers?'.   We examine the properties of a morphologically-selected sample of 0.4<z<1.0 spheroidal galaxies in the GOODS fields in order to ascertain whether their increase in abundance with time arises primarily from mergers. To address this question we determine scaling relations between the dynamical mass determined from stellar velocity dispersions, and the stellar mass determined from optical and infrared photometry. We exploit these relations across the larger sample for which we have stellar masses in order to construct the first statistically robust estimate of the evolving dynamical mass function over 0<z<1. The trends observed match those seen in the stellar mass functions of Bundy et al. 2005 regarding the top-down growth in the abundance of spheroidal galaxies. By referencing our dynamical masses to the halo virial mass we compare the growth rate in the abundance of spheroidals to that predicted by the assembly of dark matter halos. Our comparisons demonstrate that major mergers do not fully account for the appearance of new spheroidals since z~1 and that additional mechanisms, such as morphological transformations, are required to drive the observed evolution.  ", "human_text": "  We examine the properties of a morphologically-selected sample of 0.4<z<1.0 spheroidal galaxies in the GOODS fields in order to ascertain whether their increase in abundance with time arises primarily from mergers. To address this question we determine scaling relations between the dynamical mass determined from stellar velocity dispersions, and the stellar mass determined from optical and infrared photometry. We exploit these relations across the larger sample for which we have stellar masses in order to construct the first statistically robust estimate of the evolving dynamical mass function over 0<z<1. The trends observed match those seen in the stellar mass functions of Bundy et al. 2005 regarding the top-down growth in the abundance of spheroidal galaxies. By referencing our dynamical masses to the halo virial mass we compare the growth rate in the abundance of spheroidals to that predicted by the assembly of dark matter halos. Our comparisons demonstrate that major mergers do not fully account for the appearance of new spheroidals since z~1 and that additional mechanisms, such as morphological transformations, are required to drive the observed evolution. ", "machine_text": " We investigate the development of spheroidal galaxies in the range of 0<z<1 by examining a group of morphologically-selected 0.4<z<1.0 galaxies found in the GOODS fields. We use the stellar velocity dispersions to discern the dynamical masses of these galaxies and compare them to the stellar masses determined through optical and IR photometry. Our work creates a statistically-robust calculation of the earlier-mentioned evolving dynamical mass function. Results of our analysis reach the same conclusions as those from Bundy et al. in 2005, that spheroidal galaxies have grown in abundance from top-down. Looking at the ratio of spheroidal growth to that of dark matter halos, we have found that major mergers are not enough to explain the appearance of these galaxies in z~1. Consequently, we propose that other mechanisms, such as morphological changes, are accountable for this evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1007}
{"prompt": "Rephrase the abstract of an article with title 'On bounds and algorithms for frequency synchronization for collaborative   communication systems'.   Cooperative diversity systems are wireless communication systems designed to exploit cooperation among users to mitigate the effects of multipath fading. In fairly general conditions, it has been shown that these systems can achieve the diversity order of an equivalent MISO channel and, if the node geometry permits, virtually the same outage probability can be achieved as that of the equivalent MISO channel for a wide range of applicable SNR. However, much of the prior analysis has been performed under the assumption of perfect timing and frequency offset synchronization. In this paper, we derive the estimation bounds and associated maximum likelihood estimators for frequency offset estimation in a cooperative communication system. We show the benefit of adaptively tuning the frequency of the relay node in order to reduce estimation error at the destination. We also derive an efficient estimation algorithm, based on the correlation sequence of the data, which has mean squared error close to the Cramer-Rao Bound.  ", "human_text": "  Cooperative diversity systems are wireless communication systems designed to exploit cooperation among users to mitigate the effects of multipath fading. In fairly general conditions, it has been shown that these systems can achieve the diversity order of an equivalent MISO channel and, if the node geometry permits, virtually the same outage probability can be achieved as that of the equivalent MISO channel for a wide range of applicable SNR. However, much of the prior analysis has been performed under the assumption of perfect timing and frequency offset synchronization. In this paper, we derive the estimation bounds and associated maximum likelihood estimators for frequency offset estimation in a cooperative communication system. We show the benefit of adaptively tuning the frequency of the relay node in order to reduce estimation error at the destination. We also derive an efficient estimation algorithm, based on the correlation sequence of the data, which has mean squared error close to the Cramer-Rao Bound. ", "machine_text": "This article focuses on the issue of frequency synchronization for communication systems based on collaboration. We investigate the theoretical bounds and estimators of frequency offset in such systems and propose a tuning methodology to reduce the error at the receiver. Additionally, a maximum likelihood estimation algorithm based on the correlation sequence of the data is presented and its accuracy is shown to meet the Cramer-Rao bound.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3054}
{"prompt": "Rephrase the abstract of an article with title 'Nonequilibrium Steady States of Matrix Product Form: A Solver's Guide'.   We consider the general problem of determining the steady state of stochastic nonequilibrium systems such as those that have been used to model (among other things) biological transport and traffic flow. We begin with a broad overview of this class of driven diffusive systems - which includes exclusion processes - focusing on interesting physical properties, such as shocks and phase transitions. We then turn our attention specifically to those models for which the exact distribution of microstates in the steady state can be expressed in a matrix product form. In addition to a gentle introduction to this matrix product approach, how it works and how it relates to similar constructions that arise in other physical contexts, we present a unified, pedagogical account of the various means by which the statistical mechanical calculations of macroscopic physical quantities are actually performed. We also review a number of more advanced topics, including nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of a matrix product state for a given model and more complicated variants of the matrix product state that allow various types of parallel dynamics to be handled. We conclude with a brief discussion of open problems for future research.  ", "human_text": "  We consider the general problem of determining the steady state of stochastic nonequilibrium systems such as those that have been used to model (among other things) biological transport and traffic flow. We begin with a broad overview of this class of driven diffusive systems - which includes exclusion processes - focusing on interesting physical properties, such as shocks and phase transitions. We then turn our attention specifically to those models for which the exact distribution of microstates in the steady state can be expressed in a matrix product form. In addition to a gentle introduction to this matrix product approach, how it works and how it relates to similar constructions that arise in other physical contexts, we present a unified, pedagogical account of the various means by which the statistical mechanical calculations of macroscopic physical quantities are actually performed. We also review a number of more advanced topics, including nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of a matrix product state for a given model and more complicated variants of the matrix product state that allow various types of parallel dynamics to be handled. We conclude with a brief discussion of open problems for future research. ", "machine_text": "This article provides an overview and guide to the calculation of nonequilibrium steady states of matrix product form. We begin by introducing this class of stochastic nonequilibrium systems, which is used to model various phenomena such as biological transport and traffic flow, and discuss their interesting physical properties such as shocks and phase transitions. We then explain the matrix product approach and how it relates to similar methods in other physical contexts, providing a unified view of the means by which the macroscopic physical quantities can be calculated. We also analyse more advanced topics like nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of the matrix product state, and parallel dynamics. Finally, we discuss open problems for future research in this field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1678}
{"prompt": "Rephrase the abstract of an article with title 'Testing Explanations of the $B\\to\\phi K^*$ Polarization Puzzle'.   $B\\to\\phi K^*$ ($\\btos$) is three separate decays, one for each polarization of the final-state vector mesons (one longitudinal, two transverse). It is observed that the fraction of transverse decays, $\\fT$, and the fraction of longitudinal decays, $\\fL$, are roughly equal: $\\fTfL \\simeq 1$, in opposition to the naive expectation that $\\fT \\ll \\fL$. If one requires a single explanation of all polarization puzzles, two possibilities remain within the standard model: penguin annihilation and rescattering. In this paper we examine the predictions of these two explanations for $\\fTfL$ in $\\btod$ decays. In $B \\to \\rho\\rho$ decays, only $\\bd \\to \\rho^0\\rho^0$ can possibly exhibit a large $\\fTfL$. In B decays related by U-spin, we find two promising possibilities: (i) $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$) and (ii) $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$ ($\\btod$). The measurement of $\\fTfL$ in these pairs of decays will allow us to test penguin annihilation and rescattering. Finally, it is possible to distinguish penguin annihilation from rescattering by performing a time-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$.  ", "human_text": "  $B\\to\\phi K^*$ ($\\btos$) is three separate decays, one for each polarization of the final-state vector mesons (one longitudinal, two transverse). It is observed that the fraction of transverse decays, $\\fT$, and the fraction of longitudinal decays, $\\fL$, are roughly equal: $\\fTfL \\simeq 1$, in opposition to the naive expectation that $\\fT \\ll \\fL$. If one requires a single explanation of all polarization puzzles, two possibilities remain within the standard model: penguin annihilation and rescattering. In this paper we examine the predictions of these two explanations for $\\fTfL$ in $\\btod$ decays. In $B \\to \\rho\\rho$ decays, only $\\bd \\to \\rho^0\\rho^0$ can possibly exhibit a large $\\fTfL$. In B decays related by U-spin, we find two promising possibilities: (i) $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$) and (ii) $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$ ($\\btod$). The measurement of $\\fTfL$ in these pairs of decays will allow us to test penguin annihilation and rescattering. Finally, it is possible to distinguish penguin annihilation from rescattering by performing a time-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$. ", "machine_text": " In this study, we explore the two potential explanations for the puzzle of the roughly equal fraction of transverse and longitudinal decays of the $B\\to \\phi K^*$ ($\\btos$) correspondences: penguin annihilation and rescattering. We analyze the expected results of each option for $\\fTfL$ in $\\btod$ decays and assess two promising U-spin related pairs of decays, $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$), and  $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$ ($\\btod$). The comparison of these pairs of decays can be used to assess the validity of penguin annihilation and rescattering as an explanation for the observed polarization puzzle. Moreover, the time-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$ decays offers a potential way to discriminate between the two options.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3915}
{"prompt": "Rephrase the abstract of an article with title 'Discovery of two candidate pulsar wind nebulae in very-high-energy gamma   rays'.   We present the discovery of two very-high-energy gamma-ray sources in an ongoing systematic search for emission above 100 GeV from pulsar wind nebulae in survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov Telescopes are ideal tools for searching for extended emission from pulsar wind nebulae in the very-high-energy regime. H.E.S.S., with its large field of view of 5 degrees and high sensitivity, gives new prospects for the search for these objects. An ongoing systematic search for very-high-energy emission from energetic pulsars over the region of the Galactic plane between -60 degrees < l < 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting candidates, the standard H.E.S.S. analysis was applied and a search for multi-wavelength counterparts was performed. We present the discovery of two new candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193. H.E.S.S. has proven to be a suitable instrument for pulsar wind nebula searches.  ", "human_text": "  We present the discovery of two very-high-energy gamma-ray sources in an ongoing systematic search for emission above 100 GeV from pulsar wind nebulae in survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov Telescopes are ideal tools for searching for extended emission from pulsar wind nebulae in the very-high-energy regime. H.E.S.S., with its large field of view of 5 degrees and high sensitivity, gives new prospects for the search for these objects. An ongoing systematic search for very-high-energy emission from energetic pulsars over the region of the Galactic plane between -60 degrees < l < 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting candidates, the standard H.E.S.S. analysis was applied and a search for multi-wavelength counterparts was performed. We present the discovery of two new candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193. H.E.S.S. has proven to be a suitable instrument for pulsar wind nebula searches. ", "machine_text": " This article discusses the results of a systematic survey conducted by the H.E.S.S. telescope array for pulsar wind nebulae (PWNe) emitting gamma rays with energies greater than 100 GeV, from -60 degrees < l < 30 degrees, -2 degrees < b < 2 degrees, in the Galactic plane. We found indications of two new PWNe, HESS J1718-385 and HESS J1809-193, which were then confirmed with a standard H.E.S.S. analysis and search for multi-wavelength counterparts. H.E.S.S.'s large field of view and high sensitivity make it an effective tool for discovering PWNe in the very-high-energy regime. Our study suggests that these discoveries represent a promising future for using H.E.S.S. in searches of this kind.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1605}
{"prompt": "Rephrase the abstract of an article with title 'Wavelet transforms in a critical interface model for Barkhausen noise'.   We discuss the application of wavelet transforms to a critical interface model, which is known to provide a good description of Barkhausen noise in soft ferromagnets. The two-dimensional version of the model (one-dimensional interface) is considered, mainly in the adiabatic limit of very slow driving. On length scales shorter than a crossover length (which grows with the strength of surface tension), the effective interface roughness exponent $\\zeta$ is $\\simeq 1.20$, close to the expected value for the universality class of the quenched Edwards-Wilkinson model. We find that the waiting times between avalanches are fully uncorrelated, as the wavelet transform of their autocorrelations scales as white noise. Similarly, detrended size-size correlations give a white-noise wavelet transform. Consideration of finite driving rates, still deep within the intermittent regime, shows the wavelet transform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies. This behavior is ascribed to intra-avalanche correlations.  ", "human_text": "  We discuss the application of wavelet transforms to a critical interface model, which is known to provide a good description of Barkhausen noise in soft ferromagnets. The two-dimensional version of the model (one-dimensional interface) is considered, mainly in the adiabatic limit of very slow driving. On length scales shorter than a crossover length (which grows with the strength of surface tension), the effective interface roughness exponent $\\zeta$ is $\\simeq 1.20$, close to the expected value for the universality class of the quenched Edwards-Wilkinson model. We find that the waiting times between avalanches are fully uncorrelated, as the wavelet transform of their autocorrelations scales as white noise. Similarly, detrended size-size correlations give a white-noise wavelet transform. Consideration of finite driving rates, still deep within the intermittent regime, shows the wavelet transform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies. This behavior is ascribed to intra-avalanche correlations. ", "machine_text": " We make use of wavelet transforms to show how a critical interface model is able to describe Barkhausen noise in soft ferromagnets. For this purpose, the two-dimensional version of the model is used, in the adiabatic limit of slow driving. We observe that when the length scale is shorter than a crossover length, the effective interface roughness exponent $\\zeta$ is near 1.20, close to the expected value for the Edwards-Wilkinson model. Our analysis suggests that the waiting times between avalanches are uncorrelated, as demonstrated by the white noise scaling of the wavelet transform of their autocorrelations. Moreover, size-size correlations with the data detrended also lead to a white-noise wavelet transform. Finite driving rates which remain within the intermittent regime, show a scaling of $1/f^{1.5}$ of the wavelet transform of correlations for intermediate frequencies. This can be determined to be caused by intra-avalanche correlations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1574}
{"prompt": "Rephrase the abstract of an article with title 'Orbits of tori extended by finite groups and their polynomial hulls: the   case of connected complex orbits'.   Let $V$ be a complex linear space, $G\\subset\\GL(V)$ be a compact group. We consider the problem of description of polynomial hulls $\\wh{Gv}$ for orbits $Gv$, $v\\in V$, assuming that the identity component of $G$ is a torus $T$. The paper contains a universal construction for orbits which satisfy the inclusion $Gv\\subset T^\\bbC v$ and a characterization of pairs $(G,V)$ such that it is true for a generic $v\\in V$. The hull of a finite union of $T$-orbits in $T^\\bbC v$ can be distinguished in $\\clos T^\\bbC v$ by a finite collection of inequalities of the type $\\abs{z_1}^{s_1}...\\abs{z_n}^{s_n}\\leq c$. In particular, this is true for $Gv$. If powers in the monomials are independent of $v$, $Gv\\subset T^\\bbC v$ for a generic $v$, and either the center of $G$ is finite or $T^\\bbC$ has an open orbit, then the space $V$ and the group $G$ are products of standard ones; the latter means that $G=S_nT$, where $S_n$ is the group of all permutations of coordinates and $T$ is either $\\bbT^n$ or $\\SU(n)\\cap\\bbT^n$, where $\\bbT^n$ is the torus of all diagonal matrices in $\\rU(n)$. The paper also contains a description of polynomial hulls for orbits of isotropy groups of bounded symmetric domains. This result is already known, but we formulate it in a different form and supply with a shorter proof.  ", "human_text": "  Let $V$ be a complex linear space, $G\\subset\\GL(V)$ be a compact group. We consider the problem of description of polynomial hulls $\\wh{Gv}$ for orbits $Gv$, $v\\in V$, assuming that the identity component of $G$ is a torus $T$. The paper contains a universal construction for orbits which satisfy the inclusion $Gv\\subset T^\\bbC v$ and a characterization of pairs $(G,V)$ such that it is true for a generic $v\\in V$. The hull of a finite union of $T$-orbits in $T^\\bbC v$ can be distinguished in $\\clos T^\\bbC v$ by a finite collection of inequalities of the type $\\abs{z_1}^{s_1}...\\abs{z_n}^{s_n}\\leq c$. In particular, this is true for $Gv$. If powers in the monomials are independent of $v$, $Gv\\subset T^\\bbC v$ for a generic $v$, and either the center of $G$ is finite or $T^\\bbC$ has an open orbit, then the space $V$ and the group $G$ are products of standard ones; the latter means that $G=S_nT$, where $S_n$ is the group of all permutations of coordinates and $T$ is either $\\bbT^n$ or $\\SU(n)\\cap\\bbT^n$, where $\\bbT^n$ is the torus of all diagonal matrices in $\\rU(n)$. The paper also contains a description of polynomial hulls for orbits of isotropy groups of bounded symmetric domains. This result is already known, but we formulate it in a different form and supply with a shorter proof. ", "machine_text": "This article examines the problem of describing polynomial hulls for orbits $Gv$, $v \\in V$, of a compact group $G \\subset \\GL(V)$, in the case where the identity component of $G$ is a torus $T$. It provides a universal construction for orbits that include $Gv \\subset T^\\bbC v$ and characterizes the pairs of $(G,V)$ where this holds in a generic form. Additionally, it provides a finite collection of inequalities that can be used to distinguish the hull of a finite union of $T$-orbits in $T^\\bbC v$ within the closure of $T^\\bbC v$. If the powers in the monomials do not depend on $v$ and $Gv$ is included in $T^\\bbC v$ for a generic $v$, the space $V$ and the group $G$ are determined as products of standard ones, where $G=S_nT$ is either $\\bbT^n$ or $\\SU(n)\\cap\\bbT^n$ with the torus of all diagonal matrices in $\\rU(n)$. Lastly, this paper also provides a new and more concise description of polynomial hulls for orbits of isotropy groups of bounded symmetric domains.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1095}
{"prompt": "Rephrase the abstract of an article with title 'Einstein in the crossroad of the sciences, arts and humanities'.   Western thinking underwent a turning point between 1885 and 1925. Einstein in 1905 symbolizes the emblematic hinge of this change of direction. To find an equivalent phenomenon in the past we need to go back to the period from the XV century to the XVII century. It was not a mere reform of codes but a new code. In 1905 the perception of reality changed through the introduction of relativism in three levels of the reference systems: the ego-other relation, the world perceived by the senses, and the 'ideal' universe of the concepts. We will try to identify how this change was expressed and developed in the cited levels, both in the physic and nature based sciences, in the social sciences, and in literature and fine arts. Today, 100 years after, the 1905's generation still proposes us two options: to live sheltered by the dogma that reassures us with its only and exclusive viewpoint claimed objective, or to dare to live with the multiple, the transient, the relative. The first way led to the worst regimes and intolerant ideas of the XX century, the second option throws us into the uncertainty of the creative adventure, but also leads us to the possibility of a fairer society in the XXI century.  ", "human_text": "  Western thinking underwent a turning point between 1885 and 1925. Einstein in 1905 symbolizes the emblematic hinge of this change of direction. To find an equivalent phenomenon in the past we need to go back to the period from the XV century to the XVII century. It was not a mere reform of codes but a new code. In 1905 the perception of reality changed through the introduction of relativism in three levels of the reference systems: the ego-other relation, the world perceived by the senses, and the 'ideal' universe of the concepts. We will try to identify how this change was expressed and developed in the cited levels, both in the physic and nature based sciences, in the social sciences, and in literature and fine arts. Today, 100 years after, the 1905's generation still proposes us two options: to live sheltered by the dogma that reassures us with its only and exclusive viewpoint claimed objective, or to dare to live with the multiple, the transient, the relative. The first way led to the worst regimes and intolerant ideas of the XX century, the second option throws us into the uncertainty of the creative adventure, but also leads us to the possibility of a fairer society in the XXI century. ", "machine_text": " In 1905, the concept of relativism revolutionized the way we perceive reality. In this historic transformation, Einstein symbolizes the pivotal figure connecting the sciences, arts, and humanities. By analyzing the physic and nature based sciences, the social sciences, and literature and fine arts between 1885 and 1925, this paper seeks to understand the shift away from dogma toward the uncertainty of creative adventure. At its core is the adamant belief that taking the second path ultimately leads to more equitable societies. Now, a century later, we are still presented with the same two choices - to stay sheltered in the confines of 'objective' dogma, or to embrace the challenge of multiple, ever-changing perspectives.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0999}
{"prompt": "Rephrase the abstract of an article with title 'GRB blastwaves through wind-shaped circumburst media'.   Context:A significant fraction of progenitors for long gamma-ray bursts (GRBs) are believed to be massive stars. The investigation of long GRBs therefore requires modeling the propagation of ultra-relativistic blastwaves through the circumburst medium surrounding massive stars. We simulate the expansion of an isotropic, adiabatic relativistic fireball into the wind-shaped medium around a massive GRB progenitor. The circumburst medium is composed of a realistically stratified stellar wind zone up to its termination shock, followed by a region of shocked wind characterized by a constant density. Aims: We followed the evolution of the blastwave through all its stages, including the extremely rapid acceleration up to a Lorentz factor 75 flow, its deceleration by interaction with stellar wind, its passage of the wind termination shock, until its propagation through shocked wind. Methods: We used the adaptive mesh refinement versatile advection code to follow the evolution of the fireball. Results: We show that the acceleration from purely thermal to ultra-relativistic kinetic regimes is abrupt and produces an internally structured blastwave. We resolved the structure of this ultra-relativistic shell in all stages, thanks to the adaptive mesh. We comment on the dynamical roles played by forward and reverse shock pairs in the phase of interaction with the free stellar wind and clearly identify the complex shock-dominated structure created when the shell crosses the terminal shock. Conclusion: We show that in our model where the terminal shock is taken relatively close to the massive star, the phase of self-similar deceleration of Blandford-McKee type can only be produced in the constant density, shocked wind zone.  ", "human_text": "  Context:A significant fraction of progenitors for long gamma-ray bursts (GRBs) are believed to be massive stars. The investigation of long GRBs therefore requires modeling the propagation of ultra-relativistic blastwaves through the circumburst medium surrounding massive stars. We simulate the expansion of an isotropic, adiabatic relativistic fireball into the wind-shaped medium around a massive GRB progenitor. The circumburst medium is composed of a realistically stratified stellar wind zone up to its termination shock, followed by a region of shocked wind characterized by a constant density. Aims: We followed the evolution of the blastwave through all its stages, including the extremely rapid acceleration up to a Lorentz factor 75 flow, its deceleration by interaction with stellar wind, its passage of the wind termination shock, until its propagation through shocked wind. Methods: We used the adaptive mesh refinement versatile advection code to follow the evolution of the fireball. Results: We show that the acceleration from purely thermal to ultra-relativistic kinetic regimes is abrupt and produces an internally structured blastwave. We resolved the structure of this ultra-relativistic shell in all stages, thanks to the adaptive mesh. We comment on the dynamical roles played by forward and reverse shock pairs in the phase of interaction with the free stellar wind and clearly identify the complex shock-dominated structure created when the shell crosses the terminal shock. Conclusion: We show that in our model where the terminal shock is taken relatively close to the massive star, the phase of self-similar deceleration of Blandford-McKee type can only be produced in the constant density, shocked wind zone. ", "machine_text": " This article discusses the results of simulated expansion of an isotropic adiabatic relativistic fireball around a massive GRB progenitor from within its wind-shaped circumburst medium. Utilizing the adaptive mesh refinement versatile advection code, we were able to follow the transition from thermal to ultra-relativistic kinetic explosion. We found that the blastwave passed through a forward and reverse shock pair during interaction with the free stellar wind, ultimately creating a complex shock-governed structure when entering the shocked wind region. Ultimately, we show that the self-similar deceleration found in the Blandford-McKee type can only be produced in the constant density atmosphere of the shocked wind zone in our model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2461}
{"prompt": "Rephrase the abstract of an article with title 'Near infrared spectroscopic search for the close orbiting planet HD   75289b'.   We present a search for the near infrared spectroscopic signature of the close orbiting extrasolar giant planet HD 75289b. We obtained ~230 spectra in the wavelength range 2.18 - 2.19 microns using the Phoenix spectrograph at Gemini South. By considering the direct spectrum, derived from irradiated model atmospheres, we search for the absorption profile signature present in the combined star and planet light. Since the planetary spectrum is separated from the stellar spectrum at most phases, we apply a phase dependent orbital model and tomographic techniques to search for absorption signatures.   Because the absorption signature lies buried in the noise of a single exposure we apply a multiline deconvolution to the spectral lines available in order to boost the effective S/N ratio of the data. The wavelength coverage of 80 angstroms is expected to contain ~100 planetary lines, enabling a mean line with S/N ratio of ~800 to be achieved after deconvolution. We are nevertheless unable to detect the presence of the planet in the data and carry out further simulations to show that broader wavelength coverage should enable a planet like HD 75289b to be detected with 99.9 per cent (4 sigma) confidence. We investigate the sensitivity of our method and estimate detection tolerances for mismatches between observed and model planetary atmospheres.  ", "human_text": "  We present a search for the near infrared spectroscopic signature of the close orbiting extrasolar giant planet HD 75289b. We obtained ~230 spectra in the wavelength range 2.18 - 2.19 microns using the Phoenix spectrograph at Gemini South. By considering the direct spectrum, derived from irradiated model atmospheres, we search for the absorption profile signature present in the combined star and planet light. Since the planetary spectrum is separated from the stellar spectrum at most phases, we apply a phase dependent orbital model and tomographic techniques to search for absorption signatures.   Because the absorption signature lies buried in the noise of a single exposure we apply a multiline deconvolution to the spectral lines available in order to boost the effective S/N ratio of the data. The wavelength coverage of 80 angstroms is expected to contain ~100 planetary lines, enabling a mean line with S/N ratio of ~800 to be achieved after deconvolution. We are nevertheless unable to detect the presence of the planet in the data and carry out further simulations to show that broader wavelength coverage should enable a planet like HD 75289b to be detected with 99.9 per cent (4 sigma) confidence. We investigate the sensitivity of our method and estimate detection tolerances for mismatches between observed and model planetary atmospheres. ", "machine_text": " In this study, we perform a near infrared spectroscopic search for the close orbiting extrasolar giant planet HD 75289b. To do so, we use the Phoenix spectrograph at Gemini South to take ~230 spectra in the 2.18 - 2.19 micron wavelength. We compare the combined star and planet light to the direct spectrum of an irradiated model atmosphere in search of an absorption profile signature. We also adapt phase dependent orbital models and tomographic techniques to seek out the detection of absorption signatures. With the multiline deconvolution technique, we increase the signal-to-noise ratio of the data, though no planet signature is observed. Simulations suggest that widening the wavelength coverage can enable the detection of a planet such as HD 75289b with a 4 sigma confidence. In addition, we examine the sensitivity of our method, estimating detection assumptions under mismatched observed and modeled planetary atmospheres.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0272}
{"prompt": "Rephrase the abstract of an article with title 'Dark Matter Annihilation in Substructures Revised'.   Upcoming $\\gamma$-ray satellites will search for Dark Matter annihilations in Milky Way substructures (or 'clumps'). The prospects for detecting these objects strongly depend on the assumptions made on the distribution of Dark Matter in substructures, and on the distribution of substructures in the Milky Way halo. By adopting simplified, yet rather extreme, prescriptions for these quantities, we compute the number of sources that can be detected with upcoming experiments such as GLAST, and show that, for the most optimistic particle physics setup ($m_\\chi=40$ GeV and annihilation cross section $\\sigma v = 3 \\times 10^{-26}$ cm$^3$ s$^{-1}$), the result ranges from zero to $\\sim$ hundred sources, all with mass above $10^{5}M\\odot$. However, for a fiducial DM candidate with mass $m_\\chi=100$ GeV and $\\sigma v = 10^{-26}$ cm$^3$ s$^{-1}$, at most a handful of large mass substructures can be detected at $5 \\sigma$, with a 1-year exposure time, by a GLAST-like experiment. Scenarios where micro-clumps (i.e. clumps with mass as small as $10^{-6}M\\odot$) can be detected are severely constrained by the diffuse $\\gamma$-ray background detected by EGRET.  ", "human_text": "  Upcoming $\\gamma$-ray satellites will search for Dark Matter annihilations in Milky Way substructures (or 'clumps'). The prospects for detecting these objects strongly depend on the assumptions made on the distribution of Dark Matter in substructures, and on the distribution of substructures in the Milky Way halo. By adopting simplified, yet rather extreme, prescriptions for these quantities, we compute the number of sources that can be detected with upcoming experiments such as GLAST, and show that, for the most optimistic particle physics setup ($m_\\chi=40$ GeV and annihilation cross section $\\sigma v = 3 \\times 10^{-26}$ cm$^3$ s$^{-1}$), the result ranges from zero to $\\sim$ hundred sources, all with mass above $10^{5}M\\odot$. However, for a fiducial DM candidate with mass $m_\\chi=100$ GeV and $\\sigma v = 10^{-26}$ cm$^3$ s$^{-1}$, at most a handful of large mass substructures can be detected at $5 \\sigma$, with a 1-year exposure time, by a GLAST-like experiment. Scenarios where micro-clumps (i.e. clumps with mass as small as $10^{-6}M\\odot$) can be detected are severely constrained by the diffuse $\\gamma$-ray background detected by EGRET. ", "machine_text": "This paper revised the potential of upcoming $\\gamma$-ray satellites to detect Dark Matter annihilations in Milky Way substructures, taking into account different sources of variables on the subject. We compute the estimated number of sources that can be detected with GLAST and other experiments, depending on the particle physics parameters of the Dark Matter candidate. Our results suggest that for a fiducial DM particle, only a handful of larger masses may be detected with a 1-year exposure time. Furthermore, depending on the assumed parameters, scenarios where micro-clumps can be detected may be severely hindered by the observed gamma-ray background.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2101}
{"prompt": "Rephrase the abstract of an article with title 'Pure inductive limit state and Kolmogorov's property'.   Let $(\\clb,\\lambda_t,\\psi)$ be a $C^*$-dynamical system where $(\\lambda_t: t \\in \\IT_+)$ be a semigroup of injective endomorphism and $\\psi$ be an $(\\lambda_t)$ invariant state on the $C^*$ subalgebra $\\clb$ and $\\IT_+$ is either non-negative integers or real numbers. The central aim of this exposition is to find a useful criteria for the inductive limit state $\\clb \\raro^{\\lambda_t} \\clb$ canonically associated with $\\psi$ to be pure. We achieve this by exploring the minimal weak forward and backward Markov processes associated with the Markov semigroup on the corner von-Neumann algebra of the support projection of the state $\\psi$ to prove that Kolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition for the inductive state to be pure. As an application of this criteria we find a sufficient condition for a translation invariant factor state on a one dimensional quantum spin chain to be pure. This criteria in a sense complements criteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states.  ", "human_text": "  Let $(\\clb,\\lambda_t,\\psi)$ be a $C^*$-dynamical system where $(\\lambda_t: t \\in \\IT_+)$ be a semigroup of injective endomorphism and $\\psi$ be an $(\\lambda_t)$ invariant state on the $C^*$ subalgebra $\\clb$ and $\\IT_+$ is either non-negative integers or real numbers. The central aim of this exposition is to find a useful criteria for the inductive limit state $\\clb \\raro^{\\lambda_t} \\clb$ canonically associated with $\\psi$ to be pure. We achieve this by exploring the minimal weak forward and backward Markov processes associated with the Markov semigroup on the corner von-Neumann algebra of the support projection of the state $\\psi$ to prove that Kolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition for the inductive state to be pure. As an application of this criteria we find a sufficient condition for a translation invariant factor state on a one dimensional quantum spin chain to be pure. This criteria in a sense complements criteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states. ", "machine_text": "This article examines a way to determine whether a certain limit state $\\clb \\raro^{\\lambda_t} \\clb$ canonically associated with an $(\\lambda_t)$ invariant state $\\psi$ on a $C^*$-dynamical system $(\\clb,\\lambda_t,\\psi)$ is pure. It studies the minimal weak forward and backward Markov processes arising from the Markov semigroup linked to the $\\psi$ to show that Kolmogorov's property [Mo2] of the Markov semigroup is sufficient for the limit state to be pure. We give a criterion for the purity of a translation invariant factor state on a one-dimensional quantum spin chain, and this is a complement to the criteria established earlier by [BJKW,Mo2] as it goes beyond lattice symmetric states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1987}
{"prompt": "Rephrase the abstract of an article with title 'Fractionally charged excitations on frustrated lattices'.   Systems of strongly correlated fermions on certain geometrically frustrated lattices at particular filling factors support excitations with fractional charges $\\pm e/2$. We calculate quantum mechanical ground states, low--lying excitations and spectral functions of finite lattices by means of numerical diagonalization. The ground state of the most thoroughfully studied case, the criss-crossed checkerboard lattice, is degenerate and shows long--range order. Static fractional charges are confined by a weak linear force, most probably leading to bound states of large spatial extent. Consequently, the quasi-particle weight is reduced, which reflects the internal dynamics of the fractionally charged excitations. By using an additional parameter, we fine--tune the system to a special point at which fractional charges are manifestly deconfined--the so--called Rokhsar--Kivelson point. For a deeper understanding of the low--energy physics of these models and for numerical advantages, several conserved quantum numbers are identified.  ", "human_text": "  Systems of strongly correlated fermions on certain geometrically frustrated lattices at particular filling factors support excitations with fractional charges $\\pm e/2$. We calculate quantum mechanical ground states, low--lying excitations and spectral functions of finite lattices by means of numerical diagonalization. The ground state of the most thoroughfully studied case, the criss-crossed checkerboard lattice, is degenerate and shows long--range order. Static fractional charges are confined by a weak linear force, most probably leading to bound states of large spatial extent. Consequently, the quasi-particle weight is reduced, which reflects the internal dynamics of the fractionally charged excitations. By using an additional parameter, we fine--tune the system to a special point at which fractional charges are manifestly deconfined--the so--called Rokhsar--Kivelson point. For a deeper understanding of the low--energy physics of these models and for numerical advantages, several conserved quantum numbers are identified. ", "machine_text": " At particular filling factors, strongly correlated fermions governing systems on specific geometrically frustrated lattices can exhibit excitations with fractional charges $\\pm e/2$.  To investigate the ground states, low-lying excitations, and spectral functions of these lattices, we employ numerical diagonalization. Most notably, the criss-crossed checkerboard lattice was found  to have a degenerate ground state in addition to long-range ordering. These fractional charges  are shown to be bound by a weak linear force, leading to large-spatial-extent bound states. Thus,  the quasi-particle weight is diminished, reflecting the composition of such fractionally charged  excitations. By exploiting a primary parameter, we are able to tune the system to a specially  defined 'Rokhsar-Kivelson' point at which fractional charges can be definitively identified as being deconfined. Far furthering our perception of the physics pertinent to those systems, several  conserved quantum numbers are identified.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0521}
{"prompt": "Rephrase the abstract of an article with title 'Cohomology of affine Artin groups and applications'.   The result of this paper is the determination of the cohomology of Artin groups of type A_n, B_n and \\tilde{A}_{n} with non-trivial local coefficients. The main result is an explicit computation of the cohomology of the Artin group of type B_n with coefficients over the module \\Q[q^{\\pm 1},t^{\\pm 1}]. Here the first (n-1) standard generators of the group act by (-q)-multiplication, while the last one acts by (-t)-multiplication. The proof uses some technical results from previous papers plus computations over a suitable spectral sequence. The remaining cases follow from an application of Shapiro's lemma, by considering some well-known inclusions: we obtain the rational cohomology of the Artin group of affine type \\tilde{A}_{n} as well as the cohomology of the classical braid group {Br}_{n} with coefficients in the n-dimensional representation presented in \\cite{tong}. The topological counterpart is the explicit construction of finite CW-complexes endowed with a free action of the Artin groups, which are known to be K(\\pi,1) spaces in some cases (including finite type groups). Particularly simple formulas for the Euler-characteristic of these orbit spaces are derived.  ", "human_text": "  The result of this paper is the determination of the cohomology of Artin groups of type A_n, B_n and \\tilde{A}_{n} with non-trivial local coefficients. The main result is an explicit computation of the cohomology of the Artin group of type B_n with coefficients over the module \\Q[q^{\\pm 1},t^{\\pm 1}]. Here the first (n-1) standard generators of the group act by (-q)-multiplication, while the last one acts by (-t)-multiplication. The proof uses some technical results from previous papers plus computations over a suitable spectral sequence. The remaining cases follow from an application of Shapiro's lemma, by considering some well-known inclusions: we obtain the rational cohomology of the Artin group of affine type \\tilde{A}_{n} as well as the cohomology of the classical braid group {Br}_{n} with coefficients in the n-dimensional representation presented in \\cite{tong}. The topological counterpart is the explicit construction of finite CW-complexes endowed with a free action of the Artin groups, which are known to be K(\\pi,1) spaces in some cases (including finite type groups). Particularly simple formulas for the Euler-characteristic of these orbit spaces are derived. ", "machine_text": " This paper provides concrete calculations of the cohomology of affine Artin groups of types A_n, B_n, and \\tilde{A}_n with non-trivial local coefficients. The core result demonstrates the cohomology of the B_n Artin group when coefficients are taken from the module \\Q[q^{\\pm 1}, t^{\\pm 1}], where the first (n-1) standard generators act by a (-q)-multiplicative influence, and the last one acts by a (-t)-multiplicative influence. The proof uses technical results from earlier papers, calculations over a certain spectral sequence, and Shapiro's lemma for determining the cohomology for the remaining batches of cases. As an extra outcome of this article, there is the explicit construction of finite CW-complexes that encase a free action of the Artin groups, oftentimes exhibiting K(\\pi,1) space properties. Furthermore, concise formulas are revealed for calculating the Euler-characteristics of these orbit spaces.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2823}
{"prompt": "Rephrase the abstract of an article with title 'Statistical analyses of long-term variability of AGN at high radio   frequencies'.   We present a study of variability time scales in a large sample of Active Galactic Nuclei at several frequencies between 4.8 and 230 GHz. We investigate the differences of various AGN types and frequencies and correlate the measured time scales with physical parameters such as the luminosity and the Lorentz factor. Our sample consists of both high and low polarization quasars, BL Lacertae objects and radio galaxies. The basis of this work is the 22 GHz, 37 GHz and 87 GHz monitoring data from the Metsahovi Radio Observatory spanning over 25 years. In addition,we used higher 90 GHz and 230 GHz frequency data obtained with the SEST-telescope between 1987 and 2003. Further lower frequency data at 4.8 GHz, 8 GHz and 14.5 GHz from the University of Michigan monitoring programme have been used. We have applied three different statistical methods to study the time scales: The structure function, the discrete correlation function and the Lomb-Scargle periodogram. We discuss also the differences and relative merits of these three methods. Our study reveals that smaller flux density variations occur in these sources on short time scales of 1-2 years, but larger outbursts happen quite rarely, on the average only once in every 6 years. We do not find any significant differences in the time scales between the source classes. The time scales are also only weakly related to the luminosity suggesting that the shock formation is caused by jet instabilities rather than the central black hole.  ", "human_text": "  We present a study of variability time scales in a large sample of Active Galactic Nuclei at several frequencies between 4.8 and 230 GHz. We investigate the differences of various AGN types and frequencies and correlate the measured time scales with physical parameters such as the luminosity and the Lorentz factor. Our sample consists of both high and low polarization quasars, BL Lacertae objects and radio galaxies. The basis of this work is the 22 GHz, 37 GHz and 87 GHz monitoring data from the Metsahovi Radio Observatory spanning over 25 years. In addition,we used higher 90 GHz and 230 GHz frequency data obtained with the SEST-telescope between 1987 and 2003. Further lower frequency data at 4.8 GHz, 8 GHz and 14.5 GHz from the University of Michigan monitoring programme have been used. We have applied three different statistical methods to study the time scales: The structure function, the discrete correlation function and the Lomb-Scargle periodogram. We discuss also the differences and relative merits of these three methods. Our study reveals that smaller flux density variations occur in these sources on short time scales of 1-2 years, but larger outbursts happen quite rarely, on the average only once in every 6 years. We do not find any significant differences in the time scales between the source classes. The time scales are also only weakly related to the luminosity suggesting that the shock formation is caused by jet instabilities rather than the central black hole. ", "machine_text": "We have conducted a long-term statistical analysis of variability in a large sample of Active Galactic Nuclei (AGN) across multiple high radio frequencies. Our sample was composed of various AGN types (high and low polarization quasars, BL Lacertae objects and radio galaxies) and was gathered using the Metsahovi Radio Observatory's 22 GHz, 37 GHz and 87GHz monitoring data from the past 25 years, as well as the data obtained using the SEST-telescope between 1987 and 2003. We also used the University of Michigan monitoring program data at 4.8 GHz, 8 GHz and 14.5 GHz. Three different statistical methods (structure function, discrete correlation function and Lomb-Scargle periodogram) were applied in order to examine the flux density variations of AGN on short timescales, as well as the frequency and physical parameter differences regarding their variability. Results showed that 1-2 year short-timescale fluctuations occur more frequently compared to large outbursts, with an average of once every 6 years. Differing from the hypothesis, there were no significant differences between AGN types and the time scales appeared to be only weakly related to luminosity, suggesting that instability in the jet, rather than the black hole, may be the source of these shock formations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3293}
{"prompt": "Rephrase the abstract of an article with title 'Adiabatic quantum dynamics of a random Ising chain across its quantum   critical point'.   We present here our study of the adiabatic quantum dynamics of a random Ising chain across its quantum critical point. The model investigated is an Ising chain in a transverse field with disorder present both in the exchange coupling and in the transverse field. The transverse field term is proportional to a function $\\Gamma(t)$ which, as in the Kibble-Zurek mechanism, is linearly reduced to zero in time with a rate $\\tau^{-1}$, $\\Gamma(t)=-t/\\tau$, starting at $t=-\\infty$ from the quantum disordered phase ($\\Gamma=\\infty$) and ending at $t=0$ in the classical ferromagnetic phase ($\\Gamma=0$). We first analyze the distribution of the gaps -- occurring at the critical point $\\Gamma_c=1$ -- which are relevant for breaking the adiabaticity of the dynamics. We then present extensive numerical simulations for the residual energy $E_{\\rm res}$ and density of defects $\\rho_k$ at the end of the annealing, as a function of the annealing inverse rate $\\tau$. %for different lenghts of the chain. Both the average $E_{\\rm res}(\\tau)$ and $\\rho_k(\\tau)$ are found to behave logarithmically for large $\\tau$, but with different exponents, $[E_{\\rm res}(\\tau)/L]_{\\rm av}\\sim 1/\\ln^{\\zeta}(\\tau)$ with $\\zeta\\approx 3.4$, and $[\\rho_k(\\tau)]_{\\rm av}\\sim 1/\\ln^{2}(\\tau)$. We propose a mechanism for $1/\\ln^2{\\tau}$-behavior of $[\\rho_k]_{\\rm av}$ based on the Landau-Zener tunneling theory and on a Fisher's type real-space renormalization group analysis of the relevant gaps. The model proposed shows therefore a paradigmatic example of how an adiabatic quantum computation can become very slow when disorder is at play, even in absence of any source of frustration.  ", "human_text": "  We present here our study of the adiabatic quantum dynamics of a random Ising chain across its quantum critical point. The model investigated is an Ising chain in a transverse field with disorder present both in the exchange coupling and in the transverse field. The transverse field term is proportional to a function $\\Gamma(t)$ which, as in the Kibble-Zurek mechanism, is linearly reduced to zero in time with a rate $\\tau^{-1}$, $\\Gamma(t)=-t/\\tau$, starting at $t=-\\infty$ from the quantum disordered phase ($\\Gamma=\\infty$) and ending at $t=0$ in the classical ferromagnetic phase ($\\Gamma=0$). We first analyze the distribution of the gaps -- occurring at the critical point $\\Gamma_c=1$ -- which are relevant for breaking the adiabaticity of the dynamics. We then present extensive numerical simulations for the residual energy $E_{\\rm res}$ and density of defects $\\rho_k$ at the end of the annealing, as a function of the annealing inverse rate $\\tau$. %for different lenghts of the chain. Both the average $E_{\\rm res}(\\tau)$ and $\\rho_k(\\tau)$ are found to behave logarithmically for large $\\tau$, but with different exponents, $[E_{\\rm res}(\\tau)/L]_{\\rm av}\\sim 1/\\ln^{\\zeta}(\\tau)$ with $\\zeta\\approx 3.4$, and $[\\rho_k(\\tau)]_{\\rm av}\\sim 1/\\ln^{2}(\\tau)$. We propose a mechanism for $1/\\ln^2{\\tau}$-behavior of $[\\rho_k]_{\\rm av}$ based on the Landau-Zener tunneling theory and on a Fisher's type real-space renormalization group analysis of the relevant gaps. The model proposed shows therefore a paradigmatic example of how an adiabatic quantum computation can become very slow when disorder is at play, even in absence of any source of frustration. ", "machine_text": " We investigate the adiabatic quantum dynamics of a disordered Ising chain at its quantum critical point. This model is composed of an Ising chain in a transverse field with disorder in both the exchange coupling and the transverse field. By applying the Kibble-Zurek mechanism, the transverse field is reducing linearly from infinity to zero with an annealing rate $\\tau^{-1}$, from the quantum disordered phase to the classical ferromagnetic phase. Our study addressed the gap distribution at the critical point $\\Gamma_c=1$, and then moved to simulating the results from the residual energy and the defect density as a function of the inverse annealing rate $\\tau$. From the findings, the average quantities $E_{\\rm res}(\\tau)$ and $\\rho_k(\\tau)$ both have logarithmic behavior with different exponents. We then proposed a mechanism to explain the $1/\\ln^2(\\tau)$ behavior of $[\\rho_k]_{\\rm av}$ through the use of Landau-Zener tunneling theory and a real-space renormalization of the relevant gaps. This model serves as a demonstration of how an adiabatic quantum computation can become slower due to disorder even in the absence of frustration.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1832}
{"prompt": "Rephrase the abstract of an article with title 'Loop Spaces and Langlands Parameters'.   We apply the technique of S^1-equivariant localization to sheaves on loop spaces in derived algebraic geometry, and obtain a fundamental link between two families of categories at the heart of geometric representation theory. Namely, we categorify the well known relationship between free loop spaces, cyclic homology and de Rham cohomology to recover the category of D-modules on a smooth stack X as a localization of the category of S^1-equivariant coherent sheaves on its loop space LX. The main observation is that this procedure connects categories of equivariant D-modules on flag varieties with categories of equivariant coherent sheaves on the Steinberg variety and its relatives. This provides a direct connection between the geometry of finite and affine Hecke algebras and braid groups, and a uniform geometric construction of all of the categorical parameters for representations of real and complex reductive groups. This paper forms the first step in a project to apply the geometric Langlands program to the complex and real local Langlands programs, which we describe.  ", "human_text": "  We apply the technique of S^1-equivariant localization to sheaves on loop spaces in derived algebraic geometry, and obtain a fundamental link between two families of categories at the heart of geometric representation theory. Namely, we categorify the well known relationship between free loop spaces, cyclic homology and de Rham cohomology to recover the category of D-modules on a smooth stack X as a localization of the category of S^1-equivariant coherent sheaves on its loop space LX. The main observation is that this procedure connects categories of equivariant D-modules on flag varieties with categories of equivariant coherent sheaves on the Steinberg variety and its relatives. This provides a direct connection between the geometry of finite and affine Hecke algebras and braid groups, and a uniform geometric construction of all of the categorical parameters for representations of real and complex reductive groups. This paper forms the first step in a project to apply the geometric Langlands program to the complex and real local Langlands programs, which we describe. ", "machine_text": " In this work, we apply the S^1-equivariant localization technique to the sheaves on loop spaces in derived algebraic geometry, and uncover the intimate connection between two families of categories--those of D-modules on a smooth stack X, and of S^1-equivariant coherent sheaves on its loop space LX. By studying the relationship between free loop spaces, cyclic homology, and de Rham cohomology, we are able to quantitatively connect the geometry of finite and affine Hecke algebras, braid groups, and the categorical parameters of representations of real and complex reductive groups. Our analysis provides a uniform geometric construction of Langlands parameters, and lays the groundwork for applying the Geometric Langlands Program to the local Langlands Program of both the real and complex kind.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0322}
{"prompt": "Rephrase the abstract of an article with title 'Optimal Investment with an Unbounded Random Endowment and Utility-Based   Pricing'.   This paper studies the problem of maximizing the expected utility of terminal wealth for a financial agent with an unbounded random endowment, and with a utility function which supports both positive and negative wealth. We prove the existence of an optimal trading strategy within a class of permissible strategies -- those strategies whose wealth process is a supermartingale under all pricing measures with finite relative entropy. We give necessary and sufficient conditions for the absence of utility-based arbitrage, and for the existence of a solution to the primal problem.   We consider two utility-based methods which can be used to price contingent claims. Firstly we investigate marginal utility-based price processes (MUBPP's). We show that such processes can be characterized as local martingales under the normalized optimal dual measure for the utility maximizing investor. Finally, we present some new results on utility indifference prices, including continuity properties and volume asymptotics for the case of a general utility function, unbounded endowment and unbounded contingent claims.  ", "human_text": "  This paper studies the problem of maximizing the expected utility of terminal wealth for a financial agent with an unbounded random endowment, and with a utility function which supports both positive and negative wealth. We prove the existence of an optimal trading strategy within a class of permissible strategies -- those strategies whose wealth process is a supermartingale under all pricing measures with finite relative entropy. We give necessary and sufficient conditions for the absence of utility-based arbitrage, and for the existence of a solution to the primal problem.   We consider two utility-based methods which can be used to price contingent claims. Firstly we investigate marginal utility-based price processes (MUBPP's). We show that such processes can be characterized as local martingales under the normalized optimal dual measure for the utility maximizing investor. Finally, we present some new results on utility indifference prices, including continuity properties and volume asymptotics for the case of a general utility function, unbounded endowment and unbounded contingent claims. ", "machine_text": " This paper explores the problem of optimizing a financial agent's expected utility of terminal wealth when there is an unbounded random endowment and a utility function with the capacity to support both positive and negative wealth. We prove that an optimal trading strategy exists within a prescribed class of strategies with a supermartingale-based wealth process under pricing measures of finite relative entropy. Necessary and sufficient conditions are proposed for utility-based arbitrage avoidance and the solution to the primary problem. Two utility-based approaches, marginal utility-based price processes (MUBPP's) and utility indifference prices, are utilized in the pricing of contingent claims. Characterization of MUBPP's as local martingales under the normalized optimal dual measure for the utility maximizing investor is outlined. Furthermore, properties of utility indifference pricing, such as continuity and volume asymptotics for the context of unbounded endowment and claims, are presented.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0478}
{"prompt": "Rephrase the abstract of an article with title 'Improved constraints on dark energy from Chandra X-ray observations of   the largest relaxed galaxy clusters'.   We present constraints on the mean matter density, Omega_m, dark energy density, Omega_de, and the dark energy equation of state parameter, w, using Chandra measurements of the X-ray gas mass fraction (fgas) in 42 hot (kT>5keV), X-ray luminous, dynamically relaxed galaxy clusters spanning the redshift range 0.05<z<1.1. Using only the fgas data for the 6 lowest redshift clusters at z<0.15, for which dark energy has a negligible effect on the measurements, we measure Omega_m=0.28+-0.06 (68% confidence, using standard priors on the Hubble Constant, H_0, and mean baryon density, Omega_bh^2). Analyzing the data for all 42 clusters, employing only weak priors on H_0 and Omega_bh^2, we obtain a similar result on Omega_m and detect the effects of dark energy on the distances to the clusters at ~99.99% confidence, with Omega_de=0.86+-0.21 for a non-flat LCDM model. The detection of dark energy is comparable in significance to recent SNIa studies and represents strong, independent evidence for cosmic acceleration. Systematic scatter remains undetected in the fgas data, despite a weighted mean statistical scatter in the distance measurements of only ~5%. For a flat cosmology with constant w, we measure Omega_m=0.28+-0.06 and w=-1.14+-0.31. Combining the fgas data with independent constraints from CMB and SNIa studies removes the need for priors on Omega_bh^2 and H_0 and leads to tighter constraints: Omega_m=0.253+-0.021 and w=-0.98+-0.07 for the same constant-w model. More general analyses in which we relax the assumption of flatness and/or allow evolution in w remain consistent with the cosmological constant paradigm. Our analysis includes conservative allowances for systematic uncertainties. The small systematic scatter and tight constraints bode well for future dark energy studies using the fgas method. (Abridged)  ", "human_text": "  We present constraints on the mean matter density, Omega_m, dark energy density, Omega_de, and the dark energy equation of state parameter, w, using Chandra measurements of the X-ray gas mass fraction (fgas) in 42 hot (kT>5keV), X-ray luminous, dynamically relaxed galaxy clusters spanning the redshift range 0.05<z<1.1. Using only the fgas data for the 6 lowest redshift clusters at z<0.15, for which dark energy has a negligible effect on the measurements, we measure Omega_m=0.28+-0.06 (68% confidence, using standard priors on the Hubble Constant, H_0, and mean baryon density, Omega_bh^2). Analyzing the data for all 42 clusters, employing only weak priors on H_0 and Omega_bh^2, we obtain a similar result on Omega_m and detect the effects of dark energy on the distances to the clusters at ~99.99% confidence, with Omega_de=0.86+-0.21 for a non-flat LCDM model. The detection of dark energy is comparable in significance to recent SNIa studies and represents strong, independent evidence for cosmic acceleration. Systematic scatter remains undetected in the fgas data, despite a weighted mean statistical scatter in the distance measurements of only ~5%. For a flat cosmology with constant w, we measure Omega_m=0.28+-0.06 and w=-1.14+-0.31. Combining the fgas data with independent constraints from CMB and SNIa studies removes the need for priors on Omega_bh^2 and H_0 and leads to tighter constraints: Omega_m=0.253+-0.021 and w=-0.98+-0.07 for the same constant-w model. More general analyses in which we relax the assumption of flatness and/or allow evolution in w remain consistent with the cosmological constant paradigm. Our analysis includes conservative allowances for systematic uncertainties. The small systematic scatter and tight constraints bode well for future dark energy studies using the fgas method. (Abridged) ", "machine_text": " Using Chandra X-ray observations of 42 of the most massive, X-ray luminous, and dynamically relaxed galaxy clusters over a redshift range of 0.05 to 1.1, we have determined constraints on the mean matter density, Omega_m, dark energy density, Omega_de, and the dark energy equation of state parameter, w. Using the 6 lowest redshift clusters, for which the dark energy has a minimal influence, we measure Omega_m to be 0.28 with a 68% confidence interval when applying standard priors on the Hubble Constant, H_0, and the mean baryon density, Omega_bh^2. Furthermore, by analyzing the entire sample for a non-flat LCDM model we detect the effects of dark energy at a very high confidence level. In addition, our fgas data has a weighted mean statistical scatter of just 5%, and combining our results with other studies of CMB and SNIa allows us to remove prior assumptions of Omega_bh and H_0, producing more specific results of Omega_m and w that support the cosmological constant paradigm. This study is remarkable in its precision and accuracy and lays the foundation for future dark energy investigations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0033}
{"prompt": "Rephrase the abstract of an article with title 'Two-sided optimal bounds for Green function of half-spaces for   relativistic $\\alpha$-stable process'.   The purpose of this paper is to find optimal estimates for the Green function of a half-space of {\\it the relativistic $\\alpha$-stable process} with parameter $m$ on $\\Rd$ space. This process has an infinitesimal generator of the form $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2},$ where $0<\\alpha<2$, $m>0$, and reduces to the isotropic $\\alpha$-stable process for $m=0$. Its potential theory for open bounded sets has been well developed throughout the recent years however almost nothing was known about the behaviour of the process on unbounded sets. The present paper is intended to fill this gap and we provide two-sided sharp estimates for the Green function for a half-space. As a byproduct we obtain some improvements of the estimates known for bounded sets specially for balls. The advantage of these estimates is a clarification of the relationship between the diameter of the ball and the parameter $m$ of the process.   The main result states that the Green function is comparable with the Green function for the Brownian motion if the points are away from the boundary of a half-space and their distance is greater than one. On the other hand for the remaining points the Green function is somehow related the Green function for the isotropic $\\alpha$-stable process. For example, for $d\\ge3$, it is comparable with the Green function for the isotropic $\\alpha$-stable process, provided that the points are close enough.  ", "human_text": "  The purpose of this paper is to find optimal estimates for the Green function of a half-space of {\\it the relativistic $\\alpha$-stable process} with parameter $m$ on $\\Rd$ space. This process has an infinitesimal generator of the form $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2},$ where $0<\\alpha<2$, $m>0$, and reduces to the isotropic $\\alpha$-stable process for $m=0$. Its potential theory for open bounded sets has been well developed throughout the recent years however almost nothing was known about the behaviour of the process on unbounded sets. The present paper is intended to fill this gap and we provide two-sided sharp estimates for the Green function for a half-space. As a byproduct we obtain some improvements of the estimates known for bounded sets specially for balls. The advantage of these estimates is a clarification of the relationship between the diameter of the ball and the parameter $m$ of the process.   The main result states that the Green function is comparable with the Green function for the Brownian motion if the points are away from the boundary of a half-space and their distance is greater than one. On the other hand for the remaining points the Green function is somehow related the Green function for the isotropic $\\alpha$-stable process. For example, for $d\\ge3$, it is comparable with the Green function for the isotropic $\\alpha$-stable process, provided that the points are close enough. ", "machine_text": "  This paper focuses on finding optimal estimates for the Green function of  the relativistic $\\alpha$-stable process defined on a half-space. This process possesses an infinitesimal generator given by $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2}$ where $0<\\alpha<2$, $m>0$, and the process reduces to the isotropic $\\alpha$-stable process for $m=0$. Two-sided sharp bounds are provided for the Green function for the half-space, as well as for bounded domains such as balls. These estimates capture the relationship between the diameter of the ball and $m$ of the process. It is found that for points away from the boundary of a half-space and when the distance between them is greater than one, the Green function is comparable to the Green function for the Brownian motion. For points closer to the boundary, the Green function is related to the Green function for the isotropic $\\alpha$-stable process. It is found that for $d\\ge3$, it is comparable with the Green function for the isotropic $\\alpha$-stable process if the points are close enough.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1175}
{"prompt": "Rephrase the abstract of an article with title 'Simulation of symmetric nuclei and the role of Pauli potential in   binding energies and radii'.   It is shown that the use of a density dependent effective Pauli potential together with a nucleon-nucleon interaction potential plays a crucial role to reproduce not only the binding energies but also the matter root mean square radii of medium mass range spin-isospin saturated nuclei. This study is performed with a semiclassical Monte Carlo many-body simulation within the context of a simplified nucleon-nucleon interaction to focus on the effect of the genuine correlations due to the fermionic nature of nucleons. The procedure obtained is rather robust and it does not depend on the detailed features of the nucleon-nucleon interaction. For nuclei below saturation the density dependence may be represented in terms either of the nucleon number, $A$, or the associated Fermi momenta. When testing the simulation procedure for idealized \"infinite\" symmetric nuclear matter within the corresponding range of densities, it turns out that finite size effects affect the Pauli potential strength parametrization in systems up to about 120 particles while remaining approximately stable for larger systems.  ", "human_text": "  It is shown that the use of a density dependent effective Pauli potential together with a nucleon-nucleon interaction potential plays a crucial role to reproduce not only the binding energies but also the matter root mean square radii of medium mass range spin-isospin saturated nuclei. This study is performed with a semiclassical Monte Carlo many-body simulation within the context of a simplified nucleon-nucleon interaction to focus on the effect of the genuine correlations due to the fermionic nature of nucleons. The procedure obtained is rather robust and it does not depend on the detailed features of the nucleon-nucleon interaction. For nuclei below saturation the density dependence may be represented in terms either of the nucleon number, $A$, or the associated Fermi momenta. When testing the simulation procedure for idealized \"infinite\" symmetric nuclear matter within the corresponding range of densities, it turns out that finite size effects affect the Pauli potential strength parametrization in systems up to about 120 particles while remaining approximately stable for larger systems. ", "machine_text": " This study presents the effects of employing a Pauli potential with a density-dependent effective framework to account for the binding energies and root mean square radii of nuclei in a medium mass range. Monte Carlo many-body simulation is used within a simplified nucleon-nucleon interaction to determine the correlations attributable to the fermionic character of nucleons. The method is demonstrated to be agnostic to the details of the nucleon-nucleon interaction. When evaluating the procedure for symmetric nuclear matter at various densities with simulations containing up to 120 nucleons, it is revealed that finite size effects may influence the Pauli potential strength parametrization. However, for larger systems, this effect remains consistent.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0958}
{"prompt": "Rephrase the abstract of an article with title 'Dislocation Dynamics in a Crystal Lattice (Peierls-Nabarro) Relief'.   The theory of the dislocation motion in the periodic potential relief of the crystal lattice (the Peierls-Nabarro barriers) is reviewed. On the basis of the kink mechanism the temperature dependence of the flow stress is described for a wide class of materials. The theory of quantum mechanical dislocation tunnelling through the Peierls-Nabarro barriers is extended and compared with experimental data on the plasticity of alkali halides, BCC and HCP metals at low temperatures. The behavior of the flow stress at the range of athermic anomalies is modeled by changing the mechanism of the dislocation motion from the thermally activated hopping over the barriers to the quantum tunnelling through them. Some results of previous calculations are represented in a more explicit convenient for applications form. The pronounced effect of the switching between the normal and the superconducting states on the flow stress of metals is explained on the basis of the change in the dissipative properties of the electron subsystem affecting the dislocation motion.  ", "human_text": "  The theory of the dislocation motion in the periodic potential relief of the crystal lattice (the Peierls-Nabarro barriers) is reviewed. On the basis of the kink mechanism the temperature dependence of the flow stress is described for a wide class of materials. The theory of quantum mechanical dislocation tunnelling through the Peierls-Nabarro barriers is extended and compared with experimental data on the plasticity of alkali halides, BCC and HCP metals at low temperatures. The behavior of the flow stress at the range of athermic anomalies is modeled by changing the mechanism of the dislocation motion from the thermally activated hopping over the barriers to the quantum tunnelling through them. Some results of previous calculations are represented in a more explicit convenient for applications form. The pronounced effect of the switching between the normal and the superconducting states on the flow stress of metals is explained on the basis of the change in the dissipative properties of the electron subsystem affecting the dislocation motion. ", "machine_text": " This paper reviews the theory surrounding the motion of dislocations within the periodic potential relief of a crystal lattice, known as the Peierls-Nabarro barriers. Based on the kink mechanism, a description is provided of the invariable temperature dependent flow stress experienced in certain types of materials. The theory of quantum mechanical dislocation tunnelling is expanded on and compared with experimental data exploring the plasticity of alkali halides, BCC and HCP metals at low temperatures. Furthermore, the behaviour of the flow stress between points of athermic anomalies is modelled by switching the mechanism of dislocation movement from one that is thermally activated and jumps over barriers, to tunnelling through them via quantum mechanics. Previous calculations are adjusted in order to make them more applicable in usage, with a specific focus on the perceptible impact on metal flow stress when switching between the normal and superconducting states due to changes in the dissipative properties of the electron subsystem, affecting the dislocation motion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1714}
{"prompt": "Rephrase the abstract of an article with title 'The Kalman--Yakubovich--Popov inequality for passive discrete   time-invariant systems'.   We consider the Kalman - Yakubovich - Popov (KYP) inequality \\[ \\begin{pmatrix} X-A^* XA-C^*C & -A^*X B- C^*D\\cr -B^*X A-D^* C & I- B^*X B-D^*D \\end{pmatrix} \\ge 0 \\] for contractive operator matrices $ \\begin{pmatrix} A&B\\cr C &D \\end{pmatrix}:\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{M} \\end{pmatrix}\\to\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{N} \\end{pmatrix}, $ where $\\mathfrak{H},$ $\\mathfrak{M}$, and $\\mathfrak{N}$ are separable Hilbert spaces. We restrict ourselves to the solutions $X$ from the operator interval $[0, I_\\mathfrak{H}]$. Several equivalent forms of KYP are obtained. Using the parametrization of the blocks of contractive operator matrices, the Kre\\u{\\i}n shorted operator, and the M\\\"obius representation of the Schur class operator-valued function we find several equivalent forms of the KYP inequality. Properties of solutions are established and it is proved that the minimal solution of the KYP inequality satisfies the corresponding algebraic Riccati equation and can be obtained by the iterative procedure with the special choice of the initial point. In terms of the Kre\\u{\\i}n shorted operators a necessary condition and some sufficient conditions for uniqueness of the solution are established.  ", "human_text": "  We consider the Kalman - Yakubovich - Popov (KYP) inequality \\[ \\begin{pmatrix} X-A^* XA-C^*C & -A^*X B- C^*D\\cr -B^*X A-D^* C & I- B^*X B-D^*D \\end{pmatrix} \\ge 0 \\] for contractive operator matrices $ \\begin{pmatrix} A&B\\cr C &D \\end{pmatrix}:\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{M} \\end{pmatrix}\\to\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{N} \\end{pmatrix}, $ where $\\mathfrak{H},$ $\\mathfrak{M}$, and $\\mathfrak{N}$ are separable Hilbert spaces. We restrict ourselves to the solutions $X$ from the operator interval $[0, I_\\mathfrak{H}]$. Several equivalent forms of KYP are obtained. Using the parametrization of the blocks of contractive operator matrices, the Kre\\u{\\i}n shorted operator, and the M\\\"obius representation of the Schur class operator-valued function we find several equivalent forms of the KYP inequality. Properties of solutions are established and it is proved that the minimal solution of the KYP inequality satisfies the corresponding algebraic Riccati equation and can be obtained by the iterative procedure with the special choice of the initial point. In terms of the Kre\\u{\\i}n shorted operators a necessary condition and some sufficient conditions for uniqueness of the solution are established. ", "machine_text": " This paper investigates the Kalman - Yakubovich - Popov (KYP) inequality for contractive operator matrices for passive discrete-time systems. Different forms of the KYP inequality are defined and properties of solutions are studied. We look further into situations where a minimal solution satisfies a corresponding Riccati equation and can be obtained iteratively with a specified initial point. The Krein shorted operator is employed to obtain a necessary condition and some sufficient conditions for the uniqueness of the solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0653}
{"prompt": "Rephrase the abstract of an article with title 'Spin Evolution of Accreting Neutron Stars: Nonlinear Development of the   R-mode Instability'.   The nonlinear saturation of the r-mode instability and its effects on the spin evolution of Low Mass X-ray Binaries (LMXBs) are modeled using the triplet of modes at the lowest parametric instability threshold. We solve numerically the coupled equations for the three mode amplitudes in conjunction with the spin and temperature evolution equations. We observe that very quickly the mode amplitudes settle into quasi-stationary states. Once these states are reached, the mode amplitudes can be found algebraically and the system of equations is reduced from eight to two equations: spin and temperature evolution. Eventually, the system may reach thermal equilibrium and either (1) undergo a cyclic evolution with a frequency change of at most 10%, (2) evolve toward a full equilibrium state in which the accretion torque balances the gravitational radiation emission, or (3) enter a thermogravitational runaway on a very long timescale of about $10^6$ years. Alternatively, a faster thermal runaway (timescale of about 100 years) may occur. The sources of damping considered are shear viscosity, hyperon bulk viscosity and boundary layer viscosity. We vary proprieties of the star such as the hyperon superfluid transition temperature T_c, the fraction of the star that is above the threshold for direct URCA reactions, and slippage factor, and map the different scenarios we obtain to ranges of these parameters. For all our bound evolutions the r-mode amplitude remains small $\\sim 10^{-5}$. The spin frequency is limited by boundary layer viscosity to $\\nu_{max} \\sim 800 Hz [S_{ns}/(M_{1.4} R_6)]^{4/11} T_8^{-2/11}$. We find that for $\\nu > 700$ Hz the r-mode instability would be active for about 1 in 1000 LMXBs and that only the gravitational waves from LMXBs in the local group of galaxies could be detected by advanced LIGO interferometers.  ", "human_text": "  The nonlinear saturation of the r-mode instability and its effects on the spin evolution of Low Mass X-ray Binaries (LMXBs) are modeled using the triplet of modes at the lowest parametric instability threshold. We solve numerically the coupled equations for the three mode amplitudes in conjunction with the spin and temperature evolution equations. We observe that very quickly the mode amplitudes settle into quasi-stationary states. Once these states are reached, the mode amplitudes can be found algebraically and the system of equations is reduced from eight to two equations: spin and temperature evolution. Eventually, the system may reach thermal equilibrium and either (1) undergo a cyclic evolution with a frequency change of at most 10%, (2) evolve toward a full equilibrium state in which the accretion torque balances the gravitational radiation emission, or (3) enter a thermogravitational runaway on a very long timescale of about $10^6$ years. Alternatively, a faster thermal runaway (timescale of about 100 years) may occur. The sources of damping considered are shear viscosity, hyperon bulk viscosity and boundary layer viscosity. We vary proprieties of the star such as the hyperon superfluid transition temperature T_c, the fraction of the star that is above the threshold for direct URCA reactions, and slippage factor, and map the different scenarios we obtain to ranges of these parameters. For all our bound evolutions the r-mode amplitude remains small $\\sim 10^{-5}$. The spin frequency is limited by boundary layer viscosity to $\\nu_{max} \\sim 800 Hz [S_{ns}/(M_{1.4} R_6)]^{4/11} T_8^{-2/11}$. We find that for $\\nu > 700$ Hz the r-mode instability would be active for about 1 in 1000 LMXBs and that only the gravitational waves from LMXBs in the local group of galaxies could be detected by advanced LIGO interferometers. ", "machine_text": " A numerical study was conducted to investigate the nonlinear saturation of the r-mode instability and its effects on the spin evolution of Low Mass X-ray Binaries (LMXBs). By solving the equations for the three mode amplitudes in conjunction with the spin and temperature evolution equations, the system eventually reaches either a cyclic evolution with a frequency change of at most 10%, a full equilibrium state in which the accretion torque balances the gravitational radiation emission, or a thermogravitational runaway. Various sources of damping such as shear viscosity, hyperon bulk viscosity and boundary layer viscosity are considered, along with properties of the star like the hyperon superfluid transition temperature, the fraction of the star that is above the threshold for direct URCA reactions, and slippage factor. Results of the study suggest that for $\\nu > 700$ Hz the r-mode instability would be active for about 1 in 1000 LMXBs, and that only the gravitational waves from LMXBs in the local group of galaxies could be detected by advanced LIGO interferometers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0799}
{"prompt": "Rephrase the abstract of an article with title 'Sensor Networks with Random Links: Topology Design for Distributed   Consensus'.   In a sensor network, in practice, the communication among sensors is subject to:(1) errors or failures at random times; (3) costs; and(2) constraints since sensors and networks operate under scarce resources, such as power, data rate, or communication. The signal-to-noise ratio (SNR) is usually a main factor in determining the probability of error (or of communication failure) in a link. These probabilities are then a proxy for the SNR under which the links operate. The paper studies the problem of designing the topology, i.e., assigning the probabilities of reliable communication among sensors (or of link failures) to maximize the rate of convergence of average consensus, when the link communication costs are taken into account, and there is an overall communication budget constraint. To consider this problem, we address a number of preliminary issues: (1) model the network as a random topology; (2) establish necessary and sufficient conditions for mean square sense (mss) and almost sure (a.s.) convergence of average consensus when network links fail; and, in particular, (3) show that a necessary and sufficient condition for both mss and a.s. convergence is for the algebraic connectivity of the mean graph describing the network topology to be strictly positive. With these results, we formulate topology design, subject to random link failures and to a communication cost constraint, as a constrained convex optimization problem to which we apply semidefinite programming techniques. We show by an extensive numerical study that the optimal design improves significantly the convergence speed of the consensus algorithm and can achieve the asymptotic performance of a non-random network at a fraction of the communication cost.  ", "human_text": "  In a sensor network, in practice, the communication among sensors is subject to:(1) errors or failures at random times; (3) costs; and(2) constraints since sensors and networks operate under scarce resources, such as power, data rate, or communication. The signal-to-noise ratio (SNR) is usually a main factor in determining the probability of error (or of communication failure) in a link. These probabilities are then a proxy for the SNR under which the links operate. The paper studies the problem of designing the topology, i.e., assigning the probabilities of reliable communication among sensors (or of link failures) to maximize the rate of convergence of average consensus, when the link communication costs are taken into account, and there is an overall communication budget constraint. To consider this problem, we address a number of preliminary issues: (1) model the network as a random topology; (2) establish necessary and sufficient conditions for mean square sense (mss) and almost sure (a.s.) convergence of average consensus when network links fail; and, in particular, (3) show that a necessary and sufficient condition for both mss and a.s. convergence is for the algebraic connectivity of the mean graph describing the network topology to be strictly positive. With these results, we formulate topology design, subject to random link failures and to a communication cost constraint, as a constrained convex optimization problem to which we apply semidefinite programming techniques. We show by an extensive numerical study that the optimal design improves significantly the convergence speed of the consensus algorithm and can achieve the asymptotic performance of a non-random network at a fraction of the communication cost. ", "machine_text": " This paper investigates the challenge of designing the topology of a sensor network to optimise the rate at which average consensus is obtained given the uncertainties in communication failures or errors, power and data rate limits or constraints, and the SNR of links. We show how this problem can be modelled as a constrained convex optimisation and can be solved using semidefinite programming, and demonstrate through extensive numerical research how the optimal topology design can improve the speed of consensus algorithm to approach the performance of a non-random network, but with a significantly lower communication cost. Necessary and sufficient conditions for mss and almost sure convergence of average consensus when links fail are established in the paper, and a pivotal role for the algebraic connectivity of the mean graph in determining such convergence is also highlighted.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0954}
{"prompt": "Rephrase the abstract of an article with title 'Lower order terms in the 1-level density for families of holomorphic   cuspidal newforms'.   The Katz-Sarnak density conjecture states that, in the limit as the conductors tend to infinity, the behavior of normalized zeros near the central point of families of L-functions agree with the N -> oo scaling limits of eigenvalues near 1 of subgroups of U(N). Evidence for this has been found for many families by studying the n-level densities; for suitably restricted test functions the main terms agree with random matrix theory. In particular, all one-parameter families of elliptic curves with rank r over Q(T) and the same distribution of signs of functional equations have the same limiting behavior. We break this universality and find family dependent lower order correction terms in many cases; these lower order terms have applications ranging from excess rank to modeling the behavior of zeros near the central point, and depend on the arithmetic of the family. We derive an alternate form of the explicit formula for GL(2) L-functions which simplifies comparisons, replacing sums over powers of Satake parameters by sums of the moments of the Fourier coefficients lambda_f(p). Our formula highlights the differences that we expect to exist from families whose Fourier coefficients obey different laws (for example, we expect Sato-Tate to hold only for non-CM families of elliptic curves). Further, by the work of Rosen and Silverman we expect lower order biases to the Fourier coefficients in families of elliptic curves with rank over Q(T); these biases can be seen in our expansions. We analyze several families of elliptic curves and see different lower order corrections, depending on whether or not the family has complex multiplication, a forced torsion point, or non-zero rank over Q(T).  ", "human_text": "  The Katz-Sarnak density conjecture states that, in the limit as the conductors tend to infinity, the behavior of normalized zeros near the central point of families of L-functions agree with the N -> oo scaling limits of eigenvalues near 1 of subgroups of U(N). Evidence for this has been found for many families by studying the n-level densities; for suitably restricted test functions the main terms agree with random matrix theory. In particular, all one-parameter families of elliptic curves with rank r over Q(T) and the same distribution of signs of functional equations have the same limiting behavior. We break this universality and find family dependent lower order correction terms in many cases; these lower order terms have applications ranging from excess rank to modeling the behavior of zeros near the central point, and depend on the arithmetic of the family. We derive an alternate form of the explicit formula for GL(2) L-functions which simplifies comparisons, replacing sums over powers of Satake parameters by sums of the moments of the Fourier coefficients lambda_f(p). Our formula highlights the differences that we expect to exist from families whose Fourier coefficients obey different laws (for example, we expect Sato-Tate to hold only for non-CM families of elliptic curves). Further, by the work of Rosen and Silverman we expect lower order biases to the Fourier coefficients in families of elliptic curves with rank over Q(T); these biases can be seen in our expansions. We analyze several families of elliptic curves and see different lower order corrections, depending on whether or not the family has complex multiplication, a forced torsion point, or non-zero rank over Q(T). ", "machine_text": " This paper confirms evidence for the Katz-Sarnak density conjecture, as many families of L-functions show agreement with the N -> oo scaling limits of eigenvalues near 1 of subgroups of U(N). We find that even for suitably restricted test functions, there can be family dependent lower order correction terms in the 1-level density, which have wide-ranging applications from the theory of excess rank to predicting the behavior of zeros near the central point. We also derive a more suitable explicit formula for GL(2) L-functions which facilitates making comparisons among various families. Notably, this expression shines light on differences in behavior seen by families whose Fourier coefficients follow different laws. We investigate a host of families of elliptic curves and uncover differing lower order corrections that are contingent upon the background features of the family such as complex multiplication, a forced torsion point, and non-zero rank over Q(T).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0924}
{"prompt": "Rephrase the abstract of an article with title 'The interplay of university and industry through the FP5 network'.   To improve the quality of life in a modern society it is essential to reduce the distance between basic research and applications, whose crucial roles in shaping today's society prompt us to seek their understanding. Existing studies on this subject, however, have neglected the network character of the interaction between university and industry. Here we use state-of-the-art network theory methods to analyze this interplay in the so-called Framework Programme--an initiative which sets out the priorities for the European Union's research and technological development. In particular we study in the 5th Framework Programme (FP5) the role played by companies and scientific institutions and how they contribute to enhance the relationship between research and industry. Our approach provides quantitative evidence that while firms are size hierarchically organized, universities and research organizations keep the network from falling into pieces, paving the way for an effective knowledge transfer.  ", "human_text": "  To improve the quality of life in a modern society it is essential to reduce the distance between basic research and applications, whose crucial roles in shaping today's society prompt us to seek their understanding. Existing studies on this subject, however, have neglected the network character of the interaction between university and industry. Here we use state-of-the-art network theory methods to analyze this interplay in the so-called Framework Programme--an initiative which sets out the priorities for the European Union's research and technological development. In particular we study in the 5th Framework Programme (FP5) the role played by companies and scientific institutions and how they contribute to enhance the relationship between research and industry. Our approach provides quantitative evidence that while firms are size hierarchically organized, universities and research organizations keep the network from falling into pieces, paving the way for an effective knowledge transfer. ", "machine_text": " In order to develop a strong economy and maintain a high quality of life, bridging the gap between theory and practical application is essential. Previous studies on this issue, however, have not explored the interplay between university and industry using a network perspective. To fill this gap, we applied the latest network theory methods to study the impact of the 5th Framework Programme of the European Union research and technological advances. Specifically, we analysed the role of companies and scientific institutions to strengthen the link between research and industry. Our results provide quantitative evidence that, despite firms being hierarchically structured by size, universities and research organisations keep the network connected, providing an effective knowledge transfer.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0353}
{"prompt": "Rephrase the abstract of an article with title 'The 74MHz System on the Very Large Array'.   The Naval Research Laboratory and the National Radio Astronomy Observatory completed implementation of a low frequency capability on the VLA at 73.8 MHz in 1998. This frequency band offers unprecedented sensitivity (~25 mJy/beam) and resolution (~25 arcsec) for low-frequency observations. We review the hardware, the calibration and imaging strategies, comparing them to those at higher frequencies, including aspects of interference excision and wide-field imaging. Ionospheric phase fluctuations pose the major difficulty in calibrating the array. Over restricted fields of view or at times of extremely quiescent ionospheric ``weather'', an angle-invariant calibration strategy can be used. In this approach a single phase correction is devised for each antenna, typically via self-calibration. Over larger fields of view or at times of more normal ionospheric ``weather'' when the ionospheric isoplanatic patch size is smaller than the field of view, we adopt a field-based strategy in which the phase correction depends upon location within the field of view. This second calibration strategy was implemented by modeling the ionosphere above the array using Zernike polynomials. Images of 3C sources of moderate strength are provided as examples of routine, angle-invariant calibration and imaging. Flux density measurements indicate that the 74 MHz flux scale at the VLA is stable to a few percent, and tied to the Baars et al. value of Cygnus A at the 5 percent level. We also present an example of a wide-field image, devoid of bright objects and containing hundreds of weaker sources, constructed from the field-based calibration. We close with a summary of lessons the 74 MHz system offers as a model for new and developing low-frequency telescopes. (Abridged)  ", "human_text": "  The Naval Research Laboratory and the National Radio Astronomy Observatory completed implementation of a low frequency capability on the VLA at 73.8 MHz in 1998. This frequency band offers unprecedented sensitivity (~25 mJy/beam) and resolution (~25 arcsec) for low-frequency observations. We review the hardware, the calibration and imaging strategies, comparing them to those at higher frequencies, including aspects of interference excision and wide-field imaging. Ionospheric phase fluctuations pose the major difficulty in calibrating the array. Over restricted fields of view or at times of extremely quiescent ionospheric ``weather'', an angle-invariant calibration strategy can be used. In this approach a single phase correction is devised for each antenna, typically via self-calibration. Over larger fields of view or at times of more normal ionospheric ``weather'' when the ionospheric isoplanatic patch size is smaller than the field of view, we adopt a field-based strategy in which the phase correction depends upon location within the field of view. This second calibration strategy was implemented by modeling the ionosphere above the array using Zernike polynomials. Images of 3C sources of moderate strength are provided as examples of routine, angle-invariant calibration and imaging. Flux density measurements indicate that the 74 MHz flux scale at the VLA is stable to a few percent, and tied to the Baars et al. value of Cygnus A at the 5 percent level. We also present an example of a wide-field image, devoid of bright objects and containing hundreds of weaker sources, constructed from the field-based calibration. We close with a summary of lessons the 74 MHz system offers as a model for new and developing low-frequency telescopes. (Abridged) ", "machine_text": " This paper reviews the implementation of a low frequency capability on the Very Large Array at 73.8 MHz and its associated hardware, calibration and imaging strategies. Challenges associated with ionospheric phase fluctuation calibration are discussed, as well as strategies for addressing them - angle-invariant and field-based. Examples of routine angle-invariant calibration and imaging are provided, along with a flux density measure of the VLA's 74 MHz flux scale stability and an example of a wide-field image from the field-based calibration. Finally, the paper sumarizes the lessons the 74MHz system offers for new and developing low-frequency telescopes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3088}
