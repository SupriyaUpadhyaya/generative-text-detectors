title,abstract,machine_abstract,source,model,source_id,no_sentence_human,no_sentence_machine,num_words_human,num_words_machine,character0_human,character1_human,character2_3_human,character4_human,character5_human,character0_machine,character1_machine,character2_3_machine,character4_machine,character5_machine,std_dev_human,std_dev_machine,sent_len_diff_human,sent_len_diff_machine,count_short_sentences_in_paragraphs_human,count_short_sentences_in_paragraphs_machine,count_long_sentences_in_paragraphs_human,count_long_sentences_in_paragraphs_machine,check_word0_human,check_word1_human,check_word2_3_human,check_word3_human,check_word4_human,check_word5_human,check_word0_machine,check_word1_machine,check_word2_3_machine,check_word3_machine,check_word4_machine,check_word5_machine,check_num_human,check_num_machine,check_capitals_human,check_capitals_machine,check_et_human,check_et_machine
Faithful Effective-One-Body waveforms of small-mass-ratio coalescing black-hole binaries,"  We address the problem of constructing high-accuracy, faithful analytic
waveforms describing the gravitational wave signal emitted by inspiralling and
coalescing binary black holes. We work within the Effective-One-Body (EOB)
framework and propose a methodology for improving the current
(waveform)implementations of this framework based on understanding, element by
element, the physics behind each feature of the waveform, and on systematically
comparing various EOB-based waveforms with ``exact'' waveforms obtained by
numerical relativity approaches. The present paper focuses on small-mass-ratio
non-spinning binary systems, which can be conveniently studied by
Regge-Wheeler-Zerilli-type methods. Our results include: (i) a resummed,
3PN-accurate description of the inspiral waveform, (ii) a better description of
radiation reaction during the plunge, (iii) a refined analytic expression for
the plunge waveform, (iv) an improved treatment of the matching between the
plunge and ring-down waveforms. This improved implementation of the EOB
approach allows us to construct complete analytic waveforms which exhibit a
remarkable agreement with the ``exact'' ones in modulus, frequency and phase.
In particular, the analytic and numerical waveforms stay in phase, during the
whole process, within $\pm 1.1 %$ of a cycle. We expect that the extension of
our methodology to the comparable-mass case will be able to generate comparably
accurate analytic waveforms of direct use for the ground-based network of
interferometric detectors of gravitational waves.
","We present the first results for effective-one-body (EOB) waveforms that are faithful to numerical relativity simulations over an entire inspiral, merger and ringdown phase of binary black hole systems with mass ratios q = m1/m2 as low as 1/10.  We use EOB theory in conjunction with fits to numerical-relativity data to construct accurate templates for gravitational waves emitted by such systems. The resulting template bank is used to search for signals from these sources using LIGO's second observing run data. Our analysis shows that this new class of EOB waveforms can be used to detect binary black holes out to redshifts z ~ 5 at design sensitivity of Advanced LIGO/VIRGO detectors. This represents a significant improvement compared to previous searches based on post-Newtonian approximations or phenomenological models. 
The detection rate of binary black holes predicted by our analysis agrees well with current estimates obtained within the standard ΛCDM cosmology model.",arxiv,bigscience bloomz,705.2519,0.3333333333333333,0.24369747899159663,0.4717948717948718,0.3836598184424272,1,1,1,0,1,1,1,0,0,1,0.1420201444765811,0.07226943955359821,0.1556420233463035,0.06060606060606061,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Pairing based cooling of Fermi gases,"  We propose a pairing-based method for cooling an atomic Fermi gas. A three
component (labels 1, 2, 3) mixture of Fermions is considered where the
components 1 and 2 interact and, for instance, form pairs whereas the component
3 is in the normal state. For cooling, the components 2 and 3 are coupled by an
electromagnetic field. Since the quasiparticle distributions in the paired and
in the normal states are different, the coupling leads to cooling of the normal
state even when initially $T_{paired}\geq T_{normal}$ (notation $T_S\geq T_N$).
The cooling efficiency is given by the pairing energy and by the linewidth of
the coupling field. No superfluidity is required: any type of pairing, or other
phenomenon that produces a suitable spectral density, is sufficient. In
principle, the paired state could be cooled as well but this requires
$T_N<T_S$. The method has a conceptual analogy to cooling based on
superconductor -- normal metal (SN) tunneling junctions. Main differences arise
from the exact momentum conservation in the case of the field-matter coupling
vs. non-conservation of momentum in the solid state tunneling process.
Moreover, the role of processes that relax the energy conservation requirement
in the tunneling, e.g. thermal fluctuations of an external reservoir, is now
played by the linewidth of the field. The proposed method should be
experimentally feasible due to its close connection to RF-spectroscopy of
ultracold gases which is already in use.
","We propose to cool fermionic atoms in optical lattices by using the pairing mechanism between two different hyperfine states, which is analogous to Cooper pair formation in superconductors. We show that this method can be used for both bosonic and fermionic systems with attractive interactions. The proposed scheme has several advantages over other methods such as evaporative cooling or sympathetic cooling.  It does not require any additional laser beams besides those needed for trapping and manipulating cold atoms. In addition it works even when there are no free particles present initially (e.g., at zero temperature). Finally we discuss how our proposal could be realized experimentally. Cooling fermions down to quantum degeneracy temperatures below 1 microkelvin remains one of the most challenging problems in atomic physics today [1] . This problem becomes particularly difficult if the initial number density of fermions is high because then elastic collisions cannot remove enough energy from the system [2] .
In recent years, however, new experimental techniques have been developed [3, 4] , allowing us to trap and manipulate cold atoms on an unprecedented level [5] . These developments make it possible to study many-body phenomena [6] like superfluidity [7, 8] and Bose-Einstein condensation [9] in ultracold atomic gases. One important goal in these experiments is to reach quantum degenerate regimes where the gas consists of strongly interacting fermions [10] . However, reaching low temperatures requires efficient cooling schemes [11] .
One promising approach towards achieving this goal is to use the pairing mechanism [12] . Pairs of fermions form bound states called Cooper pairs in conventional superconductors [13] . Analogously, pairs of fermions may also form bound states in ultracold atomic clouds [14] . If the interaction strength between fermions is sufficiently large, they will preferentially bind into pairs rather than remaining unpaired [15] . Therefore, cooling fermions via pairing should work well even",arxiv,bigscience bloomz,705.0271,0.6111111111111112,0.7983193277310925,0.558974358974359,0.8423315814620163,1,1,1,0,0,1,1,0,0,0,0.09293827404362683,0.057488559397069705,0.12062256809338522,0.03787878787878788,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Constraints on the Abundance of Highly Ionized Proto-Cluster Regions from the Absence of Large Voids in the Lyman Alpha Forest,"  Energetic feedback processes during the formation of galaxy clusters may have
heated and ionized a large fraction of the intergalactic gas in proto-cluster
regions. When such a highly ionized hot ``super-bubble'' falls along the
sightline to a background quasar, it would be seen as a large void, with little
or no absorption, in the Lyman alpha forest. We examine the spectra of 137
quasars in the Sloan Digital Sky Survey, to search for such voids, and find no
clear evidence of their existence. The size distribution of voids in the range
5-70 Angstrom (corresponding to physical sizes of approximately 3-35 comoving
Mpc/h) is consistent with the standard model for the Lyman alpha forest without
additional hot bubbles. We adapt a physical model for HII bubble growth during
cosmological reionization (Furlanetto, Zaldarriaga and Hernquist 2004), to
describe the expected size-distribution of hot super-bubbles at redshift around
z = 3. This model incorporates the conjoining of bubbles around individual
neighboring galaxies. Using the non-detection of voids, we find that models in
which the volume filling factor of hot bubbles exceeds approximately 20 percent
at z=3 can be ruled out, primarily because they overproduce the number of large
(40-50 Angstrom) voids. We conclude that any pre-heating mechanism that
explains galaxy cluster observations must avoid heating the low-density gas in
the proto-cluster regions, either by operating relatively recently (z<3) or by
depositing entropy in the high-density regions.
","We use hydrodynamic simulations to study how proto-clusters grow and evolve into galaxy clusters, focusing on their baryon content at high redshifts (z > 5). We find that most of these regions are highly ionized by z = 3 due to photo-heating by UV background radiation. The resulting low neutral hydrogen fraction leads to an under-density of absorbers along the line-of-sight towards such objects compared with lower redshift observations. This effect is more pronounced for higher mass halos which have larger gas fractions than less massive ones. Using this result we derive constraints on the abundance of high-redshift proto-clusters as a function of halo mass. These results can be used to test models of structure formation and reionization. In addition they provide useful input parameters for future studies of cluster scaling relations using weak lensing techniques. 
 
 Keywords: Hydrogen ionization state, Galaxy Cluster, Reionization",arxiv,bigscience bloomz,705.2584,0.3888888888888889,0.3445378151260504,0.5641025641025641,0.3635929288103201,1,1,0,0,1,1,1,1,0,0,0.0943702908784649,0.0443478298707348,0.1245136186770428,0.01893939393939394,0,1,5,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On the Origin of the Dichotomy of Early-Type Galaxies: The Role of Dry Mergers and AGN Feedback,"  Using a semi-analytical model for galaxy formation, combined with a large
N-body simulation, we investigate the origin of the dichotomy among early-type
galaxies. We find that boxy galaxies originate from mergers with a progenitor
mass ratio $n < 2$ and with a combined cold gas mass fraction $F_{\rm cold} <
0.1$. Our model accurately reproduces the observed fraction of boxy systems as
a function of luminosity and halo mass, for both central galaxies and
satellites. After correcting for the stellar mass dependence, the properties of
the last major merger of early-type galaxies are independent of their halo
mass. This provides theoretical support for the conjecture of Pasquali et al
(2007) that the stellar mass of an early-type galaxy is the main parameter that
governs its isophotal shape. We argue that the observed dichotomy of early-type
galaxies has a natural explanation within hierarchical structure formation, and
does not require AGN feedback. Rather, we argue that it owes to the fact that
more massive systems (i) have more massive progenitors, (ii) assemble later,
and (iii) have a larger fraction of early-type progenitors. Each of these three
trends causes the cold gas mass fraction of the progenitors of more massive
early-types to be lower, so that their last major merger was dryer. Finally,
our model predicts that (i) less than 10 percent of all early-type galaxies
form in major mergers that involve two early-type progenitors, (ii) more than
95 percent of all boxy early-type galaxies with $M_* < 2 \times 10^{10} h^{-1}
\Msun$ are satellite galaxies, and (iii) about 70 percent of all low mass
early-types do not form a supermassive black hole binary at their last major
merger. The latter may help to explain why low mass early-types have central
cusps, while their massive counterparts have cores.
","We present an analysis of the evolution of early-type galaxies (ETGs) in hydrodynamical cosmological simulations, focusing on their formation history as well as their internal structure at z = 0. We find that ETG progenitors are typically gas-rich systems with high star formation rates (SFRs), which evolve into red-sequence objects through dry mergers. In addition to this major merger channel for forming ETGs, we show that minor mergers can also contribute significantly to the growth of massive ETGs by bringing in fresh cold gas. Our results suggest that both processes play important roles in shaping the observed properties of local ETGs. This is consistent with recent observational studies showing that most massive ETGs have experienced multiple episodes of merging over cosmic time. 
 
 Keywords: galaxy evolution, galaxy morphology, galaxy scaling relations, galaxy clusters, semi-analytic models, hydrodynamics, dark matter",arxiv,bigscience bloomz,704.0932,0.5,0.24369747899159663,0.882051282051282,0.3463927376970855,1,1,0,0,0,1,1,1,0,0,0.17268056175564162,0.04847712745619124,0.2529182879377432,0.041666666666666664,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0
The Discovery of 1000 km/s Outflows in Massive Post-starburst Galaxies at z=0.6,"  Numerical simulations suggest that active galactic nuclei (AGNs) play an
important role in the formation of early-type galaxies by expelling gas and
dust in powerful galactic winds and quenching star formation. However, the
existence of AGN feedback capable of halting galaxy-wide star formation has yet
to be observationally confirmed. To investigate this question, we have obtained
spectra of 14 post-starburst galaxies at z~0.6 to search for evidence of
galactic winds. In 10/14 galaxies we detect Mg II 2796,2803 absorption lines
which are blueshifted by 490 - 2020 km/s with respect to the stars. The median
blueshift is 1140 km/s. We hypothesize that the outflowing gas represents a
fossil galactic wind launched near the peak of the galaxy's activity, a few 100
Myr ago. The velocities we measure are intermediate between those of luminous
starbursts and broad absorption line quasars, which suggests that feedback from
an AGN may have played a role in expelling cool gas and shutting down star
formation.
","We report the discovery of massive outflows (1000 km s-1) in two post-starburst galaxies, which are thought to be progenitors of present-day elliptical galaxies. The observations were made with Subaru/FOCAS and VLT/VIMOS using near-infrared spectroscopy covering rest-frame optical emission lines for these objects at redshift 0.6. We found that both galaxies show strong [O III]5007Å/Hβ ratios indicating high ionization parameters. In addition, we detected blueshifted high-velocity components in Hα profiles as well as broad wings on their Hα line profiles. These results suggest that there is an energetic ionized gas flow driven by AGN and/or supernovae activity. This work was supported by Grants-in-Aid for Scientific Research from MEXT Japan (No. 20540230). Keywords: Emission-line galaxy, Galaxy evolution, Nearby galaxy",arxiv,bigscience bloomz,706.0527,0.3333333333333333,0.3445378151260504,0.18974358974358974,0.2919254658385093,1,1,0,0,1,1,1,1,0,0,0.09179245436417881,0.06135382566594191,0.07782101167315175,0.030303030303030304,1,2,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity,"  A generalized geometric method is developed for constructing exact solutions
of gravitational field equations in Einstein theory and generalizations. First,
we apply the formalism of nonholonomic frame deformations (formally considered
for nonholonomic manifolds and Finsler spaces) when the gravitational field
equations transform into systems of nonlinear partial differential equations
which can be integrated in general form. The new classes of solutions are
defined by generic off-diagonal metrics depending on integration functions on
one, two and three (or three and four) variables if we consider four (or five)
dimensional spacetimes. Second, we use a general scheme when one (two)
parameter families of exact solutions are defined by any source-free solutions
of Einstein's equations with one (two) Killing vector field(s). A successive
iteration procedure results in new classes of solutions characterized by an
infinite number of parameters for a non-Abelian group involving arbitrary
functions on one variable. Five classes of exact off-diagonal solutions are
constructed in vacuum Einstein and in string gravity describing solitonic
pp-wave interactions. We explore possible physical consequences of such
solutions derived from primary Schwarzschild or pp-wave metrics.
","We present new exact solutions to the Einstein field equations for stationary axisymmetric spacetimes with two commuting Killing vectors, which are generated by applying nonholonomic frame transforms (NFT) to known vacuum solutions. The NFT is constructed using an ansatz for the metric coefficients that depends on one arbitrary function of the radial coordinate only. We show how this method can be used to generate families of black hole solutions with different horizon topologies. In particular we find new rotating black ring solutions with toroidal horizons. These solutions have been obtained previously as limits of static black rings but our approach allows us to obtain them directly without any additional assumptions or approximations. Finally, we discuss some open problems related to these results. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq 
I. INTRODUCTORY REMARkS
The study of exact solutions to the Einstein equations has played a crucial role in understanding many aspects of general relativity. However, it is often difficult to construct such solutions because they require solving complicated nonlinear partial differential equations. This problem becomes even more challenging when considering physically interesting situations like those involving rotation and/or matter fields. Nevertheless, there exist several techniques that allow one to generate new classes of solutions starting from simpler ones. One of the most powerful methods involves transforming the original solution into another one via so-called nonholonomic frame transforms [1] . Such transformations preserve certain geometric properties of the spacetime while changing others; see [2] - [4] for reviews. For example, if the transformed solution satisfies the vacuum Einstein equations then so does the original one [5] .
In this work we apply nonholonomic frame transforms to known vacuum solutions of the Einstein equations in order to generate new exact solutions describing stationary axisymmetric spacetimes: i.e., spacetimes admitting at least two independent Killing vector fields whose orbits are closed curves [6] . Stationary axisymmetric spacetimes play an important role in astrophysics since they describe the exterior gravitational field of spinning objects like stars, planets, and black holes [7, 8]",arxiv,bigscience bloomz,704.3986,0.3333333333333333,0.7478991596638657,0.28717948717948716,0.9111323459149546,1,1,0,0,1,1,1,1,0,0,0.09472013865248516,0.07722114025046738,0.08171206225680934,0.08333333333333333,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Strategies for the Design of a Slide-o-Cam Transmission,"  The optimization of the pressure angle in a cam-follower transmission is
reported in this paper. This transmission is based on Slide-o-Cam, a cam
mechanism with multiple rollers mounted on a common translating follower. The
design of Slide-o-Cam, a transmission intended to produce a sliding motion from
a turning drive, or vice versa, was reported elsewhere. This transmission
provides pure-rolling motion, thereby reducing the friction of rack-and-pinions
and linear drives. The pressure angle is a suitable performance index for this
transmission because it determines the amount of force transmitted to the load
vs. that transmitted to the machine frame. Two alternative design strategies
are studied, namely, (i) increase the number of lobes on each cam or (ii)
increase the number of cams. This device is intended to replace the current
ball-screws in Orthoglide, a three-DOF parallel robot for the production of
translational motions, currently under development at Ecole Centrale de Nantes
for machining applications.
","A slide-o-cam transmission is an alternative to conventional geared transmissions in which the input and output shafts are connected by means of cams that rotate on their own axes, with no gears or other mechanical elements between them.  The main advantages of this type of transmission are:  • No backlash due to tooth meshing; • High efficiency (up to 98%); • Low noise levels; • Reduced weight and volume compared to traditional gearboxes; • Easy assembly and disassembly; • Possibility of using different types of motors as inputs. This article presents some strategies for designing a slide-o-cam transmission based on the analysis of its kinematic characteristics. These strategies have been applied to develop two prototypes of slide-o-cam transmissions intended for use in electric vehicles. In addition, a mathematical model has been developed to simulate the behavior of these transmissions under various operating conditions. Finally, experimental tests were carried out to validate both the design process proposed here and the results obtained through simulation.",arxiv,bigscience bloomz,705.1036,0.3333333333333333,0.24369747899159663,0.15384615384615385,0.4209268991877688,1,1,0,0,0,1,1,1,0,0,0.0669206119634292,0.13153437153522587,0.054474708171206226,0.14015151515151514,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
"Spitzer Observations of Transient, Extended Dust in Two Elliptical Galaxies: New Evidence of Recent Feedback Energy Release in Galactic Cores","  Spitzer observations of extended dust in two optically normal elliptical
galaxies provide a new confirmation of buoyant feedback outflow in the hot gas
atmospheres around these galaxies. AGN feedback energy is required to prevent
wholesale cooling and star formation in these group-centered galaxies. In NGC
5044 we observe interstellar (presumably PAH) emission at 8 microns out to
about 5 kpc. Both NGC 5044 and 4636 have extended 70 microns emission from cold
dust exceeding that expected from stellar mass loss. The sputtering lifetime of
this extended dust in the ~1keV interstellar gas, ~10^7 yrs, establishes the
time when the dust first entered the hot gas. Evidently the extended dust
originated in dusty disks or clouds, commonly observed in elliptical galaxy
cores, that were disrupted, heated and buoyantly transported outward. The
surviving central dust in NGC 5044 and 4636 has been disrupted into many small
filaments. It is remarkable that the asymmetrically extended 8 micron emission
in NGC 5044 is spatially coincident with Halpha+[NII] emission from warm gas. A
calculation shows that dust-assisted cooling in buoyant hot gas moving out from
the galactic core can cool within a few kpc in about ~10^7 yrs, explaining the
optical line emission observed. The X-ray images of both galaxies are
disturbed. All timescales for transient activity - restoration of equilibrium
and buoyant transport in the hot gas, dynamics of surviving dust fragments, and
dust sputtering - are consistent with a central release of feedback energy in
both galaxies about 10^7 yrs ago.
","We report the discovery of transient dust emission at mid-infrared wavelengths (5-20 microns) in two elliptical galaxies with active galactic nuclei (AGN). The observations were made using Spitzer Space Telescope's Infrared Array Camera and Multiband Imaging Photometer for Spitzer instruments over a period of several years. We find that the infrared luminosity is consistent with heating by AGN radiation or supernovae remnants within the central kpc region. This suggests that recent feedback energy release has been occurring in these cores. These results are important because they provide new evidence on how supermassive black holes grow through accretion onto their host galaxy centers. They also demonstrate the power of combining multiwavelength data to study the physical processes associated with nuclear activity. 
 
 Keywords: Active galactic nucleus, Galaxy evolution, Mid-infrared, Nuclear starbursts 
 
 1. Introduction 
 
 Supermassive black holes reside in the center of most massive galaxies. Their growth is thought to be fueled by gas inflow driven by gravitational torques produced during mergers and/or interactions between galaxies (Barnes & Hernquist 1996; Hopkins et al. 2006) . However, it remains unclear what happens after this fuel supply runs out. One possibility is that the black hole continues growing via radiatively inefficient accretion flows (Narayan & Yi 1994) , which may produce powerful winds and jets that can drive large-scale outflows into the surrounding interstellar medium (ISM) (Silk & Rees 1998; Di Matteo et al. 2005 ). Another possibility is that the black holes become dormant as the ISM becomes too hot to cool efficiently (Bower et al. 2006; Croton et al. 2006 ) until another merger event triggers renewed activity. Understanding the mechanisms responsible for shutting off black-hole growth will help us understand why some galaxies have large black holes while others do not. 
 
 2. Previous Work 
 
 Several studies have shown that there exists an anti-correlation between the mass of the central supermassive black hole and the stellar velocity dispersion of its host galaxy bulge (Ferrar",arxiv,bigscience bloomz,705.371,0.5555555555555556,0.8991596638655462,0.6410256410256411,0.8738652651696129,1,1,0,0,0,1,1,1,0,1,0.08690296056426766,0.1030623094862319,0.13618677042801555,0.17045454545454544,1,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
HST/ACS Coronagraphic Observations of the Dust Surrounding HD 100546,"  We present ACS/HST coronagraphic observations of HD 100546, a B9.5 star, 103
pc away from the sun, taken in the F435W, F606W, and F814W bands. Scattered
light is detected up to 14'' from the star. The observations are consistent
with the presence of an extended flattened nebula with the same inclination as
the inner disk. The well-known ``spiral arms'' are clearly observed and they
trail the rotating disk material. Weaker arms never before reported are also
seen. The inter-arm space becomes brighter, but the structures become more
neutral in color at longer wavelengths, which is not consistent with models
that assume that they are due to the effects of a warped disk. Along the major
disk axis, the colors of the scattered-light relative to the star are \Delta
(F435W-F606W) ~ 0.0--0.2 mags and \Delta (F435W-F814W)~0.5--1 mags. To explain
these colors, we explore the role of asymmetric scattering, reddening, and
large minimum sizes on ISM-like grains. We conclude each of these hypotheses by
itself cannot explain the colors. The disk colors are similar to those derived
for Kuiper Belt objects, suggesting that the same processes responsible for
their colors may be at work here. We argue that we are observing only the
geometrically thick, optically thin envelope of the disk, while the optically
thick disk responsible for the far-IR emission is undetected. The observed
spiral arms are then structures on this envelope. The colors indicate that the
extended nebulosity is not a remnant of the infalling envelope but reprocessed
disk material.
","We present new Hubble Space Telescope (HST) Advanced Camera for Survey (ACS)
coronagraphic observations in visible light and near-infrared wavelengths that reveal an extended dusty disk surrounding the Herbig Ae star HD 100546, which is known to harbor a protoplanetary disk with spiral arms. The ACS coronagraph was used to block out direct stellar radiation at small angular separations from the central star while allowing us to detect scattered light from circumstellar material located farther away. We find evidence for two bright rings of emission separated by ~0.5′′ along the major axis of the disk. These features are most likely due to scattering off large grains or planetesimals orbiting close to their parent stars. 
 
 In addition, we have detected several dark gaps within these bright rings as well as fainter structures extending outward into the outer regions of the disk. Our results suggest that this system may be undergoing planet formation through gravitational interactions between larger bodies such as planets and/or planetesimals.",arxiv,bigscience bloomz,704.1507,0.6666666666666666,0.24369747899159663,0.6512820512820513,0.4180602006688964,1,1,0,0,1,1,1,0,0,0,0.0889354402803727,0.08908094807638159,0.11284046692607004,0.04924242424242424,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"First CO J=6-5, 4-3 detections in local ULIRGs: the dense gas in Mrk231, and its colling budget","  We report on detections of the high-excitation CO J=6-5, J=4-3 lines in
Mrk231, a prototypical Ultra Luminous Infrared Galaxy (ULIRG) and Seyfert 1
QSO. These observations are combined with CO J=3-2, HCN J=4-3 (this work), and
CO J=2-1, J=1-0, 13CO J=2-1, HCN J=1-0 measurements taken from the literature
to provide better constraints on the properties of the molecular gas in an
extreme starburst/QSO in the local Universe. We find that the CO J=4-3 and
J=6-5 transitions trace a different gas phase from that dominating the lower
three CO transitions, with n(H_2) ~ (1-3)x10^4 cm-3 and Tk ~ (40-70) K. This
phase is responsible for the luminous HCN emission, and contains most of the H2
gas mass of this galaxy. The total CO line cooling emanating from this dense
phase is found similar to that of the [CII] line at 158 micron, suggesting a
very different thermal balance to that seen in lower IR-luminosity galaxies,
and one likely dominated by dense photon-dominated regions. Our dense
""sampling"" of the CO rotational ladder and the HCN lines enables us to produce
well-constrained Spectral Line Energy Distributions (SLEDs) for the dense
molecular gas in Mrk231 and compare them to those of high redshift starbursts,
many of which have SLEDs that may be affected by strong lensing. Finally, we
use our local molecular line excitation template to assess the capabilities of
future cm and mm/sub-mm arrays in detecting CO and HCN transitions in similar
systems throughout the local and distant universe.
","We report on high-resolution observations with Herschel PACS (Poglitsch et al., 2010) and SPIRE (Griffin et al., 2010 ) that reveal for the first time the presence of cold dust emission at temperatures as low as T = 20 K in two nearby ultraluminous infrared galaxies (ULIRGs), Arp220 and Mrk 231. The observed fluxes are consistent with predictions based on models of starbursts heated by young stars. We find evidence for an additional component of cooler dust which is likely to be associated with the obscured AGN activity present in these objects. In addition we have detected the [CII] 158 µm line in both sources using PACS spectroscopy. This allows us to estimate the total mass of warm molecular hydrogen M(H2). For Arp 220 this amounts to 1.5 x 10^9 solar masses within a radius of 100 pc around the nucleus.",arxiv,bigscience bloomz,706.0811,0.2777777777777778,0.24369747899159663,0.6307692307692307,0.35785953177257523,1,1,0,0,0,1,1,0,0,0,0.11121681693442,0.13165686718134492,0.08560311284046693,0.14772727272727273,0,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Accurate description of optical precursors and their relation to weak-field coherent optical transients,"  We study theoretically the propagation of a step-modulated optical field as
it passes through a dispersive dielectric made up of a dilute collection of
oscillators characterized by a single narrow-band resonance. The propagated
field is given in terms of an integral of a Fourier type, which cannot be
evaluated even for simple models of the dispersive dielectric. The fact that
the oscillators have a low number density (dilute medium) and have a
narrow-band resonance allows us to simplify the integrand. In this case, the
integral can be evaluated exactly, although it is not possible using this
method to separate out the transient part of the propagated field known as
optical precursors. We also use an asymptotic method (saddle-point method) to
evaluate the integral. The contributions to the integral related to the
saddle-points of the integrand give rise to the optical precursors. We obtain
analytic expressions for the precursor fields and the domain over which the
asymptotic method is valid. When combined to obtain the total transient field,
we find that the agreement between the solutions obtained by the asymptotic and
the exact methods is excellent. Our results demonstrate that precursors can
persist for many nanoseconds and the chirp in the instantaneous frequency of
the precursors can manifest itself in beats in the transmitted intensity. Our
work strongly suggests that precursors have been observed in many previous
experiments.
","We present an accurate analytical model for the description of optical precursors in ultrashort laser pulses propagating through dispersive media, which is based on the concept of nonlinear phase modulation by self-phase-modulation (SPM) and cross-phase-modulation (XPM). The proposed approach allows us to describe accurately both the temporal shape as well as the spectral content of these phenomena. We show that this new method can be used to predict the appearance of weak-field coherent optical transience (WFCOT), i.e., the generation of sub-femtosecond bursts of light with high peak power at specific wavelengths within the spectrum of the pulse. This prediction is confirmed experimentally using a Ti:Sapphire femtosecond oscillator operating at 800 nm central wavelength. Finally we demonstrate how our results are relevant for applications such as ultrafast spectroscopy or attosecond science. 
 
 Optical precursors have been observed since the early days of ultrafast optics [1–3] . They appear when short intense laser pulses propagate through dispersive media like glass fibers [4] , air [5] , water [6] , crystals [7, 8] , etc.. These effects were first explained theoretically by assuming that the propagation of the pulse was governed by the slowly varying envelope approximation [9] . However it has recently become clear that this assumption does not hold true anymore if one wants to explain the details of the experimental observations [10–12] .
 
In order to overcome this limitation several authors have developed more sophisticated models [13–19] . In particular, the so-called generalized nonlinear Schrödinger equation (GNLSE) [20, 21] has proven very useful because it takes into account all orders of dispersion [22] , self-steepening [23] , third-order dispersion [24] , Raman scattering [25] , stimulated Brillouin scattering [26] , self-frequency shift [27] , plasma defocusing [28] , gain saturation [29] , and other higher-order effects [30] . 
 
However, despite its successes, there still remain some discrepancies between theory and experiment [31] . For example, the GNLSE predicts that the intensity profile of the precursor should always exhibit a smooth bell-shaped structure [32]",arxiv,bigscience bloomz,705.4238,0.5,0.596638655462185,0.5333333333333333,0.9053989488772097,1,1,0,0,0,1,1,1,0,0,0.06624802592869215,0.15653160318725204,0.07392996108949416,0.23863636363636365,0,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Quantum mechanical approach to decoherence and relaxation generated by fluctuating environment,"  We consider an electrostatic qubit, interacting with a fluctuating charge of
single electron transistor (SET) in the framework of exactly solvable model.
The SET plays a role of the fluctuating environment affecting the qubit's
parameters in a controllable way. We derive the rate equations describing
dynamics of the entire system for both weak and strong qubit-SET coupling.
Solving these equation we obtain decoherence and relaxation rates of the qubit,
as well as the spectral density of the fluctuating qubit's parameters. We found
that in the weak coupling regime the decoherence and relaxation rates are
directly related to the spectral density taken at Rabi or at zero frequency,
depending on what a particular qubit's parameters is fluctuating. This relation
holds also in the presence of weak back-action of the qubit on the fluctuating
environment. In the case of strong back-action, such simple relationship no
longer holds, even if the qubit-SET coupling is small. It does not hold either
in the strong-coupling regime, even in the absence of the back-action. In
addition, we found that our model predicts localization of the qubit in the
strong-coupling regime, resembling that of the spin-boson model.
","We present an exact quantum-mechanical treatment for the dynamics of open systems in which the system is coupled to many harmonic oscillators representing its surrounding environment.  We show that, under certain conditions, this model can be reduced exactly into a master equation with Lindblad form. The resulting master equations are used to study the effects of environmental fluctuations on the evolution of the density matrix describing the state of the system. In particular we consider two different models of environments corresponding to Ohmic dissipation and spin-boson interaction respectively. For both cases it is shown how the effect of the environment leads to irreversible loss of information about the initial state of the system as well as to thermalization at late times. Finally, we discuss possible applications of our results to problems such as transport through mesoscopic conductors or dissipative tunneling between localized states in disordered solids. Decoherence and relaxation processes play a crucial role in understanding the physics of open quantum systems [1, 2] . These phenomena arise when the system interacts with some external degrees of freedom (environment) whose influence cannot be neglected [3] .
In recent years there has been considerable interest in developing theoretical methods capable of treating these effects beyond the perturbative regime [4] . A number of approaches have been proposed ranging from phenomenological treatments based on stochastic Schrödinger equations [5] , to more microscopic descriptions using path integral techniques [6] or field-theoretical formulations [7, 8] . However, despite their successes, all these methods suffer from one common drawback: they do not provide any insight into the underlying physical mechanisms responsible for decoherence and relaxation; nor do they allow us to make quantitative predictions regarding the time scales involved [9] .
Recently, several authors [10 -12] have suggested that the problem may be tackled within the framework of quantum mechanics itself. This idea was first put forward by Feynman [13] who showed that the statistical properties of macroscopic objects could be obtained by averaging over an ensemble of identical but microscopically distinct realizations of the same experiment. More recently, Leggett [14] introduced a method...",arxiv,bigscience bloomz,704.0194,0.4444444444444444,0.6470588235294118,0.3435897435897436,0.9541328236980411,1,1,0,0,1,1,1,1,0,0,0.061652648756780795,0.08101503580256714,0.08171206225680934,0.09090909090909091,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
Quasi Equilibrium Grid Algorithm: geometric construction for model reduction,"  The Method of Invariant Grid (MIG) is an iterative procedure for model
reduction in chemical kinetics which is based on the notion of Slow Invariant
Manifold (SIM) [1-4]. Important role, in that method, is played by the initial
grid which, once refined, gives a description of the invariant manifold: the
invariant grid. A convenient way to get a first approximation of the SIM is
given by the Spectral Quasi Equilibrium Manifold (SQEM) [1-2]. In the present
paper, a flexible numerical method to construct the discrete analog of a Quasi
Equilibrium Manifold, in any dimension, is presented. That object is named
Quasi Equilibrium Grid (QEG), while the procedure Quasi Equilibrium Grid
Algorithm. Extensions of the QEM notion are also suggested. The QEG is a
numerical tool which can be used to find a grid-based approximation for the
locus of minima of a convex function under some linear constraints. The method
is validated by construction of one and two-dimensional grids for model
hydrogen oxidation reaction.
","We present an algorithm to construct the reduced basis space in the context of nonlinear problems with multiple solutions, which is based on the concept of quasi-equilibrium grid (QEG). The QEG method was originally developed by Simo and Armero as a numerical technique for solving rate-independent processes such as plasticity or damage mechanics. We show that this approach can be used to generate snapshots for constructing the reduced basis spaces associated with nonlinear problems with multiple solutions. In particular, we consider two examples arising from structural dynamics and fluid flow computations. Numerical results demonstrate that our proposed method yields accurate approximations at significantly lower computational cost than existing approaches. Keywords: Reduced Basis Method; Quasi-Equilibrium Grids; Nonlinear Problems; Model Order Reduction; Geometric Construction; Snapshot Generation. 1 Introduction.
The goal of this work is to develop efficient algorithms for generating snapshots for constructing the RB spaces associated with nonlinear problems having multiple solutions. This problem arises frequently when one solves engineering applications involving complex physical phenomena such as multiphysics coupling, material failure, contact/impact, etc.. For example, in structural dynamics, it may happen that different initial conditions lead to different equilibrium states [19, 20] . Similarly, in fluid flows, there are often many steady-state solutions corresponding to different boundary conditions [7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18] .
In order to solve these types of problems efficiently using the reduced basis method (RBM), it is necessary to have a good set of snapshots representing all possible solution behaviors. However, since each snapshot corresponds to a specific solution behavior, it is not easy to obtain them directly through standard finite element analysis. Therefore, various techniques have been developed over the past decade to overcome this difficulty [1, 2, 3, 4, 5, 6, 7, 9, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40",arxiv,bigscience bloomz,704.2317,0.3888888888888889,0.596638655462185,0.20512820512820512,0.8537983755375059,1,1,1,0,0,1,1,1,0,0,0.07574194932542652,0.14060136487514857,0.07782101167315175,0.1553030303030303,1,1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Regular homogeneous T-models with vacuum dark fluid,"  We present the class of regular homogeneous T-models with vacuum dark fluid,
associated with a variable cosmological term. The vacuum fluid is defined by
the symmetry of its stress-energy tensor, i.e., its invariance under Lorentz
boosts in a distinguished spatial direction (p_j=-\rho), which makes this fluid
essentially anisotropic and allows its density to evolve. Typical features of
homogeneous regular T-models are: the existence of a Killing horizon; beginning
of the cosmological evolution from a null bang at the horizon; the existence of
a regular static pre-bang region visible to cosmological observers; creation of
matter from anisotropic vacuum, accompanied by very rapid isotropization. We
study in detail the spherically symmetric regular T-models on the basis of a
general exact solution for a mixture of the vacuum fluid and dustlike matter
and apply it to give numerical estimates for a particular model which
illustrates the ability of cosmological T-models to satisfy the observational
constraints.
","We study the cosmological evolution in regular homogeneous T-models filled by a perfect fluid and a vacuum energy density term, which is responsible for an accelerated expansion at late times.  We find that this model can be described as a mixture between dust matter (dark matter) and radiation-like components. The latter component behaves like a relativistic gas whose pressure decreases more slowly than its energy density does. This leads to a negative effective equation-of-state parameter w eff < 0 during most of the cosmic history. However, we show that there exists a time interval where w eff > -1, so that our model cannot explain the current acceleration of the universe without introducing additional ingredients such as quintessence or modified gravity theories. Nevertheless, it may provide useful insights into the nature of dark energy. In addition, we discuss how the presence of a non-vanishing vacuum energy density affects the growth rate of structure formation on sub-horizon scales.",arxiv,bigscience bloomz,705.2368,0.16666666666666666,0.29411764705882354,0.14871794871794872,0.4037267080745342,1,1,1,0,0,1,1,0,0,0,0.12830232825485782,0.0715830143969732,0.08560311284046693,0.08712121212121213,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Retaining Black Holes with Very Large Recoil Velocities,"  Recent numerical simulations of binary black hole mergers show the
possibility of producing very large recoil velocities (> 3000 km/s). Kicks of
this magnitude should be sufficient to eject the final black hole from
virtually any galactic potential. This result has been seen as a potential
contradiction with observations of supermassive black holes residing in the
centers of most galaxies in the local universe. Using an extremely simplified
merger tree model, we show that, even in the limit of very large ejection
probability, after a small number of merger generations there should still be
an appreciable fraction (>50%) of galaxies with supermassive black holes today.
We go on to argue that the inclusion of more realistic physics ingredients in
the merger model should systematically increase this retention fraction,
helping to resolve a potential conflict between theory and observation. Lastly,
we develop a more realistic Monte Carlo model to confirm the qualitative
arguments and estimate occupation fractions as a function of the central
galactic velocity dispersion.
","We study the possibility that black holes can be retained in binary systems by gravitational radiation reaction even if their initial velocities are very large, and we find that this is possible for certain ranges of parameters.  We consider two types of binaries:  those consisting of one black hole and another compact object (such as neutron star or white dwarf), and those consisting of two black holes.   In both cases, we show how to calculate the final velocity after emission of gravitational waves using post-Newtonian approximations up to third order.  For binaries containing at least one black hole, we also use numerical relativity simulations to check our results.  Finally, we discuss some astrophysical implications of these findings. The discovery of gravitational waves has opened an exciting new window on the universe [1] . One of its most surprising features was the detection of merging black holes [2] , which were found to have masses ranging between about 4M☉ and 36M☉ [3] . This raises the question whether there exist other ways besides mergers through which black holes may form [4] .
In particular, it would be interesting to know what happens when a black hole moves into a binary system composed of either another black hole or a nonblack-hole companion [5] . If the black hole's initial speed is too high, then it will escape the system before emitting enough energy via gravitational waves [6] . However, if the black hole starts out slowly but still faster than the orbital speed of the binary components, then it could potentially be captured [7, 8] .  Here, we investigate this scenario further and determine under which conditions such capture is indeed possible.",arxiv,bigscience bloomz,706.1548,0.2777777777777778,0.546218487394958,0.2153846153846154,0.7563306258958433,1,0,0,0,0,1,1,1,0,1,0.09356095983386718,0.06995715911903584,0.08560311284046693,0.041666666666666664,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
"A ""diamond-ring"" star: the unusual morphologic structure of a young (multiple?) object","  We have observed IRAS06468-0325 obtaining optical and infrared images through
IJHKs and L' filters, K-band low-resolution spectroscopy, together with
millimetre line observations of CO and CS. IRAS06468-0325 has a very unusual
and enigmatic morphology with two components: a bright, close to point-like
source (the diamond) and a sharp-edge ring-like structure (the ring). The
source is not detected in the optical, at wavelengths shorter than the I-band.
The diamond is seen in all the imaging bands observed. The ring-like structure
in IRAS06468-0325 is clearly seen in the I, J, H, and Ks. It is not detected in
the L'-band image. Infrared colours of the diamond are compatible with excess
circumstellar emission and a young stellar nature. A strongly non-gaussian and
moderately bright CO(1-0) and {13}CO(2-1) lines are seen towards
IRAS06468-0325, at v_{LSR} of 30.5 km s{-1} (corresponding to a kinematic
distance of 3 kpc). Very weak C{18}O(2-1) and CS(2-1) lines were detected.
K-band spectra of the diamond and of the ring are similar both in the slope of
the continuum and in the presence of lines supporting the idea that the ring is
reflected light from the diamond. With the current data, a few different
scenarios are possible to explain the morphology of this object. However, the
available data seem to favour that the morphology of IRAS06468-0325 correspond
to a young stellar multiple system in a transient stage where a binary
co-exists with a circumbinary disc, similar to the case of GG Tau. In this
case, the sharpness of the well-defined ring may be due to tidal truncation
from dynamic interactions between components in a binary or multiple stellar
system. IRAS06468-0325 may be an important rare case that illustrates a
short-lived stage of the process of binary or multiple star formation.
","We report on near-infrared observations of an extremely red, faint source in the field of view of the Hubble Space Telescope's Wide Field Planetary Camera 2 (WFPC2). The source is located at RA = 03h45m55s and Dec = -05d20'00"" (J2000), about 1 arcmin south-east of the open cluster NGC 6231. It was detected by WFPC2 as a point-like object with mF606W ~ 26 mag., mF814W ~ 25 mag. (Vega system) and mH ~ 20 mag.. We have obtained additional photometry for this object using the ESO NTT telescope equipped with SOFI camera. Our results show that it has very red colors (R-I > 5 mag.) and its spectrum exhibits strong absorption features characteristic of late-type stars. Its absolute magnitude M(K) = -4.3 ± 0.1 suggests that we are dealing with either a brown dwarf or a low-mass star.",arxiv,bigscience bloomz,704.3236,0.7222222222222222,0.29411764705882354,0.8564102564102564,0.34925943621595795,1,1,1,0,1,1,1,0,0,1,0.10630463369630778,0.05592745547131851,0.11673151750972763,0.03787878787878788,1,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On Gene Duplication Models for Evolving Regulatory Networks,"  Background: Duplication of genes is important for evolution of molecular
networks. Many authors have therefore considered gene duplication as a driving
force in shaping the topology of molecular networks. In particular it has been
noted that growth via duplication would act as an implicit way of preferential
attachment, and thereby provide the observed broad degree distributions of
molecular networks.
  Results: We extend current models of gene duplication and rewiring by
including directions and the fact that molecular networks are not a result of
unidirectional growth. We introduce upstream sites and downstream shapes to
quantify potential links during duplication and rewiring. We find that this in
itself generates the observed scaling of transcription factors for genome sites
in procaryotes. The dynamical model can generate a scale-free degree
distribution, p(k)&prop; 1/k^&gamma;, with exponent &gamma;=1 in the
non-growing case, and with &gamma;>1 when the network is growing.
  Conclusions: We find that duplication of genes followed by substantial
recombination of upstream regions could generate main features of genetic
regulatory networks. Our steady state degree distribution is however to broad
to be consistent with data, thereby suggesting that selective pruning acts as a
main additional constraint on duplicated genes. Our analysis shows that gene
duplication can only be a main cause for the observed broad degree
distributions, if there is also substantial recombinations between upstream
regions of genes.
","We present an analysis of gene duplication models in the context of evolving regulatory networks, and show that they are not sufficient to explain all observed features of these networks. We consider two types of duplications: whole-genome duplicates (WGDs) and local duplicates (LDs). WGDs occur when a complete genome is duplicated; LDs occur when only one or few genes are duplicated at once. 
 
 In both cases we study how new duplicate copies evolve after their creation by comparing them with their parent copy using sequence similarity measures. For each type of duplication event, we find that there exists a large number of duplicates which do not resemble any other existing gene more than expected under random chance. This suggests that many duplicates may be created through mechanisms different from those considered here. Furthermore, we observe that duplicates tend to have higher expression levels compared to non-duplicates. Finally, we compare our results on duplicates with previous studies on network evolution, and discuss possible extensions of this work.",arxiv,bigscience bloomz,704.3808,0.5,0.3445378151260504,0.5128205128205128,0.4295269947443861,1,1,1,0,0,1,1,1,0,0,0.08894792547499353,0.04855973299025033,0.10505836575875487,0.045454545454545456,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1
Spheroidal and torsional modes of quasistatic shear oscillations in the solid globe models of nuclear physics and pulsar astrophysics,"  The past three decades of investigation on nuclear physics and pulsar
astrophysics have seen gradual recognition that elastodynamic approach to the
continuum mechanics of nuclear matter provides proper account of macroscopic
motions of degenerate Fermi-matter constituting interior of the nuclear
material objects, the densest of all known today. This paper focuses on one
theoretical issue of this development which is concerned with oscillatory
behavior of a viscoelastic solid globe in the regime of quasistatic,
force-free, non-compressional oscillations less investigated in the literature
compared to oscillations in the regime of standing shear waves. We show that in
this case the problem of computing frequency and lifetime of spheroidal and
torsional modes of non-radial shear vibrations damped by viscosity can be
unambiguously resolved by working from the energy balance equation and taking
advantage of the Rayleigh's variational method. The efficiency of this method
is demonstrated by solid globe models of nuclear physics and pulsar
astrophysics dealing with oscillations of a spherical mass of a viscoelastic
Fermi-solid with homogeneous and non-homogeneous profiles of the bulk density,
the shear modulus, and the shear viscosity.
","We study spheroidal and torsional normal modes of quasi-static shear oscillations in the spherical shell model with incompressible liquid core, which is used to describe the dynamics of superfluid neutron stars. We show that there are two types of spheroidal modes: one type corresponds to the usual fluid-like mode, while another type describes the motion of the whole star as a rigid body. The latter type can be excited only by external perturbations. In addition we find three new families of torsional modes corresponding to different motions of the inner core. These results may have important implications for understanding the observed phenomena related to the glitch activity of pulsars. 
 
 Keywords: Quasi-static shear oscillations; Spherical shell model; Superfluidity of neutrons; Pulsar glitches; Torsional waves; Rigid-body rotation; Neutron stars; Nuclear matter; Energy density functional theory",arxiv,bigscience bloomz,704.1732,0.16666666666666666,0.24369747899159663,0.2923076923076923,0.3349259436215958,0,1,0,0,1,0,1,1,0,0,0.014458034482155716,0.07688116896029035,0.011673151750972763,0.07575757575757576,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,0
The Advantages of Four Dimensions for Composite Higgs Models,"  We examine the relationship between little Higgs and 5d composite models with
identical symmetry structures. By performing an ""extreme"" deconstruction, one
can reduce any warped composite model to a little Higgs theory on a handful of
sites. This allows us to use 4d intuition and the powerful constraints of
nonlinear sigma models to elucidate obscure points in the original setup. We
find that the finiteness of the Higgs potential in 5d is due to the same
collective symmetry breaking as in the little Higgs. We compare a 4d and a 5d
model with the same symmetry to the data. Reviewing the constraints on models
related to the Minimal Composite Higgs (hep-ph/0412089), we see that it has
difficulty in producing acceptable values for S, T, and m_{top} simultaneously.
By contrast, in a global analysis, the Minimal Moose with custodial symmetry is
viable in a large region of its parameter space and suffers from no numeric
tunings. We conjecture that this result is generic for 4d and 5d models with
identical symmetries. The data will less strongly constrain the little theory.
","We study the advantages and disadvantages of composite Higgs models in four dimensions (4D) versus five dimensions (5D). In 4D, we find that there are two types of composite Higgs models with different phenomenological consequences. The first type is based on an underlying global symmetry group SU(2)L ×SU(2)R ×U(1)B−L which leads to three Goldstone bosons after spontaneous breaking of this symmetry down to U(1)EM . This model has been studied extensively by many authors including ourselves [1–3] .
The second type is based on an extended gauge symmetry group SU(3)C ×SU(2)L ×U(1)Y ×Z′ where Z′ is a new abelian gauge factor associated with extra spatial dimension [4–6] . We show that both these models can be embedded into 5D theories compactified on orbifolds [7–9] , but they have very different properties when considered as effective 4D theories.",arxiv,bigscience bloomz,706.138,0.4444444444444444,0.24369747899159663,0.28717948717948716,0.3463927376970855,1,1,0,0,0,1,0,0,0,0,0.07777599045473405,0.10206610953627783,0.08171206225680934,0.10227272727272728,1,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On the dimension of subspaces with bounded Schmidt rank,"  We consider the question of how large a subspace of a given bipartite quantum
system can be when the subspace contains only highly entangled states. This is
motivated in part by results of Hayden et al., which show that in large d x
d--dimensional systems there exist random subspaces of dimension almost d^2,
all of whose states have entropy of entanglement at least log d - O(1). It is
also related to results due to Parthasarathy on the dimension of completely
entangled subspaces, which have connections with the construction of
unextendible product bases. Here we take as entanglement measure the Schmidt
rank, and determine, for every pair of local dimensions dA and dB, and every r,
the largest dimension of a subspace consisting only of entangled states of
Schmidt rank r or larger. This exact answer is a significant improvement on the
best bounds that can be obtained using random subspace techniques. We also
determine the converse: the largest dimension of a subspace with an upper bound
on the Schmidt rank. Finally, we discuss the question of subspaces containing
only states with Schmidt equal to r.
","We study the problem of finding an explicit formula for the dimension of the space spanned by all vectors in a given finite set $S$ whose Schatten $p$-norms are bounded above by some constant $C$, where $1<p<\infty$ is fixed and $p>2$.  We show that this dimension can be expressed as a polynomial in $C^{1/p}$ (and hence also in the cardinality of $S$) if we assume that $S$ has no two elements which are orthogonal under any inner product on $\mathbb{C}^n$.   This result generalizes earlier results obtained independently by M. Lustig and A. Shub and by J. Bourgain and G. Bouschler. It should be noted that our proof does not use the fact that the underlying field is complex; it works over arbitrary fields of characteristic zero. The main ingredient of our argument is a new combinatorial identity involving binomial coefficients.",arxiv,bigscience bloomz,706.0705,0.3333333333333333,0.19327731092436976,0.3230769230769231,0.35499283325370284,1,1,1,0,0,1,1,1,0,0,0.11484173465797402,0.16272762913094518,0.09727626459143969,0.12121212121212122,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On smooth foliations with Morse singularities,"  Let $M$ be a smooth manifold and let $\F$ be a codimension one, $C^\infty$
foliation on $M$, with isolated singularities of Morse type. The study and
classification of pairs $(M,\F)$ is a challenging (and difficult) problem. In
this setting, a classical result due to Reeb \cite{Reeb} states that a manifold
admitting a foliation with exactly two center-type singularities is a sphere.
In particular this is true if the foliation is given by a function. Along these
lines a result due to Eells and Kuiper \cite{Ku-Ee} classify manifolds having a
real-valued function admitting exactly three non-degenerate singular points. In
the present paper, we prove a generalization of the above mentioned results. To
do this, we first describe the possible arrangements of pairs of singularities
and the corresponding codimension one invariant sets, and then we give an
elimination procedure for suitable center-saddle and some saddle-saddle
configurations (of consecutive indices). In the second part, we investigate if
other classical results, such as Haefliger and Novikov (Compact Leaf) theorems,
proved for regular foliations, still hold true in presence of singularities. At
this purpose, in the singular set, $Sing(\F)$ of the foliation $\F$, we
consider {\em{weakly stable}} components, that we define as those components
admitting a neighborhood where all leaves are compact. If $Sing(\F)$ admits
only weakly stable components, given by smoothly embedded curves diffeomorphic
to $S^1$, we are able to extend Haefliger's theorem. Finally, the existence of
a closed curve, transverse to the foliation, leads us to state a Novikov-type
result.
","In this article we study the structure of smooth foliations on closed manifolds, which are given by submersions whose fibers have only Morse singularities (i.e., they look like graphs over their tangent spaces). We prove that such foliations can be approximated in the C 1 -topology by regular ones and give an explicit bound for the approximation error. This result is used to show that any leafwise Riemannian metric on these foliations has bounded geometry. The main tool here is the theory of harmonic maps into Hilbert spaces developed by Eells-Elworthy-Malliavin. In particular, we use the fact that every harmonic map into a Hilbert space is weakly conformal. As another application of our results, we obtain some estimates for the volume growth rate along leaves of such foliations. Finally, using the above mentioned bounds for the approximation error, we also get lower bounds for the number of critical points of generic functions on closed manifolds.",arxiv,bigscience bloomz,704.0164,0.5555555555555556,0.29411764705882354,0.6358974358974359,0.39799331103678937,1,1,0,0,1,1,1,0,0,0,0.09823322405361055,0.05875479726432475,0.10505836575875487,0.030303030303030304,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Charmless Three-body Decays of B Mesons,"  Charmless 3-body decays of B mesons are studied in the framework of the
factorization approach. The nonresonant contributions arising from $B\to
P_1P_2$ transitions are evaluated using heavy meson chiral perturbation theory
(HMChPT). The momentum dependence of nonresonant amplitudes is assumed to be in
the exponential form $e^{-\alpha_{NR}} p_B\cdot(p_i+p_j)}$ so that the HMChPT
results are recovered in the soft meson limit $p_i, p_j\to 0$. In addition, we
have identified another large source of the nonresonant signal in the matrix
elements of scalar densities, e.g. $<K\bar K|\bar ss|0>$, which can be
constrained from the decay $\bar B^0\to K_SK_SK_S$ or $B^-\to K^-K_SK_S$. The
intermediate vector meson contributions to 3-body decays are identified through
the vector current, while the scalar meson resonances are mainly associated
with the scalar density. Their effects are described in terms of the
Breit-Wigner formalism. Our main results are: (i) All KKK modes are dominated
by the nonresonant background. The predicted branching ratios of
$K^+K^-K_{S(L)}$, $K^+K^-K^-$ and $K^-K_SK_S$ modes are consistent with the
data within errors. (ii) Although the penguin-dominated $B^0\to K^+K^-K_{S}$
decay is subject to a potentially significant tree pollution, its effective
$\sin 2\beta$ is very similar to that of the $K_SK_SK_S$ mode. However, direct
CP asymmetry of the former, being of order -4%, is more prominent than the
latter. (iii) For $B\to K\pi\pi$ decays, we found sizable nonresonant
contributions in $K^-\pi^+\pi^-$ and $\bar K^0\pi^+\pi^-$ modes, in agreement
with the Belle measurements but larger than the BaBar result.
","We present the results on charmless three-body decays of B mesons using data collected by the Belle experiment at KEKB in 2003-2007, corresponding to an integrated luminosity of 711 fb-1. We measure branching fractions for the decay modes B+ -> J/psi K*(892)0 and B- -> J/psi K*0(1430), where J/psi is reconstructed in its decay into muon pairs.  The measured values are  B+ -> J/psi: (4.6 +/- 0.7 +/- 1.1) x 10^-6; B->J/psi: (3.2 +/- 0.5 +/- 0.9) x 10^-6 , where the first errors are statistical and systematic respectively, and the second error is due to uncertainty in the number of BB events. These measurements are consistent with previous measurements but have improved precision. In addition we report new upper limits on the branching fraction for the decay mode B+ -> J/psi/phi .",arxiv,bigscience bloomz,704.1049,0.6111111111111112,0.19327731092436976,0.5948717948717949,0.3349259436215958,1,1,1,0,0,1,1,1,0,0,0.09962570018598596,0.1397290523289467,0.09727626459143969,0.1590909090909091,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
Constraining Models of Neutrino Mass and Neutrino Interactions with the Planck Satellite,"  In several classes of particle physics models -- ranging from the classical
Majoron models, to the more recent scenarios of late neutrino masses or
Mass-Varying Neutrinos -- one or more of the neutrinos are postulated to couple
to a new light scalar field. As a result of this coupling, neutrinos in the
early universe instead of streaming freely could form a self-coupled fluid,
with potentially observable signatures in the Cosmic Microwave Background and
the large scale structure of the universe. We re-examine the constraints on
this scenario from the presently available cosmological data and investigate
the sensitivity expected from the Planck satellite. In the first case, we find
that the sensitivity strongly depends on which piece of data is used. The SDSS
Main sample data, combined with WMAP and other data, disfavors the scenario of
three coupled neutrinos at about the 3.5$\sigma$ confidence level, but also
favors a high number of freely streaming neutrinos, with the best fit at 5.2.
If the matter power spectrum is instead taken from the SDSS Large Red Galaxy
sample, best fit point has 2.5 freely streaming neutrinos, but the scenario
with three coupled neutrinos becomes allowed at $2\sigma$. In contrast, Planck
alone will exclude even a single self-coupled neutrino at the $4.2\sigma$
confidence level, and will determine the total radiation at CMB epoch to
$\Delta N_\nu^{eff} = ^{+0.5}_{-0.3}$ ($1\sigma$ errors). We investigate the
robustness of this result with respect to the details of Planck's detector.
This sensitivity to neutrino free-streaming implies that Planck will be capable
of probing a large region of the Mass-Varying Neutrino parameter space. Planck
may also be sensitive to a scale of neutrino mass generation as high as 1 TeV.
","We present constraints on models of neutrino mass, mixing angles, and interactions using data from the Planck satellite experiment. We use measurements of the cosmic microwave background temperature anisotropy power spectrum to constrain cosmological parameters including the sum of the masses of all three active neutrinos ( m ), the effective number of relativistic species at recombination (), and the primordial helium abundance (). The results are consistent with previous analyses but have improved precision due to the inclusion of polarization information in addition to temperature fluctuations. 
 
 In particular we find that the total neutrino mass is constrained by Planck to be less than 0.23 eV at 95% confidence level for normal hierarchy or less than 0.28 eV for inverted hierarchy. These limits improve upon those obtained previously from WMAP7+SDSS3+HST by factors of 2.5-3.0. For comparison, these values correspond roughly to one third of an electron volt per neutrino flavor.",arxiv,bigscience bloomz,704.3271,0.5,0.24369747899159663,0.8051282051282052,0.3836598184424272,1,1,0,0,1,1,1,0,0,0,0.12576181672331685,0.10469353585876691,0.14007782101167315,0.09090909090909091,0,0,5,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Impact of Cosmic Rays on Population III Star Formation,"  We explore the implications of a possible cosmic ray (CR) background
generated during the first supernova explosions that end the brief lives of
massive Population III stars. We show that such a CR background could have
significantly influenced the cooling and collapse of primordial gas clouds in
minihaloes around redshifts of z ~ 15 - 20, provided the CR flux was sufficient
to yield an ionization rate greater than about 10^-19 s^-1 near the center of
the minihalo. The presence of CRs with energies less than approximately 10^7 eV
would indirectly enhance the molecular cooling in these regions, and we
estimate that the resulting lower temperatures in these minihaloes would yield
a characteristic stellar mass as low as ~ 10 M_sun. CRs have a less pronounced
effect on the cooling and collapse of primordial gas clouds inside more massive
dark matter haloes with virial masses greater than approximately 10^8 M_sun at
the later stages of cosmological structure formation around z ~ 10 - 15. In
these clouds, even without CR flux the molecular abundance is already
sufficient to allow cooling to the floor set by the temperature of the cosmic
microwave background.
","We study the impact of cosmic rays (CRs) on population iii star formation in minihalos, using cosmological hydrodynamic simulations with CR physics implemented self-consistently. We find that CR pressure suppresses fragmentation and increases the Jeans mass by factors of 2-5 at redshifts z = 10-20. This effect is more pronounced for higher values of the CR diffusion coefficient Dcr. The suppression of fragmentation leads to an increase in the number density of massive stars formed per halo as well as their total luminosity. For our fiducial value of Dcr = 3 × 1026 cm2 s−1 we obtain a factor of 4-10 enhancement over the case without CR feedback. Our results are consistent with recent observations of high-z galaxies. In addition, we show that CR feedback can explain the observed correlation between galaxy stellar masses and black hole masses. Finally, we discuss possible observational signatures of this mechanism.",arxiv,bigscience bloomz,705.3634,0.2222222222222222,0.3445378151260504,0.35384615384615387,0.3750597228858099,1,1,0,0,0,1,1,0,0,0,0.08719685225556344,0.052130214693100106,0.08949416342412451,0.041666666666666664,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Optical properties of Er3+ doped alkali-chloro phosphate glasses for optical amplifiers,"  A new class of Erbium doped glasses with compositions xNa2O - (60-x)PbCl2 -
40P2O5 (x=0, 10, 20 and 30) were fabricated and characterized for optical
properties. Absorption spectra were analyzed for important Judd-Ofelt
parameters from the integrated intensities of various Er3+ glass absorption
bands. Photoluminescence (PL) and its decay behavior studies were carried out
for the transition 4I13/2 -> 4I15/2. A systematic correlation between the
Judd-Ofelt parameter {omega}2 and the covalent nature of the glass matrix was
observed, due to increased role of bridging oxygens in the glass network. The
PL broadness and life times of 4I13/2_> 4I15/2 transition were typically in the
range of 40-60nm and 2.13-2.5ms respectively. These glasses broadly showed high
transparency, high refractive index, shorter life times and, most importantly,
these glasses were found to be capable of being doped with larger
concentrations of Er3+ (up to 4 wt%). Increase of Er3+ concentration resulted
in the increase in PL line-widths with no significant effect of concentration
quenching, indicating that these glasses are suitable for optical
fibre/waveguide amplifiers.
","Erbium-doped fiber amplifiers (EDFAs) are widely used in the field of telecommunication and sensing applications due to their high gain, low noise figure, wide bandwidths and compatibility with silica fibers. However, EDFAs have some disadvantages such as high cost and limited lifetime because they require expensive rare-earth elements like erbium ions. In this study, we report on the preparation of new glass-ceramic materials based on sodium chloride and potassium chloride phosphates containing different concentrations of Er3+ ions by melt-quenching method. The structural characterization was performed using X-ray powder diffraction analysis (XRPD), scanning electron microscopy (SEM), energy dispersive spectroscopy (EDS). Optical absorption spectra were recorded at room temperature between 300 nm and 1600 nm. Photoluminescence emission measurements were carried out under 980-nm excitation wavelength. It is found that the prepared samples show good transparency over a broad range of wavelengths up to 1600 nm.",arxiv,bigscience bloomz,705.0847,0.3333333333333333,0.29411764705882354,0.24615384615384617,0.3635929288103201,1,1,0,0,0,1,1,0,0,0,0.07723236185521931,0.06677105021276207,0.07782101167315175,0.03409090909090909,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Satellite Galaxies and Fossil Groups in the Millennium Simulation,"  We use a semianalytic galaxy catalogue constructed from the Millennium
Simulation to study the satellites of isolated galaxies in the LCDM cosmogony.
This sample (~80,000$ bright primaries, surrounded by ~178,000 satellites)
allows the characterization, with minimal statistical uncertainty, of the
dynamical properties of satellite/primary galaxy systems in a LCDM universe. We
find that, overall, the satellite population traces the dark matter rather
well: its spatial distribution and kinematics may be approximated by an NFW
profile with a mildly anisotropic velocity distribution. Their spatial
distribution is also mildly anisotropic, with a well-defined ``anti-Holmberg''
effect that reflects the misalignment between the major axis and angular
momentum of the host halo. The isolation criteria for our primaries picks not
only galaxies in sparse environments, but also a number of primaries at the
centre of ''fossil'' groups. We find that the abundance and luminosity function
of these unusual systems are in reasonable agreement with the few available
observational constraints. We recover the expected L_{host} \sigma_{sat}^3
relation for LCDM models for truly-isolated primaries. Less strict primary
selection, however, leads to substantial modification of the scaling relation.
Our analysis also highlights a number of difficulties afflicting studies that
rely on blind stacking of satellite systems to constrain the mean halo mass of
the primary galaxies.
","We present an analysis of satellite galaxies, fossil groups (FGs), and galaxy clusters in the Millennium Run simulation. We find that FGs are rare objects with only 0.5% of all halos being classified as such at z=0. The number density of FGs is consistent with observations for systems with Mvir>1013M⊙/h. However, we also find that there exists a population of low-mass FGs which have not been observed yet but may be detectable by future surveys. In addition to their rarity, FGs show several other interesting properties compared to normal galaxy clusters: they tend to reside in more massive dark matter haloes than normal galaxy clusters; they contain fewer bright central galaxies; and they exhibit higher velocity dispersions. These results suggest that FGs can provide important constraints on models of galaxy formation and evolution. This work was supported by NASA grant NAG5-10842.",arxiv,bigscience bloomz,706.2009,0.4444444444444444,0.29411764705882354,0.441025641025641,0.35785953177257523,1,1,1,0,1,1,1,1,0,0,0.05932027631870045,0.09566262573422858,0.05058365758754864,0.09848484848484848,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Lensing, reddening and extinction effects of MgII absorbers from z=0.4 to z=2","  Using a sample of almost 7000 strong MgII absorbers with 0.4 < z < 2.2
detected in the SDSS DR4 dataset, we investigate the gravitational lensing and
dust extinction effects they induce on background quasars. After carefully
quantifying several selection biases, we isolate the reddening effects as a
function of redshift and absorber rest equivalent width, W_0. We find the
amount of dust to increase with cosmic time as (1+z)^(-1.1 +/- 0.4), following
the evolution of cosmic star density or integrated star formation rate. We
measure the reddening effects over a factor 30 in E(B-V) and we find the dust
column density to be proportional to W_0^(1.9 +/- 0.2), which provides an
important scaling for theoretical modeling of metal absorbers. We also measure
the dust-to-metals ratio and find it similar to that of the Milky Way.
  In contrast to previous studies, we do not detect any gravitational
magnification by MgII systems. We measure the upper limit \mu<1.10 and discuss
the origin of the discrepancy. Finally, we estimate the fraction of absorbers
missed due to extinction effects and show that it rises from 1 to 50% in the
range 1<W_0<6 Angstrom. We parametrize this effect and provide a correction for
recovering the intrinsic distribution of absorber rest equivalent widths.
","We have used the Hubble Space Telescope (HST) to study the lensing effect on background quasars by foreground galaxies associated with Mg II absorption systems at 0.4 <z abs < 2.0 in order to determine their masses and sizes. We find that most of these galaxy halos are well described by singular isothermal spheres with velocity dispersions ranging between 100 - 300 km/sec. The mean mass density within one effective radius for our sample is $\rho_e = 1.5 \times 10^{20} \ M_{\odot}/\text{Mpc}^{3}$ which corresponds to an average halo circular velocity of $220\ \mathrm{km/sec}$. This value agrees very well with previous studies based on gravitational lensing measurements as well as dynamical estimates using virial theorem arguments. Using this result we can estimate the total number of dark matter particles enclosed within one effective radius of each absorber system. For all but two cases, the estimated particle numbers agree reasonably well with those expected if the absorbing gas traces the underlying dark matter distribution.",arxiv,bigscience bloomz,706.0898,0.4444444444444444,0.24369747899159663,0.4358974358974359,0.4180602006688964,1,1,0,0,0,1,1,0,0,0,0.09520154585179333,0.09601104121737426,0.10505836575875487,0.0946969696969697,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Non-saturating magnetoresistance of inhomogeneous conductors: comparison of experiment and simulation,"  The silver chalcogenides provide a striking example of the benefits of
imperfection. Nanothreads of excess silver cause distortions in the current
flow that yield a linear and non-saturating transverse magnetoresistance (MR).
Associated with the large and positive MR is a negative longitudinal MR. The
longitudinal MR only occurs in the three-dimensional limit and thereby permits
the determination of a characteristic length scale set by the spatial
inhomogeneity. We find that this fundamental inhomogeneity length can be as
large as ten microns. Systematic measurements of the diagonal and off-diagonal
components of the resistivity tensor in various sample geometries show clear
evidence of the distorted current paths posited in theoretical simulations. We
use a random resistor network model to fit the linear MR, and expand it from
two to three dimensions to depict current distortions in the third (thickness)
dimension. When compared directly to experiments on Ag$_{2\pm\delta}$Se and
Ag$_{2\pm\delta}$Te, in magnetic fields up to 55 T, the model identifies
conductivity fluctuations due to macroscopic inhomogeneities as the underlying
physical mechanism. It also accounts reasonably quantitatively for the various
components of the resistivity tensor observed in the experiments.
","We report on the non-saturating magnetoresistance (NSMR) effect observed for thin films with an inhomogeneous distribution of charge carriers, which is caused by their trapping at defects or impurities. We show that this NSMR can be explained within the framework of the semiclassical Boltzmann transport theory if one takes into account the spatial dependence of the scattering time. The latter was calculated using Monte Carlo simulations based on the solution of the kinetic equation for electrons interacting with phonons and static disorder potential fluctuations. Our results are compared to experimental data obtained for InAs/GaSb superlattices grown by molecular beam epitaxy. Non-saturating magnetoresistivity has been recently discovered in various materials including semiconductors [1] , metals [2] , carbon nanotubes [3] . This phenomenon manifests itself as a linear increase of resistivity ρ(H) ∝ H when magnetic field H increases up to several Tesla. It is believed that it originates from the presence of spatially localized states near the Fermi level [4] .
In this work we study the non-saturating magnetotransport properties of semiconductor heterostructures consisting of alternating layers of GaSb/InAs. These structures were grown by molecular beam epi-taxy [5] . They have a high density of structural imperfections such as dislocations [6] and stacking faults [7] . As a result, they exhibit strong electron localization [8] leading to pronounced quantum confinement effects [9] . Figure 1 shows typical temperature dependences of resistance R xx measured along the growth direction z for different values of applied magnetic fields. One can see that all curves demonstrate metallic behavior down to low temperatures T < 2 K. At higher temperatures there appears a weak insulating-like behavior due to thermally activated hopping between localized states [10] . For small magnetic fields [ Fig.  1(a) ] the resistance decreases monotonically upon cooling indicating the dominance of elastic scattering processes [11] . However, for larger fields [Figs. 1(c),1(d)] the resistance exhibits non-monotonic behavior with a minimum around 10-20 K followed by",arxiv,bigscience bloomz,705.0393,0.4444444444444444,0.7983193277310925,0.31794871794871793,0.8824653607262303,1,1,0,0,0,1,1,0,0,0,0.10154424936858655,0.06615218214244022,0.11284046692607004,0.10227272727272728,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Vacuum Energy and Renormalization on the Edge,"  The vacuum dependence on boundary conditions in quantum field theories is
analysed from a very general viewpoint. From this perspective the
renormalization prescriptions not only imply the renormalization of the
couplings of the theory in the bulk but also the appearance of a flow in the
space of boundary conditions. For regular boundaries this flow has a large
variety of fixed points and no cyclic orbit. The family of fixed points
includes Neumann and Dirichlet boundary conditions. In one-dimensional field
theories pseudoperiodic and quasiperiodic boundary conditions are also RG fixed
points. Under these conditions massless bosonic free field theories are
conformally invariant. Among all fixed points only Neumann boundary conditions
are infrared stable fixed points. All other conformal invariant boundary
conditions become unstable under some relevant perturbations. In finite volumes
we analyse the dependence of the vacuum energy along the trajectories of the
renormalization group flow providing an interesting framework for dark energy
evolution. On the contrary, the renormalization group flow on the boundary does
not affect the leading behaviour of the entanglement entropy of the vacuum in
one-dimensional conformally invariant bosonic theories.
","We study vacuum energy in quantum field theory with boundary conditions that break conformal invariance, such as Dirichlet or Neumann boundary conditions. We show how to renormalize this quantity using zeta function regularization techniques. In particular we find that for any number of dimensions there is an infinite set of counterterms which must be included when computing the vacuum energy density at zero temperature. This result has implications for Casimir effect calculations where one considers two parallel plates separated by some distance. The presence of these additional terms can lead to significant changes in the results obtained previously. Finally we consider the case of fermions coupled to scalar fields and compute the vacuum expectation value of the stress-energy tensor. For certain values of the coupling constant it turns out that the vacuum state becomes unstable due to spontaneous symmetry breaking. Vacuum energy plays an important role in many areas of physics including cosmology [1] , black hole thermodynamics [2] , and condensed matter systems [3] . It also appears in various contexts within string theory [4] .
In recent years much progress has been made towards understanding the nature of vacuum fluctuations in quantum field theories (QFTs) [5] - [8] . However most work done so far has focused primarily on QFTs defined on flat space-time manifolds without boundaries [9] - [11] . Recently however there have been several attempts to understand vacuum fluctuations in QFTs defined on curved backgrounds [12] - [14] . Another interesting problem involves studying vacuum fluctuations in QFT's defined on spaces with boundaries [15] - [17] . Such problems are relevant for example in the context of Casimir effects [18] - [20] .",arxiv,bigscience bloomz,704.1084,0.5,0.6470588235294118,0.3076923076923077,0.7505972288580984,0,1,0,0,0,1,1,0,0,1,0.07640751675273806,0.047342776072346555,0.06614785992217899,0.056818181818181816,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Origin of magnetoelectric behavior in BiFeO$_3$,"  The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of
accurate density functional calculations. The structural, electronic, magnetic,
and ferroelectric properties of BiFeO$_3$ are predicted correctly without
including strong correlation effect in the calculation. Moreover, the
experimentally-observed elongation of cubic perovskite-like lattice along the
[111] direction is correctly reproduced. At high pressure we predicted a
pressure-induced structural transition and the total energy calculations at
expanded lattice show two lower energy ferroelectric phases, closer in energy
to the ground state phase. Band-structure calculations show that BiFeO$_3$ will
be an insulator in A- and G-type antiferromagnetic phases and a metal in other
magnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using
various tools and electron localization function analysis shows that
stereochemically active lone-pair electrons at the Bi sites are responsible for
displacements of the Bi atoms from the centro-symmetric to the
noncentrosymmetric structure and hence the ferroelectricity. A large
ferroelectric polarization (88.7 $\mu$C/cm$^{2}$) is predicted in accordance
with recent experimental findings. The net polarization is found to mainly ($>$
98%) originate from Bi atoms. Moreover the large scatter in experimentally
reported polarization values is due to the large anisotropy in the spontaneous
polarization.
","The origin of the magnetoelectric effect (ME) is investigated by first-principles calculations for bulk and surface structures of BiFeO$_{3}$, which has been recently discovered to be ferroelectric with antiferromagnetic ordering at room temperature.  The calculated results show that the ME coupling constant is strongly dependent on the oxygen octahedral tilt angle $\theta_{oct}$; it increases rapidly as $\theta_{oct}$ decreases below $11^{\circ} \sim 13^{\circ}$. This result suggests that the large ME response observed experimentally can be attributed mainly to the rotation of oxygen octahedra around the c-axis. In addition, we find that the contribution from the Fe magnetic moment plays an important role in enhancing the ME effect when $\theta_{oct}$ becomes small enough. Finally, we discuss possible origins of the discrepancy between our theoretical prediction and experimental observation. We also present some suggestions for further experiments.",arxiv,bigscience bloomz,705.046,0.4444444444444444,0.24369747899159663,0.3641025641025641,0.3377926421404682,1,1,0,0,0,1,1,1,0,0,0.08514007469244106,0.12103044837704867,0.08560311284046693,0.07954545454545454,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The evolution of interstellar clouds in a streaming hot plasma including heat conduction,"  To examine the evolution of giant molecular clouds in the stream of a hot
plasma we performed two-dimensional hydrodynamical simulations that take full
account of self-gravity, heating and cooling effects and heat conduction by
electrons. We use the thermal conductivity of a fully ionized hydrogen plasma
proposed by Spitzer and a saturated heat flux according to Cowie & McKee in
regions where the mean free path of the electrons is large compared to the
temperature scaleheight. Significant structural and evolutionary differences
occur between simulations with and without heat conduction. Dense clouds in
pure dynamical models experience dynamical destruction by Kelvin-Helmholtz (KH)
instability. In static models heat conduction leads to evaporation of such
clouds. Heat conduction acting on clouds in a gas stream smooths out steep
temperature and density gradients at the edge of the cloud because the
conduction timescale is shorter than the cooling timescale. This diminishes the
velocity gradient between the streaming plasma and the cloud, so that the
timescale for the onset of KH instabilities increases, and the surface of the
cloud becomes less susceptible to KH instabilities. The stabilisation effect of
heat conduction against KH instability is more pronounced for smaller and less
massive clouds. As in the static case more realistic cloud conditions allow
heat conduction to transfer hot material onto the cloud's surface and to mix
the accreted gas deeper into the cloud.
","We study the thermal instability and fragmentation of an initially uniform, isothermal cloud embedded in a hot plasma flow with constant velocity shear using two-dimensional hydrodynamic simulations. The initial temperature difference between the cloud and its surroundings leads to the development of Rayleigh-Taylor instabilities at the cloud boundary which grow into mushroom-like structures that are unstable against Kelvin-Helmholtz modes as well. We find that these two types of instabilities can lead to the formation of filaments and clumps within the cloud on different timescales depending on the strength of the magnetic field. In addition we show that heat conduction has only minor effects on the cloud's morphology but significantly influences the cloud's internal structure by smoothing out density fluctuations. Finally, we discuss how our results may be used to explain observations of cometary globules and other dense molecular clouds. Subject headings: Instability -Conductivity -Magnetic fields -Clouds",arxiv,bigscience bloomz,704.3592,0.4444444444444444,0.24369747899159663,0.5384615384615384,0.37219302436693746,1,1,0,0,1,0,1,1,0,1,0.1058794447323221,0.07572539447928633,0.10894941634241245,0.03787878787878788,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
Measuring Electric Fields From Surface Contaminants with Neutral Atoms,"  In this paper we demonstrate a technique of utilizing magnetically trapped
neutral Rb-87 atoms to measure the magnitude and direction of stray electric
fields emanating from surface contaminants. We apply an alternating external
electric field that adds to (or subtracts from) the stray field in such a way
as to resonantly drive the trapped atoms into a mechanical dipole oscillation.
The growth rate of the oscillation's amplitude provides information about the
magnitude and sign of the stray field gradient. Using this measurement
technique, we are able to reconstruct the vector electric field produced by
surface contaminants. In addition, we can accurately measure the electric
fields generated from adsorbed atoms purposely placed onto the surface and
account for their systematic effects, which can plague a precision
surface-force measurement. We show that baking the substrate can reduce the
electric fields emanating from adsorbate, and that the mechanism for reduction
is likely surface diffusion, not desorption.
","We report on the measurement of electric fields produced by surface contaminants using neutral atoms as probes. The technique is based on measuring the Stark shift in atomic resonance lines due to an applied electric field, and has been used previously for studying electric fields near surfaces such as those found at liquid helium temperatures or in high vacuum environments.  We have extended this method to measure electric fields over a wide range of temperatures (4 K - 300 K) and pressures (10-6 Torr - atmospheric pressure). In addition we demonstrate that it can be used to study electric fields generated by charged particles trapped close to surfaces. This work opens up new possibilities for probing electric fields in many different systems including biological samples where conventional techniques are limited. Measurement of electric fields produced by charged particle traps using neutral atoms: A novel probe of local electrostatic potentials. Measuring electric fields produced by surface contaminant... Neutral atoms provide a unique tool for investigating electric fields because they respond directly to the vector potential associated with electromagnetic fields. Here we use this property to measure electric fields produced by surface contamination. Our approach relies on observing the Stark splitting of atomic energy levels when exposed to external electric fields. Previous experiments have demonstrated this effect in low temperature and ultra-high vacuum conditions1-5 but here we show how these measurements may also be performed under more typical laboratory conditions.",arxiv,bigscience bloomz,705.2027,0.2777777777777778,0.49579831932773116,0.15384615384615385,0.6359292881032013,1,1,0,0,1,1,1,1,0,0,0.05794358944446991,0.07936068123189412,0.058365758754863814,0.08712121212121213,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Gas-grain chemistry in cold interstellar cloud cores with a microscopic Monte Carlo approach to surface chemistry,"  AIM: We have recently developed a microscopic Monte Carlo approach to study
surface chemistry on interstellar grains and the morphology of ice mantles. The
method is designed to eliminate the problems inherent in the rate-equation
formalism to surface chemistry. Here we report the first use of this method in
a chemical model of cold interstellar cloud cores that includes both gas-phase
and surface chemistry. The surface chemical network consists of a small number
of diffusive reactions that can produce molecular oxygen, water, carbon
dioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation
is started by running a gas-phase model including accretion onto grains but no
surface chemistry or evaporation. The starting surface consists of either flat
or rough olivine. We introduce the surface chemistry of the three species H, O
and CO in an iterative manner using our stochastic technique. Under the
conditions of the simulation, only atomic hydrogen can evaporate to a
significant extent. Although it has little effect on other gas-phase species,
the evaporation of atomic hydrogen changes its gas-phase abundance, which in
turn changes the flux of atomic hydrogen onto grains. The effect on the surface
chemistry is treated until convergence occurs. We neglect all non-thermal
desorptive processes. RESULTS: We determine the mantle abundances of assorted
molecules as a function of time through 2x10^5 yr. Our method also allows
determination of the abundance of each molecule in specific monolayers. The
mantle results can be compared with observations of water, carbon dioxide,
carbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than
a slight underproduction of mantle CO, our results are in very good agreement
with observations.
","We present results for the chemical composition and temperature structure of two different models of dense molecular clouds, which are based on detailed microphysical calculations including gas-grain interactions. The first model is an isolated spherical core that collapses under its own gravity; it has been evolved up to densities of 10^8 cm^{-3}. In this case we find that grain-surface reactions play only a minor role because they occur mainly at low temperatures where the density is too small to allow efficient freeze-out onto grains. However, these processes can be important if the collapse proceeds faster than predicted by standard theory (e.g., due to magnetic fields). We also study the evolution of a protostellar envelope surrounding a newly formed star. Here we find that the formation of complex organic molecules such as methanol or formaldehyde requires high densities and relatively warm temperatures. This suggests that these species may not be abundant enough to explain their observed abundances in dark clouds unless additional sources of heating exist.",arxiv,bigscience bloomz,704.2704,0.7222222222222222,0.29411764705882354,0.7692307692307693,0.42666029622551366,0,1,1,0,0,1,1,1,0,0,0.07507881541065482,0.043948834500170314,0.10116731517509728,0.026515151515151516,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Transition region features observed with Hinode/EIS,"  Two types of active region feature prominent at transition region
temperatures are identified in Hinode/EIS data of AR 10938 taken on 2007
January 20. The footpoints of 1 MK TRACE loops are shown to emit strongly in
emission lines formed at log T=5.4-5.8, allowing the temperature increase along
the footpoints to be clearly seen. A density diagnostic of Mg VII yields the
density in the footpoints, with one loop showing a decrease from 3x10^9 cm^-3
at the base to 1.5x10^9 cm^-3 at a projected height of 20 Mm. The second
feature is a compact active region transition region brightening which is
particularly intense in O V emission (log T=5.4) but also has a signature at
temperatures up to log T=6.3. The Mg VII diagnostic gives a density of 4x10^10
cm^-3, and emission lines of Mg VI and Mg VII show line profiles broadened by
50 km/s and wings extending beyond 200 km/s. Continuum emission in the short
wavelength band is also found to be enhanced, and is suggested to be free-bound
emission from recombination onto He^+.
","We present the first results on transition region (TR) lines obtained by the Extreme Ultraviolet Imaging Spectrometer (EIS), aboard the Solar-B satellite, in active regions and quiet Sun areas. The EIS data are compared to those taken simultaneously by the EUV Imaging Telescope (EIT). We find that TR line intensities show significant enhancements over their photospheric values at temperatures between 10 5 K and 2 Â 10 6 K. In addition, we observe strong spatial variations in the intensity ratios among different TR lines. These observations suggest that there is an abundance variation across the solar surface for some elements such as Fe xii, Fe xiii, Si vii, and Mg ix. This work was supported by NASA grants NNG05GE73G and NNX07AQ85G. Hinode is a Japanese mission developed and launched by ISAS/JAXA, collaborating with NAOJ as domestic partner, NASA and STFC (UK) as international partners. Scientific operation of the Hinode mission is conducted by the Hinode science team organized at ISAS/JAXA.",arxiv,bigscience bloomz,706.1856,0.2777777777777778,0.29411764705882354,0.2717948717948718,0.4123268036311515,1,1,0,0,0,1,1,0,0,0,0.04151977372233294,0.08843872348141836,0.0311284046692607,0.07575757575757576,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Probing the Structure of Gamma-Ray Burst Jets with Steep Decay Phase of their Early X-ray Afterglows,"  We show that the jet structure of gamma-ray bursts (GRBs) can be investigated
with the tail emission of the prompt GRB. The tail emission which we consider
is identified as a steep-decay component of the early X-ray afterglow observed
by the X-ray Telescope onboard Swift. Using a Monte Carlo method, we derive,
for the first time, the distribution of the decay index of the GRB tail
emission for various jet models. The new definitions of the zero of time and
the time interval of a fitting region are proposed. These definitions for
fitting the light curve lead us an unique definition of the decay index, which
is useful to investigate the structure of the GRB jet. We find that if the GRB
jet has a core-envelope structure, the predicted distribution of the decay
index of the tail has a wide scatter and has multiple peaks, which cannot be
seen for the case of the uniform and the Gaussian jet. Therefore, the decay
index distribution tells us the information on the jet structure. Especially,
if we observe events whose decay index is less than about 2, both the uniform
and the Gaussian jet models will be disfavored according to our simulation
study.
","We present an analysis of early X-ray afterglow data for eight gamma-ray bursts (GRBs) in which we find evidence that they are associated with relativistic jets viewed off-axis, and show how this can be used to probe jet structure. We use our model to predict the late-time behaviour of these GRB afterglows and compare it with observations made by Swift/XRT. The results suggest that the majority of GRB jets have a structured energy distribution, with most of the kinetic energy contained within a narrow cone along the jet axis. This is consistent with theoretical expectations based on models where GRBs result from the collapse of massive stars into black holes or neutron stars. 
Introduction

Gamma-ray bursts (GRBs; see Piran 2004 , Gehrels et al. 2009 ) are brief flashes of high-energy radiation lasting typically 10 s but ranging up to several hundred seconds. They were first detected over 50 years ago (Klebesadel et al. 1973; Strong et al. 1974) , but despite extensive observational efforts there remain many open questions about them. In particular, what powers the emission? What causes the observed diversity between different bursts?
The standard fireball model (see e.g., Rees & Meszaros 1992; Sari 1997; Piran 1999; Wijers 2001; Kumar & Zhang 2015) provides one explanation for the prompt phase of GRB emission. It involves the dissipation of kinetic energy stored in a relativistically expanding shell of plasma produced during some catastrophic event such as the merger of two compact objects or the collapse of a massive star. However, this model cannot explain all aspects of GRB phenomenology. For example, it does not account for the wide range of durations seen across the population of GRBs (e.g., Nakar 2007), nor do current models provide any satisfactory explanation for why only a small fraction of collapsing stars produce observable GRBs (e. g., Bromm & Loeb 2006) . Furthermore, the lack of detection of optical counterparts to short-duration GRBs has led to suggestions that at least some",arxiv,bigscience bloomz,704.1055,0.3888888888888889,0.3697478991596639,0.4,0.4237935977066412,1,1,0,0,0,2,2,1,1,0,0.08727373091093897,0.12145748537952618,0.1245136186770428,0.14772727272727273,0,4,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1
Kirillov-Reshetikhin conjecture : the general case,"  We prove the Kirillov-Reshetikhin (KR) conjecture in the general case : for
all twisted quantum affine algebras we prove that the characters of KR modules
solve the twisted Q-system and we get explicit formulas for the character of
their tensor products (the untwisted simply-laced case was treated by Najakima,
and the untwisted case by the author). The proof is uniform and provides
several new developments for the representation theory of twisted quantum
affine algebras, including twisted Frenkel-Reshetikhin q-characters (expected
by Frenkel-Reshetikhin and Frenkel-Mukhin). We also prove the twisted T-system.
As an application we get explicit formulas for the twisted q-characters of
fundamental representations for all types, including the formulas for types
D_4^{(3)}, E_6^{(2)} conjectured by Reshetikhin. We prove the formulas for KR
modules in types A_n^{(2)} and D_4^{(3)} conjectured by Kuniba-Suzuki.
Eventually our results imply the conjectural branching rules [HKOTT] to the
quantum subalgebra of finite type.
","We prove that the Kirillov-Reshitikhin conjecture holds for any semisimple Lie algebra over an arbitrary field, and in particular we show that the number of irreducible representations of the quantum group is equal to the dimension of its Cartan subalgebra.  We also give some applications of this result to the representation theory of finite groups. The Kirillov-Reshetkhin Conjecture states that if $\mathfrak{g}$ is a simple complex Lie algebra with root system $R = \Phi(\mathfrak{g})$ then there exists a bijection between the set of isomorphism classes of irreducible representations of the quantized enveloping algebra $U_q(\mathfrak{g}^{0})$ (where $q$ is not a root of unity), and the set of dominant weights $\lambda \in P^{+}(R)$ such that $|\lambda| \leq q - 1$. 
The proof uses results on the classification of indecomposable tilting modules due to Donkin, Erdmann, Mathieu and Schmidt; these are combined with techniques developed by Lusztig and Kashiwara to obtain our main theorem.",arxiv,bigscience bloomz,704.2838,0.2777777777777778,0.14285714285714285,0.12307692307692308,0.38652651696129964,1,1,1,0,0,1,1,1,0,0,0.16633528810607878,0.2889533534331307,0.12840466926070038,0.3181818181818182,1,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Cut-off Covering Spectrum,"  We introduce the $R$ cut-off covering spectrum and the cut-off covering
spectrum of a complete length space or Riemannian manifold. The spectra measure
the sizes of localized holes in the space and are defined using covering spaces
called $\delta$ covers and $R$ cut-off $\delta$ covers. They are investigated
using $\delta$ homotopies which are homotopies via grids whose squares are
mapped into balls of radius $\delta$.
  On locally compact spaces, we prove that these new spectra are subsets of the
closure of the length spectrum. We prove the $R$ cut-off covering spectrum is
almost continuous with respect to the pointed Gromov-Hausdorff convergence of
spaces and that the cut-off covering spectrum is also relatively well behaved.
This is not true of the covering spectrum defined in our earlier work which was
shown to be well behaved on compact spaces. We close by analyzing these spectra
on Riemannian manifolds with lower bounds on their sectional and Ricci
curvature and their limit spaces.
","The cut-off covering spectrum is the set of all functions in $L^2(\mathbb{R})$ whose Fourier transforms are supported on $[-1,1]$ and have absolute value at most 1 everywhere.  It was introduced by David Hilbert as an example of a non-trivial closed subspace of $L^2$ that does not contain any nonconstant entire analytic function.   In this talk we will discuss some recent results about the structure of the cut-off covering spectrum. The first part of our discussion concerns the problem of determining whether or not a given bounded linear operator on $L^2$ has finite rank.    We show how to use the theory of Toeplitz operators with matrix symbols developed by Sarason and others to give a complete solution to this problem for certain classes of operators including those arising from multiplication by polynomials.   For other classes of operators such as those coming from multiplication by trigonometric polynomials it turns out that there exist examples which do not fall into one of these categories but still have finite rank.     The second part of our discussion concerns a theorem due to Joram Lindenstrauss concerning the existence of extremal points in the unit ball of the space of continuous functions on the circle with absolutely convergent Fourier series.   This theorem can be viewed as a generalization of the classical result of Carleson stating that every point in the unit ball of $H^1_0(T)$ (the Hardy space of order 1)  is an extreme point of the unit ball of $H^1_o(T)$ where $T = [0,2\pi]$.   By using techniques similar to those used in the proof of the original theorem of Carleson we prove a version of Lindenstrauss' theorem for the space of continuous functions...",arxiv,bigscience bloomz,705.3822,0.3333333333333333,0.3949579831932773,0.18461538461538463,0.7448638318203535,0,1,0,0,0,1,1,0,0,1,0.041991504141377506,0.09639738204834947,0.04669260700389105,0.09848484848484848,0,0,0,5,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Distortion of Gravitational-Wave Packets Due to their Self-Gravity,"  When a source emits a gravity-wave (GW) pulse over a short period of time,
the leading edge of the GW signal is redshifted more than the inner boundary of
the pulse. The GW pulse is distorted by the gravitational effect of the
self-energy residing in between these shells. We illustrate this distortion for
GW pulses from the final plunge of black hole (BH) binaries, leading to the
evolution of the GW profile as a function of the radial distance from the
source. The distortion depends on the total GW energy released and the duration
of the emission, scaled by the total binary mass, M. The effect should be
relevant in finite box simulations where the waveforms are extracted within a
radius of <~ 100M. For characteristic emission parameters at the final plunge
between binary BHs of arbitrary spins, this effect could distort the simulated
GW templates for LIGO and LISA by a fraction of 0.001. Accounting for the wave
distortion would significantly decrease the waveform extraction errors in
numerical simulations.
","We study the gravitational self-force acting on a wave packet in curved spacetime, and show that it causes its distortion.  We consider two types of wavepackets: one is constructed by superposing plane waves with different frequencies; another is made up of spherical waves emitted at various angles around an isolated source point. In both cases we find that the force acts as if there were additional sources located behind the packet's center-of-mass worldline. The effect can be understood intuitively using the concept of ""gravitational memory"". Our results are relevant for understanding how gravitational waves propagate through space-time. They also provide new insights into the problem of gravitational radiation reaction. Introduction - A fundamental question about gravitational waves (GWs) concerns how they evolve over time when propagating through curved space-time [1] . This issue has been studied extensively within the framework of linearized gravity theory [2] , where GWs are treated as small perturbations of flat Minkowski background geometry [3] .
In this work we focus on the effects due to gravitational self-coupling [4] . These arise because each part of a GW carries energy density which exerts pressure back onto itself via Newtonian gravity [5] . As such, the total force acting upon any given portion of a GW depends not only on the local curvature but also on the entire history of the wave [6] . It turns out that these forces cause significant distortions of the wave packets [7, 8] . For example, the shape of a plane-wave packet changes during propagation so that its peak moves away from the direction of motion [9] . Similar behavior was found for spherical wave packets [10] .",arxiv,bigscience bloomz,704.1149,0.2777777777777778,0.6470588235294118,0.24102564102564103,0.747730530339226,1,1,0,0,0,1,1,1,0,1,0.10321352037043872,0.0646298230089792,0.07782101167315175,0.04924242424242424,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
"Extended Comment on ""One-Range Addition Theorems for Coulomb Interaction Potential and Its Derivatives"" by I. I. Guseinov (Chem. Phys. Vol. 309 (2005), pp. 209 - 213)","  Addition theorems are principal tools that express a function $f (\bm{r} \pm
\bm{r}')$ in terms of products of other functions that only depend on either
$\bm{r}$ or $\bm{r}'$. The best known example of such an addition theorem is
the Laplace expansion of the Coulomb potential which possesses a characteristic
two-range form. Guseinov [Chem. Phys. {\bf 309}, 209 - 213 (2005)] derived
one-range addition theorems for the Coulomb potential via the limit $\beta \to
0$ in previously derived one-range addition theorems for the Yukawa potential
$\exp \bigl(-\beta | \bm{r}-\bm{r}'| \bigr) /| \bm{r}-\bm{r}'|$. At first
sight, this looks like a remarkable achievement, but from a mathematical point
of view, Guseinov's work is at best questionable and in some cases
fundamentally flawed. One-range addition theorems are expansions in terms of
functions that are complete and orthonormal in a given Hilbert space, but
Guseinov replaced the complete and orthonormal functions by nonorthogonal
Slater-type functions and rearranged the resulting expansions. This is a
dangerous operation whose validity must be checked. It is shown that the
one-center limit $\bm{r}' = \bm{0}$ of Guseinov's rearranged Yukawa addition
theorems as well as of several other addition theorems does not exist.
Moreover, the Coulomb potential does not belong to any of the Hilbert spaces
implicitly used by Guseinov. Accordingly, one-range addition theorems for the
Coulomb potential diverge in the mean. Instead, these one-range addition
theorems have to interpreted as expansions of generalized functions in the
sense of Schwartz that converge weakly in suitable functionals.
","We have recently shown that the one-range addition theorems derived in our previous work are valid not only for the Coulomb interaction potential but also its derivatives, such as the nuclear attraction potential or the exchange potential. 
 
 In this comment we show how these results can be used to derive new addition theorems for the nuclear attraction potential and the exchange potential. These new addition theorems are useful when calculating matrix elements between atomic orbitals with different angular momenta. We illustrate their application using examples involving hydrogenic wave functions. Finally, we discuss some possible extensions of these results. DOI: 10.1063/1.2055316 
 
 This is an extended version of a comment published in ChemPhysChem. DOI: 10.1002/cphc.201500420 
 
 
 
 One-range addition theorems play important roles in many areas of physics including quantum chemistry [1-3], molecular physics [4], condensed matter physics [5], etc.. They provide simple expressions for evaluating matrix elements of various potentials between two arbitrary wavefunctions. For example, they allow us to calculate matrix elements of the Coulomb interaction potential between any pair of atomic orbital basis sets without having to perform complicated numerical integrations [6]. Recently, we showed that the same approach could be applied to other types of potentials [7-9].",arxiv,bigscience bloomz,704.1088,0.6111111111111112,0.4453781512605043,0.6256410256410256,0.5183946488294315,1,1,0,0,1,0,1,1,0,0,0.1782994762995082,0.08448031095529517,0.2529182879377432,0.06439393939393939,2,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Spectral method for matching exterior and interior elliptic problems,"  A spectral method is described for solving coupled elliptic problems on an
interior and an exterior domain. The method is formulated and tested on the
two-dimensional interior Poisson and exterior Laplace problems, whose solutions
and their normal derivatives are required to be continuous across the
interface. A complete basis of homogeneous solutions for the interior and
exterior regions, corresponding to all possible Dirichlet boundary values at
the interface, are calculated in a preprocessing step. This basis is used to
construct the influence matrix which serves to transform the coupled boundary
conditions into conditions on the interior problem. Chebyshev approximations
are used to represent both the interior solutions and the boundary values. A
standard Chebyshev spectral method is used to calculate the interior solutions.
The exterior harmonic solutions are calculated as the convolution of the
free-space Green's function with a surface density; this surface density is
itself the solution to an integral equation which has an analytic solution when
the boundary values are given as a Chebyshev expansion. Properties of Chebyshev
approximations insure that the basis of exterior harmonic functions represents
the external near-boundary solutions uniformly. The method is tested by
calculating the electrostatic potential resulting from charge distributions in
a rectangle. The resulting influence matrix is well-conditioned and solutions
converge exponentially as the resolution is increased. The generalization of
this approach to three-dimensional problems is discussed, in particular the
magnetohydrodynamic equations in a finite cylindrical domain surrounded by a
vacuum.
","We consider the problem of finding an approximate solution to the following boundary value problem:
  \begin{cases}
    -\Delta u = f & \text{in } \Omega,\\
    u = 0 & \text{on } \partial\Omega.
  \end{cases}
Here $\Omega$ is a bounded domain in $R^n$ with smooth boundary $\partial\Omega$.  We assume that $f$ belongs to $L^2(\Omega)$ and satisfies some additional conditions which are specified below. The main goal of this work is to develop efficient numerical methods for solving (1). In particular we will focus on spectral methods based on the use of spherical harmonics expansions. These methods have been successfully applied to various types of partial differential equations arising in mathematical physics. However their application to the problem under consideration has not yet been studied systematically. Here we present several new results concerning the convergence analysis of these methods as well as their implementation details. Our approach allows us to obtain optimal order error estimates without any regularity assumptions about the exact solution or its derivatives.",arxiv,bigscience bloomz,705.0643,0.5555555555555556,0.3949579831932773,0.6,0.4180602006688964,0,1,1,0,1,1,1,1,0,0,0.09201819090469322,0.06321234862878554,0.13229571984435798,0.056818181818181816,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Transient behavior of surface plasmon polaritons scattered at a subwavelength groove,"  We present a numerical study and analytical model of the optical near-field
diffracted in the vicinity of subwavelength grooves milled in silver surfaces.
The Green's tensor approach permits computation of the phase and amplitude
dependence of the diffracted wave as a function of the groove geometry. It is
shown that the field diffracted along the interface by the groove is equivalent
to replacing the groove by an oscillating dipolar line source. An analytic
expression is derived from the Green's function formalism, that reproduces well
the asymptotic surface plasmon polariton (SPP) wave as well as the transient
surface wave in the near-zone close to the groove. The agreement between this
model and the full simulation is very good, showing that the transient
""near-zone"" regime does not depend on the precise shape of the groove. Finally,
it is shown that a composite diffractive evanescent wave model that includes
the asymptotic SPP can describe the wavelength evolution in this transient
near-zone. Such a semi-analytical model may be useful for the design and
optimization of more elaborate photonic circuits whose behavior in large part
will be controlled by surface waves.
","We study the scattering properties of surface plasmons (SPs) by a single subwavelength groove in an optically thick metal film, which is excited by a normally incident plane wave with circular polarization. The SP field distribution and its decay length are calculated using the Green's function method for different values of the groove depth hg and width wg. It is found that when the groove depth increases to a certain value, the SP field decays exponentially along both directions away from the groove center instead of being confined within the groove region as before. This phenomenon can be explained by the fact that the SP mode becomes leaky once it scatters into radiation modes through the groove aperture. We also find that there exists another critical groove depth beyond which no SP field can exist inside or outside the groove due to total internal reflection between the groove walls. These results provide useful information on how to design efficient plasmonic devices based on grooves.",arxiv,bigscience bloomz,704.0703,0.3333333333333333,0.24369747899159663,0.3230769230769231,0.4237935977066412,1,1,0,0,1,1,0,0,0,1,0.046491374143439075,0.061371764531086205,0.05058365758754864,0.045454545454545456,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
Radio Astrometric Detection and Characterization of Extra-Solar Planets: A White Paper Submitted to the NSF ExoPlanet Task Force,"  The extraordinary astrometric accuracy of radio interferometry creates an
important and unique opportunity for the discovery and characterization of
exo-planets. Currently, the Very Long Baseline Array can routinely achieve
better than 100 microarcsecond accuracy, and can approach 10 microarcsecond
with careful calibration. We describe here RIPL, the Radio Interferometric
PLanet search, a new program with the VLBA and the Green Bank 100 m telescope
that will survey 29 low-mass, active stars over 3 years with sub-Jovian planet
mass sensitivity at 1 AU. An upgrade of the VLBA bandwidth will increase
astrometric accuracy by an order of magnitude. Ultimately, the colossal
collecting area of the Square Kilometer Array could push astrometric accuracy
to 1 microarcsecond, making detection and characterizaiton of Earth mass
planets possible.
  RIPL and other future radio astrometric planet searches occupy a unique
volume in planet discovery and characterization parameter space. The parameter
space of astrometric searches gives greater sensitivity to planets at large
radii than radial velocity searches. For the VLBA and the expanded VLBA, the
targets of radio astrometric surveys are by necessity nearby, low-mass, active
stars, which cannot be studied efficiently through the radial velocity method,
coronagraphy, or optical interferometry. For the SKA, detection sensitivity
will extend to solar-type stars. Planets discovered through radio astrometric
methods will be suitable for characterization through extreme adaptive optics.
  The complementarity of radio astrometric techniques with other methods
demonstrates that radio astrometry can play an important role in the roadmap
for exoplanet discovery and characterization.
","The National Science Foundation (NSF) has recently formed an ""Exoplanet Task Force"" with the goal of identifying key science goals for future space missions in exoplanet research, including radio astrometry.  In this white paper we present our vision on how such a mission could be designed to meet these goals. We argue that a dedicated radio telescope is needed to detect and characterize extrasolar planets using their radio emission. The proposed instrument would have unprecedented sensitivity at decimeter wavelengths, allowing it to detect planetary mass companions around nearby stars as well as directly measure the masses of known giant planet systems. This will enable us to answer fundamental questions about the formation and evolution of planetary systems. Keywords: Radio astronomy, Extrasolar planet detection, Planetary system characterization, Space mission concept development. 1 Introduction   The discovery of more than 1000 extra-solar planets over the past decade has revolutionized our understanding of planetary systems beyond our own solar system. However, many important questions remain unanswered regarding the origin and evolution of these systems. For example, what are the physical characteristics of most of these newly discovered planets? How do they form? What happens when two or more planets interact gravitationally? Are there other Earth-like worlds orbiting Sun-like stars within reachable distances?  Answering these questions requires detailed observations of individual planets, which can only be achieved by direct imaging techniques. Unfortunately, current ground-based observatories cannot achieve high enough angular resolution to resolve the majority of close-in planets due to atmospheric turbulence effects.   To overcome this limitation, NASA's Kepler satellite was launched in 2009 to search for transiting planets around bright stars. Although Kepler has been extremely successful, its primary focus is on detecting large planets in short orbits. It does not provide any information on the orbital inclination angle of detected planets, nor does it allow for precise measurements of planet radii and masses. Furthermore, because of its relatively small field-of-view, Kepler misses out on discoveries made outside of its target fields.",arxiv,bigscience bloomz,704.0238,0.5555555555555556,0.8487394957983193,0.6256410256410256,0.8939321548017201,0,1,0,0,0,1,1,1,1,1,0.0953537638397194,0.06316306468185026,0.11673151750972763,0.04924242424242424,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Structures in the Universe and Origin of Galaxies,"  The analysis of images (of obtained in various ranges of the lengths of
waves) of luminous objects in the Universe by means of a method of multilevel
dynamic contrasting led author to the conclusions: a) the structures of all
observable galaxies represents a complicated constructions which have the
tendency to self-similarity and made of separate (basic) blocks, which are a
coaxially tubular structures and a cartwheel-like structures; b) the majority
of observable objects in the Universe are luminous butt-ends of almost
invisible (of almost completely transparent) of filamentary formations which
structures are seen only near to their luminous butt-ends; c) the result of
analysis of images of cosmic objects show the structure of many pairs of
cooperating galaxies point to opportunity of their formation at butt-ends
generated in a place of break of the similar filament; d) the interacting
galaxies (M 81 and M 82) show they are butt-ends of sawed off of two branches
of a treelike filament and their interaction is coming out through this
filament; e) as our Universe is in dynamics the processes of formation of
stars, galaxies and their congestions can go presently by means of a fracturing
of filaments with a corresponding diameters and of the time for their such
formation is necessary much less, than along existing standard model.
","The book is divided into three parts, each part containing several chapters. The first part deals with cosmological models and their predictions for large-scale structures observed today. In this section we will discuss how galaxies form and evolve within these models. We will also introduce some basic concepts such as dark matter halos, galaxy biasing etc., which are important to understand the formation of large scale structure. The second part discusses observational techniques used to study the distribution of galaxies on different scales. Here we will describe various surveys that have been carried out over past few decades using ground-based telescopes or space based missions like Hubble Space Telescope (HST). Finally, third part describes statistical methods commonly used to analyze data obtained by observing the universe. This includes topics ranging from correlation functions to power spectrum analysis. The main goal of this course is to provide an introduction to modern astrophysics. It covers many aspects of theoretical physics and observational astronomy including general relativity, quantum mechanics, nuclear physics, particle physics, stellar evolution, black holes, supernovae, quasars, gamma-ray bursts, pulsar, gravitational waves, cosmic microwave background radiation, big bang nucleosynthesis, inflationary cosmology, dark energy, dark matter, baryonic acoustic oscillations, primordial fluctuations, galaxy clusters, supermassive black holes, active galactic nuclei, starburst galaxies, infrared galaxies, radio galaxies, interacting galaxies, merging galaxies, elliptical galaxies, lenticular galaxies, spiral galaxies, irregular galaxies, dwarf galaxies, blue compact dwarfs, Lyman-break galaxies, high-z quasars, distant red galaxies, high-redshift galaxies, intergalactic medium, interstellar medium, Milky Way Galaxy, Local Group of Galaxies, Virgo Cluster of Galaxies, Coma Cluster of Galaxies, Perseus Cluster of Galaxies, Abell Clusters of Galaxies, Large Scale Structure of the Universe, Cosmic Web, Supercluster-void network, Dark Matter Halos, Biased Growth of Structures, Observational Techniques, Statistical Methods, Cosmological Parameters, Future Directions...",arxiv,bigscience bloomz,704.1448,0.0,0.4453781512605043,0.47692307692307695,0.78786430960344,1,1,1,0,0,1,1,0,0,0,0.0,0.46677426067738376,0.0,0.6590909090909091,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Families of holomorphic bundles,"  The first goal of the article is to solve several fundamental problems in the
theory of holomorphic bundles over non-algebraic manifolds: For instance we
prove that stability and semi-stability are Zariski open properties in families
when the Gauduchon degree map is a topological invariant, or when the parameter
manifold is compact. Second we show that, for a generically stable family of
bundles over a K\""ahler manifold, the Petersson-Weil form extends as a closed
positive current on the whole parameter space of the family. This extension
theorem uses classical tools from Yang-Mills theory developed by Donaldson
(e.g. the Donaldson functional and the heat equation for Hermitian metrics on a
holomorphic bundle). We apply these results to study families of bundles over a
K\""ahlerian manifold $Y$ parameterized by a non-K\""ahlerian surface $X$,
proving that such families must satisfy very restrictive conditions. These
results play an important role in our program to prove existence of curves on
class VII surfaces.
","In this article, we study families of holomorphic vector bundles on complex algebraic varieties. We prove that the set of isomorphism classes of such families is naturally an affine scheme over the base variety and give explicit equations for it in terms of Chern classes.  In particular, if the base variety has dimension one then these schemes are reduced to points corresponding to the rank and degree of each bundle in the family. 
We also show how our results can be used to construct moduli spaces of stable vector bundles with fixed determinant. The main result of this article was announced by J. P. Serre at the conference ""Algebraic geometry and number theory"" held in Paris in June 2005 (see [Ser] ). Families of holomorphic vector bundles have been studied extensively since the work of Grothendieck [Gro1] . They play important roles both in algebraic geometry and mathematical physics; see e.g., [Bri1,  Bri2,   Bri3,   ...",arxiv,bigscience bloomz,704.2629,0.2777777777777778,0.29411764705882354,0.17435897435897435,0.39799331103678937,1,1,1,0,0,1,0,1,0,0,0.139011159114237,0.05641227563210842,0.08949416342412451,0.04924242424242424,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
Relation between exchange-only optimized potential and Kohn-Sham methods with finite basis sets; solution of a paradox,"  Arguments showing that exchange-only optimized effective potential (xOEP)
methods, with finite basis sets, cannot in general yield the Hartree-Fock (HF)
ground state energy, but a higher one, are given. While the orbital products of
a complete basis are linearly dependent, the HF ground state energy can only be
obtained via a basis set xOEP scheme in the special case that all products of
occupied and unoccupied orbitals emerging from the employed orbital basis set
are linearly independent from each other. In this case, however, exchange
potentials leading to the HF ground state energy exhibit unphysical
oscillations and do not represent a Kohn-Sham (KS) exchange potential. These
findings solve the seemingly paradoxical results of Staroverov, Scuseria and
Davidson that certain finite basis set xOEP calculations lead to the HF ground
state energy despite the fact that within a real space (or complete basis)
representation the xOEP ground state energy is always higher than the HF
energy. Moreover, whether or not the occupied and unoccupied orbital products
are linearly independent, it is shown that basis set xOEP methods only
represent exact exchange-only (EXX) KS methods, i.e., proper density-functional
methods, if the orbital basis set and the auxiliary basis set representing the
exchange potential are balanced to each other, i.e., if the orbital basis is
comprehensive enough for a given auxiliary basis. Otherwise xOEP methods do not
represent EXX KS methods and yield unphysical exchange potentials.
","We show that the exchange-only optimized potentials (OEPs) are not equivalent to the Kohn-Sham (KS) method in general, even if one uses an exact density functional for the exchangecorrelation energy. We demonstrate this by solving analytically the OEPs for two simple model systems using Gaussian-type orbitals as basis functions. The results obtained within both approaches differ significantly. In particular, we find that the KS approach yields incorrect values for the total energies of these systems. This is due to the fact that the KS equations do not have solutions corresponding to all possible densities which can be generated by the given basis sets. On the other hand, the OEP formalism always provides unique solutions for any given density matrix. Our analysis shows also how to resolve the apparent paradox arising when trying to apply the OEP formalism to the case where only a limited number of basis functions is used.",arxiv,bigscience bloomz,705.1717,0.2777777777777778,0.29411764705882354,0.5641025641025641,0.3836598184424272,1,1,0,0,0,1,1,0,0,0,0.18215310082313635,0.07292399028444795,0.22957198443579765,0.045454545454545456,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
Beryllium in Ultra-Lithium-Deficient Halo Stars - The Blue Straggler Connection,"  There are nine metal-deficient stars that have Li abundances well below the
Li plateau that is defined by over 100 unevolved stars with temperatures above
5800 K and values of [Fe/H] $<$ $-$1.0. Abundances of Be have been determined
for most of these ultra-Li-deficient stars in order to investigate the cause of
the Li deficiencies. High-resolution and high signal-to-noise spectra have been
obtained in the Be II spectral region near 3130 \AA for six ultra-Li-deficient
stars with the Keck I telescope and its new uv-sensitive CCD on the upgraded
HIRES. The spectrum synthesis technique has been used to determine Be
abundances. All six stars are found to have Be deficiencies also. Two have
measurable - but reduced - Be and four have only upper limits on Be. These
results are consistent with the idea that these Li- and Be-deficient stars are
analogous to blue stragglers. The stars have undergone mass transfer events (or
mergers) which destroy or dilute both Li and Be. The findings cannot be matched
by the models that predict that the deficiencies are due to extra-mixing in a
subset of halo stars that were initially rapid rotators, with the possible
exception of one star, G 139-8. Because the ultra-Li-deficient stars are also
Be-deficient, they appear to be genuine outliers in population of halo stars
used to determine the value of primordial Li; they no longer have the Li in
their atmospheres that was produced in the Big Bang.
","We report the detection of beryllium (Be) lines in two ultra-low metallicity halo stars, CS 22892-052 and HE 0107-5240.  These are the first detections of Be in metal-poor halo stars with [Fe/H] < -2.5 dex. We find that these stars have high surface gravities for their temperatures, indicating they may be blue stragglers or other evolved objects. In addition to the Be features at 4131 Å and 4130 Å we also see evidence for an unidentified feature near 3970 Å which is likely due to C+N+O. This work was supported by NASA grant NAG5-9998. Keywords: Beryllium; Blue straggler; Metal poor star; Ultracool dwarf. 1. Introduction.
The discovery of extremely low-mass stars has opened up new avenues into understanding how planets form around very cool dwarfs. However, there remains much uncertainty about the formation process itself as well as the chemical composition of such systems. One important aspect of this problem involves determining whether or not terrestrial planet formation can occur within the habitable zone of ultracool dwarfs. To address this question it will be necessary to determine if the atmospheres of these stars contain significant amounts of heavy elements like carbon, nitrogen, oxygen, sulfur, sodium, potassium, magnesium, aluminum, silicon, calcium, titanium, iron, nickel, cobalt, copper, zinc, arsenic, selenium, silver, gold, mercury, lead, uranium, thorium, and plutonium. It should be noted that while some of these metals are produced during stellar nucleosynthesis others are synthesized only through cosmic ray spallation reactions occurring outside of stars.",arxiv,bigscience bloomz,705.1551,0.5,0.596638655462185,0.6051282051282051,0.6531294792164358,1,1,1,0,0,1,1,1,0,0,0.118226298645286,0.1498173157164412,0.0933852140077821,0.17424242424242425,0,3,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A p-adic quasi-quadratic point counting algorithm,"  In this article we give an algorithm for the computation of the number of
rational points on the Jacobian variety of a generic ordinary hyperelliptic
curve defined over a finite field of cardinality $q$ with time complexity
$O(n^{2+o(1)})$ and space complexity $O(n^2)$, where $n=\log(q)$. In the latter
complexity estimate the genus and the characteristic are assumed as fixed. Our
algorithm forms a generalization of both, the AGM algorithm of J.-F. Mestre and
the canonical lifting method of T. Satoh. We canonically lift a certain
arithmetic invariant of the Jacobian of the hyperelliptic curve in terms of
theta constants. The theta null values are computed with respect to a
semi-canonical theta structure of level $2^\nu p$ where $\nu >0$ is an integer
and $p=\mathrm{char}(\F_q)>2$. The results of this paper suggest a global
positive answer to the question whether there exists a quasi-quadratic time
algorithm for the computation of the number of rational points on a generic
ordinary abelian variety defined over a finite field.
","We present an efficient algorithm for computing the number of points on curves over finite fields with odd characteristic, which is based on the use of quadratic reciprocity laws and the Hasse-Weil bound in the form of Weierstrass functions. The main idea behind our approach consists in reducing the problem to that of finding the number of solutions of certain systems of linear equations modulo primes of small norm. This allows us to obtain a very fast running time by using standard techniques such as modular reduction or lattice basis reduction algorithms. In particular we show how this method can be used to compute efficiently the number of rational points on hyperelliptic curves defined over prime fields. Finally, we give some numerical examples illustrating the efficiency of our algorithm compared to other known methods. Keywords: Computational algebraic geometry, Number theory, Finite field arithmetic, Prime numbers, Hyperelliptic curve cryptography, Quadratic reciprocity law",arxiv,bigscience bloomz,706.0234,0.2777777777777778,0.24369747899159663,0.20512820512820512,0.38652651696129964,1,1,0,0,0,0,1,1,0,0,0.17583822084082434,0.05894681468414926,0.21011673151750973,0.022727272727272728,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
A Global Approach to the Theory of Special Finsler Manifolds,"  The aim of the present paper is to provide a global presentation of the
theory of special Finsler manifolds. We introduce and investigate globally (or
intrinsically, free from local coordinates) many of the most important and most
commonly used special Finsler manifolds: locally Minkowskian, Berwald,
Landesberg, general Landesberg, $P$-reducible, $C$-reducible,
semi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent,
$C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of
the second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like,
$R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant
curvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global
definitions of these special Finsler manifolds are introduced. Various
relationships between the different types of the considered special Finsler
manifolds are found. Many local results, known in the literature, are proved
globally and several new results are obtained. As a by-product, interesting
identities and properties concerning the torsion tensor fields and the
curvature tensor fields are deduced. Although our investigation is entirely
global, we provide; for comparison reasons, an appendix presenting a local
counterpart of our global approach and the local definitions of the special
Finsler spaces considered.
","In this article, we present an approach for studying special Finsler manifolds by using global methods and techniques in Riemannian geometry. We introduce some new concepts such as geodesic convexity, strongly convexity, and strictly convexity on special Finsler manifolds. Then, we prove that every special Finsler manifold is locally geodesically convex at any point. Finally, we show that if a special Finsler manifold admits a strictly convex function then it has constant flag curvature. Keywords: Geodesic convexity, Finsler metric, Flag curvature. Mathematics Subject Classification (2010): 53C20, 53C25, 53A10. In this article, we study special Finsler manifolds with global methods and techniques in the theory of Riemannian geometry. First, we define geodesic convexity and strongly convexity on special Finslser manifolds. Then, under certain conditions, we prove that every Finsler manifold is locally  geodesically convex at each point. Next, we give necessary and sufficient conditions for a special Finsler manifold to have constant flag curvature.",arxiv,bigscience bloomz,704.0053,0.3333333333333333,0.4453781512605043,0.24102564102564103,0.3922599139990445,1,1,1,0,0,1,0,1,0,0,0.5632640758599304,0.030766453918339192,0.6809338521400778,0.026515151515151516,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
High Resolution X-Ray Imaging of the Center of IC342,"  We presented the result of a high resolution (FWHM~0.5'') 12 ks Chandra HRC-I
observation of the starburst galaxy IC342 taken on 2 April 2006. We identified
23 X-ray sources within the central 30' x 30' region of IC342. Our HRC-I
observation resolved the historical Ultraluminous X-ray sources (ULX), X3, near
the nucleus into 2 sources, namely C12 and C13, for the first time. The
brighter source C12, with L(0.08-10keV)=(6.66\pm0.45)\times10^{38}ergs^-1, was
spatially extended (~82 pc x 127 pc). From the astrometric registration of the
X-ray image, C12 was at R.A.=03h:46m:48.43s, decl.=+68d05m47.45s, and was
closer to the nucleus than C13. Thus we concluded that source was not an ULX
and must instead be associated with the nucleus. The fainter source C13, with
L(0.08-10keV)=(5.1\pm1.4) x 10^{37}ergs^-1 was consistent with a point source
and located $6.51'' at P.A. 240 degree of C12.
  We also analyzed astrometrically corrected optical Hubble Space Telescope and
radio Very Large Array images, a comparison with the X-ray image showed
similarities in their morphologies. Regions of star formation within the
central region of IC342 were clearly visible in HST H alpha image and this was
the region where 3 optical star clusters and correspondingly our detected X-ray
source C12 were observed. We found that a predicted X-ray emission from
starburst was very close to the observed X-ray luminosity of C12, suggesting
that nuclear X-ray emission in IC342 was dominated by starburst. Furthermore,
we discussed the possibility of AGN in the nucleus of IC342. Although our data
was not enough to give a firm existence of an AGN, it could not be discarded.
","We present high resolution X-ray imaging and spectroscopy of the central region of the galaxy cluster Abell S1063 (IC342). The data were obtained with Chandra ACIS-S3 in August 2002, for an exposure time of 50 ks. We detect two bright point sources at the center of the cluster which are associated to AGNs. Their luminosities range between 1043 erg/sec and 1044 erg/sec in the 0.5-10 keV energy band. In addition we find evidence that there is diffuse emission around these sources. This emission has a temperature of about 3 keV and its spectrum can be fitted by a thermal plasma model with solar abundance ratios. From our analysis it appears that this gas may have been heated up recently due to shocks produced during mergers or interactions among subclusters. Finally, we also detected extended soft emission surrounding both AGN candidates. Its origin could be either thermal bremsstrahlung radiation from hot gas or inverse Compton scattering off relativistic electrons.",arxiv,bigscience bloomz,706.077,0.6666666666666666,0.3949579831932773,0.7128205128205128,0.40659340659340665,1,1,1,0,1,1,1,0,0,0,0.0866943250295659,0.032321461975464025,0.11284046692607004,0.030303030303030304,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Landau (\Gamma,\chi)-automorphic functions on \mathbb{C}^n of magnitude \nu","  We investigate the spectral theory of the invariant Landau Hamiltonian
$\La^\nu$ acting on the space ${\mathcal{F}}^\nu_{\Gamma,\chi}$ of
$(\Gamma,\chi)$-automotphic functions on $\C^n$, for given real number $\nu>0$,
lattice $\Gamma$ of $\C^n$ and a map $\chi:\Gamma\to U(1)$ such that the
triplet $(\nu,\Gamma,\chi)$ satisfies a Riemann-Dirac quantization type
condition. More precisely, we show that the eigenspace $
{\mathcal{E}}^\nu_{\Gamma,\chi}(\lambda)=\set{f\in
{\mathcal{F}}^\nu_{\Gamma,\chi}; \La^\nu f = \nu(2\lambda+n) f}$;
$\lambda\in\C,$ is non trivial if and only if $\lambda=l=0,1,2, ...$. In such
case, ${\mathcal{E}}^\nu_{\Gamma,\chi}(l)$ is a finite dimensional vector space
whose the dimension is given explicitly. We show also that the eigenspace
${\mathcal{E}}^\nu_{\Gamma,\chi}(0)$ associated to the lowest Landau level of
$\La^\nu$ is isomorphic to the space, ${\mathcal{O}}^\nu_{\Gamma,\chi}(\C^n)$,
of holomorphic functions on $\C^n$ satisfying $$ g(z+\gamma) = \chi(\gamma)
e^{\frac \nu 2 |\gamma|^2+\nu\scal{z,\gamma}}g(z), \eqno{(*)} $$ that we can
realize also as the null space of the differential operator
$\sum\limits_{j=1}\limits^n(\frac{-\partial^2}{\partial z_j\partial \bar z_j} +
\nu \bar z_j \frac{\partial}{\partial \bar z_j})$ acting on $\mathcal C^\infty$
functions on $\C^n$ satisfying $(*)$.
","We introduce the notion of Landau (\Gamma, \chi)-automorphic functions of magnitude $\nu$ for any integer $\nu \geq 0$ and show that they are holomorphic sections of certain line bundles over the complex flag manifold $\mathbb{C}^{N} / \Lambda^{(\nu)}_{\mathbb{N}} = \mathrm{SL}_N(\mathbb{C})/\mathrm{Sp}_{2N - N_0}(\mathbb{C})$.  We also prove an analogue of the Riemann-Roch theorem in this setting which allows us to compute the dimension of these spaces explicitly as a function of $\nu$. Finally we give some examples of explicit bases for these spaces. This is joint work with Jens Franke. The results presented here were obtained while I was at the University of Hamburg under the supervision of Prof. Dr.-Ing. Henning Samtleben. In this article we study automorphic forms on the complex flag manifold $\mathrm{SL}_N(\mathbb{Z})/\mathrm{Sp}^{2N-N_0}(\mathbb{Z})$ where $N$ denotes the number of rows of the matrix representation of the group element. These automorphic forms can be viewed as holomorphic sections of certain vector bundles over the flag manifold whose fibers are given by homogeneous polynomials of degree $\nu$ in $n$ variables. For each such polynomial there exists a unique irreducible representation of the Lie algebra $\mathfrak{sl}_n$ into the space of endomorphisms of the corresponding fiber. Using this correspondence between representations and vector bundles one obtains a decomposition of the flag bundle into line bundles. Our main result shows how to construct holomorphic sections of these line bundles using theta series associated to the underlying lattice $\Lambda_{(\nu)}$.",arxiv,bigscience bloomz,705.1763,0.16666666666666666,0.49579831932773116,0.17435897435897435,0.6187290969899666,1,1,1,0,0,1,1,0,0,0,0.46051859698089365,0.2160152449616025,0.5058365758754864,0.22727272727272727,0,2,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA Networks with Delay Constraints,"  A game-theoretic framework is used to study the effect of constellation size
on the energy efficiency of wireless networks for M-QAM modulation. A
non-cooperative game is proposed in which each user seeks to choose its
transmit power (and possibly transmit symbol rate) as well as the constellation
size in order to maximize its own utility while satisfying its delay
quality-of-service (QoS) constraint. The utility function used here measures
the number of reliable bits transmitted per joule of energy consumed, and is
particularly suitable for energy-constrained networks. The best-response
strategies and Nash equilibrium solution for the proposed game are derived. It
is shown that in order to maximize its utility (in bits per joule), a user must
choose the lowest constellation size that can accommodate the user's delay
constraint. Using this framework, the tradeoffs among energy efficiency, delay,
throughput and constellation size are also studied and quantified. The effect
of trellis-coded modulation on energy efficiency is also discussed.
","We consider the problem of energy-efficient modulation for downlink transmissions over code-division multiple-access (CDMA) networks, where each user has an individual delay constraint and is equipped with a rechargeable battery that can be charged by harvesting ambient radio-frequency signals. We formulate this problem as a noncooperative game between users competing for limited power resources under their own constraints on transmission rates and delays. In particular, we show how to compute Nash equilibria of such games using convex optimization techniques. Our numerical results demonstrate significant gains in terms of both network throughput and energy efficiency compared to conventional schemes based on fixed-rate transmissions. The proposed approach also allows us to quantify tradeoffs among different performance metrics, including average packet delay, outage probability, and energy consumption per bit. This work was supported by NSF grants CNS-0932040 and CCF-0939370. 
 
 Code available at http://arxiv.org/abs/1206.5481",arxiv,bigscience bloomz,704.3878,0.3333333333333333,0.29411764705882354,0.17435897435897435,0.35499283325370284,1,1,0,0,1,1,1,1,0,0,0.1020620493947158,0.09600449556310359,0.08560311284046693,0.05303030303030303,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Variation of fundamental constants: theory and observations,"  Review of recent works devoted to the variation of the fundamental constants
is presented including atomic clocks, quasar absorption spectra, and Oklo
natural nuclear reactor data. Assuming linear variation with time we can
compare different results. From the quasar absorption spectra:
  $\dot{\mu}/\mu=(1 \pm 3) \times 10^{-16}$ yr$^{-1}$. A combination of this
result and the atomic clock results gives the best limt on variation of
$\alpha$: $\dot{\alpha}/\alpha=(-0.8 \pm 0.8) \times 10^{-16}$ yr$^{-1}$. The
Oklo natural reactor gives the best limit on the variation of
$m_s/\Lambda_{QCD}$ where $m_s$ is the strange quark mass.
  Huge enhancement of the relative variation effects happens in transitions
between close atomic, molecular and nuclear energy levels. We suggest several
new cases where the levels are very narrow. Large enhancement of the variation
effects is also possible in cold atomic and molecular collisions near Feshbach
resonance. Massive bodies (stars or galaxies) can also affect physical
constants. They have large scalar charge $S$ proportional to number of
particles which produces a Coulomb-like scalar field $U=S/r$. This leads to a
variation of the fundamental constants proportional to the gravitational
potential, e.g. $\delta \alpha/ \alpha = k_\alpha \delta (GM/ r c^2)$. We
compare different manifestations of this effect.The strongest limit
  $k_\alpha +0.17 k_e= (-3.5\pm 6) \times 10^{-7}$.
","The variation in the values of physical constants is one of the most important problems for modern physics, cosmology and astrophysics. The main goal of this work was to study the possible time variations of some fundamental constants (fine structure constant α, gravitational constant G, proton-to-electron mass ratio μ) using different theoretical approaches as well as observational data on distant objects.  In our previous works we have shown that the observed redshifts of quasars can be explained by varying fine-structure constant with cosmic time. We also found that the evolution of the universe may lead to the change of other fundamental constants such as gravitational constant or proton-to-electron mass ratio. Here we present new results obtained within the framework of these models. First, we show how the model based on varying fine-structure constant explains the recent measurements of quasar absorption lines at high redshift performed by Webb et al. (1999) . Second, we discuss the possibility of explaining the Hubble parameter H0 = 72 ± 8 km s-1 Mpc-1 measured recently by Freedman et al. (2001) using the same approach. Finally, we consider another class of models where all three fundamental constants vary simultaneously.",arxiv,bigscience bloomz,705.3704,0.6666666666666666,0.4453781512605043,0.4256410256410256,0.5097945532728142,1,1,1,0,0,1,1,0,0,0,0.09069210246798642,0.09589595608885243,0.07782101167315175,0.07954545454545454,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Entangling Independent Photons by Time Measurement,"  A quantum system composed of two or more subsystems can be in an entangled
state, i.e. a state in which the properties of the global system are well
defined but the properties of each subsystem are not. Entanglement is at the
heart of quantum physics, both for its conceptual foundations and for
applications in information processing and quantum communication. Remarkably,
entanglement can be ""swapped"": if one prepares two independent entangled pairs
A1-A2 and B1-B2, a joint measurement on A1 and B1 (called a ""Bell-State
Measurement"", BSM) has the effect of projecting A2 and B2 onto an entangled
state, although these two particles have never interacted or shared any common
past[1,2]. Experiments using twin photons produced by spontaneous parametric
down-conversion (SPDC) have already demonstrated entanglement swapping[3-6],
but here we present its first realization using continuous wave (CW) sources,
as originally proposed[2]. The challenge was to achieve sufficiently sharp
synchronization of the photons in the BSM. Using narrow-band filters, the
coherence time of the photons that undergo the BSM is significantly increased,
exceeding the temporal resolution of the detectors. Hence pulsed sources can be
replaced by CW sources, which do not require any synchronization[6,7], allowing
for the first time the use of completely autonomous sources. Our experiment
exploits recent progress in the time precision of photon detectors, in the
efficiency of photon pair production by SPDC with waveguides in nonlinear
crystals[8], and in the stability of narrow-band filters. This approach is
independent of the form of entanglement; we employed time-bin entangled
photons[9] at telecom wavelengths. Our setup is robust against thermal or
mechanical fluctuations in optical fibres thanks to cm-long coherence lengths.
","We propose an experiment to entangle two independent photons in the time domain, using only linear optical elements and single-photon detectors.  The scheme is based on measuring the arrival times of the photons at different locations with respect to each other. We show that this measurement can be used to generate entanglement between the photons without any post-selection or feed-forward operations. This method may find applications for quantum communication networks where it would allow one to distribute entangled states over large distances. Entanglement plays a central role in many areas of physics ranging from condensed matter systems [1] , atomic gases [2] , and trapped ions [3] to quantum information processing [4] . In particular, entanglement has been shown to be essential for quantum teleportation [5] , superdense coding [6] , quantum key distribution [7] , and quantum computing [8] .
In recent years there have been several proposals to create entanglement between distant particles [9] - [11] . However, most schemes require either nonlinear interactions [12] , which are difficult to implement experimentally [13] , or postselection [14] , which introduces additional noise into the system [15] . Recently, we proposed a new scheme [16] to produce entanglement between remote particles using only linear optics [17] and single photon detection [18] . Our approach relies on performing measurements on the arrival times of the particles at different locations [19] . Here we present detailed calculations showing how our proposal works as well as its experimental feasibility [20] .  Figure 1 shows a schematic diagram of our setup. Two identical sources emit pairs of photons (red) towards Alice's station A and Bob's station B respectively [21] . Each source consists of a pulsed laser [22] generating pairs of photons via spontaneous parametric down-conversion [23] . These photons travel through separate paths until they reach stations A and B [24] . At these stations, Alice and Bob perform measurements on their respective photons [25] . They measure the arrival times tA and tB [26] of...",arxiv,bigscience bloomz,704.0758,0.5555555555555556,0.7983193277310925,0.7538461538461538,0.9111323459149546,1,1,1,0,0,1,1,0,0,1,0.13756759809306857,0.06887563090759469,0.16342412451361868,0.04924242424242424,0,1,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Red Sequence Cluster Finding in the Millennium Simulation,"  We investigate halo mass selection properties of red-sequence cluster finders
using galaxy populations of the Millennium Simulation (MS). A clear red
sequence exists for MS galaxies in massive halos at redshifts z < 1, and we use
this knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h
projections of the simulated volume. At low redshift (z=0.4), we find that 90%
of the clusters found have galaxy membership dominated by a single, real-space
halo, and that 10% are blended systems for which no single halo contributes a
majority of a cluster's membership. At z=1, the fraction of blends increases to
22%, as weaker redshift evolution in observed color extends the comoving length
probed by a fixed range of color. Other factors contributing to the increased
blending at high-z include broadening of the red sequence and confusion from a
larger number of intermediate mass halos hosting bright red galaxies of
magnitude similar to those in higher mass halos. Our method produces catalogs
of cluster candidates whose halo mass selection function, p(M|\Ngal,z), is
characterized by a bimodal log-normal model with a dominant component that
reproduces well the real-space distribution, and a redshift-dependent tail that
is broader and displaced by a factor ~2 lower in mass. We discuss implications
for X-ray properties of optically selected clusters and offer ideas for
improving both mock catalogs and cluster-finding in future surveys.
","We present an algorithm for finding galaxy clusters using only photometric redshifts and no spectroscopic information, based on identifying overdensities of galaxies with similar colours. We apply this method to the Millennium simulation (Springel et al., 2005) and compare our results against those obtained by applying the same technique to mock catalogues constructed from semi-analytic models of galaxy formation within dark matter haloes. The comparison shows that we are able to recover most of the true cluster population at z < 1.5, but find significant contamination due to projection effects beyond this redshift. This is mainly caused by the fact that the colour-magnitude relation becomes less tight as one moves towards higher redshifts. Our analysis also reveals that there exists a large number of spurious detections which can be removed by imposing additional constraints such as requiring all candidate members to have magnitudes brighter than some threshold value or by restricting ourselves to systems whose total luminosity exceeds a certain limit.",arxiv,bigscience bloomz,706.0211,0.3333333333333333,0.19327731092436976,0.5282051282051282,0.41519350215002393,1,1,0,0,1,1,1,0,0,0,0.10975986453834007,0.08596123866826684,0.12062256809338522,0.09090909090909091,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Effective conservation of energy and momentum algorithm using switching potentials suitable for molecular dynamics simulation of thermodynamical systems,"  During a crossover via a switching mechanism from one 2-body potential to
another as might be applied in modeling (chemical) reactions in the vicinity of
bond formation, energy violations would occur due to finite step size which
determines the trajectory of the particles relative to the potential
interactions of the unbonded state by numerical (e.g. Verlet) integration. This
problem is overcome by an algorithm which preserves the coordinates of the
system for each move, but corrects for energy discrepancies by ensuring both
energy and momentum conservation in the dynamics. The algorithm is tested for a
hysteresis loop reaction model with an without the implementation of the
algorithm. The tests involve checking the rate of energy flow out of the MD
simulation box; in the equilibrium state, no net rate of flows within
experimental error should be observed. The temperature and pressure of the box
should also be invariant within the range of fluctuation of these quantities.
It is demonstrated that the algorithm satisfies these criteria.
","We present an effective method to conserve the total energy and linear momentum in molecular dynamics (MD) simulations by introducing two types of potentials: one is used during the MD run, while another is only used when calculating the forces on particles at each time step. The latter type of potentials are switched off after being calculated so that they do not affect the subsequent MD trajectories. We show how this scheme can be implemented into existing MD codes with minimal modifications. In addition, we demonstrate its effectiveness through several examples including liquid argon, water clusters, and carbon nanotubes. Our results indicate that our new scheme conserves both energy and momentum very well even though it does not require any additional computational cost compared to conventional schemes. This work was supported by the National Natural Science Foundation of China under Grants No. 10874145 and No. 10934011 . Keywords: Energy-momentum conservation; Switching potentials; Molecular dynamics",arxiv,bigscience bloomz,704.0556,0.3333333333333333,0.3949579831932773,0.2153846153846154,0.3951266125179169,1,1,1,0,0,1,1,1,0,0,0.16668558774154024,0.12027558176000963,0.2178988326848249,0.0946969696969697,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
On the Performance Evaluation of Encounter-based Worm Interactions Based on Node Characteristics,"  An encounter-based network is a frequently disconnected wireless ad-hoc
network requiring nearby neighbors to store and forward data utilizing mobility
and encounters over time. Using traditional approaches such as gateways or
firewalls for deterring worm propagation in encounter-based networks is
inappropriate. Because this type of network is highly dynamic and has no
specific boundary, a distributed counter-worm mechanism is needed. We propose
models for the worm interaction approach that relies upon automated beneficial
worm generation to alleviate problems of worm propagation in such networks. We
study and analyze the impact of key mobile node characteristics including node
cooperation, immunization, on-off behavior on the worm propagations and
interactions. We validate our proposed model using extensive simulations. We
also find that, in addition to immunization, cooperation can reduce the level
of worm infection. Furthermore, on-off behavior linearly impacts only timing
aspect but not the overall infection. Using realistic mobile network
measurements, we find that encounters are non-uniform, the trends are
consistent with the model but the magnitudes are drastically different.
Immunization seems to be the most effective in such scenarios. These findings
provide insight that we hope would aid to develop counter-worm protocols in
future encounter-based networks.
","In this work, we propose an encounter based worm interaction model to evaluate the performance of different node characteristics in terms of their ability to detect and prevent worms spreading over mobile ad hoc networks (MANETs). We consider two types of nodes with distinct capabilities for detecting and preventing worms: normal nodes that are vulnerable to infection by worms but can detect them using signature detection techniques; and immune nodes which have no vulnerability to worm infections but can prevent worm propagation through quarantine mechanisms. The proposed model is used to study how these two types of nodes interact when they meet each other during network operation. In particular, our results show that: 1) Immune nodes play a significant role in reducing the number of infected nodes as well as the total number of encounters between susceptible and infectious nodes; 2) Immune nodes should be deployed at strategic locations within MANETs; 3) Immune nodes should not only focus on quarantining infectious nodes but also on isolating suspicious nodes; 4) Immune nodes should use both signature detection and quarantine mechanisms simultaneously to achieve better performance against worm propagation; 5) Immune nodes should adopt dynamic quarantine strategies instead of static ones since static quarantine may lead to unnecessary isolation of legitimate nodes.",arxiv,bigscience bloomz,706.2025,0.5555555555555556,0.14285714285714285,0.36923076923076925,0.5556617295747731,0,1,0,0,0,1,0,1,0,0,0.05580515068399964,0.3064337193233113,0.06614785992217899,0.3333333333333333,1,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Resonating singlet valence plaquettes,"  We consider the simplest generalizations of the valence bond physics of SU(2)
singlets to SU(N) singlets that comprise objects with N sites -- these are
SU(N) singlet plaquettes with N=3 and N=4 in three spatial dimensions.
Specifically, we search for a quantum mechanical liquid of such objects -- a
resonating singlet valence plaquette phase that generalizes the celebrated
resonating valence bond phase for SU(2) spins. We extend the Rokhsar-Kivelson
construction of the quantum dimer model to the simplest SU(4) model for valence
plaquette dynamics on a cubic lattice. The phase diagram of the resulting
quantum plaquette model is analyzed both analytically and numerically. We find
that the ground state is solid everywhere, including at the Rokhsar-Kivelson
point where the ground state is an equal amplitude sum. By contrast, the equal
amplitude sum of SU(3) singlet triangular plaquettes on the face centered cubic
lattice is liquid and thus a candidate for describing a resonating single
valence plaquette phase, given a suitably defined local Hamiltonian.
","We study the ground state properties and excitations in the spin-1/2 Heisenberg antiferromagnet on the square lattice with nearest-neighbor interactions only, using exact diagonalization (ED) for small clusters up to 12 sites as well as density-matrix renormalization group (DMRG) calculations for larger systems. We find that the ground-state energy per site is lower than the classical value by about 0.25J, where J denotes the exchange coupling constant between neighboring spins. The magnetic susceptibility shows Curie-Weiss behavior at high temperatures but decreases rapidly below T = 2J/3. This indicates strong quantum fluctuations which are also reflected in the low-temperature dependence of the specific heat. In addition we observe an unusual peak structure in the spin-spin correlation function S(q). For q along the principal axes of the Brillouin zone this peak has its maximum at q = π while it shifts towards smaller values when approaching the diagonals.",arxiv,bigscience bloomz,705.0846,0.2777777777777778,0.24369747899159663,0.20512820512820512,0.37219302436693746,1,1,0,0,0,1,1,0,0,0,0.10038695146907024,0.0961436681141972,0.07003891050583658,0.06060606060606061,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Nonlinear Evolution of Baryon Acoustic Oscillations,"  We study the nonlinear evolution of the baryon acoustic oscillations (BAO) in
the dark matter power spectrum and correlation function using renormalized
perturbation theory (RPT). In a previous paper we showed that RPT successfully
predicts the damping of acoustic oscillations; here we extend our calculation
to the enhancement of power due to mode-coupling. We show that mode-coupling
generates additional oscillations that are out of phase with those in the
linear spectrum, leading to shifts in the scales of oscillation nodes defined
with respect to a smooth spectrum. When Fourier transformed, these out of phase
oscillations induce percent-level shifts in the acoustic peak of the two-point
correlation function. We present predictions for these shifts as a function of
redshift; these should be considered as a robust lower limit to the more
realistic case that includes in addition redshift distortions and galaxy bias.
We show that these nonlinear effects occur at very large scales, leading to a
breakdown of linear theory at scales much larger than commonly thought. We
discuss why virialized halo profiles are not responsible for these effects,
which can be understood from basic physics of gravitational instability. Our
results are in excellent agreement with numerical simulations, and can be used
as a starting point for modeling BAO in future observations. To meet this end,
we suggest a simple physically motivated model to correct for the shifts caused
by mode-coupling.
","We study the nonlinear evolution of baryonic acoustic oscillations (BAO) in an expanding universe using numerical simulations with N-body particles and hydrodynamic gas dynamics. We find that BAOs are suppressed by nonlinear gravitational clustering, but they can be recovered by applying a Wiener filter to the density field at each redshift. The reconstructed power spectrum agrees well with linear theory predictions on large scales where the effect is negligible. On small scales, however, we observe significant deviations between the two spectra due to nonlinear effects such as shell crossing and virialization. These results suggest that it may be possible to use BAOs as standard rulers for cosmological distance measurements even when the underlying matter distribution becomes highly nonlinear. In this work, we present our main findings below. 
1 Introduction

Baryons play important roles in galaxy formation through their interactions with dark matter. For example, observations show that galaxies form around peaks of the primordial density fluctuations which grow into massive halos via gravitational instability. Therefore, understanding how baryons evolve in time and space is crucial for studying galaxy formation processes.

In recent years, there has been growing interest in measuring the large-scale structure of the Universe using baryonic tracers like neutral hydrogen or stars. One promising method involves tracing the spatial distribution of these objects back in time using spectroscopic surveys. This technique allows us to measure the statistical properties of the cosmic web, including its geometry and topology, over a wide range of redshifts. 

The most prominent feature observed in the measured correlation functions of various types of baryonic tracers is known as ""baryonic acoustic oscillation"" (BAO). It refers to periodic wiggles seen in the power spectrum of the tracer population caused by sound waves propagating through the early universe before decoupling [see e.g., 1] . Since the amplitude of the BAO signal depends only weakly on the physical state of the medium, it provides a robust way to probe the expansion history of the universe independent of other cosmological parameters [2] .
Recently, several groups have reported detections of the BAO signature in the correlation function of Lyman",arxiv,bigscience bloomz,704.2783,0.4444444444444444,0.15546218487394958,0.5487179487179488,0.20449116101290013,1,1,1,0,0,2,2,0,0,0,0.05048327428874142,0.05341556610593253,0.054474708171206226,0.07196969696969698,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,2,1,2,1,1
The multiple viewpoints as approach to information retrieval within collaborative development context,"  Nowadays, to achieve competitive advantage, the industrial companies are
considering that success is sustained to great product development. That is to
manage the product throughout its entire lifecycle. Achieving this goal
requires a tight collaboration between actors from a wide variety of domains,
using different software tools producing various product data types and
formats. The actors' collaboration is mainly based on the exchange /share
product information. The representation of the actors' viewpoints is the
underlying requirement of the collaborative product development. The multiple
viewpoints approach was designed to provide an organizational framework
following the actors' perspectives in the collaboration, and their
relationships. The approach acknowledges the inevitability of multiple
integration of product information as different views, promotes gathering of
actors' interest, and encourages retrieved adequate information while providing
support for integration through PLM and/or SCM collaboration. In this paper, a
multiple viewpoints representation is proposed. The product, process,
organization information models are discussed. A series of issues referring to
the viewpoints representation are discussed in detail. Based on XML standard,
taking electrical connector as an example, an application case of part of
product information modeling is stated.
","The main goal of this research is the study and analysis of how different users can contribute in an open source software project, by sharing their knowledge through comments on issues or pull requests (PRs). The authors propose a new method for analyzing user participation based on the number of views that each comment receives during its life cycle. This work also presents a novel technique for identifying relevant comments using text mining techniques applied over the textual content of PRs. Finally, it proposes a ranking algorithm which takes into account both the relevance score assigned to each comment and the number of times they have been viewed. In order to evaluate these proposals, we conducted experiments with data collected from GitHub repositories related to two well-known open-source projects. We found out that our proposed methods are able to identify relevant comments more accurately than other state-of-the-art approaches. Moreover, we observed that the proposed ranking algorithm improves the results obtained when only considering the relevance scores.",arxiv,bigscience bloomz,706.1162,0.5555555555555556,0.29411764705882354,0.3282051282051282,0.4295269947443861,0,0,0,0,1,1,1,0,0,0,0.07908561839534858,0.05087539689743856,0.10505836575875487,0.03787878787878788,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1
"A Search for Planets Transiting the M Dwarf Debris Disk Host, AU Microscopii","  We present high cadence, high precision multi-band photometry of the young,
M1Ve, debris disk star, AU Microscopii. The data were obtained in three
continuum filters spanning a wavelength range from 4500\AA to 6600\AA, plus
H$\alpha$, over 28 nights in 2005. The lightcurves show intrinsic stellar
variability due to starspots with an amplitude in the blue band of 0.051
magnitudes and a period of 4.847 days. In addition, three large flares were
detected in the data which all occur near the minimum brightness of the star.
We remove the intrinsic stellar variability and combine the lightcurves of all
the filters in order to search for transits by possible planetary companions
orbiting in the plane of the nearly edge-on debris disk. The combined final
lightcurve has a sampling of 0.35 minutes and a standard deviation of 6.8
millimags (mmag). We performed Monte Carlo simulations by adding fake transits
to the observed lightcurve and find with 95% significance that there are no
Jupiter mass planets orbiting in the plane of the debris disk on circular
orbits with periods, P $\le 5$ days. In addition, there are no young
Neptune-like planets (with radii 2.5$\times$ smaller than the young Jupiter) on
circular orbits with periods, P $\le 3$ days.
","We report on our search for planets transiting the debris disk host star AU Mic (M3V). We observed two transit events with Spitzer Space Telescope's IRAC camera at 3.6 and 4.5 microns in 2009-2010 using the same technique as described by Charbonneau et al. (2005) . The first event was detected only in one bandpass while the second event showed no evidence of a transit signal above the noise level. Using these data we place upper limits on the radius R p /R s < 0.11 and mass m sin i < 1.1 MJup for any planet orbiting AU Mic within an orbital period P = 2 days. These results are consistent with previous studies that have found few or none giant planets around low-mass stars like AU Mic. 
 
 Keywords: Planetary systems - Formation, evolution, structure; Exoplanet detection techniques - Transit photometry",arxiv,bigscience bloomz,704.3584,0.3888888888888889,0.29411764705882354,0.4153846153846154,0.3607262302914477,1,1,0,0,0,1,1,1,0,1,0.08092159302135445,0.08623313674221507,0.10116731517509728,0.08333333333333333,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Mapping the Cosmological Confidence Ball Surface,"  We present a new technique to compute simultaneously valid confidence
intervals for a set of model parameters. We apply our method to the Wilkinson
Microwave Anisotropy Probe's (WMAP) Cosmic Microwave Background (CMB) data,
exploring a seven dimensional space (tau, Omega_DE, Omega_M, omega_DM, omega_B,
f_nu, n_s). We find two distinct regions-of-interest: the standard Concordance
Model, and a region with large values of omega_DM, omega_B and H_0. This second
peak in parameter space can be rejected by applying a constraint (or a prior)
on the allowable values of the Hubble constant. Our new technique uses a
non-parametric fit to the data, along with a frequentist approach and a smart
search algorithm to map out a statistical confidence surface. The result is a
confidence ``ball'': a set of parameter values that contains the true value
with probability at least 1-alpha. Our algorithm performs a role similar to the
often used Markov Chain Monte Carlo (MCMC), which samples from the posterior
probability function in order to provide Bayesian credible intervals on the
parameters. While the MCMC approach samples densely around a peak in the
posterior, our new technique allows cosmologists to perform efficient analyses
around any regions of interest: e.g., the peak itself, or, possibly more
importantly, the 1-alpha confidence surface.
","We present an algorithm for mapping the cosmological confidence ball surface, which is defined as the set of all points in parameter space that are consistent with current observations at some specified level of statistical significance.  The algorithm uses Monte Carlo Markov Chains to generate samples from the posterior probability distribution function (PDF) and then calculates the likelihoods of these samples using a modified version of CosmoMC.   We apply this method to two different data sets - WMAP7+BAO+H0 and Planck+WP+highL+BAO+H0+JLA - and find that our results agree well with those obtained by other authors who have used similar techniques.  In addition we show how one can use this technique to calculate the volume enclosed within the cosmological confidence ball. This work was performed under the auspices of the U.S Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344.",arxiv,bigscience bloomz,704.2605,0.3888888888888889,0.19327731092436976,0.4307692307692308,0.35499283325370284,1,1,1,0,1,1,1,0,0,0,0.08613525636062391,0.056644691335827176,0.09727626459143969,0.030303030303030304,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Strings on AdS_2 and the High-Energy Limit of Noncritical M-Theory,"  Noncritical M-theory in 2+1 dimensions has been defined as a double-scaling
limit of a nonrelativistic Fermi liquid on a flat two-dimensional plane. Here
we study this noncritical M-theory in the limit of high energies, analogous to
the \alpha'\to\infty limit of string theory. In the related case of
two-dimensional Type 0A strings, it has been argued that the conformal
\alpha'\to\infty limit leads to AdS_2 with a propagating fermion whose mass is
set by the value of the RR flux. Here we provide evidence that in the
high-energy limit, the natural ground state of noncritical M-theory similarly
describes the AdS_2\times S^1 spacetime, with a massless propagating fermion.
We argue that the spacetime effective theory in this background is captured by
a topological higher-spin extension of conformal Chern-Simons gravity in 2+1
dimensions, consistently coupled to a massless Dirac field. Intriguingly, the
two-dimensional plane populated by the original nonrelativistic fermions is
essentially the twistor space associated with the symmetry group of the
AdS_2\times S^1 spacetime; thus, at least in the high-energy limit, noncritical
M-theory can be nonperturbatively described as a ""Fermi liquid on twistor
space.""
","We study string theory in anti-de Sitter space-time (AdS) with two dimensions, which is dual to noncritical M-theory at high energies. We show that this duality can be understood as an equivalence between certain two-dimensional conformal field theories (CFTs). The CFT corresponding to strings on AdS_2 has central charge c = 3l/2G, where l is the radius of curvature of AdS_2 and G is Newton's constant. This CFT contains a free boson X_0 and a fermion $\psi$; we find that the partition function $Z(\beta)$ for these fields satisfies the following functional equation: 
$$Z(\beta) = Z(1/\beta) \exp\left[-\frac{\beta^2}{2}\ln\left(1-e^{-2\pi i/3}\right)\right].$$ Here $1/\beta$ plays the role of the coupling constant $\lambda$ in the worldsheet action. In particular, when $1/\beta \to 0$, the partition function becomes $Z(0) = 1$, while it vanishes exponentially fast if $1/\beta \to \infty$.",arxiv,bigscience bloomz,704.223,0.2777777777777778,0.19327731092436976,0.29743589743589743,0.3349259436215958,0,1,1,0,1,1,1,1,0,1,0.09766359981143037,0.21517130155619224,0.07392996108949416,0.20454545454545456,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A possible explanation why the Theta+ is seen in some experiments and not in others,"  To understand the whole set of positive and null data on the
Theta+(1530)-production, we suggest the hypothesis that multiquark hadrons are
mainly generated from many-quark states, which emerge either as short-term
hadron fluctuations, or as hadron remnants in hard processes. This approach
allows us to describe both non-observation of the Theta+ in current null
experiments and peculiar features of its production in positive experiments.
Further, we are able to propose new experiments that might be decisive for the
problem of the Theta+ existence. Distributions of the Theta+ in such
experiments can give important information both on higher Fock components of
conventional hadrons and about structure and hadronization properties of hadron
remnants produced in hard processes. We also explain that description of
multiquark hadrons may require a modified form of the constituent quark model,
with quark masses and couplings being intermediate between their values for the
familiar constituent quarks and the current ones.
","The theta + (θ+) effect has been observed by many authors, but it was never explained satisfactorily.  In this work we propose an explanation for its origin based on the fact that θ+ appears only when there are two or more particles with opposite spin states present at the same time. We show how to calculate the probability amplitude of finding such pairs using Feynman diagrams. The results obtained agree well with those reported experimentally. This article is available from: http://arxiv.org/abs/1401.5189. The theta + (θ+ ) effect [1] , which consists of a small increase in the intensity of the scattered beam as compared to the unscattered one, has been observed by several authors [2] - [4] . However, no satisfactory explanation has yet been given for its origin [5] .
In this work we propose an interpretation for the appearance of θ+ based on the fact that it occurs only if there are simultaneously two or more particles with different spins [6] . To demonstrate our hypothesis, we use Feynman's diagrammatic method [7] to calculate the probability amplitudes corresponding to these processes [8] .",arxiv,bigscience bloomz,704.3045,0.2222222222222222,0.3949579831932773,0.14871794871794872,0.4839942666029623,1,1,0,0,0,1,1,1,0,1,0.09333118854568087,0.09973067405470433,0.08949416342412451,0.11742424242424243,0,2,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Nova Geminorum 1912 and the Origin of the Idea of Gravitational Lensing,"  Einstein's early calculations of gravitational lensing, contained in a
scratch notebook and dated to the spring of 1912, are reexamined. A hitherto
unknown letter by Einstein suggests that he entertained the idea of explaining
the phenomenon of new stars by gravitational lensing in the fall of 1915 much
more seriously than was previously assumed. A reexamination of the relevant
calculations by Einstein shows that, indeed, at least some of them most likely
date from early October 1915. But in support of earlier historical
interpretation of Einstein's notes, it is argued that the appearance of Nova
Geminorum 1912 (DN Gem) in March 1912 may, in fact, provide a relevant context
and motivation for Einstein's lensing calculations on the occasion of his first
meeting with Erwin Freundlich during a visit in Berlin in April 1912. We also
comment on the significance of Einstein's consideration of gravitational
lensing in the fall of 1915 for the reconstruction of Einstein's final steps in
his path towards general relativity.
","The gravitational lensing effect was first predicted by Einstein in 1915, but it took another 50 years before the first confirmed observation could be made.  In this talk I will describe how one particular event - Nova Geminorum 1912 - played an important role in motivating Einstein to develop his theory of general relativity.   The talk is based on my recent book ""The First Lensing Event"" (Cambridge University Press). 

Gravitational lensing occurs when light passes close to a massive object such as a galaxy or cluster of galaxies.  This causes the light rays to bend towards each other so that distant objects appear magnified and distorted.  

In 1919, Einstein published his famous field equations which described gravity as curvature in space-time caused by matter/energy.  These equations were able to explain many phenomena including the perihelion precession of Mercury's orbit around the Sun. 

However, there remained some puzzles about these equations.  For example, they did not predict any bending of light passing near the Sun.

Einstein realised he needed to modify his original field equations if he wanted them to account for gravitational lensing effects.  He introduced what we now call the cosmological constant into his new set of equations.  However, despite considerable effort over several decades, no-one has been able to measure the value of this constant with sufficient accuracy to test whether Einstein's prediction is correct.  

This talk describes how astronomers finally managed to observe gravitational lensing in 1979 using observations of a distant quasar known as Q0957+561A-B.  It also explains why the discovery of gravitational lenses led to the awarding of the Nobel Prize in Physics to Roger Blandford and Roman Vishniac in 1997.",arxiv,bigscience bloomz,704.0963,0.2222222222222222,0.05882352941176469,0.20512820512820512,0.08552317247969422,1,0,0,0,1,1,4,0,0,2,0.13882390258474067,0.02071851374069911,0.14785992217898833,0.045454545454545456,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,3,1,3,1,1
Intricate Knots in Proteins: Function and Evolution,"  A number of recently discovered protein structures incorporate a rather
unexpected structural feature: a knot in the polypeptide backbone. These knots
are extremely rare, but their occurrence is likely connected to protein
function in as yet unexplored fashion. Our analysis of the complete Protein
Data Bank reveals several new knots which, along with previously discovered
ones, can shed light on such connections. In particular, we identify the most
complex knot discovered to date in human ubiquitin hydrolase, and suggest that
its entangled topology protects it against unfolding and degradation by the
proteasome. Knots in proteins are typically preserved across species and
sometimes even across kingdoms. However, we also identify a knot which only
appears in some transcarbamylases while being absent in homologous proteins of
similar structure. The emergence of the knot is accompanied by a shift in the
enzymatic function of the protein. We suggest that the simple insertion of a
short DNA fragment into the gene may suffice to turn an unknotted into a
knotted structure in this protein.
","The authors present an overview of the role that knots play in proteins, with particular emphasis on their function and evolution.  They discuss how protein knots are formed by covalent bonds between amino acids (the building blocks of proteins) as well as non-covalent interactions such as hydrogen bonding.  The authors also describe how different types of knots can be classified based upon their topology.   Finally they explain why it is important to study knots in proteins since these structures may have evolved for specific functions or because they provide stability against proteolysis (breakdown into smaller peptides).    This article was originally published on BioMed Central. It has been re-posted here under Creative Commons License 3.0. Protein knots are intriguing structural motifs found within many naturally occurring polypeptides. These knotted conformations result from noncovalent interactions among residues along the backbone chain combined with covalent cross-linkages at certain positions. In this review we summarize our current understanding about the formation mechanisms of various knot topologies observed in nature. We then highlight recent advances made toward characterizing the functional roles played by protein knots.",arxiv,bigscience bloomz,704.0191,0.3888888888888889,0.4453781512605043,0.24102564102564103,0.4696607740086001,0,0,1,0,0,1,1,0,0,0,0.05440472545453558,0.06533117598171556,0.07392996108949416,0.08333333333333333,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
The Wide Field Spectrograph (WiFeS),"  This paper describes the Wide Field Spectrograph (WiFeS) under construction
at the Research School of Astronomy and Astrophysics (RSAA) of the Australian
National University (ANU) for the ANU 2.3m telescope at the Siding Spring
Observatory. WiFeS is a powerful integral field, double-beam, concentric,
image-slicing spectrograph designed to deliver excellent thoughput, wavelength
stability, spectrophotometric performance and superb image quality along with
wide spectral coverage throughout the 320-950 nm wavelength region. It provides
a 25x38 arcsec. field with 0.5 arcsec. sampling along each of twenty five 38X1
arcsec slitlets. The output format is optimized to match the 4096x4096 pixel
CCD detectors in each of two cameras individually optimized for the blue and
the red ends of the spectrum, respectively. A process of ""interleaved
nod-and-shuffle"" will be applied to permit quantum noise-limited sky
subtraction. Using VPH gratings, spectral resolutions of 3000 and 7000 are
provided. The full spectral range is covered in a single exposure at R=3000,
and in two exposures in the R=7000 mode. The use of transmissive coated optics,
VPH gratings and optimized mirror coatings ensures a throughput (including
telescope atmosphere and detector) > 30% over a wide spectral range. The
concentric image-slicer design ensures an excellent and uniform image quality
across the full field. To maximize scientific return, the whole instrument is
configured for remote observing, pipeline data reduction, and the accumulation
of calibration image libraries.
","The WiFeS instrument is an integral field spectrograph for the Australian National University 2.3m telescope at Siding Spring Observatory, Australia.  It has been in operation since 2005 and was designed to provide high quality optical spectroscopy over a wide range of wavelengths with minimal overheads.   The WiFeS instrument consists of two cameras that are mounted on a common baseplate which sits inside a vacuum chamber attached to the Cassegrain focus of the ANU 2.3m telescope.    Each camera contains a lenslet array that produces a set of images across its focal plane.  These images can be combined into a single data cube using software developed by Dopita et al. (2007).    This data cube provides information about both spatial position and wavelength along each line-of-sight through the object being observed.  In addition to this capability, WiFeS also offers several other advantages including:  - High throughput due to the use of dichroic beam splitters and fibre optic coupling between the lenses and detectors.  - Flexible observing modes ranging from fully automated observations to manual control via remote desktop interface.  - Fast readout times allowing multiple targets to be observed simultaneously or rapid cycling between different targets during a night's observation run.  - Low maintenance requirements as it does not require any moving parts within the vacuum enclosure.  - Excellent stability thanks to the design of the optics bench and the thermal isolation provided by the vacuum enclosure.  - Large format detector arrays providing excellent signal-to-noise ratio even under poor seeing conditions.  - Robust mechanical design ensuring long-term reliability...",arxiv,bigscience bloomz,705.0287,0.6111111111111112,0.6470588235294118,0.5282051282051282,0.6846631629240325,1,1,0,0,0,1,1,1,0,1,0.11706974588057142,0.06554843351670653,0.13229571984435798,0.05303030303030303,3,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Formation and Collapse of Quiescent Cloud Cores Induced by Dynamic Compressions,"  (Abridged) We present numerical hydrodynamical simulations of the formation,
evolution and gravitational collapse of isothermal molecular cloud cores. A
compressive wave is set up in a constant sub-Jeans density distribution of
radius r = 1 pc. As the wave travels through the simulation grid, a
shock-bounded spherical shell is formed. The inner shock of this shell reaches
and bounces off the center, leaving behind a central core with an initially
almost uniform density distribution, surrounded by an envelope consisting of
the material in the shock-bounded shell, with a power-law density profile that
at late times approaches a logarithmic slope of -2 even in non-collapsing
cases. The resulting density structure resembles a quiescent core of radius <
0.1 pc, with a Bonnor-Ebert-like (BE-like) profile, although it has significant
dynamical differences: it is initially non-self-gravitating and confined by the
ram pressure of the infalling material, and consequently, growing continuously
in mass and size. With the appropriate parameters, the core mass eventually
reaches an effective Jeans mass, at which time the core begins to collapse.
Thus, there is necessarily a time delay between the appearance of the core and
the onset of its collapse, but this is not due to the dissipation of its
internal turbulence as it is often believed. These results suggest that
pre-stellar cores may approximate Bonnor-Ebert structures which are however of
variable mass and may or may not experience gravitational collapse, in
qualitative agreement with the large observed frequency of cores with BE-like
profiles.
","We present numerical simulations to study the formation, evolution, and collapse of quiescent cloud cores induced by dynamic compressions in turbulent molecular clouds. We find that these cloud cores are formed through shock compression at intersections between shocks driven into the clouds by supersonic turbulence. The cloud core masses range from 0.1 M⊙ to 1 M⊙ with typical sizes of about 1000 AU. These cloud cores have low internal velocities (< 2 km s-1) but can be accelerated up to 10 km s-1 during their lifetimes due to gravitational interactions with other dense clumps within the same clouds. Most of them evolve quasi-statically for several free-fall times before collapsing dynamically on time scales ranging from one to ten free-fall times. Our results suggest that such cloud cores may represent an important source of prestellar objects in star-forming regions. Keywords: Turbulence, Star Formation",arxiv,bigscience bloomz,705.0559,0.3888888888888889,0.29411764705882354,0.6256410256410256,0.3607262302914477,1,1,1,0,0,1,1,1,0,0,0.14728599045373833,0.07469723725379666,0.16731517509727625,0.056818181818181816,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Multi-wavelength analysis of 18um-selected galaxies in the AKARI/IRC monitor field towards the North Ecliptic Pole,"  We present an initial analysis of AKARI 18um-selected galaxies using all 9
photometric bands at 2-24um available in the InfraRed Camera (IRC), in order to
demonstrate new capabilities of AKARI cosmological surveys. We detected 72
sources at 18um in an area of 50.2 arcmin^2 in the AKARI/IRC monitor field
towards the North Ecliptic Pole (NEP). From this sample, 25 galaxies with
probable redshifts z>~ 0.5 are selected with a single colour cut (N2-N3>0.1)
for a detailed SED analysis with ground-based BVRi'z'JK data. Using an SED
radiative transfer model of starbursts covering the wavelength range UV --
submm, we derive photometric redshifts from the optical-MIR SEDs of
18um-selected galaxies. From the best-fit SED models, we show that the IRC
all-band photometry is capable of tracing the steep rise in flux at the blue
side of the PAH 6.2um emission feature. This indicates that the IRC all-band
photometry is useful to constrain the redshift of infrared galaxies,
specifically for dusty galaxies with a less prominent 4000A break. Also, we
find that the flux dip between the PAH 7.7 and 11.2um emission feature is
recognizable in the observed SEDs of galaxies at z~1. By using such a colour
anomaly due to the PAH and silicate absorption features, unique samples of
ULIRGs at z~1, `silicate-break' galaxies, can be constructed from large
cosmological surveys of AKARI towards the NEP, i.e. the NEP-Deep and NEP-Wide
survey. This pilot study suggests the possibility of detecting many interesting
galaxy properties in the NEP-Deep and Wide surveys, such as a systematic
difference in SEDs between high- and low-z ULIRGs, and a large variation of the
PAH inter-band strength ratio in galaxies at high redshifts. [abridged]
","We have carried out multi-wavelength observations for a sample of infrared (IR) selected galaxies with AKARI and other telescopes to investigate their physical properties, such as dust temperature T d , luminosity L IR , star formation rate SFR, stellar mass M * . The main results are summarized below.  We found that most of our targets show red colors at optical wavelengths indicating old ages and/or low metallicities. In addition, we detected strong polycyclic aromatic hydrocarbon emission features at 6.2, 7.7, 8.6, 11.3 um which indicate active star-formation activities. By fitting the observed spectral energy distributions (SEDs), we derived the following parameters;  - Dust temperatures range between 30 K and 60 K. - Luminosities range between 10^10 and 10^12 Lsun. - Star formation rates range between 0.1 and 100 Msun yr-1. - Stellar masses range between 10^9 and 10^11 Msun.",arxiv,bigscience bloomz,705.1365,0.5555555555555556,0.29411764705882354,0.7846153846153846,0.35785953177257523,1,1,0,0,1,1,1,1,0,0,0.12589898742067349,0.12010676729001055,0.17509727626459143,0.14015151515151514,2,2,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On the nature of the short duration GRB 050906,"  We present deep optical and infrared observations of the short duration GRB
050906. Although no X-ray or optical/IR afterglow was discovered to deep
limits, the error circle of the GRB (as derived from the Swift BAT) is unusual
incontaining the relatively local starburst galaxy IC328. This makes GRB 050906
a candidate burst from a soft-gamma repeater, similar to the giant flare from
SGR 1806-20. The probability of chance alignment of a given BAT position with
such a galaxy is small (<1%), although the size of the error circle (2.6
arcminute radius) is such that a higher-z origin can't be ruled out. Indeed,
the error circle also includes a moderately rich galaxy cluster at z=0.43,
which is a plausible location for the burst given the apparent preference that
short GRBs have for regions of high mass density. No residual optical or
infrared emission has been observed, either in the form of an afterglow or
later time emission from any associated supernova-like event. We discuss the
constraints these limits place on the progenitor of GRB 050906 based on the
expected optical signatures from both SGRs and merging compact object systems.
","We report on optical and near-infrared observations made with the Hubble Space Telescope (HST) in response to an alert issued by Swift/BAT for GRB050906, which was detected at 07:47:06 UT on September 6, 2005. The prompt emission lasted about 1 s and had a peak flux density of ~1 Crab. We find that this burst is similar to other short-duration gamma-ray bursts observed previously; it has no detectable afterglow down to limits of R > 26 mag at t = 0.5 hr and JHK > 23 mag at t = 2 days. However, we do detect a bright source coincident with the position of the X-ray afterglow reported by Swift/XRT. This object shows significant variability over timescales ranging from minutes to hours. It also exhibits strong H-alpha absorption lines characteristic of young stellar objects. These properties are consistent with those expected if the source were a massive star forming region within our Galaxy.",arxiv,bigscience bloomz,705.1705,0.3333333333333333,0.29411764705882354,0.3333333333333333,0.3922599139990445,1,1,0,0,1,1,1,1,0,0,0.09679910183486169,0.09961259519793159,0.09727626459143969,0.08712121212121213,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Growth window and possible mechanism of millimeter-thick single-walled carbon nanotube forests,"  Our group recently reproduced the water-assisted growth method, so-called
""super growth"", of millimeter-thick single-walled carbon nanotube (SWNT)
forests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this
current work, a parametric study was carried out on both reaction and catalyst
conditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm)
yielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3
support enhanced the activity of Fe, Co, and Ni catalysts. The growth window
for the rapid SWNT growth was narrow, however. Optimum amount of added H2O
increased the SWNT growth rate but further addition of H2O degraded both the
SWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT
growth, but again, further addition decreased both the SWNT growth rate and
quality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly
enhances the SWNT growth rate by supplying the carbon source to the catalyst
nanoparticles. The origin of the narrow window for rapid SWNT growth will also
be discussed.
","We report the growth of millimeter-thick vertically aligned single-walled carbon-nanotube forests on SiO 2 /Si substrates by chemical vapor deposition using Fe nanoparticles as catalysts at temperatures between 700 °C and 850 °C in Ar/H 2 . The diameter distribution is centered around 1 nm, with an average tube length of about 10 μm. We find that the density of the grown forests increases linearly with time up to a maximum value of 3 × 10 11 cm -2 , which corresponds to a volume filling factor of 0.7 for the tubes. This high density can be explained by considering the balance between the nucleation rate and the growth rate of individual tubes. In addition, we show that the vertical alignment of the tubes is maintained over large areas (1 cm   2 ) without any noticeable defects or cracks. These results suggest that these thick forests are promising candidates for applications such as field emitters and transparent electrodes. 
 
 Carbon nanotubes have attracted considerable attention because they exhibit unique physical properties [1]. However, it has been difficult to grow high-quality carbon nanotubes due to their extremely small diameters [2]. Recently, several groups reported the growth of vertically aligned carbon nanotube arrays [3]–[6]. Although these studies demonstrated the potential use of carbon nanotubes in various fields [7, 8], most of them were limited to thin films less than 100 nm thick [9]. To fully exploit the advantages offered by carbon nanotubes, it is necessary to develop techniques capable of producing thicker films [10].",arxiv,bigscience bloomz,704.1903,0.3888888888888889,0.49579831932773116,0.2512820512820513,0.6731963688485428,1,1,0,0,0,1,1,0,0,0,0.08768029420055598,0.06436346429517104,0.10505836575875487,0.06060606060606061,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Quantum Electrodynamics of qubits,"  Systematic description of a spin one-half system endowed with magnetic moment
or any other two-level system (qubit) interacting with the quantized
electromagnetic field is developed. This description exploits a close analogy
between a two-level system and the Dirac electron that comes to light when the
two-level system is described within the formalism of second quantization in
terms of fermionic creation and annihilation operators. The analogy enables one
to introduce all the powerful tools of relativistic QED (albeit in a greatly
simplified form). The Feynman diagrams and the propagators turn out to be very
useful. In particular, the QED concept of the vacuum polarization finds its
close counterpart in the photon scattering off a two level-system leading via
the linear response theory to the general formulas for the atomic
polarizability and the dynamic single spin susceptibility. To illustrate the
usefulness of these methods, we calculate the polarizability and susceptibility
up to the fourth order of perturbation theory. These {\em ab initio}
calculations resolve some ambiguities concerning the sign prescription and the
optical damping that arise in the phenomenological treatment. We also show that
the methods used to study two-level systems (qubits) can be extended to
many-level systems (qudits). As an example, we describe the interaction with
the quantized electromagnetic field of an atom with four relevant states: one S
state and three degenerate P states.
","The quantum electrodynamic (QED) effects on the dynamics and decoherence of semiconductor-based qubit systems are investigated in this work. The QED effect is described by an effective interaction between the qubit system and its environment, which consists of vacuum fluctuations of the electromagnetic field as well as thermal photons at finite temperature. We show that the QED effect can be treated perturbatively for typical experimental parameters. In particular, we find that the spontaneous emission rate of excitons into free space modes increases with increasing number N of electrons involved in the qubit state. This leads to faster relaxation times T 1 , but also to stronger pure dephasing rates T 2 . For realistic values of N = 10 − 100, however, these effects remain small compared to other sources of relaxation such as phonon scattering or electron-electron interactions. 
 
 Introduction 
 
 Quantum information processing has attracted considerable attention over recent years due to its potential applications in various fields ranging from communication technology [1] to metrology [2] . Semiconductor-based solid-state devices have been proposed as promising candidates for realizing scalable quantum computers [3] . Among them, excitonic states in semiconductors [4] represent one of the most important classes of physical objects suitable for storing and manipulating quantum information [5] . However, it turns out that exciton-exciton interactions [6] lead to rapid decay processes [7, 8] , so that only few excitations may be stored coherently within each individual device [9] . To overcome this problem, several proposals have been made recently [10] - [13] based on hybrid structures consisting of different materials [14] - [16] .
 
In this Letter, we investigate how the quantum electrodynamic (or radiative) coupling [17] affects the dynamics of semiconductor-based qubit sys-tems. As shown schematically in Fig. 1(a) , our model includes two types of environments surrounding the qubit system: First, there exist vacuum fluctuations of the electromagnetic fields inside the cavity [18] , leading to spontaneous emission of excitons into free-space modes [19, 20] . Second, there exists a bath of thermal photons [21]",arxiv,bigscience bloomz,705.2121,0.4444444444444444,0.6974789915966387,0.517948717948718,0.9225991399904443,1,1,1,0,0,1,1,1,0,0,0.08242956588252036,0.09276412418986411,0.11673151750972763,0.14772727272727273,0,1,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Asynchronous games: innocence without alternation,"  The notion of innocent strategy was introduced by Hyland and Ong in order to
capture the interactive behaviour of lambda-terms and PCF programs. An innocent
strategy is defined as an alternating strategy with partial memory, in which
the strategy plays according to its view. Extending the definition to
non-alternating strategies is problematic, because the traditional definition
of views is based on the hypothesis that Opponent and Proponent alternate
during the interaction. Here, we take advantage of the diagrammatic
reformulation of alternating innocence in asynchronous games, in order to
provide a tentative definition of innocence in non-alternating games. The task
is interesting, and far from easy. It requires the combination of true
concurrency and game semantics in a clean and organic way, clarifying the
relationship between asynchronous games and concurrent games in the sense of
Abramsky and Melli\`es. It also requires an interactive reformulation of the
usual acyclicity criterion of linear logic, as well as a directed variant, as a
scheduling criterion.
","We study the computational complexity of games with imperfect information, where players have no knowledge about each other's moves and actions are not necessarily alternating between them. We show that such games can be solved in polynomial time if they satisfy certain conditions on their structure (e.g., being bipartite). In particular, we prove this for all perfect-information games played by two or more players who do not know which player has made what move at any given point during play. Our results also apply to multiplayer versions of some well-known combinatorial problems like the traveling salesman problem. Games with imperfect information arise naturally when modeling situations involving multiple agents whose decisions cannot always be observed directly. For example, consider a group of people playing a board game together; it is often impossible to tell exactly who moved last because there may be several pieces involved in one move. Another common situation occurs in distributed systems, where different processes communicate indirectly via messages sent over an unreliable network.",arxiv,bigscience bloomz,706.1118,0.3333333333333333,0.29411764705882354,0.19487179487179487,0.43239369326325855,0,1,0,0,0,1,1,1,0,1,0.07154871514478996,0.050012797447652586,0.10116731517509728,0.041666666666666664,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1
Anatomy of Malicious Singularities,"  As well known, the b-boundaries of the closed Friedman world model and of
Schwarzschild solution consist of a single point. We study this phenomenon in a
broader context of differential and structured spaces. We show that it is an
equivalence relation $\rho $, defined on the Cauchy completed total space
$\bar{E}$ of the frame bundle over a given space-time, that is responsible for
this pathology. A singularity is called malicious if the equivalence class
$[p_0]$ related to the singularity remains in close contact with all other
equivalence classes, i.e., if $p_0 \in \mathrm{cl}[p]$ for every $p \in E$. We
formulate conditions for which such a situation occurs. The differential
structure of any space-time with malicious singularities consists only of
constant functions which means that, from the topological point of view,
everything collapses to a single point. It was noncommutative geometry that was
especially devised to deal with such situations. A noncommutative algebra on
$\bar{E}$, which turns out to be a von Neumann algebra of random operators,
allows us to study probabilistic properties (in a generalized sense) of
malicious singularities. Our main result is that, in the noncommutative regime,
even the strongest singularities are probabilistically irrelevant.
","We present an anatomical study on the structure and evolution of malicious singularities in complex networks, which are defined as nodes that have a disproportionately large number of connections to other nodes. We show how these nodes can be identified by their topological properties using statistical mechanics methods. In particular we find that the degree distribution of such nodes follows a power law with exponent 2.5 ± 0.1 for all studied real-world networks ranging from social networks like Facebook or Twitter to biological networks like metabolic pathways or protein-protein interaction networks. This finding is consistent across different network sizes and types. The results presented here provide new insights into the organization principles of complex systems and may help to identify key players within them. Complex networks play a crucial role in many fields including physics, biology, sociology, computer science, engineering, economics, etc., where they represent interactions between entities [1] . A common feature of most complex networks is the presence of so-called ""hubs"" -highly connected nodes [2] , whose removal often has dramatic effects [3] .
In this work we focus on identifying hubs in complex networks based solely on their topological features. To do so, we use statistical mechanics techniques [4] to analyze the degree distributions of several real world networks [5] . Our analysis reveals that the degree distribution of hubs follows a power-law [6] with exponent 2.5±0.1 independently of the size and type of the considered network (see Fig.  1 ). Interestingly, our findings are also valid when considering only the largest component of each network [7, 8] . These results suggest that the observed scaling behavior is not due to finite-size effects but rather reflects some fundamental property of complex networks [9] .",arxiv,bigscience bloomz,706.1416,0.4444444444444444,0.596638655462185,0.36923076923076925,0.7763975155279503,1,1,0,0,0,1,1,0,0,0,0.12990948573374297,0.08995410084680226,0.1556420233463035,0.10984848484848485,1,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Rational points on certain elliptic surfaces,"  Let $\mathcal{E}_{f}:y^2=x^3+f(t)x$, where $f\in\Q[t]\setminus\Q$, and let us
assume that $\op{deg}f\leq 4$. In this paper we prove that if $\op{deg}f\leq
3$, then there exists a rational base change $t\mapsto\phi(t)$ such that on the
surface $\cal{E}_{f\circ\phi}$ there is a non-torsion section. A similar
theorem is valid in case when $\op{deg}f=4$ and there exists $t_{0}\in\Q$ such
that infinitely many rational points lie on the curve
$E_{t_{0}}:y^2=x^3+f(t_{0})x$. In particular, we prove that if $\op{deg}f=4$
and $f$ is not an even polynomial, then there is a rational point on
$\cal{E}_{f}$. Next, we consider a surface $\cal{E}^{g}:y^2=x^3+g(t)$, where
$g\in\Q[t]$ is a monic polynomial of degree six. We prove that if the
polynomial $g$ is not even, there is a rational base change $t\mapsto\psi(t)$
such that on the surface $\cal{E}^{g\circ\psi}$ there is a non-torsion section.
Furthermore, if there exists $t_{0}\in\Q$ such that on the curve
$E^{t_{0}}:y^2=x^3+g(t_{0})$ there are infinitely many rational points, then
the set of these $t_{0}$ is infinite. We also present some results concerning
diophantine equation of the form $x^2-y^3-g(z)=t$, where $t$ is a variable.
","We study the rational points on some families of K3 surfaces and abelian surfaces over finite fields, especially those with Picard number one or two.  We prove that for any prime power $q$ there are infinitely many primes $p$ such that the Fermat curve $F_q(x)=x^{q+1}-1$ has no solutions in $\mathbb{F}_p$ (Theorem 1).  This is done by showing that if $p\neq q+1$ then the equation $x^{q+1}-1=y^p$ always has at least one solution in $\mathbb{F}_{p}^{\times}$.   As an application we show how to construct infinite families of supersingular primes (Corollary 2).   In Theorem 3 we give necessary conditions for the existence of a point of order $m_1m_2$ on an abelian surface $A=E_1\times E_2$ where $E_i$ are ordinary elliptic curves defined over a field $K$ of characteristic zero.   ...",arxiv,bigscience bloomz,705.2955,0.3888888888888889,0.24369747899159663,0.24102564102564103,0.3119923554706163,1,1,1,0,0,1,1,0,0,0,0.08430410355946456,0.1498370870776098,0.10894941634241245,0.15151515151515152,0,1,7,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
"FIRST-based survey of Compact Steep Spectrum sources, V. Milliarcsecond-scale morphology of CSS objects","  Multifrequency VLBA observations of the final group of ten objects in a
sample of FIRST-based compact steep spectrum (CSS) sources are presented. The
sample was selected to investigate whether objects of this kind could be relics
of radio-loud AGNs switched off at very early stages of their evolution or
possibly to indicate intermittent activity. Initial observations were made
using MERLIN at 5 GHz. The sources have now been observed with the VLBA at 1.7,
5 and 8.4 GHz in a snapshot mode with phase-referencing. The resulting maps are
presented along with unpublished 8.4-GHz VLA images of five sources. Some of
the sources discussed here show a complex radio morphology and therefore a
complicated past that, in some cases, might indicate intermittent activity. One
of the sources studied - 1045+352 - is known as a powerful radio and
infrared-luminous broad absorption line (BAL) quasar. It is a young CSS object
whose asymmetric two-sided morphology on a scale of several hundred parsecs,
extending in two different directions, may suggest intermittent activity. The
young age and compact structure of 1045+352 is consistent with the evolution
scenario of BAL quasars. It has also been confirmed that the submillimetre flux
of 1045+352 can be seriously contaminated by synchrotron emission.
",We present the results of our study on milliarcsec (mas) scale radio morphologies for a sample of compact steep spectrum (CSS) objects using Very Long Baseline Array (VLBA). The VLBA observations were carried out at 5 GHz in full polarization mode with an angular resolution of 0.5 mas and sensitivity better than 100 microJy beam-1 . We have detected all but one source in our sample which is unresolved by the VLBA. Our main findings are as follows:  1. All the resolved sources show core-jet structure except two sources where we see only jet emission.  2. Most of the jets appear to be straight or slightly bent towards north-east direction.  3. There appears to be no correlation between the linear size and the position angle of the jet axis.  4. A comparison of the observed flux density ratio between the core and the first component shows that most of these sources lie below the theoretical limit predicted by the standard model of relativistic beaming.,arxiv,bigscience bloomz,704.0351,0.5,0.49579831932773116,0.4153846153846154,0.4237935977066412,1,1,0,0,0,1,1,1,0,0,0.06291783414343133,0.10044476227469047,0.08949416342412451,0.10984848484848485,1,4,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Sunyaev-Zel'dovich profiles and scaling relations: modelling effects and observational biases,"  We use high-resolution hydrodynamic re-simulations to investigate the
properties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters.
We compare results obtained using different physical models for the
intracluster medium (ICM), and show how they modify the SZ emission in terms of
cluster profiles and scaling relations. We also produce realistic mock
observations to verify whether the results from hydrodynamic simulations can be
confirmed. We find that SZ profiles depend marginally on the modelled physical
processes, while they exhibit a strong dependence on cluster mass. The central
and total SZ emission strongly correlate with the cluster X-ray luminosity and
temperature. The logarithmic slopes of these scaling relations differ from the
self-similar predictions by less than 0.2; the normalization of the relations
is lower for simulations including radiative cooling. The observational test
suggests that SZ cluster profiles are unlikely to be able to probe the ICM
physics. The total SZ decrement appears to be an observable much more robust
than the central intensity, and we suggest using the former to investigate
scaling relations.
","We present the results of our analysis on simulated galaxy clusters, which are used to study how different physical processes affect SZ observables (profiles and scaling relations). We use hydrodynamical simulations performed with GADGET-2 code in order to investigate the effect of: gas clumping, AGN feedback, cooling flows, mergers, triaxiality and orientation of the cluster relative to observer's line-of-sight. The main conclusions are:  - Gas clumpiness has an important impact on SZ observable quantities such as integrated Comptonization parameter Y500 or pressure profile P(r), especially at small radii.  - Cooling flow regions have lower values for Y500 than expected by self-similar model predictions due to their low temperature and density compared to other parts of the cluster.  - Mergers can significantly change the shape of the pressure profile leading to higher central pressures and steeper slopes towards outer parts.  - Triaxiality affects both the amplitude and slope of the pressure profile depending on its orientation wrt. the observer's line-of-sigh.  - Inclination angle between the major axis of the cluster and the observer's line-ofsight is one of the most significant factors affecting the observed properties of galaxy clusters.",arxiv,bigscience bloomz,704.2535,0.3888888888888889,0.3445378151260504,0.2512820512820513,0.4897276636407072,1,1,1,0,1,1,1,1,0,1,0.05557939588712319,0.08610463122176812,0.058365758754863814,0.07954545454545454,0,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"TRUFAS, a wavelet based algorithm for the rapid detection of planetary transits","  Aims: We describe a fast, robust and automatic detection algorithm, TRUFAS,
and apply it to data that are being expected from the CoRoT mission. Methods:
The procedure proposed for the detection of planetary transits in light curves
works in two steps: 1) a continuous wavelet transformation of the detrended
light curve with posterior selection of the optimum scale for transit
detection, and 2) a period search in that selected wavelet transformation. The
detrending of the light curves are based on Fourier filtering or a discrete
wavelet transformation. TRUFAS requires the presence of at least 3 transit
events in the data. Results: The proposed algorithm is shown to identify
reliably and quickly the transits that had been included in a standard set of
999 light curves that simulate CoRoT data. Variations in the pre-processing of
the light curves and in the selection of the scale of the wavelet transform
have only little effect on TRUFAS' results. Conclusions: TRUFAS is a robust and
quick transit detection algorithm, especially well suited for the analysis of
very large volumes of data from space or ground-based experiments, with long
enough durations for the target-planets to produce multiple transit events.
","We present TRUFAS (Transit Recognition Using Fast Approximate Signatures), an efficient and robust transit search pipeline that uses fast approximate signatures to detect periodic signals in time series data. The method is particularly well suited for detecting short duration transits with high signal-to-noise ratio. We demonstrate its performance on simulated light curves generated by the Exoplanet Transit Database as well as real Kepler light curves. Our results show that TRUFAS can achieve higher efficiency than other algorithms while maintaining low false positive rates. 
 
 Keywords: Transiting planet, Wavelets, Time-series analysis, False positives reduction, Planetary system characterization 
 
 
 
 1 Introduction 
 
 Planets are detected indirectly through their gravitational effects upon their host stars. These effects include changes in stellar radius or luminosity caused by the passage of planets across the line-of-sight between the star and Earth. This phenomenon is known as a transit event. In order to characterize exoplanet systems it is necessary to identify these events efficiently and accurately. However, this task has been made more difficult due to the large number of false positives produced by systematic noise sources such as instrumental artifacts and astrophysical phenomena like eclipsing binaries and pulsating stars. 
 
 To date there have been several methods developed specifically for identifying transit-like features within astronomical time series data. Some examples include: Box Least Squares (BLS) [1] , BLS+ [2] , TrES [3] , TAP [4] , EXOTRANS [5] . While each of these techniques performs reasonably well under certain conditions they all suffer from one common drawback; they require significant computational resources when searching for multiple transit candidates simultaneously. For example, the most widely used technique, Box Least Squares, requires O(N3) operations where N is the length of the time series being analyzed [6] . As a result, many of these techniques cannot be applied directly to current and future surveys which will produce enormous amounts of data [7][8][9] . 
 
 In recent years wavelet transforms have become increasingly popular for analyzing astronomical time series data [10][",arxiv,bigscience bloomz,705.4557,0.3333333333333333,0.6974789915966387,0.3641025641025641,0.8881987577639752,1,1,1,0,1,1,1,1,0,0,0.12221596615860612,0.07080485533621163,0.14007782101167315,0.056818181818181816,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Accretion vs colliding wind models for the gamma-ray binary LS I +61 303: an assessment,"  LS I +61 303 is a puzzling Be/X-ray binary with variable gamma-ray emission
at up TeV energies. The nature of the compact object and the origin of the
high-energy emission are unclear. One family of models invokes particle
acceleration in shocks from the collision between the B-star wind and a
relativistic pulsar wind, while another centers on a relativistic jet powered
by accretion. Recent high-resolution radio observations showing a putative
""cometary tail"" pointing away from the Be star near periastron have been cited
as support for the pulsar-wind model. We wish here to carry out a quantitative
assessment of these competing models for this extraordinary source. We apply a
3D SPH code for dynamical simulations of both the pulsar-wind-interaction and
accretion-jet models. The former yields a description of the shape of the
wind-wind interaction surface. The latter provides an estimation of the
accretion rate. The results allow critical evaluation of how the two distinct
models confront the data in various wavebands under a range of conditions. When
one accounts for the 3D dynamical wind interaction under realistic constraints
for the relative strength of the B-star and pulsar winds, the resulting form of
the interaction front does not match the putative ""cometary tail"" claimed from
radio observations. On the other hand, dynamical simulations of the
accretion-jet model indicate that the orbital phase variation of accretion
power includes a secondary broad peak well away from periastron, thus providing
a plausible way to explain the observed TeV gamma ray emission toward apastron.
We conclude that the colliding-wind model is not clearly established for LS I
+61 303, while the accretion-jet model can reproduce many key characteristics
of the observed TeV gamma-ray emission.
","We present new results on the nature and geometry of the compact object in the gamma-ray binary system LS I +61 303, based on observations with the INTEGRAL satellite. We find that the source is variable at all wavelengths studied here (radio to hard X-rays), but shows no evidence for orbital modulation or eclipses. The X-ray spectrum can be described by either a power law model or thermal bremsstrahlung emission; both are consistent with previous studies. In addition we report the detection of pulsations in the radio band which have been previously reported only once before. These pulsations show up as periodic intensity variations in our data set, and their periodicity has been confirmed using two independent methods. Using these results together with those obtained from optical photometry and spectroscopy, we conclude that this source most likely contains a neutron star accreting matter from its companion Be-star via Roche lobe overflow.",arxiv,bigscience bloomz,706.132,0.6111111111111112,0.24369747899159663,0.8,0.38652651696129964,0,1,0,0,0,1,1,1,0,0,0.10862251589400967,0.038354774150069056,0.08171206225680934,0.026515151515151516,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Projectile Fragmentation of $^{86}$Kr at 64 MeV/nucleon,"  We measured fragmentation cross sections produced using the primary beam of
$^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross
sections were obtained by integrating the momentum distributions of isotopes
with 25<Z<36 measured using the RIPS fragment separator at RIKEN. The
cross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend
on the fragment masses, contrary to the simple geometrical models. We compared
the extracted cross sections to EPAX; an empirical parameterization of
fragmentation cross sections. Predictions from current EPAX parameterization
severely overestimate the production cross sections of very neutron-rich
isotopes. Attempts to obtain another set of EPAX parameters specific to the
reaction studied here, to extrapolate the neutron-rich nuclei more accurately
have not been very successful, suggesting that accurate predictions of
production cross sections of nuclei far from the valley of stability require
information of nuclear properties which are not present in EPAX.
","The projectile fragmentation of 86Kr at 64MeV/nucleon has been studied with the INDRA multidetector in inverse kinematics using an 8cm thick natK target and a beam intensity of 1nAe. The main results are as follows:  - A total number of about 10000 events have been recorded for this experiment.  - The charge distribution is peaked around Z=40, but shows also a large contribution between 30 and 40 charges units (see fig.1 ). This indicates that the fragments produced by the break-up of 86Kr are not only light particles like neutrons or protons, but contain many intermediate mass fragments too.   - The angular distributions show two peaks corresponding to forward and backward emission respectively (see fig.2 ).  - The energy spectra present a maximum around 10-12 MeV/u which corresponds to the most probable kinetic energy per nucleon of the emitted fragments (see fig.3 ).
- The isotopic composition of the fragments is shown on figure 4 . It can be seen that there is no significant difference between the fragment production in the forward hemisphere and in the backward one.",arxiv,bigscience bloomz,705.4313,0.2777777777777778,0.3445378151260504,0.11794871794871795,0.46679407548972773,0,1,1,0,0,1,1,1,0,0,0.13067644587905114,0.04455235703510969,0.1556420233463035,0.045454545454545456,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Fractal analysis for sets of non-differentiability of Minkowski's question mark function,"  In this paper we study various fractal geometric aspects of the Minkowski
question mark function $Q.$ We show that the unit interval can be written as
the union of the three sets $\Lambda_{0}:=\{x:Q'(x)=0\}$,
$\Lambda_{\infty}:=\{x:Q'(x)=\infty\}$, and $\Lambda_{\sim}:=\{x:Q'(x)$ does
not exist and $Q'(x)\not=\infty\}.$ The main result is that the Hausdorff
dimensions of these sets are related in the following way.
$\dim_{H}(\nu_{F})<\dim_{H}(\Lambda_{\sim})= \dim_{H} (\Lambda_{\infty}) =
\dim_{H} (\mathcal{L}(h_{\mathrm{top}}))<\dim_{H}(\Lambda_{0})=1.$
  Here, $\mathcal{L}(h_{\mathrm{top}})$ refers to the level set of the
  Stern-Brocot multifractal decomposition at the topological entropy
  $h_{\mathrm{top}}=\log2$ of the Farey map $F,$ and $\dim_{H}(\nu_{F})$
denotes the Hausdorff dimension of the measure of maximal entropy of the
dynamical system associated with $F.$ The proofs rely partially on the
multifractal formalism for Stern-Brocot intervals and give non-trivial
applications of this formalism.
","In this work, we study the fractal dimension and Hausdorff measure of the set of points where  is not differentiable in . We show that these measures are equal to one half times the corresponding values on the unit interval with Lebesgue measure.  This result generalizes previous results by Jarník (for ) and Marstrand (for ). The proof relies on an explicit formula for the Fourier transform of , which was obtained recently by Fejér and Riesz. In addition, we prove that the same holds true if instead of the Lebesgue measure on the unit interval, we consider any other probability measure whose support has positive length. Finally, we give some applications of our main theorem to the theory of lacunary series. Let be the space of all complex-valued functions defined on the real line equipped with the topology of uniform convergence on compact subsets of .
Let denote the class of all infinitely differentiable functions on such that their derivatives satisfy the Hölder condition with exponent greater than or equal to 1 at every point of the domain. 
For each integer let us define the operator as follows: 
where denotes the th derivative of .  It can easily be seen that is continuous linear functional on .",arxiv,bigscience bloomz,706.0453,0.05555555555555555,0.4453781512605043,0.0,0.5499283325370282,1,1,1,0,1,1,1,1,0,0,0.21687051723233575,0.05413788218587198,0.17509727626459143,0.045454545454545456,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Generic Gravitational Wave Signals from the Collapse of Rotating Stellar Cores: A Detailed Analysis,"  We present detailed results from performing general relativistic (GR)
simulations of stellar core collapse to a proto-neutron star, using a
microphysical equation of state (EoS) as well as an approximate description of
deleptonization during the collapse phase. We show that for a wide variety of
rotation rates and profiles the gravitational wave (GW) burst signals from the
core bounce are of a generic type, already known as Type I in the literature.
In addition, for most models the characteristic frequency of the GW burst
signal lies in a narrow range around approximately 718 Hz. In our systematic
study, using both GR and Newtonian gravity, we identify, individually quantify,
and discuss in detail the micro- and macrophysical mechanisms leading to this
result, i.e. the effects of rotation, the EoS, and deleptonization. We also
discuss the detectability prospects of such GW burst signals by GW detectors,
and infer that such a generic type of signal templates will likely facilitate a
more efficient search in current and future detectors of both interferometric
and resonant type.
","We present an analysis of gravitational wave signals produced by rotating stellar cores collapsing to black holes, using numerical relativity simulations performed with the Einstein Toolkit. We find that generic collapse models produce characteristic features in their gravitational waveforms which can be used as templates for matched filtering searches. These include (i) a precursor signal, (ii) a ringdown phase and (iii) a post-merger phase. The precursor is associated with the formation of a shock front at the surface of the core; it has been observed previously but its properties have not yet been studied systematically. In this work we show how these properties depend on the rotation rate of the progenitor star. For rapidly-rotating progenitors, the precursor signal contains multiple peaks whose frequencies are determined primarily by the spin frequency of the central object prior to merger. This suggests that such precursors could be detected even if they were emitted by binary neutron stars or black hole-neutron star systems where no information about the pre-merger spins would be available.",arxiv,bigscience bloomz,705.2675,0.2777777777777778,0.29411764705882354,0.2512820512820513,0.4381270903010034,1,1,0,0,0,1,1,1,0,0,0.11278365268763804,0.04062986663479952,0.12840466926070038,0.041666666666666664,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1
Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in hypre and PETSc,"  We describe our software package Block Locally Optimal Preconditioned
Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as
a stand-alone serial library, as an external package to PETSc (``Portable,
Extensible Toolkit for Scientific Computation'', a general purpose suite of
tools for the scalable solution of partial differential equations and related
problems developed by Argonne National Laboratory), and is also built into {\it
hypre} (``High Performance Preconditioners'', scalable linear solvers package
developed by Lawrence Livermore National Laboratory). The present BLOPEX
release includes only one solver--the Locally Optimal Block Preconditioned
Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\it
hypre} provides users with advanced high-quality parallel preconditioners for
linear systems, in particular, with domain decomposition and multigrid
preconditioners. With BLOPEX, the same preconditioners can now be efficiently
used for symmetric eigenvalue problems. PETSc facilitates the integration of
independently developed application modules with strict attention to component
interoperability, and makes BLOPEX extremely easy to compile and use with
preconditioners that are available via PETSc. We present the LOBPCG algorithm
in BLOPEX for {\it hypre} and PETSc. We demonstrate numerically the scalability
of BLOPEX by testing it on a number of distributed and shared memory parallel
systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron
workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition
and {\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,
the standard 7-point finite-difference approximation of the 3-D Laplacian, with
the problem size in the range $10^5-10^8$.
","We present Block Locally Optimal Precondioner for the solution of large sparse linear systems arising from discretized partial differential equations using Krylov subspace methods.  The preconditioners are constructed by solving local eigenvalue problems on small subdomains, which can be done efficiently with parallel iterative solvers such as GMRES or BiCGSTAB. We show that these preconditioners have good convergence properties when used within an inexact Newton-Krylov-Schwarz method to solve nonlinear PDEs. In addition we demonstrate how this approach is implemented in two popular libraries, PETSc and hypre. Finally, we provide numerical results showing the effectiveness of our proposed algorithm. Keywords: Nonlinear PDE, Inexact Newton Method, Parallel Iterative Solver, Preconditioning, Subdomain Decomposition. 1 Introduction.
The goal of this work is to develop efficient algorithms for solving large-scale nonlinear partial differential equations (PDEs). These algorithms will use domain decomposition techniques combined with parallel iterative solving strategies to construct effective preconditioners for the resulting linear system. Our focus here is on developing new approaches for constructing locally optimal block diagonal preconditioners based on the Schur complements associated with overlapping Schwarz methods. This type of preconditioner has been shown to perform well for many types of applications including convection-diffusion-reaction equations [19, 20] , Stokes flow [3, 4] , Maxwell's equations [6] , elasticity [7, 8] , and incompressible Navier-Stokes flows [9, 10] . However, there remain several challenges related to their construction and application. First, it is difficult to compute accurate approximations to the Schur complement matrices due to the presence of singularities at corners and edges of the computational domains. Second, the number of unknowns per subdomain increases rapidly as the problem size grows making direct factorization impractical. Third, the condition numbers of the Schur complement matrices grow exponentially fast with respect to the number of subdomains. Fourth, the cost of applying the preconditioner may become prohibitively expensive if one",arxiv,bigscience bloomz,705.2626,0.4444444444444444,0.7478991596638657,0.6153846153846154,0.8308647873865265,1,1,0,0,1,1,1,1,0,1,0.18745874000811674,0.09240088924579959,0.23346303501945526,0.14772727272727273,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
4U 0115+63 from RXTE and INTEGRAL Data: Pulse Profile and Cyclotron Line Energy,"  We analyze the observations of the transient X-ray pulsar 4U 0115+63 with the
RXTE and INTEGRAL observatories in a wide X-ray (3-100 keV) energy band during
its intense outbursts in 1999 and 2004. The energy of the fundamental harmonic
of the cyclotron resonance absorption line near the maximum of the X-ray flux
from the source (luminosity range 5x10^{37} - 2x10^{38} erg/s) is ~11 keV. When
the pulsar luminosity falls below ~5x10^{37} erg/s, the energy of the
fundamental harmonic is displaced sharply toward the high energies, up to ~16
keV. Under the assumption of a dipole magnetic field configuration, this change
in cyclotron harmonic energy corresponds to a decrease in the height of the
emitting region by ~2 km, while other spectral parameters, in particular, the
cutoff energy, remain essentially constant. At a luminosity ~7x10^{37} erg/s,
four almost equidistant cyclotron line harmonics are clearly seen in the
spectrum. This suggests that either the region where the emission originates is
compact or the emergent spectrum from different (in height) segments of the
accretion column is uniform. We have found significant pulse profile variations
with energy, luminosity, and time. In particular, we show that the profile
variations from pulse to pulse are not reduced to a simple modulation of the
accretion rate specified by external conditions.
","We have analyzed the pulse profiles in two energy bands (3-20 keV, 20-100 keV) for 4U0115+63 using data obtained by the Rossi X-ray Timing Explorer (RXTE). The results show that there is no significant difference between these two energy bands except at phase 0.7-0.9 where we see an excess emission above 100 keV. We also find that this source shows a double peaked profile with a dip around phase 0.5 which can be explained as due to absorption effects on the line-of-sight. In addition, we have used data from the International Gamma-Ray Astrophysics Laboratory (INTEGRAL), which has detected cyclotrons lines near 30 keV and 60 keV respectively. Using our model parameters derived from the RXTE data analysis, we are able to reproduce both the observed pulse profiles and the cyclotrons line energies simultaneously.",arxiv,bigscience bloomz,704.2874,0.3888888888888889,0.19327731092436976,0.46153846153846156,0.3349259436215958,1,1,0,0,0,1,1,0,0,0,0.09038680902557009,0.008953303533783036,0.09727626459143969,0.0,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Incoherent non-Fermi liquid scattering in a Kondo lattice,"  One of the most notorious non-Fermi liquid properties of both archetypal
heavy-fermion systems [1-4] and the high-Tc copper oxide superconductors [5] is
an electrical resistivity that evolves linearly with temperature, T. In the
heavy-fermion superconductor CeCoIn5 [5], this linear behaviour was one of the
first indications of the presence of a zero-temperature instability, or quantum
critical point. Here, we report the observation of a unique control parameter
of T-linear scattering in CeCoIn5, found through systematic chemical
substitutions of both magnetic and non-magnetic rare-earth, R, ions into the Ce
sub-lattice. We find that the evolution of inelastic scattering in Ce1-xRxCoIn5
is strongly dependent on the f-electron configuration of the R ion, whereas two
other key properties -- Cooper-pair breaking and Kondo-lattice coherence -- are
not. Thus, T-linear resistivity in CeCoIn5 is intimately related to the nature
of incoherent scattering centers in the Kondo lattice, which provides insight
into the anomalous scattering rate synonymous with quantum criticality [7].
","We study the incoherent transport properties of a strongly correlated electron system, namely the periodic Anderson model (PAM) with strong hybridization between conduction and localized electrons. We show that this PAM can be mapped onto an effective spinless fermion model which is equivalent to a disordered Fermi gas at low temperatures. The resulting density of states exhibits a pseudogap structure near the chemical potential. In addition we find that the resistivity shows a linear temperature dependence below some characteristic temperature T*. This behavior is consistent with recent experiments on heavy-fermion compounds such as Yb$_{1}$-xYb$x$Cu$_2$Si$2$O$_{7-x}$. Finally, we discuss how our results are related to previous theoretical work based on the dynamical mean-field theory. PACS numbers: 71.27.+a, 72.25.+f, 74.78.+h",arxiv,bigscience bloomz,705.2592,0.16666666666666666,0.29411764705882354,0.16923076923076924,0.28905876731963687,0,1,0,0,0,1,1,1,0,0,0.1252102515033824,0.08117725541945629,0.11673151750972763,0.06060606060606061,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Computer simulation of model cohesive powders: influence of assembling procedure and contact laws on low consolidation states,"  The structure and mechanical properties of a simple two-dimensional model of
a cohesive powder are investigated by molecular dynamics simulations.
Micromechanical ingredients involve elasticity, friction, a short range
attraction and, possibly, rolling resistance (RR) in contacts. The
microstructure of the cohesive packing varies according to the assembling
procedure, from rather densely packed if isolated particles are directly
compressed to much looser if the formation of large aggregates is allowed prior
to compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure
P, acting on grains of diameter $a$, to maximum tensile contact force F0. At
low P* the final structure depends on the level of velocity fluctuations at the
early stages of cluster aggregation. With RR the coordination number approaches
2 in the limit of low initial velocities or large rolling friction. The force
network generally comprises small hyperstatic clusters with forces of the order
of F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly
rearranges into force chain-like patterns. Density correlations witness a
fractal structure, with dimension Df, up to some density-dependent blob size.
WIth RR Df coincides with the ballistic aggregation result, despite a possibly
different connectivity. Possible effects of some parameters on material
strength are evoked.
","The aim of this work is to study the effect of different assembly procedures, as well as different contact laws between particles in powder compaction processes using computer simulations. The results show that the packing density depends strongly on the applied pressure during the assembly process. In addition, it was found that the densification behavior can be influenced by changing the contact law parameters. Finally, we have shown how the microstructure evolves with increasing pressure for two different types of particle contacts. Powder compaction has been studied extensively over many years due to its importance in various industrial applications such as pharmaceutical tablets or metal parts produced via hot pressing techniques [1] . However, despite these efforts there are still open questions regarding the underlying mechanisms governing the densification behavior under external loads [2] .
In order to understand the complex phenomena occurring inside compacted materials, several experimental studies were performed [3] , which revealed important information about the evolution of the microstructure [4] . Nevertheless, experiments cannot provide detailed insight into the local interactions taking place at the grain scale [5] . Therefore, numerical methods based on discrete element models (DEM) [6] became an alternative approach to investigate the mechanical properties of granular systems [7, 8] . These DEM-based approaches allow one to track individual grains within large assemblies and thus enable us to obtain valuable insights into the micromechanical response [9] . For example, recent investigations showed that the macroscopic stress-strain curve obtained from compression tests can be reproduced accurately if realistic inter-particle contact laws are used [10] .",arxiv,bigscience bloomz,705.3295,0.5555555555555556,0.49579831932773116,0.4205128205128205,0.7018633540372672,1,1,0,0,0,1,1,0,0,0,0.07170229136324599,0.04741070247427756,0.058365758754863814,0.03409090909090909,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Many-to-One Throughput Capacity of IEEE 802.11 Multi-hop Wireless Networks,"  This paper investigates the many-to-one throughput capacity (and by symmetry,
one-to-many throughput capacity) of IEEE 802.11 multi-hop networks. It has
generally been assumed in prior studies that the many-to-one throughput
capacity is upper-bounded by the link capacity L. Throughput capacity L is not
achievable under 802.11. This paper introduces the notion of ""canonical
networks"", which is a class of regularly-structured networks whose capacities
can be analyzed more easily than unstructured networks. We show that the
throughput capacity of canonical networks under 802.11 has an analytical upper
bound of 3L/4 when the source nodes are two or more hops away from the sink;
and simulated throughputs of 0.690L (0.740L) when the source nodes are many
hops away. We conjecture that 3L/4 is also the upper bound for general
networks. When all links have equal length, 2L/3 can be shown to be the upper
bound for general networks. Our simulations show that 802.11 networks with
random topologies operated with AODV routing can only achieve throughputs far
below the upper bounds. Fortunately, by properly selecting routes near the
gateway (or by properly positioning the relay nodes leading to the gateway) to
fashion after the structure of canonical networks, the throughput can be
improved significantly by more than 150%. Indeed, in a dense network, it is
worthwhile to deactivate some of the relay nodes near the sink judiciously.
","In this work, we study the throughput capacity region for multi-hop wireless networks with multiple transmitters and one receiver (MISO-MHWN). We first show that the MISO-MHWN is equivalent to an interference channel where each transmitter has only one antenna but can communicate simultaneously with all receivers in the network. Then, by using the concept of degrees-of-freedom (DoF), which characterizes how many parallel data streams are supported at high signal-to-noise ratio (SNR) regime, we derive outer bounds on the DoF region of the MISO-MHWNS. Finally, based on these results, we propose a novel transmission scheme called ""Interference Alignment"" (IA) to achieve the optimal DoF region. The proposed IA scheme exploits both spatial multiplexing gain as well as multiuser diversity gain. In particular, it allows different users to transmit their signals over non-overlapping time-frequency resources while maintaining full spatial reuse among them.",arxiv,bigscience bloomz,704.0528,0.4444444444444444,0.24369747899159663,0.517948717948718,0.35499283325370284,1,1,1,0,0,1,1,0,0,0,0.10428586870822774,0.06681847489066246,0.14007782101167315,0.03787878787878788,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1
Towards the optimal window for the 2MASS dipole,"  A comparison of the 2MASS flux dipole to the CMB dipole can serve as a method
to constrain a combination of the cosmological parameter Omega_m and the
luminosity bias of the 2MASS survey. For this constraint to be as tight as
possible, it is necessary to maximize the correlation between the two dipoles.
This can be achieved by optimizing the survey window through which the flux
dipole is measured. Here we explicitly construct such a window for the 2MASS
survey. The optimization in essence reduces to excluding from the calculation
of the flux dipole galaxies brighter than some limiting magnitude K_min of the
near-infrared K_s band. This exclusion mitigates nonlinear effects and shot
noise from small scales, which decorrelate the 2MASS dipole from the CMB
dipole. Under the assumption of negligible shot noise we find that the optimal
value of K_min is about five. Inclusion of shot noise shifts the optimal K_min
to larger values. We present an analytical formula for shot noise for the 2MASS
flux dipole, to be used in follow-up work with 2MASS data.
  The misalignment angle between the two dipoles is a sensitive measure of
their correlation: the higher the correlation, the smaller the expectation
value of the angle. A minimum of the misalignment is thus a sign of the optimal
gravity window. We model analytically the distribution function for the
misalignment angle and show that the misalignment estimated by Maller et al. is
consistent with the assumed underlying model (though it is greater than the
expectation value). We predict with about 90% confidence that the misalignment
will decrease if 2MASS galaxies brighter than K_min = 5 mag are excluded from
the calculation of the flux dipole. This prediction has been indirectly
confirmed by the results of Erdogdu et al. (ABRIDGED)
","We present an analysis of the Galactic latitude distribution of stars in the 2MASS survey, and find that it is well described by a superposition of two Gaussians with different widths. The narrower Gaussian has a mean latitude of $-2^{\circ}$ , while the broader one peaks at $+3^{\circ}$ . We show that this double-Gaussian model can be used to explain the observed latitude dependence of the number density fluctuations as measured by the power spectrum of the 2MASS all-sky map. 
 
 In addition we demonstrate how our results are consistent with previous studies on the subject. Finally, using the derived parameters of the double-Gaussian model, we calculate the expected value of the quadrupole moment of the CMB temperature anisotropy induced by the Galaxy's gravitational potential. This calculation shows that the quadrupole moment predicted by the model agrees very well with recent measurements made by WMAP satellite.",arxiv,bigscience bloomz,706.0619,0.8333333333333334,0.24369747899159663,0.882051282051282,0.369326325848065,1,1,1,0,0,0,1,0,0,1,0.07481635102184556,0.05252165119471142,0.06614785992217899,0.04924242424242424,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Orbifoldes speciales et classification bimeromorphe des varietes kaehleriennes compactes,"  This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\it
category} of geometric orbifolds. These interpolate between (compact K\"" ahler)
manifolds and such manifolds with logarithmic structure. These geometric
orbifolds are considered from the point of view of their geometry, and thus
equipped with the usual invariants of varieties: morphisms and bimeromorphic
maps, differential forms, fundamental groups and universal covers, fields of
definition and rational points. The most elementary properties, directly
adapted from the case of varieties without orbifold structure, are established
here. The arguments of [Ca01] can then be directly adapted to extend the main
structure results to this orbifold category. We hope to come back to deeper
aspects later. The motivation is that the natural frame for the theory of
classification of compact K\"" ahler (and complex projective) manifolds includes
at least the category of orbifolds, as shown in [Ca01] by the fonctorial
decomposition of {\it special} manifolds as tower of orbifolds with either
$\kappa_+=-\infty$ or $\kappa=0$, and also, seemingly, by the minimal model
program, in which most proofs work only after the adjunction of a ""boundary"".
  Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds
extension properties not satisfied in the category of varieties without
orbifold structure, permitting to express invariants of the total space from
those of the generic fibre and of the base. For example, the natural sequence
of fundamental groups is exact there; also the total space is special if so are
the generic fibre and the base. This makes this category suitable to lift
properties from orbifolds having either $\kappa_+=-\infty$ or $\kappa=0$ to
those which are special.
","Dans cet article, nous donnons une nouvelle preuve de la classification bimeromorphee des varietes kahleriennes compactes en utilisant les orbifolds speciaux. Nous montrons que si X est un orbifold special alors le groupe fondamental de X s'identifie au groupe fondamental d'une variete kahlerienne compacte Y . _SPLIT_ En particulier, on obtient que tout orbifold special admet une resolution symplectique. On montre aussi que toute application holomorphe entre deux orbifolds speciaux induit par passage aux groupes fondamentaux une application holomorphe sur leurs resolutions respectives. Enfin, on donne quelques exemples d'orbifolds speciaux qui ne sont pas resolubles. Keywords: Orbifoldes spéciaux, Variétés Kähleriennes Compactes, Groupes fondamentaux, Résolutions symplectiques. 1 Introduction Soit X un espace analytique complexe connexe muni d'un feuilletage holomorphe F . Un tel objet sera appelé dans ce texte un orbifold spécial (voir [V]). Dans cette note, nous allons donner une nouvelle démonstration du théorème suivant dû à Verbitsky : Théorème 0.1. (Verbitsky) Tout orbifold spécial admet une résolution symplectique.",arxiv,bigscience bloomz,705.0737,0.5555555555555556,0.4453781512605043,0.7333333333333333,0.4094601051122791,1,1,1,0,0,1,0,1,0,1,0.2078861255225385,0.03741074253825315,0.29961089494163423,0.026515151515151516,2,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Anonymity in the Wild: Mixes on unstructured networks,"  As decentralized computing scenarios get ever more popular, unstructured
topologies are natural candidates to consider running mix networks upon. We
consider mix network topologies where mixes are placed on the nodes of an
unstructured network, such as social networks and scale-free random networks.
We explore the efficiency and traffic analysis resistance properties of mix
networks based on unstructured topologies as opposed to theoretically optimal
structured topologies, under high latency conditions. We consider a mix of
directed and undirected network models, as well as one real world case study --
the LiveJournal friendship network topology. Our analysis indicates that
mix-networks based on scale-free and small-world topologies have, firstly,
mix-route lengths that are roughly comparable to those in expander graphs;
second, that compromise of the most central nodes has little effect on
anonymization properties, and third, batch sizes required for warding off
intersection attacks need to be an order of magnitude higher in unstructured
networks in comparison with expander graph topologies.
","We study anonymity systems that operate over unstructured networks, such as Tor and Mixminion. We show how to construct mixes with provable guarantees against traffic analysis attacks by using only local information about the topology of the underlying network. Our construction is based on mixing small groups of users together at each node along their paths through the system. This approach allows us to achieve high levels of anonymity while maintaining low latency for most messages. In addition, we present several extensions to our basic scheme which allow it to be deployed more easily in practice. Finally, we evaluate our system both analytically and experimentally, showing that it achieves good performance under realistic conditions. Anonymity systems are used to protect user privacy when sending or receiving data over public communication channels. These systems typically consist of a set of nodes (called mixes) connected via some anonymous communication channel. Each message entering the system is encrypted multiple times before being sent out again; this process is called ""mixing"". The goal of these systems is to prevent attackers from linking senders and receivers of messages within the system. However, if all messages go through exactly the same sequence of mixes then they can still be linked using statistical techniques known as ""traffic analysis"". Traffic analysis has been shown to compromise the security of many existing anonymity systems including Tor [1] , Crowds [2] , Onion Routing [3] , Freenet [4] , and Mixminion [5] . To overcome this problem, researchers have proposed various approaches [6] - [8] .
In this work, we focus on anonymity systems operating over unstructured networks [9]- [11] . Unstructured networks differ from traditional peer-to-peer networks [12] because there is no global knowledge available regarding the structure of the network. Instead, each node maintains only partial information about its immediate neighbors. For example, in the case of Tor [13] , each node knows only the identity of its direct neighbors but not those of other nodes further away. As another example, in Mixminion [14] , each node knows only whether two given nodes are directly connected or not",arxiv,bigscience bloomz,706.043,0.2222222222222222,0.8487394957983193,0.18461538461538463,0.9569995222169135,0,1,1,0,0,1,1,1,0,0,0.18098163856394633,0.052226148906731995,0.17898832684824903,0.07575757575757576,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
SDSS J080531.84+481233.0: An Unresolved L Dwarf/T Dwarf Binary,"  SDSS J080531.84+481233.0 is a peculiar L-type dwarf that exhibits unusually
blue near-infrared and mid-infrared colors and divergent optical (L4) and
near-infrared (L9.5) spectral classifications. These peculiar spectral traits
have been variously attributed to condensate cloud effects or subsolar
metallicity. Here I present an improved near-infrared spectrum of this source
which further demonstrates the presence of weak CH4 absorption at 1.6 micron
but no corresponding band at 2.2 micron. It is shown that these features can be
collectively reproduced by the combined light spectrum of a binary with L4.5
and T5 components, as deduced by spectral template matching. Thus, SDSS
J080531.84+481233.0 appears to be a new low-mass binary straddling the L
dwarf/T dwarf transition, an evolutionary phase for brown dwarfs that remains
poorly understood by current theoretical models. The case of SDSS
J080531.84+481233.0 further illustrates how a select range of L dwarf/T dwarf
binaries could be identified and characterized without the need for high
angular resolution imaging or radial velocity monitoring, potentially
alleviating some of the detection biases and limitations inherent to such
techniques.
","We report the discovery and characterization of an unresolved binary system consisting of two late-type dwarf stars, SDSS J080531.8+481233.0AB (hereafter referred to as J0805+4812). The primary component is classified as a T6p dwarf star with a mass of ~70 MJup while its companion has been identified as a cool brown dwarf candidate with a temperature between 1000-2000 K. We have used high-resolution near-infrared spectroscopy obtained at Gemini Observatory in order to confirm that both components are gravitationally bound. Our analysis shows that this object is one of the most massive known binaries composed by two low-mass objects. This work was supported by NASA's Astrophysics Data Analysis Program under award NNX10AD20G issued through the Space Telescope Science Institute, which is operated by AURA for NASA under contract NAS 5-26555. In addition we acknowledge support from NSF grant AST-0908816. 
 
 We present the discovery and characterization of a new unresolved binary system made up of two late type dwarfs, SDSSJ080531.8 + 481233.0 AB (hereafter J0805+4812; see Figure 1 ). The primary component is classified spectroscopically as a T6p star with a mass of about 70 M Jup , while its companion has been tentatively identified as a cool brown-dwarf candidate with temperatures ranging from 1000 - 2000K . Using high resolution infrared spectroscopy taken at Gemini Observatory , we show that these two objects are gravitationally bound . This makes it one of the most massive systems ever found containing two low-mass objects .",arxiv,bigscience bloomz,706.1965,0.2777777777777778,0.3949579831932773,0.2564102564102564,0.6445293836598185,1,1,0,0,0,1,1,1,0,1,0.08997544558944534,0.11125549169797905,0.058365758754863814,0.11742424242424243,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Aspects of stochastic resonance in reaction-diffusion systems: The nonequilibrium-potential approach,"  We analyze several aspects of the phenomenon of stochastic resonance in
reaction-diffusion systems, exploiting the nonequilibrium potential's
framework. The generalization of this formalism (sketched in the appendix) to
extended systems is first carried out in the context of a simplified scalar
model, for which stationary patterns can be found analytically. We first show
how system-size stochastic resonance arises naturally in this framework, and
then how the phenomenon of array-enhanced stochastic resonance can be further
enhanced by letting the diffusion coefficient depend on the field. A yet less
trivial generalization is exemplified by a stylized version of the
FitzHugh-Nagumo system, a paradigm of the activator-inhibitor class. After
discussing for this system the second aspect enumerated above, we derive from
it -through an adiabatic-like elimination of the inhibitor field- an effective
scalar model that includes a nonlocal contribution. Studying the role played by
the range of the nonlocal kernel and its effect on stochastic resonance, we
find an optimal range that maximizes the system's response.
","We study the effects of noise on spatially extended systems by using an extension of the concept of nonequilibrium potential (NEP). We show that NEPs can be used to characterize different types of stochastic resonances, such as those observed for excitable and bistable systems near their respective Hopf bifurcations. In particular we find that the presence of noise enhances the amplitude of oscillations in both cases but with very different mechanisms. For excitable systems this is due to the fact that noise increases the probability of crossing the threshold between two stable states; while for bistable systems it occurs because noise induces transitions between these states. Finally, we discuss how our results are related to previous studies based on other approaches. Stochastic resonance has been studied extensively during recent years [1] . It refers to the phenomenon whereby weak signals can be enhanced or detected more easily when they are embedded into a noisy background [2] .
In many physical situations, however, one needs to consider not only the effect of external noise sources but also internal fluctuations arising from the dynamics itself [3] . This problem becomes particularly relevant if the signal-to-noise ratio is small [4] , which may occur either because the signal is intrinsically weak or because its intensity is comparable to the level of intrinsic noise [5] . Moreover, even though the signal is strong enough so that it could be clearly distinguished without any additional noise [6] , there might still exist some optimal amount of noise that maximizes the detection efficiency [7, 8] .",arxiv,bigscience bloomz,704.1148,0.2777777777777778,0.4453781512605043,0.20512820512820512,0.6989966555183947,1,1,0,0,1,1,1,1,0,0,0.05959035376988173,0.08076863677205,0.0622568093385214,0.06060606060606061,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Radio Through X-ray Spectral Energy Distributions of 38 Broad Absorption Line Quasars,"  We have compiled the largest sample of multiwavelength spectral energy
distributions (SEDs) of Broad Absorption Line (BAL) quasars to date, from the
radio to the X-ray. We present new Spitzer MIPS (24, 70, and 160 micron)
observations of 38 BAL quasars in addition to data from the literature and
public archives. In general, the mid-infrared properties of BAL quasars are
consistent with those of non-BAL quasars of comparable luminosity. In
particular, the optical-to-mid-infrared luminosity ratios of the two
populations are indistinguishable. We also measure or place upper limits on the
contribution of star formation to the far-infrared power. Of 22 (57%) upper
limits, seven quasars have sufficiently sensitive constraints to conclude that
star formation likely contributes little (<20%) to their far-infrared power.
The 17 BAL quasars (45%) with detected excess far-infrared emission likely host
hyperluminous starbursts with L_fir,SF=10^{13-14} L_sun. Mid-infrared through
X-ray composite BAL quasar SEDs are presented, incorporating all of the
available photometry. Overall, we find no compelling evidence for inherent
differences between the SEDs of BAL vs. non-BAL quasars of comparable
luminosity. Therefore a ``cocoon'' picture of a typical BAL quasar outflow
whereby the wind covers a large fraction of the sky is not supported by the
mid-infrared SED comparison with normal quasars, and the disk-wind paradigm
with a typical radio-quiet quasar hosting a BAL region remains viable.
","We present the radio through X-ray spectral energy distributions (SEDs) for 38 quasars with broad absorption lines in their optical spectra, selected from the Sloan Digital Sky Survey Data Release 5 quasar catalog and observed by Chandra and/or XMM-Newton. We find that these sources are typically characterized by steep radio to infrared continua, weak or absent emission lines at ultraviolet wavelengths, and strong soft excesses below 1 keV. The majority of our sample show evidence for significant intrinsic reddening as indicated by the presence of deep UV troughs and high values of the Balmer decrement. In addition, we detect several objects which exhibit extremely flat radio-to-X-ray slopes indicative of relativistic beaming effects. These results suggest that BAL quasars represent an important phase in the evolution of luminous active galactic nuclei during which they undergo rapid changes in physical conditions within their central regions. This is supported by recent theoretical models suggesting that BAL outflows may play an important role in regulating black hole growth via feedback processes. 
 
 Keywords: Active Galactic Nuclei",arxiv,bigscience bloomz,705.0538,0.5,0.29411764705882354,0.49743589743589745,0.4438604873387483,1,1,0,0,1,1,1,1,0,0,0.09723140162230136,0.09443201205733132,0.10894941634241245,0.06060606060606061,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Atomic force microscopy (AFM) study of thick lamellar stacks of phospholipid bilayers,"  We report an Atomic Force Microscopy (AFM) study on thick multi lamellar
stacks of approx. 10 mum thickness (about 1500 stacked membranes) of DMPC
(1,2-dimyristoyl-sn-glycero-3-phoshatidylcholine) deposited on silicon wafers.
These thick stacks could be stabilized for measurements under excess water or
solution. From force curves we determine the compressional modulus B and the
rupture force F_r of the bilayers in the gel (ripple), the fluid phase and in
the range of critical swelling close to the main transition. AFM allows to
measure the compressional modulus of stacked membrane systems and values for B
compare well to values reported in the literature. We observe pronounced
ripples on the top layer in the Pbeta' (ripple) phase and find an increasing
ripple period Lambda_r when approaching the temperature of the main phase
transition into the fluid Lalpha phase at about 24 C. Metastable ripples with
2Lambda_r are observed. Lambda_r also increases with increasing osmotic
pressure, i.e., for different concentrations of polyethylene glycol (PEG).
","The structure and dynamics of lipid membranes are important for many biological processes, such as cell division or protein transport across the membrane. In this work we use atomic force microscopy to investigate the structural properties of stacked layers of phospholipids in water. We find that these structures form spontaneously on mica surfaces at room temperature within minutes after adding the lipids into solution. The height profiles show that the thicknesses of the individual layers vary between 1 nm and 2 nm depending on their composition. By analyzing the lateral diffusion coefficients of single molecules with respect to time, we can determine whether they are mobile or immobile. Our results indicate that the mobility is strongly dependent on the number of layers present in each stack. For example, while most of the molecules in one layer diffuse freely over large distances, those in two layers exhibit only small displacements perpendicular to the surface. This behavior suggests that the mobility decreases significantly when more than one layer forms.",arxiv,bigscience bloomz,706.0196,0.3333333333333333,0.3445378151260504,0.18974358974358974,0.43239369326325855,1,1,0,0,1,0,0,0,0,0,0.11386349373115531,0.032425212692689935,0.10894941634241245,0.041666666666666664,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Ballistic Graphene Nanoribbon MOSFETs: a full quantum real-space simulation study,"  A real-space quantum transport simulator for carbon nanoribbon (CNR) MOSFETs
has been developed. Using this simulator, the performance of carbon nanoribbon
(CNR) MOSFETs is examined in the ballistic limit. The impact of quantum effects
on device performance of CNR MOSFETs is also studied. We found that 2D
semi-infinite graphene contacts provide metal-induced-gap-states (MIGS) in the
CNR channel. These states would provide quantum tunneling in the short channel
device and cause Fermi level pining. These effects cause device performance
degradation both on the ON-state and the OFF-state. Pure 1D devices (infinite
contacts), however, show no MIGS. Quantum tunneling effects are still playing
an important role in the device characteristics. Conduction due to band-to-band
tunneling is accurately captured in our simulations. It is important in these
devices, and found to dominate the off-state current. Based on our simulations,
both a 1.4nm wide and a 1.8nm wide CNR with channel length of 12.5nm can
outperform ultra scaled Si devices in terms of drive current capabilities and
electrostatic control. Although subthreshold slopes in the forward-bias
conduction are better than in Si transistors, tunneling currents are important
and prevent the achievement of the theoretical limit of 60mV/dec.
","We present the first fully self-consistent, atomistic quantum transport calculations for ballistic graphene nanoribbons (GNRs) with realistic band structure and electrostatic potential profiles using nonequilibrium Green's function formalism in combination with density functional theory (DFT). We show that the GNRs' electronic properties are strongly dependent on their widths as well as edge structures. The calculated current-voltage characteristics reveal several interesting features such as negative differential resistance at low bias voltages due to resonant tunneling through localized states near the Fermi level. In addition, we find that the presence of hydrogen passivation layers can significantly enhance the device performance by suppressing the backscattering effect caused by defects or impurities along the edges. 
 
 Keywords: Ballistic transport, Graphene nanoribbon, Nonequilibrium Green's functions, Density functional theory, Quantum transport calculation. 1 Introduction 
 
 Graphene is an emerging material which has attracted considerable attention recently because it exhibits unique physical properties [1] . It consists of carbon atoms arranged into a honeycomb lattice where each carbon atom forms covalent bonds with three neighboring carbons [2] . Due to its two-dimensional nature, graphene shows high carrier mobility [3] , thermal conductivity [4] , mechanical strength [5] , optical transparency [6] , and flexibility [7] . These remarkable properties make graphene promising candidates for future nanoelectronic devices [8] .
 
Graphene nanoribbons (G-NR), i.e., strips of graphene with finite width [9] , have been proposed as building blocks for various applications including transistors [10] , interconnects [11] , photodetectors [12] , solar cells [13] , sensors [14] , etc.. Compared to conventional silicon-based electronics [15] , GNRs offer many advantages [16] : they exhibit higher electron mobilities [17] ; they allow better control over the charge carriers [18] ; they provide more design freedom [19] ; and they enable new functionality [20] . However, there still exist some challenges associated with practical realization of GNRs [21] . For example, the fabrication process requires precise control of ribbon width [22] and edge roughness [23] . Moreover, the electrical properties of GNRs depend sensitively",arxiv,bigscience bloomz,705.0556,0.6111111111111112,0.6470588235294118,0.35384615384615387,0.9053989488772097,1,1,0,0,0,1,1,1,0,1,0.06355122373558042,0.12027049156360956,0.07782101167315175,0.14015151515151514,0,1,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"The Use of ITIL for Process Optimisation in the IT Service Centre of Harz University, exemplified in the Release Management Process","  This paper details the use of the IT Infrastructure Library Framework (ITIL)
for optimising process workflows in the IT Service Centre of Harz University in
Wernigerode, Germany, exemplified by the Release Management Process. It is
described, how, during the course of a special ITIL project, the As-Is-Status
of the various original processes was documented as part of the process life
cycle and then transformed in the To-Be-Status, according to the ITIL Best
Practice Framework. It is also shown, how the ITIL framework fits into the
four-layered-process model, that could be derived from interviews with the
universities IT support staff, and how the various modified processes
interconnect with each other to form a value chain. The paper highlights the
final results of the project and gives an outlook on the future use of ITIL as
a business modelling tool in the IT Service Centre of Harz University. It is
currently being considered, whether the process model developed during the
project could be used as a reference model for other university IT centres.
","The purpose of this study is to examine how an organisation can use Information Technology Infrastructure Library (ITIL) as a process optimisation tool within its service centre environment. The research focuses on the release management process at the IT service centre of Harz University and examines whether it complies with all relevant aspects of the ITIL framework. A case study approach was used to collect data through interviews and document analysis. This article presents the results of the investigation into the current state of the release management process at Harz University's IT service centre. It also provides recommendations for improving the process based on the findings. Keywords: information technology infrastructure library, process optimization, release management process, university, IT service centre, case study method. 1 Introduction Today, universities are increasingly relying on their computer systems to support teaching and research activities. As such, they need reliable services that meet user requirements [1] . However, many universities have experienced problems related to poor quality software releases [2] , which may lead to system failures or even loss of data [3] .
In order to avoid these issues, organisations should implement appropriate processes [4] . One widely accepted set of guidelines for managing information technology (IT) services is provided by the Information Technology Infrastructure Library [5] . According to [6] , ITIL has been adopted by more than 80% of Fortune 500 companies worldwide since 2003.",arxiv,bigscience bloomz,705.2351,0.2222222222222222,0.546218487394958,0.24615384615384617,0.621595795508839,1,1,0,0,0,1,0,1,0,1,0.06749836107875828,0.05311829144817537,0.042801556420233464,0.04924242424242424,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
A study of the $p d \to p d \eta$ reaction,"  A study of the $p d \to p d \eta$ reaction in the energy range where the
recent data from Uppsala are available, is done in the two-step model of $\eta$
production including the final state interaction. The $\eta -d$ final state
interaction is incorporated through the solution of the Lippmann Schwinger
equation using an elastic scattering matrix element, $T_{\eta d \to \eta d}$,
which is required to be half off-shell. It is written in a factorized form,
with an off-shell form factor multiplying an on-shell part given by an
effective range expansion up to the fourth power in momentum. The parameters of
this expansion have been taken from an existing recent relativistic Faddeev
equation solution for the $\eta NN$ system corresponding to different $\eta-N$
scattering amplitudes. Calculations have also been done using few body
equations within a finite rank approximation (FRA) to generate $T_{\eta d \to
\eta d}$. The $p-d$ final state interaction is included in the spirit of the
Watson-Migdal prescription by multiplying the matrix element by the inverse of
the Jost function. The $\eta-d$ interaction is found to be dominant in the
region of small invariant $\eta -d$ mass, $M_{\eta d}$. The $p-d$ interaction
enhances the cross section in the whole region of $M_{\eta d}$, but is larger
for large $M_{\eta d}$. We find nearly isotropic angular distributions of the
proton and the deuteron in the final state. All the above observations are in
agreement with data. The production mechanism for the entire range of the
existing data on the $p d \to p d \eta$ reaction seems to be dominated by the
two-step model of $\eta$ production.
","We have studied the $^{p}_{d}$ elastic scattering at low energies in order to extract information on the nucleon-nucleon interaction and its off-shell behavior.  We used an effective Lagrangian approach with one-boson exchange potentials for the mesons, which are constrained by experimental data. The results obtained show that the inclusion of the pion-exchange potential is essential to reproduce correctly the phase shifts up to about 100 MeV/c. 
The analysis performed shows also that the contribution coming from the rho-meson exchange gives rise to a repulsive effect in the nuclear force, while the omega-meson exchange produces attractive effects. Finally we have calculated the cross section for the process $$^{p}_{d} \to ^{p}_d\eta$$ using the same formalism as before. Our results agree well with those reported recently by other authors. In this work we present some new results concerning the calculation of the cross sections for the processes $$^{p}_{d} \rightarrow ^{p}_d \eta$$  and $$^{p}_{d} \leftarrow ^{p}_d \gamma$$ . These reactions can be considered as complementary probes of the nucleonnucleon interaction since they involve different spin states (scalar versus vector) and different orbital angular momenta (zero versus one).",arxiv,bigscience bloomz,704.153,0.5555555555555556,0.3445378151260504,0.7589743589743589,0.47826086956521746,1,1,0,0,0,1,1,0,0,0,0.09174242401297053,0.10760425343322623,0.10116731517509728,0.1590909090909091,1,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
Sharp $L^p$-estimates for maximal operators associated to hypersurfaces in $\bR^3$ for $p>2.$,"  We study the boundedness problem for maximal operators $\M$ associated to
smooth hypersurfaces $S$ in 3-dimensional Euclidean space. For $p>2,$ we prove
that if no affine tangent plane to $S$ passes through the origin and $S$ is
analytic, then the associated maximal operator is bounded on $L^p(\RR^3)$ if
and only if $p>h(S),$ where $h(S)$ denotes the so-called height of the surface
$S.$ For non-analytic finite type $S$ we obtain the same statement with the
exception of the exponent $p=h(S).$ Our notion of height $h(S)$ is closely
related to A. N. Varchenko's notion of height $h(\phi)$ for functions $\phi$
such that $S$ can be locally represented as the graph of $\phi$ after a
rotation of coordinates.
  Several consequences of this result are discussed. In particular we verify a
conjecture by E.M. Stein and its generalization by A. Iosevich and E. Sawyer on
the connection between the decay rate of the Fourier transform of the surface
measure on $S$ and the $L^p$-boundedness of the associated maximal operator
$\M$, and a conjecture by Iosevich and Sawyer which relates the
$L^p$-boundedness of $\M$ to an integrability condition on $S$ for the distance
function to tangential hyperplanes, in dimension three.
  In particular, we also give ess. sharp uniform estimates for the Fourier
transform of the surface measure on $S,$ thus extending a result by V.N.
Karpushkin from the analytic to the smooth setting and implicitly verifying a
conjecture by V.I. Arnol'd in our context.
","In this article, we prove sharp Lp estimates for the maximal operator associated with the surface measure on a closed convex surface in R3 when p>2.  We also show that these results are optimal by constructing examples where the bounds cannot be improved. The main tool used is an extension theorem due to Coifman and Weiss which allows us to reduce matters to studying the case of surfaces contained in planes. This reduction leads naturally to consideration of certain singular integral operators whose kernels have been studied extensively over the past several decades. In particular, we use recent work of David Jerison and Michael Loss concerning the behavior of such operators near their singularities. Finally, we apply our results to obtain new information about the regularity properties of solutions to the Dirichlet problem for Laplace's equation on bounded domains in R3. Our results can be viewed as extensions of earlier work done by Kenig and Stein who proved similar results for the unit sphere in R4.",arxiv,bigscience bloomz,706.1006,0.3888888888888889,0.29411764705882354,0.5948717948717949,0.4295269947443861,1,1,0,0,1,0,0,0,0,1,0.47734479257351214,0.03060353689365952,0.5642023346303502,0.026515151515151516,3,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Analysis of long range order,"  A first principles analysis of order-disorder transition in alloys shows that
ordering energy is a function of temperature due to thermal vibrations. The
inter-nuclear potential energy term converges if zero point vibrations are
incorporated and this method can replace the Ewald sum method. Core energy
contributions to the ordering energy are stored exclusively in superlattice
lines. The effect of electron-phonon interactions on ordering energy is of the
same order of magnitude as ordering energy near transition temperatures and
cannot be ignored. Ising model and variants are incorrect in explaining alloy
phase transitions as they ignore the role of electron-phonon interactions
without justification. A theoretical formalism that incorporates the
Debye-Waller Factor component of electron-phonon interactions in electronic
structure calculations already exists and must be adopted when modeling
temperature dependent phenomena. It is suggested that DWF correction will
account substantially for the discrepancy between experimental and theoretical
ordering energy in Ni3V. Thermal vibrations alter magnetic ordering energy at
finite temperatures. The role of electron-phonon interactions in alloy and
magnetic phase transitions cannot be ignored and must be incorporated in all
models. This will also ensure consistency with x-ray and electron diffraction
(alloy transitions) and neutron diffraction (magnetic transitions) results. An
isotope effect is predicted for (magnetic) phase transitions if the transition
temperature is below Debye temperature. Recent observations of an isotope
effect in magnetic phase transitions confirm our above conclusions and imply
that the role of electron-phonon interactions must be incorporated in all
theories and models of magnetism to avoid contradictions.
","The concept of long-range order is central to the understanding of many physical phenomena, including phase transitions and critical behavior in statistical mechanics.  In this article we present an analysis of the mathematical foundations for the study of such systems.   We begin by introducing the notion of a measure-preserving transformation on a probability space (X, \Sigma, \mu) as well as that of a measurable partition of X into subsets with equal probabilities.    Next, we define the entropy H(T) associated with T as the supremum over all possible values of the Shannon information content of any finite collection of sets belonging to some fixed partition P of X.   Finally, we introduce the Kolmogorov-Sinai entropy hKS(T), which measures the rate at which information can be produced by observing the evolution of the system under consideration.   The main result presented here shows how these two quantities are related through the use of conditional entropies.",arxiv,bigscience bloomz,705.4382,0.6111111111111112,0.24369747899159663,0.6461538461538462,0.38652651696129964,1,1,0,0,0,1,1,0,0,0,0.06038087534747853,0.07123417112856462,0.0622568093385214,0.056818181818181816,1,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1
Discovery of extreme asymmetry in the debris disk surrounding HD 15115,"  We report the first scattered light detection of a dusty debris disk
surrounding the F2V star HD 15115 using the Hubble Space Telescope in the
optical, and Keck adaptive optics in the near-infrared. The most remarkable
property of the HD 15115 disk relative to other debris disks is its extreme
length asymmetry. The east side of the disk is detected to ~315 AU radius,
whereas the west side of the disk has radius >550 AU. We find a blue optical to
near-infrared scattered light color relative to the star that indicates grain
scattering properties similar to the AU Mic debris disk. The existence of a
large debris disk surrounding HD 15115 adds further evidence for membership in
the Beta Pic moving group, which was previously argued based on kinematics
alone. Here we hypothesize that the extreme disk asymmetry is due to dynamical
perturbations from HIP 12545, an M star 0.5 degrees (0.38 pc) east of HD 15115
that shares a common proper motion vector, heliocentric distance, galactic
space velocity, and age.
","We report on new observations made with the Hubble Space Telescope (HST) that reveal an extremely asymmetric distribution of dust around the young star HD 15115, located at a distance of about 150 light-years away in the constellation Pictor.  The images show two bright lobes extending to distances greater than 100 AU and separated by more than 50 AU along the major axis of the system's circumstellar disk. We interpret these features as evidence for recent planet formation activity within this protoplanetary disk. This is one of only three known cases where such structures have been observed directly; all other examples are inferred indirectly through modeling or scattered-light imaging techniques. These results provide important constraints on models of planet formation and migration. In addition, we find no evidence for any significant amount of cold dust beyond 250 AU from the central star. Our findings suggest that the outer regions of protoplanetary disks may be cleared out much faster than previously thought.",arxiv,bigscience bloomz,704.0645,0.2777777777777778,0.29411764705882354,0.24615384615384617,0.41519350215002393,1,1,0,0,0,1,1,1,0,1,0.08502043079117372,0.0807375951216303,0.06614785992217899,0.045454545454545456,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Spitzer observations of a 24 micron shadow: Bok Globule CB190,"  We present Spitzer observations of the dark globule CB190 (L771). We observe
a roughly circular 24 micron shadow with a 70 arcsec radius. The extinction
profile of this shadow matches the profile derived from 2MASS photometry at the
outer edges of the globule and reaches a maximum of ~32 visual magnitudes at
the center. The corresponding mass of CB190 is ~10 Msun. Our 12CO and 13CO J =
2-1 data over a 10 arcmin X 10 arcmin region centered on the shadow show a
temperature ~10 K. The thermal continuum indicates a similar temperature for
the dust. The molecular data also show evidence of freezeout onto dust grains.
We estimate a distance to CB190 of 400 pc using the spectroscopic parallax of a
star associated with the globule. Bonnor-Ebert fits to the density profile, in
conjunction with this distance, yield xi_max = 7.2, indicating that CB190 may
be unstable. The high temperature (56 K) of the best fit Bonnor-Ebert model is
in contradiction with the CO and thermal continuum data, leading to the
conclusion that the thermal pressure is not enough to prevent free-fall
collapse. We also find that the turbulence in the cloud is inadequate to
support it. However, the cloud may be supported by the magnetic field, if this
field is at the average level for dark globules. Since the magnetic field will
eventually leak out through ambipolar diffusion, it is likely that CB190 is
collapsing or in a late pre-collapse stage.
","We report the detection of an infrared dark cloud (IRDC) in the vicinity of the open cluster NGC 6334, using data obtained with Spitzer Space Telescope's Infrared Array Camera (IRAC). The IRDC is associated with the molecular cloud complex G327.3+0.6 and has been identified as Bok globule CB190 by Clemens & Barvainis (1988) . We find that this object exhibits a prominent 24 micron shadow which may be caused by absorption against bright mid-infrared emission from nearby protostars or young stellar objects. This feature suggests that the cloud contains dense cores at different evolutionary stages. Using near-infrared extinction mapping we identify two candidate starless cores within the cloud. These are located near the center of the cloud where the 24 micron shadow is most pronounced. Our analysis shows that these cores have masses between 0.5 Msun to 1 Msun and radii ranging from 1000 AU to 3000 AU .",arxiv,bigscience bloomz,705.224,0.6111111111111112,0.29411764705882354,0.6205128205128205,0.38079311992355475,1,1,0,0,0,1,1,0,0,1,0.09279585579412762,0.06556883970859034,0.10505836575875487,0.041666666666666664,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Testing Explanations of the $B\to\phi K^*$ Polarization Puzzle,"  $B\to\phi K^*$ ($\btos$) is three separate decays, one for each polarization
of the final-state vector mesons (one longitudinal, two transverse). It is
observed that the fraction of transverse decays, $\fT$, and the fraction of
longitudinal decays, $\fL$, are roughly equal: $\fTfL \simeq 1$, in opposition
to the naive expectation that $\fT \ll \fL$. If one requires a single
explanation of all polarization puzzles, two possibilities remain within the
standard model: penguin annihilation and rescattering. In this paper we examine
the predictions of these two explanations for $\fTfL$ in $\btod$ decays. In $B
\to \rho\rho$ decays, only $\bd \to \rho^0\rho^0$ can possibly exhibit a large
$\fTfL$. In B decays related by U-spin, we find two promising possibilities:
(i) $B^+ \to K^{*0} \rho^+$ ($\btos$) and $B^+ \to \Kbar^{*0} K^{*+}$ ($\btod$)
and (ii) $\bs \to K^{*0} \Kbar^{*0}$ ($\btos$) and $\bd \to \Kbar^{*0} K^{*0}$
($\btod$). The measurement of $\fTfL$ in these pairs of decays will allow us to
test penguin annihilation and rescattering. Finally, it is possible to
distinguish penguin annihilation from rescattering by performing a
time-dependent angular analysis of $\bd \to \Kbar^{*0} K^{*0}$.
","We present new measurements of the longitudinal polarization fraction $f_L$ in B meson decays to $\phi K^*$ final states, using data collected by the Belle experiment at KEKB with an integrated luminosity of 711 fb-1. We measure $f_L = 0.65 \pm 0.04(stat) \pm 0.03(syst),$ which is consistent with previous results and indicates that there are no large contributions from physics beyond the Standard Model. 
 
 The measurement was performed on $^{B}_{s \to \phi K^*}$ events where one or both kaons were identified as charged pions (K+/-). This method allows for a precise determination of the decay time distribution without relying on Monte Carlo simulation techniques. Using this technique we find that the measured value of $f_L$ does not depend strongly on the choice of fitting range used to extract it. In addition, we perform a study of systematic uncertainties associated with our analysis procedure.",arxiv,bigscience bloomz,705.3915,0.3888888888888889,0.24369747899159663,0.2923076923076923,0.3635929288103201,1,1,1,0,0,1,1,0,0,0,0.2261211479276125,0.08047660440964952,0.28793774319066145,0.03787878787878788,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
"Reparametrization Invariance, the controversial extraction of $\alpha$ from $B\to\pi\pi$ and New Physics","  The extraction of the weak phase $\alpha$ from $B\to\pi\pi$ decays has been
controversial from a statistical point of view, as the frequentist vs. bayesian
confrontation shows. We analyse several relevant questions which have not
deserved full attention and pervade the extraction of $\alpha$.
Reparametrization Invariance proves appropriate to understand those issues. We
show that some Standard Model inspired parametrizations can be senseless or
inadequate if they go beyond the minimal Gronau and London assumptions: the
single weak phase $\alpha$ just in the $\Delta I=3/2$ amplitudes, the isospin
relations and experimental data. Beside those analyses, we extract $\alpha$
through the use of several adequate parametrizations, showing that there is no
relevant discrepancy between frequentist and bayesian results. The most
relevant information, in terms of $\alpha$, is the exclusion of values around
$\alpha\sim \pi/4$; this result is valid in the presence of arbitrary New
Physics contributions to the $\Delta I=1/2$ piece.
","We present an overview of our recent work on extracting information about physics beyond the Standard Model (SM) from B-decay data.  We discuss how to extract the weak phase angle $\Delta\alpha = \alpha_s - \alpha_W$ in the SM from measurements of CP asymmetries in decays such as $B \to \pi \pi$ using reparametrization invariance.  This method is based on the fact that the decay amplitudes for these processes are invariant under certain transformations which leave their physical properties unchanged.   The extracted value of $\Delta\alpha$ can then be compared with theoretical predictions obtained within specific extensions of the SM.  We also show how this approach allows one to test whether new physics contributions to the decay amplitude violate or preserve flavor symmetry.  Finally we comment on some of the difficulties associated with applying this technique experimentally. A more detailed discussion of these issues will appear elsewhere. [1]  [2] . 
[3]  [4]",arxiv,bigscience bloomz,704.0174,0.2777777777777778,0.3949579831932773,0.13333333333333333,0.3836598184424272,0,0,1,0,0,1,1,0,0,0,0.12461110652705716,0.08306958978992941,0.14785992217898833,0.03787878787878788,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The effect of stellar-mass black holes on the structural evolution of massive star clusters,"  We present the results of realistic N-body modelling of massive star clusters
in the Magellanic Clouds, aimed at investigating a dynamical origin for the
radius-age trend observed in these systems. We find that stellar-mass black
holes, formed in the supernova explosions of the most massive cluster stars,
can constitute a dynamically important population. If a significant number of
black holes are retained (here we assume complete retention), these objects
rapidly form a dense core where interactions are common, resulting in the
scattering of black holes into the cluster halo, and the ejection of black
holes from the cluster. These two processes heat the stellar component,
resulting in prolonged core expansion of a magnitude matching the observations.
Significant core evolution is also observed in Magellanic Cloud clusters at
early times. We find that this does not result from the action of black holes,
but can be reproduced by the effects of mass-loss due to rapid stellar
evolution in a primordially mass segregated cluster.
","We study how the presence of a central supermassive black hole (SMBH) affects the dynamical evolution and mass loss rate of an open cluster with N = 10, 000 stars in virial equilibrium. We use direct N-body simulations to follow the long-term evolution of this system for up to 1 Gyr. The SMBH is modeled as a point particle that interacts gravitationally only with the most bound particles of each star cluster orbiting it. Our results show that the presence of the SMBH causes significant changes in the structure of the open cluster over time. In particular, we find that:  -The open cluster loses about half its initial total mass within 0.5 Gyr due to tidal stripping by the SMBH.  -The open cluster becomes more spherical after being tidally stripped by the SMBH. -The open cluster develops a core-halo structure where the density profile follows a power law at large radii but has a flat distribution near the center.",arxiv,bigscience bloomz,704.2494,0.2777777777777778,0.29411764705882354,0.2,0.4094601051122791,1,1,0,0,0,1,1,1,0,0,0.1141369912212494,0.056197278632862044,0.12062256809338522,0.05303030303030303,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0
A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA Networks with Delay QoS Constraints,"  A game-theoretic framework is used to study the effect of constellation size
on the energy efficiency of wireless networks for M-QAM modulation. A
non-cooperative game is proposed in which each user seeks to choose its
transmit power (and possibly transmit symbol rate) as well as the constellation
size in order to maximize its own utility while satisfying its delay
quality-of-service (QoS) constraint. The utility function used here measures
the number of reliable bits transmitted per joule of energy consumed, and is
particularly suitable for energy-constrained networks. The best-response
strategies and Nash equilibrium solution for the proposed game are derived. It
is shown that in order to maximize its utility (in bits per joule), a user must
choose the lowest constellation size that can accommodate the user's delay
constraint. This strategy is different from one that would maximize spectral
efficiency. Using this framework, the tradeoffs among energy efficiency, delay,
throughput and constellation size are also studied and quantified. In addition,
the effect of trellis-coded modulation on energy efficiency is discussed.
","In this work, we propose an energy-efficient modulation scheme for downlink transmission over code division multiple access (CDMA) networks by exploiting the inherent multiuser diversity and delay requirements. We formulate the problem as a noncooperative game between users competing for limited power resources under their individual delay constraints. The proposed algorithm is shown to converge to Nash equilibrium points that are Pareto optimal solutions to the formulated optimization problems. Numerical results show that our approach can significantly improve system performance compared to existing schemes. In particular, it achieves higher data rates while maintaining low outage probabilities at different signal-to-noise ratios. 
 
 Keywords: Code Division Multiple Access, Noncooperative Games, Power Allocation, Energy Efficiency, Multiuser Diversity, Delay Constraint. 1 Introduction 
 
 With the rapid growth of wireless communication systems such as mobile phones and personal digital assistants, there has been increasing interest in developing efficient resource allocation algorithms to maximize network capacity or minimize total transmit power consumption [1] . For example, [2] considers joint subcarrier and bit allocations among users in orthogonal frequency-division multiplexing (OFDM)-based broadband wireless networks using Lagrangian relaxation techniques; [3] proposes a distributed algorithm based on dual decomposition theory to solve the sum-power minimization problem subject to rate constraints in OFDMA cellular networks; [4] develops a low-complexity iterative water-filling algorithm to optimize the tradeoff between spectral efficiency and fairness in multi-cell OFDMA networks. However, these works do not consider user-specific delay requirements which may be important in some applications like voice communications. To address this issue, [5] presents a cross-layer design framework where packet scheduling decisions are made jointly across physical layer, MAC layer, and application layer according to both channel conditions and end-to-end delay requirements. [6] studies the problem of maximizing the weighted sum-rate of all users in a single-cell uplink scenario with per-user delay constraints. It shows that the resulting optimization problem is NP-hard and then solves it via convex programming methods. Although these works have considered various aspects of resource allocation in wireless networks, they",arxiv,bigscience bloomz,705.1788,0.3888888888888889,0.596638655462185,0.2358974358974359,0.8939321548017201,1,1,0,0,1,1,1,1,0,0,0.10186389585875427,0.14872733367601687,0.08560311284046693,0.20833333333333334,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
"Bayesian reconstruction of the cosmological large-scale structure: methodology, inverse algorithms and numerical optimization","  We address the inverse problem of cosmic large-scale structure reconstruction
from a Bayesian perspective. For a linear data model, a number of known and
novel reconstruction schemes, which differ in terms of the underlying signal
prior, data likelihood, and numerical inverse extra-regularization schemes are
derived and classified. The Bayesian methodology presented in this paper tries
to unify and extend the following methods: Wiener-filtering, Tikhonov
regularization, Ridge regression, Maximum Entropy, and inverse regularization
techniques. The inverse techniques considered here are the asymptotic
regularization, the Jacobi, Steepest Descent, Newton-Raphson,
Landweber-Fridman, and both linear and non-linear Krylov methods based on
Fletcher-Reeves, Polak-Ribiere, and Hestenes-Stiefel Conjugate Gradients. The
structures of the up-to-date highest-performing algorithms are presented, based
on an operator scheme, which permits one to exploit the power of fast Fourier
transforms. Using such an implementation of the generalized Wiener-filter in
the novel ARGO-software package, the different numerical schemes are
benchmarked with 1-, 2-, and 3-dimensional problems including structured white
and Poissonian noise, data windowing and blurring effects. A novel numerical
Krylov scheme is shown to be superior in terms of performance and fidelity.
These fast inverse methods ultimately will enable the application of sampling
techniques to explore complex joint posterior distributions. We outline how the
space of the dark-matter density field, the peculiar velocity field, and the
power spectrum can jointly be investigated by a Gibbs-sampling process. Such a
method can be applied for the redshift distortions correction of the observed
galaxies and for time-reversal reconstructions of the initial density field.
","We present an overview of our recent work on Bayesian methods for reconstructing the large scale structures in the universe using galaxy redshift surveys. We discuss how to formulate this problem as a statistical inference task with priors that encode physical information about the underlying matter distribution. The posterior probability density function is then evaluated by applying Bayes' theorem together with Markov Chain Monte Carlo (MCMC) sampling techniques. In particular we focus on two different approaches which are based either on Gibbs sampling or Metropolis-Hastings algorithm. Finally we describe some applications of these methods to simulated data sets. This research was supported by NSF grant AST-0707763. Cosmology has been revolutionized over the past decade by precision measurements of the cosmic microwave background anisotropies made by WMAP [1] , PLANCK [2] and other experiments [3] . These observations have provided strong evidence for the existence of dark energy [4] and have led to tight constraints on many parameters describing the physics of the early universe [5] .
However, despite their successes there remain several open questions regarding fundamental aspects of the standard model of cosmology [6] . One such question concerns the nature of dark matter [7, 8] : what is its particle content? What is its mass? How does it interact with ordinary matter?
Answering these questions requires detailed knowledge of the spatial distribution of dark matter throughout space and time [9] . Unfortunately direct detection experiments [10] cannot provide this information because they only measure the gravitational effects of dark matter particles [11] . Instead one must rely on indirect probes like galaxy clustering [12] , weak lensing [13] and 21 cm emission [14] .",arxiv,bigscience bloomz,705.0429,0.5,0.6974789915966387,0.6410256410256411,0.7448638318203535,0,1,1,0,0,1,1,1,1,1,0.08433715751233607,0.0737293202030306,0.0933852140077821,0.08333333333333333,0,3,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A Surprising Reversal of Temperatures in the Brown-Dwarf Eclipsing Binary 2MASS J05352184-0546085,"  The newly discovered brown-dwarf eclipsing binary 2MASS J05352184-0546085
provides a unique laboratory for testing the predictions of theoretical models
of brown-dwarf formation and evolution. The finding that the lower-mass brown
dwarf in this system is hotter than its higher-mass companion represents a
challenge to brown-dwarf evolutionary models, none of which predict this
behavior. Here we present updated determinations of the basic physical
properties of 2M0535-05, bolstering the surprising reversal of temperatures
with mass in this system. We compare these measurements with widely used
brown-dwarf evolutionary tracks, and find that the temperature reversal can be
explained by some models if the components of 2M0535-05 are mildly non-coeval,
possibly consistent with dynamical simulations of brown-dwarf formation.
Alternatively, a strong magnetic field on the higher-mass brown dwarf might
explain its anomalously low surface temperature, consistent with emerging
evidence that convection is suppressed in magnetically active, low-mass stars.
Finally, we discuss future observational and theoretical work needed to further
characterize and understand this benchmark system.
","We report on an unexpected reversal of temperatures between two components of a brown-dwarf eclipsing binary system, which we have discovered using infrared photometry and spectroscopy obtained with Spitzer Space Telescope (Werner et al., 2004) and Gemini Observatory (Gemini North telescope). The primary component is cooler than its secondary by about 300 K at optical wavelengths but warmer by about 100 K at near-infrared wavelengths. We find that this temperature inversion can be explained if both stars are irradiated by their mutual accretion disk. This finding suggests that the disks around young low-mass objects may be more complex than previously thought. 
 
 Keywords: Accretion Disk, Inverse P-Cygni profile, Irradiation, Low-Mass Star, Near-Infrared Spectroscopy, Photometric variability, Stellar radius, Temperature inversion, Young star 
 
 
 
 1 Introduction 
 
 An important goal for understanding how planets form is to determine what happens during the earliest stages of planet formation when protoplanetary disks surround young stellar systems. One key question concerns whether or not these disks evolve into planetary systems like our own solar system. To answer such questions it will be necessary to study individual examples of young circumstellar disks as they evolve over time. However, because most young stars are deeply embedded within dense molecular clouds, direct observations of the inner regions of these disks are difficult. Fortunately, some young stars are surrounded by optically thin dusty envelopes that allow us to probe the physical conditions near the central object through scattered light. These so-called transitional disks show evidence of clearing out large amounts of material inside several AU of the central star while still retaining significant quantities of gas farther away (Strom et al., 1989; Skrutskie et al., 1990; Calvet et al., 2002; Muzerolle et al., 2003; Sicilia-Aguilar et al., 2006; Espaillat et al., 2007) . 
 
 A number of studies suggest that the outer edges of transitional disks are sculpted by photoevaporative winds driven off the surface of the disk by intense ultraviolet radiation from nearby",arxiv,bigscience bloomz,704.3106,0.2777777777777778,0.49579831932773116,0.19487179487179487,0.8738652651696129,0,1,0,0,0,1,1,1,0,0,0.06870266748002085,0.13986507605621368,0.0622568093385214,0.13636363636363635,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Anomalous structural and mechanical properties of solids confined in quasi one dimensional strips,"  We show using computer simulations and mean field theory that a system of
particles in two dimensions, when confined laterally by a pair of parallel hard
walls within a quasi one dimensional channel, possesses several anomalous
structural and mechanical properties not observed in the bulk. Depending on the
density $\rho$ and the distance between the walls $L_y$, the system shows
structural characteristics analogous to a weakly modulated liquid, a strongly
modulated smectic, a triangular solid or a buckled phase. At fixed $\rho$, a
change in $L_y$ leads to many reentrant discontinuous transitions involving
changes in the number of layers parallel to the confining walls depending
crucially on the commensurability of inter-layer spacing with $L_y$. The solid
shows resistance to elongation but not to shear. When strained beyond the
elastic limit it fails undergoing plastic deformation but surprisingly, as the
strain is reversed, the material recovers completely and returns to its
original undeformed state. We obtain the phase diagram from mean field theory
and finite size simulations and discuss the effect of fluctuations.
","We study the elasticity of thin films with periodic microstructure, which are constrained to lie on an underlying substrate. We show that such systems can exhibit anomalously large values for their Young's moduli as well as Poisson ratios. The origin of these effects is traced back to the presence of phonon soft modes associated with the periodicity along the film normal direction. These results have implications for the design of novel materials with tailored elastic properties. 
 
 In recent years there has been growing interest in understanding how confinement affects the physical behavior of matter at the nanoscale [1] . This problem arises naturally when considering thin films or nanowires embedded within bulk materials; however it also applies more generally whenever a system is restricted to occupy only part of its available phase space [2] . For example, this situation occurs frequently during crystal growth where defects may be introduced into the lattice structure by impurities [3] , or when studying colloidal suspensions [4] .
 
In this work we consider the case of a thin film with periodic microstructure, whose thickness h lies between two length scales L and d (see Fig 1) . Here L represents the typical size of the unit cell while d denotes the characteristic spacing between adjacent layers; both quantities are assumed to be much smaller than the in-plane dimensions of the sample. Such structures arise commonly in nature, e.g., in layered compounds like graphite [5] , transition metal dichalcogenides [6] , and hexagonal boron nitride [7] . They are also used extensively in technological applications ranging from photovoltaics [8] to optoelectronics [9] . 
 
 Figure 1: Schematic illustration of our model geometry. A thin film with periodic microstructures is confined to lie on top of a rigid substrate.",arxiv,bigscience bloomz,705.3135,0.2777777777777778,0.596638655462185,0.2512820512820513,0.7907310081223125,0,1,0,0,0,1,1,1,0,1,0.12807332686858916,0.07227286736829708,0.1245136186770428,0.03787878787878788,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
An Optical Source Catalog of the North Ecliptic Pole Region,"  We present a five (u*,g',r',i',z') band optical photometry catalog of the
sources in the North Ecliptic Pole (NEP) region based on deep observations made
with MegaCam at CFHT. The source catalog covers about 2 square degree area
centered at the NEP and reaches depths of about 26 mag for u*, g', r' bands,
about 25 mag for i' band, and about 24 mag for z' band (4 sigma detection over
an 1 arcsec aperture). The total number of cataloged sources brighter than r'=
23 mag is about 56,000 including both point sources and extended sources. From
the investigation of photometric properties using the color-magnitude diagrams
and color-color diagrams, we have found that the colors of extended sources are
mostly (u*-r') < 3.0 and (g'-z') > 0.5. This can be used to separate the
extended sources from the point sources reliably, even for the faint source
domain where typical morphological classification schemes hardly work
efficiently. We have derived an empirical color-redshift relation of the red
sequence galaxies using the Sloan Digital Sky Survey data. By applying this
relation to our photometry catalog and searching for any spatial overdensities,
we have found two galaxy clusters and one nearby galaxy group.
","We present an optical source catalog for the north ecliptic pole region (NEPR) based on data obtained with the Palomar Observatory Sky Survey (POSS-II). The NEPR is defined as the area within 10 degrees in right ascension and declination centered at RA = 20 h 00 m , Dec = +85 deg . We have used POSS-II plates taken between 1950 and 1990 to produce this catalog, which contains over 1 million sources down to B J = 22 mag .
The photometric calibration was performed using Landolt standard stars observed during the same nights that the sky survey plates were exposed. Photometry has been carried out by means of aperture photometry techniques. Magnitudes are given in the Johnson system. In addition we provide proper motions for all objects brighter than B J = 18 mag . This catalog will be useful for studies related to galactic structure and evolution. 
 
 Keywords: Palomar Observatory Sky Survey",arxiv,bigscience bloomz,704.1182,0.3333333333333333,0.3949579831932773,0.38461538461538464,0.39799331103678937,1,1,0,0,1,1,1,1,0,0,0.12455171007529474,0.07297425126354709,0.14007782101167315,0.022727272727272728,0,2,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On generalized entropy measures and pathways,"  Product probability property, known in the literature as statistical
independence, is examined first. Then generalized entropies are introduced, all
of which give generalizations to Shannon entropy. It is shown that the nature
of the recursivity postulate automatically determines the logarithmic
functional form for Shannon entropy. Due to the logarithmic nature, Shannon
entropy naturally gives rise to additivity, when applied to situations having
product probability property. It is argued that the natural process is
non-additivity, important, for example, in statistical mechanics, even in
product probability property situations and additivity can hold due to the
involvement of a recursivity postulate leading to a logarithmic function.
Generalizations, including Mathai's generalized entropy are introduced and some
of the properties are examined. Situations are examined where Mathai's entropy
leads to pathway models, exponential and power law behavior and related
differential equations. Connection of Mathai's entropy to Kerridge's measure of
""inaccuracy"" is also explored.
","We present an approach to the analysis of metabolic networks based on information-theoretic concepts, in particular Shannon's entropy measure. We show that this concept can be extended by considering not only single metabolites but also pairs or higher-order tuples of them as elementary units for measuring entropy. This leads us to define so-called pathway entropies which are used to quantify how much uncertainty is associated with different parts of the network. The proposed method allows one to identify those parts of the network where most of the uncertainty resides. In addition we introduce a novel way of visualizing metabolic networks using these new entropy-based quantities. Finally, we demonstrate our approach by applying it to two examples taken from biochemistry literature. Metabolic networks play important roles in many biological processes such as cell growth and development [1] . They consist of chemical reactions transforming various compounds into each other [2] , e.g., glucose molecules are transformed into energy-rich adenosine triphosphate (ATP) molecules via glycolysis [3] .
The study of metabolic networks has been attracting increasing interest over recent years [4] - [8] . One reason for this growing interest lies in their potential use as drug targets [9] . Another motivation comes from the fact that they provide valuable insights into cellular metabolism [10] . For example, the identification of key enzymes involved in certain diseases may help to develop drugs against these diseases [11] . Furthermore, metabolic networks have been shown to exhibit scale-free properties [12] similar to those observed in social systems [13] . These findings suggest that there might exist common principles underlying both types of networks [14] .
In order to understand the functioning of metabolic networks better, several mathematical models have been developed [15] - [17] . Amongst others, stoichiometric approaches [18] try to describe all possible states of a given metabolic system mathematically. However, due to the high number of degrees of freedom inherent in such models [19] , it becomes difficult to analyze large metabolic networks [20] . Therefore, alternative methods have been suggested [21] - [23] .",arxiv,bigscience bloomz,704.0326,0.3888888888888889,0.8487394957983193,0.1282051282051282,0.939799331103679,0,1,0,0,1,1,1,0,0,1,0.08206164081734948,0.04253796950567114,0.10116731517509728,0.045454545454545456,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Massive CP$^1$ theory from a microscopic model for doped antiferromagnets,"  A path-integral for the t-J model in two dimensions is constructed based on
Dirac quantization, with an action found originally by Wiegmann (Phys. Rev.
Lett. {\bf 60}, 821 (1988); Nucl. Phys. B323, 311 (1989)). Concentrating on the
low doping limit, we assume short range antiferromagnetic order of the spin
degrees of freedom. Going over to a local spin quantization axis of the dopant
fermions, that follows the spin degree of freedom, staggered CP$^1$ fields
result and the constraint against double occupancy can be resolved. The
staggered CP$^1$ fields are split into slow and fast modes, such that after a
gradient expansion, and after integrating out the fast modes and the dopant
fermions, a CP$^1$ field-theory with a massive gauge field is obtained that
describes generically incommensurate coplanar magnetic structures, as discussed
previously in the context of frustrated quantum antiferromagnets. Hence, the
possibility of deconfined spinons is opened by doping a colinear
antiferromagnet.
","We propose an explicit microscopic model for the recently proposed massive CP$^1$ theory, which is based on the idea that the Higgs field arises as a collective mode in strongly correlated systems with spontaneously broken symmetry.  We show how this can be realized by considering a system of fermions coupled to bosonic degrees of freedom via a four-fermion interaction term and derive the effective action for the Higgs field. The resulting Higgs potential has two degenerate minima corresponding to the vacuum expectation values $\langle H \rangle = \pm v_0$ where $v_0 \sim J$ (the strength of the coupling between the fermions and bosons) and $J > 0$ is determined self-consistently within our approach. In addition we find that there are no massless excitations associated with the Higgs field. Finally, we discuss possible experimental realizations of such a scenario using cold atoms or trapped ions. Introduction - Recently it was suggested [1] that the Standard Model Higgs field may arise as a collective mode in a class of strongly correlated systems with spontaneusly broken symmetry. This proposal relies on the observation [2] that the Higgs mechanism can be understood as arising from the condensation of bound states of fermions into bosonic particles [3] . It follows then that if one could engineer a system of fermions interacting with some other degree(s) of freedom so that these bound states condense, then one would have spontaneous breaking of gauge symmetry and hence a Higgs-like state. A concrete realization of this idea was given in Ref. [4] , where it was shown that the Higgs field emerges naturally when one considers a system of fermions with spin-1/2 coupled to bosonic degrees",arxiv,bigscience bloomz,705.1918,0.5,0.4453781512605043,0.14871794871794872,0.747730530339226,1,1,1,0,0,1,1,0,0,0,0.18472367038329207,0.10798286716549056,0.19844357976653695,0.125,4,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Connecting LHC, ILC, and Quintessence","  If the cold dark matter consists of weakly interacting massive particles
(WIMPs), anticipated measurements of the WIMP properties at the Large Hadron
Collider (LHC) and the International Linear Collider (ILC) will provide an
unprecedented experimental probe of cosmology at temperatures of order 1 GeV.
It is worth emphasizing that the expected outcome of these tests may or may not
be consistent with the picture of standard cosmology. For example, in
kination-dominated quintessence models of dark energy, the dark matter relic
abundance can be significantly enhanced compared to that obtained from freeze
out in a radiation-dominated universe. Collider measurements then will
simultaneously probe both dark matter and dark energy. In this article, we
investigate the precision to which the LHC and ILC can determine the dark
matter and dark energy parameters under those circumstances. We use an
illustrative set of four benchmark points in minimal supergravity in analogy
with the four LCC benchmark points. The precision achievable together at the
LHC and ILC is sufficient to discover kination-dominated quintessence, under
the assumption that the WIMPs are the only dark matter component. The LHC and
ILC can thus play important roles as alternative probes of both dark matter and
dark energy.
","We propose to connect the Large Hadron Collider (LHC) with an International Linear Collider (ILC), which will be built in Japan or Korea, by using quintessence as dark energy.  We show that this connection is possible if we assume that the universe has been expanding at a constant rate for about 10 billion years since its birth. The expansion speed of the universe can then be determined by measuring the time delay between signals emitted simultaneously from distant galaxies observed today and those emitted from them when they were closer together during their youthful days. This measurement would provide us with information on how much dark energy there was back then. If our proposal turns out to be correct, it may lead to new insights into the nature of dark energy. In addition, it could also shed light on why the universe looks so different now than what it looked like just after its birth. It might even help explain why the universe appears to have evolved in such a way that life forms are able to exist here on Earth.",arxiv,bigscience bloomz,706.2375,0.3888888888888889,0.29411764705882354,0.38974358974358975,0.47252747252747257,1,1,0,0,0,1,0,0,0,0,0.10467523772915092,0.0586255020968074,0.10894941634241245,0.06818181818181818,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Near and Mid-IR Photometry of the Pleiades, and a New List of Substellar Candidate Members","  We make use of new near and mid-IR photometry of the Pleiades cluster in
order to help identify proposed cluster members. We also use the new photometry
with previously published photometry to define the single-star main sequence
locus at the age of the Pleiades in a variety of color-magnitude planes.
  The new near and mid-IR photometry extend effectively two magnitudes deeper
than the 2MASS All-Sky Point Source catalog, and hence allow us to select a new
set of candidate very low mass and sub-stellar mass members of the Pleiades in
the central square degree of the cluster. We identify 42 new candidate members
fainter than Ks =14 (corresponding to 0.1 Mo). These candidate members should
eventually allow a better estimate of the cluster mass function to be made down
to of order 0.04 solar masses.
  We also use new IRAC data, in particular the images obtained at 8 um, in
order to comment briefly on interstellar dust in and near the Pleiades. We
confirm, as expected, that -- with one exception -- a sample of low mass stars
recently identified as having 24 um excesses due to debris disks do not have
significant excesses at IRAC wavelengths. However, evidence is also presented
that several of the Pleiades high mass stars are found to be impacting with
local condensations of the molecular cloud that is passing through the Pleiades
at the current epoch.
","We present new near-infrared photometric data for the Pleiades open cluster obtained with the Infrared Survey Facility (IRSF) on the South African Astronomical Observatory's 1-m telescope at Sutherland in November 2005. The observations were made using the IRSF/SIRIUS camera which has simultaneous JHK s imaging capability over an 8 x8 field-of-view. We have also used archival 2MASS data to supplement our sample. Our results are presented as colour-magnitude diagrams (CMDs), where we show that there is good agreement between our photometry and previous studies. Using these CMDs, we identify several previously unreported candidate members of the Pleiades based upon their location relative to theoretical pre-main sequence evolutionary tracks. These candidates include two objects located near the substellar boundary, one of which appears to be a brown dwarf member of the Pleiades.",arxiv,bigscience bloomz,704.1832,0.3888888888888889,0.24369747899159663,0.558974358974359,0.32919254658385094,1,1,0,0,0,1,1,0,0,1,0.0916942888767814,0.05697047688726842,0.1245136186770428,0.03787878787878788,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Black Holes and Large N Species Solution to the Hierarchy Problem,"  We provide the perturbative and non-perturbative arguments showing that
theories with large number of species of the quantum fields, imply an
inevitable hierarchy between the masses of the species and the Planck scale,
shedding a different light on the hierarchy problem. In particular, using the
black hole physics, we prove that any consistent theory that includes N number
of the Z_2-conserved species of the quantum fields of mass \Lambda, puts a
lower bound on the Planck mass, which in large N limit is given by N\Lambda^2.
An useful byproduct of this proof is that any exactly conserved quantum charge,
not associated with a long-range classical field, must be defined maximum
modulo N, bounded by the the ratio of the Planck to the unit charge masses
squared. For example, a continuous global U(1) `baryon number' symmetry, must
be explicitly broken by gravity, at least down to a Z_N subgroup, with N
bounded by the ratio of the Planck to baryon masses squared. The same
constraint applies to any discrete gauge symmetry, as well as to other
quantum-mechanically detectable black hole charges that are associated with the
massive quantum hair of the black hole. We show that the
gravitationally-coupled N-species sector that solves the gauge hirearchy
problem, should be probed by LHC.
","The Standard Model (SM) is an extremely successful theory, but it has some problems that need to be addressed before we can claim to have found ""theory of everything"".  The SM does not explain why there are three generations of quarks and leptons with different masses or how neutrinos acquire mass. It also fails to provide any explanation for dark matter in our universe.   In this talk I will discuss my recent work on addressing these issues by introducing new particles into the SM which interact only gravitationally. These new particles are called gravitons and they carry spin-2 quantum number like graviton in general relativity. We show that if gravitons exist then their interactions with other fields lead to generation dependent masses for fermions as well as small Majorana masses for neutrinos. Gravitons also contribute to the energy density of the universe leading to possible solution to the problem of missing dark matter. Finally, we argue that gravitons may play important role in understanding hierarchy between Planck scale and electroweak scale.",arxiv,bigscience bloomz,706.205,0.2777777777777778,0.3445378151260504,0.4461538461538462,0.4438604873387483,1,1,0,0,1,1,1,0,0,0,0.09665426709335724,0.049309096468965315,0.05058365758754864,0.030303030303030304,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The host galaxies of strong CaII QSO absorption systems at z<0.5,"  We present new imaging and spectroscopic observations of the fields of five
QSOs with very strong intervening CaII absorption systems at redshifts z<0.5
selected from the Sloan Digital Sky Survey. Recent studies of these very rare
absorbers indicate that they may be related to damped Lyman alpha systems
(DLAs). In all five cases we identify a galaxy at the redshift of the CaII
system with impact parameters up to ~24 kpc. In four out of five cases the
galaxies are luminous (L ~L*), metal-rich (Z ~Zsun), massive (velocity
dispersion, sigma ~100 km/s) spirals. Their star formation rates, deduced from
Halpha emission, are high, in the range SFR = 0.3 - 30 Msun/yr. In our
analysis, we paid particular attention to correcting the observed emission line
fluxes for stellar absorption and dust extinction. We show that these effects
are important for a correct SFR estimate; their neglect in previous low-z
studies of DLA-selected galaxies has probably led to an underestimate of the
star formation activity in at least some DLA hosts. We discuss possible links
between CaII-selected galaxies and DLAs and outline future observations which
will help clarify the relationship between these different classes of QSO
absorbers.
","We have obtained deep optical spectra for eight QSOs with known redshifts in the range 0.4-0.5, and searched them for intervening Ca II absorbers using the equivalent width (EW) method. We find that all eight QSOs show strong Ca II absorptions associated with their own galaxy halos. The EWs are found to be correlated with the luminosities of the QSOs themselves. This correlation is consistent with previous results on Mg II absorbers but not with those on C IV absorbers. In addition we find that there exists an anti-correlation between the EWs and the impact parameters of the absorber-galaxy pairs. These results suggest that the Ca II absorbers may arise mainly from gaseous disks surrounding massive elliptical galaxies rather than from galactic winds driven by starburst activity. 
 
 
 
 Keywords: Absorber-galaxy pairs; Galaxy halo; Quasar; Redshift",arxiv,bigscience bloomz,705.3462,0.3888888888888889,0.29411764705882354,0.37435897435897436,0.3377926421404682,1,1,1,0,0,1,1,1,0,0,0.06066203733230514,0.06005880301174275,0.07003891050583658,0.04924242424242424,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Tests of Bayesian Model Selection Techniques for Gravitational Wave Astronomy,"  The analysis of gravitational wave data involves many model selection
problems. The most important example is the detection problem of selecting
between the data being consistent with instrument noise alone, or instrument
noise and a gravitational wave signal. The analysis of data from ground based
gravitational wave detectors is mostly conducted using classical statistics,
and methods such as the Neyman-Pearson criteria are used for model selection.
Future space based detectors, such as the \emph{Laser Interferometer Space
Antenna} (LISA), are expected to produced rich data streams containing the
signals from many millions of sources. Determining the number of sources that
are resolvable, and the most appropriate description of each source poses a
challenging model selection problem that may best be addressed in a Bayesian
framework. An important class of LISA sources are the millions of low-mass
binary systems within our own galaxy, tens of thousands of which will be
detectable. Not only are the number of sources unknown, but so are the number
of parameters required to model the waveforms. For example, a significant
subset of the resolvable galactic binaries will exhibit orbital frequency
evolution, while a smaller number will have measurable eccentricity. In the
Bayesian approach to model selection one needs to compute the Bayes factor
between competing models. Here we explore various methods for computing Bayes
factors in the context of determining which galactic binaries have measurable
frequency evolution. The methods explored include a Reverse Jump Markov Chain
Monte Carlo (RJMCMC) algorithm, Savage-Dickie density ratios, the Schwarz-Bayes
Information Criterion (BIC), and the Laplace approximation to the model
evidence. We find good agreement between all of the approaches.
","Gravitational wave astronomy is an emerging field that will provide new insights into the universe and its fundamental laws through observations of gravitational waves emitted by merging black holes, neutron stars or other compact objects in distant galaxies.  In this work we present several tests of different techniques used to select between competing models describing the observed data. We consider two examples where the signal-to-noise ratio (SNR) of the detected signals are low enough so that it becomes difficult to distinguish between different physical scenarios using standard frequentist hypothesis testing methods. The first example considers the problem of distinguishing between binary black hole systems with spin aligned versus anti-aligned with their orbital angular momentum vector. The second example considers the problem of determining whether a given source has been emitting gravitational radiation continuously over time as opposed to being active only during short bursts. For both cases we compare results obtained using three different model selection methods: Akaike's information criterion (AIC), Bayes factors computed via nested sampling (NS-BF), and the Deviance Information Criterion (DIC).",arxiv,bigscience bloomz,704.1808,0.6111111111111112,0.24369747899159663,0.7435897435897436,0.45246058289536556,1,1,0,0,0,1,1,1,0,1,0.07942989238657248,0.06237696706393506,0.10505836575875487,0.056818181818181816,1,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
New smooth hybrid inflation,"  We consider the extension of the supersymmetric Pati-Salam model which solves
the b-quark mass problem of supersymmetric grand unified models with exact
Yukawa unification and universal boundary conditions and leads to the so-called
new shifted hybrid inflationary scenario. We show that this model can also lead
to a new version of smooth hybrid inflation based only on renormalizable
interactions provided that a particular parameter of its superpotential is
somewhat small. The potential possesses valleys of minima with classical
inclination, which can be used as inflationary paths. The model is consistent
with the fitting of the three-year Wilkinson microwave anisotropy probe data by
the standard power-law cosmological model with cold dark matter and a
cosmological constant. In particular, the spectral index turns out to be
adequately small so that it is compatible with the data. Moreover, the
Pati-Salam gauge group is broken to the standard model gauge group during
inflation and, thus, no monopoles are formed at the end of inflation.
Supergravity corrections based on a non-minimal Kaehler potential with a
convenient choice of a sign keep the spectral index comfortably within the
allowed range without generating maxima and minima of the potential on the
inflationary path. So, unnatural restrictions on the initial conditions for
inflation can be avoided.
","We propose a new inflationary model, which is based on the idea that there are two scalar fields in nature and they interact with each other through their potentials. We call this model ""smooth hybrid inflation"" (SHI). In SHI, one field plays the role of the waterfall field while another field acts as an inflaton. The potential for our model has three parameters; we show how these parameters can be fixed by using observational data such as WMAP7+BAO+H0. Our results indicate that the tensor-to-scalar ratio r=0.0055+0.0005-0.0004 at 95% CL. This value is consistent with recent observations. Moreover, we find that the spectral index ns=1.0145+0.0025-0.0024 at 68% CL. Therefore, our model predicts values for both nS and r within 1 sigma error bars of current experimental bounds.",arxiv,bigscience bloomz,705.3786,0.3888888888888889,0.3445378151260504,0.4358974358974359,0.31485905398948877,0,1,0,0,0,1,1,1,0,0,0.0820351022598235,0.058558933019312275,0.08949416342412451,0.05303030303030303,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Polymer Quantum Mechanics and its Continuum Limit,"  A rather non-standard quantum representation of the canonical commutation
relations of quantum mechanics systems, known as the polymer representation has
gained some attention in recent years, due to its possible relation with Planck
scale physics. In particular, this approach has been followed in a symmetric
sector of loop quantum gravity known as loop quantum cosmology. Here we explore
different aspects of the relation between the ordinary Schroedinger theory and
the polymer description. The paper has two parts. In the first one, we derive
the polymer quantum mechanics starting from the ordinary Schroedinger theory
and show that the polymer description arises as an appropriate limit. In the
second part we consider the continuum limit of this theory, namely, the reverse
process in which one starts from the discrete theory and tries to recover back
the ordinary Schroedinger quantum mechanics. We consider several examples of
interest, including the harmonic oscillator, the free particle and a simple
cosmological model.
","The present work is devoted to the study of quantum mechanics in polymer chains, which are modeled as one-dimensional systems with nearest-neighbor interactions between particles.  We consider two different models for such systems:  The first model describes an ensemble of interacting fermions on a chain; it can be viewed as a generalization of the Hubbard model (which corresponds to spinless fermions) to include spin-dependent hopping amplitudes and repulsive interaction terms.  In this case we show that there exists a critical value U_c of the interaction strength above which the ground state energy per particle becomes negative.  This result implies that the ground state of the system undergoes a phase transition at U = U_c from a metallic-like phase into an insulating phase.   The second model considered here consists of bosons moving along a ring subject to periodic boundary conditions.  Here we prove rigorously that the ground-state energy per particle converges to zero when the number N of particles tends to infinity.  Moreover, we provide upper bounds on the rate of convergence towards the limit.  These results imply that the ground state of our system exhibits superfluid behavior.",arxiv,bigscience bloomz,704.0007,0.3333333333333333,0.3445378151260504,0.16923076923076924,0.4897276636407072,0,1,0,0,0,1,1,1,0,0,0.10054605317125674,0.09099687908788738,0.08949416342412451,0.07196969696969698,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1
SW Sextantis stars: the dominant population of CVs with orbital periods between 3-4 hours,"  [Abridged] We present time-series optical photometry of five new CVs
identified by the Hamburg Quasar Survey. The eclipses observed in HS 0129+2933,
HS 0220+0603, and HS 0455+8315 provided very accurate orbital periods of
3.35129827(65), 3.58098501(34), and 3.56937674(26) h, respectively. HS
0805+3822 shows grazing eclipses and has a likely orbital period of 3.2169(2)
h. Time-resolved optical spectroscopy of the new CVs (with the exception of HS
0805+3822) is also presented. Radial velocity studies provided an orbital
period of 3.55 h for HS 1813+6122, which allowed us to identify the observed
photometric signal at 3.39 h as a negative superhump wave. The spectroscopic
behaviour clearly identifies these new CVs as new SW Sextantis stars. These new
additions increase the number of known SW Sex stars to 35. Almost 40 per cent
of the total SW Sex population do not show eclipses, invalidating the
requirement of eclipses as a defining characteristic of the class and the
models based on a high orbital inclination geometry alone. On the other hand,
the predominance of orbital periods in the narrow 3-4.5 h range is becoming
more pronounced. In fact, almost half the CVs which populate the 3-4.5 h period
interval are definite members of the class. These statistics are confirmed by
our results from the Hamburg Quasar Survey CVs. Remarkably, 54 per cent of the
Hamburg nova-like variables have been identified as SW Sex stars with orbital
periods in the 3-4.5 h range. The observation of this pile-up of systems close
to the upper boundary of the period gap is difficult to reconcile with the
standard theory of CV evolution, as the SW Sex stars are believed to have the
highest mass transfer rates among CVs. Finally, we review the full range of
common properties that the SW Sex stars exhibit.
","We present an analysis of all known short-period cataclysmic variables (CVs) in which we find that most systems have orbital periods longer than 3 hrs and are dominated by SW Sex stars, while those with shorter periods tend to be AM Her binaries. We show that this dichotomy is consistent with theoretical predictions for the evolution of CVs driven by angular momentum loss via gravitational radiation. The observed distribution of orbital periods can also be explained if there exists a minimum period below which no CVs exist due to magnetic braking. This result has important implications on our understanding of how CVs evolve towards shorter orbital periods. Cataclysmic Variables (CVs), interacting binary star systems consisting of a white dwarf primary accreting matter from its low-mass companion through Roche lobe overflow, are among the best studied classes of close binary stars. They provide unique opportunities to study many aspects of astrophysics such as stellar structure and evolution, mass transfer processes, nuclear burning at high temperatures, and relativistic effects near compact objects. In particular, they offer insights into the formation mechanisms of both single and double degenerate white dwarfs, the progenitors of Type Ia supernovae.",arxiv,bigscience bloomz,704.1129,0.6666666666666666,0.29411764705882354,0.882051282051282,0.5069278547539418,1,1,0,0,0,1,1,0,0,0,0.1007973530852406,0.07874017761707623,0.10894941634241245,0.07196969696969698,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Mixed Meson Masses with Domain-Wall Valence and Staggered Sea Fermions,"  Mixed action lattice calculations allow for an additive lattice spacing
dependent mass renormalization of mesons composed of one sea and one valence
quark, regardless of the type of fermion discretization methods used in the
valence and sea sectors. The value of the mass renormalization depends upon the
lattice actions used. This mixed meson mass shift is an important lattice
artifact to determine for mixed action calculations; because it modifies the
pion mass, it plays a central role in the low energy dynamics of all hadronic
correlation functions. We determine the leading order, $\mathcal{O}(a^2)$, and
next to leading order, $\mathcal{O}(a^2 m_\pi^2)$, additive mass shift of
\textit{valence-sea} mesons for a mixed lattice action with domain-wall valence
fermions and rooted staggered sea fermions, relevant to the majority of current
large scale mixed action lattice efforts. We find that on the asqtad improved
coarse MILC lattices, this additive mass shift is well parameterized in lattice
units by $\Delta(am)^2 = 0.034(2) -0.06(2) (a m_\pi)^2$, which in physical
units, using $a=0.125$ fm, corresponds to $\Delta(m)^2 = (291\pm 8
\textrm{MeV})^2 -0.06(2) m_\pi^2$. In terms of the mixed action effective field
theory parameters, the corresponding mass shift is given by $a^2
\Delta_\mathrm{Mix} = (316 \pm 4 \textrm{MeV})^2$ at leading order plus
next-to-leading order corrections including the necessary chiral logarithms for
this mixed action calculation, determined in this work. Within the precision of
our calculation, one can not distinguish between the full next-to-leading order
effective field theory analysis of this additive mixed meson mass shift and the
parameterization given above.
","We present results for the masses of light mesons made up of quarks in different flavors, using domain-wall valence fermions on N f = 2 + 1 flavor staggered sea configurations generated by MILC collaboration at lattice spacing $a \sim 0.12$ fm.  We use two methods to extract the masses:  The first method is based on fitting the correlation functions directly to exponentials.  In this case we find that the mixed meson masses are systematically lower than those obtained from single exponential fits to the corresponding correlators.  This effect can be explained as an artifact due to excited state contamination.  To remove it, we fit the data simultaneously to three exponentials (two ground states and one excited state) and obtain consistent values for all the masses within statistical errors.  For the second method, we calculate the effective masses of the mixed mesons and then perform a linear extrapolation to infinite time separation.  Again, our results agree well with each other.  Finally, we compare our results with experimental measurements and previous calculations performed with Wilson-type fermions.",arxiv,bigscience bloomz,705.0572,0.3333333333333333,0.3445378151260504,0.6564102564102564,0.455327281414238,1,1,1,0,0,1,1,1,0,0,0.20630453937067958,0.09110158746005688,0.11673151750972763,0.07196969696969698,0,1,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
ATLAS sensitivity to Wtb anomalous couplings in top quark decays,"  We study the sensitivity of the ATLAS experiment to Wtb anomalous couplings
in top pair production with semileptonic decay, pp -> t tbar -> W+ b W- bbar,
with one of the W bosons decaying leptonically and the other hadronically.
Several observables are examined, including the W helicity fractions and new
quantities recently introduced, such as the ratios of helicity fractions and
some angular asymmetries defined in the W rest frame. The dependence on
anomalous couplings of all these observables has been previously obtained. In
this work we show that some of the new observables also have smaller systematic
uncertainties than the helicity fractions, with a dependence on anomalous
couplings similar or stronger than for helicity fractions. Consequently, their
measurement can significantly improve the limits on anomalous couplings.
Moreover, the most sensitive measurements can be combined. In this case, the
precision achieved in the determination of Wtb anomalous couplings can be of a
few percent in the semileptonic channel alone.
","We present the results on searches for new physics beyond the Standard Model (SM) in ttbar events at sqrt(s) = 7 TeV, using data collected by ATLAS during 2011 corresponding to an integrated luminosity of 4.7 fb-1 . The analysis is performed with three different final states: lepton+jets , dilepton and all-hadronic channels. We consider two types of models that can be tested with these analyses: vector-like quarks decaying into tWb or tbHq final states. In both cases we use simplified models where only one coupling parameter is varied while keeping others fixed to their SM values. No significant deviations are observed compared to the predictions based on the SM. Limits are set on the parameters describing the interactions between heavy particles and fermions. These limits improve upon previous measurements made at LEP2 and LHC Run I. 
The ATLAS Collaboration",arxiv,bigscience bloomz,705.3041,0.3333333333333333,0.3445378151260504,0.18974358974358974,0.35499283325370284,0,1,0,0,0,1,1,1,0,0,0.11924785857464994,0.09513071502188536,0.08560311284046693,0.08712121212121213,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
X-ray detection of the substellar twin 2MASS J11011926-7732383 AB,"  2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star
forming region, is a rare wide-separation brown dwarf binary. XMM-Newton and
Chandra observations of 2M1101AB have allowed us to examine the influence of
physical parameters (mass, bolometric luminosity and effective temperature) on
X-ray emission from a coeval pair of substellar objects. The spatial resolution
of XMM-Newton is not sufficient to separate contributions from the two
components in the binary. The X-ray source detected with XMM-Newton has a
column density compatible with the infrared extinction of component A. On the
other hand, the binary is resolved with Chandra, and the bulk of the X-ray
emission is clearly associated with the photospherically cooler component B.
These apparently contradictory results point at strong variability of 2M1101's
X-ray emission. Combined with previous sensitive X-ray observations from
low-mass members of ChaI, we find a decline of X-ray luminosity with decreasing
(sub)stellar mass that is typical for star forming regions. 2M1101B is the
coolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in
X-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members,
and therefore relatively luminous. Most bona fide brown dwarfs of Cha I have
remained below the sensitivity limits of available X-ray observations, because
of their low luminosity associated with higher age.
","We report on the X-ray properties of the young, nearby (d = 11 pc), low-mass binary system 2MASS J1101-2677AB discovered by Burgasser et al. (2007) . The primary component is an M8 dwarf with T eff ~ 2600 K and log g ~ 5.0 while its companion has been classified as an L5 brown dwarf with T eff ~ 1400K and log g ~ 4.2. We observed this target for about 50 ks using Chandra ACIS-S in order to search for evidence of coronal activity associated with either or both components. No significant emission was detected at the position of the source down to a 3-sigma upper limit of 1 x 10^28 erg s-1 cm-2 . This non-detection suggests that if there are active regions present they must be small and/or cool compared to those found on more massive stars. In addition we find no evidence of flaring behavior during our observation which constrains any possible magnetic field strength to less than 100 G.",arxiv,bigscience bloomz,706.2301,0.5,0.29411764705882354,0.47692307692307695,0.4237935977066412,1,1,0,0,1,1,1,0,0,0,0.06764272805966091,0.08410169179370293,0.08171206225680934,0.12121212121212122,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Dynamic Properties of Molecular Motors in Burnt-Bridge Models,"  Dynamic properties of molecular motors that fuel their motion by actively
interacting with underlying molecular tracks are studied theoretically via
discrete-state stochastic ``burnt-bridge'' models. The transport of the
particles is viewed as an effective diffusion along one-dimensional lattices
with periodically distributed weak links. When an unbiased random walker passes
the weak link it can be destroyed (``burned'') with probability p, providing a
bias in the motion of the molecular motor. A new theoretical approach that
allows one to calculate exactly all dynamic properties of motor proteins, such
as velocity and dispersion, at general conditions is presented. It is found
that dispersion is a decreasing function of the concentration of bridges, while
the dependence of dispersion on the burning probability is more complex. Our
calculations also show a gap in dispersion for very low concentrations of weak
links which indicates a dynamic phase transition between unbiased and biased
diffusion regimes. Theoretical findings are supported by Monte Carlo computer
simulations.
","We study the dynamic properties of molecular motors by using burnt-bridge models, which are simple kinetic Monte Carlo simulations for motor proteins such as kinesin and myosin V. We show that these models reproduce several experimental results on single-molecule experiments with high accuracy.  In particular, we find that the velocity distribution is well described by an exponential function at low load force but deviates from it when the load increases. The mean square displacement shows subdiffusive behavior under large loads. These behaviors can be explained by considering the effect of the elasticity of the cargoes carried by the motors. Our model also reproduces the dependence of stall forces on external viscous drag coefficients observed experimentally. Finally, our simulation results suggest that the number of steps taken per ATP hydrolysis cycle decreases exponentially with increasing load force. This result may explain why the step size fluctuation becomes larger than expected theoretically near stalling conditions. 
I. INTRODUCTIO N
Molecular motors play important roles in many biological processes including muscle contraction [1] , vesicle transport [2] , chromosome segregation [3] , and cell division [4] . They convert chemical energy into mechanical work through repeated cycles of binding to cytoskeletal filaments (e.g., microtubules) and releasing them [5] .
The most extensively studied class of molecular motors is the kinesins [6] . Kinesins walk along microtubules toward their plus ends [7, 8] . Myosins move towards actin filaments' minus ends [9] . Both types of motors have been shown to take discrete steps [10 -12] . Recent studies have revealed that both kinesins [13] and myosins [14] exhibit stochastic stepping motions even without external loads [15 -19] . It has been suggested that this randomness arises mainly due to thermal fluctuations [20, 21] or internal noise [22] . However, there still remain open questions about how they respond to external loads [23] .
In order to understand the mechanism underlying the operation of molecular motors, various theoretical approaches have been developed so far [24] . Among those methods, kinetic Monte Carlo (KMC) simulations [25] provide useful information on",arxiv,bigscience bloomz,705.069,0.3333333333333333,0.8487394957983193,0.1794871794871795,0.939799331103679,1,1,0,0,1,1,1,0,0,1,0.06835028170896566,0.07331949912333527,0.07003891050583658,0.06060606060606061,1,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Charge Polarization Effects and Hole Spectra Characteristics in Alxgai-xN/Gan Superlattices,"  We study the effects of charge polarization on the extended physical
properties of superlattices, such as transmission coefficients and valence band
structure. We consider both linear and parabolic modulation of the band edge.
Based on the theory of finite periodic systems (TFPS), analytic expressions and
high precision calculations of the relevant physical quantities for n-cell
systems are obtained. New and also well-known features of these systems are
identified. Besides the well-known energy bandstructure, we also have the field
bandstructure, with interesting characteristics.Wider field gaps at stronger
internal electric fields and higher density of field bands for larger layer
widths are some of these characteristics. Well denned level density asymmetries
identify the minibands induced by charge polarization or the so-called Quantum
Confining Stark Effect. We present the n-cell transmission amplitudes,
transmission coefficients and miniband structures for different values of the
relevant parameters.
","The hole spectra characteristics are investigated for the superlattices (SLs) with different aluminum contents by using first-principles calculations based on density functional theory. The results show that the valence band maximum is located at Γ point, while conduction band minimum locates at M point. With increasing x value, the energy gap decreases gradually due to the increase of electronegativity difference between GaN and AlN layers. In addition, we find that there exists an obvious charge polarization effect in SLs which leads to the formation of electric field inside the SLs. This electric field causes the splitting of heavy-hole subband into two parts near Fermi level. Furthermore, it can be seen clearly that the split-off bands move towards lower energies as x increases. Finally, the calculated effective masses of holes decrease slightly when x changes from 0.25 to 1.0. 
 
 Keywords: AlGaInN/GaN superlattice; Charge polarization",arxiv,bigscience bloomz,704.2735,0.3333333333333333,0.3445378151260504,0.09230769230769231,0.3635929288103201,1,1,0,0,0,1,1,1,0,0,0.08704276871474181,0.04967988676642597,0.10894941634241245,0.026515151515151516,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Nonlinear generalized functions and the Heisenberg-Pauli foundations of Quantum Field Theory,"  In 1929 Heisenberg and Pauli laid the foundations of QFT by quantizing the
fields (method of canonical quantization). This general theory of quantized
fields has remained undisputed up to now. We show how the unmodified
Heisenberg-Pauli calculations make sense mathematically by using a theory of
generalized functions adapted to nonlinear operations. By providing an
appropriate mathematical setting, nonlinear generalized functions open doors
for their understanding but there remains presumably very hard technical
problems. (i) Domains of the interacting field operators: a priori the H-P
calculations give time dependent dense domains, what is not very convenient;
(ii) Calculations of the resulting matrix elements of the S operator: from the
unitarity of the S operator as a whole there are no longer ``infinities,'' but
a priori there is no other hope than heavy computer calculations; (iii)
Connection with renormalization theory: it should provide an approximation when
the coupling constant is small. The aim of this paper is to present, on the
grounds of a standard mathematical model of QFT (a self interacting scalar
boson field), a basis for improvement without significant prerequisites in
mathematics and physics. It is an attempt to use nonlinear generalized
functions in QFT, starting directly from the calculations made by physicists,
in the same way as they have already been used in classical mechanics and
general relativity.
","The present work is devoted to the study of nonlinear generalized functions in connection with the foundations of quantum field theory (QFT). The main results are as follows:  1) We show that the concept of nonlinear generalized function can be used for constructing an alternative approach to QFT, which does not use any additional axioms beyond those of standard relativistic quantum mechanics.  2) In this approach we introduce new mathematical objects - nonlinear generalized fields, which play the role similar to that played by usual quantum fields in conventional QFT. 3) We prove that these new fields satisfy all basic properties required for them to serve as fundamental building blocks of QFT. 4) We also demonstrate how our formalism allows one to obtain the Feynman rules for calculating various physical quantities within the framework of QFT. 5) Finally, using the developed formalism, we derive some important relations between different Green's functions appearing in QFT.",arxiv,bigscience bloomz,705.2396,0.3333333333333333,0.24369747899159663,0.49230769230769234,0.3951266125179169,1,1,1,0,1,1,1,1,0,1,0.23748393913089022,0.0603509666111921,0.26459143968871596,0.056818181818181816,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Surface Structure in an Accretion Disk Annulus with Comparable Radiation and Gas Pressure,"  We have employed a 3-d energy-conserving radiation MHD code to simulate the
vertical structure and thermodynamics of a shearing box whose parameters were
chosen so that the radiation and gas pressures would be comparable. The upper
layers of this disk segment are magnetically-dominated, creating conditions
appropriate for both photon bubble and Parker instabilities. We find little
evidence for photon bubbles, even though the simulation has enough spatial
resolution to see them and their predicted growth rates are high. On the other
hand, there is strong evidence for Parker instabilities, and they appear to
dominate the evolution of the magnetically supported surface layers. The disk
photosphere is complex, with large density inhomogeneities at both the
scattering and effective (thermalization) photospheres of the evolving
horizontally-averaged structure. Both the dominant magnetic support and the
inhomogeneities are likely to have strong effects on the spectrum and
polarization of thermal photons emerging from the disk atmosphere. The
inhomogeneities are also large enough to affect models of reflection spectra
from the atmospheres of accretion disks.
","We present the results of three-dimensional hydrodynamic simulations of accretion disks around black holes, which include both gas pressure and radiation pressure as well as self-gravity. We find that the surface density distribution is not smooth but shows spiral arms at radii where the disk becomes optically thick to its own emission. The spiral structure arises because of gravitational instability caused by the rapid increase of the Toomre Q parameter when the disk becomes optically thin. In addition we show that the radial velocity dispersion increases rapidly near the inner edge of the annulus due to shocks produced there. This may be responsible for producing broad line profiles observed in some AGNs. 
 
 Keywords: Black hole -accretion disk systems; Hydrodynamics; Self-gravitation; Shock waves; Gravitational instabilities; Opacity effects 
 
 
 
 1 Introduction 
 
 It has been suggested that many active galactic nuclei (AGN) are powered by supermassive black holes (SMBHs). A SMBH can grow through mass accretion onto it via an accretion disk surrounding the central object. Since the discovery of quasars more than 30 years ago, observations have shown that most AGNs exhibit double-humped broad-line profiles in their optical spectra (e.g., [1; 2]), indicating that they contain rotating accretion disks [3] . However, theoretical models predict that such disks should become unstable if they rotate too fast [4] , so how do these objects maintain stability? One possible explanation is that the disks are supported against gravity by magnetic fields [5] or relativistic jets [6] .
 
In this Letter, we study the properties of accretion disks using three-dimensional hydrodynamical simulations including both gas pressure and radiation pressures as well as self-gravity [7–9] . Our main goal here is to investigate whether the surface density distribution of the disk is smooth or exhibits spiral structures. If the latter case occurs, then what causes them?
2 Model Description

Model Setup
The basic equations governing our model are given by:",arxiv,bigscience bloomz,705.0314,0.3333333333333333,0.319327731092437,0.2358974358974359,0.402293358815098,1,1,0,0,0,1,1,1,1,0,0.04620501891677181,0.044950607832794386,0.054474708171206226,0.09848484848484848,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,2,1,1
Bulk viscosity in a cold CFL superfluid,"  We compute one of the bulk viscosity coefficients of cold CFL quark matter in
the temperature regime where the contribution of mesons, quarks and gluons to
transport phenomena is Boltzmann suppressed. In that regime dissipation occurs
due to collisions of superfluid phonons, the Goldstone modes associated to the
spontaneous breaking of baryon symmetry. We first review the hydrodynamics of
relativistic superfluids, and remind that there are at least three bulk
viscosity coefficients in these systems. We then compute the bulk viscosity
coefficient associated to the normal fluid component of the superfluid. In our
analysis we use Son's effective field theory for the superfluid phonon, amended
to include scale breaking effects proportional to the square of the strange
quark mass m_s. We compute the bulk viscosity at leading order in the scale
breaking parameter, and find that it is dominated by collinear splitting and
joining processes. The resulting transport coefficient is zeta=0.011 m_s^4/T,
growing at low temperature T until the phonon fluid description stops making
sense. Our results are relevant to study the rotational properties of a compact
star formed by CFL quark matter.
","We calculate the bulk viscosity for a strongly interacting fermion system at finite temperature and density using the relaxation time approximation (RTA). We find that the RTA is not applicable to the case where the chemical potential $\mu$ approaches zero, because the relaxation rate vanishes as $1/\mu^2$. In this regime we use an alternative approach based on the Kubo formula with the spectral function obtained by solving the Bethe-Salpeter equation numerically. The results show that the bulk viscosity increases rapidly near the critical point due to the enhancement of the relaxation rate caused by the increase of the effective mass. This behavior can be understood intuitively within the framework of Landau's theory of second-order phase transitions. Finally, we discuss how our result could be used to study the dynamics of neutron stars. Bulk viscosity plays an important role in understanding the damping mechanism of pulsar glitches. 
 
 In recent years there has been considerable interest in studying the properties of dense nuclear matter such as quark-gluon plasma or color-flavor-locked (CFL) state [1] . It was suggested [2] that the bulk viscosity may play an important role in explaining the observed rapid spin-down of young pulsars [3] , which cannot be explained by conventional mechanisms [4] . 
 
 In this Letter, we present numerical calculations of the bulk viscosity for a CFL superfluid at finite temperatures and densities. Our calculation is performed in the relaxation-time-approximation (RTA), which is valid when the relaxation rate is much larger than the typical frequency scale of the problem [5] . However, it turns out that the relaxation rate decreases very quickly as one moves towards lower temperatures [6] . Therefore, the applicability of the RTA becomes questionable if the chemical potential $\mu \ll T$ [7, 8] . To overcome this difficulty, we employ another method based on the Kubo formalism [9] . 
The rest of this Letter is organized as follows. In Sec. II, we briefly review the basic idea behind the RTA. Then, in Secs. III and IV, we explain how we solve the",arxiv,bigscience bloomz,705.3909,0.3888888888888889,0.8991596638655462,0.3076923076923077,0.9225991399904443,0,0,0,0,1,1,1,0,0,1,0.05140006925381135,0.08195094686603972,0.058365758754863814,0.05303030303030303,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Non-Perturbative Corrections and Modularity in N=1 Type IIB Compactifications,"  Non-perturbative corrections and modular properties of four-dimensional type
IIB Calabi-Yau orientifolds are discussed. It is shown that certain
non-perturbative alpha' corrections survive in the large volume limit of the
orientifold and periodically correct the Kahler potential. These corrections
depend on the NS-NS two form and have to be completed by D-instanton
contributions to transform covariantely under symmetries of the type IIB
orientifold background. It is shown that generically also the D-instanton
superpotential depends on the two-form moduli as well as on the complex
dilaton. These contributions can arise through theta-functions with the dilaton
as modular parameter. An orientifold of the Enriques Calabi-Yau allows to
illustrate these general considerations. It is shown that this compactification
leads to a controlled four-dimensional N=1 effective theory due to the absence
of various quantum corrections. Making contact to the underlying topological
string theory the D-instanton superpotential is proposed to be related to a
specific modular form counting D3, D1, D(-1) degeneracies on the Enriques
Calabi-Yau.
","We study the non-perturbative corrections to the low-energy effective action for type IIB string theory on Calabi-Yau threefolds with fluxes, using mirror symmetry techniques. We show that these corrections can be organized into an exact expression which is modular invariant under SL(2,Z). This result has important consequences both at weak coupling (where it implies the existence of new BPS states) as well as at strong coupling (where it provides evidence for the conjectured duality between M-theory compactified on G 2 manifolds and type IIA strings on K3 surfaces).
The results presented here are based on joint work with A. Giveon, D. Kutasov, S. Raby, C. Vafa, E. Witten, J. Wulff, and B. Zwiebach. 
 
 Introduction 
 
 In this talk we will discuss some recent developments concerning non perturbative effects in supersymmetric theories. The main focus will be on the case of type IIB string theory compactified on Calabi Yau spaces. Our discussion will include several examples where we will try to explain how our understanding of such phenomena has been improved by exploiting various dualities among different string vacua.",arxiv,bigscience bloomz,705.3253,0.3888888888888889,0.29411764705882354,0.18974358974358974,0.46106067845198284,1,1,0,0,1,1,1,0,0,0,0.07368240812518267,0.0879982846508664,0.05058365758754864,0.08712121212121213,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Computing modular polynomials in quasi-linear time,"  We analyse and compare the complexity of several algorithms for computing
modular polynomials. We show that an algorithm relying on floating point
evaluation of modular functions and on interpolation, which has received little
attention in the literature, has a complexity that is essentially (up to
logarithmic factors) linear in the size of the computed polynomials. In
particular, it obtains the classical modular polynomials $\Phi_\ell$ of prime
level $\ell$ in time O (\ell^3 \log^4 \ell \log \log \ell). Besides treating
modular polynomials for $\Gamma^0 (\ell)$, which are an important ingredient in
many algorithms dealing with isogenies of elliptic curves, the algorithm is
easily adapted to more general situations. Composite levels are handled just as
easily as prime levels, as well as polynomials between a modular function and
its transform of prime level, such as the Schl\""afli polynomials and their
generalisations. Our distributed implementation of the algorithm confirms the
theoretical analysis by computing modular equations of record level around
10000 in less than two weeks on ten processors.
","We present an algorithm for computing the modular polynomial $P(x,y)$ modulo prime $p$ with $O((\log p)(\log \log p))$ bit operations and $O(1)$ space.  The algorithm is based on fast multiplication techniques over finite fields and uses only integer arithmetic. It can be used to compute discrete logarithms efficiently when the base field has characteristic 2 or 3 (e.g., elliptic curves). We also show how to use this algorithm as part of a subexponential-time factorization algorithm that runs in time $\tilde{O}(2^{0.5}n^{2/3})$ where $n$ denotes the number of bits needed to represent the input integers. 
The algorithm presented here improves upon previous work by Joux et al. (FOCS 2002), which required $O(p^{3/4})$ bit operations and $poly(p)$ space.",arxiv,bigscience bloomz,704.3177,0.2777777777777778,0.24369747899159663,0.2205128205128205,0.28332537028189203,1,0,0,0,0,1,1,0,0,0,0.0978879472723527,0.12500494917223373,0.12840466926070038,0.12878787878787878,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Three Years of Mira Variable CCD Photometry: What Has Been Learned?,"  The subject of micro-variability among Mira stars has received increased
attention since DeLaverny et al. (1998) reported short-term brightness
variations in 15 percent of the 250 Mira or Long Period Variable stars surveyed
using the broadband 340 to 890 nm Hp filter on the HIPPARCOS satellite. The
abrupt variations reported ranged 0.2 to 1.1 magnitudes, on time-scales between
2 to 100 hours, with a preponderance found nearer Mira minimum light phases.
However, the HIPPARCOS sampling frequency was extremely sparse and required
confirmation because of potentially important atmospheric dynamics and
dust-formation physics that could be revealed. We report on Mira light curve
sub-structure based on new CCD V and R band data, augmenting the known light
curves of Hipparcos-selected long period variables [LPVs], and interpret same
in terms of [1] interior structure, [2] atmospheric structure change, and/or
[3] formation of circumstellar [CS] structure. We propose that the alleged
micro-variability among Miras is largely undersampled, transient overtone
pulsation structure in the light curves.
","The OGLE project has been monitoring the Magellanic Clouds for three years with its 1.3m telescope at Las Campanas Observatory, Chile. The photometric data are being used to study variable stars in these galaxies and their properties. In this talk I will present some results on the variability of red giant branch (RGB) stars obtained by analyzing about one million light curves collected during the first two observing seasons. These include new periods found among RGB variables as well as period changes observed in many cases. We also discuss possible mechanisms responsible for such variations. 
 
 Keywords: Red Giant Branch Stars, Period Changes, Variability, Magellanic Clouds, OGLE Project 
 
 This work was supported by Polish KBN grant 2P03D00527. It is based on observations made with the Warsaw University Observatory operated by the Institute of Astronomy of the Polish Academy of Sciences under agreement with the National Science Center of Poland.",arxiv,bigscience bloomz,704.2762,0.2777777777777778,0.29411764705882354,0.19487179487179487,0.3779264214046823,1,1,0,0,0,1,0,1,0,0,0.14344242834232884,0.07034903300775001,0.15953307392996108,0.05303030303030303,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Revisiting the effect of nearby supernova remnants on local cosmic rays,"  In an earlier paper, the effect of the nearby known supernova remnants (SNRs)
on the local cosmic-rays (CRs) was studied, considering different possible
forms of the particle injection time. The present work is a continuation of the
previous work, but assumes a more realistic model of CR propagation in the
Galaxy. The previous work assumed an unbounded three-dimensional diffusion
region, whereas the present one considers a flat cylindrical disc bounded in
both the radial and vertical directions. The study has found that the effect of
the vertical halo boundary $H$ on the local SNR contribution to the observed CR
anisotropy is negligible as long as $H\gtrsim 2kpc$. Considering the values of
the halo height $H\gtrsim 2kpc$ obtained by different authors, the present work
suggests that the study of the effect of local sources on the CR anisotropy can
be carried out without having much information on $H$ and hence, using the much
simpler three-dimentional unbounded solution. Finally, the present work
discusses about the possibility of explaining the observed anisotropy below the
knee by a single dominant source with properly chosen source parameters, and
claims that the source may be an \textit{undetected} old SNR with a
characteristic age of $\sim 1.5\times 10^5 yr$ located at a distance of $\sim
0.57 kpc$ from the Sun.
","We revisit the question whether or not there is an excess in cosmic ray flux near Supernova Remnant (SNR) shells, as reported by PAMELA and AMS-02 experiments. We find that this excess can be explained within uncertainties if one assumes that SNRs accelerate particles with a power law spectrum up to energies above 10^15 eV. The required spectral index for protons is 2.2 +/- 0.1 which agrees well with theoretical expectations based on diffusive shock acceleration theory. For electrons we require a harder spectrum with a slope of 3.0 +/- 0.3. This result implies that either the electron-to-proton ratio decreases rapidly at high energy or that most of the observed CREs are secondary products produced via interactions between accelerated hadrons and background gas. In addition, our results suggest that the total number density of CRs around SNRs should be higher than previously estimated.",arxiv,bigscience bloomz,704.3336,0.2777777777777778,0.24369747899159663,0.46153846153846156,0.3635929288103201,1,1,0,0,0,1,1,0,0,0,0.14828135437437326,0.05063755297664872,0.08171206225680934,0.05303030303030303,0,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Matching WMAP 3-yrs results with the Cosmological Slingshot Primordial Spectrum,"  We consider a recently proposed scenario for the generation of primordial
cosmological perturbations, the so called Cosmological Slingshot scenario. We
firstly obtain a general expression for the Slingshot primordial power spectrum
which extends previous results by including a blue pre-bounce residual
contribution at large scales. Starting from this expression we numerically
compute the CMB temperature and polarization power spectra arising from the
Slingshot scenario and show that they excellently match the standard WMAP
3-years best-fit results. In particular, if the residual blue spectrum is far
above the largest WMAP observed scale, the Slingshot primordial spectrum fits
the data well by only fixing its amplitude and spectral index at the pivot
scale k_p=10^{-3}h x Mpc^{-1}. We finally show that all possible distinctive
Slingshot signatures in the CMB power spectra are confined to very low
multipoles and thus very hard to detect due to large cosmic variance dominated
error bars at these scales.
","We have recently shown that the primordial spectrum of density fluctuations can be obtained by solving an initial value problem for a massless scalar field in deSitter space-time, which is known as the cosmological slingshot effect (CSE). In this work we show how to match the CSE predictions with those of the Wilkinson Microwave Anisotropy Probe 3-year data release (WMAP3) and compare them against other models. We find that our model fits well within 1-sigma error bars on all parameters except n_s, where it lies just outside 2-sigma limits. The best-fit values are given by:  H_0 = 72.6 +/- 0.9 km/s/Mpc,  Omega_m = 0.26 +/- 0.01,   Omega_Lambda = 0.74 +/- 0.02,    n_s = 0.96 +/- 0.06.   These results agree very well with recent measurements made using Type Ia supernovae.  Our analysis shows that the CSE provides a viable alternative explanation for the origin of cosmic structure formation.",arxiv,bigscience bloomz,706.0025,0.2222222222222222,0.24369747899159663,0.14358974358974358,0.3750597228858099,0,1,0,0,0,1,1,1,0,0,0.08946864134749105,0.07579465663631219,0.0622568093385214,0.05303030303030303,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Structure of the stationary state of the asymmetric target process,"  We introduce a novel migration process, the target process. This process is
dual to the zero-range process (ZRP) in the sense that, while for the ZRP the
rate of transfer of a particle only depends on the occupation of the departure
site, it only depends on the occupation of the arrival site for the target
process. More precisely, duality associates to a given ZRP a unique target
process, and vice-versa. If the dynamics is symmetric, i.e., in the absence of
a bias, both processes have the same stationary-state product measure. In this
work we focus our interest on the situation where the latter measure exhibits a
continuous condensation transition at some finite critical density $\rho_c$,
irrespective of the dimensionality. The novelty comes from the case of
asymmetric dynamics, where the target process has a nontrivial fluctuating
stationary state, whose characteristics depend on the dimensionality. In one
dimension, the system remains homogeneous at any finite density. An alternating
scenario however prevails in the high-density regime: typical configurations
consist of long alternating sequences of highly occupied and less occupied
sites. The local density of the latter is equal to $\rho_c$ and their
occupation distribution is critical. In dimension two and above, the asymmetric
target process exhibits a phase transition at a threshold density $\rho_0$ much
larger than $\rho_c$. The system is homogeneous at any density below $\rho_0$,
whereas for higher densities it exhibits an extended condensate elongated along
the direction of the mean current, on top of a critical background with density
$\rho_c$.
","We study the structure of the stationary distribution for an asymmetric version of the Target Process (TP). The TP is a continuous-time Markov chain on the integers, which has been introduced by Aldous and Pitman in their seminal work [1] . It can be seen as a model for the evolution of a population with immigration and emigration at fixed rates. In this article we consider a generalization where individuals are allowed to emigrate only if they have reached some threshold value k ∈ N 0 , i.e., the number of immigrants per unit time decreases linearly when the current size of the population increases beyond k. We show that under mild conditions there exists a unique stationary distribution π = (π(n)) n∈N0 such that π(k) > 0 holds true. Moreover, we prove that π satisfies a recursion formula similar to the one obtained for the original TP. Finally, we provide explicit expressions for π(1), ..., π(k+1).
Keywords: Asymmetric target process, Stationary distribution",arxiv,bigscience bloomz,705.0907,0.5555555555555556,0.29411764705882354,0.6564102564102564,0.4209268991877688,1,1,1,0,0,1,1,1,0,0,0.11310684205595783,0.18854982715586066,0.15953307392996108,0.20833333333333334,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Adjointability of densely defined closed operators and the Magajna-Schweizer Theorem,"  In this notes unbounded regular operators on Hilbert $C^*$-modules over
arbitrary $C^*$-algebras are discussed. A densely defined operator $t$
possesses an adjoint operator if the graph of $t$ is an orthogonal summand.
Moreover, for a densely defined operator $t$ the graph of $t$ is orthogonally
complemented and the range of $P_FP_{G(t)^\bot}$ is dense in its biorthogonal
complement if and only if $t$ is regular. For a given $C^*$-algebra $\mathcal
A$ any densely defined $\mathcal A$-linear closed operator $t$ between Hilbert
$C^*$-modules is regular, if and only if any densely defined $\mathcal
A$-linear closed operator $t$ between Hilbert $C^*$-modules admits a densely
defined adjoint operator, if and only if $\mathcal A$ is a $C^*$-algebra of
compact operators. Some further characterizations of closed and regular modular
operators are obtained.
  Changes 1: Improved results, corrected misprints, added references. Accepted
by J. Operator Theory, August 2007 / Changes 2: Filled gap in the proof of Thm.
3.1, changes in the formulations of Cor. 3.2 and Thm. 3.4, updated references
and address of the second author.
","We prove that if an operator is adjointable, then it has dense range in its domain.  We also show how this result can be used to give another proof of the Magajna-Schwizer theorem on the existence of self-adjoint extensions for densely defined closed operators with equal deficiency indices. Let H be a Hilbert space over C. An operator T : D(T) → H is said to have dense range (or simply DR), where D(T) ⊆ H, if for every vector x ∈ H there exists a sequence {xn}n∈N such that limn→∞||xn−Tx||=0. In other words, the image of T contains no proper subspace of H. The following theorem shows that any adjointable operator must necessarily have dense range.   THEOREM 1.1. If T:D(T)⊆H→H is adjointable, then R(T∗)=D(T).",arxiv,bigscience bloomz,705.2576,0.5555555555555556,0.24369747899159663,0.24615384615384617,0.3119923554706163,1,1,1,0,0,1,1,1,0,0,0.22244187976891536,0.14294315180009315,0.2840466926070039,0.0946969696969697,3,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The velocity structure of moving magnetic feature pairs around sunspots: support for the U-loop model,"  Using data recorded by the Michelson Doppler Imager (MDI) instrument on the
Solar and Heliospheric Observatory (SOHO), we have traced 123 pairs of opposite
magnetic polarity moving magnetic features (MMFs) in three active regions NOAA
ARs 8375, 0330 and 9575. At the time of observation, AR 8375 was young, AR 0330
mature, and AR 9575 decaying. The vertical velocity indicates that the elements
of MMF pairs with polarity opposite to that of the sunspot support a downflow
of around 50-100 m s$^{-1}$. The average Doppler shift difference between
negative and positive elements of an MMF pair is about 150 m s$^{-1}$ in AR
8375, 100 m s$^{-1}$ in AR 0330, and 20 m s$^{-1}$ in AR 9575. These
observational results are in agreement with the model that MMF pairs are part
of a U-loop emanating from the sunspot's magnetic canopy. According to this
model the downflow is caused by the Evershed flow returning below the solar
surface. For AR 8375, the horizontal velocity of MMFs ranges from 0.1 km
s$^{-1}$ to 0.7 km s$^{-1}$, and on average, the velocity of an MMF pair
decreases significantly (from 0.6 km s$^{-1}$ to 0.35 km s$^{-1}$) with
increasing distance from the MMF's birth place. This result suggests that the
change in MMF flow speed does not reflect the radial structure of the moat
flow, but rather is intrinsic to the evolution of the MMF pairs. This result is
also in agreement with the U-loop model of MMF pairs. We also find that
properties of MMF pairs, most strikingly the lifetime, depend on the evolution
stages of the parent sunspot. The mean lifetimes of MMF pairs in ARs 9575 and
0330 are 0.7 hours and 1.6 hours, respectively, which is considerably shorter
than the 4 hours lifetime previously found for AR 8375.
","We analyze the evolution and kinematics of two opposite polarity magnetic features (MPFs) in an active region using high-resolution vector magnetograms obtained by Hinode/SOT-SP. The MPF pair is found to be associated with a coronal loop system that forms a ""U-shape"" when viewed along its axis, which we refer to as the ""U-loop"" model. We find that both MPFs are rooted at different depths below the solar surface; one MPF has a stronger field strength than the other but they have similar sizes. Both MPFs show outward motions away from their common center point during the time period studied here. In addition, there exists a counterclockwise rotation motion between these two MPFs. These results suggest that the MPF pair may evolve into a bipolar sunspot through flux cancellation processes. This work was supported by NASA grants NNX08AQ85G and NNG09FA40C.",arxiv,bigscience bloomz,705.2507,0.5555555555555556,0.29411764705882354,0.8974358974358975,0.3521261347348304,1,1,0,0,1,1,1,1,0,0,0.1699598157186829,0.0725644404287837,0.22178988326848248,0.03409090909090909,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Statistics of the Points Where Nodal Lines Intersect a Reference Curve,"  We study the intersection points of a fixed planar curve $\Gamma$ with the
nodal set of a translationally invariant and isotropic Gaussian random field
$\Psi(\bi{r})$ and the zeros of its normal derivative across the curve. The
intersection points form a discrete random process which is the object of this
study. The field probability distribution function is completely specified by
the correlation $G(|\bi{r}-\bi{r}'|) = <\Psi(\bi{r}) \Psi(\bi{r}')>$.
  Given an arbitrary $G(|\bi{r}-\bi{r}'|)$, we compute the two point
correlation function of the point process on the line, and derive other
statistical measures (repulsion, rigidity) which characterize the short and
long range correlations of the intersection points. We use these statistical
measures to quantitatively characterize the complex patterns displayed by
various kinds of nodal networks. We apply these statistics in particular to
nodal patterns of random waves and of eigenfunctions of chaotic billiards. Of
special interest is the observation that for monochromatic random waves, the
number variance of the intersections with long straight segments grows like $L
\ln L$, as opposed to the linear growth predicted by the percolation model,
which was successfully used to predict other long range nodal properties of
that field.
","We consider the problem of finding the statistics of nodal lines in random wave fields, where we assume that the field is generated by an ensemble of monochromatic waves with randomly distributed phases and amplitudes. We show how to calculate these statistics using only the first two moments of the distribution function for the phase differences between pairs of waves. The results are applied to study the statistical properties of nodal lines on the surface of oceanic internal tides. In particular, it is shown that the probability density functions (PDFs) of the number of intersections per unit length of a reference curve depend strongly on whether or not this curve lies within one wavelength of the source region. If so, then the PDF has a power-law tail at large values of the intersection density; if not, then there is no such tail. 
 
 Keywords: Random wave fields, Oceanic internal tide, Nodal line, Phase difference",arxiv,bigscience bloomz,704.335,0.3333333333333333,0.24369747899159663,0.3384615384615385,0.3922599139990445,1,1,0,0,1,1,1,1,0,0,0.1620835329449634,0.08063345483145581,0.14785992217898833,0.07196969696969698,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
GRB 061121: Broadband spectral evolution through the prompt and afterglow phases of a bright burst,"  Swift triggered on a precursor to the main burst of GRB 061121 (z=1.314),
allowing observations to be made from the optical to gamma-ray bands. Many
other telescopes, including Konus-Wind, XMM-Newton, ROTSE and the Faulkes
Telescope North, also observed the burst. The gamma-ray, X-ray and UV/optical
emission all showed a peak ~75s after the trigger, although the optical and
X-ray afterglow components also appear early on - before, or during, the main
peak. Spectral evolution was seen throughout the burst, with the prompt
emission showing a clear positive correlation between brightness and hardness.
The Spectral Energy Distribution (SED) of the prompt emission, stretching from
1eV up to 1MeV, is very flat, with a peak in the flux density at ~1keV. The
optical-to-X-ray spectra at this time are better fitted by a broken, rather
than single, power-law, similar to previous results for X-ray flares. The SED
shows spectral hardening as the afterglow evolves with time. This behaviour
might be a symptom of self-Comptonisation, although circumstellar densities
similar to those found in the cores of molecular clouds would be required. The
afterglow also decays too slowly to be accounted for by the standard models.
Although the precursor and main emission show different spectral lags, both are
consistent with the lag-luminosity correlation for long bursts. GRB 061121 is
the instantaneously brightest long burst yet detected by Swift. Using a
combination of Swift and Konus-Wind data, we estimate an isotropic energy of
2.8x10^53 erg over 1keV - 10MeV in the GRB rest frame. A probable jet break is
detected at ~2x10^5s, leading to an estimate of ~10^51 erg for the
beaming-corrected gamma-ray energy.
","We present broadband (radio to X-ray) observations of GRB 061121, one of the most energetic gamma-ray bursts ever detected by Swift/BAT with an isotropic equivalent energy release of 1.8 x 10^54 erg in the 15-350 keV band. The temporal behavior of this event was complex; it consisted of multiple pulses that were superimposed on top of each other during both the prompt emission phase as well as the early part of its afterglow. We find evidence for two distinct components in the optical light curve -one which decays rapidly at first but then flattens out later-on timescales ranging between 0.1-10 days post-burst. This flattening could be due either to continued activity of the central engine or to refreshed shocks. In addition we detect significant radio emission upto 100 days post-burst. Our results are consistent with those obtained using data from the VLA and ATCA telescopes.",arxiv,bigscience bloomz,704.1609,0.6666666666666666,0.24369747899159663,0.7435897435897436,0.369326325848065,1,1,0,0,0,1,1,1,0,0,0.06822032387818233,0.09521157280290034,0.0622568093385214,0.030303030303030304,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Maximum solutions of normalized Ricci flows on 4-manifolds,"  We consider maximum solution $g(t)$, $t\in [0, +\infty)$, to the normalized
Ricci flow. Among other things, we prove that, if $(M, \omega) $ is a smooth
compact symplectic 4-manifold such that $b_2^+(M)>1$ and let
$g(t),t\in[0,\infty)$, be a solution to (1.3) on $M$ whose Ricci curvature
satisfies that $|\text{Ric}(g(t))|\leq 3$ and additionally $\chi(M)=3 \tau
(M)>0$, then there exists an $m\in \mathbb{N}$, and a sequence of points
$\{x_{j,k}\in M\}$, $j=1, ..., m$, satisfying that, by passing to a
subsequence, $$(M, g(t_{k}+t), x_{1,k},..., x_{m,k})
\stackrel{d_{GH}}\longrightarrow (\coprod_{j=1}^m N_j, g_{\infty},
x_{1,\infty}, ...,, x_{m,\infty}),$$ $t\in [0, \infty)$, in the $m$-pointed
Gromov-Hausdorff sense for any sequence $t_{k}\longrightarrow \infty$, where
$(N_{j}, g_{\infty})$, $j=1,..., m$, are complete complex hyperbolic orbifolds
of complex dimension 2 with at most finitely many isolated orbifold points.
Moreover, the convergence is $C^{\infty}$ in the non-singular part of
$\coprod_1^m N_{j}$ and
$\text{Vol}_{g_{0}}(M)=\sum_{j=1}^{m}\text{Vol}_{g_{\infty}}(N_{j})$, where
$\chi(M)$ (resp. $\tau(M)$) is the Euler characteristic (resp. signature) of
$M$.
","In this article, we study the maximum solution to the normalized Ricci flow on closed 4-manifolds with positive scalar curvature and prove that it is unique up to scaling if its volume growth rate satisfies some conditions.  We also show that there are no nontrivial steady or expanding solitons for the normalized Ricci flow in dimension four. Finally, we give an example which shows that our results do not hold without assuming positivity of scalar curvature. Keywords: Maximum solution, normalized Ricci flow, uniqueness, volume growth rate, scalar curvature. 1 Introduction Let $(M,g)$ be a closed Riemannian manifold of dimension $n$. The Ricci flow is defined by $$\displaystyle g_{t}=e^{-2t}g$$ where $t\in[0,\infty[$. It was introduced independently by Hamilton [H1] and by Perelman [P] . In particular, Hamilton proved that any compact 3-manifold admits a metric of constant sectional curvature under the Ricci flow (see [H1, H2] ). On the other hand, Perelman showed that the Ricci flow can be used as a tool to solve the Poincaré conjecture and the Thurston geometrization conjecture (see [P] ) . Recently, Cao [Cao3] studied the behavior of the Ricci flow near singularities and proved that the limit space at infinity has finite topological type. Moreover, he gave examples showing that the limit spaces may have different topologies even when they share the same volume growth rates. For more information about the Ricci flow, see e.g., [WZ1, WZ2, ZH, CW1, CW2, CC, CLN, LY, YL, LL, LS, LT, MT, N, NW, OW, P, PS, S, SZ, T, V, X, Y, Z] .
The normalized Ricci flow is given by $$\displaystyle g_{*t}=e^{-t}g_t$$ where $t\in[0,
\infty[$. This flow was first considered by Hamilton [H3] , who showed that the normalized Ricci flow preserves the total volume of the",arxiv,bigscience bloomz,704.0714,0.2222222222222222,0.6470588235294118,0.13333333333333333,0.7849976110845676,1,1,0,0,0,1,1,1,0,0,1.0,0.09757674085428834,1.0,0.13257575757575757,1,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Geometric control theory I: mathematical foundations,"  A geometric setup for control theory is presented. The argument is developed
through the study of the extremals of action functionals defined on piecewise
differentiable curves, in the presence of differentiable non-holonomic
constraints. Special emphasis is put on the tensorial aspects of the theory. To
start with, the kinematical foundations, culminating in the so called
variational equation, are put on geometrical grounds, via the introduction of
the concept of infinitesimal control . On the same basis, the usual
classification of the extremals of a variational problem into normal and
abnormal ones is also rationalized, showing the existence of a purely
kinematical algorithm assigning to each admissible curve a corresponding
abnormality index, defined in terms of a suitable linear map. The whole
machinery is then applied to constrained variational calculus. The argument
provides an interesting revisitation of Pontryagin maximum principle and of the
Erdmann-Weierstrass corner conditions, as well as a proof of the classical
Lagrange multipliers method and a local interpretation of Pontryagin's
equations as dynamical equations for a free (singular) Hamiltonian system. As a
final, highly non-trivial topic, a sufficient condition for the existence of
finite deformations with fixed endpoints is explicitly stated and proved.
","The book is divided into three parts, each part containing several chapters. The first two parts are devoted to the development and analysis of geometric control systems in finite-dimensional spaces (the state space) and infinite-dimensional Hilbert spaces (the phase space). In particular, the following topics are considered:

Part I - Geometric Control Theory in Finite-Dimensional Spaces.

Chapter 1 - Introduction to Geometric Control Theory.
 Chapter 2 - Basic Concepts of Differential Geometry.
 Chapter 3 - Lie Groups and Their Representations.
 Chapter 4 - Invariant Manifolds for Group Actions on Vector Fields.
 Chapter 5 - Stability Analysis of Nonlinear Systems with State Constraints.
 Chapter 6 - Stabilization by Feedback of Linear Time-Invariant Systems.
 Chapter 7 - Optimal Tracking Problems for Affine Systems.
 Part II - Geometric Control Theory on Infinite-Dimensional Hilbert Spaces.

 Chapter 8 - Generalized Euler-Lagrange Equations.
 Chapter 9 - Hamilton-Jacobi Equations.
 Chapter 10 - Pontryagin Maximum Principle.
 Chapter 11 - Optimal Control Problem for Discrete-Time Systems.
 Chapter 12 - Optimal Control Problem with Uncertain Dynamics.
 Chapter 13 - Optimal Control Problem under Stochastic Disturbances.
 Chapter 14 - Optimal Control Problem over Networks.
 Part III - Applications of Geometric Control Theory.

 Chapter 15 - Motion Planning for Mobile Robots.
 Chapter 16 - Robot Manipulation Tasks via Task Space Formulation.
 Chapter 17 - Visual Servoing Based on Image Feature Extraction.
 Chapter 18 - Model Predictive Control for Industrial Processes.",arxiv,bigscience bloomz,705.2362,0.3888888888888889,0.18319327731092436,0.36923076923076925,0.08437649307214524,1,1,0,0,1,1,5,1,0,0,0.14485618997617394,0.020405812421883784,0.1556420233463035,0.056818181818181816,1,16,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,3,0,5,1,1
Primordial Evolution in the Finitary Process Soup,"  A general and basic model of primordial evolution--a soup of reacting
finitary and discrete processes--is employed to identify and analyze
fundamental mechanisms that generate and maintain complex structures in
prebiotic systems. The processes--$\epsilon$-machines as defined in
computational mechanics--and their interaction networks both provide well
defined notions of structure. This enables us to quantitatively demonstrate
hierarchical self-organization in the soup in terms of complexity. We found
that replicating processes evolve the strategy of successively building higher
levels of organization by autocatalysis. Moreover, this is facilitated by local
components that have low structural complexity, but high generality. In effect,
the finitary process soup spontaneously evolves a selection pressure that
favors such components. In light of the finitary process soup's generality,
these results suggest a fundamental law of hierarchical systems: global
complexity requires local simplicity.
","We present an approach to primordial evolution based on the finitary process soup (FPS) model, which is a generalization of the standard quantum field theory. The FPS consists of all possible finite sequences of elementary processes that can be constructed by applying a set of basic operations to a given initial sequence. We show how this formalism allows one to describe and analyze various aspects of primordial evolution such as entropy production, particle creation, time dilation etc., using only few parameters characterizing the initial state. In particular we demonstrate that the FPS provides a natural description for the inflationary scenario with no need to introduce additional fields or particles beyond those already existing within the Standard Model. Finally, we discuss some open problems related to our approach. PACS numbers: 04.60.Kz, 11.10.Wx, 12.20.Ds, 98.80.Cq . 
I. INTRODUCTORY REMARkS

The idea behind the finitary process soup [1] , also known as the ""quantum soup"" [2] , is very simple - it represents any physical system as a collection of all its possible states. This concept has been used successfully in many areas of physics including statistical mechanics [3] , condensed matter [4] , nuclear [5] and atomic [6] physics, cosmology [7, 8] , quantum gravity [9] , string theory [10, 11] .
In this work we apply the FPS formalism to study primordial evolution during the early stages of the universe's expansion. Our main goal will be to develop a general framework allowing us to describe different phenomena associated with the Big Bang without introducing new degrees of freedom not included into the Standard Model [12] . As we shall see below, the FPS naturally leads to a description of the inflationary scenario [13] where the inflaton field [14] emerges as a consequence of the underlying dynamics rather than being introduced ad hoc. 
II. THE FINITARY PROCESS SOUP MODEL AND ITS APPLICATION TO PRIMORDIAL EVOLUTION A. General Description
Let us start by briefly reviewing the key features of the FPS formalism",arxiv,bigscience bloomz,704.3771,0.3333333333333333,0.3445378151260504,0.046153846153846156,0.42522694696607743,0,1,1,0,1,1,1,1,0,1,0.0644968150051453,0.13092051949221664,0.042801556420233464,0.14015151515151514,0,3,1,5,1,1,1,1,1,1,1,1,1,1,1,1,0,2,0,2,1,1
Two branches of neutron stars - reconciling a 2M_sun pulsar and SN1987A,"  The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the
maximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max,
due to a kaon condensation in the stellar core, implies collapse of a too
massive deleptonized protoneutron star into a black hole. This would naturally
explain the lack of a neutron star in the SN1987A remnant. On the other hand,
recent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This
contradicts the original Bethe-Brown model, but can be reconciled within
scenarios proposed in the present Letter. We consider two types of dense matter
models with high-density softening, due to a transition from a non-strange
N-phase of matter to a strangeness carrying phase S: kaon condensation and
deconfinement of quarks. Two scenarios of neutron star formation in stellar
core collapse are considered. In the first scenario, realized in sufficiently
hot and dense supernova cores, nucleation of an S-phase is sufficiently rapid
so as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the
second scenario, nucleation of the S-phase at neutron star birth is too slow to
materialize, and the star becomes cold without forming an S-phase core. Then,
stellar mass can increase via accretion, until central density \rho_crit is
reached, and the S phase forms. This N branch of neutron stars ends at
M=M_crit. We select several models of N-phase satifying the necessary condition
M^N_max > 2M_sun and combine them with models of kaon condensation and quark
deconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun,
which is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark
deconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and
PSR J0751+1807.
","We propose that the two branches in the mass distribution of neutron stars are due to different mechanisms for their formation, with one branch being formed by accretion-induced collapse (AIC) of white dwarfs into neutron stars, while another is formed through core-collapse supernovae (CCSNe). We show how this scenario can explain both the existence of massive pulsars as well as the absence of such objects in the observed sample of CCSNe remnants. The proposed model also explains why there have been no successful attempts so far at detecting gravitational waves emitted during AIC events. In addition we argue that our model provides an explanation for the apparent discrepancy between the masses inferred from observations of binary systems containing black holes or neutron stars on one hand, and those inferred from measurements of the radii of isolated neutron stars on the other. Finally, we discuss possible observational tests which could be used to verify our hypothesis.",arxiv,bigscience bloomz,705.4594,0.7222222222222222,0.19327731092436976,0.8615384615384616,0.39799331103678937,1,1,1,0,0,1,1,0,0,0,0.07673053783485856,0.12097766703366304,0.0933852140077821,0.10984848484848485,1,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Results on axion physics from the CAST Experiment at CERN,"  Axions are expected to be produced in the sun via the Primakoff process. They
may be detected through the inverse process in the laboratory, under the
influence of a strong magnetic field, giving rise to X-rays of energies in the
range of a few keV. Such an Axion detector is the CERN Axion Solar Telescope
(CAST), collecting data since 2003. Results have been published, pushing the
axion-photon coupling g$_{a\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at
95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of
magnitude lower than previous experimental limits and surpassed for the first
time limits set from astrophysical arguments based on the energy-loss concept.
The experiment is currently exploring axion masses in the range of 0.02 eV $<
m_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass
explored will be extended up to the limit of 1.1 eV, testing for the first time
the region of theoretical axion models with the axion helioscope method.
","The Axion Dark Matter Search (ADMX) experiment is designed to search for dark matter in the form of axions, which are hypothetical particles predicted by theories beyond the Standard Model.  The ADMX experiment consists of two main components: an antenna and a microwave cavity system that can be tuned over a wide range of frequencies.   In this thesis we present results obtained with the first phase of the experiment using data taken between September 2005 and March 2007.    We report limits on the coupling strength of axions to photons as well as limits on the mass of axions produced via Primakoff conversion inside a strong magnetic field.  These results improve upon previous experimental bounds by more than one order of magnitude. This work was performed under the auspices of the U.S Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. The Axion Dark Matter Search experiment is designed to search directly for dark matter in the universe in the form of axionic particles. The experiment consists of two main parts: an antenna and a microwave resonator system that can be tunable across a large frequency range. In this dissertation I will discuss our recent results from the first stage of the experiment.",arxiv,bigscience bloomz,706.0637,0.3333333333333333,0.3949579831932773,0.23076923076923078,0.5384615384615385,1,1,0,0,0,1,1,1,0,0,0.10669407409657251,0.04541161643818618,0.10505836575875487,0.041666666666666664,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Succinct Indexable Dictionaries with Applications to Encoding $k$-ary Trees, Prefix Sums and Multisets","  We consider the {\it indexable dictionary} problem, which consists of storing
a set $S \subseteq \{0,...,m-1\}$ for some integer $m$, while supporting the
operations of $\Rank(x)$, which returns the number of elements in $S$ that are
less than $x$ if $x \in S$, and -1 otherwise; and $\Select(i)$ which returns
the $i$-th smallest element in $S$. We give a data structure that supports both
operations in O(1) time on the RAM model and requires ${\cal B}(n,m) + o(n) +
O(\lg \lg m)$ bits to store a set of size $n$, where ${\cal B}(n,m) = \ceil{\lg
{m \choose n}}$ is the minimum number of bits required to store any $n$-element
subset from a universe of size $m$. Previous dictionaries taking this space
only supported (yes/no) membership queries in O(1) time. In the cell probe
model we can remove the $O(\lg \lg m)$ additive term in the space bound,
answering a question raised by Fich and Miltersen, and Pagh.
  We present extensions and applications of our indexable dictionary data
structure, including:
  An information-theoretically optimal representation of a $k$-ary cardinal
tree that supports standard operations in constant time,
  A representation of a multiset of size $n$ from $\{0,...,m-1\}$ in ${\cal
B}(n,m+n) + o(n)$ bits that supports (appropriate generalizations of) $\Rank$
and $\Select$ operations in constant time, and
  A representation of a sequence of $n$ non-negative integers summing up to $m$
in ${\cal B}(n,m+n) + o(n)$ bits that supports prefix sum queries in constant
time.
","We present succinct indexable dictionaries for encoding k-ary trees, prefix sums and multisets in $O(n)$ bits of space using only $O(\log n)$ time per operation on average (and worst-case). Our data structure is based on the concept of rank-select queries over bit vectors that are compressed by run-length coding or arithmetic coding. We also show how our results can be used to solve several problems related to range searching in static databases. 
Index Terms: Data compression, Dictionary, Ranking, Searching, Run length coding, Arithmetic coding, Range searching, Database management systems, Computational geometry, Bit vector, Compressed sensing, Data structures, Information retrieval, Data mining, Computational complexity theory, Computational biology, Computational number theory, Computational statistics, Computational algebra, Computational geometry, Computational complexity theory. Data Structures. Algorithms",arxiv,bigscience bloomz,705.0552,0.2222222222222222,0.24369747899159663,0.6051282051282051,0.3005255613951266,1,1,1,0,0,1,1,1,0,0,0.42187962153540187,0.2031760859855629,0.39299610894941633,0.23106060606060605,0,2,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
"Jets, Blazars and the EBL in the GLAST-EXIST Era","  The synergy of GLAST and the proposed EXIST mission as the Black Hole Finder
Probe in the Beyond Einstein Program is remarkable. With its full-sky per orbit
hard X-ray imaging (3-600 keV) and ""nuFnu"" sensitivity comparable to GLAST,
EXIST could measure variability and spectra of Blazars in the hard X-ray
synchrotron component simultaneous with GLAST (~10-100GeV) measures of the
inverse Compton component, thereby uniquely constraining intrinsic source
spectra and allowing measured high energy spectral breaks to measure the cosmic
diffuse extra-galactic background light (EBL) by determining the intervening
diffuse IR photon field required to yield the observed break from photon-photon
absorption. Such studies also constrain the physics of jets (and parameters and
indeed the validity of SSC models) and the origin of the >100 MeV gamma-ray
diffuse background likely arising from Blazars and jet-dominated sources. An
overview of the EXIST mission, which could fly in the GLAST era, is given
together with a synopsis of other key synergies of GLAST-EXIST science.
","The Fermi Large Area Telescope (LAT) has revolutionized our understanding of blazar jets by providing unprecedented sensitivity to gamma rays above 100 MeV. The LAT is now routinely detecting flaring activity at GeV energies that are not seen with previous instruments such as EGRET on CGRO or AGILE/GRID. This new data allows us to probe deeper into the physics of these objects than ever before. 
 
 In this talk I will discuss how we can use the upcoming generation of space-based observatories - including GLAST and EXIST - to study blazars over an even broader energy range. These missions promise to provide detailed information about the physical processes occurring within relativistic jets through observations across many decades in photon energy. We will also explore some of the exciting science questions that could be addressed using these facilities. Finally, I will present preliminary results from my recent work studying the effects of intergalactic infrared background radiation on blazar spectra.",arxiv,bigscience bloomz,705.4492,0.16666666666666666,0.29411764705882354,0.19487179487179487,0.4037267080745342,1,1,0,0,0,1,1,0,0,0,0.2556525023671762,0.03625149848820357,0.2607003891050584,0.03787878787878788,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Fourier resolved spectroscopy of 4U 1728-34: New Insights into Spectral and Temporal Properties of Low-Mass X-ray Binaries,"  Using archival RXTE data we derive the 2-16 keV Fourier-resolved spectra of
the Atoll source 4U 1728-34 in a sequence of its timing states as its low QPO
frequency spans the range between 6 and 94 Hz. The increase in the QPO
frequency accompanies a spectral transition of the source from its island to
its banana states. The banana-states' Fourier-resolved spectra are well fitted
by a single blackbody component with $kT \sim 2-3$ keV depending on the source
position in the color -- color diagram and the Fourier frequency, thus
indicating that this spectral component is responsible for the source
variability on these timescales. This result is in approximate agreement with
similar behavior exhibited by the Z sources, suggesting that, as in that case,
the boundary layer -- the likely source of the thermal component -- is
supported by radiation pressure. Furthermore, it is found that the iron line at
$\sim$6.6 keV, clearly present in the averaged spectra, not apparent within the
limitations of our measurements in the frequency-resolved spectra irrespective
of the frequency range. This would indicate that this spectral component
exhibits little variability on time scales comprising the interval
$10^{-2}-10^2$ seconds. In the island state the single blackbody model proved
inadequate, particularly notable in our lowest frequency band ($0.008-0.8$ Hz).
An absorbed powerlaw or an additive blackbody plus hard powerlaw model was
required to obtain a satisfactory fit. Statistics do not allow unambiguous
discrimination between these possible scenarios.
","We present the first simultaneous broadband (0.5-10 keV) spectral analysis of the neutron star low-mass X-ray binary system 4U 1728-34 using data obtained with XMM-Newton, Chandra, Suzaku, Swift-XRT and RXTE. We find that the source spectrum is well described by an absorbed blackbody plus power-law model in all observations except for one observation where we detect emission lines at 6.7 and 7.1 keV which are consistent with being produced by highly ionized iron. The temperature of the blackbody component varies between 0.6-0.9 keV while its radius ranges between 3-7 km depending on whether or not the absorption column density was allowed to vary freely during fitting. In addition, we also found evidence for a soft excess below 1 keV in some of our spectra. Using these results as input parameters, we simulated light curves based on the continuum models used in this work. Our simulations show that the observed flux variations can be explained solely due to changes in the blackbody normalization factor without requiring any additional variability mechanism such as obscuration effects.",arxiv,bigscience bloomz,706.1552,0.4444444444444444,0.24369747899159663,0.6,0.4495938843764931,1,1,0,0,1,1,1,0,0,0,0.12030141877887539,0.07074813724279222,0.12062256809338522,0.03787878787878788,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On Newton's law in supersymmetric braneworld models,"  We study the propagation of gravitons within 5-D supersymmetric braneworld
models with a bulk scalar field. The setup considered here consists of a 5-D
bulk spacetime bounded by two 4-D branes localized at the fixed points of an
$S^1/Z_2$ orbifold. There is a scalar field $\phi$ in the bulk which, provided
a superpotential $W(\phi)$, determines the warped geometry of the 5-D
spacetime. This type of scenario is common in string theory, where the bulk
scalar field $\phi$ is related to the volume of small compact extra dimensions.
We show that, after the moduli are stabilized by supersymmetry breaking terms
localized on the branes, the only relevant degrees of freedom in the bulk
consist of a 5-D massive spectrum of gravitons. Then we analyze the
gravitational interaction between massive bodies localized at the positive
tension brane mediated by these bulk gravitons. It is shown that the Newtonian
potential describing this interaction picks up a non-trivial contribution at
short distances that depends on the shape of the superpotential $W(\phi)$. We
compute this contribution for dilatonic braneworld scenarios $W(\phi) =
e^{\alpha \phi}$ (where $\alpha$ is a constant) and discuss the particular case
of 5-D Heterotic M-theory: It is argued that a specific footprint at micron
scales could be observable in the near future.
","We study the gravitational field equations for static spherically symmetric configurations on Randall-Sundrum type II brane-worlds with bulk cosmological constant and matter fields localized on the branes. We show that, under certain conditions, these solutions can be interpreted as black holes embedded into an anti-de Sitter space-time. In particular we find that there is no restriction to the mass parameter M0 appearing in the solution of the vacuum Einstein equation on the brane. The corresponding horizon radius r0 satisfies the relation r0 = (3M0/4π)1/3. This result implies that the Schwarzschild-de Sitter metric describes not only black hole but also naked singularity solutions. Finally, we discuss how this picture changes when one takes into account quantum corrections due to loop effects. PACS numbers: 04.20.-q; 11.10.Kk  Supersymmetry has been proposed as a possible extension of general relativity which could provide a consistent description of gravity at all scales [1] . It was shown recently [2] , however, that it does not lead to any new predictions if applied to standard four-dimensional theories. On the other hand, higher dimensional extensions of supergravity have attracted considerable attention during recent years [3] .
In this letter we consider five-dimensional supergravities [4] where the extra dimension is compactified on a circle [5] or orbifold [6] . These are known as Randall-Sundrum type I [7] and type II [8] scenarios respectively. They allow for localization of Standard Model particles [9] and their excitations [10] on the so-called visible brane while gravitons propagate freely through the bulk [11] . As a consequence they may solve some problems associated with the hierarchy between the electroweak scale and the Planck scale [12] . Moreover, such models offer interesting possibilities for constructing regular black-hole-like objects [13] - [16] .",arxiv,bigscience bloomz,705.4104,0.3888888888888889,0.6470588235294118,0.4461538461538462,0.7792642140468228,1,1,1,0,0,1,1,1,0,0,0.10883612970091722,0.0411028130619876,0.0933852140077821,0.03787878787878788,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Route to Lambda in conformally coupled phantom cosmology,"  In this letter we investigate acceleration in the flat cosmological model
with a conformally coupled phantom field and we show that acceleration is its
generic feature. We reduce the dynamics of the model to a 3-dimensional
dynamical system and analyze it on a invariant 2-dimensional submanifold. Then
the concordance FRW model with the cosmological constant $\Lambda$ is a global
attractor situated on a 2-dimensional invariant space. We also study the
behaviour near this attractor, which can be approximated by the dynamics of the
linearized part of the system. We demonstrate that trajectories of the
conformally coupled phantom scalar field with a simple quadratic potential
crosses the cosmological constant barrier infinitely many times in the phase
space. The universal behaviour of the scalar field and its potential is also
calculated. We conclude that the phantom scalar field conformally coupled to
gravity gives a natural dynamical mechanism of concentration of the equation of
state coefficient around the magical value $w_{\text{eff}}=-1$. We demonstrate
route to Lambda through the infinite times crossing the $w_{\text{eff}}=-1$
phantom divide.
","We study the evolution of an open universe with negative spatial curvature and a scalar field that is minimally coupled to gravity but has a positive kinetic energy density, known as a phantom field.  We find that this model can be mapped onto a closed universe filled with ordinary matter and radiation by means of a coordinate transformation which preserves the form of Einstein's equations.  This mapping allows us to use results obtained for standard Friedmann-Robertson-Walker models to calculate the time dependence of the scale factor and Hubble parameter during the entire history of our universe.   In particular we show how the present value of the dark energy density parameter $\Omega_{\Lambda}$ may be determined from measurements of the cosmic microwave background temperature anisotropy spectrum at large angular scales (low multipoles).   The resulting values are consistent with those inferred from observations of type Ia supernovae and large-scale structure formation. We also discuss some possible observational tests of these predictions.",arxiv,bigscience bloomz,704.1651,0.3888888888888889,0.24369747899159663,0.2512820512820513,0.40659340659340665,0,1,0,0,0,1,1,0,0,1,0.06455718820686139,0.08984993074198265,0.09727626459143969,0.07196969696969698,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1
In-plane structure and ordering at liquid sodium surfaces and interfaces from ab initio molecular dynamics,"  Atoms at liquid metal surfaces are known to form layers parallel to the
surface. We analyze the two-dimensional arrangement of atoms within such layers
at the surface of liquid sodium, using ab initio molecular dynamics (MD)
simulations based on density functional theory. Nearest neighbor distributions
at the surface indicate mostly 5-fold coordination, though there are noticeable
fractions of 4-fold and 6-fold coordinated atoms. Bond angle distributions
suggest a movement toward the angles corresponding to a six-fold coordinated
hexagonal arrangement of the atoms as the temperature is decreased towards the
solidification point. We rationalize these results with a distorted hexagonal
order at the surface, showing a mixture of regions of five and six-fold
coordination. The liquid surface results are compared with classical MD
simulations of the liquid surface, with similar effects appearing, and with ab
initio MD simulations for a model solid-liquid interface, where a pronounced
shift towards hexagonal ordering is observed as the temperature is lowered.
","We have performed ab initio molecular dynamics simulations to study the in-plane structure, order parameters, and surface tension of liquid Na(l) in contact with vacuum or solid NaCl (001). We find that the density profile is strongly dependent on the presence of an underlying substrate; it exhibits a pronounced double peak for the case without substrate but becomes single-peaked when the substrate is present. The height fluctuations are found to be larger than those observed experimentally by STM measurements. This discrepancy may arise due to the fact that our simulation cell contains only one layer of liquid sodium atoms while experiments typically involve several layers. In addition, we observe that the average nearest neighbor distance decreases as the number of layers increases. Our results show that the in-plane structure of liquid sodium can be significantly influenced by its environment. Finally, we calculate the surface tensions using two different methods and compare them against each other.",arxiv,bigscience bloomz,705.3872,0.2777777777777778,0.29411764705882354,0.16923076923076924,0.39799331103678937,1,1,0,0,0,1,1,1,0,0,0.09536405216497862,0.07158301439697319,0.08949416342412451,0.06439393939393939,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Theory of capillary-induced interactions beyond the superposition approximation,"  Within a general theoretical framework we study the effective,
deformation-induced interaction between two colloidal particles trapped at a
fluid interface in the regime of small deformations. In many studies, this
interaction has been computed with the ansatz that the actual interface
configuration for the pair is given by the linear superposition of the
interface deformations around the single particles. Here we assess the validity
of this approach and compute the leading term of the effective interaction for
large interparticle separation beyond this so-called superposition
approximation. As an application, we consider the experimentally relevant case
of interface deformations owing to the electrostatic field emanating from
charged colloidal particles. In mechanical isolation, i.e., if the net force
acting on the total system consisting of the particles plus the interface
vanishes, the superposition approximation is actually invalid. The effective
capillary interaction is governed by contributions beyond this approximation
and turns out to be attractive. For sufficiently small surface charges on the
colloids, such that linearization is strictly valid, and at asymptotically
large separations, the effective interaction does not overcome the direct
electrostatic repulsion between the colloidal particles.
","We present an analytical theory for describing capillary forces between two spherical particles in contact with each other and immersed into a liquid, which is valid even when the separation distance between them becomes comparable to their size. The theory takes into account both the effect of surface tension on the shape of menisci formed around the particles as well as the effect of gravity. We show that these effects lead to new types of attractive and repulsive capillary forces acting between the particles at small separations. In particular, we find that the gravitational force can induce a net attraction between the particles even if they are completely wetted by the liquid phase (i.e., have no dry patches). This prediction agrees very well with our numerical results obtained using Surface Evolver software package. Our theoretical predictions are also confirmed by experiments performed with polystyrene microspheres suspended in water. Capillary forces play important role in many physical phenomena such as adhesion [1] , sedimentation [2] , flotation [3] , etc.. However, despite numerous experimental studies [4] - [8] there still remains significant uncertainty about how exactly these forces depend on various parameters characterizing the system under consideration [9] . One of the main reasons behind this situation is that existing theories [10] - [12] developed within the framework of classical continuum mechanics cannot be applied directly to describe capillary interactions occurring at distances smaller than the characteristic length scale associated with the curvature of interfaces separating different phases [13] .
In order to overcome this difficulty one usually resorts to some approximate approaches based either on the concept of effective Hamaker constants [14] or on the so-called ""superposition approximation"" [15] . These methods allow one to obtain simple expressions for the total interaction energy but do not provide any information about its dependence on the detailed geometry of the problem [16] . Moreover, it has been shown recently [17] that the latter approach fails...",arxiv,bigscience bloomz,706.0013,0.3333333333333333,0.546218487394958,0.3128205128205128,0.8795986622073578,0,1,0,0,0,1,1,0,0,0,0.05802851247649454,0.10059301099372459,0.07392996108949416,0.06818181818181818,0,0,2,5,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Softening of the stiffness of bottlebrush polymers by mutual interaction,"  We study bottlebrush macromolecules in a good solvent by small-angle neutron
scattering (SANS), static light scattering (SLS), and dynamic light scattering
(DLS). These polymers consist of a linear backbone to which long side chains
are chemically grafted. The backbone contains about 1600 monomer units (weight
average) and every second monomer unit carries side-chains with ca. 60 monomer
units. The SLS- and SANS data extrapolated to infinite dilution lead to the
form factor of the polymer that can be described in terms of a worm-like chain
with a contour length of 380 nm and a persistence length of 17.5 nm. An
analysis of the DLS data confirm these model parameters. The scattering
intensities taken at finite concentration can be modeled using the polymer
reference interaction site model. It reveals a softening of the bottlebrush
polymers caused by their mutual interaction. We demonstrate that the
persistence decreases from 17.5 nm down to 5 nm upon increasing the
concentration from dilute solution to the highest concentration 40.59 g/l under
consideration. The observed softening of the chains is comparable to the
theoretically predicted decrease of the electrostatic persistence length of
linear polyelectrolyte chains at finite concentrations.
","The effect of intermolecular interactions on the elastic properties of bottlebrush polymer networks is investigated using molecular dynamics simulations and experimental measurements. The results show that the network becomes softer with increasing density, which can be explained in terms of an increase in the number of entanglements between neighboring chains. This softening behavior is also observed experimentally for bottlebrush polyurethane networks prepared at different densities. It is found that the simulated stress-strain curves are well described by the Gent model, where the effective spring constant decreases as the density increases. These findings suggest that the mechanical properties of bottlebrush polymer gels can be tuned by changing their density. 
 
 Soft materials such as rubbers have been widely used in many applications including tires, seals, adhesives, and biomaterials because they exhibit unique physical characteristics such as high extensibility and low modulus [1–3]. In particular, bottlebrush polymers consisting of densely grafted side chains have attracted considerable attention due to their outstanding mechanical properties [4–6]. For example, it has recently been reported that bottlebrush poly(ether urethane)s (PEUs), synthesized via ring-opening metathesis polymerization [7, 8], possess higher tensile strength than conventional PEU elastomers [9]. However, despite these advantages, there remain some challenges associated with the use of bottlebrush polymers in practical applications. One of them is how to control the mechanical properties of bottle brushes since the macroscopic properties depend strongly on the microstructure [10, 11]. Therefore, understanding the relationship between structure and property is important for designing new types of bottlebrush-based materials. 
In this study, we investigate the influence of chain density on the mechanical properties of bottle-brush polyurethanes (BPUs). We find that BPUs become softer when the density increases. To understand this phenomenon, we perform molecular dynamics (MD) simulations based on coarse-grained models [12]. Our simulation results reveal that the network becomes sof...",arxiv,bigscience bloomz,705.3329,0.5,0.6974789915966387,0.35384615384615387,0.8136645962732919,1,1,0,0,0,1,1,0,0,0,0.10116492427135748,0.07276834396064974,0.14785992217898833,0.06818181818181818,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
X-ray Timing Observations of PSR J1930+1852 in the Crab-like SNR G54.1+0.3,"  We present new X-ray timing and spectral observations of PSR J1930+1852, the
young energetic pulsar at the center of the non-thermal supernova remnant
G54.1+0.3. Using data obtained with the Rossi X-ray Timing Explorer and Chandra
X-ray observatories we have derived an updated timing ephemeris of the 136 ms
pulsar spanning 6 years. During this interval, however, the period evolution
shows significant variability from the best fit constant spin-down rate of
$\dot P = 7.5112(6) \times 10^{-13}$ s s$^{-1}$, suggesting strong timing noise
and/or glitch activity. The X-ray emission is highly pulsed ($71\pm5%$
modulation) and is characterized by an asymmetric, broad profile ($\sim 70%$
duty cycle) which is nearly twice the radio width. The spectrum of the pulsed
emission is well fitted with an absorbed power law of photon index $\Gamma =
1.2\pm0.2$; this is marginally harder than that of the unpulsed component. The
total 2-10 keV flux of the pulsar is $1.7 \times 10^{-12}$ erg cm$^{-2}$
s$^{-1}$. These results confirm PSR J1930+1852 as a typical Crab-like pulsar.
","We report on X-ray timing observations of the pulsar candidate PSR J1930+1855 located at the center of the supernova remnant (SNR) G54.1+0. 
 
 The source was discovered by Chandra and confirmed as a pulsar with XMM-Newton, but its spin period is not stable over time scales longer than one day. We performed two sets of pointed RXTE observations to study this behavior further. In both cases we found that the pulse frequency decreases smoothly during our observation runs. This trend can be described well using an exponential decay model for which we find characteristic timescales of 1.1 days and 0.7 days respectively. These values are consistent with those reported previously based on Chandra data alone. However, when comparing these results directly it should be noted that the uncertainties associated with the previous measurements were significantly larger due to the lower signal-to-noise ratio achieved with Chandra compared to RXTE.",arxiv,bigscience bloomz,704.0973,0.3333333333333333,0.29411764705882354,0.22564102564102564,0.3750597228858099,1,1,1,0,0,1,1,0,0,0,0.10934449932263197,0.06297928353247462,0.08560311284046693,0.06439393939393939,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Collisions between equal sized ice grain agglomerates,"  Following the recent insight in the material structure of comets,
protoplanetesimals are assumed to have low densities and to be highly porous
agglomerates. It is still unclear if planetesimals can be formed from these
objects by collisional growth. Therefore, it is important to study numerically
the collisional outcome from low velocity impacts of equal sized porous
agglomerates which are too large to be examined in a laboratory experiment. We
use the Lagrangian particle method Smooth Particle Hydrodynamics to solve the
equations that describe the dynamics of elastic and plastic bodies.
Additionally, to account for the influence of porosity, we follow a previous
developed equation of state and certain relations between the material strength
and the relative density. Collisional growth seems possible for rather low
collision velocities and particular material strengths. The remnants of
collisions with impact parameters that are larger than 50% of the radius of the
colliding objects tend to rotate. For small impact parameters, the colliding
objects are effectively slowed down without a prominent compaction of the
porous structure, which probably increases the possibility for growth. The
protoplanetesimals, however, do not stick together for the most part of the
employed material strengths. An important issue in subsequent studies has to be
the influence of rotation to collisional growth. Moreover, for realistic
simulations of protoplanetesimals it is crucial to know the correct material
parameters in more detail.
","We present results on collisions between two identical spherical grains with radii ranging from 0.1 to 1 mm and velocities up to 10 m/s, which are relevant for the growth of planetesimals in protoplanetary disks. We find that the collision outcome depends strongly on the impact velocity. At low velocities (<5 m/s), the colliding particles stick together after the first contact without any fragmentation or erosion. For higher velocities we observe bouncing, sticking, partial fragmentation, and complete fragmentation depending on the impact angle. The transition between different outcomes is smooth but can be described by simple scaling laws. In particular, we show that the critical velocity at which the transition from sticking to bouncing occurs scales as vcrit ∝ R0.6 where R is the radius of one particle. This dependence agrees well with recent experiments performed under microgravity conditions. Finally, we discuss how these findings affect our understanding of dust coagulation in protoplanetary discs.",arxiv,bigscience bloomz,705.2672,0.5555555555555556,0.3445378151260504,0.5384615384615384,0.3951266125179169,0,0,0,0,0,1,0,0,0,0,0.05518253747794224,0.07105779360193541,0.0622568093385214,0.07575757575757576,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
The competition of hydrogen-like and isotropic interactions on polymer collapse,"  We investigate a lattice model of polymers where the nearest-neighbour
monomer-monomer interaction strengths differ according to whether the local
configurations have so-called ``hydrogen-like'' formations or not. If the
interaction strengths are all the same then the classical $\theta$-point
collapse transition occurs on lowering the temperature, and the polymer enters
the isotropic liquid-drop phase known as the collapsed globule. On the other
hand, strongly favouring the hydrogen-like interactions give rise to an
anisotropic folded (solid-like) phase on lowering the temperature. We use Monte
Carlo simulations up to a length of 256 to map out the phase diagram in the
plane of parameters and determine the order of the associated phase
transitions. We discuss the connections to semi-flexible polymers and other
polymer models. Importantly, we demonstrate that for a range of energy
parameters two phase transitions occur on lowering the temperature, the second
being a transition from the globule state to the crystal state. We argue from
our data that this globule-to-crystal transition is continuous in two
dimensions in accord with field-theory arguments concerning Hamiltonian walks,
but is first order in three dimensions.
","We study the effect of competing short-range attractive and repulsive interactions in a model for collapsed polymers, which are described by an effective one-dimensional potential with two minima separated by a barrier. We show that this system exhibits a rich phase diagram as function of temperature T , interaction strength U0 and asymmetry parameter . The main results are: (i) For small values of we find three different phases: a low-temperature disordered phase, a high-temperature ordered phase and a critical point separating them. (ii) In the limit of large barriers between the wells, i.e., when becomes very large or T decreases to zero, the transition line approaches the value Uc = 2U0/3 predicted by mean-field theory. 
 
 Introduction 
 
 Collapsed polymers have been studied extensively over many years [1]-[6]. They can be found in biological systems such as proteins [7][8][9], but also occur in synthetic materials like micelles [10]-[12]. A common feature of these systems is their ability to form compact structures due to strong shortrange attractions combined with longer-ranged repulsions. This leads to a double-well type of potential energy landscape [13][14][15], where particles tend to aggregate into clusters [16]. These aggregates may undergo structural changes [17], resulting in transitions between different states [18]. Such phenomena are often observed experimentally [19][20][21] [22]. However, despite extensive research efforts there still remain open questions about the nature of the underlying mechanisms leading to these complex behaviors [23].",arxiv,bigscience bloomz,706.2162,0.3333333333333333,0.49579831932773116,0.29743589743589743,0.621595795508839,1,1,0,0,1,1,1,1,0,0,0.07338023988329717,0.05940981265608459,0.08560311284046693,0.06439393939393939,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Simulation of ASTROD I test mass charging due to solar energetic particles,"  As ASTROD I travels through space, its test mass will accrue charge due to
galactic cosmic-rays and solar energetic particles incident on the spacecraft.
This test mass charge will result in Coulomb forces between the test mass and
the surrounding electrodes. In earlier work using the GEANT4 toolkit, we
predicted a net charging rate of nearly 9.0 +e/s from cosmic-ray protons
between 0.1 and 1000 GeV at solar maximum, and rising to 26.5 +e/s at solar
minimum. Here we use GEANT4 to simulate the charging process due to solar
energetic particle events and to estimate the magnitude of acceleration noise
due to this charging. The predicted charging rates range from 2840 to 64300
+e/s, at peak intensity, for the 4 largest SEP events in September and October
1989. For the 2 larger events, the acceleration disturbances due to charging
exceeds the ASTROD I acceleration noise budget requirement. Continuous
discharge should be considered for suppressing this charging noise. The
acceleration noise during the 2 small events is well below the design target,
although during these events, the net charging rate will be dominated by these
solar fluxes.
","The Astrodynamics Space Test of Relativity using Optical Devices (ASTROD) mission is proposed as an experiment for testing the gravitational theory in space, and it will be launched into orbit around L2 point by 2020.  The ASTROD satellite system consists of two satellites with four free-floating test masses each. In this study we simulated the charging process of these test masses caused by solar energetic particles during their lifetime in space. We used the SPENVIS software package developed at the European Space Research and Technology Centre (ESTEC). Our results show that the maximum charge accumulated on one of the test masses can reach up to 1.5 nC after 10 years' exposure time. This value is much higher than the expected measurement uncertainty of 0.1 nC. Therefore, it should be taken into account when designing the electrostatic control systems of the ASTROD satellites. Keywords: Charging, Solar Energetic Particles, ASTROD",arxiv,bigscience bloomz,704.3493,0.3888888888888889,0.3445378151260504,0.3230769230769231,0.3779264214046823,0,1,0,0,0,1,1,1,0,1,0.0776722309826514,0.07301081766492863,0.08171206225680934,0.07575757575757576,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Catastrophic eruption of magnetic flux rope in the corona and solar wind with and without magnetic reconnection,"  It is generally believed that the magnetic free energy accumulated in the
corona serves as a main energy source for solar explosions such as coronal mass
ejections (CMEs). In the framework of the flux rope catastrophe model for CMEs,
the energy may be abruptly released either by an ideal magnetohydrodynamic
(MHD) catastrophe, which belongs to a global magnetic topological instability
of the system, or by a fast magnetic reconnection across preexisting or
rapidly-developing electric current sheets. Both ways of magnetic energy
release are thought to be important to CME dynamics. To disentangle their
contributions, we construct a flux rope catastrophe model in the corona and
solar wind and compare different cases in which we either prohibit or allow
magnetic reconnection to take place across rapidly-growing current sheets
during the eruption. It is demonstrated that CMEs, even fast ones, can be
produced taking the ideal MHD catastrophe as the only process of magnetic
energy release. Nevertheless, the eruptive speed can be significantly enhanced
after magnetic reconnection sets in. In addition, a smooth transition from slow
to fast eruptions is observed when increasing the strength of the background
magnetic field, simply because in a stronger field there is more free magnetic
energy at the catastrophic point available to be released during an eruption.
This suggests that fast and slow CMEs may have an identical driving mechanism.
","We investigate the evolution of an eruptive coronal mass ejection (CME) by using three-dimensional magnetohydrodynamic simulations, which include both ideal MHD effects and resistivity. The initial condition is constructed as follows. First we solve the Grad-Shafranov equation for force-free equilibrium to obtain the distribution of poloidal current density on the surface of a torus-like structure. Then we construct a 3D model of the torus-like structure by assuming that it has uniform temperature T = 1 MK and pressure P = 0.1 dyn cm-2 inside its volume. We also assume that there are two types of plasma flows along the field lines; one is slow solar wind flowing out from the bottom boundary at r = 2 R_sun , where Rsun denotes the radius of the Sun, and another is fast solar wind flowing into the top boundary at r = 20 Rsun . Finally, we add random fluctuations to the velocity fields so that they have kinetic energy comparable to their thermal energies. 
 
 In our simulation runs, we find three different phases during the CME evolution. During phase I, the magnetic flux rope rises slowly due to the Lorentz force associated with the toroidal component of the magnetic field. At t ~ 50 min., when the height reaches about 5 RSUN , the rising motion suddenly accelerates because of the rapid expansion of the flux rope's cross section caused by magnetic reconnection between open field lines and closed loops around the flux rope. This acceleration continues until the flux rope reaches the upper boundary at t ~ 80 min. . 
 
 During phase II, the flux rope expands rapidly outward while maintaining its shape. After reaching the maximum size at t ~ 90 min. , however, the flux rope starts contracting inward again. As a result, the flux rope becomes thinner than before but still maintains its twisted structure. Meanwhile, the surrounding open field lines become more bent toward each other near the center of the flux rope. These results suggest that the flux rope undergoes a kink instability after expanding outward beyond its critical size.",arxiv,bigscience bloomz,705.3885,0.3888888888888889,0.7983193277310925,0.517948717948718,0.9426660296225513,1,1,0,0,0,1,1,1,0,1,0.1414079459591663,0.11780731188920503,0.1517509727626459,0.125,0,2,3,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
"A Novel String Derived Z' With Stable Proton, Light-Neutrinos and R-parity violation","  The Standard Model indicates the realization of grand unified structures in
nature, and can only be viewed as an effective theory below a higher energy
cutoff. While the renormalizable Standard Model forbids proton decay mediating
operators due to accidental global symmetries, many extensions of the Standard
Model introduce such dimension four, five and six operators. Furthermore,
quantum gravity effects are expected to induce proton instability, indicating
that the higher energy cutoff scale must be above 10^{16}GeV. Quasi-realistic
heterotic string models provide the arena to explore how perturbative quantum
gravity affects the particle physics phenomenology. An appealing explanation
for the proton longevity is provided by the existence of an Abelian gauge
symmetry that suppresses the proton decay mediating operators. Additionally,
such a low-scale U(1) symmetry should: allow the suppression of the left-handed
neutrino masses by a seesaw mechanism; allow fermion Yukawa couplings to the
electroweak Higgs doublets; be anomaly free; be family universal. These
requirements render the existence of such U(1) symmetries in quasi-realistic
heterotic string models highly non-trivial. We demonstrate the existence of a
U(1) symmetry that satisfies all of the above requirements in a class of
left-right symmetric heterotic string models in the free fermionic formulation.
The existence of the extra Z' in the energy range accessible to future
experiments is motivated by the requirement of adequate suppression of proton
decay mediation. We further show that while the extra U(1) forbids dimension
four baryon number violating operators it allows dimension four lepton number
violating operators and R-parity violation.
","We propose a new string derived model with stable proton in which the lightest supersymmetric particle (LSP) is not neutralino but gravitino. The LSP decays into photon or neutrino-antineutrino pair through gravitational interaction. In this scenario we can explain the observed dark matter abundance without conflicting with other experimental results such as relic density measurement by WMAP experiment. We also show that our model predicts interesting signatures at LHC experiments. Introduction:-The discovery of Higgs boson [1-3] has opened up an exciting possibility to explore physics beyond Standard Model(SM). Supersymmetry(SUSY), one of the most promising extensions of SM [4] , provides natural solution for hierarchy problem [5] . However, SUSY models are severely constrained by various experimental observations [6] .
In order to solve these problems, several authors have proposed different mechanisms [7-9]. One of them is introducing additional gauge symmetries [10] . Another way is adding extra dimensions [11] . Recently, it was shown that there exists a class of string derived models where the lightest superpartner is gravitino [12] . Gravitino is weakly interacting massive particle so its decay rate is suppressed compared to neutralino case [13] . This feature makes gravitino a good candidate for cold dark matter [14] . Moreover, if gravitino mass m 3/2 < 1 GeV then its lifetime becomes longer than age of universe [15] . Therefore, gravitino may be regarded as a viable candidate for dark matter [16] . On the other hand, gravitino is unstable because it couples to gravity [17] . It decays into photon or lepton-neutrino pairs [18] . If gravitino is heavier than 100 MeV then its decay products will contribute to diffuse gamma ray background [19] . Thus, gravitino should satisfy following conditions [20] :",arxiv,bigscience bloomz,704.1256,0.5,0.8991596638655462,0.6461538461538462,0.7763975155279503,1,1,1,0,1,1,1,1,0,0,0.062495586888128146,0.0466122387955655,0.08949416342412451,0.03787878787878788,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Revisiting the slow dynamics of a silica melt using Monte Carlo simulations,"  We implement a standard Monte Carlo algorithm to study the slow, equilibrium
dynamics of a silica melt in a wide temperature regime, from 6100 K down to
2750 K. We find that the average dynamical behaviour of the system is in
quantitative agreement with results obtained from molecular dynamics
simulations, at least in the long-time regime corresponding to the
alpha-relaxation. By contrast, the strong thermal vibrations related to the
Boson peak present at short times in molecular dynamics are efficiently
suppressed by the Monte Carlo algorithm. This allows us to reconsider silica
dynamics in the context of mode-coupling theory, because several shortcomings
of the theory were previously attributed to thermal vibrations. A mode-coupling
theory analysis of our data is qualitatively correct, but quantitative tests of
the theory fail, raising doubts about the very existence of an avoided
singularity in this system. We discuss the emergence of dynamic heterogeneity
and report detailed measurements of a decoupling between translational
diffusion and structural relaxation, and of a growing four-point dynamic
susceptibility. Dynamic heterogeneity appears to be less pronounced than in
more fragile glass-forming models, but not of a qualitatively different nature.
","We revisit the slow relaxation in a model glass-forming system, namely a binary mixture of Lennard-Jones particles interacting via a Weeks-Chandler-Andersen potential with an additional repulsive shoulder at short distances. The main goal is to investigate whether this simple model can reproduce some of the features observed experimentally for silicate melts and glasses such as the stretched exponential decay of the intermediate scattering function or the presence of two distinct time scales in the structural relaxation process. To that end we perform molecular dynamics (MD) and Monte Carlo (MC) computer simulations on systems containing up to N = 1000 particles. In particular, by means of MC simulations we are able to study much larger systems than those accessible through MD runs. Our results show that both methods give rise to similar relaxation patterns but there exist subtle differences between them which may be relevant when comparing theory and experiment. Finally, we discuss how our findings compare with previous theoretical predictions based on mode-coupling theories.",arxiv,bigscience bloomz,705.2783,0.2777777777777778,0.24369747899159663,0.3333333333333333,0.4237935977066412,0,1,0,0,0,1,1,0,0,0,0.13372174258203387,0.08115421353544276,0.14007782101167315,0.06060606060606061,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Hamiltonian formalism in Friedmann cosmology and its quantization,"  We propose a Hamiltonian formalism for a generalized
Friedmann-Roberson-Walker cosmology model in the presence of both a variable
equation of state (EOS) parameter $w(a)$ and a variable cosmological constant
$\Lambda(a)$, where $a$ is the scale factor. This Hamiltonian system containing
1 degree of freedom and without constraint, gives Friedmann equations as the
equation of motion, which describes a mechanical system with a variable mass
object moving in a potential field. After an appropriate transformation of the
scale factor, this system can be further simplified to an object with constant
mass moving in an effective potential field. In this framework, the $\Lambda$
cold dark matter model as the current standard model of cosmology corresponds
to a harmonic oscillator. We further generalize this formalism to take into
account the bulk viscosity and other cases. The Hamiltonian can be quantized
straightforwardly, but this is different from the approach of the
Wheeler-DeWitt equation in quantum cosmology.
","We present the Hamiltonian formulation for general relativity with matter fields on an arbitrary spacetime manifold, including both classical and quantum aspects. The basic idea is to use the ADM decomposition of the metric into space and time components as well as lapse and shift functions. We then introduce canonical momenta conjugate to these variables which are used to construct the primary constraints of the theory. These constraints generate gauge transformations under which all physical quantities must be invariant. In order to obtain the correct number of degrees of freedom we have to impose secondary constraints that eliminate unphysical modes. Finally, we perform the canonical quantization by promoting the phase-space variables to operators acting on wave-functions defined over superspace (the space of all possible metrics). This leads us to the Wheeler-DeWitt equation whose solutions can be interpreted as probability amplitudes between different states of the universe. We also discuss how this approach could be applied to inflationary models.",arxiv,bigscience bloomz,704.0672,0.2777777777777778,0.3445378151260504,0.14871794871794872,0.40659340659340665,1,1,0,0,0,1,1,0,0,0,0.11281796994164618,0.04067399194847953,0.058365758754863814,0.01893939393939394,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1
"Controlling for individual heterogeneity in longitudinal models, with applications to student achievement","  Longitudinal data tracking repeated measurements on individuals are highly
valued for research because they offer controls for unmeasured individual
heterogeneity that might otherwise bias results. Random effects or mixed models
approaches, which treat individual heterogeneity as part of the model error
term and use generalized least squares to estimate model parameters, are often
criticized because correlation between unobserved individual effects and other
model variables can lead to biased and inconsistent parameter estimates.
Starting with an examination of the relationship between random effects and
fixed effects estimators in the standard unobserved effects model, this article
demonstrates through analysis and simulation that the mixed model approach has
a ``bias compression'' property under a general model for individual
heterogeneity that can mitigate bias due to uncontrolled differences among
individuals. The general model is motivated by the complexities of longitudinal
student achievement measures, but the results have broad applicability to
longitudinal modeling.
","We propose an extension of the linear mixed model that allows researchers to control for unobserved individual heterogeneity when estimating treatment effects using panel data. We show how this approach can be used to estimate the effect of school choice on test scores and college enrollment decisions while controlling for selection bias due to unobserved differences between students who choose different schools. Our results suggest that school choice has no significant impact on either test scores or college enrollment rates once we account for unobserved individual characteristics. 
 
 Keywords: Panel Data, Mixed Models, Treatment Effects, School Choice 
 
 
 
 1 Introduction 
 
 In recent years there have been numerous studies examining the relationship between school choice policies and student outcomes (see Hanushek et al., 2007 , for a review). Most of these studies use cross-sectional data to compare average performance across groups of students attending public versus private schools. However, it is well known that such comparisons are subject to endogeneity problems because they do not take into account the fact that students self-select into different types of schools based on their observed and unobserved characteristics (Hoxby & Weingarth, 2005) . This problem may lead to biased estimates if the factors driving students' choices also affect their academic performance. 
 
 2 The Model 
In order to address this issue, several authors have proposed alternative estimation strategies aimed at correcting for sample selectivity by explicitly modeling the process through which individuals make educational choices (e.g., Heckman, 1979; Lee, 1997; Wooldridge, 2002 ) . These approaches typically rely on parametric assumptions about the distribution of the error terms associated with both the outcome equation and the selection equation. For example, one popular method consists of jointly estimating two equations -one describing the probability that each individual chooses a particular type of school,...",arxiv,bigscience bloomz,706.1401,0.16666666666666666,0.4453781512605043,0.1282051282051282,0.7993311036789298,0,0,0,0,1,1,1,1,0,1,0.14255814250539758,0.09191051596543034,0.13229571984435798,0.09848484848484848,0,0,2,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
"Asteroid Deflection: How, where and when?","  To deflect impact-trajectory of massive km^3 and spinning asteroid by a few
terrestrial radius one need a large momentum exchange. The dragging of huge
spinning bodies in space by external engine seems difficult or impossible. Our
solution is based on the landing of multi screw-rockets, powered by
mini-nuclear engines, on the body, that dig a small fraction of the soil
surface, to use as an exhaust propeller, ejecting it vertically in phase among
themselves. Such a mass ejection increases the momentum exchange, their number
redundancy guarantees the stability of the system. The slow landing (below 40
cm s^-1) of each engine-unity at those lowest gravity field, may be achieved by
save rolling and bouncing along the surface. The engine array tuned activity,
overcomes the asteroid angular velocity. Coherent turning of the jet heads
increases the deflection efficiency. A procession along its surface may
compensate at best the asteroid spin. A small skin-mass (about 2 10^4 tons) may
be ejected by mini nuclear engines. Such prototypes may also build first save
galleries for humans on the Moon. Conclusive deflecting tests might be
performed on remote asteroids. The incoming asteroid 99942 Apophis (just 2% of
km^3) may be deflected safely a few Earth radius. How to tag its trajectory is
described. Its encounter maybe not just a hazard but an opportunity, learning
how to land, dig, build and also to nest save human station inside. Asteroids
amplified deflections by gravity swing maybe driven into longest planetary
journeys. Mars journey may benefict by Phobos natural asteroid parking and
fueling role.
","The possibility that an asteroid could hit the Earth is not new.  In fact, it has been discussed for many years in popular science fiction books such as H G Wells' The War of the Worlds (1898) or Arthur C Clarke's 2001 Space Odyssey (1968). However, there are now several groups around the world working on ways to deflect asteroids before they impact with our planet.   This talk will discuss how this might be achieved by using nuclear explosions, kinetic impacts, laser beams or even tractor beams. It will also look at what would happen if one were successful - would we survive?  Would life return to normal?
This talk was given at the University of Southampton on 24th February 2015. For more information about Prof David Jewitt please visit his website: http://www.astro.su.se/~david/ . 
Prof David Jewitt is Professor of Planetary Science at the University of Southampton. He leads the Asteroid Terrestrial-impact Last Alert System (ATLAS), which monitors near-Earth objects including asteroids and comets.",arxiv,bigscience bloomz,705.1805,0.8333333333333334,0.4453781512605043,0.6871794871794872,0.4237935977066412,1,1,0,0,0,1,1,1,1,1,0.08809116072450804,0.07540378838611403,0.11284046692607004,0.09090909090909091,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
The absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type,"  We show that the Galois group $Gal(\bar{\Q} /\Q)$ operates faithfully on the
set of connected components of the moduli spaces of surfaces of general type,
and also that for each element $\sigma \in Gal(\bar{\Q} /\Q)$ different from
the identity and from complex conjugation, there is a surface of general type
such that $X$ and the Galois conjugate variety $X^{\sigma}$ have nonisomorphic
fundamental groups. The result was announced by the second author at the
Alghero Conference 'Topology of algebraic varieties' in september 2006. Before
the present paper was actually written, we received a very interesting preprint
by Robert Easton and Ravi Vakil (\cite{e-v}), where it is proven, with a
completely different type of examples, that the Galois group $Gal(\bar{\Q}
/\Q)$ operates faithfully on the set of irreducible components of the moduli
spaces of surfaces of general type. We also give other simpler examples of
surfaces with nonisomorphic fundamental groups which are Galois conjugate,
hence have isomorphic algebraic fundamental groups.
","We prove that for any surface S of general type, the action of its absolute Galois group G(S) on the set of connected components of the modulis space M_g(S) is faithful.  This result has been conjectured by Grothendieck and proved in many cases (e.g., when g = 0 or 1).  We use this to show that if S admits an automorphism of order p > 2 then it also admits one of order q prime to p; we give examples where both orders are arbitrarily large. The proof relies on results about the existence of certain families of curves on S which have been obtained recently using techniques from algebraic geometry and number theory. In particular, we make essential use of the fact that the canonical map of such a curve C onto P^1 is birational; this implies that the image of C under the Albanese map Alb_S : S -> Alb_S(S) is not contained in a fiber of Alb_S.",arxiv,bigscience bloomz,706.1466,0.16666666666666666,0.19327731092436976,0.1794871794871795,0.4123268036311515,1,1,0,0,1,1,1,1,0,0,0.2856452959138399,0.08670145433915974,0.26459143968871596,0.07575757575757576,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Collective states of the odd-mass nuclei within the framework of the Interacting Vector Boson Model,"  A supersymmetric extension of the dynamical symmetry group $Sp^{B}(12,R)$ of
the Interacting Vector Boson Model (IVBM), to the orthosymplectic group
$OSp(2\Omega/12,R)$ is developed in order to incorporate fermion degrees of
freedom into the nuclear dynamics and to encompass the treatment of odd mass
nuclei. The bosonic sector of the supergroup is used to describe the complex
collective spectra of the neighboring even-even nuclei and is considered as a
core structure of the odd nucleus. The fermionic sector is represented by the
fermion spin group $SO^{F}(2\Omega)\supset SU^{F}(2)$.
  The so obtained, new exactly solvable limiting case is applied for the
description of the nuclear collective spectra of odd mass nuclei. The
theoretical predictions for different collective bands in three odd mass
nuclei, namely $^{157}Gd$, $^{173}Yb$ and $^{163}Dy$ from rare earth region are
compared with the experiment. The $B(E2)$ transition probabilities for the
$^{157}Gd$ and $^{163}Dy$ between the states of the ground band are also
studied. The important role of the symplectic structure of the model for the
proper reproduction of the $B(E2)$ behavior is revealed. The obtained results
reveal the applicability of the models extension.
","The collective properties of odd-mass nuclei are investigated in terms of the interacting vector boson model (IVBM). The IVBM is based on an effective Lagrangian density that describes the coupling between nucleons and mesons, including the rho-meson field as well as the omega-meson fields with their respective neutral currents. In this work we have used the extended version of the IVBM which includes also the delta-resonance degrees of freedom. We have calculated the energy levels for some selected even-even nuclei along with those corresponding to the first excited state of neighboring odd-A nuclei using the same set of parameters. It has been found that the inclusion of the delta resonance leads to better agreement with experimental data than without it. This fact indicates that the role played by the delta resonance should not be neglected when studying nuclear structure phenomena such as pairing correlations or shape coexistence. Finally, we have studied the effect of the spin-orbit interaction on the ground-state band built upon the lowest 0+ state.",arxiv,bigscience bloomz,705.2169,0.3888888888888889,0.29411764705882354,0.3076923076923077,0.43239369326325855,1,1,0,0,0,1,1,0,0,0,0.14759612356669244,0.04138423756595421,0.13229571984435798,0.03787878787878788,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Simulation of Heme using DFT+U: a step toward accurate spin-state energetics,"  We investigate the DFT+U approach as a viable solution to describe the
low-lying states of ligated and unligated iron heme complexes. Besides their
central role in organometallic chemistry, these compounds represent a
paradigmatic case where LDA, GGA, and common hybrid functionals fail to
reproduce the experimental magnetic splittings. In particular, the imidazole
pentacoordinated heme is incorrectly described as a triplet by all usual DFT
flavors. In this study we show that a U parameter close to 4 eV leads to spin
transitions and molecular geometries in quantitative agreement with
experiments, and that DFT+U represents an appealing tool in the description of
iron porphyrin complexes, at a much reduced cost compared to correlated
quantum-chemistry methods. The possibility of obtaining the U parameter from
first-principles is explored through a self-consistent linear-response
formulation. We find that this approach, which proved to be successful in other
iron systems, produces in this case some overestimation with respect to the
optimal values of U.
","The electronic structure and magnetic properties of heme are investigated by density functional theory (DFT) with the Hubbard U correction for strong electron correlation effects, which is essential to reproduce the correct ground state spin multiplicity in this system. The calculated results show that the ferromagnetic coupling between iron ions leads to an antiferromagnetically ordered ground state when the axial ligands are included. In addition, we find that the inclusion of the solvent effect on the geometry optimization does not change the energy difference significantly but it can affect the relative stability among different spin states. Finally, our calculations suggest that the high-spin state may be more stable than previously thought based on experimental measurements. This work was supported by the National Natural Science Foundation of China under Grant No. 11404160. We thank Prof. Yi-Kai Wu at Peking University for helpful discussions. 
 
 Introduction 
 
 Heme is one of the most important cofactors found in many proteins involved in biological processes such as oxygen transport, storage, sensing, and catalysis1-5. It consists of a porphyrin ring coordinated to Fe(II), where four nitrogen atoms form two pyrrole rings connected through methine bridges6-8. Due to its importance in biology, there have been numerous theoretical studies investigating the structural9-12, optical13-15, vibrational16-19, and magnetic20-24 properties of heme. However, despite these efforts, some fundamental questions remain unanswered regarding the electronic structure and magnetic behavior of heme25-27. For example, although the ground state spin multiplicity has been determined experimentally28-30, the exact nature of the excited spin states remains unclear31-33. Moreover, the origin of the observed ferromagnetic coupling between iron centers34-36 still needs further investigation37-39.",arxiv,bigscience bloomz,705.2743,0.2777777777777778,0.596638655462185,0.1794871794871795,0.7133301481127569,0,1,0,0,0,1,1,0,0,0,0.1133200956958544,0.08389296841488192,0.13618677042801555,0.05303030303030303,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Z^0 \to 2\gamma and the Twisted Coproduct of the Poincar\'{e} Group,"  Yang's theorem forbids the process $Z^0 \to 2\gamma$ in any Poincar\'{e}
invariant theory if photons are bosons and their two-particle states transform
under the Poincar\'{e} group in the standard way (under the standard coproduct
of the Poincar\'{e} group). This is an important result as it does not depend
on the assumptions of quantum field theory. Recent work on noncommutative
geometry requires deforming the above coproduct by the Drinfel'd twist. We
prove that $Z^0 \to 2\gamma$ is forbidden for the twisted coproduct as well.
This result is also independent of the assumptions of quantum field theory. As
an illustration of the use of our general formulae, we further show that $Z^0
\to \nu + \nu$ is forbidden for the standard or twisted coproduct of the
Poincar\'{e} group if the neutrino is massless, even if lepton number is not
conserved. This is a special case of our general result that a massive particle
of spin $j$ cannot decay into two identical massless particles of the same
helicity if $j$ is odd, regardless of the coproduct used.
","We study the decay Z_0\to 2 \gamma in terms of the twisted coproduct on the Poincare group, which is related to the Wess-Zumino-Witten model.  We show that this process can be described by an effective Lagrangian with two coupling constants, one for each helicity state of the photon pair. The corresponding Feynman rules are derived using the method developed in Ref. [1] . In particular we find that there exists no contribution from the axial vector current at tree level. This result agrees with the prediction based on chiral symmetry arguments [2] , but disagrees with previous calculations [3, 4] .
The results presented here were obtained during my stay as a postdoctoral fellow at Harvard University supported by the Alexander von Humboldt Foundation. I would like to thank Prof. M. J. Duffy for his hospitality. Introduction -In recent years much attention has been paid to the investigation of processes involving photons in connection with their possible role in physics beyond the Standard Model (SM). One such process is the decay Z_0\to2 \gamma, where the neutral gauge boson Z_0 decays into a photon-antiphoton pair. It was first studied within the SM framework [3] , and later also considered in various extensions [4] . Recently it attracted renewed interest due to its potential relevance for Higgs searches [5] . However, since the experimental signature of this process is very similar to that of the background [6] , it will probably not be observable before LHC starts operating [7, 8] . Nevertheless, it still provides valuable information about the underlying theory [9] . For example, if the Higgs particle turns out to have spin zero or one [10] , then the decay Z_0\to2\gamma could provide important constraints on the couplings between the Higgs field and other particles [11] . Furthermore, the measurement of the branching ratio BR(Z_0\to2\gamma) allows us to determine the fine structure constant [12] . Finally, the decay Z_0\to\bar{\nu} e e + e - followed by the subsequent decay of the electron-positron pair into a photon-antiphoton pair",arxiv,bigscience bloomz,704.0921,0.3333333333333333,0.7983193277310925,0.26153846153846155,0.9197324414715718,1,1,0,0,1,1,1,0,0,0,0.16787568796711638,0.07482204871919197,0.1517509727626459,0.08333333333333333,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Effects of the galactic winds on the stellar metallicity distribution of dwarf spheroidal galaxies,"  To study the effects of galactic winds on the stellar metallicity
distributions and on the evolution of Draco and Ursa Minor dwarf spheroidal
galaxies, we compared the predictions of several chemical evolution models,
adopting different prescriptions for the galactic winds, with the
photometrically-derived stellar metallicity distributions of both galaxies. The
chemical evolution models for Draco and Ursa Minor, which are able to reproduce
several observational features of these two galaxies, such as the several
abundance ratios, take up-to-date nucleosynthesis into account for
intermediate-mass stars and supernovae of both types, as well as the effect of
these objects on the energetics of the systems. For both galaxies, the model
that best fits the data contains an intense continuous galactic wind, occurring
at a rate proportional to the star formation rate. Models with a wind rate
assumed to be proportional only to the supernova rate also reproduce the
observed SMD, but do not match the gas mass, whereas the models with no
galactic winds fail to reproduce the observed SMDs. In the case of Ursa Minor,
the same model as in previous works reproduces the observed distribution very
well with no need to modify the main parameters of the model. The model for
Draco, on the other hand, is slightly modified. The observed SMD requires a
model with a lower supernova type Ia thermalization efficiency ($\eta_{SNeIa}$
= 0.5 instead of $\eta_{SNeIa}$ = 1.0) in order to delay the galactic wind,
whereas all the other parameters are kept the same. The model results, compared
to observations, strongly suggest that intense and continuous galactic winds
play a very important role in the evolution of local dSphs.
","We study how the effects of galactic winds can be used to explain the observed properties of the metal-poor tail in the stellar metallicity distributions (SMDs) of nearby dwarf spheroidal galaxies (dSph). We find that SMD is sensitive to both the mass loss rate and wind velocity, but not very sensitive to other parameters such as the initial mass function or star formation history. The best-fit model for each galaxy has been obtained by comparing its SMD with those predicted using different sets of free parameters. Our results show that all these dSph have experienced strong outflows driven by supernovae explosions during their early evolution stages. These outflows are responsible for removing most metals produced by stars formed before z = 1.5-2.0. In addition, we also found that some of them may experience additional late-time outflow events which could remove more metals produced after this time period.",arxiv,bigscience bloomz,704.2032,0.3888888888888889,0.24369747899159663,0.764102564102564,0.3750597228858099,1,1,0,0,0,1,1,0,0,0,0.13917292443980936,0.05875372089780213,0.14785992217898833,0.026515151515151516,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Gamma Rays frim the Galactic Centre,"  Recent results from the HESS gamma ray telescope have shown the presence of
both a diffuse, extended, flux of gamma rays above ~0.4 TeV and discrete
sources in and near the Galactic Centre. Here, we put forward a possible
explanation in terms of the diffusion of cosmic ray protons from a succession
of supernova remnants (SNR) in the SgrA* region of the Galaxy plus a
contribution from SNR in the rest of the Galactic Centre Region, to be called
the Galactic Centre Ridge (GCR). Protons are favoured over electrons because
the mG magnetic fields in the Region will attenuate energetic electrons
severely. Prominent features are the need for 'anomalous diffusion' of the
protons in the whole region and the adoption of low efficiency for SNR
acceleration in the high density regions. The latter is related by us to the
well-known low 'cosmic ray gradient' in the Galaxy. A corroborating feature is
the close correlation of inferred cosmic ray intensity with the smoothed
intensity of 5 GHZ radio radiation. We attribute this to the presence of the
SNR in the GCR.
","The gamma ray emission in the energy range 100 MeV to 10 GeV is studied using data taken by EGRET on board CGRO during its first four years of operation (1991) (1992) (1993) (1994) . The analysis has been performed for two different regions, one centered at l = 0° and b = - 5° , which includes the galactic centre region, and another centered at l = 180° and b = + 5° . In both cases we have used an iterative maximum likelihood method to determine the fluxes of individual sources as well as their spectral parameters.  We find that there are three distinct components contributing to the observed gamma-ray flux above 1 GeV :  A diffuse component with a power law spectrum extending upto ~10 GeV .
A point source located near Sgr A* with a power law spectrum .
An extended source towards the galactic center with a broken power law spectrum . 
We also present results obtained when the same analysis was repeated after excluding the contribution due to the central part of the Galaxy .",arxiv,bigscience bloomz,705.2333,0.3333333333333333,0.29411764705882354,0.2923076923076923,0.47252747252747257,1,1,0,0,1,1,1,1,0,0,0.13993555408519492,0.09386905894704166,0.1556420233463035,0.04924242424242424,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Unitarity analysis of a non-Abelian gauge invariant action with a mass,"  In previous work done by us and coworkers, we have been able to construct a
local, non-Abelian gauge invariant action with a mass parameter, based on the
nonlocal gauge invariant mass dimension two operator F1/D^2F. The
renormalizability of the resulting action was proven to all orders of
perturbation theory, in the class of linear covariant gauges. We also discussed
the perturbative equivalence of the model with ordinary massless Yang-Mills
gauge theories when the mass is identically zero. Furthermore, we pointed out
the existence of a BRST symmetry with corresponding nilpotent charge. In this
paper, we study the issue of unitarity of this massive gauge model. Firstly, we
provide a short review how to discuss the unitarity making use of the BRST
charge. Afterwards we make a detailed study of the most general version of our
action, and we come to the conclusion that the model is not unitary, as we are
unable to remove all the negative norm states from the physical spectrum in a
consistent way.
","We study the unitarity properties of an effective field theory describing the interactions between gluons and quarks in QCD at high energies, where perturbation theory is not applicable anymore. The model we consider consists of a gauge-invariant action containing both massive and massless fields. We show that this model can be written as a sum over Feynman diagrams which are all unitary individually if certain conditions on the parameters appearing in the Lagrangian density are satisfied. In particular, it turns out that the masses of the particles involved must satisfy some relations to ensure unitarity. Finally, we discuss how these results could be used for phenomenological applications. PACS numbers: 11.10.Wx, 12.38.Qk, 13 .60.Hb 
I. INTRODUCTORY REMAR K S
The Standard Model (SM) describes successfully most experimental data available today [1] , but its validity has been tested only up to energies of about 1 TeV [2] . At higher energies new phenomena may appear beyond those predicted by the SM [3] .
In order to describe such effects one usually considers extensions of the SM [4] or models based on effective theories [5] . Effective theories provide a systematic way to include corrections due to physics at scales above the energy scale considered [6] . They allow us to calculate observables using perturbative techniques even when the underlying dynamics cannot be described within the framework of standard quantum mechanics [7, 8] . This approach is particularly useful in cases where there exists no fundamental description of the physical system under consideration [9] .
One example of an effective theory is Quantum Chromodynamics (QCD), the theory of strong interactions [10] . It predicts the existence of hadrons made of quarks and gluons [11] . However, since the typical momentum transfer inside a hadron is much smaller than the characteristic scale of QCD processes [12] , the latter can be studied separately from the former [13] . For instance, the production of jets [14] and heavy flavors [15] in high-energy collisions can be calculated using perturbative methods [16] . On the other hand, the interaction among partons [17]",arxiv,bigscience bloomz,705.0871,0.3333333333333333,0.7983193277310925,0.22564102564102564,0.9455327281414238,0,1,0,0,0,1,1,1,0,0,0.11091119325169567,0.07133727425378696,0.11284046692607004,0.09090909090909091,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Formation and Collisional Evolution of Kuiper Belt Objects,"  This chapter summarizes analytic theory and numerical calculations for the
formation and collisional evolution of KBOs at 20--150 AU. We describe the main
predictions of a baseline self-stirring model and show how dynamical
perturbations from a stellar flyby or stirring by a giant planet modify the
evolution. Although robust comparisons between observations and theory require
better KBO statistics and more comprehensive calculations, the data are broadly
consistent with KBO formation in a massive disk followed by substantial
collisional grinding and dynamical ejection. However, there are important
problems reconciling the results of coagulation and dynamical calculations.
Contrasting our current understanding of the evolution of KBOs and asteroids
suggests that additional observational constraints, such as the identification
of more dynamical families of KBOs (like the 2003 EL61 family), would provide
additional information on the relative roles of collisional grinding and
dynamical ejection in the Kuiper Belt. The uncertainties also motivate
calculations that combine collisional and dynamical evolution, a `unified'
calculation that should give us a better picture of KBO formation and
evolution.
","The Kuiper belt is the source region for most short period comets, but its formation remains poorly understood. We present results from N-body simulations that show how collisions among planetesimals in Neptune's feeding zone can produce objects with orbits similar to those observed today. The initial conditions are based on models of planet migration during which Neptune migrated outward by about 30 AU before being halted at its current location. Our calculations suggest that the Kuiper belt formed as a result of collisional grinding between bodies whose sizes were comparable to Pluto (r ~ 1000 km). This process produced a population of small bodies with orbital eccentricities ranging up to 0.3. Subsequent encounters with Neptune caused some of these bodies to be scattered into highly eccentric orbits. These results provide an explanation for why there appears to be no correlation between the size distribution of KBOs and their orbital eccentricity.",arxiv,bigscience bloomz,704.0259,0.2777777777777778,0.29411764705882354,0.24102564102564103,0.3836598184424272,1,1,0,0,1,1,1,0,0,1,0.11870337528021355,0.039899485187319644,0.1517509727626459,0.03409090909090909,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The InterHourly-Variability (IHV) Index of Geomagnetic Activity and its Use in Deriving the Long-term Variation of Solar Wind Speed,"  We describe the derivation of the InterHourly Variability (IHV) index of
geomagnetic activity. The IHV-index for a geomagnetic element is mechanically
derived from hourly values as the sum of the unsigned differences between
adjacent hours over a seven-hour interval centered on local midnight. The index
is derived separately for stations in both hemispheres within six longitude
sectors using only local night hours. It is intended as a long-term index.
Available data allows derivation of the index back well into the 19th century.
On a time scale of a 27-day Bartels rotation, IHV averages for stations with
corrected geomagnetic latitude less than 55 degrees are strongly correlated
with midlatitude range indices. Assuming a constant calibration of the aa-index
we find that observed yearly values of aa before the year 1957 are 2.9 nT too
small compared to values calculated from IHV using the regression constants
based on 1980-2004. We interpret this discrepancy as an indication that the
calibration of the aa index is in error before 1957. There is no such problem
with the ap index. Rotation averages of IHV are also strongly correlated with
solar wind parameters (BV^2). On a time scale of a year combining the IHV-index
and the recently-developed Inter-Diurnal Variability (IDV) index (giving B)
allows determination of solar wind speed, V, from 1890-present. Over the
~120-year series, the yearly mean solar wind speed varied from a low of 303
km/s in 1902 to a high value of 545 km/s in 2003. The calculated yearly values
of the product BV using B and V separately derived from IDV and IHV agree
quantitatively with (completely independent) BV derived from the amplitude of
the diurnal variation of the H component in the polar caps since 1926 and
sporadically beyond.
","The inter-hourly-variability index is proposed to measure geomagnetic activity on hourly basis, which can be used as an indicator for solar wind speed variation over time scales longer than one day.  The IHV index was calculated using hourly values of Kp index during the period 1957-2009. It shows that there are two peaks at about 1965-1970 and 1990-1995 . A linear regression analysis between the IHV index and solar wind speed data obtained by spacecraft observations reveals that they have good correlation with each other. This suggests that the IHV index may provide useful information for long-term prediction of solar wind speed. Keywords: Geomagnetism; Solar wind; Variability index; Prediction modeling; Data mining. 1 Introduction Space weather has been attracting more attention recently because it affects many aspects of human life such as satellite communications, aviation safety, power grids etc. (e.g., [1] ). In particular, solar wind plays important roles in space weather since it carries away magnetic fluxes generated by the Sun's dynamo action [2] , and thus controls the Earth's magnetosphere [3] .
Solar wind is driven out from the Sun by coronal mass ejections [4] . Coronal mass ejections occur when huge amounts of plasma suddenly escape from the Sun into space [5] . They usually last several hours [6] . Therefore, solar wind speed varies significantly within 24 h [7, 8] . However, most previous studies only focus on the average solar wind speed or daily averaged solar wind speed [9] . As a result, little work has been done on investigating how solar wind speed changes on shorter timescales [10] .",arxiv,bigscience bloomz,706.0961,0.6666666666666666,0.6974789915966387,0.8512820512820513,0.7133301481127569,1,1,0,0,0,1,1,1,0,1,0.11102270870880211,0.07130402043201968,0.07392996108949416,0.10227272727272728,2,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Integral Field Spectroscopy of the Extended Emission-Line Region of 4C 37.43,"  We present Gemini integral field spectroscopy and Keck II longslit
spectroscopy of the extended emission-line region (EELR) around the quasar 4C
37.43. The velocity structure of the ionized gas is complex and cannot be
explained globally by a simple dynamical model. The spectra from the clouds are
inconsistent with shock or ``shock + precursor'' ionization models, but they
are consistent with photoionization by the quasar nucleus. The best-fit
photoionization model requires a low-metallicity (12+log(O/H) < 8.7) two-phase
medium, consisting of a matter-bounded diffuse component with a unity
filling-factor (N ~ 1 \cc, T ~ 15000 K), in which are embedded small, dense
clouds (N ~ 400 \cc, T ~ 10^4 K). The high-density clouds are transient and can
be re-generated through compressing the diffuse medium by low-speed shocks (V_S
\lesssim 100 \kms). Our photoionization model gives a total mass for the
ionized gas of about 3x10^{10} M_sun, and the total kinetic energy implied by
this mass and the observed velocity field is ~2x10^{58} ergs. The fact that
luminous EELRs are confined to steep-spectrum radio-loud quasars, yet show no
morphological correspondence to the radio jets, suggests that the driving force
producing the 4C 37.43 EELR was a roughly spherical blast wave initiated by the
production of the jet. That such a mechanism seems capable of ejecting a mass
comparable to that of the total interstellar medium of the Milky Way suggests
that ``quasar-mode'' feedback may indeed be an efficient means of regulating
star formation in the early universe.
","We present integral field spectroscopy (IFS) observations of the extended emission-line region (EELR) 
 
 
 
 We use these data to study the kinematics and excitation conditions in this EELR, which is found 
 
 
 
 The IFS data reveal that the gas has an average velocity dispersion of ~200 km s-1 across most of the 
 
 
 
 We find evidence for two distinct components within the EELR: one component with low-excitation 
 
 
 
 properties similar to those observed in other radio galaxies; and another component with higher- 
 
 
 
 excitation properties than are typically seen in radio galaxies. 


The high-excitation component appears to be associated with shocks driven by the radio jets into the surrounding medium. In addition, we detect several compact knots of [O III] emission along the northern edge of the EELR, which may represent sites where new stars have formed as a result of jet-induced star formation or galaxy mergers.",arxiv,bigscience bloomz,705.4365,0.3888888888888889,0.016806722689075626,0.6358974358974359,0.15719063545150502,1,1,0,0,1,1,2,1,0,0,0.121920851874307,0.04699183915703521,0.14007782101167315,0.2727272727272727,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1
Highly turbulent solutions of LANS-alpha and their LES potential,"  We compute solutions of the Lagrangian-Averaged Navier-Stokes alpha-model
(LANS) for significantly higher Reynolds numbers (up to Re 8300) than have
previously been accomplished. This allows sufficient separation of scales to
observe a Navier-Stokes (NS) inertial range followed by a 2nd LANS inertial
range. The analysis of the third-order structure function scaling supports the
predicted l^3 scaling; it corresponds to a k^(-1) scaling of the energy
spectrum. The energy spectrum itself shows a different scaling which goes as
k^1. This latter spectrum is consistent with the absence of stretching in the
sub-filter scales due to the Taylor frozen-in hypothesis employed as a closure
in the derivation of LANS. These two scalings are conjectured to coexist in
different spatial portions of the flow. The l^3 (E(k) k^(-1)) scaling is
subdominant to k^1 in the energy spectrum, but the l^3 scaling is responsible
for the direct energy cascade, as no cascade can result from motions with no
internal degrees of freedom. We verify the prediction for the size of the LANS
attractor resulting from this scaling. From this, we give a methodology either
for arriving at grid-independent solutions for LANS, or for obtaining a
formulation of a LES optimal in the context of the alpha models. The fully
converged grid-independent LANS may not be the best approximation to a direct
numerical simulation of the NS equations since the minimum error is a balance
between truncation errors and the approximation error due to using LANS instead
of the primitive equations. Furthermore, the small-scale behavior of LANS
contributes to a reduction of flux at constant energy, leading to a shallower
energy spectrum for large alpha. These small-scale features, do not preclude
LANS to reproduce correctly the intermittency properties of high Re flow.
","We present highly resolved numerical simulations of the incompressible Navier-Stokes equations with the LANS-alpha model, which is known to produce good results for wall-bounded flows at low Reynolds numbers. We show that this method can also be used in high-Reynolds number situations where it produces accurate results even though its underlying assumptions are not valid anymore. The main advantage over standard LES methods lies in the fact that no explicit subgrid-scale models have to be introduced. This makes the approach very attractive since there is no need to tune any parameters or coefficients as required by other LES approaches. In addition we demonstrate how the LANS-alpha method can be combined with an implicit LES scheme based on the variational multiscale formulation (VMS-LES) to obtain more efficient computations. Finally, we discuss some open issues related to the use of these schemes in practical applications. Turbulence plays a crucial role in many physical phenomena ranging from weather prediction to oceanic circulation and combustion processes. However, despite decades of research turbulence still remains one of the most challenging problems in computational fluid dynamics. One reason for this difficulty is due to the wide range of length scales involved in turbulent flows. While large eddies contain most of the kinetic energy they only occupy a small fraction of the total volume. On the other hand smaller eddies fill up almost all space but contribute little to the overall kinetic energy. Therefore, if one wants to resolve all relevant flow structures accurately enough then extremely fine grids would be needed leading to prohibitively expensive calculations. To overcome this problem so-called Large Eddy Simulations (LESs) were developed during the last two decades [1, 2] . These techniques aim at resolving only those large-scale motions responsible for the bulk of the kinetic energy while modeling the effect of unresolved small-scale fluctuations using suitable closure relations. Although LES has been successfully applied to various engineering problems [3–5] , it suffers from several drawbacks such as the lack of universality of the employed sub-grid scale models [6] .
In recent years new classes of LES-like methods have emerged [7–10] . They are based",arxiv,bigscience bloomz,704.1928,0.6111111111111112,0.7983193277310925,0.841025641025641,0.9684663162924032,1,1,1,0,0,1,1,0,0,0,0.10101481649902111,0.06121989089354715,0.12840466926070038,0.06439393939393939,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
3-He in the Milky Way Interstellar Medium: Ionization Structure,"  The cosmic abundance of the 3-He isotope has important implications for many
fields of astrophysics. We are using the 8.665 GHz hyperfine transition of
3-He+ to determine the 3-He/H abundance in Milky Way HII regions and planetary
nebulae. This is one in a series of papers in which we discuss issues involved
in deriving accurate 3-He/H abundance ratios from the available measurements.
Here we describe the ionization correction we use to convert the 3-He+/H+
abundance, y3+, to the 3-He/H abundance, y3. In principle the nebular
ionization structure can significantly influence the y3 derived for individual
sources. We find that in general there is insufficient information available to
make a detailed ionization correction. Here we make a simple correction and
assess its validity. The correction is based on radio recombination line
measurements of H+ and 4-He+, together with simple core-halo source models. We
use these models to establish criteria that allow us to identify sources that
can be accurately corrected for ionization and those that cannot. We argue that
this effect cannot be very large for most of the sources in our observational
sample. For a wide range of models of nebular ionization structure we find that
the ionization correction factor varies from 1 to 1.8. Although large
corrections are possible, there would have to be a conspiracy between the
density and ionization structure for us to underestimate the ionization
correction by a substantial amount.
","We present new measurements of 3 He+ and 3 He++ column densities toward eight nearby stars, using data obtained with the Far Ultraviolet Spectroscopic Explorer (FUSE). The results are compared to previous observations made by Copernicus and IUE satellites as well as FUSE. We find that our values for N(3 He+)/N(H+), which range between 0.0015-0.0125, agree within uncertainties with those measured previously at high latitudes but disagree significantly with lower latitude measurements. Our results suggest that there is an additional source of ionization near the Galactic plane not accounted for by cosmic rays or X-rays. This could be due to shocks driven into the interstellar medium by supernovae remnants and/or winds associated with massive OB associations. 
 
 Keywords: Helium abundance, Interstellar medium, Shocks, Supernova remnant, Winds, Cosmic ray",arxiv,bigscience bloomz,706.1939,0.6111111111111112,0.24369747899159663,0.5692307692307692,0.3177257525083612,0,1,0,0,0,1,1,1,0,0,0.05015489998214689,0.06328529595238738,0.038910505836575876,0.06439393939393939,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Grain Retention and Formation of Planetesimals near the Snow Line in MRI-driven Turbulent Protoplanetary Disks,"  The first challenge in the formation of both terrestrial planets and the
cores of gas giants is the retention of grains in protoplanetary disks. In most
regions of these disks, gas attains sub-Keplerian speeds as a consequence of a
negative pressure gradient. Hydrodynamic drag leads to orbital decay and
depletion of the solid material in the disk, with characteristic timescales as
short as only a few hundred years for meter-sized objects at 1 AU. In this
paper, we suggest a particle retention mechanism which promotes the
accumulation of grains and the formation of planetesimals near the water
sublimation front or ``snow line.'' This model is based on the assumption that,
in the regions most interesting for planet formation, the viscous evolution of
the disk is due to turbulence driven by the magneto-rotational instability
(MRI) in the surface layers of the disk. The depth to which MRI effectively
generates turbulence is a strong function of the grain size and abundance. A
sharp increase in the grain-to-gas density ratio across the snow line reduces
the column depth of the active layer. As the disk evolves towards a
quasi-steady-state, this change in the active layer creates a local maximum in
radial distribution of the gas surface density and pressure, causing the gas to
rotate at super-Keplerian speed and halting the inward migration of grains.
This senario presents a robust process for grain retention which may aid in the
formation of proto-gas-giant cores preferentially near the snow line.
","We perform global three-dimensional magnetohydrodynamic simulations to study grain growth, dust settling, and planetesimal formation around protoplanets embedded within turbulent disks with dead zone boundaries. We find that grains grow by coagulation up to millimeter sizes at the snow line ($R_s = 2.7 \ast d_{s} AU$), where $R_s$ is the distance between the central star and the snowline, $ds$ is the disk scale height, and $AU$ denotes astronomical unit. Grains are trapped inside the dead zone due to magnetic pressure gradient force and settle toward midplane. The maximum size of grains increases as they approach the planet's location because of higher gas density there. Dust particles can be captured into growing planetesimals when their Stokes number becomes smaller than unity. Our results show that planetesimals form efficiently only if the initial dust-to-gas mass ratio is larger than $10^{-3}$.",arxiv,bigscience bloomz,706.1272,0.4444444444444444,0.24369747899159663,0.6205128205128205,0.34925943621595795,1,1,0,0,1,1,1,0,0,1,0.09087443755521103,0.13168951406968132,0.09727626459143969,0.14772727272727273,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Some properties of the resonant state in quantum mechanics and its computation,"  The resonant state of the open quantum system is studied from the viewpoint
of the outgoing momentum flux. We show that the number of particles is
conserved for a resonant state, if we use an expanding volume of integration in
order to take account of the outgoing momentum flux; the number of particles
would decay exponentially in a fixed volume of integration. Moreover, we
introduce new numerical methods of treating the resonant state with the use of
the effective potential. We first give a numerical method of finding a
resonance pole in the complex energy plane. The method seeks an energy
eigenvalue iteratively. We found that our method leads to a super-convergence,
the convergence exponential with respect to the iteration step. The present
method is completely independent of commonly used complex scaling. We also give
a numerical trick for computing the time evolution of the resonant state in a
limited spatial area. Since the wave function of the resonant state is
diverging away from the scattering potential, it has been previously difficult
to follow its time evolution numerically in a finite area.
","The problem of finding the energy levels of an electron bound to a nucleus is one of the most important problems in physics, which has been studied for many years. In this article we consider the case where there are two electrons with opposite spins that can occupy different orbitals around the same nucleus. We show how to compute these states using only polynomial time computations on classical computers. This result was obtained by applying some techniques developed recently in computational complexity theory such as the PCP theorem (the probabilistic checkable proof) and the local testability of CSPs (constraint satisfaction problems). The results presented here have applications not only in theoretical physics but also in computer science. For example they provide new insights into the structure of NP-complete problems. Quantum mechanical systems play an essential role in modern physics. One of their main features is that particles may be found in superposition of several states at once. A famous example is Schrödinger's cat experiment [1] . Another feature is entanglement [2] , i.e., correlations between particles that cannot be explained classically [3] .
In this work we study the following problem: given a system consisting of N spin-1/2 particles, what is the ground state? That means, if all particles were measured simultaneously, what would be the probability distribution over the possible outcomes?
We will focus our attention on the simplest non-trivial case: two spin-½ particles occupying different orbitals around the nucleus [4] . It turns out that it is sufficient to solve this problem in order to find the ground state of any number of particles [5] .",arxiv,bigscience bloomz,705.1388,0.4444444444444444,0.6470588235294118,0.30256410256410254,0.7219302436693742,0,1,1,0,0,1,1,1,1,1,0.10477962328020615,0.06047822186672934,0.10894941634241245,0.06439393939393939,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Pioneer Anomaly and Accelerating Universe as Effects of the Minkowski Space Conformal Symmetry,"  On the basis of the nonisometric transformations subgroup of the SO(4.2)
group, the nonlinear time inhomogeneity one-parameter conformal transformations
are constructed. The connection between the group parameter and the Hubble
constant H0 is established. It is shown that the existence of an anomalous
blue-shifted frequency drift is a pure kinematic manifestation of the time
inhomogeneity induced by the Universe expansion. This conclusion is confirmed
via a generalization of the standard Special Relativity clock synchronization
procedure to the space expanding case. The obtained formulae are in accordance
with the observable Pioneer Anomaly effect. The anomalous blue-shifted drift is
universal, does not depend on the presence of graviting centers and can be, in
principle, observed on any frequencies under suitable experimental conditions.
The explicit analytic expression for the speed of recession--intergalactic
distance ratio is obtained in the form of a function of the red shift z valid
in the whole range of its variation. In the small z limit this expression
exactly reproduces the Hubble law. The maximum value of this function at
z=0.475 quantitatively corresponds to the experimentally found value z(exp) =
0.46 +/- 0.13 of the transition from the decelerated to the accelerated
expansion of the Universe.
","We show that the Pioneer anomaly, which is an anomalous acceleration observed in radio tracking data for two spacecrafts launched by NASA (Pioneer 10/11), can be explained if we assume that there exists a conformal symmetry breaking effect at large distances from our solar system. We also argue that this effect may lead to accelerating expansion of the universe. The idea behind these results is based on the fact that the space-time metric around massive bodies has been shown to have a certain degree of anisotropy due to quantum gravity effects. This anisotropic nature of space-time leads to violation of Lorentz invariance, which in turn causes violations of energy-momentum conservation laws. In order to explain such violations within the framework of general relativity one needs to introduce new fields into the theory. These are called ""dark fields"" because they do not interact with ordinary matter but only affect gravitational interactions between particles.",arxiv,bigscience bloomz,704.2745,0.4444444444444444,0.24369747899159663,0.37948717948717947,0.38939321548017203,1,1,0,0,0,1,1,0,0,0,0.08606459076658539,0.09711097245916536,0.0933852140077821,0.11742424242424243,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Nonlinear Dynamics of Infectious Diseases Transfer with Possible Applications for Tubercular Infection,"  In this paper, we model a nonlinear dynamics of infectious diseases transfer.
Particularly, we study possible applications to tubercular infection in models
with different profiles (peak values) of the population density dependence on
spatial coordinates. Our approach is based on the well known method of
instantons which has been used by the authors to describe kinetics of adiabatic
chemical reactions as a function of the heat-bath temperature and other system
parameters. In our approach, we use ""social temperature"" T as one of the
controlling parameters. Increase of T leads to acceleration of the infectious
diseases transfer. The ""blockage"" effect for the infectious diseases transfer
has been demonstrated in the case when peak values (in the population density)
are equal to one and under condition that the ""social temperature"" is low.
Existence of such effect essentially depends from environment ""activity""
(social and prophylactic). Results of our modeling qualitatively meet the
tuberculosis dynamic spread data in Penza region of Russia.
","We study the nonlinear dynamics of infectious diseases transfer in a population, where individuals are divided into three classes: susceptible (S), infected (I) and recovered/removed (R). We consider two different models: SIR model and SEIR model. In both cases we assume that there is no birth or death in the population. The main goal of this work is to investigate how the disease spreads through the population depending on its parameters. For example, if the infection rate is too high then it may lead to an epidemic outbreak. On the other hand, if the recovery rate is very large compared to the infection rate then the number of infectives will decrease rapidly. Finally, we show some numerical simulations which illustrate our results. 
 
 Keywords: Nonlinear dynamics, infectious diseases, tuberculosis, SIR model, SEIR model. 1 Introduction 
 
 Many mathematical models have been developed over time to describe the spread of infectious diseases within populations [1–3] . These models can be used as tools to understand the transmission mechanisms of these diseases and help public health authorities make decisions about prevention strategies [4] .
 
In particular, many researchers have studied the effects of vaccination programs [5–7] , quarantine [8, 9] and isolation [10, 11] on the evolution of epidemics. Other studies focus on the impact of environmental factors such as temperature [12, 13] , humidity [14, 15] and rainfall [16] on the propagation of pathogens. 
The majority of existing works use deterministic models based on ordinary differential equations [17] . However, stochastic models [18, 19] and agent-based models [20, 21] also exist. Agent-based models allow us to take into account individual behaviors [22] while stochastic models provide more realistic descriptions of random events [23] . 
 
In this article, we propose new mathematical models describing the spread of infectious diseases in a closed population. Our aim is to analyze the influence of various parameters on the behavior of the system. More specifically, we want to determine whether the disease will die out naturally or cause an epidemic outbreak. To do so, we first introduce the basic reproduction number R0 [24] , which represents the average number",arxiv,bigscience bloomz,706.1434,0.3888888888888889,0.8991596638655462,0.1794871794871795,0.959866220735786,1,1,0,0,0,1,1,1,0,0,0.09846541867937392,0.05944089515421226,0.11284046692607004,0.07575757575757576,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Ongoing Galactic Accretion: Simulations and Observations of Condensed Gas in Hot Halos,"  Ongoing accretion onto galactic disks has been recently theorized to progress
via the unstable cooling of the baryonic halo into condensed clouds. These
clouds have been identified as analogous to the High-Velocity Clouds (HVCs)
observed in HI in our Galaxy. Here we compare the distribution of HVCs observed
around our own Galaxy and extra-planar gas around the Andromeda galaxy to these
possible HVC analogs in a simulation of galaxy formation that naturally
generates these condensed clouds. We find a very good correspondence between
these observations and the simulation, in terms of number, angular size,
velocity distribution, overall flux and flux distribution of the clouds. We
show that condensed cloud accretion only accounts for ~ 0.2 M_solar / year of
the current overall Galactic accretion in the simulations. We also find that
the simulated halo clouds accelerate and become more massive as they fall
toward the disk. The parameter space of the simulated clouds is consistent with
all of the observed HVC complexes that have distance constraints, except the
Magellanic Stream which is known to have a different origin. We also find that
nearly half of these simulated halo clouds would be indistinguishable from
lower-velocity gas and that this effect is strongest further from the disk of
the galaxy, thus indicating a possible missing population of HVCs. These
results indicate that the majority of HVCs are consistent with being infalling,
condensed clouds that are a remnant of Galaxy formation.
","We present new simulations that show how condensed gas is formed by ongoing accretion onto galactic halos, which are heated to temperatures above 10 million degrees Kelvin (MK). The condensed gas forms as the hot halo cools radiatively on timescales shorter than its dynamical time. We compare these results with observations of cool clouds in nearby galaxy clusters. Our models predict that condensed gas should be found at distances between 100 kpc and 1 Mpc from galaxies within massive clusters. This prediction agrees well with recent X-ray observations of cool clouds in Abell 1795 and Abell 2163. These clouds have masses ranging from $10^{9}$ to $10^{11}$ solar masses, sizes less than 50 kiloparsecs, and densities greater than 1000 atoms per cubic centimeter. They also appear to be moving outward relative to their host galaxies at velocities up to several hundred kilometers per second. In addition, we find that our model predicts cloud lifetimes longer than one billion years for most observed clouds.",arxiv,bigscience bloomz,705.0357,0.4444444444444444,0.3445378151260504,0.5897435897435898,0.4180602006688964,1,1,0,0,0,1,1,0,0,0,0.06847482504053516,0.06200597870088366,0.0622568093385214,0.06060606060606061,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
VSOP: The Variable Star One-shot Project I. Project presentation and first data release,"  The Variable Star One-shot Project (VSOP) is aimed at (1) providing the
variability type and spectral type of all unstudied variable stars, (2)
process, publish, and make the data available as automatically as possible, and
(3) generate serendipitous discoveries. This first paper describes the project
itself, the acquisition of the data, the dataflow, the spectroscopic analysis
and the on-line availability of the fully calibrated and reduced data. We also
present the results on the 221 stars observed during the first semester of the
project. We used the high-resolution echelle spectrographs HARPS and FEROS in
the ESO La Silla Observatory (Chile) to survey known variable stars. Once
reduced by the dedicated pipelines, the radial velocities are determined from
cross correlation with synthetic template spectra, and the spectral types are
determined by an automatic minimum distance matching to synthetic spectra, with
traditional manual spectral typing cross-checks. The variability types are
determined by manually evaluating the available light curves and the
spectroscopy. In the future, a new automatic classifier, currently being
developed by members of the VSOP team, based on these spectroscopic data and on
the photometric classifier developed for the COROT and Gaia space missions,
will be used. We confirm or revise spectral types of 221 variable stars from
the GCVS. We identify 26 previously unknown multiple systems, among them
several visual binaries with spectroscopic binary individual components. We
present new individual results for the multiple systems V349 Vel and BC Gru,
for the composite spectrum star V4385 Sgr, for the T-Tauri star V1045 Sco, and
for DM Boo which we re-classify as a BY Draconis variable. The complete data
release can be accessed via the VSOP web site.
","The VSOP (Variable Star One-shot Project) is an ambitious project to obtain high-precision radial velocities for thousands of stars with the goal of detecting extrasolar planets by means of gravitational microlensing, transit photometry or direct imaging techniques.  This article presents the main characteristics of this new survey as well as its first results obtained on two open clusters. We have observed more than 1000 targets in the open cluster M67 during three nights using the HARPS spectrograph at La Silla Observatory. Our observations show that we can reach precisions better than 1 m/s over periods of one hour. In addition, we present our preliminary analysis of these data which shows that we are able to detect binaries down to separations smaller than 0.1 AU. Finally, we report on the detection of several new spectroscopic binary systems among our sample. Keywords: Open Cluster, Radial Velocity Survey",arxiv,bigscience bloomz,705.4195,0.5555555555555556,0.29411764705882354,0.7897435897435897,0.369326325848065,1,1,0,0,0,1,1,1,0,0,0.12977888264634044,0.08079507074172225,0.11673151750972763,0.056818181818181816,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Sparse and Dense Encoding in Layered Associative Network of Spiking Neurons,"  A synfire chain is a simple neural network model which can propagate stable
synchronous spikes called a pulse packet and widely researched. However how
synfire chains coexist in one network remains to be elucidated. We have studied
the activity of a layered associative network of Leaky Integrate-and-Fire
neurons in which connection we embed memory patterns by the Hebbian Learning.
We analyzed their activity by the Fokker-Planck method. In our previous report,
when a half of neurons belongs to each memory pattern (memory pattern rate
$F=0.5$), the temporal profiles of the network activity is split into
temporally clustered groups called sublattices under certain input conditions.
In this study, we show that when the network is sparsely connected ($F<0.5$),
synchronous firings of the memory pattern are promoted. On the contrary, the
densely connected network ($F>0.5$) inhibit synchronous firings. The sparseness
and denseness also effect the basin of attraction and the storage capacity of
the embedded memory patterns. We show that the sparsely(densely) connected
networks enlarge(shrink) the basion of attraction and increase(decrease) the
storage capacity.
","We propose an encoding scheme for layered associative network (LAN) of spiking neurons, which is based on sparse coding and dense coding. The proposed method can be used to learn the association between input patterns and output patterns by using unsupervised learning algorithms such as Hebbian learning rule or spike-timing-dependent plasticity (STDP). We show that our model has better performance than conventional LANs with respect to both storage capacity and retrieval accuracy. In addition, we demonstrate that our model can perform pattern completion task without any additional training data. 
Index Terms-Layered associaton network, Sparse coding, Dense coding, Pattern completion, STDP, Unsupervised learning algorithm. 1 Introduction Recently, there have been many studies about artificial neural networks [1] . Among them, layered associative network (L AN ) [2] , which consists of multiple layers of neurons connected through synapses, has attracted much attention because it shows high storage capacity and good retrieval accuracy [3] .
In L AN s, each neuron receives inputs from all neurons in previous layer via synaptic connections. Then, the activity level of each neuron is determined by its firing rate according to the following equation: 
where x i denotes the activity level of ith neuron at time t, w ij represents connection weight from jth neuron in previous layer to ith neuron in current layer, f(·) stands for activation function, and b i indicates bias term [4] . Since the number of possible combinations of activities among neurons increases exponentially when the number of neurons becomes large, storing information in L AN requires huge amount of memory space [5] . To overcome this problem, several approaches have been suggested [6] - [8] . For example, sparseness constraint was introduced into L AN so that only small fraction of neurons are active simultaneously [9] . However, these methods require supervised learning algorithms to train parameters of L AN , which makes their applications limited [10] .",arxiv,bigscience bloomz,705.2491,0.4444444444444444,0.596638655462185,0.2512820512820513,0.8652651696129957,1,1,0,0,0,1,1,1,0,0,0.09279778704147787,0.12390925588572142,0.13618677042801555,0.18181818181818182,1,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Dynamic Effects Increasing Network Vulnerability to Cascading Failures,"  We study cascading failures in networks using a dynamical flow model based on
simple conservation and distribution laws to investigate the impact of
transient dynamics caused by the rebalancing of loads after an initial network
failure (triggering event). It is found that considering the flow dynamics may
imply reduced network robustness compared to previous static overload failure
models. This is due to the transient oscillations or overshooting in the loads,
when the flow dynamics adjusts to the new (remaining) network structure. We
obtain {\em upper} and {\em lower} limits to network robustness, and it is
shown that {\it two} time scales $\tau$ and $\tau_0$, defined by the network
dynamics, are important to consider prior to accurately addressing network
robustness or vulnerability. The robustness of networks showing cascading
failures is generally determined by a complex interplay between the network
topology and flow dynamics, where the ratio $\chi=\tau/\tau_0$ determines the
relative role of the two of them.
","We study the vulnerability of interdependent networks under cascading failures, where nodes are subject to random attacks and their neighbors can fail as well due to loss of connectivity. We show that dynamic effects increase network vulnerability by enhancing the spreading of failures in time. In particular, we find that increasing the number of attackers or decreasing the recovery rate increases the probability for global cascade failure. Our results suggest that it is important to consider both static and dynamic aspects when studying the robustness of real-world systems against cascading failures. Interdependence between different components of complex systems has been shown to be crucial for understanding many phenomena such as epidemic outbreaks [1] , traffic jams [2] , financial crashes [3] , and blackouts [4] . The recent 2008 power grid crisis caused by an unprecedented series of cascading failures [5] highlighted the importance of considering interdependence among system elements [6] .
In this work, we focus on interdependent networks [7, 8] , which consist of two types of nodes: source (S) and target (T). Source nodes provide services to other nodes while target nodes depend on these services. For example, in the case of the power grid, generators supply electricity to substations; if one generator fails then its neighboring substations will also lose power [9] . Similarly, in social networks people may rely on each other's opinions [10] ; if someone becomes ill [11] or loses her job [12] she might affect others' health status [13] or income [14] respectively. Recent studies have shown that interdependency plays an important role in determining the resilience of interconnected systems [15, 16] . However, most previous works focused only on static properties [17] , i.e., they assumed that all links remain stable over time [18] . This assumption does not hold true in practice since links often break down [19] and new ones form [20] . Therefore, it is necessary to take into account the dynamics of interactions [21] .",arxiv,bigscience bloomz,704.1952,0.2222222222222222,0.6470588235294118,0.1641025641025641,0.8939321548017201,1,0,0,0,0,1,1,1,0,1,0.11063939447261381,0.07718505591852548,0.10505836575875487,0.07954545454545454,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Inter-network regions of the Sun at millimetre wavelengths,"  The continuum intensity at wavelengths around 1 mm provides an excellent way
to probe the solar chromosphere. Future high-resolution millimetre arrays, such
as the Atacama Large Millimeter Array (ALMA), will thus produce valuable input
for the ongoing controversy on the thermal structure and the dynamics of this
layer. Synthetic brightness temperature maps are calculated on basis of
three-dimensional radiation (magneto-)hydrodynamic (MHD) simulations. While the
millimetre continuum at 0.3mm originates mainly from the upper photosphere, the
longer wavelengths considered here map the low and middle chromosphere. The
effective formation height increases generally with wavelength and also from
disk-centre towards the solar limb. The average intensity contribution
functions are usually rather broad and in some cases they are even
double-peaked as there are contributions from hot shock waves and cool
post-shock regions in the model chromosphere. Taking into account the
deviations from ionisation equilibrium for hydrogen gives a less strong
variation of the electron density and with it of the optical depth. The result
is a narrower formation height range. The average brightness temperature
increases with wavelength and towards the limb. The relative contrast depends
on wavelength in the same way as the average intensity but decreases towards
the limb. The dependence of the brightness temperature distribution on
wavelength and disk-position can be explained with the differences in formation
height and the variation of temperature fluctuations with height in the model
atmospheres.
","We present new observations made with the Atacama Large Millimeter/submillimeter Array (ALMA) of two inter-network sunspots in active region NOAA AR 12192 on 2013 May 24 and 25, respectively. The first sunspot was observed for about 3 hours during which time it rotated by more than 90 degrees. We find that this sunspot is composed of several magnetic flux tubes with different orientations. In addition to these features we also observe an extended bright feature located between the main sunspot umbrae. This feature has been previously reported as a penumbral filament but our data show no evidence of such structure. Instead, we interpret this feature as a coronal rain blob. The second sunspot was observed for only 1 hour before being occulted by Earths atmosphere. During this observation period the sunspot rotated by less than 30 degrees. Our analysis shows that both sunspots are surrounded by a dark lane which may be associated with the moat surrounding large sunspots.",arxiv,bigscience bloomz,705.2304,0.5555555555555556,0.3949579831932773,0.5487179487179488,0.4094601051122791,1,1,0,0,0,1,1,0,0,0,0.0824880780601427,0.04863552348018324,0.07003891050583658,0.03409090909090909,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Carbon Nanotube Thin Film Field Emitting Diode: Understanding the System Response Based on Multiphysics Modeling,"  In this paper, we model the evolution and self-assembly of randomly oriented
carbon nanotubes (CNTs), grown on a metallic substrate in the form of a thin
film for field emission under diode configuration. Despite high output, the
current in such a thin film device often decays drastically. The present paper
is focused on understanding this problem. A systematic, multiphysics based
modelling approach is proposed. First, a nucleation coupled model for
degradation of the CNT thin film is derived, where the CNTs are assumed to
decay by fragmentation and formation of clusters. The random orientation of the
CNTs and the electromechanical interaction are then modeled to explain the
self-assembly. The degraded state of the CNTs and the electromechanical force
are employed to update the orientation of the CNTs. Field emission current at
the device scale is finally obtained by using the Fowler-Nordheim equation and
integration over the computational cell surfaces on the anode side. The
simulated results are in close agreement with the experimental results. Based
on the developed model, numerical simulations aimed at understanding the
effects of various geometric parameters and their statistical features on the
device current history are reported.
","Carbon nanotubes (CNTs) are promising materials for field emission devices due to their unique physical and chemical properties, such as high aspect ratio, low work function, and excellent mechanical strength.  In this study, we present an integrated multiphysics model that can be used to simulate the system response of CNT-based field emitting diodes (FEDs). The proposed model consists of three sub-models: 1) electron transport in CNT; 2) electrostatic potential distribution; 3) current density distribution. We have developed these models using COMSOL Multiphysics software package with built-in physics modules. To verify our simulation results, we fabricated a CNT-FED device by growing vertically aligned CNTs onto silicon substrate via plasma-enhanced chemical vapor deposition method followed by sputtering gold film over them. Our experimental data show good agreement with simulated results obtained from the proposed model.",arxiv,bigscience bloomz,704.168,0.5,0.24369747899159663,0.3487179487179487,0.3349259436215958,1,1,0,0,0,1,1,1,0,0,0.08770677971519132,0.06816220740159463,0.08560311284046693,0.05303030303030303,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Evolution of interstellar dust and stardust in the solar neighbourhood,"  The abundance evolution of interstellar dust species originating from stellar
sources and from condensation in molecular clouds in the local interstellar
medium of the Milky Way is studied and the input of dust material to the Solar
System is determined. A one-zone chemical evolution model of the Milky Way for
the elemental composition of the disk combined with an evolution model for its
interstellar dust component similar to that of Dwek (1998) is developed. The
dust model considers dust-mass return from AGB stars as calculated from
synthetic AGB models combined with models for dust condensation in stellar
outflows. Supernova dust formation is included in a simple parameterized form
which is gauged by observed abundances of presolar dust grains with supernova
origin. For dust growth in the ISM a simple method is developed for coupling
this with disk and dust evolution models. The time evolution of the abundance
of the following dust species is followed in the model: silicate, carbon,
silicon carbide, and iron dust from AGB stars and from SNe as well as silicate,
carbon, and iron dust grown in molecular clouds. It is shown that the
interstellar dust population is dominated by dust accreted in molecular clouds;
most of the dust material entering the Solar System at its formation does not
show isotopic abundance anomalies of the refractory elements, i.e.,
inconspicuous isotopic abundances do not point to a Solar System origin of dust
grains. The observed abundance ratios of presolar dust grains formed in SN
ejecta and in AGB star outflows requires that for the ejecta from SNe the
fraction of refractory elements condensed into dust is 0.15 for carbon dust and
is quite small ($\sim10^{-4}$) for other dust species.
","We present an analysis of the evolution of interstellar dust grains, based on their size distribution inferred by infrared observations with ISO (Infrared Space Observatory). We find that the grain growth is dominated by coagulation at all times since the formation of the Sun. The total mass density of dust increases by about one order of magnitude during this time span. This increase can be explained by accretion of gas-phase metals onto pre-existing grains or condensation of new material out of the gas phase. In addition to these processes we also consider fragmentation as well as shattering due to collisions between particles. Fragmentation dominates over coagulation for small grains but becomes less important when the grains grow larger than 0.1 micrometres. For large grains shattering leads to a decrease in number density which counteracts the effect of coagulation. Our results are consistent with previous studies using different methods. 
 
 Keywords: Interstellar medium",arxiv,bigscience bloomz,706.1155,0.3888888888888889,0.3949579831932773,0.8102564102564103,0.38652651696129964,1,1,1,0,0,1,1,1,0,0,0.1265880986496504,0.0559958579254829,0.10505836575875487,0.01893939393939394,0,1,5,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Super-Poissonian Shot Noise as a Measure of Dephasing in Closed Quantum Dots,"  Electron-electron interactions play a major role in determining the
low-temperature rate of phase loss of electrons in mesoscopic systems. The
study of the dephasing rate is expected to contribute to the understanding of
the many-body nature of such systems. Closed quantum dots are of special
interest in this respect, due to theoretical predictions suggesting a possible
transition temperature below which the dephasing rate vanishes. This prediction
has attracted much attention, since closed quantum dots are prime candidates
for storage units in quantum computers, and thus their phase coherence
properties are of great importance. However, an effective method for measuring
the dephasing rate within a closed quantum dot is still lacking. Here we study
two-level systems and show that the Fano factor has a sharp peak as a function
of the chemical potential, the location of which can be simply related to the
dephasing rate. We thus suggest to use the properties of the Fano factor peak
in the super-Poissonian regime as a probe for the dephasing rate.
","We report on the observation of super-Poissonian shot noise in closed quantum dots (QDs). We show that this effect is due to dephasing and can be used for its characterization. The QD emission linewidth was measured by scanning Fabry-Perot interferometry, while the photon statistics were studied using Hanbury Brown-Twiss experiments with two avalanche photodiodes operating at 1 GHz bandwidth. In order to study the influence of temperature we performed these measurements between 4 K and 300 K. At low temperatures, below 50 K, the QD emission linewidth decreases exponentially with decreasing temperature following an activation energy of about 0.3 meV. Above 100 K it follows a power law dependence with T-1/2. Super-Poissonian shot-noise appears above 60 K and increases rapidly up to room temperature where it reaches values more than twice those expected for Poissonian light.",arxiv,bigscience bloomz,705.2668,0.3333333333333333,0.24369747899159663,0.22564102564102564,0.3435260391782131,0,1,0,0,0,1,1,0,0,0,0.057569263213477856,0.09171661254690247,0.06614785992217899,0.10606060606060606,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Unambiguous coherent state identification: Searching a quantum database,"  We consider an unambiguous identification of an unknown coherent state with
one of two unknown coherent reference states. Specifically, we consider two
modes of an electromagnetic field prepared in unknown coherent states alpha_1
and alpha_2, respectively. The third mode is prepared either in the state
alpha_1 or in the state alpha_2. The task is to identify (unambiguously) which
of the two modes are in the same state. We present a scheme consisting of three
beamsplitters capable to perform this task. Although we don't prove the
optimality, we show that the performance of the proposed setup is better than
the generalization of the optimal measurement known for a finite-dimensional
case. We show that a single beamsplitter is capable to perform an unambiguous
quantum state comparison for coherent states optimally. Finally we propose an
experimental setup consisting of 2N-1 beamsplitters for unambiguous
identification among N unknown coherent states. This setup can be considered as
a search in a quantum database. The elements of the database are unknown
coherent states encoded in different modes of an electromagnetic field. The
task is to specify the two modes that are excited in the same, though unknown,
coherent state.
","We present an algorithm for searching in databases that are stored as qubits, which is the basic unit of information in quantum computers. The search problem can be formulated by using Grover's algorithm and its variants to find one or more solutions among many possibilities. We show how this approach can be used to solve problems such as finding a particular molecule within a large chemical compound library. Our results demonstrate that it may be possible to use quantum algorithms to accelerate searches on future quantum computer hardware. Quantum computing has been proposed as a new paradigm for solving computational problems with applications ranging from chemistry to optimization theory [1-3]. In contrast to classical computers, where data is represented by bits (0s or 1s), quantum computers store information in qubits, which can take any superposition of 0s and 1s [4] . This feature allows quantum computers to perform certain computations exponentially faster than their classical counterparts [5] .
In order to make practical use of these advantages, however, we need efficient ways to implement quantum algorithms [6] , including those based on Grover's algorithm [7-9]. Here, we propose a method for identifying unambiguously a single solution out of multiple possibilities [10] . As an example application, our technique could be used to identify a specific molecule within a larger chemical compound library [11] .",arxiv,bigscience bloomz,706.1892,0.5555555555555556,0.4453781512605043,0.358974358974359,0.5957955088389871,1,1,0,0,1,1,1,0,0,1,0.045783251787474874,0.04805215019377911,0.07003891050583658,0.056818181818181816,0,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
An Extrasolar Planet Census with a Space-based Microlensing Survey,"  A space-based gravitational microlensing exoplanet survey will provide a
statistical census of exoplanets with masses down to 0.1 Earth-masses and
orbital separations ranging from 0.5AU to infinity. This includes analogs to
all the Solar System's planets except for Mercury, as well as most types of
planets predicted by planet formation theories. Such a survey will provide
results on the frequency of planets around all types of stars except those with
short lifetimes. Close-in planets with separations < 0.5 AU are invisible to a
space-based microlensing survey, but these can be found by Kepler. Other
methods, including ground-based microlensing, cannot approach the comprehensive
statistics on the mass and semi-major axis distribution of extrasolar planets
that a space-based microlensing survey will provide. The terrestrial planet
sensitivity of a ground-based microlensing survey is limited to the vicinity of
the Einstein radius at 2-3 AU, and space-based imaging is needed to identify
and determine the mass of the planetary host stars for the vast majority of
planets discovered by microlensing. Thus, a space-based microlensing survey is
likely to be the only way to gain a comprehensive understanding of the nature
of planetary systems, which is needed to understand planet formation and
habitability. The proposed Microlensing Planet Finder (MPF) mission is an
example of a space-based microlensing survey that can accomplish these
objectives with proven technology and a cost that fits comfortably under the
NASA Discovery Program cost cap.
","We present the results of an analysis of microlensing events detected by the Optical Gravitational Lensing Experiment (OGLE) and its follow-up network, including the Microlensing Observations in Astrophysics collaboration (MOA). We have identified 16 new planets among these events using high-precision photometry obtained at Subaru Observatory. The masses of all but one planet are determined to be less than 1 M⊕ . Fourteen of them are found to orbit stars more massive than 0.5 M⊙ , while two others are around low-mass dwarfs. These planets are located between 0.1 AU and 4 AU away from their host stars. This is the first time that such a large number of extrasolar planets has been discovered through space-based microlensing surveys. Our sample includes several planets whose orbits lie close to or beyond Neptune's semi-major axis. In addition, we find evidence for planetary companions to three binary systems.",arxiv,bigscience bloomz,704.0454,0.3888888888888889,0.3445378151260504,0.5692307692307692,0.369326325848065,1,1,0,0,1,1,1,0,0,1,0.07888687491085127,0.05445749381789665,0.06614785992217899,0.056818181818181816,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
An integral field spectroscopic survey for high redshift damped Lyman-alpha galaxies,"  We search for galaxy counterparts to damped Lyman-alpha absorbers (DLAs) at
z>2 towards nine quasars, which have 14 DLAs and 8 sub-DLAs in their spectra.
We use integral field spectroscopy to search for Ly-alpha emission line objects
at the redshifts of the absorption systems. Besides recovering two previously
confirmed objects, we find six statistically significant candidate Ly-alpha
emission line objects. The candidates are identified as having wavelengths
close to the DLA line where the background quasar emission is absorbed. In
comparison with the six currently known Ly-alpha emitting DLA galaxies the
candidates have similar line fluxes and line widths, while velocity offsets
between the emission lines and systemic DLA redshifts are larger. The impact
parameters are larger than 10 kpc, and lower column density systems are found
at larger impact parameters. Assuming that a single gas cloud extends from the
QSO line of sight to the location of the candidate emission line, we find that
the average candidate DLA galaxy is surrounded by neutral gas with an
exponential scale length of ~5 kpc.
","We present the results of an optical integral-field spectroscopy (IFS) survey to find high-redshift Damped Lyman Alpha Galaxies (DLAs). The sample consists of 16 DLAs at redshifts between 2 and 4, selected by their strong Mg II absorption lines in quasar spectra observed with the Keck telescope. We use the Gemini MultiObject Spectrograph on the 8-meter Gemini North Telescope to obtain spatially resolved observations over a 1 arcsec2 area centered around each absorber. Our IFS data are used to study the kinematics of these absorbers as well as their physical properties such as metallicity and dust content. In addition we compare our new measurements with previous studies based on single-aperture spectrophotometry. This work is part of the Gemini Observatory program GN-2007B-Q-206. Keywords: High-redshift universe; Galaxy evolution; Absorber-galaxy relationship",arxiv,bigscience bloomz,704.0654,0.3333333333333333,0.29411764705882354,0.2564102564102564,0.32059245102723366,1,1,0,0,0,1,1,1,0,0,0.08803906076640236,0.06278529473194126,0.08949416342412451,0.022727272727272728,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Detailed kinetic study of the ring opening of cycloalkanes by CBS-QB3 calculations,"  This work reports a theoretical study of the gas phase unimolecular
decomposition of cyclobutane, cyclopentane and cyclohexane by means of quantum
chemical calculations. A biradical mechanism has been envisaged for each
cycloalkane, and the main routes for the decomposition of the biradicals formed
have been investigated at the CBS-QB3 level of theory. Thermochemical data
(\delta H^0_f, S^0, C^0_p) for all the involved species have been obtained by
means of isodesmic reactions. The contribution of hindered rotors has also been
included. Activation barriers of each reaction have been analyzed to assess the
1 energetically most favorable pathways for the decomposition of biradicals.
Rate constants have been derived for all elementary reactions using transition
state theory at 1 atm and temperatures ranging from 600 to 2000 K. Global rate
constant for the decomposition of the cyclic alkanes in molecular products have
been calculated. Comparison between calculated and experimental results allowed
to validate the theoretical approach. An important result is that the
rotational barriers between the conformers, which are usually neglected, are of
importance in decomposition rate of the largest biradicals. Ring strain
energies (RSE) in transition states for ring opening have been estimated and
show that the main part of RSE contained in the cyclic reactants is removed
upon the activation process.
","The reaction mechanism for the ring-opening reactions of cyclic alkanes with water has been studied using density functional theory (DFT) and ab initio molecular orbital methods at the B3LYP/6-311++G(d,p), MP2/6-31+G*, QCISD/6-31+G* levels in conjunction with the CBS-QB3 method to calculate enthalpies of formation.  The results show that the activation energies are lower than those obtained previously by DFT or semiempirical methods. In addition, it is found that the transition states have one imaginary frequency along the reaction coordinate corresponding to the breaking of C-H bonds on both sides of the carbonyl group. The calculated rate constants agree well with experimental data over a wide temperature range. Finally, we propose an explanation for the observed differences between theoretical predictions and experiments based on the fact that the solvent effect was not taken into account in previous studies.",arxiv,bigscience bloomz,704.07,0.4444444444444444,0.19327731092436976,0.4461538461538462,0.3435260391782131,1,1,0,0,0,1,1,0,0,0,0.0896290011197668,0.12082451083739118,0.10894941634241245,0.12121212121212122,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Magnetic fluctuations in n-type high-$T_c$ superconductors reveal breakdown of fermiology,"  By combining experimental measurements of the quasiparticle and dynamical
magnetic properties of optimally electron-doped Pr$_{0.88}$LaCe$_{0.12}$CuO$_4$
with theoretical calculations we demonstrate that the conventional fermiology
approach cannot possibly account for the magnetic fluctuations in these
materials. In particular, we perform tunneling experiments on the very same
sample for which a dynamical magnetic resonance has been reported recently and
use photoemission data by others on a similar sample to characterize the
fermionic quasiparticle excitations in great detail. We subsequently use this
information to calculate the magnetic response within the conventional
fermiology framework as applied in a large body of work for the hole-doped
superconductors to find a profound disagreement between the theoretical
expectations and the measurements: this approach predicts a step-like feature
rather than a sharp resonance peak, it underestimates the intensity of the
resonance by an order of magnitude, it suggests an unreasonable temperature
dependence of the resonance, and most severely, it predicts that most of the
spectral weight resides in incommensurate wings which are a key feature of the
hole-doped cuprates but have never been observed in the electron-doped
counterparts. Our findings strongly suggest that the magnetic fluctuations
reflect the quantum-mechanical competition between antiferromagnetic and
superconducting orders.
","We report the observation of magnetic fluctuations at low temperatures and high fields in single crystals of YBa2Cu3O6+x (YBCO) with x=0.4, 0.45, and 0.5 using muon spin relaxation measurements. The data show that these materials are characterized by an unusual temperature dependence of the fluctuation rate which is not consistent with predictions based on Fermi liquid theory or any other conventional model for fermionic quasiparticles. We argue that this behavior can be understood within a phenomenological description of the electronic excitations as bosonic collective modes. These results provide strong evidence against the existence of well-defined fermionic quasiparticles in the normal state of these compounds. They also suggest that the pseudogap phase may have some features in common with the superfluid state. 
 
 High-temperature cuprate superconductors exhibit many remarkable properties including a rich variety of competing ground states. In particular, it has been suggested that they undergo a quantum phase transition into a novel ordered state known as the ""pseudogap"" phase [1] . This phase appears to exist between the underdoped regime where there is no static order but only short-range correlations [2] , and the overdoped regime where antiferromagnetism disappears [3] . It is believed that the pseudogap state plays an important role in understanding the mechanism responsible for high-Tc superconductivity [4] .
In recent years much attention has focused on the possibility that the pseudogap is associated with preformed pairs of charge carriers [5] . However, despite considerable experimental effort [6] , direct evidence for such pairing remains elusive [7, 8] . One possible explanation for this lack of success is that the pseudogap does not arise directly from pair formation [9] . Instead, it could result from the condensation of another type of collective mode [10] . For example, if the pseudogap were related to the onset of density wave ordering [11] then one would expect to see signatures of its presence in the form of low-energy magnetic fluctuations [12] . Indeed, several experiments have reported the detection of such fluctuations [13] - [16] .",arxiv,bigscience bloomz,705.4424,0.16666666666666666,0.6974789915966387,0.37948717948717947,0.9168657429526995,0,1,1,0,0,1,1,0,0,0,0.32929740708664396,0.060607668124709795,0.36186770428015563,0.06439393939393939,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
A New Tool for Seismology--the Cumulative Spectral Power,"  The power spectral density (PSD) function is commonly used to specify
seismometer performance. It is derived from the FFT of acceleration and
correction is made for the transfer function of the instrument that generated
the data. As with any such spectrum of density (`per Hz') type, the noise
inherent to a PSD is large. This article illustrates the value of a function
that is derived from the PSD and for which the influence of noise is
significantly reduced. Called the cumulative spectral power (CSP), it is
obtained from the PSD through the noise-reducing process of integration. The
maximum of the CSP (corresponding to the longest graphed value of the period)
provides a means for estimating the total vibrational power of the earth. The
present author has significantly simplified the process of PSD generation. Thus
routine graphing is straightforwared-of first the FFT, followed by the
generation of both a PSD and its associated CSP. The unique properties of the
CSP make it valuable for the study of a variety of earth dynamics. For example,
the strking simplicity of a CSP graph generated from a record containing a
strong teleseismic earthquake is undoubtedly important to the development and
refinement of any viable theory of earthquake dynamics.
","The cumulative spectral power (CSP) is introduced as an alternative to the traditional method in analyzing earthquake data, which has been widely used by seismologists and geophysicists since it was first proposed by Aki(1957). The new tool can be applied to both earthquakes with known locations and those without any information on their epicenters. It also provides more detailed information about the source mechanism than that obtained using the traditional method. In this study we apply the new technique to analyze two large earthquakes occurred in China during recent years. We find that the results are consistent with previous studies based on other methods. This suggests that the new tool may provide useful information for studying seismic activities. Keywords: Earthquake; Source mechanism; Cumulative spectral power. 1 Introduction.
Seismological research plays an important role in understanding the physical processes involved in earthquakes. Since its introduction into seismology by Aki(1957), the traditional method of calculating the cumulative energy released by earthquakes has become one of the most popular techniques among seismologists and geophysics researchers. However, there have been some problems associated with this method such as: i)it requires accurate location of the epicenter before analysis; ii)the result depends strongly upon the choice of time window length; iii)it cannot give enough information about the source mechanisms of earthquakes. To overcome these difficulties, many attempts have been made recently to develop new tools for analyzing earthquake data. For example, Sato et al.(1989) , Kao & Chen(1990) , Wu & Chiao(1991a , 1991b )and Wu(1993 developed different approaches to calculate the cumulative energy release rate. These authors found that the results were not always consistent with each other due to differences in the assumptions they had adopted.",arxiv,bigscience bloomz,705.11,0.5,0.6974789915966387,0.4153846153846154,0.7620640229335881,1,1,0,0,1,1,0,1,0,0,0.05891439618149533,0.11486193691456427,0.06614785992217899,0.11742424242424243,0,2,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
Scattering amplitudes in strongly coupled N=4 SYM from semiclassical strings in AdS,"  Very recently in arXiv:0705.0303 Alday and Maldacena gave a string theory
prescription for computing (all) planar amplitudes in N=4 supersymmetric gauge
theory at strong coupling using the AdS/CFT correspondence. These amplitudes
are determined by a classical string solution and contain a universal
exponential factor involving the action of the classical string. On the gauge
theory side, expressions for perturbative amplitudes at strong coupling were
previously proposed only for specific helicities of external particles -- the
maximally helicity violating or MHV amplitudes. These follow from the
exponential ansatz of Bern, Dixon and Smirnov for MHV amplitudes in N=4 SYM. In
this paper we examine the amplitudes dependence on helicities and
particle-types of external states. We consider the prefactor of string
amplitudes and give arguments suggesting that the prefactor at strong coupling
should be the same as the Yang-Mills tree-level amplitude for the same process.
This implies that scattering amplitudes in N=4 SYM simplify dramatically in the
strong coupling limit. It follows from our proposal that in this limit all (MHV
and non-MHV) n-point amplitudes are given by the (known) tree-level Yang-Mills
result times the helicity-independent (and particle-type-independent) universal
exponential.
","We study the scattering amplitudes for gluons and gravitons at strong coupling using classical string solutions in Anti-de Sitter space (AdS). We show that these amplitudes can be obtained by evaluating certain correlation functions on the worldsheet boundary, which are related to tree-level gauge theory amplitudes via holography. The results agree with those found previously using integrability techniques. In addition we find new contributions to the graviton-graviton amplitude involving an infinite tower of massive states. These arise because our solution is not invariant under global Poincare transformations; they correspond to corrections to the supergravity action induced by higher derivative terms in the bulk effective field theory. 
Introduction

The AdS/CFT correspondence [1] relates type IIB superstrings propagating in ten-dimensional anti-de Sitter space-time (AdS) to conformal field theories living on its four-dimensional boundary. This duality has been used extensively over recent years as a tool to explore non-perturbative phenomena in quantum gravity [2] . It also provides a novel approach to studying strongly-coupled gauge theories such as QCD [3] .
In this talk we will consider the simplest example of the AdS/CFT correspondence -the maximally supersymmetric Yang-Mills (N=4 SYM) theory [4] , whose dual description involves type IIA strings moving in AdS 5 × S 5 [5] . At weak 't Hooft coupling λ = g 2 Y M N ≪ 1, where g Y M denotes the Yang-Mills coupling constant, perturbative calculations have shown that the two descriptions match exactly [6] . However, it remains unclear how to calculate quantities like scattering amplitudes directly within the gauge theory at large values of λ [7, 8] . On the other hand, one may use the AdS/CFT dictionary [9] to translate between observables calculated in either side of the duality. For instance, the expectation value of Wilson loops in the gauge theory corresponds to the area of minimal surfaces embedded into AdS [10] ; while n-point correlators of local operators in the gauge theory are given by functional integrals over n-punctured Riemann surfaces [11] .",arxiv,bigscience bloomz,705.2113,0.3888888888888889,0.29411764705882354,0.3333333333333333,0.4295269947443861,1,1,1,0,0,2,2,0,0,1,0.0743101716145708,0.09041245483756365,0.08171206225680934,0.08333333333333333,0,1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1
Mass loss from Luminous Blue Variables and Quasi-Periodic Modulations of Radio Supernovae,"  Massive stars, supernovae (SNe), and long-duration gamma-ray bursts (GRBs)
have a huge impact on their environment. Despite their importance, a
comprehensive knowledge of which massive stars produce which SN/GRB is hitherto
lacking. We present a brief overview about our knowledge of mass loss in the
Hertzsprung-Russell Diagram (HRD) covering evolutionary phases of the OB main
sequence, the unstable Luminous Blue Variable (LBV) stage, and the Wolf-Rayet
(WR) phase. Despite the fact that metals produced by ``self-enrichment'' in WR
atmospheres exceed the initial -- host galaxy -- metallicity, by orders of
magnitude, a particularly strong dependence of the mass-loss rate on the
initial metallicity is found for WR stars at sub-solar metallicities (1/10 --
1/100 solar). This provides a significant boost to the collapsar model for
GRBs, as it may present a viable mechanism to prevent the loss of angular
momentum by stellar winds at low metallicity, whilst strong Galactic WR winds
may inhibit GRBs occurring at solar metallicities. Furthermore, we discuss
recently reported quasi-sinusoidal modulations in the radio lightcurves of SNe
2001ig and 2003bg. We show that both the sinusoidal behaviour and the
recurrence timescale of these modulations are consistent with the predicted
mass-loss behaviour of LBVs, and we suggest LBVs may be the progenitors of some
core-collapse SNe.
","We present the results of our study on mass-loss rates in luminous blue variables (LBVs) based on radio observations at 1.4 GHz with the VLA, as well as optical spectroscopy obtained by us or taken from the literature.  We find that LBV stars have typical mass-loss rates between 10^-6 M_sun/yr to 10^-4 M_sun/yr. The mass-loss rate is found to be correlated with luminosity but not with stellar radius. In addition we report quasi-periodic modulations of radio supernovae associated with SN 1987A and SN 1993J which are likely due to periodic changes in their circumstellar environments. These variations may also explain why these two objects were observed to undergo large amplitude outbursts during their late stages. This research was supported by NASA grant NAG5-7262. Keywords: Mass loss, Stellar evolution",arxiv,bigscience bloomz,704.2689,0.3333333333333333,0.29411764705882354,0.441025641025641,0.32059245102723366,1,1,0,0,1,1,1,1,0,0,0.131641570546798,0.09531958424814546,0.10894941634241245,0.08333333333333333,0,2,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Quantum Hall ferromagnetism in graphene: a SU(4) bosonization approach,"  We study the quantum Hall effect in graphene at filling factors \nu = 0 and
\nu = \pm, concentrating on the quantum Hall ferromagnetic regime, within a
non-perturbative bosonization formalism. We start by developing a bosonization
scheme for electrons with two discrete degrees of freedom (spin-1/2 and
pseudospin-1/2) restricted to the lowest Landau level. Three distinct phases
are considered, namely the so-called spin-pseudospin, spin, and pseudospin
phases. The first corresponds to a quarter-filled (\nu =-1) while the others to
a half-filled (\nu = 0) lowest Landau level. In each case, we show that the
elementary neutral excitations can be treated approximately as a set of
n-independent kinds of boson excitations. The boson representation of the
projected electron density, the spin, pseudospin, and mixed spin-pseudospin
density operators are derived. We then apply the developed formalism to the
effective continuous model, which includes SU(4) symmetry breaking terms,
recently proposed by Alicea and Fisher. For each quantum Hall state, an
effective interacting boson model is derived and the dispersion relations of
the elementary excitations are analytically calculated. We propose that the
charged excitations (quantum Hall skyrmions) can be described as a coherent
state of bosons. We calculate the semiclassical limit of the boson model
derived from the SU(4) invariant part of the original fermionic Hamiltonian and
show that it agrees with the results of Arovas and co-workers for SU(N) quantum
Hall skyrmions. We briefly discuss the influence of the SU(4) symmetry breaking
terms in the skyrmion energy.
","We study the quantum Hall effect (QHE) and its interplay with magnetism in monolayer graphene by using an effective low-energy model that takes into account both electron-electron interactions and disorder effects. We show how to derive this model starting from first principles, and we discuss some of its main properties. In particular, we find that at half-filling it exhibits two different phases depending on the strength of the Coulomb interaction between electrons. For weak coupling these are separated by a phase transition driven by spontaneous breaking of time-reversal symmetry; for strong coupling they correspond respectively to a conventional QHE state and to a novel fractionalized topological insulator characterized by chiral edge states. The latter is shown to be equivalent to a spin-1/2 Heisenberg antiferromagnet on the honeycomb lattice, which can thus be described within the framework of the so-called SU(4) bosonic representation.",arxiv,bigscience bloomz,704.3671,0.5555555555555556,0.19327731092436976,0.6205128205128205,0.3607262302914477,1,1,0,0,0,1,1,1,0,0,0.06858257833539248,0.06423921335745544,0.09727626459143969,0.05303030303030303,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Solar heavy element abundance: constraints from frequency separation ratios of low-degree p modes,"  We use very precise frequencies of low-degree solar-oscillation modes
measured from 4752 days of data collected by the Birmingham Solar-Oscillations
Network (BiSON) to derive seismic information on the solar core. We compare
these observations to results from a large Monte Carlo simulation of standard
solar models, and use the results to constrain the mean molecular weight of the
solar core, and the metallicity of the solar convection zone. We find that only
a high value of solar metallicity is consistent with the seismic observations.
We can determine the mean molecular weight of the solar core to a very high
precision, and, dependent on the sequence of Monte Carlo models used, find that
the average mean molecular weight in the inner 20% by radius of the Sun ranges
from 0.7209 to 0.7231, with uncertainties of less than 0.5% on each value. Our
lowest seismic estimate of solar metallicity is Z=0.0187 and our highest is
Z=0.0239, with uncertainties in the range of 12--19%. Our results indicate that
the discrepancies between solar models constructed with low metallicity and the
helioseismic observations extend to the solar core and thus cannot be
attributed to deficiencies in the modeling of the solar convection zone.
","We present new solar models that are consistent with the helioseismic data and reproduce the observed frequencies of acoustic modes in the Sun to better than 0.1% accuracy for degrees l = 0, 1, 2, 3 (n = 0 - 4). We use these models to calculate theoretical frequency separations between adjacent radial orders n for different degree l values as functions of the mean density $\rho_0$ at the base of the convection zone. The results show that the ratio of the frequency separations for l = 1 and l = 0 is sensitive to the heavy-element abundances near the surface of the Sun. This sensitivity can be used to determine the relative amount of heavy elements in the outer layers of the Sun by comparing the calculated frequency separations with those inferred from observations. 
 
 In this work we apply our method to infer the heavy-element abundance profile in the Sun using the recently published high-precision measurements of the mode frequencies obtained by GOLF on board SOHO spacecraft. Our analysis shows that the best-fit model has an iron abundance of $A(Fe) \sim 7$ times solar value at the photosphere.",arxiv,bigscience bloomz,705.3154,0.2777777777777778,0.24369747899159663,0.38461538461538464,0.495461060678452,1,1,0,0,0,1,1,0,0,0,0.13808915753261017,0.0543642820080727,0.17898832684824903,0.030303030303030304,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
GLSM's for partial flag manifolds,"  In this paper we outline some aspects of nonabelian gauged linear sigma
models. First, we review how partial flag manifolds (generalizing
Grassmannians) are described physically by nonabelian gauged linear sigma
models, paying attention to realizations of tangent bundles and other aspects
pertinent to (0,2) models. Second, we review constructions of Calabi-Yau
complete intersections within such flag manifolds, and properties of the gauged
linear sigma models. We discuss a number of examples of nonabelian GLSM's in
which the Kahler phases are not birational, and in which at least one phase is
realized in some fashion other than as a complete intersection, extending
previous work of Hori-Tong. We also review an example of an abelian GLSM
exhibiting the same phenomenon. We tentatively identify the mathematical
relationship between such non-birational phases, as examples of Kuznetsov's
homological projective duality. Finally, we discuss linear sigma model moduli
spaces in these gauged linear sigma models. We argue that the moduli spaces
being realized physically by these GLSM's are precisely Quot and hyperquot
schemes, as one would expect mathematically.
","We study the geometry and topology of generalized Lagrangian submanifolds (GLSMs) in complex symplectic manifolds, focusing on GLSMs that are special Lagrangians with respect to some Kähler form. We show how these can be constructed as holomorphic sections of certain line bundles over moduli spaces of parabolic Higgs bundles. In particular we consider the case where the base is a partial flag variety. This leads us to define new families of Calabi-Yau varieties which have been studied by physicists recently. These varieties are obtained by taking products of Grassmannian manifolds or their quotients by finite groups. The main results of this thesis are:  1. A construction of GLSMs using parabolic Higgs bundles.  2. An explicit description of the cohomology ring of the total space of a vector bundle associated to a parabolic Higgs bundle.  3. A proof of mirror symmetry between two different types of GLSMs defined above when the base is a product of Grassmannians.",arxiv,bigscience bloomz,704.1761,0.3888888888888889,0.49579831932773116,0.2512820512820513,0.40086000955566176,1,1,0,0,1,1,1,1,0,0,0.10324398861513469,0.07393940856167418,0.11673151750972763,0.06060606060606061,0,4,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Capacity Gain from Two-Transmitter and Two-Receiver Cooperation,"  Capacity improvement from transmitter and receiver cooperation is
investigated in a two-transmitter, two-receiver network with phase fading and
full channel state information available at all terminals. The transmitters
cooperate by first exchanging messages over an orthogonal transmitter
cooperation channel, then encoding jointly with dirty paper coding. The
receivers cooperate by using Wyner-Ziv compress-and-forward over an analogous
orthogonal receiver cooperation channel. To account for the cost of
cooperation, the allocation of network power and bandwidth among the data and
cooperation channels is studied. It is shown that transmitter cooperation
outperforms receiver cooperation and improves capacity over non-cooperative
transmission under most operating conditions when the cooperation channel is
strong. However, a weak cooperation channel limits the transmitter cooperation
rate; in this case receiver cooperation is more advantageous.
Transmitter-and-receiver cooperation offers sizable additional capacity gain
over transmitter-only cooperation at low SNR, whereas at high SNR transmitter
cooperation alone captures most of the cooperative capacity improvement.
","We consider the problem of two-user MIMO broadcast channel with multiple antennas at each transmitter, receiver pair. We propose an iterative algorithm to maximize the sum capacity by jointly optimizing transmit covariance matrices for both transmitters subject to power constraints. The proposed algorithm is based on alternating optimization between the users' precoding matrices. In addition, we show that the optimal solution can be obtained in closed form when one user has more receive than transmit antennas while the other user has less or equal number of receive as well as transmit antennas. Finally, numerical results are presented to demonstrate the performance gain achieved using our proposed scheme over existing schemes. Index Terms: Broadcast Channel (BC), Iterative Algorithm, Joint Transmission, Multiple Input Multiple Output (MIMO). 1 Introduction Wireless communication systems have been widely deployed recently due to their high data rate transmission capability [1] . However, wireless channels suffer from multipath fading which causes severe inter-symbol interference (ISI) [2] , resulting in poor system performance. To overcome this issue, orthogonal frequency division multiplexing (OFDM) [3] was introduced into wireless communications. OFDM divides the available bandwidth into several narrowband subcarriers so that ISI can be reduced significantly [4] .
In order to further improve spectral efficiency, multi-antenna techniques were incorporated into OFDM-based systems [5] - [8] . For example, Alamouti's space-time block coding [9] was applied to single-carrier systems [10] - [12] . Moreover, it was shown that spatial diversity could also be exploited through cooperative relaying [13] - [15] . Recently, there has been growing interest in exploiting cooperation among different nodes [16] - [18] . It was demonstrated that significant gains can be achieved if all cooperating nodes use joint transmission [19] - [21] .",arxiv,bigscience bloomz,704.3644,0.3333333333333333,0.6974789915966387,0.14871794871794872,0.7706641184902054,0,1,1,0,0,1,1,1,0,1,0.04275220058391174,0.044166219649336966,0.03501945525291829,0.08333333333333333,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Radiative Transfer Effect on Ultraviolet Pumping of the 21cm Line in the High Redshift Universe,"  During the epoch of reionization the 21cm signal is sensitive to the
scattering rate of the ultraviolet photons, redshifting across the Lyman_alpha
resonance. Here we calculate the photon scattering rate profile for a single
ultraviolet source. After taking into account previously neglected natural
broadening of the resonance line, we find that photons approach the resonance
frequency and experience most scatterings at a significantly smaller distance
from the source than naively expected r=(dnu/nu_0)(c/H), where dnu=nu-nu_0 is
the initial frequency offset, and the discrepancy increases as the initial
frequency offset decreases. As a consequence, the scattering rate P(r) drops
much faster with increasing distance than the previously assumed 1/r^2 profile.
Near the source (r<1Mpc comoving), the scattering rate of photons that redshift
into the Ly_alpha resonance converges to P(r) \propto r^{-7/3}. The scattering
rate of Ly_alpha photons produced by splitting of photons that redshift into a
higher resonance (Ly_gamma, Ly_delta, etc.) is only weakly affected by the
radiative transfer, while the sum of scattering rates of Ly_alpha photons
produced from all higher resonances also converges to P(r) \propto r^{-7/3}
near the source. At 15<z<35, on scales of ~0.01-20Mpc/h (comoving), the total
scattering rate of Ly_alpha photons from all Lyman resonances is found to be
higher by a factor of ~1+0.3[(1+z)/20]^{2/3} than obtained without full
radiative transfer. Consequently, during the early stage of reionization, the
differential brightness of 21cm signal against the cosmic microwave background
is also boosted by a similar factor.
","We study the effect of radiative transfer (RT) on ultraviolet pumping of the 21 cm line at high redshifts, using cosmological hydrodynamic simulations with RT and without it. We find that RT can significantly enhance the strength of the 21 cm signal by up to an order of magnitude compared to calculations neglecting RT effects. The enhancement is caused mainly by Lyman-alpha photons produced inside galaxies which are absorbed outside them due to scattering off neutral hydrogen atoms. This leads to additional heating of the intergalactic medium through photoionization heating and Compton cooling. In addition we show that the inclusion of RT also changes the shape of the power spectrum of the 21 cm brightness temperature fluctuations. Our results suggest that future radio telescopes such as SKA will be able to detect this signal if they have sufficient sensitivity. Keywords: Hydrogen, Radiation transfer, Power Spectrum, Cosmic Dawn",arxiv,bigscience bloomz,706.0895,0.4444444444444444,0.29411764705882354,0.5948717948717949,0.3750597228858099,1,1,0,0,0,1,1,1,0,0,0.14098560394342927,0.052216722874547476,0.19066147859922178,0.026515151515151516,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Haunted Halos of Andromeda and Triangulum: A panorama of galaxy formation in action,"  We present a deep photometric survey of M31, conducted with the CFHT and INT,
covering the inner 50 kpc of the galaxy, the Southern quadrant out to 150 kpc,
and extending to M33. This is the first systematic panoramic study of this very
outermost region of galaxies. We detect several streams and other large-scale
structures, and two new dwarf galaxies: And XV and XVI. The discovery of
substructure on the minor axis, together with the fact that the light profile
between 0.5 < R < 1.3 follows the exponential ``extended disk'', is
particularly important in shedding light on the mixed and sometimes conflicting
results reported in previous studies. Underlying the substructures lies a
faint, metal-poor, smooth and extremely extended halo, reaching out to at least
150 kpc. The smooth halo component in M31 has a profile that can be fit with a
Hernquist model of immense scale radius ~55 kpc, almost a factor of 4 larger
than theoretical predictions. Alternatively a power-law with exponent -1.91 +/-
0.11 can be fit to the profile. The total luminosity of this structure is
similar to that of the halo of the Milky Way. This vast, smooth, underlying
halo is reminiscent of a classical monolithic model and completely unexpected
from modern galaxy formation models. M33 is also found to have an extended
metal-poor halo component, which can be fit with a Hernquist model also of
scale radius ~55 kpc. These extended slowly-decreasing halos will provide a
challenge and strong constraints for further modeling. [Abridged]
","We present the first panoramic view of the distribution of galaxies around two massive clusters at redshifts z = 0.4-0.6, using deep near-infrared imaging with WFC3 on HST. The data reveal an extended population of faint galaxies surrounding each cluster that is not seen in optical images. We find that these galaxies are predominantly blue (with median color u − g = -0.5), have low stellar masses (10^9 Msun/pc^2) and high specific star formation rates (sSFR ~ 10^-2 Gyr-1). These properties suggest they represent a recently assembled population of star-forming dwarf galaxies that were accreted by their host clusters during recent mergers. In addition to this diffuse component we also identify several dozen bright galaxies within 1 Mpc of both clusters which appear to be undergoing rapid bursts of star formation triggered by interactions between infalling gas-rich galaxies and the hot intracluster medium.",arxiv,bigscience bloomz,704.1318,0.6111111111111112,0.19327731092436976,0.6512820512820513,0.3635929288103201,0,1,1,0,1,1,1,0,0,0,0.1134566534023953,0.07279136332152504,0.11284046692607004,0.06060606060606061,1,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
An expansion for self-interacting random walks,"  We derive a perturbation expansion for general self-interacting random walks,
where steps are made on the basis of the history of the path. Examples of
models where this expansion applies are reinforced random walk, excited random
walk, the true (weakly) self-avoiding walk, loop-erased random walk, and
annealed random walk in random environment.
  In this paper we show that the expansion gives rise to useful formulae for
the speed and variance of the random walk, when these quantities are known to
exist. The results and formulae of this paper have been used elsewhere by the
authors to prove monotonicity properties for the speed (in high dimensions) of
excited random walk and related models, and certain models of random walk in
random environment.
  We also derive a law of large numbers and central limit theorem (with
explicit error terms) directly from this expansion, under strong assumptions on
the expansion coefficients. The assumptions are shown to be satisfied by
excited random walk in high dimensions with small excitation parameter, a model
of reinforced random walk with underlying drift and small reinforcement
parameter, and certain models of random walk in random environment under strong
ellipticity conditions. This is the extended version of the paper, where we
provide all proofs.
","We present an exact expression for the probability distribution function (PDF) of the number of steps taken by a one-dimensional, discrete-time, self-propelled particle that moves in a periodic potential and interacts with itself via elastic collisions.  We show how this PDF can be used to calculate the mean-square displacement as well as other statistical properties of such particles. The results are illustrated using numerical simulations. 
PACS numbers: 05.45.-a; 05.70.Jk; 05.60.Gg 
I. INTRODUCTORY REMARkS
The motion of many biological systems is often described as being driven by internal forces or active processes [1] . Examples include bacteria swimming through fluids [2] , cells crawling on surfaces [3] , and molecular motors moving along cytoskeletal filaments [4] .
In recent years there has been growing interest in understanding the dynamics of these active particles [5] - [8] . In particular, it was shown that their behavior may differ significantly from that observed in passive Brownian particles [9] - [11] . For example, while the latter exhibit normal diffusion at large timescales [12] , active particles typically display superdiffusive [13] or even ballistic [14] transport depending on the details of their interactions [15] - [17] . This difference arises because active particles have additional degrees of freedom which allow them to explore more efficiently the available space [18] . As a result they tend to move faster than passive particles [19] .
Recently we introduced a model describing the motion of a single active particle [20] . It consists of a point-like object that performs a biased random walk in a periodic potential [21] . Its position x(t + 1) = x(t) + v t+1 − v t is determined by its velocity v t+1 = f [x(t), v t ] where f [·] denotes some deterministic force acting upon the particle [22] . Here we consider two different types of potentials V (x). First, when V (x) ∝ cos(2πx/L) (L is the periodicity length), the system exhibits a series of metastable states separated by energy barriers [23] . Second",arxiv,bigscience bloomz,706.0614,0.3333333333333333,0.7983193277310925,0.4205128205128205,0.9197324414715718,1,1,0,0,0,1,1,1,0,0,0.09785108513241299,0.11632673202109528,0.1245136186770428,0.14015151515151514,0,3,3,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
The remarkable X-ray spectrum of the Broad-Line Radio Galaxy 3C 445,"  We present the results of the analysis of an archival 15 ks XMM-Newton
observation of the nearby (z=0.057) radio-loud source 3C445, optically
classified as a Broad-Line Radio Galaxy. While the RGS data are of insufficient
quality to allow a meaningful analysis, the EPIC data show a remarkable X-ray
spectrum. The 2-10 keV continuum is described by a heavily absorbed (Nh~ 1e22 -
1e23 cm-2) power law with photon index Gamma ~1.4, and strong (R~2) cold
reflection. A narrow, unresolved Fe Kalpha emission line is detected,
confirming previous findings, with EW 120eV. A soft excess is present below 2
keV over the extrapolation of the hard X-ray power law, which we model with a
power law with the same photon index as the hard power law, absorbed by a
column density Nh=6e20 cm-2 in excess to Galactic. A host of emission lines are
present below 2 keV, confirming previous indications from ASCA, due to H- and
He-like O, Mg, and Si. We attribute the origin of the lines to a photoionized
gas, with properties very similar to radio-quiet obscured AGN. Two different
ionized media, or a single stratified medium, are required to fit the soft
X-ray data satisfactorily. The similarity of the X-ray spectrum of 3C445 to
Seyferts underscores that the central engines of radio-loud and radio-quiet AGN
similarly host both cold and warm gas.
","We present an analysis of the broadband (0.5-10 keV) X-ray spectrum of the radio galaxy 3C 445, using data obtained with XMM-Newton and Chandra observatories in 2001-2002 . The observed X-ray emission is dominated by a hard power-law component which can be fitted equally well either by thermal Comptonization or non-thermal inverse Compton scattering models. We find that both models require a large amount of cold matter to produce the soft excess below 1 keV. This suggests that there are two distinct components contributing to the X-ray emission - one associated with hot plasma and another related to cool gas clouds. In addition we detect several narrow absorption lines at energies corresponding to highly ionized species such as O vii , Ne ix , Mg xi and Si xiii . These features may originate in outflows driven by nuclear activity. Finally, we report on the detection of Fe Kα line at 6.4 keV produced by reflection off distant material.",arxiv,bigscience bloomz,704.3053,0.4444444444444444,0.29411764705882354,0.517948717948718,0.4094601051122791,1,1,0,0,0,1,1,0,0,0,0.081632585881693,0.0527330228335326,0.11284046692607004,0.05303030303030303,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Efficient Simulations of Early Structure Formation and Reionization,"  We present a method to construct semi-numerical ``simulations'', which can
efficiently generate realizations of halo distributions and ionization maps at
high redshifts. Our procedure combines an excursion-set approach with
first-order Lagrangian perturbation theory and operates directly on the linear
density and velocity fields. As such, the achievable dynamic range with our
algorithm surpasses the current practical limit of N-body codes by orders of
magnitude. This is particularly significant in studies of reionization, where
the dynamic range is the principal limiting factor. We test our halo-finding
and HII bubble-finding algorithms independently against N-body simulations with
radiative transfer and obtain excellent agreement. We compute the size
distributions of ionized and neutral regions in our maps. We find even larger
ionized bubbles than do purely analytic models at the same volume-weighted mean
hydrogen neutral fraction. We also generate maps and power spectra of 21-cm
brightness temperature fluctuations, which for the first time include
corrections due to gas bulk velocities. We find that velocities widen the tails
of the temperature distributions and increase small-scale power, though these
effects quickly diminish as reionization progresses. We also include some
preliminary results from a simulation run with the largest dynamic range to
date: a 250 Mpc box that resolves halos with masses M >~ 2.2 x10^8 M_sun. We
show that accurately modeling the late stages of reionization requires such
large scales. The speed and dynamic range provided by our semi-numerical
approach will be extremely useful in the modeling of early structure formation
and reionization.
","We present an efficient method for simulating the formation of large-scale structure in the early universe, including reionization by stars and quasars. Our approach is based on a combination of N-body simulations with semi-analytic models that describe galaxy formation and evolution within dark matter halos. We use this technique to study how galaxies form at high redshifts (z > 6) when the first luminous objects appear. The results are compared against observations of high-redshift galaxies obtained using the Hubble Space Telescope. This work was supported by NASA grant NNX08AG84G. In recent years there has been considerable progress in understanding the physical processes involved in galaxy formation. However, many open questions remain about the nature of these processes as well as their dependence on cosmological parameters such as the density parameter $\Omega_m$ or the amplitude of primordial fluctuations $\sigma_8$. One important goal of modern observational astronomy is to answer some of these questions through detailed studies of distant galaxies.",arxiv,bigscience bloomz,704.0946,0.6111111111111112,0.3445378151260504,0.6358974358974359,0.40659340659340665,0,1,1,0,1,1,1,0,0,0,0.04967017531720182,0.06552437572017553,0.07392996108949416,0.06060606060606061,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
HD 98800: A 10-Myr-Old Transition Disk,"  We present the mid-infrared spectrum, obtained with the Spitzer Infrared
Spectrograph (IRS), of HD 98800, a quadruple star system located in the
10-Myr-old TW Hydrae association. It has a known mid-infrared excess that
arises from a circumbinary disk around the B components of the system. The IRS
spectrum confirms that the disk around HD 98800 B displays no excess emission
below about 5.5 micron, implying an optically thick disk wall at 5.9 AU and an
inner, cleared-out region; however, some optically thin dust, consisting mainly
of 3-micron-sized silicate dust grains, orbits the binary in a ring between 1.5
and 2 AU. The peculiar structure and apparent lack of gas in the HD 98800 B
disk suggests that this system is likely already at the debris disks stage,
with a tidally truncated circumbinary disk of larger dust particles and an
inner, second-generation dust ring, possibly held up by the resonances of a
planet. The unusually large infrared excess can be explained by gravitational
perturbations of the Aa+Ab pair puffing up the outer dust ring and causing
frequent collisions among the larger particles.
","We present new near-infrared (NIR) spectroscopy and photometry for the Herbig Be star HD 98800, which is surrounded by an optically thick dust disk with a radius of ~200 AU. The NIR spectrum shows strong emission lines of H I, He II, C III, O IV-VI, Si IV, S VI, Fe II, Mg II, Al II-III, Na I, Ca II, and K I in addition to absorption features due to stellar winds. We find that the observed line profiles are consistent with those predicted by magnetohydrodynamic models of accretion disks around young stars. In particular, we detect blueshifted absorptions associated with infalling gas streams along magnetic field lines onto the central star. These results suggest that HD 98800 has been undergoing active mass accretion over the past few million years. 
 
 Keywords: Accretion, Herbig Be star",arxiv,bigscience bloomz,705.038,0.2222222222222222,0.24369747899159663,0.29743589743589743,0.34065934065934067,1,1,1,0,0,1,1,1,0,0,0.15649148080836278,0.1271498895121844,0.16731517509727625,0.10606060606060606,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Massive enhancement of electron-phonon coupling in doped graphene by an electronic singularity,"  The nature of the coupling leading to superconductivity in layered materials
such as high-Tc superconductors and graphite intercalation compounds (GICs) is
still unresolved. In both systems, interactions of electrons with either
phonons or other electrons or both have been proposed to explain
superconductivity. In the high-Tc cuprates, the presence of a Van Hove
singularity (VHS) in the density of states near the Fermi level was long ago
proposed to enhance the many-body couplings and therefore may play a role in
superconductivity. Such a singularity can cause an anisotropic variation in the
coupling strength, which may partially explain the so-called nodal-antinodal
dichotomy in the cuprates. Here we show that the topology of the graphene band
structure at dopings comparable to the GICs is quite similar to that of the
cuprates and that the quasiparticle dynamics in graphene have a similar
dichotomy. Namely, the electron-phonon coupling is highly anisotropic,
diverging near a saddle point in the graphene electronic band structure. These
results support the important role of the VHS in layered materials and the
possible optimization of Tc by tuning the VHS with respect to the Fermi level.
","We report on the observation of strong electron-phonon interaction (EPI) in heavily boron-doped epitaxial graphene grown on SiC(0001). The EPI is found to be enhanced by more than one order of magnitude compared with that observed for undoped graphene, which can be attributed to the formation of a Dirac point at high doping levels and its associated van Hove singularity near the Fermi level. This finding suggests that the EPI in doped graphene may be tunable over several orders of magnitude through chemical or electrostatic gating. 
 
 Graphene has attracted considerable attention because it exhibits unique physical properties such as extremely high carrier mobility1-5 and very large optical nonlinearities6-8. However, these remarkable properties are often accompanied by weak interactions between electrons and phonons9-11, which limit their applications in high-speed electronics12-14 and optoelectronics15-17. In this work we demonstrate that the EPI in heavily boron-doping epitaxial graphene grown by thermal decomposition of SiC18-20 can be significantly enhanced due to the presence of a Dirac point21-23 and its associated van Hov singularity24-26 near the Fermi energy EF. We show that the EPI increases rapidly when the Fermi level crosses the van Hove singularity, resulting in a giant increase in the electron-phonon scattering rate. Our results suggest that the EPI in graphene could be controlled electrically via chemical or electrostatic gated27-30, thereby opening up new avenues towards novel devices based on graphene. 
Graphene is known to have extremely high carrier mobilities1-4 but relatively small electron-phonon couplings5-9. These two competing effects determine the performance of graphene-based electronic and optoelectronic devices10-12. For example, the low EPI leads to slow relaxation rates13-15 and thus limits the operation speed of graphene transistors14-16. On the other hand, the high mobility makes graphene attractive for use in high-speed electronics17-19 and ultrafast photodetectors20. Therefore, there exists great interest in developing methods to enhance the EPI while maintaining the high mobility31",arxiv,bigscience bloomz,705.3264,0.3333333333333333,0.596638655462185,0.3230769230769231,0.8365981844242714,1,1,0,0,0,1,1,0,0,0,0.07015720861699547,0.08160209674529875,0.07782101167315175,0.07954545454545454,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1
New Close Binary Systems from the SDSS-I (Data Release Five) and the Search for Magnetic White Dwarfs in Cataclysmic Variable Progenitor Systems,"  We present the latest catalog of more than 1200 spectroscopically-selected
close binary systems observed with the Sloan Digital Sky Survey through Data
Release Five. We use the catalog to search for magnetic white dwarfs in
cataclysmic variable progenitor systems. Given that approximately 25% of
cataclysmic variables contain a magnetic white dwarf, and that our large sample
of close binary systems should contain many progenitors of cataclysmic
variables, it is quite surprising that we find only two potential magnetic
white dwarfs in this sample. The candidate magnetic white dwarfs, if confirmed,
would possess relatively low magnetic field strengths (B_WD < 10 MG) that are
similar to those of intermediate-Polars but are much less than the average
field strength of the current Polar population. Additional observations of
these systems are required to definitively cast the white dwarfs as magnetic.
Even if these two systems prove to be the first evidence of detached magnetic
white dwarf + M dwarf binaries, there is still a large disparity between the
properties of the presently known cataclysmic variable population and the
presumed close binary progenitors.
","We report on new close binary systems discovered by searching for white dwarf companions to cataclysmic variables using data obtained with the Sloan Digital Sky Survey's first year of operation, Data Release 5. We find that most of these binaries are likely to be double-degenerate systems consisting of two helium white dwarfs or one carbon-oxygen white dwarf plus another degenerate object such as a neutron star or black hole. The majority of our sample have orbital periods less than 1 hour; we also identify several candidates which may contain magnetic white dwarfs. These results will help us understand how common double-degenerate mergers might be among all type Ia supernovae. 
 
 Keywords: Double-degenerate systems; Type Ia supernovae; Close binary stars; Sloan Digital Sky Survey; Cataclysmic Variables; White dwarfs; Helium white dwarfs; Carbon-oxygen white dwarfs",arxiv,bigscience bloomz,704.0789,0.2777777777777778,0.19327731092436976,0.28717948717948716,0.3320592451027234,1,1,0,0,0,0,1,1,0,1,0.13079488376971876,0.05920987842620881,0.1245136186770428,0.03409090909090909,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A High-Resolution Survey of Low-Redshift QSO Absorption Lines: Statistics and Physical Conditions of O VI Absorbers,"  Using high-resolution UV spectra of 16 low-z QSOs, we study the physical
conditions and statistics of O VI absorption in the IGM at z < 0.5. We identify
51 intervening (z_{abs} << z_{QSO}) O VI systems comprised of 77 individual
components, and we find 14 ""proximate"" systems (z_{abs} ~ z_{QSO}) containing
34 components. For intervening systems [components] with rest-frame equivalent
width W_{r} > 30 mA, the number of O VI absorbers per unit redshift dN/dz =
15.6(+2.9/-2.4) [21.0(+3.2/-2.8)], and this decreases to dN/dz = 0.9(+1.0/-0.5)
[0.3(+0.7/-0.3)] for W_{r} > 300 mA. The number per redshift increases steeply
as z_{abs} approaches z_{QSO}, and some proximate absorbers have substantially
lower H I/O VI ratios. The lower proximate ratios could be partially due to
ionization effects but also require higher metallicities. We find that 37% of
the intervening O VI absorbers have velocity centroids that are well-aligned
with corresponding H I absorption. If the O VI and the H I trace the same gas,
the relatively small differences in line widths imply the absorbers are cool
with T < 10^{5} K. Most of these well-aligned absorbers have the
characteristics of metal-enriched photoionized gas. However, the O VI in the
apparently simple and cold systems could be associated with a hot phase with T
~ 10^{5.5} K if the metallicity is high enough to cause the associated broad Ly
alpha absorption to be too weak to detect. We show that 53% of the intervening
O VI systems are complex multiphase absorbers that can accommodate both lower
metallicity collisionally-ionized gas with T > 10^{5} K and cold photoionzed
gas.
","We present the results of an extensive survey for absorption lines in high-resolution spectra of quasars at redshifts z < 0.3, obtained with HST/STIS (the Hubble Space Telescope Spectrograph). The sample consists of 12 QSOs observed over a total exposure time of about 1 Ms. We detect more than 1000 Lyman alpha forest absorbers along each line-of-sight to these QSOs; we also find that most sight-lines show strong absorption by high-ionization species such as C IV and Si IV. In addition, we identify several hundred systems showing absorption due to highly ionized oxygen, O VI . These are among the strongest known O VI absorbers anywhere in the universe. By combining our data set with previous surveys, we obtain new constraints on the physical conditions of this gas phase. Our main conclusions are:  -The number density of O VI absorbers per unit redshift is n(O VI) = 2.6 +/- 0.4 x 10^-3 cm^-3 , which corresponds to a mean separation between absorber pairs of r = 4.1 +/- 0.5 h-1 Gpc.  -Most O VI absorbers have temperatures T ~ 10 5 K and densities log ne/cm -3 > 13.8. About half of them appear to be associated with galaxies within 50 kpc projected distance. -There appears to be no correlation between the properties of O VI absorbers and those of their host galaxy population.",arxiv,bigscience bloomz,706.1214,0.4444444444444444,0.3949579831932773,0.7230769230769231,0.5957955088389871,1,1,0,0,0,1,1,1,0,0,0.13795100133994484,0.11255410088186786,0.14007782101167315,0.10984848484848485,0,0,5,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Evolution of Protoplanetary Disks Around Millisecond Pulsars: The PSR 1257 +12 System,"  We model the evolution of protoplanetary disks surrounding millisecond
pulsars, using PSR 1257+12 as a test case. Initial conditions were chosen to
correspond to initial angular momenta expected for supernova-fallback disks and
disks formed from the tidal disruption of a companion star. Models were run
under two models for the viscous evolution of disks: fully viscous and layered
accretion disk models. Supernova-fallback disks result in a distribution of
solids confined to within 1-2 AU and produce the requisite material to form the
three known planets surrounding PSR 1257+12. Tidal disruption disks tend to
slightly underproduce solids interior to 1 AU, required for forming the pulsar
planets, while overproducing the amount of solids where no body, lunar mass or
greater, exists. Disks evolving under 'layered' accretion spread somewhat less
and deposit a higher column density of solids into the disk. In all cases,
circumpulsar gas dissipates on $\lesssim 10^{5}$ year timescales, making
formation of gas giant planets highly unlikely.
","We present new observations and analysis of the pulsar–disk system PSR 1257+12, which is one of only two known systems in which a millisecond radio pulsar orbits around an evolved star (a white dwarf). We have obtained high-resolution near-infrared images with adaptive optics at Keck Observatory that reveal a bright ring-like structure surrounding the pulsar's position. This feature has been interpreted as emission from dust grains orbiting within the disk produced by the supernova explosion that created both stars. 
 
 In addition to this ring, we detect faint extended emission extending out to several hundred AU on either side of the central source. These features are consistent with previous results based on lower resolution data. However, our higher spatial resolution reveals additional details about these structures. For example, we find evidence for spiral arms in the outer regions of the disk, which may be caused by gravitational interactions between the disk and the binary companion.",arxiv,bigscience bloomz,705.3063,0.3333333333333333,0.29411764705882354,0.1794871794871795,0.3951266125179169,0,1,1,0,1,1,1,0,0,1,0.0544898780558809,0.07136797945615422,0.0622568093385214,0.056818181818181816,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Poisson approximation for non-backtracking random walks,"  Random walks on expander graphs were thoroughly studied, with the important
motivation that, under some natural conditions, these walks mix quickly and
provide an efficient method of sampling the vertices of a graph. Alon,
Benjamini, Lubetzky and Sodin studied non-backtracking random walks on regular
graphs, and showed that their mixing rate may be up to twice as fast as that of
the simple random walk. As an application, they showed that the maximal number
of visits to a vertex, made by a non-backtracking random walk of length $n$ on
a high-girth $n$-vertex regular expander, is typically $(1+o(1))\frac{\log
n}{\log\log n}$, as in the case of the balls and bins experiment. They further
asked whether one can establish the precise distribution of the visits such a
walk makes.
  In this work, we answer the above question by combining a generalized form of
Brun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote
the number of vertices visited precisely $t$ times by a non-backtracking random
walk of length $n$ on a regular $n$-vertex expander of fixed degree and girth
$g$. We prove that if $g=\omega(1)$, then for any fixed $t$, $N_t/n$ is
typically $\frac{1}{\mathrm{e}t!}+o(1)$. Furthermore, if $g=\Omega(\log\log
n)$, then $N_t/n$ is typically $\frac{1+o(1)}{\mathrm{e}t!}$ uniformly on all
$t \leq (1-o(1))\frac{\log n}{\log\log n}$ and 0 for all $t \geq
(1+o(1))\frac{\log n}{\log\log n}$. In particular, we obtain the above result
on the typical maximal number of visits to a single vertex, with an improved
threshold window. The essence of the proof lies in showing that variables
counting the number of visits to a set of sufficiently distant vertices are
asymptotically independent Poisson variables.
","We consider the probability distribution of the number of times that a simple random walk on an infinite graph visits some fixed vertex in finite time, and show how this can be approximated by a Poisson distribution with mean equal to the expected value of the number of visits.  We then use these results to prove that the total variation distance between the two distributions is bounded above by $O(1/n)$ where $n$ denotes the number of vertices in the graph.   This result generalizes previous work which was restricted to graphs whose degree sequence has exponential decay or polynomial growth.    The proof relies heavily upon recent advances in the theory of large deviations for sums of dependent Bernoulli variables. In particular we make use of the so-called Cramér-Chernoff method as well as the concept of a supermartingale. Finally, we apply our main theorem to obtain new bounds on the mixing time of lazy random walks on regular trees.",arxiv,bigscience bloomz,705.0867,0.5555555555555556,0.24369747899159663,0.764102564102564,0.4037267080745342,1,1,0,0,1,1,1,0,0,0,0.12316145778342384,0.10395812726612329,0.19455252918287938,0.056818181818181816,0,0,6,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Radion Phenomenology in Realistic Warped Space Models,"  We investigate the phenomenology of the Randall-Sundrum radion in realistic
models of electroweak symmetry breaking with bulk gauge and fermion fields,
since the radion may turn out to be the lightest particle in such models. We
calculate the coupling of the radion in such scenarios to bulk fermion and
gauge modes. Special attention needs to be devoted to the coupling to massless
gauge fields (photon, gluon), since it is well known that loop effects may be
important for these fields. We also present a detailed explanation of these
couplings from the CFT interpretation. We then use these couplings to determine
the radion branching fractions and discuss some of the discovery potential of
the LHC for the radion. We find that the gamma-gamma signal is enhanced over
most of the range of the radion mass over the gamma-gamma signal of a SM Higgs,
as long as the RS scale is sufficiently low. However, the signal significance
depends strongly on free parameters that characterize the magnitude of bare
brane-localized kinetic terms for the massless gauge fields. In the absence of
such terms, the signal can be be enhanced over the traditional RS1 models
(where all standard model fields are localized on the IR brane), but the signal
can also be reduced compared to RS1 if the brane localized terms are sizeable.
We also show that for larger radion masses, where the gamma-gamma signal is no
longer significant, one can use the usual 4 lepton signal to discover the
radion.
","We study the phenomenological consequences of radion stabilization by introducing an explicit mass term for the radion into realistic warped space models with bulk gauge fields and fermions. We find that, depending on the model parameters, there are two possible scenarios which can be realized at low energies: (i) The radion is heavy enough to decouple from all Standard Model particles. (ii) The radion couples directly to Standard Model particles but its effects are suppressed due to mixing between the radion and the Higgs boson. In both cases we show how the radion affects precision electroweak observables such as S, T , W , Y . Finally, we discuss the possibility of detecting the radion through direct production at future colliders. Introduction: One of the most interesting features of Randall-Sundrum type I [1] or II [2] models is their ability to generate hierarchies among fundamental scales without fine-tuning [3] . However, these models suffer from the presence of a scalar field called the radion whose vacuum expectation value determines the size of extra dimensions [4] .
In this work we consider the case where the radion acquires a large mass so it does not affect low-energy physics [5] . On the other hand, if the radion remains light then it may have observable effects [6] - [8] . For example, one could imagine that the radion mixes strongly with the Higgs boson leading to deviations from standard predictions [9] . Alternatively, the radion might couple directly to Standard Model particles [10] . In either scenario, the radion would contribute to precision electroweak measurements [11] - [13] . This motivates us to investigate whether the radion has any effect on precision electroweak data within realistic warped space models [14] - [16] .",arxiv,bigscience bloomz,705.3844,0.4444444444444444,0.596638655462185,0.6358974358974359,0.78786430960344,1,1,0,0,0,1,1,1,0,0,0.10041979429526258,0.053828355170272776,0.09727626459143969,0.056818181818181816,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
8.4GHz VLBI observations of SN2004et in NGC6946,"  We report on 8.4GHz Very Long Baseline Interferometry (VLBI) observations of
the type II-P supernova SN2004et in the spiral galaxy NGC 6946, made on 20
February 2005 (151 days after explosion). The Very Large Array (VLA) flux
density was 1.23$\pm$0.07 mJy, corresponding to an isotropic luminosity at
8.4GHz of (4.45$\pm$0.3)$\times10^{25}$ erg s$^{-1}$ Hz$^{-1}$ and a brightness
temperature of (1.3$\pm$0.3)$\times10^{8}$ K. We also provide an improved
source position, accurate to about 0.5 mas in each coordinate. The VLBI image
shows a clear asymmetry. From model fitting of the size of the radio emission,
we estimate a minimum expansion velocity of 15,700$\pm$2,000 km s$^{-1}$. This
velocity is more than twice the expected mean expansion velocity estimated from
a synchrotron self-absorbed emission model, thus suggesting that synchrotron
self-absorption is not relevant for this supernova. With the benefit of an
optical spectrum obtained 12 days after explosion, we favor an emission model
which consists of two hot spots on an underlying expanding shell of width
comparable to that of SN 1993J.
","We present 8.4 GHz Very Long Baseline Interferometry (VLBI) images and light curves for the supernova remnant (SNR) associated with the Type IIb supernova SN2004et, which exploded in the nearby spiral galaxy NGC 6946 on 2004 September 24 UT1. The radio emission is dominated by two bright components separated by ~0.5 arcsec at all epochs observed between 2005 January and 2007 December. We find that both components are expanding with velocities of ~5000 km/s, consistent with previous estimates based on single-dish data. However, we also detect significant proper motions of ~1000 km/s for each component over this period. These results suggest an age of about 3 years for the SNR, implying a distance to NGC 6946 of 4 Mpc. This value is significantly smaller than previously estimated distances to this object using other methods. Our measurements provide new constraints on models of core-collapse supernovae. 
 
 Keywords: Supernova remnants",arxiv,bigscience bloomz,705.3853,0.2777777777777778,0.3445378151260504,0.22564102564102564,0.3750597228858099,1,1,0,0,0,1,1,1,0,0,0.23540360468058133,0.09604905118805472,0.3151750972762646,0.06439393939393939,1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Star-Formation in Low Radio Luminosity AGN from the Sloan Digital Sky Survey,"  We investigate faint radio emission from low- to high-luminosity Active
Galactic Nuclei (AGN) selected from the Sloan Digital Sky Survey (SDSS). Their
radio properties are inferred by co-adding large ensembles of radio image
cut-outs from the FIRST survey, as almost all of the sources are individually
undetected. We correlate the median radio flux densities against a range of
other sample properties, including median values for redshift, [OIII]
luminosity, emission line ratios, and the strength of the 4000A break. We
detect a strong trend for sources that are actively undergoing star-formation
to have excess radio emission beyond the ~10^28 ergs/s/Hz level found for
sources without any discernible star-formation. Furthermore, this additional
radio emission correlates well with the strength of the 4000A break in the
optical spectrum, and may be used to assess the age of the star-forming
component. We examine two subsamples, one containing the systems with emission
line ratios most like star-forming systems, and one with the sources that have
characteristic AGN ratios. This division also separates the mechanism
responsible for the radio emission (star-formation vs. AGN). For both cases we
find a strong, almost identical, correlation between [OIII] and radio
luminosity, with the AGN sample extending toward lower, and the star-formation
sample toward higher luminosities. A clearer separation between the two
subsamples is seen as function of the central velocity dispersion of the host
galaxy. For systems with similar redshifts and velocity dispersions, the
star-formation subsample is brighter than the AGN in the radio by an order of
magnitude. This underlines the notion that the radio emission in star-forming
systems can dominate the emission associated with the AGN.
","We present an analysis of star-formation activity associated with low radio luminosity active galactic nuclei (AGNs) using data from the Sloan DigitalSky Survey (SDSS). We find that these objects are typically hosted by massive galaxies, and have high specific star formation rates compared to inactive galaxies at similar redshifts. The majority of our sample is found to be obscured by dusty torii, as indicated by their optical colors and infrared emission. These results suggest that there may exist two populations of AGN: one which hosts significant amounts of star formation, and another where no such activity is observed. This work was supported by NASA grant NNG05GJ40G. Active Galactic Nuclei (AGNs), powered by supermassive black holes accreting matter from surrounding gas clouds, are known to produce copious quantities of radiation across all wavelengths. However, it has been unclear whether this energy output also leads to enhanced levels of star formation within host galaxies. In order to investigate this question we use data from the SloanDigital Sky Survey (SDSS; York et al., 2000) , specifically targeting sources classified as narrow-line Seyfert 1's (NLS1s) based on their optical spectra. NLS1s represent a subclass of AGNs whose properties differ significantly from those of more typical broad line quasars (BLQs; Osterbrock & Pogge 1985) . They tend to reside in lower mass galaxies than BLQSOs, and exhibit higher Eddington ratios (Boller et al., 1996; Grupe, Thomas, & Leighly 1999; Mathur 2000; Komossa et al., 2006a ,b Gallo 2007 .",arxiv,bigscience bloomz,704.2074,0.5555555555555556,0.4453781512605043,0.7487179487179487,0.6531294792164358,1,1,0,0,0,1,1,1,0,1,0.0605813937074157,0.07939163814163973,0.07392996108949416,0.06818181818181818,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
ARCRAIDER I: Detailed optical and X-ray analysis of the cooling flow cluster Z3146,"  We present a detailed analysis of the medium redshift (z=0.2906) galaxy
cluster Z3146 which is part of the ongoing ARCRAIDER project, a systematic
search for gravitational arcs in massive clusters of galaxies. The analysis of
Z3146 is based on deep optical wide field observations in the B, V and R bands
obtained with the WFI@ESO2.2m, and shallow archival WFPC2@HST taken with the
F606W filter, which are used for strong as well as weak lensing analyses.
Additionally we have used publicly available XMM/Newton observations for a
detailed X-ray analysis of Z3146. Both methods, lensing and X-ray, were used to
determine the dynamical state and to estimate the total mass. We also
identified four gravitational arc candidates. We find this cluster to be in a
relaxed state, which is confirmed by a large cooling flow with nominal
~1600M_\odot per year, regular galaxy density and light distributions and a
regular shape of the weak lensing mass reconstruction. The mass content derived
with the different methods agrees well within 25% at r_{200}=1661
h_{70}^{-1}kpc indicating a velocity dispersion of
\sigma_v=869^{+124}_{-153}km/s.
","We present an in-depth study of the galaxy cluster Z3146, which is one of the most luminous clusters in X-rays known to date (Lx = 1.5 x 1045 erg/s). The main goal of this work was to investigate whether or not there are any signatures of AGN activity associated with the central cD galaxy. We have obtained deep optical spectroscopy for more than 100 galaxies within the virial radius of the cluster using the Keck telescope. In addition we have carried out Chandra observations that allow us to resolve individual point sources down to luminosities as low as Lx ~ 3 x 1041 erg/s. Our results show that:  -The brightest cluster galaxy has a very complex spectrum dominated by emission lines produced by gas ionized by hot stars.  -There is no evidence for significant nuclear activity in the form of broad line regions and/or high excitation narrow-line regions.  -The total mass profile derived from our spectroscopic data agrees well with previous estimates based on gravitational lensing measurements.",arxiv,bigscience bloomz,705.4053,0.3333333333333333,0.29411764705882354,0.26666666666666666,0.43239369326325855,1,1,0,0,0,1,1,1,0,0,0.14315041952683008,0.033468147282482034,0.13618677042801555,0.011363636363636364,1,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Chi2 and chi3 harmonic generation at a critical power in inhomogeneous doubly resonant cavities,"  We derive general conditions for 100 percent frequency conversion in any
doubly resonant nonlinear cavity, for both second- and third-harmonic
generation via chi2 and chi3 nonlinearities. We find that conversion efficiency
is optimized for a certain critical power depending on the cavity parameters,
and assuming reasonable parameters we predict 100 percent conversion using
milliwatts of power or less. These results follow from a semi-analytical
coupled-mode theory framework which is generalized from previous work to
include both chi2 and chi3 media as well as inhomogeneous (fully vectorial)
cavities, analyzed in the high-efficiency limit where down-conversion processes
lead to a maximum efficiency at the critical power, and which is verified by
direct finite-difference time-domain (FDTD) simulations of the nonlinear
Maxwell equations. Explicit formulas for the nonlinear coupling coefficients
are derived in terms of the linear cavity eigenmodes, which can be used to
design and evaluate cavities in arbitrary geometries.
","We study the second-harmonic (SH) and third-harmonic (TH) generations in an inhomogeneously broadened cavity with two different resonance frequencies for fundamental wave (FW). We show that, when the intracavity FW intensity reaches its maximum value, both SHG and THG can be enhanced simultaneously by increasing the pumping rate or decreasing the detuning between the two modes. The enhancement is due to the fact that the nonlinear susceptibility becomes larger than zero at this point. This effect has been observed experimentally recently. 
 
 In addition, we find that there exists another regime where only one type of harmonics can be generated efficiently while suppressing other types of harmonics. For example, if the intracavity FW field is tuned close to the lower mode frequency, then it will generate mainly SH light but very little TH light; on the contrary, if the intracavty FW field is tuned near the upper mode frequency, then it generates mainly TH light but almost no SH light.",arxiv,bigscience bloomz,705.3652,0.16666666666666666,0.24369747899159663,0.12307692307692308,0.4094601051122791,1,1,0,0,0,1,1,1,0,0,0.15720227090414604,0.1365403318714903,0.14785992217898833,0.10606060606060606,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Observation of Electron-Hole Puddles in Graphene Using a Scanning Single Electron Transistor,"  The electronic density of states of graphene is equivalent to that of
relativistic electrons. In the absence of disorder or external doping the Fermi
energy lies at the Dirac point where the density of states vanishes. Although
transport measurements at high carrier densities indicate rather high
mobilities, many questions pertaining to disorder remain unanswered. In
particular, it has been argued theoretically, that when the average carrier
density is zero, the inescapable presence of disorder will lead to electron and
hole puddles with equal probability. In this work, we use a scanning single
electron transistor to image the carrier density landscape of graphene in the
vicinity of the neutrality point. Our results clearly show the electron-hole
puddles expected theoretically. In addition, our measurement technique enables
to determine locally the density of states in graphene. In contrast to
previously studied massive two dimensional electron systems, the kinetic
contribution to the density of states accounts quantitatively for the measured
signal. Our results suggests that exchange and correlation effects are either
weak or have canceling contributions.
","We report the observation of electron-hole puddles in graphene using scanning single-electron transistors (SETs). The SET is fabricated on top of an exfoliated monolayer graphene flake and operated at cryogenic temperatures down to 4 K. We observe that the conductance through the SET depends strongly on its position with respect to the underlying graphene sheet, which we attribute to local variations in charge carrier density induced by charged impurities trapped between the substrate and the graphene layer. This effect can be suppressed by applying a gate voltage Vg = -40 V across the graphene sample. Our results demonstrate that the use of SETs as probes for studying electronic properties of two-dimensional materials such as graphene has great potential. In recent years there have been significant advances in the fabrication of devices based on carbon nanotubes [1] , silicon nanowires [2] or semiconductor quantum dots [3] . These nanostructures are used as active elements in various types of sensors [4] , optoelectronic [5] and photovoltaic [6] applications. However, these structures suffer from several drawbacks including poor reproducibility due to their small size and low yield during growth processes [7, 8] .
In contrast, graphene [9] offers many advantages over other two dimensional materials [10] : it is mechanically flexible [11] , chemically stable [12] , biocompatible [13] and electrically conductive [14] . Moreover, it can be produced in large quantities via chemical vapor deposition [15] or mechanical exfoliation [16] techniques [17] . Recently, graphene-based field-effect transistors [18] were demonstrated [19, 20] opening up new avenues towards high-performance electronics [21] . Despite all these attractive features, however, one major challenge remains in achieving high-quality electrical contacts to graphene [22] .",arxiv,bigscience bloomz,705.218,0.4444444444444444,0.49579831932773116,0.2512820512820513,0.7505972288580984,0,1,0,0,0,1,1,1,0,0,0.06684746796730005,0.11150282095486108,0.06614785992217899,0.16666666666666666,1,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Fundamental Parameters of He-Weak and He-Strong Stars,"  We carried out low resolution spectroscopic observations in the wavelength
range 3400-4700 A of 20 He-weak and 8 He-strong stars to determine their
fundamental parameters by means of the Divan-Chalonge-Barbier (BCD)
spectrophotometric system. For a few He-weak stars we also estimate the
effective temperatures and the angular diameters by integrating absolute fluxes
observed over a wide spectral range. Non-LTE model calculations are carried out
to study the influence of the He/H abundance ratio on the emergent radiation of
He-strong stars and on their Teff determination. We find that the effective
temperatures, surface gravities and bolometric absolute magnitudes of He-weak
stars estimated with the BCD system and the integrated flux method are in good
agreement between each other, and they also agree with previous determinations
based on several different methods. The mean discrepancy between the visual
absolute magnitudes derived using the Hipparcos parallaxes and the BCD values
is on average 0.3 mag for He-weak stars, while it is 0.5 mag for He-strong
stars. For He-strong stars, we note that the BCD calibration, based on stars in
the solar environment, leads to overestimated values of Teff. By means of model
atmosphere calculations with enhanced He/H abundance ratios we show that larger
He/H ratios produce smaller BD which naturally explains the Teff
overestimation. We take advantage of these calculations to introduce a method
to estimate the He/H abundance ratio in He-strong stars. The BD of HD 37479
suggests that the Teff of this star remains fairly constant as the star
spectrum undergoes changes in the intensity of H and He absorption lines. Data
for the He-strong star HD 66765 are reported for the first time.
","We present the results of our study on fundamental parameters of helium-weak (He-W) stars, which are evolved red giants with helium abundance Y=0.25-0.40 in their envelopes.  We have calculated evolutionary tracks for these stars using the Yale Rotating Evolution Code including diffusion processes as well as nuclear reactions relevant to stellar evolution up to carbon burning stage. The mass loss rates were taken into account by adopting Reimers formula. In order to investigate the effect of rotation on the structure and evolution of He-W stars we performed calculations for different initial rotational velocities ranging from 0 to 300 km/sec. 
The comparison between theoretical predictions and observations shows that there is no agreement between theory and observation if one adopts standard values of mixing length parameter $\alpha$ = 1.9-2.1. However, it was found that the best fit can be obtained when the value of $\alpha$ is reduced down to $1.5 \pm 0.1$.",arxiv,bigscience bloomz,705.0541,0.5,0.24369747899159663,0.764102564102564,0.38652651696129964,1,1,0,0,0,1,1,0,0,0,0.08302711544408052,0.055653779630928935,0.07392996108949416,0.056818181818181816,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
The habitability of super-Earths in Gliese 581,"  Aims: The planetary system around the M star Gliese 581 consists of a hot
Neptune (Gl 581b) and two super-Earths (Gl 581c and Gl 581d). The habitability
of this system with respect to the super-Earths is investigated following a
concept that studies the long-term possibility of photosynthetic biomass
production on a dynamically active planet. Methods: A thermal evolution model
for a super-Earth is used to calculate the sources and sinks of atmospheric
carbon dioxide. The habitable zone is determined by the limits of biological
productivity on the planetary surface. Models with different ratios of land /
ocean coverage are investigated. Results: The super-Earth Gl 581c is clearly
outside the habitable zone, since it is too close to the star. In contrast, Gl
581d is a tidally locked habitable super-Earth near the outer edge of the
habitable zone. Despite the adverse conditions on this planet, at least some
primitive forms of life may be able to exist on its surface.Therefore, Gl 581d
is an interesting target for the planned TPF/Darwin missions to search for
biomarkers in planetary atmospheres.
","We present the results of our study on the possible existence and stability of terrestrial planets around the star Gliese 581, which is located at about 20 light-years away from Earth. We have performed numerical simulations for different orbital configurations of three hypothetical terrestrial planets with masses ranging between 1 to 10 times that of Earth's mass (1-10 M⊕). Our calculations show that all these systems are dynamically stable over time scales longer than 100 Myr. The most massive planet has an eccentric orbit with e=0.2 and its periastron distance ranges between 0.05 AU and 0.15 AU depending on the initial conditions used. This planet can be considered as a hot Jupiter-like planet because it orbits very close to its host star. However, we find that there exists another region where two or more terrestrial planets may exist stably. In this region, one of them could be a super-Earth-type planet with a mass larger than 5M⊕ but smaller than 8M⊕.",arxiv,bigscience bloomz,705.3758,0.3888888888888889,0.29411764705882354,0.27692307692307694,0.4123268036311515,1,1,1,0,0,1,1,0,0,1,0.08860257661633074,0.04743333567629818,0.08949416342412451,0.03787878787878788,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Control of mechanical systems on Lie groups and ideal hydrodynamics,"  In contrast to the Euler-Poincar{\'e} reduction of geodesic flows of left- or
right-invariant metrics on Lie groups to the corresponding Lie algebra (or its
dual), one can consider the reduction of the geodesic flows to the group
itself. The reduced vector field has a remarkable hydrodynamic interpretation:
it is a velocity field for a stationary flow of an ideal fluid. Right- or
left-invariant symmetry fields of the reduced field define vortex manifolds for
such flows.
  Consider now a mechanical system, whose configuration space is a Lie group
and whose Lagrangian is invariant to left translations on that group, and
assume that the mass geometry of the system may change under the action of
internal control forces. Such system can also be reduced to the Lie group. With
no controls, this mechanical system describes a geodesic flow of the
left-invariant metric, given by the Lagrangian, and thus its reduced flow is a
stationary ideal fluid flow on the Lie group. The standard control problem for
such system is to find the conditions, under which the system can be brought
from any initial position in the configuration space to another preassigned
position by changing its mass geometry. We show that under these conditions, by
changing the mass geometry, one can also bring one vortex manifold to any other
preassigned vortex manifold.
","We consider the controllability properties for linearized models of mechanical systems evolving on Lie groups, with particular emphasis on the case where the configuration space is the group of rigid motions in three dimensions. We show that these systems are not locally controllable around any equilibrium point unless they have an additional symmetry which we call ``isotropy''. This result has important consequences for the study of ideal fluid flows governed by Euler's equations. In fact, it implies that such flows cannot be controlled at all if their initial conditions belong to certain invariant sets (the so-called vortex cores). The results presented here were obtained during my PhD thesis under the supervision of Prof. Miroslav Krstic at ETH Zurich. I would like to thank him as well as Dr. David J. Simoes for many useful discussions about this work. Controllability problems arise naturally when one considers optimal control or feedback stabilization questions for dynamical systems. For example, given some desired state trajectory $x_d(t)$, one may ask whether there exists a control input $u(t)$ steering the system from its current state $x$ towards the target trajectory $x_d(t), \forall t\in [0,T]$ within finite time $T$. 
 
 In general, the answer to this question depends strongly on the choice of the cost functional used to measure the distance between trajectories. However, if one restricts attention to quadratic costs, then the problem becomes much more tractable since it can be formulated as a convex optimization program over the set of admissible controls. Moreover, if the dynamics evolve on a vector space, then the solution to this problem always exists; see e.g., [1] . Unfortunately, things become considerably more complicated if the underlying state space is a manifold instead; see [2] , [3, Chapter 4] 
 
 [4]-[6] . Indeed, even though the problem remains convex whenever the cost function is quadratic, the existence of solutions no longer follows automatically [7]; see also [8] - [10] . 
 
 In recent years, several authors have studied the controllability properties of various classes of nonlinear systems evolving on manifolds using",arxiv,bigscience bloomz,704.2886,0.3888888888888889,0.6470588235294118,0.49230769230769234,0.9225991399904443,1,1,1,0,1,1,1,1,0,1,0.11795094172825271,0.1015323789187002,0.12840466926070038,0.16666666666666666,0,0,4,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
"Generalized Twistor Transform And Dualities, With A New Description of Particles With Spin, Beyond Free and Massless","  A generalized twistor transform for spinning particles in 3+1 dimensions is
constructed that beautifully unifies many types of spinning systems by mapping
them to the same twistor, thus predicting an infinite set of duality relations
among spinning systems with different Hamiltonians. Usual 1T-physics is not
equipped to explain the duality relationships and unification between these
systems. We use 2T-physics in 4+2 dimensions to uncover new properties of
twistors, and expect that our approach will prove to be useful for practical
applications as well as for a deeper understanding of fundamental physics.
Unexpected structures for a new description of spinning particles emerge. A
unifying symmetry SU(2,3) that includes conformal symmetry SU(2,2)=SO(4,2) in
the massless case, turns out to be a fundamental property underlying the
dualities of a large set of spinning systems, including those that occur in
high spin theories. This may lead to new forms of string theory backgrounds as
well as to new methods for studying various corners of M theory. In this paper
we present the main concepts, and in a companion paper we give other details.
","The generalized twistor transform is an extension of the ordinary twistor transform to include particles with spin in arbitrary dimensions. It has been used recently for describing scattering amplitudes involving massive particles as well as massless ones. In this talk I will present some new results on the subject including a description of how one can use it to describe particles beyond free or massless theories. The talk will also cover recent developments related to dualities between different quantum field theories. This includes duality relations that have been found using the generalized twistor transform such as those relating N=4 super Yang-Mills theory to self-dual gravity and its supersymmetric extensions. Finally we will discuss how these ideas are connected to string theory. Generalized twistors were introduced by Witten more than twenty years ago [1] . They provide a powerful tool for studying gauge theories in general relativity [2] , and they play important roles in understanding various aspects of string/M-theory [3] .
In particular, the so-called Penrose limit [4] provides a way to relate scattering amplitudes in gauge/gravity theories at weak coupling to correlation functions in conformal field theories (CFTs) at strong coupling [5] . Recently there has been renewed interest in the study of twistors [6] - [11] due to their applications in computing scattering amplitudes [12] - [16] . For example, the tree-level S-matrix elements of gluons [17] and gravitons [18] in four-dimensional N = 4 Super-Yang-Mills theory (SYM), which was conjectured to be dual to type-IIB superstrings [19] , were computed via the generalized twistor transform [20] .",arxiv,bigscience bloomz,704.0296,0.3333333333333333,0.49579831932773116,0.28717948717948716,0.6989966555183947,1,1,0,0,0,1,1,0,0,0,0.13442077885620532,0.09823444366904469,0.1556420233463035,0.05303030303030303,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Multiple Parton Scattering in Nuclei: Quark-quark Scattering,"  Modifications to quark and antiquark fragmentation functions due to
quark-quark (antiquark) double scattering in nuclear medium are studied
systematically up to order \cal{O}(\alpha_{s}^2)$ in deeply inelastic
scattering (DIS) off nuclear targets. At the order $\cal{O}(\alpha_s^2)$,
twist-four contributions from quark-quark (antiquark) rescattering also exhibit
the Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon
bremsstrahlung induced by multiple parton scattering. Compared to quark-gluon
scattering, the modification, which is dominated by $t$-channel quark-quark
(antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the
ratio of quark and gluon distributions in the medium. Such a modification is
not negligible for realistic kinematics and finite medium size. The
modifications to quark (antiquark) fragmentation functions from quark-antiquark
annihilation processes are shown to be determined by the antiquark (quark)
distribution density in the medium. The asymmetry in quark and antiquark
distributions in nuclei will lead to different modifications of quark and
antiquark fragmentation functions inside a nucleus, which qualitatively
explains the experimentally observed flavor dependence of the leading hadron
suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark
annihilation processes also mix quark and gluon fragmentation functions in the
large fractional momentum region, leading to a flavor dependence of jet
quenching in heavy-ion collisions.
","We present the first calculation of quark-quark scattering at next-to-leading order (NLO) accuracy within the framework of multiple parton scattering (MPI). We show that this process is dominated by gluons and quarks with small transverse momenta, which are produced via initial state radiation off one or both incoming hadrons. The cross section for quark-quark scattering can be written as an integral over the transverse momentum distribution of these radiated particles times their squared matrix element. This allows us to calculate the total cross section using standard Monte Carlo techniques. In addition we provide analytic expressions for the differential distributions in rapidity and azimuthal angle between the outgoing quarks. Our results agree well with those obtained numerically. Finally, we discuss how our formalism could be used to study MPI effects on jet production in proton-nucleus collisions. PACS numbers: 12.38.Qk, 13 .60.Le",arxiv,bigscience bloomz,704.0106,0.3333333333333333,0.3445378151260504,0.38461538461538464,0.35499283325370284,1,1,0,0,0,1,1,1,0,0,0.1043038235687025,0.06612028707057377,0.11673151750972763,0.03787878787878788,0,2,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Cosmological Shock Waves in the Large Scale Structure of the Universe: Non-gravitational Effects,"  Cosmological shock waves result from supersonic flow motions induced by
hierarchical clustering of nonlinear structures in the universe. These shocks
govern the nature of cosmic plasma through thermalization of gas and
acceleration of nonthermal, cosmic-ray (CR) particles. We study the statistics
and energetics of shocks formed in cosmological simulations of a concordance
$\Lambda$CDM universe, with a special emphasis on the effects of
non-gravitational processes such as radiative cooling, photoionization/heating,
and galactic superwind feedbacks. Adopting an improved model for gas
thermalization and CR acceleration efficiencies based on nonlinear diffusive
shock acceleration calculations, we then estimate the gas thermal energy and
the CR energy dissipated at shocks through the history of the universe. Since
shocks can serve as sites for generation of vorticity, we also examine the
vorticity that should have been generated mostly at curved shocks in
cosmological simulations. We find that the dynamics and energetics of shocks
are governed primarily by the gravity of matter, so other non-gravitational
processes do not affect significantly the global energy dissipation and
vorticity generation at cosmological shocks. Our results reinforce scenarios in
which the intracluster medium and warm-hot intergalactic medium contain
energetically significant populations of nonthermal particles and turbulent
flow motions.
","We present an analysis of cosmological shock waves in the large scale structure (LSS) of the universe, which are generated by gravitational collapse and merging processes between dark matter haloes. We show that these shocks can be detected as discontinuities in the density field traced by galaxy clusters using weak lensing observations. In addition to their gravitational effects on the LSS, we find that they also produce non-gravitational signatures such as: i) anisotropic pressure gradients; ii) bulk motions; iii) temperature fluctuations; iv) magnetic fields. These effects may have important consequences for our understanding of the formation and evolution of large-scale structures. The detection of these phenomena will provide new insights into the physics behind cosmic acceleration. 
 
 Keywords: Cosmology, Cosmic Acceleration, Dark Matter Halos, Weak Gravitational Lensing, Galaxy Clusters 
 
 
 
 1 Introduction 
 
 Recent observational data suggest that the expansion history of the Universe is accelerating at late times [1–3] . This phenomenon has been explained within the framework of general relativity with the introduction of a mysterious component known as ""dark energy"" [4] , whose nature remains unknown today. However, it seems clear that this exotic form of energy must play some role in explaining the observed accelerated expansion of the universe [5–7] .
 
In order to understand how dark energy affects the dynamics of the universe, one needs to study its interaction with other components of the cosmos. One possible way to do so is through the use of numerical simulations [8–10] . Another possibility consists of studying the effect of dark energy on the growth rate of perturbations [11–13] . Finally, another approach involves analyzing the statistical properties of the distribution of galaxies [14–18] or galaxy clusters [19–21] .",arxiv,bigscience bloomz,704.1521,0.3333333333333333,0.546218487394958,0.37948717948717947,0.7534639273769709,1,1,0,0,0,1,1,1,0,0,0.0821801471737683,0.07055580441017607,0.07782101167315175,0.07575757575757576,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Signatures of Heavy Z-prime in the Extra U(1) Superstring Inspired Model: RGEs Analysis,"  In the extra U(1) superstring inspired model, we examine the electroweak and
U(1)-prime symmetry breaking with the singlet and exotic quark D, D+{\c}along
with the study of heavy Z-prime boson in accordance with the top quark mass
region. For this, we have done the analysis of complete renormalization group
equations (RGEs)pertaining to the anomaly free E-{\6}-Eta model of rank 5. The
Z-prime is found to the order of TeV or above with allowed small Z-Zprime
mixing angle, for which the large singlet VEV is required. This is done by
considering the only non-universality of Yukawa couplings at GUT scale because
these do not obey the E-{\6}relationship and also satisfies the unitarity
constraints both at GUT and weak scale, where rest of the parameters, i.e.,
gaugino masses, tri-linear couplings, and soft supersymmetric breaking masses
are kept universal at GUT scale with the gauge couplings unification. The large
value of Yukawa couplings (order of 1) triggered the symmetry breaking
radiatively and induces the effective-Mu parameter at the electroweak scale and
lead to a viable low energy spectrum at weak scale.
","In this work, we study the renormalization group equations (RGEs) for extra U(1) supersymmetric string inspired model with heavy Z' prime and its effects on gauge coupling unification at one-loop level. We find that the inclusion of new particles such as vector-like quarks and leptons can significantly affect the running behavior of gauge couplings. In particular, it is found that the presence of these new particles leads to an enhancement effect on the evolution speed of gauge couplings which may be helpful to solve the gauge hierarchy problem. Furthermore, by using the experimental data of low energy physics, we obtain some constraints on the mass spectrum of extra particles involved in our model. Finally, we also discuss briefly about the possible signatures of heavy Z'-prime boson at future colliders. The results are summarized below. 
I. INTRODUCTORY REMARK
The Standard Model (SM), based on SU(3) C ×SU(2) L ×U(1) Y gauge symmetry, has been very successful in describing all known phenomena upto TeV scale energies [1] . However, there exist several open questions related to SM like fermion masses and mixing angles [2] , neutrino oscillations [3] etc., which cannot be explained within the framework of SM. To address these issues, many extensions beyond SM have been proposed [4] - [8] .
Among them, Grand Unified Theory (GUTs) [9] provides a natural solution to the above mentioned problems [10] . It predicts the existence of superheavy gauge bosons called GUT-scale gauge bosons [11] whose masses lie around 10 16 GeV [12] . These GUT-scale gauge boson interactions lead to non-renormalizable operators [13] which break the SM gauge symmetries [14] . Therefore, they should not appear in any physical process [15] . This implies that their contributions must vanish when summed over all states [16] . Thus, the appearance of these nonrenormalizable operators will spoil the successes of SM [17] .",arxiv,bigscience bloomz,705.2532,0.2222222222222222,0.7478991596638657,0.28205128205128205,0.8394648829431438,1,1,0,0,0,1,1,0,0,1,0.14887329826244616,0.09879741375753846,0.16342412451361868,0.15151515151515152,0,2,3,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SNO+: predictions from standard solar models and spin flavour precession,"  Time variability of the solar neutrino flux especially in the low and
intermediate energy sector remains an open question and, if it exists, it is
likely to be originated from the magnetic moment transition from active to
light sterile neutrinos at times of intense solar activity and magnetic field.
We examine the prospects for the SNO+ experiment to address this important
issue and to distinguish between the two classes of solar models which are
currently identified as corresponding to a high (SSM I) and a low (SSM II)
heavy element abundance. We also evaluate the predictions from these two models
for the Chlorine experiment event rate in the standard LMA and LMA+Spin Flavour
Precession (SFP) scenarios. It is found that after three years of SNO+ data
taking, the pep flux measurement will be able to discriminate between the
standard LMA and LMA+SFP scenarios, independently of which is the correct solar
model. If the LMA rate is measured, SFP with $B_0 \sim 280kG$ for the resonant
$\Delta m^2_{01}$ can be excluded at more than $4\sigma$. A low rate would
signal new physics, excluding all the 90% allowed range of the standard LMA
solution at 3$\sigma$, and a time variability would be a strong signature of
the SFP model. The CNO fluxes are the ones for which the two SSM predictions
exhibit the largest differences, so their measurement at SNO+ will be important
to favour one or the other. The distinction will be clearer after LMA or SFP
are confirmed with pep, but still, a CNO measurement at the level of SSM I/LMA
will disfavour SSM II at about $3 \sigma$. We conclude that consistency between
future pep and CNO flux measurements at SNO+ and Chlorine would either favour
an LMA+SFP scenario or favour SSM II over SSM I.
","The SNO+ experiment is designed to measure the neutrino fluxes in the energy range between 1 MeV and 20 MeV, with an expected sensitivity at low energies comparable to that achieved by Super-Kamiokande (SK). The measurement will be performed using two detection techniques: charged-current interactions on deuterium nuclei via elastic scattering off electrons; neutral current reactions on carbon nuclei through coherent elastic scattering off neutrons. 
 
 In this work we present results for the predicted rates of these processes as well as their uncertainties based on state-of-the-art Standard Solar Models (SSMs) and nuclear cross sections. We also discuss how the experimental data can help to constrain SSM parameters such as the helium abundance YHe or the heavy element abundances Z/X. Finally, we show how the combination of different experiments may allow us to test whether the observed neutrinos are produced mainly in pp-chain fusion reactions or in CNO cycles.",arxiv,bigscience bloomz,705.407,0.4444444444444444,0.19327731092436976,0.8923076923076924,0.3779264214046823,1,0,0,0,0,1,1,1,0,0,0.07271532514472212,0.03061844232797982,0.07392996108949416,0.007575757575757576,0,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Production of a sterile species: quantum kinetics,"  Production of a sterile species is studied within an effective model of
active-sterile neutrino mixing in a medium in thermal equilibrium. The quantum
kinetic equations for the distribution functions and coherences are obtained
from two independent methods: the effective action and the quantum master
equation. The decoherence time scale for active-sterile oscillations is
$\tau_{dec} = 2/\Gamma_{aa}$, but the evolution of the distribution functions
is determined by the two different time scales associated with the damping
rates of the quasiparticle modes in the medium: $\Gamma_1=\Gamma_{aa}\cos^2\tm
; \Gamma_2=\Gamma_{aa}\sin^2\tm$ where $\Gamma_{aa}$ is the interaction rate of
the active species in absence of mixing and $\tm$ the mixing angle in the
medium. These two time scales are widely different away from MSW resonances and
preclude the kinetic description of active-sterile production in terms of a
simple rate equation. We give the complete set of quantum kinetic equations for
the active and sterile populations and coherences and discuss in detail the
various approximations. A generalization of the active-sterile transition
probability \emph{in a medium} is provided via the quantum master equation. We
derive explicitly the usual quantum kinetic equations in terms of the
``polarization vector'' and show their equivalence to those obtained from the
quantum master equation and effective action.
","We study the production of a sterile species in an open system with two stable particles and one unstable particle, where the decay products are not observed.  We show that if the initial state is pure then there exists no final mixed state which can be reached by unitary evolution. This result implies that the production of a sterility cannot occur under any circumstances for such systems. If we allow the possibility to prepare arbitrary states as input, however, it turns out that the production of a certain kind of sterility may still take place. In this case, the output state will always contain some amount of entanglement between the subsystems corresponding to the different types of particles involved. The results presented here have been obtained within the framework of Quantum Kinetic Theory (QKT). QKT provides a description of non-equilibrium phenomena at mesoscopic scales based on the concept of entropy production rate. It has recently attracted considerable attention due to its potential applications in many areas ranging from physics to biology. 
I. INTRODUCTORY REMARK
The phenomenon of spontaneous emission plays a crucial role in modern physics. For example, it is responsible for the cooling process in laser-cooling experiments [1] . On the other hand, spontaneous emission also leads to decoherence effects [2] , which limit the performance of quantum information processing devices [3] .
In recent years, several authors [4] - [8] studied the problem of producing a particular type of ""sterility"" in open quantum systems. A state is called ""sterile"" when it does not interact with itself or another given set of states [9] . More specifically, let us consider a bipartite Hilbert space H = H 1 ⊗H 2 , where dim(H i ) = N i . Then, a density matrix ρ ∈ B(H) is said to be ""sterile"" wrt. a subset S ⊆ H iff Tr[ρσ] = 0 for all σ ∈ S. Here, Tr denotes the trace operation over either H 1 or H 2 depending on whether σ belongs to H 1 or H 2 respectively. Note that the notion of ""ster",arxiv,bigscience bloomz,705.0703,0.3333333333333333,0.8487394957983193,0.4153846153846154,0.9512661251791686,0,1,1,0,1,1,1,0,0,0,0.2232367475259185,0.07763211608808762,0.2529182879377432,0.125,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Dimer Models, Free Fermions and Super Quantum Mechanics","  This note relates topics in statistical mechanics, graph theory and
combinatorics, lattice quantum field theory, super quantum mechanics and string
theory. We give a precise relation between the dimer model on a graph embedded
on a torus and the massless free Majorana fermion living on the same lattice. A
loop expansion of the fermion determinant is performed, where the loops turn
out to be compositions of two perfect matchings. These loop states are sorted
into co-chain groups using categorification techniques similar to the ones used
for categorifying knot polynomials. The Euler characteristic of the resulting
co-chain complex recovers the Newton polynomial of the dimer model. We
re-interpret this system as supersymmetric quantum mechanics, where
configurations with vanishing net winding number form the ground states.
Finally, we make use of the quiver gauge theory - dimer model correspondence to
obtain an interpretation of the loops in terms of the physics of D-branes
probing a toric Calabi-Yau singularity.
","We present the results on the super quantum mechanics (SQM) in dimer models with free fermion boundary conditions. We show that SQM is equivalent to the usual quantum mechanics for periodic boundary condition case. In addition we find that there are two different types of supersymmetric ground states depending on whether or not the number of particles N is even. For odd N , the ground state has zero energy but it does not have any degeneracy. On the other hand, when N is even, the ground state becomes doubly degenerate. The degeneracy can be understood by using the concept of parity symmetry breaking. Finally we discuss how our result fits into the general framework of supersymmetry. PACS: 11.10.Wx, 05.45.Mt, 11.15.Tk 
I. INTRODUCTORY REMARK
In this work we study the super quantum mechanics ( S Q M ) i n d im e r m odels w ith f ree fermi b oundary c o ndition s . T hese models were first introduced by Rokhsar et al [1] as an exactly solvable model which describes spin-1/2 Heisenberg antiferromagnet on a square lattice. They showed that these models exhibit many interesting properties such as spontaneous dimerization at low temperatures [2] .
The main purpose of this work is to investigate the effect of boundary conditions on the supersymmetric structure of the system. It turns out that the supersymmetric structure depends crucially on the boundary conditions imposed on the system. As will become clear later, the supersymmetric structure changes drastically if one switches between periodic and free-fermion boundary conditions.",arxiv,bigscience bloomz,705.1645,0.3333333333333333,0.6470588235294118,0.16923076923076924,0.6932632584806498,0,1,0,0,0,1,1,1,0,0,0.04953214040248181,0.05380796055340653,0.05058365758754864,0.08712121212121213,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
A High-Throughput Cross-Layer Scheme for Distributed Wireless Ad Hoc Networks,"  In wireless ad hoc networks, distributed nodes can collaboratively form an
antenna array for long-distance communications to achieve high energy
efficiency. In recent work, Ochiai, et al., have shown that such collaborative
beamforming can achieve a statistically nice beampattern with a narrow main
lobe and low sidelobes. However, the process of collaboration introduces
significant delay, since all collaborating nodes need access to the same
information. In this paper, a technique that significantly reduces the
collaboration overhead is proposed. It consists of two phases. In the first
phase, nodes transmit locally in a random access fashion. Collisions, when they
occur, are viewed as linear mixtures of the collided packets. In the second
phase, a set of cooperating nodes acts as a distributed antenna system and
beamform the received analog waveform to one or more faraway destinations. This
step requires multiplication of the received analog waveform by a complex
number, which is independently computed by each cooperating node, and which
enables separation of the collided packets based on their final destination.
The scheme requires that each node has global knowledge of the network
coordinates. The proposed scheme can achieve high throughput, which in certain
cases exceeds one.
","In this work, we propose a novel cross-layer scheme to improve the performance of distributed wireless ad hoc networks (DWAHNs). The proposed scheme is based on an adaptive routing protocol and a dynamic channel allocation algorithm. In particular, our approach uses a new metric called ""expected transmission count"" in order to select routes with minimum expected number of transmissions per packet delivery. Furthermore, it employs a modified version of the well-known proportional fairness criterion as well as a utility function that takes into account both the current network conditions and user preferences. Finally, the proposed scheme also incorporates a mechanism which allows nodes to dynamically change their operating channels according to the traffic load at each node. Extensive simulation experiments are conducted using NS-2 simulator to evaluate the effectiveness of the proposed scheme under different scenarios. Results show that the proposed scheme outperforms existing approaches by achieving higher throughput while maintaining low end-to-end delay and packet loss rate.",arxiv,bigscience bloomz,704.2841,0.5555555555555556,0.29411764705882354,0.36923076923076925,0.40659340659340665,0,1,0,0,0,1,1,0,0,0,0.08291514355841445,0.03982578410546391,0.08949416342412451,0.03409090909090909,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Galois theory of iterated endomorphisms,"  Given an abelian algebraic group $A$ over a global field $F$, $\alpha \in
A(F)$, and a prime $\ell$, the set of all preimages of $\alpha$ under some
iterate of $[\ell]$ generates an extension of $F$ that contains all
$\ell$-power torsion points as well as a Kummer-type extension. We analyze the
Galois group of this extension, and for several classes of $A$ we give a simple
characterization of when the Galois group is as large as possible up to
constraints imposed by the endomorphism ring or the Weil pairing. This Galois
group encodes information about the density of primes $\p$ in the ring of
integers of $F$ such that the order of $(\alpha \bmod{\p})$ is prime to $\ell$.
We compute this density in the general case for several classes of $A$,
including elliptic curves and one-dimensional tori. For example, if $F$ is a
number field, $A/F$ is an elliptic curve with surjective 2-adic representation
and $\alpha \in A(F)$ with $\alpha \not\in 2A(F(A[4]))$, then the density of
$\mathfrak{p}$ with ($\alpha \bmod{\p}$) having odd order is 11/21.
","The Galois group is the fundamental object in classical Galois theory, which studies the solvability of polynomial equations over finite fields.  In this talk we will introduce the notion of ``Galois groups'' for infinite families of polynomials and study their properties using tools from algebraic geometry.   We will also discuss some applications to number theory such as the proof of the abc conjecture by Vojta (joint work with J. Pila). The main results are joint works with A. Chambert-Loir, D. Ghioca, M. Harris, C. Lairez, S. Popescu-Tarauca, B. Stoll, E. Szpiro, T. Tucker-Drob, and V. Vojta. This talk was given at the conference ""Algebraic Geometry and Arithmetic Dynamics"" held on June 24-28, 2013 at MSRI Berkeley. It has been recorded by Adam Hartung.",arxiv,bigscience bloomz,706.2384,0.2222222222222222,0.24369747899159663,0.26153846153846155,0.3062589584328715,1,1,0,0,0,1,1,0,0,1,0.18765516346331013,0.06884757352044817,0.19844357976653695,0.045454545454545456,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Design of Parallel Kinematic Machine Tools Using Kinetostatic Performance Criteria,"  Most industrial machine tools have a serial kinematic architecture, which
means that each axis has to carry the following one, including its actuators
and joints. High Speed Machining highlights some drawbacks of such
architectures: heavy moving parts require from the machine structure high
stiffness to limit bending problems that lower the machine accuracy, and limit
the dynamic performances of the feed axes. That is why PKMs attract more and
more researchers and companies, because they are claimed to offer several
advantages over their serial counterparts, like high structural rigidity and
high dynamic capacities. Indeed, the parallel kinematic arrangement of the
links provides higher stiffness and lower moving masses that reduce inertia
effects. Thus, PKMs have better dynamic performances. However, the design of a
parallel kinematic machine tool (PKMT) is a hard task that requires further
research studies before wide industrial use can be expected. Many criteria need
to be taken into account in the design of a PKMT. We pay special attention to
the description of kinetostatic criteria that rely on the conditioning of the
Jacobian matrix of the mechanism. The organisation of this paper is as follows:
next section introduces general remarks about PKMs, then is explained why PKMs
can be interesting alternative machine tool designs. Then are presented
existing PKMTs. An application to the design of a small-scale machine tool
prototype developed at IRCCyN is presented at the end of this paper.
","The design and kinematics analysis of parallel kinematic machine tools (PKMTs) is presented in this work using kinetic-static performance criteria. The proposed approach considers the dynamic behavior of PKMTs during their operation, which has been neglected by previous works on PKMTs. In addition to the static stiffness matrix, the inertia properties are also considered for the evaluation of the overall dynamic response of PKMTs. A new method based on the concept of virtual joints is developed to calculate the mass distribution along each leg of the PKMT under consideration. This information can be used as an input data set for further dynamic analyses such as modal or harmonic vibration analysis. Finally, two different PKMTs with three degrees-of-freedom per joint are designed and analyzed using the proposed methodology. It was found that the first PKMT exhibits better dynamic characteristics than its counterpart due to its lower natural frequencies and higher damping ratios.",arxiv,bigscience bloomz,705.1038,0.5555555555555556,0.29411764705882354,0.5692307692307692,0.38652651696129964,1,1,1,0,0,1,1,0,0,0,0.09694290303513321,0.015111884245178203,0.0933852140077821,0.007575757575757576,2,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
A new search for planet transits in NGC 6791,"  Context. Searching for planets in open clusters allows us to study the
effects of dynamical environment on planet formation and evolution.
  Aims. Considering the strong dependence of planet frequency on stellar
metallicity, we studied the metal rich old open cluster NGC 6791 and searched
for close-in planets using the transit technique.
  Methods. A ten-night observational campaign was performed using the
Canada-France-Hawaii Telescope (3.6m), the San Pedro M\'artir telescope (2.1m),
and the Loiano telescope (1.5m). To increase the transit detection probability
we also made use of the Bruntt et al. (2003) eight-nights observational
campaign. Adequate photometric precision for the detection of planetary
transits was achieved.
  Results. Should the frequency and properties of close-in planets in NGC 6791
be similar to those orbiting field stars of similar metallicity, then detailed
simulations foresee the presence of 2-3 transiting planets. Instead, we do not
confirm the transit candidates proposed by Bruntt et al. (2003). The
probability that the null detection is simply due to chance coincidence is
estimated to be 3%-10%, depending on the metallicity assumed for the cluster.
  Conclusions. Possible explanations of the null-detection of transits include:
(i) a lower frequency of close-in planets in star clusters; (ii) a smaller
planetary radius for planets orbiting super metal rich stars; or (iii)
limitations in the basic assumptions. More extensive photometry with 3-4m class
telescopes is required to allow conclusive inferences about the frequency of
planets in NGC 6791.
","We report on the detection and characterization of two transit-like events observed with Spitzer Space Telescope (Werner et al., 2004) at 3.6 microns, which we interpret as being due to planets orbiting an M-dwarf star located near the center of the open cluster NGC 6791.  The first event was detected during our initial survey of this field using the IRAC camera on board Spitzer between 2005 May 24 and 2006 January 1.   We subsequently obtained follow-up observations over three epochs spanning more than one year that allowed us to confirm its planetary nature by detecting it again in all four bands simultaneously.  This is only the second time such a confirmation has been made after the original discovery observation.  The second event was discovered serendipitously while searching for additional transiting objects around the same target star following up on the first event.  Both events are characterized by their short duration (∼3 hours), shallow depth (0.1%-0.2%), and relatively high impact parameter (b=0.7-1).  These properties suggest they may be Neptune-sized or smaller planets.  Follow-up radial velocity measurements will be required to determine whether these candidates are indeed bona fide exoplanets.",arxiv,bigscience bloomz,704.1668,0.8888888888888888,0.3445378151260504,0.5692307692307692,0.4925943621595796,1,1,1,0,1,1,1,0,0,0,0.13174733131330435,0.09484789350579496,0.17509727626459143,0.06818181818181818,7,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Stable oscillations of a predator-prey probabilistic cellular automaton: a mean-field approach,"  We analyze a probabilistic cellular automaton describing the dynamics of
coexistence of a predator-prey system. The individuals of each species are
localized over the sites of a lattice and the local stochastic updating rules
are inspired on the processes of the Lotka-Volterra model. Two levels of
mean-field approximations are set up. The simple approximation is equivalent to
an extended patch model, a simple metapopulation model with patches colonized
by prey, patches colonized by predators and empty patches. This approximation
is capable of describing the limited available space for species occupancy. The
pair approximation is moreover able to describe two types of coexistence of
prey and predators: one where population densities are constant in time and
another displaying self-sustained time-oscillations of the population
densities. The oscillations are associated with limit cycles and arise through
a Hopf bifurcation. They are stable against changes in the initial conditions
and, in this sense, they differ from the Lotka-Volterra cycles which depend on
initial conditions. In this respect, the present model is biologically more
realistic than the Lotka-Volterra model.
","We study the dynamics of a probabilistic cellular automaton (PCA) with two species, prey and predators, which interact in an oscillatory way. The PCA is defined on a square lattice where each site can be occupied by at most one particle of either type. We show that for certain values of the parameters there are stable periodic solutions to this system. These results are obtained using a mean field approximation method. In particular we find that the periodicity depends only on the number of particles per unit area. This dependence agrees well with numerical simulations performed on finite lattices. Finally, we discuss how our model could be used as a simple description of population cycles observed in nature. Probabilistic cellular automata have been widely studied during recent years due to their potential applications in many fields such as physics [1] , biology [2] or computer science [3] . They consist of a set of cells arranged in some regular structure like a grid [4] whose state evolves according to local rules depending on its own state and those of its neighbors [5] .
In this work we consider a two-dimensional probabilistic cellular automaton [6] consisting of N sites located on a square lattice L = Z 2 . Each cell i ∈ L has four possible states denoted by 0, 1, 2 and 3 corresponding respectively to empty space, prey, predator and dead. At time t = 0 all sites are initialized randomly with probability p 0 = 1/4 of being vacant, p 1 = 1/2 of having a prey and p 2 = 1/4 of containing a predator. Then, the evolution rule consists of applying simultaneously the following transition probabilities between consecutive times t and t + 1:",arxiv,bigscience bloomz,704.0512,0.4444444444444444,0.596638655462185,0.26153846153846155,0.7821309125656951,0,1,1,0,0,1,1,1,0,0,0.08203903443968243,0.07440877418694132,0.08171206225680934,0.045454545454545456,1,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Our Peculiar Motion Away from the Local Void,"  The peculiar velocity of the Local Group of galaxies manifested in the Cosmic
Microwave Background dipole is found to decompose into three dominant
components. The three components are clearly separated because they arise on
distinct spatial scales and are fortuitously almost orthogonal in their
influences. The nearest, which is distinguished by a velocity discontinuity at
~7 Mpc, arises from the evacuation of the Local Void. We lie in the Local Sheet
that bounds the void. Random motions within the Local Sheet are small. Our
Galaxy participates in the bulk motion of the Local Sheet away from the Local
Void. The component of our motion on an intermediate scale is attributed to the
Virgo Cluster and its surroundings, 17 Mpc away. The third and largest
component is an attraction on scales larger than 3000 km/s and centered near
the direction of the Centaurus Cluster. The amplitudes of the three components
are 259, 185, and 455 km/s, respectively, adding collectively to 631 km/s in
the reference frame of the Local Sheet. Taking the nearby influences into
account causes the residual attributed to large scales to align with observed
concentrations of distant galaxies and reduces somewhat the amplitude of motion
attributed to their pull. On small scales, in addition to the motion of our
Local Sheet away from the Local Void, the nearest adjacent filament, the Leo
Spur, is seen to be moving in a direction that will lead to convergence with
our filament. Finally, a good distance to an isolated galaxy within the Local
Void reveals that this dwarf system has a motion of at least 230 km/s away from
the void center. Given the velocities expected from gravitational instability
theory in the standard cosmological paradigm, the distance to the center of the
Local Void must be at least 23 Mpc from our position. The Local Void is large!
","We present an analysis of peculiar velocities in the local universe, based on data obtained by the Sloan Digital Sky Survey (SDSS). We use a sample of galaxies with measured redshifts and distances to construct a map of the velocity field around us. The resulting flow is dominated by coherent motions that are consistent with our location within a void centered at about 50 Mpc distance. This result confirms earlier findings using different methods. 
 
 In addition we find evidence for a dipole component in this flow which points away from the center of the void towards Virgo. Our results suggest that the bulk motion of matter in the nearby universe may be influenced by large-scale structure. These results have implications for cosmological models as well as for studies of galaxy formation and evolution. They also provide new constraints on theories of dark energy. A full version of this article can be found at: http://arxiv.org/abs/astro-ph/0403320",arxiv,bigscience bloomz,705.4139,0.7222222222222222,0.3949579831932773,0.9435897435897436,0.3951266125179169,0,0,0,0,0,1,1,1,0,0,0.09942725981203307,0.04702962874465979,0.10505836575875487,0.041666666666666664,2,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Fundamental Limits to Position Determination by Concentration Gradients,"  Position determination in biological systems is often achieved through
protein concentration gradients. Measuring the local concentration of such a
protein with a spatially-varying distribution allows the measurement of
position within the system. In order for these systems to work effectively,
position determination must be robust to noise. Here, we calculate fundamental
limits to the precision of position determination by concentration gradients
due to unavoidable biochemical noise perturbing the gradients. We focus on
gradient proteins with first order reaction kinetics. Systems of this type have
been experimentally characterised in both developmental and cell biology
settings. For a single gradient we show that, through time-averaging, great
precision can potentially be achieved even with very low protein copy numbers.
As a second example, we investigate the ability of a system with oppositely
directed gradients to find its centre. With this mechanism, positional
precision close to the centre improves more slowly with increasing averaging
time, and so longer averaging times or higher copy numbers are required for
high precision. For both single and double gradients, we demonstrate the
existence of optimal length scales for the gradients, where precision is
maximized, as well as analyzing how precision depends on the size of the
concentration measuring apparatus. Our results provide fundamental constraints
on the positional precision supplied by concentration gradients in various
contexts, including both in developmental biology and also within a single
cell.
","We present an analysis of the fundamental limits on position determination using concentration gradients in biological systems, such as bacteria and neurons. We show that these limits are determined by the number of molecules available for measurement at each location along the gradient. The optimal strategy is to measure all locations with equal precision; this leads to a limit on the accuracy of position determination given by $1/\sqrt{N}$ where $N$ is the total number of molecules measured across the entire system. This result holds even if we allow arbitrary prior information about the distribution of positions within the system. Our results provide insight into how cells can optimally use concentration gradients to determine their positions relative to other cells or external cues. In addition, our results suggest new ways to improve existing techniques used to track cell migration over time. 
 
 Bacteria and neurons both sense chemical concentrations through receptors located throughout their surfaces. These receptors convert local chemical concentrations into electrical signals which are then transmitted back to the cell body via specialized signaling pathways. As a consequence, the amount of signal received depends not only upon the local concentration but also upon the distance between the receptor and the source of the signal (see Figure 1). For example, when a bacterium senses a nutrient molecule it will produce more signal if the nutrient is closer than if it were farther away. Similarly, when a neuron receives input from another neuron, its response will depend upon whether the synapse connecting them lies close to the center of the cell's dendritic tree or near one of its tips.",arxiv,bigscience bloomz,704.3639,0.5555555555555556,0.49579831932773116,0.5384615384615384,0.7190635451505017,0,1,0,0,0,1,0,1,0,1,0.08044287346579665,0.07936068123189412,0.05058365758754864,0.09090909090909091,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
The Millennium Galaxy Catalogue: The local supermassive black hole mass function in early- and late-type galaxies,"  We provide a new estimate of the local supermassive black hole mass function
using (i) the empirical relation between supermassive black hole mass and the
Sersic index of the host spheroidal stellar system and (ii) the measured
(spheroid) Sersic indices drawn from 10k galaxies in the Millennium Galaxy
Catalogue. The observational simplicity of our approach, and the direct
measurements of the black hole predictor quantity, i.e. the Sersic index, for
both elliptical galaxies and the bulges of disc galaxies makes it
straightforward to estimate accurate black hole masses in early- and late-type
galaxies alike. We have parameterised the supermassive black hole mass function
with a Schechter function and find, at the low-mass end, a logarithmic slope
(1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxy
sample. Considering spheroidal stellar systems brighter than M_B = -18 mag, and
integrating down to black hole masses of 10^6 M_sun, we find that the local
mass density of supermassive black holes in early-type galaxies rho_{bh,
early-type} = (3.5+/-1.2) x 10^5 h^3_{70} M_sun Mpc^{-3}, and in late-type
galaxies rho_{bh, late-type} = (1.0+/-0.5) x 10^5 h^3_{70} M_sun Mpc^{-3}. The
uncertainties are derived from Monte Carlo simulations which include
uncertainties in the M_bh-n relation, the catalogue of Sersic indices, the
galaxy weights and Malmquist bias. The combined, cosmological, supermassive
black hole mass density is thus Omega_{bh, total} = (3.2+/-1.2) x 10^{-6} h_70.
That is, using a new and independent method, we conclude that (0.007+/-0.003)
h^3_{70} per cent of the universe's baryons are presently locked up in
supermassive black holes at the centres of galaxies.
","We present the first measurement of the supermassive black hole (SMBH) mass function for both early-(elliptical/S0, Sa-Sb) and latetype (Scd-Sm) galaxies using data from the Millennium Galaxy Catalogue (MGC). We use two different methods to measure SMBH masses - stellar velocity dispersion measurements and bulge luminosity scaling relations. Our results show that there is no significant difference between the SMBH mass functions of these galaxy types at z < 0.1. However we find evidence for an evolution with redshift such that the number density of massive SMBHs decreases more rapidly than less-massive ones. This suggests that the most massive SMBHs are likely to have grown by accretion over cosmic time rather than merging events. These findings will be important constraints on models of SMBH growth and AGN feedback.",arxiv,bigscience bloomz,704.0316,0.3888888888888889,0.24369747899159663,0.7128205128205128,0.32059245102723366,1,1,0,0,1,1,1,0,0,0,0.18426905330006627,0.06464951604536572,0.2140077821011673,0.06060606060606061,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Lyman Break Galaxies at z~5: Rest-frame UV Spectra II,"  We present the results of spectroscopy of Lyman Break Galaxies (LBGs) at z~5
in the J0053+1234 field with the Faint Object Camera and Spectrograph on the
Subaru telescope. Among 5 bright candidates with z' < 25.0 mag, 2 objects are
confirmed to be at z~5 from their Ly alpha emission and the continuum
depression shortward of Ly alpha. The EWs of Ly alpha emission of the 2 LBGs
are not so strong to be detected as Ly alpha emitters, and one of them shows
strong low-ionized interstellar (LIS) metal absorption lines. Two faint objects
with z' \geq 25.0 mag are also confirmed to be at z~5, and their spectra show
strong Ly alpha emission in contrast to the bright ones. These results suggest
a deficiency of strong Ly alpha emission in bright LBGs at z~5, which has been
discussed in our previous paper. Combined with our previous spectra of LBGs at
z~5 obtained around the Hubble Deep Field-North (HDF-N), we made a composite
spectrum of UV luminous (M_1400 \leq -21.5 mag) LBGs at z~5. The resultant
spectrum shows a weak Ly alpha emission and strong LIS absorptions which
suggests that the bright LBGs at z~5 have chemically evolved at least to ~0.1
solar metallicity. For a part of our sample in the HDF-N region, we obtained
near-to-mid infrared data, which constraint stellar masses of these objects.
With the stellar mass and the metallicity estimated from LIS absorptions, the
metallicities of the LBGs at z~5 tend to be lower than those of the galaxies
with the same stellar mass at z \lesssim 2, although the uncertainty is very
large.
","We present new rest-UV spectra for four Lyman break galaxies (LBGs) with redshifts between 5 and 6, obtained using the Ultraviolet Echelle Spectrograph on board the Hubble Space Telescope.  The data are used to measure the interstellar medium properties in these objects by fitting models to their observed absorption line profiles. We find that all four LBGs have high metallicities ranging from 0.2 solar to 1 solar, which is consistent with previous results based on optical spectroscopy. In addition we detect strong outflows in three of our targets, as evidenced by blueshifted interstellar absorption lines. These observations suggest that massive stars may be responsible for driving galactic-scale winds even before reionization has completed. This work was supported by NASA grant HST-GO-10775.01-A awarded through the Space Telescope Science Institute, which is operated by AURA under NASA contract NAS5-26555.",arxiv,bigscience bloomz,705.1145,0.4444444444444444,0.24369747899159663,0.7435897435897436,0.3463927376970855,1,1,0,0,1,1,1,0,0,0,0.056831852543206926,0.03858780348696234,0.07782101167315175,0.022727272727272728,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Dual Computations of Non-abelian Yang-Mills on the Lattice,"  In the past several decades there have been a number of proposals for
computing with dual forms of non-abelian Yang-Mills theories on the lattice.
Motivated by the gauge-invariant, geometric picture offered by dual models and
successful applications of duality in the U(1) case, we revisit the question of
whether it is practical to perform numerical computation using non-abelian dual
models. Specifically, we consider three-dimensional SU(2) pure Yang-Mills as an
accessible yet non-trivial case in which the gauge group is non-abelian. Using
methods developed recently in the context of spin foam quantum gravity, we
derive an algorithm for efficiently computing the dual amplitude and describe
Metropolis moves for sampling the dual ensemble. We relate our algorithms to
prior work in non-abelian dual computations of Hari Dass and his collaborators,
addressing several problems that have been left open. We report results of spin
expectation value computations over a range of lattice sizes and couplings that
are in agreement with our conventional lattice computations. We conclude with
an outlook on further development of dual methods and their application to
problems of current interest.
","We present an algorithm for computing non-abelian gauge theories in two different ways, which we call ""directly"" and ""indirectly"". The directly computed quantities are related to those obtained by standard Monte Carlo techniques via Feynman rules. In contrast, indirectly computed quantities can be evaluated without any reference to Feynman diagrams or perturbation theory at all. We demonstrate that both computations agree with each other within statistical errors over several orders of magnitude in lattice spacing and volume. This provides strong evidence that our approach is correct. Finally, we show how this method allows us to compute observables such as glueball masses and decay constants accurately even when they cannot be extracted using conventional methods. Introduction: Gauge theories play a central role in particle physics. However, it has been notoriously difficult to study them numerically because of their nonperturbative nature. Here we propose a new numerical technique based on dual formulations of quantum field theories (QFTs) [1] . Duality transformations relate QFTs formulated in terms of fields living on spacetime points to equivalent ones defined in terms of fields living only on links between these points [2] .
In particular, we consider SU(Nc) Yang-Mills theories coupled to fermions transforming according to some representation R of SU(Nc). These theories have a number of interesting physical applications ranging from nuclear physics [3] , where Nc= 3, to high-energy phenomenology [4] , where Nc> 4. For example, one may use this formalism to calculate hadronic matrix elements relevant for precision measurements of Standard Model parameters [5] .",arxiv,bigscience bloomz,705.2629,0.3333333333333333,0.596638655462185,0.2923076923076923,0.6789297658862877,1,1,0,0,0,1,1,1,0,0,0.06387649689729356,0.05716873385857426,0.06614785992217899,0.06439393939393939,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Stringy E-functions of hypersurfaces and of Brieskorn singularities,"  We show that for a hypersurface Batyrev's stringy E-function can be seen as a
residue of the Hodge zeta function, a specialization of the motivic zeta
function of Denef and Loeser. This is a nice application of inversion of
adjunction. If an affine hypersurface is given by a polynomial that is
non-degenerate with respect to its Newton polyhedron, then the motivic zeta
function and thus the stringy E-function can be computed from this Newton
polyhedron (by work of Artal, Cassou-Nogues, Luengo and Melle based on an
algorithm of Denef and Hoornaert). We use this procedure to obtain an easy way
to compute the contribution of a Brieskorn singularity to the stringy
E-function. As a corollary, we prove that stringy Hodge numbers of varieties
with a certain class of strictly canonical Brieskorn singularities are
nonnegative. We conclude by computing an interesting 6-dimensional example. It
shows that a result, implying nonnegativity of stringy Hodge numbers in lower
dimensional cases, obtained in our previous paper, is not true in higher
dimension.
","We study the stringy e-functions of smooth hypersurfaces in weighted projective spaces, which are defined by the generating functions for Gromov-Witten invariants with insertions of arbitrary genus zero descendant classes. We show that these functions can be written as certain infinite products over all prime ideals in the homogeneous coordinate ring of the ambient space. As an application we give explicit formulas for the stringy e-function of any smooth hypersurface in $\mathbb{P}^n(\mathcal{O}_{\mathbb{C}})$ or in $\mathbb{P}^n(t_1^{a_1}, ..., t_r^{a_0})$ (with $a_i \geq 1$). In particular this gives new proofs of the results of Batyrev-Borisov on the stringy Hodge numbers of Calabi-Yau varieties. 
The second part is devoted to the stringy e-functons of Brieskorn-Pham singularities. These are given by the generating series for Gromov-Wittet invariants with insertions only of one-pointed genus-zero descendent classes. We prove that they also have an expression as infinite products over all prime ideal in their homogeneous coordinate rings. This allows us to compute explicitly the stringy e-functons of many examples including the quintic threefold and its generalizations.",arxiv,bigscience bloomz,706.0798,0.3333333333333333,0.3445378151260504,0.23076923076923078,0.4381270903010034,1,1,0,0,1,1,1,0,0,0,0.14589233528969478,0.13766074007641727,0.1828793774319066,0.16287878787878787,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Recovering galaxy star formation and metallicity histories from spectra using VESPA,"  We introduce VErsatile SPectral Analysis (VESPA): a new method which aims to
recover robust star formation and metallicity histories from galactic spectra.
VESPA uses the full spectral range to construct a galaxy history from synthetic
models. We investigate the use of an adaptative parametrization grid to recover
reliable star formation histories on a galaxy-by-galaxy basis. Our goal is
robustness as opposed to high resolution histories, and the method is designed
to return high time resolution only where the data demand it. In this paper we
detail the method and we present our findings when we apply VESPA to synthetic
and real Sloan Digital Sky Survey (SDSS) spectroscopic data. We show that the
number of parameters that can be recovered from a spectrum depends strongly on
the signal-to-noise, wavelength coverage and presence or absence of a young
population. For a typical SDSS sample of galaxies, we can normally recover
between 2 to 5 stellar populations. We find very good agreement between VESPA
and our previous analysis of the SDSS sample with MOPED.
","We present the results obtained by applying the semi-analytic code VESPA to model the evolution of galaxies in the Millennium Simulation, including chemical enrichment as well as dust extinction effects on their observed properties.  We show that our models reproduce many observational trends for different types of galaxies at z=0 (e.g., luminosity functions), but also predict some new ones which can be tested with future surveys such as Euclid or LSST. In particular we find that:  - The predicted number density of massive quiescent galaxies is too high compared to observations; this problem could be alleviated if AGN feedback were more efficient than assumed here. - Our predictions are consistent with current estimates of the cosmic SFRD out to redshifts of about 4.5, although they tend to overpredict it slightly beyond that redshift. - At low masses (Mstar < 10^10 Msun) there appears to be an excess of blue galaxies relative to red galaxies in both the real Universe and in our simulations. This may indicate that either our treatment of supernova feedback and/or reionization physics needs improvement, or else that these processes have been affected by baryonic effects not included in our simulation.",arxiv,bigscience bloomz,704.0941,0.3888888888888889,0.24369747899159663,0.24615384615384617,0.5097945532728142,1,1,1,0,0,1,1,1,0,0,0.05493577489392958,0.02959045312694359,0.04669260700389105,0.011363636363636364,0,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
Absolute Calibration and Characterization of the Multiband Imaging Photometer for Spitzer. I. The Stellar Calibrator Sample and the 24 micron Calibration,"  We present the stellar calibrator sample and the conversion from instrumental
to physical units for the 24 micron channel of the Multiband Imaging Photometer
for Spitzer (MIPS). The primary calibrators are A stars, and the calibration
factor based on those stars is 4.54*10^{-2} MJy sr^{-1} (DN/s)^{-1}, with a
nominal uncertainty of 2%. We discuss the data-reduction procedures required to
attain this accuracy; without these procdures, the calibration factor obtained
using the automated pipeline at the Spitzer Science Center is 1.6% +/- 0.6%
lower. We extend this work to predict 24 micron flux densities for a sample of
238 stars which covers a larger range of flux densities and spectral types. We
present a total of 348 measurements of 141 stars at 24 micron. This sample
covers a factor of ~460 in 24 micron flux density, from 8.6 mJy up to 4.0 Jy.
We show that the calibration is linear over that range with respect to target
flux and background level. The calibration is based on observations made using
3-second exposures; a preliminary analysis shows that the calibration factor
may be 1% and 2% lower for 10- and 30-second exposures, respectively. We also
demonstrate that the calibration is very stable: over the course of the
mission, repeated measurements of our routine calibrator, HD 159330, show a
root-mean-square scatter of only 0.4%. Finally, we show that the point spread
function (PSF) is well measured and allows us to calibrate extended sources
accurately; Infrared Astronomy Satellite (IRAS) and MIPS measurements of a
sample of nearby galaxies are identical within the uncertainties.
","We present an absolute calibration of MIPS photometry at 24, 70, and 160 microns using stellar calibrators observed by the Infrared Array Camera (IRAC) onboard the Spitzer Space Telescope. We use these observations to derive corrections that account for differences in aperture size between IRAC and MIPS as well as color-dependent effects due to differing filter profiles. These corrections are applied to all sources detected with signal-to-noise ratios greater than 5 in each band. For fainter sources we apply additional corrections based upon the measured fluxes of bright stars within the same field-of-view. This method is used to calibrate over 1 million objects across the sky. We find excellent agreement between our results and those obtained independently by other groups. Our final uncertainties include contributions from both statistical errors and systematics associated with the choice of stellar calibrators. We also provide estimates of the uncertainty introduced into the derived colors when applying this technique.",arxiv,bigscience bloomz,704.2195,0.5,0.3445378151260504,0.6923076923076923,0.3951266125179169,1,1,1,0,0,1,1,0,0,0,0.09385233247247218,0.05451052325566515,0.0622568093385214,0.026515151515151516,0,0,5,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Network statistics on early English Syntax: Structural criteria,"  This paper includes a reflection on the role of networks in the study of
English language acquisition, as well as a collection of practical criteria to
annotate free-speech corpora from children utterances. At the theoretical
level, the main claim of this paper is that syntactic networks should be
interpreted as the outcome of the use of the syntactic machinery. Thus, the
intrinsic features of such machinery are not accessible directly from (known)
network properties. Rather, what one can see are the global patterns of its use
and, thus, a global view of the power and organization of the underlying
grammar. Taking a look into more practical issues, the paper examines how to
build a net from the projection of syntactic relations. Recall that, as opposed
to adult grammars, early-child language has not a well-defined concept of
structure. To overcome such difficulty, we develop a set of systematic criteria
assuming constituency hierarchy and a grammar based on lexico-thematic
relations. At the end, what we obtain is a well defined corpora annotation that
enables us i) to perform statistics on the size of structures and ii) to build
a network from syntactic relations over which we can perform the standard
measures of complexity. We also provide a detailed example.
","The present study investigates the structural properties of Early Modern English syntax by applying network analysis to data obtained through corpus linguistics techniques. The results show that, in general terms, syntactic networks are characterized by high clustering coefficients and low average path lengths. In addition, it is shown how these two parameters can be used as indicators for identifying different types of syntactic structures. Finally, some possible applications of this approach are discussed. Keywords: Network Analysis; Corpus Linguistics; Syntactic Structures; Clustering Coefficients; Average Path Lengths. 1 Introduction A growing number of studies have been carried out recently using network theory (Watts & Strogatz 1998 , Newman 2003a ) to investigate various aspects of language structure (Ferrer-i-Cancho 2004 , Ferrer-i-Cancho et al 2005 . These investigations have mainly focused on phonological systems (e.g., Ferrer-i-Cancho 2002 , Ferrer-i-Cancho & Solé 2007 or lexical-semantic relations (e.g., Steyvers & Tenenbaum 2005 ) . However, there has also been interest in exploring other linguistic levels such as morphosyntax (Ferrer-i-Canchos 2006 ) , prosody (Ferrer-i-Canchós 2008) , pragmatics (Ferrer-i-Canchis 2009) or even discourse (Ferrer-i-Canchi 2010) . This article focuses on one particular aspect of syntax -namely, word order-using network analysis to explore its structural characteristics. More specifically, we will use network theory to analyze data collected with corpus-linguistic methods. We believe that this type of investigation could provide new insights into the way in which syntactic structures emerge during language acquisition.",arxiv,bigscience bloomz,704.3708,0.4444444444444444,0.49579831932773116,0.4307692307692308,0.6273291925465839,1,1,0,0,0,1,1,1,0,0,0.10190505618823463,0.07167151714328839,0.1556420233463035,0.06818181818181818,1,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
The Araucaria Project. The Distance to the Local Group Galaxy WLM from Cepheid Variables discovered in a Wide-Field Imaging Survey,"  We have conducted an extensive wide-field imaging survey for Cepheid
variables in the Local Group irregular galaxy WLM. From data obtained on 101
nights, we have discovered 60 Cepheids which include 14 of the 15 Cepheid
variables previously detected by Sandage and Carlson. Down to a period of 3
days, our Cepheid survey in WLM should be practically complete. Importantly, we
have found for the first time a long-period Cepheid (P=54.2 days) in this
galaxy, alleviating the puzzle that WLM with its many blue, massive stars does
not contain Cepheids with periods longer than about 10 days. Our data define
tight period-luminosity relations in V, I and the reddening-free Wesenheit
magnitude ${\rm W}_{\rm I}$ which are all extremely well fit by the
corresponding slopes of the LMC Cepheid PL relation, suggesting no change of
the PL relation slope down to a Cepheid metal abundance of about -1.0 dex, in
agreement with other recent studies. We derive a true distance modulus to WLM
of 25.144 $\pm$0.03 (r) $\pm$0.07 (s) mag from our data, in good agreement with
the earlier 24.92 $\pm$ 0.21 mag determination of Lee, Freedman and Madore
(1993a) from Cepheid variables. The quoted value of the systematic uncertainty
does not include the contribution from the LMC distance which we have assumed
to be 18.50 mag, as in the previous papers in our project.
","We present results on distance determinations for two galaxies, NGC 3109 and WLM, based on observations made with the Hubble Space Telescope (HST). We have used HST/WFPC2 images taken through filters F555W and F814W to search for Cepheids among young open clusters located within these galaxies. Our survey has resulted in the discovery of four new Cepheids in NGC 3109 and one in WLM. These five Cepheids are all short-period classical pulsators with periods ranging between 4.5 days and 8.6 days. Using the period-luminosity relation derived by Madore & Freedman we find distances to NGC 3109 and W LM that agree well with previous estimates obtained using other methods. 
 
 Keywords: Cepheid variables; open cluster; galaxy distance scale; Hubble Space Telescope; Araucaria Project. 1. Introduction 
 
 Open clusters provide an important tool for determining extragalactic distances because they contain many stars at nearly identical ages and chemical compositions. In addition, open clusters can be found over a wide range of galactocentric radii, allowing us to probe different environments. However, open clusters are relatively rare objects compared to field stars or globular clusters. Therefore, it is necessary to conduct surveys covering large areas of sky in order to obtain statistically significant samples of open clusters suitable for use as calibrators of the cosmic distance ladder. 
 
 The Araucaria Project was initiated in 1998 with the goal of obtaining accurate distances to nearby galaxies via measurements of Cepheid variable stars associated with open clusters. This project uses data collected primarily with the Hubble Space Telescope's WFPC2 camera. A total of eight fields were observed during Cycle 9-10 of the HST program. Each field covers about 0.25 square degrees centered around a target galaxy. For each field, deep exposures were obtained in both the F555W and F850LP bands. Details regarding this project may be found in Pietrzyński et al. (2002) and references therein. 
 
 2. Searching for Cepheids Among Young Open",arxiv,bigscience bloomz,704.2075,0.3333333333333333,0.9495798319327731,0.517948717948718,0.8537983755375059,1,1,0,0,0,1,1,1,0,1,0.17025320419136195,0.07391726551527206,0.10116731517509728,0.06818181818181818,0,4,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Dark Matter in Gauge Mediation from Emergent Supersymmetry,"  We investigated the viability of neutralino dark matter in the gauge
mediation from emergent supersymmetry proposal. In this proposal, supersymmetry
is broken at Planck scale and consequently, the gravitino is superheavy and
completely decouples from the low energy theory. Squarks and sleptons obtain
their soft masses dominantly through gauge mediation with other mechanisms
highly suppressed. The lightest supersymmetric partner, in contrast to
traditional gauge mediation, is a neutralino which is also a dark matter
candidate. By explicit calculation of the low energy spectra, the parameter
space was constrained using the WMAP observed relic density of dark matter,
LEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic
B-meson decays. We found that the model has intriguing hybrid features such as
a nearly gauge-mediated spectrum (the exception being the superheavy gravitino)
but with a dominant mSUGRA-like bino-stau coannihilation channel and at large
$\tan \beta$, A-resonance-like annihilation.
","We propose that the dark matter (DM) and supersymmetric particles are generated by an emergent gauge symmetry at high energy scales, which is broken down to Standard Model symmetries below TeV scale. The DM candidate can be identified as a pseudo-Nambu-Goldstone boson associated with spontaneous breaking of global U(1) symmetry. We show how this scenario can explain various experimental results on DM searches including recent LHC data. In addition we discuss possible collider signatures for future experiments such as ILC or CLIC. Introduction: Dark matter (DM), whose existence has been inferred through its gravitational effects over many decades [1] , remains one of the most mysterious phenomena in particle physics today [2] . Although there have been numerous proposals for explaining the origin of DM [3] , none of them has yet provided compelling evidence for their viability [4] .
In this work, motivated by the idea of ""emergent"" theories [5] - [8] , we consider a new possibility where DM emerges from a spontaneously-broken global symmetry [9] . This approach provides a simple explanation for why DM should exist without introducing any additional fields beyond those already present within the Standard Model [10] . Furthermore, it allows us to identify the DM candidate as a pseudo-NambuGoldstone boson [11] , thereby providing a natural solution to the so-called ""WIMP miracle"" [12] problem [13] . Finally, our model also predicts the presence of light scalar superpartners [14] , which may provide interesting signals at upcoming high-energy accelerator facilities [15] .
The rest of this article is organised as follows. In Sec. 2, we introduce our theoretical framework based upon emergent gauge mediation [16] . Then, in Secs. 3-7, we demonstrate how this framework can simultaneously address all current experimental constraints [17] - [20] while predicting novel phenomenological features [21] . Finally, in Sec. 8, we conclude with some remarks about further directions of research.",arxiv,bigscience bloomz,705.2258,0.2777777777777778,0.7983193277310925,0.11794871794871795,0.8509316770186335,1,1,0,0,0,1,1,1,0,0,0.09520154585179327,0.10387014459171151,0.0622568093385214,0.07954545454545454,0,4,2,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Culminating paths,"  Let a and b be two positive integers. A culminating path is a path of Z^2
that starts from (0,0), consists of steps (1,a) and (1,-b), stays above the
x-axis and ends at the highest ordinate it ever reaches. These paths were first
encountered in bioinformatics, in the analysis of similarity search algorithms.
They are also related to certain models of Lorentzian gravity in theoretical
physics. We first show that the language on a two letter alphabet that
naturally encodes culminating paths is not context-free. Then, we focus on the
enumeration of culminating paths. A step by step approach, combined with the
kernel method, provides a closed form expression for the generating fucntion of
culminating paths ending at a (generic) height k. In the case a=b, we derive
from this expression the asymptotic behaviour of the number of culminating
paths of length n. When a>b, we obtain the asymptotic behaviour by a simpler
argument. When a<b, we only determine the exponential growth of the number of
culminating paths. Finally, we study the uniform random generation of
culminating paths via various methods. The rejection approach, coupled with a
symmetry argument, gives an algorithm that is linear when a>= b, with no
precomputation stage nor non-linear storage required. The choice of the best
algorithm is not as clear when a<b. An elementary recursive approach yields a
linear algorithm after a precomputation stage involving O(n^3) arithmetic
operations, but we also present some alternatives that may be more efficient in
practise.
","We consider the problem of finding a shortest path between two nodes in an undirected graph with non-negative edge weights, subject to the constraint that no node can be visited more than once along this path.  We show how to solve this problem by reducing it to the minimum cost flow problem on a directed acyclic network and then applying standard techniques for solving such problems.   The running time is O(n3 log n), where n denotes the number of vertices in the input graph. This result improves upon previous algorithms which have been known only for special cases (e.g., when all edges are unit-weight).    Keywords: Shortest paths, Minimum-cost flows, Directed graphs, Undirected graphs, Culminating paths, Constraints, Flow networks, Computational complexity theory.    1 Introduction

In many applications one needs to find a shortest path between two given nodes s and t in an undirected weighted graph G = (V , E) without allowing any vertex to appear twice or more times in the path.   For example, if we want to compute the distance between two cities using road maps, we may not allow a city to be used as a starting point again after visiting another city.   In other words, we do not want to use the same road segment twice even though there might exist several different ways to reach some destination.   Another application arises in computational biology, where one wants to find a sequence of genes that minimizes the total length while avoiding certain regions of DNA.   A third application occurs in computer vision, where one seeks to minimize the total length of a path through a set of images while ensuring that each image appears at most once in the path.   Finally, our results also apply to the problem of computing the diameter of a connected undirected graph.

The first algorithm for computing the shortest path satisfying these constraints was presented by Hassin and Rubinov [HR91] who showed how to reduce the problem to the minimum cost flow",arxiv,bigscience bloomz,706.0694,0.6111111111111112,0.15966386554621848,0.6358974358974359,0.26899187768752986,1,1,0,0,0,2,1,1,0,0,0.1608214398064871,0.051722292950652414,0.22568093385214008,0.056818181818181816,1,1,2,4,1,1,1,1,1,1,1,1,1,1,1,1,1,2,0,3,1,1
Modules over operads and functors,"  In the theory of operads we consider functors of generalized symmetric powers
defined by sums of coinvariant modules under actions of symmetric groups. One
observes classically that the construction of symmetric functors provides an
isomorphism from the category of symmetric modules to a subcategory of the
category of functors on the base category. The purpose of this book is to
obtain a similar relationship for functors on a category of algebras over an
operad.
  We observe that right modules over operads, symmetric modules equipped with a
right operad action, give rise to functors on categories of algebras and we
prove that this construction yields an embedding of categories. Then we check
that right modules over operads form a model category. In addition we prove
that weak-equivalences of right modules correspond to pointwise
weak-equivalences at the functor level. As a conclusion, we obtain that right
modules over operads supply good models for the homotopy of associated functors
on algebras over operads.
","In this article, we introduce the notion of modules over an operad in any symmetric monoidal category $\mathcal{C}$ with unit object $I$.  We define the free module on a set $X$ to be the tensor product $\bigotimes_{X\times X} I$ (where $*$ denotes the cartesian product); it is shown that this construction satisfies all axioms for a free module except possibly associativity.   The missing axiom is established by showing that the free module on two sets $X,Y$ can be constructed as the coequalizer of certain morphisms between free modules on three sets $Z_1,Z_2, Z_3$ where $Z_1$ has one element less than $X$, $Z_2$ has one element more than $Y$, and $Z_3$ has one element less than $Y\cup X$.    This result generalizes the classical theorem stating that the free group on a set $X$ is the quotient of the free group on the disjoint union of $X$ and its complement modulo the relation that identifies each element $x$ of $X$ with its inverse $x^{-1}$. 
The main results are applied to give new proofs of some well-known theorems about groups, rings, algebras, Lie algebras, and Hopf algebras.",arxiv,bigscience bloomz,704.309,0.3333333333333333,0.19327731092436976,0.18974358974358974,0.48112756808408985,0,1,0,0,0,1,1,1,0,0,0.07096333091904397,0.16874381942302918,0.0933852140077821,0.10606060606060606,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Evolutionary dynamics of the most populated genotype on rugged fitness landscapes,"  We consider an asexual population evolving on rugged fitness landscapes which
are defined on the multi-dimensional genotypic space and have many local
optima. We track the most populated genotype as it changes when the population
jumps from a fitness peak to a better one during the process of adaptation.
This is done using the dynamics of the shell model which is a simplified
version of the quasispecies model for infinite populations and standard
Wright-Fisher dynamics for large finite populations. We show that the
population fraction of a genotype obtained within the quasispecies model and
the shell model match for fit genotypes and at short times, but the dynamics of
the two models are identical for questions related to the most populated
genotype. We calculate exactly several properties of the jumps in infinite
populations some of which were obtained numerically in previous works. We also
present our preliminary simulation results for finite populations. In
particular, we measure the jump distribution in time and find that it decays as
$t^{-2}$ as in the quasispecies problem.
","We study evolutionary dynamics in an ensemble of genotypes, each with its own fitness value and connected to other genotypes by mutations. We show that for large ensembles there is always one genotype which has more connections than any other genotype. This genotype dominates all others at equilibrium. The dominance of this genotype depends only on the distribution of mutational distances between pairs of genotypes. For example, if we consider two different distributions of mutational distances (the exponential and power law), then the same genotype will dominate both cases. However, the time it takes to reach equilibrium can be very different depending on how many paths lead away from the dominant genotype. In particular, when the number of paths leading away from the dominant genotype increases exponentially as a function of distance, the system reaches equilibrium much faster compared to the case where the number of paths grows slower or even remains constant. 
 
 We also find that the average population size of the dominant genotype decreases slowly over time until reaching equilibrium.",arxiv,bigscience bloomz,706.0406,0.3333333333333333,0.3445378151260504,0.2564102564102564,0.44672718585762067,0,1,0,0,0,1,0,0,0,0,0.09226630476913537,0.08204515208099301,0.0933852140077821,0.07575757575757576,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1
"How a ""Hit"" is Born: The Emergence of Popularity from the Dynamics of Collective Choice","  In recent times there has been a surge of interest in seeking out patterns in
the aggregate behavior of socio-economic systems. One such domain is the
emergence of statistical regularities in the evolution of collective choice
from individual behavior. This is manifested in the sudden emergence of
popularity or ""success"" of certain ideas or products, compared to their
numerous, often very similar, competitors. In this paper, we present an
empirical study of a wide range of popularity distributions, spanning from
scientific paper citations to movie gross income. Our results show that in the
majority of cases, the distribution follows a log-normal form, suggesting that
multiplicative stochastic processes are the basis for emergence of popular
entities. This suggests the existence of some general principles of complex
organization leading to the emergence of popularity. We discuss the theoretical
principles needed to explain this socio-economic phenomenon, and present a
model for collective behavior that exhibits bimodality, which has been observed
in certain empirical popularity distributions.
","We study how popularity emerges in collective choice dynamics, where individuals sequentially choose between two options and are influenced by their peers. We show that when agents have boundedly rational expectations about others' choices they may end up choosing an option which has no majority support but nevertheless becomes popular over time. This phenomenon can be explained as a consequence of herding behavior among agents who do not fully understand the underlying social network structure. Our results suggest that such herding behavior could play an important role for understanding the emergence of popularity in real-world settings like online communities or political elections. In many situations people make decisions based on what other people think. For example, consumers often base their purchase decision on reviews written by other customers [1] , while voters decide to vote for one candidate rather than another because of information received through word-of-mouth communication [2] . Such phenomena are known under different names including bandwagon effects [3] , herd behavior [4] , informational cascades [5] , peer pressure [6] , conformity [7] , imitation [8] , and influence [9] .
In this work we focus on the case where individuals' decisions are made collectively via voting [10] . More specifically, consider a group of N agents who must select one out of M possible alternatives (e.g., candidates) at each round t = 1, ..., T . At every round t ∈ [T ], agent i chooses alternative xt(i), receives feedback f (xt−1)(−i) (e.g., votes casted against his/her choice), and updates his/her belief about the state of nature θ according to Bayes' rule [11] :",arxiv,bigscience bloomz,704.2955,0.3333333333333333,0.4453781512605043,0.2,0.7219302436693742,0,1,0,0,0,1,1,1,0,1,0.053965420441669985,0.10665522350561003,0.058365758754863814,0.09090909090909091,0,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
A ferrofluid based neural network: design of an analogue associative memory,"  We analyse an associative memory based on a ferrofluid, consisting of a
system of magnetic nano-particles suspended in a carrier fluid of variable
viscosity subject to patterns of magnetic fields from an array of input and
output magnetic pads. The association relies on forming patterns in the
ferrofluid during a trainingdphase, in which the magnetic dipoles are free to
move and rotate to minimize the total energy of the system. Once equilibrated
in energy for a given input-output magnetic field pattern-pair the particles
are fully or partially immobilized by cooling the carrier liquid. Thus produced
particle distributions control the memory states, which are read out
magnetically using spin-valve sensors incorporated in the output pads. The
actual memory consists of spin distributions that is dynamic in nature,
realized only in response to the input patterns that the system has been
trained for. Two training algorithms for storing multiple patterns are
investigated. Using Monte Carlo simulations of the physical system we
demonstrate that the device is capable of storing and recalling two sets of
images, each with an accuracy approaching 100%.
","We present the design and fabrication of a novel analog electronic device, which is capable to store information in its magnetic state. The proposed system consists of two layers of ferromagnetic wires with perpendicular anisotropy (PMA) that are connected by Josephson junctions. We show how this structure can be used as an analogue associative memory. In particular we demonstrate that it allows for storing multiple patterns simultaneously and retrieving them using only one input signal. This feature makes our proposal suitable for applications where high storage density or low power consumption are required. 
 
 Keywords: Analogue memory, Ferrofluids, Magnetic wire networks, PMA, Josephson junction, Pattern recognition, Associative memory. Introduction 
 
 Memory devices play a crucial role in many modern technologies such as computers, mobile phones, digital cameras etc., but their development has been mainly focused on digital memories due to their higher performance compared to conventional analog ones [1] . However, there exist several important applications where analog memories could provide significant advantages over digital counterparts [2] , e.g. pattern recognition [3] , data compression [4] , image processing [5] , bio-inspired computing [6] .
 
In recent years, considerable efforts have been made towards developing new types of analog memories [7, 8] . Among these proposals, spintronic systems [9] offer great potential thanks to their unique properties [10] including non-volatility [11] , fast switching [12] , large integration densities [13] , compatibility with CMOS technology [14] and energy efficiency [15] . These features make spintronic devices promising candidates for future generations of nonvolatile memories [16] . 
 
 Herein, we propose a novel concept of an analogue memory based on a magnetic wire network [17] . Our approach relies on the use of a ferrofluid [18] , i.e. colloidal suspension of superparamagnetic nanoparticles [19] , confined between two layers of ferromagnetic nanowires [20] . Due to the presence of the ferrofluid layer, each nanowire acquires a net magnetization [21] . As shown schematically in Fig.   1(a) , when applying a bias current I b through the nanowires, they become superconducting [22]",arxiv,bigscience bloomz,705.3402,0.3333333333333333,0.8487394957983193,0.28717948717948716,0.9197324414715718,0,1,0,0,0,1,1,1,0,0,0.08726032158772817,0.08871196660527943,0.08560311284046693,0.12121212121212122,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Simulation of Single Reed Instruments Oscillations Based on Modal Decomposition of Bore and Reed Dynamics,"  This paper investigates the sound production in a system made of a bore
coupled with a reed valve. Extending previous work (Debut, 2004), the input
impedance of the bore is projected on the modes of the air column. The acoustic
pressure is therefore calculated as the sum of modal components. The
airr&#114;&#64258;ow blown into the bore is modulated by reed motion, assuming
the reed to be a single degree of freedom oscillator. Calculation of
self-sustained oscillations controlled by time-varying mouth pressure and
player's embouchure parameter is performed using ODE solvers. Results emphasize
the par ticipation of the whole set of components in the mode locking process.
Another impor tant feature is the mutual inn&#110;&#64258;uence of reed and
bore resonance during growing blowing pressure transients, oscillation
threshold being altered by the reed natural frequency and the reed damping.
Steady-state oscillations are also investigated and compared with results given
by harmonic balance method and by digital sound synthesis.
","The reed is the key component in single-reed musical instruments, such as clarinets or saxophones. The dynamics of its motion are strongly influenced by the bore geometry and boundary conditions at both ends. In this work we present an approach to simulate the oscillations of a single reed instrument based on modal decomposition of the bore and reed dynamics. We show that it is possible to accurately reproduce the sound produced by a real clarinet using only one degree-of-freedom for each mode. This method can be used to study the influence of different parameters (such as mouthpiece diameter) on the acoustic response of the instrument without requiring expensive experimental measurements. It also allows us to investigate how changes in the design affect the performance of new prototypes. 
 
 Keywords: Musical Instrument, Clarinet, Sound Generation, Modeling, Simulation, Acoustics, Vibration Analysis, Modal Analysis, Finite Element Method",arxiv,bigscience bloomz,705.2803,0.3888888888888889,0.29411764705882354,0.16923076923076924,0.3635929288103201,1,1,1,0,1,1,1,1,0,0,0.08566207499431734,0.03859149218908086,0.09727626459143969,0.03409090909090909,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1
"Complexity Considerations, cSAT Lower Bound","  This article discusses completeness of Boolean Algebra as First Order Theory
in Goedel's meaning. If Theory is complete then any possible transformation is
equivalent to some transformation using axioms, predicates etc. defined for
this theory. If formula is to be proved (or disproved) then it has to be
reduced to axioms. If every transformation is deducible then also optimal
transformation is deducible. If every transformation is exponential then
optimal one is too, what allows to define lower bound for discussed problem to
be exponential (outside P). Then we show algorithm for NDTM solving the same
problem in O(n^c) (so problem is in NP), what proves that P \neq NP.
  Article proves also that result of relativisation of P=NP question and oracle
shown by Baker-Gill-Solovay distinguish between deterministic and
non-deterministic calculation models. If there exists oracle A for which
P^A=NP^A then A consists of infinite number of algorithms, DTMs, axioms and
predicates, or like NDTM infinite number of simultaneous states.
","We consider the complexity class #P and its subclass #P^{NP}. We show that for any polynomial time computable function f : {0,1}^n \to {0,1} there is an algorithm A such that for every input x to A it computes f(x) in time O(n^k), where k = log2|f|. This implies that if we can solve SAT in time n^k then we can compute f in time O(n^l). In particular this shows that if P != NP then #P^{NP} cannot be solved by deterministic algorithms running in sub-exponential time unless co-NP=PSPACE. The proof uses ideas similar to those used in proving lower bounds on the number of queries needed to solve problems like 3-SUM or Vertex Cover using dynamic programming techniques. It also relies heavily on the fact that the problem being considered has no efficient parallel solution (i.e., it does not belong to NC).
Theorem 1 Let f : {0,1}^m \to {0,1} be a polynomial-time computable function with m > 0. Then there exists an algorithm A which solves f in time O(m^k), where k = \lg |f| .
Proof: 
Let us assume without loss of generality that m is even. For each i between 1 and m/2 let g_i : {0,1}^{2i} \to {0,1} be defined as follows:",arxiv,bigscience bloomz,704.0514,0.4444444444444444,0.4453781512605043,0.18461538461538463,0.5470616340181558,1,1,0,0,1,1,1,1,0,0,0.08014372076798561,0.08032156082843248,0.0622568093385214,0.11363636363636363,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
A Systematic Scan for 7-colourings of the Grid,"  We study the mixing time of a systematic scan Markov chain for sampling from
the uniform distribution on proper 7-colourings of a finite rectangular
sub-grid of the infinite square lattice, the grid. A systematic scan Markov
chain cycles through finite-size subsets of vertices in a deterministic order
and updates the colours assigned to the vertices of each subset. The systematic
scan Markov chain that we present cycles through subsets consisting of 2x2
sub-grids and updates the colours assigned to the vertices using a procedure
known as heat-bath. We give a computer-assisted proof that this systematic scan
Markov chain mixes in O(log n) scans, where n is the size of the rectangular
sub-grid. We make use of a heuristic to compute required couplings of
colourings of 2x2 sub-grids. This is the first time the mixing time of a
systematic scan Markov chain on the grid has been shown to mix for less than 8
colours. We also give partial results that underline the challenges of proving
rapid mixing of a systematic scan Markov chain for sampling 6-colourings of the
grid by considering 2x3 and 3x3 sub-grids.
","We present an algorithm that systematically scans all possible 7-colourings of the grid, and report on its performance in terms of running time and memory consumption. The algorithm is based on a simple backtracking scheme combined with some heuristics to prune parts of the search space. We have implemented this algorithm using Java 1.6 and tested it on several instances ranging from small grids up to large ones containing more than one million nodes. For each instance we provide detailed information about how much time was spent by our program during colouring as well as how many colours were used. In addition, we also show how these results compare against those obtained by other algorithms proposed recently in the literature. 
 
 Keywords: Coloring problems, Computational complexity theory, Graphs, Backtrack search, Heuristic methods, Grid graphs, Integer programming, Optimization problems, Search trees, Time-complexity analysis 
 
 
 
 INTRODUCTION 
 
 A graph G = (V, E) consists of two sets V and E where V denotes the set of vertices or nodes and E denotes the set of edges between pairs of nodes. An edge e=(u,v) connects node u ∈ V to v ∈ V . If there exists no such connection then e is not included in E. A path P is defined as a sequence of distinct nodes v1 , v2 , … , vn such that vi−1vi ∈ E for i = 2 , 3 , … , n . A cycle C is defined as a path whose first and last nodes are identical. A connected component is a subgraph H of G which has the property that any pair of nodes in H can be joined by a path within H but cannot be joined by paths outside H. A clique K is a complete subgraph of G; that is, every pair of nodes in K is adjacent to each other. A k-clique is a clique consisting of exactly k nodes. A vertex cover S is a subset of V such that every edge in G has at least one endpoint in S. A dominating set D is a subset of V",arxiv,bigscience bloomz,704.1625,0.3333333333333333,0.546218487394958,0.31794871794871793,0.9541328236980411,1,1,0,0,0,1,1,1,0,0,0.05214282212645487,0.15171762112129658,0.054474708171206226,0.17803030303030304,0,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Using Images to create a Hierarchical Grid Spatial Index,"  This paper presents a hybrid approach to spatial indexing of two dimensional
data. It sheds new light on the age old problem by thinking of the traditional
algorithms as working with images. Inspiration is drawn from an analogous
situation that is found in machine and human vision. Image processing
techniques are used to assist in the spatial indexing of the data. A fixed grid
approach is used and bins with too many records are sub-divided hierarchically.
Search queries are pre-computed for bins that do not contain any data records.
This has the effect of dividing the search space up into non rectangular
regions which are based on the spatial properties of the data. The bucketing
quad tree can be considered as an image with a resolution of two by two for
each layer. The results show that this method performs better than the quad
tree if there are more divisions per layer. This confirms our suspicions that
the algorithm works better if it gets to look at the data with higher
resolution images. An elegant class structure is developed where the
implementation of concrete spatial indexes for a particular data type merely
relies on rendering the data onto an image.
","We present an algorithm for creating a hierarchical grid spatial index using images as the basis for its construction.  The algorithm is based on the observation that many real-world datasets are naturally represented by images, and can be used in conjunction with existing techniques such as R-tree or Quadtree to improve performance.   We show how our technique performs against these other methods through experiments conducted over synthetic data sets generated according to different distributions (uniform, normal, exponential) and sizes ranging between 1K and 100M points.   Our results demonstrate significant improvements in query response times when compared to traditional approaches. In this work we propose a new approach for building a spatial index which uses image processing algorithms to extract information about the dataset being indexed. This information is then used to build a hierarchy of grids whose leaf nodes contain pointers to individual objects within the dataset. These grids provide efficient access to all objects contained therein while also allowing fast queries across multiple grids at once.",arxiv,bigscience bloomz,705.0204,0.5555555555555556,0.29411764705882354,0.39487179487179486,0.43239369326325855,0,1,0,0,0,1,1,0,0,0,0.042675896612661475,0.06448786703585924,0.042801556420233464,0.07196969696969698,0,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Unicast and Multicast Qos Routing with Soft Constraint Logic Programming,"  We present a formal model to represent and solve the unicast/multicast
routing problem in networks with Quality of Service (QoS) requirements. To
attain this, first we translate the network adapting it to a weighted graph
(unicast) or and-or graph (multicast), where the weight on a connector
corresponds to the multidimensional cost of sending a packet on the related
network link: each component of the weights vector represents a different QoS
metric value (e.g. bandwidth, cost, delay, packet loss). The second step
consists in writing this graph as a program in Soft Constraint Logic
Programming (SCLP): the engine of this framework is then able to find the best
paths/trees by optimizing their costs and solving the constraints imposed on
them (e.g. delay < 40msec), thus finding a solution to QoS routing problems.
Moreover, c-semiring structures are a convenient tool to model QoS metrics. At
last, we provide an implementation of the framework over scale-free networks
and we suggest how the performance can be improved.
","We present an algorithm for unicast and multicast quality-of-service (QoS) routing in the Internet using soft constraint logic programming (SCLP). The proposed approach is based on the concept that each node maintains its own view about the network topology, which may be different than other nodes' views due to link failures or congestion. We use SCLP as our underlying framework because it can naturally represent such inconsistent information among nodes. In addition, we show how to incorporate bandwidth constraints into the SCLP model by introducing new variables representing available bandwidths between two adjacent links. Finally, we propose several algorithms to solve the problem efficiently. Our experimental results demonstrate that the proposed method outperforms existing approaches significantly under various conditions. Keywords: Quality-of-Service, Constraint Logic Programming, Bandwidth Allocation, Network Optimization, Link Failure, Congestion Control, Internet Service Provider, Unicast",arxiv,bigscience bloomz,704.1783,0.3333333333333333,0.29411764705882354,0.20512820512820512,0.3435260391782131,1,1,1,0,0,1,1,1,0,1,0.172180033510767,0.06143615771662113,0.19844357976653695,0.05303030303030303,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
The building up of the disk galaxy M33 and the evolution of the metallicity gradient,"  The evolution of radial gradients of metallicity in disk galaxies and its
relation with the disk formation are not well understood. Theoretical models of
galactic chemical evolution make contrasting predictions about the time
evolution of metallicity gradients. To test chemical evolution models and trace
the star formation and accretion history of low luminosity disk galaxies we
focus on the Local Group galaxy M33. We analyze O/H and S/H abundances in
planetary nebulae, H{\sc ii} regions, and young stars, together with known
[Fe/H] abundances in the old stellar population of M33. With a theoretical
model, we follow the time evolution of gas (diffuse and condensed in clouds),
stars, and chemical abundances in the disk of M33, assuming that the galaxy is
accreting gas from an external reservoir. Our model is able to reproduce the
available observational constraints on the distribution of gas and stars in M33
and to predict the time evolution of several chemical abundances. In
particular, we find that a model characterized by a continuous infall of gas on
the disk, at a rate of $\dot M_{\rm inf}\approx 1$ $M_\odot$ yr$^{-1}$, almost
constant with time, can also account for the relatively high rate of star
formation and for the shallow chemical gradients. Supported by a large sample
of high resolution observations for this nearby galaxy, we conclude that the
metallicity in the disk of M33 has increased with time at all radii, with a
continuous flattening of the gradient over the last $\sim 8$ Gyr.
","We present new spectroscopic observations in the near-infrared (NIR) for a sample of about 100 HII regions located along the major axis of the nearby spiral galaxy M33, at distances between 1 kpc and 8 kpc from its center. The main goal is to study how the chemical composition changes with galactocentric distance within this galaxy. We have used the NIR spectrograph ISAAC on board the European Southern Observatory's Very Large Telescope UT1 telescope to obtain high signal-to-noise ratio spectra covering the wavelength range 0.9-2.5 microns. From these data we derive oxygen abundances using two different methods based on strong emission lines. In addition, we use our results together with published photometric data to construct radial profiles of several physical parameters such as electron density, temperature or ionized gas mass fraction. Our analysis shows that there are no significant differences between both abundance determination techniques. However, when comparing our results with previous studies carried out by other authors it becomes clear that some discrepancies exist among them which can be explained mainly due to the fact that they were obtained under very different observational conditions.",arxiv,bigscience bloomz,704.3187,0.3888888888888889,0.29411764705882354,0.6307692307692307,0.4839942666029623,1,1,0,0,0,1,1,0,0,1,0.14568059160880864,0.09363631544209851,0.14396887159533073,0.08712121212121213,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Neutral Networks of Sequence to Shape Maps,"  In this paper we present a novel framework for sequence to shape maps. These
combinatorial maps realize exponentially many shapes, and have preimages which
contain extended connected subgraphs of diameter n (neutral networks). We prove
that all basic properties of RNA folding maps also hold for combinatorial maps.
Our construction is as follows: suppose we are given a graph $H$ over the $\{1
>...,n\}$ and an alphabet of nucleotides together with a symmetric relation
$\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of
length n is the maximal H subgraph in which all pairs of nucleotides incident
to H-edges satisfy $\mathcal{R}$. Our main result is to prove the existence of
at least $\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes
that have a preimage with diameter $n$ and a connected component of size at
least $(\frac{1+\sqrt{5}}{2})^n+(\frac{1-\sqrt{5}}{2})^n$. Furthermore, we show
that there exists a certain subset of shapes which carries a natural graph
structure. In this graph any two shapes are connected by a path of shapes with
respective neutral networks of distance one. We finally discuss our results and
provide a comparison with RNA folding maps.
","We introduce the concept of neutral networks, which are graphs that represent relationships between sequences and shapes in an unsupervised manner. We show how these can be used for shape recognition by training them on synthetic data generated using computer graphics techniques. The resulting network is able to recognize shapes with high accuracy even when they have been transformed or distorted. Finally we demonstrate our method on real world images showing its ability to generalize well beyond the training set. In this work we present a novel approach to learning about shapes through their relationship to sequences. Our main contribution is introducing the concept of neutral networks as a way to learn such relationships without supervision. Neutral networks are graphs whose nodes correspond to sequences (e.g., strings) and edges connect similar sequences. They provide a natural representation for capturing relationships between different types of information. For example, one could use a neutral network to capture relationships between sentences and documents, or between music notes and melodies. Here we focus on applying neutral networks to the problem of recognizing shapes based solely on their sequence of points sampled along their boundary. This task has many applications including medical image analysis where it may not always be possible to obtain ground truth labels due to privacy concerns.",arxiv,bigscience bloomz,706.076,0.5,0.49579831932773116,0.3435897435897436,0.5699952221691352,1,1,1,0,0,1,0,0,0,0,0.11861855685189115,0.024723902126992617,0.13229571984435798,0.022727272727272728,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1
Fluidization of a vertically oscillated shallow granular layer,"  Molecular dynamics simulations are used to study fluidization of a vertically
vibrated, three-dimensional shallow granular layer. As the container
acceleration is increased above g, the granular temperature and root mean
square particle displacement increase, gradually fluidizing the layer. For
nearly elastic particles, or low shaking frequencies, or small layer depths,
the end of the fluidization process is marked by an abrupt increase in the
granular temperature and rms particle displacement. The layer is then fully
fluidized since macroscopic, fluid-like phenomena such as convection rolls and
surface waves are observed. Increasing the total dissipation (by either
decreasing the restitution coefficient or increasing the total number of
particles) decreases the increase in granular temperature and rms particle
displacement at fluidization, and shifts the increase to higher accelerations.
Increasing the frequency also decreases the magnitude of the jump, and shifts
the change to lower accelerations.
","We report on the fluidization of a thin, horizontally vibrating granular bed by vertical oscillations at low frequency and amplitude. The system is studied experimentally using high-speed video imaging in combination with particle tracking velocimetry (PTV). We find that for sufficiently large vibration amplitudes, particles are ejected from the surface into the air as they reach their maximum height during an upward motion. This leads to the formation of a dilute gas phase above the dense packing near the bottom of the container. In addition we observe convection rolls which transport grains across the entire depth of the bed. These results show striking similarities to those observed in vibrated beds of sand or glass beads but differ significantly from previous studies performed on systems where only horizontal vibrations were applied. Vibrations can induce transitions between different states of matter such as solids, liquids, and gases [1] . For example, it has been shown that a solid state may become unstable when subjected to periodic forcing [2] , resulting in the spontaneous generation of traveling waves [3] . A particularly interesting case occurs if both horizontal and vertical components of the driving force act simultaneously [4] .
In this work we study the response of a thin granular layer to simultaneous application of horizontal and vertical vibrations. Our experiments reveal new phenomena not seen before in other types of driven granular media.",arxiv,bigscience bloomz,704.3852,0.2777777777777778,0.49579831932773116,0.09743589743589744,0.6158623984710941,1,1,0,0,0,1,1,0,0,0,0.08192886206554906,0.04805693584281791,0.08171206225680934,0.041666666666666664,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,1
Almost the supersymmetric Standard Model from intersecting D6-branes on the Z_6' orientifold,"  Intersecting stacks of supersymmetric fractional branes on the Z_6'
orientifold may be used to construct the supersymmetric Standard Model. If a,b
are the stacks that generate the SU(3)_{colour} and SU(2)_L gauge particles,
then, in order to obtain {\em just} the chiral spectrum of the (supersymmetric)
Standard Model (with non-zero Yukawa couplings to the Higgs mutiplets), it is
necessary that the number of intersections a \cap b of the stacks a and b, and
the number of intersections a \cap b' of a with the orientifold image b' of b
satisfy (a \cap b,a \cap b')=(2,1) or (1,2). It is also necessary that there is
no matter in symmetric representations of the gauge group, and not too much
matter in antisymmetric representations, on either stack. Fractional branes
having all of these properties may be constructed on the Z_6' orientifold. We
construct a (four-stack) model with two further stacks, each with just a single
brane, which has precisely the matter spectrum of the supersymmetric Standard
Model, including a single pair of Higgs doublets. However, the gauge group is
SU(3)_{\rm colour} x SU(2)_L x U(1)_Y x U(1)_H. Only the Higgs doublets are
charged with respect to U(1)_H.
","We propose an explicit construction for a string model with gauge group SU(3)xSU(2)xU(1), three generations of quarks and leptons, right-handed neutrinos, and no exotic particles beyond those in the minimal supersymmetric standard model (MSSM). The model is based on type IIA string theory compactified to four dimensions on a Calabi-Yau manifold X which has h^{1,1} = 1 and h^{1,2} = 0. We consider a stack of N=2 D6-branes wrapping a divisor S inside X that supports a non-abelian gauge symmetry U(N_c) where N_c = 3. In addition we introduce two sets of fractional branes at singularities of order 6 along divisors T_1 and T_2 such that the total number of D6-branes is 24. By using mirror symmetry arguments it can be shown that this configuration preserves one half of the original supersymmetry.",arxiv,bigscience bloomz,705.0646,0.3333333333333333,0.19327731092436976,0.3641025641025641,0.3320592451027234,1,1,0,0,1,1,1,0,0,0,0.31223817025938694,0.08792196398041197,0.36964980544747084,0.04924242424242424,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Testing String Theory with CMB,"  Future detection/non-detection of tensor modes from inflation in CMB
observations presents a unique way to test certain features of string theory.
Current limit on the ratio of tensor to scalar perturbations, r=T/S, is r <
0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all
known string theory inflation models predict tensor modes well below the level
of detection. Therefore a possible experimental discovery of tensor modes may
present a challenge to string cosmology.
  The strongest bound on r in string inflation follows from the observation
that in most of the models based on the KKLT construction, the value of the
Hubble constant H during inflation must be smaller than the gravitino mass. For
the gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an
extremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r
> 10^{-3} would imply that the gravitinos in this class of models are
superheavy, m_{3/2} > 10^{13} GeV. This would have important implications for
particle phenomenology based on string theory.
","The cosmic microwave background (CMB) is the remnant radiation left over after the Big Bang, and it provides an important test for theories about how our universe evolved.  In this article we will discuss some recent results on testing string theory using measurements of the temperature fluctuations in the CMB.   We will also describe what these tests tell us about the possible future development of string theory. The cosmic microwave background (CMB; see Figure below ) is the remnant radiation that remains today from when the early universe was only 380,000 years old. It contains information about the physical processes that took place during the first few minutes following the Big Bang. This includes the physics of inflationary expansion as well as the physics of particle production at very high energies. Because of its importance to cosmology, there are many ongoing experiments designed to measure the properties of the CMB more accurately than ever before. These include satellite missions such as WMAP and Planck, which have already produced impressive data sets, and ground-based telescopes like SPT and ACT, which are currently taking new observations.",arxiv,bigscience bloomz,704.0647,0.3888888888888889,0.3445378151260504,0.26666666666666666,0.48112756808408985,1,1,0,0,0,1,1,1,0,0,0.09715941408575242,0.043819772044305066,0.09727626459143969,0.026515151515151516,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On Classification of Finite Dimensional Complex Filiform Leibniz Algebras (Part 2),"  The paper is devoted to classification problem of finite dimensional complex
none Lie filiform Leibniz algebras. Actually, the observations show there are
two resources to get classification of filiform Leibniz algebras. The first of
them is naturally graded none Lie filiform Leibniz algebras and the another one
is naturally graded filiform Lie algebras. Using the first resource we get two
disjoint classes of filiform Leibniz algebras. The present paper deals with the
second of the above two classes, the first class has been considered in our
previous paper. The algebraic classification here means to specify the
representatives of the orbits, whereas the geometric classification is the
problem of finding generic structural constants in the sense of algebraic
geometry. Our main effort in this paper is the algebraic classification. We
suggest here an algebraic method based on invariants. Utilizing this method for
any given low dimensional case all filiform Leibniz algebras can be classified.
Moreover, the results can be used for geometric classification of orbits of
such algebras.
","In this article, we continue the classification of finite dimensional complex filiform Leibniz algebras begun in Part 1.  We show that if an algebra is not isomorphic to one of the previously classified ones then it has dimension at least 8 and its derived subalgebra has dimension at most 3. In particular, any such algebra satisfies dim(DerA) = 3 or 4. If dim(DerA)=4, then A is isomorphic either to L4(C), L1(C2), L2(C2), L3(C2), or L5(C2). If dim(DerA )=3, then A is isomorphic to one of the following Lie algebras:  L6(C3), L7(C3), L8(C3), L9(C3), L10(C3), L11(C3), L12(C3), L13(C3), L14(C3), L15(C3), L16(C3), L17(C3), L18(C3), L19(C3), L20(C3), L21(C3), L22(C3), L23(C3), L24(C3), L25(C3), L26(C3), L27(C3), L28(C3), L29(C3), L30(C3), L31(C3), L32(C3), L33(C3), L34(C3), L35(C3), L36(C3), L37(C3), L38(C3), L39(C3), L40(C3), L41(C3), L42(C3), L43(C3), L44(C3), L45(C3), L46(C3), L47(C3), L48(C3), L49(C3), L50(C3), L51(C3), L52(C3), L53(C3), L54(C3), L55(C3), L56(C3), L57(C3), L58(C3), L59(C3), L60(C3), L61(C3), L62(C3), L63(C3",arxiv,bigscience bloomz,704.3885,0.5,0.19327731092436976,0.22564102564102564,0.3750597228858099,0,0,0,0,0,1,0,1,0,0,0.06041697981754701,1.0,0.08171206225680934,1.0,1,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0
Detection of GRB 060927 at z = 5.47: Implications for the Use of Gamma-Ray Bursts as Probes of the End of the Dark Ages,"  We report on follow-up observations of the GRB 060927 using the ROTSE-IIIa
telescope and a suite of larger aperture ground-based telescopes. An optical
afterglow was detected 20 s after the burst, the earliest rest-frame detection
of optical emission from any GRB. Spectroscopy performed with the VLT about 13
hours after the trigger shows a continuum break at lambda ~ 8070 A produced by
neutral hydrogen absorption at z~5.6. We also detect an absorption line at 8158
A which we interpret as SiII at z=5.467. Hence, GRB 060927 is the second most
distant GRB with a spectroscopically measured redshift. The shape of the red
wing of the spectral break can be fitted by a damped Lyalpha profile with a
column density with log(N_HI/cm^-2) ~ 22.5. We discuss the implications of this
work for the use of GRBs as probes of the end of the dark ages and draw three
main conclusions: i) GRB afterglows originating from z>6 should be relatively
easy to detect from the ground, but rapid NIR monitoring is necessary to ensure
that they are found; ii) The presence of large HI column densities in some GRBs
host galaxies at z>5 makes the use of GRBs to probe the reionization epoch via
spectroscopy of the red damping wing challenging; iii) GRBs appear crucial to
locate typical star-forming galaxies at z>5 and therefore the type of galaxies
responsible for the reionization of the universe.
","We report on the detection by Swift/BAT and Konus-Wind of gamma-ray burst (GRB) 060927, which is one of only two events detected with redshifts greater than five to date.  The redshift was determined using optical spectroscopy obtained with the Very Large Telescope in Chile within three hours after the burst trigger time.  We find that this event has an extremely hard spectrum, similar to other high-redshift bursts observed previously.  Using our current understanding of the physics behind these phenomena we can estimate the total energy released during the prompt emission phase of the burst to be ~10^53 erg.  This value is comparable to or larger than the energies released by some supernovae.  If confirmed, it would make GRB 060927 the most energetic event ever recorded.  In addition, if the host galaxy mass function evolves similarly to what is seen locally, then the progenitor system responsible for producing such an energetic explosion must have been hosted by a very massive galaxy.  These results are consistent with theoretical predictions made about the progenitors of high-z GRBs.  Finally, we discuss how future observations of this object may help us understand the end of cosmic reionization.",arxiv,bigscience bloomz,706.1257,0.3333333333333333,0.3949579831932773,0.5692307692307692,0.5040611562350693,1,1,1,0,0,1,1,0,0,0,0.34542106829743835,0.06807374047397291,0.3657587548638132,0.07196969696969698,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Nurturing Breakthroughs: Lessons from Complexity Theory,"  A general theory of innovation and progress in human society is outlined,
based on the combat between two opposite forces (conservatism/inertia and
speculative herding ""bubble"" behavior). We contend that human affairs are
characterized by ubiquitous ``bubbles'', which involve huge risks which would
not otherwise be taken using standard cost/benefit analysis. Bubbles result
from self-reinforcing positive feedbacks. This leads to explore uncharted
territories and niches whose rare successes lead to extraordinary discoveries
and provide the base for the observed accelerating development of technology
and of the economy. But the returns are very heterogeneous, very risky and may
not occur. In other words, bubbles, which are characteristic definitions of
human activity, allow huge risks to get huge returns over large scales. We
outline some underlying mathematical structure and a few results involving
positive feedbacks, emergence, heavy-tailed power laws, outliers/kings/black
swans, the problem of predictability and the illusion of control, as well as
some policy implications.
","The book Nurturing Breakthroughs by James Watson and Peter Winkler is about how to create breakthroughs in science, technology, engineering or mathematics (STEM). The authors argue that the best way for scientists to make new discoveries is not through individual genius but rather by working together as teams on problems they are passionate about.  They also claim that it helps if you have an idea of what your problem looks like before you start solving it because this will help guide your research efforts. This article describes some of their ideas and provides examples of how these concepts can be applied to physics research. In his book Nurturing Breakdowns, James Watson argues that the most successful people who solve complex problems do so by working with others instead of trying to work alone. He says that when we work individually our brains tend to focus only on one aspect of the problem at hand which may lead us down dead ends while working collaboratively allows us to see all aspects of the problem simultaneously.",arxiv,bigscience bloomz,706.1839,0.3333333333333333,0.24369747899159663,0.15384615384615385,0.45246058289536556,1,1,0,0,1,1,0,0,0,0,0.10065913217963193,0.051039523551342836,0.0933852140077821,0.026515151515151516,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1
The metallicity gradient of M 33: chemical abundances of HII regions,"  We present spectroscopic observations of a sample of 72 emission-line
objects, including mainly HII regions, in the spiral galaxy M 33. Spectra were
obtained with the multi-object, wide field spectrograph AF2/WYFFOS at the 4.2m
WHT telescope. Line intensities, extinction, and electron density were
determined for the whole sample of objects. The aim of the present work was to
derive chemical and physical parameters of a set of HII regions, and from them
the metallicity gradient. Electron temperatures and chemical abundances were
derived for the 14 HII regions where both [OII] and [OIII] emission line fluxes
were measured, including the electron temperature sensitive emission line
[OIII] 436.3 nm and in a few cases [NII] 575.5 nm. The ionization correction
factor (ICF) method was used to derive the total chemical abundances. The
presence of abundance gradients was inferred from the radial behaviour of
several emission-line ratios, and accurately measured from chemical abundances
directly derived in 14 HII regions. The oxygen abundances of our HII regions,
located in the radial region from ~2 to ~7.2 kpc, gave an oxygen gradient
-0.054+/-0.011 dex/kpc The overall oxygen gradient for M 33 obtained using ours
and previous oxygen determinations in a large number of HII regions with direct
electron temperature determination as well as abundance in young stars
presented a two slope shape: -0.19 dex/kpc for the central regions (R<3kpc),
and -0.038dex/kpc for the outer regions (R>=3kpc).
","We present the results on abundance determinations for a sample of H II regions in M33, based on high resolution spectroscopy obtained with VLT/UVES and GIRAFFE spectrographs. The main goal is to study the radial distribution of oxygen abundance across this galaxy. We find that there are no significant differences between the gradients derived using different methods (T e , P method). Our best fit linear relation has slope -0.071 dex/kpc ± 0.005 dex/kpc. This value agrees well within errors with previous studies but it is slightly steeper than those found by other authors. In addition we have studied the behaviour of several α-elements as a function of galactocentric distance. We do not detect any clear trend neither for Mg nor Si or S elements. However, our data show an increase of [Ne/O] ratio towards the center of the galaxy which could be explained if Ne were produced mainly during type Ia supernovae explosions. 
 
 Keywords: Chemical composition",arxiv,bigscience bloomz,705.3116,0.3888888888888889,0.3949579831932773,0.5538461538461539,0.4037267080745342,1,1,1,0,0,1,1,1,0,0,0.22116211805849648,0.06852177002302924,0.22957198443579765,0.0946969696969697,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Two-sided optimal bounds for Green function of half-spaces for relativistic $\alpha$-stable process,"  The purpose of this paper is to find optimal estimates for the Green function
of a half-space of {\it the relativistic $\alpha$-stable process} with
parameter $m$ on $\Rd$ space. This process has an infinitesimal generator of
the form $mI-(m^{2/\alpha}I-\Delta)^{\alpha/2},$ where $0<\alpha<2$, $m>0$, and
reduces to the isotropic $\alpha$-stable process for $m=0$. Its potential
theory for open bounded sets has been well developed throughout the recent
years however almost nothing was known about the behaviour of the process on
unbounded sets. The present paper is intended to fill this gap and we provide
two-sided sharp estimates for the Green function for a half-space. As a
byproduct we obtain some improvements of the estimates known for bounded sets
specially for balls. The advantage of these estimates is a clarification of the
relationship between the diameter of the ball and the parameter $m$ of the
process.
  The main result states that the Green function is comparable with the Green
function for the Brownian motion if the points are away from the boundary of a
half-space and their distance is greater than one. On the other hand for the
remaining points the Green function is somehow related the Green function for
the isotropic $\alpha$-stable process. For example, for $d\ge3$, it is
comparable with the Green function for the isotropic $\alpha$-stable process,
provided that the points are close enough.
","We study the Green function of a relativistic $\alpha$-ssble process in a half-space with reflecting boundary condition at the boundary, and obtain two-sided estimates on its tail behavior by using the method of reflection principle. The results are applied to the case when the underlying space is $\mathbb{R}^d$ or $\mathbb{H}^1(\mathbb{R})$. We also give an example showing that our upper bound can be strictly smaller than the lower one. Finally we prove some properties of the Green functions of relativistic $\alpha$-stables processes killed upon leaving a domain. Let $(X_t)_{t \geq 0}$ be a relativistic $\alpha$-self-decomposable Lévy process (see Definition 2 below), which has been introduced independently by Bertoin [1] , Sato [2] and Watanabe [3] . It is known that this process possesses many interesting properties such as self-similarity, infinite divisibility etc. (see e.g., [4] ). In particular, it follows from [5] that there exists a constant $c > 0$ depending only on $\alpha$ such that 
$$P[X_1 = 0] \leq c \exp \left( - \frac{1}{2} |x|^{2 + \alpha} \right). $$",arxiv,bigscience bloomz,706.1175,0.4444444444444444,0.3949579831932773,0.517948717948718,0.4381270903010034,1,1,0,0,0,1,1,0,0,0,0.09636309437508658,0.15091503302207931,0.0933852140077821,0.19318181818181818,0,2,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale bar funnelling gas into the nuclear region","  This work is part of the NUGA survey of CO emission in nearby active
galaxies. We present observations of NGC4569, a member of the Virgo Cluster. We
analyse the molecular gas distribution and kinematics in the central region and
we investigate a possible link to the strong starburst present at the nucleus.
70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20"" is found
to be concentrated within the inner 800 pc and is distributed along the large
scale stellar bar seen in near-infrared observations. A hole in the CO
distribution coincides with the nucleus where most of the Halpha emission and
blue light are emitted. The kinematics are modelled in three different ways,
ranging from the purely geometrical to the most physical. This approach allows
us to constrain progressively the physical properties of the galaxy and
eventually to emerge with a reasonable fit to an analytical model of orbits in
a barred potential. Fitting an axisymmetric model shows that the non-circular
motions must be comparable in amplitude to the circular motions (120 km/s).
Fitting a model based on elliptical orbits allows us to identify with
confidence the single inner Lindblad resonance (ILR) of the large scale bar.
Finally, a model based on analytical solutions for the gas particle orbits in a
weakly barred potential constrained by the ILR radius reproduces the
observations well. The mass inflow rate is then estimated and discussed based
on the best fit model solution. The gravitational torques implied by this model
are able to efficiently funnel the gas inside the ILR down to 300 pc, although
another mechanism must take over to fuel the nuclear starburst inside 100 pc.
","We present new CO(2-1), 13CO(1-0), and C18O(1-0) observations with the IRAM 30m telescope towards the nearby spiral galaxy NGC 4565. The data reveal that this galaxy hosts an extended molecular disk which is warped by interactions with its companion galaxies. We find evidence for two distinct components to the molecular gas distribution; one associated with the main body of the galaxy and another component located along the southern edge of the optical disk. This second component has been previously detected as a dust lane but we show here it also contains significant amounts of molecular gas. In addition, our high resolution maps reveal a prominent central concentration of molecular gas coincident with the position of the AGN. Using these data together with previous results on other galaxies observed within the NUGA survey we investigate how the properties of the molecular gas are related to those of the stars and black holes hosted by each system.",arxiv,bigscience bloomz,705.3662,0.6111111111111112,0.24369747899159663,0.7948717948717948,0.39799331103678937,1,1,0,0,0,1,1,1,0,0,0.07589511823681892,0.05556126923807616,0.07782101167315175,0.045454545454545456,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
HST/FGS Parallaxes of AM CVn Stars and Astrophysical Consequences,"  We present absolute parallaxes and relative proper motions for five AM CVn
stars, which we obtained using the Fine Guidance Sensors on board the Hubble
Space Telescope. Our parallax measurements translate into distances d(AM
CVn)=606+135-93 pc, d(HP Lib)=197+14-12 pc, d(CR Boo)=337+44-35 pc, d(V803
Cen)=347+32-27 pc, and d(GP Com)=75+2-2 pc. From these distances we estimate
the space density of AM CVn stars and suggest that previous estimates have been
too high by about an order of magnitude. We also infer the mass accretion rates
which allows us to constrain the masses of the donor stars, and we show that
relatively massive, semi-degenerate donor stars are favored in all systems
except GP Com. Finally, we give updated estimates for their gravitational-wave
signals, relevant for future space missions such as the proposed Laser
Interferometer Space Antenna (LISA), based on their distances and the inferred
masses of the binary components. We show that all systems but GP Com are
excellent candidates for detection with LISA.
","We present parallax measurements for four short-period (P orb < 80 min) AM CVn stars using the Fine Guidance Sensor on board HST, which are accurate to better than 1% in distance. We find that all systems have distances consistent with their being located within 20 pc of Earth. The derived absolute magnitudes range between MV = 12.5 and 14.1 mag, corresponding to luminosities of 1030 - 1600 L⊙ . These values are significantly brighter than those predicted by theoretical models of these objects, indicating either an underestimate of the mass transfer rates or an overestimate of the white dwarf masses. In addition we use our new parallaxes together with previously published data to derive improved estimates of the orbital periods and component masses for three of the targets studied here. Finally, we discuss how our results can be used to test current evolutionary scenarios for this class of binary system.",arxiv,bigscience bloomz,705.3855,0.2777777777777778,0.24369747899159663,0.19487179487179487,0.38652651696129964,1,1,0,0,0,1,1,0,0,0,0.09757107151039997,0.056970476887268424,0.09727626459143969,0.056818181818181816,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Electrical transport and optical studies of ferromagnetic Cobalt doped ZnO nanoparticles exhibiting a metal-insulator transition,"  The observed correlation of oxygen vacancies and room temperature
ferromagnetic ordering in Co doped ZnO1-o nanoparticles reported earlier (Naeem
et al Nanotechnology 17, 2675-2680) has been further explored by transport and
optical measurements. In these particles room temperature ferromagnetic
ordering had been observed to occur only after annealing in forming gas. In the
current work the optical properties have been studied by diffuse reflection
spectroscopy in the UV-Vis region and the band gap of the Co doped compositions
has been found to decrease with Co addition. Reflections minima are observed at
the energies characteristic of Co+2 d-d (tethrahedral symmetry) crystal field
transitions, further establishing the presence of Co in substitutional sites.
Electrical transport measurements on palletized samples of the nanoparticles
show that the effect of a forming gas is to strongly decrease the resistivity
with increasing Co concentration. For the air annealed and non-ferromagnetic
samples the variation in the resistivity as a function of Co content are
opposite to those observed in the particles prepared in forming gas. The
ferromagnetic samples exhibit an apparent change from insulator to metal with
increasing temperatures for T>380K and this change becomes more pronounced with
increasing Co content. The magnetic and resistive behaviors are correlated by
considering the model by Calderon et al [M. J. Calderon and S. D. Sarma, Annals
of Physics 2007 (Accepted doi: 10.1016/j.aop.2007.01.010] where the
ferromagnetism changes from being mediated by polarons in the low temperature
insulating region to being mediated by the carriers released from the weakly
bound states in the higher temperature metallic region.
","ZnO:Co nanocrystals were synthesized by the sol-gel method followed by annealing at different temperatures (500-700 °C). The structural, morphological, magnetic and electrical properties have been investigated in detail using X-ray powder diffraction (XRD), scanning electron microscopy (SEM) with energy dispersive spectroscopy (EDS), vibrating sample magnetometer (VSM), Hall effect measurement system and UV-Vis-NIR spectrophotometry techniques. XRD analysis reveals that all samples are single phase wurtzite structure without any impurity peaks. SEM images show that the particles are spherical in shape and their size increases with increasing temperature. VSM measurements reveal that the saturation magnetization decreases gradually as the annealing temperature is increased up to 700 °C due to the decrease in Co content. It was found that the resistivity shows an abrupt increase around 500 °C which indicates the occurrence of semiconductor-metal transition.",arxiv,bigscience bloomz,705.1593,0.3888888888888889,0.24369747899159663,0.6820512820512821,0.3320592451027234,1,1,1,0,0,1,1,1,0,0,0.13136030299025503,0.10454073500797108,0.1517509727626459,0.12121212121212122,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
BVRI Surface Photometry of Isolated Spiral Galaxies,"  A release of multicolor broad band (BVRI) photometry for a subsample of 44
isolated spirals drawn from the Catalogue of Isolated Galaxies (CIG) is
presented. Total magnitudes and colors at various circular apertures, as well
as some global structural/morphological parameters are estimated. Morphology is
reevaluated through optical and sharp/filtered R band images, (B-I) color index
maps, and archive near-IR JHK images from the Two-Micron Survey. The CAS
structural parameters (Concentration, Asymmetry, and Clumpiness) were
calculated from the images in each one of the bands. The fraction of galaxies
with well identified optical/near-IR bars (SB) is 63%, while a 17% more shows
evidence of weak or suspected bars (SAB). The sample average value of the
maximum bar ellipticity is 0.4. Half of the galaxies in the sample shows rings.
We identify two candidates for isolated galaxies with disturbed morphology. The
structural CAS parameters change with the observed band, and the tendencies
they follow with the morphological type and global color are more evident in
the redder bands. In any band, the major difference between our isolated
spirals and a sample of interacting spirals is revealed in the A-S plane. A
deep and uniformly observed sample of isolated galaxies is intended for various
purposes including (i) comparative studies of environmental effects, (ii)
confronting model predictions of galaxy evolution and (iii) evaluating the
change of galaxy properties with redshift.
","We present BVRI surface photometry for isolated spiral galaxies in the nearby universe (0.01 < z < 0.1). The sample consists of 12 objects selected by their morphological type, inclination and apparent size to be suitable targets for detailed studies with integral field spectroscopy. We use archival data obtained at the Kitt Peak National Observatory 4m telescope as well as new observations taken during our own observing runs between 2005-2007. Our analysis is based on two-dimensional fitting of exponential disk models using GALFIT. In addition we perform bulge-disk decomposition using two different methods. First, we fit Sérsic profiles to both components simultaneously. Second, we apply an iterative method where we first subtract the best-fit model from each image before performing another round of fits. This procedure allows us to study the properties of individual galaxy components separately. For all but one object we find that the results are consistent within the uncertainties.",arxiv,bigscience bloomz,705.2041,0.5555555555555556,0.3949579831932773,0.5282051282051282,0.38939321548017203,1,1,0,0,0,1,1,0,0,0,0.09939100579831825,0.05199038283620508,0.08560311284046693,0.03409090909090909,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Galactic Wind Signatures around High Redshift Galaxies,"  We carry out cosmological chemodynamical simulations with different strengths
of supernova (SN) feedback and study how galactic winds from star-forming
galaxies affect the features of hydrogen (HI) and metal (CIV and OVI)
absorption systems in the intergalactic medium at high redshift. We find that
the outflows tend to escape to low density regions, and hardly affect the dense
filaments visible in HI absorption. As a result, the strength of HI absorption
near galaxies is not reduced by galactic winds, but even slightly increases. We
also find that a lack of HI absorption for lines of sight (LOS) close to
galaxies, as found by Adelberger et al., can be created by hot gas around the
galaxies induced by accretion shock heating. In contrast to HI, metal
absorption systems are sensitive to the presence of winds. The models without
feedback can produce the strong CIV and OVI absorption lines in LOS within 50
kpc from galaxies, while strong SN feedback is capable of creating strong CIV
and OVI lines out to about twice that distance. We also analyze the mean
transmissivity of HI, CIV, and OVI within 1 h$^{-1}$ Mpc from star-forming
galaxies. The probability distribution of the transmissivity of HI is
independent of the strength of SN feedback, but strong feedback produces LOS
with lower transmissivity of metal lines. Additionally, strong feedback can
produce strong OVI lines even in cases where HI absorption is weak. We conclude
that OVI is probably the best tracer for galactic winds at high redshift.
","We present the results of an analysis of deep Chandra X-ray Observatory observations of two high redshift galaxies, MS1512-cB58 and APM 08279+5255 (z = 3.91). We find that both sources show evidence for extended soft X-ray emission with luminosities in excess of 1043 erg/sec. The observed properties are consistent with those expected from galactic winds driven by supernovae or active nuclei. In addition to these diffuse components we detect several point-like X-ray sources within each galaxy's field-of-view which may be associated with young supermassive black holes at early stages of their formation. These objects have bolometric luminosities ranging between 1044-1046 erg/sec and appear to lie on tracks similar to those followed by quasars as they evolve through cosmic time. This work is based upon data obtained for the Guaranteed Time Observing program operated by NASA under contract NAS8-39073.",arxiv,bigscience bloomz,704.0652,0.5,0.24369747899159663,0.6461538461538462,0.34925943621595795,1,1,0,0,0,1,1,0,0,1,0.10533989824321734,0.045540218997337185,0.10116731517509728,0.041666666666666664,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Gauge symmetry in Kitaev-type spin models and index theorems on odd manifolds,"  We construct an exactly soluble spin-$\frac{1}2$ model on a honeycomb
lattice, which is a generalization of Kitaev model. The topological phases of
the system are analyzed by study of the ground state sector of this model, the
vortex-free states. Basically, there are two phases, A phase and B phase. The
behaviors of both A and B phases may be studied by mapping the ground state
sector into a general p-wave paired states of spinless fermions with tunable
pairing parameters on a square lattice. In this p-wave paired state theory, the
A phase is shown to be the strong paired phase, an insulating phase. The B
phase may be either gapped or gapless determined by the generalized inversion
symmetry is broken or not. The gapped B is the weak pairing phase described by
either the Moore-Read Pfaffian state of the spinless fermions or anti-Pfaffian
state of holes depending on the sign of the next nearest neighbor hopping
amplitude. A phase transition between Pfaffian and anti-Pfaffian states are
found in the gapped B phase. Furthermore, we show that there is a hidden SU(2)
gauge symmetry in our model. In the gapped B phase, the ground state has a
non-trivial topological number, the spectral first Chern number or the chiral
central charge, which reflects the chiral anomaly of the edge state. We proved
that the topological number is identified to the reduced eta-invariant and this
anomaly may be cancelled by a bulk Wess-Zumino term of SO(3) group through an
index theorem in 2+1 dimensions.
","We study the gauge structure of quantum spin systems with local interactions, which are described by the so-called Kitaev model. We show that this model is equivalent to an exactly solvable lattice gauge theory (LGT) whose action functional is given by the Chern-Simons term. The equivalence between these two theories allows us to use powerful techniques developed for LGTs such as the index theorem or the localization technique. In particular we prove that the ground state degeneracy of the Kitaev model on any closed 3-manifold M equals the number of independent solutions of certain differential equations called Witten's equation. This result can be viewed as a generalization of the Atiyah-Patodi-Singer index theorem to manifolds with boundary. Finally, using the results obtained above, we derive some exact formulas for the partition function of the Kitaev model defined on surfaces with boundaries. These formulas generalize the celebrated formula due to Witten for the partition function of Yang-Mills fields on Riemann surfaces.",arxiv,bigscience bloomz,704.3829,0.5555555555555556,0.29411764705882354,0.6564102564102564,0.4094601051122791,1,1,0,0,0,1,1,0,0,1,0.08089972261067525,0.03747681218578519,0.08560311284046693,0.041666666666666664,0,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Unravelling the morphologies of Luminous Compact Galaxies using the HST/ACS GOODS survey,"  (Abridged) Luminous Compact Galaxies (LCGs) (M_B < -20, R_{1/2} < 4.5kpc and
EW_{0}(OII) >15\AA) constitute one of the most rapidly evolving galaxy
populations over the last ~8 Gyr history of the universe. Due to their
inherently compact sizes, any detailed quantitative analysis of their
morphologies has proved to be difficult in the past. In this work we use the
high angular resolution imaging data, from the HST/ACS GOODS survey, to study
the quantitative morphology of a complete sample of LCGs in the redshift range
0.5 < z < 1.2. We have derived structural parameters for a representative
sample of 39 LCGs selected from the GOODS-S field, using full 2-dimensional
surface brightness profile fitting of the galaxy images in each of the four
filters available. B-z color maps are used as an aid in the morphological
classification. We then use the rest frame B band bulge flux fraction (B/T) to
determine the morphological class of the galaxies. Mergers were essentially
identified visually by the presence of multiple maxima of comparable intensity
in the rest frame B band images, aided by the color maps to distinguish them
from HII regions. We derive the following morphological mix for our sample of
intermediate redshift LCGs: Mergers: ~36%, Disk dominated: ~22%, S0: ~20%,
Early types: ~7%, Irr/tadpole: ~15%. We establish that our sample LCGs are
intermediate mass objects with a median stellar mass of Log(M/M_{\odot})=10.32.
We also derive dust enshrouded SFR values ranging from a few to ~65
$M_{\odot}$/year using Spitzer 24$\mu m$ data. We estimate a factor ~11 fall in
the comoving number density of blue LCGs from redshifts 0.5 < z < 1.2 to the
current epoch. We finally discuss the evolutionary scenario of these LCGs which
might give us some clues regarding their descendants in the local universe.
","We present an analysis of morphological properties for a sample of luminous compact galaxies (LCGs) selected in the Hubble Ultra Deep Field and studied with the Advanced Camera for Surveys on board the Hubble Space Telescope. We use GALFIT to fit single Sérsic profiles to all objects, allowing us to derive their structural parameters such as effective radius Re, Sérsic index n, axis ratio q, position angle PA, total magnitude mT , and half-light surface brightness SB e . The results show that most of these galaxies are bulge-dominated systems with high central concentration indices (n > 2). In addition, we find that there is no significant correlation between galaxy luminosity or size and its Sérsic index. Finally, by comparing our results with those obtained for other samples of massive early-type galaxies at different redshifts, we conclude that LCGs have similar sizes but higher concentrations than local elliptical galaxies.",arxiv,bigscience bloomz,704.2177,0.6111111111111112,0.19327731092436976,0.8871794871794871,0.38079311992355475,1,1,1,0,0,1,1,0,0,0,0.09412128215549241,0.08764441669953664,0.10505836575875487,0.08333333333333333,0,0,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Augmented Sparse Reconstruction of Protein Signaling Networks,"  The problem of reconstructing and identifying intracellular protein signaling
and biochemical networks is of critical importance in biology today. We sought
to develop a mathematical approach to this problem using, as a test case, one
of the most well-studied and clinically important signaling networks in biology
today, the epidermal growth factor receptor (EGFR) driven signaling cascade.
More specifically, we suggest a method, augmented sparse reconstruction, for
the identification of links among nodes of ordinary differential equation (ODE)
networks from a small set of trajectories with different initial conditions.
Our method builds a system of representation by using a collection of integrals
of all given trajectories and by attenuating block of terms in the
representation itself. The system of representation is then augmented with
random vectors, and minimization of the 1-norm is used to find sparse
representations for the dynamical interactions of each node. Augmentation by
random vectors is crucial, since sparsity alone is not able to handle the large
error-in-variables in the representation. Augmented sparse reconstruction
allows to consider potentially very large spaces of models and it is able to
detect with high accuracy the few relevant links among nodes, even when
moderate noise is added to the measured trajectories. After showing the
performance of our method on a model of the EGFR protein network, we sketch
briefly the potential future therapeutic applications of this approach.
","We propose an algorithm for reconstructing the signaling network in which each node is associated with multiple time series data, and we assume that only some nodes are observed at any given time point. The proposed method consists of two steps: (1) estimating the state vector by solving a sparse reconstruction problem; (2) inferring the edge set using the estimated states as features. We show through numerical experiments on synthetic networks that our approach can accurately recover both the structure and parameters of the underlying network even when only partial information about the system is available. Our results also suggest that the performance of the proposed method depends strongly on how well the sparsity pattern of the true signal is captured by the observation matrix. Finally, we apply this method to analyze the dynamics of protein phosphorylation in yeast cells responding to heat shock stress. In particular, we identify several key proteins involved in regulating the response process. This work was supported by NIH grant R01GM084283-01A1",arxiv,bigscience bloomz,705.3989,0.3888888888888889,0.29411764705882354,0.5282051282051282,0.4295269947443861,1,1,0,0,0,1,1,1,0,0,0.07450526297580273,0.0875734797848535,0.08949416342412451,0.015151515151515152,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Spherically symmetric problem on the brane and galactic rotation curves,"  We investigate the braneworld model with induced gravity to clarify the role
of the cross-over length scale \ell in the possible explanation of the
dark-matter phenomenon in astrophysics and in cosmology. Observations of the 21
cm line from neutral hydrogen clouds in spiral galaxies reveal that the
rotational velocities remain nearly constant at a value v_c ~ 10^{-3}--10^{-4}
in the units of the speed of light in the region of the galactic halo. Using
the smallness of v_c, we develop a perturbative scheme for reconstructing the
metric in a galactic halo. In the leading order of expansion in v_c, at the
distances r \gtrsim v_c \ell, our result reproduces that obtained in the
Randall-Sundrum braneworld model. This inequality is satisfied in a real spiral
galaxy such as our Milky Way for distances r ~ 3 kpc, at which the rotational
velocity curve becomes flat, v_c ~ 7 \times 10^{-4}, if \ell \lesssim 2 Mpc.
The gravitational situation in this case can be approximately described by the
Einstein equations with the so-called Weyl fluid playing the role of dark
matter. In the region near the gravitating body, we derive a closed system of
equations for static spherically symmetric situation under the approximation of
zero anisotropic stress of the Weyl fluid. We find the Schwarzschild metric to
be an approximate vacuum solution of these equations at distances r \lesssim
(r_g \ell^2)^{1/3}. The value \ell \lesssim 2 Mpc complies well with the
solar-system tests. At the same time, in cosmology, a low-density braneworld
with \ell of this order of magnitude can mimic the expansion properties of the
high-density LCDM (lambda + cold dark matter) universe at late times. Combined
observations of galactic rotation curves and gravitational lensing can possibly
discriminate between the higher-dimensional effects and dark matter.
","We consider a spherically symmetric solution to Einstein's equations in five dimensions with an extra dimension compactified on S 1 /Z 2 . The bulk is assumed to be empty, while matter fields are confined to our four-dimensional world (the ""brane""). We find that this model can explain the observed flatness of galactic rotation curves without introducing any new particles or exotic forms of energy density. In particular we show how the mass distribution within galaxies may arise naturally as a consequence of the geometry of space-time. This work was supported by NSF grant PHY-0456728. PACS numbers: 04.20.-q, 11.10.-z, 98.80.Cq  A fundamental question about the nature of dark matter has been whether it consists of one or more species of particle. If so, what are their masses? What interactions do they have with ordinary matter? How much dark matter does each galaxy contain? These questions motivate us to study models for which the dark matter is described by some field theory living on a higher dimensional spacetime manifold. 
 
 Here we will focus on a class of solutions where the extra dimension is compactified on a circle $S^1$. Such configurations were first studied in [1] , where it was shown that if the fifth dimension is small compared to the other length scales involved then the gravitational potential felt by observers on the brane is indistinguishable from that produced by a point-like source located at the center of the sphere. However, when the size of the extra dimension becomes comparable to the radius of curvature of the brane, the gravitational force law changes dramatically [2] . 
 
 In [3] , Randall and Sundrum showed that such a configuration could provide a natural explanation for the hierarchy between the weak scale and the Planck scale. They considered a 5D anti-de-Sitter space with two 3-branes embedded along its boundary. One of these branes represents our universe, while the second acts like a mirror image of ours. Matter fields are localized near either brane, but gravity propagates freely throughout the entire bulk.",arxiv,bigscience bloomz,706.0649,0.5555555555555556,0.7983193277310925,0.8769230769230769,0.9197324414715718,1,1,0,0,0,1,1,1,1,1,0.10365642986056979,0.0954859671167173,0.12062256809338522,0.10984848484848485,0,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Redesigning Computer-based Learning Environments: Evaluation as Communication,"  In the field of evaluation research, computer scientists live constantly upon
dilemmas and conflicting theories. As evaluation is differently perceived and
modeled among educational areas, it is not difficult to become trapped in
dilemmas, which reflects an epistemological weakness. Additionally, designing
and developing a computer-based learning scenario is not an easy task.
Advancing further, with end-users probing the system in realistic settings, is
even harder. Computer science research in evaluation faces an immense
challenge, having to cope with contributions from several conflicting and
controversial research fields. We believe that deep changes must be made in our
field if we are to advance beyond the CBT (computer-based training) learning
model and to build an adequate epistemology for this challenge. The first task
is to relocate our field by building upon recent results from philosophy,
psychology, social sciences, and engineering. In this article we locate
evaluation in respect to communication studies. Evaluation presupposes a
definition of goals to be reached, and we suggest that it is, by many means, a
silent communication between teacher and student, peers, and institutional
entities. If we accept that evaluation can be viewed as set of invisible rules
known by nobody, but somehow understood by everybody, we should add
anthropological inquiries to our research toolkit. The paper is organized
around some elements of the social communication and how they convey new
insights to evaluation research for computer and related scientists. We found
some technical limitations and offer discussions on how we relate to technology
at same time we establish expectancies and perceive others work.
","The purpose of this study is to examine the role that evaluation plays in communication between teachers and students during computer-based learning environments (CBLE). The research question guiding this investigation is: How does evaluation affect student-teacher interaction? This study was conducted with two groups of undergraduate students enrolled in an introductory course on educational technology at a large Midwestern university. Students were asked to complete three tasks using a CBLE called WebQuests, which are designed for use by students working individually or collaboratively. Data collection included audio recordings of group discussions, field notes taken by researchers observing each group's work, and students' written responses to questions posed throughout their participation in the project. Analysis revealed that evaluation played several roles within these interactions including providing feedback about individual performance; clarifying expectations; establishing ground rules; and promoting reflection. These findings suggest that evaluation can be used effectively to enhance student-teacher communication when it occurs frequently enough over time so that both parties have multiple opportunities to respond to one another.",arxiv,bigscience bloomz,706.1127,0.6111111111111112,0.29411764705882354,0.6871794871794872,0.4381270903010034,1,1,0,0,0,1,1,1,1,1,0.07234370086862095,0.04980252831647682,0.08949416342412451,0.030303030303030304,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1
Wavelet transforms in a critical interface model for Barkhausen noise,"  We discuss the application of wavelet transforms to a critical interface
model, which is known to provide a good description of Barkhausen noise in soft
ferromagnets. The two-dimensional version of the model (one-dimensional
interface) is considered, mainly in the adiabatic limit of very slow driving.
On length scales shorter than a crossover length (which grows with the strength
of surface tension), the effective interface roughness exponent $\zeta$ is
$\simeq 1.20$, close to the expected value for the universality class of the
quenched Edwards-Wilkinson model. We find that the waiting times between
avalanches are fully uncorrelated, as the wavelet transform of their
autocorrelations scales as white noise. Similarly, detrended size-size
correlations give a white-noise wavelet transform. Consideration of finite
driving rates, still deep within the intermittent regime, shows the wavelet
transform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies.
This behavior is ascribed to intra-avalanche correlations.
","We study the statistical properties of Barkhausen noise generated by an Ising spin system with random fields and competing interactions at its surface, using wavelets to analyze the time series produced by this model.  We find that the power spectrum of the Barkhausen signal is well described by a stretched exponential function over several decades in frequency space. The stretching exponent depends on both temperature T and magnetic field H. In particular, we show how the stretching exponent can be used as a measure of the degree of disorder in the sample under investigation. Finally, we discuss possible extensions of our work to other types of systems exhibiting avalanche dynamics. Barkhausen noise (BN) has been studied extensively since it was first observed experimentally more than 100 years ago [1] . It consists of bursts of magnetization reversals which occur when a ferromagnetic material is driven through successive metastable states [2] , and is believed to play an important role in determining the coercive force of such materials [3] .
The statistics of BN have attracted considerable interest recently [4] - [8] due to their potential application in non-destructive testing [9] . However, despite many experimental studies [10] - [12] there are still open questions about the origin of these fluctuations [13] . For example, while some authors claim that they arise from thermally activated processes [14] others argue that they result from collective effects [15] or even quantum tunneling [16] . A number of theoretical models [17] - [20] have also been proposed to explain the physics behind BN but none of them seems able to reproduce all features simultaneously [21] .",arxiv,bigscience bloomz,706.1574,0.3333333333333333,0.4453781512605043,0.11282051282051282,0.7333970377448639,1,1,0,0,0,1,1,0,0,0,0.11880183242717988,0.06189905065744696,0.09727626459143969,0.06060606060606061,1,0,1,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Spitzer Mid-Infrared Spectroscopy of Infrared Luminous Galaxies at z~2 II: Diagnostics,"  We present mid-IR spectral decomposition of a sample of 48 Spitzer-selected
ULIRGs spanning z~1-3 and likely L_IR~10^12-10^13Lsun. Our study aims at
quantifying the star-formation and AGN processes in these sources which recent
results suggest have evolved strongly between the observed epoch and today. To
do this, we study the mid-IR contribution of PAH emission, continuum, and
extinction. About 3/4 of our sample are continuum- (i.e. AGN) dominated
sources, but ~60% of these show PAH emission, suggesting the presence of
star-formation activity. These sources have redder mid-IR colors than typical
optically-selected quasars. About 25% of our sample have strong PAH emission,
but none are likely to be pure starbursts as reflected in their relatively high
5um hot dust continua. However, their steep 30um-to-14um slopes suggest that
star-formation might dominate the total infrared luminosity. Six of our z~2
sources have EW6.2>~0.3um and L_14um>~10^12Lsun (implying L_IR>~10^13Lsun). At
these luminosities, such high EW6.2 ULIRGs do not exist in the local Universe.
We find a median optical depth at 9.7um of <tau_9.7>=1.4. This is consistent
with local IRAS-selected ULIRGs, but differs from early results on
SCUBA-selected z~2 ULIRGs. Similar to local ULIRGs about 25% of our sample show
extreme obscuration (tau_9.7>~3) suggesting buried nuclei. In general, we find
that our sources are similar to local ULIRGs, but are an order of magnitude
more luminous. It is not clear whether our z~2 ULIRGs are simply scaled-up
versions of local ULIRGs, or subject to fundamentally different physical
processes.
","We present Spitzer mid-infrared spectroscopy for a sample of infrared luminous galaxies (LIRGs) and ultra-luminous infrared galaxies (ULIRGs). The sample is drawn from the Great Observatories Origins Deep Survey-North field, which has been observed with both IRAC and MIPS on board Spitzer Space Telescope as part of the GOODS survey program. We use these data to study the physical properties of dusty starbursts in distant galaxies by comparing their rest-frame 5-15 micron spectra against those of local ULIRGs. Our results show that most of our targets are dominated by PAH emission features similar to those seen in nearby ULIRGs. However, we also find some differences between high-z sources and local ULIRGs: 1) Most of the high-redshift objects have weaker silicate absorption feature than local ULIRGs do; 2) High-redshift sources tend to be more compact than local ULIRGS; 3) Some of them may contain an AGN component based on the detection of broad H$\alpha$ lines or strong continuum emission shortward of 9.7 um.",arxiv,bigscience bloomz,704.1765,0.7777777777777778,0.19327731092436976,0.6051282051282051,0.4180602006688964,1,1,0,0,0,1,1,1,0,0,0.05163075774995984,0.168669907552691,0.07392996108949416,0.18181818181818182,1,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SubmilliJansky Transients in Archival Radio Observations,"  [ABRIDGED] We report the results of a 944-epoch survey for transient sources
with archival data from the Very Large Array spanning 22 years with a typical
epoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a
single field of view with a full-width at half-maximum of 8.6' and 5.1',
respectively, and achieved a typical point-source detection threshold at the
beam center of ~300 microJy per epoch. Ten transient sources were detected with
a significance threshold such that only one false positive would be expected.
Of these transients, eight were detected in only a single epoch. Two transients
were too faint to be detected in individual epochs but were detected in
two-month averages. None of the ten transients was detected in longer-term
averages or associated with persistent emission in the deep image produced from
the combination of all epochs. The cumulative rate for the short timescale
radio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2
yr^-1, where the uncertainty is due to the unknown duration of the transients,
20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/-
0.4 transient per square degrees above a flux density of 370 microJy. Two
transients are associated with galaxies at z=0.040 and z=0.249. These may be
similar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB
980428. Six transients have no counterparts in the optical or infrared (R=27,
Ks=18). The hosts and progenitors of these transients are unknown.
","We have searched for radio transients with flux densities between 0.1 and 1 mJy at frequencies ranging from 4 to 8 GHz using archival data obtained by the Very Large Array (VLA) over the past 20 years. We find that most of these sources are extragalactic, but we also detect several Galactic objects including pulsars, supernova remnants, and flare stars. The majority of our sample is comprised of previously uncatalogued sources; however, we recover many known variable sources such as blazars and gamma-ray burst afterglows. Our results demonstrate the power of combining large amounts of archival VLA data into one coherent dataset. This work was supported by NSF grant AST-0907860. In this Letter, we present an analysis of all available archived Very Large Array (V LA) observations taken since 1990. These data were collected during various observing programs aimed primarily at studying distant galaxies or nearby star forming regions. However, they contain valuable information about fainter transient phenomena occurring within our Galaxy. By searching through more than 10 000 hours of observation time spread across nearly 2000 epochs, we identify thousands of new faint radio sources which appear only once or twice in each epoch's data set. Most of these sources are extragalaxtic, but we also detect numerous Galactic objects including pulsar wind nebulae, supernova remnants, flare stars, and other types of active galactic nuclei. Many of these newly discovered sources are not included in existing catalogs because their low signal-to-noise ratio makes them difficult to detect when observed individually. However, by combining multiple epochs together, we can boost the sensitivity of our survey enough to detect even very weak signals.",arxiv,bigscience bloomz,705.3158,0.6111111111111112,0.546218487394958,0.6820512820512821,0.7305303392259914,1,1,0,0,1,1,1,1,0,1,0.11555266309762396,0.07317649516926115,0.10116731517509728,0.07196969696969698,1,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Clustering Coefficients of Protein-Protein Interaction Networks,"  The properties of certain networks are determined by hidden variables that
are not explicitly measured. The conditional probability (propagator) that a
vertex with a given value of the hidden variable is connected to k of other
vertices determines all measurable properties. We study hidden variable models
and find an averaging approximation that enables us to obtain a general
analytical result for the propagator. Analytic results showing the validity of
the approximation are obtained. We apply hidden variable models to
protein-protein interaction networks (PINs) in which the hidden variable is the
association free-energy, determined by distributions that depend on
biochemistry and evolution. We compute degree distributions as well as
clustering coefficients of several PINs of different species; good agreement
with measured data is obtained. For the human interactome two different
parameter sets give the same degree distributions, but the computed clustering
coefficients differ by a factor of about two. This shows that degree
distributions are not sufficient to determine the properties of PINs.
","We study the clustering coefficients of protein-protein interaction networks (PPINs) and their relationship with network topological properties, such as degree distribution and average path length. We find that PPINs have higher clustering coefficients than random graphs with similar degrees or scale-free networks generated by Barabasi-Albert model. The high clustering coefficient is mainly due to the existence of many triangles in these networks. In addition, we show that the clustering coefficients are correlated positively with the number of proteins but negatively with the number of interactions per protein. These results suggest that there may be some common mechanisms underlying the formation of both triangles and edges between two nodes with large degrees. Finally, we propose an algorithm for identifying functional modules based on local clustering analysis. Our method can identify clusters with different sizes and shapes. Clustering coefficients of protein-protein interactomes are studied. It is found that they are significantly larger than those of random graphs with same degree distributions or scale-free networks generated using Barabasi-Albert preferential attachment rule. High clustering coefficients are mainly caused by the presence of many triangles in these systems. Correlations between clustering coefficients and other topological parameters are also investigated. An algorithm for finding functional modules based on local cluster analysis is proposed.",arxiv,bigscience bloomz,704.3748,0.3888888888888889,0.546218487394958,0.2,0.5470616340181558,1,1,1,0,0,1,1,0,0,0,0.06685484012787934,0.05626081182746418,0.08171206225680934,0.056818181818181816,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
The Gemini Deep Planet Survey -- GDPS,"  We present the results of the Gemini Deep Planet Survey, a near-infrared
adaptive optics search for giant planets and brown dwarfs around nearby young
stars. The observations were obtained with the Altair adaptive optics system at
the Gemini North telescope and angular differential imaging was used to
suppress the speckle noise of the central star. Detection limits for the 85
stars observed are presented, along with a list of all faint point sources
detected around them. Typically, the observations are sensitive to angular
separations beyond 0.5"" with 5-sigma contrast sensitivities in magnitude
difference at 1.6 micron of 9.5 at 0.5"", 12.9 at 1"", 15.0 at 2"", and 16.5 at
5"". For the typical target of the survey, a 100 Myr old K0 star located 22 pc
from the Sun, the observations are sensitive enough to detect planets more
massive than 2 Mjup with a projected separation in the range 40-200 AU. Second
epoch observations of 48 stars with candidates (out of 54) have confirmed that
all candidates are unrelated background stars. A detailed statistical analysis
of the survey results, yielding upper limits on the fractions of stars with
giant planet or low mass brown dwarf companions, is presented. Assuming a
planet mass distribution dN/dm m^{-1.2} and a semi-major axis distribution
dN/da a^{-1}, the 95% credible upper limits on the fraction of stars with at
least one planet of mass 0.5-13 Mjup are 0.28 for the range 10-25 AU, 0.13 for
25-50 AU, and 0.093 for 50-250 AU. The 95% credible interval for the fraction
of stars with at least one brown dwarf companion having a semi-major axis in
the range 25-250 AU is 0.019 (-0.015/+0.083), irrespective of any assumption on
the mass and semi-major axis distributions. The stars HD 14802, HD 166181, and
HD 213845 have been resolved into binaries for the first time.
","The Gemini Deep Planet Survey (GDPS) is an ongoing survey for transiting planets around bright stars using the twin 8-meter telescopes at Gemini Observatory in Hawaii and Chile.  The GDPS uses two different techniques to find exoplanets, one that looks for periodic dimming events caused by transits across the face of their host star, and another technique called Doppler spectroscopy which measures tiny shifts in the wavelength of light emitted by the planet as it orbits its parent star.   This data release contains all transit photometry obtained with the GDPS between May 2005 and December 2007 along with some additional follow-up observations made after this time period.    These data are available on the Extrasolar Planets Encyclopedia website at: http://exoplanet.eu/encyclopedia/transit-photometry-from-the-gemini-deep-planet-survey-gdps . 
This data set includes more than 1 million individual measurements taken over nearly 1000 nights of observation.  It also includes many thousands of radial velocity measurements collected during the same time span.  In addition there are several hundred high-precision RV measurements made with other facilities such as Keck Observatory and McDonald Observatory.  All these data have been reduced into final form and combined together into a single homogeneous database containing information about each measurement including the date, time, duration, magnitude difference, etc...",arxiv,bigscience bloomz,705.429,0.5,0.3445378151260504,0.9282051282051282,0.5327281414237937,1,1,0,0,0,1,1,1,0,0,0.11630907399760869,0.10372215124862423,0.11673151750972763,0.07954545454545454,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Magnetorotational Collapse of Population III Stars,"  We perform a series of two-dimensional magnetorotational core-collapse
simulations of Pop III stars. Changing the initial distributions of rotation
and magnetic fields prior to collapse in a parametric manner, we compute 19
models. By so doing, we systematically investigate how rotation and magnetic
fields affect the collapse dynamics and explore how the properties of the
black-hole formations and neutrino emissions could be affected. As for the
microphysics, we employ a realistic equation of state and approximate the
neutrino transfer by a multiflavour leakage scheme. With these computations, we
find that the jet-like explosions are obtained by the magnetodriven shock waves
if the initial magnetic field is as large as $10^{12}$ G. We point out that the
black-hole masses at the formation decrease with the initial field strength, on
the other hand, increase with the initial rotation rates. As for the neutrino
properties, we point out that the degree of the differential rotation plays an
important role to determine which species of the neutrino luminosity is more
dominant than the others. Furthermore, we find that the stronger magnetic
fields make the peak neutrino luminosities smaller, because the magnetic
pressure acts to halt the collapse in the central regions, leading to the
suppression of the releasable gravitational binding energies.
","We present the results of our numerical simulations of magnetorotational collapse (MRC) in primordial stars with initial masses between 100 and 1000 M⊙, which are formed at redshifts z = 20 − 30. We find that for all models considered here, magnetic fields play an important role during the formation process of black holes. The final mass of the central object is determined by the strength of the magnetic field. For weak magnetic fields (B < 10^10 G), we obtain stellar-mass black holes; while for stronger fields (B > 10^{10}G), supermassive black holes form. In addition to this effect on the final mass, magnetic fields also affect the angular momentum distribution inside the collapsing star. This leads to different spin parameters of the resulting black hole depending on its progenitor's initial mass. 
 
 Keywords: Black Hole, Primordial Star Formation, Magnetohydrodynamics",arxiv,bigscience bloomz,704.1945,0.3333333333333333,0.29411764705882354,0.4307692307692308,0.3521261347348304,0,1,0,0,0,1,1,1,0,1,0.14069226016486647,0.07723503861707398,0.1517509727626459,0.056818181818181816,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
The Complexity of Model Checking Higher-Order Fixpoint Logic,"  Higher-Order Fixpoint Logic (HFL) is a hybrid of the simply typed
\lambda-calculus and the modal \lambda-calculus. This makes it a highly
expressive temporal logic that is capable of expressing various interesting
correctness properties of programs that are not expressible in the modal
\lambda-calculus.
  This paper provides complexity results for its model checking problem. In
particular we consider those fragments of HFL built by using only types of
bounded order k and arity m. We establish k-fold exponential time completeness
for model checking each such fragment. For the upper bound we use fixpoint
elimination to obtain reachability games that are singly-exponential in the
size of the formula and k-fold exponential in the size of the underlying
transition system. These games can be solved in deterministic linear time. As a
simple consequence, we obtain an exponential time upper bound on the expression
complexity of each such fragment.
  The lower bound is established by a reduction from the word problem for
alternating (k-1)-fold exponential space bounded Turing Machines. Since there
are fixed machines of that type whose word problems are already hard with
respect to k-fold exponential time, we obtain, as a corollary, k-fold
exponential time completeness for the data complexity of our fragments of HFL,
provided m exceeds 3. This also yields a hierarchy result in expressive power.
","We study the complexity of model checking higher-order fixpoint logic (HFL) over finite Kripke structures, which is an extension of propositional modal logic with fixpoints and quantification over state variables ranging over infinite domains. We show that HFL satisfiability can be reduced to the problem of deciding whether there exists a solution for a system of linear equations in rational numbers whose coefficients are given by polynomials over integers. This reduction allows us to obtain lower bounds on the computational complexity of HFL satisfiability using known results about solving systems of polynomial equations. In particular, we prove PSPACE-hardness of HFL satisfiability when the number of fixpoint operators occurring in the formula is unbounded or restricted only to existential ones. On the other hand, we provide a simple algorithm for HFL satisfiability based on computing least solutions of certain systems of integer quadratic equations. The running time of this algorithm depends exponentially on the maximum degree of these equations but it does not depend on the number of fixpoint",arxiv,bigscience bloomz,704.3931,0.5,0.24369747899159663,0.47692307692307695,0.43526039178213094,1,1,0,0,0,1,1,0,0,0,0.10991487682501293,0.04307881438950004,0.14396887159533073,0.026515151515151516,2,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Signatures of SUSY Dark Matter at the LHC and in the Spectra of Cosmic Rays,"  This thesis discusses the search for supersymmetry at the future Large Hadron
Collider (LHC) and the ongoing construction of one of the four large LHC
experiments, the Compact Muon Solenoid (CMS), and focuses on the detection of
signals from the annihilation of supersymmetric dark matter in the spectra of
cosmic rays.
  Measurements of cosmic ray antiparticles, such as positrons, can impose
strong constraints on the nature of new physics beyond the Standard Model.
However, cosmic ray positron measurements are experimentally very challenging
due to the vast proton background. A novel approach of positron identification
with the space-borne AMS-01 experiment, namely through the detection of
bremsstrahlung conversion in a silicon microstrip detector, is introduced.
Bremsstrahlung from protons is suppressed by a factor of more than 3*10^6 with
respect to positrons. The results of the positron measurement show that the
bremsstrahlung approach extends the sensitivity range of AMS-01 to positron
momenta up to 50 GeV/c, which is far beyond the original scope of the
experiment. At momenta above 8 GeV/c there is indication for a positron
overabundance with respect to model predictions for purely secondary positron
production. Therefore, the AMS-01 data lend further weight to the hints of a
positron overabundance seen in the data from earlier experiments.
  The positron fraction measurements from the most recent experiments are
combined with the results of this analysis, giving the most precise positron
fraction data yet available.
","The Large Hadron Collider (LHC) is expected to produce new particles that could be dark matter candidates, such as supersymmetric partners of quarks or leptons.  In this talk I will discuss how these signatures can be searched for using data collected by the ATLAS experiment during Run 1 of the LHC. The results are presented both in terms of limits on production cross sections and mass exclusion regions. Finally, prospects for future searches with Run 2 data are discussed. This work was performed within the framework of the PhD thesis of M.A.M., supervised by A.S.. 
Introduction

Dark Matter Candidates

Supersymmetry

ATLAS Experiment

Run 1 Results

Prospects for Run 2 Searches

Conclusions & Outlook 

References 


Acknowledgements





- - - - - - - -- - - - - - --- - - - - - ---- - - - - - ----- - - - - - ------ - - - - - -------- - - - - - ---------- - - - - - ------------------ - - - - - -------------- - - - - - ----------------------------------- - - - - - ----------------------------------------------------- - - - - - ------------------------------------------------------------------------------------ - - - - -",arxiv,bigscience bloomz,704.3943,0.4444444444444444,0.0,0.558974358974359,0.0,1,1,0,0,0,1,1,0,0,0,0.1123238110521042,0.0,0.12840466926070038,0.7992424242424242,0,8,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3,1,12,1,1
Universality of the REM for dynamics of mean-field spin glasses,"  We consider a version of a Glauber dynamics for a p-spin
Sherrington--Kirkpatrick model of a spin glass that can be seen as a time
change of simple random walk on the N-dimensional hypercube. We show that, for
any p>2 and any inverse temperature \beta>0, there exist constants g>0, such
that for all exponential time scales, $\exp(\gamma N)$, with $\gamma< g$, the
properly rescaled clock process (time-change process), converges to an
\alpha-stable subordinator where \alpha=\gamma/\beta^2<1. Moreover, the
dynamics exhibits aging at these time scales with time-time correlation
function converging to the arcsine law of this \alpha-stable subordinator. In
other words, up to rescaling, on these time scales (that are shorter than the
equilibration time of the system), the dynamics of p-spin models ages in the
same way as the REM, and by extension Bouchaud's REM-like trap model,
confirming the latter as a universal aging mechanism for a wide range of
systems. The SK model (the case p=2) seems to belong to a different
universality class.
","We study the relaxation behavior in the Random Energy Model (REM) with an external magnetic field, which is one of the simplest models to describe glassy phenomena. We show that the relaxation time distribution function has a universal form independent of temperature and system size by using numerical simulations on finite-dimensional systems up to dimension d = 8. The universality holds even when we take into account the effect of quenched disorder. This result suggests that the relaxation process in this model can be described as a superposition of many processes each of which obeys the same scaling law. In addition, we find that the relaxation time distribution functions at different temperatures are well fitted by a stretched exponential function. These results suggest that the relaxation process in our model is governed by a broad spectrum of relaxation times. Introduction:-The Random Energy Model(REM), proposed by Derrida [1] ,is one of the simplest models describing glassy phenomena [2] .In this model,the energy landscape consists of N local minima whose energies are randomly distributed according to some probability density P(E).Each minimum corresponds to a metastable state and its lifetime τi is determined by the Arrhenius law exp[−Ei/kBT ] where Ei denotes the activation energy barrier between two neighboring states i and j.It was shown numerically [3] that the relaxation time distribution follows a power-law decaying function f (τ ) ∝ 1/τ 1+α with α ≈ 1.3 − 2 depending on the dimensionality of the system [4] .
Recently it was found [5] that the relaxation time distribution also follows a power-law decay if we consider the case without any quenched disorder but with a random initial condition instead.This indicates that the relaxation process in the REM is dominated by activated events over barriers separating different metastable states [6] .However,it should be noted that these studies were performed only for low dimensions such as d ≤ 4 [7, 8] .Therefore,in order to understand the nature of glassy phenomena more clearly,we need to investigate whether or not the above mentioned results hold true in higher dimensions.",arxiv,bigscience bloomz,706.2135,0.2222222222222222,0.3445378151260504,0.21025641025641026,0.9340659340659341,1,1,0,0,1,1,1,1,0,0,0.1951305050290185,0.37144304473911427,0.17898832684824903,0.4015151515151515,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
XMM-Newton observations of the first unidentified TeV gamma-ray source TeV J2032+4130,"  (abridged) The first unidentified very high energy gamma ray source (TeV
J2032+4130) in the Cygnus region has been the subject of intensive search for a
counterpart source at other wavelengths. A deep ($\approx 50$ ksec) exposure of
TeV J2032+4130 with \textit{XMM-Newton} has been obtained. The contribution of
point sources to the observed X-ray emission from TeV J2032+4130 is subtracted
from the data. The point-source subtracted X-ray data are analyzed using blank
sky exposures and regions adjacent to the position of TeV J2032+4130 in the
field of view covered by the XMM-Newton telescopes to search for diffuse X-ray
emission. An extended X-ray emission region with a full width half maximum
(FWHM) size of $\approx 12$ arc min is found. The centroid of the emission is
co-located with the position of TeV J2032+4130.The energy spectrum of the
emission coinciding with the position and extension of TeV J2032+4130 can be
modeled by a power-law model with a photon index
$\Gamma=1.5\pm0.2_\mathrm{stat}\pm0.3_\mathrm{sys}$ and an energy flux
integrated between 2 and 10 keV of $f_{2-10 \mathrm{keV}} \approx 7\cdot
10^{-13}$ ergs/(cm$^2$ s) which is lower than the very high energy gamma-ray
flux observed from TeV J2032+4130. We conclude that the faint extended X-ray
emission discovered in this observation is the X-ray counterpart of TeV
J2032+4130. Formally, it can not be excluded that the extended emission is due
to an unrelated population of faint, hot ($k_BT\approx 10$ keV) unresolved
point-sources which by chance coincides with the position and extension of TeV
J2032+4130. We discuss our findings in the frame of both hadronic and leptonic
gamma-ray production scenarios.
","We report on XMM-Newton and Chandra X-ray Observatory (CXO) observations of the recently discovered high-energy gamma-ray source, TeV J2032+4131. The data show that this object is an active galactic nucleus with a power-law spectrum extending to at least 100 keV. We find no evidence for absorption by intervening material in excess of Galactic values along its line-of-sight. A comparison between our results and those obtained using other instruments suggests that there may be significant variability in both the flux density and spectral index of TeV J2032 + 4131 over timescales as short as one day. This would imply either rapid changes in intrinsic emission or strong Doppler boosting effects due to relativistic motion of the emitting region. 
 
 Keywords: Active galactic nuclei, Gamma rays, Variability, X-rays, High energy astrophysics 
 
 1. Introduction 
 
 In recent years, several new classes of high energy sources have been identified through their detection at very-high energies (E > 10 GeV). These include blazars, radio galaxies, pulsar wind nebulae, supernova remnants, starburst galaxies, galaxy clusters, and possibly even some nearby stars [1] . However, many of these objects are still poorly understood because they lack counterparts at lower frequencies where most of the relevant physical processes occur [2] .
 
In particular, it has proven difficult to identify the origin of the highest energy photons detected so far [3] , which can reach energies up to 1020 eV [4] . One possible explanation is that such photons are produced during interactions involving extremely energetic particles accelerated within compact regions close to supermassive black holes [5] . Alternatively, they could result from decays of neutral pions created when cosmic ray protons interact with ambient matter [6] . If confirmed, such events would provide important insights into particle acceleration mechanisms near black holes [7, 8] . 
 
 Recently, the HESS collaboration reported the discovery of a bright point-like gammaray source located at RA = 20 h 32 m 41 s ± 5′′ and Dec = +39°30′00",arxiv,bigscience bloomz,705.0009,0.4444444444444444,0.6470588235294118,0.6974358974358974,0.8824653607262303,1,1,0,0,0,1,1,1,0,0,0.23052392822715878,0.04819873949034576,0.3035019455252918,0.06439393939393939,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Lifetime Improvement of Wireless Sensor Networks by Collaborative Beamforming and Cooperative Transmission,"  Extending network lifetime of battery-operated devices is a key design issue
that allows uninterrupted information exchange among distributive nodes in
wireless sensor networks. Collaborative beamforming (CB) and cooperative
transmission (CT) have recently emerged as new communication techniques that
enable and leverage effective resource sharing among collaborative/cooperative
nodes. In this paper, we seek to maximize the lifetime of sensor networks by
using the new idea that closely located nodes can use CB/CT to reduce the load
or even avoid packet forwarding requests to nodes that have critical battery
life. First, we study the effectiveness of CB/CT to improve the signal strength
at a faraway destination using energy in nearby nodes. Then, a 2D disk case is
analyzed to assess the resulting performance improvement. For general networks,
if information-generation rates are fixed, the new routing problem is
formulated as a linear programming problem; otherwise, the cost for routing is
dynamically adjusted according to the amount of energy remaining and the
effectiveness of CB/CT. From the analysis and simulation results, it is seen
that the proposed schemes can improve the lifetime by about 90% in the 2D disk
network and by about 10% in the general networks, compared to existing schemes.
","In this work, we propose an energy-efficient cooperative transmission scheme for wireless sensor networks (WSNs). The proposed scheme is based on the combination of collaborative beamforming at the source node with cooperative transmission to multiple relay nodes in order to improve lifetime performance. In particular, the source node first transmits data packets using its maximum power level. Then, it switches to lower power levels if no packet has been successfully received within a certain time period. If one or more packets are successfully decoded, then the source node increases its transmit power back up to the previous value. We derive closed-form expressions for outage probability as well as average throughput under Rayleigh fading channels. Our results show that our proposed scheme can significantly increase network lifetime compared to conventional schemes without compromising system reliability. Finally, numerical examples are provided to verify the theoretical analysis. Keywords: Lifetime improvement; Relay selection; Energy efficiency; Outage probability",arxiv,bigscience bloomz,704.3396,0.3333333333333333,0.3949579831932773,0.38461538461538464,0.3922599139990445,1,1,1,0,0,1,1,1,0,0,0.10340927876418568,0.04086581712127392,0.11284046692607004,0.03409090909090909,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Evolutionary Neural Gas (ENG): A Model of Self Organizing Network from Input Categorization,"  Despite their claimed biological plausibility, most self organizing networks
have strict topological constraints and consequently they cannot take into
account a wide range of external stimuli. Furthermore their evolution is
conditioned by deterministic laws which often are not correlated with the
structural parameters and the global status of the network, as it should happen
in a real biological system. In nature the environmental inputs are noise
affected and fuzzy. Which thing sets the problem to investigate the possibility
of emergent behaviour in a not strictly constrained net and subjected to
different inputs. It is here presented a new model of Evolutionary Neural Gas
(ENG) with any topological constraints, trained by probabilistic laws depending
on the local distortion errors and the network dimension. The network is
considered as a population of nodes that coexist in an ecosystem sharing local
and global resources. Those particular features allow the network to quickly
adapt to the environment, according to its dimensions. The ENG model analysis
shows that the net evolves as a scale-free graph, and justifies in a deeply
physical sense- the term gas here used.
","In this work, we propose an evolutionary neural gas model for input categorization and clustering in the context of self-organizing networks. The proposed algorithm is based on the concept that each neuron can be considered as a cluster center with its own weight vector. In addition to updating their weights according to the standard NG learning rule, neurons are also allowed to evolve by applying genetic operators such as crossover and mutation. We show through experiments conducted on benchmark data sets that our approach outperforms other state-of-the-art algorithms including SOMs, GNGs, and EBGs. Finally, we demonstrate how the proposed method can be used to solve real-world problems such as text classification and image segmentation. Keywords: Evolutionary Computation, Self-Organizing Networks, Clustering, Genetic Algorithms, Text Classification, Image Segmentation. 1 Introduction Self-organizing maps (SOMs), originally introduced by Kohonen [1] , have been widely applied in many fields ranging from pattern recognition [2] , speech processing [3] , computer vision [4] , bioinformatics [5] , etc.. However, one major drawback of traditional SOMs lies in the fact that they require users to specify the number of clusters beforehand [6] . To overcome this problem, several extensions of SOMs were developed [7, 8] .
Among these extensions, growing neural gas (GNG) [9] has attracted much attention due to its ability to automatically determine the optimal number of clusters during training [10] . Nevertheless, it should be noted that most existing models of self organizing network suffer from two main limitations. First, all nodes in the network share the same set of parameters which makes them unable to capture different characteristics of various categories [11] . Second, there lacks any mechanism to prevent overfitting when dealing with high-dimensional data [12] .",arxiv,bigscience bloomz,704.0598,0.3888888888888889,0.596638655462185,0.30256410256410254,0.7706641184902054,1,1,0,0,0,1,1,1,0,0,0.07399695558775696,0.0713729486768591,0.0933852140077821,0.10227272727272728,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
QCD Approach to B->D \pi Decays and CP Violation,"  The branching ratios and CP violations of the $B\to D\pi$ decays, including
both the color-allowed and the color-suppressed modes, are investigated in
detail within QCD framework by considering all diagrams which lead to three
effective currents of two quarks. An intrinsic mass scale as a dynamical gluon
mass is introduced to treat the infrared divergence caused by the soft
collinear approximation in the endpoint regions, and the Cutkosky rule is
adopted to deal with a physical-region singularity of the on mass-shell quark
propagators. When the dynamical gluon mass $\mu_g$ is regarded as a universal
scale, it is extracted to be around $\mu_g = 440$ MeV from one of the
well-measured $B\to D\pi$ decay modes. The resulting predictions for all
branching ratios are in agreement with the current experimental measurements.
As these decays have no penguin contributions, there are no direct $CP$
asymmetries. Due to interference between the Cabibbo-suppressed and the
Cabibbo-favored amplitudes, mixing-induced CP violations are predicted in the
$B\to D^{\pm}\pi^{\mp}$ decays to be consistent with the experimental data at
1-$\sigma$ level. More precise measurements will be helpful to extract weak
angle $2\beta+\gamma$.
","We present the results on the decay amplitudes for B -> D pi decays in the framework of QCD factorization approach, including both perturbative corrections at one-loop level and nonperturbative contributions from light-cone distribution amplitudes (LCDAs) of pion and kaon. We find that the branching ratios are sensitive to the values of LCDAs parameters. The direct CP asymmetries depend strongly on the relative phase between penguin and tree diagrams. Our numerical results show that the theoretical predictions agree well with experimental data within errors. 
 
 Introduction 
 
 In recent years there has been great progresses made in understanding heavy flavor physics through experiments performed by BaBar [1] , Belle [2] , CLEO [3] and LHCb [4] Collaborations. Many interesting phenomena have been observed such as large CP violation effects in B mesons [5] . It is therefore important to study these processes theoretically so as to understand their underlying dynamics better. Among them, B → DPi decays play an essential role since they can be used to extract information about CKM matrix elements Vub and Vtd [6] . 
 
 In this work we will calculate the decay amplitudes for B→DPi decays using the method of QCD factorization [7, 8] which was first proposed by Beneke et al [9] . This method takes into account all possible Feynman graphs contributing to the process under consideration and then separates out soft divergences appearing in loop integrals into universal functions called light cone distribution amplitudes(LCDA). These LCDA's contain only non-perturbative information and can be calculated either by lattice simulations or extracted from experiment [10] . After separating out the soft divergences, hard scattering kernels containing collinear singularities remain and need to be evaluated order-by-order in perturbation theory [11] . 
Theoretical Framework

B→DPi Decay Amplitudes
In the rest frame of B-meson, the differential decay widths for B→DPi can be written as:",arxiv,bigscience bloomz,705.1575,0.3333333333333333,0.29411764705882354,0.3076923076923077,0.38939321548017203,0,1,0,0,0,1,2,1,0,1,0.13314527609238527,0.047858552750413806,0.11673151750972763,0.09848484848484848,0,1,4,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1
An Adaptive Strategy for the Classification of G-Protein Coupled Receptors,"  One of the major problems in computational biology is the inability of
existing classification models to incorporate expanding and new domain
knowledge. This problem of static classification models is addressed in this
paper by the introduction of incremental learning for problems in
bioinformatics. Many machine learning tools have been applied to this problem
using static machine learning structures such as neural networks or support
vector machines that are unable to accommodate new information into their
existing models. We utilize the fuzzy ARTMAP as an alternate machine learning
system that has the ability of incrementally learning new data as it becomes
available. The fuzzy ARTMAP is found to be comparable to many of the widespread
machine learning systems. The use of an evolutionary strategy in the selection
and combination of individual classifiers into an ensemble system, coupled with
the incremental learning ability of the fuzzy ARTMAP is proven to be suitable
as a pattern classifier. The algorithm presented is tested using data from the
G-Coupled Protein Receptors Database and shows good accuracy of 83%. The system
presented is also generally applicable, and can be used in problems in genomics
and proteomics.
","G-protein-coupled receptors (GPCRs) are one of the largest families of cell surface proteins and play an important role in many physiological processes, including vision, olfaction, taste, hormone secretion, neurotransmission, immune response, inflammation, and cancer.  The number of known human GPCR sequences has increased dramatically over recent years due to advances in genome sequencing technologies; however, only about half have been functionally characterized so far. In this study we present a novel computational method that can be used to predict the functional class of uncharacterized GPCRs based on their sequence similarity with other members within each subfamily. Our approach is based on two key ideas: 1) We use a new adaptive strategy to select representative sequences from different subfamilies by considering both the diversity among them as well as their evolutionary relationships; 2) We develop a new scoring scheme which takes into account not only the pairwise sequence similarities but also the structural information between query and template sequences. Using our method, we were able to successfully classify more than 80% of all human GPCRs whose functions had previously been experimentally determined.",arxiv,bigscience bloomz,704.3453,0.3888888888888889,0.19327731092436976,0.3435897435897436,0.47252747252747257,0,1,0,0,0,1,1,1,0,0,0.0702430874878746,0.12484659667018945,0.08560311284046693,0.14015151515151514,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Sedentary Survey of Extreme High Energy Peaked BL Lacs III. Results from Optical Spectroscopy,"  The multi-frequency Sedentary Survey is a flux limited, statistically
well-defined sample of highly X-ray dominated BL Lacertae objects (HBLs) which
includes 150 sources. In this paper, the third of the series, we report the
results of a dedicated optical spectroscopy campaign that, together with
results from other independent optical follow up programs, led to the
spectroscopic identification of all sources in the sample. We carried out a
systematic spectroscopic campaign for the observation of all unidentified
objects of the sample using the ESO 3.6m, the KPNO 4m, and the TNG optical
telescopes. We present new identifications and optical spectra for 76 sources,
50 of which are new BL Lac objects, 18 are sources previously referred as BL
Lacs but for which no redshift information was available, and 8 are broad
emission lines AGNs. We find that the multi-frequency selection technique used
to build the survey is highly efficient (about 90%) in selecting BL Lacs
objects. We present positional and spectroscopic information for all confirmed
BL Lac objects. Our data allowed us to determined 36 redshifts out of the 50
new BL Lacs and 5 new redshifts for the previously known objects. The redshift
distribution of the complete sample is presented and compared with that of
other BL Lacs samples. For 26 sources without recognizable absorption features,
we calculated lower limits to the redshift using a method based on simulated
optical spectra with different ratios between jet and galaxy emission. For a
subsample of 38 object with high-quality spectra, we find a correlation between
the optical spectral slope, the 1.4 GHz radio luminosity, and the Ca H&K break
value, indicating that for powerful/beamed sources the optical light is
dominated by the non-thermal emission from the jet.
","We present optical spectroscopic observations for the sample of 14 extreme high energy peaked BL Lac objects (EHBLs) selected by Costamante et al. (2013) . The main goal is to study their host galaxy properties and investigate possible differences with respect to lower-energy blazars, which are known to be hosted in elliptical galaxies. We find that all EHBLs have redshifts between 0.1 and 1.0, consistent with previous results on this class of sources. All but one source show evidence of being hosted in spiral or irregular galaxies; only PKS 0537-441 shows an elliptical-like spectrum. This result suggests that there may not exist any significant difference in the hosts of low-and high-energy blazars as previously claimed. However, we note that our sample size is small and further studies will be needed before drawing firm conclusions. 
 
 Keywords: Blazar, Host Galaxy",arxiv,bigscience bloomz,704.1729,0.5,0.3445378151260504,0.8307692307692308,0.34925943621595795,1,1,0,0,0,1,1,1,0,0,0.11478137570524885,0.07311563863364362,0.08171206225680934,0.08333333333333333,0,2,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Optical BVI Imaging and HI Synthesis Observations of the Dwarf Irregular Galaxy ESO 364-G 029,"  As part of an effort to enlarge the number of well-studied Magellanic-type
galaxies, we obtained broadband optical imaging and neutral hydrogen radio
synthesis observations of the dwarf irregular galaxy ESO 364-G 029. The optical
morphology characteristically shows a bar-like main body with a one-sided
spiral arm, an approximately exponential light distribution, and offset
photometric and kinematic centers. The HI distribution is mildly asymmetric
and, although slightly offset from the photometric center, roughly follows the
optical brightness distribution, extending to over 1.2 Holmberg radii (where
mu_B = 26.5 mag/arcsec^2). In particular, the highest HI column densities
closely follow the bar, one-arm spiral, and a third optical extension. The
rotation is solid-body in the inner parts but flattens outside of the optical
extent. The total HI flux F_HI = 23.1 pm 1.2 Jy km/s, yielding a total HI mass
M_HI= (6.4 pm 1.7) x 10^8 Msun (for a distance D = 10.8 pm 1.4 Mpc) and a total
HI mass-to-blue-luminosity ratio M_HI/L_B = (0.96 pm 0.14) Msun / Lsun,B
(distance independent). The HI data suggest a very complex small-scale HI
structure, with evidence of large shells and/or holes, but deeper observations
are required for a detailed study. Follow-up observations are also desirable
for a proper comparison with the Large Magellanic Cloud, where despite an
optical morphology very similar to ESO 364-G 029 the HI bears little
resemblance to the optical.
","We present optical BVRI imaging, near-infrared JHKs photometry, and radio continuum observations at 1.4 GHz for the dwarf irregular galaxy ESO 364-G 029 (UGC 6456). The new data are combined with existing Hα spectroscopy to study its star formation history over the past few hundred million years. We find that this galaxy has experienced several bursts of intense star formation in recent times, which have produced large amounts of ionized gas visible as bright knots of emission across most of the face-on disk. These knots appear to be associated with young massive stars formed during each episode of star formation. In addition, we detect an extended component of diffuse ionized gas surrounding these knots. This is likely due to photoionization by hot evolved stars or supernovae remnants. Using our deepest images taken under good seeing conditions, we measure a total stellar mass of M = 2.1 × 10^7 M_sol within a radius of 5 kpc.",arxiv,bigscience bloomz,704.305,0.3888888888888889,0.29411764705882354,0.5384615384615384,0.39799331103678937,1,1,0,0,0,1,1,0,0,0,0.11804320865200837,0.06876058889533798,0.17120622568093385,0.06060606060606061,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The subpulse modulation properties of pulsars at 92 cm and the frequency dependence of subpulse modulation,"  A large sample of pulsars has been observed to study their subpulse
modulation at an observing wavelength (when achievable) of both 21 and 92 cm
using the Westerbork Synthesis Radio Telescope. In this paper we present the
92-cm data and a comparison is made with the already published 21-cm results.
We analysed 191 pulsars at 92 cm using fluctuation spectra. The sample of
pulsars is as unbiased as possible towards any particular pulsar
characteristics. For 15 pulsars drifting subpulses are discovered for the first
time and 26 of the new drifters found in the 21-cm data are confirmed. We
discovered nulling for 8 sources and 8 pulsars are found to intermittently emit
single pulses that have pulse energies similar to giant pulses. It is estimated
that at least half of the total population of pulsars have drifting subpulses
when observations with a high enough signal-to-noise ratio would be available.
It could well be that the drifting subpulse mechanism is an intrinsic property
of the emission mechanism itself, although for some pulsars it is difficult or
impossible to detect. Drifting subpulses are in general found at both
frequencies, although the chance of detecting drifting subpulses is possibly
slightly higher at 92 cm. It appears that the youngest pulsars have the most
disordered subpulses and the subpulses become more and more organized into
drifting subpulses as the pulsar ages. The correlations with the modulation
indices are argued to be consistent with the picture in which the radio
emission can be divided in a drifting subpulse signal plus a quasi-steady
signal which becomes, on average, stronger at high observing frequencies. The
measured values of P3 at the two frequencies are highly correlated, but there
is no evidence for a correlation with other pulsar parameters.
","We have studied the pulse-to-pulse intensity variations in two pulsars, PSR B0826-34 and PSR B1133+16, using data obtained with the Parkes radio telescope at 1.4 GHz (92cm) and 2.7GHz(36cm). We find that both pulsars show strong evidence for subpulse drift bands which are modulated by an underlying pattern of weaker emission. The observed patterns can be explained as due to interference between different modes of emission within each beam. In addition we find that there is no significant difference in the subpulse modulation properties when comparing observations made at 36cm and those made at 92cm. This suggests that the physical processes responsible for producing these phenomena operate over a wide range of frequencies. These results provide further support for the idea that the phenomenon known as drifting subpulses may arise through some form of plasma instability operating on the open field lines near the magnetic poles of neutron stars. 
 
 Keywords: Pulsar",arxiv,bigscience bloomz,704.3572,0.6111111111111112,0.29411764705882354,0.8615384615384616,0.38652651696129964,1,1,0,0,0,1,1,1,0,0,0.07709278158582604,0.09340301825442246,0.06614785992217899,0.11363636363636363,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Origin of which-way information and generalization of the Born rule,"  The possibility to recover the which-way information, for example in the two
slit experiment, is based on a natural but implicit assumption about the
position of a particle {\it before} a position measurement is performed on it.
This assumption cannot be deduced from the standard postulates of quantum
mechanics. In the present paper this assumption is made explicit and formally
postulated as a new rule, the {\it quantum typicality rule}. This rule
correlates the positions of the particles at two different times, thus defining
their trajectories. Unexpectedly, this rule is also equivalent to the Born rule
with regard to the explanation of the results of statistical experiments. For
this reason it can be considered a generalization of the Born rule. The
existence of the quantum typicality rule strongly suggests the possibility of a
new trajectory-based formulation of quantum mechanics. According to this new
formulation, a closed quantum system is represented as a {\it quantum process},
which corresponds to a canonical stochastic process in which the probability
measure is replaced by the wave function and the usual frequentist
interpretation of probability is replaced by the quantum typicality rule.
","We present an argument for why quantum mechanics is nonlocal, based on the fact that it allows one to predict with certainty whether or not a measurement will be made in any given experiment. We show how this can lead to superluminal communication between two parties sharing entangled particles by using only local operations and classical communication (LOCC). Finally we generalize the Born rule to allow for arbitrary measurements instead of just von Neumann ones. The usual formulation of quantum mechanics assumes that all experiments are performed under ideal conditions where no errors occur during the preparation of states or the execution of measurements. However, in practice there always exist some experimental imperfections such as decoherence due to environmental noise, imprecision in state preparations, and inaccuracy in measurements. In order to account for these effects, several approaches have been proposed including stochastic Schrödinger equations [1] , open systems [2] , and generalized probabilistic theories [3] . Here we consider another approach known as Quantum Bayesianism [4] .
In Quantum Bayesianism, the wave function is regarded as representing our knowledge about the system rather than describing its physical properties. This means that when performing a measurement, the outcome is determined by updating our knowledge according to Bayes' theorem [5] . For example, if Alice performs a measurement of spin along the x-axis on her particle, she would update her knowledge accordingly depending on what value was obtained [6] . If Bob also measures his particle's spin along the same axis but obtains different results, then he must perform a new measurement since his knowledge has changed [7, 8] .",arxiv,bigscience bloomz,705.2877,0.3888888888888889,0.49579831932773116,0.3282051282051282,0.7219302436693742,0,1,0,0,0,1,1,0,0,1,0.12672563216090693,0.058733230854712534,0.12840466926070038,0.06818181818181818,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Timing and Lensing of the Colliding Bullet Clusters: barely enough time and gravity to accelerate the bullet,"  We present semi-analytical constraint on the amount of dark matter in the
merging bullet galaxy cluster using the classical Local Group timing arguments.
We consider particle orbits in potential models which fit the lensing data.
{\it Marginally consistent} CDM models in Newtonian gravity are found with a
total mass M_{CDM} = 1 x 10^{15}Msun of Cold DM: the bullet subhalo can move
with V_{DM}=3000km/s, and the ""bullet"" X-ray gas can move with
V_{gas}=4200km/s. These are nearly the {\it maximum speeds} that are
accelerable by the gravity of two truncated CDM halos in a Hubble time even
without the ram pressure. Consistency breaks down if one adopts higher end of
the error bars for the bullet gas speed (5000-5400km/s), and the bullet gas
would not be bound by the sub-cluster halo for the Hubble time. Models with
V_{DM}~ 4500km/s ~ V_{gas} would invoke unrealistic large amount M_{CDM}=7x
10^{15}Msun of CDM for a cluster containing only ~ 10^{14}Msun of gas. Our
results are generalisable beyond General Relativity, e.g., a speed of
$4500\kms$ is easily obtained in the relativistic MONDian lensing model of
Angus et al. (2007). However, MONDian model with little hot dark matter
$M_{HDM} \le 0.6\times 10^{15}\msun$ and CDM model with a small halo mass $\le
1\times 10^{15}\msun$ are barely consistent with lensing and velocity data.
","We present new results on the timing and lensing properties of two colliding galaxy clusters, Abell 520 (z = 0.2) and Abell 521 (z = 0.3). We find that the collision is occurring at an angle of ~45 degrees with respect to our line-of-sight. The mass distribution in each cluster has been determined by fitting parametric models to strong gravitational lensing data obtained using Hubble Space Telescope images. Using these models we have calculated the expected arrival times for multiply-imaged background galaxies as well as their magnifications. These predictions are compared directly against observations made using the Advanced Camera for Surveys aboard HST. In addition, we use the observed positions of multiple images of lensed quasars behind both clusters to measure the relative velocity between them. Our analysis shows that there is only marginally more than sufficient time available before the collision occurs for the dark matter halos to be accelerated up to the current velocities inferred from the lensing measurements.",arxiv,bigscience bloomz,704.0094,0.4444444444444444,0.29411764705882354,0.4717948717948718,0.41519350215002393,1,1,1,0,0,1,1,0,0,0,0.15857524256948738,0.05361144154616202,0.1828793774319066,0.03409090909090909,1,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Antiproliferative MCR peptides block physical interaction of insulin with retinoblastoma protein (RB) in human lung cancer cells,"  Fifteen years ago, a structural analysis of the hormone insulin and the
retinoblastoma tumor suppressor protein (RB) revealed that they may physically
interact with one another. Subsequently, an RB peptide corresponding to the
proposed RB binding site for insulin was found to recognize full-length insulin
in vitro. As part of efforts aimed at developing this RB peptide into an
anti-cancer drug, this molecule was chemically coupled to a cellular
internalization signal and termed ""MCR peptide"". Meanwhile, several such MCR
peptide variants have been demonstrated to restrain the proliferation of
different human cancer cells in vitro and in vivo. Moreover, one of the MCR
peptides coined MCR-10 was shown to be capable of interfering with the complex
formation between insulin and RB in HepG2 human hepatoma cells, as monitored by
immunofluorescence. This latter result indicating an in vivo association
between insulin and RB was confirmed by a follow-up study combining the methods
of co-immunoprecipitation and immunoblotting. Here, we provide evidence for the
existence of the insulin-RB complex in A549 human non-small cell lung cancer
cells. Specifically, we demonstrate this heterodimer by means of a magnetic
beads-based immunoprecipitation approach and equally show that this dimer can
be disrupted by MCR-4 or MCR-10 each of which is known to possess
antiproliferative properties, yet to a much lesser extent by a control peptide.
Thus, this investigation has yielded another important proof for the occurrence
of the insulin-RB dimer and, furthermore, its validity as a target for
antineoplastic MCR peptides.
","The aim of this study was to investigate the effect of novel antimicrobial cyclic peptides, named microbe-derived cationic ring structures (MCRs), on cell proliferation and apoptosis induction in A549 non-small-cell lung carcinoma cells. The results showed that treatment with MCR1 or MCR3 significantly inhibited cell growth by inducing G0/G1-phase arrest and apoptosis through activation of caspase-3/7/9 signaling pathways. In addition, we found that both MCR1 and MCR3 suppressed expression levels of cyclins D1 and E as well as CDK4/6 proteins but increased p21WAF1/cip1 level. Furthermore, our data indicated that MCR1 and MRC3 blocked the binding between insulin-like growth factor 1 receptor (IGF-1R) and retinoblastoma tumor suppressor protein (RB). These findings suggest that MCR1 and 3 may be potential therapeutic agents for treating lung cancers.",arxiv,bigscience bloomz,706.1991,0.4444444444444444,0.19327731092436976,0.6256410256410256,0.30912565695174393,1,1,0,0,0,1,1,0,0,0,0.07354656366982244,0.056065755272533595,0.10505836575875487,0.03409090909090909,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Galaxy evolution in the infra-red: comparison of a hierarchical galaxy formation model with SPITZER data,"  We present predictions for the evolution of the galaxy luminosity function,
number counts and redshift distributions in the IR based on the Lambda-CDM
cosmological model. We use the combined GALFORM semi-analytical galaxy
formation model and GRASIL spectrophotometric code to compute galaxy SEDs
including the reprocessing of radiation by dust. The model, which is the same
as that in Baugh et al (2005), assumes two different IMFs: a normal solar
neighbourhood IMF for quiescent star formation in disks, and a very top-heavy
IMF in starbursts triggered by galaxy mergers. We have shown previously that
the top-heavy IMF seems to be necessary to explain the number counts of faint
sub-mm galaxies. We compare the model with observational data from the SPITZER
Space Telescope, with the model parameters fixed at values chosen before
SPITZER data became available. We find that the model matches the observed
evolution in the IR remarkably well over the whole range of wavelengths probed
by SPITZER. In particular, the SPITZER data show that there is strong evolution
in the mid-IR galaxy luminosity function over the redshift range z ~ 0-2, and
this is reproduced by our model without requiring any adjustment of parameters.
On the other hand, a model with a normal IMF in starbursts predicts far too
little evolution in the mid-IR luminosity function, and is therefore excluded.
","We present results on the infrared (IR) properties of galaxies obtained by comparing predictions made using a semi-analytic galaxy formation model to observations taken as part of the Spitzer Infrared Nearby Galaxies Survey (SINGS). We find that our model reproduces many observed trends, including the IR luminosity function and the correlation between star formation rate and dust temperature. However, we also identify some discrepancies which suggest that further work is needed before this type of modelling can be used for detailed studies of individual objects or small samples. The main conclusions are summarised below:-The predicted number counts at 24 microns agree well with those measured by Spitzer/MIPS over most of the range probed by SINGS. -Our model predicts too few low-luminosity galaxies compared to the observations; however, these systems may not have been detected due to their extremely faint flux levels. -The predicted distribution of dust temperatures agrees reasonably well with the observations although there appears to be an excess of cold dusty galaxies in the simulations relative to what is seen in the data. -The predicted relationship between far-infrared colour and total infrared luminosity agrees fairly well with the observations but shows signs of being slightly steeper than suggested by the data.",arxiv,bigscience bloomz,704.1562,0.3888888888888889,0.29411764705882354,0.49743589743589745,0.5355948399426661,1,1,1,0,0,1,1,1,0,0,0.07620053242144187,0.03161393383637826,0.0933852140077821,0.03409090909090909,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
What is the order of 2D polymer escape transition?,"  An end-grafted flexible polymer chain in 3d space between two pistons
undergoes an abrupt transition from a confined coil to a flower-like
conformation when the number of monomers in the chain, N, reaches a critical
value. In 2d geometry, excluded volume interactions between monomers of a chain
confined inside a strip of finite length 2L transform the coil conformation
into a linear string of blobs. However, the blob picture raises questions on
the nature of this escape transition. To check the theoretical predictions
based on the blob picture we study 2d single polymer chains with excluded
volume interactions and with one end grafted in the middle of a strip of length
  2L and width H by simulating self-avoiding walks on a square lattice with the
pruned-enriched-Rosenbluth method (PERM). We estimate the free energy, the
end-to-end distance, the number of imprisoned monomers, the order parameter,
and its distribution. It is shown that in the thermodynamic limit of large N
and L but finite L/N, there is a small but finite jump in several average
characteristics, including the order parameter. We also present a theoretical
description based on the Landau free energy approach, which is in good
agreement with the simulation results. Both simulation results and the
analytical theory indicate that the 2d escape transition is a weak first-order
phase transition.
","We study the escape dynamics of an elastic string in two dimensions confined by a potential well with periodic boundary conditions and subject to thermal noise. We find that there are three different regimes for the escape process depending on the depth of the confining potential, V0.  For small values of V0 (V0 < Vc), we observe a single exponential decay of the survival probability as expected for a first-order phase transition. In this regime, the mean lifetime decreases exponentially with increasing temperature T . For intermediate values of V0 ( Vc < V0 < Vs ), we observe a double-exponential decay of the survival probability indicating a second-order phase transition. The mean lifetime increases linearly with decreasing temperature below Tc , where Tc is the critical temperature at which the system undergoes a continuous phase transition into the metastable state. Finally, for large values of V0 (Vs < V0) no escape occurs within our simulation time window.",arxiv,bigscience bloomz,704.1857,0.3888888888888889,0.29411764705882354,0.49230769230769234,0.40659340659340665,1,1,0,0,0,1,1,0,0,0,0.10904932506625323,0.044016263828211506,0.14785992217898833,0.041666666666666664,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
MiniBooNE Results and Neutrino Schemes with 2 sterile Neutrinos: Possible Mass Orderings and Observables related to Neutrino Masses,"  The MiniBooNE and LSND experiments are compatible with each other when two
sterile neutrinos are added to the three active ones. In this case there are
eight possible mass orderings. In two of them both sterile neutrinos are
heavier than the three active ones. In the next two scenarios both sterile
neutrinos are lighter than the three active ones. The remaining four scenarios
have one sterile neutrino heavier and another lighter than the three active
ones. We analyze all scenarios with respect to their predictions for
mass-related observables. These are the sum of neutrino masses as constrained
by cosmological observations, the kinematic mass parameter as measurable in the
KATRIN experiment, and the effective mass governing neutrinoless double beta
decay. It is investigated how these non-oscillation probes can distinguish
between the eight scenarios. Six of the eight possible mass orderings predict
positive signals in the KATRIN and future neutrinoless double beta decay
experiments. We also remark on scenarios with three sterile neutrinos. In
addition we make some comments on the possibility of using decays of high
energy astrophysical neutrinos to discriminate between the mass orderings in
presence of two sterile neutrinos.
","We present results on the MiniBooNE experiment, which has recently reported an excess in electron neutrino appearance events at low energies ($E < 100 MeV$). We show that this excess can be explained by adding two light sterile neutrinos to the Standard Model. The new states are required to have masses below $2\times 10^{-3}$ eV/c2 and mix strongly into the active neutrino flavors. In addition we find that there is no need for additional CP violation beyond what is already predicted within the Standard Model. This work was supported by the U.S. 
 
 Department of Energy under Contract No. DE-AC02-05CH11231. We thank J. A. Aguilar-Arevalo, S. Babu, D. Blum, C. Boehm, R. Brandt, P. Cardarelli, E. Cholis, T. Creminelli, G. Danilov, K. Enberg, H. Eriksson, L. F. Ferreira, W. Galsterer, V. Grigoriev, N. Gupta, Y. Hanagaki, A. Iwamoto, A. Khodjamirian, A. Kravchuk, A. Lehtinen, A. Marchesini, A. Melnikov, A. Mironov, A. Murayama, A. Oganessian, A. Ostapchenko, A. Petrovich, A. Polukhin, A. Popov, A. Pruneda, A. Reece, A. Ryabtsev, A. Shabalina, A. Smirnov, A. Stepanenko, A. Strumia, A. Tanaka, A. Trubnikov, A. Tsang, A. Voloshin, A. Zatsepin, A. Zhavoronkov, A. Zhitnitsky, A. Zvezdaev, A. Zwickl, A. Zyuzikov, A. Zyuzaev, A.",arxiv,bigscience bloomz,706.1462,0.5555555555555556,0.3445378151260504,0.3435897435897436,0.5212613473483039,0,1,0,0,0,1,1,0,0,0,0.07146632207556616,0.38065780497514295,0.08171206225680934,0.5151515151515151,2,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
On the generalization of the Costas property in the continuum,"  We extend the definition of the Costas property to functions in the
continuum, namely on intervals of the reals or the rationals, and argue that
such functions can be used in the same applications as discrete Costas arrays.
We construct Costas bijections in the real continuum within the class of
piecewise continuously differentiable functions, but our attempts to construct
a fractal-like Costas bijection there are successful only under slight but
necessary deviations from the usual arithmetic laws. Furthermore, we are able,
contingent on the validity of Artin's conjecture, to set up a limiting process
according to which sequences of Welch Costas arrays converge to smooth Costas
bijections over the reals. The situation over the rationals is different:
there, we propose an algorithm of great generality and flexibility for the
construction of a Costas fractal bijection. Its success, though, relies heavily
on the enumerability of the rationals, and therefore it cannot be generalized
over the reals in an obvious way.
","We study the problem of finding an optimal set of points on the unit circle that are equidistant to each other and have minimum angular separation between them, known as the Costas array or Costas configuration.  We show how this problem can be formulated as a convex optimization problem with linear constraints over the space of probability measures supported by the unit circle. This formulation allows us to use tools from convex analysis for solving it efficiently. In particular we provide a polynomial time algorithm which computes an approximate solution within any desired accuracy. The proposed method is based on the Frank-Wolfe (FW) algorithm combined with the Sinkhorn-Knopp scaling technique. Finally, numerical experiments demonstrate the efficiency of our approach compared to existing methods. Keywords: Convex Optimization; Probability Measures; Frank Wolfe Algorithm; Scaling Technique; Unit Circle; Costas Array; Costas Configuration.",arxiv,bigscience bloomz,706.1379,0.2222222222222222,0.29411764705882354,0.18461538461538463,0.3521261347348304,0,1,1,0,1,1,1,1,0,0,0.05540360399958436,0.06465345397901215,0.038910505836575876,0.03409090909090909,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
X-ray Timing of PSR J1852+0040 in Kesteven 79: Evidence of Neutron Stars Weakly Magnetized at Birth,"  The 105-ms X-ray pulsar J1852+0040 is the central compact object (CCO) in SNR
Kes 79. We report a sensitive upper limit on its radio flux density of 12 uJy
at 2 GHz using the NRAO GBT. Timing using XMM and Chandra over a 2.4 yr span
reveals no significant change in its spin period. The 2 sigma upper limit on
the period derivative leads, in the dipole spin-down formalism, to an energy
loss rate E-dot < 7e33 ergs/s, surface magnetic field strength B_p < 1.5e11 G,
and characteristic age tau_c = P/2P-dot > 8 Myr. This tau_c exceeds the age of
the SNR by 3 orders of magnitude, implying that the pulsar was born spinning at
its current period. However, the X-ray luminosity of PSR J1852+0040, L(bol) ~
3e33(d/7.1 kpc)^2 ergs/s is a large fraction of E-dot, which challenges the
rotation-powered assumption. Instead, its high blackbody temperature,
0.46+/-0.04 keV, small blackbody radius ~ 0.8 km, and large pulsed fraction, ~
80%, may be evidence of accretion onto a polar cap, possibly from a fallback
disk made of supernova debris. If B_p < 1e10 G, an accretion disk can penetrate
the light cylinder and interact with the magnetosphere while resulting torques
on the neutron star remain within the observed limits. A weak B-field is also
inferred in another CCO, the 424-ms pulsar 1E 1207.4-5209, from its steady spin
and soft X-ray absorption lines. We propose this origin of radio-quiet CCOs:
the B-field, derived from a turbulent dynamo, is weaker if the NS is formed
spinning slowly, which enables it to accrete SN debris. Accretion excludes
neutron stars born with both B_p < 1e11 G and P > 0.1 s from radio pulsar
surveys, where B_p < 1e11 G is not encountered except among very old (tau_c >
40 Myr) or recycled pulsars. Finally, such a CCO, if born in SN 1987A, could
explain the non-detection of a pulsar there.
","We report on the discovery and timing analysis of pulsar PSR J1852 + 0040, which is associated with supernova remnant (SNR) Kes 79. The pulsar has spin period P = 1.56 ms and characteristic age τc = 3 kyrs. We find that its surface magnetic field strength Bs = 2 × 10^10 G, assuming an inclination angle i = 60 degrees between the rotation axis and line-of-sight to Earth. This value is consistent with theoretical predictions for neutron stars born weakly magnetized. In addition we have detected X-ray pulsations from this source using Chandra observations taken during 2009-2011. These results are presented here along with our timing solution obtained over a span of eight years. 
 
 Keywords: Pulsar, Supernova Remnant, X-Ray Pulsars, Chandra Observatory, Radio Pulsar Timing 
 
 Introduction 
 
 A number of young radio pulsars show very low values of their surface dipole magnetic fields inferred from their spin-down rates. Such objects include Geminga, B1951+32, B1620-26, B1509-58, B0531+21, B1757-24, B1800-21, B1853+01, B1857+09, B1913+16, B1957+50, B2224+65, B2303+46, B2334+61, B0826-34, B1133+16, B1237+25, B1929+10, B1930+42, B1932+29, B1933+16, B1944+43, B1946+35, B1947+36, B1953+50, B1954+28, B1956+54, B1959+20, B1960+03, B1962+14, B1963+27, B1968+18, B1969+22, B1970+38, B1971+02, B1973+51, B1974+14, B1975+28, B1976+44, B1977+47, B1980+12, B1981+24, B1983",arxiv,bigscience bloomz,705.0978,0.6111111111111112,0.3445378151260504,1.0,0.5097945532728142,1,1,1,0,0,1,1,1,0,0,0.09487569819012553,0.19994587754373366,0.10505836575875487,0.17045454545454544,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman Break Galaxy at z=3.07,"  We report the detection of CO(3-2) emission from a bright, gravitationally
lensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07
using the Plateau de Bure Interferometer. This is only the second detection of
molecular gas emission from an LBG and yields an intrinsic molecular gas mass
of (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG
indicates that it comprises two components separated by ~2 kpc. The CO emission
is unresolved, and appears to be centered on the intrinsically fainter (and
also less highly magnified) of the two UV components. The width of the CO line
indicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc.
Employing mid-infrared observations from Spitzer we derive a stellar mass of
~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the
molecular gas will be consumed in ~40 Myr. The gas fractions, star-formation
efficiencies and line widths suggests that LBGJ213512 is a high-redshift,
gas-rich analog of a local luminous infrared galaxy. This galaxy has a similar
gas-to-dynamical mass fraction as observed in the submillimeter-selected
population, although the gas surface density and star-formation efficiency is a
factor of 3x less, suggesting less vigorous activity. We discuss the
uncertainties in our conclusions arising from adopting a CO-to-H2 conversion
factor appropriate for either the Milky Way or local luminous infrared
galaxies. These observations demonstrate that current facilities, when aided by
fortuitous gravitational magnification, can study 'ordinary' galaxies at
high-redshift and so act as pathfinders for ALMA.
","We present the results of an extensive study of gas dynamics, star formation activity, dust extinction, stellar populations, and black hole accretion properties for a strongly lensed galaxy (A1689-zD1) at redshift 3.07. The lensing magnification factor is ~30Â±5. We use deep near-infrared spectroscopy to measure the kinematics of molecular hydrogen emission lines with high spatial resolution. Our observations reveal that this system consists of two merging galaxies separated by 1 kpc along the line-of-sight. One of these components shows strong HÎ² emission indicative of active galactic nuclei (AGN). This AGN component has a mass of âˆ¼10^9 M_sol , which corresponds to a supermassive black hole with a mass of âˆ½â€“1 Ã— 10^8 M_sol . Using our spatially resolved measurements we find evidence for intense nuclear starbursts on scales as small as 100 pc.",arxiv,bigscience bloomz,705.1721,0.5,0.29411764705882354,0.6358974358974359,0.3349259436215958,1,1,0,0,1,1,1,0,0,0,0.049795750704106675,0.07791179125449295,0.04669260700389105,0.10606060606060606,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Room temperature spin polarized magnetic semiconductor,"  Alternating layers of granular Iron (Fe) and Titanium dioxide
(TiO$_{2-\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$)
substrates in low oxygen chamber pressure using a controlled pulsed laser
ablation deposition technique. The total thickness of the film was about 200
nm. The films show ferromagnetic behavior for temperatures ranging from 4 to
$400 ^oK$. The layered film structure was characterized as p-type magnetic
semiconductor at $300 ^oK$ with a carrier density of the order of $10^{20}
/cm^3$. The undoped pure TiO$_{2-\delta}$ film was characterized as an n-type
magnetic semiconductor. The hole carriers were excited at the interface between
the granular Fe and TiO$_{2-\delta}$ layers similar to holes excited in the
metal/n-type semiconductor interface commonly observed in
Metal-Oxide-Semiconductor (MOS) devices. The holes at the interface were
polarized in an applied magnetic field raising the possibility that these
granular MOS structures can be utilized for practical spintronic device
applications.
","We report on the room-temperature ferromagnetism in Mn-doped ZnO thin films grown by pulsed laser deposition (PLD). The Curie temperatures are found to be around 300 K for all samples with different doping levels, which is much higher than that reported previously. We also find that the magnetization increases linearly as the applied field decreases and shows hysteresis loops at low fields. These results indicate that the observed ferromagnetic behavior may originate from exchange coupling between localized spins rather than intrinsic ferromagnetism. 
 
 In recent years, there has been growing interest in developing new materials for spintronic applications such as nonvolatile memory devices or logic circuits based on the manipulation of electron spins instead of charge carriers1-5 . Among these materials, diluted magnetic semiconductors have attracted considerable attention because they can combine both electronic and magnetic functionalities into one material6-8 .
 


ZnO-based DMSs have been extensively studied due to their wide band gap energy (3.37 eV), large exciton binding energy (60 meV)9 , high transparency10-12 , and good chemical stability13-15 . However, it remains challenging to achieve room-temperature ferromagnetically ordered states in ZnO-based DMSs16-18 . Although several groups have recently demonstrated room-temperature ferromagnetic ordering in various types of ZnO-based DMS systems19-24 , most of them show relatively small saturation magnetizations25-27 . 
 
 Here we report on the observation of room-temperature ferromagnetisms in Mn-doped ZnObased DMSs prepared using pulsed laser deposition28-30 . Our experimental data clearly demonstrate that the dopant concentration plays an important role in determining the Curie temperature31-33 . For example, our sample with x = 0.5% exhibits a Curie temperature of about 300 K while those with lower concentrations exhibit smaller values ranging from 150-250 K34-36 . Moreover, we observe that the magnetization increases almost linearly when decreasing the external magnetic field below 1 T and displays hysteretic behaviors at very low fields. This indicates that the observed ferr",arxiv,bigscience bloomz,705.2993,0.3333333333333333,0.29411764705882354,0.12307692307692308,0.39655996177735314,1,1,0,0,0,2,2,0,0,0,0.12002441606257315,0.060558899648059716,0.14785992217898833,0.06818181818181818,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,2,1,1
The Kinematic Evolution of Strong MgII Absorbers,"  We consider the evolution of strong (W_r(2796) > 0.3A) MgII absorbers, most
of which are closely related to luminous galaxies. Using 20 high resolution
quasar spectra from the VLT/UVES public archive, we examine 33 strong MgII
absorbers in the redshift range 0.3 < z < 2.5. We compare and supplement this
sample with 23 strong MgII absorbers at 0.4 < z < 1.4 observed previously with
HIRES/Keck. We find that neither equivalent width nor kinematic spread (the
optical depth weighted second moment of velocity) of MgII2796 evolve. However,
the kinematic spread is sensitive to the highest velocity component, and
therefore not as sensitive to additional weak components at intermediate
velocities relative to the profile center. The fraction of absorbing pixels
within the full velocity range of the system does show a trend of decreasing
with decreasing redshift. Most high redshift systems (14/20) exhibit absorption
over the entire system velocity range, which differs from the result for low
redshift systems (18/36) at the 95% level. This leads to a smaller number of
separate subsystems for high redshift systems because weak absorping components
tend to connect the stronger regions of absorption. We hypothesize that low
redshift MgII profiles are more likely to represent well formed galaxies, many
of which have kinematics consistent with a disk/halo structure. High redshift
MgII profiles are more likely to show evidence of complex protogalactic
structures, with multiple accretion or outflow events. Although these results
are derived from measurements of gas kinematics, they are consistent with
hierarchical galaxy formation evidenced by deep galaxy surveys.
","We present the kinematics and physical properties of strong Mg II absorbers at z = 1.5 − 3, using high-resolution (R ≈ 45000) spectroscopy obtained with Keck/HIRES. We find that these systems are composed primarily of cool gas clouds in pressure equilibrium with their surroundings; they have typical sizes of 100-200 pc, masses of 10^6−10^7 M_sun, and temperatures of ~10 4 K. The majority of our sample show no evidence for bulk motions exceeding 50 km/s relative to their surrounding medium. However, we do detect two outliers which exhibit large velocity shifts between multiple components within each system. These objects may be associated with galactic winds or tidal interactions. Our results suggest that strong Mg II absorbers evolve into galaxies through gravitational collapse on timescales less than one billion years after the Big Bang. This work is based upon observations made with the NASA/ESA Hubble Space Telescope, obtained from the Data Archive at the Space Telescope Science Institute, which is operated by AURA under NASA contract NAS 5-26555.",arxiv,bigscience bloomz,706.0515,0.5555555555555556,0.24369747899159663,0.6820512820512821,0.43526039178213094,1,0,0,0,0,1,1,1,0,0,0.035463554341622225,0.12687945824488292,0.042801556420233464,0.13257575757575757,0,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The generator coordinate method in time-dependent density-functional theory: memory made simple,"  The generator coordinate (GC) method is a variational approach to the quantum
many-body problem in which interacting many-body wave functions are constructed
as superpositions of (generally nonorthogonal) eigenstates of auxiliary
Hamiltonians containing a deformation parameter. This paper presents a
time-dependent extension of the GC method as a new approach to improve existing
approximations of the exchange-correlation (XC) potential in time-dependent
density-functional theory (TDDFT). The time-dependent GC method is shown to be
a conceptually and computationally simple tool to build memory effects into any
existing adiabatic XC potential. As an illustration, the method is applied to
driven parametric oscillations of two interacting electrons in a harmonic
potential (Hooke's atom). It is demonstrated that a proper choice of
time-dependent generator coordinates in conjunction with the adiabatic
local-density approximation reproduces the exact linear and nonlinear
two-electron dynamics quite accurately, including features associated with
double excitations that cannot be captured by TDDFT in the adiabatic
approximation.
","The Generator Coordinate Method (GCM) is an efficient approach to calculate the electronic structure and properties of materials with strong electron-phonon coupling, such as polar semiconductors or insulators. In this work we present a new implementation of GCM within Time-Dependent Density Functional Theory (TDDFT), which allows us to study phonon-assisted optical excitations on large systems. The key idea behind our scheme is that it exploits the fact that TDDFT can be formulated as a linear response problem for the Kohn-Sham system, so that the calculation of the ground state wavefunction does not need to be repeated at each step during the self-consistent field iteration. We demonstrate the efficiency of our algorithm by calculating the absorption spectrum of bulk silicon under hydrostatic pressure up to 100 GPa. Our results show good agreement with previous calculations based on supercell approaches.",arxiv,bigscience bloomz,704.2855,0.2222222222222222,0.19327731092436976,0.14871794871794872,0.34925943621595795,1,1,0,0,1,1,1,0,0,0,0.0807351743194397,0.10755516281677364,0.08171206225680934,0.09090909090909091,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Inhomogeneities in the Universe and the Fitting Problem,"  Observational cosmology provides us with a large number of high precision
data which are used to derive models trying to reproduce ``on the mean'' our
observable patch of the Universe. Most of these attempts are achieved in the
framework of a Friedmann-Lema\^itre cosmology where large scale homogeneity is
assumed. However, we know, from the observation of structures at increasing
scales, that these models are only approximations of a smoothed or averaged
inhomogeneous underlying patern. Anyhow, when modelling the Universe, the usual
method is to use continuous functions representing the kinematical scalars of
the velocity field, implicitly assuming that they represent volume averages of
the corresponding fine-scale inhomogeneous quantities, then put them into the
Einstein equations which are solved to give the model and its dependance upon a
number of parameters arbitrarily defined. In General Relativity, such a method
is very much involved since the equations which determine the metric tensor and
the quantities calculated from it are highly nonlinear. The question raised by
the method consisting of determining the parameters of an a priori assumed FLRW
model from observational data is the ``fitting problem'' brought to general
attention by Ellis and Stoeger in the 80's. This problem has recently
experienced a reniewed attention due to the amount of available data and the
increase of the minimum scale at which homogeneity can be assumed. We propose a
discussion of this issue in the light of the latest developments of
observational and theoretical cosmology.
","The fitting problem is one of the most important problems in cosmology, which has been studied for more than 50 years.  The main goal of this work was to study the effect of different types of initial conditions on the evolution of density perturbations in an expanding universe with a positive cosmological constant (dark energy).  We have used two methods to solve numerically the Einstein equations coupled to the matter fields:  the standard method based on the expansion of the metric tensor into spherical harmonics; and the new method developed by us that uses the expansion of the metric into Chebyshev polynomials.  In both cases we have considered three types of initial conditions: Gaussian random fields generated using the Zel'dovich approximation, Gaussian random fields generated using a fast Fourier transform algorithm, and white noise.  Our results show that all these models give similar predictions at late times when they are evolved up to z = 0.5.  However, there are some differences between them at early times.  These differences can be explained as follows:  the Zel'dovich model predicts larger fluctuations compared to other models because it does not take into account the pressure term in the fluid equation; the white noise model gives smaller fluctuations due to its statistical properties; finally, the Gaussian random fields obtained via the fast Fourier transform algorithm predict intermediate values.  This result shows that the choice of the initial conditions may affect significantly the final value of the power spectrum of primordial density fluctuations predicted by inflationary theories.",arxiv,bigscience bloomz,706.1029,0.3888888888888889,0.3445378151260504,0.6102564102564103,0.6760630673674153,0,1,0,0,1,1,0,1,0,1,0.12450686654564724,0.13196618811904293,0.13229571984435798,0.17803030303030304,0,0,2,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
The Thurston norm via Normal Surfaces,"  Given a triangulation of a closed, oriented, irreducible, atoroidal
3-manifold every oriented, incompressible surface may be isotoped into normal
position relative to the triangulation. Such a normal oriented surface is then
encoded by non-negative integer weights, 14 for each 3-simplex, that describe
how many copies of each oriented normal disc type there are. The Euler
characteristic and homology class are both linear functions of the weights.
There is a convex polytope in the space of weights, defined by linear equations
given by the combinatorics of the triangulation, whose image under the homology
map is the unit ball, B, of the Thurston norm.
  Applications of this approach include (1) an algorithm to compute B and hence
the Thurston norm of any homology class, (2) an explicit exponential bound on
the number of vertices of B in terms of the number of simplices in the
triangulation, (3) an algorithm to determine the fibred faces of B and hence an
algorithm to decide whether a 3-manifold fibres over the circle.
","In this talk, we will discuss the relationship between the Thurston norm and normal surfaces in 3-manifolds.  We will begin by recalling some basic definitions about the Thurston norm on homology classes of surface bundles over circles (or equivalently, mapping tori).  Then, using techniques developed by Gabai, we will show that any class with positive Thurston norm can be represented by an embedded surface which is incompressible and not boundary-parallel.  Finally, we will give examples to illustrate how these results are used to study the topology of hyperbolic 3-manifolds. The Thurston norm was introduced in 1982 as part of the solution to the Geometrization Conjecture for Haken manifolds.   It assigns each element of $H_1(M;\mathbb{R})$ a non-negative real number, where $M$ is a closed orientable 3-manifold.  This assignment satisfies certain natural properties, including additivity under connected sums and multiplicativity under finite covers.  In particular, if $M_1$ and $M_2$ are two closed orientable 3-manfolds whose fundamental groups have isomorphic subgroups of finite index, then there exists a constant $C > 0$ such that $||[\phi]||_{Th} = C ||[\psi]||_{Th}$ whenever $\phi : \pi_1 M_1 \to \pi_1 M_2 \cong H_3$ is a homomorphism inducing isomorphism on all subgroups of finite index.    If $\mu \in H_1(M;\mathbb{R};\mathbb{Z})$ represents a fibered knot or link in a closed oriented 3-manifold, then its Thurston norm measures the complexity of the associated fibration.  For example, if $L \subseteq M$ is a fibered torus knot or link, then $||\mu||_{Th} = 1$ if and only if $L$ bounds a Seifert surface in $M$.  On the other hand, if $L$ does not bound a Seifert surface in...",arxiv,bigscience bloomz,706.0673,0.2222222222222222,0.49579831932773116,0.22564102564102564,0.707596751075012,1,1,0,0,0,1,1,1,0,0,0.1926773820900818,0.15719786464286992,0.12840466926070038,0.22727272727272727,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Magnetic structure of Sm2IrIn8,"  The magnetic structure of the intermetallic antiferromagnet Sm2IrIn8 was
determined using x-ray resonant magnetic scattering (XRMS). Below TN = 14.2,
Sm2IrIn8 has a commensurate antiferromagnetic structure with a propagation
vector (1/2,0,0). The Sm magnetic moments lie in the ab plane and are rotated
roughly 18 degrees away from the a axis. The magnetic structure of this
compound was obtained by measuring the strong dipolar resonant peak whose
enhancement was of over two orders of magnitude at the L2 edge. At the L3 edge
both quadrupolar and dipolar features were observed in the energy line shape.
The magnetic structure and properties of Sm2IrIn8 are found to be consistent
with the general trend already seen for the Nd-, Tb- and the Ce-based compounds
from the RmMnIn3m+2n family (R = rare earth; M=Rh or Ir, m = 1, 2; n = 0, 1),
where the crystalline electrical field (CEF) effects determine the direction of
magnetic moments and the TN evolution in the series. The measured Neel
temperature for Sm2IrIn8 is slightly suppressed when compared to the TN of the
parent cubic compound SmIn3.
","We have performed neutron powder diffraction experiments on the intermetallic compound Sm2IrIn8 in order to determine its magnetic structure and compare it with that proposed for YbMgGaO4, another member of this family of compounds. The results show that Sm2IrIn8 has an antiferromagnetic ordering at TN = 3.5 K with moments aligned along the c-axis. This is similar to what was found previously for YbMgGaO4 but different than the theoretical prediction based on band-structure calculations which suggested that the ordered moment should be perpendicular to the c-axis.  We also find evidence for a structural phase transition near T* ~ 80 K where there are changes in both the lattice parameters as well as the unit cell volume. These results suggest that the low temperature crystal structure may not correspond exactly to the high-temperature tetragonal symmetry predicted by theory. Finally we present specific heat data showing clear anomalies associated with both the magnetic ordering and the structural phase transition.",arxiv,bigscience bloomz,704.148,0.3333333333333333,0.24369747899159663,0.2923076923076923,0.4037267080745342,1,1,1,0,0,0,1,0,0,0,0.1919458416966615,0.05183485027435556,0.23346303501945526,0.041666666666666664,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Flavour-Dependent Type II Leptogenesis,"  We reanalyse leptogenesis via the out-of-equilibrium decay of the lightest
right-handed neutrino in type II seesaw scenarios, taking into account
flavour-dependent effects. In the type II seesaw mechanism, in addition to the
type I seesaw contribution, an additional direct mass term for the light
neutrinos is present. We consider type II seesaw scenarios where this
additional contribution arises from the vacuum expectation value of a Higgs
triplet, and furthermore an effective model-independent approach. We
investigate bounds on the flavour-specific decay asymmetries, on the mass of
the lightest right-handed neutrino and on the reheat temperature of the early
universe, and compare them to the corresponding bounds in the type I seesaw
framework. We show that while flavour-dependent thermal type II leptogenesis
becomes more efficient for larger mass scale of the light neutrinos, and the
bounds become relaxed, the type I seesaw scenario for leptogenesis becomes more
constrained. We also argue that in general, flavour-dependent effects cannot be
ignored when dealing with leptogenesis in type II seesaw models.
","We study the possibility that leptons acquire their masses through an effective dimension-5 operator, which is suppressed by some heavy scale M . We show how this scenario can be realized in supersymmetric theories with extra dimensions and discuss its phenomenological consequences for neutrino physics. 
 
 In particular we consider the case where the lepton number violating interactions are localized on a brane at y = 0 while the Standard Model fields live in the bulk. The resulting mass matrix has two zero eigenvalues corresponding to the light active neutrinos and one massive eigenvalue m ~ 10 GeV associated with the sterile neutrino. This leads to interesting predictions for neutrinoless double beta decay as well as for cosmology. For example, if the Majorana phase vanishes then there will be no contribution to neutrinoless double-beta decay but the sterile neutrino may still contribute significantly to dark matter production during inflation or reheating.",arxiv,bigscience bloomz,704.1591,0.2777777777777778,0.24369747899159663,0.2205128205128205,0.3836598184424272,0,1,0,0,0,0,1,0,0,0,0.06553048884685275,0.05006981371134522,0.058365758754863814,0.056818181818181816,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Effective inverse spectral problem for rational Lax matrices and applications,"  We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the
desingularization of the characteristic polynomial) and some additional data.
Using a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu))
we provide a residue-formula for the entries of the Lax matrix in terms of
bases of dual differentials of weights nu and 1-nu respectively. All objects
are described in the most explicit terms using Theta functions. Via a sequence
of ``elementary twists'', we construct sequences of Lax matrices sharing the
same spectral curve and polar structure and related by conjugations by rational
matrices. Particular choices of elementary twists lead to construction of
sequences of Lax matrices related to finite--band recurrence relations (i.e.
difference operators) sharing the same shape. Recurrences of this kind are
satisfied by several types of orthogonal and biorthogonal polynomials. The
relevance of formulae obtained to the study of the large degree asymptotics for
these polynomials is indicated.
","We consider the effective inverse spectral problems (EISP) associated with rational Lax matrices, which are generalizations of classical EISP in terms of Jacobi matrices. We show that these new EISPs can be reduced to some special cases of classical EISP by using an explicit formula for the coefficients of the characteristic polynomial of a rational matrix. As examples we study two classes of rational Lax matrices: one is related to the Toda lattice hierarchy and another is connected with the modified Volterra lattice hierarchy. In particular, we give a complete description on all solutions of the corresponding EISPs. Finally, as applications of our results, we present several interesting properties about the spectra of these rational Lax matrices. The research was supported by NSFC under Grant No.11571040. Keywords: Effective inverse spectral problem; Rational Lax matrices; Toda lattice hierarchy; Modified Volterra lattice hierarchy",arxiv,bigscience bloomz,705.012,0.3888888888888889,0.29411764705882354,0.15384615384615385,0.35785953177257523,1,1,0,0,1,1,0,1,0,0,0.10071738893493365,0.06382150212792079,0.11673151750972763,0.03787878787878788,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
A Comparison between Anomalous 6-cm H$_2$CO Absorption and CO(1-0) Emission in the L1204/S140,"  We report observations of the dust cloud L1204 with the Onsala 25-m telescope
in the 6 cm (1$_{11}-1_{10}$) transition of \htco. The observed region includes
the
  S140 H${\alpha}$ arc. This spectral line is seen here in absorption against
the cosmic microwave background, indicating the presence of widespread warm
molecular gas at intermediate densities. Overall, the distributions of H$_2$CO
and CO (taken from the literature) are fairly similar, though significant
differences exist at small scales. Most notably, while the CO peak is nearly
coincident with the S140 H${\alpha}$ arc, the maximum H$_2$CO absorption is
clearly separated from it by a full 10$'$ beam ($\sim$ 3 pc). We argue that
these differences result from differing abundances and excitation requirements.
The CO(1-0) line is more optically thick and more biased towards warm gas than
the H$_2$CO 6 cm line. On the other hand, formaldehyde is more easily
photodissociated and is, therefore, a poorer tracer of the molecular gas
located immediately behind Photon Dominated Regions.
","We present new observations of molecular hydrogen (H_2CO) absorption toward the low-mass protostar IRAS 16293-2422, which is associated with two outflows driven by different components of this binary system. The main component drives an east-west bipolar flow that has been traced over more than 1000 AU using SiO emission lines observed at high angular resolution. We have detected anomalously strong absorption features near the systemic velocity of the source for both ortho- and para-H_2CO transitions. These are likely due to self-absorption within the dense gas surrounding the central protostars. In addition, we find evidence for blueshifted absorption features in the para-H_2CO line profiles that may be tracing infalling material along the axis of one of the outflow lobes. Finally, we compare our results with previous studies of carbon monoxide (CO) emission towards the same region.",arxiv,bigscience bloomz,704.0272,0.3888888888888889,0.24369747899159663,0.19487179487179487,0.34065934065934067,1,1,0,0,1,1,1,0,0,0,0.10508354571715117,0.051577607866002205,0.14396887159533073,0.045454545454545456,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Searching for Gravitational Radiation from Binary Black Hole MACHOs in the Galactic Halo,"  The Laser Interferometer Gravitational Wave Observatory (LIGO) is one of a
new generation of detectors of gravitational radiation. The existence of
gravitational radiation was first predicted by Einstein in 1916, however
gravitational waves have not yet been directly observed. One source of
gravitation radiation is binary inspiral. Two compact bodies orbiting each
other, such as a pair of black holes, lose energy to gravitational radiation.
As the system loses energy the bodies spiral towards each other. This causes
their orbital speed and the amount of gravitational radiation to increase,
producing a characteristic ``chirp'' waveform in the LIGO sensitive band. In
this thesis, matched filtering of LIGO science data is used to search for low
mass binary systems in the halo of dark matter surrounding the Milky Way.
Observations of gravitational microlensing events of stars in the Large
Magellanic Cloud suggest that some fraction of the dark matter in the halo may
be in the form of Massive Astrophysical Compact Halo Objects (MACHOs). It has
been proposed that low mass black holes formed in the early universe may be a
component of the MACHO population; some fraction of these black hole MACHOs
will be in binary systems and detectable by LIGO. The inspiral from a MACHO
binary composed of two 0.5 solar mass black holes enters the LIGO sensitive
band around 40 Hz. The chirp signal increases in amplitude and frequency,
sweeping through the sensitive band to 4400 Hz in 140 seconds. By using
evidence from microlensing events and theoretical predictions of the population
an upper limit is placed on the rate of black hole MACHO inspirals in the
galactic halo.
","We present results on gravitational radiation searches using data collected by the LIGO and Virgo detectors during their second observing run (O2). We search for signals from binary black holes with masses between 10$^{-3}$ M$\sim10^2$M, which are expected to be abundant in galactic halos if they exist as massive compact halo objects (MACHOs) predicted by some theories of galaxy formation. The analysis is performed over a large range of source parameters including mass ratio, spin magnitudes and orientations, sky position, distance, inclination angle, eccentricity, and time of coalescence. No significant signal candidates were found above background noise levels. Upper limits on the rate density of binary black hole mergers are set at 90% confidence level within different ranges of component masses. These upper limits can be used to constrain theoretical models of binary black hole merger rates. This work was supported by NSF grants PHY-0960291, PHY-1125897, PHY-1214379, PHY-1430152, and PHY-1505155.",arxiv,bigscience bloomz,705.1514,0.6111111111111112,0.29411764705882354,0.7538461538461538,0.3836598184424272,1,0,1,0,1,1,1,0,0,0,0.0847125431187434,0.10913853416161795,0.06614785992217899,0.08712121212121213,1,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Gauge-Higgs Unification and Radiative Electroweak Symmetry Breaking in Warped Extra Dimensions,"  We compute the Coleman Weinberg effective potential for the Higgs field in RS
Gauge-Higgs unification scenarios based on a bulk SO(5) x U(1)_X gauge
symmetry, with gauge and fermion fields propagating in the bulk and a custodial
symmetry protecting the generation of large corrections to the T parameter and
the coupling of the Z to the bottom quark. We demonstrate that electroweak
symmetry breaking may be realized, with proper generation of the top and bottom
quark masses for the same region of bulk mass parameters that lead to good
agreement with precision electroweak data in the presence of a light Higgs. We
compute the Higgs mass and demonstrate that for the range of parameters for
which the Higgs boson has Standard Model-like properties, the Higgs mass is
naturally in a range that varies between values close to the LEP experimental
limit and about 160 GeV. This mass range may be probed at the Tevatron and at
the LHC. We analyze the KK spectrum and briefly discuss the phenomenology of
the light resonances arising in our model.
","We study the possibility that electroweak symmetry breaking is triggered by strong dynamics at an ultraviolet (UV) fixed point, as suggested by gauge-Higgs unification models with warped extra dimensions. We show how this scenario can be realized within the framework of composite Higgs models based on strongly-coupled gauge theories. In particular we consider two different realizations of such scenarios: one where the Higgs arises as a pseudo-Nambu-Goldstone boson associated to spontaneous breaking of approximate global symmetries; another where it emerges as a bound state of new fermions charged under the Standard Model gauge group. The latter case leads to novel signatures for Higgs production through gluon fusion which are potentially observable at future colliders. Finally, we discuss possible implications of these results for cosmology. Gauge-Higgs unification provides a compelling explanation for why the weak scale is so much smaller than any other mass scale in nature [1] . It also offers a natural solution to the hierarchy problem between the Planck and TeV scales [2] , since quantum corrections to the Higgs potential are cut off at the UV scale [3] .
In order to realize this idea in practice, however, several challenges must be overcome [4] : i) the Higgs should arise naturally out of some strongly coupled sector; ii) the Higgs couplings to SM particles should agree with experiment; iii) there should exist a mechanism to generate masses for all SM fields without introducing large hierarchies among them. These issues have been addressed recently using the Randall-Sundrum model [5] , where the Higgs field lives on the IR brane while gravity propagates into the bulk [6] - [8] . This setup allows for a calculable description of the Higgs physics [9] , but introduces additional complications due to the presence of Kaluza-Klein gravitons [10] .",arxiv,bigscience bloomz,706.1281,0.2222222222222222,0.4453781512605043,0.2717948717948718,0.8050645007166746,1,1,0,0,0,1,1,1,0,0,0.18743720163503289,0.13050134711270342,0.1245136186770428,0.10227272727272728,0,0,3,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Post-Newtonian gravitational radiation and equations of motion via direct integration of the relaxed Einstein equations. V. Evidence for the strong equivalence principle to second post-Newtonian order,"  Using post-Newtonian equations of motion for fluid bodies valid to the second
post-Newtonian order, we derive the equations of motion for binary systems with
finite-sized, non-spinning but arbitrarily shaped bodies. In particular we
study the contributions of the internal structure of the bodies (such as
self-gravity) that would diverge if the size of the bodies were to shrink to
zero. Using a set of virial relations accurate to the first post-Newtonian
order that reflect the stationarity of each body, and redefining the masses to
include 1PN and 2PN self-gravity terms, we demonstrate the complete
cancellation of a class of potentially divergent, structure-dependent terms
that scale as s^{-1} and s^{-5/2}, where s is the characteristic size of the
bodies. This is further evidence of the Strong Equivalence Principle, and
supports the use of post-Newtonian approximations to derive equations of motion
for strong-field bodies such as neutron stars and black holes. This extends
earlier work done by Kopeikin.
","We present evidence that the strong equivalence principle (SEP) holds in general relativity at least up to second post Newtonian order, by showing that the SEP is satisfied if it holds at first PN order.  We show this by directly integrating the relaxed Einstein field equations with an appropriate source term which incorporates the effects of gravitational waves generated by accelerating bodies. The results are consistent with those obtained previously using perturbation theory. This work was supported by NSF grant PHY-0456747. In this article we will consider only isolated systems where no external forces act on any body. For such systems the total energy E = T + U , where T is the kinetic energy and U is the potential energy associated with all interactions between particles within the system. If there were no gravitational fields then the total energy would be conserved since the net force acting on each particle vanishes. However when gravitational fields exist they can exchange energy with matter through emission or absorption of gravitational waves.",arxiv,bigscience bloomz,704.2243,0.2222222222222222,0.3445378151260504,0.16923076923076924,0.4438604873387483,1,1,0,0,0,1,1,0,0,0,0.18773435956874052,0.08270737825002258,0.14007782101167315,0.045454545454545456,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
One- and two-component bottle-brush polymers: simulations compared to theoretical predictions,"  Scaling predictions and results from self-consistent field calculations for
bottle-brush polymers with a rigid backbone and flexible side chains under good
solvent conditions are summarized and their validity and applicability is
assessed by a comparison with Monte Carlo simulations of a simple lattice
model. It is shown that under typical conditions, as they are also present in
experiments, only a rather weak stretching of the side chains is realized, and
then the scaling predictions based on the extension of the Daoud-Cotton blob
picture are not applicable.
  Also two-component bottle brush polymers are considered, where two types
(A,B) of side chains are grafted, assuming that monomers of different kind
repel each other. In this case, variable solvent quality is allowed for, such
that for poor solvent conditions rather dense cylinder-like structures result.
Theories predict ``Janus Cylinder''-type phase separation along the backbone in
this case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth
method (PERM) then are restricted to rather short side chain length.
Nevertheless, evidence is obtained that the phase separation between an A-rich
part of the cylindrical molecule and a B-rich part can only occur locally. The
correlation length of this microphase separation can be controlled by the
solvent quality. This lack of a phase transition is interpreted by an analogy
with models for ferromagnets in one space dimension.
","We study the conformational properties of one- and two-component bottlebrush polymers in good solvent conditions by means of Monte Carlo (MC) simulations, using an off-lattice model with freely jointed chains. We compare our results for the radius of gyration Rg(N), end-to-end distance Ree(N), persistence length P(N), and contour length Lc(N) as functions of chain length N to those obtained within the framework of the worm-like-chain (WLC) theory. The WLC approach is found to be very accurate at predicting the scaling behavior of these quantities over several orders of magnitude in chain lengths. In particular, we find that the persistence length scales linearly with the number of monomers per backbone segment, which agrees well with recent experimental findings on bottle-brush polyelectrolytes. 
 
 Keywords: Polymer brushes, Persistence length",arxiv,bigscience bloomz,705.1124,0.4444444444444444,0.19327731092436976,0.49230769230769234,0.3119923554706163,1,1,0,0,1,1,1,1,0,0,0.10440677990096357,0.1332590792131638,0.054474708171206226,0.0946969696969697,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0
Discovery of two candidate pulsar wind nebulae in very-high-energy gamma rays,"  We present the discovery of two very-high-energy gamma-ray sources in an
ongoing systematic search for emission above 100 GeV from pulsar wind nebulae
in survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov
Telescopes are ideal tools for searching for extended emission from pulsar wind
nebulae in the very-high-energy regime. H.E.S.S., with its large field of view
of 5 degrees and high sensitivity, gives new prospects for the search for these
objects. An ongoing systematic search for very-high-energy emission from
energetic pulsars over the region of the Galactic plane between -60 degrees < l
< 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting
candidates, the standard H.E.S.S. analysis was applied and a search for
multi-wavelength counterparts was performed. We present the discovery of two
new candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193.
H.E.S.S. has proven to be a suitable instrument for pulsar wind nebula
searches.
","We report the discovery of two new TeV PWN candidates, HESS J1825-137 and HESS J1857+026, using data taken with the High Energy Stereoscopic System (H.E.S.S.) between 2004 and 2007. The sources are spatially coincident with extended radio emission that is likely to be associated with supernova remnants G18.0-0.7 and CTB 37A respectively. Both objects show hard power-law spectra extending up to at least 100 GeV. We discuss possible scenarios for their origin as well as implications on our understanding of particle acceleration mechanisms within PWNe. Keywords: Very high energy gamma ray astronomy, Pulsar Wind Nebula, Supernova Remnant, Particle Acceleration. 1 Introduction Pulsar Wind Nebulae (PWNe) are believed to be powered by relativistic winds ejected from young rotation-powered pulsars [1] . These winds interact with surrounding material creating shocks which accelerate particles to extremely high energies [2] , resulting in synchrotron radiation observed across the electromagnetic spectrum [3] .
The detection of high-energy photons emitted by these systems can provide important information about the physical processes occurring inside them [4] . In particular, observations above 10 GeV have been used to study the spectral properties of several known PWNe [5] . However, only one object has so far been detected beyond 30 GeV [6] . This lack of detections may be due to the fact that most current instruments were not designed specifically for this purpose or because they operate under unfavourable observing conditions such as large zenith angles [7, 8] .",arxiv,bigscience bloomz,705.1605,0.5,0.546218487394958,0.1641025641025641,0.6445293836598185,0,1,0,0,0,1,1,1,0,0,0.10291304369102905,0.07239967455352848,0.10505836575875487,0.07954545454545454,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Two-dimensional Ising model with competing interactions and its application to clusters and arrays of $\pi$-rings and adiabatic quantum computing,"  We study planar clusters consisting of loops including a Josephson
$\pi$-junction ($\pi$-rings). Each $\pi$-ring carries a persistent current and
behaves as a classical orbital moment. The type of particular state associated
with the orientation of orbital moments at the cluster depends on the
interaction between these orbital moments and can be easily controlled, i.e. by
a bias current or by other means. We show that these systems can be described
by the two-dimensional Ising model with competing nearest-neighbor and diagonal
interactions and investigate the phase diagram of this model. The
characteristic features of the model are analyzed based on the exact solutions
for small clusters such as a 5-site square plaquette as well as on a mean-field
type approach for the infinite square lattice of Ising spins. The results are
compared with spin patterns obtained by Monte Carlo simulations for the 100
$\times$ 100 square lattice and with experiment. We show that the $\pi$-ring
clusters may be used as a new type of superconducting memory elements. The
obtained results may be verified in experiments and are applicable to adiabatic
quantum computing where the states are switched adiabatically with the slow
change of coupling constants.
","We study the two-dimensional (2D) Ising model on square lattices with competing nearest-neighbor ferromagnetic interaction J1, next-nearest neighbor antiferromagnetic interaction J2, and external magnetic field H. We find that for small values of J2 there is no phase transition at finite temperature T in this system. However, when J2 increases beyond some critical value, we observe two successive transitions between paramagnetic state and ordered states as T decreases. The first-order transition line ends at tricritical point where second-order transition starts. In addition, we show that the ground-state energy per spin can be used to predict whether or not an array of π-rings will exhibit macroscopic degeneracy. Finally, by using the exact solution of 2D Ising model, we propose a new scheme for implementing adiabatic quantum computing which may lead to faster algorithms than those based on conventional methods. Two-dimensional Ising models have been studied extensively over past decades due to their rich physics and wide applications ranging from statistical mechanics [1] , condensed matter physics [2] , and biophysics [3] . Recently, it has also attracted much attention because of its potential use in designing efficient quantum computers [4] .
In this work, we consider the following Hamiltonian,
where Sx = ± 1 are classical spins located at each site x of a square lattice; J1 > 0 denotes the strength of nearest-neighbor ferromagnetic coupling while J2 < 0 represents the strength of next-nearest neighbor antifermomagnetic coupling. Here, h stands for the magnitude of external magnetic field applied along positive z-direction. It should be noted that our results remain valid even if one replaces the term −J2Sx2Sy2 with −J2(Sx1 + Sy1)(Sx2 + Sy2). This is because both terms give rise to same contribution after summation over all sites y such that |y| = 2.",arxiv,bigscience bloomz,705.1643,0.4444444444444444,0.49579831932773116,0.3641025641025641,0.7964644051600573,1,1,0,0,0,1,1,1,0,0,0.07910659081591957,0.1044644649445812,0.08560311284046693,0.11742424242424243,1,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
"Information, information processing and gravity","  I discuss fundamental limits placed on information and information processing
by gravity. Such limits arise because both information and its processing
require energy, while gravitational collapse (formation of a horizon or black
hole) restricts the amount of energy allowed in a finite region. Specifically,
I use a criterion for gravitational collapse called the hoop conjecture. Once
the hoop conjecture is assumed a number of results can be obtained directly:
the existence of a fundamental uncertainty in spatial distance of order the
Planck length, bounds on information (entropy) in a finite region, and a bound
on the rate of information processing in a finite region. In the final section
I discuss some cosmological issues related to the total amount of information
in the universe, and note that almost all detailed aspects of the late universe
are determined by the randomness of quantum outcomes. This paper is based on a
talk presented at a 2007 Bellairs Research Institute (McGill University)
workshop on black holes and quantum information.
","The author considers the problem of gravitational interaction between bodies in terms of their informational content. The main idea is that the gravitational field can be considered as an ensemble of gravitons which carry information about the source body. Gravitational waves are treated as carriers of information on the state of motion of gravitating objects. It is shown how this approach allows one to explain some phenomena observed in astrophysics (the Pioneer anomaly) and cosmology (dark energy). In addition, it is proposed to use the concept of ""information potential"" for describing the evolution of the universe. This article was published by the journal Classical and Quantum Gravity Volume 27, Issue 14, pages 5993-6010, November 2010. DOI: 10.1088/0264-9381/27/14/05993/abstract. The following text is taken directly from the original publication. 
 
 Abstract 
 
 We consider the problem of gravitational interaction among bodies in terms of their information content. The main idea here is that the gravitational field may be viewed as an ensemble of gravitons/quanta carrying information about the source body; gravitational waves are then seen as carriers of information regarding the state of motion of the gravitating objects. This viewpoint enables us to provide explanations for certain phenomena observed in astrophysical settings (e.g., the Pioneer anomaly), as well as in cosmological contexts (e.g., dark energy). Moreover, we propose using the notion of “information potential” to describe the evolution of the Universe.",arxiv,bigscience bloomz,704.1154,0.2777777777777778,0.546218487394958,0.2153846153846154,0.6043956043956045,1,0,1,0,0,1,1,1,0,0,0.14239512570821644,0.08365829098783353,0.15953307392996108,0.08333333333333333,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
The Kinematics and Dynamics of the Globular Clusters and the Planetary Nebulae of NGC 5128,"  A new kinematic and dynamic study of the halo of the giant elliptical galaxy,
NGC 5128, is presented. From a spectroscopically confirmed sample of 340
globular clusters and 780 planetary nebulae, the rotation amplitude, rotation
axis, velocity dispersion, and the total dynamical mass are determined for the
halo of NGC 5128. The globular cluster kinematics were searched for both radial
dependence and metallicity dependence by subdividing the globular cluster
sample into 158 metal-rich ([Fe/H] > -1.0) and 178 metal-poor ([Fe/H] < -1.0)
globular clusters. Our results show the kinematics of the metal-rich and
metal-poor subpopulations are quite similar. The kinematics are compared to the
planetary nebula population where differences are apparent in the outer regions
of the halo. The total mass of NGC 5128 is found using the Tracer Mass
estimator (Evans et al. 2003), to determine the mass supported by internal
random motions, and the spherical component of the Jeans equation to determine
the mass supported by rotation. We find a total mass of (1.0+/-0.2) x 10^(12)
Msun from the planetary nebulae data out to a projected radius of 90 kpc and
(1.3+/-0.5) x 10^(12) Msun from the globular clusters out to a projected radius
of 50 kpc. Lastly, we present a new and homogeneous catalog of known globular
clusters in NGC 5128. This catalog combines all previous definitive cluster
identifications from radial velocity studies and HST imaging studies, as well
as 80 new globular clusters from a study of M.A. Beasley et al. (2007, in
preparation).
","We present new spectroscopic observations for two globular clusters (GCs) in the nearby galaxy NGC 5128, which is known as Centaurus A. The GCs are located at projected distances of ~3 kpc to ~10 kpc from the nucleus of this elliptical galaxy. We have obtained high-resolution spectra with Gemini/GMOS-S on three different nights during 2013-14. These data allow us to measure radial velocities accurate to better than 1 km/sec for both GCs. In addition we also obtain line-of-sight velocity dispersions using these same GMOS-S data. For one cluster, we find that its systemic velocity agrees well with previous measurements by other authors. However, our measurement for the second cluster differs significantly from previously published values. This discrepancy may be due to contamination from an underlying stellar population or possibly because it has been misclassified as a GC.",arxiv,bigscience bloomz,704.1189,0.6111111111111112,0.3445378151260504,0.6410256410256411,0.3463927376970855,1,1,0,0,0,1,1,0,0,0,0.12994121097603065,0.03237431706760395,0.13229571984435798,0.015151515151515152,2,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Stellar Evolution in NGC 6791: Mass Loss on the Red Giant Branch and the Formation of Low Mass White Dwarfs,"  We present the first detailed study of the properties (temperatures,
gravities, and masses) of the NGC 6791 white dwarf population. This unique
stellar system is both one of the oldest (8 Gyr) and most metal-rich ([Fe/H] ~
0.4) open clusters in our Galaxy, and has a color-magnitude diagram (CMD) that
exhibits both a red giant clump and a much hotter extreme horizontal branch.
Fitting the Balmer lines of the white dwarfs in the cluster, using Keck/LRIS
spectra, suggests that most of these stars are undermassive, <M> = 0.43 +/-
0.06 Msun, and therefore could not have formed from canonical stellar evolution
involving the helium flash at the tip of the red giant branch. We show that at
least 40% of NGC 6791's evolved stars must have lost enough mass on the red
giant branch to avoid the flash, and therefore did not convert helium into
carbon-oxygen in their core. Such increased mass loss in the evolution of the
progenitors of these stars is consistent with the presence of the extreme
horizontal branch in the CMD. This unique stellar evolutionary channel also
naturally explains the recent finding of a very young age (2.4 Gyr) for NGC
6791 from white dwarf cooling theory; helium core white dwarfs in this cluster
will cool ~3 times slower than carbon-oxygen core stars and therefore the
corrected white dwarf cooling age is in fact ~7 Gyr, consistent with the well
measured main-sequence turnoff age. These results provide direct empirical
evidence that mass loss is much more efficient in high metallicity environments
and therefore may be critical in interpreting the ultraviolet upturn in
elliptical galaxies.
","We present new optical photometry for the open cluster NGC 6791, obtained with the Wide Field Camera 3 (WFC3) aboard HST as part of program GO-12775 (PI: A. Dotter). The data cover an area of 0.5 deg2 around the cluster center at high spatial resolution (0.1 arcsec/pixel), allowing us to study individual stars down to V = 20 mag. We use these observations together with archival WFC3/UVIS images taken under programs GO-10775 (PI: J. Kalirai) and GO-11775 (PI: S. Casagrande) to derive accurate stellar parameters for more than 1000 red giant branch (RGB) stars in this cluster. Our analysis shows that RGB mass loss is very efficient among low-mass stars, leading to the formation of white dwarfs with masses below 0.45 M . This result has important implications for our understanding of the evolution of low-mass stars near the end of their lives. 
 
 Keywords: Open clusters",arxiv,bigscience bloomz,705.0977,0.3333333333333333,0.24369747899159663,0.7435897435897436,0.37219302436693746,1,1,1,0,1,1,1,1,0,0,0.14816196518080182,0.11593320988474598,0.15953307392996108,0.06060606060606061,0,1,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On Predicting the Solar Cycle using Mean-Field Models,"  We discuss the difficulties of predicting the solar cycle using mean-field
models. Here we argue that these difficulties arise owing to the significant
modulation of the solar activity cycle, and that this modulation arises owing
to either stochastic or deterministic processes. We analyse the implications
for predictability in both of these situations by considering two separate
solar dynamo models. The first model represents a stochastically-perturbed flux
transport dynamo. Here even very weak stochastic perturbations can give rise to
significant modulation in the activity cycle. This modulation leads to a loss
of predictability. In the second model, we neglect stochastic effects and
assume that generation of magnetic field in the Sun can be described by a fully
deterministic nonlinear mean-field model -- this is a best case scenario for
prediction. We designate the output from this deterministic model (with
parameters chosen to produce chaotically modulated cycles) as a target
timeseries that subsequent deterministic mean-field models are required to
predict. Long-term prediction is impossible even if a model that is correct in
all details is utilised in the prediction. Furthermore, we show that even
short-term prediction is impossible if there is a small discrepancy in the
input parameters from the fiducial model. This is the case even if the
predicting model has been tuned to reproduce the output of previous cycles.
Given the inherent uncertainties in determining the transport coefficients and
nonlinear responses for mean-field models, we argue that this makes predicting
the solar cycle using the output from such models impossible.
","The solar cycle is an important phenomenon in space weather, which can have significant effects on Earth and its technological infrastructure. The prediction of future solar activity has been studied for many years with varying degrees of success.  In this work we use mean-field models to predict the next solar cycle (24) based on data from previous cycles. We find that our model predicts the amplitude of the current cycle well but underestimates the length by about one year. Our results suggest that the Sun will enter into minimum phase around 2013-14 followed by maximum phase around 2017-18. This prediction agrees reasonably well with other recent predictions made by different groups. However, it should be noted that there are large uncertainties associated with these predictions due to the chaotic nature of the solar dynamo process. Future observations may help reduce some of these uncertainties. Keywords: Space Weather, Solar Dynamo, Mean Field Modeling, Prediction",arxiv,bigscience bloomz,704.2345,0.6111111111111112,0.3949579831932773,0.6512820512820513,0.3922599139990445,1,1,0,0,0,1,1,1,0,0,0.08950094132994729,0.04112664942309341,0.11673151750972763,0.045454545454545456,2,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0
Hidden Symmetry of the CKM and Neutrino Mapping Matrices,"  We propose that the smallness of the light quark masses is related to the
smallness of the T violation in hadronic weak interactions. Accordingly, for
each of the two quark sectors (""upper"" and ""lower"") we construct a 3\times 3
mass matrix in a bases of unobserved quark states, such that the ""upper""and
""lower"" basis states correspond exactly via the $W^\pm$ transitions in the weak
interaction. In the zeroth approximation of our formulation, we assume T
conservation by making all matrix elements real. In addition, we impose a
""hidden symmetry"" (invariance under simultaneous translations of all three
basis quark states in each sector), which ensures a zero mass eigenstate in
each sector.
  Next, we simultaneously break the hidden symmetry and T invariance by
introducing a phase factor e^{i\chi} in the interaction for each sector. The
Jarlskog invariant J_{CKM}, as well as the light quark masses are evaluated in
terms of the parameters of the model. We find a simple relation with
J_{CKM}=(m_dm_s/m_b^2)^{1/2}A\lambda^3\cos(\chi/2), with A and \lambda the
Wolfenstein parameters. Setting J_{CKM}=3.08 \times 10^{-5}, m_b=4.7GeV,
m_s=95MeV, A=0.818 and \lambda=0.227, we find m_d\cos^2(\chi/2) \simeq 2.4MeV,
consistent with the accepted value m_d=3-7MeV.
  We make a parallel proposal for the lepton sectors. With the hidden symmetry
and in the approximation of T invariance, both the masses of e and \nu_1 are
zero. The neutrino mapping matrix V_\nu is shown to be of the same
Harrison-Scott form which is in agreement with experiments. We also examine the
correction due to T violation, and evaluate the corresponding Jarlskog
invariant {\cal J}_\nu.
","We present an explicit construction for the CKM matrix, VCKM, in terms of the neutrino mixing matrices UPMNS and UMNS. The latter are defined as unitary transformations that diagonalize the Majorana mass matrices MPMNS and MMNS respectively. We show how this mapping can be used to derive relations between observables associated with quarks and leptons. In particular we find that the Jarlskog invariant JCPV is related to the lepton CP violating phase $\Delta$ by $JCPV = 2 \Delta \cos(2 \theta_{13})$ where $\theta_{13}$ denotes the Cabibbo angle. This relation holds independently of whether or not there exists a Dirac CP violating phase in the PMNS matrix. Furthermore it allows us to relate the quark and lepton unitarity triangles. Finally we discuss possible implications on models beyond the Standard Model. Introduction: It has been known since the work of Kobayashi-Maskawa [1] , that the observed pattern of flavor changing neutral currents (FCNCs), which occur at tree level in the standard model (SM), requires new physics contributions [2] . These FCNC processes have so far only been observed within experimental uncertainties consistent with SM predictions [3] .
In order to explain these results one usually assumes that the underlying theory respects some form of approximate symmetry [4] . One possibility would be to assume that the Yukawa couplings respect such symmetries [5] . However, if the fermion masses arise through spontaneous breaking of global symmetries [6] then the resulting effective Lagrangian will contain higher dimensional operators [7] . Such operators may induce large effects in FCNC processes [8] . Alternatively, one could consider extensions of the SM gauge group [9] .",arxiv,bigscience bloomz,705.4156,0.6111111111111112,0.6470588235294118,0.6717948717948717,0.7219302436693742,1,1,0,0,0,1,1,1,0,0,0.11069349550085616,0.09642008833586208,0.1517509727626459,0.125,1,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Top production at the Tevatron/LHC and nonstandard, strongly interacting spin one particles","  In this note, we consider possible constraints from $t \bar t$ production on
the gauge bosons of theories with an extended strong interaction sector such as
axigluons or flavour universal colorons. Such constraints are found to be
competitive with those obtained from the dijet data. The current $t \bar t$
data from the Tevatron rule out axigluon masses ($m_A$) up to 900 GeV and 850
GeV at 2 $\sigma$ and 4 $\sigma$ levels respectively. For the case of flavour
universal colorons the data rule out a mass ($m_C$) below 800 GeV (780 GeV) at
the $2 (4) \sigma $ level and also the mass range between 900 GeV to 2.1 TeV at
2 $\sigma$ level, for $\cot \xi = 1$, where $\xi$ is the mixing angle. For
$\cot \xi =2$ on the other hand, the excluded range is $m_C \lsim 950 (920)$
GeV and $m_C \gsim 1.02 (1.15 \lsim m_C \lsim 1.8)$ TeV at $2 \sigma$ ($4
\sigma $) level. We point out that for higher axigluon/coloron masses, even for
the dijet channel, the limits on the coloron mass, for $\cot \xi = 1$, may be
different than those for the axigluon. We also compute the expected
forward-backward asymmetry for the case of the axigluons which would allow it
to be discriminated against the SM as also the colorons. We further find that
at the LHC, the signal should be visible in the $t \bar t$ invariant mass
spectrum for a wide range of axigluon and coloron masses that are still
allowed. We point out how top polarisation may be used to further discriminate
the axigluon and coloron case from the SM as well as from each other.
",We propose to search for new physics in events with two energetic jets and large missing transverse energy (MET) using data collected by the CDF experiment during Run II of Fermilab's Tevatron Collider. The MET is due to the presence of weakly-interacting stable massive particles that escape detection. We consider models where these particles are produced via interactions mediated by heavy gauge bosons associated with an extended electroweak symmetry group SU(2)xSU(3). In this class of models there exist exotic states such as color octets or triplets which can decay into pairs of quarks and/or gluons leading to final state signatures similar to those expected from supersymmetric theories. These models predict cross sections larger than Standard Model backgrounds over most of the parameter space considered here. This analysis will be performed on 1 fb-1 of integrated luminosity recorded by CDF between 2002-2007 corresponding to about 2 million events.,arxiv,bigscience bloomz,705.1499,0.4444444444444444,0.24369747899159663,0.7948717948717948,0.3750597228858099,1,1,0,0,0,1,1,0,0,1,0.1421684033950182,0.07011006543456372,0.11673151750972763,0.06439393939393939,0,0,6,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Anomalies and de Sitter radiation from the generic black holes in de Sitter spaces,"  Robinson-Wilczek's recent work shows that, the energy momentum tensor flux
required to cancel gravitational anomaly at the event horizon of a
Schwarzschild-type black hole has an equivalent form to that of a
(1+1)-dimensional blackbody radiation at the Hawking temperature. Motivated by
their work, Hawking radiation from the cosmological horizons of the general
Schwarzschild-de Sitter and Kerr-de Sitter black holes, has been studied by the
method of anomaly cancellation. The result shows that the absorbing gauge
current and energy momentum tensor fluxes required to cancel gauge and
gravitational anomalies at the cosmological horizon are precisely equal to
those of Hawking radiation from it. It should be emphasized that the effective
field theory for generic black holes in de Sitter spaces should be formulated
within the region between the event horizon (EH) and the cosmological horizon
(CH), to integrate out the classically irrelevant ingoing modes at the EH and
the classically irrelevant outgoing modes at the CH, respectively.
","We study the thermodynamics of the Schwarzschild-de Sitter (SdS) black hole by using the tunneling method, which is based on the WKB approximation to quantum gravity. We find that there are two kinds of Hawking radiations for this black hole: one is thermal radiation with temperature T = 1/2πr0, where r0 is the radius of event horizon; another is nonthermal radiation with temperature T = 0. The latter can be regarded as the effect of the cosmological constant Λ. In addition, we also calculate the entropy of the SdS black hole and show that it agrees well with Bekenstein-Hawking entropy when the mass M ≫ 1/(8πGΛ). Finally, we discuss some possible applications of our results. It has been shown recently that the existence of the cosmological constant leads to new phenomena in physics [1] . For example, the vacuum fluctuations around an electrically charged particle lead to spontaneous emission [2] , while those around a neutral particle result in stimulated emission [3] . Moreover, the presence of the cosmological constant may affect the evaporation process of black holes [4] .
In fact, the effects of the cosmological constant have already been studied extensively in the literature [5] - [8] . However, most works focus only on static or stationary black holes. Recently, the authors [9] investigated the thermodynamic properties of the Reissner-Nordström-de Sitter (RNdS) black hole by applying the tunneling method [10] . They found that besides the usual thermal radiation, there exists another kind of Hawking radiation whose temperature vanishes at the end point of evaporation. This phenomenon was interpreted as the effect of the negative pressure due to the cosmological constant [11] . Furthermore, they showed that the entropy of the RNdS black hole agrees very well with BekensteinHawking entropy [12] if its charge Q satisfies Q ≫ G/(2πℓ), where ℓ denotes the radius of the event horizon.",arxiv,bigscience bloomz,705.3871,0.16666666666666666,0.6470588235294118,0.16923076923076924,0.8423315814620163,1,1,0,0,1,1,1,1,0,0,0.10912916594948072,0.08337971388880787,0.10116731517509728,0.09848484848484848,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Information-Based Asset Pricing,"  A new framework for asset price dynamics is introduced in which the concept
of noisy information about future cash flows is used to derive the price
processes. In this framework an asset is defined by its cash-flow structure.
Each cash flow is modelled by a random variable that can be expressed as a
function of a collection of independent random variables called market factors.
With each such ""X-factor"" we associate a market information process, the values
of which are accessible to market agents. Each information process is a sum of
two terms; one contains true information about the value of the market factor;
the other represents ""noise"". The noise term is modelled by an independent
Brownian bridge. The market filtration is assumed to be that generated by the
aggregate of the independent information processes. The price of an asset is
given by the expectation of the discounted cash flows in the risk-neutral
measure, conditional on the information provided by the market filtration. When
the cash flows are the dividend payments associated with equities, an explicit
model is obtained for the share-price, and the prices of options on
dividend-paying assets are derived. Remarkably, the resulting formula for the
price of a European call option is of the Black-Scholes-Merton type. The
information-based framework also generates a natural explanation for the origin
of stochastic volatility.
","The information-based asset pricing model is an extension to the traditional CAPM (Capital Assets Pricing Model) that incorporates additional factors into its analysis.  The first factor, market risk premium, represents the excess return investors demand for holding risky assets over and above their returns on low-risk investments such as Treasury bills or bonds.   The second factor, size effect, captures differences in expected returns between small-cap stocks and large-cap stocks.   The third factor, value effect, measures the difference in returns between high book-to-market ratio stocks and low book-to-market ratio stocks; this factor has been shown to be particularly important during periods when interest rates are falling.    This article provides a brief overview of these three factors along with some examples of how they can affect investment decisions. The Capital Assets Pricing Model (CAPM), developed by Sharpe (1964), Lintner (1965), Mossin (1966), and Black (1972), is one of the most widely used models in finance today.  It states that the expected rate of return on any given security should equal the sum of two components - the risk-free rate plus a risk premium associated with the level of systematic risk inherent in each security.  In other words, if you hold a portfolio consisting only of risk-free securities then your expected return will simply be the risk-free rate; however, if you hold a diversified portfolio containing both risky and non-risky securities then your expected rate of return will increase proportionately with the amount of risk you take on.  For example, suppose we have a hypothetical investor who holds a portfolio consisting of 50% U.S. Treasury bills and 50% Standard & Poor’s 500 Index Funds.  If the current yield on 10-year Treasuries is 5% per year while the S&P 500 Index earns 10% annually,...",arxiv,bigscience bloomz,704.1976,0.5555555555555556,0.4453781512605043,0.5076923076923077,0.7849976110845676,0,1,1,0,0,1,1,1,0,0,0.06936182432658144,0.09386648516076361,0.07003891050583658,0.07954545454545454,0,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Non-equilibrium coherence dynamics in one-dimensional Bose gases,"  Low-dimensional systems are beautiful examples of many-body quantum physics.
For one-dimensional systems the Luttinger liquid approach provides insight into
universal properties. Much is known of the equilibrium state, both in the
weakly and strongly interacting regime. However, it remains a challenge to
probe the dynamics by which this equilibrium state is reached. Here we present
a direct experimental study of the coherence dynamics in both isolated and
coupled degenerate 1d Bose gases. Dynamic splitting is used to create two 1d
systems in a phase coherent state. The time evolution of the coherence is
revealed in local phase shifts of the subsequently observed interference
patterns. Completely isolated 1d Bose gases are observed to exhibit a universal
sub-exponential coherence decay in excellent agreement with recent predictions
by Burkov et al. [Phys. Rev. Lett. 98, 200404 (2007)]. For two coupled 1d Bose
gases the coherence factor is observed to approach a non-zero equilibrium value
as predicted by a Bogoliubov approach. This coupled-system decay to finite
coherence is the matter wave equivalent of phase locking two lasers by
injection. The non-equilibrium dynamics of superfluids plays an important role
in a wide range of physical systems, such as superconductors, quantum-Hall
systems, superfluid Helium, and spin systems. Our experiments studying
coherence dynamics show that 1d Bose gases are ideally suited for investigating
this class of phenomena.
","We study the non-equilibrium evolution of an interacting onedimensional Bose gas initially prepared in a coherent state with finite particle number fluctuations and show that it exhibits universal features, which are independent of microscopic details such as interactions or initial conditions. We find that the system evolves into a stationary state characterized by non-vanishing density-density correlations at all distances. The time dependence of these correlations is governed by a single parameter, which we identify with the inverse temperature of the final equilibrium state. This allows us to determine this temperature directly from experimental data without any fitting parameters. Our results provide new insights into the nonequilibrium physics of quantum many-body systems and may be tested experimentally using ultracold atoms trapped in optical lattices. 
I. INTRODUCTORY REMARK
The recent development of techniques for trapping and manipulating cold atomic gases has opened up exciting possibilities for studying strongly correlated quantum matter far from thermal equilibrium [1] . In particular, experiments have demonstrated how isolated quantum systems can evolve towards their ground states [2] , while being driven out of equilibrium by sudden changes in external control parameters [3] .
In this work, we consider the case where the system is suddenly quenched across a phase transition [4] . For example, if the particles were originally confined to a harmonic trap, they would expand freely after switching off the confining potential [5] . Alternatively, the system could be initialized in its ground state [6] before undergoing a rapid change in some other parameter (e.g., magnetic field) [7, 8] . In both cases, the subsequent relaxation process will depend crucially on whether the system was initially prepared close to equilibrium [9] or not [10] . If the latter situation applies, then the system typically relaxes towards a metastable state [11] whose properties cannot be inferred from those of the original equilibrium ensemble [12] .",arxiv,bigscience bloomz,706.2259,0.8333333333333334,0.596638655462185,0.49743589743589745,0.8423315814620163,1,1,0,0,0,1,1,0,0,0,0.07991752215797862,0.08727359746639758,0.08560311284046693,0.10227272727272728,5,1,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Gamma-ray probe of cosmic-ray pressure in galaxy clusters and cosmological implications,"  Cosmic rays produced in cluster accretion and merger shocks provide pressure
to the intracluster medium (ICM) and affect the mass estimates of galaxy
clusters. Although direct evidence for cosmic-ray ions in the ICM is still
lacking, they produce gamma-ray emission through the decay of neutral pions
produced in their collisions with ICM nucleons. We investigate the capability
of the Gamma-ray Large Area Space Telescope (GLAST) and imaging atmospheric
Cerenkov telescopes (IACTs) for constraining the cosmic-ray pressure
contribution to the ICM. We show that GLAST can be used to place stringent
upper limits, a few per cent for individual nearby rich clusters, on the ratio
of pressures of the cosmic rays and thermal gas. We further show that it is
possible to place tight (<~10%) constraints for distant (z <~ 0.25) clusters in
the case of hard spectrum, by stacking signals from samples of known clusters.
The GLAST limits could be made more precise with the constraint on the
cosmic-ray spectrum potentially provided by IACTs. Future gamma-ray
observations of clusters can constrain the evolution of cosmic-ray energy
density, which would have important implications for cosmological tests with
upcoming X-ray and Sunyaev-Zel'dovich effect cluster surveys.
","We present the first measurement of the gamma-ray emission associated with the hot gas in galaxy clusters using data collected by Fermi Large Area Telescope (LAT). We find that the observed gamma-ray luminosity is consistent with theoretical predictions based on the assumption that the energy density of relativistic particles follows closely that of thermal plasma, as expected for hadronic models where cosmic rays are accelerated at shocks driven into intracluster medium by mergers or AGN activity. The inferred cosmic ray pressure is found to be comparable to the thermal pressure within r500 but decreases more rapidly outside this radius. This result suggests that cosmic rays may play an important role in regulating cluster dynamics over large scales. In addition, we use our results together with those obtained previously by Suzaku X-ray observatory to constrain the fraction of nonthermal pressure support in galaxy clusters. Our analysis indicates that the contribution of cosmic rays to total pressure can reach up to 30%-40% inside r500 while it drops below 10% beyond 2r500. Finally, we discuss how these findings could affect constraints on dark matter annihilation cross section derived from observations of galaxy clusters.",arxiv,bigscience bloomz,705.2588,0.3333333333333333,0.29411764705882354,0.358974358974359,0.49832775919732447,1,1,0,0,1,1,1,0,0,0,0.05906481780252049,0.084598092978457,0.08171206225680934,0.09090909090909091,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Recent progresses in the simulation of small-scale magnetic fields,"  New high-resolution observations reveal that small-scale magnetic flux
concentrations have a delicate substructure on a spatial scale of 0.1''. Its
basic structure can be interpreted in terms of a magnetic flux sheet or tube
that vertically extends through the ambient weak-field or field-free atmosphere
with which it is in mechanical equilibrium. A more refined interpretation comes
from new three-dimensional magnetohydrodynamic simulations that are capable of
reproducing the corrugated shape of magnetic flux concentrations and their
signature in the visible continuum. Furthermore it is shown that the
characteristic asymmetric shape of the contrast profile of facular granules is
an effect of radiative transfer across the rarefied atmosphere of the magnetic
flux concentration. I also discuss three-dimensional radiation
magnetohydrodynamic simulations of the integral layers from the top of the
convection zone to the mid-chromosphere. They show a highly dynamic
chromospheric magnetic field, marked by rapidly moving filaments of stronger
than average magnetic field that form in the compression zone downstream and
along propagating shock fronts. The simulations confirm the picture of flux
concentrations that strongly expand through the photosphere into a more
homogeneous, space filling chromospheric field. Future directions in the
simulation of small-scale magnetic fields are indicated by a few examples of
very recent work.
","The origin and evolution of cosmic magnetic fields are one of the most important unsolved problems in astrophysics, which is closely related to many other fundamental issues such as star formation, galaxy formation and structure formation. In this talk I will review our recent work on simulating primordial magnetic fields with different physical processes involved. The first part focuses on the generation of seed magnetic fields during inflation by quantum fluctuations. We show that these seeds can be amplified significantly after reheating due to the magnetohydrodynamic turbulence driven by the decaying inflaton perturbations. Then we discuss how these seeds evolve into large-scale coherent magnetic fields through various mechanisms including inverse cascade, dynamo action and turbulent pumping. Finally, we present some possible observational signatures for future detection. This talk was given at the International Conference on Computation & Theory (ICCT) held in Beijing, China between September 24-27, 2014.",arxiv,bigscience bloomz,705.1848,0.3888888888888889,0.29411764705882354,0.4153846153846154,0.3750597228858099,0,1,0,0,1,1,1,0,0,0,0.051102670021288696,0.06605681607821703,0.04669260700389105,0.056818181818181816,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Evaporation of buffer gas-thermalized anions out of a multipole rf ion trap,"  We identify plain evaporation of ions as the fundamental loss mechanism out
of a multipole ion trap. Using thermalized negative Cl- ions we find that the
evaporative loss rate is proportional to a Boltzmann factor. This thermodynamic
description sheds new light on the dynamics of particles in time-varying
confining potentials. It specifically allows us to extract the effective depth
of the ion trap as the activation energy for evaporation. As a function of the
rf amplitude we find two distinct regimes related to the stability of motion of
the trapped ions. For low amplitudes the entire trap allows for stable motion
and the trap depth increases with the rf field. For larger rf amplitudes,
however, rapid energy transfer from the field to the ion motion can occur at
large trap radii, which leads to a reduction of the effective trapping volume.
In this regime the trap depth decreases again with increasing rf amplitude. We
give an analytical parameterization of the trap depth for various multipole
traps that allows predictions of the most favorable trapping conditions.
","We report on the evaporation of buffer-gas thermalized ions in a linear quadrupole ion trap (QIT). The QIT is filled with helium buffer gas at pressures between 0 and 1 mbar, which leads to temperatures up to 1000 K for trapped ions. We evaporate the ions by lowering the temperature of the surrounding helium bath down to 300 K within less than one second. This results in a significant reduction of the number density inside the QIT without affecting its trapping properties significantly. In this way we are able to reduce the number of stored ions by more than two orders of magnitude while keeping their kinetic energy below 10 eV per charge state. Our experimental findings agree well with theoretical predictions based on rate equations describing the time evolution of the number densities of all relevant species involved. 
 
 Introduction 
 
 Multipole radio-frequency ion traps have been used extensively over the past decades as mass spectrometers [1] . They provide high resolution and sensitivity [2] , but they suffer from space-charge effects when storing large numbers of ions [3] . Space charge can be reduced by cooling the ions [4] or by removing them selectively [5] . Cooling requires sophisticated laser systems [6] that may not always be available. Selective removal has been demonstrated using pulsed electric fields [7, 8] , collisions with neutral atoms [9] , photoionization [10] , electron impact ionization [11] , and resonant photodissociation [12] .
 
In our experiment, we use selective removal via rapid heating of the helium buffer gas [13] . Heating the helium causes the ions to lose their kinetic energy rapidly through elastic collisions [14] . As a result, the ions escape the trap volume before they gain enough energy to cause space charge problems [15] . A similar approach was recently reported [16] where the authors heated the helium buffer gas directly instead of indirectly via the ions [17] . 
 
 Herein, we present detailed measurements of the process of evaporative cooling of buffer gas-thermalised ions in a linear quadrupolar ion trap (QIT) [18] . We show how the number density of the ions decreases exponentially after switching off the helium flow into the vacuum chamber containing the",arxiv,bigscience bloomz,705.0224,0.4444444444444444,0.7983193277310925,0.26666666666666666,1.0,0,1,0,0,0,1,1,0,0,0,0.05634540833838763,0.05044646103642777,0.08560311284046693,0.08712121212121213,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
GRB blastwaves through wind-shaped circumburst media,"  Context:A significant fraction of progenitors for long gamma-ray bursts
(GRBs) are believed to be massive stars. The investigation of long GRBs
therefore requires modeling the propagation of ultra-relativistic blastwaves
through the circumburst medium surrounding massive stars. We simulate the
expansion of an isotropic, adiabatic relativistic fireball into the wind-shaped
medium around a massive GRB progenitor. The circumburst medium is composed of a
realistically stratified stellar wind zone up to its termination shock,
followed by a region of shocked wind characterized by a constant density. Aims:
We followed the evolution of the blastwave through all its stages, including
the extremely rapid acceleration up to a Lorentz factor 75 flow, its
deceleration by interaction with stellar wind, its passage of the wind
termination shock, until its propagation through shocked wind. Methods: We used
the adaptive mesh refinement versatile advection code to follow the evolution
of the fireball. Results: We show that the acceleration from purely thermal to
ultra-relativistic kinetic regimes is abrupt and produces an internally
structured blastwave. We resolved the structure of this ultra-relativistic
shell in all stages, thanks to the adaptive mesh. We comment on the dynamical
roles played by forward and reverse shock pairs in the phase of interaction
with the free stellar wind and clearly identify the complex shock-dominated
structure created when the shell crosses the terminal shock. Conclusion: We
show that in our model where the terminal shock is taken relatively close to
the massive star, the phase of self-similar deceleration of Blandford-McKee
type can only be produced in the constant density, shocked wind zone.
","We present the results of our analysis on GRB 080916C, one of the most energetic bursts ever detected by Swift/BAT and Fermi/GBM. We find that this burst is consistent with being produced in an off-axis jet viewed at an angle θ ~ 60° to its axis. The observed light curve can be explained as emission from two components: (1) A bright component which peaks early during the prompt phase; it has a duration T90 = 1 s and a fluence Fγ = 2×10−6 erg cm−2. (2) An extended tail lasting for several hundred seconds after the end of the prompt phase; it contains about half of the total energy emitted by the source. Using detailed modeling we show that both these features are naturally reproduced if the burst was generated within a dense stellar wind environment surrounding a Wolf-Rayet star. In particular, we demonstrate how the density profile of such winds leads to a double-peaked structure in the time integrated spectrum of the burst.",arxiv,bigscience bloomz,704.2461,0.5,0.24369747899159663,0.6923076923076923,0.4237935977066412,1,1,1,0,0,1,1,1,0,0,0.10383423546781989,0.0567529951114854,0.12062256809338522,0.056818181818181816,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Virtual photons in imaginary time: Computing exact Casimir forces via standard numerical-electromagnetism techniques,"  We describe a numerical method to compute Casimir forces in arbitrary
geometries, for arbitrary dielectric and metallic materials, with arbitrary
accuracy (given sufficient computational resources). Our approach, based on
well-established integration of the mean stress tensor evaluated via the
fluctuation-dissipation theorem, is designed to directly exploit fast methods
developed for classical computational electromagnetism, since it only involves
repeated evaluation of the Green's function for imaginary frequencies
(equivalently, real frequencies in imaginary time). We develop the approach by
systematically examining various formulations of Casimir forces from the
previous decades and evaluating them according to their suitability for
numerical computation. We illustrate our approach with a simple
finite-difference frequency-domain implementation, test it for known geometries
such as a cylinder and a plate, and apply it to new geometries. In particular,
we show that a piston-like geometry of two squares sliding between metal walls,
in both two and three dimensions with both perfect and realistic metallic
materials, exhibits a surprising non-monotonic ``lateral'' force from the
walls.
","We present an efficient method for computing the vacuum energy and force between two parallel plates using only standard numerical electromagnetism methods, without resorting to any approximations or special treatments such as analytic continuation into complex frequencies. The key idea is that we can use the Feynman-Kac formula to express the vacuum expectation value of the stress tensor at finite temperature T = 1/β (where β is the inverse temperature) in terms of the corresponding quantity at zero temperature but with one additional term involving the time evolution operator over a period of length β . We then show how this expression may be evaluated efficiently by expressing it in terms of the Green's function of Maxwell's equations on a periodic domain. This allows us to compute the vacuum energy and force exactly within our computational framework, which consists of solving the vector wave equation numerically on a rectangular grid. Our results are compared against those obtained previously using other approaches, including analytic continuation into complex frequencies and the PFA.",arxiv,bigscience bloomz,705.3661,0.2222222222222222,0.19327731092436976,0.20512820512820512,0.44099378881987583,1,1,0,0,1,1,1,0,0,1,0.10061240826516538,0.11653675135762714,0.10894941634241245,0.10606060606060606,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
A model for the Globular Cluster extreme anomalies,"  In spite of the efforts made in the latest years, still there is no
comprehensive explanation for the chemical anomalies of globular cluster stars.
Among these, the most striking is oxygen depletion, which reaches values down
to [O/Fe]~-0.4 in most clusters, but in M13 it goes down to less than [O/Fe]~ -
1. In this work we suggest that the anomalies are due to the super position of
two different events: 1) PRIMORDIAL SELF-ENRICHMENT: this is asked to explain
the oxygen depletion down to a minimum value [O/Fe]~ -0.4; 2) EXTRA MIXING IN A
FRACTION OF THE STARS ALREADY BORN WITH ANOMALOUS COMPOSITION: these objects,
starting with already low [O/Fe], will reduce the oxygen abundance down to the
most extreme values. Contrary to other models that invoke extra mixing to
explain the chemical anomalies, we suggest that it is active only if there is a
fraction of the stars in which the primordial composition is not only oxygen
depleted, but also extremely helium rich (Y~ 0.4), as found in a few GCs from
their main sequence multiplicity. We propose that the rotational evolution (and
an associated extra mixing) of extremely helium rich stars may be affected by
the fact that they develop a very small or non existent molecular weight
barrier during the evolution. We show that extra mixing in these stars, having
initial chemistry that has already been CNO processed, affects mainly the
oxygen abundance, and to a much smaller extent if affects the sodium abundance.
The model also predicts a large fluorine depletion concomitant with the oxygen
depletion, and a further enhancement of the surface helium abundance, which
reaches values close to Y=0.5 in the computed models. We stress that, in this
tentative explanation, those stars that are primordially O--depleted, but ARE
NOT extremely helium rich do not suffer deep extra mixing.
","We present an explanation to the observed anomalies in globular cluster luminosity functions (GCLFs) and mass-to-light ratios, based on the assumption that these clusters are composed by two different populations with distinct chemical compositions.  We show how this hypothesis can be tested using photometric data obtained at near-infrared wavelengths. The proposed scenario is able to explain all the main observational features associated to GCLFs:  i) the presence of a peaked distribution; ii) its width; iii) the existence of a tail towards high luminosities; iv) the lack of low-luminosity stars. In addition, it also explains why some GCs have very large values of M/LV . Finally we discuss possible implications of our results regarding the formation history of globulars. Keywords: Globular cluster, Mass-to-light ratio, Luminosity function, Chemical composition, Near-infrared",arxiv,bigscience bloomz,705.3401,0.3888888888888889,0.24369747899159663,0.9282051282051282,0.32059245102723366,1,1,1,0,0,1,1,1,0,0,0.16805629661318183,0.11703564378119038,0.16731517509727625,0.10984848484848485,0,0,6,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
"TrES-3: A Nearby, Massive, Transiting Hot Jupiter in a 31-Hour Orbit","  We describe the discovery of a massive transiting hot Jupiter with a very
short orbital period (1.30619 d), which we name TrES-3. From spectroscopy of
the host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +-
0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We
estimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal
variation of our high-precision radial velocity measurements. This variation
has a period and phase consistent with our transit photometry. Our spectra show
no evidence of line bisector variations that would indicate a blended eclipsing
binary star. From detailed modeling of our B and z photometry of the 2.5%-deep
transits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary
radius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of
the known transiting exoplanets, facilitating studies of orbital decay and mass
loss due to evaporation, and making it an excellent target for future studies
of infrared emission and reflected starlight.
","We report the discovery and characterization of TrES-3b, an extrasolar planet with mass M = 1.3 MJup orbiting its host star every 31 hours at 0.081 AU (1.7 stellar radii). The planet is one of only two known transiting planets that are more massive than Saturn but less massive than Neptune; it has a radius R = 2.2 RJup and effective temperature T eff = 2400 K. We find no evidence for additional bodies in this system using radial velocity measurements taken over three years. This planet's proximity to Earth makes it an excellent target for atmospheric studies. 
 
 Keywords: Extrasolar planet - Discovery - Transit photometry - Radial velocities - Atmosphere - Planetary systems 
 
 
 
 Introduction 
 
 In recent years there have been several discoveries of giant exoplanets with orbital periods shorter than four days. These short-period planets are particularly interesting because they may be tidally locked into synchronous rotation about their axes, which would lead to strong day-night contrasts on their surfaces. Furthermore, these planets' atmospheres will experience extreme conditions due to high temperatures and intense radiation fields. As such, understanding how planetary atmospheres respond under these circumstances can provide important insights into processes occurring within our own Solar System as well as other planetary systems. 
 
 Here we present the discovery and initial characterization of TrES-3b; a hot Jupiter with a period P = 3.09 d discovered by the transit method. Using follow-up observations made with the Spitzer Space Telescope, we show that TrES-3b orbits close enough to its parent star so that tidal forces should synchronize the planet's spin axis with its orbital angular momentum vector. However, we do not detect any significant infrared excess emission associated with the planet itself or its host star, indicating that either the planet does not possess a large amount of dusty material surrounding it and/or that the planet is too cool to produce detectable thermal emission beyond 4 microns.",arxiv,bigscience bloomz,705.2004,0.3333333333333333,0.4453781512605043,0.26666666666666666,0.8595317725752508,1,1,0,0,0,1,1,1,0,1,0.0968578451002067,0.10836995975687815,0.0622568093385214,0.14393939393939395,0,0,2,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
The influence of AGN nuclear parameters on the FRI/FRII dichotomy,"  We have investigated the influence of nuclear parameters such as black hole
(BH) mass and photoionizing luminosity on the FRI/FRII transition in a sample
of nearby (z<0.2) 3CR radio galaxies. The sample was observed with
medium-resolution, optical spectroscopy and contains some galaxies with
unpublished velocity dispersion measurements and emission-line fluxes. Measured
velocity dispersions are 130-340 km/s with a mean of 216 km/s. Converting to BH
mass, we find that the BH mass distribution is identical for FRIs and FRIIs,
with a mean of approximately 2.5x10^8 Msun. We convert [OII] and [OIII]
emission-line luminosities to photoionizing luminosity under the assumption
that the gas is ionized by the nuclear UV continuum. Most of the galaxies with
FRI morphology and/or low-excitation emission-line spectra have progressively
lower BH masses at lower photoionizing (and jet) luminosities. This agrees with
the Ledlow-Owen relation which states that the radio luminosity at the FRI/FRII
transition depends on the optical luminosity of the host, L_radio ~
L_optical^1.8, because both L_radio and L_optical relate to AGN nuclear
parameters. When recasting the Ledlow-Owen relation into BH mass versus
photoionizing and jet luminosity, we find that the recasted relation describes
the sample quite well. The FRI/FRII transition occurs at approximately an order
of magnitude lower luminosity relative to the Eddington luminosity than the
soft-to-hard transition in X-ray binaries. This difference is consistent with
the Ledlow-Owen relation, which predicts a weak BH mass dependence in the
transition luminosity. We conclude that the FRI/FRII dichotomy is caused by a
combination of external and nuclear factors, with the latter dominating.
","We study how the properties of active galactic nuclei (AGNs) affect their radio morphologies, and in particular whether they can explain the observed difference between Fanaroff-Riley type I (FRI) and II (FRII). We use high-resolution hydrodynamical simulations to follow the growth of supermassive black holes (SMBHs), which are fed by cold gas accretion at rates that depend on the SMBH mass and its environment. The resulting jets are simulated using relativistic magnetohydrodynamics with an adiabatic index of 4/3. Our results show that FRIs have lower jet powers than FRIIs for similar BH masses because of differences in the accretion rate onto the central BH. This is consistent with observations showing that FRIs typically reside in less massive galaxies compared to FRIIs. In addition, we find that FRIs produce more collimated jets due to higher magnetic field strengths close to the BH horizon.",arxiv,bigscience bloomz,705.1891,0.5555555555555556,0.24369747899159663,0.676923076923077,0.3607262302914477,1,1,0,0,0,1,1,0,0,0,0.06815582816640828,0.07634661595964537,0.058365758754863814,0.06439393939393939,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
New possible properties of atomic nuclei investigated by non linear methods: Fractal and recurrence quantification analysis,"  For the first time we apply the methodologies of nonlinear analysis to
investigate atomic matter. We use these methods in the analysis of Atomic
Weights and of Mass Number of atomic nuclei. Using the AutoCorrelation Function
and Mutual Information we establish the presence of nonlinear effects in the
mechanism of increasing mass of atomic nuclei considered as a function of the
atomic number. We find that increasing mass is divergent, possibly chaotic. We
also investigate the possible existence of a Power Law for atomic nuclei and,
using also the technique of the variogram, we conclude that a fractal regime
could superintend to the mechanism of increasing mass for nuclei. Finally,
using the Hurst exponent, evidence is obtained that the mechanism of increasing
mass in atomic nuclei is in the fractional Brownian regime. The most
interesting results are obtained by using Recurrence Quantification Analysis
(RQA). New recurrences, psudoperiodicities, self-resemblance and class of
self-similarities are identified with values of determinism showing oscillating
values indicating the presence of more or less stability during the process of
increasing mass of atomic nuclei. In brief, new regimes of regularities are
identified for atomic nuclei that deserve to be studied by future researches.
In particular an accurate analysis of binding energy values by nonlinear
methods is further required.
","The present work is devoted to the investigation of new possible nuclear properties using nonlinear methods, namely fractal dimension (FD) and recurrence quantification analysis (RQA). The FD was calculated for different mass number A in order to study its dependence on the system size. It has been found that there exists an optimal value of the scaling parameter which provides the best results for each nucleus separately. This fact indicates that the structure of the studied systems can be characterized as multifractals with non-trivial behavior. In addition we have shown that the obtained values are very close to those predicted by the percolation theory. We also applied RQA method to investigate the temporal evolution of the considered systems. Our calculations show that the complexity of the time series increases with increasing mass number A. Moreover it turns out that this increase follows closely the predictions made within the framework of the Random Matrix Theory. Finally we have compared our results with experimental data available for some light nuclei.",arxiv,bigscience bloomz,704.0903,0.5,0.3949579831932773,0.4564102564102564,0.43526039178213094,1,1,0,0,0,1,1,0,0,0,0.09192702871418552,0.0374686370292163,0.11284046692607004,0.026515151515151516,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
A modified cable formalism for modeling neuronal membranes at high frequencies,"  Intracellular recordings of cortical neurons in vivo display intense
subthreshold membrane potential (Vm) activity. The power spectral density (PSD)
of the Vm displays a power-law structure at high frequencies (>50 Hz) with a
slope of about -2.5. This type of frequency scaling cannot be accounted for by
traditional models, as either single-compartment models or models based on
reconstructed cell morphologies display a frequency scaling with a slope close
to -4. This slope is due to the fact that the membrane resistance is
""short-circuited"" by the capacitance for high frequencies, a situation which
may not be realistic. Here, we integrate non-ideal capacitors in cable
equations to reflect the fact that the capacitance cannot be charged
instantaneously. We show that the resulting ""non-ideal"" cable model can be
solved analytically using Fourier transforms. Numerical simulations using a
ball-and-stick model yield membrane potential activity with similar frequency
scaling as in the experiments. We also discuss the consequences of using
non-ideal capacitors on other cellular properties such as the transmission of
high frequencies, which is boosted in non-ideal cables, or voltage attenuation
in dendrites. These results suggest that cable equations based on non-ideal
capacitors should be used to capture the behavior of neuronal membranes at high
frequencies.
","We present an extension to the cable model that allows one to account for membrane dynamics in neurons with active conductances over a wide range of time scales and spatial dimensions, including those relevant to subthreshold electrogenesis. The proposed approach is based on a reformulation of the cable equation as a system of first-order differential equations describing voltage changes along the axon or dendrite. This formulation leads naturally to a generalization of the concept of space constants to include both passive and active components of the membrane impedance. We show how this generalized cable formalism can be used to describe propagation of action potentials through a single compartment neuron with Hodgkin-Huxley type currents. Finally we demonstrate its utility by applying it to study spatiotemporal patterns of activity in networks of coupled neurons. Neurons are highly specialized cells capable of generating electrical signals known as action potentials (APs). These APs propagate down the length of the cell's axon toward synaptic terminals where they trigger release of neurotransmitters into the synapse. In turn these transmitters bind to receptors located on the postsynaptic side of the synapse initiating signaling cascades which ultimately lead to generation of new APs. Thus information transfer between neurons occurs via propagating APs across chemical synapses.",arxiv,bigscience bloomz,705.3759,0.4444444444444444,0.3949579831932773,0.40512820512820513,0.5470616340181558,1,1,0,0,0,1,1,0,0,1,0.06427577797869134,0.057113032332688475,0.058365758754863814,0.03787878787878788,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1
Non-adiabatic transport in a quantum dot turnstile,"  We present a theoretical study of the electronic transport through a
many-level quantum dot driven by time-dependent signals applied at the contacts
to the leads. If the barriers oscillate out of phase the system operates like a
turnstile pump under a finite constant bias, as observed in the experiments of
Kouwenhoven {\it et al.} [Phys. Rev. Lett. {\bf 67}, 1626 (1991)]. The
time-dependent currents and their averages over succesive pumping periods are
computed from the Keldysh formalism for tight-binding models. The calculation
considers a sudden application of the pumping potentials at $t=0$ which leads
to transient features of the time-dependent and averaged currents during the
first pumping cycles which turn out to be important in the high-frequency
regime. We show that in the transient regime the efficiency of the system as a
pump is rather poor because it mainly absorbs charge from both leads in order
to fill the levels located below the bias window. Under a finite bias and a
low-frequency pumping signal the charge transferred across the system depends
on the number of levels located within the bias window. The internal charge
dynamics and the role of energy sidebands are investigated. The so called
satellite peaks of the averaged current are observed also in the transient
regime.
","We study the non-adiabatic current through an open quantum dot connected to two leads with different chemical potentials, which is driven by time-dependent gate voltages applied on both sides of the dot. We show that this system can be described as a ""turnstile"" where electrons are pumped between the leads when the driving frequencies match certain resonances. The effect is robust against disorder and dephasing. This work was supported by NSERC (Canada) and CIFAR (Canadian Institute for Advanced Research). In recent years there has been growing interest in studying electron pumps based on semiconductor nanostructures such as quantum dots or carbon nanotubes [1, 2] . These devices have potential applications ranging from metrology [3] , single-electron transistors [4] , and spintronics [5] .
In these systems, charge carriers are transported across the device via sequential tunneling processes [6] . A number of theoretical studies [7, 8] have shown that it is possible to achieve high efficiency in these devices even at room temperature [9] . However, most previous works focused only on adiabatic pumping [10] , i.e., the case where the frequency of the external drive is much smaller than all other relevant energy scales [11] . Recently, several experiments [12, 13] reported large currents generated by nonadiabatic pumping [14, 15] . It remains unclear whether these results can be explained within existing theories [16] .
Here we consider a simple model of a quantum dot connected to two metallic leads [see Fig. 1(a) ] [17] . The dot level is modulated periodically by applying oscillating gate voltages V L/R = ±V 0 cos ωt on each side of the dot [18] . When the modulation period T ≡ 2π/ω matches one of the dwell times τ n = π /[2(E F − E n )] associated with the discrete levels E n of the isolated dot, electrons will be transferred coherently between the left and right leads [19] . Here E F denotes the Fermi energy of the leads [20] . As illustrated schematically in Figs. 1(b-c), depending on",arxiv,bigscience bloomz,706.0968,0.6111111111111112,0.8487394957983193,0.441025641025641,0.9283325370281892,1,1,0,0,0,1,1,0,0,0,0.12723181902715988,0.10375866426589547,0.11673151750972763,0.14015151515151514,3,4,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Holography in Three-dimensional Kerr-de Sitter Space with a Gravitational Chern-Simons Term,"  The holographic description of the three-dimensional Kerr-de Sitter space
with a gravitational Chern-Simons term is studied, in the context of dS/CFT
correspondence. The space has only one (cosmological) event horizon and its
mass and angular momentum are identified from the holographic energy-momentum
tensor at the asymptotic infinity. The thermodynamic entropy of the
cosmological horizon is computed directly from the first law of thermodynamics,
with the usual Hawking temperature, and it is found that the usual
Gibbons-Hawking entropy is modified. It is remarked that, due to the
gravitational Chern-Simons term, (a) the results go beyond analytic
continuation from AdS, (b) the maximum-mass/N-bound conjecture may be violated,
and (c) the three-dimensional cosmology is chiral. A statistical mechanical
computation of the entropy, from a Cardy-like formula for a dual CFT at the
asymptotic boundary, is discussed. Some technical difference in the
Chern-Simons energy-momentum tensor, from literatures is remarked also.
","We study the holographic entanglement entropy for three-dimensional de Sitter space with gravitational Chern-Simons term by using the replica trick and the covariant phase-space method. We find that there is no logarithmic correction to the entanglement entropy, which agrees with previous results obtained via other methods. In addition, we show that the first-order corrections are proportional to the square root of the volume enclosed by the entangling surface. Finally, we calculate the second-order corrections and obtain an expression containing two terms. One of them has been previously found in Ref. [Phys. Rev. D 98 (2018) 084011] while another one is new. The latter can be written as a sum over all possible contractions between the Riemann tensor and its derivatives at the boundary points. This result shows that the gravitational Chern-Simons coupling constant plays a role similar to the Newton's constant in four dimensions.",arxiv,bigscience bloomz,705.4381,0.2777777777777778,0.4453781512605043,0.11794871794871795,0.36645962732919257,1,1,0,0,0,1,1,0,0,1,0.08845682462322911,0.07164354437965237,0.07782101167315175,0.026515151515151516,0,3,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,1
The nature of a broad line radio galaxy: Simultaneous RXTE and Chandra HETG observations of 3C 382,"  We present the results from simultaneous chandra and rxte observations of the
X-ray bright Broad-Line Radio Galaxy (BLRG) 3C 382. The long (120 ks) exposure
with chandra HETG allows a detailed study of the soft X-ray continuum and of
the narrow component of the Fe Kalpha line. The rxte PCA data are used to put
an upper limit on the broad line component and constrain the hard X-ray
continuum. A strong soft excess below 1 keV is observed in the time-averaged
HETG spectrum, which can be parameterized with a steep power law or a thermal
model. The flux variability at low energies indicates that the origin of the
soft excess cannot be entirely ascribed to the circumnuclear diffuse emission,
detected by chandra on scales of 20-30 arcsec (22-33 kpc). A narrow (sigma<90
eV) Fe Kalpha line (with EW< 100 eV) is observed by the chandra HEG. Similar
values for the line parameters are measured by the rxte PCA, suggesting that
the contribution from a broad line component is negligible. The fact that the
exposure is split into two observations taken three days apart allows us to
investigate the spectral and temporal evolution of the source on different
timescales. Significant flux variability associated with spectral changes is
observed on timescales of hours and days. The spectral variability is similar
to that observed in radio-quiet AGN ruling out a jet-dominated origin of the
X-rays.
","We present the results of simultaneous X-ray (Chandra) and radio (RXTE )observations of the Broad Line Radio Galaxy, 3C382 . The data were taken on 2001 September 24-25 UT during an outburst in which the source was detected at radio frequencies as high as 22 GHz. We find that the X-ray spectrum is well described by a power law with photon index Γ = 1.7 ± 0.1 modified by photoelectric absorption consistent with N_H = 2 x 1022 cm-2. There are no significant spectral changes between the two epochs observed. In addition to the continuum emission we detect several narrow lines including Fe Kα , He-like Si XIII , S XV and Ar XVII . These features appear blueshifted relative to their rest wavelengths indicating bulk motion towards us along our line-of-sight. Using these velocities together with estimates for the mass of the central black hole derived from optical measurements we estimate the distance of the emitting material from the center of the AGN to be ~10 light days.",arxiv,bigscience bloomz,704.2756,0.5,0.29411764705882354,0.558974358974359,0.4381270903010034,1,1,0,0,0,1,1,0,0,0,0.05627707251907111,0.068827461703976,0.054474708171206226,0.06818181818181818,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Exact half-BPS Type IIB interface solutions I: Local solution and supersymmetric Janus,"  The complete Type IIB supergravity solutions with 16 supersymmetries are
obtained on the manifold $AdS_4 \times S^2 \times S^2 \times \Sigma$ with
$SO(2,3) \times SO(3) \times SO(3)$ symmetry in terms of two holomorphic
functions on a Riemann surface $\Sigma$, which generally has a boundary. This
is achieved by reducing the BPS equations using the above symmetry
requirements, proving that all solutions of the BPS equations solve the full
Type IIB supergravity field equations, mapping the BPS equations onto a new
integrable system akin to the Liouville and Sine-Gordon theories, and mapping
this integrable system to a linear equation which can be solved exactly.
Amongst the infinite class of solutions, a non-singular Janus solution is
identified which provides the AdS/CFT dual of the maximally supersymmetric
Yang-Mills interface theory discovered recently. The construction of general
classes of globally non-singular solutions, including fully back-reacted $AdS_5
\times S^5$ and supersymmetric Janus doped with D5 and/or NS5 branes, is
deferred to a companion paper.
","We present the first exact local solution to the equations of motion for type II B supergravity in AdS 5 × S 5 . The solution is supported by two independent harmonic functions, one on each side of an arbitrary surface Σ which divides space into three regions. We show that this solution preserves eight real supercharges and has vanishing central charge. It can be interpreted as a bound state of N = 4 SYM theory with gauge group SU(N)×SU(N), where the number of degrees of freedom scales like O(N 2 ) at large N. In addition we find a new class of solutions describing interfaces between different vacua of the same field theory. These are obtained by taking appropriate limits of our general solution. They preserve four supercharges and have non-vanishing central charges. One particular member of this family describes a supersymmetric Janus-like configuration interpolating between two distinct conformal fixed points of the same field theory. 
Introduction

The study of holographic duals of strongly coupled quantum systems has been greatly advanced over recent years through the use of string/M-theory [1, 2] . A particularly interesting application of these ideas involves studying non-conformal theories using their dual description in terms of gravitational backgrounds [3, 4] .
In order to construct such models it is necessary to solve the equations of motion associated with the relevant supergravity or gauged supergravity theory. This problem becomes more tractable when considering specific classes of solutions preserving some fraction of the original supersymmetry [5] , since only certain combinations of fields may then appear [6] . For example, if one considers configurations preserving all but one of the original supersymmetries (BPS states), then the resulting system will depend upon just five scalar fields [7, 8] . However, even in this case finding explicit solutions remains difficult [9] .
One approach to solving BPS-type problems is to consider special cases where the geometry admits additional symmetries [10] . An important subclass of such solutions arises when the internal manifold M 6 factorises into a product of two spaces M 3 × M 3 [11] . In this",arxiv,bigscience bloomz,705.0022,0.16666666666666666,0.3697478991596639,0.18461538461538463,0.45676063067367423,1,1,0,0,0,2,2,0,0,0,0.14906896527378868,0.11859649796269561,0.13618677042801555,0.17803030303030304,0,3,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,2,1,1
Homogenized spectral problems for exactly solvable operators: asymptotics of polynomial eigenfunctions,"  Consider a homogenized spectral pencil of exactly solvable linear
differential operators $T_{\la}=\sum_{i=0}^k Q_{i}(z)\la^{k-i}\frac
{d^i}{dz^i}$, where each $Q_{i}(z)$ is a polynomial of degree at most $i$ and
$\la$ is the spectral parameter. We show that under mild nondegeneracy
assumptions for all sufficiently large positive integers $n$ there exist
exactly $k$ distinct values $\la_{n,j}$, $1\le j\le k$, of the spectral
parameter $\la$ such that the operator $T_{\la}$ has a polynomial eigenfunction
$p_{n,j}(z)$ of degree $n$. These eigenfunctions split into $k$ different
families according to the asymptotic behavior of their eigenvalues. We
conjecture and prove sequential versions of three fundamental properties: the
limits $\Psi_{j}(z)=\lim_{n\to\infty} \frac{p_{n,j}'(z)}{\la_{n,j}p_{n,j}(z)}$
exist, are analytic and satisfy the algebraic equation $\sum_{i=0}^k Q_{i}(z)
\Psi_{j}^i(z)=0$ almost everywhere in $\bCP$. As a consequence we obtain a
class of algebraic functions possessing a branch near $\infty\in \bCP$ which is
representable as the Cauchy transform of a compactly supported probability
measure.
","We study the asymptotic behavior as $|x|\to\infty$ of solutions to certain homogenized spectral problems associated with Schrödinger-type operators on unbounded domains in $R^n$, $n\geq 3$.  We show that if the potential is periodic and satisfies some mild decay conditions at infinity then there exists an explicit formula for the leading term of this expansion which involves only the first two terms of the Taylor series of the potential about zero. This result generalizes previous results obtained by one of us (S.V.) for potentials satisfying stronger decay assumptions near infinity. 
The proof relies heavily on the fact that the spectrum of these operators consists entirely of eigenvalues of finite multiplicity. The main idea behind our approach is to use the method of matched asymptotic expansions together with suitable integral representations of the solution to obtain information about its large-$x$ behavior. In particular we prove that under appropriate hypotheses on the coefficients of the operator the solution has an exponential decay rate at infinity.",arxiv,bigscience bloomz,705.2822,0.2222222222222222,0.29411764705882354,0.11794871794871795,0.4180602006688964,1,1,1,0,1,1,1,0,0,0,0.27846306197796483,0.10110791899844923,0.29961089494163423,0.10606060606060606,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Dirichlet sigma models and mean curvature flow,"  The mean curvature flow describes the parabolic deformation of embedded
branes in Riemannian geometry driven by their extrinsic mean curvature vector,
which is typically associated to surface tension forces. It is the gradient
flow of the area functional, and, as such, it is naturally identified with the
boundary renormalization group equation of Dirichlet sigma models away from
conformality, to lowest order in perturbation theory. D-branes appear as fixed
points of this flow having conformally invariant boundary conditions. Simple
running solutions include the paper-clip and the hair-pin (or grim-reaper)
models on the plane, as well as scaling solutions associated to rational (p, q)
closed curves and the decay of two intersecting lines. Stability analysis is
performed in several cases while searching for transitions among different
brane configurations. The combination of Ricci with the mean curvature flow is
examined in detail together with several explicit examples of deforming curves
on curved backgrounds. Some general aspects of the mean curvature flow in
higher dimensional ambient spaces are also discussed and obtain consistent
truncations to lower dimensional systems. Selected physical applications are
mentioned in the text, including tachyon condensation in open string theory and
the resistive diffusion of force-free fields in magneto-hydrodynamics.
","We study the relationship between Dirichlet sigma-models on Riemannian manifolds with boundary, and mean curvature flows in the interior of these manifolds.  We show that if the initial metric is conformally equivalent to the standard round sphere then there exists an explicit solution for all time which converges exponentially fast towards the round sphere as $t \to \infty$.   In particular we prove that this holds true even when the manifold has corners or conical singularities at its boundary.    The results are obtained by combining techniques from geometric analysis (in particular heat kernel estimates) and functional analysis (in particular spectral theory).    Keywords: Mean Curvature Flow, Sigma Models, Conformal Geometry, Geometric Analysis, Functional Analysis. 1 Introduction   Let $(M^n,g_0)$ be a compact smooth Riemannian n-manifold with nonempty boundary $\partial M = \varnothing$. Consider the following evolution equation for metrics $g_t$ on $M$:  $$\displaystyle g_{t+1} = e^{-2tH_g}g_t$$ where $H_g$ denotes the mean curvature vector field of the hypersurface $M^n$ equipped with the metric $g$. This is called the Ricci-DeTurck flow [DeT84], since it can also be written as:  $$\displaystyle g^{ij}_{t} = e^{-2tH_{g}}g^{ij}_0 + 2e^{-2tH_{g}}\Gamma_{ij}^{k}\nabla_k \log g_{0j}$$ Here, $\Gamma_{ij}^{k}$ denote the Christoffel symbols associated to the metric $g$. If one starts with a metric $g$ such that the scalar curvature $R_g$ satisfies $R_g > 0$ everywhere, then the above flow preserves positivity of the scalar curvature. Moreover, if the initial metric is Einstein, i.e., $R_g = c g_0$ for some constant $c>0$, then the flow will preserve Einstein-ness.",arxiv,bigscience bloomz,704.3985,0.3888888888888889,0.4453781512605043,0.38461538461538464,0.6502627806975634,1,1,0,0,0,1,1,1,0,0,0.08883165106560802,0.17721921345504027,0.10505836575875487,0.1893939393939394,0,0,2,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
The KATRIN sensitivity to the neutrino mass and to right-handed currents in beta decay,"  The aim of the KArlsruhe TRItium Neutrino experiment KATRIN is the
determination of the absolute neutrino mass scale down to 0.2 eV, with
essentially smaller model dependence than from cosmology and neutrinoless
double beta decay. For this purpose, the integral electron energy spectrum is
measured close to the endpoint of molecular tritium beta decay. The endpoint,
together with the neutrino mass, should be fitted from the KATRIN data as a
free parameter. The right-handed couplings change the electron energy spectrum
close to the endpoint, therefore they have some effect also to the precise
neutrino mass determination. The statistical calculations show that, using the
endpoint as a free parameter, the unaccounted right-handed couplings
constrained by many beta decay experiments can change the fitted neutrino mass
value, relative to the true neutrino mass, by not larger than about 5-10 %.
Using, incorrectly, the endpoint as a fixed input parameter, the above change
of the neutrino mass can be much larger, order of 100 %, and for some cases it
can happen that for large true neutrino mass value the fitted neutrino mass
squared is negative. Publications using fixed endpoint and presenting large
right-handed coupling effects to the neutrino mass determination are not
relevant for the KATRIN experiment.
","The Karlsruhe Tritium Neutrino experiment (KATRIN) is currently under construction at the Karlsruhe Institute for Technology, Germany. It will measure the electron energy spectrum near the endpoint with unprecedented precision by using an electrostatic retardation spectrometer combined with a magnetic filter. The measurement aims at determining the absolute value of the effective electron antineutrino mass mneff with a statistical uncertainty of 0.2 eV/c2 or better. In this contribution we present results on the expected sensitivities of KATRIN to mneff as well as to possible contributions from right-handed currents in beta-decay. We show that these sensitivities are mainly determined by systematic uncertainties which can be controlled within the experimental accuracy required. This allows us to conclude that KATRIN has excellent prospects to determine mneff precisely enough to test whether it agrees with the predictions of standard model extensions such as supersymmetry.",arxiv,bigscience bloomz,704.393,0.3333333333333333,0.24369747899159663,0.4205128205128205,0.35499283325370284,0,1,0,0,0,1,1,0,0,0,0.11342972646398301,0.025859604929172265,0.10894941634241245,0.022727272727272728,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Role of the rho meson in the description of pion electroproduction experiments at JLab,"  We study the p(e,e' pi+)n reaction in the framework of an effective
Lagrangian approach including nucleon, pi and rho meson degrees of freedom and
show the importance of the rho-meson t-pole contribution to sigmaT, the
transverse part of cross section. We test two different field representations
of the rho meson, vector and tensor, and find that the tensor representation of
the rho meson is more reliable in the description of the existing data. In
particular, we show that the rho-meson t-pole contribution, including the
interference with an effective non-local contact term, sufficiently improves
the description of the recent JLab data at invariant mass W less 2.2 GeV and Q2
less 2.5 GeV2/c2. A ``soft'' variant of the strong piNN and rhoNN form factors
is also found to be compatible with these data. On the basis of the successful
description of both the sigmaL and sigmaT parts of the cross section we discuss
the importance of taking into account the sigmaT data when extracting the
charge pion form factor Fpi from sigmaL.
","We present results on the role played by the rho meson in describing pion electroproduction data obtained with the CLAS detector at Jefferson Lab (JLab). The analysis is performed within an effective field theory approach, where we use chiral perturbation theory to describe the interaction between pions and nucleons up to next-to-leading order. We then introduce vector-meson degrees of freedom through the hidden gauge formalism. In particular, we consider contributions coming from one-loop diagrams involving rho mesons as well as tree-level processes mediated by rho mesons. Our theoretical framework allows us to study both neutral current reactions such as elastic ep scattering or charged current reactions like single-pion production off protons. Using this model, we are able to reproduce experimental data for all these observables simultaneously. Finally, we discuss how our findings can be used to extract information about the properties of the rho meson. This work was supported by the U.S. 


Department of Energy under Contract No. DE-SC0012704.

PACS numbers: 12.38.Mh",arxiv,bigscience bloomz,706.1844,0.2222222222222222,0.12605042016806722,0.24615384615384617,0.10845676063067367,1,1,0,0,1,1,2,1,0,0,0.08634028087782081,0.024297076543273375,0.07782101167315175,0.04924242424242424,0,4,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,3,0,1
Constraining the Geometry of the Neutron Star RX J1856.5-3754,"  RX J1856.5-3754 is one of the brightest, nearby isolated neutron stars, and
considerable observational resources have been devoted to its study. In
previous work, we found that our latest models of a magnetic, hydrogen
atmosphere matches well the entire spectrum, from X-rays to optical (with
best-fitting neutron star radius R=14 km, gravitational redshift z_g~0.2, and
magnetic field B~4x10^12 G). A remaining puzzle is the non-detection of
rotational modulation of the X-ray emission, despite extensive searches. The
situation changed recently with XMM-Newton observations that uncovered 7 s
pulsations at the 1% level. By comparing the predictions of our model (which
includes simple dipolar-like surface distributions of magnetic field and
temperature) with the observed brightness variations, we are able to constrain
the geometry of RX J1856.5-3754, with one angle < 6 deg and the other angle =
20-45 deg, though the solutions are not definitive given the observational and
model uncertainties. These angles indicate a close alignment between the
rotation and magnetic axes or between the rotation axis and the observer. We
discuss our results in the context of RX J1856.5-3754 being a normal radio
pulsar and a candidate for observation by future X-ray polarization missions
such as Constellation-X or XEUS.
","We present new observations and analysis of the neutron star (NS) candidate RX J1856.5-37543, which is one of only two NSs with measured parallaxes to date.  We use these measurements along with optical photometry in order to constrain its radius and distance as well as the interstellar extinction towards it. Our results are consistent with previous estimates for this source's radius but we find that our best-fit model has an unusually large value of A V = 1.6 ± 0.2 mag compared to other nearby stars. This suggests that there may be additional absorption by dust associated with the system or possibly even circumstellar material around the NS itself. The latter possibility would have important implications for understanding how such objects form. Subject headings: Black holes - accretion disks - binaries -X-ray sources: general - Stars: neutron - Parallaxes: fundamental constants - Stellar radii",arxiv,bigscience bloomz,705.4543,0.3333333333333333,0.24369747899159663,0.38974358974358975,0.36645962732919257,1,1,0,0,0,1,1,1,0,1,0.15445244853072276,0.059730692898013756,0.17898832684824903,0.03787878787878788,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A discrete computer network model with expanding dimensions,"  Complex networks with expanding dimensions are studied, where the networks
may be directed and weighted, and network nodes are varying in discrete time in
the sense that some new nodes may be added and some old nodes may be removed
from time to time. A model of such networks in computer data transmission is
discussed. Each node on the network has fixed dimensionality, while the
dimension of the whole network is defined by the total number of nodes. Based
on the spectacular properties of data transmission on computer networks, some
new concepts of stable and unstable networks differing from the classical
Lyapunov stability are defined. In particular, a special unstable network
model, called devil network, is introduced and discussed. It is further found
that a variety of structures and connection weights affects the network
stability substantially. Several criteria on stability, instability, and devil
network are established for a rather general class of networks, where some
conditions are actually necessary and sufficient. Mathematically, this paper
makes a first attempt to rigorously formulate a fundamental issue of modeling
discrete linear time-varying systems with expanding dimensions and study their
basic stability property.
","We present an algorithm for the construction of a discrete computer network in which each node is connected to all nodes within its distance, and also to some other nodes at larger distances. The number of additional connections per node increases exponentially as one moves away from it along any path. We show that this property can be used to construct efficient routing tables for such networks. Our results are based on a new concept called ""expanding dimension"". This concept allows us to define a natural hierarchy among the nodes of our network. In particular, we prove that if there exists a polynomial time algorithm for finding shortest paths between two given nodes then there must exist another polynomial time algorithm for solving the same problem but restricted only to pairs of nodes whose distance belongs to a certain range. Finally, we discuss possible applications of these ideas to distributed computing problems. Keywords: Computer network, Expanding Dimension, Hierarchy, Routing",arxiv,bigscience bloomz,705.0855,0.3888888888888889,0.3445378151260504,0.3384615384615385,0.4094601051122791,0,1,0,0,0,0,0,1,0,0,0.09638689654770477,0.10586741839841826,0.13618677042801555,0.11742424242424243,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1
Dynamic response of Ag monolayers adsorbed on Au(100) upon an oscillatory variation of the chemical potential: A Monte Carlo simulation study,"  Based on the fact that the underpotential electrochemical deposition of Ag
atoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at
well-defined values of the (coexistence) chemical potential ($\mu_{coex}$), we
performed extensive simulations aimed at investigating the hysteretic dynamic
behavior of the system close to coexistence upon the application of a periodic
signal of the form $\mu(t) = \mu_{coex} + \mu_{o}sin(2\Pi t/\tau) $, where
$\mu_{o}$ and $\tau$ are the amplitude and the period of the sweep,
respectively. For relatively short periods and small enough amplitudes the
system becomes trapped either at low or high Ag coverage states, as evidenced
by recording hysteresis loops. This scenario is identified as dynamically
ordered states (DOS), such that the relaxation time $(\tau_{relax})$ of the
corresponding metastable state obeys $\tau_{relax} > \tau $. On the other hand,
by properly increasing $\mu_{o}$ or/and $\tau$, one finds that the $Ag$
coverage gently follows the external drive (here $\tau_{relax} < \tau $) and
the system is said to enter into dynamically disordered states (DDS), where
hysteresis loops show almost symmetric limiting cycles. This symmetry breaking
between limiting cycles driven by an external signal is discussed in terms of
the concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and
DDS, similar to those encountered when a magnetic system is placed in the
presence of a variable external magnetic field. However, a careful finite-size
scaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system
does not exhibit true second-order phase transitions but rather a crossover
behavior between states. A diagram showing the location of the ordered and
disordered states in the $\mu$ versus $\tau$ plane is obtained and discussed.
","We have studied by means of molecular dynamics simulations how the dynamic behavior of silver atoms deposited on gold (100) is affected when the substrate temperature and the coverage are varied in such a way that the average number of nearest neighbors per atom changes between 1 to 4. We find that, for low coverages, the system behaves as if it were made up of isolated particles with no interaction among them. However, at higher coverages we observe collective effects which lead to the formation of ordered structures. The results obtained show that these structures can be classified into two different categories depending on whether they are formed by one or more layers of silver atoms. In particular, we found that the structure of the first layer depends strongly on the substrate temperature while the second layer shows only small variations. Finally, our calculations indicate that the third layer forms a disordered arrangement of silver atoms. This work was supported by DGESIC under project PB98-0443-C02-01",arxiv,bigscience bloomz,705.447,0.3333333333333333,0.29411764705882354,0.7692307692307693,0.42666029622551366,1,1,0,0,0,1,1,0,0,0,0.28089220578954166,0.10857662287498022,0.3463035019455253,0.08333333333333333,0,1,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
High-energy threshold reaction rates on 0.8 GeV proton-irradiated thick Pb-target,"  This works presents results of activation-aided determination of threshold
reaction rates in 92 209Bi, natPb, 197Au, 181Ta, 169Tm, natIn, 93Nb, 64Zn,
65Cu, 63Cu, 59Co, 19F, and 12C samples and in 121 27Al samples. All the samples
were aligned with the proton beam axis inside and outside the demountable 92-cm
thick Pb target of 15-cm diameter assembled of 23 4-cm thick discs. The samples
were placed on 12 target disks to reproduce the long axis distribution of
protons and neutrons. In June 2006, the target was exposed for 18 hours to a
800-MeV proton beam extracted from the ITEP U-10 accelerator. The proton
fluence and the proton beam shape were determined using the 27Al(p,x)7Be
monitor reaction. The reaction rates were determined by the direct
gamma-spectrometry techniques. In total, 1196 gamma-spectra have been measured,
and about 1500 reaction rates determined. The measured reaction rates were
simulated by the MCNPX code using the following databases: ENDF/B6 for neutrons
below 20 MeV, MENDL2 for 20-100 MeV neutrons, and MENDL2P for proton cross
sections up to 200 MeV. An acceptable agreement of simulations with
experimental data has been found.
","The high-energy threshold reaction rates for the reactions induced by protons with energies up to 800 MeV are calculated using the statistical model code TALYS-1.6 and compared with experimental data obtained at JINR-Dubna in the framework of the project ""Study of nuclear processes under extreme conditions"". The results show that the theoretical predictions agree well with experiment within uncertainties, except for some cases where there is an overestimation or underestimation of the measured cross sections. 
 
 Keywords: Reaction rate, Thick target, Proton beam, Statistical model, Nuclear physics, Cross section measurement, High energy threshold reaction rate calculation, Extreme condition study, Projectile fragmentation, Heavy ion collision, Energy deposition, Radiation damage, Lead target, Inverse kinematics, Fragmentation function, Neutron emission probability distribution, Excitation functions, Stopping power, Energy loss straggling, Energy transfer",arxiv,bigscience bloomz,705.1024,0.4444444444444444,0.09243697478991597,0.3128205128205128,0.31485905398948877,1,1,1,0,0,0,1,1,0,0,0.1085221571085966,0.14185371301756933,0.10505836575875487,0.13636363636363635,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Information diffusion epidemics in social networks,"  The dynamics of information dissemination in social networks is of paramount
importance in processes such as rumors or fads propagation, spread of product
innovations or ""word-of-mouth"" communications. Due to the difficulty in
tracking a specific information when it is transmitted by people, most
understanding of information spreading in social networks comes from models or
indirect measurements. Here we present an integrated experimental and
theoretical framework to understand and quantitatively predict how and when
information spreads over social networks. Using data collected in Viral
Marketing campaigns that reached over 31,000 individuals in eleven European
markets, we show the large degree of variability of the participants' actions,
despite them being confronted with the common task of receiving and forwarding
the same piece of information. This have a profound effect on information
diffusion: Firstly, most of the transmission takes place due to super-spreading
events which would be considered extraordinary in population-average models.
Secondly, due to the different way individuals schedule information
transmission we observe a slowing down of the spreading of information in
social networks that happens in logarithmic time. Quantitative description of
the experiments is possible through an stochastic branching process which
corroborates the importance of heterogeneity. Since high variability of both
the intensity and frequency of human responses are found in many other
activities, our findings are pertinent to many other human driven diffusion
processes like rumors, fads, innovations or news which has important
consequences for organizations management, communications, marketing or
electronic social communities.
","We study information diffusion on networks with multiple communities, where each community has its own set of nodes and edges. We propose an epidemic model that captures the effect of both global and local interactions between users within different communities. The proposed model is based on two key ideas: (1) we assume that there are some influential individuals who can spread information to their neighbors faster than others; and (2) we allow for cross-influences among neighboring communities through these influential individuals. Our main goal is to understand how the structure of the underlying network affects the spreading process. In particular, our contributions include:  1. We develop a novel mathematical framework to analyze the dynamics of information diffusion under the proposed epidemic model. 2. We show that if all communities have similar sizes then the number of infected nodes at time t grows as O(t log n), where n denotes the total number of nodes in the network. 3. We prove that if one community dominates the other ones by size then the number of infected individuals grows exponentially fast. 4. Finally, we provide extensive numerical experiments to validate our theoretical results.",arxiv,bigscience bloomz,706.0641,0.3888888888888889,0.546218487394958,0.6153846153846154,0.5011944577161969,0,1,1,0,1,1,1,1,0,0,0.1070881844747106,0.11821650120818558,0.13618677042801555,0.125,0,4,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Near- and Far-Infrared Counterparts of Millimeter Dust Cores in the Vela Molecular Ridge Cloud D,"  The aim of this paper is to identify the young protostellar counterparts
associated to dust millimeter cores of the Vela Molecular Ridge Cloud D through
new IR observations (H_2 narrow-band at 2.12 micron and N broad band at 10.4
micron) along with an investigation performed on the existing IR catalogues.
The association of mm continuum emission with infrared sources from catalogues
(IRAS, MSX, 2MASS), JHK data from the literature and new observations, has been
established according to spatial coincidence, infrared colours and spectral
energy distributions. Only 7 out of 29 resolved mm cores (and 16 out of the 26
unresolved ones) do not exhibit signposts of star formation activity. The other
ones are clearly associated with: far-IR sources, H_2 jets or near-IR objects
showing a high intrinsic colour excess. The distribution of the spectral
indices pertaining to the associated sources is peaked at values typical of
Class I objects, while three objects are signalled as candidates Class 0
sources. We remark the high detection rate (30%) of H_2 jets driven by sources
located inside the mm-cores. They appear not driven by the most luminous
objects in the field, but rather by less luminous objects in young clusters,
testifying the co-existence of both low- and intermediate-mass star formation.
The presented results reliably describe the young population of VMR-D. However,
the statistical evaluation of activity vs inactivity of the investigated cores,
even in good agreement with results found for other star forming regions, seems
to reflect the limiting sensitivity of the available facilities rather than any
property intrinsic to the mm-condensations.
","We present near-infrared (NIR) observations toward two millimeter dust cores, MM1 and MM2, located at the edge of the Vela Molecular Ridge cloud D. The NIR data were obtained with Subaru/Suprime-Cam on 2005 December 8-9 under photometric conditions. We detected several point sources associated with each core. In addition to these point-like objects, we found extended emission around MM1 that is likely due to scattered light by interstellar grains. Using our NIR data together with previous infrared and radio continuum surveys, we investigated the nature of the observed objects. Our results are summarized as follows:  1. Two brightest point-like objects within MM1 have been identified as young stellar objects based on their spectral energy distributions.  2. One of them shows an excess flux over its photosphere in K-band which suggests the presence of circumstellar disks or envelopes.  3. Another object has no significant excess but exhibits strong H$\alpha$ emission line suggesting active accretion onto the central star.  4. Several other fainter point-like objects show neither excess nor H$\alpha$ emission lines indicating they may be background stars.  5. Extended emission was also seen around MM1.",arxiv,bigscience bloomz,704.1228,0.4444444444444444,0.6470588235294118,0.6974358974358974,0.48112756808408985,1,1,1,0,0,1,1,1,0,0,0.12147789597572231,0.0993946929561209,0.13618677042801555,0.10984848484848485,0,7,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Separability Criterion for multipartite quantum states based on the Bloch representation of density matrices,"  We give a new separability criterion, a necessary condition for separability
of $N$-partite quantum states. The criterion is based on the Bloch
representation of a $N$-partite quantum state and makes use of multilinear
algebra, in particular, the matrization of tensors. Our criterion applies to
{\it arbitrary} $N$-partite quantum states in
$\mathcal{H}=\mathcal{H}^{d_1}\otimes \mathcal{H}^{d_2} \otimes ... \otimes
\mathcal{H}^{d_N}.$ The criterion can test whether a $N$-partite state is
entangled and can be applied to different partitions of the $N$-partite system.
We provide examples that show the ability of this criterion to detect
entanglement. We show that this criterion can detect bound entangled states. We
prove a sufficiency condition for separability of a 3-partite state,
straightforwardly generalizable to the case $N > 3,$ under certain condition.
We also give a necessary and sufficient condition for separability of a class
of $N$-qubit states which includes $N$-qubit PPT states.
","We present an explicit criterion to determine whether or not two given multipartite quantum states are separable, i.e., can be written as convex combinations of product states. The criterion is formulated in terms of the Bloch representation of the corresponding density matrices and it relies only on local measurements performed by each party. We show that our method provides a necessary condition for separability which is strictly weaker than other known criteria. Finally we illustrate its usefulness with some examples. Introduction:-The problem of determining if a given state belongs to the set of separable states has been extensively studied during last years [1] . In particular, several authors have proposed different methods to solve this problem [2] - [4] , but none of them seems to provide a complete solution yet. Recently, Vidal et al [5] introduced a new approach to study separability problems using the Bloch representation [6] of the density matrix associated to any pure state. This technique allows one to obtain simple conditions for separability which involve only local measurements made by each party involved in the system under consideration. However, these results do not apply directly when dealing with mixed states since they require the knowledge of all possible pure-state decompositions of such states. Here we will use another version of the Bloch representation [7] to derive a general criterion for separability applicable also to mixed states. Our main result consists of showing that there exists at least one decomposition into pure states compatible with the Bloch representation of every separable state. As a consequence, we prove that the criterion presented here constitutes a necessary condition for separabilty which is strictly weaker than previous ones [8] .
Preliminaries:-In what follows we consider N-partite systems described by Hilbert spaces H 1 ,H 2 ...H N . A generic element |ψ⟩ ∈ H = ∑ N i=1 H i is called a pure state vector while ρ ∈ D(H) denotes a density operator acting on H. Any density operator can always be expressed in terms of its spectral decomposition [9] 
where {|λ⟩} λ=1,...,d is an orthonormal basis of eigenvectors of ρ and p λ ≥ 0 (p",arxiv,bigscience bloomz,704.3942,0.3333333333333333,0.6470588235294118,0.10256410256410256,0.9827998088867654,0,1,0,0,0,1,1,1,0,0,0.2006957165795842,0.11385014426663476,0.2490272373540856,0.17424242424242425,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Imaging the Cosmic Matter Distribution using Gravitational Lensing of Pregalactic HI,"  21-cm emission from neutral hydrogen during and before the epoch of cosmic
reionisation is gravitationally lensed by material at all lower redshifts.
Low-frequency radio observations of this emission can be used to reconstruct
the projected mass distribution of foreground material, both light and dark. We
compare the potential imaging capabilities of such 21-cm lensing with those of
future galaxy lensing surveys. We use the Millennium Simulation to simulate
large-area maps of the lensing convergence with the noise, resolution and
redshift-weighting achievable with a variety of idealised observation
programmes. We find that the signal-to-noise of 21-cm lens maps can far exceed
that of any map made using galaxy lensing. If the irreducible noise limit can
be reached with a sufficiently large radio telescope, the projected convergence
map provides a high-fidelity image of the true matter distribution, allowing
the dark matter halos of individual galaxies to be viewed directly, and giving
a wealth of statistical and morphological information about the relative
distributions of mass and light. For instrumental designs like that planned for
the Square Kilometer Array (SKA), high-fidelity mass imaging may be possible
near the resolution limit of the core array of the telescope.
","We present an analysis of gravitational lensing by large-scale structure in the universe, as traced by neutral hydrogen (HI) at high redshifts z > 6. We use numerical simulations to show that this effect is detectable with future radio telescopes such as SKA and ngVLA. The signal-to-noise ratio for detecting these effects depends on the angular resolution of the telescope used; we find that it can be improved significantly if one uses multiple frequency channels instead of single-frequency data. This technique could provide valuable information about dark matter halos at early times when they were still forming their first stars. In addition, our results suggest that the cosmic web may have been denser than previously thought. Finally, we discuss how this method could be applied to detect primordial black holes. Introduction -Gravitational lensing has become a powerful tool for studying the distribution of mass in the Universe. It allows us to probe structures which are too distant or small to be detected directly through other means. For example, galaxy clusters act like lenses, magnifying background galaxies behind them. By measuring the distortion caused by lensing, one can infer properties of the cluster's dark matter halo [1] . Similarly, weak gravitational lensing measurements allow astronomers to map out the total projected mass density field over large areas of sky [2] .
In recent years there has been growing interest in applying gravitational lensing techniques to study high-redshift objects [3] , including the epoch of reionization [4] . However, most previous studies focused only on the lensing produced by visible matter, such as galaxies and quasars [5] . Here we consider another source of lensing: the intergalactic medium (IGM). At very high redshift, before galaxies formed, the IGM was filled with neutral hydrogen gas [6] . As time passed, some fraction of this gas became ionized due to ultraviolet radiation emitted by young stars [7, 8] . But even today, much of the IGM remains neutral [9] . Since the IGM contains more mass than any individual galaxy [10] , its contribution to lensing should not be ignored [11] .
The goal of this",arxiv,bigscience bloomz,706.0849,0.3333333333333333,0.8991596638655462,0.358974358974359,0.9627329192546584,1,1,0,0,0,1,1,1,0,1,0.12721758890359178,0.05722767780414715,0.1517509727626459,0.06818181818181818,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Comment on the statistical analysis in ""A new experimental limit for the stability of the electron"" by H.V. Klapdor-Kleingrothaus, I.V. Krivosheina and I.V. Titkova","  We point out the evident errors in statistical analysis of the data,
performed by Klapdor-Kleingrothaus et al in recently published paper to
establish a limit on the stability of electron with respect to the decay into
$\nu+\gamma$. We performed the reestimation of the sensitivity of the
experimental setups to the 256 keV gamma emitted in the hypothetical electron
decay, and show that in [1] the limits on the electron stability and charge
nonconservation parameter $\epsilon_{e\nu\gamma}^{2}$ are overestimated by at
least a factor of 5. We have revealed evident errors in the statistical
analysis, performed by Klapdor-Kleingrothaus et al in a recently published
paper [1] to establish a limit on the stability of electron with respect to the
decay into $\nu+\gamma$. The performed reestimation of the sensitivity of the
experimental setups to the 256 keV gamma emitted in the hypothetical electron
decay, has shown that the limits on the electron stability and charge
nonconservation parameter $\epsilon_{e\nu\gamma}^{2}$ presented in [1], have
been overestimated by at least a factor of 5.
","We have read with interest the recent preprint [1] . In this work we find that the authors' claim to set an upper bound on the lifetime of the electron is not justified because they did not take into account all relevant decay channels. 
 
 We would like to comment briefly on their treatment of backgrounds as well as their choice of cuts used to select events. The main source of background comes from radiative Bhabha scattering e+e-→e+e-γ which has been studied extensively at LEP2 [2] , where it was found to be negligible compared to other sources such as two-photon processes or four-fermion final states (e.g., W pair production). This process can only contribute if one photon escapes detection; however, since photons are emitted almost collinearly with electrons/positrons, the probability of missing both photons is very small. Furthermore, the cross section for this process decreases rapidly when the invariant mass of the lepton pairs increases [3] .
 
The authors also use a cut on the total energy of the event, Evis>10 GeV, which removes most of these events. They do mention that there may still be some residual contamination due to radiative Bhabhas but argue that this will be suppressed by requiring the presence of additional jets. However, even though the jet multiplicity distribution does decrease slightly after applying this requirement, the effect is too small to compensate for the loss of signal efficiency caused by removing events with low visible energies. 
 
In addition, the authors state that the contribution from radiative Bhabhas should be included in the systematic uncertainty estimate. However, this statement is misleading given that the quoted systematic error already includes contributions from many different sources including those related to the modelling of initial-state radiation [4] . 


Finally, we note that the authors present results obtained using Monte Carlo simulations performed with PYTHIA 6 [5] . It is known [6] that this generator underestimates the number of high-multiplicity...",arxiv,bigscience bloomz,704.2047,0.16666666666666666,0.2689075630252101,0.23076923076923078,0.4137601528905877,0,1,0,0,0,1,2,1,0,1,0.094285650378769,0.053472541288789664,0.07782101167315175,0.08333333333333333,0,0,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1
Massive gravity and structure formation,"  We study the growth of cosmological perturbations in the model of
Lorentz-violating massive gravity. The Friedman equation in this model acquires
an unconventional term due to the Lorentz-breaking condensates which has the
equation of state w = -1 / (3 gamma) with gamma being a free parameter taking
values outside of the range [0,1/3]. Apart from the standard contributions, the
perturbations above the Friedmann background contain an extra piece which is
proportional to an arbitrary function theta(x) of the space coordinates. This
function appears as an integration constant and corresponds to a
non-propagating scalar mode which may, however, become dynamical with the
account of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1
the ``anomalous'' perturbations grow slower than the standard ones and thus the
model is compatible with observations. Whether the model is experimentally
acceptable at other values of \gamma depends on the value of the function
theta(x) at the beginning of the radiation-dominated epoch.
","We study the evolution of density fluctuations in massive gravity, which is an extension to general relativity that includes terms quadratic in curvature invariants. We show that this theory predicts a scale-invariant spectrum of primordial perturbations with amplitude given by $\Delta^2 R = (4\pi)^{-3/2} H_0^2 \sim 10^{-20}$ at horizon crossing during inflation.  This value agrees well with current observations of the cosmic microwave background anisotropy. The same mechanism also leads to a suppression of power on small scales due to nonlinear effects. In addition, we find that massive gravity can lead to significant modifications to the growth rate of large-scale structures compared to standard ΛCDM cosmology. These results are consistent with recent measurements of galaxy clustering using data from the Sloan Digital Sky Survey. Finally, we discuss how these predictions could be tested observationally through future surveys such as Euclid or LSST. Massive gravity is an extension to general",arxiv,bigscience bloomz,705.1301,0.2777777777777778,0.3445378151260504,0.18974358974358974,0.38079311992355475,1,1,0,0,1,1,1,0,0,0,0.08392058731559736,0.07738168619715453,0.11673151750972763,0.08333333333333333,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0
The Cosmic Code Comparison Project,"  Current and upcoming cosmological observations allow us to probe structures
on smaller and smaller scales, entering highly nonlinear regimes. In order to
obtain theoretical predictions in these regimes, large cosmological simulations
have to be carried out. The promised high accuracy from observations make the
simulation task very demanding: the simulations have to be at least as accurate
as the observations. This requirement can only be fulfilled by carrying out an
extensive code validation program. The first step of such a program is the
comparison of different cosmology codes including gravitation interactions
only. In this paper we extend a recently carried out code comparison project to
include five more simulation codes. We restrict our analysis to a small
cosmological volume which allows us to investigate properties of halos. For the
matter power spectrum and the mass function, the previous results hold, with
the codes agreeing at the 10% level over wide dynamic ranges. We extend our
analysis to the comparison of halo profiles and investigate the halo count as a
function of local density. We introduce and discuss ParaView as a flexible
analysis tool for cosmological simulations, the use of which immensely
simplifies the code comparison task.
","The cosmic code comparison project is an effort to compare the results produced by different cosmological codes, and thereby test their accuracy.  The goal is to produce a set of simulated data that can be used as input for any number of codes, and then have each code run on this same dataset.   This will allow us to determine how well these codes agree with one another in terms of both the physical quantities they predict (e.g., matter density profiles) and also the statistical properties of those predictions (e.g., power spectra).   We are currently working towards producing a large suite of simulations covering a wide range of parameter space, including dark energy models, modified gravity theories, neutrino masses, and primordial non-Gaussianity. In addition we plan to make available a variety of observational datasets which can be compared against the simulation outputs using standard techniques such as cross-correlation functions or likelihood analysis. The cosmic code comparison project is funded through NASA's Astrophysics Theory Program under grant NNX09AC84G.",arxiv,bigscience bloomz,706.127,0.5,0.24369747899159663,0.37435897435897436,0.4295269947443861,0,0,1,0,0,1,1,0,0,1,0.03880694941902128,0.07394561686427542,0.042801556420233464,0.03787878787878788,0,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Characterization of Instrumental Phase Stability,"  Atmospheric water vapor causes significant undesired phase fluctuations for
the Submillimeter Array (SMA) interferometer, particularly in its highest
frequency observing band of 690 GHz. One proposed solution to this atmospheric
effect is to observe simultaneously at two separate frequency bands of 230 and
690 GHz. Although the phase fluctuations have a smaller magnitude at the lower
frequency, they can be measured more accurately and on shorter timescales due
to the greater sensitivity of the array to celestial point source calibrators
at this frequency. In theory, we can measure the atmospheric phase fluctuations
in the 230 GHz band, scale them appropriately with frequency, and apply them to
the data in 690 band during the post-observation calibration process. The
ultimate limit to this atmospheric phase calibration scheme will be set by the
instrumental phase stability of the IF and LO systems. We describe the
methodology and initial results of the phase stability characterization of the
IF and LO systems.
","We present an analysis method for characterizing the stability of optical phase in astronomical instruments, based on the measurement and characterization of fringe contrasts obtained with different integration times.  We show that this method can be used to characterize both short-term (< 1 hour) and long-term (> 24 hours) instrumental instabilities. The results are compared against those obtained using other methods such as power spectral density or Allan variance measurements. This new technique is applied to data taken at the Palomar Observatory Interferometer during commissioning runs in 2007-2008. It allows us to identify specific sources of instability which could not have been detected by previous techniques. In particular we find that the main source of instability comes from atmospheric turbulence effects rather than mechanical vibrations. Finally, we demonstrate how our method can also be used to measure the coherence time of the atmosphere. Keywords: Fringe contrast, Optical interferometry, Instrumentation, Atmospheric turbulence",arxiv,bigscience bloomz,704.216,0.2777777777777778,0.3445378151260504,0.17435897435897435,0.38652651696129964,1,1,0,0,0,1,1,1,0,0,0.07438393293348965,0.043312053392124295,0.07003891050583658,0.015151515151515152,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Measurement of the top-quark mass using missing $E_T$+jets events with secondary vertex $b$-tagging at CDF II,"  We present a measurement of the top-quark mass in $p\bar p$ collisions at
\hbox{$\sqrt{s}=1.96$} TeV which uses events with an inclusive signature of
missing transverse energy and jets. % The event selection is sensitive to
$t\bar t\to W^+bW^-\bar b\to l\nu b q q^\prime \bar b$ independent of the
lepton flavor, and results in a large acceptance for $W\to\tau\nu$ decays. %
All-hadronic $t\bar t$ decays and events with identified electrons or muons are
vetoed to provide a statistically independent sample with respect to all
previous measurements. % The top-quark mass is inferred from the distribution
of the scalar sum of all jet transverse energies and the missing transverse
energy. Using 311 pb$^{-1}$ of integrated luminosity recorded by the Collider
Detector at Fermilab, we measure a top-quark mass $m_t = 172.3
^{+10.8}_{-9.6}$(stat.)$\pm 10.8$(syst.) GeV/$c^2$. While the uncertainty on
$m_t$ is larger than that of other measurements, the result is statistically
uncorrelated with those of other methods, and thus can help to reduce the
overall $m_t$ uncertainty when combined with other existing measurements.
","We present measurements of the top quark mass in final states containing one or two jets and large missing transverse energy, based on data collected by the Collider Detector at Fermilab during Run I (1992-1996). The analysis uses an iterative likelihood fit to extract the signal yield as a function of the assumed top quark mass for each jet multiplicity bin. We find mtop = 174.3 +/- 1.7 GeV/c2(stat) +/-3.1(syst), where the systematic uncertainty is dominated by uncertainties associated with modeling of initial state radiation and gluon splitting.  These results are consistent with previous measurements performed by D0 and CDF experiments. This measurement supersedes our previously published result. 
The full text can be found at: http://arxiv.org/abs/0907.4189v1  # Measurement of the top-quarks mass using missing E_T+jets events with secondary-vertex b-tagging at CDF-II",arxiv,bigscience bloomz,705.1594,0.3888888888888889,0.24369747899159663,0.24102564102564103,0.32919254658385094,1,1,0,0,0,1,1,1,0,0,0.1356925883720178,0.09291076183808421,0.1556420233463035,0.06439393939393939,2,1,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Compton Scattering of Fe K alpha Lines in Magnetic Cataclysmic Variables,"  Compton scattering of X-rays in the bulk flow of the accretion column in
magnetic cataclysmic variables (mCVs) can significantly shift photon energies.
We present Monte Carlo simulations based on a nonlinear algorithm demonstrating
the effects of Compton scattering on the H-like, He-like and neutral Fe K alpha
lines produced in the post-shock region of the accretion column. The peak line
emissivities of the photons in the post-shock flow are taken into consideration
and frequency shifts due to Doppler effects are also included. We find that
line profiles are most distorted by Compton scattering effects in strongly
magnetized mCVs with a low white dwarf mass and high mass accretion rate and
which are viewed at an oblique angle with respect to the accretion column. The
resulting line profiles are most sensitive to the inclination angle. We have
also explored the effects of modifying the accretion column width and using a
realistic emissivity profile. We find that these do not have a significant
overall effect on the resulting line profiles. A comparison of our simulated
line spectra with high resolution Chandra/HETGS observations of the mCV GK Per
indicates that a wing feature redward of the 6.4 keV line may result from
Compton recoil near the base of the accretion column.
","We report on the first detection of Compton scattering of iron K-alpha lines (6.4 keV) by hot plasma in magnetic cataclysmic variables (mCVs). The observations were made with Suzaku satellite, which has an unprecedented combination of high sensitivity and energy resolution at 6.4 keV for mCVs. We detected significant excess emission above continuum around 6.4 keV in three out of four targets observed. This is interpreted as Compton-scattered line photons produced in the accretion disk coronae surrounding white dwarfs. In one target, we found that the scattered component was significantly stronger than the direct component. Our results suggest that the geometry of the X-ray emitting region may be more complex than previously thought.  Keywords: Accreting compact objects, Hot plasma, Iron K-shell lines, Compton scattering, Suzaku, Cataclysmic variable",arxiv,bigscience bloomz,704.1516,0.3888888888888889,0.29411764705882354,0.4358974358974359,0.3177257525083612,1,1,0,0,0,1,1,1,0,0,0.10301877991915635,0.0299450982005106,0.11673151750972763,0.011363636363636364,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Suzaku Observation of the Nucleus of the Radio-Loud Active Galaxy Centaurus A: Constraints on Abundances of the Accreting Material,"  A Suzaku observation of the nucleus of the radio-loud AGN Centaurus A in 2005
has yielded a broadband spectrum spanning 0.3 to 250 keV. The net exposure
times after screening were: 70 ks per X-ray Imaging Spectrometer (XIS) camera,
60.8 ks for the Hard X-ray Detector (HXD) PIN, and 17.1 ks for the HXD-GSO. The
hard X-rays are fit by two power-laws of the same slope, absorbed by columns of
1.5 and 7 * 10^{23} cm^{-2} respectively. The spectrum is consistent with
previous suggestions that the power-law components are X-ray emission from the
sub-pc VLBI jet and from Bondi accretion at the core, but it is also consistent
with a partial covering interpretation. The soft band is dominated by thermal
emission from the diffuse plasma and is fit well by a two-temperature VAPEC
model, plus a third power-law component to account for scattered nuclear
emission, jet emission, and emission from X-ray Binaries and other point
sources. Narrow fluorescent emission lines from Fe, Si, S, Ar, Ca and Ni are
detected. The Fe K alpha line width yields a 200 light-day lower limit on the
distance from the black hole to the line-emitting gas. Fe, Ca, and S K-shell
absorption edges are detected. Elemental abundances are constrained via
absorption edge depths and strengths of the fluorescent and diffuse plasma
emission lines. The high metallicity ([Fe/H]=+0.1) of the circumnuclear
material suggests that it could not have originated in the relatively
metal-poor outer halo unless enrichment by local star formation has occurred.
Relative abundances are consistent with enrichment from Type II and Ia
supernovae.
","We report results of X-ray observations with Suzaku satellite of the nucleus of radio-loud active galaxy Centaurus A (NGC 5128). The data were obtained in 2006 and 2007, when the source was observed for about 100 ks each time. We find that the spectrum is well described by an absorbed power-law model modified at low energies by photoelectric absorption due to cold gas. No significant emission lines are detected above 3 keV. Using this spectral model we derive constraints on abundances of heavy elements in the accretion flow onto supermassive black hole located in the center of NGC 5128. In particular, we show that iron abundance relative to solar value cannot be higher than 1.5-2 times its solar value. This result agrees with previous findings based on Chandra observation but contradicts earlier XMM-Newton measurement which suggested much larger overabundance of iron. Our analysis also shows that the absorbing material has relatively high column density NH ~ 2 x 1023 cm-2 .",arxiv,bigscience bloomz,704.3743,0.5555555555555556,0.3445378151260504,0.7076923076923077,0.41519350215002393,1,1,1,0,0,1,1,0,0,0,0.10407778417395874,0.039820885546785555,0.10894941634241245,0.05303030303030303,0,1,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Curvature Inspired Cosmological Scenario,"  Using modified gravity with non-linear terms of curvature, $R^2$ and $R^{(r
+2)}$ (with $r$ being the positive real number and $R$ being the scalar
curvature), cosmological scenario,beginning at the Planck scale, is obtained.
Here, a unified picture of cosmology is obtained from $f(R)-$ gravity. In this
scenario, universe begins with power-law inflation, followed by deceleration
and acceleration in the late universe as well as possible collapse of the
universe in future. It is different from $f(R)-$ dark energy models with
non-linear curvature terms assumed as dark energy. Here, dark energy terms are
induced by linear as well as non-linear terms of curvature in Friedmann
equation being derived from modified gravity.It is also interesting to see
that, in this model, dark radiation and dark matter terms emerge spontaneously
from the gravitational sector. It is found that dark energy, obtained here,
behaves as quintessence in the early universe and phantom in the late universe.
Moreover, analogous to brane-tension in brane-gravity inspired Friedmann
equation, a tension term $\lambda$ arises here being called as cosmic tension.
It is found that, in the late universe, Friedmann equation (obtained here)
contains a term $- \rho^2/2\lambda$ ($\rho$ being the phantom energy density)
analogous to a similar term in Friedmann equation with loop quantum effects, if
$\lambda > 0$ and brane-gravity correction when $\lambda < 0.$
","We propose an alternative scenario for the evolution of our universe, which is based on the idea that the expansion rate of the universe may be driven by its curvature rather than dark energy. We show how this can lead to a viable cosmology with no need for dark energy and without any fine tuning problems associated with other models in the literature. In particular we find that:  The model has a number of interesting features including:  This work was supported by the Australian Research Council (ARC) Discovery Project DP0877481. Any opinions expressed are those of the authors only. 1 Introduction.
The discovery of accelerated cosmic expansion [1, 2] , as well as the recent detection of gravitational waves [3] have led to renewed interest in understanding the nature of gravity at large scales [4] . A possible explanation for these phenomena could lie within the framework of modified theories of gravity [5] .
In order to explain the observed acceleration of the universe it seems necessary to introduce some form of ""dark energy"" [6] into Einstein's field equations [7, 8] . However, there appears to be little agreement amongst theorists about what exactly constitutes dark energy [9] or whether it should even exist [10] . Furthermore, if one assumes that dark energy exists then it must be extremely finely tuned [11] so that it behaves like a cosmological constant [12] over many orders of magnitude [13] . It also remains unclear why such a small value of vacuum energy density would arise naturally [14] .
Another possibility is that the apparent accelerating behaviour of the universe arises due to quantum effects [15] . For example, loop quantum gravity [16] predicts that space-time becomes discrete [17] leading to corrections to the Friedmann equation [18] . These corrections become significant when the scale factor reaches values close to the Planck length [19] . Other approaches include string theory [20] where the extra dimensions of spacetime [21] provide another source of potential modifications [22] .",arxiv,bigscience bloomz,706.041,0.3888888888888889,0.6974789915966387,0.48717948717948717,0.9082656473960822,1,1,0,0,0,1,1,1,0,1,0.14657465068302736,0.08887926026970976,0.14007782101167315,0.13257575757575757,0,2,3,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Pseudo-random Puncturing: A Technique to Lower the Error Floor of Turbo Codes,"  It has been observed that particular rate-1/2 partially systematic parallel
concatenated convolutional codes (PCCCs) can achieve a lower error floor than
that of their rate-1/3 parent codes. Nevertheless, good puncturing patterns can
only be identified by means of an exhaustive search, whilst convergence towards
low bit error probabilities can be problematic when the systematic output of a
rate-1/2 partially systematic PCCC is heavily punctured. In this paper, we
present and study a family of rate-1/2 partially systematic PCCCs, which we
call pseudo-randomly punctured codes. We evaluate their bit error rate
performance and we show that they always yield a lower error floor than that of
their rate-1/3 parent codes. Furthermore, we compare analytic results to
simulations and we demonstrate that their performance converges towards the
error floor region, owning to the moderate puncturing of their systematic
output. Consequently, we propose pseudo-random puncturing as a means of
improving the bandwidth efficiency of a PCCC and simultaneously lowering its
error floor.
","Turbo codes are powerful error correcting codes that have been adopted in several wireless standards, such as WiMax and 3GPP-LTE. However, their performance is limited by an error floor at high signal-to-noise ratios (SNRs). In this work we propose pseudo-random puncturing for turbo codes which can be used to lower the error floor. The proposed technique exploits the correlation between parity bits generated by different component encoders within a turbo code. We show through simulation results that our method outperforms existing techniques with respect to both coding gain and bit error rate (BER) performance. Finally, we present some practical considerations on how to implement the proposed scheme efficiently. 
 
 Turbo codes were invented by Berrou et al., [1] and they are powerful error-correcting codes that have been widely adopted in many communication systems including WiMAX [2] , DVB-S2 [3] , and 3GPP-LTE [4] . Turbo codes achieve near Shannon limit performance over additive white Gaussian noise channels [5] .
However, there exists an error floor [6] - [8] when using turbo codes due to the inherent structure of these codes [9] . This limits the use of turbo codes in applications where low BERs are required [10] . Several methods have been proposed to reduce or eliminate the error floor [11]- [16] . These include interleaver design [17] , iterative decoding [18] , soft-decision feedback [19] , irregular repeat accumulate [20] , and concatenated codes [21] .",arxiv,bigscience bloomz,704.0361,0.2777777777777778,0.546218487394958,0.18461538461538463,0.6301958910654564,1,1,0,0,0,1,1,0,0,0,0.05508970003420477,0.06788624229259427,0.06614785992217899,0.09090909090909091,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Lorentzian and signature changing branes,"  General hypersurface layers are considered in order to describe brane-worlds
and shell cosmologies. No restriction is placed on the causal character of the
hypersurface which may thus have internal changes of signature. Strengthening
the results in our previous letter [1], we confirm that a good, regular and
consistent description of signature change is achieved in these brane/shells
scenarios, while keeping the hypersurface and the bulk completely regular. Our
formalism allows for a unified description of the traditional timelike
branes/shells together with the signature-changing, or pure null, ones. This
allows for a detailed comparison of the results in both situations. An
application to the case of hypersurface layers in static bulks is presented,
leading to the general Robertson-Walker geometry on the layer --with a possible
signature change. Explicit examples on anti de Sitter bulks are then studied.
The permitted behaviours in different settings ($Z_{2}$-mirror branes,
asymmetric shells, signature-changing branes) are analysed in detail. We show
in particular that (i) in asymmetric shells there is an upper bound for the
energy density, and (ii) that the energy density within the brane vanishes when
approaching a change of signature. The description of a signature change as a
`singularity' seen from within the brane is considered. We also find new
relations between the fundamental constants in the brane/shell, its tension,
and the cosmological and gravitational constants of the bulk, independently of
the existence or not of a change of signature.
","We study the dynamics of Lorentzian brane-worlds with time dependent bulk cosmological constant in the context of Randall-Sundrum type II models, where we allow for both positive and negative values of the bulk cosmological constant. We show that there are two branches of solutions corresponding to either an expanding or contracting universe on the brane depending upon whether the bulk cosmological constant is positive or negative respectively. In addition, we find that these solutions can be smoothly connected by a branch of static solutions which correspond to Minkowski space-time on the brane. Finally, we also consider the possibility of having a change of signature across the brane and discuss how this affects our results. The main motivation behind studying braneworld scenarios comes from the fact that they provide us with a natural framework within which one may address some of the fundamental issues related to quantum gravity such as the hierarchy problem [1] . However, it has been shown recently [2] , that even if one considers only classical gravitational effects, then the standard four dimensional Friedmann equations cannot be recovered unless certain conditions are satisfied. These include the requirement that the energy density of matter fields localized on the brane should satisfy the weak energy condition (WEC) [3] .
In order to overcome this difficulty, several authors have considered different approaches [4] - [8] . For example, in ref. [6] , the authors studied the case when the bulk cosmological constant changes sign at late times thereby allowing them to obtain realistic cosmologies without violating WEC. On the other hand, in ref. [7] , the authors showed that it was possible to recover the standard Friedmann equation provided the stress-energy tensor satisfies the null energy condition (NEC).",arxiv,bigscience bloomz,705.338,0.5555555555555556,0.546218487394958,0.5794871794871795,0.7792642140468228,1,1,0,0,1,1,1,0,0,0,0.10087854162107628,0.09035521378616682,0.08171206225680934,0.07575757575757576,0,2,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Multicolor observations of the afterglow of the short/hard GRB 050724,"  New information on short/hard gamma-ray bursts (GRBs) is being gathered
thanks to the discovery of their optical and X-ray afterglows. However, some
key aspects are still poorly understood, including the collimation level of the
outflow, the duration of the central engine activity, and the properties of the
progenitor systems. We want to constrain the physical properties of the short
GRB 050724 and of its host galaxy, and make some inferences on the global short
GRB population. We present optical observations of the afterglow of GRB 050724
and of its host galaxy, significantly expanding the existing dataset for this
event. We compare our results with models, complementing them with available
measurements from the literature. We study the afterglow light curve and
spectrum including X-ray data. We also present observations of the host galaxy.
The observed optical emission was likely related to the large flare observed in
the X-ray light curve. The apparent steep decay was therefore not due to the
jet effect. Available data are indeed consistent with low collimation, in turn
implying a large energy release, comparable to that of long GRBs. The flare
properties also constrain the internal shock mechanism, requiring a large
Lorentz factor contrast between the colliding shells. This implies that the
central engine was active at late times, rather than ejecting all shells
simultaneously. The host galaxy has red colors and no ongoing star formation,
consistent with previous findings on this GRB. However, it is not a pure
elliptical, and has some faint spiral structure. GRB 050724 provides the most
compelling case for association between a short burst and a galaxy with old
stellar population. It thus plays a pivotal role in constraining progenitors
models, which should allow for long delays between birth and explosion.
","We report on multiwavelength observations of the X-ray, optical and radio afterglows of the short-hard gamma-ray burst (GRB) 050724 detected by Swift satellite at 07:24:06 UT on 24 July 2005. The prompt emission lasted for about 1 s with an average photon energy E = 300 keV in the 15-350 keV band. We find that the temporal decay index is ~1.2 between 10s to 1000s post-burst time scale which indicates that this event belongs to the class of ultra-long GRBs. In addition we also detect a possible rebrightening feature around 100s post-burst time-scale. Our spectral analysis shows that the spectrum can be fitted well using both single power-law model as well as broken power law model. However, the best fit parameters are found to be consistent within their errors when compared with each other. Using our multi-wavelength data set, we estimate the total energetics associated with this event to be ~3 x 1044 erg.",arxiv,bigscience bloomz,706.1273,0.8333333333333334,0.29411764705882354,0.8512820512820513,0.3951266125179169,1,1,0,0,0,1,1,1,0,0,0.05920884341943056,0.04852338316575216,0.042801556420233464,0.041666666666666664,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Depletion effects in smectic phases of hard rod--hard sphere mixtures,"  It is known that when hard spheres are added to a pure system of hard rods
the stability of the smectic phase may be greatly enhanced, and that this
effect can be rationalised in terms of depletion forces. In the present paper
we first study the effect of orientational order on depletion forces in this
particular binary system, comparing our results with those obtained adopting
the usual approximation of considering the rods parallel and their orientations
frozen. We consider mixtures with rods of different aspect ratios and spheres
of different diameters, and we treat them within Onsager theory. Our results
indicate that depletion effects, and consequently smectic stability, decrease
significantly as a result of orientational disorder in the smectic phase when
compared with corresponding data based on the frozen--orientation
approximation. These results are discussed in terms of the $\tau$ parameter,
which has been proposed as a convenient measure of depletion strength. We
present closed expressions for $\tau$, and show that it is intimately connected
with the depletion potential. We then analyse the effect of particle geometry
by comparing results pertaining to systems of parallel rods of different shapes
(spherocylinders, cylinders and parallelepipeds). We finally provide results
based on the Zwanzig approximation of a Fundamental--Measure
density--functional theory applied to mixtures of parallelepipeds and cubes of
different sizes. In this case, we show that the $\tau$ parameter exhibits a
linear asymptotic behaviour in the limit of large values of the hard--rod
aspect ratio, in conformity with Onsager theory, as well as in the limit of
large values of the ratio of rod breadth to cube side length, $d$, in contrast
to Onsager approximation, which predicts $\tau\sim d^3$.
","We study the effect of depletants on the phase behavior of binary mixtures of hard rods and hard spheres by computer simulation. We find that for sufficiently large concentrations of depletant, the system undergoes an isostructural transition to a new smectic phase with a different layer spacing than found in pure systems. The results are explained within mean-field theory using a free energy functional approach. DOI: 10.1063/1.3189000
I. INTRODUCTIO N
The addition of small particles (depletants) to colloidal suspensions can lead to dramatic changes in their structure [1] . In particular, it has been shown experimentally [2] , theoretically [3] , and computationally [4] that adding nonadsorbing polymer chains or other types of depletants leads to the formation of ordered structures such as crystals [5] .
In this work we consider the case where the depletants are spherical particles which do not adsorb onto the surfaces of the larger colloids [6] . This type of interaction between the two species gives rise to a rich variety of phenomena [7, 8] including liquid crystal phases [9] . Here we focus our attention on one aspect of these mixtures -the effect of depletants upon the smectic phases formed by mixtures of hard rods and spheres [10] . Smectics are mesophases characterized by layers of parallel oriented molecules separated by regions of disordered fluid [11] . These materials have attracted considerable interest because they exhibit many properties similar to those observed in biological membranes [12] . For example, both smectic A and C phases form spontaneously when lipids are mixed with water [13] . It was recently suggested [14] that smectic phases may also be present in certain protein solutions [15] .",arxiv,bigscience bloomz,704.114,0.4444444444444444,0.546218487394958,0.7794871794871795,0.7534639273769709,1,1,0,0,0,1,1,1,0,0,0.1475835558931755,0.06517415544464455,0.17509727626459143,0.05303030303030303,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Where post-Newtonian and numerical-relativity waveforms meet,"  We analyze numerical-relativity (NR) waveforms that cover nine orbits (18
gravitational-wave cycles) before merger of an equal-mass system with low
eccentricity, with numerical uncertainties of 0.25 radians in the phase and
less than 2% in the amplitude; such accuracy allows a direct comparison with
post-Newtonian (PN) waveforms. We focus on one of the PN approximants that has
been proposed for use in gravitational-wave data analysis, the restricted 3.5PN
``TaylorT1'' waveforms, and compare these with a section of the numerical
waveform from the second to the eighth orbit, which is about one and a half
orbits before merger. This corresponds to a gravitational-wave frequency range
of $M\omega = 0.0455$ to 0.1. Depending on the method of matching PN and NR
waveforms, the accumulated phase disagreement over this frequency range can be
within numerical uncertainty. Similar results are found in comparisons with an
alternative PN approximant, 3PN ``TaylorT3''. The amplitude disagreement, on
the other hand, is around 6%, but roughly constant for all 13 cycles that are
compared, suggesting that only 4.5 orbits need be simulated to match PN and NR
waves with the same accuracy as is possible with nine orbits. If, however, we
model the amplitude up to 2.5PN order, the amplitude disagreement is roughly
within numerical uncertainty up to about 11 cycles before merger.
","We present the first results for gravitational waves generated by binary black holes in full general relativity, using both post-post-Newtonian (PPN) theory and numerical relativity. We find that our PPN-calculated waveform agrees with the numerical one to within 1% at frequencies above 100 Hz. This is an improvement over previous calculations which used only PN theory or numerical relativity alone. 
 
 The agreement between these two methods provides us with confidence that we can use this hybrid approach as part of future searches for gravitational waves produced during mergers of compact objects such as neutron stars and/or black holes. In addition, it allows us to test whether current models are accurate enough to detect gravitational waves emitted by merging binaries containing supermassive black holes. These tests will be performed on data collected by LIGO/VIRGO detectors when they become operational later this year. Finally, we show how the hybrid method could also be useful for testing alternative theories of gravity.",arxiv,bigscience bloomz,706.1305,0.3333333333333333,0.29411764705882354,0.4717948717948718,0.40659340659340665,1,1,1,0,1,1,1,0,0,0,0.16159148205287643,0.060210486062284435,0.1556420233463035,0.06818181818181818,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Cornell Caltech Atacama Telescope,"  Cornell University, the California Institute for Technology, and the Jet
Propulsion Laboratory are jointly studying the construction of a 25 m diameter
telescope for submillimeter astronomy on a high mountain in northern Chile.
This Cornell Caltech Atacama Telescope (CCAT) will combine high sensitivity, a
wide field of view, and a broad wavelength range to provide an unprecedented
capability for deep, large area, multi-color submillimeter surveys to
complement narrow field, high resolution studies with ALMA. CCAT observations
will address fundamental themes in contemporary astronomy, notably the
formation and evolution of galaxies, the nature of the dark matter and dark
energy that comprise most of the content of the universe, the formation of
stars and planets, the conditions in circumstellar disks, and the conditions
during the early history of the Solar system. The candidate CCAT site, at 5600
m in northern Chile, enjoys superb observing conditions. To accommodate large
format bolometer cameras, CCAT is designed with a 20 arcmin field of view. CCAT
will incorporate closed loop active control of its segmented primary mirror to
maintain a half wavefront error of 10 mum rms or less. Instrumentation under
consideration includes both short (650 mum-200 mum) and long (2 mm-750 mum)
wavelength bolometer cameras, direct detection spectrometers, and heterodyne
receiver arrays. The University of Colorado, a Canadian university consortium,
and the UK Astronomy Technology Centre on behalf of the UK community are
pursuing participation in the CCAT consortium. When complete early in the next
decade, CCAT will be the largest and most sensitive facility of its class as
well as the highest altitude astronomical facility on Earth.
","The Cornell Caltech Atacama: The Cornell Caltech Atacame Observatory (CCAT) is an optical and infrared telescope under construction in Chile's northern desert, near the town of San Pedro de Atacama.  CCAT will be one of the largest telescopes ever built with a diameter of 24 meters.   It was designed to have unprecedented sensitivity for detecting faint objects such as distant galaxies or exoplanets around other stars.    CCAT will also provide high angular resolution images that can resolve individual stars within these distant galaxies. CCAT will use adaptive optics technology to correct for atmospheric distortions caused by turbulence in Earth's atmosphere. This will allow it to produce sharper images than are possible today using conventional techniques. CCAT will operate at wavelengths ranging from 0.35 microns to 16 microns. CCAT will consist of two main components:  A large primary mirror made out of silicon carbide.",arxiv,bigscience bloomz,704.3031,0.4444444444444444,0.3445378151260504,0.7230769230769231,0.3635929288103201,1,1,0,0,0,1,0,1,0,1,0.13120092538728054,0.05382810131776045,0.17509727626459143,0.056818181818181816,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Growth mechanisms and structure of fullerene-like carbon-based thin films: superelastic materials for tribological applications,"  In this chapter we review our findings on the bonding structure and growth
mechanisms of carbon-based thin solid films with fullerene-like (FL)
microstructure. The so-called FL arrangements arise from the curvature and
cross-linking of basal planes in graphitic-like structures, partially
resembling that of molecular fullerenes. This three-dimensional superstructure
takes advantage of the strength of planar pi bonds in sp2 hybrids and confers
the material interesting mechanical properties, such as high hardness, high
elastic recovery, low-friction and wear-resistance. These properties can be
tailored by controlling the curvature, size and connectivity of the FL
arrangements, making these materials promising coatings for tribological
applications. We have focused our interest mostly on carbon nitride (CNx) since
nitrogen promotes the formation of FL arrangements at low substrate
temperatures and they are emerging over pure carbon coatings in tribological
applications such as protective overcoats in magnetic hard disks. We address
structural issues such as origin of plane curvature, nature of the
cross-linking sites and sp2 clustering, together with growth mechanisms based
on the role of film-forming precursors, chemical re-sputtering or concurrent
ion assistance during growth.
","Fullerenes are spherical molecules composed entirely of sp2-hybridized carbons, which can be arranged in different ways to form various allotropes with unique properties. The most common is the C60 molecule (buckminsterfullerene), but other forms such as nanotubes or graphene have also been reported. Fullerenes were first discovered by Kroto et al., who received the Nobel Prize in Chemistry in 1996 for their work on them.  In this study we report on the growth mechanism and structural characterization of novel carbon-based nanomaterials that consist of an amorphous network of interconnected nanoparticles resembling fullerenes. These structures grow spontaneously when evaporating carbon atoms onto silicon substrates at temperatures between 600-700 °C under ultrahigh vacuum conditions. We show how these new carbon nanostructures exhibit remarkable mechanical properties including high elasticity and hardness combined with low friction coefficients making them ideal candidates for use as protective coatings against wear and corrosion.",arxiv,bigscience bloomz,706.2258,0.2777777777777778,0.24369747899159663,0.28717948717948716,0.37219302436693746,1,1,0,0,0,1,1,0,0,0,0.07466096902437555,0.03536872138733988,0.06614785992217899,0.03787878787878788,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Interval Conjectures for level Hilbert functions,"  We conjecture that the set of all Hilbert functions of (artinian) level
algebras enjoys a very natural form of regularity, which we call the {\em
Interval Conjecture} (IC): If, for some positive integer $\alpha $,
$(1,h_1,...,h_i,...,h_e)$ and $(1,h_1,...,h_i+\alpha ,...,h_e)$ are both level
$h$-vectors, then $(1,h_1,...,h_i+\beta ,...,h_e)$ is also level for each
integer $\beta =0,1,..., \alpha .$ In the Gorenstein case, i.e. when $h_e=1$,
we also supply the {\em Gorenstein Interval Conjecture} (GIC), which naturally
generalizes the IC, and basically states that the same property simultaneously
holds for any two symmetric entries, say $h_i$ and $h_{e-i}$, of a Gorenstein
$h$-vector.
  These conjectures are inspired by the research performed in this area over
the last few years. A series of recent results seems to indicate that it will
be nearly impossible to characterize explicitly the sets of all Gorenstein or
of all level Hilbert functions. Therefore, our conjectures would at least
provide the existence of a very strong - and natural - form of order in the
structure of such important and complicated sets.
  We are still far from proving the conjectures at this point. However, we will
already solve a few interesting cases, especially when it comes to the IC, in
this paper. Among them, that of Gorenstein $h$-vectors of socle degree 4, that
of level $h$-vectors of socle degree 2, and that of non-unimodal level
$h$-vectors of socle degree 3 and any given codimension.
","We prove the following interval conjectures on the values of certain level Hilbert functions, which are defined as follows.  Let $(R,m)$ be an Artinian local ring with maximal ideal $m$ and residue field $k$. For each integer $n$ let $R_n$ denote the localization of $R$ at the prime ideals containing $m^n$. The nth level Hilbert function $H_n(R)$ is then defined to be the number of elements in $k^n/m^{n+1}$. 
Theorem 1 (Main theorem). If $(R,m,k)$ satisfies Serre's condition $S_2$, then there exists a positive constant $c$ such that 
$$H_n(R) \geq c n^2 + cn - 2c \tag{1}$$
for all integers $n \geq 1$.
Corollary 1. If $(R, m, k)$ satisfies Serre’s condition $S_2$, then we have
$$H_n(R)  \geq  \frac{n}{2}(n-1)^2 + \frac{n}{2}(n-1),\tag{2}$$
for all integers $1 \leq n \leq 4$.
Corollary 2. If $(R_1, m_1, k_1), (R_2, m_2, k_2)$ satisfy Serre’s condition $S_{2}$, then we have
$$\max_{1\leq i\leq 2} H_i(R_i) \geq \frac{1}{2}(\max_{1\leq i \leq 2} H_i(R_1)+H_i(R_2)).\tag{3}$$",arxiv,bigscience bloomz,705.0806,0.3888888888888889,0.4453781512605043,0.5692307692307692,0.3951266125179169,1,1,1,0,0,1,1,0,0,1,0.32451050432739487,0.22259935337257267,0.245136186770428,0.26136363636363635,0,3,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
The Stokes phenomenon in the confluence of the hypergeometric equation using Riccati equation,"  In this paper we study the confluence of two regular singular points of the
hypergeometric equation into an irregular one. We study the consequence of the
divergence of solutions at the irregular singular point for the unfolded
system. Our study covers a full neighborhood of the origin in the confluence
parameter space. In particular, we show how the divergence of solutions at the
irregular singular point explains the presence of logarithmic terms in the
solutions at a regular singular point of the unfolded system. For this study,
we consider values of the confluence parameter taken in two sectors covering
the complex plane. In each sector, we study the monodromy of a first integral
of a Riccati system related to the hypergeometric equation. Then, on each
sector, we include the presence of logarithmic terms into a continuous
phenomenon and view a Stokes multiplier related to a 1-summable solution as the
limit of an obstruction that prevents a pair of eigenvectors of the monodromy
operators, one at each singular point, to coincide.
","In this article, we study the confluence of the second order linear differential equations with variable coefficients and their solutions by applying the method of successive approximations to find the solution of the confluent hypergeometric equation (CHGE). We also use the concept of the Stokes phenomenon for finding the singularities of the CHGE's solutions at infinity. The results are illustrated numerically through examples. Keywords: Confluence of differential equations; Stokes phenomenon; Hypergeometric functions. 1 Introduction In mathematics, the confluent hypergeometic function is defined as the sum of all possible products of n terms taken from an infinite series of complex numbers [1] . It has been used extensively in many fields such as physics [2] , engineering [3] , computer science [4] , statistics [5] , etc., because it can be applied to solve various types of problems [6] .
The confluent hypergeometric function is denoted by ${}_1F_1$ or ${_2F_1}$ depending on whether the first argument is equal to one or not [7, 8] . For example, if the first argument equals one then the function is called the Kummer confluent hypergeometric function:",arxiv,bigscience bloomz,706.1773,0.3333333333333333,0.3445378151260504,0.24102564102564103,0.475394171046345,0,1,0,0,0,1,0,1,0,1,0.11745359180673788,0.11362222741571373,0.12062256809338522,0.06060606060606061,0,1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Valley Dependent Optoelectronics from Inversion Symmetry Breaking,"  Inversion symmetry breaking allows contrasted circular dichroism in different
k-space regions, which takes the extreme form of optical selection rules for
interband transitions at high symmetry points. In materials where band-edges
occur at noncentral valleys, this enables valley dependent interplay of
electrons with light of different circular polarizations, in analogy to spin
dependent optical activities in semiconductors. This discovery is in perfect
harmony with the previous finding of valley contrasted Bloch band features of
orbital magnetic moment and Berry curvatures from inversion symmetry breaking
[Phys. Rev. Lett. 99, 236809 (2007)]. A universal connection is revealed
between the k-resolved optical oscillator strength of interband transitions,
the orbital magnetic moment and the Berry curvatures, which also provides a
principle for optical measurement of orbital magnetization and intrinsic
anomalous Hall conductivity in ferromagnetic systems. The general physics is
demonstrated in graphene where inversion symmetry breaking leads to valley
contrasted optical selection rule for interband transitions. We discuss
graphene based valley optoelectronics applications where light polarization
information can be interconverted with electronic information.
","We report on the valley dependent optoelectronic properties in monolayer WSe2, which is an inversion symmetry breaking semiconductor with strong spin-orbit coupling and large exciton binding energy. We show that circularly polarized light can be used to control the valley polarization of photoexcited carriers by optical pumping at room temperature. The valley polarization lifetime is found to be about 1 ns for both electrons and holes under weak excitation conditions. This work opens up new opportunities for exploring novel valleytronic devices based on 2D materials. 
 
 Valleytronics has been proposed as one promising approach towards realizing spin-based electronics beyond conventional silicon technology1-5 . Recently, it was shown that the valley degree of freedom could also play important roles in many other physical phenomena such as phonon transport6 , thermoelectricity7-10 , and superconductivity11-13 .
 
 
 Monolayer transition metal dichalcogenides (TMDCs) are emerging two-dimensional semiconductors14-17 with broken inversion symmetry18-20 due to their unique layered structure21-23 . They have attracted great attention because they exhibit remarkable electronic24-26 , mechanical27-29 , thermal30-32 , and optical33-35 properties. Moreover, TMDCs possess high carrier mobility36-38 , making them ideal candidates for future valleytronic applications39-41 . 
 
 Here we demonstrate valley-dependent optoelectronic properties of monolayer WSe2 using time-resolved photoluminescence spectroscopy42-45 . By exciting WSe2 with circularly polarized light, we observe that the valley polarization lifetimes of photo-excited carriers are around 1ns for both electrons and holes46-48 . Our results provide direct evidence for valleydependent optoelectronic processes in this material system49-51 .",arxiv,bigscience bloomz,705.4683,0.4444444444444444,0.546218487394958,0.2358974358974359,0.641662685140946,1,1,0,0,0,1,1,0,0,0,0.1332050360936404,0.04515527758322754,0.14007782101167315,0.03787878787878788,3,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Theory of anomalous diffusive reaction rates on realistic self-affine fractals,"  In this letter, a theoretical method for the analysis of diffusive
flux/current to limited scale self-affine random fractals is presented and
compared with experimentally measured electrochemical current for such
roughness. The theory explains the several experimental findings of the
temporal scale invariance as well as deviation from this of current transients
in terms of three dominant fractal parameters for the limited-length scales of
roughness. This theoretical method is based on limited scale power-law
characterization of the interfacial roughness spectrum and the solution of
diffusion equation under the diffusion-limited boundary conditions on rough
interfaces. More broadly, these calculations challenges the earlier belief that
the anomalous behavior is solely dependent on fractal dimension of roughness
and highlight the potential to apply this equation for the scale invariant
roughness determination. Finally, the validity of theoretical result is tested
with extensive experimental data.
","We present the theory for anomalous diffusion in terms of fractional Fokker-Planck equations and apply it to study the time evolution of chemical reactions occurring on realistic self-affined fractals, such as porous media or biological tissues. We show that the rate at which reactants are consumed is determined by the geometry of the medium through an effective fractal dimension D(t) that evolves with time according to a nonlinear differential equation. The solution of this equation depends on the initial conditions and can be obtained numerically using standard methods. In particular we find that if the initial distribution has compact support then the system reaches equilibrium after some characteristic relaxation time t*. For times larger than t* the consumption rate becomes independent of the initial condition and coincides with the one predicted by classical mean field theories. This result suggests that the dynamics of chemical reactions in complex environments may be described by simple models based only on geometrical information about the environment.",arxiv,bigscience bloomz,705.2813,0.2222222222222222,0.24369747899159663,0.08205128205128205,0.4180602006688964,0,1,0,0,0,1,1,0,0,0,0.07701307002438564,0.05731325641951,0.08560311284046693,0.056818181818181816,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1
Is diversity good?,"  Prominent ethical and policy issues such as affirmative action and female
enrollment in science and engineering revolve around the idea that diversity is
good. However, even though diversity is an ambiguous concept, a precise
definition is seldom provided. We show that diversity may be construed as a
factual description, a craving for symmetry, an intrinsic good, an instrumental
good, a symptom, or a side effect. These acceptions differ vastly in their
nature and properties. The first one cannot lead to any action and the second
one is mistaken. Diversity as intrinsic good is a mere opinion, which cannot be
concretely applied; moreover, the most commonly invoked forms of diversity
(sexual and racial) are not intrinsically good. On the other hand, diversity as
instrumental good can be evaluated empirically and can give rise to policies,
but these may be very weak. Finally, symptoms and side effects are not actually
about diversity. We consider the example of female enrollment in science and
engineering, interpreting the various arguments found in the literature in
light of this polysemy.
  Keywords: ethics, policy, higher education, female students, minority
students, affirmative action
","The question is not new, but it has been recently revived by the publication of two papers in Nature and Science that claim to show that biodiversity loss leads to ecosystem collapse.  The authors argue that this finding should be taken seriously because ecosystems are essential for human well-being.   They also point out that there have been many previous studies showing that biodiversity loss can lead to declines in ecosystem functioning (e.g., productivity) without necessarily causing an abrupt change in state or collapse.    In this article we review these recent findings on biodiversity-ecosystem function relationships as well as some earlier results suggesting that biodiversity may sometimes enhance rather than reduce ecosystem stability.  We conclude with a discussion about how our understanding of biodiversity-ecosystem function interactions could be improved through further research. Biodiversity loss is one of humanity's greatest challenges today. It threatens the sustainability of natural resources used directly by humans such as food production systems and water supply, and indirectly via changes in climate regulation and disease transmission pathways. There is growing concern over the rate at which species extinction rates are increasing globally due to anthropogenic activities including habitat destruction, pollution, overexploitation, and invasive alien species1–3. This situation has led to calls for urgent action to conserve biological diversity4–6. However, despite widespread recognition of the importance of conserving biodiversity7–10, there remains considerable uncertainty regarding its role in maintaining ecosystem functions11–13. A number of theoretical models suggest that biodiversity loss will cause reductions in ecosystem functioning14–16. For example, Tilman et al. (1997)17 showed theoretically that reducing plant species richness would decrease primary productivity in grassland communities. Similarly, Naeem & Li (1998)18 found experimentally that removing species from soil microcosms reduced decomposition rates. These predictions were supported by numerous subsequent empirical studies19–22.",arxiv,bigscience bloomz,704.2466,0.5,0.6974789915966387,0.31794871794871793,0.7907310081223125,1,0,1,0,0,1,1,0,0,1,0.0788725204995706,0.07840570115748605,0.08949416342412451,0.06439393939393939,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Linkage between Accretion Disks and Blazars,"  The magnetic field in an accretion disk is estimated assuming that all of the
angular momentum within prescribed accretion disk radii is removed by a jet.
The magnetic field estimated at the base of the jet is extrapolated to the
blazar emission region using a model for a relativistic axisymmetric jet
combined with some simplifying assumptions based on the relativistic nature of
the flow. The extrapolated magnetic field is compared with estimates based upon
the synchrotron and inverse Compton emission from three blazars, MKN 501, MKN
421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self-
Compton models are inconsistent with the magnetic fields extrapolated in this
way. However, in two cases inverse Compton models in which a substantial part
of the soft photon field is generated locally agree well, mainly because these
models imply magnetic field strengths which are closer to being consistent with
Poynting flux dominated jets. This comparison is based on estimating the mass
accretion rate from the jet energy flux. Further comparisons along these lines
will be facilitated by independent estimates of the mass accretion rate in
blazars and by more detailed models for jet propagation near the black hole.
","We present the results of our analysis on the correlation between blazar activity and accretion disk luminosity in active galactic nuclei (AGN). We use data for all AGNs with available information about their black hole mass, bolometric luminosity, radio flux density at 5 GHz, and redshift taken from the literature. The sample consists of 1248 objects including both BL Lacertae-type and flat-spectrum radio quasars. Our main result is that there exists an anti-correlation between the radio emission produced by jets and the optical/UV radiation emitted by disks. This effect can be explained if we assume that the jet power decreases as the disk luminosity increases. In addition to this general trend, we find evidence for two separate branches in the distribution of sources along the radio-optical plane. One branch corresponds to low-luminosity AGNs whose radio emission correlates positively with the disk luminosity; another one includes high-luminosity AGN where the radio emission anticorrelates strongly with the disk luminosity.",arxiv,bigscience bloomz,704.2636,0.3333333333333333,0.29411764705882354,0.37435897435897436,0.4037267080745342,0,1,0,0,0,1,1,1,0,0,0.08649649264775867,0.047244161718672836,0.10894941634241245,0.04924242424242424,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Cryptoplanet update,"  We have had several talks recently reviewing 11 years of exoplanet
discoveries through radial velocity variations, or from transits, or from
microlensing. More than 200 exoplanets have been found, including some around
pulsars that we do not discuss here.
  My physical definition for a planet is a roughly spherical, self-gravitating
body more massive than 10**26 g formed from the leftover material in a
protostellar disk after the protostar forms. Radiation from the protostar
pushes the inner wall of the disk outward. The material agglomerates and forms
planets in radial sequence. The outer planets are formed slowly by classical
dynamical mechanisms acting in the snow zone. Planets have dense cores because
of agglomeration.
  Not one of the exoplanets discovered thus far is a planet. They are
cryptoplanets formed from matter ejected by protostars. When protostars have
excessive infall at high latitudes, they partially balance angular momentum
through outflow at the equator as they spin up. The ejected matter is trapped
in the magnetic torus formed between the star and the disk, like a tokamak. The
tokamak eventully reconnects and magnetic compression forms self-gravitating
remnants trapped and compressed by a closed spherical magnetic field,
spheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They
can merge with each other or fall into the star or be ejected. They can grow by
accreting gas. They have a low density core and abundances characteristic of
the protostar. Their masses, radii, densities, and orbits are random, and are
inconsistent with the parameters for planets. They tend to have lower density
than planets.
","The Cryptoplanet project is an ongoing effort to collect and archive data on the world's cryptocurrencies, including Bitcoin (BTC), Ethereum (ETH) and Litecoin (LTC). The goal of this project is to provide researchers with access to historical information about these currencies in order to facilitate research into their underlying technologies.  This article describes how we collected our dataset for analysis as well as some preliminary results that have been obtained using it. We also describe plans for future work. In recent years there has been growing interest among academics in studying virtual currency systems such as Bitcoin [1] . One reason for this interest is that many believe that Bitcoin's success will lead to the development of new types of digital payment systems [2] , which could potentially be used by millions of people around the world [3] .
In addition to its potential use as a means of exchange, Bitcoin may also serve as a platform for other applications [4] . For example, one can imagine a system where users pay each other directly via Bitcoins without having to rely on third parties like banks or credit card companies [5] . Another possible application would involve storing Bitcoins in cold storage [6] so they are not vulnerable to theft or loss due to hacking attacks [7, 8] . Finally, Bitcoin transactions might even be used to settle financial contracts [9] .
Despite all of these exciting possibilities, however, little academic research has been done on Bitcoin itself [10] . Most existing studies focus instead on related topics such as mining [11] , price prediction [12] , transaction processing [13] , and security [14] .",arxiv,bigscience bloomz,704.286,1.0,0.546218487394958,0.6923076923076923,0.7419971333014811,0,1,0,0,0,1,0,0,0,1,0.07380814825462542,0.0779499823835918,0.08560311284046693,0.07196969696969698,7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Outer jet X-ray and radio emission in R Aquarii: 1999.8 to 2004.0,"  Chandra and VLA observations of the symbiotic star R Aqr in 2004 reveal
significant changes over the three to four year interval between these
observations and previous observations taken with the VLA in 1999 and with
Chandra in 2000. This paper reports on the evolution of the outer thermal X-ray
lobe-jets and radio jets. The emission from the outer X-ray lobe-jets lies
farther away from the central binary than the outer radio jets, and comes from
material interpreted as being shock heated to ~10^6 K, a likely result of
collision between high speed material ejected from the central binary and
regions of enhanced gas density. Between 2000 and 2004, the Northeast (NE)
outer X-ray lobe-jet moved out away from the central binary, with an apparent
projected motion of ~580 km s^-1. The Southwest (SW) outer X-ray lobe-jet
almost disappeared between 2000 and 2004, presumably due to adiabatic expansion
and cooling. The NE radio bright spot also moved away from the central binary
between 2000 and 2004, but with a smaller apparent velocity than of the NE
X-ray bright spot. The SW outer lobe-jet was not detected in the radio in
either 1999 or 2004. The density and mass of the X-ray emitting material is
estimated. Cooling times, shock speeds, pressure and confinement are discussed.
","We present new results on the outer jets of the symbiotic star, R Aqr (=V1016 Cyg). We have analyzed archival Chandra data obtained between 1999 August 31 and 2000 September 30 as well as XMM-Newton observations taken between 2001 October 24 and 2002 November 3. The analysis shows that both jets are still active at least up to 2004 January 1. In addition we report on an optical spectroscopic campaign carried out with the Nordic Optical Telescope during 2003 December 10-17 which revealed no significant changes compared to previous campaigns. Finally, we discuss our findings within the context of current models for the formation of bipolar nebulae around evolved stars. Keywords: Symbiosis, Jets, Bipolar Nebulae, Stellar Winds, Mass Ejection, Binary Star Systems, Chandra Observatory, XMM-Newton Observatory, R Aquarius, V1016 Cyg",arxiv,bigscience bloomz,705.257,0.4444444444444444,0.24369747899159663,0.4666666666666667,0.3263258480649785,1,1,0,0,0,1,1,1,0,0,0.12975046692247658,0.043567307274972086,0.14785992217898833,0.03409090909090909,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Non-cooperative games for spreading code optimization, power control and receiver design in wireless data networks","  This paper focuses on the issue of energy efficiency in wireless data
networks through a game theoretic approach. The case considered is that in
which each user is allowed to vary its transmit power, spreading code, and
uplink receiver in order to maximize its own utility, which is here defined as
the ratio of data throughput to transmit power. In particular, the case in
which linear multiuser detectors are employed at the receiver is treated first,
and, then, the more challenging case in which non-linear decision feedback
multiuser receivers are adopted is addressed. It is shown that, for both
receivers, the problem at hand of utility maximization can be regarded as a
non-cooperative game, and it is proved that a unique Nash equilibrium point
exists. Simulation results show that significant performance gains can be
obtained through both non-linear processing and spreading code optimization; in
particular, for systems with a number of users not larger than the processing
gain, remarkable gains come from spreading code optimization, while, for
overloaded systems, the largest gainscome from the use of non-linear
processing. In every case, however, the non-cooperative games proposed here are
shown to outperform competing alternatives.
","In this thesis we study the problem of optimizing resource allocation in wireless networks by using non-cooperative game theory. We consider three different problems: (1) Code Optimization, (2) Power Control, and (3) Receiver Design. In each case, we formulate an optimization problem as a noncooperative game between users competing to maximize their own utility functions. Then, we propose distributed algorithms that converge to Nash equilibria of these games. Finally, we evaluate our proposed schemes through extensive simulations on both static and mobile scenarios. 
 
 Keywords: Non-Cooperative Game Theory; Wireless Networks; Resource Allocation; Distributed Algorithms; Nash Equilibrium. 1 Introduction 
 
 The rapid growth of wireless communication has led to increased demand for high quality services such as voice over IP (VoIP), video streaming, online gaming etc., which require efficient use of limited resources available at base stations or access points. To meet this growing demand, researchers have been working towards developing new techniques to improve the performance of existing wireless systems while maintaining low cost and energy consumption [1] . One promising approach is to optimize resource allocations among users in order to increase overall system throughput [2] , reduce interference [3] , minimize transmission delay [4] , and/or enhance fairness [5] .
 
The main challenge faced when designing resource allocation strategies lies in the fact that there are usually multiple conflicting objectives [6] . For example, maximizing total user satisfaction may lead to unfair distribution of resources across users [7]; increasing spectral efficiency can cause severe inter-user interference [8] ; minimizing transmission delays may result in poor channel utilization [9] . Therefore, it becomes necessary to develop novel approaches that strike a balance between various conflicting goals [10] . 
 
 This work was supported in part by NSF under Grants CNS-0721440, CCF-0729260, ECCS-0801571, and CNS-0916275.",arxiv,bigscience bloomz,705.0783,0.2777777777777778,0.596638655462185,0.358974358974359,0.7907310081223125,0,1,1,0,0,1,1,1,0,0,0.14071790017585767,0.09162407158074631,0.16342412451361868,0.09848484848484848,0,0,4,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Complementarity in the Bohr-Einstein Photon Box,"  The photon box thought experiment can be considered a forerunner of the
EPR-experiment: by performing suitable measurements on the box it is possible
to ``prepare'' the photon, long after it has escaped, in either of two
complementary states. Consistency requires that the corresponding box
measurements be complementary as well. At first sight it seems, however, that
these measurements can be jointly performed with arbitrary precision: they
pertain to different systems (the center of mass of the box and an internal
clock, respectively). But this is deceptive. As we show by explicit
calculation, although the relevant quantities are simultaneously measurable,
they develop non-vanishing commutators when calculated back to the time of
escape of the photon. This justifies Bohr's qualitative arguments in a precise
way; and it illustrates how the details of the dynamics conspire to guarantee
the requirements of complementarity. In addition, our calculations exhibit a
``fine structure'' in the distribution of the uncertainties over the
complementary quantities: depending on \textit{when} the box measurement is
performed, the resulting quantum description of the photon differs. This brings
us close to the argumentation of the later EPR thought experiment.
","We present an experimental investigation into complementarity between position and momentum measurements on single photons using a modified version of the original Einstein-Bohr photon box experiment.  The results show that, for this particular measurement scheme, there is no violation of Bell's inequality or any other form of nonlocality. We also demonstrate how our setup can be used to investigate quantum contextuality by performing two different experiments with identical settings but opposite outcomes. In one case we observe violations of Bell inequalities while in the other they are not violated. This shows that the observed behavior cannot be explained within classical physics and demonstrates quantum contextuality. Quantum mechanics predicts that certain physical quantities such as position and momentum do not have simultaneous well-defined values. Instead these quantities exist only as probability distributions which evolve continuously over time according to Schrödinger's equation. However, it has been shown that if both position and momentum were measured simultaneously then their respective probabilities would interfere destructively resulting in a zero probability of measuring either quantity at its most probable value [1] . This phenomenon known as Heisenberg uncertainty principle leads to the concept of complementarity: the impossibility of observing all properties of a system simultaneously [2] .
In 1964 John Bell showed that local hidden variable theories could not explain some predictions made by quantum mechanics [3] , leading to the formulation of Bell's theorem [4] . Since then many experiments have been performed to test whether quantum mechanical predictions violate Bell's theorem [5] . These tests typically involve entangled particles [6] where each particle carries information about the state of another distant particle [7, 8] . If the particles are separated far enough so that they never interact again after being created, then the correlations between them must be due solely to quantum effects [9] .",arxiv,bigscience bloomz,705.2762,0.3888888888888889,0.596638655462185,0.3230769230769231,0.8193979933110368,1,1,1,0,1,0,1,1,0,1,0.13668918538953312,0.05549417845497933,0.13618677042801555,0.06439393939393939,1,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Relaxation of a dewetting contact line Part 2: Experiments,"  The dynamics of receding contact lines is investigated experimentally through
controlled perturbations of a meniscus in a dip coating experiment. We first
characterize stationary menisci and their breakdown at the coating transition.
It is then shown that the dynamics of both liquid deposition and
long-wavelength perturbations adiabatically follow these stationary states.
This provides a first experimental access to the entire bifurcation diagram of
dynamical wetting, confirming the hydrodynamic theory developed in Part 1. In
contrast to quasi-static theories based on a dynamic contact angle, we
demonstrate that the transition strongly depends on the large scale flow
geometry. We then establish the dispersion relation for large wavenumbers, for
which we find that sigma is linear in q. The speed dependence of sigma is well
described by hydrodynamic theory, in particular the absence of diverging
time-scales at the critical point. Finally, we highlight some open problems
related to contact angle hysteresis that lead beyond the current description.
","We present new experimental results on the relaxation dynamics of a liquid film that is pulled off an inclined solid substrate by gravity and capillarity. The experiments are performed in a microgravity environment aboard the International Space Station (ISS). We find that, for sufficiently large pulling speeds, the relaxation process can be described as a succession of three stages. In stage I, the contact angle decreases rapidly to its equilibrium value at which point the contact line stops moving. Stage II starts when the contact line has stopped moving; during this stage, the contact angle remains constant while the height profile of the free surface continues evolving towards its final shape. Finally, in stage III, the contact angle increases again until it reaches its initial value. This behavior is explained using a simple model based on lubrication theory. Our analysis shows that the relaxation time scales with the inverse of the pulling speed. For small pulling speeds, we observe deviations from our theoretical predictions due to inertial effects. 
 
 Liquid films play important roles in many natural phenomena such as rain drops falling down a window or water evaporating into air. Dewetting processes occur frequently in nature but also have applications in industrial processes like coating technologies where thin films need to be removed from substrates. Understanding how these systems evolve over time requires knowledge about their relaxation dynamics after they have been perturbed out of equilibrium. Here, we study experimentally the relaxation of a liquid film that was pulled off an inclined solid wall by gravity and capillary forces.",arxiv,bigscience bloomz,705.3583,0.3888888888888889,0.596638655462185,0.1641025641025641,0.6961299569995223,0,1,0,0,0,1,0,1,0,0,0.036064674345593524,0.044822137433637055,0.0311284046692607,0.04924242424242424,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1
Possible X-ray diagnostic for jet/disk dominance in Type 1 AGN,"  Using Rossi X-ray Timing Explorer Seyfert 1 and 1.2 data spanning 9 years, we
study correlations between X-ray spectral features. The sample consists of 350
time-resolved spectra from 12 Seyfert 1 and 1.2 galaxies. Each spectrum is
fitted to a model with an intrinsic powerlaw X-ray spectrum produced close to
the central black hole that is reprocessed and absorbed by material around the
black hole. To test the robustness of our results, we performed Monte Carlo
simulations of the spectral sample. We find a complex relationship between the
iron line equivalent width (EW) and the underlying power law index (Gamma). The
data reveal a correlation between Gamma and EW which turns over at Gamma <~ 2,
but finds a weak anti-correlation for steeper photon indices. We propose that
this relationship is driven by dilution of a disk spectrum (which includes the
narrow iron line) by a beamed jet component and, hence, could be used as a
diagnostic of jet-dominance. In addition, our sample shows a strong correlation
between the reflection fraction (R) and Gamma, but we find that it is likely
the result of modeling degeneracies. We also see the X-ray Baldwin effect (an
anti-correlation between the 2-10 keV X-ray luminosity and EW) for the sample
as a whole, but not for the individual galaxies and galaxy types.
","We present the results of an analysis of Chandra observations of two nearby radio-quiet quasars, PG 1211+143 and Mrk 335 (z=0.034). We find that both sources show evidence for significant variability on timescales as short as hours to days. The observed flux changes are consistent with those expected if these objects have relativistic jets which precess around their axes at small angles to our line-of-sight. In addition we detect rapid flaring activity in the soft X-rays during one observation of each source. This is most likely due to thermal instabilities within the accretion disk. Finally, we discuss how this behaviour may be used to diagnose whether or not an active galactic nucleus has a dominant jet component. Keywords: Active Galactic Nuclei, Quasars, Jet Precession, Flare Activity, Accretion Disk Instability, Chandra Observatory",arxiv,bigscience bloomz,704.1587,0.4444444444444444,0.29411764705882354,0.48717948717948717,0.32919254658385094,1,1,0,0,0,1,1,1,0,0,0.07424502724190656,0.03641166912095373,0.06614785992217899,0.030303030303030304,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Nonholonomic Ricci Flows: III. Curve Flows and Solitonic Hierarchies,"  The geometric constructions are elaborated on (semi) Riemannian manifolds and
vector bundles provided with nonintegrable distributions defining nonlinear
connection structures induced canonically by metric tensors. Such spaces are
called nonholonomic manifolds and described by two equivalent linear
connections also induced in unique forms by a metric tensor (the Levi Civita
and the canonical distinguished connection, d-connection). The lifts of
geometric objects on tangent bundles are performed for certain classes of
d-connections and frame transforms when the Riemann tensor is parametrized by
constant matrix coefficients. For such configurations, the flows of
non-stretching curves and corresponding bi-Hamilton and solitonic hierarchies
encode information about Ricci flow evolution, Einstein spaces and exact
solutions in gravity and geometric mechanics. The applied methods were
elaborated formally in Finsler geometry and allows us to develop the formalism
for generalized Riemann-Finsler and Lagrange spaces. Nevertheless, all
geometric constructions can be equivalently re-defined for the Levi Civita
connections and holonomic frames on (semi) Riemannian manifolds.
","We study the curve flows associated with nonholonomic solitonic hierarchies in terms of nonlinear connections (N-connections) on fiber bundles, which are generated by horizontal lifts of vector fields along curves. We show that these N-connection structures can be derived as solutions to certain classes of generalized Einstein equations for metrics depending on higher order derivatives of time variables. The corresponding geometric objects are defined by using the so-called anholonomy coefficients of N-connections. In particular, we consider the case when the base manifold is an arbitrary smooth n-dimensional Riemannian space $(M^n,g)$ equipped with a family of local coordinates $x^{\mu} = (x^1,..., x^n)$. Then any point $p\in M^n$ has its natural coordinate neighborhood $U_p\subset M^n$ such that all points $q\in U_p$ have their own sets of coordinates $\bar{x}_q = \bar{x^1}_q, ...,\bar{x}_n_q$ related to each other via some diffeomorphism $\Phi_q : U_p\to V_q\subset \mathbb R^{n+1}$. This allows us to define the following class of metric tensors on $(M^n, g)$: 
$$
G_{\alpha\beta}(x) := g_{\alpha\beta} + \sum\limits_{q=1}^{n} h^{q}_{\alpha\beta}\bigl(x, \bar{x}_q\bigr)
$$
where $h^{q}_{\alpha\beta}(p, \bar{x}_q)$ are functions of two arguments satisfying certain conditions. These conditions guarantee that the tensor field $G_{\alpha\beta}$ defines a pseudo-Riemannian metric on $M$.",arxiv,bigscience bloomz,704.2062,0.2777777777777778,0.29411764705882354,0.16923076923076924,0.49832775919732447,1,1,0,0,0,1,1,1,0,0,0.04189104585358772,0.22817629833530653,0.038910505836575876,0.2537878787878788,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Multidimensional fluid motions with planar waves,"  In the classical one-dimensional solution of fluid dynamics equations all
unknown functions depend only on time t and Cartesian coordinate x. Although
fluid spreads in all directions (velocity vector has three components) the
whole picture of motion is relatively simple: trajectory of one fluid particle
from plane x=const completely determines motion of the whole plane. Basing on
the symmetry analysis of differential equations we propose generalization of
this solution allowing movements in different directions of fluid particles
belonging to plane x=const. At that, all functions but an angle determining the
direction of particle's motion depend on t and x only, whereas the angle
depends on all coordinates. In this solution the whole picture of motion
superposes from identical trajectories placed under different angles in 3D
space. Orientations of the trajectories are restricted by a finite relation
possessing functional arbitrariness. The solution describes three-dimensional
nonlinear processes and singularities in infinitely conducting plasma, gas or
incompressible liquid.
","We consider the motion of an incompressible, inviscid fluid in two dimensions under the influence of gravity and surface tension. The flow is assumed to be irrotational except for a finite number of singularities at which point vorticity may accumulate. We show that if the initial data are sufficiently small then there exists a unique global solution whose velocity field has only one component along each line parallel to the x-axis. This result generalizes previous results on two-dimensional flows by allowing more complicated wave patterns such as those generated by water waves or nonlinear optics. 
 
 Keywords: Fluids; Vortices; Water waves; Nonlinear optics. 1 Introduction 
 
 In this work we study the dynamics of fluids governed by the Euler equations in two space dimensions. Our main goal is to prove existence of solutions having certain special properties. More precisely, let us assume that the initial velocity field u0(x) = (u0x(x), u0y(x)) satisfies the following conditions:",arxiv,bigscience bloomz,705.2311,0.3333333333333333,0.3445378151260504,0.1641025641025641,0.3922599139990445,1,1,1,0,1,1,1,1,0,0,0.0725748384588388,0.05670645345074402,0.0622568093385214,0.05303030303030303,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
A theorem about relative entropy of quantum states with an application to privacy in quantum communication,"  We prove the following theorem about relative entropy of quantum states.
""Substate theorem: Let rho and sigma be quantum states in the same Hilbert
space with relative entropy S(rho|sigma) = Tr rho (log rho - log sigma) = c.
Then for all epsilon > 0, there is a state rho' such that the trace distance
||rho' - rho||_t = Tr sqrt{(rho' - rho)^2} <= epsilon, and
rho'/2^{O(c/epsilon^2)} <= sigma.""
  It states that if the relative entropy of rho and sigma is small, then there
is a state rho' close to rho, i.e. with small trace distance ||rho' - rho||_t,
that when scaled down by a factor 2^{O(c)} `sits inside', or becomes a
`substate' of, sigma. This result has several applications in quantum
communication complexity and cryptography. Using the substate theorem, we
derive a privacy trade-off for the set membership problem in the two-party
quantum communication model. Here Alice is given a subset A of [n], Bob an
input i in [n], and they need to determine if i in A.
  ""Privacy trade-off for set membership: In any two-party quantum communication
protocol for the set membership problem, if Bob reveals only k bits of
information about his input, then Alice must reveal at least n/2^{O(k)} bits of
information about her input.""
  We also discuss relationships between various information theoretic
quantities that arise naturally in the context of the substate theorem.
","We prove that the relative entropy between two density matrices is equal to the difference between their von Neumann entropies, and we show how this result can be used for proving security against eavesdropping attacks on quantum key distribution protocols.  We also present some examples where our results are applied. The relative entropy between two density operators $\rho$ and $\sigma$ is defined as $$D(\rho||\sigma) = \sum_i p_i \log \frac{p_i}{\sigma^{*}}(\sigma(\hat{\psi}_i))$$
  where $(\hat{\psi_i},p_1,...,p_n)$ is any complete set of eigenvectors of both $\rho$ and $\sigma^∗ \sigma$ such that $\sum_ip_i = 1$.
  In particular, if one considers the case when $\rho$ is the state sent by Alice (the sender), while $\sigma$ is the state received by Bob (the receiver), then the quantity $D(\rho||\sigma)$ represents Eve's uncertainty about what was transmitted through the channel.",arxiv,bigscience bloomz,705.2437,0.4444444444444444,0.14285714285714285,0.5435897435897435,0.32345914954610605,1,1,1,0,1,1,0,0,0,1,0.2132647062475998,0.244938306124346,0.28793774319066145,0.2765151515151515,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
"Near-Infrared Spectra of the Black Hole X-Ray Binary, A0620-00","  We present broadband NIR spectra of A0620-00 obtained with SpeX on the IRTF.
The spectrum is characterized by a blue continuum on which are superimposed
broad emission lines of HI and HeII and a host of narrower absorption lines of
neutral metals and molecules. Spectral type standard star spectra scaled to the
dereddened spectrum of A0620-00 in K exceed the A0620-00 spectrum in J and H
for all stars of spectral type K7V or earlier, demonstrating that the donor
star, unless later than K7V, cannot be the sole NIR flux source in A0620-00. In
addition, the atomic absorption lines in the K3V spectrum are too weak with
respect to those of A0620-00 even at 100% donor star contribution, restricting
the spectral type of the donor star in A0620-00 to later than K3V. Comparison
of the A0620-00 spectrum to scaled K star spectra indicates that the CO
absorption features are significantly weaker in A0620-00 than in field dwarf
stars. Fits of scaled model spectra of a Roche lobe-filling donor star to the
spectrum of A0620-00 show that the best match to the CO absorption lines is
obtained when the C abundance is reduced to [C/H] = -1.5. The donor star
contribution in the H waveband is determined to be 82+-2%. Combined with
previous published results from Froning & Robinson (2001) and Marsh et al.
(1994), this gives a precise mass for the black hole in A0620-00 of M_BH =
9.7+-0.6 M_solar.
","We present near-infrared (NIR) spectroscopy of the black hole X-ray binary system A0620-00 obtained with the Subaru Telescope and Gemini Observatory in 2001-2002. The NIR spectrum shows strong emission lines originating from highly ionized species such as FeXXV-XXVI, NeIX-XI, MgXI-XII, SiXIV-XVII, SXV-XXIII, ArXVIII-XXIV, CaXIX-XXVIII, and NiXXI-XXIV. We find that these features are well reproduced by our photoionization model calculations for an accretion disk irradiated by hard X-rays emitted from the central source. In addition to the above mentioned ions, we also detect absorption lines due to neutral hydrogen and helium at wavelengths longer than 1 micron. These absorptions originate from the interstellar medium along the line-of-sight toward this object. 
 
 Keywords: Near-infrared spectroscopy",arxiv,bigscience bloomz,704.0267,0.4444444444444444,0.24369747899159663,0.6,0.27472527472527475,1,1,0,0,0,1,1,1,0,0,0.12875660382077192,0.07909159962672667,0.10116731517509728,0.030303030303030304,0,1,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Scaling Relations of Compressible MHD Turbulence,"  We study scaling relations of compressible strongly magnetized turbulence. We
find a good correspondence of our results with the Fleck (1996) model of
compressible hydrodynamic turbulence. In particular, we find that the
density-weighted velocity, i.e. $u \equiv \rho^{1/3} v$, proposed in Kritsuk et
al. (2007) obeys the Kolmogorov scaling, i.e. $E_{u}(k)\sim k^{-5/3}$ for the
high Mach number turbulence. Similarly, we find that the exponents of the third
order structure functions for $u$ stay equal to unity for the all the Mach
numbers studied. The scaling of higher order correlations obeys the She-Leveque
(1994) scalings corresponding to the two-dimensional dissipative structures,
and this result does not change with the Mach number either. In contrast to $v$
which exhibits different scaling parallel and perpendicular to the local
magnetic field, the scaling of $u$ is similar in both directions. In addition,
we find that the peaks of density create a hierarchy in which both physical and
column densities decrease with the scale in accordance to the Fleck (1996)
predictions. This hierarchy can be related ubiquitous small ionized and neutral
structures (SINS) in the interstellar gas. We believe that studies of
statistics of the column density peaks can provide both consistency check for
the turbulence velocity studies and insight into supersonic turbulence, when
the velocity information is not available.
","We present the results of high-resolution numerical simulations of compressible magnetohydrodynamic (MHD) turbulence in periodic boxes with different sizes and resolutions, ranging from $(2^{10} \sim 2^{12})^3$ to $(4^{10} \sim 4^{12})^3$ grid points at resolution levels between 64 3 and 512 3 . We find that the scaling relations for kinetic energy spectra are consistent with those predicted by Kolmogorov's theory when normalized appropriately.  The magnetic field spectrum follows a power law over several decades in wavenumber space, but deviates significantly from the prediction of idealized MHD turbulence theories such as Iroshnikov-Kraichnan or Goldreich-Sridhar models. In addition, we show that the anisotropy of velocity fluctuations is negligible compared to that of magnetic fields. Finally, we demonstrate that our simulation data can be used to test theoretical predictions on the statistics of Alfvénic modes.",arxiv,bigscience bloomz,705.2464,0.6111111111111112,0.19327731092436976,0.4717948717948718,0.3320592451027234,1,1,0,0,0,1,1,0,0,1,0.08705630607510599,0.1528266719164186,0.0622568093385214,0.15151515151515152,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Detection of Crab Giant Pulses Using the Mileura Widefield Array Low Frequency Demonstrator Field Prototype System,"  We report on the detection of giant pulses from the Crab Nebula pulsar at a
frequency of 200 MHz using the field deployment system designed for the Mileura
Widefield Array's Low Frequency Demonstrator (MWA-LFD). Our observations are
among the first high-quality detections at such low frequencies. The measured
pulse shapes are deconvolved for interstellar pulse broadening, yielding a
pulse-broadening time of 670$\pm$100 $\mu$s, and the implied strength of
scattering (scattering measure) is the lowest that is estimated towards the
Crab nebula from observations made so far. The sensitivity of the system is
largely dictated by the sky background, and our simple equipment is capable of
detecting pulses that are brighter than $\sim$9 kJy in amplitude. The brightest
giant pulse detected in our data has a peak amplitude of $\sim$50 kJy, and the
implied brightness temperature is $10^{31.6}$ K. We discuss the giant pulse
detection prospects with the full MWA-LFD system. With a sensitivity over two
orders of magnitude larger than the prototype equipment, the full system will
be capable of detecting such bright giant pulses out to a wide range of
Galactic distances; from $\sim$8 to $\sim$30 kpc depending on the frequency.
The MWA-LFD will thus be a highly promising instrument for the studies of giant
pulses and other fast radio transients at low frequencies.
","We report on the detection and analysis of giant pulses (GPs) from the Crab pulsar using data recorded with the MWA-LFD prototype system at frequencies between 80 and 240 MHz. The GPs are detected by searching for excess power in short time intervals, which is then compared to that expected from background noise fluctuations. We find that the number of GP candidates increases as we lower the frequency below 150 MHz. This increase can be explained if the emission mechanism responsible for producing GPs has an intrinsic spectral index steeper than -1.5. In addition, we show that the pulse width distribution changes significantly when going from high to low radio frequencies. Finally, we present results showing how the flux density of individual GPs varies across our observing bandwidth. These observations provide new insights into the physical processes occurring within the magnetosphere of this energetic pulsar. Keywords: Radio astronomy, Pulsar",arxiv,bigscience bloomz,705.0404,0.3333333333333333,0.3445378151260504,0.4717948717948718,0.38079311992355475,1,1,1,0,1,1,1,1,0,0,0.12825660175173523,0.059893877838492975,0.1517509727626459,0.030303030303030304,0,1,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The origin of the molecular emission around the southern hemisphere Re 4 IRS - HH 188 region,"  We present SEST observations of the molecular environment ahead of the
southern Herbig-Haro object 188 (HH188), associated with the low-mass protostar
Re4 IRS. We have also used the SuperCosmos Halpha survey to search for Halpha
emission associated with the Re4 IRS - HH188 region. The aim of the present
work is to study the properties of the molecular gas and to better characterize
this southern star forming region. We mapped the HCO+ 3-2 and H13CO+ 1-0
emission around the YSO and took spectra of the CH3OH 2(0)-1(0)A+ and
2(-1)-1(-1)E and SO 6(5)-5(4) towards the central source. Column densities are
derived and different scenarios are considered to explain the origin of the
molecular emission. HCO+ arises from a relatively compact region around the
YSO; however, its peak emission is displaced to the south following the outflow
direction. Our chemical analysis indicates that a plausible scenario is that
most of the emission arises from the cold, illuminated dense gas ahead of the
HH188 object. We have also found that HH188, a high excitation object, seems to
be part of a parsec scale and highly collimated HH system. Re4 IRS is probably
a binary protostellar system, in the late Class 0 or Class I phase. One of the
protostars, invisible in the near-IR, seems to power the HH188 system.
","We present new observations in the mid-infrared (MIR) and near-infrared (NIR), as well as archival data, to study the physical conditions of the gas surrounding the young stellar object Re 4 IRS located at the center of the reflection nebula NGC 1333 IRAS 2. We find that the MIR spectrum is dominated by strong ro-vibrational lines of H$_2$O and CO, while the NIR spectrum shows prominent Brackett-γ line emission with an equivalent width of ~1 Å. The observed fluxes are consistent with those expected for a T Tauri star surrounded by a dense circumstellar disk heated by accretion shocks. In addition, we detect several forbidden transitions of [Fe II] , [S III] , [N II] , and [C II] . These results suggest that the central source has recently undergone a burst of enhanced mass loss activity which may be related to its recent transition into the main sequence phase.",arxiv,bigscience bloomz,705.1427,0.5,0.19327731092436976,0.47692307692307695,0.3836598184424272,1,1,1,0,0,1,1,0,0,0,0.09103332891243385,0.0781951646560414,0.13229571984435798,0.03787878787878788,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Chandra Observations of Supernova 1987A,"  We have been monitoring Supernova (SN) 1987A with {\it Chandra X-Ray
Observatory} since 1999. We present a review of previous results from our {\it
Chandra} observations, and some preliminary results from new {\it Chandra} data
obtained in 2006 and 2007. High resolution imaging and spectroscopic studies of
SN 1987A with {\it Chandra} reveal that X-ray emission of SN 1987A originates
from the hot gas heated by interaction of the blast wave with the ring-like
dense circumstellar medium (CSM) that was produced by the massive progenitor's
equatorial stellar winds before the SN explosion. The blast wave is now
sweeping through dense CSM all around the inner ring, and thus SN 1987A is
rapidly brightening in soft X-rays. At the age of 20 yr (as of 2007 January),
X-ray luminosity of SN 1987A is $L_{\rm X}$ $\sim$ 2.4 $\times$ 10$^{36}$ ergs
s$^{-1}$ in the 0.5$-$10 keV band. X-ray emission is described by two-component
plane shock model with electron temperatures of $kT$ $\sim$ 0.3 and 2 keV. As
the shock front interacts with dense CSM all around the inner ring, the X-ray
remnant is now expanding at a much slower rate of $v$ $\sim$ 1400 km s$^{-1}$
than it was until 2004 ($v$ $\sim$ 6000 km s$^{-1}$).
","The Chandra X-ray Observatory has observed the supernova remnant (SNR) produced by SN1987A in the Large Magellanic Cloud for over ten years, providing an unprecedented view into this young and energetic object.  The observations have revealed that the blast wave is interacting with dense circumstellar material surrounding the progenitor star at velocities up to 1000 km/sec.  This interaction produces bright knots of emission which are seen as moving outward through the shell of the remnant.  These knots appear to be composed primarily of oxygen-rich ejecta mixed with shocked interstellar gas.  In addition, there appears to be a large amount of hot plasma trapped behind the forward shock front.  We present here new results on these features based on our analysis of data obtained during the first year of the Chandra mission. The Chandra X-ray Observatory has observed  the supernova remnant ( SNR ) produced by SN1987A , in the Large Magellan ic Cloud , for over ten years . It provides an unprecedented view into this y oung and en erg i c obj ect .  T he obse rvations ha ve reve al ed tha t th e b las t wa ve is interactin g wi th d ens e circumstell ar m aterial surroundi ng th e proge nitor star-at-rou nd -velocities up to 1 000 k m/ sec . Thi s interac tion produ ces brigh t kn ots of emi ssion wh ich appea r to be co mp osed pri marily of oxyg ene -rico h ej ec ta mixe d w ith sh ocked int erstel lar ga s .",arxiv,bigscience bloomz,704.0209,0.3333333333333333,0.4453781512605043,0.4153846153846154,0.7190635451505017,1,1,0,0,1,1,1,0,0,0,0.16876556432267717,0.08928457251542207,0.1556420233463035,0.09848484848484848,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Performance of the Charge Injection Capability of Suzaku XIS,"  A charge injection technique is applied to the X-ray CCD camera, XIS (X-ray
Imaging Spectrometer) onboard Suzaku. The charge transfer inefficiency (CTI) in
each CCD column (vertical transfer channel) is measured by the injection of
charge packets into a transfer channel and subsequent readout. This paper
reports the performances of the charge injection capability based on the ground
experiments using a radiation damaged device, and in-orbit measurements of the
XIS. The ground experiments show that charges are stably injected with the
dispersion of 91eV in FWHM in a specific column for the charges equivalent to
the X-ray energy of 5.1keV. This dispersion width is significantly smaller than
that of the X-ray events of 113eV (FWHM) at approximately the same energy. The
amount of charge loss during transfer in a specific column, which is measured
with the charge injection capability, is consistent with that measured with the
calibration source. These results indicate that the charge injection technique
can accurately measure column-dependent charge losses rather than the
calibration sources. The column-to-column CTI correction to the calibration
source spectra significantly reduces the line widths compared to those with a
column-averaged CTI correction (from 193eV to 173eV in FWHM on an average at
the time of one year after the launch). In addition, this method significantly
reduces the low energy tail in the line profile of the calibration source
spectrum.
","We have investigated charge injection capability (CIC) of Suzaku X-ray Imaging Spectrometer (XIS). The CIC is an important feature for high energy resolution spectroscopy, which can be used to reduce the effect of pile-up in bright sources and improve the spectral quality at low energies. We performed detailed analysis on the performance of CIC by using Crab observations with different count rates. By comparing the results obtained with and without CIC we found that CIC improves the spectral fitting significantly especially below 1 keV where the pile-up fraction becomes large when the source flux increases. This improvement was confirmed also by analyzing simulated data generated by xisrmfgen and xissimarfgen. Finally, we applied this method to analyze the observation of Mrk 421 during its flare state. We successfully detected emission lines such as O VII Kα line and Fe XXV Kα line from the spectrum taken with CIC enabled.  These results show that CIC works well even under strong pile-up conditions.",arxiv,bigscience bloomz,705.1771,0.4444444444444444,0.3445378151260504,0.5282051282051282,0.4123268036311515,1,1,0,0,0,1,1,0,0,0,0.06781842100408998,0.06408033876870922,0.08949416342412451,0.056818181818181816,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The time evolution of cosmological redshift as a test of dark energy,"  The variation of the expansion rate of the Universe with time produces an
evolution in the cosmological redshift of distant sources (for example quasar
Lyman-$\alpha$ absorption lines), that might be directly observed by future
ultra stable, high-resolution spectrographs (such as CODEX) coupled to
extremely large telescopes (such as European Southern Observatory's Extremely
Large Telescope, ELT). This would open a new window to explore the physical
mechanism responsible for the current acceleration of the Universe. We
investigate the evolution of cosmological redshift from a variety of dark
energy models, and compare it with simulated data. We perform a Fisher matrix
analysis and discuss the prospects for constraining the parameters of these
models and for discriminating among competing candidates. We find that, because
of parameter degeneracies, and of the inherent technical difficulties involved
in this kind of observations, the uncertainties on parameter reconstruction can
be rather large unless strong external priors are assumed. However, the method
could be a valuable complementary cosmological tool, and give important
insights on the dynamics of dark energy, not obtainable using other probes.
","We propose to use the time evolution of cosmological redshifts in order to probe the nature of dark energy, which is one of the most important problems in modern physics and astronomy. We show that this method can be used for testing various models of dark energy by using only two parameters (the present-day values of Hubble constant H0 and deceleration parameter q0). The proposed method does not require any additional information about the universe beyond what we already know today. This makes it possible to perform an independent check on the results obtained with other methods such as supernovae Ia observations or cosmic microwave background anisotropy measurements. In particular, our analysis shows that the current data are consistent with the standard ΛCDM model at 1σ level but do not rule out some alternative models like quintessence or phantom fields. Finally, we discuss how future surveys could improve the constraints on these models. Cosmological redshifts play an important role in modern astrophysics and cosmology because they provide us with valuable information about the expansion history of the Universe. However, their interpretation requires knowledge of the underlying theory describing the dynamics of space-time. For example, if we assume general relativity then cosmological redshifts can be interpreted as due to the Doppler effect caused by the recession velocities of distant galaxies [1] . On the other hand, if we consider modified gravity theories then cosmological redshifting may have different physical origins [2] .
In recent years there has been growing interest in studying the possibility of probing the nature of dark energy through its effects on cosmological redshifts [3] - [8] . Dark energy is currently believed to dominate the content of the Universe [9] , however its exact origin remains unknown [10] . It is usually described within the framework of Einstein's field equations by introducing a new component into the stress-energy tensor [11] . Its presence leads to accelerated expansion of the Universe [12] , which manifests itself in the form of observed...",arxiv,bigscience bloomz,704.235,0.2777777777777778,0.6470588235294118,0.2717948717948718,0.9082656473960822,1,1,0,0,1,1,1,0,0,1,0.16249762298144732,0.052950332511360255,0.19066147859922178,0.056818181818181816,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
Ly-alpha Emission-Line Galaxies at z = 3.1 in the Extended Chandra Deep Field South,"  We describe the results of an extremely deep, 0.28 deg^2 survey for z = 3.1
Ly-alpha emission-line galaxies in the Extended Chandra Deep Field South. By
using a narrow-band 5000 Anstrom filter and complementary broadband photometry
from the MUSYC survey, we identify a statistically complete sample of 162
galaxies with monochromatic fluxes brighter than 1.5 x 10^-17 ergs cm^-2 s^-1
and observers frame equivalent widths greater than 80 Angstroms. We show that
the equivalent width distribution of these objects follows an exponential with
a rest-frame scale length of w_0 = 76 +/- 10 Angstroms. In addition, we show
that in the emission line, the luminosity function of Ly-alpha galaxies has a
faint-end power-law slope of alpha = -1.49 +/- 0.4, a bright-end cutoff of log
L^* = 42.64 +/- 0.2, and a space density above our detection thresholds of 1.46
+/- 0.12 x 10^-3 h70^3 galaxies Mpc^-3. Finally, by comparing the emission-line
and continuum properties of the LAEs, we show that the star-formation rates
derived from Ly-alpha are ~3 times lower than those inferred from the
rest-frame UV continuum. We use this offset to deduce the existence of a small
amount of internal extinction within the host galaxies. This extinction,
coupled with the lack of extremely-high equivalent width emitters, argues that
these galaxies are not primordial Pop III objects, though they are young and
relatively chemically unevolved.
","We present spectroscopic redshifts for Lyman alpha emission-line galaxies (LAEs) selected with narrow-band imaging data taken by Subaru/Suprime-Cam and VLT/VIMOS on the basis of their strong rest-frame ultraviolet emission lines, including Ly-alpha line. We have obtained spectra for 16 LAEs using Keck/DEIMOS over an area of 0.5 deg2 centered around the Hubble Ultra Deep Field (HUDF). The median redshift is found to be $3.10 \pm 0.01$. This value agrees well with that estimated from photometric redshifts based on multi-band optical-to-infrared SEDs constructed from deep ground-based observations as well as those derived from Spitzer/MIPS 24 micron fluxes. Our sample consists of two sub-samples; one has been observed only once while another was observed twice or more times. No significant difference between these samples are seen except for the fraction of objects showing double peaks in their Ly-alpha profiles.",arxiv,bigscience bloomz,705.3917,0.3333333333333333,0.24369747899159663,0.5333333333333333,0.3463927376970855,0,1,0,0,0,1,1,1,0,0,0.1192160549046418,0.06317036827447807,0.12840466926070038,0.05303030303030303,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"The Long Period, Massive Binaries HD 37366 and HD 54662: Potential Targets for Long Baseline Optical Interferometry","  We present the results from an optical spectroscopic analysis of the massive
stars HD 37366 and HD 54662. We find that HD 37366 is a double-lined
spectroscopic binary with a period of 31.8187 +/- 0.0004 days, and HD 54662 is
also a double lined binary with a much longer period of 557.8 +/- 0.3 days. The
primary of HD 37366 is classified as O9.5 V, and it contributes approximately
two-thirds of the optical flux. The less luminous secondary is a broad-lined,
early B-type main-sequence star. Tomographic reconstruction of the individual
spectra of HD 37366 reveals absorption lines present in each component,
enabling us to constrain the nature of the secondary and physical
characteristics of both stars. Tomographic reconstruction was not possible for
HD 54662; however, we do present mean spectra from our observations that show
that the secondary component is approximately half as bright as the primary.
The observed spectral energy distributions (SEDs) were fit with model SEDs and
galactic reddening curves to determine the angular sizes of the stars. By
assuming radii appropriate for their classifications, we determine distance
ranges of 1.4 - 1.9 and 1.2 - 1.5 kpc for HD 37366 and HD 54662, respectively.
",We present the first results on two massive binary systems with periods longer than 100 days that are potential targets for future space-based optical interferometers such as SIM or TPF-I. The primary stars in these binaries have masses between 8 to 12 Msun and their companions are less massive (1-5 Msun). We used high resolution spectroscopy obtained at McDonald Observatory to determine orbital parameters for both systems. In addition we determined stellar atmospheric properties using photometric data taken by Hipparcos satellite and spectroscopic observations made at McDonald Observatory. Our analysis shows that the components of HD 37362 system are very similar while those of HD 54672 differ significantly. This is consistent with our expectations based on evolutionary models which predict that the more massive star will evolve faster and become redder. These results demonstrate that it may be possible to use astrometric measurements combined with radial velocity curves to measure directly mass loss rates due to winds driven by radiation pressure.,arxiv,bigscience bloomz,704.3229,0.3888888888888889,0.29411764705882354,0.37948717948717947,0.41519350215002393,1,1,1,0,0,1,1,0,0,0,0.07881323487154725,0.03824867256573036,0.07782101167315175,0.011363636363636364,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Bounds on quark mass matrices elements due to measured properties of the mixing matrix and present values of the quark masses,"  We obtain constraints on possible structures of mass matrices in the quark
sector by using as experimental restrictions the determined values of the quark
masses at the $M_Z$ energy scale, the magnitudes of the quark mixing matrix
elements $V_{\rm ud}$, $V_{\rm us}$, $V_{\rm cd}$, and $V_{\rm cs}$, and the
Jarlskog invariant $J(V)$. Different cases of specific mass matrices are
examined in detail. The quality of the fits for the Fritzsch and Stech type
mass matrices is about the same with $\chi^2/{\rm dof}=4.23/3=1.41$ and
$\chi^2/{\rm dof}=9.10/4=2.28$, respectively. The fit for a simple
generalization (one extra parameter) of the Fritzsch type matrices, in the
physical basis, is much better with $\chi^2/{\rm dof}=1.89/4=0.47$. For
comparison we also include the results using the quark masses at the 2 GeV
energy scale. The fits obtained at this energy scale are similar to that at
$M_Z$ energy scale, implying that our results are unaffected by the evolution
of the quark masses from 2 to 91 GeV.
","We derive bounds on the absolute values of all entries in the up- and down-quark mass matrices, using only information about the CKM-matrix and current experimental data for the masses of quarks. We find that these bounds are much stronger than those obtained previously by other authors. 
 
 The results presented here can be used as input parameters for future studies of CP violation within the Standard Model or its extensions. They also provide useful constraints on models with extra dimensions where quarks propagate into higher-dimensional bulk spaces. 
I. INTRODUCTORY REMARK
The Cabibbo-Kobayashi-Maskawa (CKM) [1] quark mixing matrix V is an unitary 3 x 3 complex matrix which describes how quarks mix among themselves after electroweak symmetry breaking. It contains nine independent real parameters, three angles θ12 , θ23 , θ13 and six phases φ1 , φ2 ,...",arxiv,bigscience bloomz,704.2851,0.2777777777777778,0.29411764705882354,0.18974358974358974,0.3463927376970855,1,0,0,0,0,1,1,0,0,0,0.22759466147654173,0.08762668759537869,0.28793774319066145,0.10606060606060606,0,1,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"""Illusion of control"" in Minority and Parrondo Games","  Human beings like to believe they are in control of their destiny. This
ubiquitous trait seems to increase motivation and persistence, and is probably
evolutionarily adaptive. But how good really is our ability to control? How
successful is our track record in these areas? There is little understanding of
when and under what circumstances we may over-estimate or even lose our ability
to control and optimize outcomes, especially when they are the result of
aggregations of individual optimization processes. Here, we demonstrate
analytically using the theory of Markov Chains and by numerical simulations in
two classes of games, the Minority game and the Parrondo Games, that agents who
optimize their strategy based on past information actually perform worse than
non-optimizing agents. In other words, low-entropy (more informative)
strategies under-perform high-entropy (or random) strategies. This provides a
precise definition of the ""illusion of control"" in set-ups a priori defined to
emphasize the importance of optimization.
","We study the effect of ""illusion of control"" on minority games with different number of players, as well as on Parrondo's paradoxical games. We show that for all these cases there is an optimal value of illusion of control which maximizes the performance of the system. The results are obtained by using numerical simulations based on Monte Carlo method. In particular we find that the optimal values of illusion of control depend strongly on the number of players involved in each game. 
I. INTRODUCTIO N

A. Illusion of Control (IC)
The term ""illusion of control"" was first introduced by Langer [1] . It refers to situations where people tend to overestimate their ability to influence events or outcomes [2] , even when they have no real control [3] .
In recent years this concept has been applied to many fields such as: gambling [4] , stock markets [5] , sports [6] , health [7] , education [8] etc., showing its importance in human behavior [9] - [11] .
B. Minority Game (MG) MGs were proposed by Challet and Zhang [12] as models of financial markets. They consist of agents who make decisions according to some strategy at discrete time steps. At every step one agent makes a decision among two options, called spin-up and spindown. If more than half of the agents choose the same option then it wins; otherwise it loses. Agents can change their strategies during the course of play [13] . There exist several variants of MGs: single-agent [14] , multi-agent [15] , continuous-time [16] , quantum [17] , evolutionary [18] , co-evolutionary [19] , spatially extended [20] , and others [21] - [23] .
C. Parrondo's Paradoxical Games (PPGs)
Parrondo's paradoxical games [24] are simple two-player games played between a player A and B [25] . Each player plays against his opponent with a certain probability p i = 1 − q i , where 0 < p i , q i ≤ 1 [26] . When both players use the same strategy s i ∈ {−1, 1}, the expected return per round is zero [27] . However if",arxiv,bigscience bloomz,704.112,0.3888888888888889,0.4453781512605043,0.15897435897435896,0.4596273291925466,1,1,0,1,0,1,1,1,0,2,0.11929703817511057,0.105813087497668,0.10894941634241245,0.1856060606060606,2,4,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,2,1,1
A CLT for Information-theoretic statistics of Gram random matrices with a given variance profile,"  Consider a $N\times n$ random matrix $Y_n=(Y_{ij}^{n})$ where the entries are
given by $$ Y_{ij}^{n}=\frac{\sigma_{ij}(n)}{\sqrt{n}} X_{ij}^{n} $$ the
$X_{ij}^{n}$ being centered, independent and identically distributed random
variables with unit variance and $(\sigma_{ij}(n); 1\le i\le N, 1\le j\le n)$
being an array of numbers we shall refer to as a variance profile. We study in
this article the fluctuations of the random variable $$ \log\det(Y_n Y_n^* +
\rho I_N) $$ where $Y^*$ is the Hermitian adjoint of $Y$ and $\rho > 0$ is an
additional parameter. We prove that when centered and properly rescaled, this
random variable satisfies a Central Limit Theorem (CLT) and has a Gaussian
limit whose parameters are identified. A complete description of the scaling
parameter is given; in particular it is shown that an additional term appears
in this parameter in the case where the 4$^\textrm{th}$ moment of the
$X_{ij}$'s differs from the 4$^{\textrm{th}}$ moment of a Gaussian random
variable. Such a CLT is of interest in the field of wireless communications.
","We consider the information-theoretic limit theorems (CLTs) for linear spectral statistics of large dimensional Gram random matrices, which are defined as follows.  Let $(X_1,\ldots, X_n)$ be an iid sequence of zero-mean complex Gaussian vectors in $\mathbb{C}^d$ and let $Y=XX^*$ denote its covariance matrix. We assume that the distribution of $X$ is invariant under unitary transformations on each coordinate axis. Then we define the Gram random matrix $G_n$ by $$G_n = Y^{1/2}Y^{1/2}$$ where $Y^{1/2}$ denotes the square root of $Y$. The main purpose of this work is to establish central limit theorems for linear spectral statistics of the form $\displaystyle{\sum_{j=1}^n f_j(\lambda_j)}$, where $\lambda_j$'s are the eigenvalues of $G$ and $f_j$'s are functions satisfying some regularity conditions. In particular, we show that if $f$ has bounded variation then the limiting distribution of $\displaystyle{\sum_{j=0}^n f_j(\lambda_i)}$ can be expressed explicitly using the Stieltjes transform of the Marchenko-Pastur law.",arxiv,bigscience bloomz,706.0166,0.2222222222222222,0.24369747899159663,0.2153846153846154,0.36645962732919257,1,0,1,0,1,1,1,0,0,1,0.35448369745063074,0.10885892744740619,0.2801556420233463,0.06818181818181818,0,0,3,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Studies of Thermally Unstable Accretion Disks around Black Holes with Adaptive Pseudo-Spectral Domain Decomposition Method I. Limit-Cycle Behavior in the Case of Moderate Viscosity,"  We present a numerical method for spatially 1.5-dimensional and
time-dependent studies of accretion disks around black holes, that is
originated from a combination of the standard pseudo-spectral method and the
adaptive domain decomposition method existing in the literature, but with a
number of improvements in both the numerical and physical senses. In
particular, we introduce a new treatment for the connection at the interfaces
of decomposed subdomains, construct an adaptive function for the mapping
between the Chebyshev-Gauss-Lobatto collocation points and the physical
collocation points in each subdomain, and modify the over-simplified
1-dimensional basic equations of accretion flows to account for the effects of
viscous stresses in both the azimuthal and radial directions. Our method is
verified by reproducing the best results obtained previously by Szuszkiewicz &
Miller on the limit-cycle behavior of thermally unstable accretion disks with
moderate viscosity. A new finding is that, according to our computations, the
Bernoulli function of the matter in such disks is always and everywhere
negative, so that outflows are unlikely to originate from these disks. We are
encouraged to study the more difficult case of thermally unstable accretion
disks with strong viscosity, and wish to report our results in a subsequent
paper.
","We have studied thermally unstable accretion disks by using an adaptive pseudo-spectral domain decomposition method (PSDDM). We found that limit-cycles appear when the viscosity is moderate, and they are suppressed as the viscosity decreases. The results obtained here agree well with those reported previously for non-adaptive PSDDMs. 
 
 Keywords: black hole, disk instability, limit cycle, spectral methods, viscous flow 
 
 1 Introduction 
 
 In recent years there has been considerable interest in studying the nonlinear behavior of thermally unstable accretion flows onto black holes because such instabilities may be responsible for some observed phenomena associated with active galactic nuclei (AGNs) or quasars [1, 2] . For example, it was suggested that the rapid variability of AGNs/quasars could result from thermal-viscous instabilities [3 -5] , which can lead to limit cycles [6] . However, previous studies on this subject were limited mainly due to computational difficulties [7 -9] . 
 
 In order to overcome these difficulties we developed recently an adaptive pseudospectral domain decomposition method (APSDDM), which allows us to study numerically the nonlinear evolution of thermally unstable accretions more efficiently than before [10, 11] . Using APSDDM we investigated the effects of various physical parameters on the nonlinear evolution of thermallly unstable accretion disks [11] . It turned out that the effect of magnetic fields on the nonlinear evolution depends strongly on their strength; while weak magnetic fields tend to enhance the growth rate of the limit-cycle amplitude, strong ones suppress them [12] . 
In this work we continue our investigation into the nonlinear evolution of thermaly unstable accretion disks by considering the case where the viscosity parameter α = 0.1. This value of α corresponds roughly to the situation expected at distances of about 10 Schwarzschild radii from the central black hole [13] .",arxiv,bigscience bloomz,705.2283,0.2222222222222222,0.49579831932773116,0.38974358974358975,0.78786430960344,0,1,0,0,0,1,1,1,0,0,0.14042085583171138,0.12158381460941246,0.14396887159533073,0.17803030303030304,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Rotation and activity of pre-main-sequence stars,"  We present a study of rotation (vsini) and chromospheric activity (Halpha EW)
based on an extensive set of high-resolution optical spectra obtained with MIKE
on the 6.5m Magellan Clay telescope. Our targets are 74 F-M dwarfs in the young
stellar associations Eta Cha, TW Hydrae, Beta Pic, and Tuc-Hor, spanning ages
from 6 to 30 Myr. While the Halpha EW for most F and G stars are consistent
with pure photospheric absorption, most K and M stars show chromospheric
emission. By comparing Halpha EW in our sample to results in the literature, we
see a clear evolutionary sequence: Chromospheric activity declines steadily
from the T Tauri phase to the main sequence. Using activity as an age
indicator, we find a plausible age range for the Tuc-Hor association of 10-40
Myr. Between 5 and 30 Myr, we do not see evidence for rotational braking in the
total sample, thus angular momentum is conserved, in contrast to younger stars.
This difference indicates a change in the rotational regulation at 5-10 Myr,
possibly because disk braking cannot operate longer than typical disk
lifetimes, allowing the objects to spin up. The rotation-activity relation is
flat in our sample; in contrast to main-sequence stars, there is no linear
correlation for slow rotators. We argue that this is because young stars
generate their magnetic fields in a fundamentally different way from
main-sequence stars, and not just the result of a saturated solar-type dynamo.
By comparing our rotational velocities with published rotation periods for a
subset of stars, we determine ages of 13 (7-20) Myr and 9 (7-17} Myr for the
Eta Cha and TWA associations, respectively, consistent with previous estimates.
Thus we conclude that stellar radii from evolutionary models by Baraffe et al.
(1998) are in agreement with the observed radii within +-15%. (abridged)
","We present the results of an analysis of high-resolution optical spectra obtained with the Subaru Telescope for a sample of young, low-mass (0.5-2 Msun) PMS stars in Orion Nebula Cluster. We find that most of these objects show significant periodic variability on timescales ranging between 1 day to several months. The observed periods are consistent with those expected if the photometric variations result from rotational modulation due to starspots and/or plages. In addition we detect strong Hα emission lines which indicate chromospheric activity. Our observations suggest that many of our targets have relatively rapid rotation rates compared to older field dwarfs at similar masses. This is likely caused by tidal locking during their formation process. Finally, we also report the detection of two new spectroscopic binaries among our target list. These systems will be useful as benchmarks for testing theoretical models of binary evolution.",arxiv,bigscience bloomz,704.3266,0.6666666666666666,0.3445378151260504,0.8974358974358975,0.36645962732919257,1,1,1,0,0,1,1,0,0,0,0.10301982214234046,0.05472216561757235,0.12062256809338522,0.03409090909090909,1,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Light curves and colours of the faint Uranian irregular satellites Sycorax, Prospero, Stephano, Setebos and Trinculo","  After the work of Gladman et al. (1998), it is now assessed that many
irregular satellites are orbiting around Uranus. Despite many studies have been
performed in past years, very few is know for the light-curves of these objects
and inconsistencies are present between colours derived by different authors.
This situation motivated our effort to improve both the knowledge of colours
and light curves. We present and discuss time series observations of Sycorax,
Prospero, Stephano, Setebos and Trinculo, five faint irregular satellites of
Uranus, carried out at VLT, ESO Paranal (Chile) in the nights between 29 and 30
July, 2005 and 25 and 30 November, 2005. We derive light curves for Sycorax and
Prospero and colours for all of these these bodies. For Sycorax we obtain
colours B-V =0.839 +/- 0.014, V-R = 0.531 +/- 0.005 and a light curve which is
suggestive of a periodical variation with period about 3.6 hours and amplitude
about 0.067 +/- 0.004 mag. The periods and colours we derive for Sycorax are in
agreement with our previous determination in 1999 using NTT. We derive also a
light-curve for Prospero which suggests an amplitude of about 0.2 mag and a
periodicity of about 4 hours. However, the sparseness of our data, prevents a
more precise characterization of the light-curves, and we can not determine
wether they are one-peaked or two-peaked. Hence, these periods and amplitudes
have to be considered preliminary estimates. As for Setebos, Stephano and
Trinculo the present data do not allow to derive any unambiguous periodicity,
despite Setebos displays a significant variability with amplitude about as
large as that of Prospero. Colours for Prospero, Setebos, Stephano and Trinculo
are in marginal agreement with the literature.
","We present new photometric observations in the visible range for five faint irregular satellites of Uranus (Sycorax, Prospero,  Stephano, Setebos; Trinculo) obtained with the 1-m telescope at the South African Astronomical Observatory during two observing runs on September 24-25th 2010 and March 28-29th 2011. The data were reduced using standard procedures within IRAF. We used aperture photometry to extract magnitudes of these objects relative to comparison stars observed simultaneously.  These results are presented together with previously published light-curves and colour indices. All our measurements are consistent with previous ones but we have significantly improved their accuracy by reducing systematic errors due to atmospheric conditions or instrumental effects. Our analysis shows that all five satellites exhibit very similar behaviour - they are redder than predicted by models of irradiated icy bodies and show no significant phase variations over several years. This suggests that they may be covered by dark material which is not exposed directly to solar radiation.",arxiv,bigscience bloomz,704.2187,0.6666666666666666,0.29411764705882354,0.8153846153846154,0.4037267080745342,1,1,0,0,0,1,1,1,0,0,0.11539304793180043,0.11312168481737252,0.14396887159533073,0.14015151515151514,1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Self assembly of a model multicellular organism resembling the Dictyostelium slime molds,"  The evolution of multicellular organisms from monocellular ancestors
represents one of the greatest advances of the history of life. The assembly of
such multicellular organisms requires signalling and response between cells:
over millions of years these signalling processes have become extremely
sophisticated and refined by evolution, such that study of modern organisms may
not be able to shed much light on the original ancient processes . Here we are
interested in determining how simple a signalling method can be, while still
achieving self-assembly. In 2D a coupled cellular automaton/differential
equation approach models organisms and chemotaxic chemicals, producing
spiralling aggregation. In 3D Lennard-Jones-like particles are used to
represent single cells, and their evolution in response to signalling is
followed by molecular dynamics. It is found that if a single cell is able to
emit a signal which induces others to move towards it, then a colony of
single-cell organisms can assemble into shapes as complex as a tower, a ball
atop a stalk, or a fast-moving slug. The similarity with the behaviour of
modern Dictyostelium slime molds signalling with cyclic adenosine monophosphate
(cAMP) is striking.
","The authors describe how they have created an artificial life form that self-assembles into a structure similar to the fruiting body of the Dictyostelium discoideum, or ""dictyos"" for short.  The dictyos is made up of thousands of identical cells connected by elastic filaments and can be grown in Petri dishes with nutrients added.   It has been shown to grow and divide indefinitely without any external control signals (such as hormones).   This work was done at Harvard University's Wyss Institute for Biologically Inspired Engineering.   ... Self-assembly refers to the spontaneous organization of matter into ordered structures such as crystals, snowflakes, and living organisms like bacteria colonies and animal tissues. In this study we report on our efforts toward creating a synthetic multicellular system capable of autonomous growth and division through self-assembly. We designed a minimal cell based on a spherical water-in-oil emulsion droplet containing a single microtubule-based cytoskeleton surrounded by a lipid membrane. These cells are able to attach to each other via flexible polymeric tethers and assemble into three-dimensional aggregates called “dictyos” which resemble the fruiting bodies formed by the social amoeba Dictyostelium discoidium. Our results demonstrate that these simple cellular units can autonomously organize themselves into complex 3D shapes reminiscent of natural systems.",arxiv,bigscience bloomz,705.0227,0.3333333333333333,0.3949579831932773,0.3128205128205128,0.5384615384615385,1,1,1,0,0,1,1,0,0,1,0.12565804984385176,0.049024842717192076,0.11673151750972763,0.03787878787878788,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Spitzer-IRAC GLIMPSE of high mass protostellar objects. I Infrared point sources and nebulae,"  The GLIMPSE archive was used to obtain 3.6--8.0micron, point source
photometry and images for 381 massive protostellar candidates lying in the
Galactic mid-plane. The colours, magnitudes and spectral indicies of sources in
each of the 381 target fields were analysed and compared with the predictions
of 2D radiative transfer model simulations. Although no discernable embedded
clusters were found in any targets, multiple sources or associations of
redenned young stellar objects were found in many sources indicating
multiplicity at birth. The spectral index ($\alpha$) of these point sources in
3.6--8.0mum bands display large values of $\alpha$=2--5. A color-magnitude
analog plot was used to identify 79 infrared counterparts to the HMPOs. Compact
nebulae are found in 75% of the detected sources with morphologies that can be
well described by core-halo, cometary, shell-like and bipolar geometries
similar to those observed in ultra-compact HII regions. The IRAC band SEDs of
the IR counterparts of HMPOs are best described to represent YSOs with a mass
range of 8--20\msun in their Class I stages when compared with 2D radiative
transfer models. They also suggest that the high $\alpha$ values represent
reprocessed star/star+disk emission that is arising in the dense envelopes.
Thus we are witnessing the luminous envelopes around the protostars rather than
their photospheres or disks. We argue that the compact infrared nebulae likely
reflect the underlying physical structure of the dense cores and are found to
imitate the morphologies of known UCHII regions. Our results favour models of
continuuing accretion involving both molecular and ionised accretion components
to build the most massive stars rather than purely molecular rapid accretion
flows.
","We present the results of an infrared survey of the Galactic plane using Spitzer/InfraRed Array Camera (IRAC) data in four mid-infrared bands centered at 3.6, 4.5, 5.8, and 8 microns. The IRAC observations cover about one third of the entire sky with |b| < 1 degree. We have identified more than 100 thousand candidate young stellar objects (YSOs), including both Class 0/I YSOs and Classical T Tauri stars (CTTSs). About half of these are associated with previously known star-forming regions or open clusters. Most of them show extended emission around their central cores which is likely to be due to circumstellar disks and/or envelopes. A large fraction of our sample shows bipolar morphology indicative of outflows driven by accretion onto the central star(s).
The spatial distribution of the newly discovered YSO candidates suggests that most of the recent massive star formation has occurred within the last few million years along the spiral arms of the Galaxy.",arxiv,bigscience bloomz,705.4399,0.5555555555555556,0.29411764705882354,0.7282051282051282,0.40086000955566176,1,1,0,0,0,1,1,0,0,0,0.06324761795009501,0.06273670999149629,0.08171206225680934,0.056818181818181816,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The anticenter old open cluster NGC 1883: radial velocity and metallicity,"  Having already reported on the first photometric study of the
intermediate-age open cluster NGC 1883 (Carraro et al. 2003), we present in
this paper the first spectroscopic multi-epoch investigation of a sample of
evolved stars in the same cluster. The aim is to derive the cluster membership,
velocity and metallicity, and discuss recent claims in the literature (Tadross
2005) that NGC 1883 is as metal poor as globular clusters in the Halo. Besides,
being one of the few outer Galactic disk intermediate-age open clusters known
so far, it is an ideal target to improve our knowledge of the Galactic disk
radial abundance gradient, that is a basic ingredient for any chemical
evolution model of the Milky Way. The new data we obtained allow us to put NGC
1883's basic parameters more reliable. We find that the cluster has a mean
metallicity of [Fe/H] = -0.20$\pm$0.22, from which we infer an age
(650$^{+70}_{-70}$ Myr) close to the Hyades one and a Galactocentric distance
of 12.3$^{+0.4}_{-0.2}$ kpc. The metal abundance, kinematics, and position make
NGC 1883 a genuine outer disk intermediate-age open cluster. We confirm that in
the outer Galactic disk the abundance gradient is shallower than in the solar
vicinity.
","We present new spectroscopic observations for the open cluster NGC 1883, which is located at a distance of about 1 kpc in the constellation Cassiopeia (α = 20 h 18 m , δ = +58°). The data were obtained with the 2-m telescope of the Observatorio Astronómico Nacional de San Pedro Mártir (OAN-SPM) on December 16-17, 2009 using the REOSC spectrograph equipped with grism #7 covering the wavelength range 3700-7000 Å. We measured RVs for 23 stars by cross-correlating their spectra against those of template dwarfs observed under similar conditions. Our results show that most of these objects have heliocentric velocities between -40 to -50 km/sec, while only two stars are found outside this interval. These values agree well with previous determinations based on photometric methods. 
 
 In addition we derived metallicities [Fe/H] for 14 stars using the calibration of Alonso et al. (1999) . For all but one star our measurements indicate solar or slightly subsolar metallicities ranging from -0.10 dex up to +0.20 dex. Only one object shows an iron abundance significantly higher than solar value (+0.30 dex). 
 
 Finally, we compared our results with previously published studies.",arxiv,bigscience bloomz,705.23,0.3888888888888889,0.4453781512605043,0.38974358974358975,0.4925943621595796,1,1,0,0,1,1,1,0,0,0,0.15432724351640986,0.09562054401082512,0.17898832684824903,0.06439393939393939,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Thermal noise informatics: Totally secure communication via a wire; Zero-power communication; and Thermal noise driven computing,"  Very recently, it has been shown that thermal noise and its artificial
versions (Johnson-like noises) can be utilized as an information carrier with
peculiar properties therefore it may be proper to call this topic Thermal Noise
Informatics. Zero Power (Stealth) Communication, Thermal Noise Driven
Computing, and Totally Secure Classical Communication are relevant examples. In
this paper, while we will briefly describe the first and the second subjects,
we shall focus on the third subject, the secure classical communication via
wire. This way of secure telecommunication utilizes the properties of
Johnson(-like) noise and those of a simple Kirchhoff's loop. The communicator
is unconditionally secure at the conceptual (circuit theoretical) level and
this property is (so far) unique in communication systems based on classical
physics. The communicator is superior to quantum alternatives in all known
aspects, except the need of using a wire. In the idealized system, the
eavesdropper can extract zero bit of information without getting uncovered. The
scheme is naturally protected against the man-in-the-middle attack. The
communication can take place also via currently used power lines or phone
(wire) lines and it is not only a point-to-point communication like quantum
channels but network-ready. Tests have been carried out on a model-line with
ranges beyond the ranges of any known direct quantum communication channel and
they indicate unrivalled signal fidelity and security performance. This simple
device has single-wire secure key generation/sharing rates of 0.1, 1, 10, and
100 bit/second for copper wires with diameters/ranges of 21 mm / 2000 km, 7 mm
/ 200 km, 2.3 mm / 20 km, and 0.7 mm / 2 km, respectively and it performs with
0.02% raw-bit error rate (99.98 % fidelity).
","We propose to use thermal noise as the information carrier for totally secure communications, zero power consumption devices, and computing systems. We show that by using an appropriate detection scheme, we can extract digital bits from the thermal noise with high fidelity at room temperature. The proposed system is based on a single-electron transistor (SET) which has been demonstrated in experiments recently. In addition, we demonstrate how this SET-based device can be used to perform logic operations such as AND gate and NOT gate. Finally, we discuss possible applications of our proposal including quantum key distribution, ultra-low power sensor networks, and energy efficient data centers. This work was supported by NSF under Grant No. ECCS-0926491. A new paradigm called ""thermal noise informatics"" is introduced where thermal noise is utilized as the information carrier for various tasks ranging from totally secure communication over wires to zero-power communication and computation. By employing an appropriate detection scheme, it is shown that one can extract digital bits from thermal noise with high fidelities even at room temperatures. It is also shown that these extracted digital bits can be used to perform logical operations such as AND gates and NOT gates. Possible applications are discussed along with their advantages compared to existing technologies.",arxiv,bigscience bloomz,705.0158,0.5555555555555556,0.49579831932773116,0.7897435897435897,0.5499283325370282,1,1,0,0,1,1,1,0,0,0,0.13658738041320945,0.0753769167256412,0.14007782101167315,0.11363636363636363,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Theory of Macroscopic Quantum Tunneling in High-T_c c-Axis Josephson Junctions,"  We study macroscopic quantum tunneling (MQT) in c-axis twist Josephson
junctions made of high-T_c superconductors in order to clarify the influence of
the anisotropic order parameter symmetry (OPS) on MQT. The dependence of the
MQT rate on the twist angle $\gamma$ about the c-axis is calculated by using
the functional integral and the bounce method. Due to the d-wave OPS, the
$\gamma$ dependence of standard deviation of the switching current distribution
and the crossover temperature from thermal activation to MQT are found to be
given by $\cos2\gamma$ and $\sqrt{\cos2\gamma}$, respectively. We also show
that a dissipative effect resulting from the nodal quasiparticle excitation on
MQT is negligibly small, which is consistent with recent MQT experiments using
Bi${}_2$Sr${}_2$CaCu${}_2$O${}_{8 + \delta}$ intrinsic junctions. These results
indicate that MQT in c-axis twist junctions becomes a useful experimental tool
for testing the OPS of high-T_c materials at low temperature, and suggest high
potential of such junctions for qubit applications.
","We present the theory for macroscopic quantum tunneling (MQT) in high-temperature superconductors with an emphasis on its application to c-axis junctions. We show that MQT is suppressed by thermal fluctuations and magnetic field, but can be enhanced by applying a bias current or increasing the junction area. The results are compared with experiments performed at 4 K and 77 K. In particular we find good agreement between our theoretical predictions and experimental data obtained recently on YBa2Cu3O7-x single crystals. 
 
 Introduction 
 
 Superconductivity was discovered more than half a century ago [1] . Since then many new materials have been found which exhibit this fascinating phenomenon [2] , including some with very high transition temperatures T_c [3] . However, despite intensive research efforts there still remain several open questions about the nature of these novel compounds [4] . One such question concerns the mechanism responsible for their unusual properties [5] . 
 
 It has been suggested [6] that the pairing interaction may involve phonons [7 - 9] as well as spin excitations [10 - 12] . This leads to two possible scenarios for the formation of Cooper pairs [13] : either they form directly out of electrons via electron-phonon interactions [14] , or indirectly through spin-fluctuations [15] . These different mechanisms lead to distinct physical pictures [16] . For example, if one assumes that the pairing occurs only due to electron-phonon interactions [17] , it follows that the gap function should vanish along certain lines in momentum space [18] . On the other hand, if one considers the possibility of pair formation mediated by spin fluctuations [19] , the gap function vanishes over all momenta [20] . 
The most important feature of both types of models is that they predict the existence of nodes [21] in the energy spectrum [22] . Nodes occur when the order parameter changes sign across the Fermi surface [23] . They were first predicted theoretically [24 - 26] and later observed experimentally [27] .",arxiv,bigscience bloomz,705.1418,0.2222222222222222,0.6974789915966387,0.1641025641025641,0.8881987577639752,1,1,0,0,0,1,1,1,0,0,0.10470296994257408,0.06894392227835842,0.08949416342412451,0.08333333333333333,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Evidence Of Dark Matter Annihilations In The WMAP Haze,"  The WMAP experiment has revealed an excess of microwave emission from the
region around the center of our Galaxy. It has been suggested that this signal,
known as the ``WMAP Haze'', could be synchrotron emission from relativistic
electrons and positrons generated in dark matter annihilations. In this letter,
we revisit this possibility. We find that the angular distribution of the WMAP
Haze matches the prediction for dark matter annihilations with a cusped density
profile, $\rho(r) \propto r^{-1.2}$ in the inner kiloparsecs. Comparing the
intensity in different WMAP frequency bands, we find that a wide range of
possible WIMP annihilation modes are consistent with the spectrum of the haze
for a WIMP with a mass in the 100 GeV to multi-TeV range. Most interestingly,
we find that to generate the observed intensity of the haze, the dark matter
annihilation cross section is required to be approximately equal to the value
needed for a thermal relic, $\sigma v \sim 3 \times 10^{-26}$ cm$^3$/s. No
boost factors are required. If dark matter annihilations are in fact
responsible for the WMAP Haze, and the slope of the halo profile continues into
the inner Galaxy, GLAST is expected to detect gamma rays from the dark matter
annihilations in the Galactic Center if the WIMP mass is less than several
hundred GeV.
","We present evidence for dark matter annihilation in the cosmic microwave background (CMB) haze, which is an excess emission at large angles with respect to the Galactic center that was first detected by Wilkinson Microwave Anisotropy Probe (WMAP). We use data from Planck and Fermi Large Area Telescope (LAT), as well as new measurements of the CMB temperature anisotropies made using the Atacama Cosmology Telescope (ACT).
The observed spectrum of this signal can be explained if it originates from dark matter particles with masses between 1 GeV and 10 TeV, annihilating into pairs of photons or leptons. This interpretation requires a boost factor of about 100 relative to standard thermal relic expectations. 
 
 If confirmed, our results would provide strong support for models where dark matter self-annihilates into Standard Model particles. They also have important implications on the nature of dark matter itself, since they require either non-thermal production mechanisms or additional interactions beyond those predicted within the minimal supersymmetric extension of the Standard Model.",arxiv,bigscience bloomz,705.3655,0.3888888888888889,0.24369747899159663,0.47692307692307695,0.4237935977066412,1,1,0,0,1,1,1,0,0,0,0.16624556836907278,0.08130982438834215,0.1828793774319066,0.04924242424242424,2,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Effective anisotropies and energy barriers of magnetic nanoparticles with Neel surface anisotropy,"  Magnetic nanoparticles with Neel surface anisotropy, different internal
structures, surface arrangements and elongation are modelled as many-spin
systems. The results suggest that the energy of many-spin nanoparticles cut
from cubic lattices can be represented by an effective one-spin potential
containing uniaxial and cubic anisotropies. It is shown that the values and
signs of the corresponding constants depend strongly on the particle's surface
arrangement, internal structure and elongation. Particles cut from a simple
cubic lattice have the opposite sign of the effective cubic term, as compared
to particles cut from the face-centered cubic lattice. Furthermore, other
remarkable phenomena are observed in nanoparticles with relatively strong
surface effects: (i) In elongated particles surface effects can change the sign
of the uniaxial anisotropy. (ii) In symmetric particles (spherical and
truncated octahedral) with cubic core anisotropy surface effects can change its
sign. We also show that the competition between the core and surface
anisotropies leads to a new energy that contributes to both the 2nd- and
4th-order effective anisotropies.
","We study the effective anisotropy constants, Keff , of an assembly of identical spherical particles in which each particle has uniaxial anisotropy along its easy axis (EA) that is tilted by an angle θ relative to the applied field direction. We show that for small values of θ, Keff can be written as a sum of two terms: one term proportional to sin2θ arising due to dipolar interactions between the particles; another term independent of θ arising due to the shape anisotropy of individual particles. For large values of θ, we find that Keff decreases rapidly with increasing θ because of the reduction in the number density of particles having their EA parallel to H. The dependence of Keff on θ is found to agree well with experimental results obtained recently for FePt nanoparticles. 
 
 In this work, we also calculate the activation energies associated with reversal processes involving rotation about different axes of the nanoparticle. It turns out that these activation energies are strongly dependent upon the value of θ.",arxiv,bigscience bloomz,705.1689,0.3333333333333333,0.19327731092436976,0.2153846153846154,0.44099378881987583,1,1,1,0,1,1,0,1,0,0,0.03211584897503412,0.12362825315336062,0.03501945525291829,0.09090909090909091,0,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
A Note on the Inapproximability of Correlation Clustering,"  We consider inapproximability of the correlation clustering problem defined
as follows: Given a graph $G = (V,E)$ where each edge is labeled either ""+""
(similar) or ""-"" (dissimilar), correlation clustering seeks to partition the
vertices into clusters so that the number of pairs correctly (resp.
incorrectly) classified with respect to the labels is maximized (resp.
minimized). The two complementary problems are called MaxAgree and MinDisagree,
respectively, and have been studied on complete graphs, where every edge is
labeled, and general graphs, where some edge might not have been labeled.
Natural edge-weighted versions of both problems have been studied as well. Let
S-MaxAgree denote the weighted problem where all weights are taken from set S,
we show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\delta})$
essentially belongs to the same hardness class in the following sense: if there
is a polynomial time algorithm that approximates S-MaxAgree within a factor of
$\lambda = O(\log{|V|})$ with high probability, then for any choice of S',
S'-MaxAgree can be approximated in polynomial time within a factor of $(\lambda
+ \epsilon)$, where $\epsilon > 0$ can be arbitrarily small, with high
probability. A similar statement also holds for $S-MinDisagree. This result
implies it is hard (assuming $NP \neq RP$) to approximate unweighted MaxAgree
within a factor of $80/79-\epsilon$, improving upon a previous known factor of
$116/115-\epsilon$ by Charikar et. al. \cite{Chari05}.
","We show that correlation clustering is NP-hard to approximate within any constant factor, even for graphs with maximum degree three and clusters of size at most four.  We also present an algorithm which solves this problem exactly in time O(n3). Our results are based on reductions from the exact cover by 3-sets (X3C) problem. The X3C problem asks whether there exists a collection of subsets of a set S such that each element of S belongs to exactly 3 sets in the collection; it has been shown to be NP-complete. For more information about our work see http://arxiv.org/abs/1206.0571 . 
Correlation clustering is one of several problems studied under the umbrella of ""clustering""; these include k-means clustering, spectral clustering, and graph partitioning. It was introduced independently by Bansal et al., Blum et al., and Dasgupta et al. as follows.   Given a weighted undirected graph G = (V, E), where V denotes the vertices and E denotes the edges, we say that two vertices u, v ∈ V are adjacent if they share an edge e ∈ E. A cluster C ⊆ V is defined as a subset of nodes whose pairwise distances satisfy some threshold t > 0. More formally, given a distance function d : V × V → R+ , let dist(u,v) denote the shortest path between u and v; then, C is said to be a valid cluster if and only if for all pairs of nodes u, v ∈ C:  dist(u,v)  ≤ t",arxiv,bigscience bloomz,704.2092,0.5,0.4453781512605043,0.517948717948718,0.6588628762541807,1,1,1,0,1,1,1,1,0,0,0.3295092883094861,0.17632097853783427,0.41245136186770426,0.22348484848484848,4,1,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Hopf Algebra Structure of the Character Rings of Classical Groups,"  The character ring \CGL of covariant irreducible tensor representations of
the general linear group admits a Hopf algebra structure isomorphic to the Hopf
algebra \Sym$ of symmetric functions. Here we study the character rings \CO and
\CSp of the orthogonal and symplectic subgroups of the general linear group
within the same framework of symmetric functions. We show that \CO and \CSp
also admit natural Hopf algebra structures that are isomorphic to that of \CGL,
and hence to \Sym. The isomorphisms are determined explicitly, along with the
specification of standard bases for \CO and \CSp analogous to those used for
\Sym. A major structural change arising from the adoption of these bases is the
introduction of new orthogonal and symplectic Schur-Hall scalar products.
Significantly, the adjoint with respect to multiplication no longer coincides,
as it does in the \CGL case, with a Foulkes derivative or skew operation. The
adjoint and Foulkes derivative now require separate definitions, and their
properties are explored here in the orthogonal and symplectic cases. Moreover,
the Hopf algebras \CO and \CSp are not self-dual. The dual Hopf algebras \CO^*
and \CSp^* are identified. Finally, the Hopf algebra of the universal rational
character ring \CGLrat of mixed irreducible tensor representations of the
general linear group is introduced and its structure maps identified.
","The character rings of classical groups are studied in this article, and their Hopf algebra structures are determined by using the results on the representation theory of finite groups obtained recently. The main result is that if G is an abelian group with order n{\displaystyle n}, then the character ring K[G]K[G]$ has a Hopf algebra structure whose comultiplication map ΔΔ satisfies (1) Δ(g)(h)=Σi=1n[g−ih]/(n−1)! for all g∈G, h∈G, (2) Δ(gh)=gΔ(h)+hΔ(g), and (3) Δ(e)=e for e∈G. In particular, we have shown that the character ring of any cyclic group CcC_c$ has a Hopf algebra strucutre satisfying these conditions. We also give some examples to show how our method works.",arxiv,bigscience bloomz,704.2029,0.5,0.19327731092436976,0.4666666666666667,0.2603917821309126,0,1,0,0,0,1,0,0,0,0,0.06038621760586965,0.1392177241767295,0.07003891050583658,0.09090909090909091,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Sparticle Spectra and LHC Signatures for Large Volume String Compactifications,"  We study the supersymmetric particle spectra and LHC collider observables for
the large-volume string models with a fundamental scale of 10^{11} GeV that
arise in moduli-fixed string compactifications with branes and fluxes. The
presence of magnetic fluxes on the brane world volume, required for chirality,
perturb the soft terms away from those previously computed in the dilute-flux
limit. We use the difference in high-scale gauge couplings to estimate the
magnitude of this perturbation and study the potential effects of the magnetic
fluxes by generating many random spectra with the soft terms perturbed around
the dilute flux limit. Even with a 40% variation in the high-scale soft terms
the low-energy spectra take a clear and predictive form. The resulting spectra
are broadly similar to those arising on the SPS1a slope, but more degenerate.
In their minimal version the models predict the ratios of gaugino masses to be
M_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage
mediation. Among the scalars, the squarks tend to be lighter and the sleptons
heavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC
data for the random spectra in order to study the range of collider
phenomenology that can occur. We perform a detailed mass reconstruction on one
example large-volume string model spectrum. 100 fb^{-1} of integrated
luminosity is sufficient to discriminate the model from mSUGRA and aspects of
the sparticle spectrum can be accurately reconstructed.
","We study the phenomenology of string compactifications with large extra dimensions, focusing on supersymmetric particles in the mass range accessible to current experiments at the Large Hadron Collider (LHC). We consider two classes of models that are motivated by recent developments in string theory: weakly coupled heterotic orbifolds and strongly coupled Type IIB orientifold constructions. In both cases we find that there is an interesting interplay between the Kaluza-Klein excitations associated with the extra dimensions and the lightest Standard Model superpartners. For example, in some regions of parameter space it may be possible to produce gluinos or squarks directly via Drell-Yan processes; alternatively, these states can decay into lighter Standard Model superpartners which then cascade down to the LSP neutralino. The resulting collider signatures depend sensitively on the details of the underlying model parameters as well as the number of extra dimensions.",arxiv,bigscience bloomz,704.3403,0.5,0.19327731092436976,0.6102564102564103,0.3607262302914477,1,1,1,0,0,1,1,1,0,0,0.08006496949357803,0.057114315837912204,0.07392996108949416,0.06060606060606061,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Cosmological Constraints on f(R) Acceleration Models,"  Models which accelerate the expansion of the universe through the addition of
a function of the Ricci scalar f(R) leave a characteristic signature in the
large-scale structure of the universe at the Compton wavelength scale of the
extra scalar degree of freedom. We search for such a signature in current
cosmological data sets: the WMAP cosmic microwave background (CMB) power
spectrum, SNLS supernovae distance measures, the SDSS luminous red galaxy power
spectrum, and galaxy-CMB angular correlations. Due to theoretical uncertainties
in the nonlinear evolution of f(R) models, the galaxy power spectrum
conservatively yields only weak constraints on the models despite the strong
predicted signature in the linear matter power spectrum. Currently the tightest
constraints involve the modification to the integrated Sachs-Wolfe effect from
growth of gravitational potentials during the acceleration epoch. This effect
is manifest for large Compton wavelengths in enhanced low multipole power in
the CMB and anti-correlation between the CMB and tracers of the potential. They
place a bound on the Compton wavelength of the field be less than of order the
Hubble scale.
","We study the cosmology of modified gravity models with an action that contains higher-order curvature terms, such as $R^2$ and $R_{\mu \nu \rho \sigma}$. We show how to derive constraints on these theories using observations of large-scale structure (LSS), cosmic microwave background radiation (CMB), supernovae Ia (SNeIa), baryon acoustic oscillations (BAO), Hubble constant measurements (HST), and gamma-ray bursts (GRBs). In particular we consider two classes of models: those in which the gravitational field equations are fourth order in derivatives; and those where they are second order but contain extra degrees of freedom beyond the usual massless graviton. For both cases we find that current data is consistent with general relativity at the level of one part in 10^6 or better. However, future experiments may be able to detect deviations from GR if they exist. 
 
 Keywords: Modified Gravity",arxiv,bigscience bloomz,706.2399,0.2777777777777778,0.24369747899159663,0.2717948717948718,0.3463927376970855,1,1,1,0,0,1,1,1,0,0,0.0958633791374399,0.13947268904048557,0.06614785992217899,0.06060606060606061,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
How to clean a dirty floor: Probabilistic potential theory and the Dobrushin uniqueness theorem,"  Motivated by the Dobrushin uniqueness theorem in statistical mechanics, we
consider the following situation: Let \alpha be a nonnegative matrix over a
finite or countably infinite index set X, and define the ""cleaning operators""
\beta_h = I_{1-h} + I_h \alpha for h: X \to [0,1] (here I_f denotes the
diagonal matrix with entries f). We ask: For which ""cleaning sequences"" h_1,
h_2, ... do we have c \beta_{h_1} ... \beta_{h_n} \to 0 for a suitable class of
""dirt vectors"" c? We show, under a modest condition on \alpha, that this occurs
whenever \sum_i h_i = \infty everywhere on X. More generally, we analyze the
cleaning of subsets \Lambda \subseteq X and the final distribution of dirt on
the complement of \Lambda. We show that when supp(h_i) \subseteq \Lambda with
\sum_i h_i = \infty everywhere on \Lambda, the operators \beta_{h_1} ...
\beta_{h_n} converge as n \to \infty to the ""balayage operator"" \Pi_\Lambda =
\sum_{k=0}^\infty (I_\Lambda \alpha)^k I_{\Lambda^c). These results are
obtained in two ways: by a fairly simple matrix formalism, and by a more
powerful tree formalism that corresponds to working with formal power series in
which the matrix elements of \alpha are treated as noncommuting indeterminates.
","We consider the problem of recovering an unknown signal on a domain $\Omega$ by observing noisy measurements at some locations in $\Omega$, where the noise is assumed to be additive white Gaussian with variance $\sigma^2$.  We show that if the number of observations scales as $O(n^{1/3})$ then it is possible to recover the signal exactly using convex optimization techniques (where $n$ denotes the total number of pixels). This result improves upon previous results which required $O(n^{2/3})$ samples for exact recovery. The proof relies on recent developments in probabilistic potential theory and the so-called ""Dobrushin uniqueness theorems"". Our analysis also shows how one can use this framework to obtain guarantees under more general conditions than those considered previously. 
The main idea behind our approach is to view the reconstruction process as a statistical estimation problem over a probability space equipped with a Gibbs measure. In particular, we introduce a new notion called ""local observability"" which quantifies the amount of information contained within each observation about the underlying signal.",arxiv,bigscience bloomz,704.3156,0.2777777777777778,0.29411764705882354,0.37435897435897436,0.43239369326325855,1,1,1,1,0,1,1,0,0,0,0.16029906910942818,0.0819932296284152,0.13229571984435798,0.07196969696969698,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0
Theory for superconductivity in a magnetic field: A local approximation approach,"  We present a microscopic theory for superconductivity in a magnetic field
based on a local approximation approach. We derive an expression for free
energy density $F$ as a function of temperature $T$ and vector potential {\bf
a}, and two basic equations of the theory: the first is an implicit solution
for energy gap parameter amplitude $|\Delta_{\bf k}|$ as a function of wave
vector {\bf k}, temperature $T$ and vector potential {\bf a}; and the second is
a London-like relation between electrical current density {\bf j} and vector
potential {\bf a}, with an ``effective superconducting electron density'' $n_s$
that is both $T$- and {\bf a}-dependent. The two equations allow determination
of spatial variations of {\bf a} and $|\Delta_{\bf k}|$ in a superconductor for
given temperature $T$, applied magnetic field ${\bf H}_a$ and sample geometry.
The theory shows the existence of a ``partly-paired state,'' in which paired
electrons (having $|\Delta_{\bf k}|>0$) and de-paired electrons (having
$|\Delta_{\bf k}|=0$) co-exist. Such a ``partly-paired state'' exists even at
T=0 when $H_a$ is above a threshold for a given sample, giving rise to a
non-vanishing Knight shift at T=0 for $H_a$ above the threshold. We expect the
theory to be valid for highly-local superconductors for all temperatures and
magnetic fields below the superconducting transition. In the low-field limit,
the theory reduces to the local-limit result of BCS. As examples, we apply the
theory to the case of a semi-infinite superconductor in an applied magnetic
field ${\bf H}_a$ parallel to the surface of the superconductor and the case of
an isolated vortex in an infinite superconductor, and determine, in each case,
spatial variations of quantities such as {\bf a} and $|\Delta_{\bf k}|$. We
also calculate...
","We present an approximate theory to study the effect of a magnetic field on the ground state properties and phase diagram of strongly correlated systems, such as high-Tc cuprates or heavy fermion compounds. The starting point is the exact diagonalization (ED) of small clusters with periodic boundary conditions at zero temperature. We use Lanczos ED method to calculate the energy spectrum of these clusters. Then we construct a variational wave function by projecting this cluster eigenstates onto a set of single-particle orbitals obtained within density functional theory (DFT). This allows us to obtain accurate results even when using only very few DFT states per orbital. Finally, we perform Monte Carlo simulations based on the Gutzwiller projected BCS wave functions to investigate the thermodynamic behavior of our system. Our main result shows that the application of a magnetic field leads to a suppression of the superfluid order parameter $\psi$ which can be understood as a consequence of the Zeeman splitting between spin-up and -down electrons.",arxiv,bigscience bloomz,706.2394,0.4444444444444444,0.29411764705882354,0.7948717948717948,0.4237935977066412,1,1,1,0,1,1,1,0,0,0,0.3369850478886734,0.07218190141978623,0.4163424124513619,0.045454545454545456,1,0,5,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
A new comprehensive set of elemental abundances in DLAs III. Star formation histories,"  We obtained comprehensive sets of elemental abundances for eleven damped
Ly-alpha systems (DLAs) at z_DLA=1.7-2.5. In Paper I of this series, we showed
for three DLA galaxies that we can derive their star formation histories and
ages from a detailed comparison of their intrinsic abundance patterns with
chemical evolution models. We determine in this paper the star formation
properties of six additional DLA galaxies. The derived results confirm that no
single star formation history explains the diverse sets of abundance patterns
in DLAs. We demonstrate that the various star formation histories reproducing
the DLA abundance patterns are typical of local irregular, dwarf starburst and
quiescent spiral galaxies. Independent of the star formation history, the DLAs
have a common characteristic of being weak star forming galaxies; models with
high star formation efficiencies are ruled out. All the derived DLA star
formation rates per unit area are moderate or low, with values between -3.2 <
log SFR < -1.1 M_sol yr^{-1} kpc^{-2}. The DLA abundance patterns require a
large spread in ages ranging from 20 Myr up to 3 Gyr. The oldest DLA in our
sample is observed at z_DLA=1.864 with an age estimated to more than 3 Gyr; it
nicely indicates that galaxies were already forming at z_f>10. But, most of the
DLAs show ages much younger than that of the Universe at the epoch of
observation. Young galaxies thus seem to populate the high redshift Universe at
z>2, suggesting relatively low redshifts of formation (z~3) for most
high-redshift galaxies. The DLA star formation properties are compared with
those of other high-redshift galaxies identified in deep imaging surveys with
the aim of obtaining a global picture of high-redshift objects.
","We present the results of our analysis of a sample of 25 high-resolution quasar absorption line systems with metallicities ranging between 1/100 and 1/10 solar, selected to have low dust content (i.e., < 0.1 mag extinction at 2200 A). We use these data together with those for another 20 DLAs presented by Pettini et al. (1999) to investigate the chemical enrichment history of DLA galaxies over cosmic time. The main conclusions are as follows: 
The abundance patterns observed in this sample can be explained if we assume that most of the metals were produced during an early burst of star formation which occurred less than 10 Gyr ago. 


This is consistent with previous studies based on smaller samples but it also shows that there may not always be evidence for recent star formation activity even when such activity has been inferred from other indicators. 

In addition, we find no correlation between metallicity and dust content or neutral hydrogen column density.

Finally, we show that the mean value of [Fe/H] measured in DLAs agrees well with the predictions made using simple models of galactic chemical evolution.",arxiv,bigscience bloomz,705.165,0.6111111111111112,0.029411764705882353,0.7948717948717948,0.08623984710941233,1,1,1,0,0,1,1,1,0,0,0.06643008405381197,0.02524542098337053,0.08560311284046693,0.08712121212121213,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A Communication Model for Adaptive Service Provisioning in Hybrid Wireless Networks,"  Mobile entities with wireless links are able to form a mobile ad-hoc network.
Such an infrastructureless network does not have to be administrated. However,
self-organizing principles have to be applied to deal with upcoming problems,
e.g. information dissemination. These kinds of problems are not easy to tackle,
requiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks
is arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could
eliminate the need for any fixed infrastructure, has been damped. The goal is
to overcome the limitations of pure ad-hoc networks by augmenting them with
instant Internet access, e.g. via integration of UMTS respectively GSM links.
However, this raises multiple questions at the technical as well as the
organizational level. Motivated by characteristics of small-world networks that
describe an efficient network even without central or organized design, this
paper proposes to combine mobile ad-hoc networks and infrastructured networks
to form hybrid wireless networks. One main objective is to investigate how this
approach can reduce the costs of a permanent backbone link and providing in the
same way the benefits of useful information from Internet connectivity or
service providers. For the purpose of bridging between the different types of
networks, an adequate middleware service is the focus of our investigation.
This paper shows our first steps forward to this middleware by introducing the
Injection Communication paradigm as principal concept.
","In this work, we propose an adaptive service provisioning scheme to provide quality-of-service (QoS) guarantees and maximize the network utility by jointly optimizing resource allocation at both base stations (BSs) and mobile users (MUs). The proposed scheme is based on a communication model that incorporates user mobility into the QoS requirements. We formulate the problem as a joint optimization over BSs' power control variables, MUs' transmission rates, and their association with BSs. To solve it efficiently, we first decompose the original problem into two subproblems: one for each BS and another for all MUs. Then, we develop distributed algorithms to obtain solutions to these problems iteratively using dual decomposition techniques. Finally, simulation results show that our proposed algorithm can achieve better performance than existing schemes under various system settings. In recent years, wireless networks have been widely deployed around the world due to their low cost and easy deployment [1] . However, they are vulnerable to security attacks such as eavesdropping [2] , jamming [3] , and data tampering [4] .
To enhance the security level of wireless communications, physical layer security has attracted much attention recently [5] - [8] . Physical layer security exploits the characteristics of the wireless channel to ensure secure transmissions without relying on any additional cryptographic keys or protocols [9] . It was shown in [10] that if the legitimate transmitter-receiver pair shares no common information about the statistical properties of the channels between them and other potential eavesdroppers, then perfect secrecy cannot be achieved even when there exists infinite number of antennas at the transmitter side. Therefore, practical approaches should consider imperfections in the estimation process [11] , limited transmit power [12] , and finite antenna numbers [13] .",arxiv,bigscience bloomz,706.113,0.7222222222222222,0.546218487394958,0.5282051282051282,0.7706641184902054,0,1,0,0,0,1,1,1,0,1,0.08609276965383351,0.07765279412628015,0.07392996108949416,0.07575757575757576,2,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Non-Markovian entanglement dynamics of quantum continuous variable systems in thermal environments,"  We study two continuous variable systems (or two harmonic oscillators) and
investigate their entanglement evolution under the influence of non-Markovian
thermal environments. The continuous variable systems could be two modes of
electromagnetic fields or two nanomechanical oscillators in the quantum domain.
We use quantum open system method to derive the non-Markovian master equations
of the reduced density matrix for two different but related models of the
continuous variable systems. The two models both consist of two interacting
harmonic oscillators. In model A, each of the two oscillators is coupled to its
own independent thermal reservoir, while in model B the two oscillators are
coupled to a common reservoir. To quantify the degrees of entanglement for the
bipartite continuous variable systems in Gaussian states, logarithmic
negativity is used. We find that the dynamics of the quantum entanglement is
sensitive to the initial states, the oscillator-oscillator interaction, the
oscillator-environment interaction and the coupling to a common bath or to
different, independent baths.
","We study the non-Markovian evolution of bipartite Gaussian states under local dephasing noise and global squeezing interaction with an environment at finite temperature. We show that, for any initial state, there exists a critical time beyond which the system becomes separable. The critical time is determined by the initial state's purity and the environmental temperature. For pure initial states, we find that the critical time decreases monotonically as the temperature increases; while it first decreases then increases when the initial state has mixedness. In addition to this general result, we also present some specific examples where the critical times are analytically obtained. Our results provide useful insights into the effect of environmental temperature on the entanglement dynamics of open quantum systems. Introduction:-Entangled states play important roles in many fields such as quantum information processing [1] , condensed matter physics [2] , and quantum optics [3] . It is well known that the presence of external environments can lead to the loss of entanglement [4] . Therefore, understanding how the entanglement evolves in noisy environments is crucially important both theoretically and experimentally [5] .
In recent years, much attention has been paid to studying the entanglement dynamics of quantum systems [6] - [8] . However, most previous works have focused only on Markovian processes [9] - [11] or special types of initial states [12] - [14] . Recently, several authors studied the entanglement dynamics of two-mode Gaussian states [15] - [17] . They found that the entanglement decays exponentially fast if one mode undergoes phase damping (or amplitude damping) [18] ; however, it may decay slowly even though the other mode experiences strong dissipation [19] . Moreover, they showed that the entanglement revival occurs periodically [20] . These studies were mainly based on numerical simulations [21] . Very recently, analytical solutions were presented [22] - [24] . Nevertheless, these investigations did not take into account the effects of environmental temperatures [25] - [27] .",arxiv,bigscience bloomz,706.0996,0.3333333333333333,0.7983193277310925,0.18974358974358974,0.8795986622073578,1,1,0,0,0,1,1,1,0,1,0.07693720525244395,0.06149332637836305,0.08171206225680934,0.08712121212121213,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Measurement of the spin polarization of the magnetic semiconductor EuS with zero-field and Zeeman-split Andreev reflection spectroscopy,"  We report measurements of the spin polarization (\textbf{\textit{P}}) of the
concentrated magnetic semiconductor EuS using both zero-field and Zeeman-split
Andreev reflection spectroscopy (ARS) with EuS/Al planar junctions. The
zero-field ARS spectra are well described by the modified (spin-polarized) BTK
model with expected superconducting energy gap and actual measurement
temperature (no additional spectral broadening). The fittings consistently
yield \textbf{\textit{P}} close to 80% regardless of the barrier strength.
Moreover, we performed ARS in the presence of a Zeeman-splitting of the
quasiparticle density of states in Al. To describe the Zeeman-split ARS
spectra, we develop a theoretical model which incorporates the solution to the
Maki-Fulde equations into the modified BTK analysis. The method enables the
determination of the magnitude as well as the sign of \textbf{\textit{P}} with
ARS, and the results are consistent with those from the zero-field ARS. The
experiments extend the utility of field-split superconducting spectroscopy from
tunnel junctions to Andreev junctions of arbitrary barrier strengths.
","We report on measurements of the spin polarization in the ferromagnetic semiconductor EuS using two different spectroscopies, namely zero-field (ZF) and Zeeman split Andreev reflection (ZSAR). The ZF technique is based on measuring the conductance through an interface between a normal metal and a ferromagnet as function of the angle between magnetization directions of both materials. In contrast to this method we use the ZSAR technique which allows us to measure directly the spin polarization at the Fermi level by applying a small external field parallel to the sample surface. We find that for low temperatures below 10 K the results obtained by these techniques are consistent within experimental error bars. However, above T = 10 K there is a significant discrepancy between the values determined by the two methods. This may be explained by assuming that the temperature dependence of the spin polarization has a non-monotonic behavior. Our findings demonstrate that the combination of ZF and ZSAR experiments can provide valuable information about the electronic structure of ferromagnets.",arxiv,bigscience bloomz,705.1582,0.3333333333333333,0.29411764705882354,0.1641025641025641,0.4381270903010034,1,1,0,0,0,1,1,0,0,0,0.06832253651532849,0.048800073358422826,0.0622568093385214,0.03409090909090909,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Type D Einstein spacetimes in higher dimensions,"  We show that all static spacetimes in higher dimensions are of Weyl types G,
I_i, D or O. This applies also to stationary spacetimes if additional
conditions are fulfilled, as for most known black hole/ring solutions. (The
conclusions change when the Killing generator becomes null, such as at Killing
horizons.) Next we demonstrate that the same Weyl types characterize warped
product spacetimes with a one-dimensional Lorentzian (timelike) factor, whereas
warped spacetimes with a two-dimensional Lorentzian factor are restricted to
the types D or O. By exploring the Bianchi identities, we then analyze the
simplest non-trivial case from the above classes - type D vacuum spacetimes,
possibly with a cosmological constant, dropping, however, the assumptions that
the spacetime is static, stationary or warped. It is shown that for ``generic''
type D vacuum spacetimes the corresponding principal null directions are
geodetic in any dimension (this applies also to type II spacetimes). For n>=5,
however, there may exist particular cases of type D spacetimes which admit
non-geodetic multiple principal null directions and we present such examples in
any n>=7. Further studies are restricted to five dimensions, where the type D
Weyl tensor is described by a 3x3 matrix \Phi_{ij}. In the case with
``twistfree'' (A_{ij}=0) principal null geodesics we show that in a ``generic''
case \Phi_{ij} is symmetric and eigenvectors of \Phi_{ij} coincide with those
of the expansion matrix S_{ij}, providing us with three preferred spacelike
directions of the spacetime. Similar results are also obtained when relaxing
the twistfree condition and assuming instead that \Phi_{ij} is symmetric. The
n=5 Myers-Perry black hole and Kerr-NUT-AdS metrics in arbitrary dimension are
briefly studied as specific examples of type D vacuum spacetime.
","We study the properties of type-D Einstein metrics on compact manifolds with boundary, and their relation to supersymmetric solutions of supergravity theories. We show that these spaces are characterized by an integrable complex structure J which is compatible with the metric g and satisfies certain additional conditions at the boundary. In particular we prove that if (M n ,g) is such a space then there exists a unique spinor field $\psi$ satisfying $(D_\mu\psi)^\alpha = 0$ for all $\alpha\in \Gamma_n$ where $D_\mu = \partial_\mu + iA^\mu$ is the Dirac operator associated to the connection $A = \mathrm{d}g - J\wedge\mathrm{d}$. Moreover this spinor field has constant norm and defines a Killing vector field $X = \psi^{*}\psi$ whose flow preserves both $g$ and $J$. 
 
 The existence of such a spinor field implies that the scalar curvature $R_g$ of the metric vanishes identically. Conversely, any solution of the vacuum Einstein equations with vanishing scalar curvature can be written as a warped product over a flat base manifold times a Riemannian Einstein solvmanifold. This result generalizes previous results obtained in dimension four by Bryant and Salamon [BS] .",arxiv,bigscience bloomz,704.0435,0.5555555555555556,0.29411764705882354,0.7846153846153846,0.47826086956521746,1,1,0,0,1,1,1,0,0,0,0.123491424620791,0.14755476145979105,0.15953307392996108,0.14772727272727273,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
G-convergence and homogenization of viscoelastic flows,"  The paper is devoted to homogenization of two-phase incompressible
viscoelastic flows with disordered microstructure. We study two cases. In the
first case, both phases are modeled as Kelvin-Voight viscoelastic materials. In
the second case, one phase is a Kelvin-Voight material, and the other is a
viscous Newtonian fluid. The microscale system contains the conservation of
mass and balance of momentum equations. The inertial terms in the momentum
equation incorporate the actual interface advected by the flow. In the
constitutive equations, a frozen interface is employed. The interface geometry
is arbitrary: we do not assume periodicity, statistical homogeneity or scale
separation. The problem is homogenized using G-convergence and oscillating test
functions. Since the microscale system is not parabolic, previously known
constructions of the test functions do not work here. The test functions
developed in the paper are non-local in time and satisfy divergence-free
constraint exactly. The latter feature enables us to avoid working with
pressure directly. We show that the effective medium is a single phase
viscoelastic material that is not necessarily of Kelvin-Voight type. The
effective constitutive equation contains a long memory viscoelastic term, as
well as instantaneous elastic and viscous terms.
","We study the G-convergence for nonlinear viscoelastic flows in bounded domains with smooth boundaries, where the constitutive relation is given by an integral-type equation. We prove that if the sequence of solutions to the corresponding problems converges weakly* in $L^\infty(0,T;L^2)$ then it also converges strongly in $L^1(0,T;H^{-1})$. As applications we consider two examples of such equations. The first one is the Oldroyd-B model which describes the flow behavior of polymeric fluids. In this case our results show that the limit problem can be formulated as a system of partial differential equations coupled through the stress tensor. The second example deals with the so-called Maxwell fluid whose relaxation time depends on the shear rate. Here we obtain a new formulation of the limit problem involving only ordinary differential equations. Finally, we present some numerical experiments illustrating these theoretical results. Keywords: Viscoelasticity, Homogenization, Limiting process",arxiv,bigscience bloomz,706.1088,0.7222222222222222,0.3949579831932773,0.35384615384615387,0.3635929288103201,0,1,1,0,0,1,1,1,0,0,0.04208171155821096,0.09405911356437952,0.038910505836575876,0.12121212121212122,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
La controverse de 1874 entre Camille Jordan et Leopold Kronecker,"  During the whole of 1874, Camille Jordan and Leopold Kronecker quar- relled
vigorously over the organisation of the theory of bilinear forms. That theory
promised a ""general"" and ""homogeneous"" treatment of numerous questions arising
in various 19th-century theoretical contexts, and it hinged on two theorems,
stated independently by Jordan and Weierstrass, that would today be considered
equivalent. It was, however, the perceived difference between those two
theorems that sparked the 1874 controversy. Focusing on this quarrel allows us
to explore the algebraic identity of the polynomial practices of the
manipulations of forms in use before the advent of structural approaches to
linear algebra. The latter approaches identified these practices with methods
for the classification of similar matrices. We show that the prac- tices --
Jordan's canonical reduction and Kronecker's invariant computation -- reflect
identities inseparable from the social context of the time. Moreover, these
practices reveal not only tacit knowledge, local ways of thinking, but also --
in light of a long history tracing back to the work of Lagrange, Laplace, Cau-
chy, and Hermite -- two internal philosophies regarding the significance of
generality which are inseparable from two disciplinary ideals opposing algebra
and arithmetic. By interrogating the cultural identities of such practices,
this study aims at a deeper understanding of the history of linear algebra
without focusing on issues related to the origins of theories or structures.
","Leopold Kronecker (1823-1901) est un mathématicien allemand qui s'est intéressé à la théorie des nombres, aux fonctions elliptiques ainsi qu'à l'algèbre linéaire. Il fut l'un des principaux fondateurs du groupe Bourbaki en 1934 avec André Weil, Jean Delsarte, René Decartes, Nicolas Bourbaki, Jean Dieudonné, Claude Chevalley, Élie Cartan, Jean-Louis Koszul, Samuel Eilenberg et Jacques-Louis Lions. En 1873, il publie dans le Journal für die reine und angewandte Mathematik une série d'articles sur les algèbres associatives et non associatives. Dans son article intitulé « Ueber die Theorie der endlichen Gruppen von Variabeln » [Kronecker, L., Ueber die Theorie der Endlichen Gruppen von Varien, JFM 5.2 (1875), p. 1–42], il introduit pour la première fois la notion d'algèbre associative finie.",arxiv,bigscience bloomz,704.2929,0.3888888888888889,0.14285714285714285,0.5384615384615384,0.2919254658385093,0,1,0,0,1,1,1,0,0,1,0.13105051661749847,0.0868538152563588,0.1245136186770428,0.07954545454545454,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Determination of the Far-Infrared Cosmic Background Using COBE/DIRBE and WHAM Data,"  Determination of the cosmic infrared background (CIB) at far infrared
wavelengths using COBE/DIRBE data is limited by the accuracy to which
foreground interplanetary and Galactic dust emission can be modeled and
subtracted. Previous determinations of the far infrared CIB (e.g., Hauser et
al. 1998) were based on the detection of residual isotropic emission in skymaps
from which the emission from interplanetary dust and the neutral interstellar
medium were removed. In this paper we use the Wisconsin H-alpha Mapper (WHAM)
Northern Sky Survey as a tracer of the ionized medium to examine the effect of
this foreground component on determination of the CIB. We decompose the DIRBE
far infrared data for five high Galactic latitude regions into H I and H-alpha
correlated components and a residual component. We find the H-alpha correlated
component to be consistent with zero for each region, and we find that addition
of an H-alpha correlated component in modeling the foreground emission has
negligible effect on derived CIB results. Our CIB detections and 2 sigma upper
limits are essentially the same as those derived by Hauser et al. and are given
by nu I_nu (nW m-2 sr-1) < 75, < 32, 25 +- 8, and 13 +- 3 at 60, 100, 140, and
240 microns, respectively. Our residuals have not been subjected to a detailed
anisotropy test, so our CIB results do not supersede those of Hauser et al. We
derive upper limits on the 100 micron emissivity of the ionized medium that are
typically about 40% of the 100 micron emissivity of the neutral atomic medium.
This low value may be caused in part by a lower dust-to-gas mass ratio in the
ionized medium than in the neutral medium, and in part by a shortcoming of
using H-alpha intensity as a tracer of far infrared emission.
","We have used data obtained by the DIRBE instrument on board the COBE satellite to determine the far-infrared cosmic background (CIB) at wavelengths between 1.25 mm and 240 m, which is dominated by emission lines from interstellar atomic hydrogen. We find that the CIB intensity in this wavelength range can be described as a power law with an index of -2.6 +/- 0.1. The total energy density of the CIB integrated over all wavelengths longer than 100 microns amounts to about 5 x 10(-3). This value agrees well with previous estimates based on IRAS observations but it is significantly higher than values derived from recent ISO measurements. Our results are consistent with theoretical predictions for the contribution of dusty galaxies to the CIB. They also provide new constraints on models describing the formation of structure in the universe. 
 
 Keywords: infrared radiation; cosmology; galaxy evolution; intergalactic medium",arxiv,bigscience bloomz,705.3966,0.5555555555555556,0.29411764705882354,0.9076923076923077,0.37219302436693746,1,1,0,0,0,1,1,1,0,0,0.07921172863051332,0.07938530926276056,0.08171206225680934,0.05303030303030303,0,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Dynamical non-axisymmetric instabilities in rotating relativistic stars,"  We present new results on dynamical instabilities in rapidly rotating
neutron-stars. In particular, using numerical simulations in full General
Relativity, we analyse the effects that the stellar compactness has on the
threshold for the onset of the dynamical bar-mode instability, as well as on
the appearance of other dynamical instabilities. By using an extrapolation
technique developed and tested in our previous study [1], we explicitly
determine the threshold for a wide range of compactnesses using four sequences
of models of constant baryonic mass comprising a total of 59 stellar models.
Our calculation of the threshold is in good agreement with the Newtonian
prediction and improves the previous post-Newtonian estimates. In addition, we
find that for stars with sufficiently large mass and compactness, the m=3
deformation is the fastest growing one. For all of the models considered, the
non-axisymmetric instability is suppressed on a dynamical timescale with an m=1
deformation dominating the final stages of the instability. These results,
together with those presented in [1], suggest that an m=1 deformation
represents a general and late-time feature of non-axisymmetric dynamical
instabilities both in full General Relativity and in Newtonian gravity.
","We study the dynamical stability properties of rapidly-rotating, axisymmetric neutron star models with different equations of state (EOS). We find that for all EOS considered here, there is an instability associated to the presence of toroidal magnetic fields which can be excited by differential rotation between core and crust regions. The growth timescale of this instability ranges from 10-100 ms depending on the strength of the field and the degree of differential rotation present initially. 
 
 This instability may have important consequences for magnetar flares as well as for the spin evolution of young pulsars. In particular we show how it could lead to rapid spindowns during the first few hundred milliseconds after birth if the initial conditions are such that the unstable mode has a large enough amplitude. Finally, we discuss possible observational signatures of these instabilities. Dynamical non-axisymmetric modes in rapidly-rotating relativistic stars",arxiv,bigscience bloomz,705.1826,0.3333333333333333,0.29411764705882354,0.3333333333333333,0.36645962732919257,0,1,0,0,0,1,1,0,0,0,0.10791327258487844,0.08363956640842295,0.12062256809338522,0.07575757575757576,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Sensitivity of solar off-limb line profiles to electron density stratification and the velocity distribution anisotropy,"  The effect of the electron density stratification on the intensity profiles
of the H I Ly-$\alpha$ line and the O VI and Mg X doublets formed in solar
coronal holes is investigated. We employ an analytical 2-D model of the large
scale coronal magnetic field that provides a good representation of the corona
at the minimum of solar activity. We use the mass-flux conservation equation to
determine the outflow speed of the solar wind at any location in the solar
corona and take into account the integration along the line of sight (LOS). The
main assumption we make is that no anisotropy in the kinetic temperature of the
coronal species is considered. We find that at distances greater than 1 Rsun
from the solar surface the widths of the emitted lines of O VI and Mg X are
sensitive to the details of the adopted electron density stratification.
However, Ly-$\alpha$, which is a pure radiative line, is hardly affected. The
calculated total intensities of Ly-$\alpha$ and the O VI doublet depend to a
lesser degree on the density stratification and are comparable to the observed
ones for most of the considered density models. The widths of the observed
profiles of Ly-$\alpha$ and Mg X are well reproduced by most of the considered
electron density stratifications, while for the O VI doublet only few
stratifications give satisfying results. The densities deduced from SOHO data
result in O VI profiles whose widths and intensity ratio are relatively close
to the values observed by UVCS although only isotropic velocity distributions
are employed. These density profiles also reproduce the other considered
observables with good accuracy. Thus the need for a strong anisotropy of the
velocity distribution (i.e. a temperature anisotropy) is not so clear cut as
previous investigations of UVCS data suggested. ...
","We have investigated how different assumptions about the velocity distribution function (VDF) affect the shape of the observed line profile in the solar corona, using an analytical model for the VDF that includes both isotropic thermal motions and anisotropic nonthermal motions. We find that the inclusion of nonthermal motions can significantly alter the shapes of the simulated line profiles compared with those obtained assuming purely Maxwellian distributions. The effects are more pronounced when the plasma temperature decreases and/or the degree of anisotropy increases. 
 
 In particular, we show that the presence of nonthermal motions leads to significant asymmetries between the red-and blueshifted wings of the line profiles. These results suggest that it may be possible to use observations of coronal lines to constrain the properties of the underlying VDFs. However, this requires accurate measurements of the Doppler shifts associated with each emission feature along the line-of-sight.",arxiv,bigscience bloomz,704.1127,0.6666666666666666,0.24369747899159663,0.9025641025641026,0.369326325848065,1,1,0,0,0,1,1,0,0,0,0.11414769383850606,0.07737150217133701,0.07782101167315175,0.05303030303030303,1,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Thermal Stability of Metallic Single-Walled Carbon Nanotubes: An O(N) Tight-Binding Molecular Dynamics Simulation Study,"  Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to
investigate the thermal stability of (10,10) metallic Single-Walled Carbon
Nanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial
direction. Velocity Verlet algorithm along with the canonical ensemble
molecular dynamics (NVT) is used to simulate the tubes at the targeted
temperatures. The effects of slow and rapid temperature increases on the
physical characteristics, structural stability and the energetics of the tube
are investigated and compared. Simulations are carried out starting from room
temperature and the temperature is raised in steps of 300K. Stability of the
simulated metallic SWCNT is examined at each step before it is heated to higher
temperatures. First indication of structural deformation is observed at 600K.
For higher heat treatments the deformations are more pronounced and the bond
breaking temperature is reached around 2500K. Gradual (slow) heating and
thermal equilibrium (fast heating) methods give the value of radial thermal
expansion coefficient in the temperature range between 300K-600K as
0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both
methods give the same value of 0.089x10^{-5}(1/K). The ratio of the total
energy per atom with respect to temperature is found to be 3x10^{-4} eV/K.
","The thermal stability and melting behavior of metallic single-wall carbon nanotubes (SWCNTs) are investigated by using an efficient tight-binding molecular dynamics simulation method with the Tersoff potential function. The results show that SWCNTs can be melted at temperatures ranging from 2000 to 3000 K, depending on their diameters. It is found that the melting temperature increases as the diameter decreases for both zigzag- and armchair-type tubes. In addition, it is shown that the melting process involves two stages in which the tube wall first becomes disordered followed by the formation of liquid-like structures inside the tube. Finally, we find that the melting point of SWCNTs depends strongly on the chirality index n-m. For example, the melting points of zigzag-type SWCNTs increase rapidly when n-m changes from 0 to 1 or -1. 
 
 Keywords: Thermal stability, Melting behavior, Carbon nanotube",arxiv,bigscience bloomz,705.1625,0.5555555555555556,0.24369747899159663,0.35384615384615387,0.34925943621595795,1,1,0,0,0,1,1,1,0,0,0.08974557740698427,0.07909159962672667,0.10894941634241245,0.09090909090909091,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Structural relaxation around substitutional Cr3+ in MgAl2O4,"  The structural environment of substitutional Cr3+ ion in MgAl2O4 spinel has
been investigated by Cr K-edge Extended X-ray Absorption Fine Structure (EXAFS)
and X-ray Absorption Near Edge Structure (XANES) spectroscopies.
First-principles computations of the structural relaxation and of the XANES
spectrum have been performed, with a good agreement to the experiment. The Cr-O
distance is close to that in MgCr2O4, indicating a full relaxation of the first
neighbors, and the second shell of Al atoms relaxes partially. These
observations demonstrate that Vegard's law is not obeyed in the MgAl2O4-MgCr2O4
solid solution. Despite some angular site distortion, the local D3d symmetry of
the B-site of the spinel structure is retained during the substitution of Cr
for Al. Here, we show that the relaxation is accomodated by strain-induced bond
buckling, with angular tilts of the Mg-centred tetrahedra around the Cr-centred
octahedron. By contrast, there is no significant alteration of the angles
between the edge-sharing octahedra, which build chains aligned along the three
four-fold axes of the cubic structure.
","The structural relaxation and the local vibrational modes (LVMs) are investigated by first-principles calculations for the substituted system Mg1-xCrxAl2-xO4 with x=0, 0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0 at%. The results show that the substitution of Al3+ ions by Cr3+ leads to an increase in volume as well as a decrease in the unit cell parameters. In addition, we find that there is no significant change in the bond lengths between nearest-neighboring atoms when the concentration of Cr3+ increases up to 5%. However, it can be seen clearly that the bond length between second-nearest neighboring atoms decreases gradually with increasing Cr3+ content. Furthermore, our calculated phonon dispersion curves indicate that all the LVMs are stable except those along the Γ-X direction which become unstable above 1% Cr3+ doping.",arxiv,bigscience bloomz,704.0878,0.3333333333333333,0.19327731092436976,0.2205128205128205,0.32059245102723366,1,1,0,0,1,1,1,0,0,0,0.05325811043695411,0.047592965208137765,0.05058365758754864,0.030303030303030304,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Charge Ordering in Half-Doped Manganites: Weak Charge Disproportion and Leading Mechanisms,"  The apparent contradiction between the recently observed weak charge
disproportion and the traditional Mn$^{3+}$/Mn$^{4+}$ picture of the
charge-orbital orders in half-doped manganites is resolved by a novel Wannier
states analysis of the LDA$+U$ electronic structure. Strong electron itinerancy
in this charge-transfer system significantly delocalizes the occupied
low-energy ""Mn$^{3+}$"" Wannier states such that charge leaks into the
""Mn$^{4+}$""-sites. Furthermore, the leading mechanisms of the charge order are
quantified via our first-principles derivation of the low-energy effective
Hamiltonian. The electron-electron interaction is found to play a role as
important as the electron-lattice interaction. \ignore{A general picture of
doped holes in strongly correlated charge-transfer systems is presented and
applied to the study of charge order in half-doped manganites, using a novel
Wannier states analysis of the LDA$+U$ electronic structure. While residing
primarily in the oxygen atoms, the doped holes form additional effective $e_g$
orbitals at the low-energy scale, leading to an effective Mn$^{3+}$/Mn$^{4+}$
valence picture that enables weak charge disproportion, resolving the current
serious contradictions between the recent experimental observations of charge
distribution and traditional models. Furthermore, the leading mechanisms of the
observed charge order are quantified via our first-principles derivation of the
low-energy effective Hamiltonian
","Charge ordering (CO) is one of the most important phenomena in strongly correlated electron systems, which has been observed in many transition metal oxides such as manganese perovskite compounds. In this work we study charge disproportionation in half-doped manganites by using density functional theory with Hubbard U correction. We find that CO state can be stabilized at low temperatures due to strong Coulomb interaction between Mn3+ and Mn4+ ions. The energy gain for CO state over metallic state increases rapidly when temperature decreases below Tc. Our results show that CO state is more stable than other competing states including ferromagnetic insulator phase and antiferromagnetic insulating phase. 
 
 Keywords: Charge-ordering, Density-functional-theory, Correlated electrons, Transition-metal-oxides, Manganites, Energy-band-structure, Insulators, Ferromagnetism, Antiferromagnetism",arxiv,bigscience bloomz,704.1834,0.3333333333333333,0.24369747899159663,0.358974358974359,0.28905876731963687,0,1,0,0,0,1,1,1,0,0,0.1650624705988908,0.04077853861627448,0.17509727626459143,0.03409090909090909,0,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A new Generation of Spectrometer Calibration Techniques based on Optical Frequency Combs,"  Typical astronomical spectrographs have a resolution ranging between a few
hundred to 200.000. Deconvolution and correlation techniques are being employed
with a significance down to 1/1000 th of a pixel. HeAr and ThAr lamps are
usually used for calibration in low and high resolution spectroscopy,
respectively. Unfortunately, the emitted lines typically cover only a small
fraction of the spectrometer's spectral range. Furthermore, their exact
position depends strongly on environmental conditions. A problem is the strong
intensity variation between different (intensity ratios {>300). In addition,
the brightness of the lamps is insufficient to illuminate a spectrograph via an
integrating sphere, which in turn is important to calibrate a long-slit
spectrograph, as this is the only way to assure a uniform illumination of the
spectrograph pupil.
  Laboratory precision laser spectroscopy has experienced a major advance with
the development of optical frequency combs generated by pulsed femto-second
lasers. These lasers emit a broad spectrum (several hundred nanometers in the
visible and near infra-red) of equally-spaced ""comb"" lines with almost uniform
intensity (intensity ratios typically <10). Self-referencing of the laser
establishes a precise ruler in frequency space that can be stabilized to the
10e-18 uncertainty level, reaching absolute frequency inaccuracies at the
10e-12 level per day when using the Global Positioning System's (GPS) time
signal as the reference. The exploration of the merits of this new technology
holds the promise for broad-band, highly accurate and reproducible calibration
required for reliable operation of current and next generation astronomic
spectrometers.
","We present the latest advances in optical frequency combs and their applications to precision metrology, including calibration techniques for high-resolution spectroscopy instruments such as Fourier transform spectrometers (FTS). We discuss how these techniques can be used to improve measurement accuracy by orders of magnitude over traditional methods.  In particular we describe two novel approaches that are being developed at NIST:  1) The use of an optical frequency comb locked to a high-accuracy atomic clock to calibrate FTS measurements with sub-Hz uncertainty. 2) A technique called ""self-calibration"" which allows one to measure absolute frequencies without requiring any external reference standards or other auxiliary equipment. These techniques have been demonstrated using both laboratory experiments and field tests. They represent important steps towards realizing the vision of a future where all spectroscopic measurements will be traceable back to fundamental physical constants. This is especially relevant today given the growing interest in developing portable, low-cost devices capable of performing accurate chemical analysis anywhere around the world.",arxiv,bigscience bloomz,705.0763,0.5555555555555556,0.29411764705882354,0.6205128205128205,0.4180602006688964,1,1,0,0,1,1,1,1,0,0,0.11661626126201753,0.06003348780452479,0.11284046692607004,0.04924242424242424,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
The Intrinsically X-ray Weak Quasar PHL 1811. II. Optical and UV Spectra and Analysis,"  This is the second of two papers reporting observations and analysis of the
unusually bright (m_b=14.4), luminous (M_B=-25.5), nearby (z=0.192) narrow-line
quasar PHL 1811. The first paper reported that PHL 1811 is intrinsically X-ray
weak, and presented a spectral energy distribution (SED). Here we present HST
STIS optical and UV spectra, and ground-based optical spectra. The optical and
UV line emission is very unusual. There is no evidence for forbidden or
semiforbidden lines. The near-UV spectrum is dominated by very strong FeII and
FeIII, and unusual low-ionization lines such as NaID and CaII H&K are observed.
High-ionization lines are very weak; CIV has an equivalent width of 6.6A, a
factor of ~5 smaller than measured from quasar composite spectra. An unusual
feature near 1200A can be deblended in terms of Ly\alpha, NV, SiII, and CIII*
using the blueshifted CIV profile as a template. Photoionization modeling shows
that the unusual line emission can be explained qualitatively by the unusually
soft SED. Principally, a low gas temperature results in inefficient emission of
collisionally excited lines, including the semiforbidden lines generally used
as density diagnostics. The emission resembles that of high-density gas; in
both cases this is a consequence of inefficient cooling. PHL 1811 is very
unusual, but we note that quasar surveys are generally biased against finding
similar objects.
","We present new optical and ultraviolet (UV) spectra for the intrinsically X-ray weak quasar PHL 1811, obtained with the Keck Observatory's HIRES spectrograph in 1998-99. The data cover wavelengths between 3200 A and 10400Å at resolution R = λ/∆λ ≈ 45000. We find that the continuum emission is well described by an accretion disk model with parameters similar to those found previously for other quasars. However, we detect no broad absorption lines or narrow absorption features associated with outflows. In addition, there are several unusual properties of the line profiles which suggest that this object may be different than most quasars studied so far. 
 
 Keywords: Quasars; Broad Absorption Lines; Accretion Disk Modeling. 1 Introduction 
 
 PHL 1811 was discovered as part of the Palomar-Green survey (Schmidt & Green 1983 ) and has been observed extensively since then. It is one of only two known examples of an X-ray weak quasar (Wilkes et al. 1994) , where the ratio of its soft X-ray flux density to its 2500 Å flux density is less than 0.1. Wilkes et al. (1994) suggested that it might have a high column density absorber along our line-of-sight, but subsequent observations failed to confirm this hypothesis (e.g., Mathur et al. 1995) . Instead, they concluded that the source must be intrinsically X-ray weak because of some unknown mechanism. Recent Chandra observations show that the spectrum below 2 keV can be fitted reasonably well using a power law plus Galactic absorption (Mathur et al. 2002 ) . This suggests that the intrinsic X-ray weakness could arise due to a steep spectral index rather than strong obscuration. Another possibility is that the X-rays are absorbed by ionized gas near the central black hole . 
 
 PHL 1811 also shows interesting variability on time scales ranging from hours to years. For example, Wilkes et al. (1995) reported rapid changes in both the hardness ratios and luminosity during their ASCA observation. They interpreted these variations as being caused by partial",arxiv,bigscience bloomz,705.094,0.6111111111111112,1.0,0.48205128205128206,0.8910654562828476,1,1,1,0,0,1,1,1,0,1,0.06687534386334801,0.07208478273128786,0.06614785992217899,0.0946969696969697,2,5,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1
Rich methane premixed laminar flames doped by light unsaturated hydrocarbons - Part I : allene and propyne,"  The structure of three laminar premixed rich flames has been investigated: a
pure methane flame and two methane flames doped by allene and propyne,
respectively. The gases of the three flames contain 20.9% (molar) of methane
and 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure
methane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to
a ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have
been stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant,
with a gas velocity at the burner of 36 cm/s at 333 K. The concentration
profiles of stable species were measured by gas chromatography after sampling
with a quartz microprobe. Quantified species included carbon monoxide and
dioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne,
allene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene,
1-butyne, vinylacetylene, and benzene. The temperature was measured using a
PtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from
700 K close to the burner up to 1850 K. In order to model these new results,
some improvements have been made to a mechanism previously developed in our
laboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main
reaction pathways of consumption of allene and propyne and of formation of C6
aromatic species have been derived from flow rate analyses.
","The effect of adding small amounts (0.5-2%) of the light unsaturated hydrocarbons, allene or propyne to rich methane/air mixtures is investigated experimentally in this study using counterflow diffusion flames at atmospheric pressure. The flame structure is examined with OH* chemiluminescence imaging and laser induced fluorescence measurements for CH2O and CH3O radicals. It was found that both additives have similar effects on the flame structure; they increase the flame temperature slightly but decrease significantly the maximum mole fraction of OH radical. This leads to an increased soot formation rate as evidenced by the higher soot volume fractions measured downstream of the flame front. In addition, it has been observed that the presence of these additives increases the flame speed.  These results are discussed in terms of chemical kinetic mechanisms involving reactions between hydrocarbon species and oxygen atoms. Finally, the influence of the additive concentration on the flame structure is analyzed.",arxiv,bigscience bloomz,704.0375,0.3333333333333333,0.29411764705882354,0.5282051282051282,0.38079311992355475,1,1,1,0,0,1,1,1,0,0,0.12785683994267108,0.06038700099851386,0.14785992217898833,0.045454545454545456,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Generalized Brjuno functions associated to $\alpha$-continued fractions,"  For \alpha in the interval [0,1], we consider the one-parameter family of
\alpha-continued fraction maps, which include the Gauss map (\alpha=1) and the
nearest integer (\alpha=1/2) and by-excess (\alpha=0) continued fraction maps.
To each of these expansions, and to each choice of a positive function u on the
interval I_\alpha=(0,max(\alpha,1-\alpha)) we associate a generalized Brjuno
function B_(\alpha,u)(x). For \alpha=1/2 or \alpha=1, and u(x)=-\log(x), these
functions were introduced by Yoccoz in his work on the linearization of
holomorphic maps. Their regularity properties, including BMO regularity and
their extension to the complex plane, have been thoroughly investigated. We
compare the functions obtained with different values of \alpha and we prove
that the set of (\alpha,u)-Brjuno numbers does not depend on the choice of
\alpha provided that \alpha>0. We then consider the case \alpha=0,
u(x)=-\log(x) and we prove that x is a Brjuno number (for \alpha> 0) if and
only if both x and -x are Brjuno numbers for \alpha=0.
","We introduce the notion of generalized Brjuno function and study its properties in connection with continued fractions. We show that if $(a_n)_n$ is an infinite sequence of positive integers such that for all $n$, $a_n+1>a_{n-1}+2$ then there exists a unique real number $x$ satisfying the following conditions: (i) $x\in[0,1]$;
(ii) the sequence $(a_nx^n)_n$ converges to $x$ as $n\to\infty$; 
(iii) the sequence $(b_n)_n$ defined by $b_0=1$ and $b_{n+1}=\prod\limits_{i=0}^{n-1}\frac1{a_i+1}-\frac1{a_ix^{i+1}}$ satisfies the condition $\displaystyle\sum\limits_{n\geq 0}\frac{|b_n|}{n^\alpha}<\infty$ for some $\alpha>0$. 
The main result of this article shows that any real number $x$ which can be written as above has a finite irrationality measure.",arxiv,bigscience bloomz,705.169,0.2777777777777778,0.09243697478991597,0.17435897435897435,0.23459149546106067,1,1,0,0,0,1,1,1,0,0,0.08305508482855052,0.5317805592347541,0.07003891050583658,0.4810606060606061,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0
High Precision CTE-Measurement of SiC-100 for Cryogenic Space-Telescopes,"  We present the results of high precision measurements of the thermal
expansion of the sintered SiC, SiC-100, intended for use in cryogenic
space-telescopes, in which minimization of thermal deformation of the mirror is
critical and precise information of the thermal expansion is needed for the
telescope design. The temperature range of the measurements extends from room
temperature down to $\sim$ 10 K. Three samples, #1, #2, and #3 were
manufactured from blocks of SiC produced in different lots. The thermal
expansion of the samples was measured with a cryogenic dilatometer, consisting
of a laser interferometer, a cryostat, and a mechanical cooler. The typical
thermal expansion curve is presented using the 8th order polynomial of the
temperature. For the three samples, the coefficients of thermal expansion
(CTE), $\bar{\alpha}_{#1}$, $\bar{\alpha}_{#2}$, and $\bar{\alpha}_{#3}$ were
derived for temperatures between 293 K and 10 K. The average and the dispersion
(1 $\sigma$ rms) of these three CTEs are 0.816 and 0.002 ($\times 10^{-6}$/K),
respectively. No significant difference was detected in the CTE of the three
samples from the different lots. Neither inhomogeneity nor anisotropy of the
CTE was observed. Based on the obtained CTE dispersion, we performed an
finite-element-method (FEM) analysis of the thermal deformation of a 3.5 m
diameter cryogenic mirror made of six SiC-100 segments. It was shown that the
present CTE measurement has a sufficient accuracy well enough for the design of
the 3.5 m cryogenic infrared telescope mission, the Space Infrared telescope
for Cosmology and Astrophysics (SPICA).
","The development of large space telescopes requires the use of lightweight materials to reduce launch costs and increase telescope performance in orbit. Silicon Carbide (SiC) is an excellent candidate material due to its high strength, low density, and radiation hardness at cryogenic temperatures. However, it has been shown that SiC exhibits significant changes in thermal expansion with temperature which can lead to dimensional instability during cool-downs or warm-ups. This work presents results on the measurement of the coefficient of thermal expansion (CTE) of SiC-100 over a wide range of temperatures using a novel technique based on laser interferometry. The measured values are compared against literature data as well as theoretical predictions obtained by ab initio calculations. It was found that the experimental measurements agree very well with theory within the uncertainty limits. These results will be used to improve the design of future space missions such as JWST and WFIRST-AFTA.",arxiv,bigscience bloomz,704.1515,0.4444444444444444,0.29411764705882354,0.6307692307692307,0.3836598184424272,1,1,0,0,0,1,1,0,0,0,0.22782132686632708,0.04237115530209928,0.29961089494163423,0.03787878787878788,1,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Sloan Digital Sky Survey Quasar Catalog IV. Fifth Data Release,"  We present the fourth edition of the Sloan Digital Sky Survey (SDSS) Quasar
Catalog. The catalog contains 77,429 objects; this is an increase of over
30,000 entries since the previous edition. The catalog consists of the objects
in the SDSS Fifth Data Release that have luminosities larger than M_i = -22.0
(in a cosmology with H_0 = 70 km/s/Mpc, Omega_M = 0.3, and Omega_Lambda = 0.7)
have at least one emission line with FWHM larger than 1000 km/s, or have
interesting/complex absorption features, are fainter than i=15.0, and have
highly reliable redshifts. The area covered by the catalog is 5740 sq. deg. The
quasar redshifts range from 0.08 to 5.41, with a median value of 1.48; the
catalog includes 891 quasars at redshifts greater than four, of which 36 are at
redshifts greater than five. Approximately half of the catalog quasars have i <
19; nearly all have i < 21. For each object the catalog presents positions
accurate to better than 0.2 arcsec. rms per coordinate, five-band (ugriz)
CCD-based photometry with typical accuracy of 0.03 mag, and information on the
morphology and selection method. The catalog also contains basic radio,
near-infrared, and X-ray emission properties of the quasars, when available,
from other large-area surveys. The calibrated digital spectra cover the
wavelength region 3800--9200A at a spectral resolution of ~2000. The spectra
can be retrieved from the public database using the information provided in the
catalog. The average SDSS colors of quasars as a function of redshift, derived
from the catalog entries, are presented in tabular form. Approximately 96% of
the objects in the catalog were discovered by the SDSS.
","The Sloan Digital Sky Survey (SDSS) is an ongoing project to map the distribution and motion of galaxies, quasars, stars, and other celestial objects in space. The fourth data release was made public on September 30th 2003. This fifth data release contains more than 100,000 new quasar candidates selected by color criteria from the SDSS imaging survey. These are supplemented with about 20,000 previously known quasars that were not included in previous releases because they did not meet the selection criteria for inclusion at that time. 
 
 In addition to these newly discovered quasars, this catalog also includes all quasars found during the first four years of the survey as well as those found since then but which have yet to be released publicly. A total of over 250,000 quasars are now available through this catalog. All of them have been spectroscopically confirmed using observations obtained with the dedicated 2.5-meter telescope located at Apache Point Observatory near Sacramento, California.",arxiv,bigscience bloomz,704.0806,0.7222222222222222,0.29411764705882354,0.7538461538461538,0.40659340659340665,1,1,1,0,0,1,1,0,0,0,0.14595892424596515,0.07820859676856959,0.22957198443579765,0.08333333333333333,2,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Magnetar Nature and the Outburst Mechanism of a Transient Anomalous X-ray Pulsar,"  Anomalous X-ray Pulsars (AXPs) belong to a class of neutron stars believed to
harbor the strongest magnetic fields in the universe, as indicated by their
energetic bursts and their rapid spindowns. However, an unambiguous measurement
of their surface field strengths has not been made to date. It is also not
known whether AXP outbursts result from changes in the neutron star magnetic
field or crust properties. Here we report a spectroscopic measurement of the
surface magnetic field strength of an AXP, XTE J1810$-$197, and solidify its
magnetar nature. The field strength obtained from detailed spectral analysis
and modeling, B = (2.72$\pm$0.03)$\times10^{14}$ G, is remarkably close to the
value inferred from the rate of spindown of this source and remains nearly
constant during numerous observations spanning over an order of magnitude in
source flux. The surface temperature, on the other hand, declines steadily and
dramatically following the 2003 outburst of this source. Our findings
demonstrate that heating occurs in the upper neutron star crust during an
outburst and sheds light on the transient behaviour of AXPs.
","We report on our analysis of the outburst mechanism of SGR 1806-20, which is one of three known magnetars (neutron stars with superstrong magnetic fields). We have analyzed all available data obtained by Swift/BAT during its first year in orbit to search for periodicities associated with this source. The BAT light curve shows that there are two major flares lasting about 100 days each; these flares were also observed simultaneously at other wavelengths. In addition we find evidence for several smaller bursts occurring between the main flares. Using an improved version of the method developed by Israel et al. (2008) we searched for pulsations in the BAT data corresponding to the time intervals when the source was active. No significant signal could be found above background noise levels down to a limit of 1 mCrab (3σ), but we did detect a weak signal below 0.5 mCrab. This signal has been confirmed using independent methods applied to different energy bands.",arxiv,bigscience bloomz,705.3713,0.3333333333333333,0.3445378151260504,0.26666666666666666,0.4094601051122791,1,1,0,0,0,1,1,1,0,0,0.1304115866112712,0.056552955497420204,0.1517509727626459,0.05303030303030303,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SQUID-based instrumentation for ultra-low-field MRI,"  Magnetic resonance imaging at ultra-low fields (ULF MRI) is a promising new
imaging method that uses SQUID sensors to measure the spatially encoded
precession of pre-polarized nuclear spin populations at a microtesla-range
measurement field. In this work, a seven-channel SQUID system designed for
simultaneous 3D ULF MRI and magnetoencephalography (MEG) is described. The
system includes seven second-order SQUID gradiometers, characterized by
magnetic field resolutions of 1.2 - 2.8 fT/rtHz. It is also equipped with five
sets of coils for 3D Fourier imaging with pre-polarization. Essential technical
details of the design are discussed. The system's ULF MRI performance is
demonstrated by multi-channel 3D images of a preserved sheep brain acquired at
46 microtesla measurement field with pre-polarization at 40 mT. The imaging
resolution is 2.5 mm x 2.5 mm x 5 mm. The ULF MRI images are compared to images
of the same brain acquired using conventional high-field MRI. Different ways to
improve imaging SNR are discussed.
","The development and application of superconducting quantum interference devices (SQUIDs) in magnetic resonance imaging has been reviewed, with emphasis on the recent advances made by our group at UCLA. The SQUID is an extremely sensitive magnetometer that can be used to detect very small changes in the local magnetic field produced by nuclear spins during NMR experiments. In this review we describe how these devices have been incorporated into several different types of low-field MRI systems including micro-SQUID arrays fabricated using standard semiconductor processing techniques as well as macroscopic SQUID gradiometers developed specifically for use in human brain studies. We also discuss some of the challenges associated with operating such instruments under conditions where the ambient magnetic fields are not completely shielded or controlled. Finally, we present results obtained recently using one of these new technologies to study the effects of anesthesia on functional connectivity within the human brain. Magnetic Resonance Imaging (MRI), which was first demonstrated more than 30 years ago, provides detailed information about the structure and function of living tissues through noninvasive measurements of their water content [1] . This technique relies upon the detection of tiny radio-frequency signals emitted by hydrogen nuclei when they precess around the main magnetic field B 0 , which is generated by a large electromagnet [2] .
In conventional clinical scanners, the strength of B 0 ranges between 1 T and 3 T [3] . However, there are many applications where it would be desirable to perform MRI scans at much lower fields [4] . For example, the use of high-field magnets may cause significant heating problems due to dielectric losses in biological tissue [5] . Moreover, the cost of building and maintaining such large-scale facilities makes them inaccessible to most research laboratories [6] . Another disadvantage of working at higher fields is related to the fact that the relaxation times of protons become shorter [7, 8] . As a result, the signal-to-noise ratio decreases rapidly [9] making it difficult to obtain high-quality images [10] .",arxiv,bigscience bloomz,705.0661,0.4444444444444444,0.596638655462185,0.16923076923076924,0.9139990444338271,1,1,0,0,1,1,1,0,0,0,0.08371361430161352,0.05587206468010717,0.07782101167315175,0.04924242424242424,2,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Produit d'entrelacement et action triangulaire d'alg\`ebres de Lie,"  Formal actions of Lie algebras over vector spaces are introduced in a purely
algebraic way, as a mimic of infinitesimal operations of Banach Lie algebras
over Banach analytic manifolds. In analogy with the case of abstract groups,
complete wreath products and triangular actions are then defined for Lie
algebras acting ""en cascade"" over vector spaces. Finally, a Kaloujnine-Krasner
type theorem for Lie algebra extensions is proved.
  -----
  En mimant les lois d'op\'erations infinit\'esimales des alg\`ebres de Lie sur
les vari\'et\'e s analytiques banachiques, on introduit de mani\`ere purement
alg\`ebrique la notion d'action formelle d'une alg\`ebre de Lie sur un espace
vectoriel. Ensuite, par analogie avec le cas des groupes abstraits, et en
faisant op\'erer les alg\`ebres de Lie ""en cascade"", on d\'efinit produit
d'entrelacement (""wreath product"") et action triangulaire pour les alg\`ebres
de Lie. On d\'emontre enfin un th\'eor\`eme du type Kaloujnine-Krasner pour les
extensions d'alg\`ebres de Lie.
","Nous donnons une nouvelle preuve du th\'eor\eme suivant, qui est un cas particulier d'un r\'esultat plus g\'en\'eral obtenu par J. Bernstein (cf. [1]): Soit G une alg\ebre de Lie nilpotente d'ordre n{\displaystyle n} sur K{\displaystyle \mathbb {K} } . _SPLIT_ Alors il existe des polynomes Pk(X), k=0,...,n-1 tels que pour tout x∈G on ait :  xn=x0P1+x1P2++xn−1Pn−1{\displaystyle x^{n}=x_{0}P_{1}+x_{1}P_{2}+\cdots +x_{n-1}P_{n-1}} o{\displaystyle o} u les Pi{\displaystyle {\text{Pi}}} sont des polynomes homogènes en X{\displaystyle x} , degXi=Pk(i). Nous montrons aussi comment ce r\'esultat peut être utilisé dans la construction d'une base de Malcev d'une algèbre de Lie nilpotente quelconque.",arxiv,bigscience bloomz,704.384,0.2777777777777778,0.14285714285714285,0.1282051282051282,0.2259913999044434,1,1,0,0,1,1,1,1,0,1,0.12735599339932663,0.24649700863987214,0.14007782101167315,0.23863636363636365,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0
Near-infrared polarimetric study of the bipolar nebula IRAS 19312+1950,"  We obtained H-band polarimetric data of IRAS 19312+1950 using the
near-infrared camera (CIAO) on the 8 m Subaru telescope. In order to
investigate the physical properties of the central star and the nebula, we
performed dust radiative transfer modeling and compared the model results with
the observed spectral energy distributions (SEDs), the radial profiles of the
total intensity image, and the fraction of linear polarization map. The total
intensity image shows a nearly spherical core with ~3"" radius, an S-shaped arm
extending ~10"" in the northwest to southeast direction, and an extended lobe
towards the southwest. The polarization map shows a centro-symmetric vector
alignment in almost the entire nebula and low polarizations along the S-shaped
arm. These results suggest that the nebula is accompanied by a central star,
and the S-shaped arm has a physically ring-like structure. From our radiative
transfer modeling, we estimated the stellar temperature, the bolometric
luminosity, and the current mass-loss rate to be 2800 K, 7000 L_sun, and
5.3x10^{-6} M_sun yr^{-1}, respectively. Taking into account previous
observational results, such as the detection of SiO maser emissions and
silicate absorption feature in the 10 $\mu$m spectrum, our dust radiative
transfer analysis based on our NIR imaging polarimetry suggests that (1) the
central star of IRAS 19312+1950 is likely to be an oxygen-rich, dust-enshrouded
AGB star and (2) most of the circumstellar material originates from other
sources (e.g. ambient dark clouds) rather than as a result of mass loss from
the central star.
","We present near-infrared (NIR) polarimetry and spectroscopy for the bipolar reflection nebula IRAS 19312; 1950 . The NIR polarization vectors are aligned with those in optical images, indicating that they trace scattered light from an illuminating source located behind the dense molecular cloud core. We find evidence for two distinct scattering regions along our line-of-sight to this object; one is associated with the brightest part of the nebula, while another region shows lower polarization degrees but higher polarized fluxes at longer wavelengths. These results suggest that there may be multiple sources contributing to the observed emission. In addition, we detect several absorption features which can be attributed to water ice on dust grains near the central star(s). Our observations also reveal a possible outflow cavity traced by blueshifted CO emission lines. This work was supported by NASA through grant number HST-GO-11775.0-A from STScI, operated under NASA contract NAS5-26555.",arxiv,bigscience bloomz,704.2741,0.3888888888888889,0.29411764705882354,0.6256410256410256,0.3779264214046823,1,1,0,0,0,1,1,1,0,0,0.18278203143859462,0.07409674741837449,0.22957198443579765,0.08333333333333333,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Hadronization in semi-inclusive deep-inelastic scattering on nuclei,"  A series of semi-inclusive deep-inelastic scattering measurements on
deuterium, helium, neon, krypton, and xenon targets has been performed in order
to study hadronization. The data were collected with the HERMES detector at the
DESY laboratory using a 27.6 GeV positron or electron beam. Hadron
multiplicities on nucleus A relative to those on the deuteron, R_A^h, are
presented for various hadrons (\pi^+, \pi^-, \pi^0, K^+, K^-, p, and \bar{p})
as a function of the virtual-photon energy \nu, the fraction z of this energy
transferred to the hadron, the photon virtuality Q^2, and the hadron transverse
momentum squared p_t^2. The data reveal a systematic decrease of R_A^h with the
mass number A for each hadron type h. Furthermore, R_A^h increases (decreases)
with increasing values of \nu (z), increases slightly with increasing Q^2, and
is almost independent of p_t^2, except at large values of p_t^2. For pions
two-dimensional distributions also are presented. These indicate that the
dependences of R_A^{\pi} on \nu and z can largely be described as a dependence
on a single variable L_c, which is a combination of \nu and z. The dependence
on L_c suggests in which kinematic conditions partonic and hadronic mechanisms
may be dominant. The behaviour of R_A^{\pi} at large p_t^2 constitutes
tentative evidence for a partonic energy-loss mechanism. The A-dependence of
R_A^h is investigated as a function of \nu, z, and of L_c. It approximately
follows an A^{\alpha} form with \alpha \approx 0.5 - 0.6.
","We present the results for hadron production in semiinclusive DIS off nuclei at large Bjorken x and low Q^2, obtained with the HERMES experiment using data taken between 1997 and 2002. The analysis is performed within the framework of collinear factorisation and the modified perturbative approach to nuclear shadowing developed by Frankfurt et al.. We find that the observed suppression of leading neutron production relative to deuterium can be explained by nuclear effects alone without invoking any additional mechanism such as intrinsic charm or gluon saturation. In addition we observe an enhancement of strange particle production which cannot be described by conventional partonic models but may be attributed to the presence of intrinsic strangeness in the proton wave function. 
 
 1 Introduction 
 
 Semi-inclusive deep-inelastic lepton-nucleus scattering (SIDIS) has been studied extensively over many years both experimentally [1]-[6] and theoretically [7][8][9] . This process provides information about the quark structure of the target nucleus through measurements of final state particles produced in association with the scattered lepton. At high values of Bjorken-x, where the struck quarks are highly virtual, SIDIS probes the transition region between the non-perturbative regime governed by confinement physics and the perturbative domain dominated by short-distance interactions [10] . 
In this kinematic range it becomes possible to study the properties of bound-state systems directly via their interaction with hard probe photons [11] , thereby providing insight into the dynamics underlying the formation of composite states [12] - [14] .
Theoretical studies have shown that the cross section for SIDIS depends strongly on the transverse momentum k_T of the outgoing hadrons [15] - [17] . It was found that the dependence of the cross sections on k_T could be used to discriminate among different theoretical approaches [18] - [20] . For example, calculations based on the standard DGLAP formalism [21] predict a strong increase of the cross section with increasing k_T [22] while those employing the CCFM evolution equations [23] lead to much weaker dependences [24] . 
 
 2 Experimentally measured quantities",arxiv,bigscience bloomz,704.327,0.5,0.49579831932773116,0.5897435897435898,0.9025322503583373,1,1,0,0,0,1,1,0,0,0,0.1797454107164859,0.11194100913851815,0.19455252918287938,0.14393939393939395,1,1,3,6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Magnetic Fields of Classical T Tauri Stars,"  We report new magnetic field measurements for 14 classical T Tauri stars
(CTTSs). We combine these data with one previous field determination in order
to compare our observed field strengths with the field strengths predicted by
magnetospheric accretion models. We use literature data on the stellar mass,
radius, rotation period, and disk accretion rate to predict the field strength
that should be present on each of our stars according to these magnetospheric
accretion models. We show that our measured field values do not correlate with
the field strengths predicted by simple magnetospheric accretion theory. We
also use our field strength measurements and literature X-ray luminosity data
to test a recent relationship expressing X-ray luminosity as a function of
surface magnetic flux derived from various solar feature and main sequence star
measurements. We find that the T Tauri stars we have observed have weaker than
expected X-ray emission by over an order of magnitude on average using this
relationship. We suggest the cause for this is actually a result of the very
strong fields on these stars which decreases the efficiency with which gas
motions in the photosphere can tangle magnetic flux tubes in the corona.
","We present the first detection of magnetic fields in classical T Tauri stars (CTTSs) using spectropolarimetric observations obtained with ESPaDOnS at CFHT and Narval at TBL, as well as archival data for some targets. We detect Zeeman signatures in Stokes V profiles of H$\alpha$ lines in all observed CTTSs except TW Hya. The longitudinal field strengths range between -100 G to +300 G. In addition, we find that the mean unsigned circular polarization is higher than 0.1% in most cases. Our results show that the magnetic properties are similar among different types of CTTSs. However, there seems to be no correlation between the strength of the magnetic field and accretion rate or mass loss rates. This suggests that the origin of the magnetic field may not be related to disk accretion processes.  These findings will help us understand how stellar magnetic fields evolve during pre-main-sequence phase.",arxiv,bigscience bloomz,704.2923,0.3333333333333333,0.29411764705882354,0.36923076923076925,0.37219302436693746,1,1,0,0,0,1,1,0,0,0,0.08127538404120872,0.06670224420367737,0.07003891050583658,0.045454545454545456,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Dynamical Coupled-Channel Model of $\pi N$ Scattering in the W $\leq$ 2 GeV Nucleon Resonance Region,"  As a first step to analyze the electromagnetic meson production reactions in
the nucleon resonance region, the parameters of the hadronic interactions of a
dynamical coupled-channel model, developed in {\it Physics Reports 439, 193
(2007)}, are determined by fitting the $\pi N$ scattering data. The channels
included in the calculations are $\pi N$, $\eta N$ and $\pi\pi N$ which has
$\pi\Delta$, $\rho N$, and $\sigma N$ resonant components. The non-resonant
meson-baryon interactions of the model are derived from a set of Lagrangians by
using a unitary transformation method. One or two bare excited nucleon states
in each of $S$, $P$, $D$, and $F$ partial waves are included to generate the
resonant amplitudes in the fits. The parameters of the model are first
determined by fitting as much as possible the empirical $\pi N$ elastic
scattering amplitudes of SAID up to 2 GeV. We then refine and confirm the
resulting parameters by directly comparing the predicted differential cross
section and target polarization asymmetry with the original data of the elastic
$\pi^{\pm} p \to \pi^{\pm} p$ and charge-exchange $\pi^- p \to \pi^0 n$
processes. The predicted total cross sections of $\pi N$ reactions and $\pi
N\to \eta N$ reactions are also in good agreement with the data. Applications
of the constructed model in analyzing the electromagnetic meson production data
as well as the future developments are discussed.
","We present results for pion-nucleon scattering amplitudes obtained with an improved coupled-channel model that includes all known nucleon resonances up to $2.0 \, \mathrm{GeV}$ and is constrained by elastic-scattering data below $1.8 \, \mathrm{GeVa}_0$ . The model incorporates explicit contributions from the Delta resonance as well as from the S11(1535) and D13(1700) states which are generated dynamically through their coupling to the pion-nucleon continuum. We find good agreement between our predictions and experimental data on total cross sections, differential cross sections, polarization observables, and invariant-mass distributions at energies above $500 \, \mathrm{MeVa}_0$ .
The resulting partial-wave amplitudes can be used to calculate nuclear reaction rates relevant for astrophysics applications such as the r-process or neutrino-induced reactions. 


PACS numbers: 13.60.-r; 14.20.Gk; 12.39.Fe",arxiv,bigscience bloomz,704.1615,0.3888888888888889,0.06722689075630252,0.5230769230769231,0.12709030100334448,1,1,0,0,0,1,2,1,0,0,0.11605893941251007,0.03395325866645156,0.08949416342412451,0.045454545454545456,0,1,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1
Pure inductive limit state and Kolmogorov's property,"  Let $(\clb,\lambda_t,\psi)$ be a $C^*$-dynamical system where $(\lambda_t: t
\in \IT_+)$ be a semigroup of injective endomorphism and $\psi$ be an
$(\lambda_t)$ invariant state on the $C^*$ subalgebra $\clb$ and $\IT_+$ is
either non-negative integers or real numbers. The central aim of this
exposition is to find a useful criteria for the inductive limit state $\clb
\raro^{\lambda_t} \clb$ canonically associated with $\psi$ to be pure. We
achieve this by exploring the minimal weak forward and backward Markov
processes associated with the Markov semigroup on the corner von-Neumann
algebra of the support projection of the state $\psi$ to prove that
Kolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition
for the inductive state to be pure. As an application of this criteria we find
a sufficient condition for a translation invariant factor state on a one
dimensional quantum spin chain to be pure. This criteria in a sense complements
criteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states.
","The pure inductive limit state is introduced as the unique solution to an infinite system of linear equations with coefficients in the Banach algebra of bounded operators on Hilbert space, which are generated by a sequence of self-adjoint operators satisfying certain conditions.  The existence theorem for this state is proved under some mild assumptions. It is shown that if the spectrum of each operator in the sequence lies in a fixed compact set then the pure inductive limit state has all properties of Kolmogorov's state except positivity. In particular it satisfies the following relations:  $|\langle \phi | \hat \rho \rangle| \leq 1$; $\langle \phi | \hat \rho\rangle = 0$ iff $\phi$ belongs to the kernel of every operator in the sequence; $|\langle \phi_1 + \phi_2 | \hat \rho \rangle - \langle \phi_1 | \hat \rho \rangle \langle \phi_2 | \hat\rho \rangle| \leq C(\phi_1)C(\phi_2)$ where $C(\phi)$ depends only on the norm of $\phi$.",arxiv,bigscience bloomz,704.1987,0.2222222222222222,0.14285714285714285,0.2,0.38939321548017203,1,1,1,0,1,1,1,1,0,1,0.17183921226795038,0.250047759630419,0.13229571984435798,0.19696969696969696,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
HS1857+5144: A hot and young pre-cataclysmic variable,"  We report the discovery of a new white dwarf/M dwarf binary, HS1857+5144,
identified in the Hamburg Quasar Survey (HQS). Time-resolved optical
spectroscopy and photometry were carried out to determine the properties of
this new cataclysmic variable progenitor pre-CV). The light curves of
HS1857+5144 display a sinusoidal variation with a period of Porb=383.52 min and
peak-to-peak amplitudes of 0.7 mag and 1.1 mag in the B-band and R-band,
respectively. The large amplitude of the brightness variation results from a
reflection effect on the heated inner hemisphere of the companion star,
suggesting a very high temperature of the white dwarf. Our radial velocity
study confirms the photometric period as the orbital period of the system. A
model atmosphere fit to the spectrum of the white dwarf obtained at minimum
light provides limits to its mass and temperature of Mwd=~0.6-1.0 Msun and
Twd=~70000-100000 K, respectively. The detection of HeII 4686 absorption
classifies the primary star of HS1857+5144 as a DAO white dwarf. Combining the
results from our spectroscopy and photometry, we estimate the mass of the
companion star and the binary inclination to be Msec=~0.15-0.30 Msun and
i=~45-55 deg, respectively. We classify HS1857+5144 as one of the youngest
pre-CV known to date. The cooling age of the white dwarf suggests that the
present system has just emerged from a common envelope phase ~10^5 yr ago.
HS1857+5144 will start mass transfer within or below the 2-3h period gap.
","We report the discovery of an eclipsing binary system HS1857+5144, which is composed of two white dwarfs with masses 0.6 M⊙and 0.8M⊙respectively. The orbital period of this system is 1.5 hours. We find that the mass ratio q = M2/M1=0.84 ±0.04 for this system by using the method of spectral disentangling. This value indicates that it may be in the stage before the final merger into one single degenerate star. In addition to its short orbital period, we also found that the temperature difference between these two components is very large (∼10000K). These results suggest that this system has just evolved out of common envelope phase. 
 
 Keywords: Hot subdwarf B stars; Eclipsing; Pre-Cataclysmic Variables; White Dwarfs; Spectral Disentangling",arxiv,bigscience bloomz,704.178,0.5555555555555556,0.29411764705882354,0.5692307692307692,0.2919254658385093,1,1,0,0,0,1,1,1,0,0,0.06936182432658144,0.040918725692279605,0.07003891050583658,0.03787878787878788,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Critical Behaviour of Irreversible Reaction Systems,"  An introductory review on the critical behaviour of some irreversible
reaction systems is given. The study of these systems has attracted great
attention during the last decades due to, on the one hand, the rich and complex
underlying physics, and on the other hand, their relevance for numerous
technological applications in heterogeneous catalysis, corrosion and coating,
development of microelectronic devices, etc. The review is focuses on recent
advances in the understanding of irreversible phase transitions (IPT's)
providing a survey of the theoretical development of the field during the last
decade, as well as a detailed discussion of relevant numerical simulations. The
Langevin formulation for the treatment of second-order IPT's is discussed.
Different Monte Carlo approaches are also presented in detail and the
finite-size scaling analysis of second-order IPT's is described. Special
attention is devoted to the description of recent progress in the study of
first-order IPT's observed upon catalytic oxidation of carbon monoxide and the
reduction of nitrogen monoxide, using lattice gas reaction models. Only brief
comments are given on other reactions such as the oxidation of hydrogen,
ammonia synthesis, etc. Also, a discussion of relevant experiments is presented
and measurement are compared with the numerical results. Furthermore, promising
areas for further research and open questions are also addressed.
","We study the critical behaviour of irreversible reaction systems with mass-action kinetics in one dimension, using Monte Carlo simulations and mean-field theory. We find that for large system sizes there is no phase transition at all; instead we observe an abrupt change between two different dynamical regimes as a function of temperature T . For low temperatures (T < Tc) the dynamics are dominated by fluctuations which lead to slow relaxation times towards equilibrium. In contrast, for high temperatures (T > Tc), the dynamics become much faster since the system relaxes quickly into metastable states. The crossover temperature Tc depends on the number N of particles present in the system and increases logarithmically with N .
The results presented here can be understood within the framework of the recently developed concept of ""active matter"". Active matter consists of self-propelled units such as living cells or artificial microswimmers. It has been shown that active matter exhibits similar properties as conventional condensed matter close to its critical point.",arxiv,bigscience bloomz,706.0419,0.4444444444444444,0.3445378151260504,0.441025641025641,0.4295269947443861,1,1,0,0,1,1,1,1,0,0,0.13796762895422085,0.04111513375975412,0.1556420233463035,0.022727272727272728,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
"A new, very massive modular Liquid Argon Imaging Chamber to detect low energy off-axis neutrinos from the CNGS beam. (Project MODULAr)","  The paper is considering an opportunity for the CERN/GranSasso (CNGS)
neutrino complex, concurrent time-wise with T2K and NOvA, to search for
theta_13 oscillations and CP violation. Compared with large water Cherenkov
(T2K) and fine grained scintillators (NOvA), the LAr-TPC offers a higher
detection efficiency and a lower backgrounds, since virtually all channels may
be unambiguously recognized. The present proposal, called MODULAr, describes a
20 kt fiducial volume LAr-TPC, following very closely the technology developed
for the ICARUS-T60o, and is focused on the following activities, for which we
seek an extended international collaboration:
  (1) the neutrino beam from the CERN 400 GeV proton beam and an optimised horn
focussing, eventually with an increased intensity in the framework of the LHC
accelerator improvement program;
  (2) A new experimental area LNGS-B, of at least 50000 m3 at 10 km off-axis
from the main Laboratory, eventually upgradable to larger sizes. A location is
under consideration at about 1.2 km equivalent water depth;
  (3) A new LAr Imaging detector of at least 20 kt fiducial mass. Such an
increase in the volume over the current ICARUS T600 needs to be carefully
considered. It is concluded that a very large mass is best realised with a set
of many identical, independent units, each of 5 kt, ""cloning"" the technology of
the T600. Further phases may foresee extensions of MODULAr to meet future
physics goals.
  The experiment might reasonably be operational in about 4/5 years, provided a
new hall is excavated in the vicinity of the Gran Sasso Laboratory and adequate
funding and participation are made available.
","The Neutrino Factory and Muon Collider Collaboration (NFMCC), in collaboration with other European laboratories is proposing an innovative concept for a large liquid argon imaging detector that will be used as part of the future Neutrino Factory or Muon Collider experiments at CERN. The proposed project aims to build a very massive modular LArTPC using state-of-the-art technology. This would allow us to exploit the unique features offered by this type of detectors such as: excellent particle identification capabilities; high spatial resolution; good time resolution; hermetic detection volume; possibility to operate under intense magnetic fields etc., which are essential requirements for precision measurements on neutrino oscillations parameters. In addition, it could also provide important information about CP violation effects in the leptonic sector. 
 
 A detailed description of the physics case can be found here [1] . 
A technical proposal has been submitted [2] , including a preliminary design study [3] .
 


In order to demonstrate the feasibility of our approach we have built a small prototype [4] consisting of: two TPCs filled with 1 tonne each of liquid argon; one central cathode made out of carbon fibre; four wire planes located above and below the cathode plane; three wire planes placed along the sides of the chamber; a set of scintillator paddles surrounding the active volume of the chambers.",arxiv,bigscience bloomz,704.1422,0.3888888888888889,0.11764705882352941,0.7025641025641025,0.2661251791686574,1,1,1,0,0,1,1,0,0,0,0.25750537820303626,0.07002059740833329,0.29571984435797666,0.20075757575757575,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,2,1,1
Analysis on Heavy Quarkonia Transitions with Pion Emission in Terms of the QCD Multipole Expansion and Determination of Mass Spectra of Hybrids,"  One of the most important tasks in high energy physics is search for the
exotic states, such as glueball, hybrid and multi-quark states. The transitions
$\psi(ns)\to \psi(ms)+\pi\pi$ and $\Upsilon(ns)\to \Upsilon(ms)+\pi\pi$ attract
great attentions because they may reveal characteristics of hybrids. In this
work, we analyze those transition modes in terms of the theoretical framework
established by Yan and Kuang. It is interesting to notice that the intermediate
states between the two gluon-emissions are hybrids, therefore by fitting the
data, we are able to determine the mass spectra of hybrids. The ground hybrid
states are predicted as 4.23 GeV (for charmonium) and 10.79 GeV (for bottonium)
which do not correspond to any states measured in recent experiments, thus it
may imply that very possibly, hybrids mix with regular quarkonia to constitute
physical states. Comprehensive comparisons of the potentials for hybrids whose
parameters are obtained in this scenario with the lattice results are
presented.
","We study heavy quarkonium transitions to hybrid mesons by using the multipole expansion method within the framework of nonrelativistic potential models. We calculate decay widths for various types of transitions, including E1, M1, E2, M2, E3, M3, E4, M4, and S-wave pion emission processes. The results are compared with available experimental data as well as theoretical predictions based on other approaches such as lattice gauge theory. 
 
 In addition we determine mass spectra of hybrids by solving Schrödinger equations numerically. It is found that our calculated masses agree reasonably well with those obtained recently by lattice gauge theories. Finally, we discuss possible production mechanisms of hybrid states at future experiments. This work was supported by the National Natural Science Foundation of China under Grant No. 10675040. We thank Professors J. H. Chen and C. T. Chan for helpful discussions.",arxiv,bigscience bloomz,706.2074,0.2777777777777778,0.3949579831932773,0.14871794871794872,0.34925943621595795,1,1,0,0,0,0,1,0,0,0,0.09935333884791726,0.0668790801775752,0.11284046692607004,0.03787878787878788,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
"Flaming, bright galaxies along the filaments of A2744","  The existence of a clumpy, large-scale filamentary structure is at the basis
of the current paradigm of cosmic formation and evolution of clusters. The
star-formation history of galaxies falling into a cluster is altered as a
result of the environmental stresses. We investigate the relation between
substructure and properties of the galaxy population in a 30'x30' region
centered on the massive merging cluster A2744 at z~0.3. Multi-object
spectroscopy at low resolution and BVR photometry are used to detect the
presence of substructure through a Dressler-Schectman analysis and the
photometric redshift technique, respectively. Galaxies at the same photometric
redshift of the cluster are divided into red and blue according to their
distribution in the B-R vs. R colour-magnitude diagram. We identify two
large-scale filaments associated with A2744. Along these filaments, the
blue-to-red galaxy number ratio increases together with the cluster-centric
distance but peaks slightly beyond the cluster virial radius. The filaments
host a population of bright, large (i.e. more luminous than R* for the main
body of the cluster and with angular sizes of 13-22 $h_{70}^{-1}$ kpc) blue
galaxies that is hardly found among galaxies lying in a neighbouring
low-density environment at the same redshift of the cluster. These results can
be interpreted as a manifestation of galaxy harassment.
","We present new observations with Hubble Space Telescope (HST) and Spitzer Space Telescope to study the galaxy population in the cluster Abell 2744 at z = 0.308. We find that most of the red sequence galaxies are located on the edges of the X-ray emission peaks, while blue cloud galaxies are found mostly inside these regions. The spatial distribution of star formation rate density is also consistent with this picture. These results suggest that ram pressure stripping may be responsible for quenching star formation activity in many central galaxies. In addition, we identify several flaring galaxies which show strong [O iii]λ5007 line emissions in their spectra taken by HST/ACS grism. They have high SFRs ranging between 100 - 400 M⊙ yr−1 , but they do not appear as AGNs based on their optical colors or mid-infrared properties. Their large velocity dispersions indicate that they might be undergoing mergers.",arxiv,bigscience bloomz,705.0273,0.5,0.29411764705882354,0.4358974358974359,0.3779264214046823,1,1,0,0,1,1,1,0,0,0,0.11217795067413944,0.057975008252171584,0.1556420233463035,0.045454545454545456,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Mean-Field Magnetohydrodynamics of Accretion Disks,"  We consider the accretion process in a disk with magnetic fields that are
dragged in from the interstellar medium by gravitational collapse. Two
diffusive processes are at work in the system: (1) ""viscous"" torques exerted by
turbulent and magnetic stresses, and (2) ""resistive"" redistribution of mass
with respect to the magnetic flux arising from the imperfect conduction of
current. In steady state, self-consistency between the two rates of drift
requires that a relationship exists between the coefficients of turbulent
viscosity and turbulent resistivity. Ignoring any interactions with a stellar
magnetosphere, we solve the steady-state equations for a magnetized disk under
the gravitational attraction of a mass point and threaded by an amount of
magnetic flux consistent with calculations of magnetized gravitational collapse
in star formation. Our model mean-field equations have an exact analytical
solution that corresponds to magnetically diluted Keplerian rotation about the
central mass point. The solution yields the strength of the magnetic field and
the surface density as functions of radial position in the disk and their
connection with the departure from pure Keplerian rotation in representative
cases. We compare the predictions of the theory with the available observations
concerning T Tauri stars, FU Orionis stars, and low- and high-mass protostars.
Finally, we speculate on the physical causes for high and low states of the
accretion disks that surround young stellar objects. One of the more important
results of this study is the physical derivation of analytic expressions for
the turbulent viscosity and turbulent resistivity.
","We present the results of our numerical simulations of magnetized accretion disks in which we solve the mean-field magnetohydrodynamic equations for an axisymmetric disk with a prescribed radial distribution of angular momentum and mass fluxes, using the shearing-box approximation.  We find that the magnetic field is amplified by differential rotation to produce large-scale poloidal fields whose strength increases outward as $(r^{-3/2})$ (where $r$ is the radius). The toroidal component of the magnetic field also grows rapidly due to winding up of the poloidal field lines by shear flows. As a result, the plasma beta parameter decreases inwardly toward the central object. In addition, we find that the Maxwell stress associated with the magnetic field causes significant redistribution of angular momentum within the disk. This leads to enhanced transport of angular momentum outwards across the disk surface compared to viscous stresses alone.",arxiv,bigscience bloomz,705.0421,0.4444444444444444,0.24369747899159663,0.6358974358974359,0.35785953177257523,1,1,1,0,0,1,1,0,0,0,0.08943684267434995,0.08295243298274732,0.09727626459143969,0.045454545454545456,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Constraining dark energy via baryon acoustic oscillations in the (an)isotropic light-cone power spectrum,"  The measurement of the scale of the baryon acoustic oscillations (BAO) in the
galaxy power spectrum as a function of redshift is a promising method to
constrain the equation-of-state parameter of the dark energy w. To measure the
scale of the BAO precisely, a substantial volume of space must be surveyed. We
test whether light-cone effects are important and whether the scaling relations
used to compensate for an incorrect reference cosmology are in this case
sufficiently accurate. We investigate the degeneracies in the cosmological
parameters and the benefits of using the two-dimensional anisotropic power
spectrum. Finally, we estimate the uncertainty with which w can be measured by
proposed surveys at redshifts of about z=3 and z=1, respectively.
  In the simulated survey we find that light-cone effects are small and that
the simple scaling relations used to correct for the cosmological distortion
work fairly well even for large survey volumes. The analysis of the
two-dimensional anisotropic power spectra enables an independent determination
to be made of the apparent scale of the BAO, perpendicular and parallel to the
line of sight. This is essential for two-parameter w-models, such as the
redshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for
the matter and baryon density and Delta(H_0)=5% for the Hubble constant, we
estimate that the BAO measurements of future surveys around z=3 and z=1 will be
able to constrain, independently of other cosmological probes, a constant w to
~ 12% and ~ 11% (68% c.l.), respectively.
","We present an analysis of anisotropies in the angular correlation function and its Fourier transform, the angular power spectrum, using data from the Sloan Digital Sky Survey III Baryonic Oscillation Spectroscopic Survey (BOSS). We use this to constrain cosmological parameters including the equation-of-state parameter w{\displaystyle w} for dark energy as well as the matter density $\Omega_{m}$ and Hubble constant $H_{0}$. The results are consistent with previous measurements but have smaller statistical errors due to our larger sample size. In addition we find that the inclusion of redshift-space distortions improves constraints on all three parameters by about 10% compared to those obtained without them. This is because the effect of these distortions can be accurately modeled at low redshifts where they dominate over other effects such as gravitational lensing or non-linear evolution. 
The full version of this article is available online at: http://arxiv.org/abs/1306.5995",arxiv,bigscience bloomz,705.0354,0.4444444444444444,0.24369747899159663,0.6153846153846154,0.3607262302914477,1,1,0,0,0,1,1,1,0,0,0.16343368910234235,0.081037319469837,0.22568093385214008,0.06818181818181818,1,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The interplay between radio galaxies and cluster environment,"  By combining the REFLEX and NORAS cluster datasets with the NVSS radio
catalogue, we obtain a sample of 145, z<0.3, X-ray selected clusters brighter
than 3 10^(-12) erg/s/cm^2 that show a central radio emission above 3 mJy. For
virial masses M_vir<~10^(14.5) M_sun, 11 clusters out of 12 (corresponding to
92% of the systems) are inhabited by a central radio source. This fraction
decreases with higher masses as M_vir^(-0.4) and suggests that the majority of
X-ray selected clusters host in their centre a radio source brighter than about
10^(20) W/Hz/sr. A division of the sample into clusters harbouring either
point-like or an extended radio-loud AGN reveals that the steepening of the
L_X-T relation for low-temperature clusters is strongly associated with the
presence of central radio objects with extended jets and/or lobe structures. In
the latter case, L_X\propto T^(4) while for point-like sources one recovers an
approximately self-similar relation L_X\propto T^(2.3). Monte Carlo simulations
show that the steepening of the L_X-T relation is not caused by clusters being
under-luminous in the X-ray band, but rather by overheating, most likely caused
by the interplay between the extended radio structures and the intracluster
medium. In the case of low-mass systems, we also find a tight correlation
between radio luminosity and cluster temperature. The effects of the central
radio source on the thermal state of a cluster become less important with
increasing cluster mass. (Abridged) The luminosity distribution of the cluster
radio population differs from that of all radio sources, as there is a deficit
of low-luminosity (L_R<~10^(22) W/Hz/sr) objects, while the number of
high-luminosity ones is boosted. The net effect on the radio luminosity
function is of a flattening at all luminosities L_R<~ 10^(24) W/Hz/sr.
","We present the results of an optical spectroscopic survey of radio galaxies in clusters at redshifts z=0.4-0.8, carried out with the William Herschel Telescope (WHT). We find that the fraction of AGN-powered radio galaxies decreases towards higher galaxy density environments within the clusters. This is consistent with previous studies which have found evidence for environmental quenching of star formation activity among massive galaxies. However we also find that there are many examples where powerful radio sources reside in dense regions without any obvious signs of being environmentally suppressed. These objects may be undergoing rapid evolution or they could represent a population of recently accreted field galaxies whose properties are still evolving to resemble those of their local counterparts. The sample consists of 20 radio galaxies selected from the VLA-COSMOS 3 GHz Large Project catalogue (Smolčić et al., 2009) using the following criteria: 1) They lie in one of four X-ray luminous clusters at 0.4 < z < 0.8; 2) Their radio luminosity lies above L(3GHz) = 10 25 W Hz-1; 3) They do not show strong emission lines indicative of ongoing nuclear activity; 4) They were observed during our WHT run on 2010 May 24-25.",arxiv,bigscience bloomz,705.0574,0.5,0.24369747899159663,0.8102564102564103,0.5126612517916866,1,1,0,0,0,1,1,1,0,0,0.09532074423714801,0.22132439081815092,0.0933852140077821,0.2159090909090909,0,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Two-photon transitions in hydrogen and cosmological recombination,"  We study the two-photon process for the transitions ns --> 1s and nd --> 1s
in hydrogen up to large n. For n<=20 we provide simple analytic fitting
formulae to describe the non-resonant part of the two-photon emission profiles.
Combining these with the analytic form of the cascade-term yields a simple and
accurate description of the full two-photon decay spectrum, which only involves
a sum over a few intermediate states. We demonstrate that the cascade term
naturally leads to a nearly Lorentzian shape of the two-photon profiles in the
vicinity of the resonances. However, due to quantum-electrodynamical
corrections, the two-photon emission spectra deviate significantly from the
Lorentzian shape in the very distant wings of the resonances. We investigate up
to which distance the two-photon profiles are close to a Lorentzian and discuss
the role of the interference term. We then analyze how the deviation of the
two-photon profiles from the Lorentzian shape affects the dynamics of
cosmological hydrogen recombination. Since in this context the escape of
photons from the Lyman-alpha resonance plays a crucial role, we concentrate on
the two-photon corrections in the vicinity of the Lyman-alpha line. Our
computations show that the changes in the ionization history due to the
additional two-photon process from high shell (n>2) likely do not reach the
percent-level. For conservative assumptions we find a correction DN_e/N_e~-0.4%
at redshift z~1160. This is numerically similar to the result of another recent
study; however, the physics leading to this conclusion is rather different. In
particular, our calculations of the effective two-photon decay rates yield
significantly different values, where the destructive interference of the
resonant and non-resonant terms plays a crucial role in this context (abridged)
","We present the results of our calculation for two-photon transition rates between excited states of atomic hydrogen, including all relevant bound-bound and bound-free processes. We use these results to calculate the evolution of the number density of neutral hydrogen atoms during cosmic reionization. The main goal is to study how this process depends on the properties of the first stars that ionize the universe. 
 
 In particular we focus on the effect of different stellar initial mass functions (IMF) on the ionization history of the universe. For example, if massive stars are more numerous than low-mass ones then they will produce more photons per unit time which can lead to faster reionization. On the other hand, if most of the energy released by the first stars goes into winds or supernovae explosions rather than radiation then less UV photons would be produced leading to slower reionization. Our calculations show that the IMF has only minor effects on the overall duration of reionization but it does affect its detailed shape.",arxiv,bigscience bloomz,705.3033,0.5555555555555556,0.29411764705882354,0.7948717948717948,0.43526039178213094,1,1,1,0,0,1,1,0,0,0,0.07605681241368675,0.03878077236861252,0.07003891050583658,0.030303030303030304,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1
Aid to Percutaneous Renal Access by Virtual Projection of the Ultrasound Puncture Tract onto Fluoroscopic Images,"  Background and Purpose: Percutaneous renal access in the context of
percutaneous nephrolithotomy (PCNL) is a difficult technique, requiring rapid
and precise access to a particular calix. We present a computerized system
designed to improve percutaneous renal access by projecting the ultrasound
puncture tract onto fluoroscopic images. Materials and Methods: The system
consists of a computer and a localizer allowing spatial localization of the
position of the various instruments. Without any human intervention, the
ultrasound nephrostomy tract is superimposed in real time onto fluoroscopic
images acquired in various views. Results: We tested our approach by laboratory
experiments on a phantom. Also, after approval by our institution's Ethics
Committee, we validated this technique in the operating room during PCNL in one
patient. Conclusion: Our system is reliable, and the absence of
image-processing procedures makes it robust. We have initiated a prospective
study to validate this technique both for PCNL specialists and as a learning
tool.
","The aim of this study was to evaluate whether virtual ultrasound (US) puncture tracts can improve percutaneous renal access in patients with complex anatomy and difficult-to-visualize calices on fluoroscopy.  In total, 50 consecutive patients underwent US-guided percutaneous nephrolithotomy using an in-room C-arm system for real-time image guidance. The procedure was performed under general anesthesia or conscious sedation. A pre-procedural CT scan was obtained without intravenous contrast medium injection. Using OsiriX MD software, two urologists delineated the kidney contour and identified all visible calices. Subsequently, they projected their findings onto the live fluoroscopic images during the procedure. They were asked to perform punctures into each calyx that could be visualized on fluoroscopy. After successful puncture, stone removal was attempted through the sheath inserted via the needle. Successful puncture was defined as reaching at least one calix. Overall success rate was 88%. No complications occurred related to the use of the US puncture tract projections. This technique may help urologists to achieve safe and efficient percutaneous renal access even if only few calices are clearly seen on fluoroscopy.",arxiv,bigscience bloomz,705.4412,0.3888888888888889,0.546218487394958,0.15384615384615385,0.4581939799331104,1,1,1,0,1,1,1,0,0,0,0.04865808252869863,0.052614222656258945,0.04669260700389105,0.030303030303030304,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
J-class operators and hypercyclicity,"  The purpose of the present work is to treat a new notion related to linear
dynamics, which can be viewed as a ""localization"" of the notion of
hypercyclicity. In particular, let $T$ be a bounded linear operator acting on a
Banach space $X$ and let $x$ be a non-zero vector in $X$ such that for every
open neighborhood $U\subset X$ of $x$ and every non-empty open set $V\subset X$
there exists a positive integer $n$ such that $T^{n}U\cap V\neq\emptyset$. In
this case $T$ will be called a $J$-class operator. We investigate the class of
operators satisfying the above property and provide various examples. It is
worthwhile to mention that many results from the theory of hypercyclic
operators have their analogues in this setting. For example we establish
results related to the Bourdon-Feldman theorem and we characterize the
$J$-class weighted shifts. We would also like to stress that even non-separable
Banach spaces which do not support topologically transitive operators, as for
example $l^{\infty}(\mathbb{N})$, do admit $J$-class operators.
","We study the connection between J-operators, which are defined as bounded linear operators on Banach spaces that satisfy the functional equation $T_J(x+y) = T_J(x) + T_J(y)$ for all $x, y \in X$, and hypercyclic operators. 
The main result is that if $X$ has an unconditional basis then every operator in the commutator ideal generated by any J-operator is hypercyclic (and even supercyclic). This generalizes earlier results due to Ansari, Bernal-González, Herrero-Burton, Johnson, Lancien, Salas, Shkarin, and Sourour.  We also show how this theorem can be used to prove that certain classes of operators are not hypercyclic or have only trivial hypercyclic vectors. Finally we give some examples illustrating our results. The research leading to these results was supported by EPSRC grant EP/D076446/1",arxiv,bigscience bloomz,704.3354,0.3333333333333333,0.24369747899159663,0.2205128205128205,0.30339225991399904,1,1,0,0,0,1,1,0,0,0,0.19128288271457958,0.1223253142594887,0.22957198443579765,0.06060606060606061,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Phase structure of a surface model on dynamically triangulated spheres with elastic skeletons,"  We find three distinct phases; a tubular phase, a planar phase, and the
spherical phase, in a triangulated fluid surface model. It is also found that
these phases are separated by discontinuous transitions. The fluid surface
model is investigated within the framework of the conventional curvature model
by using the canonical Monte Carlo simulations with dynamical triangulations.
The mechanical strength of the surface is given only by skeletons, and no
two-dimensional bending energy is assumed in the Hamiltonian. The skeletons are
composed of elastic linear-chains and rigid junctions and form a
compartmentalized structure on the surface, and for this reason the vertices of
triangles can diffuse freely only inside the compartments. As a consequence, an
inhomogeneous structure is introduced in the model; the surface strength inside
the compartments is different from the surface strength on the compartments.
However, the rotational symmetry is not influenced by the elastic skeletons;
there is no specific direction on the surface. In addition to the three phases
mentioned above, a collapsed phase is expected to exist in the low bending
rigidity regime that was not studied here. The inhomogeneous structure and the
fluidity of vertices are considered to be the origin of such variety of phases.
","We study the phase structure of a surface model defined by an energy functional that consists of two competing terms, one favoring smooth surfaces and another penalizing their curvature fluctuations. The latter is modeled as a harmonic term in the local mean curvature. We show that this model exhibits three phases depending on temperature T . At high temperatures (T > Tc), it behaves like a liquid; at low temperatures (T < Ts) it forms a solid-like state where all triangles are equilateral; for intermediate temperatures (Ts<T< Tc) we find a disordered glassy phase which can be characterized by its fractal dimension D = 2 − H ≈ 1.7 ± 0.1. This value agrees well with numerical simulations performed recently by other authors. 
 
 In addition to these results, our analysis also provides evidence for a first-order transition between the ordered and disordered states. Finally, we discuss possible extensions of our approach towards more realistic models of biomembranes.",arxiv,bigscience bloomz,704.0493,0.4444444444444444,0.29411764705882354,0.4,0.4037267080745342,0,1,1,0,0,1,1,1,0,0,0.05622313967710581,0.1610166810082874,0.05058365758754864,0.19318181818181818,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Dirichlet or Potts ?,"  When modeling the distribution of a set of data by a mixture of Gaussians,
there are two possibilities: i) the classical one is using a set of parameters
which are the proportions, the means and the variances; ii) the second is to
consider the proportions as the probabilities of a discrete valued hidden
variable. In the first case a usual prior distribution for the proportions is
the Dirichlet which accounts for the fact that they have to sum up to one. In
the second case, to each data is associated a hidden variable for which we
consider two possibilities: a) assuming those variables to be i.i.d. We show
then that this scheme is equivalent to the classical mixture model with
Dirichlet prior; b) assuming a Markovian structure. Then we choose the simplest
markovian model which is the Potts distribution. As we will see this model is
more appropriate for the case where the data represents the pixels of an image
for which the hidden variables represent a segmentation of that image. The main
object of this paper is to give some details on these models and different
algorithms used for their simulation and the estimation of their parameters.
  Key Words: Mixture of Gaussians, Dirichlet, Potts, Classification,
Segmentation.
","We consider the problem of learning an unknown distribution over binary strings, where each string is generated by sampling independently at random with replacement according to some fixed probability vector . We show that if we are given samples drawn iid from , then it can be learned in polynomial time using standard statistical techniques (e.g., maximum likelihood). However, when the number of possible values for each bit grows large, this approach fails because there may not exist any sample which contains all possible values for every bit. In such cases, we propose a novel algorithm based on Gibbs sampling and prove its correctness under certain conditions. Finally, we present experimental results demonstrating our method's effectiveness. The main contribution of this work lies in showing how to learn distributions over combinatorial objects like graphs and trees. This is achieved by first reducing these problems into learning distributions over binary strings, and then applying our proposed algorithms. Learning distributions over combinatorial objects has many applications including data mining, computer vision, bioinformatics, etc. .",arxiv,bigscience bloomz,705.245,0.3888888888888889,0.3949579831932773,0.4307692307692308,0.44672718585762067,1,0,1,0,0,1,0,0,0,1,0.13281099200374244,0.08248080640985987,0.12840466926070038,0.05303030303030303,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1
Two Energy Release Processes for CMEs: MHD Catastrophe and Magnetic Reconnection,"  It remains an open question how magnetic energy is rapidly released in the
solar corona so as to create solar explosions such as solar flares and coronal
mass ejections (CMEs). Recent studies have confirmed that a system consisting
of a flux rope embedded in a background field exhibits a catastrophic behavior,
and the energy threshold at the catastrophic point may exceed the associated
open field energy. The accumulated free energy in the corona is abruptly
released when the catastrophe takes place, and it probably serves as the main
means of energy release for CMEs at least in the initial phase. Such a release
proceeds via an ideal MHD process in contrast with nonideal ones such as
magnetic reconnection. The catastrophe results in a sudden formation of
electric current sheets, which naturally provide proper sites for fast magnetic
reconnection. The reconnection may be identified with a solar flare associated
with the CME on one hand, and produces a further acceleration of the CME on the
other. On this basis, several preliminary suggestions are made for future
observational investigations, especially with the proposed KuaFu satellites, on
the roles of the MHD catastrophe and magnetic reconnection in the magnetic
energy release associated with CMEs and flares.
","We propose that the energy release process in coronal mass ejections (CMEs) is due to two different physical mechanisms, magnetic reconnection and catastrophic loss of equilibrium driven by ideal magnetohydrodynamic (MHD) instabilities.  The first mechanism releases free magnetic energy stored in the corona into kinetic energy of plasma flows during solar eruptive events such as flares or CMEs. This mechanism has been studied extensively using numerical simulations based on resistive MHD models with various levels of complexity ranging from simple two-dimensional configurations to more realistic three-dimensional ones. In this work we focus our attention on the second mechanism which involves rapid conversion of magnetic field energy into thermal energy through an explosive reconfiguration of the magnetic topology. We show how this mechanism can be modeled analytically within the framework of ideal MHD theory. Our results suggest that both processes are likely to operate simultaneously but at different stages of evolution of the erupting flux rope.",arxiv,bigscience bloomz,705.3886,0.3333333333333333,0.24369747899159663,0.41025641025641024,0.39799331103678937,1,0,0,0,0,1,1,0,0,0,0.07531834208630458,0.05436428200807271,0.06614785992217899,0.03787878787878788,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
A Pair of Bootes: A New Milky Way Satellite,"  As part of preparations for a southern sky search for faint Milky Way dwarf
galaxy satellites, we report the discovery of a stellar overdensity in the
Sloan Digital Sky Survey Data Release 5, lying at an angular distance of only
1.5 degrees from the recently discovered Bo{\""o}tes dwarf. The overdensity was
detected well above statistical noise by employing a sophisticated data mining
algorithm and does not correspond to any catalogued object. Overlaid isochrones
using stellar population synthesis models show that the color-magnitude diagram
of that region has the signature of an old (12 Gyr), metal-poor (${\rm
Fe/H}\approx-2.0$) stellar population at a tentative distance of 60 kpc,
evidently the same heliocentric distance as the Bo\""otes dwarf. We estimate the
new object to have a total magnitude of $M_{V}\sim-3.1\pm1.1$ mag and a
half-light radius of $r_{h}=4'.1\pm1'.6$ ($72\pm28$ pc) placing it in an
apparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies,
occupied only by another recently discovered Milky Way Satellite, Coma
Berenices.
","We report the discovery of a new satellite galaxy, dubbed ""A pair of bootes"" (ApoBootes), orbiting around our Galaxy at a distance of about 300 kpc in projection and with an estimated mass of 1.5 x 10^10 M_sun . ApoBootes is located on the opposite side of the Galactic center to the Magellanic Clouds and has a very low surface brightness. We have used deep near-infrared images taken by the VISTA telescope as part of the Vista Variables in the Via Lactea survey to identify this object. The photometric properties are consistent with those expected for a dwarf spheroidal galaxy. This work was supported by the Australian Research Council Discovery Project funding scheme under grant DP130104011. We present evidence that ApoBootes may be associated with a previously known overdensity of stars discovered by Belokurov et al. (2007) using SDSS data.",arxiv,bigscience bloomz,705.1378,0.16666666666666666,0.29411764705882354,0.19487179487179487,0.35499283325370284,1,1,0,0,1,1,1,0,0,0,0.17527778911966466,0.0952704819714123,0.13229571984435798,0.06818181818181818,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Oscillation thresholds for ""strinking outwards"" reeds coupled to a resonator","  This paper considers a ""striking outwards"" reed coupled to a resonator. This
expression, due to Helmholtz, is not discussed here : it corresponds to the
most common model of a lip-type valve, when the valve is assumed to be a one
degree of freedom oscillator. The presented work is an extension of the works
done by Wilson and Beavers (1974), Tarnopolsky (2000). The range of the playing
frequencies is investigated. The first results are analytical : when no losses
are present in the resonator, it is proven that the ratio between the threshold
frequency and the reed resonance frequency is found to be necessarily within
the interval between unity and the square root of 3. This is a musical sixth.
Actually the interval is largely smaller, and this is in accordance with e.g.
the results by Cullen et al.. The smallest blowing pressure is found to be
directly related to the quality factor of the reed. Numerical results confirm
these statements, and are discussed in comparison with previous ones by Cullen
et al (2000).
","We study the dynamics of an ensemble of elastically-coupled reed oscillators driven by a common acoustic field, and show that they can exhibit striking phenomena such as synchronized chaos or phase-locked states with multiple incommensurate frequencies. We also demonstrate how these effects are modified when the system is connected to a passive resonator. The results presented here may be relevant to understanding the behavior of biological systems such as colonies of fireflies or neurons. 
 
 In recent years there has been growing interest in studying nonlinear dynamical systems composed of many interacting elements [1-3]. These studies have revealed new collective behaviors which cannot occur in single element systems [4] . Examples include synchronization [5-7] , clustering [8] , chimera states [9] , and spatiotemporal patterns [10-12] .
In this work we consider a model consisting of N identical elastically-coupled reed-oscillators [13] driven by a common acoustic wavefield [14-16] (see Fig 1) . Each oscillator consists of two vibrating plates separated by a thin layer of air [17] . When the pressure difference across one plate exceeds its critical value, it begins to expand rapidly until the restoring force due to the other plate causes it to contract again. This process repeats periodically resulting in self-sustained oscillations at a frequency determined by the geometry of the device [18] . 
The coupling between neighboring oscillators arises because each oscillator acts like a small loudspeaker radiating sound into the surrounding medium [19-21] . As a result, nearby oscillators experience similar driving forces and their natural frequencies become locked [22] . If all oscillators lock onto the same frequency then the entire system behaves coherently; if different groups of oscillators lock on to different frequencies then the system exhibits spatially-extended multistability [23] .",arxiv,bigscience bloomz,705.4242,0.5,0.596638655462185,0.26153846153846155,0.7792642140468228,1,1,1,0,0,1,1,1,0,0,0.12256305501013655,0.05325692440512501,0.15953307392996108,0.06060606060606061,3,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Observations towards early-type stars in the ESO-POP survey: II -- searches for intermediate and high velocity clouds,"  We present CaII K and TiII optical spectra of early-type stars taken mainly
from the UVES Paranal Observatory Project, plus HI 21-cm spectra from the
Vila-Elisa and Leiden-Dwingeloo surveys, which are employed to obtain distances
to intermediate and high velocity clouds. HI emission at a velocity of -117
km/s towards the sightline HD 30677 with NHI=1.7x10^19 cm-2 has no
corresponding CaII K absorption, which has a signal-to-noise (S/N) ratio of
610. The star has a spectroscopically determined distance of 2.7-kpc, and hence
sets this as a firm lower distance limit towards Anti-Centre cloud ACII.
Towards another sightline (HD 46185), HI at +122 km/s and NHI=1.2x10^19 cm-2 is
seen. The CaII K spectrum has a S/N = 780, although no absorption is observed
at the cloud velocity. This similarly places a firm lower distance limit of
2.9-kpc towards this parcel of gas that may be an intermediate velocity cloud.
The lack of intermediate velocity (IV) CaII K absorption towards HD 196426 at a
S/N = 500 reinforces a lower distance limit of 700-pc towards this part of
Complex gp, where NHI is 1.1x10^19 cm-2 and velocity is +78 km/s. Additionally,
no IV CaII K is seen in absorption in the spectrum of HD 19445, which is strong
in HI with NHI=8x10^19 cm-2 at -42 km/s, placing a firm although uninteresting
lower distance limit of 39-pc to this part of IV South. Finally, no HV CaII K
absorption is seen towards HD 115363 at a S/N = 410, placing a lower distance
of 3.2-kpc towards the HVC gas at velocity of +224 km/s and NHI=5.2x10^19 cm-2.
This gas is in the same region of the sky as complex WE (Wakker 2001), but at
higher velocities. The non-detection of CaII K absorption sets a lower distance
of 3.2-kpc towards the HVC, which is unsurprising if this feature is indeed
related to the Magellanic System.
","We present new results on interstellar absorption lines toward early type stars observed with UVES at VLT, as part of the ESO-POP project (ESO program 085.D-0571). We have searched for high-velocity clouds (HVCs) by looking for blueshifted components in the MgII doublet line profiles. The sample consists of 16 OB-stars located within 1 kpc distance from Earth. In addition to previously known HVCs we find several new ones. Some of these are associated with nearby galaxies while others may be related to Galactic halo gas. A comparison between our data set and previous surveys shows that there is no significant difference in the number density distribution of HVCs along different sightlines. This suggests that most of them are small structures which do not cover much solid angle around their host galaxy or star. 
 
 Keywords: Interstellar medium",arxiv,bigscience bloomz,704.1315,0.5555555555555556,0.3445378151260504,0.9641025641025641,0.3435260391782131,1,1,0,0,0,1,1,1,0,0,0.09471550652109612,0.06654413251713183,0.08171206225680934,0.056818181818181816,0,1,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Ray-tracing and physical-optics analysis of the aperture efficiency in a radio telescope,"  The performance of telescope systems working at microwave or visible/IR
wavelengths is typically described in terms of different parameters according
to the wavelength range. Most commercial ray tracing packages have been
specifically designed for use with visible/IR systems and thus, though very
flexible and sophisticated, do not provide the appropriate parameters to fully
describe microwave antennas, and thus to compare with specifications. In this
work we demonstrate that the Strehl ratio is equal to the phase efficiency when
the apodization factor is taken into account. The phase efficiency is the most
critical contribution to the aperture efficiency of an antenna, and the most
difficult parameter to optimize during the telescope design. The equivalence
between the Strehl ratio and the phase efficiency gives the designer/user of
the telescope the opportunity to use the faster commercial ray-tracing software
to optimize the design. We also discuss the results of several tests performed
to check the validity of this relationship that we carried out using a
ray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3,
applied to three different telescope designs that span a factor of $\simeq 10
in terms of D/lambda. The maximum measured discrepancy between phase efficiency
and Strehl ratio varies between $\simeq 0.4 and 1.9 up to an offset angle of
>40 beams, depending on the optical configuration, but it is always less than
0.5 where the Strehl ratio is >0.95.
","We present an analytical model for calculating the aperture efficiency of a reflector antenna with circularly polarized feeds, based on ray tracing through the feed-horn optics and physical optics (PO) at the aperture plane. The PO method is used to calculate the electric field distribution over the aperture surface by solving Maxwell's equations using Green functions. We show that this approach can be applied to any type of feed horns, including corrugated conical horns or dual-polarized log-periodic dipole arrays. This work was motivated by our recent study of aperture efficiencies of two different types of antennas operating at 1.4 GHz: a single-dish radio telescope equipped with a corrugated conical feed horn and a multi-element interferometer consisting of eight log-periodic dipole array elements. In both cases we found good agreement between numerical results obtained with our new model and experimental data. 
 
 Keywords: Antenna design",arxiv,bigscience bloomz,705.3379,0.3333333333333333,0.24369747899159663,0.5538461538461539,0.3635929288103201,0,1,0,0,0,1,1,1,0,1,0.10738488713865262,0.11347157632571553,0.0933852140077821,0.08333333333333333,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Spinons and triplons in spatially anisotropic frustrated antiferromagnets,"  The search for elementary excitations with fractional quantum numbers is a
central challenge in modern condensed matter physics. We explore the
possibility in a realistic model for several materials, the spin-1/2 spatially
anisotropic frustrated Heisenberg antiferromagnet in two dimensions. By
restricting the Hilbert space to that expressed by exact eigenstates of the
Heisenberg chain, we derive an effective Schr\""odinger equation valid in the
weak interchain-coupling regime. The dynamical spin correlations from this
approach agree quantitatively with inelastic neutron measurements on the
triangular antiferromagnet Cs_2CuCl_4. The spectral features in such
antiferromagnets can be attributed to two types of excitations: descendents of
one-dimensional spinons of individual chains, and coherently propagating
""triplon"" bound states of spinon pairs. We argue that triplons are generic
features of spatially anisotropic frustrated antiferromagnets, and arise
because the bound spinon pair lowers its kinetic energy by propagating between
chains.
","We study the spin-1/2 Heisenberg model on the square lattice with nearest-neighbor (NN) exchange interactions J1, J2, and J3 along x-, y-, and z-directions respectively. We show that this system can be mapped onto an effective spin-1/2 XXZ chain by using the Holstein-Primakoff transformation for spins 1/2. The ground state phase diagram is obtained numerically by exact diagonalization method. In addition to the Néel ordered phase at small values of |J2/J1| < 0.5, we find two different types of quantum disordered phases depending upon the value of J3/J2. For large values of J3/J2 > 1.0, there exists a gapless singlet phase where all excitations are gapped out except one massless excitation corresponding to the Goldstone mode associated with the spontaneous breaking of translational symmetry. On the other hand, when J3/J2 < 0.5, there appears another type of disordered phase which has a finite energy gap between the ground state and first excited states. This phase corresponds to a valence bond solid phase where each site forms singlets with its NN sites only.  Finally, we also discuss how these results may be relevant to understand the magnetic properties of some quasi-two-dimensional organic compounds such as EtMe3Sb[Pd(dmit)2]2 and κ-(BEDT-TTF)2Cu[N(CN)2]Cl.",arxiv,bigscience bloomz,706.2012,0.2777777777777778,0.3445378151260504,0.09230769230769231,0.5183946488294315,0,1,1,0,0,1,1,0,0,0,0.05862986027321094,0.08488867061879252,0.0622568093385214,0.08712121212121213,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A general approach to statistical modeling of physical laws: nonparametric regression,"  Statistical modeling of experimental physical laws is based on the
probability density function of measured variables. It is expressed by
experimental data via a kernel estimator. The kernel is determined objectively
by the scattering of data during calibration of experimental setup. A physical
law, which relates measured variables, is optimally extracted from experimental
data by the conditional average estimator. It is derived directly from the
kernel estimator and corresponds to a general nonparametric regression. The
proposed method is demonstrated by the modeling of a return map of noisy
chaotic data. In this example, the nonparametric regression is used to predict
a future value of chaotic time series from the present one. The mean predictor
error is used in the definition of predictor quality, while the redundancy is
expressed by the mean square distance between data points. Both statistics are
used in a new definition of predictor cost function. From the minimum of the
predictor cost function, a proper number of data in the model is estimated.
","We present an overview of the theory and practice of nonparametric regression, with emphasis on its application in physics. We begin by introducing some basic concepts such as kernel density estimation (KDE) and spline smoothing. Then we discuss how these methods can be used for data analysis problems that arise frequently in physics experiments. Finally, we provide several examples illustrating our discussion. The goal is not only to introduce readers unfamiliar with this topic but also to give physicists who are familiar with it a new perspective on their work. This article serves as a companion piece to another one entitled ""Statistical Modeling of Physical Laws"" which appeared earlier in ArXiv.org. In that article, we introduced the concept of parametric models and discussed how they can be applied to solve various types of data analysis problems encountered in physics experiments. Parametric models assume that all unknown parameters have been determined exactly beforehand; however, in many cases there may exist uncertainty about those values due to limited experimental precision or lack of knowledge. Nonparametric regression provides a way around this problem by allowing us to estimate the functional form of the underlying model without making any assumptions about the exact value of each parameter.",arxiv,bigscience bloomz,704.0089,0.5,0.3949579831932773,0.2205128205128205,0.5355948399426661,0,0,0,0,0,1,0,1,0,0,0.04341692093314855,0.06237511955617216,0.054474708171206226,0.056818181818181816,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1
"Constraints on the merging timescale of luminous red galaxies, or, where do all the halos go?","  In the LCDM cosmology dark matter halos grow primarily through the accretion
of smaller halos. Much of the mass in a halo of 10^14Msun comes in through
accretion of ~10^13Msun halos. If each such halo hosted one luminous red galaxy
(LRG) then the accretion of so many halos is at odds with the observed number
of LRGs in clusters unless these accreted LRGs merge or disrupt on relatively
short timescales (~2Gyr). These timescales are consistent with classical
dynamical friction arguments, and imply that 2-3 LRGs have merged or disrupted
within each halo more massive than 10^14Msun by z=0. The total amount of
stellar mass brought into these massive halos by z=0 is consistent with
observations once the intracluster light (ICL) is included. If disrupted LRGs
build up the ICL, then the hierarchical growth of massive halos implies that a
substantial amount of ICL should also surround satellite LRGs, as suggested by
recent observations of the Virgo cluster. Finally, we point out that these
results are entirely consistent with a non-evolving clustering strength and
halo occupation distribution, and note that observations of the latter in fact
support the hypothesis that merging/disruption of massive galaxies does indeed
take place at late times.
","We present new constraints on the merger rate density and mass ratio distribution for luminous red galaxies (LRGs) using data from the Sloan Digital Sky Survey Data Release 7 (SDSS DR7). We use these results to place limits on the number of massive dark matter haloes that are not associated with LRG hosts in the local universe. The halo occupation model we employ is based upon an extension of the HOD formalism developed by Zheng et al. (2005) , which allows us to simultaneously constrain both the mean occupation function and its scatter at fixed luminosity as well as the fraction of satellite galaxies that have been recently accreted into their host haloes. Our analysis indicates that there exists a significant population of massive haloes that are not occupied by LRGs within our sample volume. This result suggests that either many of the most massive haloes were assembled very early during cosmic history and/or that they contain only low-mass galaxies.",arxiv,bigscience bloomz,706.052,0.3333333333333333,0.24369747899159663,0.39487179487179486,0.4123268036311515,1,1,0,0,0,1,1,0,0,0,0.10994971584932375,0.054590566232071897,0.10894941634241245,0.05303030303030303,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Carrier-carrier entanglement and transport resonances in semiconductor quantum dots,"  We study theoretically the entanglement created in a scattering between an
electron, incoming from a source lead, and another electron bound in the ground
state of a quantum dot, connected to two leads. We analyze the role played by
the different kinds of resonances in the transmission spectra and by the number
of scattering channels, into the amount of quantum correlations between the two
identical carriers. It is shown that the entanglement between their energy
states is not sensitive to the presence of Breit-Wigner resonances, while it
presents a peculiar behavior in correspondence of Fano peaks: two close maxima
separated by a minimum, for a two-channel scattering, a single maximum for a
multi-channel scattering. Such a behavior is ascribed to the different
mechanisms characterizing the two types of resonances. Our results suggest that
the production and detection of entanglement in quantum dot structures may be
controlled by the manipulation of Fano resonances through external fields.
","We study the dynamics of carrier-carrier interactions in semiconductor quantum dots (QDs) by solving numerically the time-dependent Schrödinger equation for two interacting electrons or holes confined to an anisotropic QD potential well. We find that, depending on the initial state, there are three different regimes of interaction between carriers which can be classified as weak coupling regime with no significant energy exchange; strong coupling regime where one electron is excited into higher states while another remains in its ground state; and finally, intermediate regime where both carriers undergo transitions simultaneously but at slightly different frequencies. In addition we show how these results depend on the dot shape and size parameters. Finally, we discuss possible applications of our findings such as generation of entangled photon pairs via biexciton decay. Quantum dots have been studied extensively over past decade due to their unique optical properties [1] . The most important feature of QDs is the possibility of controlling their emission wavelength through variation of their size [2] , allowing them to operate within a wide range of wavelengths [3] .
In this work we focus on studying the effects of carrier-carrier interactions [4] in semiconductor QDs using numerical solution of timedependent Schrödinger equations [5] . Carriers interact strongly when they occupy neighboring single-particle levels [6] leading to formation of bound excitonic complexes [7, 8] . However, if carriers occupy distant single particle levels then their mutual Coulomb attraction leads to formation of virtual excitons [9] . These virtual excitons may either recombine radiatively [10] or non-radiatively [11] giving rise to Auger processes [12] . On the other hand, if carriers occupy adjacent single particle levels then their interaction becomes so strong that it cannot be treated perturbatively anymore [13] . This situation occurs e.g., during relaxation of photoexcited carriers [14] or in presence of external electric field [15] .",arxiv,bigscience bloomz,706.2312,0.2222222222222222,0.546218487394958,0.1641025641025641,0.8337314859053989,0,1,1,0,0,1,1,1,0,0,0.11751298157698145,0.11501604242543598,0.14396887159533073,0.1856060606060606,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Dyson Indices and Hilbert-Schmidt Separability Functions and Probabilities,"  A confluence of numerical and theoretical results leads us to conjecture that
the Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional
convex sets of complex and real two-qubit states (representable by 4 x 4
density matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning
are the modifications of two ansatze, recently advanced (quant-ph/0609006),
involving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11}
rho_{44})/(rho_{22} rho_{33}). We, now, set the separability function
S_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the
complex case -- conforming to a pattern we find, manifesting the Dyson indices
(1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2}
(nu). We also investigate the real and complex qubit-qutrit cases. Now, there
are two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}),
nu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably
coalesce into the product, eta = nu_1 nu_2 = rho_{11} \rho_{66}}{\rho_{33}
\rho_{44}}, so that the real and complex separability functions are again
univariate in nature.
","We introduce the concept of separability functions, which are generalizations of Dyson indices to arbitrary finite groups. We show that these functions can be used as indicators for quantum entanglement in mixed states. In particular we prove that separability probabilities vanish if and only if all separable pure state decompositions have vanishing Schmidt coefficients. This is an extension of the result by Peres-Horodecki on positive partial transpose matrices. Finally we present some explicit examples illustrating our results. The concept of separability functions was introduced recently [1] . These functions provide a generalization of Dyson indices [2] , which were originally defined for Lie algebras, to arbitrary finite groups. They play an important role in physics since they appear naturally when studying the properties of many-body systems with short-range interactions [3] .
In this work we study how separability functions behave under tensor products. It turns out that their behavior depends crucially on whether or not the group has Abelian subgroups. For example it follows directly from the definition that separability functions do not change at all under tensor product over Abelian groups. On the other hand there exist non-Abelian groups where separability functions increase exponentially under tensor product [4] . As another consequence of our analysis we obtain new bounds on the number of linearly independent separability functions [5] .",arxiv,bigscience bloomz,704.3723,0.2777777777777778,0.596638655462185,0.18974358974358974,0.5843287147634975,1,1,0,0,0,0,1,0,0,0,0.2890892831252597,0.03789760114118612,0.38910505836575876,0.03409090909090909,1,1,5,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Challenging the Cosmological Constant,"  We outline a dynamical dark energy scenario whose signatures may be
simultaneously tested by astronomical observations and laboratory experiments.
The dark energy is a field with slightly sub-gravitational couplings to matter,
a logarithmic self-interaction potential with a scale tuned to $\sim 10^{-3}
{\rm eV}$, as is usual in quintessence models, and an effective mass $m_\phi$
influenced by the environmental energy density. Its forces may be suppressed
just below the current bounds by the chameleon-like mimicry, whereby only outer
layers of mass distributions, of thickness $1/m_\phi$, give off appreciable
long range forces. After inflation and reheating, the field is relativistic,
and attains a Planckian expectation value before Hubble friction freezes it.
This can make gravity in space slightly stronger than on Earth. During the
matter era, interactions with nonrelativistic matter dig a minimum close to the
Planck scale. However, due to its sub-gravitational matter couplings the field
will linger away from this minimum until the matter energy density dips below
$\sim 10^{-12} {\rm eV}^4$. Then it starts to roll to the minimum, driving a
period of cosmic acceleration. Among the signatures of this scenario may be
dark energy equation of state $w \ne -1$, stronger gravity in dilute mediums,
that may influence BBN and appear as an excess of dark matter, and
sub-millimeter corrections to Newton's law, close to the present laboratory
limits.
","The cosmological constant is one of the most important parameters in modern physics, and its value has been determined by observations to be extremely small but nonzero.  In this article we will discuss how it can be explained as an effect of quantum gravity at very high energies. We will also show that if the universe underwent inflationary expansion after the Big Bang then there should exist primordial gravitational waves which could have observable effects on the cosmic microwave background radiation (CMBR). Finally, we will argue that these effects may provide us with new ways for testing the predictions of general relativity against those of alternative theories such as string theory or loop quantum gravity. The cosmological constant is one  of the most important parameters of modern physics. Its value was determined by observations to be incredibly small but non-zero. It plays a crucial role in our understanding of the evolution of the Universe since it determines whether the current accelerated expansion of space-time will continue forever or eventually slow down and stop. This question remains open despite many years of research into the nature of dark energy.",arxiv,bigscience bloomz,706.1977,0.4444444444444444,0.3445378151260504,0.5076923076923077,0.4925943621595796,0,1,0,0,1,1,1,0,0,0,0.14559617667868086,0.07898513268157964,0.14396887159533073,0.06439393939393939,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1
Low-temperature and high-temperature approximations for penetrable-sphere fluids. Comparison with Monte Carlo simulations and integral equation theories,"  The two-body interaction in dilute solutions of polymer chains in good
solvents can be modeled by means of effective bounded potentials, the simplest
of which being that of penetrable spheres (PSs). In this paper we construct two
simple analytical theories for the structural properties of PS fluids: a
low-temperature (LT) approximation, that can be seen as an extension to PSs of
the well-known solution of the Percus-Yevick (PY) equation for hard spheres,
and a high-temperature (HT) approximation based on the exact asymptotic
behavior in the limit of infinite temperature. Monte Carlo simulations for a
wide range of temperatures and densities are performed to assess the validity
of both theories. It is found that, despite their simplicity, the HT and LT
approximations exhibit a fair agreement with the simulation data within their
respective domains of applicability, so that they complement each other. A
comparison with numerical solutions of the PY and the hypernetted-chain
approximations is also carried out, the latter showing a very good performance,
except inside the core at low temperatures.
","We present low-temperature (LT) and high-temperature (HT) expansions for the excess internal energy, entropy, pressure, and chemical potential of hard-core penetrable-sphere (HCP-S) fluids in terms of the packing fraction $\eta$. The LT expansion is obtained by using an exact expression for the HCP-S pair correlation function at contact to calculate the virial coefficients up to order $(\eta^{10})$. We show that this approach yields results which are accurate over a wide range of temperatures and densities when compared against computer simulation data. In addition, we compare our results with those predicted by various integral equations including the Percus-Yevick approximation, the hypernetted chain closure, and the mean spherical approximation. Finally, we use the HT expansion to obtain analytical expressions for the thermodynamic properties of HCP-S fluids near their critical points. 
I. INTRODUCTORY REMARkS
The study of simple model systems has played an important role in understanding many aspects of condensed matter physics [1] . One such system consists of particles interacting via repulsive potentials whose cores can be penetrated [2] , i.e., they do not have any finite minimum separation distance between them. This class of models includes both soft spheres [3] as well as hard-core penetrable-spheres [4] .
In recent years there has been renewed interest in studying these types of interactions due to their relevance in describing colloidal suspensions [5] , granular materials [6] , and protein solutions [7, 8] . For example, it was shown recently [9] that the effective interaction between two proteins immersed in water can be accurately described by a hard-core repulsion plus a short-range attraction. It should also be noted that the concept of ""penetrability"" may be used to describe other physical phenomena besides inter-particle interactions [10] .",arxiv,bigscience bloomz,705.1069,0.2222222222222222,0.546218487394958,0.24615384615384617,0.7649307214524605,1,1,1,0,0,1,1,0,0,0,0.15088167233786348,0.0869176799886757,0.1828793774319066,0.07196969696969698,0,1,3,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Energy dependence of jet transport parameter and parton saturation in quark-gluon plasma,"  We study the evolution and saturation of the gluon distribution function in
the quark-gluon plasma as probed by a propagating parton and its effect on the
computation of jet quenching or transport parameter $\hat{q}$. For thermal
partons, the saturation scale $Q^2_s$ is found to be proportional to the Debye
screening mass $\mu_D^2$. For hard probes, evolution at small $x=Q^2_s/6ET$
leads to jet energy dependence of $\hat{q}$. We study this dependence for both
a conformal gauge theory in weak and strong coupling limit and for (pure gluon)
QCD. The energy dependence can be used to extract the shear viscosity $\eta$ of
the medium since $\eta$ can be related to the transport parameter for thermal
partons in a transport description. We also derive upper bounds on the
transport parameter for both energetic and thermal partons. The later leads to
a lower bound on shear viscosity-to-entropy density ratio which is consistent
with the conjectured lower bound $\eta/s\geq 1/4\pi$. We also discuss the
implications on the study of jet quenching at the BNL Relativistic Heavy Ion
Collider and the CERN Large Hadron Collider and the bulk properties of the
dense matter.
","We study the energy dependence of jet transport coefficient $\kappa$ and parton saturation scale $Q_s$ in strongly coupled N = 4 supersymmetric Yang-Mills theory (SYM) at finite temperature using AdS/CFT correspondence. We find that both quantities exhibit power law behavior with respect to the temperature, i.e., $\kappa \sim T^{-2/3}$ and $Q_s\sim T^{-1/2}$. The results are consistent with those obtained by lattice QCD simulations for hot nuclear matter produced in heavy ion collisions. In addition, we show that the ratio between these two scales is independent of temperature as expected from the dimensional analysis. Finally, we discuss possible implications on the phenomenology of relativistic heavy-ion collisions. PACS: 05.45.Mt, 11.10.Wx, 12.38.Gc, 14.20.Dh, 25 .75.-q",arxiv,bigscience bloomz,705.1352,0.3888888888888889,0.24369747899159663,0.3282051282051282,0.27472527472527475,1,1,0,0,0,1,1,1,0,0,0.07163458004786365,0.0811412331913283,0.07782101167315175,0.03409090909090909,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
J/psi Production in an Equilibrating Partonic System,"  Any color singlet or octet ccbar pair is created at short distances and then
expands to a full size of J/psi. Such a dynamical evolution process is included
here in calculations for the J/psi number distribution as a function of
transverse momentum and rapidity in central Au-Au collisions at both RHIC and
LHC energies. The ccbar pairs are produced in the initial collision and in the
partonic system during the prethermal and thermal stages through the partonic
channels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, and then they
dissociate in the latter two stages. Dissociation of ccbar in the medium occurs
via two reactions: (a) color singlet ccbar plus a gluon turns to color octet
ccbar, (b) color octet ccbar plus a gluon persists as color octet. There are
modest yields of ccbar in the prethermal stage at RHIC energy and through the
reactions ab to ccbar [{2S+1}L_J] at LHC energy for partons with large average
momentum in the prethermal stage at both collider energies and in the thermal
stage at LHC energy. Production from the partonic system competes with the
suppression of the initial yield in the deconfined medium. Consequently, a
bulge within -1.5<y<1.5 has been found for the J/psi number distribution and
the ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon
collisions. This bulge is caused by the partonic system and is thus an
indicator of a deconfined partonic medium. Based on this result we suggest the
rapidity region worth measuring in future experiments at RHIC and LHC to be
-3<y<3.
","We present results on J/psi production at midrapidity (y = 0) and forward rapidity (y = 3.2), using the PHENIX detector, for Au+Au collisions at sqrt(s_NN) = 130 GeV. The data are compared to theoretical calculations based on perturbative QCD with different sets of parton distribution functions. We find that none of these models can describe both datasets simultaneously.  These results suggest that there is significant medium-induced gluon radiation which affects the fragmentation function of quarks into hadrons containing charm or bottom quarks. This effect may be related to the observed suppression of high-pT particles produced by heavy flavor quarks. PACS numbers: 25.75.-q, 11.10.Kk, 12.38.Mh  I . Introduction   Heavy quarkonia such as J/ psi , \Psi_c$, and $\Psi_b$ have been proposed as probes of the hot dense matter created in relativistic nuclear collisions [1] . In particular, it has been suggested that their yields could be suppressed due to color screening effects [2] and/or Debye mass effects [3] in this medium. However, recent measurements [4] show no evidence for such a suppression. Instead, they indicate that the yield increases slightly with centrality [5] .
In order to understand how heavy quarks fragment in the presence of a thermalized medium [6] , we study J/psi production in Au+Au collisions at sNN= 130 GeV. Measurements were performed with the PHENIX experiment [7] at RHIC [8] . 
II. Experiment

A. Detector Description
The PHENIX detector consists of four main subsystems: two spectrometers covering the pseudorapidity range |η| < 0.35 [9] ; one electromagnetic calorimeter covering -1< η < 1 [10] ; and one muon identifier covering -2.2< η < 2.4 [11] . A detailed description of each subdetector system can be found elsewhere [12] .  Figure 1 shows a schematic view of the PHENIX detector. 
B. Data Analysis
J/psi mes",arxiv,bigscience bloomz,704.0668,0.4444444444444444,0.4453781512605043,0.6871794871794872,0.3793597706641185,1,1,1,0,0,1,2,1,0,0,0.12388992797812508,0.12222263265628265,0.13229571984435798,0.16666666666666666,0,6,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,2,1,1
Fifteen Years of High-Resolution Radio Imaging of Supernova 1987A,"  Supernova 1987A in the Large Magellanic Cloud provides a spectacularly
detailed view of the aftermath of a core-collapse explosion. The supernova
ejecta initially coasted outward at more than 10% of the speed of light, but in
1990 were observed to decelerate rapidly as they began to encounter dense
circumstellar material expelled by the progenitor star. The resulting shock has
subsequently produced steadily brightening radio synchrotron emission, which is
resolved by the Australia Telescope Compact Array (ATCA) into an expanding
limb-brightened shell. Here we present 15 years of ATCA imaging of Supernova
1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio
remnant has accelerated in its expansion over this period, from approx 3600
km/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of
the evolving X-ray shell have been ~15% smaller than the corresponding radio
values, but a simultaneous Fourier analysis of both radio and X-ray data
eliminates this discrepancy, and yields a current diameter for the shell in
both wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is
seen in radio images at all ATCA epochs: the eastern and western rims have
higher fluxes than the northern and southern regions, indicating that most of
the radio emission comes from the equatorial plane of the system, where the
progenitor star's circumstellar wind is thought to be densest. The eastern lobe
is brighter than and further from the supernova site than the western lobe,
suggesting an additional asymmetry in the initial distribution of supernova
ejecta.
","Supernova remnants are the most energetic phenomena in our universe, and their study is important for understanding how stars die.  The supernova remnant Cassiopeia A (CasA) was discovered by radio astronomers in 1974.   In this talk I will describe recent results on CasA obtained with the Very Large Array (VLA), which has been observing it since its first light in 1980.  These observations have revealed many new details about the explosion that created CasA more than 30 years ago.  They also provide an opportunity to test models of core-collapse supernovae against data taken at very early times after the explosion. This work was supported by NSF grant AST-0907860. Keywords: Supernova Remnant; Core-Collapse Supernovae; VLA; Cassiopeia A. URL: http://arxiv.org/abs/astro-ph/0504070",arxiv,bigscience bloomz,705.0057,0.3888888888888889,0.29411764705882354,0.676923076923077,0.2919254658385093,1,1,1,0,1,1,1,1,0,0,0.12132407466461026,0.05389198028275344,0.11284046692607004,0.045454545454545456,0,1,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Mapping the circumstellar SiO maser emission in R Leo,"  The study of the innermost circumstellar layers around AGB stars is crucial
to understand how these envelopes are formed and evolve. The SiO maser emission
occurs at a few stellar radii from the central star, providing direct
information on the stellar pulsation and on the chemical and physical
properties of these regions. Our data also shed light on several aspects of the
SiO maser pumping theory that are not well understood yet. We aim to determine}
the relative spatial distribution of the 43 GHz and 86 GHz SiO maser lines in
the oxygen-rich evolved star R Leo. We have imaged with milliarcsecond
resolution, by means of Very Long Baseline Interferometry, the 43 GHz (28SiO
v=1, 2 J=1-0 and 29SiO v=0 J=1-0) and 86 GHz (28SiO v=1 J=2-1 and 29SiO v=0
J=2-1) masing regions. We confirm previous results obtained in other
oxygen-rich envelopes. In particular, when comparing the 43 GHz emitting
regions, the 28SiO v=2 transition is produced in an inner layer, closer to the
central star. On the other hand, the 86 GHz line arises in a clearly farther
shell. We have also mapped for the first time the 29SiO v=0 J=1-0 emission in R
Leo. The already reported discrepancy between the observed distributions of the
different maser lines and the theoretical predictions is also found in R Leo.
","We present new maps of the circumstellar SiO (v=1, v=2) masers around the Mira variable R Leo obtained with the Very Long Baseline Array at 22 GHz and 43 GHz. The observations were carried out on September 24th 2004 using all ten antennas available for VLBA operation during that time period. We detect two distinct groups of masers: one group is located near the star's position as determined by optical astrometry; another group lies about 0.5 arcsec to the south-west of this location. Both groups are associated with an extended bipolar structure seen in previous single-dish observations. This structure has been interpreted as a shell-like envelope surrounding the central star. Our results show that both groups of masers trace different parts of this shell-like structure. In addition we find evidence for a third component which may be related to the presence of a companion object. 
 
 Keywords: Masers",arxiv,bigscience bloomz,704.0682,0.5,0.3445378151260504,0.49230769230769234,0.3750597228858099,1,1,0,0,0,1,1,1,0,1,0.087685591943481,0.08627012043730635,0.13229571984435798,0.06439393939393939,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Pseudogap and charge density waves in two dimensions,"  An interaction between electrons and lattice vibrations (phonons) results in
two fundamental quantum phenomena in solids: in three dimensions it can turn a
metal into a superconductor whereas in one dimension it can turn a metal into
an insulator. In two dimensions (2D) both superconductivity and charge-density
waves (CDW) are believed to be anomalous. In superconducting cuprates, critical
transition temperatures are unusually high and the energy gap may stay unclosed
even above these temperatures (pseudogap). In CDW-bearing dichalcogenides the
resistivity below the transition can decrease with temperature even faster than
in the normal phase and a basic prerequisite for the CDW, the favourable
nesting conditions (when some sections of the Fermi surface appear shifted by
the same vector), seems to be absent. Notwithstanding the existence of
alternatives to conventional theories, both phenomena in 2D still remain the
most fascinating puzzles in condensed matter physics. Using the latest
developments in high-resolution angle-resolved photoemission spectroscopy
(ARPES) here we show that the normal-state pseudogap also exists in one of the
most studied 2D examples, dichalcogenide 2H-TaSe2, and the formation of CDW is
driven by a conventional nesting instability, which is masked by the pseudogap.
Our findings reconcile and explain a number of unusual, as previously believed,
experimental responses as well as disprove many alternative theoretical
approaches. The magnitude, character and anisotropy of the 2D-CDW pseudogap are
intriguingly similar to those seen in superconducting cuprates.
","We study the competition between pseudogap formation, CDW ordering, and superconductivity within an extended Hubbard model on square lattice using DMFT+ED method. We find that at low temperatures there is no phase separation but instead a coexistence region where both phases are present with different weights depending on doping concentration. The results show that the pseudogap opens up around half-filling for all values of U studied here (U = 2 − 8t). At higher dopings we observe a dome-like structure which becomes more pronounced as U increases. In addition to this feature, we also see another peak in DOS near the Fermi level which corresponds to the onset of CDW order. This second peak disappears when temperature is increased or doping decreases. Finally, we have calculated the superfluid weight $\Delta_{s}^{2}$ by solving linearized Eliashberg equations self-consistently. Our results indicate that the maximum value of $\Delta_{s}^{2}$ occurs close to optimal doping.",arxiv,bigscience bloomz,704.1544,0.3888888888888889,0.3445378151260504,0.5538461538461539,0.3836598184424272,1,1,1,0,0,1,1,0,0,0,0.12784896171964427,0.043259674069406305,0.11284046692607004,0.03787878787878788,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Detecting and Characterizing Planetary Systems with Transit Timing,"  In the coming decades, research in extrasolar planets aims to advance two
goals: 1) detecting and characterizing low-mass planets increasingly similar to
the Earth, and 2) improving our understanding of planet formation. We present a
new planet detection method that is capable of making large advances towards
both of these objectives and describe a modest network of telescopes that is
able to make the requisite observations. In a system where a known planet
transits its host star, a second planet in that system will cause the time
between transits to vary. These transit timing variations can be used to infer
the orbital elements and mass of the perturbing planet even if it has a mass
that is smaller than the mass of the Earth. This detection technique
complements other techniques because it is most sensitive in mean-motion
resonances where, due to degeneracies, other techniques have reduced
sensitivity. Small ground-based observatories have already exceeded the
photometric precision necessary to detect sub-Earth mass planets. However, TTV
planet searches are currently limited by the relatively small number of
high-precision transit data and insufficient observing time on existing
telescopes. These issues will be compounded as the number of known transiting
planets suitable for TTV study will increase substantially in the near future.
A relatively modest investment in a ground-based network of small ($\sim 0.5
{\rm m}$ telescopes could provide the needed coverage and so dramatically
increase the effectiveness of transit timing observations.
","Transit timing is an important tool for detecting planets in multi-planet systems, as well as characterizing their orbits. In this work we present the first transit timing analysis of the Kepler data using the method developed by Agol et al. (2005) to detect additional bodies in planetary systems. We find that there are two new candidate planet pairs around KOI-284 (Kepler Object of Interest 284), which has been previously identified as having three transiting planets. The best-fitting model consists of four planets orbiting one star with periods ranging between 1.5 days and 12 years. This system shows strong evidence for orbital eccentricity among its planets. We also report on another system containing five planets, KOI-377, where our results show that it contains at least six planets. Finally, we discuss how these newly discovered systems can be used to test theories about formation and evolution of planetary systems. Transits provide information not only about the radius but also the mass of exoplanets. However, most known transiting planets have been found through photometric surveys such as Kepler or CoRoT, which do not allow precise measurements of the masses due to limited precision of the light curves. On the other hand, radial velocity surveys usually measure the mass more precisely than photometry does, but they cannot determine whether a given object transits because they lack phase coverage near inferior conjunction. Therefore, combining both techniques allows us to obtain accurate values of the radii and masses of transiting planets. 
 
 Here we present the discovery of two new multi-planet systems based on combined photometric and spectroscopic observations made with the HARPS spectrograph attached to the 3.6 m telescope at La Silla Observatory. Both systems contain several super-Earths with short orbital periods. One of them, KOI-284, was already known to host three transiting planets; however, here we demonstrate that it actually harbors four planets. Our results suggest that all four planets have significant orbital eccentricities. Another system, KOI-377, hosts at least six planets.",arxiv,bigscience bloomz,704.0632,0.4444444444444444,0.7983193277310925,0.5897435897435898,0.8910654562828476,1,1,1,0,0,1,1,1,0,0,0.06537277384358915,0.07366119721619035,0.04669260700389105,0.07196969696969698,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Photon Dominated Region Modeling of Barnard 68,"  We use the Barnard 68 dark globule as a test case for a spherically symmetric
PDR model exposed to low-UV radiation fields. With a roughly spherical
morphology and an accurately determined density profile, Barnard 68 is ideal
for this purpose. The processes governing the energy balance in the cloud
surface are studied in detail. We compare the spherically symmetric PDR model
by Stoerzer, Stutzki & Sternberg (1996) to observations of the three lowest
rotational transitions of 12CO, 13CO J = 2-1 and J = 3-2 as well as the [CI]
3P_1-3P_0 fine structure transition. We study the role of Polycyclic Aromatic
Hydrocarbons (PAHs) in the chemical network of the PDR model and consider the
impact of depletion as well as of a variation of the external FUV field. We
find it difficult to simultaneously model the observed 12CO and 13CO emission.
The 12CO and [CI] emission can be explained by a PDR model with a external FUV
field of 1-0.75 chi_0, but this model fails to reproduce the observed 13CO by a
factor of ~2. Adding PAHs to the chemical network increases the [CI] emission
by 50% in our model but makes [CII] very faint. CO depletion only slightly
reduces the 12CO and 13CO line intensity (by <10% and <20%, respectively).
Predictions for the [CII] 2P_3/2-2P_1/2, [CI] 3P_2-3P_1 and 12CO J= 5-4 and 4-3
transitions are presented. This allows a test of our model with future
observations (APEX, NANTEN2, HERSCHEL, SOFIA).
","We present new near-infrared (NIR) observations and modeling results for the young stellar object, Barnard 68 (B68). The NIR data were obtained with the Gemini Near-Infrared Spectrograph on the 8-meter Gemini North telescope in Hawaii during two nights in December 2005. We used these data to construct an SED model that includes both photospheric emission and dust continuum emission. Our best-fit model suggests that B68 is surrounded by a dense core with a mass of 0.1 M_solar_(M_solar = 1.99 x 10^30 kg), which has been heated up to about 100 K due to the central star's radiation. This temperature corresponds to a luminosity of 3 L_sun_(L_sun = 3.84 x 10^26 W). In addition, we found that there are at least three other sources within the field-of-view of our observation whose fluxes contribute significantly to the total observed flux density.",arxiv,bigscience bloomz,705.0913,0.5555555555555556,0.24369747899159663,0.6051282051282051,0.3521261347348304,1,1,0,0,0,1,1,0,0,1,0.09515224672060606,0.07400228881799643,0.1245136186770428,0.08333333333333333,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Personalizing Image Search Results on Flickr,"  The social media site Flickr allows users to upload their photos, annotate
them with tags, submit them to groups, and also to form social networks by
adding other users as contacts. Flickr offers multiple ways of browsing or
searching it. One option is tag search, which returns all images tagged with a
specific keyword. If the keyword is ambiguous, e.g., ``beetle'' could mean an
insect or a car, tag search results will include many images that are not
relevant to the sense the user had in mind when executing the query. We claim
that users express their photography interests through the metadata they add in
the form of contacts and image annotations. We show how to exploit this
metadata to personalize search results for the user, thereby improving search
performance. First, we show that we can significantly improve search precision
by filtering tag search results by user's contacts or a larger social network
that includes those contact's contacts. Secondly, we describe a probabilistic
model that takes advantage of tag information to discover latent topics
contained in the search results. The users' interests can similarly be
described by the tags they used for annotating their images. The latent topics
found by the model are then used to personalize search results by finding
images on topics that are of interest to the user.
","We present an approach to personalize image search results in the context of social networks, by exploiting user-generated tags and ratings. We propose a novel method for ranking images based on their relevance with respect to users' interests as well as their popularity among other users. Our experiments show that our proposed algorithm outperforms state-of-the-art approaches both quantitatively (in terms of precision) and qualitatively (by showing more relevant images). In addition, we demonstrate how this new ranking can be used to improve the performance of existing applications such as tag recommendation systems or photo sharing services. Social media has become one of the most popular ways people share information online. One of its main advantages is that it allows users to easily connect with each other through shared content. For example, Facebook currently hosts over 1 billion photos uploaded by its members [1] . Similarly, Flickr [2] , which was launched in 2002, now contains more than 100 million public photos [3] .
In these platforms, users are able to upload pictures they have taken themselves or find interesting ones from others. They also provide mechanisms to annotate them using free-form text labels called ""tags"" [4] . These tags allow users to describe what is depicted in the picture, but may not always accurately reflect the user's true interest [5] . As a result, when searching for specific topics, users often get irrelevant results [6] . To address this problem, researchers have recently started exploring techniques to rank images according to their relevance to users' interests [7, 8] . However, there still exists significant room for improvement [9] .",arxiv,bigscience bloomz,704.1676,0.5,0.6470588235294118,0.5025641025641026,0.7247969421882466,0,0,0,0,1,1,1,0,0,1,0.08982100386092028,0.0408692091241939,0.10505836575875487,0.041666666666666664,1,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Estimation of experimental data redundancy and related statistics,"  Redundancy of experimental data is the basic statistic from which the
complexity of a natural phenomenon and the proper number of experiments needed
for its exploration can be estimated. The redundancy is expressed by the
entropy of information pertaining to the probability density function of
experimental variables. Since the calculation of entropy is inconvenient due to
integration over a range of variables, an approximate expression for redundancy
is derived that includes only a sum over the set of experimental data about
these variables. The approximation makes feasible an efficient estimation of
the redundancy of data along with the related experimental information and
information cost function. From the experimental information the complexity of
the phenomenon can be simply estimated, while the proper number of experiments
needed for its exploration can be determined from the minimum of the cost
function. The performance of the approximate estimation of these statistics is
demonstrated on two-dimensional normally distributed random data.
","The problem is to estimate the number of independent measurements in an experiment, given that some statistical properties are known for each measurement. The method proposed here uses only information about the mean value and variance of the distribution of results obtained by repeated measurements on one sample (or several samples). It can be used as a tool for planning experiments with minimal error or for estimating the accuracy of existing experimental data. This article presents a new approach to this problem based on the concept of entropy. In particular, it shows how to calculate the mutual information between two random variables using their probability density functions. A numerical example illustrates the application of these methods. 
 
 Keywords: Redundancy estimation, Entropy, Mutual Information, Experiment Planning 
 
 1 Introduction 
 
 When designing an experiment, we need to know what kind of precision our measuring instrument will give us. If we want to measure something precisely enough, then we should make sure that there is no correlation between successive measurements made on the same object [1] . For example, if we have a device which measures the temperature of water at room temperature T = 20 °C , then we would like to obtain values close to 20 ± 0.1°C when repeating the measurement many times [2] .
 
In practice, however, such repeatability cannot always be achieved because of various factors affecting the measurement process [3] . Therefore, before starting any research work, you must determine whether your measuring equipment meets all requirements [4] . 
 
 2 Problem statement 
 
 Let X be a continuous random variable describing the result of a single measurement performed under certain conditions [5] . We assume that the distribution function F(x) of X has been determined experimentally [6] . Then the question arises - how many independent measurements do we need to perform so that the average deviation of the measured values does not exceed a specified threshold ?",arxiv,bigscience bloomz,704.0162,0.2777777777777778,0.6470588235294118,0.1641025641025641,0.8652651696129957,0,1,0,0,0,1,1,1,1,0,0.0741232712291613,0.06717110083330727,0.07392996108949416,0.07575757575757576,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
VLBI observations of nineteen GHz-Peaked-Spectrum radio sources at 1.6 GHz,"  Aims and Methods: We present the results of VLBI observations of nineteen
GHz-Peaked-Spectrum (GPS) radio sources at 1.6 GHz. Of them, 15 sources are
selected from the Parkes Half Jansky (PHJ) sample (Snellen 2002), 4 others are
from our previous observation list. We aimed at imaging the structure of GPS
sources, searching for Compact Symmetric Objects (CSOs) and studying the
absorption for the convex radio spectra of GPS sources.
  Results: We obtained total intensity 1.6 GHz VLBI images of 17 sources for
the first time. Of them, 80% show mini-double-lobe radio structure, indicating
that they are CSOs or candidates, and their host AGNs could be edge-on to us.
This result suggests that there is a high incidence of mini double-lobe sources
(or CSOs) in the PHJ sample. The sources J0323+0534, J1135-0021, J1352+0232,
J2058+0540, J2123-0112 and J2325-0344 with measured redshift, showing
double-lobe structure with sizes of <1 kpc, are classified as CSOs. Three
sources J1057+0012, J1600-0037 and J1753+2750 are considered as core-jet
sources according to their morphologies and flux variability.
","We present the results of Very Long Baseline Interferometry (VLBI) observations made with the European VLBI Network (EVN) and the NRAO Very Large Array (VLA). The sample consists of 19 GPS radio sources selected on the basis that they have flat or inverted spectra between 5 and 8GHz, but steep spectra above 10GHz. We find that all these objects are compact in our EVN images; their sizes range from 0.1 to 2 mas. In addition we detect one source which is resolved into two components separated by about 3mas. This object has been previously detected as an extended source using VLA data alone. Our results show that most GPS sources appear unresolved even when observed with baselines up to 6000 km. However there appears to be some evidence for structural evolution within this class of objects. These results will help us understand how GPS sources evolve over time. 
 
 Keywords: Radio astronomy",arxiv,bigscience bloomz,704.031,0.3888888888888889,0.3949579831932773,0.2358974358974359,0.38652651696129964,1,1,1,0,0,1,0,1,0,0,0.04867299688384695,0.06785551447001151,0.05058365758754864,0.01893939393939394,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Intervening Metal Systems in GRB and QSO sight-lines: The Mgii and Civ Question,"  Prochter et al. 2006 recently found that the number density of strong
intervening 0.5<z<2 MgII absorbers detected in gamma-ray burst (GRB) afterglow
spectra is nearly 4 times larger than in QSO spectra. We have conducted a
similar study using CIV absorbers. Our CIV sample, consisting of a total of 20
systems, is drawn from 3 high resolution and high to moderate S/N VLT/UVES
spectra of 3 long-duration GRB afterglows, covering the redshift interval 1.6<
z<3.1. The column density distribution and number density of this sample do not
show any statistical difference with the same quantities measured in QSO
spectra. We discuss several possibilities for the discrepancy between CIV and
MgII absorbers and conclude that a higher dust extinction in the MgII QSO
samples studied up to now would give the most straightforward solution.
However, this effect is only important for the strong MgII absorbers.
Regardless of the reasons for this discrepancy, this result confirms once more
that GRBs can be used to detect a side of the universe that was unknown before,
not necessarily connected with GRBs themselves, providing an alternative and
fundamental investigative tool of the cosmic evolution of the universe.
","We present new observations of intervening metal systems at z ~ 1.5-2.0 towards the gamma-ray burst (GRB) 050525A, which is one of only two GRBs with spectroscopic redshifts known to date. We detect absorption lines due to Mg ii λλ2796, 2803, Feii λ2382, 2344+2600, Ciii λ977, Siiv λ1394, 1403, Ovi λ1032, 1038, Nv λ1239, 1243, Lyα, and Lyβ associated with an absorber at z = 2.01 ± 0.02. This system has log NHI/cm−2 = 19.6 +0.2 −0.1 , corresponding to a total hydrogen column density of 5 × 1020 cm−2 . It also shows strong low-ionization transitions such as Al iii λ1854, 1854 + 1862, and S iv λ1063, 1073 that are not seen in typical high-redshift absorbers. These features suggest that this absorber may be similar to those found along quasar sightlines.",arxiv,bigscience bloomz,705.0706,0.3888888888888889,0.19327731092436976,0.35384615384615387,0.3349259436215958,1,1,0,0,0,1,1,0,0,0,0.15179023647363785,0.09878409613895323,0.1517509727626459,0.08712121212121213,2,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Quantum spin liquid states in the two dimensional kagome antiferromagnets, ZnxCu4-x(OD)6Cl2","  A three-dimensional system of interacting spins typically develops static
long-range order when it is cooled. If the spins are quantum (S = 1/2),
however, novel quantum paramagnetic states may appear. The most highly sought
state among them is the resonating valence bond (RVB) state in which every pair
of neighboring quantum spins form entangled spin singlets (valence bonds) and
the singlets are quantum mechanically resonating amongst all the possible
highly degenerate pairing states. Here we provide experimental evidence for
such quantum paramagnetic states existing in frustrated antiferromagnets,
ZnxCu4-x(OD)6Cl2, where the S = 1/2 magnetic Cu2+ moments form layers of a
two-dimensional kagome lattice. We find that in Cu4(OD)6Cl2, where distorted
kagome planes are weakly coupled to each other, a dispersionless excitation
mode appears in the magnetic excitation spectrum below ~ 20 K, whose
characteristics resemble those of quantum spin singlets in a solid state, known
as a valence bond solid (VBS), that breaks translational symmetry. Doping
nonmagnetic Zn2+ ions reduces the distortion of the kagome lattice, and weakens
the interplane coupling but also dilutes the magnetic occupancy of the kagome
lattice. The VBS state is suppressed and for ZnCu3(OD)6Cl2 where the kagome
planes are undistorted and 90% occupied by the Cu2+ ions, the low energy spin
fluctuations in the spin liquid phase become featureless.
","We report on neutron scattering experiments performed to investigate magnetic excitations and their dispersion relations in the two-dimensional (2D) frustrated quantum magnets Zn0.8Cu3.2(OD)6Cl2 and Zn1.5Cu2.5(OD)6Cl2 with different Cu2+/Cu3+ ratio. The results show that both compounds are characterized by an energy gap at the zone center which is consistent with theoretical predictions for the 2D Heisenberg model on the kagome lattice. In addition we find evidence for a broad continuum of low-energy excitations extending up to about 5 meV. These findings suggest that these materials may be close to a quantum spin liquid state. We also present high-resolution powder x-ray diffraction data showing that the crystal structure remains unchanged upon deuteration. 
 
 
 
 Quantum spin liquids are exotic phases of matter where spins remain disordered down to zero temperature due to strong quantum fluctuations. They have been predicted theoretically as ground states of many strongly correlated systems such as doped Mott insulators or geometrically frustrated magnets but so far only few experimental realizations exist. Here we report on neutron scattering investigations of two new candidate materials for this fascinating phase - the deuterated copper-oxalate based salts Zn0.8Cu2.9(OD)6Cl2 (Zn0.8Cu3O2Cl2·2H2O) and Zn1.5-Cu1.5(OD) 6Cl2 (Zn1.5Cu2O3Cl2·2H2O). Both compounds crystallize in the same monoclinic space group C2/c as previously reported for the non-deuterated parent compound ZnCu3(OH)6Cl2. However, they differ significantly in the amount of Cu2+ ions replaced by Cu3+ leading to changes in the local environment around each Cu ion. This has important consequences for the exchange interactions between neighboring spins resulting in significant differences in the observed magnetic properties. While Zn0.8Cu 3.2(OD) 6Cl2 shows no sign of long-range order down to 1.7 K it exhibits",arxiv,bigscience bloomz,705.2279,0.3333333333333333,0.546218487394958,0.4666666666666667,0.7219302436693742,1,1,0,0,0,1,1,0,0,0,0.14864745019974887,0.06667801884824953,0.14007782101167315,0.045454545454545456,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Extraction of Freshwater and Energy from Atmosphere,"  Author offers and researches a new, cheap method for the extraction of
freshwater from the Earth atmosphere. The suggected method is fundamentally
dictinct from all existing methods that extract freshwater from air. All other
industrial methods extract water from a saline water source (in most cases from
seawater). This new method may be used at any point in the Earth except Polar
Zones. It does not require long-distance freshwater transportation. If seawater
is not utilized for increasing its productivity, this inexpensive new method is
very environment-friendly. The author method has two working versions: (1) the
first variant the warm (hot) atmospheric air is lifted by the inflatable tube
in a high altitude and atmospheric steam is condenced into freswater: (2) in
the second version, the warm air is pumped 20-30 meters under the sea-surface.
In the first version, wind and solar heating of air are used for causing air
flow. In version (2) wind and propeller are used for causing air movment.
  The first method does not need energy, the second needs a small amount.
Moreover, in variant (1) the freshwater has a high pressure (>30 or more atm.)
and can be used for production of energy such as electricity and in that way
the freshwater cost is lower. For increasing the productivity the seawater is
injected into air and solar air heater may be used. The solar air heater
produces a huge amount of electricity as a very powerful electricity generation
plant. The offered electricity installation in 100 - 200 times cheaper than any
common electric plant of equivalent output.
  Key words: Extraction freshwater, method of getting freshwater, receiving
energy from atmosphere, powerful renewal electric plant.
","The extraction of fresh water and energy from the atmosphere is proposed as an alternative to conventional sources, which are limited in supply or environmentally damaging.  The process involves condensing atmospheric moisture into liquid water using solar power and then collecting this water on a surface coated with hydrophobic materials that allow it to be easily transported by air currents.   This technology could provide clean drinking water for remote communities without requiring large amounts of land area or infrastructure investment. It also has potential applications in agriculture where irrigation can be provided at low cost through the use of wind-driven sprayers. In addition, the collected water may be used directly as fuel if combined with electrolysis cells powered by renewable electricity. The process requires minimal maintenance once installed and would operate continuously over many years. A pilot-scale demonstration system was constructed near Tucson Arizona (USA) during 2011-2013. The results show that the system produces up to 1 gallon per day of potable water under favorable conditions.",arxiv,bigscience bloomz,704.2571,0.8333333333333334,0.3445378151260504,0.7897435897435897,0.4295269947443861,1,1,1,0,0,1,1,0,0,0,0.09911929061034778,0.051014485766974316,0.1556420233463035,0.03787878787878788,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0
Millimeter dust continuum emission unveiling the true mass of giant molecular clouds in the Small Magellanic Cloud,"  CO observations have been so far the best way to trace molecular gas in
external galaxies, but at low metallicity the gas mass deduced could be largely
underestimated. At present, the kinematic information of CO data cubes are used
to estimate virial masses and trace the total mass of the molecular clouds.
Millimeter dust emission can also be used as a dense gas tracer and could
unveil H2 envelopes lacking CO. These different tracers must be compared in
different environments. This study compares virial masses to masses deduced
from millimeter emission, in two GMC samples: the local molecular clouds in our
Galaxy and their equivalents in the Small Magellanic Cloud (SMC), one of the
nearest low metallicity dwarf galaxy. In our Galaxy, mass estimates deduced
from millimeter emission are consistent with masses deduced from gamma ray
analysis and trace the total mass of the clouds. Virial masses are
systematically larger (twice on average) than mass estimates from millimeter
dust emission. This difference decreases toward high masses and has already
been reported in previous studies. In the SMC however, molecular cloud masses
deduced from SIMBA millimeter observations are systematically higher (twice on
average for conservative values of the dust to gas ratio and dust emissivity)
than the virial masses from SEST CO observations. The observed excess can not
be accounted for by any plausible change of dust properties. Taking a general
form for the virial theorem, we show that a magnetic field strength of ~15
micro Gauss in SMC clouds could provide additional support to the clouds and
explain the difference observed. Masses of SMC molecular clouds have therefore
been underestimated so far. Magnetic pressure may contribute significantly to
their support.
","We present new observations at 1 mm and 3 mm wavelengths toward two Giant Molecular Clouds (GMC) in the Small Magellanic: Cloud, LMC N11B and 30 Doradus. We use these data to derive accurate masses for both GMCs by fitting their spectral energy distributions with modified blackbody functions. The derived masses are M(LMC N11B) = 2.1 x 10^6 M_sol and M(30 Doradus) = 5.2 x 10^7 M_sol . These values are significantly higher than those obtained using previous methods based on CO line measurements alone. This discrepancy is likely due to an underestimation of the gas temperature when only one or few lines are used as tracers. Our results show that the total cloud masses inferred from millimeter dust continuum emission can be up to three times larger than previously estimated. Millimeter dust continuum emission has been shown to provide more reliable estimates of the total cloud masses compared to other techniques such as single-dish radio observations of carbon monoxide (CO). However, most studies have focused on Galactic Giant Molecular Clouds (GMGs), while little work has been done towards extragalactic GMGs. In this study we present new observations at 1mm and 3mm wavelengths toward two Giant Molecular Clusters (GMCs) in the Small Magellan: Cloud, LMC N 11B and 30 Doradus; we also include archival data taken with the IRAM-30m telescope. Using these data sets we fit the observed SEDs with modified blackbody functions; our analysis shows that the derived masses are M(N11B)=2.1x10^6M_sol and M(Doradus)=5.2x10^7M_sol , which are significantly higher than those reported in previous works.",arxiv,bigscience bloomz,704.3257,0.6666666666666666,0.4453781512605043,0.8051282051282052,0.6846631629240325,1,0,1,0,0,1,1,1,0,0,0.11103261128284929,0.07467413054512909,0.13618677042801555,0.06060606060606061,2,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Determination of Low-Energy Parameters of Neutron--Proton Scattering on the Basis of Modern Experimental Data from Partial-Wave Analyses,"  The triplet and singlet low-energy parameters in the effective-range
expansion for neutron--proton scattering are determined by using the latest
experimental data on respective phase shifts from the SAID nucleon--nucleon
database. The results differ markedly from the analogous parameters obtained on
the basis of the phase shifts of the Nijmegen group and contradict the
parameter values that are presently used as experimental ones. The values found
with the aid of the phase shifts from the SAID nucleon--nucleon database for
the total cross section for the scattering of zero-energy neutrons by protons,
$\sigma_{0}=20.426 $b, and the neutron--proton coherent scattering length,
$f=-3.755 $fm, agree perfectly with the experimental cross-section values
obtained by Houk, $\sigma_{0}=20.436\pm 0.023 $b, and experimental
scattering-length values obtained by Houk and Wilson, $f=-3.756\pm 0.009 $fm,
but they contradict cross-section values of $\sigma_{0}=20.491\pm 0.014 $b
according to Dilg and coherent-scattering-length values of $f=-3.7409\pm 0.0011
$fm according to Koester and Nistler.
","The low-energy parameters of neutron-proton scattering are determined by using modern experimental data obtained in partial-wave analyses (PWAs). The results for the S-wave phase shifts and mixing angles, as well as for the P-wave amplitudes at zero energy, are presented here. It is shown that these values agree with those extracted previously from other experiments within their uncertainties. In addition to this, we present new results for the D-wave amplitude at zero energy which were not available before. 
I. INTRODUCTIO N
Neutron-proton elastic scattering has been studied extensively over many decades [1] . This process plays an important role in nuclear physics since it provides information about the nucleon-nucleon interaction potential [2] , which can be used to calculate properties of nuclei [3] .
In recent years there have been significant advances in our understanding of the structure of the nucleon-nucleus system [4] . These developments include precise measurements of cross sections [5] , polarization observables [6] , spin-correlation coefficients [7] , etc., performed mainly at intermediate energies [8] . However, despite all efforts made so far, some questions remain open [9] . For example, one still needs more accurate determinations of the lowenergy parameters of the nucleonnucleon interaction [10] .",arxiv,bigscience bloomz,704.1024,0.1111111111111111,0.4453781512605043,0.13333333333333333,0.5298614429049212,0,1,0,0,0,1,1,0,0,0,0.40901069068579404,0.05229964662403902,0.3540856031128405,0.05303030303030303,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Towards an Explicit Model of D-brane Inflation,"  We present a detailed analysis of an explicit model of warped D-brane
inflation, incorporating the effects of moduli stabilization. We consider the
potential for D3-brane motion in a warped conifold background that includes
fluxes and holomorphically-embedded D7-branes involved in moduli stabilization.
Although the D7-branes significantly modify the inflaton potential, they do not
correct the quadratic term in the potential, and hence do not cause a uniform
change in the slow-roll parameter eta. Nevertheless, we present a simple
example based on the Kuperstein embedding of D7-branes, z_1=constant, in which
the potential can be fine-tuned to be sufficiently flat for inflation. To
derive this result, it is essential to incorporate the fact that the
compactification volume changes slightly as the D3-brane moves. We stress that
the compactification geometry dictates certain relationships among the
parameters in the inflaton Lagrangian, and these microscopic constraints impose
severe restrictions on the space of possible models. We note that the shape of
the final inflaton potential differs from projections given in earlier studies:
in configurations where inflation occurs, it does so near an inflection point.
Finally, we comment on the difficulty of making precise cosmological
predictions in this scenario. This is the companion paper to arXiv:0705.3837.
","We propose to use the open string field theory (OSFT) as a model for inflation in type IIB superstring theory, which is based on the tachyon condensation and its decay into closed strings. We show that this OSFT can be described by a noncommutative geometry with a fuzzy sphere background. The resulting effective action contains higher derivative terms such as R4 term, but it does not contain any ghosts or tachyons. This suggests that our proposal may provide a consistent description of inflationary universe within the framework of string theory. In addition we find that there are two possible ways to realize inflation depending on whether the inflaton is identified with the radius of the fuzzy sphere or the radial component of the gauge fields living on the branes. Finally we discuss some phenomenological consequences of these models. Introduction:-In recent years many attempts have been made towards understanding cosmology using string/M-theory [1] . One of the most interesting proposals has been the idea of D-brane inflation [2] , where one considers a stack of N coincident D3-branes moving slowly through the extra dimensions. It was shown that if the distance between the branes becomes small enough then they start to interact strongly via exchange of massless closed string modes [3] . As a result the potential energy density stored in the form of open strings stretched between them starts to decrease rapidly leading to spontaneous symmetry breaking [4] .
The main problem associated with this scenario is how to stabilize the size of the extra dimensions so that the system remains at the minimum of the potential during inflation [5] ? A simple way out would be to consider compactification of the extra dimensions [6] . However, this leads to problems like moduli stabilization [7, 8] and also introduces unwanted degrees of freedom [9] . Another possibility is to introduce anti-D3-branes [10] which lead to additional contributions to the scalar potential [11] . But again this requires fine tuning [12] . Recently Sen [13] proposed another mechanism called ""tachyon condensation"" [14] , where he showed that the unstable vacuum state corresponding to the maximum of the potential decays into stable states corresponding to minima",arxiv,bigscience bloomz,706.036,0.4444444444444444,0.7478991596638657,0.38974358974358975,0.9971333014811276,0,1,1,0,0,1,1,1,1,0,0.07817314703094791,0.07904316568593431,0.0622568093385214,0.09848484848484848,1,2,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
3D Radiative Hydrodynamics for Disk Stability Simulations: A Proposed Testing Standard and New Results,"  Recent three-dimensional radiative hydrodynamics simulations of
protoplanetary disks report disparate disk behaviors, and these differences
involve the importance of convection to disk cooling, the dependence of disk
cooling on metallicity, and the stability of disks against fragmentation and
clump formation. To guarantee trustworthy results, a radiative physics
algorithm must demonstrate the capability to handle both the high and low
optical depth regimes. We develop a test suite that can be used to demonstrate
an algorithm's ability to relax to known analytic flux and temperature
distributions, to follow a contracting slab, and to inhibit or permit
convection appropriately. We then show that the radiative algorithm employed by
Meji\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al.
(2006) and Cai et al. (2007, in prep.) pass these tests with reasonable
accuracy. In addition, we discuss a new algorithm that couples flux-limited
diffusion with vertical rays, we apply the test suite, and we discuss the
results of evolving the Boley et al. (2006) disk with this new routine.
Although the outcome is significantly different in detail with the new
algorithm, we obtain the same qualitative answers. Our disk does not cool fast
due to convection, and it is stable to fragmentation. We find an effective
$\alpha\approx 10^{-2}$. In addition, transport is dominated by low-order
modes.
","We present the results of 3D radiation hydrodynamic simulations of accretion disks around black holes, performed with our new code RHD3DPHOTON. We show that this code is able to reproduce previous results obtained by other authors using different codes (e.g., JETSPEC), as well as some new results which have not been previously reported in the literature. In particular we find that:  1) The disk becomes unstable when its luminosity exceeds a critical value Lcrit = 0.1LEdd.  2) For super-Eddington luminosities there are two types of instability modes: one associated with thermal convection and another related to photon bubbles.  3) There exists an upper limit on the mass flux through the disk, above which no steady state solution can be found. This result has important implications for models of AGN feedback. 4) When the luminosity approaches or exceeds LEdd, the disk develops strong outflows along the equatorial plane.",arxiv,bigscience bloomz,704.2532,0.7222222222222222,0.29411764705882354,0.48717948717948717,0.3750597228858099,1,1,0,0,1,1,1,1,0,0,0.1142893939018762,0.06686268826240116,0.10505836575875487,0.04924242424242424,5,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Dynamics of interacting Brownian particles: a diagrammatic formulation,"  We present a diagrammatic formulation of a theory for the time dependence of
density fluctuations in equilibrium systems of interacting Brownian particles.
To facilitate derivation of the diagrammatic expansion we introduce a basis
that consists of orthogonalized many-particle density fluctuations. We obtain
an exact hierarchy of equations of motion for time-dependent correlations of
orthogonalized density fluctuations. To simplify this hierarchy we neglect
contributions to the vertices from higher-order cluster expansion terms. An
iterative solution of the resulting equations can be represented by diagrams
with three and four-leg vertices. We analyze the structure of the diagrammatic
series for the time-dependent density correlation function and obtain a
diagrammatic interpretation of reducible and irreducible memory functions. The
one-loop self-consistent approximation for the latter function coincides with
mode-coupling approximation for Brownian systems that was derived previously
using a projection operator approach.
","We present an alternative approach to the dynamics of interacting Brownian particles, based on Feynman diagrams and path integrals in phase space. The method is illustrated by considering two examples: (i) the overdamped motion of N identical particles diffusing in one dimension under the influence of pairwise additive interactions; (ii) the diffusion of a single particle in three dimensions with arbitrary time-dependent external forces acting upon it. In both cases we obtain exact results for the mean-square displacement as well as higher-order correlation functions. We also discuss how our formalism can be used to study more complicated systems such as those involving hydrodynamic interactions between particles or active particles that perform directed motions. Interacting Brownian particles are ubiquitous in nature, ranging from colloidal suspensions [1] , granular matter [2] , and biological cells [3] to molecular motors [4] . Their collective behavior often exhibits non-trivial features which cannot be captured within standard statistical mechanics approaches [5] .
In this work we develop a new theoretical framework to describe the stochastic dynamics of many-body systems composed of interacting Brownian particles. Our starting point is Feynman's path integral representation [6] of the probability distribution function P(rN;tN|r1t1;r2t2…rntn−1), where rN denotes the positions of all particles at times tN=t1,…,tn=NΔt, Δt being the discretization step size [7, 8] . This expression involves a sum over all possible trajectories connecting pairs of points {r1,…,rn} and {t1,…,tn}; each trajectory is weighted by its corresponding action S[rN;tN]=∫dtN[−kB TlnP(rN;tN=rNt;rN−1tN−1…)+Pext(rN;tN)], where kB is Boltzmann's constant and T is temperature [9] .",arxiv,bigscience bloomz,705.3645,0.3333333333333333,0.3949579831932773,0.07179487179487179,0.6731963688485428,0,1,0,0,0,1,1,1,0,1,0.03601206355996753,0.16074240548747368,0.0311284046692607,0.11363636363636363,0,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Relaxation of a dewetting contact line Part 1: A full-scale hydrodynamic calculation,"  The relaxation of a dewetting contact line is investigated theoretically in
the so-called ""Landau-Levich"" geometry in which a vertical solid plate is
withdrawn from a bath of partially wetting liquid. The study is performed in
the framework of lubrication theory, in which the hydrodynamics is resolved at
all length scales (from molecular to macroscopic). We investigate the
bifurcation diagram for unperturbed contact lines, which turns out to be more
complex than expected from simplified 'quasi-static' theories based upon an
apparent contact angle. Linear stability analysis reveals that below the
critical capillary number of entrainment, Ca_c, the contact line is linearly
stable at all wavenumbers. Away from the critical point the dispersion relation
has an asymptotic behaviour sigma~|q| and compares well to a quasi-static
approach. Approaching Ca_c, however, a different mechanism takes over and the
dispersion evolves from |q| to the more common q^2. These findings imply that
contact lines can not be treated as universal objects governed by some
effective law for the macroscopic contact angle, but viscous effects have to be
treated explicitly.
","We present the results of a numerical study on the relaxation dynamics of an initially straight contact line in a two-dimensional geometry, which is driven by surface tension and viscous dissipation at the moving interface between liquid and gas phases.  We solve the Navier-Stokes equations for incompressible fluids with free-slip boundary conditions using a spectral element method to simulate the flow field around the evolving droplet shape. The initial condition consists of a circular droplet sitting on top of a flat substrate that has been perturbed slightly away from its equilibrium position. As time evolves, we observe the formation of capillary waves along the contact line as well as the development of small satellite drops near the main droplet due to pinching off events. In addition, we find that the contact angle decreases continuously during this process until it reaches zero degrees when the entire droplet detaches from the substrate. Finally, we compare our simulation results against experimental data obtained from high-speed video microscopy measurements performed by other researchers.",arxiv,bigscience bloomz,705.3576,0.3333333333333333,0.24369747899159663,0.26153846153846155,0.4381270903010034,1,1,0,0,1,0,1,0,0,0,0.04487270140396032,0.05498448996653902,0.042801556420233464,0.03787878787878788,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1
Jet-disturbed molecular gas near the Seyfert 2 nucleus in M51,"  Previous molecular gas observations at arcsecond-scale resolution of the
Seyfert 2 galaxy M51 suggest the presence of a dense circumnuclear rotating
disk, which may be the reservoir for fueling the active nucleus and obscures it
from direct view in the optical. However, our recent interferometric CO(3-2)
observations show a hint of a velocity gradient perpendicular to the rotating
disk, which suggests a more complex structure than previously thought. To image
the putative circumnuclear molecular gas disk at sub-arcsecond resolution to
better understand both the spatial distribution and kinematics of the molecular
gas. We carried out CO(2-1) and CO(1-0) line observations of the nuclear region
of M51 with the new A configuration of the IRAM Plateau de Bure Interferometer,
yielding a spatial resolution lower than 15 pc. The high resolution images show
no clear evidence of a disk, aligned nearly east-west and perpendicular to the
radio jet axis, as suggested by previous observations, but show two separate
features located on the eastern and western sides of the nucleus. The western
feature shows an elongated structure along the jet and a good velocity
correspondence with optical emission lines associated with the jet, suggesting
that this feature is a jet-entrained gas. The eastern feature is elongated
nearly east-west ending around the nucleus. A velocity gradient appears in the
same direction with increasingly blueshifted velocities near the nucleus. This
velocity gradient is in the opposite sense of that previously inferred for the
putative circumnuclear disk. Possible explanations for the observed molecular
gas distribution and kinematics are that a rotating gas disk disturbed by the
jet, gas streaming toward the nucleus, or a ring with another smaller counter-
or Keplarian-rotating gas disk inside.
","We present new observations with the Atacama Large Millimeter/submillimeter Array (ALMA) that reveal an extended region of disturbed molecular gas surrounding the active galactic nucleus (AGN) of NGC 5194, also known as M51a or Whirlpool Galaxy. The AGN is located at the center of this interacting galaxy pair and has been classified as a Seyfert 2 based on optical spectroscopy. We detect two prominent dust lanes extending to the north-east and south-west of the AGN along its minor axis. These are likely caused by tidal forces between the galaxies during their interaction. In addition, we find evidence for a third dust lane oriented perpendicularly to these two features which may be associated with a nuclear bar. Our ALMA data show that the distribution of dense molecular gas traced by HCN(1-0), HCO+(1-0), and CS(2-1) emission lines exhibits a ring-like structure around the AGN. This feature appears to have been shaped by powerful outflows driven by the AGN.",arxiv,bigscience bloomz,704.0947,0.5,0.29411764705882354,0.7948717948717948,0.40086000955566176,1,1,0,0,0,1,1,0,0,0,0.1115800626023926,0.08509174169542041,0.08560311284046693,0.07196969696969698,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Glimpsing through the high redshift neutral hydrogen fog,"  We analyze the transmitted flux in a sample of 17 QSOs spectra at
5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral
hydrogen fraction, xHI, at z~6. We study separately the narrow transmission
windows (peaks) and the wide dark portions (gaps) in the observed absorption
spectra. By comparing the statistics of these spectral features with Lyalpha
forest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at
z=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The
frequency and physical sizes of the peaks imply an origin in cosmic underdense
regions and/or in HII regions around faint quasars or galaxies. In one case
(the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along
the LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density
is explained by the first-ever detected transverse proximity effect in the HI
Lyalpha forest; this indicates that at least some peaks result from a locally
enhanced radiation field. We then obtain a strong lower limit on the foreground
QSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be
systematically larger than the simulated ones. Reasons for such discrepancy
might reside either in the photoionization equilibrium assumption or in
radiative transfer effects.
","We present new results on the evolution of galaxy clustering in the range 0 < z < 5, based on an analysis of data obtained with the VIMOS spectrograph at the Very Large Telescope (VLT). The sample consists of about 2000 galaxies selected by their Lyman-alpha emission line fluxes and covers a wide range of redshifts between 2<z<5. We measure the two-point correlation function for this sample using both direct counts-in-cells methods as well as Fourier space techniques. Our main result is that we find no evidence for any significant change in the amplitude or slope of the correlation function over this large redshift interval. This suggests that there has been little evolution in the typical mass scale of dark matter halos hosting these galaxies since z=5. In addition to measuring the overall shape of the correlation function, we also examine how it depends upon various physical properties such as luminosity, color, and spectral type.",arxiv,bigscience bloomz,706.1053,0.3888888888888889,0.24369747899159663,0.4461538461538462,0.39799331103678937,1,1,1,0,0,1,1,0,0,0,0.1438505812200557,0.04841410323805311,0.17120622568093385,0.026515151515151516,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Profinite complexes of curves, their automorphisms and anabelian properties of moduli stacks of curves","  Let ${\cal M}_{g,[n]}$, for $2g-2+n>0$, be the D-M moduli stack of smooth
curves of genus $g$ labeled by $n$ unordered distinct points. The main result
of the paper is that a finite, connected \'etale cover ${\cal M}^\l$ of ${\cal
M}_{g,[n]}$, defined over a sub-$p$-adic field $k$, is ""almost"" anabelian in
the sense conjectured by Grothendieck for curves and their moduli spaces.
  The precise result is the following. Let $\pi_1({\cal M}^\l_{\ol{k}})$ be the
geometric algebraic fundamental group of ${\cal M}^\l$ and let
${Out}^*(\pi_1({\cal M}^\l_{\ol{k}}))$ be the group of its exterior
automorphisms which preserve the conjugacy classes of elements corresponding to
simple loops around the Deligne-Mumford boundary of ${\cal M}^\l$ (this is the
""$\ast$-condition"" motivating the ""almost"" above). Let us denote by
${Out}^*_{G_k}(\pi_1({\cal M}^\l_{\ol{k}}))$ the subgroup consisting of
elements which commute with the natural action of the absolute Galois group
$G_k$ of $k$. Let us assume, moreover, that the generic point of the D-M stack
${\cal M}^\l$ has a trivial automorphisms group. Then, there is a natural
isomorphism: $${Aut}_k({\cal M}^\l)\cong{Out}^*_{G_k}(\pi_1({\cal
M}^\l_{\ol{k}})).$$ This partially extends to moduli spaces of curves the
anabelian properties proved by Mochizuki for hyperbolic curves over
sub-$p$-adic fields.
","We study the profinite complex associated to a family of smooth projective curves over a field k with fixed genus g>0. We show that this is homotopy equivalent to the classifying space of the group Aut(C) of automorphisms of one curve C in the family (Theorem 1). This result generalizes previous results by Deligne on families of elliptic curves. In particular we obtain new information about the cohomology groups H^1(Aut(C),k*) for all such families (Corollary 2).
In section 3 we use our results to prove some basic facts about the anabelian geometry of the moduli stack M_g of stable curves of genus g. For example we give a simple proof of the fact that the Picard scheme Pic0M_g has no torsion points if char(k)=0 or p>3g-2 (Proposition 4). The main tool used here are the results obtained in sections 1-2 combined with Grothendieck's comparison theorem between étale fundamental groups and Galois groups.",arxiv,bigscience bloomz,706.0859,0.3333333333333333,0.24369747899159663,0.3384615384615385,0.38939321548017203,1,1,1,0,1,1,1,0,0,1,0.2858302598791166,0.12735234877961224,0.377431906614786,0.11742424242424243,1,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Neutrino Decays and Neutrino Electron Elastic Scattering in Unparticle Physics,"  Following Georgi's unparticle scheme, we examine the effective couplings
between neutrinos and unparticle operators. As an immediate consequence,
neutrinos become unstable and can decay into the unparticle stuff. Assuming the
dimension transmutation scale is around $\Lambda^{}_{\cal U} \sim 1 ~{\rm
TeV}$, we implement the cosmological limit on the neutrino lifetime to
constrain the neutrino-unparticle couplings for different scaling dimensions
$d$. In addition, provided that the electron-unparticle coupling is restricted
due to the precise measurement of the anomalous magnetic moment of electron, we
calculate the unparticle contribution to the neutrino-electron elastic
scattering. It is more important to jointly deal with the couplings of the
unparticle to the standard model particles rather than separately. Taking into
account both electron- and neutrino-unparticle couplings, we find that the
scaling dimension of the scalar unparticle should lie in the narrow range $1 <
d < 2$ by requiring the observables to be physically meaningful. However, there
is no consistent range of $d$ for the vector unparticle operator.
","We study the decay modes of neutrinos into unparticles, as well as their elastic scattering off electrons mediated by virtual unparticles. We find that these processes are strongly suppressed for small values of the coupling constant between ordinary particles and unparticles. For larger values of this coupling we obtain branching ratios which can be tested at future experiments such as T2K or NOVA. The results presented here may also have implications on other models with extra dimensions beyond those considered so far. 
 
 Introduction 
 
 In recent years there has been an increasing interest in theories where new physics is described by fields whose excitations do not carry standard model (SM) charges [1] . These so-called ""unparticles"" [2] , if they exist, could manifest themselves through various experimental signatures [3] .
 
In particular, it was shown [4] that decays of SM particles to pairs of unparticles would lead to deviations from the expected exponential behavior of the corresponding lifetimes. This effect should be observable experimentally [5] . Furthermore, it was suggested [6] that unparticles might play a role in explaining some puzzling features observed recently in cosmic ray data [7, 8] . 
 
 Another interesting possibility is that unparticles couple directly to SM fermions [9] . If this were true then one would expect to see effects similar to those predicted in Ref. [10] for Kaluza-Klein gravitons coupled to leptons. Namely, the cross sections for certain processes involving SM fermions and unparticles would grow logarithmically with energy [11] . Such logarithmic growths have indeed been found [12] - [14] in several cases including e+e-→e+e-U, U→eν, and U→μτ. However, in all these studies only the case of scalar unparticles was considered. It turns out [15] that vector-like couplings give rise to additional contributions to the amplitudes which modify significantly the predictions obtained previously [16] .",arxiv,bigscience bloomz,706.0302,0.3333333333333333,0.7478991596638657,0.2,0.8165312947921644,0,1,0,0,1,1,1,0,0,0,0.11447794423166392,0.058128431327113025,0.12062256809338522,0.06818181818181818,0,2,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Energy Density-Flux Correlations in an Unusual Quantum State and in the Vacuum,"  In this paper we consider the question of the degree to which negative and
positive energy are intertwined. We examine in more detail a previously studied
quantum state of the massless minimally coupled scalar field, which we call a
``Helfer state''. This is a state in which the energy density can be made
arbitrarily negative over an arbitrarily large region of space, but only at one
instant in time. In the Helfer state, the negative energy density is
accompanied by rapidly time-varying energy fluxes. It is the latter feature
which allows the quantum inequalities, bounds which restrict the magnitude and
duration of negative energy, to hold for this class of states. An observer who
initially passes through the negative energy region will quickly encounter
fluxes of positive energy which subsequently enter the region. We examine in
detail the correlation between the energy density and flux in the Helfer state
in terms of their expectation values. We then study the correlation function
between energy density and flux in the Minkowski vacuum state, for a massless
minimally coupled scalar field in both two and four dimensions. In this latter
analysis we examine correlation functions rather than expectation values.
Remarkably, we see qualitatively similar behavior to that in the Helfer state.
More specifically, an initial negative energy vacuum fluctuation in some region
of space is correlated with a subsequent flux fluctuation of positive energy
into the region. We speculate that the mechanism which ensures that the quantum
inequalities hold in the Helfer state, as well as in other quantum states
associated with negative energy, is, at least in some sense, already
``encoded'' in the fluctuations of the vacuum.
","We study energy density-flux correlations for a free scalar field in 1+1 dimensions, both at finite temperature T and in vacuum (T=0). We show that these correlation functions are nontrivial even when evaluated on the light cone x+x=t+t0=2ct. In particular we find that they exhibit power law behavior with exponents which depend continuously on c. This is in contrast to what happens in ordinary quantum mechanics where such correlators vanish identically outside the light cone. The results presented here can be obtained by using standard techniques developed within the framework of thermofield dynamics. They provide further evidence that this formalism provides a useful description of thermal states also beyond equilibrium situations. Energy density-flux correlations play an important role in various physical phenomena ranging from hydrodynamics to particle production processes in heavy ion collisions. However their calculation has been hampered so far by the fact that it requires knowledge about off-diagonal elements of the two-point function of the corresponding operator. Here we present explicit expressions for these quantities for a free massless scalar field theory in one spatial dimension.",arxiv,bigscience bloomz,706.197,0.6111111111111112,0.3445378151260504,0.7794871794871795,0.4639273769708553,0,1,0,0,1,1,1,0,0,0,0.08799979372397447,0.05247164879148028,0.07782101167315175,0.06439393939393939,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,0
Is there Evidence for a Hubble bubble? The Nature of Type Ia Supernova Colors and Dust in External Galaxies,"  We examine recent evidence from the luminosity-redshift relation of Type Ia
Supernovae (SNe Ia) for the $\sim 3 \sigma$ detection of a ``Hubble bubble'' --
a departure of the local value of the Hubble constant from its globally
averaged value \citep{Jha:07}. By comparing the MLCS2k2 fits used in that study
to the results from other light-curve fitters applied to the same data, we
demonstrate that this is related to the interpretation of SN color excesses
(after correction for a light-curve shape-color relation) and the presence of a
color gradient across the local sample. If the slope of the linear relation
($\beta$) between SN color excess and luminosity is fit empirically, then the
bubble disappears. If, on the other hand, the color excess arises purely from
Milky Way-like dust, then SN data clearly favors a Hubble bubble. We
demonstrate that SN data give $\beta \simeq 2$, instead of the $\beta \simeq 4$
one would expect from purely Milky-Way-like dust. This suggests that either SN
intrinsic colors are more complicated than can be described with a single
light-curve shape parameter, or that dust around SN is unusual. Disentangling
these possibilities is both a challenge and an opportunity for large-survey SN
Ia cosmology.
","We present new results on the nature of dust extinction in external galaxies, based on observations with HST/ACS of type Ia supernovae (SNe) at redshifts z=0.1-0.7. We find that SNe Ia are systematically bluer than expected if they were standard candles, but this effect is consistent with being due to dust extinction by interstellar material along their line-of-sight. In addition we find evidence for an additional component of dust extinction which increases rapidly towards higher redshift. This extra extinction may be associated with the intergalactic medium surrounding galaxy clusters, or it could arise within individual galaxies as a result of recent star formation activity. These findings have important implications for cosmological studies using distant SNe Ia as distance indicators. 
 
 Keywords: Galaxy cluster, Interstellar matter, Intergalactic medium, Redshift evolution, Supernova, Supernova Ia",arxiv,bigscience bloomz,705.0367,0.3333333333333333,0.24369747899159663,0.39487179487179486,0.32919254658385094,1,1,1,0,1,1,1,1,0,0,0.12969723684777226,0.05833036332780308,0.11284046692607004,0.041666666666666664,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
Quantification of discreteness effects in cosmological N-body simulations: II. Evolution up to shell crossing,"  We apply a recently developed perturbative formalism which describes the
evolution under their self-gravity of particles displaced from a perfect
lattice to quantify precisely, up to shell crossing, the effects of
discreteness in dissipationless cosmological N-body simulations. We give simple
expressions, explicitly dependent on the particle density, for the evolution of
power in each mode as a function of red-shift. For typical starting red-shifts
the effect of finite particle number is to {\it slow down} slightly the growth
of power compared to that in the fluid limit (e.g. by about ten percent at half
the Nyquist frequency), and to induce also dispersion in the growth as a
function of direction at a comparable level. In the limit that the initial
red-shift tends to infinity, at fixed particle density, the evolution in fact
diverges from that in the fluid limit (described by the Zeldovich
approximation). Contrary to widely held belief, this means that a simulation
started at a red-shift much higher than the red-shift of shell crossing
actually gives a worse, rather than a better, result. We also study how these
effects are modified when there is a small-scale regularization of the
gravitational force. We show that such a smoothing may reduce the anisotropy of
the discreteness effects, but it then {\it increases} their average effect.
This behaviour illustrates the fact that the discreteness effects described
here are distinct from those usually considered in this context, due to
two-body collisions. Indeed the characteristic time for divergence from the
collisionless limit is proportional to $N^{2/3}$, rather than $N/ \log N$ in
the latter case.
","We present the results of an investigation into the evolution of dark matter halos and their substructure, using high-resolution cosmological N-body simulations with different mass resolutions. We find that the number density profiles of subhalos are well described by a power law at all redshifts z < 5 for both low-mass (10^9 Msun/h) and high-mass (10^12 Msun/h) halos. The slope of this profile is independent of halo mass but depends on redshift; it steepens as time progresses. This behavior can be understood if we assume that the subhalo population consists of two components: one which follows the host's potential closely and another whose orbits have been significantly affected by dynamical friction. In addition, we show that the fraction of subhalos within r200c decreases rapidly towards higher masses. Finally, we demonstrate how our findings can be used to quantify the effect of numerical resolution on the abundance of subhalos.",arxiv,bigscience bloomz,704.3697,0.5,0.24369747899159663,0.7128205128205128,0.3779264214046823,1,1,0,0,0,1,1,1,0,1,0.05520201350458265,0.06222715303021686,0.0622568093385214,0.056818181818181816,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0
Product Formulae for Ozsvath-Szabo 4-manifold Invariants,"  We give formulae for the Ozsvath-Szabo invariants of 4-manifolds X obtained
by fiber sum of two manifolds M_1, M_2 along surfaces S_1, S_2 having trivial
normal bundle and genus g>0. The formulae follow from a general theorem on the
Ozsvath-Szabo invariants of the result of gluing two 4-manifolds along a common
boundary, which is phrased in terms of relative invariants of the pieces. These
relative invariants take values in a version of Heegaard Floer homology with
coefficients in modules over certain Novikov rings; the fiber sum formula
follows from the theorem that this ""perturbed"" version of Heegaard Floer theory
recovers the usual Ozsvath-Szabo invariants, when the 4-manifold in question
has b^+>1. The construction allows an extension of the definition of the
Ozsvath-Szabo invariants to 4-manifolds having b^+ = 1 depending on certain
choices, in close analogy with Seiberg-Witten theory. The product formulae lead
quickly to calculations of the Ozsvath-Szabo invariants of various 4-manifolds;
in all cases the results are in accord with the conjectured equivalence between
the Ozsvath-Szabo and Seiberg-Witten invariants.
","We give explicit formulae for the product of two Ozsvath-Szab o 4-dimensional manifold invariants in terms of their associated modular forms and theta functions.  We also show that these products are not always positive, which is an obstruction to using them as intersection numbers on moduli spaces of curves. The results presented here were obtained by applying techniques developed by Vafa-Witten and Witten-Taubes to the case of genus 2 Riemann surfaces with four punctures. These techniques involve studying certain periods of meromorphic differentials on hyperelliptic Riemann surfaces. As such they can be used to study other problems involving hyperelliptic Riemann surface invariants. This article was published in Journal of Physics A: Mathematical and General 37 (2004) L55-L62. URL: http://arxiv.org/abs/0406.0366v1 . 
Authors: David J. Jeffrey1 , Michael A. McMullen2 .
Affiliation: 1University of California Santa Cruz, Santa Cruz, CA 95064, USA; 2University",arxiv,bigscience bloomz,706.0339,0.2222222222222222,0.3949579831932773,0.24615384615384617,0.35785953177257523,0,1,1,0,0,1,1,1,0,0,0.08477664541528739,0.05692020245748351,0.09727626459143969,0.03409090909090909,0,2,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Mid-Infrared Fine Structure Line Ratios in Active Galactic Nuclei Observed with Spitzer IRS: Evidence for Extinction by the Torus,"  We present the first systematic investigation of the [NeV] (14um/24um) and
[SIII] (18um/33um) infrared line flux ratios, traditionally used to estimate
the density of the ionized gas, in a sample of 41 Type 1 and Type 2 active
galactic nuclei (AGNs) observed with the Infrared Spectrograph on board
Spitzer. The majority of galaxies with both [NeV] lines detected have observed
[NeV] line flux ratios consistent with or below the theoretical low density
limit, based on calculations using currently available collision strengths and
ignoring absorption and stimulated emission. We find that Type 2 AGNs have
lower line flux ratios than Type 1 AGNs and that all of the galaxies with line
flux ratios below the low density limit are Type 2 AGNs. We argue that
differential infrared extinction to the [NeV] emitting region due to dust in
the obscuring torus is responsible for the ratios below the low density limit
and we suggest that the ratio may be a tracer of the inclination angle of the
torus to our line of sight. Because the temperature of the gas, the amount of
extinction, and the effect of absorption and stimulated emission on the line
ratios are all unknown, we are not able to determine the electron densities
associated with the [NeV] line flux ratios for the objects in our sample. We
also find that the [SIII] emission from the galaxies in our sample is extended
and originates primarily in star forming regions. Since the emission from
low-ionization species is extended, any analysis using line flux ratios from
such species obtained from slits of different sizes is invalid for most nearby
galaxies.
","We present mid-infrared (MIR) spectroscopic observations of six active galactic nuclei (AGNs), obtained using the Infrared Spectrograph on board the Spitzer Space Telescope, and compare them to predictions based on radiative transfer models. We find that all objects show strong silicate absorption features at 9.7{\mu}m and 18.2{\mu}m, which are well reproduced by our models if we assume an optical depth of $\sim$10-20 along the line-of-sight through each torus component. The observed MIR fine structure lines can be explained by photoionization modeling only when taking into account extinction due to dust inside the torus. This is consistent with previous results showing that AGN tori have large covering factors. Our analysis shows that the obscuring material has a temperature distribution peaking around $300\,000\,K$. Finally, we discuss how these findings may affect current ideas about the geometry of AGN tori.",arxiv,bigscience bloomz,704.0547,0.3333333333333333,0.24369747899159663,0.7487179487179487,0.3463927376970855,1,1,0,0,0,1,1,0,0,0,0.1204659156680662,0.10770583739587361,0.10894941634241245,0.07575757575757576,0,0,5,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On the Information Rate of MIMO Systems with Finite Rate Channel State Feedback and Power On/Off Strategy,"  This paper quantifies the information rate of multiple-input multiple-output
(MIMO) systems with finite rate channel state feedback and power on/off
strategy. In power on/off strategy, a beamforming vector (beam) is either
turned on (denoted by on-beam) with a constant power or turned off. We prove
that the ratio of the optimal number of on-beams and the number of antennas
converges to a constant for a given signal-to-noise ratio (SNR) when the number
of transmit and receive antennas approaches infinity simultaneously and when
beamforming is perfect. Based on this result, a near optimal strategy, i.e.,
power on/off strategy with a constant number of on-beams, is discussed. For
such a strategy, we propose the power efficiency factor to quantify the effect
of imperfect beamforming. A formula is proposed to compute the maximum power
efficiency factor achievable given a feedback rate. The information rate of the
overall MIMO system can be approximated by combining the asymptotic results and
the formula for power efficiency factor. Simulations show that this
approximation is accurate for all SNR regimes.
","In this work, we consider a multiple-input-multiple-output (MIMO) system where each transmitter has limited feedback information about its channel state to the receiver. We assume that there is no cooperation between transmitters in terms of power allocation or transmission strategies. Each transmitter can only adjust its own transmit power level based on local CSI knowledge at the transmitter side. In addition, each transmitter may turn off its radio completely when it does not have any data to send. The objective is to maximize the sum rate by optimizing both the power control policy as well as the transmission strategy for all users simultaneously under these constraints. 
 
 First, we derive an upper bound on the achievable sum-rate using finite-rate feedback assuming Gaussian codebooks. Then, we propose two algorithms to solve the optimization problem numerically. Finally, simulation results are presented to show the performance gain achieved by our proposed algorithm over existing schemes.",arxiv,bigscience bloomz,705.2273,0.3888888888888889,0.3445378151260504,0.2512820512820513,0.38652651696129964,1,1,0,0,0,1,1,0,0,0,0.08856980332998064,0.03840018470235264,0.07782101167315175,0.026515151515151516,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1
On the nature of two superconducting transitions in the specific heat of PrOs$_4$Sb$_{12}$: Effects of crystal grinding,"  Specific heat, dc- and ac-magnetic susceptibility are reported for a large
single crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room
temperature effective paramagnetic moment of the crystal was consistent with
the Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The
crystal showed two distinct anomalies in the specific heat and an overall
discontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at
$T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at
$T_{c2}$ was very sharp, consistent with a good quality of the crystal. We
observed a shoulder in $\chi$' and two peaks in $\chi$'' below $T_{c1}$.
However, there were no signatures in $\chi$' of the lower temperature
transition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which
suppresses the upper superconducting transition in both the specific heat and
magnetic susceptibility. $\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in
the powdered sample. Existing data on ground, polished, and sliced crystals
suggests the existence of a length scale of order 100 $\mu$, characterizing the
higher temperature superconducting phase.
","We report on measurements of the specific heat and magnetic susceptibility for single crystals of PrOs$_{4}$Sb$_{12}$$ The results show that there are at least three different phases, including an antiferromagnetic phase below $T_{1/2} = 1.5 K$ (the Néel temperature), a paramagnetic phase between $1.5 K < T < 5.8 K$, and another phase above $5.8 K$ which is not yet understood.  We also find that the specific heat data can be fitted with two separate power laws near the transition temperatures, suggesting that there may be more than one type of order parameter involved in this system. Finally we discuss how our results compare to previous studies of this material. PACS: 75.10.Pq, 74.20.-q, 76.30.+z 
I. INTRODUCTORY REMARk
The heavy fermion compound PrOs$_{4}\sb{_2}$Sb$_{12} $ has been studied extensively since its discovery by de Haas-van Alphen effect [1] . It was found to have several interesting properties such as non-Fermi liquid behavior [2] , unconventional superconductivity [3] , and quantum criticality [4] .
In particular, it shows two distinct superconducting transitions in both resistivity [5] and specific heat [6] experiments. However, these features were observed only after the sample had undergone severe mechanical stress during the measurement process [7, 8] . This suggests that the physical properties of PrOs$_{4}$$\sb{_2}$$ Sb$_{12} $ might depend strongly on the microscopic structure of the samples [9] .  In fact, recent theoretical calculations suggest that the ground state of PrOs$_{4}}$$\sb{_2}$ Sb$_{12} $ should contain multiple competing orders [10] . Therefore, it would be very important to study the effects of external perturbations on the physical properties of this material [11] .",arxiv,bigscience bloomz,705.4659,0.5,0.49579831932773116,0.2564102564102564,0.7104634495938844,1,1,0,0,1,1,1,1,0,0,0.05072002687742309,0.17921731032996452,0.058365758754863814,0.18181818181818182,0,1,0,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Strongly modulated transmission of a spin-split quantum wire with local Rashba interaction,"  We investigate the transport properties of ballistic quantum wires in the
presence of Zeeman spin splittings and a spatially inhomogeneous Rashba
interaction. The Zeeman interaction is extended along the wire and produces
gaps in the energy spectrum which allow electron propagation only for spinors
lying along a certain direction. For spins in the opposite direction the waves
are evanescent far away from the Rashba region, which plays the role of the
scattering center. The most interesting case occurs when the magnetic field is
perpendicular to the Rashba field. Then, the spins of the asymptotic
wavefunctions are not eigenfunctions of the Rashba Hamiltonian and the
resulting coupling between spins in the Rashba region gives rise to sudden
changes of the transmission probability when the Fermi energy is swept along
the gap. After briefly examining the energy spectrum and eigenfunctions of a
wire with extended Rashba coupling, we analyze the transmission through a
region of localized Rashba interaction, in which a double interface separates a
region of constant Rashba interaction from wire leads free from spin-orbit
coupling. For energies slightly above the propagation threshold, we find the
ubiquitous occurrence of transmission zeros (antiresonances) which are analyzed
by matching methods in the one-dimensional limit. We find that a a minimal
tight-binding model yields analytical transmission lineshapes of Fano
antiresonance type. More general angular dependences of the external magnetic
field is treated within projected Schroedinger equations with Hamiltonian
matrix elements mixing wavefunction components. Finally, we consider a
realistic quantum wire where the energy subbands are coupled via the Rashba
intersubband coupling term and discuss its effect on the transmission zeros.
","We study the transport properties in a one-dimensional (1D) spin-orbit coupled system, where the electron-electron interactions are treated within the Hartree-Fock approximation. We find that for strong enough spin-orbit coupling and repulsive interactions there is an insulating phase at half-filling which can be understood as a Mott insulator due to the formation of bound states between electrons on neighboring sites. The transition into this state occurs when the Fermi energy crosses the lowest bound state. In addition we show how the presence of disorder changes these results. Finally, we discuss possible experimental realizations of our model using semiconductor nanowires or carbon nanotubes. Introduction:-In recent years it has been realized that many interesting phenomena observed in condensed matter physics such as high-Tc superconductivity [1] , fractional quantum Hall effect [2] etc., have their origin in strongly correlated electronic systems. One of the simplest models describing interacting fermions is the Hubbard model [3] . However, even though much progress has been made over the past few decades [4] , exact solutions of the Hubbard model are still lacking [5] .
Recently, several authors [6] - [8] studied the effects of spin-orbit coupling on the ground-state properties of 1D Hubbard chains by employing various numerical techniques like density matrix renormalization group [9] , exact diagonalization [10] , DMRG [11] , Bethe ansatz [12] , variational Monte Carlo [13] , Quantum Monte Carlo [14] etc.. It was found that depending upon the strength of spin-orbit coupling and the value of Coulomb repulsion U , different phases appear in the ground state. For example, if the spin-orbit coupling is weak compared to the hopping amplitude t then the ground state is either metallic or insulating depending on whether U/t < 2 or U/t > 2 respectively [15] . On the other hand, if the spin-orbit",arxiv,bigscience bloomz,706.0107,0.5,0.546218487394958,0.7333333333333333,0.8136645962732919,1,1,0,0,0,1,1,1,0,0,0.09534023523913832,0.1457708833033582,0.10894941634241245,0.15151515151515152,0,1,2,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
"Search for a kaonic nuclear state via $^4$He$(K^-, N)$","  Very recently, we have performed a couple of experiments, {\it{KEK
PS-E549/E570}}, for the detailed study of the strange tribaryon $S^0(3115)$
obtained in {\it{KEK PS-E471}}. These experiments were performed to accumulate
much higher statistics with improved experimental apparatusespecially for the
better proton spectroscopy of the $^4$He({\it{stopped K}}$^-$, {\it{N}})
reaction. In contrast to the previous proton spectrum, no narrow ($\sim$ 20
MeV) peak structure was found either in the inclusive $^4$He({\it{stopped
K}}$^-$, {\it{p}}) or in the semi-inclusive $^4$He({\it{stopped K}}$^-$,
{\it{p}}$X^\pm$) reaction channel, which is equivalent to the previous $E471$
event trigger condition. Detailed analysis of the present data and simulation
shows that the peak, corresponding to $S^0(3115)$, has been an experimental
artifact. Present analysis does not exclude the possible existence of a much
wider structure. To be sensitive to such structure and for better understanding
of the non-mesonic $K^-$ absorption reaction channel, detailed analysis of the
data is in progress.
","We report on the search for a K-nuclear bound state in 4 He using the reaction $^4$He (K - , n). The experiment was performed at TRIUMF with an incident beam energy of 1 GeV and a target thickness of 0.5 cm. A total number of 2.1 x 10 9 events were recorded by two large area silicon strip detectors placed downstream of the target. No evidence is found for such a state within the kinematic limits set by the experimental resolution. Upper limits are determined as a function of the binding energy B and the width Γ of the hypothetical state. For a narrow resonance with B = 50 MeV/c2 we find that the upper limit to its production cross section is 3 nb/sr at 90% confidence level. This corresponds to a lower limit on the coupling constant gNN of the order of 5 x 10 -4 . 
The results presented here represent one of the most stringent constraints yet obtained on this type of exotic nuclear structure. 
 
 Keywords: Kaon nucleus interaction",arxiv,bigscience bloomz,706.0297,0.2777777777777778,0.3949579831932773,0.1282051282051282,0.4495938843764931,1,1,0,0,0,1,1,1,0,0,0.24456559264874345,0.053339307974029256,0.25680933852140075,0.045454545454545456,0,1,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Characterization of the Soluble Nanoparticles Formed through Coulombic Interaction of Bovine Serum Albumin with Anionic Graft Copolymers at Low pH,"  A static light scattering (SLS) study of bovine serum albumin (BSA) mixtures
with two anionic graft copolymers of poly (sodium acrylate-co-sodium
2-acrylamido-2-methyl-1-propanesulphonate)-graft-poly (N,
N-dimethylacrylamide), with a high composition in poly (N,
N-dimethylacrylamide) (PDMAM) side chains, revealed the formation of oppositely
charged complexes, at pH lower than 4.9, the isoelectric point of BSA. The
core-corona nanoparticles formed at pH = 3.00, were characterized. Their
molecular weight and radius of gyration were determined by SLS, while their
hydrodynamic radius was determined by dynamic light scattering. Small angle
neutron scattering measurements were used to determine the radius of the
insoluble complexes, comprising the core of the particles. The values obtained
indicated that their size and aggregation number of the nanoparticles, were
smaller when the content of the graft copolymers in neutral PDMAM side chains
was higher. Such particles should be interesting drug delivery candidates, if
the gastrointestinal tract was to be used.
","The formation and characterization of bovine serum albumin (BSA) nanoparticles formed by electrostatic interaction between anionic graft copolymer poly(acrylic acid-co-methacrylamide) (PAM-g-PAA) and protein in aqueous solution are reported here. The size, shape, surface charge density distribution, zeta potential, and stability of these particles were investigated as functions of polymer concentration, ionic strength, temperature, and pH value. It was found that PAM-g-PAA/BSA nanoparticles could be prepared over wide ranges of conditions. At low pH values, the particle sizes increased slightly with increasing polymer concentrations due to the increase in intermolecular interactions among proteins. However, when the pH value reached 7.0, the particle sizes decreased significantly because of the decrease in net charges on both polymers and proteins. In addition, it is shown that the shapes of PAM-g-PAA/protein nanoparticles changed from spherical to ellipsoidal or rod-like structures depending upon the pH values.",arxiv,bigscience bloomz,705.3707,0.2777777777777778,0.24369747899159663,0.13333333333333333,0.35499283325370284,1,1,0,0,0,1,1,0,0,0,0.1899756688061071,0.060607668124709795,0.23346303501945526,0.06060606060606061,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"On the morphologies, gas fractions, and star formation rates of small galaxies","  We use a series of N-body/smoothed particle hydrodynamics simulations and
analytic arguments to show that the presence of an effective temperature floor
in the interstellar medium at T_F ~ 10^4 K naturally explains the tendency for
low-mass galaxies to be more spheroidal, more gas rich, and less efficient in
converting baryons into stars than larger galaxies. The trend arises because
gas pressure support becomes important compared to angular momentum support in
small dark matter haloes. We suggest that dwarf galaxies with rotational
velocities ~ 40 km/s do not originate as thin discs, but rather are born as
thick, puffy systems. If accreted on to larger haloes, tenuous dwarfs of this
kind will be more susceptible to gas loss or tidal transformation than
scaled-down versions of larger spirals. For a constant temperature floor,
pressure support becomes less important in large haloes, and this produces a
tendency for massive isolated galaxies to have thinner discs and more efficient
star formation than their less massive counterparts, as observed.
","We present new results on the morphological properties, gas content, and star-formation activity in a sample of low-mass (M* < 1010 M⊙) galaxies at z = 0.5 − 1.0 drawn from the GOODS-North field. We use deep HST/ACS imaging to measure galaxy sizes, Sérsic indices, and bulge-to-disk ratios for these objects. In addition we obtain Spitzer/MIPS 24µm photometry which allows us to estimate their total infrared luminosities as well as dust-corrected SFRs using the prescription of Kennicutt et al. (2009) . Our main findings are summarized below:  -The majority of our sample is composed by disk-dominated systems with n < 2. The median value of B/T is 0.3 ± 0.1.  -There exists an anti-correlation between stellar mass and size that can be explained if most of this population has experienced recent episodes of intense star formation. This would have caused them to expand significantly while still being dominated by young stars.  -Most of the galaxies in our sample show high specific star-formation rates (SSFR > 10^-10 yr-1). These values are comparable or even higher than those found among local dwarf irregular galaxies. -Our data suggest that there may exist two different populations within our sample. One group shows relatively large sizes and low SSFRs indicative of quiescent disks. A second class displays smaller sizes but much higher SSFRs suggesting they could be undergoing rapid growth through mergers and/or accretion events.",arxiv,bigscience bloomz,706.021,0.2222222222222222,0.596638655462185,0.2153846153846154,0.6129956999522218,0,1,0,0,0,1,1,1,0,0,0.13168016438715893,0.07405381133361152,0.1517509727626459,0.07954545454545454,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Refuting the Pseudo Attack on the REESSE1+ Cryptosystem,"  We illustrate through example 1 and 2 that the condition at theorem 1 in [8]
dissatisfies necessity, and the converse proposition of fact 1.1 in [8] does
not hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for
f(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a
logic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4
to be invalid. Demonstrate through ex.4 and 5 that each or the combination of
qu+1 > qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) +
f(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4
and alg.2 based on table 1 are disordered and wrong logically. Further,
manifest through a repeated experiment and ex.5 that the data at table 2 is
falsified, and the example in [8] is woven elaborately. We explain why Cx = Ax
* W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To
the signature fraud, we point out that [8] misunderstands the existence of T^-1
and Q^-1 % (M-1), and forging of Q can be easily avoided through moving H.
Therefore, the conclusion of [8] that REESSE1+ is not secure at all (which
connotes that [8] can extract a related private key from any public key in
REESSE1+) is fully incorrect, and as long as the parameter Omega is fitly
selected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure.
","The authors present an attack against the REESSE1+ cryptosystem, which is based on the hardness of solving certain lattice problems.  They show that this system can be broken in polynomial time using their algorithm and they provide experimental results to demonstrate its efficiency.   The authors conclude by discussing possible countermeasures for the system. This work was supported by the National Science Foundation under Grant No. CCF-0430018. Authors:  Yi-Cheng Chang (Chang), Chih-Chin Chen (Chen), Hsinchu, Taiwan; Ming-Hsuan Wu (Wu), Taipei, Taiwan; Yu-Ting Lin (Lin), Taichung, Taiwan; Shih-Fang Tsai (Tsai), Taipei, Taiwan; Wen-Jen Lee (Lee), Taipei, Taiwan; Kuo-Yi Huang (Huang), Taipei, Taiwan; Tzi-Chao Chan (Chan), Taipei, Taiwan; Chin-Long Yeh (Yeh), Taipei, Taiwan; Chung-Ming Liu (Liu), Taipei, Taiwan; Yuan-Youh Chen (Chen), Taipei, Taiwan; Jyh-Shing Wang (Wang), Taipei, Taiwan; Cheng-Wei Lai (Lai), Taipei, Taiwan",arxiv,bigscience bloomz,704.0492,0.2777777777777778,0.24369747899159663,0.717948717948718,0.3263258480649785,1,1,0,0,0,1,1,1,0,0,0.2573126990012826,0.3764493554265168,0.2529182879377432,0.4583333333333333,0,1,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
Efficient Multidimensional Data Redistribution for Resizable Parallel Computations,"  Traditional parallel schedulers running on cluster supercomputers support
only static scheduling, where the number of processors allocated to an
application remains fixed throughout the execution of the job. This results in
under-utilization of idle system resources thereby decreasing overall system
throughput. In our research, we have developed a prototype framework called
ReSHAPE, which supports dynamic resizing of parallel MPI applications executing
on distributed memory platforms. The resizing library in ReSHAPE includes
support for releasing and acquiring processors and efficiently redistributing
application state to a new set of processors. In this paper, we derive an
algorithm for redistributing two-dimensional block-cyclic arrays from $P$ to
$Q$ processors, organized as 2-D processor grids. The algorithm ensures a
contention-free communication schedule for data redistribution if $P_r \leq
Q_r$ and $P_c \leq Q_c$. In other cases, the algorithm implements circular row
and column shifts on the communication schedule to minimize node contention.
","We present an efficient data redistribution scheme that allows the parallel execution of computations on dynamically resized computational domains in distributed memory environments. The proposed approach is based on multidimensional block-cyclic distributions and exploits locality by using space-filling curves to map blocks onto processors. We show how this technique can be used to efficiently redistribute data between different processor configurations, while minimizing communication overheads. Our experimental results demonstrate significant performance improvements over existing approaches when executing applications with dynamic load balancing requirements. In particular, we achieve speedups up to 3Â compared to state-of-the-art techniques such as the one presented in [1] . 
Introduction

Parallel computing has become increasingly important due to its ability to solve large problems faster than serial computers [2] , but it also presents new challenges related to the distribution of work among multiple processing units [3] .
In order to take advantage of parallelism, many algorithms are designed so that they can run simultaneously on several processors [4] . However, these algorithms often require some form of data redistribution during their execution [5] . For example, consider a computation where each process stores part of a dataset (e.g., matrix) [6] . If the number of processes changes at runtime, then all processes need to exchange information about which parts of the dataset they store before continuing [7] . This problem becomes even more challenging if the size of the datasets stored by individual processes varies [8] or if there are dependencies between them [9] .",arxiv,bigscience bloomz,706.2146,0.3333333333333333,0.24369747899159663,0.12307692307692308,0.31055900621118016,0,1,0,0,0,1,1,0,0,0,0.048877077430422036,0.06502558963743038,0.0622568093385214,0.06060606060606061,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,0,1,1
Deformation principle and further geometrization of physics,"  The space-time geometry is considered to be a physical geometry, i.e. a
geometry described completely by the world function. All geometrical concepts
and geometric objects are taken from the proper Euclidean geometry. They are
expressed via the Euclidean world function \sigma_E and declared to be concepts
and objects of any physical geometry, provided the Euclidean world function
\sigma_E is replaced by the world function \sigma of the physical geometry in
question. The set of physical geometries is more powerful, than the set of
Riemannian geometries, and one needs to choose a true space-time geometry. In
general, the physical geometry is multivariant (there are many vectors which
are equivalent to a given vector, but are not equivalent between themselves).
The multivariance admits one to describe quantum effects as geometric effects
and to consider existence of elementary particles as a geometrical problem,
when the possibility of the physical existence of an elementary geometric
object in the form of a physical body is determined by the space-time geometry.
Multivariance admits one to describe discrete and continuous geometries, using
the same technique. A use of physical geometry admits one to realize the
geometrical approach to the quantum theory and to the theory of elementary
particles.
","The deformation principle is the main tool in this article for constructing new geometric structures on physical spaces, which are not necessarily Riemannian manifolds but can be more general objects such as Finsler or pseudo-Finsler ones.  The basic idea behind it consists in deforming an initial space into another one by means of some suitable transformation group acting transitively on both spaces. This method allows to obtain many interesting results concerning various aspects of geometry and physics (e.g., geodesic flows,...). In particular, we show that any homogeneous Finsler manifold admits a canonical connection with totally skew-symmetric torsion whose curvature tensor satisfies certain properties similar to those satisfied by the Weyl conformal curvature tensor. We also prove that every locally Minkowski spacetime has a natural generalization of the Poincaré metric, called the generalized Poincaré metric, which turns out to be invariant under all local Lorentz transformations. Finally, we present several examples illustrating our approach.",arxiv,bigscience bloomz,704.3003,0.4444444444444444,0.24369747899159663,0.4,0.3922599139990445,1,1,0,0,0,1,1,0,0,0,0.12310980373255787,0.08031946370254216,0.13229571984435798,0.07954545454545454,1,1,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1
Midlatitude Cirrus Clouds and Multiple Tropopauses from a 2002-2006 Climatology over the SIRTA Observatory,"  This study present a comparison of lidar observations of midlatitude cirrus
clouds over the SIRTA observatory between 2002 and 2006 with multiple
tropopauses (MT) retrieved from radiosounding temperature profiles. The
temporal variability of MT properties (frequency, thickness) are discussed.
Results show a marked annual cycle, with MT frequency reaching its lowest point
in May (~18% occurrence of MT) and slowly rising to more than 40% in DJF. The
average thickness of the MT also follows an annual cycle, going from less than
1 km in spring to 1.5 km in late autumn. Comparison with lidar observations
show that cirrus clouds show a preference for being located close below the 1st
tropopause. When the cloud top is above the 1st tropopause (7% of
observations), in 20% of cases the cloud base is above it as well, resulting in
a cirrus cloud ""sandwiched"" between the two tropopauses. Compared to the
general distribution of cirrus, cross-tropopause cirrus show a higher frequency
of large optical depths, while inter-tropopause cirrus show almost exclusively
low optical depths (Tau < 0.03 in 90% of cases) typical of subvisible clouds.
Results suggest the occurrence of inter-tropopause cirrus clouds is correlated
with the frequency of multiple tropopauses.
","Cirrus clouds are an important component in Earth's radiation budget, but their radiative properties remain poorly understood because they occur at high altitude where direct measurements are difficult to make. In this study we use data collected by the Scripps Institution of Oceanography (SIO) lidar system located on the SIRTA observatory near Paris during [2002] [2003] [2004] [2005] [2006] . The observations show that cirrus clouds can be found between 5 km and 12 km above sea level with a mean optical depth of 0.2 ± 0.1. We find that mid-latitude cirrus clouds have multiple tropopause features such as double or triple tropopauses which may affect their microphysical structure. These results suggest that cirrus clouds play an important role in determining the vertical distribution of water vapor in the atmosphere. Citation: 
Introduction

Cirrus clouds cover about 10%-20% of the globe's surface area [Sassen et al., 2008] , yet little is known about how these clouds form and evolve. They are particularly challenging to observe since they occur at high altitudes (5-12km), where temperatures are low enough for ice particles to exist, but too cold for liquid droplets to condense. As a result, most information about cirrus clouds comes indirectly through remote sensing techniques using instruments like lidars, radars, satellites, and aircrafts. However, each instrument has its own strengths and weaknesses depending upon the measurement technique used. For example, ground-based lidars provide accurate profiles of cloud height and extinction coefficients, while satellite retrieval algorithms suffer from poor spatial resolution and uncertainties associated with aerosol contamination.",arxiv,bigscience bloomz,705.2517,0.3888888888888889,0.2184873949579832,0.38461538461538464,0.3177257525083612,1,1,0,0,0,2,2,1,0,2,0.10106270671007395,0.07913002623808685,0.10116731517509728,0.041666666666666664,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1
Spectral type dependent rotational braking and strong magnetic flux in three components of the late-M multiple system LHS 1070,"  We show individual high resolution spectra of components A, B, and C of the
nearby late-M type multiple system LHS 1070. Component A is a mid-M star, B and
C are known to have masses at the threshold to brown dwarfs. From our spectra
we measure rotation velocities and the mean magnetic field for all three
components individually. We find magnetic flux on the order of several
kilo-Gauss in all components. The rotation velocities of the two late-M objects
B and C are similar (vsini = 16km/s), the earlier A component is spinning only
at about half that rate. This suggests weakening of net rotational braking at
late-M spectral type, and that the lack of slowly rotating late-M and L dwarfs
is real. Furthermore, we found that magnetic flux in the B component is about
twice as strong as in component C at similar rotation rate. This indicates that
rotational braking is not proportional to magnetic field strength in fully
convective objects, and that a different field topology is the reason for the
weak braking in low mass objects.
","We report on spectropolarimetric observations of the M8+M9 binary star LHS 1070A,B (GJ 436) with ESPaDOnS at CFHT. The two stars are separated by only 0. ′′ 1 and have been known to be magnetically active for many years. We find that both stars show significant circularly polarized emission lines indicative of Zeeman splitting due to their magnetic fields. In addition we detect Stokes V signatures indicating net linear polarization across all observed spectral lines. This is likely caused by scattering processes within the stellar atmosphere. Using our new data set together with previously published photometric measurements we derive rotation periods of P A = 3.6 ± 0.1 days and P B = 4.2 ± 0.3 days for the primary and secondary component respectively. These values are significantly longer than those derived from previous studies which were based solely on photometry. Our results suggest that the rotation period of each individual component depends strongly on its effective temperature as well as its surface gravity.",arxiv,bigscience bloomz,706.2139,0.3888888888888889,0.3949579831932773,0.28717948717948716,0.4237935977066412,1,1,0,0,0,1,0,0,0,0,0.0617177273455541,0.06979645555810432,0.07003891050583658,0.08712121212121213,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Koszul duality in deformation quantization, I","  Let $\alpha$ be a polynomial Poisson bivector on a finite-dimensional vector
space $V$ over $\mathbb{C}$. Then Kontsevich [K97] gives a formula for a
quantization $f\star g$ of the algebra $S(V)^*$. We give a construction of an
algebra with the PBW property defined from $\alpha$ by generators and
relations. Namely, we define an algebra as the quotient of the free tensor
algebra $T(V^*)$ by relations $x_i\otimes x_j-x_j\otimes x_i=R_{ij}(\hbar)$
where $R_{ij}(\hbar)\in T(V^*)\otimes\hbar \mathbb{C}[[\hbar]]$, $R_{ij}=\hbar
\Sym(\alpha_{ij})+\mathcal{O}(\hbar^2)$, with one relation for each pair of
$i,j=1...\dim V$. We prove that the constructed algebra obeys the PBW property,
and this is a generalization of the Poincar\'{e}-Birkhoff-Witt theorem. In the
case of a linear Poisson structure we get the PBW theorem itself, and for a
quadratic Poisson structure we get an object closely related to a quantum
$R$-matrix on $V$. At the same time we get a free resolution of the deformed
algebra (for an arbitrary $\alpha$).
  The construction of this PBW algebra is rather simple, as well as the proof
of the PBW property. The major efforts should be undertaken to prove the
conjecture that in this way we get an algebra isomorphic to the Kontsevich
star-algebra.
","We give an explicit formula for the star product on the cotangent bundle $T^*M$ over a Poisson manifold $(M,\pi)$ with symplectic leaves $L_i$ and corresponding moment maps $\mu_i : T^*M \to L_i$.  We show that this star product is given by the formula 
$$ (f \star g)(x) = \sum_{i=0}^n f(x)g(\mu_i^{-1}(x)) \pi^{ij}(x)  $$
where $\pi^{ij}$ are the components of the inverse matrix to the Poisson tensor $\pi_{ij}$. 
This result generalizes earlier results obtained by Kontsevich [K] , Fedosov [F]  and others.   It also gives a new proof of the fact that the star product is uniquely determined up to isomorphism by its properties of associativity and commutativity.    The main idea behind our approach is to use the formalism of Koszul complexes developed by Getzler [G1] .",arxiv,bigscience bloomz,706.2381,0.4444444444444444,0.19327731092436976,0.3487179487179487,0.3119923554706163,1,1,0,0,1,1,1,1,0,0,0.22836440588927848,0.18573746315793488,0.3035019455252918,0.19696969696969696,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Luminosity function of binary X-ray sources calculated using the Scenario Machine,"  Using the ``Scenario Machine'' we have carried out a population synthesis of
X-ray binaries for the purpose of modelling of X-ray luminosity functions
(XLFs) in different types of galaxies: star burst, spiral, and elliptical. This
computer code allows to calculate, by using Monte Carlo simulations, the
evolution of a large ensemble of binary systems, with proper accounting for the
spin evolution of magnetized neutron stars.
  We show that the XLF has no universal type. It depends on the star formation
rate in the galaxy. Also it is of importance to take into account the evolution
of binary systems and life times of X-ray stages in theoretical models of such
functions. We have calculated cumulative and differential XLFs for the galaxy
with the constant star formation rate. Also we have calculated cumulative
luminosity functions for different intervals of time after the star formation
burst in the galaxy and curves depicting the evolution of the X-ray luminosity
after the star formation burst in the galaxy.
","We present here an application of the Scenario Machine (SM) to calculate the luminosity functions for different types of binaries in our Galaxy, including black hole and neutron star systems as well as white dwarf - main sequence stars. The SM is used to generate synthetic populations of these objects by assuming that they are formed according to some initial mass distribution and evolve through various stages following evolutionary tracks obtained from stellar evolution calculations. We find good agreement between the results of this method with those derived from observations. This work was supported by NASA grant NAG5-10842. Keywords: Binary X-rays Sources; Luminosity Function; Stellar Evolutionary Tracks. 1 Introduction X-ray binaries are composed of either two neutron stars or one neutron star plus another object such as a black hole or a white dwarf. They can be divided into three categories based on their orbital periods; short-period (P orb < 3 hrs), intermediate-period (3 hrs < P orb < 100 days), and long-period (P orb > 100 days). In addition there exist several classes of X-ray transients which have been observed at all periods but whose nature has not yet been determined conclusively [1] . These include soft X-ray transients, supersoft X-ray transients, classical novae, symbiotic stars, recurrent Novae, and microquasars [2] .
The number density of X-ray binaries per unit volume depends upon both the formation rate of binaries and how many survive until they become detectable [3] . Since most of them are located within 10 kpc of Earth [4] , it is possible to estimate the total number of X-ray binaries in our galaxy if we know the space density of each type of system [5] . However, since only about 10% of known Galactic X-ray binaries have measured distances [6] , it is difficult to determine the true space densities accurately. Therefore, it becomes necessary to use other methods to obtain estimates of the space density of X-ray binaries [7, 8] .",arxiv,bigscience bloomz,705.286,0.3333333333333333,0.596638655462185,0.20512820512820512,0.8881987577639752,1,1,1,0,1,1,1,1,0,0,0.11767937126614754,0.09375836308661353,0.09727626459143969,0.06439393939393939,1,1,3,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Variation of the Amati Relation with the Cosmological Redshift: a Selection Effect or an Evolution Effect?,"  Because of the limit in the number of gamma-ray bursts (GRBs) with available
redshifts and spectra, all current investigations on the correlation among GRB
variables use burst samples with redshifts that span a very large range. The
evolution and selection effects have thus been ignored, which might have
important influence on the results. In this Letter, we divide the 48
long-duration GRBs in Amati (2006, 2007) into four groups with redshift from
low to high, each group contains 12 GRBs. Then we fit each group with the Amati
relation $\log E_\iso = a + b \log E_\p$, and check if the parameters $a$ and
$b$ evolve with the GRB redshift. We find that $a$ and $b$ vary with the mean
redshift of the GRBs in each group systematically and significantly.
Monte-Carlo simulations show that there is only $\sim 4$ percent of chance that
the variation is caused by the selection effect arising from the fluence limit.
Hence, our results may indicate that GRBs evolve strongly with the cosmological
redshift.
","We have studied the variation of the Amati relation (Amati et al., 2002) in a sample of about 100 GRBs detected by Swift satellite and we found that it is not constant, but varies as a function of redshift z. We also find that this effect cannot be explained only by selection effects due to detector thresholds. 
 
 The observed evolution can be described by a power law dependence on cosmological time t~(1+z)3.5. This result suggests that there may exist some physical mechanism responsible for such behaviour. In particular, we suggest that the luminosity distance dL could play a role in determining the shape of the spectrum at high energies. If so, then the spectral properties of GRB prompt emission are related to its intrinsic luminosity rather than being determined solely by the geometry of the emitting region. 
The results presented here support previous claims that the Amati relation should be used cautiously when applied to distant bursts.",arxiv,bigscience bloomz,704.3128,0.3333333333333333,0.29411764705882354,0.2358974358974359,0.4037267080745342,1,1,0,0,0,1,0,0,0,0,0.0836890046585325,0.07850434010310392,0.08171206225680934,0.08333333333333333,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Interpreting and predicting the yield of transit surveys: Giant planets in the OGLE fields,"  Transiting extrasolar planets are now discovered jointly by photometric
surveys and by radial velocimetry. We want to determine whether the different
data sets are compatible between themselves and with models of the evolution of
extrasolar planets. We simulate directly a population of stars corresponding to
the OGLE transit survey and assign them planetary companions based on radial
velocimetry discoveries. We use a model of the evolution and structure of giant
planets assuming a variable fraction of heavy elements. The output list of
detectable planets of the simulations is compared to the real detections. We
confirm that the radial velocimetry and photometric survey data sets are
compatible within the statistical errors, assuming that planets with periods
between 1 and 2 days are approximately 5 times less frequent than planets with
periods between 2 and 5 days. We show that evolution models fitting present
observational constraints predict a lack of small giant planets with large
masses. We also identify distinct populations of planets: those with short
periods (P < 10d) are only found in orbit around metal-rich stars with [Fe/H] >
-0.07. We further confirm the relative absence of low-mass giant planets at
small orbital distances.
","We present an analysis of the properties of giant planet candidates detected by the Optical Gravitational Lensing Experiment (OGLE) survey, which has been monitoring stars towards the Galactic bulge for more than ten years. We find that most of these systems are likely to be composed of two low-mass objects with masses below 0.5 MJup orbiting each other on periods longer than 100 days. The majority of them have orbital inclinations close to 90 degrees. These results suggest that many of the planetary mass companions found around nearby solar-type stars may also exist around distant red giants. This is important because it allows us to study their atmospheric composition using high-resolution spectroscopy. 
 
 Keywords: Planetary systems; Planets; Transiting exoplanet searches; Red-giant stars; Bulge; Massive star formation; Stellar evolution; Extrasolar planets; Astrophysics",arxiv,bigscience bloomz,704.1919,0.4444444444444444,0.24369747899159663,0.3641025641025641,0.3263258480649785,1,1,1,0,0,1,1,1,0,0,0.08606459076658539,0.07400228881799643,0.10894941634241245,0.056818181818181816,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Local purity distillation with bounded classical communication,"  Local pure states are an important resource for quantum computing. The
problem of distilling local pure states from mixed ones can be cast in an
information theoretic paradigm. The bipartite version of this problem where
local purity must be distilled from an arbitrary quantum state shared between
two parties, Alice and Bob, is closely related to the problem of separating
quantum and classical correlations in the state and in particular, to a measure
of classical correlations called the one-way distillable common randomness. In
Phys. Rev. A 71, 062303 (2005), the optimal rate of local purity distillation
is derived when many copies of a bipartite quantum state are shared between
Alice and Bob, and the parties are allowed unlimited use of a unidirectional
dephasing channel. In the present paper, we extend this result to the setting
in which the use of the channel is bounded. We demonstrate that in the case of
a classical-quantum system, the expression for the local purity distilled is
efficiently computable and provide examples with their tradeoff curves.
","We consider the problem of local purification in quantum networks, where each node is allowed to perform only local operations and communicate classically with its neighbors. We show that for any graph G = (V, E) there exists an algorithm which transforms any pure state on V into another pure state such that:  1. The number of qubits communicated between neighboring nodes does not exceed O(log n), where n is the size of the network.  2. Each node performs at most polylogarithmic many local operations. Our result implies that if we allow unlimited amount of entanglement then it suffices to use only logarithmic amount of classical communication per edge. This improves upon previous results by Aaronson et al., who showed that Ω(n log n) bits are necessary even when all states are restricted to be product states. In addition our result shows how to constructively convert this bound into an efficient protocol.",arxiv,bigscience bloomz,705.4089,0.3888888888888889,0.3445378151260504,0.24615384615384617,0.38939321548017203,1,1,0,0,0,1,0,1,0,0,0.17850696455105222,0.08946548721315774,0.2140077821011673,0.07575757575757576,2,2,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Optical implementation and entanglement distribution in Gaussian valence bond states,"  We study Gaussian valence bond states of continuous variable systems,
obtained as the outputs of projection operations from an ancillary space of M
infinitely entangled bonds connecting neighboring sites, applied at each of $N$
sites of an harmonic chain. The entanglement distribution in Gaussian valence
bond states can be controlled by varying the input amount of entanglement
engineered in a (2M+1)-mode Gaussian state known as the building block, which
is isomorphic to the projector applied at a given site. We show how this
mechanism can be interpreted in terms of multiple entanglement swapping from
the chain of ancillary bonds, through the building blocks. We provide optical
schemes to produce bisymmetric three-mode Gaussian building blocks (which
correspond to a single bond, M=1), and study the entanglement structure in the
output Gaussian valence bond states. The usefulness of such states for quantum
communication protocols with continuous variables, like telecloning and
teleportation networks, is finally discussed.
","We propose an optical scheme for implementing the Gaussian valence bond (GVB) state, which is one of the most important classes of quantum states in condensed matter physics. The GVB state can be used to describe many-body systems with strong correlations such as spin liquids or Mott insulators. We show that our proposed scheme allows us to distribute entanglement between two distant parties by using only linear optics elements and single-photon sources. Our results may have potential applications in quantum information processing. 
 
 Introduction 
 
 Quantum entanglement plays a crucial role in various fields ranging from quantum communication [1] , quantum metrology [2] , quantum sensing [3] , and quantum computing [4] . In particular, it has been shown that quantum entangled states are useful resources for quantum teleportation [5] , superdense coding [6] , remote state preparation [7] , and quantum key distribution [8] .
 
In recent years, there has been growing interest in studying quantum entanglement in many-body systems [9] - [11] . For example, the ground-state wavefunction of strongly correlated fermions on lattices can be written as a product of local singlet pairs known as valence bonds [12] . This class of states is called valence-bond solid (VBS) states [13] . It was later found that VBS states can also be represented by so-called valence bond basis [14] . These states include the famous Néel state [15] describing antiferromagnetic order [16] , the Haldane phase [17] corresponding to integer-spin chains [18] , and the Affleck-Kennedy-Lieb-Tasaki (AKLT) model [19] representing gapped spin-1/2 chain [20] . 
 
 Recently, several schemes [21]- [23] were proposed to generate these types of quantum states experimentally. However, all existing proposals require nonlinear interactions among photons [24] and/or complicated setups [25] . Therefore, they cannot be implemented easily in practice. On the other hand, some experimental demonstrations [26] - [28] have been performed recently to produce photonic qubits [29] . Thus, it would be interesting if we could find ways to implement these quantum states without requiring any nonlinear interaction [30] .",arxiv,bigscience bloomz,704.158,0.2222222222222222,0.7478991596638657,0.15384615384615385,0.9139990444338271,1,1,0,0,0,1,1,0,0,0,0.08676962355957166,0.08575195834250104,0.07392996108949416,0.0946969696969697,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Two-dimensional N=(2,2) super Yang-Mills theory on computer","  We carry out preliminary numerical study of Sugino's lattice formulation
\cite{Sugino:2004qd,Sugino:2004qdf} of the two-dimensional $\mathcal{N}=(2,2)$
super Yang-Mills theory (2d $\mathcal{N}=(2,2)$ SYM) with the gauge group
$\SU(2)$. The effect of dynamical fermions is included by re-weighting a
quenched ensemble by the pfaffian factor. It appears that the complex phase of
the pfaffian due to lattice artifacts and flat directions of the classical
potential are not problematic in Monte Carlo simulation. Various one-point
supersymmetric Ward-Takahashi (WT) identities are examined for lattice spacings
up to $a=0.5/g$ with the fixed physical lattice size $L=4.0/g$, where $g$
denotes the gauge coupling constant in two dimensions. WT identities implied by
an exact fermionic symmetry of the formulation are confirmed in fair accuracy
and, for most of these identities, the quantum effect of dynamical fermions is
clearly observed. For WT identities expected only in the continuum limit, the
results seem to be consistent with the behavior expected from supersymmetry,
although we do not see clear distintion from the quenched simulation. We
measure also the expectation values of renormalized gauge-invariant bi-linear
operators of scalar fields.
","We present the results of numerical simulations of two-dimensional N = (2, 2)
super-Yang-Mills theory with gauge group SU(N). We use an improved action and perform calculations at several values of the coupling constant g in the range 0.1 < g < 1.0. The lattice size is 16 x 32 for all our runs except one where we used 24 x 48 sites. In order to study finite-size effects we have also performed some runs using 12 x 24 and 20 x 40 lattices. 
The main goal of this work was to check whether the phase transition between confinement and deconfinement phases observed previously by other authors persists when the continuum limit is approached. 
 
 Our data show that there are no significant differences between the results obtained on different sizes of lattices within statistical errors. This indicates that the system does not undergo any phase transitions as it approaches the continuum limit.",arxiv,bigscience bloomz,706.1392,0.3333333333333333,0.29411764705882354,0.27692307692307694,0.38939321548017203,1,1,1,0,1,1,1,0,0,0,0.13123767259991934,0.03032287639065755,0.15953307392996108,0.01893939393939394,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Phase resolved measurements of stimulated emission,"  The development of the semiconductor quantum cascade laser (QCL) [1] has
enabled bright coherent sources operating at frequencies between the optical
(>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for
fundamental science investigations [2-5] as well as for applications [6].
However, detailed information about the internal processes in QCLs and their
ultrafast dynamics are needed for their further development towards high output
power, longer wavelengths and stable pulsed operation. We introduce a novel
approach to study the gain and dynamics of a terahertz (THz) QCL [7] using
phase resolved measurements of the stimulated emission. This is enabled by
direct recording of the emitted electric field with <100 fs time resolution.
For the case of the THz QCL we demonstrate the validity of the quantum
mechanical description of the laser. We show for the first time the real
bandwidth of the terahertz gain medium, the current dependence of this gain,
and the losses associated with the wave propagation in the laser waveguide.
","We report on the measurement and analysis of phase-resolved spontaneous emission in an optically pumped semiconductor laser with external cavity feedback (ECF). The ECF is formed by two mirrors, one of which has a variable distance to the active region of the laser diode. We show that this allows for tuning the delay between the optical pulses emitted at each round trip through the external cavity. By measuring the time dependent intensity autocorrelation function we are able to determine the pulse duration as well as the repetition rate of the pulsed output. In addition, we demonstrate how these parameters can be used to extract information about the carrier dynamics inside the gain medium. 
 
 A detailed description of the experimental setup together with results obtained under different operating conditions will be presented. Finally, we discuss possible applications of our method including its use for studying relaxation oscillations or mode locking phenomena in lasers. Stimulated emission occurs when electrons in a material absorb energy from photons and then re-emit them into free space. This process is responsible for generating light in many common devices such as LEDs and lasers. However, it remains challenging to directly measure the properties of stimulated emission because the signal-to-noise ratio is often very low due to the small number of spontaneously emitted photons compared to those generated via stimulated emission. Herein, we present a new approach based on using a tunable external cavity to enhance the signal strength while simultaneously allowing us to control the timing of the emitted photons. Using this technique, we have been able to perform high-resolution measurements of the temporal characteristics of stimulated emission in a semiconductor laser.",arxiv,bigscience bloomz,705.2296,0.2777777777777778,0.546218487394958,0.21025641025641026,0.7419971333014811,1,1,0,0,0,1,1,0,0,0,0.12621613738225063,0.04447859866292373,0.10116731517509728,0.06439393939393939,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1
Vector mesons from AdS/TC to the LHC,"  With the use of the AdS/CFT dictionary, a five-dimensional effective
description of dynamical electro-weak symmetry breaking with walking behavior
is constructed. The minimal model contains only two new parameters, the
confinement scale and the effective coupling of the new strong sector. This
parameter space is restricted by the precision electro-weak constraints and by
the requirement that the five-dimensional coupling be perturbative
(corresponding to the large-N regime in four-dimensional language). The
lightest observable new states are a set of four nearly degenerate spin-1
states with the same quantum numbers as the standard-model electro-weak gauge
bosons, and masses in the few TeV range. Their decay rate is dominated by
two-fermion final states. The number of pp -> mu mu and pp -> mu nu events is
studied as a function of the LHC integrated luminosity and of the two free
parameters. Discovery at the LHC is possible over a significant part of the
allowed parameter space up to masses of 4 TeV already with 10/fm of integrated
luminosity.
","We present an overview of our recent work on vector meson production in heavy ion collisions at RHIC and LHC energies, based on holographic QCD models with chiral symmetry breaking (AdS/QCD). We discuss how these models can be used to calculate hadronic observables such as transverse momentum spectra and elliptic flow coefficients for light quarks and gluons produced in nuclear reactions. In particular we focus on the role played by the coupling between the bulk fields and the gauge field fluctuations dual to vector mesons. The results are compared with experimental data obtained at RHIC and LHC: they show good agreement both qualitatively and quantitatively. 
 
 Keywords: Vector Mesons, Heavy Ion Collisions, Holography, Chiral Symmetry Breaking, Gauge/Gravity Duality 
 
 1 Introduction 
 
 One of the most exciting discoveries made recently at RHIC is that strongly interacting matter behaves like a nearly perfect fluid [1] . This observation has led many theorists to propose new ways of describing this state of matter using effective theories which incorporate hydrodynamics [2] , or even more exotic descriptions involving quark-gluon plasma droplets [3] .
 
In order to understand better what happens during the early stages of heavy-ion collisions it would be very useful if one could study experimentally the properties of the hot dense medium created in those collisions. However, due to its extremely short lifetime, this medium cannot be directly probed through standard scattering experiments. Instead, information about the initial conditions of the collision process must be inferred indirectly from final-state measurements [4] . For example, the collective expansion of the system leads to anisotropic particle emission patterns known as azimuthal asymmetries [5] . These anisotropies have been measured [6] and found to agree well with theoretical predictions [7, 8] . 
 
 Another important observable characterizing the dynamics of the expanding fireball is the spectrum of emitted particles [9] . It was shown [10] that the shape of this spectrum depends sensitively on the equation-of-state of the medium [11] . Moreover, the observed suppression [12] of high-pT hadrons",arxiv,bigscience bloomz,704.2205,0.3333333333333333,0.6470588235294118,0.2205128205128205,0.9025322503583373,1,1,0,0,0,1,1,1,0,0,0.07371537007175405,0.0725882860317325,0.0933852140077821,0.06818181818181818,1,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Trade-off between Processing Gains of an Impulse Radio UWB System in the Presence of Timing Jitter,"  In time hopping impulse radio, $N_f$ pulses of duration $T_c$ are transmitted
for each information symbol. This gives rise to two types of processing gain:
(i) pulse combining gain, which is a factor $N_f$, and (ii) pulse spreading
gain, which is $N_c=T_f/T_c$, where $T_f$ is the mean interval between two
subsequent pulses. This paper investigates the trade-off between these two
types of processing gain in the presence of timing jitter. First, an additive
white Gaussian noise (AWGN) channel is considered and approximate closed form
expressions for bit error probability are derived for impulse radio systems
with and without pulse-based polarity randomization. Both symbol-synchronous
and chip-synchronous scenarios are considered. The effects of multiple-access
interference and timing jitter on the selection of optimal system parameters
are explained through theoretical analysis. Finally, a multipath scenario is
considered and the trade-off between processing gains of a synchronous impulse
radio system with pulse-based polarity randomization is analyzed. The effects
of the timing jitter, multiple-access interference and inter-frame interference
are investigated. Simulation studies support the theoretical results.
","In this work, we investigate the trade-offs among processing gains and timing jitters for impulse radio ultra-wideband (IR-UWB) systems with different pulse shapes. We first derive closed-form expressions to calculate the bit error rate (BER), which is used as performance measure. Then, by using these results, we analyze how the BER changes according to various system parameters such as signal-to-noise ratio (SNR), number of pulses per symbol, and timing jitter variance. Finally, numerical examples are provided to verify our analysis. The main contributions of this study can be summarized as:  1 . Derivation of closed-form expression for calculating the BER.  2 . Analysis on the effect of timing jitter on IR-UWB systems.  3 . Numerical verification of analytical results. In recent years, there has been growing interest in developing high data-rate wireless communication systems that operate over unlicensed bands [1] , especially those based on impulse radio ultrawideband (IR-UWB: [2] ). Compared to conventional narrowband systems, IR-UWB systems have several advantages including low power consumption [3] , immunity against multipath fading [4] , and high security [5] .
However, one major drawback of IR-UWB systems is their vulnerability to timing jitter [6] - [8] . This problem arises because the received signals may experience time delays due to channel dispersion or clock imperfections at both transmitter and receiver sides [9] . As a result, the transmitted symbols cannot be recovered correctly if they arrive out of phase [10] . Therefore, it is important to understand the effects of timing jitter on the performance of IR-UWB systems [11] .
To address this issue, many studies have investigated the impact of timing jitter on various aspects of IR-UWB systems [12]- [16] . For example, in [13] , the authors analyzed the effect of timing jitters on the energy efficiency of IR-UWB systems. They showed that the energy efficiency decreases when the timing jitter increases. Also, in [14] , the authors studied the relationship between timing jitter and bit error probability (BEP). However, most existing works only",arxiv,bigscience bloomz,704.3408,0.4444444444444444,1.0,0.24615384615384617,0.9111323459149546,1,1,1,0,0,1,1,1,0,0,0.1268811678829723,0.09331399666806628,0.12840466926070038,0.11363636363636363,2,5,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
The Elongated Structure of the Hercules dSph from Deep LBT Imaging,"  We present a deep, wide-field photometric survey of the newly-discovered
Hercules dwarf spheroidal galaxy, based on data from the Large Binocular
Telescope. Images in B, V and r were obtained with the Large Binocular Camera
covering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This
permitted the construction of colour-magnitude diagrams that reach
approximately 1.5 magnitudes below the Hercules main sequence turnoff.
Three-filter photometry allowed us to preferentially select probable Hercules
member stars, and examine the structure of this system at a previously
unattained level. We find that the Hercules dwarf is highly elongated (3:1),
considerably more so than any other dSph satellite of the Milky Way except the
disrupting Sagittarius dwarf. While we cannot rule out that the unusual
structure is intrinsic to Hercules as an equilibrium system, our results
suggest tidal disruption as a likely cause of this highly elliptical structure.
Given the relatively large Galactocentric distance of this system (132 +/- 12
kpc), signs of tidal disruption would require the Hercules dwarf to be on a
highly eccentric orbit around the Milky Way.
","We present deep imaging data for the nearby dwarf spheroidal galaxy, Hercules (dSph), obtained with the Large Binocular Telescope (LBT). The new observations are used to study the structure and stellar populations in this system. We find that the surface brightness profile is well described by an exponential function over most of its extent but shows evidence for a break at about 30 arcsec radius. This feature may be associated with tidal disruption or stripping due to interactions between Hercules and other galaxies. Using colour-magnitude diagrams we show that there exists two distinct components within Hercules; one which has been stripped off and another which appears to have remained intact. These results suggest that Hercules was once more extended than it currently is today. Finally, using our photometric catalogue we measure the line-of-sight velocity dispersion as a function of projected distance from the centre of Hercules. Our measurements indicate that the central region of Hercules exhibits higher values compared to those measured further out.",arxiv,bigscience bloomz,706.1669,0.3333333333333333,0.3445378151260504,0.30256410256410254,0.4237935977066412,1,1,1,0,1,1,1,1,0,0,0.0575363194263947,0.0465525224060108,0.058365758754863814,0.041666666666666664,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Position-Velocity Diagrams for the Maser Emission coming from a Keplerian Ring,"  We have studied the maser emission from a thin, planar, gaseous ring in
Keplerian rotation around a central mass observed edge-on. The absorption
coefficient within the ring is assumed to follow a power law dependence with
the distance from the central mass as, k=k0r^{-q}. We have calculated
position-velocity diagrams for the most intense maser features, for different
values of the exponent q. We have found that, depending on the value of q,
these diagrams can be qualitatively different. The most intense maser emission
at a given velocity can either come mainly from regions close to the inner or
outer edges of the amplifying ring or from the line perpendicular to the line
of sight and passing through the central mass (as is commonly assumed).
Particularly, when q>1 the position-velocity diagram is qualitatively similar
to the one observed for the water maser emission in the nucleus of the galaxy
NGC 4258. In the context of this simple model, we conclude that in this object
the absorption coefficient depends on the radius of the amplifying ring as a
decreasing function, in order to have significant emission coming from the
inner edge of the ring.
","We present position-velocity diagrams (PVD) of masers in an accretion disk around a young stellar object, obtained with VLBI observations at 22 GHz and 43 GHz. The PVD are compared to those expected by models that include both rotation and radial motions. We find that our data can be explained if we assume that the emission comes from a ring-like structure located between 0.1 AU and 1 AU from the central star. This is consistent with previous results based on single-dish observations. Our analysis also shows that there must exist some kind of mechanism able to produce inward motions within this region. These could be due either to infalling material or to outflows produced by the protostar itself. Finally, we show how these results can be used as diagnostics tools to study the physical conditions inside circumstellar disks. Keywords: Accretion Disk, Circumstellar Disks, Infrared",arxiv,bigscience bloomz,704.0819,0.3333333333333333,0.3445378151260504,0.35384615384615387,0.36645962732919257,1,1,0,0,0,1,1,1,0,0,0.10580181830666416,0.06230626345628949,0.11673151750972763,0.06060606060606061,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1
The dust temperatures of the prestellar cores in the rho Oph main cloud and in other star forming regions: consequences for the core mass function,"  We estimate the dust temperatures of the clumps in the rho Oph main cloud
taking into account the 3D geometry of the region, and external heating from
the interstellar radiation field and from HD147879,a nearby luminous B2V star,
which is believed to dominate the radiation field in the region. We find that
the regions where prestellar cores are observed (i.e. at optical visual
extinctions >7 mag) are colder than ~10-11K. These dust temperatures are
smaller than those which previous studies of the same region have assumed. We
use the new dust temperatures to estimate the masses of the prestellar cores in
the rho Oph main cloud from mm observations, and we find core masses that are
larger than previous estimates by a factor of ~2-3. This affects the core mass
function (CMF) of the region; we find that the mass at which the core mass
spectrum steepens from a slope alpha~1.5 to a slope alpha~2.5 has moved from
~0.5 Msun to ~1Msun. In contrast with the CMF in other star forming regions
(e.g. Orion), there is no indication for a turnover down to the completeness
limit (~0.2Msun), but the CMF may flatten at around ~0.4Msun. We generalize our
results to the prestellar cores in Taurus and in Orion. In Taurus the ambient
radiation field heating the prestellar cores is believed to be weaker than than
that in rho Oph. Hence, the dust temperatures of the cores in Taurus are
expected to be below ~ 10-11 K.In Orion the radiation field is believed to be
10^3 times stronger than the standard interstellar radiation field. Based on
this assumption we estimate that the dust temperatures of the prestellar cores
in Orion are around ~20-30K.
","We present Herschel Space Observatory observations at 70, 160, 250, 350, and 500 microns toward two fields centered on the densest parts of the Rho Ophiuchi (RO) molecular cloud complex. The data are used to derive the temperature distribution within dense cores identified by their infrared emission using the method developed by John Myers & Sean Carey. We find that most of these cores have temperatures between 10 K and 20 K with only one colder than 8 K. This is consistent with previous studies showing that cold cores are rare in star-forming clouds. Using our derived temperatures we calculate masses assuming optically thin greybody emission. These masses range from 0.1 Msun to more than 100 Msun. In addition, we use the same dataset to study the properties of protostars embedded in the RO region. We identify 16 Class I sources based on their spectral energy distributions and compare them to those found in other nearby star-forming regions such as Serpens South or Orion B North.",arxiv,bigscience bloomz,705.2941,0.6111111111111112,0.29411764705882354,0.8153846153846154,0.4295269947443861,1,1,1,0,0,1,1,0,0,0,0.1281740372143147,0.08534663909399025,0.15953307392996108,0.07954545454545454,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Excluded volume, local structural cooperativity,and the polymer physics of protein folding rates","  A coarse-grained variational model is used to investigate the polymer
dynamics of barrier crossing for a diverse set of two-state folding proteins.
The model gives reliable folding rate predictions provided excluded volume
terms that induce minor structural cooperativity are included in the
interaction potential. In general, the cooperative folding routes have sharper
interfaces between folded and unfolded regions of the folding nucleus and
higher free energy barriers. The calculated free energy barriers are strongly
correlated with native topology as characterized by contact order. Increasing
the rigidity of the folding nucleus changes the local structure of the
transition state ensemble non-uniformly across the set of protein studied.
Neverthless, the calculated prefactors k0 are found to be relatively uniform
across the protein set, with variation in 1/k0 less than a factor of five. This
direct calculation justifies the common assumption that the prefactor is
roughly the same for all small two-state folding proteins. Using the barrier
heights obtained from the model and the best fit monomer relaxation time 30ns,
we find that 1/k0 (1-5)us (with average 1/k0 4us). This model can be extended
to study subtle aspects of folding such as the variation of the folding rate
with stability or solvent viscosity, and the onset of downhill folding.
","We present an analysis of the relationship between excluded volume and cooperative effects in proteins with respect to their folding rates. We show that these two factors are not independent but rather have opposite relationships with rate constants for different classes of proteins. The results suggest that both excluded volume and cooperativity play important roles in determining the folding rates of globular proteins. In particular, we find that the effect of excluded volume on folding rates is strongly dependent upon the degree of cooperativity exhibited by each protein class. This dependence arises because the presence of large amounts of nonlocal structure can compensate for the loss of local interactions due to excluded volume. Our results also indicate that there may be a fundamental difference between how fast-folding and slow-folding proteins fold. Finally, our findings provide insight into why some proteins fold faster than others despite having similar structures. Proteins fold through a series of conformational changes driven by thermal fluctuations or other external forces such as ligand binding. These processes occur over time scales ranging from microseconds to seconds depending on the size and complexity of the folded state1 . Despite this wide range of timescales, all known proteins share common features including compact tertiary folds2 , hydrophobic cores3 , and secondary structure elements4 .
Theoretical studies5-7 have shown that the free energy landscape governing protein folding contains many metastable states separated by barriers whose heights depend on the strength of native contacts8-10 . Because the height of these barriers determines the overall folding rate11-13 , it has been suggested14-16 that the folding process occurs via a rugged funnel-like free energy surface17-20 . However, recent experiments21-24 have challenged this viewpoint25-27 by showing that the folding mechanism of several small single-domain proteins does not involve significant kinetic intermediates28-30 . Instead, these proteins appear to fold directly from unfolded states to folded ones without passing through any partially folded states31-33 .",arxiv,bigscience bloomz,706.0185,0.4444444444444444,0.6470588235294118,0.4256410256410256,0.8681318681318682,1,1,0,0,0,0,1,0,0,0,0.04498055172226223,0.025312056335585455,0.042801556420233464,0.011363636363636364,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
First proper motions of thin dust filaments at the Galactic Center,"  Context: L'-band (3.8 micron) images of the Galactic Center show a large
number of thin filaments in the mini-spiral, located west of the mini-cavity
and along the inner edge of the Northern Arm. One possible mechanism that could
produce such structures is the interaction of a central wind with the
mini-spiral. Additionally, we identify similar features that appear to be
associated with stars. Aims: We present the first proper motion measurements of
the thin dust filaments observed in the central parsec around SgrA* and
investigate possible mechanisms that could be responsible for the observed
motions. Methods: The observations have been carried out using the NACO
adaptive optics system at the ESO VLT. The images have been transformed to a
common coordinate system and features of interest were extracted. Then a
cross-correlation technique could be performed in order to determine the
offsets between the features with respect to their position in the reference
epoch. Results: We derive the proper motions of a number of filaments and 2
cometary shaped dusty sources close (in projection) to SgrA*. We show that the
shape and the motion of the filaments does not agree with a purely Keplerian
motion of the gas in the potential of the supermassive black hole at the
position of SgrA*. Therefore, additional mechanisms must be responsible for
their formation and motion. We argue that the properties of the filaments are
probably related to an outflow from the disk of young mass-losing stars around
SgrA*. In part, the outflow may originate from the black hole itself. We also
present some evidence and theoretical considerations that the outflow may be
collimated.
","We report on the first detection of proper motion in two thin dust filaments located near Sgr A*, the supermassive black hole (SMBH) at the center of our Galaxy. The filaments are detected as dark features against bright infrared background emission and have been observed with the Submillimeter Array for more than four years. We find that both filaments show significant proper motions toward us, which we interpret to be due to their orbital motion around Sgr A*. Using simple models, we estimate the masses of these filaments to be between 10^6 M_sol and 10^7 M_sol . These results provide new insights into the formation process of such structures close to galactic nuclei. Dust filaments are ubiquitous in galaxies across cosmic time. They can form by gravitational instabilities or through outflows driven by active galactic nuclei (AGN). However, it is still unclear how they evolve over time and what physical processes drive them. In this Letter, we present the first measurement of proper motions of two thin dust filaments at projected distances of less than 100 pc from Sagittarius A* (Sgr A*), the central supermassive black hole of the Milky Way. Our observations were carried out using the Submillimeter Array (SMA; Ho et al., 2004) , an interferometer operating at wavelengths ranging from 0.8 mm to 3.5 mm. Both filaments appear as dark features against the bright infrared background emission produced by warm dust surrounding Sgr A*. Their apparent velocities range from 50 km/s to 150 km/s , consistent with previous measurements based on single-dish data (Molinari et al., 2011) . By modeling the orbits of the filaments under Newtonian gravity, we derive mass estimates of about 106-107 solar masses (Msolar) for each filament. This result suggests that the filaments may represent gravitationally bound objects orbiting Sgr A*.",arxiv,bigscience bloomz,704.3675,0.6666666666666666,0.6470588235294118,0.7487179487179487,0.807931199235547,1,1,1,0,1,1,1,1,0,0,0.08482902358057909,0.07271269331732871,0.0933852140077821,0.08712121212121213,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The Compact X-ray Source 1E 1547.0-5408 and the Radio Shell G327.24-0.13: A New Proposed Association between a Candidate Magnetar and a Candidate Supernova Remnant,"  We present X-ray, infrared and radio observations of the field centered on
X-ray source 1E 1547.0-5408 in the Galactic Plane. A new Chandra observation of
this source shows it is unresolved at arc-second resolution, and a new XMM
observation shows that its X-ray spectrum is best described by an absorbed
power-law and blackbody model. A comparison of the X-ray flux observed from
this source between 1980 and 2006 reveals that its absorbed 0.5-10 keV X-ray
flux decreased from ~2x10^-12 ergs cm-2 s-1 to ~3x10^-13 ergs cm-2 during this
period. The most recent XMM observation allows us to put a 5 sigma confidence
upper limit of 14% for the 0.5-10 keV peak-to-peak pulsed fraction. A
near-infrared observation of this field shows a source with magnitude Ks =
15.9+/-0.2 near the position of 1E 1547.0-5408, but the implied X-ray to
infrared flux ratio indicates the infrared emission is from an unrelated field
source, allowing us to limit the IR magnitude of 1E 1547.0-5408 to >17.5.
Archival radio observations reveal that 1E 1547.0-5408 sits at the center of a
faint, small (4' diameter) radio shell, G327.24-0.13, which is possibly a
previously unidentified supernova remnant. The X-ray properties of 1E
1547.0-5408 suggest that this source is a magnetar - a young neutron star whose
X-ray emission is powered by the decay of its extremely strong magnetic field.
The spatial coincidence between this source and G327.24-0.13 suggests that 1E
1547.0-5408 is associated with a young supernova remnant, supporting a neutron
star interpretation. Additional observations are needed to confirm the nature
of both 1E 1547.0-5408 and G327.24-0.13, and to determine if these sources are
associated. If so, this pair will be an important addition to the small number
of known associations between magnetars and supernova remnants.
","We report on new observations made with Chandra, XMM-Newton, and VLA that provide evidence for an association between the compact X-ray source 1E 1547. 0-5408  and the radio shell G327. 24-0.13 . The X-ray spectrum is consistent with emission from a magnetar; however, we find no pulsations in our data set. We also present optical spectroscopy of two stars near the center of the remnant which show strong Balmer absorption lines characteristic of Wolf-Rayet (WR) stars; these are likely to be associated with the supernova event that created the remnant. 
 
 Keywords: Supernova remnants, Pulsar wind nebulae, Wolf Rayets, Chandra, XMM-NEWTON, VLA, Optical Spectroscopy 
 
 Introduction 
 
 In this Letter, we report on new observational results concerning the possible association between the candidate magnetar 1E 1547.0+ 5408 , located at the center of the supernova remnant G327.24 -0.13 , and its surrounding environment. This object was discovered by the Einstein Observatory as part of the first systematic survey of the Galactic plane (Hertz & Grindlay 1984) . It has been observed several times since then using different instruments including ASCA (Sugizaki et al. , 1997) , BeppoSAX (Giacani et al. , 2001 ) , RXTE (Israel et al. , 2002 ) and Chandra (Pavlov et al. , 2004 ) . Its position coincides within errors with the brightest peak of the radio shell detected by the VLA (Kothes et al. , 2006 ; Gaensler et al. , 2008 ) . However, there have been conflicting reports about whether or not it shows any periodic behavior. While Israel et al. (2002) reported detection of a periodicity of 6 s during their observation campaign, Sugizaki et al. (1997) found only marginal evidence for such a signal when they analyzed archival ASCA data. More recently, Pavlov et al. (2004) did not detect any significant pulsation down to a",arxiv,bigscience bloomz,706.1054,0.5,1.0,0.8564102564102564,0.8193979933110368,1,1,0,0,1,1,1,1,0,0,0.08836633765657212,0.11679632482724225,0.10894941634241245,0.10984848484848485,0,10,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
A double main sequence turn-off in the rich star cluster NGC 1846 in the Large Magellanic Cloud,"  We report on HST/ACS photometry of the rich intermediate-age star cluster NGC
1846 in the Large Magellanic Cloud, which clearly reveals the presence of a
double main sequence turn-off in this object. Despite this, the main sequence,
sub-giant branch, and red giant branch are all narrow and well-defined, and the
red clump is compact. We examine the spatial distribution of turn-off stars and
demonstrate that all belong to NGC 1846 rather than to any field star
population. In addition, the spatial distributions of the two sets of turn-off
stars may exhibit different central concentrations and some asymmetries. By
fitting isochrones, we show that the properties of the colour-magnitude diagram
can be explained if there are two stellar populations of equivalent metal
abundance in NGC 1846, differing in age by approximately 300 Myr. The absolute
ages of the two populations are ~1.9 and ~2.2 Gyr, although there may be a
systematic error of up to +/-0.4 Gyr in these values. The metal abundance
inferred from isochrone fitting is [M/H] ~ -0.40, consistent with spectroscopic
measurements of [Fe/H]. We propose that the observed properties of NGC 1846 can
be explained if this object originated via the tidal capture of two star
clusters formed separately in a star cluster group in a single giant molecular
cloud. This scenario accounts naturally for the age difference and uniform
metallicity of the two member populations, as well as the differences in their
spatial distributions.
","We present new photometry for the open cluster NGC 1846, located at the edge of the Small Magellanic Cloud (SMC). The data were obtained with the Wide Field Imager on the MPG/ESO 2.2 m telescope and cover an area of about 1 square degree around the cluster center. We find that there is no evidence for any significant differential reddening across this field. Using these observations we derive a distance modulus to the SMC of 18.9 mag, which agrees well with previous determinations based on other methods. 
 
 In addition, we identify two distinct sequences in our color-magnitude diagram (CMD) along the lines expected if the cluster contains both old and intermediate-age populations. This finding supports earlier suggestions by several authors who found similar features in CMDs of other clusters in the SMC. However, while most of those studies suggested ages between 10 and 100 Myr for their second population, we find here that it must be significantly older than 300 Myr.",arxiv,bigscience bloomz,704.336,0.4444444444444444,0.29411764705882354,0.5897435897435898,0.41519350215002393,0,1,0,0,0,1,1,0,0,0,0.056100604537589936,0.04084668369193483,0.0622568093385214,0.03409090909090909,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Hot Jupiters in binary star systems,"  Radial velocity surveys find Jupiter mass planets with semi-major axes a less
than 0.1 AU around ~1% of solar-type stars; counting planets with $a$ as large
as 5 AU, the fraction of stars having planets reaches ~ 10% {Marcy,Butler}. An
examination of the distribution of semi-major axes shows that there is a clear
excess of planets with orbital periods around 3 or 4 days, corresponding to
a~0.03$ AU, with a sharp cutoff at shorter periods (see Figure 1). It is
believed that Jupiter mass planets form at large distances from their parent
stars; some fraction then migrate in to produce the short period objects. We
argue that a significant fraction of the `hot Jupiters' (a<0.1 AU) may arise in
binary star systems in which the orbit of the binary is highly inclined to the
orbit of the planet. Mutual torques between the two orbits drive down the
minimum separation or periapse r_p between the planet and its host star (the
Kozai mechanism). This periapse collapse is halted when tidal friction on the
planet circularizes the orbit faster than Kozai torque can excite it. The same
friction then circularizes the planet orbit, producing hot Jupiters with the
peak of the semimajor axis distribution lying around 3 days. For the observed
distributions of binary separation, eccentricity and mass ratio, roughly 2.5%
of planets with initial semimajor axis a_p ~ 5au will migrate to within 0.1au
of their parent star. Kozai migration could account for 10% or more of the
observed hot Jupiters.
","We present the discovery and characterization of two ""hot Jupiter"" planets orbiting stars that are members of wide binaries, HD 196885AB (a = 1.8 AU) and HD 208598AB (a = 3.6 AU). The planet around HD 196885A is an inflated gas giant with M sin i = 0.88 MJup and P = 4.3 days; it orbits its primary at a distance of only 0.04 AU. We find no evidence for additional companions to either host star down to masses as low as 5 MJup within separations of 10 AU. Both systems have orbital eccentricities consistent with zero. These results suggest that hot Jupiters can survive close encounters with other stars during their formation or early evolution.  - Introduction 
 
 Hot Jupiters are massive gaseous planets on short-period orbits about solar-type stars. They represent one of the most extreme environments in our Solar System, but they may be common among nearby Sun-like stars. In fact, recent surveys indicate that roughly 20% of sun-like stars harbor such planets . However, these planets are thought to form beyond several AU before migrating inward through interactions with the protoplanetary disk and/or gravitational scattering by other bodies. This raises questions regarding how these planets manage to avoid being ejected into interstellar space after undergoing strong dynamical interactions with other objects while still retaining sufficient angular momentum to reach their current locations near their parent stars .

In this Letter we report the detection of two new ""hot Jupiter"" planets using high-precision radial velocity measurements obtained over more than eight years with the High Accuracy Radial Velocity Planet Searcher instrument (HARPS), which is installed on the European Southern Observatory's 3.6-m telescope located at La Silla Observatory in Chile. One of these planets has an extremely small semi-major axis of just 0.04 AU, making it one of the closest known exoplanets to its parent star.",arxiv,bigscience bloomz,706.0732,0.4444444444444444,0.24369747899159663,0.6512820512820513,0.3936932632584807,1,1,1,0,1,2,2,1,0,1,0.10470296994257408,0.10677344693179427,0.07782101167315175,0.09848484848484848,0,1,4,4,1,1,1,1,1,1,1,1,1,1,1,1,1,2,0,2,1,1
Mapping the Youngest Galaxies to Redshift One,"  We describe results of a narrow band search for ultra-strong emission line
galaxies (USELs) with EW(H beta) > 30 A. 542 candidate galaxies are found in a
half square degree survey using two ~100 Angstrom 8150 A and 9140 A filters
with Subaru/SuprimeCam. Followup spectroscopy for randomly selected objects in
the sample with KeckII/DEIMOS shows they consist of [OIII] 5007, [OII] 3727,
and H alpha selected strong-emission line galaxies at intermediate redshifts (z
< 1), and Ly alpha emitting galaxies at high-redshift (z >> 5). We determine
the H beta luminosity functions and the star formation density of the USELs,
which is 5-10% of the value found from ultraviolet continuum objects at z=0-1,
suggesting they correspond to a major epoch in galaxy formation at these
redshifts. Many USELs show the temperature-sensitive [OIII] 4363 auroral lines
and about a dozen have oxygen abundances characteristic of eXtremely Metal Poor
Galaxies (XMPGs). These XMPGs are the most distant known today. Our high yield
rate of XMPGs suggests this is a powerful method for finding such populations.
The lowest metallicity measured in our sample is 12+log(O/H) = 7.06
(6.78-7.44), close to the minimum metallicity found in local galaxies. The
luminosities, metallicities and star formation rates of USELs are consistent
with the strong emitters being start-up intermediate mass galaxies and suggest
that galaxies are still forming in relatively chemically pristine sites at z <
1.
","We present deep near-infrared imaging and spectroscopy for two fields in the Hubble Deep Field South (HDF-S) covering an area of 0.5 square degrees each, centered on RA = 03:32:47.6 Dec = -27:48:30 (J2000). The data were obtained with ISAAC at VLT as part of our ESO Large Programme ""First Stars First Galaxies"". We have detected more than 1000 galaxies down to KsAB = 24 mag over this field using SExtractor. In addition we have spectroscopically confirmed about 100 objects selected by their photometric redshifts between z=0.7-1.3. This is one of the largest samples of high-z galaxies ever assembled. Our sample includes both Lyman-break galaxies and sub-millimeter sources which are likely to be dusty starbursting systems. These results will allow us to study galaxy formation and evolution up to redshift 1.",arxiv,bigscience bloomz,704.0643,0.4444444444444444,0.29411764705882354,0.5487179487179488,0.32919254658385094,1,1,0,0,0,1,1,1,0,0,0.12787166822221557,0.06958113085737777,0.12062256809338522,0.05303030303030303,1,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
"Complex marginal deformations of D3-brane geometries, their Penrose limits and giant gravitons","  We apply the Lunin--Maldacena construction of gravity duals to beta-deformed
gauge theories to a class of Type IIB backgrounds with U(1)^3 global symmetry,
which include the multicenter D3-brane backgrounds dual to the Coulomb branch
of N=4 super Yang-Mills and the rotating D3-brane backgrounds dual to the
theory at finite temperature and chemical potential. After a general
discussion, we present the full form of the deformed metrics for three special
cases, which can be used for the study of various aspects of the
marginally-deformed gauge theories. We also construct the Penrose limits of the
solutions dual to the Coulomb branch along a certain set of geodesics and, for
the resulting PP--wave metrics, we examine the effect of beta-deformations on
the giant graviton states. We find that giant gravitons exist only up to a
critical value of the sigma-deformation parameter, are not degenerate in energy
with the point graviton, and remain perturbatively stable. Finally, we probe
the sigma-deformed multicenter solutions by examining the static heavy-quark
potential by means of Wilson loops. We find situations that give rise to
complete screening as well as linear confinement, with the latter arising is an
intriguing way reminiscent of phase transitions in statistical systems.
","We study the Penrose limit of certain complex marginal deformations of AdS5×S 5 . We show that these are dual to supergravity solutions describing wrapped M2-and M5-branes on S 3 × R 4 , which can be interpreted as giant gravitons in AdS5×S5 .
The corresponding string theory backgrounds have been constructed by Lunin and Maldacena using T-duality transformations along Hopf fibers of Sasaki-Einstein spaces . The Penrose limit is taken with respect to an appropriate null geodesic lying inside the horizon of the black hole solution . In this way we obtain new supersymmetric pp-wave solutions of type IIB supergravity whose near-horizon geometry is given by AdS3×S 3 ×R 2 or AdS2×S 2 ×R 2 depending on whether one takes the Penrose limit for the deformation parameter equal to zero or not respectively .",arxiv,bigscience bloomz,704.2067,0.2777777777777778,0.19327731092436976,0.38461538461538464,0.34065934065934067,1,1,0,0,0,0,1,0,0,0,0.12159232362205172,0.09579625653031004,0.10116731517509728,0.07954545454545454,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Shelling-type orderings of regular CW-complexes and acyclic matchings of the Salvetti complex,"  Motivated by the work of Salvetti and Settepanella we introduce certain total
orderings of the faces of any shellable regular CW-complex (called
`shelling-type orderings') that can be used to explicitly construct maximum
acyclic matchings of the poset of cells of the given complex. Building on an
application of this method to the classical zonotope shellings we describe a
class of maximum acyclic matchings for the Salvetti complex of a linear
complexified arrangement. To do this, we introduce and study a new
combinatorial stratification of the Salvetti complex. For the obtained acyclic
matchings we give an explicit description of the critical cells that depends
only on the chosen linear extension of the poset of regions. It is always
possible to choose the linear extension so that the critical cells can be
explicitly constructed from the chambers of the arrangement via the bijection
to no-broken-circuit sets defined by Jewell and Orlik. Our method can be
generalized to arbitraty oriented matroids.
","We study shelling-type orderings on regular cell complexes, which are defined by an ordering of their cells such that each new face is attached to exactly one old face in its boundary. We show how these can be used to construct acyclic matchings for the Salvetti complex associated with any finite Coxeter group W . This yields a combinatorial proof of the fact that the Poincaré polynomial of this complex satisfies P(t) = (1 − t)(1 + w∈W t l(w) ), where l denotes the length function on W .
The results presented here were obtained during my PhD thesis at ETH Zurich under the supervision of Prof. Dr. Jürg Stadler. I would like to thank him as well as Prof. Dr. Peter Schmitt for many helpful discussions. The research leading to these results has received funding from the European Research Council under the European Union's Seventh Framework Programme (FP/2007-2013 Grant Agreement n o 325928).",arxiv,bigscience bloomz,705.3107,0.2777777777777778,0.24369747899159663,0.1794871794871795,0.39799331103678937,1,1,0,0,1,1,1,0,0,1,0.1188880262935797,0.0791447822392584,0.10116731517509728,0.07575757575757576,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
The Star-forming Region NGC 346 in the Small Magellanic Cloud with Hubble Space Telescope ACS Observations. II. Photometric Study of the Intermediate-Age Star Cluster BS 90,"  We present the results of our investigation of the intermediate-age star
cluster BS 90, located in the vicinity of the HII region N 66 in the SMC,
observed with HST/ACS. The high-resolution data provide a unique opportunity
for a very detailed photometric study performed on one of the rare
intermediate-age rich SMC clusters. The complete set of observations is
centered on the association NGC 346 and contains almost 100,000 stars down to V
~28 mag. In this study we focus on the northern part of the region, which
covers almost the whole stellar content of BS 90. We construct its stellar
surface density profile and derive structural parameters. Isochrone fits on the
CMD of the cluster results in an age of about 4.5 Gyr. The luminosity function
is constructed and the present-day mass function of BS 90 has been obtained
using the mass-luminosity relation, derived from the isochrone models. We found
a slope between -1.30 and -0.95, comparable or somewhat shallower than a
typical Salpeter IMF. Examination of the radial dependence of the mass function
shows a steeper slope at larger radial distances, indicating mass segregation
in the cluster. The derived half-mass relaxation time of 0.95 Gyr suggests that
the cluster is mass segregated due to its dynamical evolution. From the
isochrone model fits we derive a metallicity for BS 90 of [Fe/H]=-0.72, which
adds an important point to the age-metallicity relation of the SMC. We discuss
our findings on this relation in comparison to other SMC clusters.
","We present photometry for stars in an intermediate-age open cluster, BS90 (Sharpless 1959), located at the center of the star-forming region NGC346 in the Small Magellan Cloud (SMC). The data were obtained using the Advanced Camera for Surveys on board the Hubble Space Telescope and cover a field-of-view of about 1 arcmin2 centered on the cluster. We have detected more than 1000 candidate members down to V = 25 mag within a radius of 3 arcmin around the cluster center. Using these new observations we derived the age, distance modulus, reddening, metallicity, mass function slope, and total luminosity of this open cluster. Our results are consistent with previous studies but provide higher precision values due to our larger sample size. 
 
 Keywords: Open clusters; SMC; HST/ACS; photometry; star formation history; intermediate-age",arxiv,bigscience bloomz,704.2942,0.6111111111111112,0.24369747899159663,0.6410256410256411,0.3263258480649785,0,1,0,0,0,1,1,1,0,0,0.05843145070157846,0.052287113467691396,0.06614785992217899,0.01893939393939394,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Single Transverse-Spin Asymmetry in Hadronic Dijet Production,"  We study the single transverse-spin asymmetry for dijet production in
hadronic collisions in both the collinear QCD factorization approach and the
Brodsky-Hwang-Schmidt model. We show that a nonvanishing asymmetry is generated
by both initial-state and final-state interactions, and that the final-state
interactions dominate. We find that in the leading kinematic region where the
transverse momentum imbalance of the two jets, q_\perp = P_{1\perp}+P_{2\perp},
is much less than the momentum of either jet, the contribution from the lowest
non-trivial perturbative order to both the spin-averaged and the spin-dependent
dijet cross sections can be factorized into a hard part that is a function only
of the averaged jet momentum P_\perp = (P_{1\perp}-P_{2\perp})/2, and
perturbatively generated transverse momentum dependent (TMD) parton
distributions. We show that the spin asymmetry at this non-trivial perturbative
order can be described by the TMD parton distributions defined in either
semi-inclusive DIS or the Drell-Yan process. We derive the same hard parts from
both the collinear factorization approach and in the context of the
Brodsky-Hwang-Schmidt model, verifying that they are not sensitive to details
of the factorized long distance physics.
","We present the first measurement of single-transverse-spin asymmetries (SSA) for hadronic dijets produced at midrapidity in p+p collisions at sqrt(sNN) = 5.02 TeV using data collected by the CMS experiment during 2012 corresponding to an integrated luminosity of 2.3 fb-1 . The SSAs are extracted as functions of jet transverse momentum and rapidity, azimuthal angle between jets, and event centrality. We observe no significant dependence on any kinematic variable except that the magnitude of the asymmetry decreases with increasing jet rapidity. Our results are compared to theoretical predictions based on perturbative QCD calculations including higher-order corrections and parton distribution function uncertainties. 
The measured values agree well within experimental and theoretical uncertainties. This is the most precise measurement of this observable performed so far. 
 
 Introduction 
 
 Single transverse-spin asymmetries have been observed in several processes involving polarized protons or neutrons [1] , such as inclusive pion production [2] , semi-inclusive deep-inelastic scattering [3] , Drell-Yan lepton pair production [4] , prompt photon production [5] , and direct photons [6] . These measurements provide important information about the spin structure of nucleons [7, 8] .
 
In particular, they can be used to test the validity of factorization theorems [9] which relate hard-scattering cross sections to partonic distributions inside the proton [10] . In addition, these observables may also shed light on new physics beyond the Standard Model [11] . 
 
 For example, it has recently been suggested [12] that large single-spin asymmetries could arise due to the interference of two amplitudes describing different helicities of quarks emitted from longitudinally polarized gluons in high-energy pp collisions. Such effects would violate parity conservation and thus constitute evidence for new physics [13] . However, there exists only one previous measurement [14] of single-spin asymmeties in hadronic dijet production at high energies. That study was carried out at RHIC [15] where the center-of-mass energy per nucleon-nucleon collision √sNN=200 GeV is much lower",arxiv,bigscience bloomz,706.1196,0.2222222222222222,0.6470588235294118,0.29743589743589743,0.8537983755375059,1,1,0,0,0,1,1,0,0,0,0.2824251204431831,0.10885252379524549,0.3035019455252918,0.15151515151515152,0,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Black-body components in Gamma-Ray Bursts spectra?,"  We study 7 Gamma Ray Bursts (GRBs), detected both by the BATSE instrument,
on-board the Compton Gamma Ray Observatory, and by the Wide Field Camera (WFC),
on-board BeppoSAX. These bursts have measured spectroscopic redshifts and are a
sizeable fraction of the bursts defining the correlation between the peak
energy E_peak (i.e. the peak of the vFv spectrum) and the total prompt
isotropic energy E_iso (the so called ""Amati"" relation). Recent theoretical
interpretations of this correlation assume that black-body emission dominates
the time resolved spectra of GRBs, even if, in the time integrated spectrum,
its presence may be hidden by the change of its temperature and by the dilution
of a possible non-thermal power law component. We perform a time resolved
spectral analysis, and show that the sum of a power-law and a black-body gives
acceptable fits to the time dependent spectra within the BATSE energy range,
but overpredicts the flux in the WFC X-ray range. Moreover, a fit with a cutoff
power-law plus a black-body is consistent with the WFC data, but the black-body
component contributes a negligible fraction of the total flux. On the contrary,
we find that fitting the spectra with a Band model or a simple cutoff power-law
model yields an X-ray flux and spectral slope which well matches the WFC
spectra.
","We present the results of our analysis on the time-averaged spectrum and light curve of GRB 090902B, which is one of the brightest bursts ever detected by Fermi/GBM (Gamma-ray Burst Monitor). We find that its average spectrum can be well fitted with two blackbody functions plus an additional power-law component at high energies. The temperature of each blackbody function decreases as the emission radius increases. This behavior is consistent with theoretical predictions for photospheric emission from relativistic outflows. In addition to this thermal component, we also detect non-thermal emission above 100 MeV. Our spectral fitting suggests that there are three distinct physical regions contributing to the observed gamma-rays: 1) A photosphere-like region producing thermal radiation; 2) An internal shock region generating nonthermal radiation; 3) A magnetized wind region responsible for high-energy photons. These findings provide new insights into the physics of GRBs. 
 
 Keywords: Black body, Photon index, Power law",arxiv,bigscience bloomz,704.3438,0.3333333333333333,0.3445378151260504,0.4717948717948718,0.38079311992355475,1,1,0,0,0,1,1,1,0,0,0.08393784398355818,0.10668019527357674,0.10116731517509728,0.12121212121212122,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Thermal inertia of near-Earth asteroids and implications for the magnitude of the Yarkovsky effect,"  Thermal inertia determines the temperature distribution over the surface of
an asteroid and therefore governs the magnitude the Yarkovsky effect. The
latter causes gradual drifting of the orbits of km-sized asteroids and plays an
important role in the delivery of near-Earth asteroids (NEAs) from the main
belt and in the dynamical spreading of asteroid families. At present, very
little is known about the thermal inertia of asteroids in the km size range.
Here we show that the average thermal inertia of a sample of NEAs in the
km-size range is 200 $\pm$ 40 J m&#8722;2 s&#8722;0.5 K&#8722;1. Furthermore,
we identify a trend of increasing thermal inertia with decreasing asteroid
diameter, D. This indicates that the dependence of the drift rate of the
orbital semimajor axis on the size of asteroids due to the Yarkovsky effect is
a more complex function than the generally adopted D^(&#8722;1) dependence, and
that the size distribution of objects injected by Yarkovsky-driven orbital
mobility into the NEA source regions is less skewed to smaller sizes than
generally assumed. We discuss how this fact may help to explain the small
difference in the slope of the size distribution of km-sized NEAs and main-belt
asteroids.
","We present new results on thermal inertia measurements of NEAs based on infrared observations with Spitzer Space Telescope (SST). We use these data to derive an improved estimate of the mean value of the surface thermal inertia, I = 100 ± 50 J m-2 s-1/2 K-1, which is in good agreement with previous estimates obtained by other authors using different methods. The derived values are also consistent with laboratory experiments performed at high temperatures that show how the thermal conductivity decreases as temperature increases. Using our measured range of thermal inertias we calculate the expected range of magnitudes of the Yarkovsky force acting upon NEAs. Our calculations suggest that this force may be responsible for driving some NEAs into orbits crossing Earth's orbit. This would have important consequences for future space missions aimed at deflecting potentially hazardous objects away from Earth. Near-Earth Asteroids (NEAs) represent a significant threat to human civilization because they can impact the Earth within one million years. In order to mitigate such threats it will be necessary to develop technologies capable of deflecting or redirecting NEAs out of their current orbits before they hit the Earth. One possible method involves applying a small impulse to the asteroid's trajectory through the action of the Yarkovsky-O'Keefe-Radzievskii-Paddack (YORP) effect. However, the effectiveness of this approach depends critically on the ability to predict accurately the strength of the YORP effect.",arxiv,bigscience bloomz,704.1915,0.2777777777777778,0.4453781512605043,0.37948717948717947,0.6129956999522218,1,1,1,0,0,1,1,0,0,1,0.21975484332152878,0.05999055580738948,0.23346303501945526,0.07196969696969698,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Particle-vibration coupling within covariant density functional theory,"  Covariant density functional theory, which has so far been applied only
within the framework of static and time dependent mean field theory is extended
to include Particle-Vibration Coupling (PVC) in a consistent way. Starting from
a conventional energy functional we calculate the low-lying collective
vibrations in Relativistic Random Phase Approximation (RRPA) and construct an
energy dependent self-energy for the Dyson equation. The resulting
Bethe-Salpeter equation in the particle-hole ($ph$) channel is solved in the
Time Blocking Approximation (TBA). No additional parameters are used and double
counting is avoided by a proper subtraction method. The same energy functional,
i.e. the same set of coupling constants, generates the Dirac-Hartree
single-particle spectrum, the static part of the residual $ph$-interaction and
the particle-phonon coupling vertices. Therefore a fully consistent description
of nuclear excited states is developed. This method is applied for an
investigation of damping phenomena in the spherical nuclei with closed shells
$^{208}$Pb and $^{132}$Sn. Since the phonon coupling terms enrich the RRPA
spectrum with a multitude of $ph\otimes$phonon components a noticeable
fragmentation of the giant resonances is found, which is in full agreement with
experimental data and with results of the semi-phenomenological
non-relativistic approach.
","We present an ab initio method for the calculation of phonon dispersion relations in solids, which is based on the direct solution of the Bethe-Salpeter equation (BSE) and includes electron-phonon interaction effects beyond the adiabatic approximation. The BSE describes the scattering between pairs of valence electrons mediated by screened Coulomb interactions. We solve this equation using a recently developed scheme that allows us to treat large supercells with high accuracy. In order to account for nonadiabatic corrections we introduce a self-consistent treatment of electronic screening into our approach. This enables us to calculate accurate phonon dispersions at arbitrary points in reciprocal space without any additional computational effort compared to standard DFT calculations. As a first application of our new method we study the influence of electron-phonon interaction on the band gap renormalization in silicon. Our results show good agreement with experimental data and previous theoretical studies.",arxiv,bigscience bloomz,705.1044,0.4444444444444444,0.29411764705882354,0.35384615384615387,0.37219302436693746,1,1,0,0,0,1,1,0,0,0,0.11249726846459715,0.06833563398144948,0.08560311284046693,0.07575757575757576,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
National Scientific Facilities and Their Science Impact on Non-Biomedical Research,"  H-index, proposed by Hirsch is a good indicator of the impact of a
scientist's research. When evaluating departments, institutions or labs, the
importance of h-index can be further enhanced when properly calibrated for
size. Particularly acute is the issue of federally funded facilities whose
number of actively publishing scientists frequently dwarfs that of academic
departments. Recently Molinari and Molinari developed a methodology that shows
the h-index has a universal growth rate for large numbers of papers, allowing
for meaningful comparisons between institutions.
  An additional challenge when comparing large institutions is that fields have
distinct internal cultures, with different typical rates of publication and
citation; biology is more highly cited than physics, which is more highly cited
than engineering. For this reason, this study has focused on the physical
sciences, engineering, and technology, and has excluded bio-medical research.
Comparisons between individual disciplines are reported here to provide
contextual framework. Generally, it was found that the universal growth rate of
Molinari and Molinari holds well across all the categories considered,
testifying to the robustness of both their growth law and our results.
  The overall goal here is to set the highest standard of comparison for
federal investment in science; comparisons are made with the nations preeminent
private and public institutions. We find that many among the national
facilities compare favorably in research impact with the nations leading
universities.
","The National Institutes of Health (NIH) is the largest funder of biomedical research in the United States, but it also supports non-biomedical research through its extramural program.  The NIH has funded thousands of scientists at hundreds of institutions across the country to conduct basic science research that may have important applications outside of medicine.   This study examines how these researchers are using their NIH funding for non-biomedical projects by analyzing data collected during interviews with them conducted as part of an ongoing longitudinal survey of NIH-funded investigators.  We find that many of these scientists use their NIH funds primarily or exclusively for non-biomedically related research activities such as teaching, administration, and service work.  However, we also find that some scientists who receive NIH support for non-biomedics-related research still spend most of their time conducting biomedically focused research.  In addition, our results show that scientists' perceptions about whether they are spending more time doing biomedically versus non-biomedically focused research do not always match up with actual behavior.",arxiv,bigscience bloomz,705.1797,0.5,0.24369747899159663,0.5282051282051282,0.4295269947443861,0,1,1,0,1,1,1,0,0,1,0.07704322274862323,0.019229855312314838,0.08949416342412451,0.007575757575757576,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1
Cosmogenic neutrinos as a probe of the transition from Galactic to extragalactic cosmic rays,"  There are two promising scenarios that explain the ankle, which is a dip in
the spectrum of cosmic rays at $\sim 10^{19}$ eV. A scenario interprets the
ankle as the transition from Galactic to extragalactic cosmic rays ({\it
ankle-transition scenario}), while the other is that the dip caused by pair
production on the cosmic microwave background radiation ({\it proton-dip
scenario}). In this paper, we consider whether cosmogenic neutrinos can be a
clue to judge which scenario is favored. We calculated the fluxes of cosmogenic
neutrinos following these scenarios with plausible physical parameter sets, and
found several important features as follows. First of all, the neutrino flux at
$\sim 10^{20}$ eV becomes much higher in the ankle-transition scenario as long
as the maximum energy of the cosmic rays at sources is sufficiently high. On
the other hand, the neutrino spectrum has a characteristic peak at $\sim
10^{16}$ eV in the proton-dip scenario on the condition that extragalactic
protons significantly contribute to the observed cosmic rays down to $10^{17}$
eV. Thus, we conclude cosmogenic neutrinos should give us a clue to judge which
scenario is favored, unless these features are masked by the neutrino
background coming from possible, powerful neutrino sources such as AGNs and
GRBs. We also found an interesting feature that the neutrino flux at $\sim
10^{18}$ eV depends only on the cosmological evolution of the cosmic ray
sources. That means cosmogenic neutrinos with the energy bring us information
on the cosmological evolution of the sources of ultra-high energy cosmic rays.
Finally, we compare the fluxes of cosmogenic neutrinos with the expected
sensitivity curves of several neutrino detectors, and conclude the detection of
cosmogenic neutrinos in the near future is promising.
","We present an analysis of cosmogenic neutrino fluxes expected in IceCube for different models of cosmic ray sources and propagation, including recent results on anisotropy measurements by PAMELA and AMS-02 experiments. We show that these data can be used to discriminate between various scenarios of cosmic ray origin and propagation. In particular we find that:  - The observed anisotropies are consistent with predictions based on conventional astrophysical acceleration mechanisms only if one assumes very hard injection spectra at source (with spectral index below -2). This is inconsistent with observations of other messengers such as gamma-rays or radio waves.  - If one allows for more exotic particle physics processes like decaying dark matter particles then it becomes possible to explain both the observed anisotropies and the spectrum of cosmic rays without violating any observational constraints. However this scenario requires fine-tuning of parameters which makes it less appealing than conventional astrophysics explanations.",arxiv,bigscience bloomz,704.0979,0.5,0.24369747899159663,0.8102564102564103,0.3836598184424272,1,1,0,0,0,1,1,1,0,0,0.08972268893827173,0.0811412331913283,0.10505836575875487,0.07196969696969698,0,0,4,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Light nuclei in galactic globular clusters : constraints on the self-enrichment scenario from nucleosynthesis,"  Hydrogen-burning is the root cause of the star-to-star abundance variations
of light nuclei in Galactic globular clusters (GC). In the present work we
constrain the physical conditions that gave rise to the observed abundance
patterns of Li, C, N, O, Na, Mg, Al, as well as Mg isotopes in the typical case
of NGC6752. We perform nucleosynthesis calculations at constant temperature,
adopting realistic initial abundances for the proto-cluster gas. We use a
detailed nuclear reaction network and state-of-the-art nuclear reaction rates.
Although simplistic, our analysis provides original results and new constraints
on the self-enrichment scenario for GCs. Our parametrized calculations allow us
to determine a narrow range of temperature where the observed extreme
abundances of all light elements and isotopes in NGC6752 are nicely reproduced
simultaneously. This agreement is obtained after mixing of the H-processed
material with 30 % of unprocessed gas. The observed C-N, O-Na, Mg-Al, Li-Na and
F-Na anticorrelations, as well as the behaviour of the Mg isotopes can be
recovered by assuming mixing with even larger dilution factors. Li production
by the stars that build up the other abundance anomalies is not mandatory in
the case of NGC 6752. Observations of O, Na, Mg and Al constrain the
temperature range for H-burning; such temperatures are encountered in the two
main candidate ``polluters'' proposed for GCs, namely massive AGBs and the most
massive main-sequence stars. (Abridged).
","We present new results for light element abundances (Li, Be and B) in two metal-poor stars belonging to the Galactic Globular Cluster M4. The observed abundance patterns are compared with predictions based on standard Big Bang Nucleosynthesis theory as well as those obtained by assuming that these elements were produced during hydrostatic burning phases in massive AGB stars. We find that both scenarios fail to reproduce simultaneously all three measured elemental ratios at metallicities below [Fe/H] = -2.0 dex. This suggests that additional processes must be responsible for producing LiBeB in this cluster.  These findings provide important clues about the origin of light elements in low-metallicity environments such as dwarf galaxies or primordial gas clouds. In particular, they suggest that the production mechanisms may have been different than previously thought. Finally, we discuss possible implications of our results for the formation history of globular clusters.",arxiv,bigscience bloomz,704.3331,0.5555555555555556,0.29411764705882354,0.5384615384615384,0.369326325848065,1,1,1,0,1,1,1,0,0,0,0.11358778962348713,0.05617035037769227,0.14785992217898833,0.030303030303030304,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Unequal dimensional small balls and quantization on Grassmann Manifolds,"  The Grassmann manifold G_{n,p}(L) is the set of all p-dimensional planes
(through the origin) in the n-dimensional Euclidean space L^{n}, where L is
either R or C. This paper considers an unequal dimensional quantization in
which a source in G_{n,p}(L) is quantized through a code in G_{n,q}(L), where p
and q are not necessarily the same. It is different from most works in
literature where p\equiv q. The analysis for unequal dimensional quantization
is based on the volume of a metric ball in G_{n,p}(L) whose center is in
G_{n,q}(L). Our chief result is a closed-form formula for the volume of a
metric ball when the radius is sufficiently small. This volume formula holds
for Grassmann manifolds with arbitrary n, p, q and L, while previous results
pertained only to some special cases. Based on this volume formula, several
bounds are derived for the rate distortion tradeoff assuming the quantization
rate is sufficiently high. The lower and upper bounds on the distortion rate
function are asymptotically identical, and so precisely quantify the asymptotic
rate distortion tradeoff. We also show that random codes are asymptotically
optimal in the sense that they achieve the minimum achievable distortion with
probability one as n and the code rate approach infinity linearly. Finally, we
discuss some applications of the derived results to communication theory. A
geometric interpretation in the Grassmann manifold is developed for capacity
calculation of additive white Gaussian noise channel. Further, the derived
distortion rate function is beneficial to characterizing the effect of
beamforming matrix selection in multi-antenna communications.
","In this work, we study the problem of finding an optimal set of points in a Grassmann manifold that are equidistant to each other with respect to some distance measure. We propose two algorithms for solving this problem: one based on random sampling and another based on gradient descent. The first algorithm is shown to be efficient when the number of dimensions is large compared to the number of points required; however it does not scale well as the dimension increases. On the other hand, our second approach scales better but requires more iterations than the first method. Finally, numerical experiments show that both methods perform similarly in practice. This research was supported by NSERC Discovery Grants RGPIN-2014-04567 (A.S.) and RGPIN-2016-05189 (M.D.). 
Introduction

Let $Gr(k,n)$ denote the Grassmannian manifold consisting of all $k$-dimensional subspaces of $\mathbb{R}^n$. In many applications such as signal processing or machine learning, one needs to find a subset of points in $Gr(k, n)$ which are close together according to some metric.  For example, consider the following scenario where one wants to transmit data over multiple channels simultaneously using space-time coding techniques. Here, the transmitter encodes information into a vector of symbols drawn from a finite alphabet $\mathcal{A}$. Then, these vectors can be transmitted across different antennas at the same time. However, if there are too few antennas available then the receiver may experience poor performance due to interference between signals received through adjacent antennas. To overcome this issue, one could use multi-antenna transmission schemes whereby the transmitter sends several independent streams of information across different antennas. These streams would correspond to different points in $Gr(1,N)$, where $N$ denotes the total number of antennas used. Another application involves compressive sensing problems where one seeks to recover a sparse vector $x$ from its noisy measurements $y$ given by: $$y = Ax + w$$",arxiv,bigscience bloomz,705.2278,0.5555555555555556,0.3445378151260504,0.676923076923077,0.39082656473960825,1,1,0,0,0,2,2,1,0,0,0.1927060713966866,0.07133574791092145,0.29571984435797666,0.041666666666666664,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,2,1,2,1,1
"Disclinations, dislocations and continuous defects: a reappraisal","  Disclinations, first observed in mesomorphic phases, are relevant to a number
of ill-ordered condensed matter media, with continuous symmetries or frustrated
order. They also appear in polycrystals at the edges of grain boundaries. They
are of limited interest in solid single crystals, where, owing to their large
elastic stresses, they mostly appear in close pairs of opposite signs. The
relaxation mechanisms associated with a disclination in its creation, motion,
change of shape, involve an interplay with continuous or quantized dislocations
and/or continuous disclinations. These are attached to the disclinations or are
akin to Nye's dislocation densities, well suited here. The notion of 'extended
Volterra process' takes these relaxation processes into account and covers
different situations where this interplay takes place. These concepts are
illustrated by applications in amorphous solids, mesomorphic phases and
frustrated media in their curved habit space. The powerful topological theory
of line defects only considers defects stable against relaxation processes
compatible with the structure considered. It can be seen as a simplified case
of the approach considered here, well suited for media of high plasticity
or/and complex structures. Topological stability cannot guarantee energetic
stability and sometimes cannot distinguish finer details of structure of
defects.
","The concept of defects in crystals has been developed by the Russian school since the 1930s. The main idea is that any crystal can be considered as an elastic continuum with some local deviations from its ideal structure which are called defects. In this work we present a brief review on the history of the development of the theory of defects in solids. We also discuss the modern concepts of point-like defects (dislocations), line-like defects (disclinations) and continuous defects. Finally, we give examples of how these ideas have been applied to different physical systems such as liquid crystals or magnetic materials. Defects play an important role in many areas of physics ranging from solid state physics to condensed matter physics and even biology. They appear naturally during phase transitions between ordered states like those occurring at melting points or critical temperatures. For example, they may lead to plastic deformations in metals or glassy materials. On the other hand, defects are responsible for macroscopic properties of solids like electrical conductivity or magnetization.",arxiv,bigscience bloomz,704.3055,0.5,0.3949579831932773,0.37948717948717947,0.4438604873387483,0,1,0,0,1,1,1,0,0,0,0.047816061784746594,0.026960153650720853,0.06614785992217899,0.022727272727272728,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
A New Proof of Pappus's Theorem,"  Any stretching of Ringel's non-Pappus pseudoline arrangement when projected
into the Euclidean plane, implicitly contains a particular arrangement of nine
triangles. This arrangement has a complex constraint involving the sines of its
angles. These constraints cannot be satisfied by any projection of the initial
arrangement. This is sufficient to prove Pappus's theorem. The derivation of
the constraint is via systems of inequalities arising from the polar
coordinates of the lines. These systems are linear in r for any given theta,
and their solubility can be analysed in terms of the signs of determinants. The
evaluation of the determinants is via a normal form for sums of products of
sines, giving a powerful system of trigonometric identities. The particular
result is generalized to arrangements derived from three edge connected totally
cyclic directed graphs, conjectured to be sufficient for a complete analysis of
angle constraining arrangements of lines, and thus a full response to Ringel's
slope conjecture. These methods are generally applicable to the realizability
problem for rank 3 oriented matroids.
","In this note, we present an elementary proof for the following theorem due to Pappus:
Theorem 1 (Pappus' theorem). Let $ABC$ be any triangle and let $D$ be its incenter. Then the three medians $AD$, $BE$, and $CF$ intersect at one point $K$ inside the triangle. 
Proof. We first prove that the line segments $AB$, $BC$, and $CA$ are concurrent in one point $K$ by using only basic geometry. The idea is as follows. Consider the circle $C_1$ centered at $A$ with radius $AC$. Similarly consider circles $C_2$ and $C_3$ centered at $B$ and $C$ respectively with radii $BD$ and $CD$. Note that all these three circles have their centers on the same side of the triangle $ABC$. Now if we draw lines through $A'$, $B'$, and $C'$ which are intersection points between the circumcircles of triangles $ABC$ and $A_1B_1C_1$, $A_2B_2C_2$, and $A_3B_3C_3$ then it can easily be seen that they will meet at one common point $K$.",arxiv,bigscience bloomz,704.3424,0.4444444444444444,0.4453781512605043,0.2358974358974359,0.40659340659340665,0,1,0,0,1,1,0,1,0,1,0.08961620337555654,0.14153747249257026,0.10505836575875487,0.15151515151515152,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
A rigidity theorem for the mapping class group action on the space of unmeasured foliations on a surface,"  Let $S$ be a surface of finite type which is not a sphere with at most four
punctures, a torus with at most two punctures, or a closed surface of genus
two. Let $\mathcal{MF}$ be the space of equivalence classes of measured
foliations of compact support on $S$ and let $\mathcal{UMF}$ be the quotient
space of $\mathcal{MF}$ obtained by identifying two equivalence classes
whenever they can be represented by topologically equivalent foliations, that
is, forgetting the transverse measure. The extended mapping class group
$\Gamma^*$ of $S$ acts as by homeomorphisms of $\mathcal{UMF}$. We show that
the restriction of the action of the whole homeomorphism group of
$\mathcal{UMF}$ on some dense subset of $\mathcal{UMF}$ coincides with the
action of $\Gamma^*$ on that subset. More precisely, let $\mathcal{D}$ be the
natural image in $\mathcal{UMF}$ of the set of homotopy classes of not
necessarily connected essential disjoint and pairwise nonhomotopic simple
closed curves on $S$. The set $\mathcal{D}$ is dense in $\mathcal{UMF}$, it is
invariant by the action of $\Gamma^*$ on $\mathcal{UMF}$ and the restriction of
the action of $\Gamma^*$ on $\mathcal{D}$ is faithful. We prove that the
restriction of the action on $\mathcal{D}$ of the group
$\mathrm{Homeo}(\mathcal{UMF})$ coincides with the action of $\Gamma^*(S)$ on
that subspace.
","We prove that if a pseudo-Anosov homeomorphism is homotopic to an automorphism, then it has no periodic points in its Julia set.  This result implies that any such map can be approximated by a linear Anosov diffeomorphism with respect to the Teichmüller metric and hence gives another proof of Thurston's classification of surfaces.   We also show how this result leads to a new proof of the fact that the mapping class group acts properly discontinuously on the space of measured laminations (and thus on the space of all measured foliations) when restricted to those which are not supported on multicurves.    The first author would like to thank his advisor Professor Richard S. Hamilton for suggesting this problem as well as many helpful discussions throughout the course of this work. The second author would like to thank Professor David Gabai for several useful conversations during the preparation of this manuscript.",arxiv,bigscience bloomz,705.1837,0.3333333333333333,0.19327731092436976,0.4153846153846154,0.38079311992355475,1,0,0,0,0,1,1,0,0,1,0.11803329498637383,0.08617334593735071,0.15953307392996108,0.06060606060606061,0,0,6,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
Higher K-theory via universal invariants,"  Using the formalism of Grothendieck's derivators, we construct `the universal
localizing invariant of dg categories'. By this, we mean a morphism U_l from
the pointed derivator associated with the Morita homotopy theory of dg
categories to a triangulated strong derivator M^loc such that U_l commutes with
filtered homotopy colimits, preserves the point, sends each exact sequence of
dg categories to a triangle and is universal for these properties. Similary, we
construct the `the universal additive invariant of dg categories', i.e. the
universal morphism of derivators U_a to a strong triangulated derivator M^add
which satisfies the first two properties but the third one only for split exact
sequences. We prove that Waldhausen K-theory appears as a mapping space in the
target of the universal additive invariant. This is the first conceptual
characterization of Quillen-Waldhausen's K-theory since its definition in the
early 70's. As an application we obtain for free the higher Chern characters
from K-theory to cyclic homology.
","We give an explicit description of the higher algebraic K-groups in terms of certain universal cohomology classes, which are defined by using only the ring structure and the unit element of the underlying commutative ring. This is done for any commutative ring with unity R (not necessarily Noetherian). The main result can be formulated as follows: Let M be a module over R. Then there exists a natural isomorphism between the higher algebraic K-groups: 
K_n(R) = Ext^n_R(M, R)
and the group of all n-fold Massey products on M modulo those that vanish under some suitable finiteness condition. We also show how this theorem leads to a new proof of Quillen's localization theorem. Finally we discuss applications to the study of equivariant K-theory. In particular, we prove that if G is a compact Lie group acting freely on a smooth manifold X then the equivariant K-theory groups of X are isomorphic to the ordinary K-theory groups of the fixed point set X^G.",arxiv,bigscience bloomz,706.242,0.3333333333333333,0.24369747899159663,0.17435897435897435,0.41519350215002393,0,1,0,0,1,1,1,1,0,1,0.12918456859361013,0.14772724257228595,0.1556420233463035,0.14772727272727273,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
SN 2005hj: Evidence for Two Classes of Normal-Bright SNe Ia and Implications for Cosmology,"  HET Optical spectra covering the evolution from about 6 days before to about
5 weeks after maximum light and the ROTSE-IIIb unfiltered light curve of the
""Branch-normal"" Type Ia Supernova SN 2005hj are presented. The host galaxy
shows HII region lines at redshift of z=0.0574, which puts the peak unfiltered
absolute magnitude at a somewhat over-luminous -19.6. The spectra show weak and
narrow SiII lines, and for a period of at least 10 days beginning around
maximum light these profiles do not change in width or depth and they indicate
a constant expansion velocity of ~10,600 km/s. We analyzed the observations
based on detailed radiation dynamical models in the literature. Whereas delayed
detonation and deflagration models have been used to explain the majority of
SNe Ia, they do not predict a long velocity plateau in the SiII minimum with an
unvarying line profile. Pulsating delayed detonations and merger scenarios form
shell-like density structures with properties mostly related to the mass of the
shell, M_shell, and we discuss how these models may explain the observed SiII
line evolution; however, these models are based on spherical calculations and
other possibilities may exist. SN 2005hj is consistent with respect to the
onset, duration, and velocity of the plateau, the peak luminosity and, within
the uncertainties, with the intrinsic colors for models with M_shell=0.2 M_sun.
Our analysis suggests a distinct class of events hidden within the
Branch-normal SNe Ia. If the predicted relations between observables are
confirmed, they may provide a way to separate these two groups. We discuss the
implications of two distinct progenitor classes on cosmological studies
employing SNe Ia, including possible differences in the peak luminosity to
light curve width relation.
","We present the discovery, photometric and spectroscopic observations of SN 2005hj (PTF10ygu), an apparently normal-bright Type Ia supernova discovered by PTF in late March 2005 at z = 0.084. The light curve shows two distinct peaks separated by about one month with no evidence for interaction between ejecta and circumstellar material. We find that this object is consistent with being a member of the class of ""normal-bright"" SNe Ia defined by Phillips et al. (1999) but has a higher peak luminosity than most members of this class. Using our own data as well as published results we estimate the distance to SN 2005hj using three different methods. All three give distances which are inconsistent with each other within their uncertainties. This may be due to systematic errors or it could indicate that there exists more than one subclass of ""normal-bright"" objects. If confirmed, these findings have important implications for cosmological studies based on SNe Ia. 
 
 Keywords: Supernovae",arxiv,bigscience bloomz,705.4467,0.5,0.3949579831932773,0.8051282051282052,0.4037267080745342,0,1,1,0,0,1,1,1,0,0,0.11217380966191286,0.0694364139504871,0.10894941634241245,0.03409090909090909,0,1,5,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Coriolis force corrections to g-mode spectrum in 1D MHD model,"  The corrections to g-mode frequencies caused by the presence of a central
magnetic field and rotation of the Sun are calculated. The calculations are
carried out in the simple one dimensional magnetohydrodynamical model using the
approximations which allow one to find the purely analytical spectra of
magneto-gravity waves beyond the scope of the JWKB approximation and avoid in a
small background magnetic field the appearance of the cusp resonance which
locks a wave within the radiative zone. These analytic results are compared
with the satellite observations of the g-mode frequency shifts which are of the
order one per cent as given in the GOLF experiment at the SoHO board. The main
contribution turns out to be the magnetic frequency shift in the strong
magnetic field which obeys the used approximations. In particular, the fixed
magnetic field strength 700 KG results in the mentioned value of the frequency
shift for the g-mode of the radial order n=-10. The rotational shift due to the
Coriolis force appears to be small and does not exceed a fracton of per cent,
\alpha_\Omega < 0.003.
","We present the results of our study on coriolis effects on the global oscillation modes (g-modes) in magnetized white dwarfs using one-dimensional, fully compressible numerical simulations with realistic equation-of-state and opacities. We find that the effect is significant for low-order g-modes but negligible for high-order ones. The frequency shifts are found to be proportional to the mode inertia which can be estimated by fitting the eigenfunctions obtained numerically into those calculated analytically under the thin-shell approximation. For typical parameters relevant to ZZ Ceti stars, we estimate the frequency shift due to coriolis forces to be about 0.1 % at most. This result suggests that it may not be necessary to take account of such effects when interpreting observed frequencies of pulsating white dwarf stars. However, this conclusion should be checked against more sophisticated models including rotation as well as magnetic fields.",arxiv,bigscience bloomz,705.2923,0.2777777777777778,0.24369747899159663,0.2923076923076923,0.35785953177257523,0,1,0,0,0,1,1,0,0,0,0.11642040492049396,0.05368014274746384,0.13618677042801555,0.056818181818181816,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Is the Concentration of Dark Matter Halos at Virialization Universal ?,"  Several recent studies suggest a correlation between dark matter halo mass
and the shape of the density profile. We re-analyze simulations from Ricotti
(2003) in which such a correlation was proposed. We use a standard analysis of
the halo density profiles and compare the old simulations to new ones performed
with Gadget2, including higher resolution runs. We confirm Ricotti's result
that, at virialization, the central log slopes alpha, at 5%-10% of the virial
radius are correlated with the halo mass and that the halo concentration is a
universal constant. Our results do not contradict the majority of published
papers: when using a split power law to fit the density profiles, due to the
alpha-concentration degeneracy, the fits are consistent with halos having a
universal shape with alpha=1 or 1.5 and concentrations that depend on the mass,
in agreement with results published elsewhere.
  Recently, several groups have found no evidence for convergence of the inner
halo profile to a constant power law. The choice of a split power law
parameterization used in this letter is motivated by the need to compare our
results to previous ones and is formally valid because we are not able to
resolve regions where the slope of the fitting function reaches its asymptotic
constant value. Using a non-parameterized technique, we also show that the
density profiles of dwarf galaxies at z ~ 10 have a log slope shallower than
0.5 within 5% of the virial radius.
","We study the concentration-mass relation for dark matter haloes in cosmological N-body simulations with different initial conditions and resolutions, focusing on the dependence on halo mass and redshift. We find that the concentrations are well described by an empirical formula proposed recently by Navarro et al. (2004) : c = c0(M/M0)^a(z), where M is the virial mass of the halo, z its formation time (defined as the epoch when half of the final mass was assembled into progenitors), c0 ,a and M0 are free parameters to be determined numerically. The best-fit values of these parameters depend only weakly on the simulation resolution or the initial power spectrum index n. In particular, we show that the value of a0 is independent of both n and the numerical resolution. This result suggests that the concentration of dark matter haloes may not be universal but depends on their formation history.",arxiv,bigscience bloomz,706.0856,0.3888888888888889,0.19327731092436976,0.6,0.3750597228858099,1,1,1,0,1,1,1,1,0,0,0.13677411848379578,0.1264452664274404,0.14396887159533073,0.13636363636363635,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Point-contact spectroscopy of the antiferromagnetic superconductor HoNi2B2C in the normal and superconducting state,"  Point-contact (PC) spectroscopy measurements on antiferromagnetic (AF)
(T_N=5.2K) HoNi2B2C single crystals in the normal and two different
superconducting (SC) states (T_c=8.5K and $T_c^*=5.6K) are reported. The PC
study of the electron-boson(phonon) interaction (EB(P)I) spectral function
reveals pronounced phonon maxima at 16, 22 and 34meV. For the first time the
high energy maxima at about 50meV and 100meV are resolved. Additionally, an
admixture of a crystalline-electric-field (CEF) excitations with a maximum near
10meV and a `magnetic` peak near 3meV are observed. The contribution of the
10-meV peak in PC EPI constant \lambda_PC is evaluated as 20-30%, while
contribution of the high energy modes at 50 and 100meV amounts about 10% for
each maxima, so the superconductivity might be affected by CEF excitations. The
SC gap in HoNi2B2C exhibits a standard single-band BCS-like dependence, but
vanishes at $T_c^*=5.6K<T_c, with 2\Delta/kT_c^*=3.9. The strong coupling
Eliashberg analysis of the low-temperature SC phase with T_c^*=5.6K =T_N,
coexisting with the commensurate AF structure, suggests a sizable value of the
EPI constant \lambda_s=0.93. We also provide strong support for the recently
proposed by us ''Fermi surface (FS) separation'' scenario for the coexistence
of magnetism and superconductivity in magnetic borocarbides, namely, that the
superconductivity in the commensurate AF phase survives at a special (nearly
isotropic) FS sheet without an admixture of Ho 5d states. Above T_c^* the SC
features in the PC characteristics are strongly suppressed pointing to a
specific weakened SC state between T_c* and T_c.
","We report on point contact Andreev reflection (PCAR) measurements performed on single crystals of the heavy fermion compound HoNi2B2C, which is an antiferromagnet with T N = 1.5 K that becomes a type-II superconductor below Tc = 0.8 K. The PCAR spectra show clear evidence for multiple gaps at low temperatures. We find two distinct gap values, one of them being close to twice the value of the other. This observation suggests that there are two different bands crossing the Fermi level. In addition we observe a temperature dependence of both gaps indicating their nodal character. Our results provide further insight into the electronic structure of this material. Heavy-fermion compounds have attracted considerable interest over recent years because they often exhibit unconventional physical properties such as non-Fermi liquid behavior or even quantum criticality [1] . These materials can be described by the periodic Anderson model [2] , where conduction electrons hybridize strongly with localized f -electrons leading to the formation of narrow bands near the Fermi energy E F [3] .
HoNi 2 B 2 C belongs to the family of so-called borocarbides [4] . It crystallizes in the tetragonal ThCr 2 Si 2 structure [5] and has been shown to become a type-II superconductor [6] below T c ≈ 0.8 K [7, 8] . At ambient pressure it orders magnetically around T N = 1.6 K [9] . Recent studies suggest that the magnetic order is driven by strong spin-orbit coupling [10] . A number of experiments indicate that the ground-state wave function consists of singlet pairs [11, 12] . However, the exact nature of the pairing mechanism remains unclear [13] .",arxiv,bigscience bloomz,705.3405,0.4444444444444444,0.596638655462185,0.5948717948717949,0.7362637362637362,1,1,0,0,1,1,1,0,0,0,0.11566427585724574,0.10652518747967336,0.12840466926070038,0.11742424242424243,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On over-reflection and generation of Gravito-Alfven waves in solar-type stars,"  The dynamics of linear perturbations is studied in magnetized plasma shear
flows with a constant shearing rate and with gravity-induced stratification.
The general set of linearized equations is derived and the two-dimensional case
is considered in detail. The Boussinesq approximation is used in order to
examine relatively small-scale perturbations of low-frequency modes:
Gravito-Alfven waves (GAW) and Entropy Mode (EM) perturbations. It is shown
that for flows with arbitrary shearing rate there exists a finite time interval
of non-adiabatic evolution of the perturbations. The non-adiabatic behavior
manifests itself in a twofold way, viz. by the over-reflection of the GAWs and
by the generation of GAWs from EM perturbations. It is shown that these
phenomena act as efficient transformers of the equilibrium flow energy into the
energy of the perturbations for moderate and high shearing rate solar plasma
flows. Efficient generation of GAW by EM takes place for shearing rates about
an order of magnitude smaller than necessary for development of a shear
instability. The latter fact could have important consequences for the problem
of angular momentum redistribution within the Sun and solar-type stars.
","We study the reflection of Alfven waves at the surface of a rotating star with an inclined magnetic field, which is relevant to the problem of coronal heating by MHD turbulence generated near the stellar surface. We show that if the angle between the wave vector k and the normal n to the reflecting surface satisfies cos(k·n) > 1 (over-reflection), then there exists a critical frequency ωcr = √ 2Ω above which no Alfven waves can propagate into the interior region of the star. This leads to the formation of standing waves on the surface of the star whose amplitude grows exponentially as time goes on. The growth rate depends only weakly on the inclination angle θB of the magnetic field lines but strongly on the density contrast across the surface layer. For typical parameters of the Sun we find that the exponential growth starts after about one day for θB = 60 degrees and after about ten days for θB = 90 degrees.",arxiv,bigscience bloomz,704.3919,0.4444444444444444,0.19327731092436976,0.30256410256410254,0.4237935977066412,1,1,1,0,0,1,1,0,0,0,0.05646741225244819,0.0952200451296513,0.058365758754863814,0.10606060606060606,0,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Effects of the anomaly on the two-flavor QCD chiral phase transition,"  We use strongly coupled lattice QED with two flavors of massless staggered
fermions to model the physics of pions in two-flavor massless QCD. Our model
has the right chiral symmetries and can be studied efficiently with cluster
algorithms. In particular we can tune the strength of the QCD anomaly and thus
study its effects on the chiral phase transition. Our study confirms the widely
accepted view point that the chiral phase transition is first order in the
absence of the anomaly. Turning on the anomaly weakens the transition and turns
it second order at a critical anomaly strength. The anomaly strength at the
tricritical point is characterized using $r = (M_{\eta'}-M_{\pi})/\rho_{\eta'}$
where $M_{\eta'}, M_{\pi}$ are the screening masses of the anomalous and
regular pions and $\rho_{\eta'}$ is the mass-scale that governs the low energy
fluctuations of the anomalous symmetry. We estimate that $r \sim 7 $ in our
model. This suggests that a strong anomaly at the two-flavor QCD chiral phase
transition is necessary to wash out the first order transition.
","We study effects of the axial U(1) A anomaly in the two-flavor lattice QCD with Wilson fermions at finite temperature and density by using the Polyakov-loop extended Nambu-Jona-Lasinio (PNJL) model. We find that the PNJL results are consistent with those obtained by the standard NJL model, which does not include the anomaly effect explicitly. The critical chemical potential for the onset of diquark condensation is shifted to larger values due to the anomaly effect. This shift becomes smaller as we increase the current quark mass. In addition, the magnitude of the diquark condensate decreases when the anomaly term is included. 
 
 PACS numbers: 11.10.Wx, 12.38.Gc, 14.40.Nd 
 
 Introduction: It has been known that the axial U(1) 
 
 
 
 Here mq denotes the current quark mass.",arxiv,bigscience bloomz,705.0617,0.3888888888888889,0.24369747899159663,0.24615384615384617,0.3005255613951266,1,1,0,0,1,1,1,1,0,0,0.18019049528742345,0.06612914315194447,0.245136186770428,0.030303030303030304,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On the nature of optical nuclei in FR I radio-galaxies from ACS/HST imaging polarimetry,"  We obtained optical imaging polarimetry with the ACS/HRC aboard the HST of
the 9 closest radio-galaxies in the 3C catalogue with an FR I morphology. The
nuclear sources seen in direct HST images in these galaxies are found to be
highly polarized with levels in the range ~2-11 % with a median value of 7 %.
We discuss the different mechanisms that produce polarized emission and
conclude that the only viable interpretation is a synchrotron origin for the
optical nuclei. This idea is strengthened by the analogy with the polarization
properties of BL Lac objects, providing also further support to the FRI/BL Lac
unified model. This confirms previous suggestions that the dominant emission
mechanism in low luminosity radio-loud AGN is related to non-thermal radiation
produced by the base of their jets. In addition to the nuclear polarization
(and to the large scale optical jets), polarization is detected co-spatially
with the dusty circumnuclear disks, likely due to dichroic transmission; the
polarization vectors are tangential to the disks as expected when the magnetic
field responsible for the grains alignment is stretched by differential
rotation. We explored the possibility to detect the polarimetric signature of a
misaligned radiation beam in FR I, expected in our sources in the frame of the
FR I/ BL Lac unification. We did not find this effect in any of the galaxies,
but our the results are not conclusive on whether a misaligned beam is indeed
present in FR I.
","We present new HST/ACS observations of four nearby Fanaroff-Riley type-I (FR I) radio galaxies, 3C 31, 3C 264, 4C+55.17 and PKS 0745-191 . We use these data to study their nuclear properties by means of aperture photometry and image decomposition techniques. The results show that all sources have an unresolved core component with typical luminosities between 1040-1050 erg s-1 Hz-1 at rest-frame 5100 Å , which is consistent with previous studies based on ground-based near-infrared spectroscopy. In addition we find evidence for extended emission around the nucleus in two out of four objects studied here. This extended emission has been previously detected only in one other FR I galaxy, namely M 87. Our analysis shows that this extended emission can be explained as scattered light from the central source. Finally, our results suggest that the observed polarization fraction increases towards shorter wavelengths, indicating that dust extinction plays an important role in determining the intrinsic polarization properties of these systems.",arxiv,bigscience bloomz,706.1944,0.3888888888888889,0.29411764705882354,0.6102564102564103,0.4094601051122791,1,1,1,0,0,1,1,0,0,0,0.09403899030836613,0.05784409413035078,0.11673151750972763,0.04924242424242424,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Probing dark energy with steerable wavelets through correlation of WMAP and NVSS local morphological measures,"  Using local morphological measures on the sphere defined through a steerable
wavelet analysis, we examine the three-year WMAP and the NVSS data for
correlation induced by the integrated Sachs-Wolfe (ISW) effect. The steerable
wavelet constructed from the second derivative of a Gaussian allows one to
define three local morphological measures, namely the signed-intensity,
orientation and elongation of local features. Detections of correlation between
the WMAP and NVSS data are made with each of these morphological measures. The
most significant detection is obtained in the correlation of the
signed-intensity of local features at a significance of 99.9%. By inspecting
signed-intensity sky maps, it is possible for the first time to see the
correlation between the WMAP and NVSS data by eye. Foreground contamination and
instrumental systematics in the WMAP data are ruled out as the source of all
significant detections of correlation. Our results provide new insight on the
ISW effect by probing the morphological nature of the correlation induced
between the cosmic microwave background and large scale structure of the
Universe. Given the current constraints on the flatness of the Universe, our
detection of the ISW effect again provides direct and independent evidence for
dark energy. Moreover, this new morphological analysis may be used in future to
help us to better understand the nature of dark energy.
","We propose to probe the nature of dark energy by correlating the morphological properties of galaxies in the nearby universe (z < 0.1) as measured by the Sloan Digital Sky Survey (SDSS), with those at higher redshifts, z ~ 1, obtained from the Wilkinson Microwave Anisotropy Probe (WMAP). We use steerable wavelet transforms on galaxy images to obtain morphological parameters such as concentration index, asymmetry index, Gini coefficient etc., which are then correlated with their counterparts derived from WMAP data using the same technique. The results show that these correlations can be used to discriminate between different models for dark energy. This is an extension of our earlier work where we have shown how one can correlate the morphology of galaxies in SDSS with CMB fluctuations observed by WMAP. In this work, we present detailed analysis of various statistical tests performed on simulated datasets generated under different cosmological scenarios.",arxiv,bigscience bloomz,704.0626,0.4444444444444444,0.19327731092436976,0.48205128205128206,0.38079311992355475,1,1,0,0,0,1,0,0,0,0,0.04945031789988919,0.12425129827365317,0.05058365758754864,0.06818181818181818,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Socioeconomic Networks with Long-Range Interactions,"  We study a modified version of a model previously proposed by Jackson and
Wolinsky to account for communicating information and allocating goods in
socioeconomic networks. In the model, the utility function of each node is
given by a weighted sum of contributions from all accessible nodes. The
weights, parameterized by the variable $\delta$, decrease with distance. We
introduce a growth mechanism where new nodes attach to the existing network
preferentially by utility. By increasing $\delta$, the network structure
evolves from a power-law to an exponential degree distribution, passing through
a regime characterised by shorter average path length, lower degree
assortativity and higher central point dominance. In the second part of the
paper we compare different network structures in terms of the average utility
received by each node. We show that power-law networks provide higher average
utility than Poisson random networks. This provides a possible justification
for the ubiquitousness of scale-free networks in the real world.
","We study the dynamics on networks where nodes are connected by both short-range and long-range interactions, which can be either attractive or repulsive. We show that in this case there is no phase transition between ordered and disordered phases as it was observed for purely local interaction models. Instead we find an intermediate regime characterized by strong fluctuations of order parameters. The critical behavior at the boundary to the ordered state depends crucially on whether the long-range interactions are attractive or repulsive. In particular, if they are repulsive then the system exhibits mean-field-like criticality while for attractive long-range interactions one finds non-trivial exponents similar to those found previously for purely local systems. 
I. INTRODUCTIO N
The concept of self-organized criticality (SOC) has been introduced recently [1] . It describes a class of dynamical systems whose evolution leads them into states close to equilibrium without any fine tuning of control parameters [2] .
In SOC systems, the appearance of power-law distributions of avalanche sizes [3] , relaxation times [4] , etc., is explained by assuming that these systems evolve towards their critical point [5] . This idea has been applied successfully to many different physical phenomena [6] including earthquakes [7] , forest fires [8] , traffic jams [9] , sandpiles [10] , neural networks [11] , epidemics [12] , population dynamics [13] , etc..
Recently, several authors have studied the effect of nonlocal interactions on the properties of SOC systems [14 -17] . They showed that nonlocal interactions lead to new interesting effects such as the absence of phase transitions [17] , the existence of multiple absorbing states [14] , and the possibility of having spatially localized solutions [15] . However, all previous studies were restricted to the case when only nearest-neighbor interactions exist. Here we consider more general cases when the network contains also long-range interactions.",arxiv,bigscience bloomz,706.0024,0.3888888888888889,0.596638655462185,0.1641025641025641,0.8308647873865265,0,1,0,0,0,1,1,0,0,0,0.07465124691104254,0.10274576516921528,0.08560311284046693,0.11363636363636363,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
L'Univers en expansion et probl\`emes d'\'energie,"  In this paper we first construct a mathematical model for the Universe
expansion that started up with the original Big Bang. Next, we discuss the
problematic of the mechanical and physical laws invariance regarding the
spatial frame exchanges. We then prove the (theoretical) existence of a
variable metric $g_t$, depending on time and satisfying to a simplified
Einstein equation, so that all free ordinary trajectories are geodesics. This
is done by considering the classical Galileo-Newtonian space and time relation,
by using generalized Newtonian principles and adding the approved physical new
ones (as covariance principle, Mach principle, the Einstein equivalence
principle ...) in order to establish a new cosmological model of the dynamical
Universe as being $(U(t))_{t\geq 0}=(B_e(O,t),g_t)_{t\geq 0}$, where $B_e(O,t)$
is the Euclidean ball of radius $t$ in $\mathbb R^3$. The cosmological metric
$g_t$ is totally determined, at time $t$, by the mass energy distribution
$E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove
that the total and global cosmological energy distribution $E_t(X)$ satisfies
to the wave equation whose solutions are characterized by pseudo-frequencies
depending on time and related to the spectrum of the Dirichlet problem on the
unit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\Delta$. Our model is
consistent in the sense that all Newtonian and classical physical laws are
valid as particular cases in classical situations. Then, we show that all basic
results of Modern Physics are still valid without using the second postulate of
special relativity nor the uncertainty principle.
","L'expansion de l'univers est un ph\u00e9nom\u00e8ne qui se produit depuis le Big Bang, il y a environ 13 milliards d'ann\u00e9es. Elle continue aujourd'hui \u00e0 une vitesse d'environ 70 km/seconde par m\u00e8tre carr\u00e9 (ou 1 m/seconde par kilom\u00e8tre). Cette vitesse d'expansion augmente avec la distance entre les objets observ\u00e9s dans l'univers. La th\u00eorie du Big Bang pr\u00e9dit que l'expansion devrait continuer \u00e0 s'accro\u00eetre au cours du temps. Cependant, si l'on observe l'univers sur des distances plus petites, on constate qu'il ne semble pas s'agrandir aussi vite qu'on pourrait s'y attendre. Il existe donc quelque chose qui contrarie cette tendance \u00e0 l'accroissement de l'expansion. On appelle cela ""l'énergie noire"" ou ""dark energy"". L'énergie noire représente environ 70% de l'énergie totale présente dans l'univers.",arxiv,bigscience bloomz,705.1248,0.3888888888888889,0.3445378151260504,0.6358974358974359,0.3005255613951266,1,1,0,0,0,1,0,0,0,1,0.2721303345935508,0.040493540756033244,0.27626459143968873,0.03787878787878788,0,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Very High Energy Gamma-ray Radiation from the Stellar-mass Black Hole Cygnus X-1,"  We report on the results from the observations in very high energy band (VHE,
E_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The
observations were performed with the MAGIC telescope, for a total of 40 hours
during 26 nights, spanning the period between June and November 2006. Searches
for steady gamma-ray signals yielded no positive result and upper limits to the
integral flux ranging between 1 and 2% of the Crab nebula flux, depending on
the energy, have been established. We also analyzed each observation night
independently, obtaining evidence of gamma-ray signals at the 4.0 standard
deviations (sigma) significance level (3.2 sigma after trial correction) for
154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41
UTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search
for faster-varying signals within a night resulted in an excess with a
significance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT
between 22h17 and 23h41 UTC. The measured excess is compatible with a
point-like source at the position of Cygnus X-1, and excludes the nearby radio
nebula powered by its relativistic jet. The differential energy spectrum is
well fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x
10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of
VHE emission from a stellar-mass black hole, and therefore from a confirmed
accreting X-ray binary.
","The Very Energetic Radiation Imaging Telescope Array System (VERITAS) is an array of four 12m diameter imaging atmospheric Cherenkov telescopes located at the Fred Lawrence Whipple Observatory in southern Arizona, USA. The instrument was designed to detect gamma rays with energies between 100 GeV and 30 TeV. In this work we report on observations made by VERITAS during 2005-2007 that reveal very high energy emission from the black hole binary system Cygnus X-1. We find evidence for two distinct spectral components; one peaking near 1 TeV and another extending up to 20 TeV. These results are consistent with previous measurements made using other instruments such as MAGIC and HEGRA. This source has been observed previously but never before detected above 10 TeV. Our data also show significant variability over timescales ranging from minutes to months. Finally, we present preliminary results from our analysis of archival data taken prior to 2005 which suggest that there may be additional periods when Cygnus X-1 emits VHE radiation.",arxiv,bigscience bloomz,706.1505,0.3888888888888889,0.3445378151260504,0.6,0.4237935977066412,1,1,0,0,0,1,1,1,0,0,0.10073900597448178,0.06285640045494667,0.09727626459143969,0.05303030303030303,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A map of the day-night contrast of the extrasolar planet HD 189733b,"  ""Hot Jupiter"" extrasolar planets are expected to be tidally locked because
they are close (<0.05 astronomical units, where 1 AU is the average Sun-Earth
distance) to their parent stars, resulting in permanent daysides and
nightsides. By observing systems where the planet and star periodically eclipse
each other, several groups have been able to estimate the temperatures of the
daysides of these planets. A key question is whether the atmosphere is able to
transport the energy incident upon the dayside to the nightside, which will
determine the temperature at different points on the planet's surface. Here we
report observations of HD 189733, the closest of these eclipsing planetary
systems, over half an orbital period, from which we can construct a 'map' of
the distribution of temperatures. We detected the increase in brightness as the
dayside of the planet rotated into view. We estimate a minimum brightness
temperature of 973 +/- 33 K and a maximum brightness temperature of 1212 +/- 11
K at a wavelength of 8 microns, indicating that energy from the irradiated
dayside is efficiently redistributed throughout the atmosphere, in contrast to
a recent claim for another hot Jupiter. Our data indicate that the peak
hemisphere-integrated brightness occurs 16$\pm$6 degrees before opposition,
corresponding to a hot spot shifted east of the substellar point. The secondary
eclipse (when the planet moves behind the star) occurs 120 +/- 24 s later than
predicted, which may indicate a slightly eccentric orbit.
","We present an analysis of high-resolution near-infrared images obtained with NACO/VLT and SPHERE/ZIMPOL/ESO to study the photometric variability of the exoplanet HD 189733b in its transit across the stellar disk. We find that the planet's brightness varies by more than one magnitude between phases 0.8-0.9, which is consistent with previous results based on lower resolution data. The observed phase curve shows two maxima at phases 0.85 and 0.95, indicating that the planet has a strong east-west temperature gradient. This result can be explained if we assume that the planet orbits close to edge-on (i = 85°) and that it receives most of its energy from the star through a single hemisphere. In this case, the planet would have a large day/night temperature difference of about 1000 K. Our observations also show evidence for a small hot spot located near the substellar point.",arxiv,bigscience bloomz,705.0993,0.3888888888888889,0.19327731092436976,0.5948717948717949,0.3607262302914477,1,1,0,0,1,1,1,0,0,1,0.09858328844317198,0.03160849941384405,0.14396887159533073,0.030303030303030304,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
On the orbital periods of the AM CVn stars HP Librae and V803 Centauri,"  We analyse high-time-resolution spectroscopy of the AM CVn stars HP Librae
and V803 Centauri, taken with the New Technology Telescope (NTT) and the Very
Large Telescope (VLT) of the European Southern Observatory, Chile.
  We present evidence that the literature value for V803 Cen's orbital period
is incorrect, based on an observed `S-wave' in the binary's spectrogram. We
measure a spectroscopic period P=1596.4+/-1.2s of the S-wave feature, which is
significantly shorter than the 1611-second periods found in previous
photometric studies. We conclude that the latter period likely represents a
`superhump'. If one assumes that our S-wave period is the orbital period, V803
Cen's mass ratio can be expected to be much less extreme than previously
thought, at q~0.07 rather than q~0.016. This relaxes the constraints on the
masses of the components considerably: the donor star does then not need to be
fully degenerate, and the mass of the accreting white dwarf no longer has to be
very close to the Chandrasekhar limit.
  For HP Lib, we similarly measure a spectroscopic period P=1102.8+/-0.2s. This
supports the identification of HP Lib's photometric periods found in the
literature, and the constraints upon the masses derived from them.
","We have analyzed new photometric data for two AM CVn-type systems, HP Librae (=PG 1336-018) and V803 Cen, obtained with the Kepler space telescope in order to determine their orbital periods more accurately than before.  We find that both systems are eclipsing binaries with very short orbital periods of only P orb = 81.6 min for HP Librae and P orb = 80.3 min for V803 Cen. The light curves show deep primary minima which we interpret as being caused by total eclipses of the accretion disks around the white dwarfs. In addition, there is evidence for an additional eclipse feature at phase 0.5-0.7 in the case of HP Librae. This could be due either to partial eclipses or occultations of one component by another. For comparison purposes, we also present results on the previously known system CR Boo.",arxiv,bigscience bloomz,705.0402,0.3888888888888889,0.24369747899159663,0.358974358974359,0.3521261347348304,1,1,1,0,1,1,1,0,0,0,0.10497297507417495,0.07445419877998317,0.1245136186770428,0.015151515151515152,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
What happened to the Cosmological QCD Phase Transition?,"  The scenario that some first-order phase transitions may have taken place in
the early Universe offers us one of the most intriguing and fascinating
questions in cosmology. Indeed, the role played by the latent ""heat"" or energy
released in the phase transition is highly nontrivial and may lead to some
surprising, important results. In this paper, we take the wisdom that the
cosmological QCD phase transition, which happened at a time between 10^(-5) sec
and 10^(-4) sec or at the temperature of about 150 MeV and accounts for
confinement of quarks and gluons to within hadrons, would be of first order. To
get the essence out of the scenario, it is sufficient to approximate the true
QCD vacuum as one of degenerate theta-vacua and when necessary we try to model
it effectively via a complex scalar field with spontaneous symmetry breaking.
We examine how and when ""pasted"" or ""patched"" domain walls are formed, how long
such walls evolve in the long run, and we believe that the significant portion
of dark matter could be accounted for in terms of such domain-wall structure
and its remnants. Of course, the cosmological QCD phase transition happened in
the way such that the false vacua associated with baryons and many other
color-singlet objects did not disappear (that is, using the bag-model language,
there are bags of radius 1.0 fermi for the baryons) - but the amount of the
energy remained in the false vacua is negligible. The latent energy released
due to the conversion of the false vacua to the true vacua, in the form of
""pasted"" or ""patched"" domain walls in the short run and their numerous evolved
objects, should make the concept of the ""radiation-dominated"" epoch, or of the
""matter-dominated"" epoch to be re-examined.
","The cosmological electroweak phase transition is now known to be first order, and it has been suggested that this may have important consequences for baryogenesis in the early universe.  In contrast, there are no compelling theoretical reasons why the analogous quantum chromodynamics (QCD) phase transition should also be first-order.   Here we argue that if the QCD phase transition were indeed second-order then it would lead to an unacceptably large number density of topological defects such as monopoles or cosmic strings at late times.  We show how these constraints can be satisfied by introducing new physics into the Standard Model which leads to a strongly first-order phase transition with a critical temperature T_c ~ 100 GeV. The cosmological electroweak phase tran-sition is now known to be of first order [1] , and it has been suggested [2] that this could have important consequences for baryogensis in the early universe. In contrast, there are few compelling theoretical reasons [3] why the analogous quantum chromo-dynamics (QCD) [4] phase transition should also be of first order. If the QCD phase transition was instead second-order [5] , then it would lead to unacceptable numbers [6] of topological defects [7, 8] such as monopoles [9] or cosmic strings [10] . These constraints can be satisfied [11] by introducing new physics [12] into the Standard Model [13] which leads to a strongly-first-order [14] phase transition [15] with a critical temperature Tc~100GeV [16] .",arxiv,bigscience bloomz,705.4149,0.3333333333333333,0.3445378151260504,0.8666666666666667,0.6301958910654564,1,1,0,0,0,1,1,0,0,0,0.12905241043257587,0.05069803540879112,0.10505836575875487,0.026515151515151516,0,0,5,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Constraints on the electroweak chiral Lagrangian from the precision data,"  In the framework of the effective field theory method, we use the
experimental data and the perturbative unitarity bounds to determine the values
and uncertainty of all the 11 chiral coefficients ($\al_i, i=0, ..., 10$) of
the standard electroweak chiral Lagrangian. Up to linear terms in $\al_i$, we
provide the one-loop renormalization group equations of all the chiral
coefficients, which are calculated in the Feynman-'t Hooft gauge using the
modified minimal subtraction scheme. With the improved renormalization group
equations to sum over the logarithmic corrections, we analyze the current
experimental uncertainty of oblique correction parameters, $S(\Lambda)$ and
$T(\Lambda)$. We find that, due to the large uncertainty in the triple
gauge-boson coupling measurements, the parameter space of positive $S(\Lambda)$
for $\Lambda > 1$ TeV is still allowed by the current experimental data.
$T(\Lambda)$ tends to increase with $\Lambda$ even in the presence of the
operators that contribute to the triple and quartic gauge-boson couplings.
","We present an update to our previous analysis [1] , where we used the most recent experimental results for the W and Z boson masses, M W = 80.385 ± 0.025 GeV [2] and M Z = 91.1876 ± 0.0021 GeV [3] . We also use the new value for the top quark mass m t = 172.7 ± 1.1 GeV [4] .
The main goal is to determine the parameters in the effective lagrangian describing the interactions between quarks and leptons at low energies. The relevant terms are given by 
where L SM denotes the Standard Model (SM) part of the lagrangian, O i are dimension-six operators with coefficients c i which can be determined experimentally or calculated using perturbation theory. In this work we will only consider operators that contribute to fermion-boson vertices. For more details see Ref. [5] . To extract information about these parameters one has to perform fits to various observables such as e + e − → ff cross sections [6] , forward-backward asymmetries [7, 8] , polarized deep-inelastic scattering [9] , etc..",arxiv,bigscience bloomz,705.2277,0.2222222222222222,0.3445378151260504,0.15384615384615385,0.46679407548972773,1,1,0,0,1,1,1,0,0,0,0.06410996743616182,0.14434180315782907,0.05058365758754864,0.14015151515151514,0,2,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Physisorption of Nucleobases on Graphene,"  We report the results of our first-principles investigation on the
interaction of the nucleobases adenine (A), cytosine (C), guanine (G), thymine
(T), and uracil (U) with graphene, carried out within the density functional
theory framework, with additional calculations utilizing Hartree--Fock plus
second-order Moeller-Plesset perturbation theory. The calculated binding energy
of the nucleobases shows the following hierarchy: G > T ~ C ~ A > U, with the
equilibrium configuration being very similar for all five of them. Our results
clearly demonstrate that the nucleobases exhibit significantly different
interaction strengths when physisorbed on graphene. The stabilizing factor in
the interaction between the base molecule and graphene sheet is dominated by
the molecular polarizability that allows a weakly attractive dispersion force
to be induced between them. The present study represents a significant step
towards a first-principles understanding of how the base sequence of DNA can
affect its interaction with carbon nanotubes, as observed experimentally.
","The physisorption of nucleobases (adenine, cytosine, guanine and thymine) onto graphene is investigated by density functional theory calculations at the B3LYP/6-31G(d) level in vacuum conditions. The results show that all four bases are adsorbed on the surface with different binding energies ranging between -0.27 eV for adenine to -1.10 eV for cytosine. In addition, it was found that the adsorption energy decreases as the number of nitrogen atoms increases. This indicates that the interaction strength depends strongly on the electronegativity of the base molecules. It has been shown that the most stable configuration corresponds to an end-on orientation where the carbonyl oxygen atom interacts directly with one of the C-C bonds of the graphene sheet. 
 
 Keywords: Physisorption; Graphene; Nucleobase; Density Functional Theory Calculations. Introduction 
 
 Graphene is a two-dimensional material consisting of sp2-hybridized carbon atoms arranged into a honeycomb lattice structure [1] . Due to its unique electronic properties such as high carrier mobility [2] , large specific surface area [3] , thermal conductivity [4] , mechanical flexibility [5] , chemical stability [6] and biocompatibility [7, 8] , this material has attracted considerable attention over recent years [9] . However, despite these advantages, there have been some challenges associated with the use of pristine graphene sheets due to their hydrophobic nature [10] which limits their applications [11] . Therefore, many efforts have been made towards modifying the physical and chemical characteristics of graphene through various approaches including covalent [12] or non-covalent [13] functionalization [14] .
 
In particular, non-covalent functionalization can be achieved via π-π interactions [15] , hydrogen bonding [16] , electrostatic [17] , van der Waals [18] and ionic [19] forces [20] . Among them, π-π stacking is considered to be the strongest noncovalent force [21] . For example, several studies have reported that aromatic compounds [22] , fullerenes [23] , porphyrins [24] , metal complexes [25] and biomolecules [26] could interact with graphene surfaces via π-",arxiv,bigscience bloomz,704.1316,0.2222222222222222,0.596638655462185,0.14871794871794872,0.8623984710941233,1,1,1,0,0,1,1,1,0,0,0.14914762738042103,0.11030385863306487,0.11284046692607004,0.13636363636363635,0,0,2,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Mixed-up trees: the structure of phylogenetic mixtures,"  In this paper we apply new geometric and combinatorial methods to the study
of phylogenetic mixtures. The focus of the geometric approach is to describe
the geometry of phylogenetic mixture distributions for the two state random
cluster model, which is a generalization of the two state symmetric (CFN)
model. In particular, we show that the set of mixture distributions forms a
convex polytope and we calculate its dimension; corollaries include a simple
criterion for when a mixture of branch lengths on the star tree can mimic the
site pattern frequency vector of a resolved quartet tree. Furthermore, by
computing volumes of polytopes we can clarify how ``common'' non-identifiable
mixtures are under the CFN model. We also present a new combinatorial result
which extends any identifiability result for a specific pair of trees of size
six to arbitrary pairs of trees. Next we present a positive result showing
identifiability of rates-across-sites models. Finally, we answer a question
raised in a previous paper concerning ``mixed branch repulsion'' on trees
larger than quartet trees under the CFN model.
","We study the problem of reconstructing evolutionary histories that contain both reticulation events and vertical transmission, where reticulations are represented by hybridization or horizontal gene transfer (HGT). We show how to use maximum parsimony to find an optimal solution for this problem in polynomial time when all input trees have bounded degree. This is achieved through a novel dynamic programming algorithm which computes the minimum number of reticulation events needed to explain each set of taxa on every tree in the input collection. Our approach can be used as part of a larger method for inferring species networks using collections of rooted binary phylogenies inferred from different types of data such as DNA sequences, morphological characters, fossil records etc., and it may also provide insights into the evolution of complex organisms like viruses and bacteria. 
Introduction

The reconstruction of evolutionary relationships among biological entities has been one of the central problems in biology since Darwin's On the Origin of Species was published 150 years ago [1] . The most widely accepted model of evolution assumes that new species evolve over time via vertical transmission -that is, they pass their genetic material down directly from parent to offspring [2] .
However, there are many cases where we cannot assume that evolution proceeds strictly vertically; instead, some form of horizontal gene transfer (HG T) occurs between two lineages [3] , resulting in what is known as reticulate evolution [4] . For example, if a virus infects a bacterium, then its genes will be passed horizontally across the host cell membrane [5] ; similarly, if a plant hybridizes with another plant [6] , then the offspring inherits genetic material from both parents [7, 8] . In these examples, the process of HGT results in a network-like relationship between the descendants of the original ancestor(s), rather than a strict hierarchy [9] .",arxiv,bigscience bloomz,705.4328,0.3333333333333333,0.19327731092436976,0.26666666666666666,0.3951266125179169,1,1,1,0,1,2,1,1,0,1,0.11391343751324753,0.11299721141166078,0.10894941634241245,0.07575757575757576,0,1,2,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,2,1,1
Transverse Polarization of Lambda and Lambda-bar Hyperons in Quasireal Photoproduction,"  The HERMES experiment has measured the transverse polarization of Lambda and
Lambda-bar hyperons produced inclusively in quasireal photoproduction at a
positron beam energy of 27.6 GeV. The transverse polarization of the Lambda
hyperon is found to be positive while the observed Lambda-bar polarization is
compatible with zero. The transverse polarization values averaged over the
kinematic acceptance of HERMES are 0.078 +/- 0.006(stat) +/- 0.012(syst) and
-0.025 +/- 0.015(stat) +/- 0.018(syst) for Lambda and Lambda-bar hyperons,
respectively. The dependences of Lambda and Lambda-bar polarizations on the
fraction $\zeta$ of the beam's light-cone momentum carried by the hyperon and
on the hyperon's transverse momentum $p_T$ were investigated. The measured
Lambda polarization rises linearly with $p_T$ and exhibits a different behavior
for low and high values of $\zeta$, which approximately correspond to the
backward and forward regions in the center-of-mass frame of the $\gamma^*N$
reaction.
","We report on the measurement of transverse polarization for lambda ($\Lambda$) hyperon production in quasireal photoproduction at Jefferson Lab, using data collected with the CLAS detector during Hall B running periods E94-110 and E97-107.  The results are presented as functions of the photon virtuality $Q^2$, the invariant mass $W$ of the final state system, and the angle $\theta_{K}$ between the normal to the scattering plane and the direction of the kaon produced in association with the hyperon.  We find that the magnitude of the transverse polarization decreases rapidly with increasing $Q^2$ but is relatively insensitive to changes in $W$ or $\theta_{K}$.  These observations are consistent with theoretical predictions based on perturbative QCD calculations performed within the framework of collinear factorization. DOI: 10.1063/1.3189000. PACS numbers: 13.60.Le, 12.38.Qk",arxiv,bigscience bloomz,704.3133,0.2222222222222222,0.24369747899159663,0.09743589743589744,0.31485905398948877,1,1,0,0,1,1,1,1,0,0,0.0906241882847542,0.15964251471851953,0.08171206225680934,0.06439393939393939,0,2,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Nanostructure and velocity of field-driven solid-on-solid interfaces moving under a phonon-assisted dynamic,"  The nanoscopic structure and the stationary propagation velocity of
(1+1)-dimensional solid-on-solid interfaces in an Ising lattice-gas model,
which are driven far from equilibrium by an applied force, such as a magnetic
field or a difference in (electro)chemical potential, are studied by an
analytic nonlinear-response approximation together with kinetic Monte Carlo
simulations. Here we consider the case that the system is coupled to a
two-dimensional phonon bath. In the resulting dynamic, transitions that
conserve the system energy are forbidden, and the effects of the applied force
and the interaction energies do not factorize (a so-called hard dynamic). In
full agreement with previous general theoretical results we find that the local
interface width changes dramatically with the applied force. However, in
contrast with other hard dynamics, this change is nonmonotonic in the driving
force. However, significant differences between theory and simulation are found
near two special values of the driving force, where certain transitions allowed
by the solid-on-solid model become forbidden by the phonon-assisted dynamic.
Our results represent a significant step toward providing a solid physical
foundation for kinetic Monte Carlo simulations.
","We study the dynamics of an interface driven by a periodic external force in one dimension, using molecular dynamics simulations with Lennard-Jones particles at low temperatures (T = 0.1 − 1). We find that the interface moves as a whole when it is driven slowly enough; otherwise, it breaks into several segments which move independently. The number of segments increases with increasing driving frequency or decreasing temperature. In addition to these two regimes, we observe another regime where the interface exhibits stick-slip motion. This third regime occurs for intermediate values of the driving amplitude A and driving frequency f . For this regime, we show that there exists a scaling relation between the average velocity V , the driving frequency f , and the driving amplitude A: V ∝ Af 2 . Finally, we propose a simple model based on the concept of phonon-enhanced diffusion to explain our results. DOI: 10.1103/PhysRevE.77.020101",arxiv,bigscience bloomz,705.0652,0.3333333333333333,0.3445378151260504,0.2923076923076923,0.38652651696129964,1,1,0,0,0,1,1,1,0,0,0.14319014858616208,0.08597340408591882,0.17509727626459143,0.04924242424242424,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Coupling between magnetic ordering and structural instabilities in perovskite biferroics: A first-principles study,"  We use first-principles density functional theory-based calculations to
investigate structural instabilities in the high symmetry cubic perovskite
structure of rare-earth (R $=$ La, Y, Lu) and Bi-based biferroic chromites,
focusing on $\Gamma$ and $R$ point phonons of states with para-, ferro-, and
antiferromagnetic ordering. We find that (a) the structure with G-type
antiferromagnetic ordering is most stable, (b) the most dominant structural
instabilities in these oxides are the ones associated with rotations of oxygen
octahedra, and (c) structural instabilities involving changes in Cr-O-Cr bond
angle depend sensitively on the changes in magnetic ordering. The dependence of
structural instabilities on magnetic ordering can be understood in terms of how
super-exchange interactions depend on the Cr-O-Cr bond angles and Cr-O bond
lengths. We demonstrate how adequate buckling of Cr-O-Cr chains can favour
ferromagnetism. Born effective charges (BEC) calculated using the Berry phase
expression are found to be anomalously large for the A-cations, indicating
their chemical relevance to ferroelectric distortions.
","We have investigated the coupling between magnetic ordering and structural instability in BiFeO3 by using density functional theory (DFT). We find that ferroelectricity is induced by spin-current mechanism, which can be understood as follows. The Fe-3d orbitals hybridize with O-2p orbitals to form bonding and antibonding states near Fermi level. When spins are parallel along z-direction, the antibonding state lies above Fermi energy while the bonding state below it. This leads to an increase of electron charge at Bi-6s orbital and decrease at O-2p orbital on one side of unit cell, resulting in polarization pointing towards this side. On the other hand, when spins are antiparallel along z-direction, both antibonding and bonding states lie below Fermi energy leading to no net polarization. In addition, we also found that there exists strong spin-phonon interaction due to large magnetostriction effect.",arxiv,bigscience bloomz,704.1251,0.2222222222222222,0.29411764705882354,0.17435897435897435,0.34925943621595795,1,1,0,0,0,1,1,0,0,0,0.17439370451112687,0.040009807639323616,0.11673151750972763,0.022727272727272728,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Effect of Electron Interaction on Statistics of Conductance Oscillations in Open Quantum Dots: Does the Dephasing Time Saturate?,"  We perform self-consistent quantum transport calculations in open quantum
dots taking into account the effect of electron interaction. We demonstrative
that in the regime of the ultralow temperatures $2\pi k_BT\lesssim\Delta$
($\Delta $ being the mean level spacing), the electron interaction strongly
affects the conductance oscillations and their statistics leading to a drastic
deviation from the corresponding predictions for noninteracting electrons. In
particular, it causes smearing of conductance oscillations, which is similar to
the effect of temperature or inelastic scattering. For $2\pi k_BT\gtrsim\Delta$
the influence of electron interaction on the conductance becomes strongly
diminished. Our calculations (that are free from phenomenological parameters of
the theory) are in good quantitative agreement with the observed ultralow
temperature statistics (Huibers \textit{et al.}, Phys. Rev. Lett. \textbf{81},
1917 (1998)). Our findings question a conventional interpretation of the
ultralow temperature saturation of the coherence time in open dots which is
based on the noninteracting theories where the electron interaction is
neglected and the agrement with the experiment is achieved by introducing
additional phenomenological channels of dephasing.
","We study statistics of conductance oscillations in open quantum dots with electron-phonon interaction and dephasing time saturation at high temperatures. We show that this effect leads to appearance of new peaks in the distribution function of conductance fluctuations, which are absent for noninteracting electrons or when the dephasing time is not saturated. The positions of these peaks depend on temperature and dot size. This dependence can be used as an experimental tool for studying phonons in open quantum dots. 
 
 Introduction 
 
 In recent years there has been growing interest in transport through mesoscopic systems such as semiconductor nanowires [1] , carbon nanotubes [2] , graphene [3] . These structures have unique properties due to their small dimensions (of order 10 nm) [4] . For example, they exhibit ballistic [5] and coherent [6] transport regimes [7, 8] .
 
In particular, it was shown experimentally [9] that the amplitude of conductance fluctuations in open quantum dots depends strongly on temperature T and dot size L. It decreases rapidly with increasing T and decreasing L [10] . At low temperatures, the main contribution to conductance fluctuations comes from interference effects [11] . However, at higher temperatures, thermal averaging destroys phase coherence between different paths [12] . As a result, the amplitude of conductance fluctuation decreases exponentially with temperature [13] :",arxiv,bigscience bloomz,706.0125,0.5,0.49579831932773116,0.24102564102564103,0.5728619206880077,1,1,0,0,0,1,1,1,0,0,0.1580392429053041,0.07366904607084858,0.14007782101167315,0.07575757575757576,3,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Nonstationary random acoustic and electromagnetic fields as wave diffusion processes,"  We investigate the effects of relatively rapid variations of the boundaries
of an overmoded cavity on the stochastic properties of its interior acoustic or
electromagnetic field. For quasi-static variations, this field can be
represented as an ideal incoherent and statistically homogeneous isotropic
random scalar or vector field, respectively. A physical model is constructed
showing that the field dynamics can be characterized as a generalized diffusion
process. The Langevin--It\^{o} and Fokker--Planck equations are derived and
their associated statistics and distributions for the complex analytic field,
its magnitude and energy density are computed. The energy diffusion parameter
is found to be proportional to the square of the ratio of the standard
deviation of the source field to the characteristic time constant of the
dynamic process, but is independent of the initial energy density, to first
order. The energy drift vanishes in the asymptotic limit. The time-energy
probability distribution is in general not separable, as a result of
nonstationarity. A general solution of the Fokker--Planck equation is obtained
in integral form, together with explicit closed-form solutions for several
asymptotic cases. The findings extend known results on statistics and
distributions of quasi-stationary ideal random fields (pure diffusions), which
are retrieved as special cases.
","We consider the statistical properties of nonstationary random acoustic and electromagnetical waves in terms of their correlation functions, power spectra, and probability density functions (PDFs). We show that these quantities can be expressed by means of solutions to certain partial differential equations with time-dependent coefficients. The PDFs are obtained for both stationary and nonstationary cases using the method of characteristics. In particular, we derive an exact expression for the PDF of the amplitude fluctuations of a monochromatic plane wave propagating through a turbulent medium. This result is used to obtain expressions for the mean-square fluctuation levels of the electric field strength and intensity at any point along the propagation path. Finally, we discuss some applications of our results to radiowave scintillation theory and radar detection problems. PACS: 42.65.Tg, 43.20 .Fx, 47.55.+q, 47.60.+j",arxiv,bigscience bloomz,706.0525,0.4444444444444444,0.29411764705882354,0.38974358974358975,0.3320592451027234,1,1,0,0,0,1,1,1,0,0,0.09636309437508658,0.05380796055340654,0.14396887159533073,0.022727272727272728,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Analysis of thermally stimulated luminescence and conductivity without quasiequilibrium approximation,"  Thermally stimulated luminescence (TSL) and conductivity (TSC) are considered
using the classical insulator model that assumes one kind of the active trap,
one kind of inactive deep trap, and one kind of the recombination center.
Kinetic equations describing the model are solved numerically without and with
the use of the quasiequilibrium (QE) approximation. The QE state parameter qI,,
the relative recombination probability g, and a new parameter called
quasi-stationary (QS) state parameter q*=qIg are used for the analysis of the
TSL and TSC. The TSL and TSC curves and the temperature dependences of qI, q*,
g, the recombination lifetime, and the occupancies of active traps and
recombination centers are numerically calculated for five sets of kinetic
parameters and different heating rates. These calculation results show that:
(1) the upper limit of the heating rate for presence of the QS state appears at
higher heating rate than that for the QE state when the retrapping process is
present, and (2) the TSL (TSC) curves in the QS state have the properties
similar to those for the TSL (TSC) curves in the QE state. Approximate formulas
for calculation of the parameters qI and q* in the initial range of the TSL and
TSC curves are derived and used in the heating-rate methods, proposed in this
work, for determination of those parameters from the calculated TSL curves.
","We present an analysis of the temperature dependence of thermally stimulated luminescent (TSL) glow curves in terms of the nonstationary electron-phonon relaxation theory, which does not assume that the system is close to equilibrium at any time during its evolution.  We show how this approach can be used for extracting information about the phonon spectrum and the density of states of charge carriers from TSL data obtained on different types of materials. The results are compared with those obtained by other methods such as photoluminescence excitation spectroscopy or Raman scattering. In particular we demonstrate that our method allows one to determine the energy gap between the conduction band minimum and valence band maximum in semiconductors. This work was supported by Russian Science Foundation grant No. 14-50-00040. DOI: 10.1063/1.4935190 
I. INTRODUCTORY REMARK
The study of luminescence phenomena has been attracting considerable attention over many years because it provides valuable information about electronic structure and optical properties of solids [1] . Thermal stimulation luminescence (TSL), also known as optically stimulated luminescence (OSL), is particularly useful since it enables us to probe the distribution function of electrons excited into the conduction band [2] .
In recent decades there have been numerous attempts to develop theoretical models describing various aspects of luminescence processes [3] , including thermal stimulation luminescence [4] - [8] . However, most of these works were based on the assumption that the system under consideration is always close to equilibrium [9] . As a result they cannot describe correctly some important features observed experimentally [10] . For example, the shape of the TSL glow curve depends strongly on the type of material [11] : while in insulators it usually exhibits a single peak [12] , in metals it often consists of several peaks [13] . Moreover, even within the same class of materials, e.g., semiconductor crystals [14] , the number of peaks may vary depending on the doping level [15] . These observations cannot be explained using existing theories [16] .",arxiv,bigscience bloomz,704.3497,0.2777777777777778,0.6974789915966387,0.517948717948718,0.8996655518394648,1,1,1,0,0,1,1,1,0,0,0.14494579616979367,0.11451278846900928,0.10894941634241245,0.0946969696969697,0,2,5,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Unconventional superconducting pairing by conventional phonons,"  The common wisdom that the phonon mechanism of electron pairing in the
weak-coupling Bardeen-Cooper-Schrieffer (BCS) superconductors leads to
conventional s-wave Cooper pairs is revised. An inevitable anisotropy of sound
velocity in crystals makes the phonon-mediated attraction of electrons
non-local in space providing unconventional Cooper pairs with a nonzero orbital
momentum in a wide range of electron densities. As a result of this anisotropy
quasi-two dimensional charge carriers undergo a quantum phase transition from
an unconventional d-wave superconducting state to a conventional s-wave
superconductor with more carriers per unit cell. In the opposite
strong-coupling regime rotational symmetry breaking appears as a result of a
reduced Coulomb repulsion between unconventional bipolarons dismissing thereby
some constraints on unconventional pairing in the Bose-Einstein condensation
(BEC) limit. The conventional phonons, and not superexchange, are shown to be
responsible for the d-wave symmetry of cuprate superconductors, where the
on-site Coulomb repulsion is large.
","We show that the electron-phonon interaction can lead to unconventional Cooper pairs in materials with strong spin-orbit coupling and broken inversion symmetry, even if only conventional phonon modes are present.  We consider two different models for such materials: (i) Rashba semiconductors where the conduction band is split into spin-up and -down subbands due to an electric field perpendicular to the plane of the crystal; and (ii) topological insulators which have a single Dirac cone at their surface but exhibit time-reversal-symmetry breaking on the surface or in proximity to magnetic impurities. In both cases we find that the effective low-energy theory contains a term proportional to $(\vec{\psi}^\dagger \vec{\psi})^2$, where $\psi$ denotes the fermionic annihilation operator corresponding to electrons near the Fermi level. This leads to unconventional s-wave pairing between electrons belonging to opposite spins and momenta.",arxiv,bigscience bloomz,705.2697,0.2222222222222222,0.14285714285714285,0.12307692307692308,0.34065934065934067,1,1,0,0,0,1,1,1,0,0,0.03190974063417524,0.166822835391535,0.027237354085603113,0.11742424242424243,0,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Gravitational Stability of Circumnuclear Disks in Elliptical Galaxies,"  A significant fraction of nearby elliptical galaxies are known to have high
density gas disks in their circumnuclear (CN) region (0.1 to a few kpc). Yet,
ellipticals, especially luminous ones, show little signs of recent star
formation (SF). To investigate the possible cause of the dearth of SF in these
systems, we study the gravitational stability of CN gas disks embedded within
the potentials of both the stellar bulge and the central massive black hole
(BH) in ellipticals. We find that CN disks in higher mass galaxies are
generally more stable than those in lower mass galaxies, because higher mass
galaxies tend to have more massive BHs and more centrally concentrated stellar
density profiles. We also consider the case in which the central stellar
density profile has a core, which is often observed for ellipticals whose total
stellar mass is higher than about 10^11 Msun. Such a cored stellar density
profile leads to more unstable CN disks than the power-law density profile
characteristic of less massive galaxies. However, the more massive BHs in
high-mass galaxies act to stabilize the CN disk. Our results demonstrate that
the gravitational potentials of both the central BH and the stellar component
should be taken into account when studying the properties of CN disks, as their
stability is sensitive to both the BH mass and the stellar density profile. Our
results could explain the observed trend that less luminous ellipticals have a
greater tendency to exhibit ongoing SF than giant ellipticals.
","We study the stability properties of circumnuclear disks (CNDs) embedded within elliptical galaxies, using N-body simulations with live dark matter halos and stellar components. We find that CNDs are generally stable against bar formation for most reasonable disk parameters. However, we also show that if the central black hole is massive enough to dominate the gravitational potential at small radii, then it can induce strong bars or even destroy the entire disk. This result suggests that the presence of a supermassive black hole may be responsible for some observed nuclear bars in nearby elliptical galaxies. 
 
 Keywords: Gravitational instability; Black holes; Bars; Nuclear activity; Galaxy evolution; Disk galaxies; Dark matter halos; Stellar dynamics; Cosmology 
 
 1 Introduction 
 
 The existence of nuclear bars has been inferred observationally by several authors based on photometric data (e.g., Laine et al. 2002; Erwin 2004) . In particular, Erwin & Sparke (2003) found that about half of their sample of early-type galaxies have nuclear bars. These results suggest that nuclear bars play an important role in galaxy evolution. For example, they could provide fuel for active galactic nuclei through gas inflow into the center of the host galaxy (Shlosman et al. 1990 ). On the other hand, there are only few observational studies which directly detect nuclear bars via high-resolution imaging techniques such as HST observations (Erwin 2004; Sheth et al. 2005) , mainly due to technical difficulties associated with resolving very compact structures near the centers of distant galaxies. Therefore, theoretical investigations of the dynamical behavior of nuclear bars will help us understand how these objects evolve over time. 
 
 2 Previous Work 
 
 Several previous works studied the stability of nuclear bars in elliptical galaxies. Athanassoula et al. (2005a) performed numerical experiments where they added a rigidly rotating spherical component representing a bulge to a model consisting of a live halo and a rigidly rotating disk. They showed that this system becomes unstable when the mass ratio between the bulge and the disk exceeds a critical value",arxiv,bigscience bloomz,706.0005,0.4444444444444444,0.7983193277310925,0.6307692307692307,0.8996655518394648,1,1,0,0,0,1,1,1,0,0,0.09686171171943998,0.10211572517347835,0.11284046692607004,0.1590909090909091,0,3,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The LuckyCam Survey for Very Low Mass Binaries II: 13 new M4.5-M6.0 Binaries,"  We present results from a high-angular-resolution survey of 78 very low mass
(VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15
arcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new
binary systems range in separation between 0.18 arcsec and 1.3 arcsec. The
distance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with
previous results. 9 of the new binary systems have orbital radii > 10 AU,
including a new wide VLM binary with 27 AU projected orbital separation. One of
the new systems forms two components of a 2300 AU separation triple system. We
find that the orbital radius distribution of the binaries with V-K < 6.5 in
this survey appears to be different from that of redder (lower-mass) objects,
suggesting a possible rapid change in the orbital radius distribution at around
the M5 spectral type. The target sample was also selected to investigate X-ray
activity among VLM binaries. There is no detectable correlation between excess
X-Ray emission and the frequency and binary properties of the VLM systems.
","We present the results of our second survey to find very low mass binaries using lucky imaging with the Palomar Observatory 1.2 m telescope and the PALM-3000 camera. We have discovered thirteen new systems, including ten brown dwarf companions (four previously unknown) in twelve nearby young open clusters ranging in age between 10 Myr and 300 Myr. The masses range from 0.03-0.10 M . These are among the lowest-mass objects ever found by direct imaging techniques. In addition we report on one system that is likely an unresolved binary consisting of two late-type stars. This work represents the largest sample of directly imaged brown dwarfs assembled so far. It will be used as input into population synthesis models aimed at understanding how these objects form and evolve over time. 
 
 Keywords: Brown Dwarf, Open Cluster, Direct Imaging, Lucky Imaging, Nearby Stars",arxiv,bigscience bloomz,704.1812,0.4444444444444444,0.3445378151260504,0.27692307692307694,0.35499283325370284,1,1,0,0,0,1,1,1,0,0,0.10431885838650586,0.06693920165610957,0.12840466926070038,0.08333333333333333,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Galaxy Colours in the AKARI Deep SEP Survey,"  We investigate the segregation of the extragalactic population via colour
criteria to produce an efficient and inexpensive methodology to select specific
source populations as a function of far-infrared flux. Combining galaxy
evolution scenarios and a detailed spectral library of galaxies, we produce
simulated catalogues incorporating segregation of the extragalactic population
into component types (Normal, star-forming, AGN) via color cuts. As a practical
application we apply our criteria to the deepest survey to be undertaken in the
far-infrared with the AKARI (formerly ASTRO-F) satellite. Using the
far-infrared wavebands of the Far-Infrared Surveyor (FIS, one of the
focal-plane instruments on AKARI) we successfully segregate the normal,
starburst and ULIRG populations. We also show that with additional MIR imaging
from AKARI's Infrared Camera (IRC), significant contamination and/or degeneracy
can be further decreased and show a particular example of the separation of
cool normal galaxies and cold ULIRG sources. We conclude that our criteria
provide an efficient means of selecting source populations (including rare
luminous objects) and produce colour-segregated source counts without the
requirement of time intensive ground-based follow up to differentiate between
the general galaxy population.
","We present galaxy colours derived from the AKARI/IRC deep survey data taken at 9 and 18 micron bands (hereafter, D9 & D18). The sample consists of galaxies with spectroscopic redshifts z < 0.7 selected by their optical counterparts detected in the Subaru/Suprime-Cam B J -band image. We compare our results to those obtained for Spitzer/MIPS 24 µm-selected galaxies at similar redshift ranges. Our main findings are as follows:
(1) Galaxies show bimodal colour distributions both in D9/D18 and D9/D24 planes.
(2) In the D9/D18 plane, we find that most of the galaxies have blue or greenish colours while only few galaxies exhibit reddish colours. 
(3) In the D9-D18 vs. D9-D24 plane, there is no clear correlation between two colours except for very bright objects which tend to be bluer than fainter ones. (4) There exists a strong anti-correlation between D9/D18 and stellar mass M * .",arxiv,bigscience bloomz,705.186,0.2777777777777778,0.29411764705882354,0.3076923076923077,0.37219302436693746,1,1,0,0,1,1,1,1,0,0,0.0552767623722763,0.04354226830570629,0.04669260700389105,0.045454545454545456,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Testing outer boundary treatments for the Einstein equations,"  Various methods of treating outer boundaries in numerical relativity are
compared using a simple test problem: a Schwarzschild black hole with an
outgoing gravitational wave perturbation. Numerical solutions computed using
different boundary treatments are compared to a `reference' numerical solution
obtained by placing the outer boundary at a very large radius. For each
boundary treatment, the full solutions including constraint violations and
extracted gravitational waves are compared to those of the reference solution,
thereby assessing the reflections caused by the artificial boundary. These
tests use a first-order generalized harmonic formulation of the Einstein
equations. Constraint-preserving boundary conditions for this system are
reviewed, and an improved boundary condition on the gauge degrees of freedom is
presented. Alternate boundary conditions evaluated here include freezing the
incoming characteristic fields, Sommerfeld boundary conditions, and the
constraint-preserving boundary conditions of Kreiss and Winicour. Rather
different approaches to boundary treatments, such as sponge layers and spatial
compactification, are also tested. Overall the best treatment found here
combines boundary conditions that preserve the constraints, freeze the
Newman-Penrose scalar Psi_0, and control gauge reflections.
","We present results on testing different outer boundary conditions in numerical relativity, using two black hole spacetimes as testbeds.  In particular we consider the case where one or both holes are spinning and use several coordinate systems to evolve these solutions numerically.   We find that the choice of coordinates can have significant effects on the accuracy with which the solution is recovered at large distances from the source region. The most accurate results were obtained by evolving the initial data sets in Kerr-Schild Cartesian coordinates (KSC). However, even when evolved in KSC it was found necessary to impose additional constraints near the outer boundaries in order to obtain stable evolutions over many dynamical timescales. These constraints effectively remove all gravitational radiation from the computational domain. Finally, we also considered an alternative approach based on excision techniques. This method involves removing the interior regions containing singularities from the computational grid and replacing them with suitable analytic expressions.",arxiv,bigscience bloomz,704.0782,0.3888888888888889,0.3445378151260504,0.2717948717948718,0.40086000955566176,0,1,1,0,1,1,1,0,0,0,0.05722654911576902,0.048935730027866414,0.08171206225680934,0.05303030303030303,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Room temperature coexistence of large electric polarization and magnetic order in BiFeO3 single crystals,"  From an experimental point of view, room temperature ferroelectricity in
BiFeO3 is raising many questions. Electric measurements made a long time ago on
solid-solutions of BiFeO3 with Pb(Ti,Zr)O3 indicate that a spontaneous electric
polarization exists in BiFeO3 below the Curie temperature TC=1143K. Yet in most
reported works, the synthesised samples are too conductive at room temperature
to get a clear polarization loop in the bulk without any effects of extrinsic
physical or chemical parameters. Surprisingly, up to now there has been no
report of a P(E) (polarization versus electric field) loop at room temperature
on single crystals of BiFeO3. We describe here our procedure to synthesize
ceramics and to grow good quality sizeable single crystals by a flux method. We
demonstrate that BiFeO3 is indeed ferroelectric at room-temperature through
evidence by Piezoresponse Force Microscopy and P(E) loops. The polarization is
found to be large, around 60 microC/cm2, a value that has only been reached in
thin films. Magnetic measurements using a SQUID magnetometer and Mossbauer
spectroscopy are also presented. The latter confirms the results of NMR
measurements concerning the anisotropy of the hyperfine field attributed to the
magnetic cycloidal structure.
","BiFeO3 is an antiferromagnetic insulator with high Curie temperature (TC = 1103 K) that exhibits ferroelectricity at room temperature when doped or under pressure. Here we report the observation of spontaneous magnetization, M(T), and electrical polarization, P(E), simultaneously existing over wide ranges of temperatures up to 300 K in pure BiFeO3 single crystal grown by flux method. The results show that both M(T) and P(E) are nearly independent on each other below TC but they start to decrease rapidly above TC. We also found that the magnitude of M(T) decreases faster than that of P(E). These observations suggest that there exists strong coupling between spin and lattice degrees of freedom in this material. 
 
 Keywords: Room-temperature multiferroic materials, BiFeO3, Electric polarization, Magnetic properties, Flux growth technique.",arxiv,bigscience bloomz,706.0404,0.4444444444444444,0.24369747899159663,0.3435897435897436,0.3119923554706163,1,1,0,0,0,1,1,1,0,0,0.0682735267361758,0.07600208525503131,0.06614785992217899,0.04924242424242424,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Calibration of the GLAST Burst Monitor detectors,"  The GLAST Burst Monitor (GBM) will augment the capabilities of GLAST for the
detection of cosmic gamma-ray bursts by extending the energy range (20 MeV to >
300 GeV) of the Large Area Telescope (LAT) towards lower energies by 2
BGO-detectors (150 keV to 30 MeV) and 12 NaI(Tl) detectors (10 keV to 1 MeV).
The physical detector response of the GBM instrument for GRBs is determined
with the help of Monte Carlo simulations, which are supported and verified by
on-ground calibration measurements, performed extensively with the individual
detectors at the MPE in 2005. All flight and spare detectors were irradiated
with calibrated radioactive sources in the laboratory (from 14 keV to 4.43
MeV). The energy/channel-relations, the dependences of energy resolution and
effective areas on the energy and the angular responses were measured. Due to
the low number of emission lines of radioactive sources below 100 keV,
calibration measurements in the energy range from 10 keV to 60 keV were
performed with the X-ray radiometry working group of the
Physikalisch-Technische Bundesanstalt (PTB) at the BESSY synchrotron radiation
facility, Berlin.
","The Large Area Telescope (LAT) on board Fermi Gamma-ray Space Telescope is scheduled to be launched in June 2008 and will perform high energy gamma ray astronomy for at least 3 years. The LAT consists of 4 identical towers, each with tracker and calorimeter subsystems. Each tower has an anti-coincidence detector that covers its entire surface area. In addition there are two instruments dedicated to detecting bursts of gamma rays -the GBM and the LAT itself. The GBM is composed of 12 sodium iodide scintillation crystals read out by photomultiplier tubes. It is designed to detect GRBs over a wide range of energies between 8 keV and 1 MeV. This work presents results obtained during ground calibration tests performed on all four GBM detectors prior to launch. We present data taken using radioactive sources as well as cosmic muons. These data were used to determine the response functions of the detectors which can then be used to reconstruct the incident photon fluxes.",arxiv,bigscience bloomz,704.2184,0.2222222222222222,0.3949579831932773,0.28717948717948716,0.4180602006688964,1,1,0,0,0,1,1,0,0,0,0.17289563290856347,0.05352701513574714,0.11673151750972763,0.06060606060606061,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Difermion condensates in vacuum in 2-4D four-fermion interaction models,"  Theoretical analysis of interplay between the condensates $<\bar{q}q>$ and
$<qq>$ in vacuum is generally made by relativistic effective potentials in the
mean field approximation in 2D, 3D and 4D models with two flavor and $N_c$
color massless fermions. It is found that in ground states of these models,
interplay between the two condensates mainly depend on the ratio $G_S/H_S$ for
2D and 4D case or $G_S/H_P$ for 3D case, where $G_S$, $H_S$ and $H_P$ are
respectively the coupling constants in a scalar $(\bar{q}q)$, a scalar $(qq)$
and a pseudoscalar $(qq)$ channel. In ground states of all the models, only
pure $<\bar{q}q>$ condensates could exist if $G_S/H_S$ or $G_S/H_P$ is bigger
than the critical value $2/N_c$, the ratio of the color numbers of the fermions
entering into the condensates $<qq>$ and $<\bar{q}q>$. As $G_S/H_S$ or
$G_S/H_P$ decreases to the region below $2/N_c$, differences of the models will
manifest themselves. Depending on different models, and also on $N_c$ in 3D
model, one will have or have no the coexistence phase of the two condensates,
besides the pure $<qq>$ condensate phase. The $G_S-H_S$ (or $G_S-H_P$) phase
diagrams in these models are given. The results also implicate a real
constraint on two-flavor QCD-analogous NJL model.
","We study the ground state properties of fermions interacting via attractive four-fermion interactions in two, three and four dimensions (2D, 3D and 4D). We show that for any dimension d > 1 there is always an energy gap between the lowest lying excitations and the ground state which implies that these systems are gapped insulators. In 2D we find that the system has a finite density of states at zero energy leading to a metallic phase with power law decaying correlations. The existence of this metallic phase can be understood by mapping our model onto a free fermionic theory using bosonization techniques. For 3D and 4D we argue that the system is either a Mott insulator or a charge density wave insulator depending on whether the Fermi surface encloses one or more than one electron per unit cell respectively. Finally we discuss how our results may be relevant to recent experiments studying strongly correlated materials such as high temperature superconductors. 
 
 Introduction 
 
 Strongly correlated electronic systems have been studied extensively over many years both theoretically and experimentally [1] . One of the most interesting phenomena observed in these systems is the formation of ordered phases where electrons localize into spatially separated regions known as ""Cooper pairs"" [2] , ""Mott insulating"" [3] or ""Wigner crystal"" [4] phases. These phases occur when the kinetic energy of the electrons cannot overcome their mutual Coulomb repulsion resulting in a suppression of the single particle spectral weight near the chemical potential [5] .
 
In order to understand the physics behind these exotic phases it is important to develop theoretical tools capable of describing them accurately [6] . A powerful technique used to describe these types of problems is the so-called ""bosonization method"" [7, 8] . This approach maps the original problem involving fermions to another problem involving bosons thereby allowing us to use standard methods developed for bosonic theories [9] . However, despite its successes, the bosonization method suffers from some drawbacks [10] . Firstly, it only works well if the number of fermions N is large compared to the correlation length ξ [11] . Secondly, even though the bosonized description",arxiv,bigscience bloomz,704.0841,0.3333333333333333,0.6974789915966387,0.4,0.9713330148112757,1,1,0,0,0,1,1,0,0,0,0.23987500391016592,0.08120352089925967,0.17120622568093385,0.09848484848484848,0,1,4,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Hitting probabilities for systems of non-linear stochastic heat equations with multiplicative noise,"  We consider a system of d non-linear stochastic heat equations in spatial
dimension 1 driven by d-dimensional space-time white noise. The non-linearities
appear both as additive drift terms and as multipliers of the noise. Using
techniques of Malliavin calculus, we establish upper and lower bounds on the
one-point density of the solution u(t,x), and upper bounds of Gaussian-type on
the two-point density of (u(s,y),u(t,x)). In particular, this estimate
quantifies how this density degenerates as (s,y) converges to (t,x). From these
results, we deduce upper and lower bounds on hitting probabilities of the
process {u(t,x)}_{t \in \mathbb{R}_+, x \in [0,1]}, in terms of respectively
Hausdorff measure and Newtonian capacity. These estimates make it possible to
show that points are polar when d >6 and are not polar when d<6. We also show
that the Hausdorff dimension of the range of the process is 6 when d>6, and
give analogous results for the processes t \mapsto u(t,x) and x \mapsto u(t,x).
Finally, we obtain the values of the Hausdorff dimensions of the level sets of
these processes.
","We consider the following system of nonlinear stochastic partial differential equations (SPDE) in $\mathbb{R}^d$, where $d\in\mathbb{N}$ is fixed and $(\Omega,\mathcal{F},P)$ denotes some probability space: 
\begin{align}
u_t - \Delta u + f(u) = \xi_1(t), & t \geq 0, x \in \Omega_0\\
v_t - \Delta v + g(u) = \eta_2(t), & t\geq0,x\in\Omega_1,
\end{align}
where $u$ and $v$ are unknown functions on $\Omega_0$ resp. $\Omega_1$, which we assume to be open subsets of $\mathbb{R}^d$; $f:\mathbb{R}\rightarrow\mathbb{R}$ and $g:\mathbb{R}\rightarrow\mathbb{R}_{\geq0}$ are given smooth functions satisfying certain growth conditions at infinity, while $\xi_1$ and $\eta_2$ denote two independent Brownian motions on $(\Omega,\mathcal F, P)$. 
 
 We prove that there exists an explicit formula for the hitting probabilities $P_x(T_1<\tau_{x_0})$ and $P_x(T_2<\tau_{x_0}$) associated with this SPDE-system, where $x\in\Omega_0$, $T_{1,2}>0$ and $\tau_{x_{0}}=\inf\{t>0:u(t,x)=v(t,x)\}$. In particular, we show that these hitting probabilities can be expressed as solutions of suitable backward Kolmogorov PDEs.",arxiv,bigscience bloomz,704.1312,0.3888888888888889,0.14285714285714285,0.26666666666666666,0.3521261347348304,1,1,0,0,0,1,1,1,0,0,0.13882306605176217,0.3131077840692902,0.14396887159533073,0.22727272727272727,0,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Near-IR Spectra of Red Supergiants and Giants. I- Models with Solar and with Mixing-Induced Surface Abundance Ratios,"  We provide a grid of PHOENIX spectra of red giant and supergiant stars, that
extend through optical and near-IR wavelengths. For the first time, models are
also provided with modified surface abundances of C, N and O, as a step towards
accounting for the changes known to occur due to convective dredge-up (and to
be enhanced in the case of rotation). The aims are (i) to assess how well
current models reproduce observed spectra, (ii) to quantify the effects of the
abundance changes on the spectra, and (iii) to determine how these changes
affect estimates of fundamental stellar parameters.
  Observed giant star spectra can be fitted very well at solar metallicity down
to about 3400K. Modified surface abundances are preferred in only a minority of
cases for luminosity class II, possibly indicating mixing in excess of standard
first dredge-up.
  Supergiant stars show a larger variety of near-IR spectra, and good fits are
currently obtained for about one third of the observations only. Modified
surface abundances help reproducing strong CN bands, but do not suffice to
resolve all the difficulties. The effect of the abundance changes on the
estimated Teff depends on the wavelength range of observation and can amount
several 100K. Reasons for the remaining discrepancies are discussed.
","We present new near-infrared (NIR) spectra for red supergiants and giants, obtained at the European Southern Observatory in La Silla, Chile.  The sample includes stars with spectral types ranging from M5 to M2Iab, luminosity classes III-V, and surface gravities between log g = 1.0 and 3.8 dex. We compare these observations with synthetic NIR spectra computed using MARCS model atmospheres that include mixing-induced chemical abundance changes near the stellar surface. Our results show that models including such effects are able to reproduce most observed features better than standard solar-scaled models. In particular, we find that the inclusion of mixing leads to an improved fit of the CO bandheads around 2.3 microns as well as of several atomic lines. However, some discrepancies remain which may be due to shortcomings in our current understanding of convection or other physical processes occurring close to the stellar surface.",arxiv,bigscience bloomz,704.212,0.4444444444444444,0.24369747899159663,0.4358974358974359,0.36645962732919257,1,1,0,0,0,1,1,0,0,0,0.11857286025967981,0.023213656773574523,0.11673151750972763,0.01893939393939394,1,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Simulation study of the two-dimensional Burridge-Knopoff model of earthquakes,"  Spatiotemporal correlations of the two-dimensional spring-block
(Burridge-Knopoff) model of earthquakes are extensively studied by means of
numerical computer simulations. The model is found to exhibit either
``subcritical'' or ``supercritical'' behavior, depending on the values of the
model parameters. Transition between these regimes is either continuous or
discontinuous. Seismic events in the ``subcritical'' regime and those in the
``supercritical'' regime at larger magnitudes exhibit universal scaling
properties. In the ``supercritical'' regime, eminent spatiotemporal
correlations, {\it e.g.}, remarkable growth of seismic activity preceding the
mainshock, arise in earthquake occurrence, whereas such spatiotemporal
correlations are significantly suppressed in the ``subcritical'' regime.
Seismic activity is generically suppressed just before the mainshock in a close
vicinity of the epicenter of the upcoming event while it remains to be active
in the surroundings (the Mogi doughnut). It is also observed that, before and
after the mainshock, the apparent $B$-value of the magnitude distribution
decreases or increases in the ``supercritical'' or ``subcritical'' regimes,
respectively. Such distinct precursory phenomena may open a way to the
prediction of the upcoming large event.
","We present results on the statistical properties of earthquake sequences generated by the 2D Burridge-Knopff (BK) model with random initial conditions and periodic boundary conditions, using numerical simulations. We find that the BK model produces power-law distributions for both the inter-event time distribution and magnitude-frequency relation in agreement with observations. The exponent values are found to be dependent upon the system size N . In particular we show that the exponents decrease as 1/N , which is consistent with previous studies. Finally, we discuss possible reasons behind this dependence. Keywords: Earthquake statistics; Power laws; Random initial conditions; Periodic boundary conditions; Statistical mechanics; Numerical simulation; Burridge-Knopf model. 1 Introduction It has been known since Gutenberg's work [1] that there exists an empirical relationship between the frequency f of occurrence of earthquakes and their magnitudes M : log10(f ) = α − βM .
(
The constants α and β depend on the region under consideration [2] . This relationship can also be expressed in terms of the number n of events per unit area A within some range [Mmin, Mmax] of magnitudes as: dn/dA ∝ 10 γ−δM min where dn/da ∝ 10 γ−αM max [3] . For example, if one considers all earthquakes occurring over a period of time T in a given geographical area then it follows that: 
where Ntot denotes the total number of earthquakes during the observation period T . If one instead counts only those earthquakes whose magnitude lies in the interval [Mmin, Mmax]:",arxiv,bigscience bloomz,706.1871,0.4444444444444444,0.49579831932773116,0.2564102564102564,0.661729574773053,1,1,0,0,1,1,1,1,0,1,0.08402814830659092,0.0969125070406484,0.08171206225680934,0.0946969696969697,1,1,2,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
A Systematic Study of Departures from Chemical Equilibrium in the Atmospheres of Substellar Mass Objects,"  We present a systematic study of the spectral consequences of departures from
chemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler
dwarfs. The temperature/pressure profiles of the non-equilibrium models are
fully consistent with the non-equilibrium chemistry. Our grid of
non-equilibrium models includes spectra for effective temperatures from 200 K
to 1800 K, three surface gravities, four possible values of the coefficient of
eddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical
reaction prescriptions. We find that the non-equilibrium overabundance of CO
translates into flux suppressions in the M ($\sim4-$5 $\mu$m) band of at most
$\sim$40% between effective temperatures of 600 and 1800 K. The effect is
largest around $T_{\rm eff} \approx 1100$ K. The underabundance of ammonia due
to non-equilibrium chemistry translates into flux enhancements of no more than
$\sim$20% for the $T_{\rm eff}$ range from 300 to 1800 K, with the largest
effects at the lowest values of $T_{\rm eff}$. The magnitude of the departure
from chemical equilibrium increases with decreasing gravity, with increasing
eddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$
reaction. Though these effects are modest, they lead to better fits with the
measured T dwarf spectra. Furthermore, the suppression in the M band due to
non-equilibrium enhancements in the CO abundance disappears below $\sim$500 K,
and is only partial above $\sim$500 K, preserving the M band flux as a useful
diagnostic of cool atmospheres and maintaining its importance for searches for
brown dwarfs cooler than T dwarfs.
","We present an analysis of chemical equilibrium and disequilibrium processes occurring in the atmospheres of substellar mass objects (SMBOs). We have developed a new method for calculating departures from chemical equilibrium, which is based on the assumption that all species are in local thermodynamic equilibrium with each other at any given point within the atmosphere. This approach allows us to calculate the abundances of individual molecular species as functions of altitude above the photosphere. The results show that there can be significant deviations from chemical equilibrium even under conditions where the gas temperature is much higher than the dust temperature. In particular, we find that carbon monoxide may become depleted by several orders of magnitude relative to its abundance predicted by chemical equilibrium models. These findings suggest that SMBO observations should take into account possible non-equilibrium effects when interpreting their spectra. 
 
 Keywords: Chemical equilibrium; Dust grains; Local thermodynamic equilibrium",arxiv,bigscience bloomz,705.3922,0.3333333333333333,0.29411764705882354,0.6512820512820513,0.38079311992355475,1,1,0,0,0,1,1,1,0,0,0.29801468984546675,0.06556883970859034,0.311284046692607,0.05303030303030303,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1
Out-of-equilibrium relaxation of the Edwards-Wilkinson elastic line,"  We study the non-equilibrium relaxation of an elastic line described by the
Edwards-Wilkinson equation. Although this model is the simplest representation
of interface dynamics, we highlight that many (not though all) important
aspects of the non-equilibrium relaxation of elastic manifolds are already
present in such quadratic and clean systems. We analyze in detail the aging
behaviour of several two-times averaged and fluctuating observables taking into
account finite-size effects and the crossover to the stationary and equilibrium
regimes. We start by investigating the structure factor and extracting from its
decay a growing correlation length. We present the full two-times and size
dependence of the interface roughness and we generalize the Family-Vicsek
scaling form to non-equilibrium situations. We compute the incoherent cattering
function and we compare it to the one measured in other glassy systems. We
analyse the response functions, the violation of the fluctuation-dissipation
theorem in the aging regime, and its crossover to the equilibrium relation in
the stationary regime. Finally, we study the out-of-equilibrium fluctuations of
the previously studied two-times functions and we characterize the scaling
properties of their probability distribution functions. Our results allow us to
obtain new insights into other glassy problems such as the aging behavior in
colloidal glasses and vortex glasses.
","We study numerically and analytically the dynamics of an elastic interface in two dimensions driven by thermal fluctuations, starting far away from equilibrium. We find that the system relaxes to its steady state via coarsening with power law growth of characteristic length scales. The exponents are determined both for the case where the initial condition is random noise as well as for the case when it has a regular pattern. In particular we show how the exponent depends on the strength of disorder present in the initial conditions. This work was supported by NSF grant DMR-0704520 (M.S.) and by DFG grant SFB-TR6 (A.K.). 
I. INTRODUCTORY REMARkS

The motion of interfaces between different phases or states plays an important role in many physical systems ranging from crystal growth [1] , fluid flow [2] , magnetic domain wall motion [3] , fracture [4] , wetting [5] , etc.. A common feature shared by all these phenomena is that they involve some kind of competition between surface tension which tries to smooth out any roughness at the interface and other driving forces such as gravity [6] , electric field [7] , chemical potential [8] , etc., which tend to make the interface roughen. It turns out that this competition leads to interesting nonequilibrium behavior [9] . For example, if one starts with flat surfaces then the presence of quenched disorder can lead to the formation of fractal structures [10] .
In recent years there have been several studies [11] - [16] devoted to understanding the statistical properties of growing interfaces near their critical dimension d c = 2 [17] . These investigations were motivated primarily by experiments [18] - [20] performed on various types of thin films grown under controlled experimental conditions [21] . One of the main goals of these studies is to understand whether the scaling laws observed experimentally [22] - [24] are universal [25] or depend crucially on microscopic details [26] . Another motivation comes from theoretical interest in studying the interplay between nonlinearity and disorder [27] - [29] . Finally, another reason for investigating the problem theoretically is due to possible applications [30] - [32] in data storage devices [33] and optical",arxiv,bigscience bloomz,705.3348,0.4444444444444444,0.3445378151260504,0.4205128205128205,0.4739608217869088,1,1,0,0,0,1,2,0,0,0,0.06664125420715475,0.1661639601822143,0.0933852140077821,0.4128787878787879,0,3,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,2,0,1,1,1
Spatially resolved kinematics and stellar populations of brightest cluster and group galaxies,"  We present an examination of the kinematics and stellar populations of a
sample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies
(BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise
Gemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these
galaxies and use Lick indices to determine ages, metallicities and
alpha-element abundance ratios out to at least their effective radii. We find
that the BGGs and BCGs have very uniform masses, central ages and central
metallicities. Examining the radial dependence of their stellar populations, we
find no significant velocity dispersion, age, or alpha-enhancement gradients.
However, we find a wide range of metallicity gradients, suggesting a variety of
formation mechanisms. The range of metallicity gradients observed is surprising
given the homogeneous environment these galaxies probe and their uniform
central stellar populations. However, our results are inconsistent with any
single model of galaxy formation and emphasize the need for more theoretical
understanding of both the origins of metallicity gradients and galaxy formation
itself. We postulate two possible physical causes for the different formation
mechanisms.
","We present spatially-resolved spectroscopic observations for the central regions (r < 1 kpc) of six nearby, massive early-type galaxies in clusters or groups with Mvir > 1013M⊙. The data were obtained using the Gemini Multi-Object Spectrograph on Gemini North telescope as part of our ongoing program to study the formation histories of these systems. We use the pPXF code to fit the observed spectra with single-single component models consisting of an old passively-evolving population plus a younger burst superimposed at different ages and metallicities. Our main results are summarized below:  - All objects show evidence for multiple components in their line-of-sight velocity distributions.  - In all cases we find that the best-fit model consists of two distinct components: one is dominated by older stars (age>8 Gyr), while the other has intermediate age (1-8 Gyr). - For four out of six targets, the second component shows higher metallicity than the first one.",arxiv,bigscience bloomz,704.3097,0.3888888888888889,0.24369747899159663,0.2717948717948718,0.38652651696129964,1,1,0,0,0,1,1,1,0,0,0.08468207371999903,0.05788630760078863,0.08171206225680934,0.06439393939393939,0,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
A Diagrammatic Category for the Representation Theory of U_q(sl_n),"  This thesis provides a partial answer to a question posed by Greg Kuperberg
in q-alg/9712003 and again by Justin Roberts as problem 12.18 in ""Problems on
invariants of knots and 3-manifolds"", math.GT/0406190, essentially: ""Can one
describe the category of representations of the quantum group U_q(sl_n)
(thought of as a spherical category) via generators and relations?""
  For each n \geq 0, I define a certain tensor category of trivalent graphs,
modulo isotopy, and construct a functor from this category onto (a full
subcategory of) the category of representations of the quantum group U_q(sl_n).
One would like to describe completely the kernel of this functor, by providing
generators. The resulting quotient of the diagrammatic category would then be a
category equivalent to the representation category of U_q(sl_n).
  I make significant progress towards this, describing certain generators of
the kernel, and some obstructions to further elements. It remains a conjecture
that these relations generate the kernel. My results extend those of
q-alg/9712003, MR1659228, math.QA/0310143 and math.GT/0506403.
  The argument is essentially by constructing a diagrammatic version of the
forgetful functor coming from the inclusion of U_q(sl_{n-1}) in U_q(sl_n}. We
know this functor is faithful, so a diagram is in the kernel for n exactly if
its image under the diagrammatic forgetful functor is in the kernel for n-1.
This allows us to perform inductive calculations, both establishing families of
elements of the kernel, and finding obstructions.
","We introduce a diagrammatic category $\mathsf{D}_n$, which is equivalent to the representation theory of the quantum group $U_q(\mathfrak{sl}_n)$ at $q = 1$.  The objects in this category are finite sets with an action of the symmetric group $S_n$ and morphisms between two such objects are given by diagrams consisting of $n$ dots arranged into rows of length $m$ and $n$ respectively, where each row has exactly one dot on top of another (and no other dots above or below).  We show that these categories have many nice properties including being monoidal, braided, spherical, ribbon, and Koszul.  In particular we prove that they satisfy the conditions necessary to be used as input data for the Fomin-Kirillov algebraization theorem, giving rise to new families of cluster algebras. This work was supported by NSF grant DMS-0805040.",arxiv,bigscience bloomz,704.1503,0.5,0.19327731092436976,0.558974358974359,0.3349259436215958,1,1,1,1,0,1,1,0,0,0,0.15924562214301824,0.17670774333438055,0.11673151750972763,0.16287878787878787,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Search for Single-Top Production at CDF,"  This article reports on recent searches for single-top-quark production by
the CDF collaboration at the Tevatron using a data set that corresponds to an
integrated luminosity of 955 pb^-1. Three different analyses techniques are
employed, one using likelihood discriminants, one neural networks and one
matrix elements. The sensitivity to single-top production at the rate predicted
by the standard model ranges from 2.1 to 2.6 sigma. While the first two
analyses observe a deficit of single-top like events compared to the
expectation, the matrix element method observes an excess corresponding to a
background fluctuation of 2.3 sigma. The null results of the likelihood and
neural network analyses translate in upper limits on the cross section of 2.6\
pb for the t-channel production mode and 3.7 pb for the s-channel mode at the
95% C.L. The matrix element result corresponds to a measurement of
2.7^+1.5_-1.3 pb for the combined t- and s-channel single-top cross section. In
addition, CDF has searched for non-standard model production of
single-top-quarks via the s-channel exchange of a heavy W^\prime boson. No
signal of this process is found resulting in lower mass limits of 760 GeV/c^2
in case the mass of the right-handed neutrino is smaller than the mass of the
right-handed W^\prime or 790 GeV/c^2 in the opposite case.
","The D0 and CDF experiments have searched for single-top production in the t-channel, s-channel, and associated Wt channel using data corresponding to an integrated luminosity of 5.4 fb-1 collected by the Fermilab Tevatron Collider between 1992 and 1996.  The results are presented as 95% confidence level upper limits on the cross sections times branching ratios into leptons (electrons or muons) plus jets.  In addition, we present measurements of the top quark mass made with these events. We find no evidence for new physics beyond standard model expectations. These results supersede those previously reported by both collaborations. 
We thank our colleagues in the CERN accelerator departments for their vital contributions to this work. This research is supported by the U.S. Department of Energy under contract No. DE-AC02-76SF00515. The D0 experiment has also performed searches for single-top quarks produced via the t-channel, s-channnel, and associated Wt channels using 4.3 fb-1 of data taken during Run II of the Fermilab TeVatron collider [1] .",arxiv,bigscience bloomz,705.2954,0.3888888888888889,0.3949579831932773,0.4564102564102564,0.41519350215002393,0,1,0,0,0,1,1,0,0,0,0.07672262252428708,0.10770143457986504,0.07003891050583658,0.125,0,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Heat Capacity of PbS: Isotope Effects,"  In recent years, the availability of highly pure stable isotopes has made
possible the investigation of the dependence of the physical properties of
crystals, in particular semiconductors, on their isotopic composition.
Following the investigation of the specific heat ($C_p$, $C_v$) of monatomic
crystals such as diamond, silicon, and germanium, similar investigations have
been undertaken for the tetrahedral diatomic systems ZnO and GaN (wurtzite
structure), for which the effect of the mass of the cation differs from that of
the anion. In this article we present measurements for a semiconductor with
rock salt structure, namely lead sulfide. Because of the large difference in
the atomic mass of both constituents ($M_{\rm Pb}$= 207.21 and ($M_{\rm
S}$=32.06 a.m.u., for the natural isotopic abundance) the effects of varying
the cation and that of the anion mass are very different for this canonical
semiconductor. We compare the measured temperature dependence of $C_p \approx
C_v$, and the corresponding derivatives with respect to ($M_{\rm Pb}$ and
$M_{\rm S}$), with \textit{\textit{ab initio}} calculations based on the
lattice dynamics obtained from the local density approximation (LDA) electronic
band structure. Quantitative deviations between theory and experiment are
attributed to the absence of spin-orbit interaction in the ABINIT program used
for the electronic band structure calculations.
","The heat capacity of lead sulfide (PbS) has been measured in the temperature range 1.8 to 300 K using adiabatic calorimetry and compared with that for lead selenide (PbSe). The results show that, at low temperatures, the heat capacities are dominated by phonon contributions which can be described within Debye theory. At higher temperatures, anharmonic effects become important leading to deviations between experiment and theory. In addition, we find evidence for isotopic effects on both lattice and electronic properties.  These findings suggest that the use of lead chalcogenides as thermoelectric materials may require careful consideration of their thermal stability. Lead chalcogenides have attracted considerable interest recently due to their potential applications in thermoelectrics [1-3]. However, there is still much debate about how these compounds behave under different conditions [4] . This is partly because it is difficult to measure accurately the physical properties such as electrical conductivity or Seebeck coefficient over large ranges of temperature and doping concentration [5] .
In this work, we report measurements of the specific heat capacity of two samples of lead sulfide (one natural abundance sample and one enriched in the heavier isotopes 206Pb and 207Pb), together with theoretical calculations based on density functional theory [6] , in order to investigate the effect of isotopic composition on the thermodynamic properties of lead chalcogenide semiconductors [7-9]. We also compare our experimental data with those obtained previously for lead selenide [10] .  Our results demonstrate that the isotopic composition affects not only the lattice but also the electronic contribution to the total heat capacity.",arxiv,bigscience bloomz,705.1804,0.2777777777777778,0.49579831932773116,0.4205128205128205,0.6903965599617774,1,1,0,0,0,1,1,0,0,0,0.18369790471651537,0.12702137831871793,0.17509727626459143,0.18181818181818182,0,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Witnessing the formation of a galaxy cluster at z=0.485: optical and X-ray properties of RX J1117.4+0743 ([VMF 98] 097),"  We present a multiwavelength study of the poor cluster RX J1117.4+0743 ([VMF
98] 097) at z=0.485, based on GMOS/Gemini South g', r' photometry and
spectroscopy, and XMM-Newton observations. We examine its nature and
surroundings by analyzing the projected galaxy distribution, the galaxy
velocity distribution, the weak-lensing mass reconstruction, and the X-ray
spectroscopy and imaging. The cluster shows a complex morphology. It is
composed by at least two structures along the line-of-sight, with velocity
dispersions of 592+-82 km s^-1 and 391+-85 km s^-1 respectively. Other
structures are also detected in X-ray, in the galaxy projected number density
map, and by weak-lensing. One of these clumps, could be gravitationally bound
and associated to the main cluster. The derived temperature and bolometric
X-ray luminosity reveal that [VMF 98] 097 behave like a normal cluster, in
agreement with Lx-Tx correlation found for both local (z=0) and moderate
redshift (z~0.4) clusters. We find that the mass determination inferred from
weak-lensing is in average 3 to 4.8 times higher (depending on the model
assumed) than the X-ray mass. We have two possible explanations for this
discrepancy: i) the cluster is in non-equilibrium, then the deviation of the
X-ray estimated mass from the true value can be as high as a factor of two; ii)
the intervening mass along the line-of-sight of the cluster is producing an
over-estimation of the weak-lensing mass. Based on the analysis presented, we
conclude that [VMF 98] 097 is a perturbed cluster with at least two
substructures in velocity space and with other nearby structures at projected
distances of about 1 h^-1 Mpc. This cluster is an example of a poor cluster
caught in the process of accreting sub-structures to become a rich cluster.
","We present new observations of the distant galaxy cluster RX J1117.4+07431, which was discovered in the ROSAT All-Sky Survey data by Voges et al. (1999) . The cluster is located at redshift z = 0.485 ± 0.001 with an estimated mass M500 = 1.7 × 1013 h-1M⊙ within r500 = 2.1h-1Mpc . We have obtained deep optical images using Suprime-Cam on Subaru telescope to study its member galaxies. In addition we observed this cluster with Chandra ACIS-I for about 50 ks. Our results are as follows:  -The color-magnitude diagram shows that there exists a red sequence of early-type galaxies down to our limiting magnitude RAB=25 mag.  -From the photometric redshift analysis, we find that the number density profile of the member galaxies follows well the NFW model prediction up to 3 virial radii. -The temperature map derived from the Chandra observation reveals two hot spots near the center of the cluster. These features may be associated with shock heating due to merging activity between sub-clusters or groups.",arxiv,bigscience bloomz,704.2459,0.5555555555555556,0.3949579831932773,0.8153846153846154,0.43239369326325855,1,1,1,0,1,1,1,1,0,0,0.13056925355195206,0.06308084482114892,0.11673151750972763,0.06818181818181818,1,1,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Modeling Repulsive Gravity with Creation,"  There is a growing interest in the cosmologists for theories with negative
energy scalar fields and creation, in order to model a repulsive gravity. The
classical steady state cosmology proposed by Bondi, Gold and Hoyle in 1948, was
the first such theory which used a negative kinetic energy creation field to
invoke creation of matter. We emphasize that creation plays very crucial role
in cosmology and provides a natural explanation to the various explosive
phenomena occurring in local (z<0.1) and extra galactic universe. We exemplify
this point of view by considering the resurrected version of this theory - the
quasi-steady state theory, which tries to relate creation events directly to
the large scale dynamics of the universe and supplies more natural explanations
of the observed phenomena. Although the theory predicts a decelerating universe
at the present era, it explains successfully the recent SNe Ia observations
(which require an accelerating universe in the standard cosmology), as we show
in this paper by performing a Bayesian analysis of the data.
","The gravitational force between two objects is proportional to the product of their masses, and inversely proportional to the square of the distance separating them.  The same relationship holds true for repulsive gravity as well.   In this article we will examine how such an effect can be modeled using creation in place of mass.    Creation is defined by Einstein's field equations as:  G = 8πG/c4T00 where T00 represents the energy density of space-time.  We will show that if one object has more creation than another then it exerts a greater repulsive force on its neighbor.   This effect may explain why some stars are surrounded by dark matter while others do not. It also provides insight into the nature of black holes which have been observed to emit radiation but no light. Gravitational attraction occurs when two bodies exert mutual forces upon each other due to their respective masses.  If body A has twice the mass of body B then it exerts double the force on body B compared to what body B exerts on itself.  Similarly, if body C has three times the mass of body D then it exerts triple the force on body D compared to what body D exerts on itself.  Force is measured in newtons (N) or dynes (dyne).",arxiv,bigscience bloomz,705.0544,0.2222222222222222,0.49579831932773116,0.23076923076923078,0.5642618251313904,1,1,0,0,0,1,1,1,0,1,0.07589511823681892,0.047078130062802113,0.04669260700389105,0.04924242424242424,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Entropy signature of the running cosmological constant,"  Renormalization group (RG) improved cosmologies based upon a RG trajectory of
Quantum Einstein Gravity (QEG) with realistic parameter values are investigated
using a system of cosmological evolution equations which allows for an
unrestricted energy exchange between the vacuum and the matter sector. It is
demonstrated that the scale dependence of the gravitational parameters, the
cosmological constant in particular, leads to an entropy production in the
matter system. The picture emerges that the Universe started out from a state
of vanishing entropy, and that the radiation entropy observed today is
essentially due to the coarse graining (RG flow) in the quantum gravity sector
which is related to the expansion of the Universe. Furthermore, the RG improved
field equations are shown to possess solutions with an epoch of power law
inflation immediately after the initial singularity. The inflation is driven by
the cosmological constant and ends automatically once the RG running has
reduced the vacuum energy to the level of the matter energy density.
","We show that entropy production in quantum field theory is related to the vacuum energy density and its time evolution, which can be used as an indicator for the presence of dark energy. We consider two different models with varying degrees of complexity: (i) a scalar field model where we calculate the entropy production using the Schwinger-Keldysh formalism; (ii) a more realistic model based on QED including fermions and photons. In both cases we find that the entropy production increases monotonically when the vacuum energy decreases over time. This behavior is consistent with our expectation that the universe becomes less ordered if it expands faster than usual due to the presence of dark energy. 
 
 Introduction 
 
 The accelerated expansion of the universe has been confirmed by many observations [1] . It is generally believed that this acceleration is driven by some form of ""dark energy"" [2] , whose nature remains unknown. One possible explanation for such a phenomenon could be provided by the so-called ""quintessence"" fields [3] - [4] . These are hypothetical scalar fields with negative pressure, which evolve slowly down their potential wells leading to a decrease in the vacuum energy density over time. Another possibility would be that the observed acceleration results from modifications of gravity at large distances [5] - [6] . However, there exist other explanations [7] - [8] . 
 
 In order to distinguish between these possibilities one needs to develop new methods allowing us to probe the properties of dark energy directly [9] . Here we propose a novel approach based on the concept of entropy production [10] - [11] . Entropy measures how much disorder or randomness exists in a system [12] . If the universe accelerates because of dark energy then the rate of entropy production should increase accordingly. On the contrary, if the universe decelerates then the entropy production will slow down. Therefore, measuring the amount of entropy produced during the cosmic evolution may provide important information about the underlying physics responsible for the current state of the universe. 
 
 In what follows we demonstrate that entropy production in quantum electrodynamics (QED), i.e., the interaction of electrons, positrons and photons, depends crucially on the value",arxiv,bigscience bloomz,706.0174,0.2222222222222222,0.7983193277310925,0.2,0.9913999044433827,1,0,0,0,0,1,1,1,0,0,0.09611663433907677,0.06396170314089648,0.08949416342412451,0.07954545454545454,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
An experimental test of non-local realism,"  Most working scientists hold fast to the concept of 'realism' - a viewpoint
according to which an external reality exists independent of observation. But
quantum physics has shattered some of our cornerstone beliefs. According to
Bell's theorem, any theory that is based on the joint assumption of realism and
locality (meaning that local events cannot be affected by actions in space-like
separated regions) is at variance with certain quantum predictions. Experiments
with entangled pairs of particles have amply confirmed these quantum
predictions, thus rendering local realistic theories untenable. Maintaining
realism as a fundamental concept would therefore necessitate the introduction
of 'spooky' actions that defy locality. Here we show by both theory and
experiment that a broad and rather reasonable class of such non-local realistic
theories is incompatible with experimentally observable quantum correlations.
In the experiment, we measure previously untested correlations between two
entangled photons, and show that these correlations violate an inequality
proposed by Leggett for non-local realistic theories. Our result suggests that
giving up the concept of locality is not sufficient to be consistent with
quantum experiments, unless certain intuitive features of realism are
abandoned.
","We report on an experiment that tests the predictions of quantum mechanics and local hidden variable theories for two entangled photons in a Bell state, using polarization-entanglement swapping to create a loophole-free Bell inequality violation.  The experiment is performed with a source of polarization-entangled photon pairs produced by spontaneous parametric down-conversion (SPDC) in a nonlinear crystal pumped by a continuous-wave laser at 405 nm.   A half wave plate rotates one of the photons' polarizations by 45 degrees before it enters a beam splitter which separates the pair into two spatially separated beams.   One of these beams passes through a quarter wave plate oriented such that its fast axis makes an angle of 22.5 degrees relative to horizontal; this transforms the horizontally polarized component of the beam's electric field vector into vertically polarized light.   After passing through another quarter wave plate whose fast axis is aligned with vertical, both components are transformed back into horizontally polarized light.   This transformation can be represented as follows:  H → V → H = HVH.   The other beam travels directly to Alice's measurement station where she performs measurements along three different axes corresponding to projections onto the basis states |V>, |H>, and |D>, where D denotes diagonal.   Bob measures his photon along four different axes corresponding to projections",arxiv,bigscience bloomz,704.2529,0.3888888888888889,0.3445378151260504,0.3230769230769231,0.5642618251313904,1,1,0,0,1,1,1,1,0,1,0.08539050839057909,0.09188327188527516,0.1245136186770428,0.0946969696969697,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
The discrete dipole approximation for simulation of light scattering by particles much larger than the wavelength,"  In this manuscript we investigate the capabilities of the Discrete Dipole
Approximation (DDA) to simulate scattering from particles that are much larger
than the wavelength of the incident light, and describe an optimized publicly
available DDA computer program that processes the large number of dipoles
required for such simulations. Numerical simulations of light scattering by
spheres with size parameters x up to 160 and 40 for refractive index m=1.05 and
2 respectively are presented and compared with exact results of the Mie theory.
Errors of both integral and angle-resolved scattering quantities generally
increase with m and show no systematic dependence on x. Computational times
increase steeply with both x and m, reaching values of more than 2 weeks on a
cluster of 64 processors. The main distinctive feature of the computer program
is the ability to parallelize a single DDA simulation over a cluster of
computers, which allows it to simulate light scattering by very large
particles, like the ones that are considered in this manuscript. Current
limitations and possible ways for improvement are discussed.
","The Discrete Dipole Approximation (DDA) is used to simulate light scattering by large spherical particles in this study. The DDA was first developed as an efficient method for calculating the interaction between electromagnetic waves and small particles, but it has been extended recently to calculate the interactions with large particles. In order to validate our numerical results obtained using the DDA code, we compare them against those calculated using Mie theory. We find that both methods agree well when the size parameter x = 2πa/λ < 100 where λ is the incident wavelength and a is the radius of the particle. However, there are some discrepancies observed at higher values of x due to the fact that the DDA assumes that the scatterers have sharp boundaries while the actual particles do not. Finally, we show how the angular distribution of scattered intensity changes as the size of the particle increases. This work will be useful for studying aerosol optical properties such as extinction efficiency and single-scattering albedo.",arxiv,bigscience bloomz,704.0037,0.2222222222222222,0.29411764705882354,0.26666666666666666,0.43239369326325855,1,1,0,0,0,1,1,0,0,0,0.14223518798001739,0.0512577423502876,0.13618677042801555,0.03409090909090909,1,0,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Approche variationnelle pour le calcul bay\'esien dans les probl\`emes inverses en imagerie,"  In a non supervised Bayesian estimation approach for inverse problems in
imaging systems, one tries to estimate jointly the unknown image pixels $\fb$
and the hyperparameters $\thetab$. This is, in general, done through the joint
posterior law $p(\fb,\thetab|\gb)$. The expression of this joint law is often
very complex and its exploration through sampling and computation of the point
estimators such as MAP and posterior means need either optimization of non
convex criteria or int\'egration of non Gaussian and multi variate probability
laws. In any of these cases, we need to do approximations. We had explored
before the possibilities of Laplace approximation and sampling by MCMC. In this
paper, we explore the possibility of approximating this joint law by a
separable one in $\fb$ and in $\thetab$. This gives the possibility of
developing iterative algorithms with more reasonable computational cost, in
particular, if the approximating laws are choosed in the exponential conjugate
families. The main objective of this paper is to give details of different
algorithms we obtain with different choices of these families.
","Nous proposons une approche variationnelle de la m{\'e}thode du maximum d'entropie (MaxEnt) pour r{\'e}soudre des probl\`emes inverses; nous montrons que cette approche permet d'obtenir un algorithme num{\'e}rique efficace et robuste, qui peut s'appliquer aux mod\`eles non-lin{\'e}aires avec incertitude sur les donn{\'e}es d'entr{\'e}e ou sur les param\`etres inconnus. Nous appliquons notre m{\'e}thodologie au cas d'un probl\`eme inverse magn{\'e}tique, o霉 l'on cherche {\`a} estimer l'aimantation d'une source inconnue plong{\'e}e dans un champ magn{\'e}tique connu. Les exp{\'e}riences num{\'e}riques montrent que l'algorithme MaxEnt est capable d'estimer correctement la distribution de probabilit{\'e} recherch{\'ee}, tout en restant stable face \u00e0 l'incertitude sur les donn{\'e",arxiv,bigscience bloomz,706.1914,0.3888888888888889,0.09243697478991597,0.2564102564102564,0.23459149546106067,1,0,0,0,1,1,1,1,0,1,0.09625879757844147,0.1656202235958801,0.12840466926070038,0.125,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Nontrivial Geometries: Bounds on the Curvature of the Universe,"  Probing the geometry of the universe is one of the most important endevours
in cosmology. Current observational data from the Cosmic Microwave Background
anisotropy (CMB), galaxy surveys and type Ia supernovae (SNe Ia) strongly
constrain the curvature of the universe to be close to zero for a universe
dominated by a cosmological constant or dark energy with a constant equation of
state. Here we investigate the role of cosmic priors on deriving these tight
bounds on geometry, by considering a landscape motivated scenario with an
oscillating curvature term. We perform a likelihood analysis of current data
under such a model of non-trivial geometry and find that the uncertainties on
curvature, and correspondingly on parameters of the matter and dark energy
sectors, are larger. Future dark energy experiments together with CMB data from
experiments like Planck could dramatically improve our ability to constrain
cosmic curvature under such models enabling us to probe possible imprints of
quantum gravity.
","The curvature of space-time is one of the most important quantities in general relativity, and it has been studied extensively for many years.  In this work we present new bounds on the curvature of the universe that are derived by using only information about its large-scale structure.   We show how these bounds can be used to constrain cosmological models with nontrivial geometries such as those containing extra dimensions or time-varying fundamental constants.    The results presented here have implications not just for theoretical physics but also for observational astronomy and cosmology. General relativity (GR) describes gravity at all scales ranging from microscopic black holes to supermassive galaxies. It predicts that matter curves spacetime around itself, which causes light rays emitted from distant sources to bend towards each other. This effect was first observed over 100 years ago when astronomers noticed that the positions of stars near the edge of our galaxy were systematically shifted away from their expected locations based on Newton's theory of gravitation [1] . Since then, gravitational lensing has become an extremely powerful tool for studying dark matter [2] , testing GR [3] , constraining modified theories of gravity [4] , and measuring distances [5] .
In addition to predicting the bending of light, GR also makes precise predictions about the geometry of spacetime [6] . For example, if you travel along a straight line through empty space, your path will remain straight even though there may be massive objects nearby [7, 8] . Similarly, if you look out into space far enough so that no matter exists, you should see nothing but flat, featureless space [9] . These predictions depend crucially on the fact that the metric describing the geometry of spacetime must satisfy Einstein's field equations [10] . However, despite decades of research, it remains unclear whether the universe actually obeys these equations [11] .",arxiv,bigscience bloomz,705.0332,0.2222222222222222,0.596638655462185,0.16923076923076924,0.8394648829431438,1,1,0,0,0,1,1,0,0,1,0.11700591132988934,0.05977196472755807,0.14396887159533073,0.056818181818181816,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1
Dynamical 3-Space: A Review,"  For some 100 years physics has modelled space and time via the spacetime
concept, with space being merely an observer dependent perspective effect of
that spacetime - space itself had no observer independent existence - it had no
ontological status, and it certainly had no dynamical description. In recent
years this has all changed. In 2002 it was discovered that a dynamical 3-space
had been detected many times, including the Michelson-Morley 1887 light-speed
anisotropy experiment. Here we review the dynamics of this 3-space, tracing its
evolution from that of an emergent phenomena in the information-theoretic
Process Physics to the phenomenological description in terms of a velocity
field describing the relative internal motion of the structured 3-space. The
new physics of the dynamical 3-space is extensively tested against experimental
and astronomical observations, including the necessary generalisation of the
Maxwell, Schrodinger and Dirac equations, leading to a derivation and
explanation of gravity as a refraction effect of quantum matter waves. The flat
and curved spacetime formalisms are derived from the new physics, so explaining
their apparent many successes.
","The concept of dynamical 3-space is introduced in this review article as an alternative to the standard space-time picture of relativistic physics. The main idea behind it is that, instead of considering time and space separately, one should consider them together as a single entity called ""dynamical 3-space"". This new approach has several advantages over the traditional viewpoint; for example, it provides a natural explanation for why we experience time flow only forward (and not backward), while at the same time allowing us to preserve causality. In addition, it also allows us to explain how particles can travel faster than light without violating any physical laws. Finally, by introducing the concept of ""quantum potential energy density"" into our description of matter fields, we are able to provide a simple mathematical framework within which all known fundamental interactions between elementary particles may be described. We conclude with some remarks on possible future research directions based upon this novel theoretical perspective.",arxiv,bigscience bloomz,705.4146,0.2777777777777778,0.24369747899159663,0.2717948717948718,0.4094601051122791,0,1,0,0,0,1,1,1,0,0,0.149391052580593,0.08668633834000741,0.16342412451361868,0.07954545454545454,1,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
"The orbit, mass, size, albedo, and density of (65489) Ceto/Phorcys: A tidally-evolved binary Centaur","  Hubble Space Telescope observations of Uranus- and Neptune-crossing object
(65489) Ceto/Phorcys (provisionally designated 2003 FX128) reveal it to be a
close binary system. The mutual orbit has a period of 9.554 +/- 0.011 days and
a semimajor axis of 1840 +/- 48 km. These values enable computation of a system
mass of (5.41 +/- 0.42) 10^18 kg. Spitzer Space Telescope observations of
thermal emission at 24 and 70 microns are combined with visible photometry to
constrain the system's effective radius (109 +10/-11 km) and geometric albedo
(0.084 +0.021/-0.014). We estimate the average bulk density to be 1.37
+0.66/-0.32 g cm^-3, consistent with ice plus rocky and/or carbonaceous
materials. This density contrasts with lower densities recently measured with
the same technique for three other comparably-sized outer Solar System binaries
(617) Patroclus, (26308) 1998 SM165, and (47171) 1999 TC36, and is closer to
the density of the saturnian irregular satellite Phoebe. The mutual orbit of
Ceto and Phorcys is nearly circular, with an eccentricity <= 0.015. This
observation is consistent with calculations suggesting that the system should
tidally evolve on a timescale shorter than the age of the solar system.
","We report the discovery of an unusual object in the outer solar system that is likely to be composed primarily of ice particles. The new body, (65489) Ceto/Phorcys, was discovered by NASA's Wide-field Infrared Survey Explorer mission on September 24th 2010 at heliocentric distance of ~5 AU. It has been observed for more than two years with ground-based telescopes as well as space-borne observatories such as Spitzer Space Telescope and Herschel Space Observatory. We present our analysis of these data sets which reveal that this object is a binary Centaur whose components are locked into mutual tidal evolution. This unique combination of properties makes it one of only three known objects in the Solar System where both components have diameters larger than 100 km. Our results show that Phorcys is a very elongated ellipsoidal shape with dimensions of about 400 x 300 x 250 kilometers. Its surface temperature is estimated to be around -100 degrees Celsius.",arxiv,bigscience bloomz,704.1523,0.3888888888888889,0.29411764705882354,0.3333333333333333,0.40086000955566176,1,1,0,0,1,1,1,0,0,1,0.10346870712583853,0.044083599439191115,0.12840466926070038,0.022727272727272728,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Testing General Metric Theories of Gravity with Bursting Neutron Stars,"  I show that several observable properties of bursting neutron stars in metric
theories of gravity can be calculated using only conservation laws, Killing
symmetries, and the Einstein equivalence principle, without requiring the
validity of the general relativistic field equations. I calculate, in
particular, the gravitational redshift of a surface atomic line, the touchdown
luminosity of a radius-expansion burst, which is believed to be equal to the
Eddington critical luminosity, and the apparent surface area of a neutron star
as measured during the cooling tails of bursts. I show that, for a general
metric theory of gravity, the apparent surface area of a neutron star depends
on the coordinate radius of the stellar surface and on its gravitational
redshift in the exact same way as in general relativity. On the other hand, the
Eddington critical luminosity depends also on an additional parameter that
measures the degree to which the general relativistic field equations are
satisfied. These results can be used in conjunction with current and future
high-energy observations of bursting neutron stars to test general relativity
in the strong-field regime.
","We present the results of an analysis of gravitational wave data collected by the LIGO and Virgo detectors during the first observing run (O1) in 2015, which includes two candidate events for binary neutron star mergers. We use these observations to test general relativity against alternative theories of gravity that predict deviations from GR at high curvature regimes such as those encountered near black holes or neutron stars. In particular we consider scalar-tensor theories where the coupling between matter fields and the metric is mediated by a light scalar field. These theories are motivated by string theory and have been studied extensively over many decades. 
 
 For each event, we perform Bayesian model selection using simulated signals generated from both GR and several representative scalartensor theories. Our results show no evidence for deviations from GR within current uncertainties. However, this does not rule out all possible deviations from GR; it only rules out certain classes of deviations predicted by specific models.",arxiv,bigscience bloomz,704.2426,0.2222222222222222,0.29411764705882354,0.28717948717948716,0.4123268036311515,0,1,0,0,0,1,1,1,0,0,0.09696349329521456,0.0731978165395714,0.058365758754863814,0.03409090909090909,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
Probing Inward Motions in Starless Cores Using The HCN J = 1-0 Hyperfine Transitions : A Pointing Survey Toward Central Regions,"  We have carried out a survey toward the central regions of 85 starless cores
in HCN J = 1-0 to study inward motions in the cores. Sixty-four cores were
detected with HCN lines. The infall asymmetry in the HCN spectra is found to be
more prevalent, and more prominent than in any other previously used infall
tracers such as CS J = 2-1, DCO+ J = 2-1, and N2H+ J = 1-0. We found close
relation between the intensities of the HCN and N2H+ lines. This implies that
the HCN is not much depleted in the central regions of the cores. In some
cores, the HCN spectra show different sign of asymmetry from other molecular
lines. A few cores show various signs of asymmetry in individual HCN hyperfine
lines. The distribution of the velocity shift dV of the HCN profiles with
respect to the systemic velocity of the optically thin tracer is found to be
more shifted toward bluer side than those of other infall tracers, indicating
that the HCN traces inward motions more frequently. The dV distribution of each
HCN hyperfine line for all sources is similar. Moreover the dV values obtained
from different HCN hyperfine lines for each source are nearly similar. These
may mean that most of starless cores are in similar kinematic states across the
layers of the cores. We identify 17 infall candidates using all available
indicators such as the velocity shift dV and the blue to red peak intensity
ratio of double peaked profiles for HCN J = 1-0, CS J = 2-1, J = 3-2, DCO+ J =
2-1, and N2H+ J = 1-0. Four of them, L63, L492, L694-2, and L1197 are found to
show higher blue to red ratio in the HCN hyperfine line along the lower
opacity, suggesting that infall speed becomes higher toward the center.
","We present the results of an unbiased survey toward starless cores using the HCN hyperfine transitions at 1.42 GHz and 2.12 GHz with the Nobeyama 45 m telescope to probe inward motions within these objects. We detected emission lines from all targets, except for L1521F (Taurus), which is known as one of the coldest prestellar cores. From our observations we found that the line widths are narrower than those observed by single-dish telescopes. This suggests that there may be unresolved substructure or turbulence on small scales inside the cores. For most sources, the peak intensities of both frequencies agree well with each other; however, for some cases they show significant differences between them. These discrepancies can be explained if the core has a temperature gradient along its radius and/or if it contains multiple velocity components. Our analysis shows that the kinetic temperatures derived from the two different frequency data sets range from 10 K to 30 K.",arxiv,bigscience bloomz,704.293,0.6666666666666666,0.29411764705882354,0.9384615384615385,0.4037267080745342,0,1,0,0,0,1,1,1,0,0,0.14047064418921312,0.048983737244791666,0.13618677042801555,0.026515151515151516,1,0,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Enhanced Kondo Effect in an Electron System Dynamically Coupled with Local Optical Phonon,"  We discuss Kondo behavior of a conduction electron system coupled with local
optical phonon by analyzing the Anderson-Holstein model with the use of a
numerical renormalization group (NRG) method. There appear three typical
regions due to the balance between Coulomb interaction $U_{\rm ee}$ and
phonon-mediated attraction $U_{\rm ph}$. For $U_{\rm ee}>U_{\rm ph}$, we
observe the standard Kondo effect concerning spin degree of freedom. Since the
Coulomb interaction is effectively reduced as $U_{\rm ee}-U_{\rm ph}$, the
Kondo temperature $T_{\rm K}$ is increased when $U_{\rm ph}$ is increased. On
the other hand, for $U_{\rm ee}<U_{\rm ph}$, there occurs the Kondo effect
concerning charge degree of freedom, since vacant and double occupied states
play roles of pseudo-spins. Note that in this case, $T_{\rm K}$ is decreased
with the increase of $U_{\rm ph}$. Namely, $T_{\rm K}$ should be maximized for
$U_{\rm ee} \approx U_{\rm ph}$. Then, we analyze in detail the Kondo behavior
at $U_{\rm ee}=U_{\rm ph}$, which is found to be explained by the polaron
Anderson model with reduced hybridization of polaron and residual repulsive
interaction among polarons. By comparing the NRG results of the polaron
Anderson model with those of the original Anderson-Holstein model, we clarify
the Kondo behavior in the competing region of $U_{\rm ee} \approx U_{\rm ph}$.
","We study the effect of local optical phonons on the electronic transport properties of a quantum dot system by using the nonequilibrium Green's function method combined with the density functional theory (DFT). We find that the electron-phonon interaction can induce a strong enhancement to the Kondo resonance peak and lead to a significant reduction of the Kondo temperature TK, which is determined as the energy scale at which the conductance reaches its maximum value Gmax. The results show that the Kondo temperature decreases rapidly when increasing the strength of the electron-phonon coupling constant λ. In addition, we also investigate how the Kondo temperature depends on the size of the quantum dots for different values of λ. Our findings may be useful for understanding the physical mechanism behind some recent experiments. Introduction:-The Kondo effect has been studied extensively both theoretically [1]-[3]and experimentally [4] - [6] . It occurs due to the formation of a many-body singlet state between localized magnetic moments and conduction electrons near the Fermi level [7, 8] , leading to a sharp zero-bias anomaly in the differential conductance [9] . Recently, it was found that this phenomenon could occur even without any magnetic impurities [10] - [12] .
In fact, the Kondo effect has attracted much attention recently because of its potential applications in spintronics devices [13] - [16] . For example, the Kondo effect can be used to design novel spin transistors [17] or single-spin qubits [18] . However, there are still several open questions about the Kondo effect such as: How does the Kondo temperature depend on the size of the nanostructures? What happens if one introduces other degrees of freedom into the system?
To answer these questions, various theoretical methods have been developed [19] - [22] . Among them, the nonequilibrium Green functions technique [23] - [25] provides us with powerful tools to calculate the current through the systems under consideration [26] - [28] . This approach allows us not only to obtain the steady-state current but also to explore the time evolution of the current after switching on/off external fields [29] - [31] . Moreover, combining the nonequilibrium Green",arxiv,bigscience bloomz,704.3874,0.4444444444444444,0.7478991596638657,0.4307692307692308,0.9713330148112757,1,1,0,0,0,1,1,1,1,1,0.0736556485789487,0.08779189994045909,0.07392996108949416,0.09090909090909091,0,1,4,4,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1
Revisiting the Issues On Netflow Sample and Export Performance,"  The high volume of packets and packet rates of traffic on some router links
makes it exceedingly difficult for routers to examine every packet in order to
keep detailed statistics about the traffic which is traversing the router.
Sampling is commonly applied on routers in order to limit the load incurred by
the collection of information that the router has to undertake when evaluating
flow information for monitoring purposes. The sampling process in nearly all
cases is a deterministic process of choosing 1 in every N packets on a
per-interface basis, and then forming the flow statistics based on the
collected sampled statistics. Even though this sampling may not be significant
for some statistics, such as packet rate, others can be severely distorted.
However, it is important to consider the sampling techniques and their relative
accuracy when applied to different traffic patterns. The main disadvantage of
sampling is the loss of accuracy in the collected trace when compared to the
original traffic stream. To date there has not been a detailed analysis of the
impact of sampling at a router in various traffic profiles and flow criteria.
In this paper, we assess the performance of the sampling process as used in
NetFlow in detail, and we discuss some techniques for the compensation of loss
of monitoring detail.
","In this work, we revisit some issues on netflow sample and export performance in terms of packet loss rate (PLR) and flow sampling accuracy (FSA). We first present an analytical model to study PLR under different traffic conditions with various sampling rates. Then, based on our analysis results, we propose a new method for estimating FSA by using only one parameter -the average number of flows per second. Finally, through extensive experiments conducted over both real-world traces and synthetic data sets, we show that our proposed estimation method is accurate enough to be used as a practical tool for evaluating network monitoring systems. The rest of this paper is organized as follows. In Section 2, we introduce related works about netflow sampling and exporting. In Section 3, we describe our experimental environment. In Section 4, we analyze the relationship between PLR and sampling rate. In Section 5, we estimate FSA according to the analysis result presented in Section 4. In Section 6, we evaluate the effectiveness of our proposed estimation method via extensive experiments. Finally, conclusions are drawn in Section 7.",arxiv,bigscience bloomz,704.073,0.3888888888888889,0.49579831932773116,0.48205128205128206,0.47252747252747257,0,1,0,0,0,1,1,0,0,0,0.06273252508486865,0.07760684172392672,0.05058365758754864,0.09090909090909091,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Controlled collisions of a single atom and ion guided by movable trapping potentials,"  We consider a system composed of a trapped atom and a trapped ion. The ion
charge induces in the atom an electric dipole moment, which attracts it with an
r^{-4} dependence at large distances. In the regime considered here, the
characteristic range of the atom-ion interaction is comparable or larger than
the characteristic size of the trapping potential, which excludes the
application of the contact pseudopotential. The short-range part of the
interaction is described in the framework of quantum-defect theory, by
introducing some short-range parameters, which can be related to the s-wave
scattering length. When the separation between traps is changed we observe
trap-induced shape resonances between molecular bound states and vibrational
states of the external trapping potential. Our analysis is extended to
quasi-one-dimensional geometries, when the scattering exhibit
confinement-induced resonances, similar to the ones studied before for
short-range interactions. For quasi-one-dimensional systems we investigate the
effects of coupling between the center of mass and relative motion, which
occurs for different trapping frequencies of atom and ion traps. Finally, we
show how the two types of resonances can be employed for quantum state control
and spectroscopy of atom-ion molecules.
","We report on the controlled collision between an individual trapped atom and a singly charged ion in a Paul trap, where both particles are confined to different regions of space separated by several micrometers. The ions can be moved along the axis connecting them with the atoms using electrostatic fields generated by electrodes outside the vacuum chamber. We demonstrate that this allows us to control the relative velocity at which they collide as well as their impact parameter. This opens up new possibilities for studying fundamental processes such as elastic scattering or charge exchange reactions. In addition we show how it is possible to use these techniques to prepare entanglement between two neutral atoms via a quantum gate operation mediated by one common ion. Quantum information processing requires scalable systems based on many qubits [1] . One promising approach towards realizing such devices relies on neutral atoms stored in optical lattices [2] , but suffers from limited coherence times due to spontaneous emission [3] . An alternative route involves storing atomic qubits in ensembles of trapped ions [4] . However, here too there exist severe limitations arising from decoherence caused by heating [5] .
In order to overcome these difficulties, hybrid approaches have been proposed [6] combining advantages of both schemes [7, 8] . Here, the storage of quantum states takes place in a small number of highly coherent ions while large numbers of neutral atoms serve as flying qubits [9] . A crucial requirement for implementing such schemes is the ability to perform high-fidelity operations involving both types of qubit [10] . For example, it has recently been shown experimentally [11] that it is possible to entangle two neutral atoms via a shared ion [12] . To achieve this goal, however, the atoms need to interact with each other before being released into free flight [13] .",arxiv,bigscience bloomz,704.1037,0.3888888888888889,0.6470588235294118,0.3384615384615385,0.8365981844242714,0,1,0,0,0,0,1,0,0,0,0.056704154010099525,0.05289341295126129,0.04669260700389105,0.056818181818181816,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1
Effect of electron-electron interaction on the phonon-mediated spin relaxation in quantum dots,"  We estimate the spin relaxation rate due to spin-orbit coupling and acoustic
phonon scattering in weakly-confined quantum dots with up to five interacting
electrons. The Full Configuration Interaction approach is used to account for
the inter-electron repulsion, and Rashba and Dresselhaus spin-orbit couplings
are exactly diagonalized. We show that electron-electron interaction strongly
affects spin-orbit admixture in the sample. Consequently, relaxation rates
strongly depend on the number of carriers confined in the dot. We identify the
mechanisms which may lead to improved spin stability in few electron (>2)
quantum dots as compared to the usual one and two electron devices. Finally, we
discuss recent experiments on triplet-singlet transitions in GaAs dots subject
to external magnetic fields. Our simulations are in good agreement with the
experimental findings, and support the interpretation of the observed spin
relaxation as being due to spin-orbit coupling assisted by acoustic phonon
emission.
","We study the effect of electron-electron interactions (EEI) on the spin-flip rate due to phonons in semiconductor quantum dots. We show that EEI leads to an enhancement of this rate by several orders of magnitude, which is explained by the formation of collective excitations known as plasmons. The latter are responsible for the strong coupling between electrons and phonons leading to the observed increase in the spin-flip rate. Our results demonstrate that EEI can be used to control the spin dynamics in quantum dot systems. 
PACS numbers: 73.20.Dd, 74.78.Na, 78.67.Hc 
The ability to manipulate spins in semiconductors has attracted considerable attention over recent years because it could lead to novel applications such as spin-based transistors or logic devices [1] . In particular, semiconductor quantum dots have been proposed as promising candidates for these purposes [2] , since they allow one to confine charge carriers within small volumes with high precision [3] .
In order to use quantum dots for spin manipulation, however, we need to understand how their spin states evolve under different conditions. This requires knowledge about the mechanisms governing spin relaxation processes [4] . One important mechanism is provided by phonons [5] : when confined charges move through the lattice potential of the crystal, they generate strain fields [6] . These strains induce local deformations of the lattice structure [7, 8] , resulting in the emission of phonons [9] . Since phonons carry angular momentum [10] , they may flip the spin state of the confined carrier [11] . However, the strength of this process depends strongly on the details of the confinement potential [12] . For example, if the confining potential is parabolic [13] , then the spin-flip rate induced by phonons scales linearly with temperature [14] . On the other hand, if the confining",arxiv,bigscience bloomz,704.0868,0.3333333333333333,0.6470588235294118,0.11282051282051282,0.807931199235547,1,1,0,0,0,1,1,1,0,0,0.06551762838380146,0.06890818499351671,0.058365758754863814,0.06818181818181818,0,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
A Study in Depth of f0(1370),"  Claims have been made that f0(1370) does not exist. The five primary sets of
data requiring its existence are refitted. Major dispersive effects due to the
opening of the 4pi threshold are included for the first time; the sigma -> 4pi
amplitude plays a strong role. Crystal Barrel data on pbar-p -> 3pizero at rest
require f0(1370) signals of at least 32 and 33 standard deviations in 1S0 and
3P1 annihilation respectively. Furthermore, they agree within 5 MeV for mass
and width. Data on pbar-p -> eta-eta-pizero agree and require at least a 19
standard deviation contribution. This alone is sufficient to demonstrate the
existence of f0(1370). BES II data for J/Psi -> phi-pi-pi contain a visible
f0(1370) signal > 8 standard devations. In all cases, a resonant phase
variation is required. The possibility of a second pole in the sigma amplitude
due to the opening of the 4pi channel is excluded. Cern-Munich data for pi-pi
elastic scattering are fitted well with the inclusion of some mixing between
sigma, f0(1370) and f0(1500). The pi-pi widths for f2(1565), rho3(1690),
rho3(1990) and f4(2040) are determined.
","The mass spectrum and decay properties of the scalar mesons are studied by using the QCD sum rule method with the light-cone distribution amplitudes (LCDAs). The masses, pole residues and coupling constants for the scalar mesons below 2 GeV are calculated systematically. In particular, we study the f0(1370), which is usually considered as an exotic state. We find that it can be naturally explained as a mixture of two conventional states, i.e., the lowest lying scalar glueball and the scalar quarkonium. Our results show that its mixing angle θ = −20° ± 5° , where the first error comes from the uncertainty of the LQCD data used to determine the parameters of LCDAs, while the second one arises from the uncertainties of the input parameters such as Borel parameter M2B and threshold s0B . 
I. INTRODUCTIO N
In recent years, there has been great interest in studying the low energy hadronic physics due to both theoretical and experimental reasons [1] - [4] . On the theory side, lattice quantum chromodynamics (LQCD) provides us with valuable information on the nonperturbative aspects of strong interactions [5] . However, at present most calculations have only focused on the ground-state hadrons [6] .
On the other hand, the experimental observations of many new excited states beyond the naive quark model predictions [7] - [9] provide further motivation to explore their underlying structures [10] - [12] . For example, the newly observed scalars around 1.4-1.7 GeV [13] - [16] may contain important information about the nature of confinement [17] - [20] . It should also be noted that some of these newly discovered resonances cannot be easily accommodated into the traditional qq picture [21] - [23] . Therefore, it becomes necessary to investigate them more carefully [24] - [26] .
In this work, we will use the QCD sum rules [27] - [29] to calculate the masses, pole residues and couplings of various scalar mesons below 2GeV systematically [30] . In particular, we focus our attention on the f 0 (1370), whose existence",arxiv,bigscience bloomz,706.1341,0.6111111111111112,0.6470588235294118,0.3076923076923077,0.9225991399904443,1,1,1,0,0,1,1,0,0,0,0.06843450799834352,0.08881583703620323,0.07392996108949416,0.08333333333333333,0,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Super stellar clusters with a bimodal hydrodynamic solution: an Approximate Analytic Approach,"  We look for a simple analytic model to distinguish between stellar clusters
undergoing a bimodal hydrodynamic solution from those able to drive only a
stationary wind. Clusters in the bimodal regime undergo strong radiative
cooling within their densest inner regions, which results in the accumulation
of the matter injected by supernovae and stellar winds and eventually in the
formation of further stellar generations, while their outer regions sustain a
stationary wind. The analytic formulae are derived from the basic hydrodynamic
equations. Our main assumption, that the density at the star cluster surface
scales almost linearly with that at the stagnation radius, is based on results
from semi-analytic and full numerical calculations. The analytic formulation
allows for the determination of the threshold mechanical luminosity that
separates clusters evolving in either of the two solutions. It is possible to
fix the stagnation radius by simple analytic expressions and thus to determine
the fractions of the deposited matter that clusters evolving in the bimodal
regime blow out as a wind or recycle into further stellar generations.
","We present the results of our study on super star clusters (SSCs) in which we have found that SSCs can be divided into two categories, namely, those having a single mode and those having a double-mode solution for their density profiles. We show how these solutions are related to each other by using approximate analytic methods. The main aim is to understand why some SSCs appear as point sources while others do not. In this work, we also discuss the possibility of formation of such objects through mergers between smaller clusters or stars. Super massive star clusters (SMCs), known as young globular clusters (YGCs), open clusters (OCs), compact elliptical galaxies (CEGs), etc., are observed in many galactic systems ranging from dwarf irregular galaxies to giant ellipticals. These objects are believed to form during violent events like galaxy mergers, tidal interactions, and/or gas-rich major mergers. However, it has been shown recently that there exists another class of SMCs whose luminosity function shows a peak at intermediate masses (10^6-10^7 Msun). This type of cluster is referred to as ""Intermediate Massive Clusters""(IMCs; Portegies Zwart et al. (2010)). It appears that IMCs may represent a transition phase between open clusters and YGCs.",arxiv,bigscience bloomz,706.1889,0.2777777777777778,0.4453781512605043,0.2564102564102564,0.5212613473483039,0,1,0,0,0,1,1,1,0,0,0.11616520620395447,0.10844084178262889,0.14396887159533073,0.09848484848484848,0,1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1
A Multiphilic Descriptor for Chemical Reactivity and Selectivity,"  In line with the local philicity concept proposed by Chattaraj et al.
(Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and
a dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.;
Toro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic
descriptor. It is defined as the difference between nucleophilic (Wk+) and
electrophilic (Wk-) condensed philicity functions. This descriptor is capable
of simultaneously explaining the nucleophilicity and electrophilicity of the
given atomic sites in the molecule. Variation of these quantities along the
path of a soft reaction is also analyzed. Predictive ability of this descriptor
has been successfully tested on the selected systems and reactions.
Corresponding force profiles are also analyzed in some representative cases.
Also, to study the intra- and intermolecular reactivities another related
descriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over
the electrophilicity in it has been defined and tested on all-metal aromatic
compounds.
","The concept of molecular descriptors is central to the development of quantitative structure-activity relationships (QSARs). In this work, we introduce a new descriptor that can be used in QSAR studies as well as other applications where chemical reactivity or selectivity are important factors.  The proposed descriptor is based on an extension of the concept of multipolarity developed by Mulliken. It has been shown previously that the multipole moments calculated using atomic orbital basis sets provide useful information about molecular properties such as polarizability, electronegativity, hardness, softness, etc.. We show here how these quantities may also be related to the electronic energy differences between different states of charge within a molecule. This relationship allows us to define a quantity called the ""multiphase index"" which provides a measure of the relative stability of molecules with respect to changes in their oxidation state. The multiphase index was applied successfully to several test cases including the prediction of the oxidation potentials of some organic compounds.",arxiv,bigscience bloomz,704.0334,0.7222222222222222,0.24369747899159663,0.18461538461538463,0.41519350215002393,1,1,1,0,0,1,1,0,0,0,0.10132793979458822,0.11740090495350111,0.10894941634241245,0.13636363636363635,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1
A Census of Baryons in Galaxy Clusters and Groups,"  We determine the contribution of stars in galaxies, intracluster stars, and
the intracluster medium to the total baryon budget in nearby galaxy clusters
and groups. We find that the baryon mass fraction (f_b) within r500 is constant
for systems with M500 between 6e13 and 1e15 Msun. Although f_b is lower than
the WMAP value, the shortfall is on the order of both the observational
systematic uncertainties and the depletion of baryons within r500 that is
predicted by simulations. The data therefore provide no compelling evidence for
undetected baryonic components, particularly any that vary in importance with
cluster mass. A unique feature of the current analysis is direct inclusion of
the contribution of intracluster light (ICL) in the baryon budget. The increase
in X-ray gas mass fraction with increasing total mass is entirely accounted for
by a decrease in the total stellar mass fraction, supporting the argument that
the behavior of both the stellar and X-ray gas components is dominated by a
decrease in star formation efficiency in more massive environments. Within just
the stellar component, the fraction of the total stellar luminosity in the BCG
and ICL decreases as velocity dispersion increases, suggesting that the BCG+ICL
component, and in particular the dominant ICL component, grows less efficiently
in higher mass environments. The degree to which this behavior arises from our
sample selection, which favored systems with central, giant elliptical
galaxies, remains unclear. A more robust result is the identification of low
mass groups with large BCG+ICL components, demonstrating that the creation of
intracluster stars does not require a massive cluster environment. Within r500
and r200, the BCG+ICL contributes on average 40% and 33% of the total stellar
light, respectively.
","We present the results of an all-sky survey for galaxy clusters using data obtained with the Sunyaev-Zel'dovich effect (SZE) by the Planck satellite, complemented at low redshifts by X-ray observations made with XMM-Newton and Chandra satellites. We use this sample to study the evolution of baryon content in massive halos over cosmic time. The total mass is estimated through gravitational lensing measurements performed on Hubble Space Telescope images. Our main findings are as follows:  1. We find that the fraction of gas mass decreases strongly towards higher redshift.  2. At z < 0.5 we measure fgas = Mgas/Mtot = 0.11 ± 0.01(stat.) ±0.02(sys.), where Mtot is the total gravitating mass within R500c, which corresponds to about half the virial radius. This value agrees well with previous estimates based on X-ray observations alone.  3. For our full cluster sample spanning the range 0.1 < z < 1.3, we obtain fgas = 0.09 ± 0.01(±stat.).",arxiv,bigscience bloomz,705.1726,0.5,0.596638655462185,0.8,0.3922599139990445,1,1,0,0,0,1,1,1,0,1,0.09667562479267734,0.08877341215736259,0.11284046692607004,0.06818181818181818,0,5,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0
Nanomechanics of single keratin fibres: A Raman study of the alpha helix -> beta sheet transition and water effect,"  The use of micro-Raman spectroscopy, through chemical bond nano-scale probes,
allows the changes in conformations (alpha helix -> beta sheet), chain
orientation, disconnection of disulfide bonds (-20%) and the increase of intra
and inter-chain distances during the strain to be distinguished. The
combination of micro-Raman spectroscopy and a allows a quantitative measure of
the extension of chemical bonds in the peptidic chain during loading. The
nano-structural transformations of keratin during the strain of human hair in a
dry environment (40-60 % relative humidity) and saturated with water have been
studied. The water permits the sliding of the chains and decreases the bond
energy hair. Spectral analyses and 2D correlation are two coherent and
independent methods to follow change the Raman probes which are sensitive to
structural . The between nano-mechanical (Raman) and micro-mechanical
(strain/stress) analyses confirms the validity of the experimental results,
tools and principles used, as well as the agreement with the structural model
of keratin fibres described by Chapman & Hearle.
","The mechanical properties of hair are determined by its molecular structure, which is mainly composed of proteins called keratins. The main structural unit in keratins is an alpha-helical coiled coil that forms microfibrils with other similar units to form intermediate filaments (IFs). These IFs then aggregate into bundles forming macrofibrils, which are further bundled together to form the basic building blocks of hair -the cortical cells-. In this work we have studied how the mechanical properties change as these structures evolve during the process known as maturation or ageing. We used confocal Raman spectroscopy to measure the changes in the secondary structure of individual keratin fibres extracted from human scalp hairs at different stages of their growth cycle. Our results show that the elastic modulus increases significantly when the fibre goes through the transformation from the alpha helix conformation to the beta-sheet one. This increase can be explained by the formation of hydrogen bonds between neighbouring strands of the protein backbone. Moreover, our measurements reveal that the presence of water molecules has a significant influence on the mechanical behaviour of the fibres.",arxiv,bigscience bloomz,706.0776,0.2777777777777778,0.3445378151260504,0.20512820512820512,0.475394171046345,1,1,0,0,0,1,1,0,0,0,0.12179378477165018,0.02417876281126967,0.10894941634241245,0.011363636363636364,0,0,2,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1
Energy-Efficient Resource Allocation in Wireless Networks: An Overview of Game-Theoretic Approaches,"  An overview of game-theoretic approaches to energy-efficient resource
allocation in wireless networks is presented. Focusing on multiple-access
networks, it is demonstrated that game theory can be used as an effective tool
to study resource allocation in wireless networks with quality-of-service (QoS)
constraints. A family of non-cooperative (distributed) games is presented in
which each user seeks to choose a strategy that maximizes its own utility while
satisfying its QoS requirements. The utility function considered here measures
the number of reliable bits that are transmitted per joule of energy consumed
and, hence, is particulary suitable for energy-constrained networks. The
actions available to each user in trying to maximize its own utility are at
least the choice of the transmit power and, depending on the situation, the
user may also be able to choose its transmission rate, modulation, packet size,
multiuser receiver, multi-antenna processing algorithm, or carrier allocation
strategy. The best-response strategy and Nash equilibrium for each game is
presented. Using this game-theoretic framework, the effects of power control,
rate control, modulation, temporal and spatial signal processing, carrier
allocation strategy and delay QoS constraints on energy efficiency and network
capacity are quantified.
","In this article, we provide an overview on the recent advances and challenges in energy-efficient resource allocation for wireless networks using game-theoretical approaches. We first introduce some basic concepts related to games and then present several representative works that have been done recently by researchers worldwide. Finally, we conclude with open research issues and future directions. In this article, we provide a survey on the recent advances and remaining challenges in energy-efficient radio resource management (RRM) for wireless networks using game theoretical approaches. The main goal is to show how these techniques can be used to improve network performance while reducing power consumption at each node. To achieve this objective, we first give a brief introduction about the concept of games as well as their applications in communication systems. Then, we review existing work on RRM problems formulated as non-cooperative or cooperative games. Finally, we discuss open research issues and possible future directions. This article is organized into four sections. Section II introduces some background information on games and their application in communications. Section III presents different types of games applied to solve RRM problems. Section IV discusses open research issues and concludes the article.",arxiv,bigscience bloomz,705.1787,0.3333333333333333,0.546218487394958,0.3384615384615385,0.5126612517916866,1,1,0,0,0,1,1,0,0,0,0.13618641462325362,0.05906501333551123,0.17898832684824903,0.056818181818181816,0,1,2,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1
Modeling transcription factor binding events to DNA using a random walker/jumper representation on a 1D/2D lattice with different affinity sites,"  Surviving in a diverse environment requires corresponding organism responses.
At the cellular level, such adjustment relies on the transcription factors
(TFs) which must rapidly find their target sequences amidst a vast amount of
non-relevant sequences on DNA molecules. Whether these transcription factors
locate their target sites through a 1D or 3D pathway is still a matter of
speculation. It has been suggested that the optimum search time is when the
protein equally shares its search time between 1D and 3D diffusions. In this
paper, we study the above problem using a Monte Carlo simulation by considering
a very simple physical model. A 1D strip, representing a DNA, with a number of
low affinity sites, corresponding to non-target sites, and high affinity sites,
corresponding to target sites, is considered and later extended to a 2D strip.
We study the 1D and 3D exploration pathways, and combinations of the two modes
by considering three different types of molecules: a walker that randomly walks
along the strip with no dissociation; a jumper that represents dissociation and
then re-association of a TF with the strip at later time at a distant site; and
a hopper that is similar to the jumper but it dissociates and then
re-associates at a faster rate than the jumper. We analyze the final
probability distribution of molecules for each case and find that TFs can
locate their targets fast enough even if they spend 15% of their search time
diffusing freely in the solution. This indeed agrees with recent experimental
results obtained by Elf et al. 2007 and is in contrast with theoretical
expectation.
","Transcription factors (TFs) are proteins that bind specific sequences in the genome and regulate gene expression by recruiting other regulatory molecules or directly modulating RNA polymerase activity. The identification of TF binding sites is an important step towards understanding how genes are regulated, but it remains challenging due to their short length and degenerate sequence patterns. In this work we present a novel computational method for predicting TF binding sites based on a random walk model on a one-dimensional (1D) or two-dimensional (2D) lattice representing the DNA molecule. We show that our approach outperforms state-of-the-art methods when applied to several datasets containing experimentally validated binding sites. Our results suggest that the proposed algorithm can be used as part of a pipeline for identifying putative binding sites in large genomic regions. Transcription factors (TFs), which include zinc finger proteins, homeodomain proteins, basic helix-loop-helix proteins, and others [1] , play key roles in regulating gene expression [2] . They bind specific sequences in the promoter region of target genes [3] and recruit other regulatory molecules such as coactivators [4] or corepressors [5] , or they may directly affect the rate at which RNA polymerases synthesize messenger RNAs [6] .
The identification of TF binding sites has been shown to be useful for studying gene regulation [7, 8] . However, it remains difficult because these sites have very short lengths [9] and exhibit highly degenerate sequence patterns [10] . Several algorithms have been developed to predict TF binding sites [11] ; however, most existing approaches suffer from high false positive rates [12] . For example, the widely-used position weight matrix (PWM)-based motif finding algorithms [13] cannot accurately identify TF binding sites [14] . This problem arises mainly because PWM models assume independence between positions within motifs [15] , while real TF binding sites often contain dependencies among adjacent bases [16] . To address this issue, some researchers have attempted to incorporate higher-order interactions into PWMs [17] . Other studies have focused on developing probabilistic graphical models [18] , hidden Markov models [19] , support vector machines [20] , and neural networks [21] .",arxiv,bigscience bloomz,704.2454,0.5,0.6470588235294118,0.7282051282051282,0.9569995222169135,1,1,1,0,0,1,1,1,0,0,0.19229125468379943,0.06419415546329452,0.16731517509727625,0.08712121212121213,2,0,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Study of Direct Photon plus Jet production in CMS Experiment at \sqrt{s}=14 TeV,"  We present simulation results of $\gamma$ + Jet analysis using CMS (Compact
Muon Solenoid) Object-Oriented software at the Large Hadron Collider (LHC)
center of mass energy $\sqrt{s}$=14 TeV. The study of direct photon production
helps in validating the perturbative Quantum Chromodynamics (pQCD) and
providing information on the gluon distribution in the nucleons. Direct photon
processes also constitute a major background to several other Standard Model
(SM) processes and signals of new physics. Thus these processes need to be
understood precisely in the new energy regime. In this work, we have done a
detailed study of the GEANT4 simulated $\gamma$ + jet events generated with
Pythia, and the related background processes. Isolation cuts have been
optimized for direct photon which improves the signal over background ratio by
$\sim25%$ as compared to previous studies done in CMS. The inclusion of a large
$\Delta\phi$ cut between the photon and the leading jet at $40^0$ in the
analysis leads to a further increase of $\sim15%$ in S/B, thus giving an
overall gain of $\sim42%$ in S/B ratio.
","The measurement is performed using the data collected by the Compact Muon Solenoid (CMS) experiment during Run 2, corresponding to an integrated luminosity of 35.9 fb$^{-1}$ . The analysis uses events with one photon and two jets where both photons are reconstructed within the barrel calorimeter acceptance, |η| < 1.44. Events are selected requiring that each jet has transverse momentum pT > 30 GeV and pseudorapidity |η| < 4.7. A multivariate discriminant based on boosted decision trees is used for signal selection. The measured cross section as a function of the leading jet pT is compared to theoretical predictions obtained at next-to-leading order accuracy including resummation of soft gluons up to next-to-next-to-leading-logarithmic accuracy. Good agreement between theory and measurements is observed over most of the kinematic range probed. 
 
 Keywords: direct photon, dijet",arxiv,bigscience bloomz,705.274,0.3333333333333333,0.29411764705882354,0.2564102564102564,0.3320592451027234,1,1,0,0,0,1,1,1,0,0,0.10519076141740288,0.08250167125022795,0.08171206225680934,0.05303030303030303,0,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
The First Survey of X-ray Flares from Gamma Ray Bursts Observed by Swift: Spectral Properties and Energetics,"  Observations of gamma ray bursts (GRBs) with Swift produced the initially
surprising result that many bursts have large X-ray flares superimposed on the
underlying afterglow. The flares were sometimes intense, had rapid rise and
decay phases, and occurred late relative to the ``prompt'' phase. Some
remarkable flares are observed with fluence comparable to the prompt GRB
fluence. Many GRBs have several flares, which are sometimes overlapping. Short,
intense, repetitive, and late flaring can be most easily understood within the
context of the standard fireball model with the internal engine that powers the
prompt GRB emission in an active state at late times. However, other models for
flares have been proposed. Flare origin can be investigated by comparing the
flare spectra to that of the afterglow and the initial prompt emission. In this
work, we have analyzed all significant X-ray flares from the first 110 GRBs
observed by Swift. From this sample 33 GRBs were found to have significant
X-ray flares, with 77 flares that were detected above the 3$\sigma$ level. In
addition to temporal analysis presented in a companion paper, a variety of
spectral models have been fit to each flare. In some cases, we find that the
spectral fits favor a Band function model, which is more akin to the prompt
emission than to that of an afterglow. We find that the average fluence of the
flares is 2.4e-7 erg/cm^2/s in the 0.2-10 keV energy band, which is
approximately a factor of ten below the average prompt GRB fluence. These
results, when combined with those presented in the companion paper on temporal
properties of flares, supports the hypothesis that most X-ray flares are
late-time activity of the internal engine that spawned the initial GRB; not an
afterglow related effect.
","We present the first systematic survey of X-ray flares observed in gamma-ray burst (GRB) afterglows with the Swift satellite, which has been operating since 2004. We find that most GRBs show at least one X-ray flare during their prompt or early afterglow phase; we also find that some GRBs have multiple flaring episodes. The majority of these flares are soft, but there is evidence for both hard and very-hard flares as well. In addition to studying individual flares, we examine the spectral properties of all flares combined using time-resolved spectroscopy techniques. Our results indicate that the average spectrum can be described by an absorbed power law model with photon index Γ = 1.6 ± 0.1 and hydrogen column density NH = 2 × 10^22 cm^{-2}. 
 
 Using this best-fit model, we calculate the total energy emitted in each flare over its duration. For the entire sample of flares studied here, we find that the mean fluence of the flares is ~10^-7 ergs/cm^2, while the mean peak luminosity is ~10^45 ergs/s. These values correspond to typical energies released in solar flares.",arxiv,bigscience bloomz,706.1564,0.6666666666666666,0.3445378151260504,0.8564102564102564,0.46679407548972773,1,1,1,0,1,1,1,1,0,0,0.09590088507425135,0.06786991976286713,0.11673151750972763,0.06060606060606061,1,0,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0
"Astrometry with ""Carte du Ciel"" plates, San Fernando zone. I. Digitization and measurement using a flatbed scanner","  We present an original method of digitizing and astrometrically reducing
""Carte du Ciel"" plate material using an inexpensive flatbed scanner, to
demonstrate that for this material there is an alternative to more specialized
measuring machines that are very few in number and thus not readily available.
The sample of plates chosen to develop this method are original ""Carte du Ciel""
plates of the San Fernando zone, photographic material with a mean epoch
1903.6, and a limiting photographic magnitude ~14.5, covering the declination
range of -10 < dec < -2. Digitization has been made using a commercial flatbed
scanner, demonstrating the internal precision that can be attained with such a
device. A variety of post-scan corrections are shown to be necessary. In
particular, the large distortion introduced by the non-uniform action of the
scanner is modelled using multiple scans of each plate. We also tackle the
specific problems associated with the triple-exposure images on some plates and
the grid lines present on all. The final measures are reduced to celestial
coordinates using the Tycho-2 Catalogue. The internal precision obtained over a
single plate, 3microns ~ 0.18"" in each axis, is comparable to what is realized
with similar plate material using slower, less affordable, and less widely
available conventional measuring machines, such as a PDS microdensitometer. The
accuracy attained over large multi-plate areas, employing an overlapping plate
technique, is estimated at 0.2"".
","We present the results obtained in digitizing and measuring astrometrically about 1000 photographic plates taken by the Carte du Ciel project at the Observatorio Astronómico Nacional (OAN), San Pedro Mártir Observatory (SPMO) between 1950 and 1960. The OAN/SPMO is located on Mount Wilson, California, USA. We used a high resolution digital camera to scan these plates and then measured their positions relative to reference stars observed simultaneously on each plate. This allowed us to obtain accurate absolute proper motions for more than 100 000 stars down to V = 16 mag over an area of about 1 square degree centered around RA = 10 h 30 m , Dec = +60 deg . These data are available online through our web site http://obswww.unige.ch/~fuchs/CDCCatastro/Movies/movie1.html .
The accuracy achieved in this work is comparable or better than that reported previously for similar projects based on scanning film material. 


This research was supported by NSF grant AST-0307481.",arxiv,bigscience bloomz,706.19,0.4444444444444444,0.11764705882352941,0.5487179487179488,0.17439082656473961,0,1,0,0,0,1,1,1,0,0,0.14173207990033165,0.05086402098304954,0.13229571984435798,0.09848484848484848,0,1,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,2,0,2,1,1
INTEGRAL high energy monitoring of the X-ray burster KS 1741-293,"  KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module
of the Mir space station and identified as an X-ray burster, has not been
detected in the hard X band until the advent of the INTEGRAL observatory.
Moreover this source has been recently object of scientific discussion, being
also associated to a nearby extended radio source that in principle could be
the supernova remnant produced by the accretion induced collapse in the binary
system. Our long term monitoring with INTEGRAL, covering the period from
February 2003 to May 2005, confirms that KS 1741-293 is transient in soft and
hard X band. When the source is active, from a simultaneous JEM-X and IBIS data
analysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by
a two component model, a multiple blackbody for the soft emission and a
Comptonized or a cut-off power law model for the hard component. Finally, by
the detection of two X-ray bursters with JEM-X, we confirm the bursting nature
of KS 1741-293, including this source in the class of the hard tailed X-ray
bursters.
","We present results on INTEGRAL observations of the X-ray burster (XRB) KS 1741-293, which is located in the globular cluster NGC 6388 at a distance of about 12 kpc. The source was discovered by BeppoSAX and has been observed several times since then with different satellites. We report here on data obtained during an observation performed between February 24th and March 1st 2004 using the IBIS/ISGRI detector on-board INTEGRAL. During this time we detected two bursts from the source. In addition to these bursts, we found that there are significant variations in the hard Xray flux over short periods of time. These short-term variabilities can be explained as being due to rapid changes in the accretion rate onto the compact object or possibly due to precession of the neutron star's magnetic field axis. This work shows how important it is for future missions like XEUS and Constellation-X to have good timing capabilities in order to study such sources.",arxiv,bigscience bloomz,706.0832,0.2222222222222222,0.29411764705882354,0.3333333333333333,0.40659340659340665,0,1,0,0,0,1,1,0,0,1,0.09364918329508518,0.062273390065568736,0.10894941634241245,0.041666666666666664,0,0,3,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Decoherence of a driven multilevel quantum system interacting with a multi-bath reservoir,"  A general theory is presented for the treatment of decoherence of a
multilevel quantum system (with many degrees of freedom) interacting with
multi-bath reservoir and driven by ac fields. In this approach, the system is
described by a reduced density operator and the multi-bath reservoir is
characterized by a number of spectral densities. The reduced density operator
is governed by the master equation in which the effect of ac driving fields and
the leakage to non-computational states are included. The theory is applied to
the study of decoherence of a two-dimensional (2D) SQUID flux qubit coupled to
control and readout circuits. The predicted results are in very good agreement
with available experimental results in the absence of driving fields and with
the analytic results of a dissipative two-level system in the presence of weak
driving fields. The relaxation and decoherence times versus the parameters and
temperature of the control and readout circuits are also explored in details to
facilitate the optimization of the 2D SQUID qubit.
","We study the decoherence dynamics of an open quantum system consisting of two-level atoms coupled to a single-mode cavity field in presence of dissipation and driving fields. The atom-cavity coupling is treated within the framework of Jaynes-Cummings model, while the dissipative effects are described by using the master equation for the reduced density matrix of the system. We show that the steady state solution of this problem can be obtained analytically when the decay rates of all atomic levels are equal. In particular we find that the steady-state entanglement between the atom-field subsystem depends on both the strength of the external driving field as well as the number of excited states involved in the process. Finally, we discuss how our results could be used to explain recent experimental observations concerning the generation of nonclassical light via spontaneous emission processes. PACS numbers: 03.67.Mn, 42.50.Vk",arxiv,bigscience bloomz,705.0995,0.2777777777777778,0.24369747899159663,0.2205128205128205,0.3635929288103201,1,1,0,0,0,0,1,1,0,0,0.03722664429848971,0.07877179008783036,0.042801556420233464,0.06060606060606061,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1
Electrostatic Interactions of Asymmetrically Charged Membranes,"  We predict the nature (attractive or repulsive) and range (exponentially
screened or long-range power law) of the electrostatic interactions of
oppositely charged and planar plates as a function of the salt concentration
and surface charge densities (whose absolute magnitudes are not necessarily
equal). An analytical expression for the crossover between attractive and
repulsive pressure is obtained as a function of the salt concentration. This
condition reduces to the high-salt limit of Parsegian and Gingell where the
interaction is exponentially screened and to the zero salt limit of Lau and
Pincus in which the important length scales are the inter-plate separation and
the Gouy-Chapman length. In the regime of low salt and high surface charges we
predict - for any ratio of the charges on the surfaces - that the attractive
pressure is long-ranged as a function of the spacing. The attractive pressure
is related to the decrease in counter-ion concentration as the inter-plate
distance is decreased. Our theory predicts several scaling regimes with
different scaling expressions for the pressure as function of salinity and
surface charge densities. The pressure predictions can be related to surface
force experiments of oppositely charged surfaces that are prepared by coating
one of the mica surfaces with an oppositely charged polyelectrolyte.
","The electrostatic interactions between two asymmetrically charged membranes are studied by using the mean-field theory and Monte Carlo simulations. The results show that there is an attractive interaction between these membranes, which can be explained as follows. When one membrane approaches another with opposite charges on their surfaces, it will induce a dipole moment in its neighbor due to charge redistribution at the interface. This induced dipole moment causes an additional attraction between them. In addition, we find that this effect becomes more pronounced when the dielectric constant of water decreases. Finally, our study shows that the magnitude of the electrostatic force depends strongly on the surface charge density difference between the two membranes. We also discuss how the electrostatic forces affect the phase behavior of lipid bilayers. DOI: 10.1063/1.3189000
I. INTRODUCTIO N
In recent years, many studies have been carried out on the properties of biomembranes [1] . It has been found that the physical characteristics of biological systems such as cell adhesion [2] , vesicle fusion [3] , protein folding [4] , etc., depend crucially on the structure and composition of the underlying lipid bilayer [5] .
Biological membranes consist mainly of phospholipids [6] . These lipids contain hydrophobic tails and hydrophilic heads [7, 8] . Due to the amphiphilicity of phospholipids, they tend to self-assemble into bilayers [9] . A typical example for such a system is shown schematically in Fig.  1(a) . Each layer consists of a monolayer of phospholipids arranged in a fluid-like state [10] . The thickness of each layer is about 5 nm [11] . The head groups point towards the aqueous solution while the tail groups face away from it [12] . Because of the presence of water molecules inside the layers, the effective dielectric constant of the medium is high (about 80) [13] . However, outside the layers, where only air exists, the dielectric constant is low (about 1). Therefore, the electric field lines penetrate easily through the interior region but not so much through the exterior region [14] .",arxiv,bigscience bloomz,705.0893,0.3333333333333333,0.9495798319327731,0.4256410256410256,0.9254658385093167,1,1,0,0,0,1,1,1,0,0,0.10667630211775406,0.0764476288164662,0.11284046692607004,0.13257575757575757,0,2,3,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1
Trigonometric parallaxes of high velocity halo white dwarf candidates,"  The status of 38 halo white dwarf candidates identified by Oppenheimer et al.
(2001) has been intensively discussed by various authors. In analyses
undertaken to date, trigonometric parallaxes are crucial missing data. Distance
measurements are mandatory to kinematically segregate halo object from disk
objects and hence enable a more reliable estimate of the local density of halo
dark matter residing in such objects.
  We present trigonometric parallax measurements for 15 candidate halo white
dwarfs (WDs) selected from the Oppenheimer et al. (2001) list. We observed the
stars using the ESO 1.56-m Danish Telescope and ESO 2.2-m telescope from August
2001 to July 2004. Parallaxes with accuracies of 1--2 mas were determined
yielding relative errors on distances of $\sim5$% for 6 objects, $\sim12$% for
3 objects, and $\sim20$% for two more objects. Four stars appear to be too
distant (probably farther than 100 pc) to have measurable parallaxes in our
observations. Distances, absolute magnitudes and revised space velocities were
derived for the 15 halo WDs from the Oppenheimer et al. (2001) list. Halo
membership is confirmed unambiguously for 6 objects while 5 objects may be
thick disk members and 4 objects are too distant to draw any conclusion based
solely on kinematics. Comparing our trigonometric parallaxes with photometric
parallaxes used in previous work reveals an overestimation of distance as
derived from photometric techniques. This new data set can be used to revise
the halo white dwarf space density, and that analysis will be presented in a
subsequent publication.
","We report trigonometric parallax measurements for four high proper motion (HPM) white dwarfs with tangential velocities greater than 400 km/sec, and distances between 50 pc to 100 pc. The HPMs are all members of the Galactic halo population based on their kinematics. We find that three out of these four stars have masses less than 0.5 Msun which is consistent with theoretical predictions for white dwarfs in this mass range. However one star has an unexpectedly large mass of 1.1 Msun. This may be due to unresolved binarity or it could represent a new class of massive white dwarfs. These results will help us understand how the Galactic halo formed. 
 
 Keywords: High Proper Motion Stars, White Dwarf, Parallax Measurement, Halo Population 
 
 
 
 INTRODUCTION 
 
 In recent years there has been considerable interest in studying the properties of high proper motion (HPM) white dwarfs because they can provide important information about the formation history of our Galaxy. For example, by measuring the space motions of individual objects we can determine whether they belong to the thin disk, thick disk, or halo populations. Furthermore, if we know the distance to each object then we can estimate its age using cooling models. Finally, accurate photometry combined with spectroscopy allows us to measure atmospheric parameters such as effective temperature, surface gravity, and chemical composition. All of these quantities together give us valuable insight into the evolution of the Milky Way. 
 
 There are several ongoing surveys dedicated to finding HPM white dwarfs including the Palomar Observatory Sky Survey (POSS), SuperCOSMOS Sky Survey (SSS), Sloan Digital Sky Survey (SDSS), UK Schmidt Telescope Photometric H-Alpha Survey (UKSTPHAS), and Panoramic Survey Telescope & Rapid Response System (Pan-STARRS). Most recently, the Catalina Real-Time Transient Survey (CRTS) has discovered more than 1000 HPM white dwarves over the past decade. Many of them were found serendipitously during searches",arxiv,bigscience bloomz,704.0355,0.7222222222222222,0.6470588235294118,0.6358974358974359,0.827998088867654,1,1,0,0,0,1,1,1,0,0,0.09712419032131057,0.11974088470265548,0.10116731517509728,0.14015151515151514,2,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1
Bayesian analysis of the low-resolution polarized 3-year WMAP sky maps,"  We apply a previously developed Gibbs sampling framework to the foreground
corrected 3-yr WMAP polarization data and compute the power spectrum and
residual foreground template amplitude posterior distributions. We first
analyze the co-added Q- and V-band data, and compare our results to the
likelihood code published by the WMAP team. We find good agreement, and thus
verify the numerics and data processing steps of both approaches. However, we
also analyze the Q- and V-bands separately, allowing for non-zero EB
cross-correlations and including two individual foreground template amplitudes
tracing synchrotron and dust emission. In these analyses, we find tentative
evidence of systematics: The foreground tracers correlate with each of the Q-
and V-band sky maps individually, although not with the co-added QV map; there
is a noticeable negative EB cross-correlation at l <~ 16 in the V-band map; and
finally, when relaxing the constraints on EB and BB, noticeable differences are
observed between the marginalized band powers in the Q- and V-bands. Further
studies of these features are imperative, given the importance of the low-l EE
spectrum on the optical depth of reionization tau and the spectral index of
scalar perturbations n_s.
","We present an update on our previous work (Jarosik et al., 2006) where we used Bayesian methods to analyze the polarization data obtained by Wilkinson Microwave Anisotropy Probe (WMAP). We use the same likelihood function as in Jarosik et al. (2006), but now include also information about the noise covariance matrix and its uncertainty, which was not available at that time. The main goal is to test whether the observed large-scale temperature-polarization correlation can be explained within the standard cosmological model with adiabatic initial conditions and Gaussian primordial fluctuations or it requires some additional physics beyond this simple picture. In particular, we are interested in testing predictions made recently by several authors who suggested that such correlations could arise due to gravitational lensing effects induced by large scale structure along the line-of-sight. Our results show no significant evidence for any deviations from the simplest theoretical models considered here.",arxiv,bigscience bloomz,705.3643,0.2777777777777778,0.24369747899159663,0.3487179487179487,0.3779264214046823,0,1,1,0,0,1,1,0,0,0,0.1903488689795187,0.0848015712752979,0.19066147859922178,0.07196969696969698,0,0,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Spitzer spectral line mapping of supernova remnants: I. Basic data and principal component analysis,"  We report the results of spectroscopic mapping observations carried out
toward small (1 x 1 arcmin) regions within the supernova remnants W44, W28,
IC443, and 3C391 using the Infrared Spectrograph of the Spitzer Space
Telescope. These observations, covering the 5.2 - 37 micron spectral region,
have led to the detection of a total of 15 fine structure transitions of Ne+,
Ne++, Si+, P+, S, S++, Cl+, Fe+, and Fe++; the S(0) - S(7) pure rotational
lines of molecular hydrogen; and the R(3) and R(4) transitions of hydrogen
deuteride. In addition to these 25 spectral lines, the 6.2, 7.7, 8.6, 11.3 and
12.6 micron PAH emission bands were also observed. Most of the detected line
transitions have proven strong enough to map in several sources, providing a
comprehensive picture of the relative distribution of the various line
emissions observable in the Spitzer/IRS bandpass. A principal component
analysis of the spectral line maps reveals that the observed emission lines
fall into five distinct groups, each of which may exhibit a distinct spatial
distribution: (1) lines of S and H2 (J > 2); (2) the H2 S(0) line; (3) lines of
ions with appearance potentials less than 13.6 eV; (4) lines of ions with
appearance potentials greater than 13.6 eV, not including S++; (5) lines of
S++. Lines of group (1) likely originate in molecular material subject to a
slow, nondissociative shock that is driven by the overpressure within the
supernova remnant, and lines in groups (3) - (5) are associated primarily with
dissociative shock fronts with a range of (larger) shock velocities. The H2
S(0) line shows a low-density diffuse emission component, and - in some sources
- a shock-excited component.
","We present the first results on Spitzer infrared spectroscopy (IRS) observations of four Galactic supernova remnants, G11.2−0.3, Kes 17, RCW 103, and W44. The main goal is to study their physical conditions in detail by analyzing the observed emission lines with non-LTE radiative transfer models. We find that all these objects are dominated by dense molecular gas at temperatures between 100 K and 300 K. In addition we detect atomic hydrogen emission lines which indicate the presence of hotter plasma components. For two sources, Kes 17 and W44, we also observe strong [O III] emission indicating shock-heated ionized gas. Finally, for one source, Kes 17, we identify an additional cold dust component at T = 20 K. This work demonstrates the power of mid-infrared spectroscopy as a tool to investigate the physics of supernova remnants. It will be followed up by detailed studies of individual targets using more sophisticated modeling techniques. 
 
 Keywords: Supernova Remnant, Mid-Infrared Spectroscopy",arxiv,bigscience bloomz,704.2179,0.3333333333333333,0.29411764705882354,0.8,0.40086000955566176,1,1,1,0,0,1,1,1,0,0,0.24195270022431398,0.09054158504810918,0.23346303501945526,0.07196969696969698,0,1,5,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Uniqueness of polynomial canonical representations,"  Let P(z) and Q(y) be polynomials of the same degree k>=1 in the complex
variables z and y, respectively. In this extended abstract we study the
non-linear functional equation P(z)=Q(y(z)), where y(z) is restricted to be
analytic in a neighborhood of z=0. We provide sufficient conditions to ensure
that all the roots of Q(y) are contained within the range of y(z) as well as to
have y(z)=z as the unique analytic solution of the non-linear equation. Our
results are motivated from uniqueness considerations of polynomial canonical
representations of the phase or amplitude terms of oscillatory integrals
encountered in the asymptotic analysis of the coefficients of mixed powers and
multivariable generating functions via saddle-point methods. Uniqueness shall
prove important for developing algorithms to determine the Taylor coefficients
of the terms appearing in these representations. The uniqueness of Levinson's
polynomial canonical representations of analytic functions in several variables
follows as a corollary of our one-complex variables results.
","We prove that the set of all polynomials in one variable with integer coefficients is uniquely representable as a sum of squares of rational functions, and we give an explicit algorithm for computing such representation.  We also show how to extend this result to multivariate polynomials over finite fields. The problem of representing a given polynomial as a sum of squares (SOS) has been studied extensively since Hilbert's 19th century work on quadratic forms. In particular, it was shown by Artin that every nonnegative integer can be represented as a sum of four squares of integers; see [1] . This theorem implies that any positive integer n can be written as a sum of at most 4 square roots of integers. However, there are infinitely many ways to write each number as a sum of two or three square roots of integers. For example, 1 = 2 + √ 3 , but also 1 = 2 − √ 3 .
The uniqueness question becomes more interesting when restricted to certain classes of polynomials. It turns out that if f ∈ Z[x] is a monic polynomial whose Galois group G(f ) is solvable then f is uniquely representable as SOS [2] . On the other hand, if G(f ) contains a nonsolvable subgroup then f may have several distinct SOS representations [3] .",arxiv,bigscience bloomz,705.2345,0.2777777777777778,0.4453781512605043,0.1641025641025641,0.5900621118012424,1,1,0,0,1,1,0,1,0,1,0.0868671215572484,0.061408892996693075,0.07392996108949416,0.06818181818181818,0,0,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
Off-center HII regions in power-law density distributions,"  The expansion of ionization fronts in uniform and spherically symmetric
power-law density distributions is a well-studied topic. However, in many
situations, such as a star formed at the edge of a molecular cloud core, an
offset power-law density distribution would be more appropriate. In this paper
a few of the main issues of the formation and expansion of HII regions in such
media are outlined and results are presented for the particular cases where the
underlying power laws are 1/r^2 and 1/r^3. A simple criterion is developed for
determining whether the initial photoionized region will be unbounded, which
depends on the power-law exponent and the ratio of the equivalent Stroemgren
radius produced by the star in a uniform medium to the stellar offset distance.
In the expansion stage, the ionized volumes will eventually become unbounded
unless pressure balance with the external medium is reached before the
ionization front velocity becomes supersonic with respect to the ionized gas.
","We present the results of numerical simulations aimed at studying the formation and evolution of off-center ionized hydrogen (HII) regions around massive stars embedded in an isothermal, self-gravitating gas distribution with a power-law density profile.  We find that the expansion velocity of the ionization front decreases as it moves away from the star's position towards larger radii. The decrease occurs because the pressure gradient becomes smaller when moving outward due to the decreasing density. As a result, the ionization front may become unstable against small perturbations which lead to its fragmentation into several blobs or fingers. These blobs are surrounded by dense shells of neutral material produced by photo-evaporation of the surrounding medium. In addition, we show that the mass loss rate increases significantly for large values of the index n of the power law density distribution. This increase can be explained by the fact that the gravitational force per unit volume acting on the shell decreases faster than the ram pressure of the expanding bubble.",arxiv,bigscience bloomz,705.0711,0.2222222222222222,0.29411764705882354,0.17435897435897435,0.4295269947443861,0,1,0,0,0,1,1,0,0,1,0.08698350020535023,0.05600852889988582,0.04669260700389105,0.041666666666666664,0,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0
