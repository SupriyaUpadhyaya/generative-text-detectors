{"prompt": "Rephrase the abstract of an article with title 'The Search for Million Degree Gas Through The NVII Hyperfine Line'.\n  Gas in the million degree range occurs in a variety of astronomical\nenvironments, and it may be the main component of the elusive missing baryons\nat low redshift. The NVII ion is found in this material and it has a hyperfine\nspin-flip transition with a rest frequency of 53.042 GHz, which can be observed\nfor z > 0.1, when it is shifted into a suitably transparent radio band. We used\nthe 42-48 GHz spectrometer on the Green Bank Telescope to search for both\nemission and absorption from this NVII transmission. For absorption studies,\n3C273, 3C 279, 3C 345, and 4C+39.25 were observed but no feature were seen\nabove the 5 sigma level. For emission line studies, we observed Abell 1835,\nAbell 2390 and the star-forming galaxy PKS 1345+12, but no features were seen\nexceeding 5 sigma. We examine whether the strongest emission feature, in Abell\n2390 (3.7 sigma), and the strongest absorption feature, toward 4C+39.25 (3.8\nsigma), might be expected from theoretical models. The emission feature would\nrequire ~1E10 Msolar of 1E6 K gas, which is inconsistent with X-ray limits for\nthe O VII Kalpha line, so it is unlikely to be real. The NVII absorption\nfeature requires a NVII column of 6E16 cm^-2, higher than model predictions by\nat least an order of magnitude, which makes it inconsistent with model\nexpectations. The individual observations were less than 1 hr in length, so for\nlengthy observations, we show that NVII absorption line observations can begin\nto be useful in in the search for hot intergalactic gas.\n\n", "human_text": "  Gas in the million degree range occurs in a variety of astronomical\nenvironments, and it may be the main component of the elusive missing baryons\nat low redshift. The NVII ion is found in this material and it has a hyperfine\nspin-flip transition with a rest frequency of 53.042 GHz, which can be observed\nfor z > 0.1, when it is shifted into a suitably transparent radio band. We used\nthe 42-48 GHz spectrometer on the Green Bank Telescope to search for both\nemission and absorption from this NVII transmission. For absorption studies,\n3C273, 3C 279, 3C 345, and 4C+39.25 were observed but no feature were seen\nabove the 5 sigma level. For emission line studies, we observed Abell 1835,\nAbell 2390 and the star-forming galaxy PKS 1345+12, but no features were seen\nexceeding 5 sigma. We examine whether the strongest emission feature, in Abell\n2390 (3.7 sigma), and the strongest absorption feature, toward 4C+39.25 (3.8\nsigma), might be expected from theoretical models. The emission feature would\nrequire ~1E10 Msolar of 1E6 K gas, which is inconsistent with X-ray limits for\nthe O VII Kalpha line, so it is unlikely to be real. The NVII absorption\nfeature requires a NVII column of 6E16 cm^-2, higher than model predictions by\nat least an order of magnitude, which makes it inconsistent with model\nexpectations. The individual observations were less than 1 hr in length, so for\nlengthy observations, we show that NVII absorption line observations can begin\nto be useful in in the search for hot intergalactic gas.\n", "machine_text": "\nWe present the results from using the a 42-48 GHz spectrometer on the Green Bank Telescope to observe the NVII hyperfine spin-flip transition with a rest frequency of 53.042 GHz in an effort to search for million degree gas in astrophysical environments. This transition can be observed for redshifts larger than 0.1, when shifted into a suitable transparent radio band. We observed 3C273, 3C 279, 3C 345, and 4C+39.25 for absorption studies, as well as Abell 1835, Abell 2390 and PKS 1345+12 in emission line studies, with no evidence seen above the 5 sigma confidence level. Analysis of the strongest emission and absorption features, seen in Abell 2390 (3.7 sigma) and 4C+39.25 (3.8 sigma) respectively, lead to the conclusion that these features are unlikely to be real. With longer observations, NVII absorption line studies may become a valuable tool in the search for hot intergalactic gas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2242}
{"prompt": "Rephrase the abstract of an article with title 'Cranked Hartree-Fock-Bogoliubov Calculation for Rotating Bose-Einstein\n  Condensates'.\n  A rotating bosonic many-body system in a harmonic trap is studied with the\n3D-Cranked Hartree-Fock-Bogoliubov method at zero temperature, which has been\napplied to nuclear many-body systems at high spin. This method is a variational\nmethod extended from the Hartree-Fock theory, which can treat the pairing\ncorrelations in a self-consistent manner. An advantage of this method is that a\nfinite-range interaction between constituent particles can be used in the\ncalculation, unlike the original Gross-Pitaevskii approach. To demonstrate the\nvalidity of our method, we present a calculation for a toy model, that is, a\nrotating system of ten bosonic particles interacting through the repulsive\nquadrupole-quadrupole interaction in a harmonic trap. It is found that the\nyrast states, the lowest-energy states for the given total angular momentum,\ndoes not correspond to the Bose-Einstein condensate, except a few special\ncases. One of such cases is a vortex state, which appears when the total\nangular momentum $L$ is twice the particle number $N$ (i.e., $L=2N$).\n\n", "human_text": "  A rotating bosonic many-body system in a harmonic trap is studied with the\n3D-Cranked Hartree-Fock-Bogoliubov method at zero temperature, which has been\napplied to nuclear many-body systems at high spin. This method is a variational\nmethod extended from the Hartree-Fock theory, which can treat the pairing\ncorrelations in a self-consistent manner. An advantage of this method is that a\nfinite-range interaction between constituent particles can be used in the\ncalculation, unlike the original Gross-Pitaevskii approach. To demonstrate the\nvalidity of our method, we present a calculation for a toy model, that is, a\nrotating system of ten bosonic particles interacting through the repulsive\nquadrupole-quadrupole interaction in a harmonic trap. It is found that the\nyrast states, the lowest-energy states for the given total angular momentum,\ndoes not correspond to the Bose-Einstein condensate, except a few special\ncases. One of such cases is a vortex state, which appears when the total\nangular momentum $L$ is twice the particle number $N$ (i.e., $L=2N$).\n", "machine_text": "\nThis paper presents a study of a rotationally driven system of many-body bosons in a harmonic trap. The calculation was accomplished using the 3D-Cranked Hartree-Fock-Bogoliubov (HF-B) method, which is an extended variational approach that incorporates pairing correlations. Unlike the original Gross-Pitaevskii theory, this method can incorporate finite-range interactions between particles. As an example, a system of ten bosons interacting with a repulsive quadrupole-quadrupole force was used to demonstrate the validity of our method. The results showed that the yrast states, or lowest-energy states for a given total angular momentum, do not generally form a Bose-Einstein condensate, but rather a vortex state when the total angular momentum ($L$) is twice the particle number ($N$), i.e. $L=2N$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0196}
{"prompt": "Rephrase the abstract of an article with title 'The VVDS type-1 AGN sample: The faint end of the luminosity function'.\n  In a previous paper (Gavignaud et al. 2006), we presented the type-1 Active\nGalactic Nuclei (AGN) sample obtained from the first epoch data of the\nVIMOS-VLT Deep Survey (VVDS). The sample consists of 130 faint, broad-line AGN\nwith redshift up to z=5 and 17.5< I <24.0, selected on the basis of their\nspectra. In this paper we present the measurement of the Optical Luminosity\nFunction up to z=3.6 derived from this sample, we compare our results with\nprevious results from brighter samples both at low and at high redshift. Our\ndata, more than one magnitude fainter than previous optical surveys, allow us\nto constrain the faint part of the luminosity function up to high redshift. By\ncombining our faint VVDS sample with the large sample of bright AGN extracted\nfrom the SDSS DR3 (Richards et al., 2006b) and testing a number of different\nevolutionary models, we find that the model which better represents the\ncombined luminosity functions, over a wide range of redshift and luminosity, is\na luminosity dependent density evolution (LDDE) model, similar to those derived\nfrom the major X-surveys. Such a parameterization allows the redshift of the\nAGN space density peak to change as a function of luminosity and explains the\nexcess of faint AGN that we find at 1.0< z <1.5. On the basis of this model we\nfind, for the first time from the analysis of optically selected samples, that\nthe peak of the AGN space density shifts significantly towards lower redshift\ngoing to lower luminosity objects. This result, already found in a number of\nX-ray selected samples of AGN, is consistent with a scenario of \"AGN cosmic\ndownsizing\", in which the density of more luminous AGN, possibly associated to\nmore massive black holes, peaks earlier in the history of the Universe, than\nthat of low luminosity ones.\n\n", "human_text": "  In a previous paper (Gavignaud et al. 2006), we presented the type-1 Active\nGalactic Nuclei (AGN) sample obtained from the first epoch data of the\nVIMOS-VLT Deep Survey (VVDS). The sample consists of 130 faint, broad-line AGN\nwith redshift up to z=5 and 17.5< I <24.0, selected on the basis of their\nspectra. In this paper we present the measurement of the Optical Luminosity\nFunction up to z=3.6 derived from this sample, we compare our results with\nprevious results from brighter samples both at low and at high redshift. Our\ndata, more than one magnitude fainter than previous optical surveys, allow us\nto constrain the faint part of the luminosity function up to high redshift. By\ncombining our faint VVDS sample with the large sample of bright AGN extracted\nfrom the SDSS DR3 (Richards et al., 2006b) and testing a number of different\nevolutionary models, we find that the model which better represents the\ncombined luminosity functions, over a wide range of redshift and luminosity, is\na luminosity dependent density evolution (LDDE) model, similar to those derived\nfrom the major X-surveys. Such a parameterization allows the redshift of the\nAGN space density peak to change as a function of luminosity and explains the\nexcess of faint AGN that we find at 1.0< z <1.5. On the basis of this model we\nfind, for the first time from the analysis of optically selected samples, that\nthe peak of the AGN space density shifts significantly towards lower redshift\ngoing to lower luminosity objects. This result, already found in a number of\nX-ray selected samples of AGN, is consistent with a scenario of \"AGN cosmic\ndownsizing\", in which the density of more luminous AGN, possibly associated to\nmore massive black holes, peaks earlier in the history of the Universe, than\nthat of low luminosity ones.\n", "machine_text": "\nIn this paper, we analyze an AGN sample obtained from the first epoch VVDS survey. This sample is comprised of 130 faint, broad-line AGN with redshift up to z=5 and 17.5 < I< 24, and has allowed us to measure the Optical Luminosity Function up to z=3.6. We compare our results to previous literature and find that the model which best fits the combined luminosity functions is a Luminosity Dependent Density Evolution (LDDE) model, similar to the one derived from X-ray surveys. For the first time in an optical sample, we observe a \"cosmic downsizing\" phenomena, in which the AGN density peaks at lower redshift for lower luminosity objects. This supports the idea that more luminous AGN are linked to more massive black holes and peaked earlier in the Universe's evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.166}
{"prompt": "Rephrase the abstract of an article with title 'Experimental studies on vacancy induced ferromagnetism in undoped TiO2'.\n  Room temperature ferromagnetism is observed in undoped TiO2 films deposited\non Si substrates using pulsed laser deposition (PLD). The ferromagnetic\nproperties of the samples depend on the oxygen partial pressure during the PLD\nsynthesis. The appearance of higher binding energy component (HBEC) in the\noxygen 1s core peak from x-ray photoelectron spectroscopy (XPS) suggests the\npresence of oxygen vacancies in these samples. The amount of oxygen during the\nsynthesis determines the vacancy concentration in the samples which is directly\nrelated to the magnetic behavior of the samples. The magnetic moment decreases\nwith oxygen vacancy concentration in the samples. Valence band measurements\nwere performed to study the electronic structure of both stoichometric and\nreduced TiO2. The analyses show the presence of Ti 3d band near the Fermi level\nin reduced TiO2 samples. These bands are otherwise empty in stoichiometric TiO2\nand reside in the conduction band which makes them unobservable by XPS. The\nexistence of this Ti 3d band near the Fermi level can possibly lead to Stoner\nsplitting of the band.\n\n", "human_text": "  Room temperature ferromagnetism is observed in undoped TiO2 films deposited\non Si substrates using pulsed laser deposition (PLD). The ferromagnetic\nproperties of the samples depend on the oxygen partial pressure during the PLD\nsynthesis. The appearance of higher binding energy component (HBEC) in the\noxygen 1s core peak from x-ray photoelectron spectroscopy (XPS) suggests the\npresence of oxygen vacancies in these samples. The amount of oxygen during the\nsynthesis determines the vacancy concentration in the samples which is directly\nrelated to the magnetic behavior of the samples. The magnetic moment decreases\nwith oxygen vacancy concentration in the samples. Valence band measurements\nwere performed to study the electronic structure of both stoichometric and\nreduced TiO2. The analyses show the presence of Ti 3d band near the Fermi level\nin reduced TiO2 samples. These bands are otherwise empty in stoichiometric TiO2\nand reside in the conduction band which makes them unobservable by XPS. The\nexistence of this Ti 3d band near the Fermi level can possibly lead to Stoner\nsplitting of the band.\n", "machine_text": "This work highlights the experimental studies on the impact of oxygen vacancies on the induced ferromagnetism in undoped TiO2 thin films. Pulsed laser deposition is used to deposit the thin films on Si substrates with different oxygen partial pressures, controlling the oxygen vacancy concentrations. As the vacancy concentration increases, the magnetic moment of the samples decreases. Through X-ray photoelectron spectroscopy, the presence of higher binding energy component is observed, suggesting the presence of oxygen vacancies in the samples. Valence band measurements were used to examine the electronic structure of both stoichiometric and reduced TiO2 thin films. These measurements indicate the presence of Ti 3d bands in the vicinity of the Fermi level which provides the basis for Stoner splitting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2621}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of Ultra-Low Potassium Contaminations with Accelerator Mass\n  Spectrometry'.\n  Levels of trace radiopurity in active detector materials is a subject of\nmajor concern in low-background experiments. Among the radio-isotopes, $\\k40$\nis one of the most abundant and yet whose signatures are difficult to reject.\nProcedures were devised to measure trace potassium concentrations in the\ninorganic salt CsI as well as in organic liquid scintillator (LS) with\nAccelerator Mass Spectrometry (AMS), giving, respectively, the\n$\\k40$-contamination levels of $\\sim 10^{-10}$ and $\\sim 10^{-13}$ g/g.\nMeasurement flexibilities and sensitivities are improved over conventional\nmethods. The projected limiting sensitivities if no excess of potassium signals\nhad been observed over background are $8 \\times 10^{-13}$ g/g and $3 \\times\n10^{-17}$ g/g for the CsI and LS, respectively. Studies of the LS samples\nindicate that the radioactive contaminations come mainly in the dye solutes,\nwhile the base solvents are orders of magnitude cleaner. The work demonstrate\nthe possibilities of measuring naturally-occurring isotopes with the AMS\ntechniques.\n\n", "human_text": "  Levels of trace radiopurity in active detector materials is a subject of\nmajor concern in low-background experiments. Among the radio-isotopes, $\\k40$\nis one of the most abundant and yet whose signatures are difficult to reject.\nProcedures were devised to measure trace potassium concentrations in the\ninorganic salt CsI as well as in organic liquid scintillator (LS) with\nAccelerator Mass Spectrometry (AMS), giving, respectively, the\n$\\k40$-contamination levels of $\\sim 10^{-10}$ and $\\sim 10^{-13}$ g/g.\nMeasurement flexibilities and sensitivities are improved over conventional\nmethods. The projected limiting sensitivities if no excess of potassium signals\nhad been observed over background are $8 \\times 10^{-13}$ g/g and $3 \\times\n10^{-17}$ g/g for the CsI and LS, respectively. Studies of the LS samples\nindicate that the radioactive contaminations come mainly in the dye solutes,\nwhile the base solvents are orders of magnitude cleaner. The work demonstrate\nthe possibilities of measuring naturally-occurring isotopes with the AMS\ntechniques.\n", "machine_text": "\nThe present study explores the use of Accelerator Mass Spectrometry (AMS) to detect ultra-low levels of potassium contamination in an inorganic salt (CsI) and an organic liquid scintillator (LS). Results show trace amounts of $\\k40$ in both samples, at concentrations of $\\sim 10^{-10}$ g/g and $\\sim 10^{-13}$ g/g respectively. The use of these techniques has improved the sensitivity and measurement of potassium contamination, with projected limits of $8 \\times 10^{-13}$ g/g and $3 \\times10^{-17}$ g/g for CsI and LS samples respectively. In addition, analysis of the LS samples revealed that the majority of the radioactive components came from the dye solutes present in the liquid scintillator, indicated by concentrations orders of magnitude higher than those in the base solvents. The results illustrate the effectiveness of AMS for measuring naturally-occurring isotopes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0059}
{"prompt": "Rephrase the abstract of an article with title 'Optical Transitions in New Trends Organic Materials'.\n  The PTCDA (3,4,9,10-Perylene-tetracarboxylic dianhydride) and the NTCDA\n(1,4,5,8-Naphtalenetetracarboxylic dianhydride) are aromatic, stable, planar\nand highly symmetric with unusual electrical properties. The PTCDA is a\nsemiconductor organic crystalline of particular interest due to its excellent\nproperties and electronic potential that are used in optoelectronic devices and\nthe NTCDA it is monoclinic and its space group is similar to that of the PTCDA.\nRecently, alternate layers of PTCDA and NTCDA were growth forming multiple\nstructures of quantum wells showing a new class of materials with new optic\nlineal properties. Some have assured that their big utilities would be centered\nin the construction of diodes and of possible guides of waves. We have carried\nout calculations semi-empirical of the electronic structures and of optic\nproperties of the PTCDA and of the NTCDA that show us that they are structures\nhighly orderly polymeric, semiconductors in a negative load state (charge\nstate= -2)\n\n", "human_text": "  The PTCDA (3,4,9,10-Perylene-tetracarboxylic dianhydride) and the NTCDA\n(1,4,5,8-Naphtalenetetracarboxylic dianhydride) are aromatic, stable, planar\nand highly symmetric with unusual electrical properties. The PTCDA is a\nsemiconductor organic crystalline of particular interest due to its excellent\nproperties and electronic potential that are used in optoelectronic devices and\nthe NTCDA it is monoclinic and its space group is similar to that of the PTCDA.\nRecently, alternate layers of PTCDA and NTCDA were growth forming multiple\nstructures of quantum wells showing a new class of materials with new optic\nlineal properties. Some have assured that their big utilities would be centered\nin the construction of diodes and of possible guides of waves. We have carried\nout calculations semi-empirical of the electronic structures and of optic\nproperties of the PTCDA and of the NTCDA that show us that they are structures\nhighly orderly polymeric, semiconductors in a negative load state (charge\nstate= -2)\n", "machine_text": "\nThis study investigates the structure, electronic, and optical properties of organic crystals, specifically the PTCDA (3,4,9,10-Perylene-tetracarboxylic dianhydride) and NTCDA (1,4,5,8-Naphtalenetetracarboxylic dianhydride). These aromatic compounds are stable, planar, and highly symmetrical and exhibit interesting properties useful in optoelectronic devices. Alternate layers of PTCDA and NTCDA grown together have created new structures with increased optical lineal properties. Subsequent semi-empirical calculations of this new material's electronic structures and optical properties showed them to be highly organized polymeric semiconductors in a negative charge state (-2). These results suggest the potential of these structures for use in devices such as diode waveguides.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3965}
{"prompt": "Rephrase the abstract of an article with title 'Domain wall switching: optimizing the energy landscape'.\n  It has recently been suggested that exchange spring media offer a way to\nincrease media density without causing thermal instability\n(superparamagnetism), by using a hard and a soft layer coupled by exchange.\nVictora has suggested a figure of merit xi = 2 E_b/mu_0 m_s H_sw, the ratio of\nthe energy barrier to that of a Stoner-Wohlfarth system with the same switching\nfield, which is 1 for a Stoner-Wohlfarth (coherently switching) particle and 2\nfor an optimal two-layer composite medium. A number of theoretical approaches\nhave been used for this problem (e.g., various numbers of coupled\nStoner-Wohlfarth layers and continuum micromagnetics). In this paper we show\nthat many of these approaches can be regarded as special cases or\napproximations to a variational formulation of the problem, in which the energy\nis minimized for fixed magnetization. The results can be easily visualized in\nterms of a plot of the energy as a function of magnetic moment m_z, in which\nboth the switching field [the maximum slope of E(m_z)] and the stability\n(determined by the energy barrier E_b) are geometrically visible. In this\nformulation we can prove a rigorous limit on the figure of merit xi, which can\nbe no higher than 4. We also show that a quadratic anistropy suggested by Suess\net al comes very close to this limit.\n\n", "human_text": "  It has recently been suggested that exchange spring media offer a way to\nincrease media density without causing thermal instability\n(superparamagnetism), by using a hard and a soft layer coupled by exchange.\nVictora has suggested a figure of merit xi = 2 E_b/mu_0 m_s H_sw, the ratio of\nthe energy barrier to that of a Stoner-Wohlfarth system with the same switching\nfield, which is 1 for a Stoner-Wohlfarth (coherently switching) particle and 2\nfor an optimal two-layer composite medium. A number of theoretical approaches\nhave been used for this problem (e.g., various numbers of coupled\nStoner-Wohlfarth layers and continuum micromagnetics). In this paper we show\nthat many of these approaches can be regarded as special cases or\napproximations to a variational formulation of the problem, in which the energy\nis minimized for fixed magnetization. The results can be easily visualized in\nterms of a plot of the energy as a function of magnetic moment m_z, in which\nboth the switching field [the maximum slope of E(m_z)] and the stability\n(determined by the energy barrier E_b) are geometrically visible. In this\nformulation we can prove a rigorous limit on the figure of merit xi, which can\nbe no higher than 4. We also show that a quadratic anistropy suggested by Suess\net al comes very close to this limit.\n", "machine_text": "This article examines the optimization of the energy landscape domain wall switching. Various approaches such as the use of multiple Stoner-Wohlfarth layers and continuum micromagnetics have been explored, with the end goal of minimizing the energy for concentration of magnetization. The stability and switching field are both important factors in reaching optimal results, as illustrated in a visualized plot of the energy depending on the value of the magnetic moment m_z. It is calculated that the potential figure of merit xi can reach no higher than 4. There is evidence of a quadratical anisotropic parameter that is proposed by Suess et al which was found to reach this limit.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0913}
{"prompt": "Rephrase the abstract of an article with title 'GRI: The Gamma-Ray Imager mission'.\n  With the INTEGRAL observatory, ESA has provided a unique tool to the\nastronomical community revealing hundreds of sources, new classes of objects,\nextraordinary views of antimatter annihilation in our Galaxy, and fingerprints\nof recent nucleosynthesis processes. While INTEGRAL provides the global\noverview over the soft gamma-ray sky, there is a growing need to perform\ndeeper, more focused investigations of gamma-ray sources. In soft X-rays a\ncomparable step was taken going from the Einstein and the EXOSAT satellites to\nthe Chandra and XMM/Newton observatories. Technological advances in the past\nyears in the domain of gamma-ray focusing using Laue diffraction have paved the\nway towards a new gamma-ray mission, providing major improvements regarding\nsensitivity and angular resolution. Such a future Gamma-Ray Imager will allow\nstudies of particle acceleration processes and explosion physics in\nunprecedented detail, providing essential clues on the innermost nature of the\nmost violent and most energetic processes in the Universe.\n\n", "human_text": "  With the INTEGRAL observatory, ESA has provided a unique tool to the\nastronomical community revealing hundreds of sources, new classes of objects,\nextraordinary views of antimatter annihilation in our Galaxy, and fingerprints\nof recent nucleosynthesis processes. While INTEGRAL provides the global\noverview over the soft gamma-ray sky, there is a growing need to perform\ndeeper, more focused investigations of gamma-ray sources. In soft X-rays a\ncomparable step was taken going from the Einstein and the EXOSAT satellites to\nthe Chandra and XMM/Newton observatories. Technological advances in the past\nyears in the domain of gamma-ray focusing using Laue diffraction have paved the\nway towards a new gamma-ray mission, providing major improvements regarding\nsensitivity and angular resolution. Such a future Gamma-Ray Imager will allow\nstudies of particle acceleration processes and explosion physics in\nunprecedented detail, providing essential clues on the innermost nature of the\nmost violent and most energetic processes in the Universe.\n", "machine_text": "The Gamma-Ray Imager (GRI) mission promises to take a major leap forward in gamma-ray observation, allowing for a deeper and more focused view of sources than ever before. Developments in Laue diffraction have enabled increased sensitivity and angular clarity, making it possible to investigate particle acceleration and explosion physics with unprecedented detail. This will be of immeasurable value in understanding the energetic and violent processes of the Universe.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1754}
{"prompt": "Rephrase the abstract of an article with title 'Validating module network learning algorithms using simulated data'.\n  In recent years, several authors have used probabilistic graphical models to\nlearn expression modules and their regulatory programs from gene expression\ndata. Here, we demonstrate the use of the synthetic data generator SynTReN for\nthe purpose of testing and comparing module network learning algorithms. We\nintroduce a software package for learning module networks, called LeMoNe, which\nincorporates a novel strategy for learning regulatory programs. Novelties\ninclude the use of a bottom-up Bayesian hierarchical clustering to construct\nthe regulatory programs, and the use of a conditional entropy measure to assign\nregulators to the regulation program nodes. Using SynTReN data, we test the\nperformance of LeMoNe in a completely controlled situation and assess the\neffect of the methodological changes we made with respect to an existing\nsoftware package, namely Genomica. Additionally, we assess the effect of\nvarious parameters, such as the size of the data set and the amount of noise,\non the inference performance. Overall, application of Genomica and LeMoNe to\nsimulated data sets gave comparable results. However, LeMoNe offers some\nadvantages, one of them being that the learning process is considerably faster\nfor larger data sets. Additionally, we show that the location of the regulators\nin the LeMoNe regulation programs and their conditional entropy may be used to\nprioritize regulators for functional validation, and that the combination of\nthe bottom-up clustering strategy with the conditional entropy-based assignment\nof regulators improves the handling of missing or hidden regulators.\n\n", "human_text": "  In recent years, several authors have used probabilistic graphical models to\nlearn expression modules and their regulatory programs from gene expression\ndata. Here, we demonstrate the use of the synthetic data generator SynTReN for\nthe purpose of testing and comparing module network learning algorithms. We\nintroduce a software package for learning module networks, called LeMoNe, which\nincorporates a novel strategy for learning regulatory programs. Novelties\ninclude the use of a bottom-up Bayesian hierarchical clustering to construct\nthe regulatory programs, and the use of a conditional entropy measure to assign\nregulators to the regulation program nodes. Using SynTReN data, we test the\nperformance of LeMoNe in a completely controlled situation and assess the\neffect of the methodological changes we made with respect to an existing\nsoftware package, namely Genomica. Additionally, we assess the effect of\nvarious parameters, such as the size of the data set and the amount of noise,\non the inference performance. Overall, application of Genomica and LeMoNe to\nsimulated data sets gave comparable results. However, LeMoNe offers some\nadvantages, one of them being that the learning process is considerably faster\nfor larger data sets. Additionally, we show that the location of the regulators\nin the LeMoNe regulation programs and their conditional entropy may be used to\nprioritize regulators for functional validation, and that the combination of\nthe bottom-up clustering strategy with the conditional entropy-based assignment\nof regulators improves the handling of missing or hidden regulators.\n", "machine_text": "\nThis study demonstrated the capacity of the synthetic data generator SynTReN to validate and compare algorithms for learning expression module networks. We proposed a new software, titled LeMoNe, for module network learning that utilizes a bottom-up Bayesian hierarchical clustering process to build regulatory programs, and a conditional entropy measure to assign regulators to program nodes. Testing with simulated data sets enabled us to assess the potentials of Genomica and LeMoNe and the effects of various parameters, like dataset size and noise, on their performance. Despite some discrepancies, both algorithms generated similar outcomes and LeMoNe is significantly faster with large datasets. Further, we showed that the regulation program inferring regulators through LeMoNe's conditional entropy metric could be used to prioritize regulators for further validational tests and that the combination of the clustering strategy and the entropy-based assignment method is effective in identifying missing or hidden regulators.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0666}
{"prompt": "Rephrase the abstract of an article with title 'Visible spectroscopic and photometric survey of Jupiter Trojans: final\n  results on dynamical families'.\n  We present the results of a visible spectroscopic and photometric survey of\nJupiter Trojans belonging to different dynamical families carried out at the\nESO-NTT telescope. We obtained data on 47 objects, 23 belonging to the L5 swarm\nand 24 to the L4 one. These data together with those already published by\nFornasier et al. (2004a) and Dotto et al. (2006), constitute a total sample of\nvisible spectra for 80 objects. The survey allows us to investigate six\nfamilies (Aneas, Anchises, Misenus, Phereclos, Sarpedon, Panthoos) in the L5\ncloud and four L4 families (Eurybates, Menelaus, 1986 WD and 1986 TS6). The\nsample that we measured is dominated by D--type asteroids, with the exception\nof the Eurybates family in the L4 swarm, where there is a dominance of C- and\nP-type asteroids. All the spectra that we obtained are featureless with the\nexception of some Eurybates members, where a drop--off of the reflectance is\ndetected shortward of 5200 A. Similar features are seen in main belt C-type\nasteroids and commonly attributed to the intervalence charge transfer\ntransition in oxidized iron. Our sample comprises fainter and smaller Trojans\nas compared to the literature's data and allows us to investigate the\nproperties of objects with estimated diameter smaller than 40--50 km. The\nanalysis of the spectral slopes and colors versus the estimated diameters shows\nthat the blue and red objects have indistinguishable size distribution. We\nperform a statistical investigation of the Trojans's spectra property\ndistributions as a function of their orbital and physical parameters, and in\ncomparison with other classes of minor bodies in the outer Solar System.\nTrojans at lower inclination appear significantly bluer than those at higher\ninclination, but this effect is strongly driven by the Eurybates family.\n\n", "human_text": "  We present the results of a visible spectroscopic and photometric survey of\nJupiter Trojans belonging to different dynamical families carried out at the\nESO-NTT telescope. We obtained data on 47 objects, 23 belonging to the L5 swarm\nand 24 to the L4 one. These data together with those already published by\nFornasier et al. (2004a) and Dotto et al. (2006), constitute a total sample of\nvisible spectra for 80 objects. The survey allows us to investigate six\nfamilies (Aneas, Anchises, Misenus, Phereclos, Sarpedon, Panthoos) in the L5\ncloud and four L4 families (Eurybates, Menelaus, 1986 WD and 1986 TS6). The\nsample that we measured is dominated by D--type asteroids, with the exception\nof the Eurybates family in the L4 swarm, where there is a dominance of C- and\nP-type asteroids. All the spectra that we obtained are featureless with the\nexception of some Eurybates members, where a drop--off of the reflectance is\ndetected shortward of 5200 A. Similar features are seen in main belt C-type\nasteroids and commonly attributed to the intervalence charge transfer\ntransition in oxidized iron. Our sample comprises fainter and smaller Trojans\nas compared to the literature's data and allows us to investigate the\nproperties of objects with estimated diameter smaller than 40--50 km. The\nanalysis of the spectral slopes and colors versus the estimated diameters shows\nthat the blue and red objects have indistinguishable size distribution. We\nperform a statistical investigation of the Trojans's spectra property\ndistributions as a function of their orbital and physical parameters, and in\ncomparison with other classes of minor bodies in the outer Solar System.\nTrojans at lower inclination appear significantly bluer than those at higher\ninclination, but this effect is strongly driven by the Eurybates family.\n", "machine_text": "\nWe present the findings for a visible spectroscopic and photometric examination of Jupiter Trojans associated with different dynamical families conducted at the ESO-NTT telescope. The survey includes data on 47 objects - 23 in the L5 swarm and 24 in the L4 swarm - in addition to already published Fornasier et al. (2004a) and Dotto et al. (2006) survey data, giving a total of 80 surveyed objects. Our sample reflects a dominance of D-type asteroids, with the exception of the Eurybates family in the L4 swarm which consists mostly of C- and P-type asteroids. Some Eurybates members were identified as having a dropoff in reflectance shortward of 5200A, a phenomenon seen in main belt C-type asteroids and attributed to the intervalence charge transfer transition in oxidized iron. The sample was found to include fainter and smaller Trojans and enabled the investigation of asteroids with diameters of 40-50km and less. The analysis of spectral slopes, colors and diameters showed no difference between blue and red objects. A statistical evaluation of the distributions based on the Trojans' physical and orbital parameters was conducted, as well as a comparison to other classes of minor bodies in the outer Solar System. The results revealed that Trojans at lower inclinations tend to be bluer than those at higher inclinations, mainly due to the dominance of the Eurybates family.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.035}
{"prompt": "Rephrase the abstract of an article with title 'Cosmology from String Theory'.\n  We explore the cosmological content of Salam-Sezgin six dimensional\nsupergravity, and find a solution to the field equations in qualitative\nagreement with observation of distant supernovae, primordial nucleosynthesis\nabundances, and recent measurements of the cosmic microwave background. The\ncarrier of the acceleration in the present de Sitter epoch is a quintessence\nfield slowly rolling down its exponential potential. Intrinsic to this model is\na second modulus which is automatically stabilized and acts as a source of cold\ndark matter with a mass proportional to an exponential function of the\nquintessence field (hence realizing VAMP models within a String context).\nHowever, any attempt to saturate the present cold dark matter component in this\nmanner leads to unacceptable deviations from cosmological data -- a numerical\nstudy reveals that this source can account for up to about 7% of the total cold\ndark matter budget. We also show that (1) the model will support a de Sitter\nenergy in agreement with observation at the expense of a miniscule breaking of\nsupersymmetry in the compact space; (2) variations in the fine structure\nconstant are controlled by the stabilized modulus and are negligible; (3)\n``fifth''forces are carried by the stabilized modulus and are short range; (4)\nthe long time behavior of the model in four dimensions is that of a\nRobertson-Walker universe with a constant expansion rate (w = -1/3). Finally,\nwe present a String theory background by lifting our six dimensional\ncosmological solution to ten dimensions.\n\n", "human_text": "  We explore the cosmological content of Salam-Sezgin six dimensional\nsupergravity, and find a solution to the field equations in qualitative\nagreement with observation of distant supernovae, primordial nucleosynthesis\nabundances, and recent measurements of the cosmic microwave background. The\ncarrier of the acceleration in the present de Sitter epoch is a quintessence\nfield slowly rolling down its exponential potential. Intrinsic to this model is\na second modulus which is automatically stabilized and acts as a source of cold\ndark matter with a mass proportional to an exponential function of the\nquintessence field (hence realizing VAMP models within a String context).\nHowever, any attempt to saturate the present cold dark matter component in this\nmanner leads to unacceptable deviations from cosmological data -- a numerical\nstudy reveals that this source can account for up to about 7% of the total cold\ndark matter budget. We also show that (1) the model will support a de Sitter\nenergy in agreement with observation at the expense of a miniscule breaking of\nsupersymmetry in the compact space; (2) variations in the fine structure\nconstant are controlled by the stabilized modulus and are negligible; (3)\n``fifth''forces are carried by the stabilized modulus and are short range; (4)\nthe long time behavior of the model in four dimensions is that of a\nRobertson-Walker universe with a constant expansion rate (w = -1/3). Finally,\nwe present a String theory background by lifting our six dimensional\ncosmological solution to ten dimensions.\n", "machine_text": "\nWe examine the implications of string theory on the cosmological landscape, particularly the solutions that can be found to the field equations in the Salam-Sezgind six-dimensional supergravity. This models complements our observations of distant supernovae, primordial nucleosynthesis abundance and recent measurements of cosmic microwave background. We find that a quintessence field slowly rolling down its exponential potential is the driving force behind the present day de Sitter epoch. Additionally, a second modulus is a source of cold dark matter, which when fully saturated, leads to unacceptable deviations from cosmological data. Numerical studies show this can account for up to 7% of total cold dark matter. Further components of this model are de Sitter energy that is consistent with observation, variations in fine structure constant that are negligible, fifth-forces that are short-ranged and a Robertson-Walker universe with a steady expansion rate. We demonstrate all this can be seen in a ten-dimensional String theory context.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0928}
{"prompt": "Rephrase the abstract of an article with title 'BEC-BCS Crossover of a Trapped Two-Component Fermi Gas with Unequal\n  Masses'.\n  We determine the energetically lowest lying states in the BEC-BCS crossover\nregime of s-wave interacting two-component Fermi gases under harmonic\nconfinement by solving the many-body Schrodinger equation using two distinct\napproaches. Essentially exact basis set expansion techniques are applied to\ndetermine the energy spectrum of systems with N=4 fermions. Fixed-node\ndiffusion Monte Carlo methods are applied to systems with up to N=20 fermions,\nand a discussion of different guiding functions used in the Monte Carlo\napproach to impose the proper symmetry of the fermionic system is presented.\nThe energies are calculated as a function of the s-wave scattering length a_s\nfor N=2-20 fermions and different mass ratios \\kappa of the two species. On the\nBEC and BCS sides, our energies agree with analytically-determined first-order\ncorrection terms. We extract the scattering length and the effective range of\nthe dimer-dimer system up to \\kappa = 20. Our energies for the\nstrongly-interacting trapped system in the unitarity regime show no shell\nstructure, and are well described by a simple expression, whose functional form\ncan be derived using the local density approximation, with one or two\nparameters. The universal parameter \\xi for the trapped system for various\n\\kappa is determined, and comparisons with results for the homogeneous system\nare presented.\n\n", "human_text": "  We determine the energetically lowest lying states in the BEC-BCS crossover\nregime of s-wave interacting two-component Fermi gases under harmonic\nconfinement by solving the many-body Schrodinger equation using two distinct\napproaches. Essentially exact basis set expansion techniques are applied to\ndetermine the energy spectrum of systems with N=4 fermions. Fixed-node\ndiffusion Monte Carlo methods are applied to systems with up to N=20 fermions,\nand a discussion of different guiding functions used in the Monte Carlo\napproach to impose the proper symmetry of the fermionic system is presented.\nThe energies are calculated as a function of the s-wave scattering length a_s\nfor N=2-20 fermions and different mass ratios \\kappa of the two species. On the\nBEC and BCS sides, our energies agree with analytically-determined first-order\ncorrection terms. We extract the scattering length and the effective range of\nthe dimer-dimer system up to \\kappa = 20. Our energies for the\nstrongly-interacting trapped system in the unitarity regime show no shell\nstructure, and are well described by a simple expression, whose functional form\ncan be derived using the local density approximation, with one or two\nparameters. The universal parameter \\xi for the trapped system for various\n\\kappa is determined, and comparisons with results for the homogeneous system\nare presented.\n", "machine_text": "\nWe investigate the structure of s-wave interacting two-component Fermi gases\nsubject to a harmonic trapping potential, in the context of the BEC-BCS\ncrossover regime. Two distinct approaches are used to solve the\nSchrodinger equation for systems with up to N=20 fermions. Exact basis set\nexpansion is applied to N=4, while a Fixed-node diffusion Monte Carlo method\nallows us to study larger systems. We show that on the BEC and BCS sides, our\nresults, expressed as a function of the s-wave scattering length and of the\nmass ratio \\kappa of the two species, agree with first order correction terms.\nFor the unitarity regime, we deduce the scattering length and effective range\nof the dimer-dimer system up to \\kappa = 20. We find that the energies of the\nstrongly-interacting trapped system present no shell structure, and are\napproximately described by a simple expression that depends on one or two\nparameters. Additionally, we determine the universal parameter \\xi for the\ntrapped system, and compare it to results for the homogeneous case.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0671}
{"prompt": "Rephrase the abstract of an article with title 'CKM and Tri-bimaximal MNS Matrices in a SU(5) x (d)T Model'.\n  We propose a model based on SU(5) x {}^{(d)}T which successfully gives rise\nto near tri-bimaximal leptonic mixing as well as realistic CKM matrix elements\nfor the quarks. The Georgi-Jarlskog relations for three generations are also\nobtained. Due to the {}^{(d)}T transformation property of the matter fields,\nthe b-quark mass can be generated only when the {}^{(d)}T symmetry is broken,\ngiving a dynamical origin for the hierarchy between m_{b} and m_{t}. There are\nonly nine operators allowed in the Yukawa sector up to at least mass dimension\nseven due to an additional Z_{12} x Z'_{12} symmetry, which also forbids, up to\nsome high orders, operators that lead to proton decay. The resulting model has\na total of nine parameters in the charged fermion and neutrino sectors, and\nhence is very predictive. In addition to the prediction for \\theta_{13} \\simeq\n\\theta_{c}/3 \\sqrt{2}, the model gives rise to a sum rule,\n\\tan^{2}\\theta_{\\odot} \\simeq \\tan^{2} \\theta_{\\odot, \\mathrm{TBM}} - {1/2}\n\\theta_{c} \\cos\\beta, which is a consequence of the Georgi-Jarlskog relations\nin the quark sector. This deviation could account for the difference between\nthe experimental best fit value for the solar mixing angle and the value\npredicted by the tri-bimaximal mixing matrix.\n\n", "human_text": "  We propose a model based on SU(5) x {}^{(d)}T which successfully gives rise\nto near tri-bimaximal leptonic mixing as well as realistic CKM matrix elements\nfor the quarks. The Georgi-Jarlskog relations for three generations are also\nobtained. Due to the {}^{(d)}T transformation property of the matter fields,\nthe b-quark mass can be generated only when the {}^{(d)}T symmetry is broken,\ngiving a dynamical origin for the hierarchy between m_{b} and m_{t}. There are\nonly nine operators allowed in the Yukawa sector up to at least mass dimension\nseven due to an additional Z_{12} x Z'_{12} symmetry, which also forbids, up to\nsome high orders, operators that lead to proton decay. The resulting model has\na total of nine parameters in the charged fermion and neutrino sectors, and\nhence is very predictive. In addition to the prediction for \\theta_{13} \\simeq\n\\theta_{c}/3 \\sqrt{2}, the model gives rise to a sum rule,\n\\tan^{2}\\theta_{\\odot} \\simeq \\tan^{2} \\theta_{\\odot, \\mathrm{TBM}} - {1/2}\n\\theta_{c} \\cos\\beta, which is a consequence of the Georgi-Jarlskog relations\nin the quark sector. This deviation could account for the difference between\nthe experimental best fit value for the solar mixing angle and the value\npredicted by the tri-bimaximal mixing matrix.\n", "machine_text": "\nWe propose a model based on SU(5) x {}^{(d)}T which gives rise to interactions allowing for near tri-bimaximal leptonic and realistic CKM matrix elements for the quarks. The Georgi-Jarlskog relations among the three generations of fermions are also obtained. As a result of the {}^{(d)}T transformation properties of the matter fields, the model dynamically generates a mass hierarchy between the b and t quarks. There are nine operators in the Yukawa sector, enabled by a Z_{12} x Z'_{12} symmetry which also suppresses, up to some high orders, operators leading to proton decay. In total, the model contains nine parameters making it highly predictive. In addition to the prediction for \\theta_{13} \\simeq \\theta_{c}/3 \\sqrt{2}, a sum rule is derived,\n\\tan^{2}\\theta_{\\odot} \\simeq \\tan^{2} \\theta_{\\odot, \\mathrm{TBM}} - {1/2}\n\\theta_{c} \\cos\\beta, which is a combined consequence of the Georgi-Jarlskog relations in the quark sector and the deviation between the experimental best fit value and the value predicted by the tri-bimaximal mixing matrix.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0714}
{"prompt": "Rephrase the abstract of an article with title 'Five Intermediate-Period Planets from the N2K Sample'.\n  We report the detection of five Jovian mass planets orbiting high metallicity\nstars. Four of these stars were first observed as part of the N2K program and\nexhibited low RMS velocity scatter after three consecutive observations.\nHowever, follow-up observations over the last three years now reveal the\npresence of longer period planets with orbital periods ranging from 21 days to\na few years. HD 11506 is a G0V star with a planet of \\msini = 4.74 \\mjup in a\n3.85 year orbit. HD 17156 is a G0V star with a 3.12 \\mjup planet in a 21.2 day\norbit. The eccentricity of this orbit is 0.67, one of the highest known for a\nplanet with a relatively short period. The orbital period for this planet\nplaces it in a region of parameter space where relatively few planets have been\ndetected. HD 125612 is a G3V star with a planet of \\msini = 3.5 \\mjup in a 1.4\nyear orbit. HD 170469 is a G5IV star with a planet of \\msini = 0.67 \\mjup in a\n3.13 year orbit. HD 231701 is an F8V star with planet of 1.08 \\mjup in a 142\nday orbit. All of these stars have supersolar metallicity. Three of the five\nstars were observed photometrically but showed no evidence of brightness\nvariability. A transit search conducted for HD 17156 was negative but covered\nonly 25% of the search space and so is not conclusive.\n\n", "human_text": "  We report the detection of five Jovian mass planets orbiting high metallicity\nstars. Four of these stars were first observed as part of the N2K program and\nexhibited low RMS velocity scatter after three consecutive observations.\nHowever, follow-up observations over the last three years now reveal the\npresence of longer period planets with orbital periods ranging from 21 days to\na few years. HD 11506 is a G0V star with a planet of \\msini = 4.74 \\mjup in a\n3.85 year orbit. HD 17156 is a G0V star with a 3.12 \\mjup planet in a 21.2 day\norbit. The eccentricity of this orbit is 0.67, one of the highest known for a\nplanet with a relatively short period. The orbital period for this planet\nplaces it in a region of parameter space where relatively few planets have been\ndetected. HD 125612 is a G3V star with a planet of \\msini = 3.5 \\mjup in a 1.4\nyear orbit. HD 170469 is a G5IV star with a planet of \\msini = 0.67 \\mjup in a\n3.13 year orbit. HD 231701 is an F8V star with planet of 1.08 \\mjup in a 142\nday orbit. All of these stars have supersolar metallicity. Three of the five\nstars were observed photometrically but showed no evidence of brightness\nvariability. A transit search conducted for HD 17156 was negative but covered\nonly 25% of the search space and so is not conclusive.\n", "machine_text": "\nAfter an initial round of observations conducted through the N2K program, subsequent follow-up over the past three years has shown that these four stars each possess a Jovian-mass planet. The orbital periods range from 21 days up to a few years, and the planets have minimum masses from 0.67 to 4.74 \\mjup. All of the stars have supersolar metallicity. HD 17156 has an eccentricity of 0.67, one of the highest known for a planet with a relatively short period. A transit search was conducted but was unsuccessful, covering only 25% of the search space. We have identified five new intermediate-period planets from the N2K sample.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1191}
{"prompt": "Rephrase the abstract of an article with title 'Critical Current of Type-II Superconductors in a Broken Bose Glass State'.\n  The tilt modulus of a defective Abrikosov vortex lattice pinned by material\nline defects is computed using the boson analogy. It tends to infinity at long\nwavelength, which yields a Bose glass state that is robust to the addition of\nweak point-pinning centers, and which implies a restoring force per vortex line\nfor rigid translations about mechanical equilibrium that is independent of\nmagnetic field. It also indicates that the Bose glass state breaks into pieces\nalong the direction of the correlated pinning centers if the latter have finite\nlength. The critical current is predicted to crossover from two dimensional to\nthree dimensional behavior as a function of sample thickness along the\ncorrelated pinning centers in such case. That crossover notably can occur at a\nfilm thickness that is much larger than that expected from point pins of\ncomparable strength. The above is compared to the dependence on thickness shown\nby the critical current in certain films of high-temperature superconductors\ncurrently being developed for wire technology.\n\n", "human_text": "  The tilt modulus of a defective Abrikosov vortex lattice pinned by material\nline defects is computed using the boson analogy. It tends to infinity at long\nwavelength, which yields a Bose glass state that is robust to the addition of\nweak point-pinning centers, and which implies a restoring force per vortex line\nfor rigid translations about mechanical equilibrium that is independent of\nmagnetic field. It also indicates that the Bose glass state breaks into pieces\nalong the direction of the correlated pinning centers if the latter have finite\nlength. The critical current is predicted to crossover from two dimensional to\nthree dimensional behavior as a function of sample thickness along the\ncorrelated pinning centers in such case. That crossover notably can occur at a\nfilm thickness that is much larger than that expected from point pins of\ncomparable strength. The above is compared to the dependence on thickness shown\nby the critical current in certain films of high-temperature superconductors\ncurrently being developed for wire technology.\n", "machine_text": "This article examines the current-carrying capabilities of type-II superconductors in a state known as a Bose glass. An analytical computation of a material's tilt modulus is used to evaluate the strength of a broken Bose glass state, which allows it to maintain its form even in the presence of weak, point pinning. The study suggests that the critical current of these superconductors is dependent on the sample's thickness, and can transition between two and three dimensional behaviour as a result. Additionally, it is shown that the film thickness needed for this transition may be larger than what is indicated through the point pinning strength. Comparisons are drawn between the results of the study and high-temperature superconductors being developed for wire technology to validate its findings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1536}
{"prompt": "Rephrase the abstract of an article with title 'Structure and magnetism of self-organized Ge(1-x)Mn(x) nano-columns'.\n  We report on the structural and magnetic properties of thin Ge(1-x)Mn(x)films\ngrown by molecular beam epitaxy (MBE) on Ge(001) substrates at temperatures\n(Tg) ranging from 80deg C to 200deg C, with average Mn contents between 1 % and\n11 %. Their crystalline structure, morphology and composition have been\ninvestigated by transmission electron microscopy (TEM), electron energy loss\nspectroscopy and x-ray diffraction. In the whole range of growth temperatures\nand Mn concentrations, we observed the formation of manganese rich\nnanostructures embedded in a nearly pure germanium matrix. Growth temperature\nmostly determines the structural properties of Mn-rich nanostructures. For low\ngrowth temperatures (below 120deg C), we evidenced a two-dimensional spinodal\ndecomposition resulting in the formation of vertical one-dimensional\nnanostructures (nanocolumns). Moreover we show in this paper the influence of\ngrowth parameters (Tg and Mn content) on this decomposition i.e. on nanocolumns\nsize and density. For temperatures higher than 180deg C, we observed the\nformation of Ge3Mn5 clusters. For intermediate growth temperatures nanocolumns\nand nanoclusters coexist. Combining high resolution TEM and superconducting\nquantum interference device magnetometry, we could evidence at least four\ndifferent magnetic phases in Ge(1-x)Mn(x) films: (i) paramagnetic diluted Mn\natoms in the germanium matrix, (ii) superparamagnetic and ferromagnetic low-Tc\nnanocolumns (120 K < Tc < 170 K), (iii) high-Tc nanocolumns (Tc> 400 K) and\n(iv) Ge3Mn5 clusters.\n\n", "human_text": "  We report on the structural and magnetic properties of thin Ge(1-x)Mn(x)films\ngrown by molecular beam epitaxy (MBE) on Ge(001) substrates at temperatures\n(Tg) ranging from 80deg C to 200deg C, with average Mn contents between 1 % and\n11 %. Their crystalline structure, morphology and composition have been\ninvestigated by transmission electron microscopy (TEM), electron energy loss\nspectroscopy and x-ray diffraction. In the whole range of growth temperatures\nand Mn concentrations, we observed the formation of manganese rich\nnanostructures embedded in a nearly pure germanium matrix. Growth temperature\nmostly determines the structural properties of Mn-rich nanostructures. For low\ngrowth temperatures (below 120deg C), we evidenced a two-dimensional spinodal\ndecomposition resulting in the formation of vertical one-dimensional\nnanostructures (nanocolumns). Moreover we show in this paper the influence of\ngrowth parameters (Tg and Mn content) on this decomposition i.e. on nanocolumns\nsize and density. For temperatures higher than 180deg C, we observed the\nformation of Ge3Mn5 clusters. For intermediate growth temperatures nanocolumns\nand nanoclusters coexist. Combining high resolution TEM and superconducting\nquantum interference device magnetometry, we could evidence at least four\ndifferent magnetic phases in Ge(1-x)Mn(x) films: (i) paramagnetic diluted Mn\natoms in the germanium matrix, (ii) superparamagnetic and ferromagnetic low-Tc\nnanocolumns (120 K < Tc < 170 K), (iii) high-Tc nanocolumns (Tc> 400 K) and\n(iv) Ge3Mn5 clusters.\n", "machine_text": "\nIn this study, we explored the structural and magnetic characteristics of Ge(1-x)Mn(x) films grown by molecular beam epitaxy (MBE). We discovered that the growth temperature plays a major role in the decomposition of the films, resulting in the formation of vertical one-dimensional nanostructures (nanocolumns) at low temperatures (\u2264120\u00b0C), and Ge3Mn5 clusters at higher temperatures (\u2265180\u00b0C). Our experimental results then demonstrated the presence of at least four different magnetic phases, including paramagnetic diluted Mn atoms, low-Tc nanocolumns (120 K < Tc < 170 K), high-Tc nanocolumns (Tc> 400 K), and Ge3Mn5 clusters, depending on the growth temperature and Mn content. Combining transmission electron microscopy and superconducting quantum interference device magnetometry, we are able to provide a comprehensive analysis of the structure and magnetism of self-organized Ge(1-x)Mn(x) nano-columns.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0566}
{"prompt": "Rephrase the abstract of an article with title 'Cooling and heating by adiabatic magnetization in the\n  Ni$_{50}$Mn$_{34}$In$_{16}$ magnetic shape memory alloy'.\n  We report on measurements of the adiabatic temperature change in the inverse\nmagnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy. It is shown that this alloy\nheats up with the application of a magnetic field around the Curie point due to\nthe conventional magnetocaloric effect. In contrast, the inverse magnetocaloric\neffect associated with the martensitic transition results in the unusual\ndecrease of temperature by adiabatic magnetization. We also provide\nmagnetization and specific heat data which enable to compare the measured\ntemperature changes to the values indirectly computed from thermodynamic\nrelationships. Good agreement is obtained for the conventional effect at the\nsecond-order paramagnetic-ferromagnetic phase transition. However, at the first\norder structural transition the measured values at high fields are lower than\nthe computed ones. Irreversible thermodynamics arguments are given to show that\nsuch a discrepancy is due to the irreversibility of the first-order martensitic\ntransition.\n\n", "human_text": "  We report on measurements of the adiabatic temperature change in the inverse\nmagnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy. It is shown that this alloy\nheats up with the application of a magnetic field around the Curie point due to\nthe conventional magnetocaloric effect. In contrast, the inverse magnetocaloric\neffect associated with the martensitic transition results in the unusual\ndecrease of temperature by adiabatic magnetization. We also provide\nmagnetization and specific heat data which enable to compare the measured\ntemperature changes to the values indirectly computed from thermodynamic\nrelationships. Good agreement is obtained for the conventional effect at the\nsecond-order paramagnetic-ferromagnetic phase transition. However, at the first\norder structural transition the measured values at high fields are lower than\nthe computed ones. Irreversible thermodynamics arguments are given to show that\nsuch a discrepancy is due to the irreversibility of the first-order martensitic\ntransition.\n", "machine_text": "\nIn this study, we investigate the adiabatic temperature alteration of the inverse\nmagnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy attained through magnetic field application around the Curie point. Using magnetization and specific heat measurements, we analyze and compare the induced temperature changes relative to thermodynamic calculations. Our results show that the conventional magnetocaloric effect causes the temperature of the alloy to rise, yet temperatures markedly reduce due to the inverse magnetocaloric effect associated with the martensitic transition. We found that the observed conventional effect observed at the second-order paramagnetic-ferromagnetic phase transition was in concurrence with our calculations. Conversely, the first order structural transition results showed that the calculated temperature increases were lower than the recorded values at high fields - a phenomenon termed here as irreversible thermodynamics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1241}
{"prompt": "Rephrase the abstract of an article with title 'Fabrication of half metallicity in a ferromagnetic metal'.\n  We investigate the growth of half metallic phase in a ferromagnetic material\nusing state-of-the-art full potential linearized augmented plane wave method.\nTo address the issue, we have substituted Ti at the Ru-sites in SrRuO3, where\nSrRuO3 is a ferromagnetic material. Calculated results establish Ti4+ valence\nstates (similar to SrTiO3), which was predicted experimentally. Thus, Ti\nsubstitution dilutes the Ru-O-Ru connectivity, which is manifested in the\ncalculated results in the form of significant band narrowing leading to finite\ngap between t2g and eg bands. At 75% substitution, a large gap (> 2 eV) appears\nat the Fermi level, e_F in the up spin density of states, while the down spin\nstates contributes at e_F characterizing the system a half-metallic\nferromagnet. The t2g - eg gap can be tailored judiciously by tuning Ti\nconcentrations to minimize thermal effects, which is often the major bottleneck\nto achieve high spin polarization at elevated temperatures in other materials.\nThis study, thus, provides a novel but simple way to fabricate half-metallicity\nin ferromagnetic materials, which are potential candidates for spin-based\ntechnology.\n\n", "human_text": "  We investigate the growth of half metallic phase in a ferromagnetic material\nusing state-of-the-art full potential linearized augmented plane wave method.\nTo address the issue, we have substituted Ti at the Ru-sites in SrRuO3, where\nSrRuO3 is a ferromagnetic material. Calculated results establish Ti4+ valence\nstates (similar to SrTiO3), which was predicted experimentally. Thus, Ti\nsubstitution dilutes the Ru-O-Ru connectivity, which is manifested in the\ncalculated results in the form of significant band narrowing leading to finite\ngap between t2g and eg bands. At 75% substitution, a large gap (> 2 eV) appears\nat the Fermi level, e_F in the up spin density of states, while the down spin\nstates contributes at e_F characterizing the system a half-metallic\nferromagnet. The t2g - eg gap can be tailored judiciously by tuning Ti\nconcentrations to minimize thermal effects, which is often the major bottleneck\nto achieve high spin polarization at elevated temperatures in other materials.\nThis study, thus, provides a novel but simple way to fabricate half-metallicity\nin ferromagnetic materials, which are potential candidates for spin-based\ntechnology.\n", "machine_text": "\nWe investigate a technique to fabricate half-metallicity in a ferromagnetic material by substituting Ti at the Ru-sites in SrRuO3, which is a known ferromagnetic material. By employing full potential linearized augmented plane wave method, we find that Ti4+ valence states, similar to SrTiO3, are obtained. Significant band narrowing is shown as a result of this Ti substitution, leading to a finite gap between the t2g and eg bands. When 75% substitution is done, a large gap (larger than 2 eV) is formed at the Fermi level in the spin density of states of the up spin electrons, while the spin density of states of the down spin electrons contribute at the Fermi level, thus characterizing the system a half-metallic ferromagnet. This study provides a simple and effective way to fabricate half-metallicity in ferromagnetic materials, which is important for developing spin-based technologies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0321}
{"prompt": "Rephrase the abstract of an article with title 'Hall drift of axisymmetric magnetic fields in solid neutron-star matter'.\n  Hall drift, i. e., transport of magnetic flux by the moving electrons giving\nrise to the electrical current, may be the dominant effect causing the\nevolution of the magnetic field in the solid crust of neutron stars. It is a\nnonlinear process that, despite a number of efforts, is still not fully\nunderstood. We use the Hall induction equation in axial symmetry to obtain some\ngeneral properties of nonevolving fields, as well as analyzing the evolution of\npurely toroidal fields, their poloidal perturbations, and current-free, purely\npoloidal fields. We also analyze energy conservation in Hall instabilities and\nwrite down a variational principle for Hall equilibria. We show that the\nevolution of any toroidal magnetic field can be described by Burgers' equation,\nas previously found in plane-parallel geometry. It leads to sharp current\nsheets that dissipate on the Hall time scale, yielding a stationary field\nconfiguration that depends on a single, suitably defined coordinate. This\nfield, however, is unstable to poloidal perturbations, which grow as their\nfield lines are stretched by the background electron flow, as in instabilities\nearlier found numerically. On the other hand, current-free poloidal\nconfigurations are stable and could represent a long-lived crustal field\nsupported by currents in the fluid stellar core.\n\n", "human_text": "  Hall drift, i. e., transport of magnetic flux by the moving electrons giving\nrise to the electrical current, may be the dominant effect causing the\nevolution of the magnetic field in the solid crust of neutron stars. It is a\nnonlinear process that, despite a number of efforts, is still not fully\nunderstood. We use the Hall induction equation in axial symmetry to obtain some\ngeneral properties of nonevolving fields, as well as analyzing the evolution of\npurely toroidal fields, their poloidal perturbations, and current-free, purely\npoloidal fields. We also analyze energy conservation in Hall instabilities and\nwrite down a variational principle for Hall equilibria. We show that the\nevolution of any toroidal magnetic field can be described by Burgers' equation,\nas previously found in plane-parallel geometry. It leads to sharp current\nsheets that dissipate on the Hall time scale, yielding a stationary field\nconfiguration that depends on a single, suitably defined coordinate. This\nfield, however, is unstable to poloidal perturbations, which grow as their\nfield lines are stretched by the background electron flow, as in instabilities\nearlier found numerically. On the other hand, current-free poloidal\nconfigurations are stable and could represent a long-lived crustal field\nsupported by currents in the fluid stellar core.\n", "machine_text": "The Hall drift, or transport of magnetic flux by moving electrons producing an electrical current, may be the main factor leading to the evolution of the magnetic field in the solid crust of neutron stars. In this article, the Hall induction equation in axial symmetry is utilised to explore the nonlinear process that has still not been fully comprehended and understand the properties of non-evolving fields as well as the evolution of purely toroidal fields, their poloidal perturbations, and current-free, purely poloidal fields. Additionally, it is shown that the evolution of any toroidal magnetic field can be detailed through Burgers' equation. The stability of poloidal magnetic field is discussed and it is shown that these are stable and could be representatives of a long-term polarized crustal field, maintained by currents in the fluid stellar core.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1901}
{"prompt": "Rephrase the abstract of an article with title 'Free zero-range processes on networks'.\n  A free zero-range process (FRZP) is a simple stochastic process describing\nthe dynamics of a gas of particles hopping between neighboring nodes of a\nnetwork. We discuss three different cases of increasing complexity: (a) FZRP on\na rigid geometry where the network is fixed during the process, (b) FZRP on a\nrandom graph chosen from a given ensemble of networks, (c) FZRP on a dynamical\nnetwork whose topology continuously changes during the process in a way which\ndepends on the current distribution of particles. The case (a) provides a very\nsimple realization of the phenomenon of condensation which manifests as the\nappearance of a condensate of particles on the node with maximal degree. The\ncase (b) is very interesting since the averaging over typical ensembles of\ngraphs acts as a kind of homogenization of the system which makes all nodes\nidentical from the point of view of the FZRP. In the case (c), the distribution\nof particles and the dynamics of network are coupled to each other. The\nstrength of this coupling depends on the ratio of two time scales: for changes\nof the topology and of the FZRP. We will discuss a specific example of that\ntype of interaction and show that it leads to an interesting phase diagram.\n\n", "human_text": "  A free zero-range process (FRZP) is a simple stochastic process describing\nthe dynamics of a gas of particles hopping between neighboring nodes of a\nnetwork. We discuss three different cases of increasing complexity: (a) FZRP on\na rigid geometry where the network is fixed during the process, (b) FZRP on a\nrandom graph chosen from a given ensemble of networks, (c) FZRP on a dynamical\nnetwork whose topology continuously changes during the process in a way which\ndepends on the current distribution of particles. The case (a) provides a very\nsimple realization of the phenomenon of condensation which manifests as the\nappearance of a condensate of particles on the node with maximal degree. The\ncase (b) is very interesting since the averaging over typical ensembles of\ngraphs acts as a kind of homogenization of the system which makes all nodes\nidentical from the point of view of the FZRP. In the case (c), the distribution\nof particles and the dynamics of network are coupled to each other. The\nstrength of this coupling depends on the ratio of two time scales: for changes\nof the topology and of the FZRP. We will discuss a specific example of that\ntype of interaction and show that it leads to an interesting phase diagram.\n", "machine_text": "\nThis article examines the dynamics of a gas of particles hopping between the nodes of a network in the context of a free zero-range process (FZRP). Three different cases of increasing complexity are discussed. These include FZRP on a rigid geometry, FZRP on a random graph drawn from a given network, and a form of FZRP where the network's topology continuously changes as the process evolves, depending on the particle distribution. The first case examines the intriguing phenomenon of condensation, which appears as a collection of particles on the node presenting the highest degree. The second considers the role of averaging over various graph ensembles, making all nodes identical with respect to the FZRP. In the final case, the distribution of particles and the dynamics of the network are interconnected, with their strength of coupling depending on the ratio of two time-scales, relating to the topology and the FZRP. A particular example is analyzed, demonstrating an interesting phase diagram in the results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0549}
{"prompt": "Rephrase the abstract of an article with title 'Reduced dimensionality in layered quantum dimer magnets: Frustration vs.\n  inhomogeneous condensates'.\n  Motivated by recent experiments on BaCuSi2O6, we investigate magnetic\nexcitations and quantum phase transitions of layered dimer magnets with\ninter-layer frustration. We consider two scenarios, (A) a lattice with one\ndimer per unit cell and perfect inter-layer frustration, and (B) an enlarged\nunit cell with inequivalent layers, with and without perfect frustration. In\nall situations, the critical behavior at asymptotically low temperatures is\nthree-dimensional, but the corresponding crossover scale may be tiny. Magnetic\nordering in case (B) can be discussed in terms of two condensates; remarkably,\nperfect frustration renders the proximity effect ineffective. Then, the\nordering transition will be generically split, with clear signatures in\nmeasurable properties. Using a generalized bond-operator method, we calculate\nthe low-temperature magnetic properties in the paramagnetic and\nantiferromagnetic phases. Based on the available experimental data on\nBaCuSi2O6, we propose that scenario (B) with inequivalent layers and imperfect\nfrustration is realized in this material, likely with an additional modulation\nof the inter-layer couling along the c axis.\n\n", "human_text": "  Motivated by recent experiments on BaCuSi2O6, we investigate magnetic\nexcitations and quantum phase transitions of layered dimer magnets with\ninter-layer frustration. We consider two scenarios, (A) a lattice with one\ndimer per unit cell and perfect inter-layer frustration, and (B) an enlarged\nunit cell with inequivalent layers, with and without perfect frustration. In\nall situations, the critical behavior at asymptotically low temperatures is\nthree-dimensional, but the corresponding crossover scale may be tiny. Magnetic\nordering in case (B) can be discussed in terms of two condensates; remarkably,\nperfect frustration renders the proximity effect ineffective. Then, the\nordering transition will be generically split, with clear signatures in\nmeasurable properties. Using a generalized bond-operator method, we calculate\nthe low-temperature magnetic properties in the paramagnetic and\nantiferromagnetic phases. Based on the available experimental data on\nBaCuSi2O6, we propose that scenario (B) with inequivalent layers and imperfect\nfrustration is realized in this material, likely with an additional modulation\nof the inter-layer couling along the c axis.\n", "machine_text": "\n\nMotivated by experiments on BaCuSi2O6, this study examines the magnetic excitations and transitions in layered quantum dimer magnets when considering two scenarios: (A) one dimer per unit cell and complete inter-layer frustration; and (B) an enlarged cell with inequivalent layers, either with or without perfect frustration. Calculations of the material's low-temperature magnetic characteristics based on a generalized bond-operator method reveal critical behavior that is three-dimensional at the lowest temperature, albeit with a tiny crossover scale. In the second case, it is demonstrated that the magnetic order can be interpreted as stemming from two condensates, and that complete frustration weakens the proximity influence. Consequently, the ordering transition typically becomes separated, leading to observable effects. Comparison with the available data indicates that BaCuSi2O6 likely implements scenario (B) with distinct layers and partially frustrated interactions, supplemented by an additional modulation of inter-layer couplings along the c-axis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1351}
{"prompt": "Rephrase the abstract of an article with title 'SLE in self-dual critical Z(N) spin systems: CFT predictions'.\n  The Schramm-Loewner evolution (SLE) describes the continuum limit of domain\nwalls at phase transitions in two dimensional statistical systems. We consider\nhere the SLEs in the self-dual Z(N) spin models at the critical point. For N=2\nand N=3 these models correspond to the Ising and three-state Potts model. For\nN>5 the critical self-dual Z(N) spin models are described in the continuum\nlimit by non-minimal conformal field theories with central charge c>=1. By\nstudying the representations of the corresponding chiral algebra, we show that\ntwo particular operators satisfy a two level null vector condition which, for\nN>=4, presents an additional term coming from the extra symmetry currents\naction. For N=2,3 these operators correspond to the boundary conditions\nchanging operators associated to the SLE_{16/3} (Ising model) and to the\nSLE_{24/5} and SLE_{10/3} (three-state Potts model). We suggest a definition of\nthe interfaces within the Z(N) lattice models. The scaling limit of these\ninterfaces is expected to be described at the self-dual critical point and for\nN>=4 by the SLE_{4(N+1)/(N+2)} and SLE_{4(N+2)/(N+1)} processes.\n\n", "human_text": "  The Schramm-Loewner evolution (SLE) describes the continuum limit of domain\nwalls at phase transitions in two dimensional statistical systems. We consider\nhere the SLEs in the self-dual Z(N) spin models at the critical point. For N=2\nand N=3 these models correspond to the Ising and three-state Potts model. For\nN>5 the critical self-dual Z(N) spin models are described in the continuum\nlimit by non-minimal conformal field theories with central charge c>=1. By\nstudying the representations of the corresponding chiral algebra, we show that\ntwo particular operators satisfy a two level null vector condition which, for\nN>=4, presents an additional term coming from the extra symmetry currents\naction. For N=2,3 these operators correspond to the boundary conditions\nchanging operators associated to the SLE_{16/3} (Ising model) and to the\nSLE_{24/5} and SLE_{10/3} (three-state Potts model). We suggest a definition of\nthe interfaces within the Z(N) lattice models. The scaling limit of these\ninterfaces is expected to be described at the self-dual critical point and for\nN>=4 by the SLE_{4(N+1)/(N+2)} and SLE_{4(N+2)/(N+1)} processes.\n", "machine_text": "\nThis article looks at the SLEs of self-dual Z(N) spin systems at the critical point. For N=2 and 3, these models represent the Ising and three-state Potts models respectively. By studying the chiral algebras represented by N>5 critical self-dual Z(N) spin models, we show that two operators satisfy a two-level null vector condition, which for N>=4 presents an additional term from symmetry currents. We suggest a definition for the interfaces within the Z(N) lattice models. The scaling limit of these interfaces is expected to be described by the SLE_{4(N+1)/(N+2)} and SLE_{4(N+2)/(N+1)} processes, when taken at the self-dual critical point and for N>=4.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2749}
{"prompt": "Rephrase the abstract of an article with title 'Thermal derivation of the Coleman-De Luccia tunneling prescription'.\n  We derive the rate for transitions between de Sitter vacua by treating the\nfield theory on the static patch as a thermal system. This reproduces the\nColeman-De Luccia formalism for calculating the rate, but leads to a modified\ninterpretation of the bounce solution and a different prediction for the\nevolution of the system after tunneling. The bounce is seen to correspond to a\nsequence of configurations interpolating between initial and final\nconfigurations on either side of the tunneling barrier, all of which are\nrestricted to the static patch. The final configuration, which gives the\ninitial data on the static patch for evolution after tunneling, is obtained\nfrom one half of a slice through the center of the bounce, while the other half\ngives the configuration before tunneling. The formalism makes no statement\nabout the fields beyond the horizon.\n  This approach resolves several puzzling aspects and interpretational issues\nconcerning the Coleman-De Luccia and Hawking-Moss bounces. We work in the limit\nwhere the back reaction of matter on metric can be ignored, but argue that the\nqualitative aspects remain in the more general case. The extension to tunneling\nbetween anti-de Sitter vacua is discussed.\n\n", "human_text": "  We derive the rate for transitions between de Sitter vacua by treating the\nfield theory on the static patch as a thermal system. This reproduces the\nColeman-De Luccia formalism for calculating the rate, but leads to a modified\ninterpretation of the bounce solution and a different prediction for the\nevolution of the system after tunneling. The bounce is seen to correspond to a\nsequence of configurations interpolating between initial and final\nconfigurations on either side of the tunneling barrier, all of which are\nrestricted to the static patch. The final configuration, which gives the\ninitial data on the static patch for evolution after tunneling, is obtained\nfrom one half of a slice through the center of the bounce, while the other half\ngives the configuration before tunneling. The formalism makes no statement\nabout the fields beyond the horizon.\n  This approach resolves several puzzling aspects and interpretational issues\nconcerning the Coleman-De Luccia and Hawking-Moss bounces. We work in the limit\nwhere the back reaction of matter on metric can be ignored, but argue that the\nqualitative aspects remain in the more general case. The extension to tunneling\nbetween anti-de Sitter vacua is discussed.\n", "machine_text": "\nUsing a thermal model, we investigate the rate at which transitions between de Sitter vacua occur, leading to a Coleman-De Luccia prescription. Our interpretation of the bounce generated by this method offers an alternative prediction for the evolution of the system after it has tunneled. This interpretation suggests that all configurations contained within the static patch leading to the initial and final states of the tunneling process adhere to the bounce solution. The configurations before and after tunneling are halves of a given slice through its center. We concentrate on the case where the matter fields have no effect on the metric, but nevertheless assume that the results may be transferred to more general cases. Finally, we briefly touch upon the idea of tunneling between anti-de Sitter vacua.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1573}
{"prompt": "Rephrase the abstract of an article with title 'Discrete Choices under Social Influence: Generic Properties'.\n  We consider a model of socially interacting individuals that make a binary\nchoice in a context of positive additive endogenous externalities. It\nencompasses as particular cases several models from the sociology and economics\nliterature. We extend previous results to the case of a general distribution of\nidiosyncratic preferences, called here Idiosyncratic Willingnesses to Pay\n(IWP). Positive additive externalities yield a family of inverse demand curves\nthat include the classical downward sloping ones but also new ones with non\nconstant convexity. When j, the ratio of the social influence strength to the\nstandard deviation of the IWP distribution, is small enough, the inverse demand\nis a classical monotonic (decreasing) function of the adoption rate. Even if\nthe IWP distribution is mono-modal, there is a critical value of j above which\nthe inverse demand is non monotonic, decreasing for small and high adoption\nrates, but increasing within some intermediate range. Depending on the price\nthere are thus either one or two equilibria. Beyond this first result, we\nexhibit the generic properties of the boundaries limiting the regions where the\nsystem presents different types of equilibria (unique or multiple). These\nproperties are shown to depend only on qualitative features of the IWP\ndistribution: modality (number of maxima), smoothness and type of support\n(compact or infinite). The main results are summarized as phase diagrams in the\nspace of the model parameters, on which the regions of multiple equilibria are\nprecisely delimited.\n\n", "human_text": "  We consider a model of socially interacting individuals that make a binary\nchoice in a context of positive additive endogenous externalities. It\nencompasses as particular cases several models from the sociology and economics\nliterature. We extend previous results to the case of a general distribution of\nidiosyncratic preferences, called here Idiosyncratic Willingnesses to Pay\n(IWP). Positive additive externalities yield a family of inverse demand curves\nthat include the classical downward sloping ones but also new ones with non\nconstant convexity. When j, the ratio of the social influence strength to the\nstandard deviation of the IWP distribution, is small enough, the inverse demand\nis a classical monotonic (decreasing) function of the adoption rate. Even if\nthe IWP distribution is mono-modal, there is a critical value of j above which\nthe inverse demand is non monotonic, decreasing for small and high adoption\nrates, but increasing within some intermediate range. Depending on the price\nthere are thus either one or two equilibria. Beyond this first result, we\nexhibit the generic properties of the boundaries limiting the regions where the\nsystem presents different types of equilibria (unique or multiple). These\nproperties are shown to depend only on qualitative features of the IWP\ndistribution: modality (number of maxima), smoothness and type of support\n(compact or infinite). The main results are summarized as phase diagrams in the\nspace of the model parameters, on which the regions of multiple equilibria are\nprecisely delimited.\n", "machine_text": "\nWe explore how individuals interact in the context of binary choices, with the presence of positive additive externalities. We extend known results to the study of Idiosyncratic Willingnesses to Pay (IWP), a general distribution of preferences. The result is a newly developed family of inverse demand curves, including decreasing slopes as well as non-uniform convexity. When the social influence effect is small relative to the standard deviation of the IWP distribution, inverse demand will normally be monotone. However, once the social influence surpasses a certain threshold, the inverse demand may become non-monotone within an intermediate rate of adoption, increasing or decreasing with the rate of adoption. Furthermore, the generic properties depending on the modality, smoothness and support of the IWP distribution allow for a precise delineation of the regions of multiple equilibria. We summarized the principal results in a phase diagram.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2333}
{"prompt": "Rephrase the abstract of an article with title 'Outflows and the Physical Properties of Quasars'.\n  We have investigated a sample of 5088 quasars from the Sloan Digital Sky\nSurvey Second Data Release in order to determine how the frequency and\nproperties of broad absorptions lines (BALs) depend on black hole mass,\nbolometric luminosity, Eddington fraction (L/L_Edd), and spectral slope. We\nfocus only on high-ionization BALs and find a number of significant results.\nWhile quasars accreting near the Eddington limit are more likely to show BALs\nthan lower $L/L_{Edd}$ systems, BALs are present in quasars accreting at only a\nfew percent Eddington. We find a stronger effect with bolometric luminosity,\nsuch that the most luminous quasars are more likely to show BALs. There is an\nadditional effect, previously known, that BAL quasars are redder on average\nthan unabsorbed quasars. The strongest effects involving the quasar physical\nproperties and BAL properties are related to terminal outflow velocity. Maximum\nobserved outflow velocities increase with both the bolometric luminosity and\nthe blueness of the spectral slope, suggesting that the ultraviolet luminosity\nto a great extent determines the acceleration. These results support the idea\nof outflow acceleration via ultraviolet line scattering.\n\n", "human_text": "  We have investigated a sample of 5088 quasars from the Sloan Digital Sky\nSurvey Second Data Release in order to determine how the frequency and\nproperties of broad absorptions lines (BALs) depend on black hole mass,\nbolometric luminosity, Eddington fraction (L/L_Edd), and spectral slope. We\nfocus only on high-ionization BALs and find a number of significant results.\nWhile quasars accreting near the Eddington limit are more likely to show BALs\nthan lower $L/L_{Edd}$ systems, BALs are present in quasars accreting at only a\nfew percent Eddington. We find a stronger effect with bolometric luminosity,\nsuch that the most luminous quasars are more likely to show BALs. There is an\nadditional effect, previously known, that BAL quasars are redder on average\nthan unabsorbed quasars. The strongest effects involving the quasar physical\nproperties and BAL properties are related to terminal outflow velocity. Maximum\nobserved outflow velocities increase with both the bolometric luminosity and\nthe blueness of the spectral slope, suggesting that the ultraviolet luminosity\nto a great extent determines the acceleration. These results support the idea\nof outflow acceleration via ultraviolet line scattering.\n", "machine_text": "\nIn this paper, we investigate the physical properties of a sample of 5088 quasars from the Sloan Digital Sky Survey Second Data Release in order to determine how the frequency and properties of broad absorption lines (BALs) depend on various factors. Specifically, we consider black hole mass, bolometric luminosity, Eddington fraction (L/L_Edd) and spectral slope. Our findings suggest that quasars with elevated Eddington fractions are more likely to exhibit BALs than those with lower fractions. Additionally, an increase in luminosity produces a greater likelihood the quasar will show BALs. Additionally, further evidence supports the idea of outflows becoming accelerated due to ultraviolet light scattering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1546}
{"prompt": "Rephrase the abstract of an article with title 'The Infrared Camera (IRC) for AKARI - Design and Imaging Performance'.\n  The Infrared Camera (IRC) is one of two focal-plane instruments on the AKARI\nsatellite. It is designed for wide-field deep imaging and low-resolution\nspectroscopy in the near- to mid-infrared (1.8--26.5um) in the pointed\nobservation mode of AKARI. IRC is also operated in the survey mode to make an\nall-sky survey at 9 and 18um. It comprises three channels. The NIR channel\n(1.8--5.5um) employs a 512 x 412 InSb array, whereas both the MIR-S\n(4.6--13.4um) and MIR-L (12.6--26.5um) channels use 256 x 256 Si:As impurity\nband conduction arrays. Each of the three channels has a field-of-view of about\n10' x 10' and are operated simultaneously. The NIR and MIR-S share the same\nfield-of-view by virtue of a beam splitter. The MIR-L observes the sky about\n$25' away from the NIR/MIR-S field-of-view. IRC gives us deep insights into the\nformation and evolution of galaxies, the evolution of planetary disks, the\nprocess of star-formation, the properties of interstellar matter under various\nphysical conditions, and the nature and evolution of solar system objects. The\nin-flight performance of IRC has been confirmed to be in agreement with the\npre-flight expectation. This paper summarizes the design and the in-flight\noperation and imaging performance of IRC.\n\n", "human_text": "  The Infrared Camera (IRC) is one of two focal-plane instruments on the AKARI\nsatellite. It is designed for wide-field deep imaging and low-resolution\nspectroscopy in the near- to mid-infrared (1.8--26.5um) in the pointed\nobservation mode of AKARI. IRC is also operated in the survey mode to make an\nall-sky survey at 9 and 18um. It comprises three channels. The NIR channel\n(1.8--5.5um) employs a 512 x 412 InSb array, whereas both the MIR-S\n(4.6--13.4um) and MIR-L (12.6--26.5um) channels use 256 x 256 Si:As impurity\nband conduction arrays. Each of the three channels has a field-of-view of about\n10' x 10' and are operated simultaneously. The NIR and MIR-S share the same\nfield-of-view by virtue of a beam splitter. The MIR-L observes the sky about\n$25' away from the NIR/MIR-S field-of-view. IRC gives us deep insights into the\nformation and evolution of galaxies, the evolution of planetary disks, the\nprocess of star-formation, the properties of interstellar matter under various\nphysical conditions, and the nature and evolution of solar system objects. The\nin-flight performance of IRC has been confirmed to be in agreement with the\npre-flight expectation. This paper summarizes the design and the in-flight\noperation and imaging performance of IRC.\n", "machine_text": "\nThe Infrared Camera (IRC), located on the AKARI satellite, provides exceptional depth and low-resolution spectroscopy with its three channels operating simultaneously in the near- to mid-infrared (1.8--26.5um) range. The NIR channel (1.8--5.5um) is equipped with a 512 x 412 InSb array, whereas the MIR-S (4.6--13.4um) and MIR-L (12.6--26.5um) channels use 256 x 256 Si:As impurity band conduction arrays, all affording a 10' x 10' field-of-view. The MIR-L observes the sky approximately $25' away from the NIR/MIR-S field-of-view which is shared due to use of a beam splitter. Through use of IRC, we are provided with new information on the formation and evolution of galaxies, the evolution of planetary disks, the process of star-formation, the properties of interstellar matter under various physical conditions, and the nature and evolution of solar system objects. This paper acquaints us with the design of IRC, its in-flight operation, and its imaging performance which is verified to match well with pre-launch expectations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4144}
{"prompt": "Rephrase the abstract of an article with title 'Poisson approximation for non-backtracking random walks'.\n  Random walks on expander graphs were thoroughly studied, with the important\nmotivation that, under some natural conditions, these walks mix quickly and\nprovide an efficient method of sampling the vertices of a graph. Alon,\nBenjamini, Lubetzky and Sodin studied non-backtracking random walks on regular\ngraphs, and showed that their mixing rate may be up to twice as fast as that of\nthe simple random walk. As an application, they showed that the maximal number\nof visits to a vertex, made by a non-backtracking random walk of length $n$ on\na high-girth $n$-vertex regular expander, is typically $(1+o(1))\\frac{\\log\nn}{\\log\\log n}$, as in the case of the balls and bins experiment. They further\nasked whether one can establish the precise distribution of the visits such a\nwalk makes.\n  In this work, we answer the above question by combining a generalized form of\nBrun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote\nthe number of vertices visited precisely $t$ times by a non-backtracking random\nwalk of length $n$ on a regular $n$-vertex expander of fixed degree and girth\n$g$. We prove that if $g=\\omega(1)$, then for any fixed $t$, $N_t/n$ is\ntypically $\\frac{1}{\\mathrm{e}t!}+o(1)$. Furthermore, if $g=\\Omega(\\log\\log\nn)$, then $N_t/n$ is typically $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all\n$t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq\n(1+o(1))\\frac{\\log n}{\\log\\log n}$. In particular, we obtain the above result\non the typical maximal number of visits to a single vertex, with an improved\nthreshold window. The essence of the proof lies in showing that variables\ncounting the number of visits to a set of sufficiently distant vertices are\nasymptotically independent Poisson variables.\n\n", "human_text": "  Random walks on expander graphs were thoroughly studied, with the important\nmotivation that, under some natural conditions, these walks mix quickly and\nprovide an efficient method of sampling the vertices of a graph. Alon,\nBenjamini, Lubetzky and Sodin studied non-backtracking random walks on regular\ngraphs, and showed that their mixing rate may be up to twice as fast as that of\nthe simple random walk. As an application, they showed that the maximal number\nof visits to a vertex, made by a non-backtracking random walk of length $n$ on\na high-girth $n$-vertex regular expander, is typically $(1+o(1))\\frac{\\log\nn}{\\log\\log n}$, as in the case of the balls and bins experiment. They further\nasked whether one can establish the precise distribution of the visits such a\nwalk makes.\n  In this work, we answer the above question by combining a generalized form of\nBrun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote\nthe number of vertices visited precisely $t$ times by a non-backtracking random\nwalk of length $n$ on a regular $n$-vertex expander of fixed degree and girth\n$g$. We prove that if $g=\\omega(1)$, then for any fixed $t$, $N_t/n$ is\ntypically $\\frac{1}{\\mathrm{e}t!}+o(1)$. Furthermore, if $g=\\Omega(\\log\\log\nn)$, then $N_t/n$ is typically $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all\n$t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq\n(1+o(1))\\frac{\\log n}{\\log\\log n}$. In particular, we obtain the above result\non the typical maximal number of visits to a single vertex, with an improved\nthreshold window. The essence of the proof lies in showing that variables\ncounting the number of visits to a set of sufficiently distant vertices are\nasymptotically independent Poisson variables.\n", "machine_text": "\nThis paper tackles the challenging problem of elucidating the precise distribution of the visits made by a non-backtracking random walk of length $n$, on a regular $n$-vertex expander of fixed degree and girth $g$. Our main result is an application of a generalized form of Brun's sieve, combined with some extensions of the ideas of Alon et al, which shows that if $g=\\omega(1)$, then for any fixed $t$, the number of vertices visited precisely $t$ times is typically $\\frac{1}{\\mathrm{e}t!}+o(1)$. We further demonstrate that if $g=\\Omega(\\log\\log n)$, then it is $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all $t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq (1+o(1))\\frac{\\log n}{\\log\\log n}$. This yields an improved result on the typical maximal number of visits to a single vertex. Our proof shows that variables counting the number of visits to a set of sufficiently distant vertices are asymptotically independent Poisson variables.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0867}
{"prompt": "Rephrase the abstract of an article with title 'Sunyaev-Zel'dovich profiles and scaling relations: modelling effects and\n  observational biases'.\n  We use high-resolution hydrodynamic re-simulations to investigate the\nproperties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters.\nWe compare results obtained using different physical models for the\nintracluster medium (ICM), and show how they modify the SZ emission in terms of\ncluster profiles and scaling relations. We also produce realistic mock\nobservations to verify whether the results from hydrodynamic simulations can be\nconfirmed. We find that SZ profiles depend marginally on the modelled physical\nprocesses, while they exhibit a strong dependence on cluster mass. The central\nand total SZ emission strongly correlate with the cluster X-ray luminosity and\ntemperature. The logarithmic slopes of these scaling relations differ from the\nself-similar predictions by less than 0.2; the normalization of the relations\nis lower for simulations including radiative cooling. The observational test\nsuggests that SZ cluster profiles are unlikely to be able to probe the ICM\nphysics. The total SZ decrement appears to be an observable much more robust\nthan the central intensity, and we suggest using the former to investigate\nscaling relations.\n\n", "human_text": "  We use high-resolution hydrodynamic re-simulations to investigate the\nproperties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters.\nWe compare results obtained using different physical models for the\nintracluster medium (ICM), and show how they modify the SZ emission in terms of\ncluster profiles and scaling relations. We also produce realistic mock\nobservations to verify whether the results from hydrodynamic simulations can be\nconfirmed. We find that SZ profiles depend marginally on the modelled physical\nprocesses, while they exhibit a strong dependence on cluster mass. The central\nand total SZ emission strongly correlate with the cluster X-ray luminosity and\ntemperature. The logarithmic slopes of these scaling relations differ from the\nself-similar predictions by less than 0.2; the normalization of the relations\nis lower for simulations including radiative cooling. The observational test\nsuggests that SZ cluster profiles are unlikely to be able to probe the ICM\nphysics. The total SZ decrement appears to be an observable much more robust\nthan the central intensity, and we suggest using the former to investigate\nscaling relations.\n", "machine_text": "\nWe studied the impact of incorporating different physical models of intracluster medium (ICM) on the thermal Sunyaev-Zel'dovich (SZ) emission from galaxy clusters. With the help of high-resolution hydrodynamic re-simulations, we explored modifications in the SZ profiles and scaling relations. Additionally, realistic mock observations were used to examine the validity of results from the simulations. It was revealed that SZ clusters' features are largely unaffiliated with ICM physics; on the other hand, dependence on the mass of the clusters was notable. The X-ray luminosity and temperature of clusters showed considerable agreement with logarithmic slopes of the scaling relations, while the normalization was discovered to be lesser in simulations including radiative cooling. Eventually, we suggested analyzing the total SZ decrement in preference to the central intensity for probing the scaling relations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2535}
{"prompt": "Rephrase the abstract of an article with title 'Immunohistochemical pitfalls in the demonstration of insulin-degrading\n  enzyme in normal and neoplastic human tissues'.\n  Previously, we have identified the cytoplasmic zinc metalloprotease\ninsulin-degrading enzyme(IDE) in human tissues by an immunohistochemical method\ninvolving no antigen retrieval (AR) by pressure cooking to avoid artifacts by\nendogenous biotin exposure and a detection kit based on the labeled\nstreptavidin biotin (LSAB) method. Thereby, we also employed 3% hydrogen\nperoxide(H2O2) for the inhibition of endogenous peroxidase activity and\nincubated the tissue sections with the biotinylated secondary antibody at room\ntemperature (RT). We now add the immunohistochemical details that had led us to\nthis optimized procedure as they also bear a more general relevance when\ndemonstrating intracellular tissue antigens. Our most important result is that\nendogenous peroxidase inhibition by 0.3% H2O2 coincided with an apparently\npositive IDE staining in an investigated breast cancer specimen whereas\ncombining a block by 3% H2O2 with an incubation of the biotinylated secondary\nantibody at RT, yet not at 37 degrees Celsius, revealed this specimen as almost\nentirely IDE-negative. Our present data caution against three different\nimmunohistochemical pitfalls that might cause falsely positive results and\nartifacts when using an LSAB- and peroxidase-based detection method: pressure\ncooking for AR, insufficient quenching of endogenous peroxidases and heating of\ntissue sections while incubating with biotinylated secondary antibodies.\n\n", "human_text": "  Previously, we have identified the cytoplasmic zinc metalloprotease\ninsulin-degrading enzyme(IDE) in human tissues by an immunohistochemical method\ninvolving no antigen retrieval (AR) by pressure cooking to avoid artifacts by\nendogenous biotin exposure and a detection kit based on the labeled\nstreptavidin biotin (LSAB) method. Thereby, we also employed 3% hydrogen\nperoxide(H2O2) for the inhibition of endogenous peroxidase activity and\nincubated the tissue sections with the biotinylated secondary antibody at room\ntemperature (RT). We now add the immunohistochemical details that had led us to\nthis optimized procedure as they also bear a more general relevance when\ndemonstrating intracellular tissue antigens. Our most important result is that\nendogenous peroxidase inhibition by 0.3% H2O2 coincided with an apparently\npositive IDE staining in an investigated breast cancer specimen whereas\ncombining a block by 3% H2O2 with an incubation of the biotinylated secondary\nantibody at RT, yet not at 37 degrees Celsius, revealed this specimen as almost\nentirely IDE-negative. Our present data caution against three different\nimmunohistochemical pitfalls that might cause falsely positive results and\nartifacts when using an LSAB- and peroxidase-based detection method: pressure\ncooking for AR, insufficient quenching of endogenous peroxidases and heating of\ntissue sections while incubating with biotinylated secondary antibodies.\n", "machine_text": "\nThrough the use of an immunohistochemical method utilizing no antigen retrieval (AR) by pressure cooking and a detection kit based on the labeled streptavidin biotin (LSAB) method, we identified the cytoplasmic zinc metalloprotease insulin-degrading enzyme (IDE) in normal and neoplastic human tissues. An important outcome of our experiments is that the combination of a blocking step with 3% hydrogen peroxide (H2O2) and an incubation of the biotinylated secondary antibody at room temperature (RT), not at 37 degrees Celsius, revealed nearly no IDE expression in a breast cancer specimen surveyed previously. Our findings forewarn potential immunohistochemical pitfalls including pressure cooking for AR, insufficient quenching of endogenous peroxidases, and heating of tissue sections during incubation with biotinylated secondary antibodies, which can give inaccurate, false-positive results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0374}
{"prompt": "Rephrase the abstract of an article with title 'Multifractality and scale invariance in human heartbeat dynamics'.\n  Human heart rate is known to display complex fluctuations. Evidence of\nmultifractality in heart rate fluctuations in healthy state has been reported\n[Ivanov et al., Nature {\\bf 399}, 461 (1999)]. This multifractal character\ncould be manifested as a dependence on scale or beat number of the probability\ndensity functions (PDFs) of the heart rate increments. On the other hand, scale\ninvariance has been recently reported in a detrended analysis of healthy heart\nrate increments [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. In\nthis paper, we resolve this paradox by clarifying that the scale invariance\nreported is actually exhibited by the PDFs of the sum of detrended healthy\nheartbeat intervals taken over different number of beats, and demonstrating\nthat the PDFs of detrended healthy heart rate increments are scale dependent.\nOur work also establishes that this scale invariance is a general feature of\nhuman heartbeat dynamics, which is shared by heart rate fluctuations in both\nhealthy and pathological states.\n\n", "human_text": "  Human heart rate is known to display complex fluctuations. Evidence of\nmultifractality in heart rate fluctuations in healthy state has been reported\n[Ivanov et al., Nature {\\bf 399}, 461 (1999)]. This multifractal character\ncould be manifested as a dependence on scale or beat number of the probability\ndensity functions (PDFs) of the heart rate increments. On the other hand, scale\ninvariance has been recently reported in a detrended analysis of healthy heart\nrate increments [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. In\nthis paper, we resolve this paradox by clarifying that the scale invariance\nreported is actually exhibited by the PDFs of the sum of detrended healthy\nheartbeat intervals taken over different number of beats, and demonstrating\nthat the PDFs of detrended healthy heart rate increments are scale dependent.\nOur work also establishes that this scale invariance is a general feature of\nhuman heartbeat dynamics, which is shared by heart rate fluctuations in both\nhealthy and pathological states.\n", "machine_text": "\nThe study of human heart rate has uncovered a complexity of fluctuation patterns. Previously, multifractality had been observed in heart rate fluctuations of healthy individuals [Ivanov et al., Nature {\\bf 399}, 461 (1999)]. Additionally, recent works have highlighted the presence of scale invariance in heart rate fluctuations, as seen in detrended analyses of healthy subjects [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. This paper provides clarification of this paradox by demonstrating that the scale invariance is present in the probability density functions (PDFs) of summed detrended heart rate intervals, and not in that of detrended heart rate increments. Our findings moreover uncover a general feature of human heartbeat dynamics, to be shared by healthy and pathological states alike.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2415}
{"prompt": "Rephrase the abstract of an article with title 'Does confining the hard-sphere fluid between hard walls change its\n  average properties?'.\n  We use grand canonical transition-matrix Monte Carlo and discontinuous\nmolecular dynamics simulations to generate precise thermodynamic and kinetic\ndata for the equilibrium hard-sphere fluid confined between smooth hard walls.\nThese simulations show that the pronounced inhomogeneous structuring of the\nfluid normal to the confining walls, often the primary focus of density\nfunctional theory studies, has a negligible effect on many of its average\nproperties over a surprisingly broad range of conditions. We present one\nconsequence of this insensitivity to confinement: a simple analytical equation\nrelating the average density of the confined fluid to that of the bulk fluid\nwith equal activity. Nontrivial implications of confinement for average fluid\nproperties do emerge in this system, but only when the fluid is both (i) dense\nand (ii) confined to a gap smaller than approximately three particle diameters.\nFor this limited set of conditions, we find that \"in-phase\" oscillatory\ndeviations in excess entropy and self-diffusivity (relative to the behavior of\nthe bulk fluid at the same average density) occur as a function of gap size.\nThese paired thermodynamic/kinetic deviations from bulk behavior appear to\nreflect the geometric packing frustration that arises when the confined space\ncannot naturally accommodate an integer number of particle layers.\n\n", "human_text": "  We use grand canonical transition-matrix Monte Carlo and discontinuous\nmolecular dynamics simulations to generate precise thermodynamic and kinetic\ndata for the equilibrium hard-sphere fluid confined between smooth hard walls.\nThese simulations show that the pronounced inhomogeneous structuring of the\nfluid normal to the confining walls, often the primary focus of density\nfunctional theory studies, has a negligible effect on many of its average\nproperties over a surprisingly broad range of conditions. We present one\nconsequence of this insensitivity to confinement: a simple analytical equation\nrelating the average density of the confined fluid to that of the bulk fluid\nwith equal activity. Nontrivial implications of confinement for average fluid\nproperties do emerge in this system, but only when the fluid is both (i) dense\nand (ii) confined to a gap smaller than approximately three particle diameters.\nFor this limited set of conditions, we find that \"in-phase\" oscillatory\ndeviations in excess entropy and self-diffusivity (relative to the behavior of\nthe bulk fluid at the same average density) occur as a function of gap size.\nThese paired thermodynamic/kinetic deviations from bulk behavior appear to\nreflect the geometric packing frustration that arises when the confined space\ncannot naturally accommodate an integer number of particle layers.\n", "machine_text": "\nWe investigate the effects of confining a hard-sphere fluid within smooth hard walls\nby means of grand canonical transition-matrix Monte Carlo and discontinuous\nmolecular dynamics simulations. Results demonstrate that the non-uniform structuring\nof the fluid, usually studied by density functional theory, has a minor influence \non its average properties within a wide range of conditions. Therefore, an analytical\nexpression is provided to relate the confined and bulk fluid average densities of equal\nactivity. While the bulk system is unaltered by confinement, we observe a distinct\noscillating behavior in excess entropy and self-diffusivity when the confined space is \ndense and smaller than three particle diameters. Such thermodynamic and kinetic deviations\nresult from the geometric frustration that arises due to difficulties in packing an\ninteger number of layers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2224}
{"prompt": "Rephrase the abstract of an article with title 'Detection of VHE gamma-ray emission from the distant blazar 1ES 1101-232\n  with H.E.S.S. and broadband characterisation'.\n  The blazar 1ES 1101-232 was observed with the High Energy Stereoscopic System\n(H.E.S.S.) of Atmospheric Cherenkov Telescopes (ACT) in 2004 and 2005, for a\nlive time of 43 hours. VHE (E > 10^11 eV) gamma-rays were detected for the\nfirst time from this object. VHE observations of blazars are used to\ninvestigate the inner parts of the blazar jets, and also to study the\nextragalactic background light (EBL) in the near-infrared band. Observations in\n2005 were conducted in a multiwavelength campaign, together with the RXTE\nsatellite and optical observations. In 2004, simultaneous observations with\nXMM-Newton were obtained. 1ES 1101-232 was detected with H.E.S.S. with an\nexcess of 649 photons, at a significance of 10 sigma. The measured VHE\ngamma-ray flux amounts to dN/dE = (5.63 +- 0.89) x 10^-13 (E/TeV)^-(2.94 +-\n0.20) cm^-2 s^-1 TeV^-1, above a spectral energy threshold of 225 GeV. No\nsignificant variation of the VHE gamma-ray flux on any time scale was found.\n1ES 1101-232 exhibits a very hard spectrum, and at a redshift of z=0.186, is\nthe blazar with the highest confirmed redshift detected in VHE gamma-rays so\nfar. The data allow the construction of truly simultaneous spectral energy\ndistributions of the source, from the optical to the VHE band. Using an EBL\nmodel with \\nu F_\\nu = 14 nW m^-2 sr^-1 at 1.5 \\mu m as presented in Aharonian\net al. (Nature, 2006, 440, 1018) suggests an intrinsic VHE power output peak of\nthe source at above 3 TeV.\n\n", "human_text": "  The blazar 1ES 1101-232 was observed with the High Energy Stereoscopic System\n(H.E.S.S.) of Atmospheric Cherenkov Telescopes (ACT) in 2004 and 2005, for a\nlive time of 43 hours. VHE (E > 10^11 eV) gamma-rays were detected for the\nfirst time from this object. VHE observations of blazars are used to\ninvestigate the inner parts of the blazar jets, and also to study the\nextragalactic background light (EBL) in the near-infrared band. Observations in\n2005 were conducted in a multiwavelength campaign, together with the RXTE\nsatellite and optical observations. In 2004, simultaneous observations with\nXMM-Newton were obtained. 1ES 1101-232 was detected with H.E.S.S. with an\nexcess of 649 photons, at a significance of 10 sigma. The measured VHE\ngamma-ray flux amounts to dN/dE = (5.63 +- 0.89) x 10^-13 (E/TeV)^-(2.94 +-\n0.20) cm^-2 s^-1 TeV^-1, above a spectral energy threshold of 225 GeV. No\nsignificant variation of the VHE gamma-ray flux on any time scale was found.\n1ES 1101-232 exhibits a very hard spectrum, and at a redshift of z=0.186, is\nthe blazar with the highest confirmed redshift detected in VHE gamma-rays so\nfar. The data allow the construction of truly simultaneous spectral energy\ndistributions of the source, from the optical to the VHE band. Using an EBL\nmodel with \\nu F_\\nu = 14 nW m^-2 sr^-1 at 1.5 \\mu m as presented in Aharonian\net al. (Nature, 2006, 440, 1018) suggests an intrinsic VHE power output peak of\nthe source at above 3 TeV.\n", "machine_text": "\nA 43 hour live time observation with the High Energy Stereoscopic System (H.E.S.S.) of Atmospheric Cherenkov Telescopes (ACT) research found VHE (E > 10^11 eV) gamma-rays detected from a distant blazar, 1ES 1101-232, for the first time. This finding can be used to investigate the inner parts of the blazar jets as well as the extragalactic background light (EBL) in the near-infrared band. During the observation period of 2004 and 2005, H.E.S.S. detected 649 photons with a significance of 10 sigma. The VHE gamma-ray flux had a measurement of dN/dE = (5.63 +- 0.89) x 10^-13 (E/TeV)^-(2.94 +- 0.20) cm^-2 s^-1 TeV^-1, with a spectral energy threshold of 225 GeV. Also found was the lack of notable flux variation on any time scale and a very hard spectrum. Lastly, 1ES 1101-232 has the highest confirmed redshift detected in VHE gamma-rays so far, at z = 0.186. Simultaneous spectral energy distributions were constructed of the source, from the optical to the VHE band, using an EBL model with a peak of 3 TeV.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2946}
{"prompt": "Rephrase the abstract of an article with title 'Capillary ordering and layering transitions in two-dimensional hard-rod\n  fluids'.\n  In this article we calculate the surface phase diagram of a two-dimensional\nhard-rod fluid confined between two hard lines. In a first stage we study the\nsemi-infinite system consisting of an isotropic fluid in contact with a single\nhard line. We have found complete wetting by the columnar phase at the\nwall-isotropic fluid interface. When the fluid is confined between two hard\nwalls, capillary columnar ordering occurs via a first-order phase transition.\nFor higher chemical potentials the system exhibits layering transitions even\nfor very narrow slits (near the one-dimensional limit). The theoretical model\nused was a density-functional theory based on the Fundamental-Measure\nFunctional applied to a fluid of hard rectangles in the restricted-orientation\napproximation (Zwanzig model). The results presented here can be checked\nexperimentally in two-dimensional granular media made of rods, where vertical\nmotions induced by an external source and excluded volume interactions between\nthe grains allow the system to explore those stationary states which\nentropically maximize packing configurations. We claim that some of the surface\nphenomena found here can be present in two-dimensional granular-media fluids.\n\n", "human_text": "  In this article we calculate the surface phase diagram of a two-dimensional\nhard-rod fluid confined between two hard lines. In a first stage we study the\nsemi-infinite system consisting of an isotropic fluid in contact with a single\nhard line. We have found complete wetting by the columnar phase at the\nwall-isotropic fluid interface. When the fluid is confined between two hard\nwalls, capillary columnar ordering occurs via a first-order phase transition.\nFor higher chemical potentials the system exhibits layering transitions even\nfor very narrow slits (near the one-dimensional limit). The theoretical model\nused was a density-functional theory based on the Fundamental-Measure\nFunctional applied to a fluid of hard rectangles in the restricted-orientation\napproximation (Zwanzig model). The results presented here can be checked\nexperimentally in two-dimensional granular media made of rods, where vertical\nmotions induced by an external source and excluded volume interactions between\nthe grains allow the system to explore those stationary states which\nentropically maximize packing configurations. We claim that some of the surface\nphenomena found here can be present in two-dimensional granular-media fluids.\n", "machine_text": "\nThis paper examines the surface phase diagram of a two-dimensional fluid of hard rods confined between two rigid lines. Utilizing a density-functional theory based on the Fundamental-Measure Functional and the Zwanzig model for restricted orientation, we discovered that the wall-fluid interface is fully wetted by the columnar phase. Through a first-order transition, confinement between the two walls leads to capillary columnar ordering. For higher chemical potentials, we also identified layering transitions occurring even for narrow slits close to the one-dimensional limit. We conjecture that these surface phenomena could be observed experimentally in two-dimensional systems of rods where external forces can induce vertical motion and excluded volume effects may lead to entropically-maximized packing configurations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1467}
{"prompt": "Rephrase the abstract of an article with title 'Selection Bias in Observing the Cosmological Evolution of the Mbh-sigma\n  and Mbh-L Relationships'.\n  Programs to observe evolution in the Mbh-sigma or Mbh-L relations typically\ncompare black-hole masses, Mbh, in high-redshift galaxies selected by nuclear\nactivity to Mbh in local galaxies selected by luminosity L, or stellar velocity\ndispersion sigma. Because AGN luminosity is likely to depend on Mbh, selection\neffects are different for high-redshift and local samples, potentially\nproducing a false signal of evolution. This bias arises because cosmic scatter\nin the Mbh-sigma and Mbh-L relations means that the mean log(L) or log(sigma)\namong galaxies that host a black hole of given Mbh, may be substantially\ndifferent than the log(L) or log(sigma) obtained from inverting the Mbh-L or\nMbh-sigma relations for the same nominal Mbh. The bias is particularly strong\nat high Mbh, where the luminosity and dispersion functions of galaxies are\nfalling rapidly. The most massive black holes occur more often as rare outliers\nin galaxies of modest mass than in the even rarer high-mass galaxies, which\nwould otherwise be the sole location of such black holes in the absence of\ncosmic scatter. Because of this bias, Mbh will typically appear to be too large\nin the distant sample for a given L or sigma. For the largest black holes and\nthe largest plausible cosmic scatter, the bias can reach a factor of 3 in Mbh\nfor the Mbh-sigma relation and a factor of 9 for the Mbh-L relation.\nUnfortunately, the actual cosmic scatter is not known well enough to correct\nfor the bias. Measuring evolution of the Mbh and galaxy property relations\nrequires object selection to be precisely defined and exactly the same at all\nredshifts.\n\n", "human_text": "  Programs to observe evolution in the Mbh-sigma or Mbh-L relations typically\ncompare black-hole masses, Mbh, in high-redshift galaxies selected by nuclear\nactivity to Mbh in local galaxies selected by luminosity L, or stellar velocity\ndispersion sigma. Because AGN luminosity is likely to depend on Mbh, selection\neffects are different for high-redshift and local samples, potentially\nproducing a false signal of evolution. This bias arises because cosmic scatter\nin the Mbh-sigma and Mbh-L relations means that the mean log(L) or log(sigma)\namong galaxies that host a black hole of given Mbh, may be substantially\ndifferent than the log(L) or log(sigma) obtained from inverting the Mbh-L or\nMbh-sigma relations for the same nominal Mbh. The bias is particularly strong\nat high Mbh, where the luminosity and dispersion functions of galaxies are\nfalling rapidly. The most massive black holes occur more often as rare outliers\nin galaxies of modest mass than in the even rarer high-mass galaxies, which\nwould otherwise be the sole location of such black holes in the absence of\ncosmic scatter. Because of this bias, Mbh will typically appear to be too large\nin the distant sample for a given L or sigma. For the largest black holes and\nthe largest plausible cosmic scatter, the bias can reach a factor of 3 in Mbh\nfor the Mbh-sigma relation and a factor of 9 for the Mbh-L relation.\nUnfortunately, the actual cosmic scatter is not known well enough to correct\nfor the bias. Measuring evolution of the Mbh and galaxy property relations\nrequires object selection to be precisely defined and exactly the same at all\nredshifts.\n", "machine_text": "\nObserving the evolution of the Mbh-sigma and Mbh-L relations requires careful consideration of selection bias, as AGN luminosity is known to be linked to black-hole mass. This bias comes from cosmic scatter in the mentioned relations, meaning the mean luminosity or stellar velocity dispersions for galaxies of a given Mbh may be different from those given by inverting said relations. The bias is particularly pronounced for high Mbh, where luminosity and dispersion functions for galaxies drop off rapidly. This can lead to Mbh being perceived as larger in distant samples for certain luminosities or dispersions. To properly measure evolution, selection must be accurately replicated across all redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4103}
{"prompt": "Rephrase the abstract of an article with title 'Constraining GRB progenitor models by probing Wolf-Rayet wind geometries\n  in the Large Magellanic Cloud'.\n  The favoured progenitors of long-duration gamma-ray bursts (GRBs) are rapidly\nrotating Wolf-Rayet (WR) stars. However, most Galactic WR stars are slow\nrotators, as stellar winds are thought to remove angular momentum. This poses a\nchallenge to the collapsar model. Recent observations indicate that GRBs occur\npredominately in low metallicity (Z) environments, which may resolve the\nproblem: lower Z leads to less mass loss, which may inhibit angular momentum\nremoval, allowing WR stars to remain rotating rapidly until collapse. We wish\nto determine whether low Z WR stars rotate on average more rapidly than\nGalactic WR stars, and perform a Very Large Telescope (VLT) linear\nspectropolarimetry survey of WR stars in the low Z environment of the Large\nMagellanic Cloud (LMC) and compare our results with the Galactic sample. We\nfind that only 2 out of 13 (i.e. 15%) of LMC WR stars show line polarization\neffects, compared to a similarly low fraction of ~15-20% for Galactic WR stars.\nThe low incidence of line polarization effects in LMC WR stars suggests that\nthe threshold metallicity where significant differences in WR rotational\nproperties occur is below that of the LMC (Z ~ 0.5 Zsun), possibly constraining\nGRB progenitor channels to this upper metallicity.\n\n", "human_text": "  The favoured progenitors of long-duration gamma-ray bursts (GRBs) are rapidly\nrotating Wolf-Rayet (WR) stars. However, most Galactic WR stars are slow\nrotators, as stellar winds are thought to remove angular momentum. This poses a\nchallenge to the collapsar model. Recent observations indicate that GRBs occur\npredominately in low metallicity (Z) environments, which may resolve the\nproblem: lower Z leads to less mass loss, which may inhibit angular momentum\nremoval, allowing WR stars to remain rotating rapidly until collapse. We wish\nto determine whether low Z WR stars rotate on average more rapidly than\nGalactic WR stars, and perform a Very Large Telescope (VLT) linear\nspectropolarimetry survey of WR stars in the low Z environment of the Large\nMagellanic Cloud (LMC) and compare our results with the Galactic sample. We\nfind that only 2 out of 13 (i.e. 15%) of LMC WR stars show line polarization\neffects, compared to a similarly low fraction of ~15-20% for Galactic WR stars.\nThe low incidence of line polarization effects in LMC WR stars suggests that\nthe threshold metallicity where significant differences in WR rotational\nproperties occur is below that of the LMC (Z ~ 0.5 Zsun), possibly constraining\nGRB progenitor channels to this upper metallicity.\n", "machine_text": "\nThis study aimed to investigate whether GRB progenitors, namely rapidly rotating Wolf-Rayet (WR) stars, could be constrained by the low-metallicity environment of the Large Magellanic Cloud (LMC). To this end, observations using the Very Large Telescope (VLT) linear spectropolarimetry were carried out on WR stars in the LMC and compared with those from the Galactic sample. We found that only 15% of LMC WR stars showed line polarization effects, similar to the Galactic samples. This suggests that the threshold metallicity where a difference in WR rotational properties occurs is less than that of the LMC (i.e. < 0.5 Zsun). This may in turn imply that GRB progenitor channels are limited to this upper metallicity.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.269}
{"prompt": "Rephrase the abstract of an article with title 'Anisotropic Locations of Satellite Galaxies: Clues to the Orientations\n  of Galaxies within their Dark Matter Halos'.\n  We investigate the locations of the satellites of relatively isolated host\ngalaxies in the Sloan Digital Sky Survey and the Millennium Run simulation.\nProvided we use two distinct prescriptions to embed luminous galaxies within\nthe simulated dark matter halos (ellipticals share the shapes of their halos,\nwhile disks have angular momenta that are aligned with the net angular momenta\nof their halos), we find a fair agreement between observation and theory.\nAveraged over scales r_p \\le 500 kpc, the satellites of red, high-mass hosts\nwith low star formation rates are found preferentially near the major axes of\ntheir hosts. In contrast, the satellites of blue, low-mass hosts with low star\nformation rates show little to no anisotropy when averaged over the same scale.\nThe difference between the locations of the satellites of red and blue hosts\ncannot be explained by the effects of interlopers in the data. Instead, it is\ncaused primarily by marked differences in the dependence of the mean satellite\nlocation, <\\phi>, on the projected distance at which the satellites are found.\nWe also find that the locations of red, high-mass satellites with low star\nformation rates show considerably more anisotropy than do the locations of\nblue, low--mass satellites with high star formation rates. There are two\ncontributors to this result. First, the blue satellites have only recently\narrived within their hosts' halos, while the red satellites arrived in the far\ndistant past. Second, the sample of blue satellites is heavily contaminated by\ninterlopers, which suppresses the measured anisotropy compared to the intrinsic\nanisotropy.\n\n", "human_text": "  We investigate the locations of the satellites of relatively isolated host\ngalaxies in the Sloan Digital Sky Survey and the Millennium Run simulation.\nProvided we use two distinct prescriptions to embed luminous galaxies within\nthe simulated dark matter halos (ellipticals share the shapes of their halos,\nwhile disks have angular momenta that are aligned with the net angular momenta\nof their halos), we find a fair agreement between observation and theory.\nAveraged over scales r_p \\le 500 kpc, the satellites of red, high-mass hosts\nwith low star formation rates are found preferentially near the major axes of\ntheir hosts. In contrast, the satellites of blue, low-mass hosts with low star\nformation rates show little to no anisotropy when averaged over the same scale.\nThe difference between the locations of the satellites of red and blue hosts\ncannot be explained by the effects of interlopers in the data. Instead, it is\ncaused primarily by marked differences in the dependence of the mean satellite\nlocation, <\\phi>, on the projected distance at which the satellites are found.\nWe also find that the locations of red, high-mass satellites with low star\nformation rates show considerably more anisotropy than do the locations of\nblue, low--mass satellites with high star formation rates. There are two\ncontributors to this result. First, the blue satellites have only recently\narrived within their hosts' halos, while the red satellites arrived in the far\ndistant past. Second, the sample of blue satellites is heavily contaminated by\ninterlopers, which suppresses the measured anisotropy compared to the intrinsic\nanisotropy.\n", "machine_text": "\nIn this article, we explore the positioning of isolated satellites of host galaxies in the Sloan Digital Sky Survey and the Millennium Run simulation in comparison. We discover a good correspondence between the observations and the theory when two distinct prescriptions to embed luminous galaxies within the simulated dark matter halos are applied. Looking at scales of up to 500 kpc, it is evident that the satellites of red hosts with low star formation rates are generally situated near the host's major axes, whereas the satellites orbiting blue, low-mass hosts with similar star formation rates show very little anisotropy. The difference in the positioning of the blue and red satellites likely stems from the varying dependence of their mean location in relation to the projected distance between them and the interloper contamination in the latter sample. Furthermore, the red satellites exhibit much greater anisotropy than the blue due to their ancient arrival date in their hosts' halos as well as the lower anisotropy rate because of the interloper pollution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3441}
{"prompt": "Rephrase the abstract of an article with title 'Dirac Neutrino Dark Matter'.\n  We investigate the possibility that dark matter is made of heavy Dirac\nneutrinos with mass in the range [O(1) GeV- a few TeV] and with suppressed but\nnon-zero coupling to the Standard Model Z as well as a coupling to an\nadditional Z' gauge boson. The first part of this paper provides a\nmodel-independent analysis for the relic density and direct detection in terms\nof four main parameters: the mass, the couplings to the Z, to the Z' and to the\nHiggs. These WIMP candidates arise naturally as Kaluza-Klein states in\nextra-dimensional models with extended electroweak gauge group SU(2)_L* SU(2)_R\n* U(1). They can be stable because of Kaluza-Klein parity or of other discrete\nsymmetries related to baryon number for instance, or even, in the low mass and\nlow coupling limits, just because of a phase-space-suppressed decay width. An\ninteresting aspect of warped models is that the extra Z' typically couples only\nto the third generation, thus avoiding the usual experimental constraints. In\nthe second part of the paper, we illustrate the situation in details in a\nwarped GUT model.\n\n", "human_text": "  We investigate the possibility that dark matter is made of heavy Dirac\nneutrinos with mass in the range [O(1) GeV- a few TeV] and with suppressed but\nnon-zero coupling to the Standard Model Z as well as a coupling to an\nadditional Z' gauge boson. The first part of this paper provides a\nmodel-independent analysis for the relic density and direct detection in terms\nof four main parameters: the mass, the couplings to the Z, to the Z' and to the\nHiggs. These WIMP candidates arise naturally as Kaluza-Klein states in\nextra-dimensional models with extended electroweak gauge group SU(2)_L* SU(2)_R\n* U(1). They can be stable because of Kaluza-Klein parity or of other discrete\nsymmetries related to baryon number for instance, or even, in the low mass and\nlow coupling limits, just because of a phase-space-suppressed decay width. An\ninteresting aspect of warped models is that the extra Z' typically couples only\nto the third generation, thus avoiding the usual experimental constraints. In\nthe second part of the paper, we illustrate the situation in details in a\nwarped GUT model.\n", "machine_text": "This article investigates the potential of Dirac Neutrinos as the composition of dark matter. A model-independent summary is given of the four main parameters determining the relic density and direct detection: mass, couplings to the Z, to the Z' and to the Higgs. The article additionally explores how extended electroweak gauge groups and discrete symmetries allow for these WIMP candidates to be stable, as well as describing how the extra Z' tends to couple mainly to the third generation, therefore avoiding various existing constraints. Ultimately, a warped GUT model is used to illustrate the situation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0526}
{"prompt": "Rephrase the abstract of an article with title 'An X-ray Survey in SA 57 with XMM-Newton'.\n  The maximum number density of Active Galactic Nuclei (AGNs), as deduced from\nX-ray studies, occurs at z<~1, with lower luminosity objects peaking at smaller\nredshifts. Optical studies lead to a different evolutionary behaviour, with a\nnumber density peaking at z~2 independently of the intrinsic luminosity, but\nthis result is limited to active nuclei brighter than the host galaxy. A\nselection based on optical variability can detect low luminosity AGNs (LLAGNs),\nwhere the host galaxy light prevents the identification by non-stellar colours.\nWe want to collect X-ray data in a field where it exists an optically-selected\nsample of \"variable galaxies'', i.e. variable objects with diffuse appearance,\nto investigate the X-ray and optical properties of the population of AGNs,\nparticularly of low luminosity ones, where the host galaxy is visible. We\nobserved a field of 0.2 deg^2 in the Selected Area 57, for 67ks with\nXMM-Newton. We detected X-ray sources, and we correlated the list with a\nphotographic survey of SA 57, complete to B_J~23 and with available\nspectroscopic data. We obtained a catalogue of 140 X-ray sources to limiting\nfluxes 5x10^-16, 2x10^-15 erg/cm^2/s in the 0.5-2 keV and 2-10 keV\nrespectively, 98 of which are identified in the optical bands. The X-ray\ndetection of part of the variability-selected candidates confirms their AGN\nnature. Diffuse variable objects populate the low luminosity side of the\nsample. Only 25/44 optically-selected QSOs are detected in X-rays. 15% of all\nQSOs in the field have X/O<0.1.\n\n", "human_text": "  The maximum number density of Active Galactic Nuclei (AGNs), as deduced from\nX-ray studies, occurs at z<~1, with lower luminosity objects peaking at smaller\nredshifts. Optical studies lead to a different evolutionary behaviour, with a\nnumber density peaking at z~2 independently of the intrinsic luminosity, but\nthis result is limited to active nuclei brighter than the host galaxy. A\nselection based on optical variability can detect low luminosity AGNs (LLAGNs),\nwhere the host galaxy light prevents the identification by non-stellar colours.\nWe want to collect X-ray data in a field where it exists an optically-selected\nsample of \"variable galaxies'', i.e. variable objects with diffuse appearance,\nto investigate the X-ray and optical properties of the population of AGNs,\nparticularly of low luminosity ones, where the host galaxy is visible. We\nobserved a field of 0.2 deg^2 in the Selected Area 57, for 67ks with\nXMM-Newton. We detected X-ray sources, and we correlated the list with a\nphotographic survey of SA 57, complete to B_J~23 and with available\nspectroscopic data. We obtained a catalogue of 140 X-ray sources to limiting\nfluxes 5x10^-16, 2x10^-15 erg/cm^2/s in the 0.5-2 keV and 2-10 keV\nrespectively, 98 of which are identified in the optical bands. The X-ray\ndetection of part of the variability-selected candidates confirms their AGN\nnature. Diffuse variable objects populate the low luminosity side of the\nsample. Only 25/44 optically-selected QSOs are detected in X-rays. 15% of all\nQSOs in the field have X/O<0.1.\n", "machine_text": "\nWe conducted a 67 ks X-ray survey in the SA 57 area with XMM-Newton to examine the X-ray and optical properties of a population of AGNs, particularly of low-luminosity AGNs, as well as to detect diffuse and variable objects. Our resulting catalogue of 140 X-ray sources has a limiting flux of 5x10^-16, 2x10^-15 erg/cm^2/s in the 0.5-2 keV and 2-10 keV, respectively. We confirm the AGN nature of some of the optically-selected variables by their X-ray detection, however, only 25 out of 44 optically-selected quasars were detected. The results indicate that variable objects may be mostly low-lumiosity and 15% of all quasars in the field have X/O<0.1.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3552}
{"prompt": "Rephrase the abstract of an article with title 'Glimpsing through the high redshift neutral hydrogen fog'.\n  We analyze the transmitted flux in a sample of 17 QSOs spectra at\n5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral\nhydrogen fraction, xHI, at z~6. We study separately the narrow transmission\nwindows (peaks) and the wide dark portions (gaps) in the observed absorption\nspectra. By comparing the statistics of these spectral features with Lyalpha\nforest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at\nz=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The\nfrequency and physical sizes of the peaks imply an origin in cosmic underdense\nregions and/or in HII regions around faint quasars or galaxies. In one case\n(the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along\nthe LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density\nis explained by the first-ever detected transverse proximity effect in the HI\nLyalpha forest; this indicates that at least some peaks result from a locally\nenhanced radiation field. We then obtain a strong lower limit on the foreground\nQSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be\nsystematically larger than the simulated ones. Reasons for such discrepancy\nmight reside either in the photoionization equilibrium assumption or in\nradiative transfer effects.\n\n", "human_text": "  We analyze the transmitted flux in a sample of 17 QSOs spectra at\n5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral\nhydrogen fraction, xHI, at z~6. We study separately the narrow transmission\nwindows (peaks) and the wide dark portions (gaps) in the observed absorption\nspectra. By comparing the statistics of these spectral features with Lyalpha\nforest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at\nz=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The\nfrequency and physical sizes of the peaks imply an origin in cosmic underdense\nregions and/or in HII regions around faint quasars or galaxies. In one case\n(the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along\nthe LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density\nis explained by the first-ever detected transverse proximity effect in the HI\nLyalpha forest; this indicates that at least some peaks result from a locally\nenhanced radiation field. We then obtain a strong lower limit on the foreground\nQSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be\nsystematically larger than the simulated ones. Reasons for such discrepancy\nmight reside either in the photoionization equilibrium assumption or in\nradiative transfer effects.\n", "machine_text": "\nAnalyzing 17 QSO spectra in a redshift range of 5.74<zem<6.42, we make an attempt to obtain a precise estimate of the ratio of neutral hydrogen atoms to the total number of hydrogen atoms in the extensive volumes of the universe at z~6. Performing a Ly\u03b1 forest simulation, we infer that xHI (the volume-averaged neutral hydrogen fraction) increases steadily from 10^-4.4 at z=5.3 to 10^-4.2 at z=5.6. The maximal upper limit is 0.36 at z=6.3. Examining the transmission windows or peaks, as well as the wide dark portions or gaps occurring between them, we infer that they stem from a mixture of cosmological underdensities and HII areas around faint quasars or galaxies. We observe a transverse proximity effect in the HI Ly\u03b1 forest in the case of the intervening HII region of a faint quasar located at z=5.70 and its impact on SDSS J1148+5251 at z=6.42, the first of its kind. This interlock provides a lower limit for the lifetime of the foreground quasar of 11 million years at least. The widths of the detected peaks seem broader than the simulated ones, suggesting that either the assumption of the photoionization equilibrium is flawed or radiative transfer effects are in play.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1053}
{"prompt": "Rephrase the abstract of an article with title 'The aqueous and crystalline forms of L-alanine zwitterion'.\n  The structural properties of L-alanine amino acid in aqueous solution and in\ncrystalline phase have been studied by means of density-functional\nelectronic-structure and molecular dynamics simulations. The solvated\nzwitterionic structure of L-alanine (+NH3-C2H4-COO-) was systematically\ncompared to the structure of its zwitterionic crystalline analogue acquired\nfrom both computer simulations and experiments. It turns out that the\nstructural properties of an alanine molecule in aqueous solution can differ\nsignificantly from those in crystalline phase, these differences being mainly\nattributed to hydrogen bonding interactions. In particular, we found that the\nlargest difference between the two alanine forms can be seen for the\norientation and bond lengths of the carboxylate (COO-) group: in aqueous\nsolution the C-O bond lengths appear to strongly correlate with the number of\nwater molecules which form hydrogen bonds with the COO- group. Furthermore, the\nhydrogen bond lengths are shorter and the hydrogen bond angles are larger for\nL-alanine in water as compared to crystal. Overall, our findings strongly\nsuggest that the generally accepted approach of extending the structural\ninformation acquired from crystallographic data to a L-alanine molecule in\naqueous solution should be used with caution.\n\n", "human_text": "  The structural properties of L-alanine amino acid in aqueous solution and in\ncrystalline phase have been studied by means of density-functional\nelectronic-structure and molecular dynamics simulations. The solvated\nzwitterionic structure of L-alanine (+NH3-C2H4-COO-) was systematically\ncompared to the structure of its zwitterionic crystalline analogue acquired\nfrom both computer simulations and experiments. It turns out that the\nstructural properties of an alanine molecule in aqueous solution can differ\nsignificantly from those in crystalline phase, these differences being mainly\nattributed to hydrogen bonding interactions. In particular, we found that the\nlargest difference between the two alanine forms can be seen for the\norientation and bond lengths of the carboxylate (COO-) group: in aqueous\nsolution the C-O bond lengths appear to strongly correlate with the number of\nwater molecules which form hydrogen bonds with the COO- group. Furthermore, the\nhydrogen bond lengths are shorter and the hydrogen bond angles are larger for\nL-alanine in water as compared to crystal. Overall, our findings strongly\nsuggest that the generally accepted approach of extending the structural\ninformation acquired from crystallographic data to a L-alanine molecule in\naqueous solution should be used with caution.\n", "machine_text": "\nThe structural properties of the L-alanine amino acid were examined through density-functional\nelectronic-structure and molecular dynamics simulations in both aqueous and crystalline form. It was\nfound that the two forms of L-alanine can be significantly different in terms of hydrogen bonding\ninteractions, with the bond lengths and angles of the carboxylate (COO-) group distinguished. The\nanalysis suggests that the bond lengths of the C-O bonds are directly related to the number of water\nmolecules interacting with the COO- unit, which tend to be longer in the crystalline form of the amino\nacid. The hydrogen bond lengths and angles are also observed to be shorter and larger in the aqueous\nform compared to the crystalline one. Consequently, our results imply that the information obtained\nfrom crystallographic data should be used with care when applied to the aqueous form of L-alanine.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.27}
{"prompt": "Rephrase the abstract of an article with title 'Investigations of the Non-Linear LMC Cepheid Period-Luminosity Relation\n  with Testimator and Schwarz Information Criterion Methods'.\n  In this paper, we investigate the linearity versus non-linearity of the Large\nMagellanic Cloud (LMC) Cepheid period-luminosity (P-L) relation using two\nstatistical approaches not previously applied to this problem: the testimator\nmethod and the Schwarz Information Criterion (SIC). The testimator method is\nextended to multiple stages for the first time, shown to be unbiased and the\nvariance of the estimated slope can be proved to be smaller than the standard\nslope estimated from linear regression theory. The Schwarz Information\nCriterion (also known as the Bayesian Information Criterion) is more\nconservative than the Akaike Information Criterion and tends to choose lower\norder models. By using simulated data sets, we verify that these statistical\ntechniques can be used to detect intrinsically linear and/or non-linear P-L\nrelations. These methods are then applied to independent LMC Cepheid data sets\nfrom the OGLE project and the MACHO project, respectively. Our results imply\nthat there is a change of slope in longer period ranges for all of the data\nsets. This strongly supports previous results, obtained from independent\nstatistical tests, that the observed LMC P-L relation is non-linear with a\nbreak period at/around 10 days.\n\n", "human_text": "  In this paper, we investigate the linearity versus non-linearity of the Large\nMagellanic Cloud (LMC) Cepheid period-luminosity (P-L) relation using two\nstatistical approaches not previously applied to this problem: the testimator\nmethod and the Schwarz Information Criterion (SIC). The testimator method is\nextended to multiple stages for the first time, shown to be unbiased and the\nvariance of the estimated slope can be proved to be smaller than the standard\nslope estimated from linear regression theory. The Schwarz Information\nCriterion (also known as the Bayesian Information Criterion) is more\nconservative than the Akaike Information Criterion and tends to choose lower\norder models. By using simulated data sets, we verify that these statistical\ntechniques can be used to detect intrinsically linear and/or non-linear P-L\nrelations. These methods are then applied to independent LMC Cepheid data sets\nfrom the OGLE project and the MACHO project, respectively. Our results imply\nthat there is a change of slope in longer period ranges for all of the data\nsets. This strongly supports previous results, obtained from independent\nstatistical tests, that the observed LMC P-L relation is non-linear with a\nbreak period at/around 10 days.\n", "machine_text": "In this research, we utilize two analytical methods, the testimator method and the Schwarz Information Criterion (SIC), to examine the linearity of the Large Magellanic Cloud Cepheid period-luminosity (P-L) relation. We demonstrate that the testimator approach is both unbiased and reduces the variance of the estimated slope. Applying SIC proves to be more conservative than the Akaike Information Criterion and usually opts for a lower order. We then apply these strategies to test simulated data sets to examine intrinsically linear or non-linear P-L relations. Ultimately, we apply the methods to independent LMC Cepheid data sets from the OGLE and MACHO projects, which exhibits changes in slope in the longer period ranges in all data sets, suggesting the non-linearity of the observed P-L correlation with a break period at approx. 10 days.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3601}
{"prompt": "Rephrase the abstract of an article with title 'Determination of the size, mass, and density of \"exomoons\" from\n  photometric transit timing variations'.\n  Precise photometric measurements of the upcoming space missions allow the\nsize, mass, and density of satellites of exoplanets to be determined. Here we\npresent such an analysis using the photometric transit timing variation\n($TTV_p$). We examined the light curve effects of both the transiting planet\nand its satellite. We define the photometric central time of the transit that\nis equivalent to the transit of a fixed photocenter. This point orbits the\nbarycenter, and leads to the photometric transit timing variations. The exact\nvalue of $TTV_p$ depends on the ratio of the density, the mass, and the size of\nthe satellite and the planet. Since two of those parameters are independent, a\nreliable estimation of the density ratio leads to an estimation of the size and\nthe mass of the exomoon. Upper estimations of the parameters are possible in\nthe case when an upper limit of $TTV_p$ is known. In case the density ratio\ncannot be estimated reliably, we propose an approximation with assuming equal\ndensities. The presented photocenter $TTV_p$ analysis predicts the size of the\nsatellite better than the mass. We simulated transits of the Earth-Moon system\nin front of the Sun. The estimated size and mass of the Moon are 0.020\nEarth-mass and 0.274 Earth-size if equal densities are assumed. This result is\ncomparable to the real values within a factor of 2. If we include the real\ndensity ratio (about 0.6), the results are 0.010 Earth-Mass and 0.253\nEarth-size, which agree with the real values within 20%.\n\n", "human_text": "  Precise photometric measurements of the upcoming space missions allow the\nsize, mass, and density of satellites of exoplanets to be determined. Here we\npresent such an analysis using the photometric transit timing variation\n($TTV_p$). We examined the light curve effects of both the transiting planet\nand its satellite. We define the photometric central time of the transit that\nis equivalent to the transit of a fixed photocenter. This point orbits the\nbarycenter, and leads to the photometric transit timing variations. The exact\nvalue of $TTV_p$ depends on the ratio of the density, the mass, and the size of\nthe satellite and the planet. Since two of those parameters are independent, a\nreliable estimation of the density ratio leads to an estimation of the size and\nthe mass of the exomoon. Upper estimations of the parameters are possible in\nthe case when an upper limit of $TTV_p$ is known. In case the density ratio\ncannot be estimated reliably, we propose an approximation with assuming equal\ndensities. The presented photocenter $TTV_p$ analysis predicts the size of the\nsatellite better than the mass. We simulated transits of the Earth-Moon system\nin front of the Sun. The estimated size and mass of the Moon are 0.020\nEarth-mass and 0.274 Earth-size if equal densities are assumed. This result is\ncomparable to the real values within a factor of 2. If we include the real\ndensity ratio (about 0.6), the results are 0.010 Earth-Mass and 0.253\nEarth-size, which agree with the real values within 20%.\n", "machine_text": "\n\n Photometric measurements taken by forthcoming space missions allow us to determine the size, mass, and density of exoplanets' satellites. We have conducted an analysis on the photometric transit timing variation ($TTV_p$) to analyze the light curve effects of the transiting planet and its satellite. We introduce the concept of the 'photocenter' time of the transit, which is equivalent to the transit of a fixed photocenter that orbits the barycenter, resulting in the photometric transit timing variations whose exact value depends on the ratio of the density, mass, and size of the satellite and the planet. When the density ratio is known, it permits a reliable estimation of the size and mass of an exomoon. An upper limit of $TTV_p$ can be set if the density ratio cannot be estimated accurately. We tested this method on the Earth-Moon system transit in front of the Sun and found that when assuming similar densities, the estimated size and mass of the Moon (0.020 Earth-mass and 0.274 Earth-size) were comparable to the real values within a factor of 2. When using the real density ratio (about 0.6), the results were 0.010 Earth-Mass and 0.253 Earth-size, which showed agreement with the true values within 20%.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1046}
{"prompt": "Rephrase the abstract of an article with title 'Is There a Universal Mass Function?'.\n  Following an old idea of Fritz Zwicky, we make an attempt to establish a\nuniversal mass function for astronomical objects on all scales. The object\nclasses considered are: solar system planets and small bodies, exoplanets,\nbrown dwarfs, stars and stellar remnants, open and globular clusters, molecular\nclouds, galaxies, groups and clusters of galaxies. For comparison we also\ninclude CDM halos taken from numerical simulations. We show that the mass\nfunctions of individual object classes, when properly normalized, can indeed be\nconcatenated to build a surprisingly continuous mass function of the universe,\nfrom approximately M = 10^(-20)Msun (sub-kilometer size asteroids) up to M =\n10^(16)Msun (rich clusters of galaxies), covering 36 orders of magnitude in\nmass. Most individual mass functions roughly follow a power law of the form\nphi(M) propto M^(-2). A notable exception are planets and small bodies which\nseem to obey a flatter distribution. CDM halos from high-resolution numerical\nsimulations show a very similar relation, again of universal slope -2, from\nclusters of galaxies all the way down to the planetary mass scale. On the scale\nof stars and star clusters this is a remarkable coincidence, as the formation\nprocesses involved are thought to be totally different (bottom-up gravitational\nclustering of DM halos versus top-down gravoturbulent fragmentation of gas\nclouds).\n\n", "human_text": "  Following an old idea of Fritz Zwicky, we make an attempt to establish a\nuniversal mass function for astronomical objects on all scales. The object\nclasses considered are: solar system planets and small bodies, exoplanets,\nbrown dwarfs, stars and stellar remnants, open and globular clusters, molecular\nclouds, galaxies, groups and clusters of galaxies. For comparison we also\ninclude CDM halos taken from numerical simulations. We show that the mass\nfunctions of individual object classes, when properly normalized, can indeed be\nconcatenated to build a surprisingly continuous mass function of the universe,\nfrom approximately M = 10^(-20)Msun (sub-kilometer size asteroids) up to M =\n10^(16)Msun (rich clusters of galaxies), covering 36 orders of magnitude in\nmass. Most individual mass functions roughly follow a power law of the form\nphi(M) propto M^(-2). A notable exception are planets and small bodies which\nseem to obey a flatter distribution. CDM halos from high-resolution numerical\nsimulations show a very similar relation, again of universal slope -2, from\nclusters of galaxies all the way down to the planetary mass scale. On the scale\nof stars and star clusters this is a remarkable coincidence, as the formation\nprocesses involved are thought to be totally different (bottom-up gravitational\nclustering of DM halos versus top-down gravoturbulent fragmentation of gas\nclouds).\n", "machine_text": "\nIn this paper we attempt to determine whether a universal mass function exists for all types of astronomical bodies. We identify nine distinct categories, including solar systems, exoplanets, brown dwarfs, stars, stellar remnants, open and globular clusters, molecular clouds, galaxies, and clusters of galaxies, along with data from high resolution numerical simulations of CDM halos. We conclude that the mass functions of each individual class, when normalized correctly, can indeed be combined to form an uninterrupted universal mass function ranging from mass values of 10^(-20)Msun to 10^(16)Msun, and spaning 36 orders of magnitude. A notable exception is seen with planets and small bodies, which appear to obey a flatter distribution. Remarkably, CDM halos from the simulations indicate a relation with a slope of -2 from galactic clusters to the planetary mass scale. This similarity is of great interest, as the formation processes for these objects are thought to be vastly different.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1599}
{"prompt": "Rephrase the abstract of an article with title 'Dahlberg's bilinear estimate for solutions of divergence form complex\n  elliptic equations'.\n  We consider divergence form elliptic operators $L=-\\dv A(x)\\nabla$, defined\nin $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$,\nwhere the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly\nelliptic, complex and $t$-independent. Using recently obtained results\nconcerning the boundedness and invertibility of layer potentials associated to\nsuch operators, we show that if $Lu=0$ in $\\mathbb{R}^{n+1}_+$, then for any\nvector-valued ${\\bf v} \\in W^{1,2}_{loc},$ we have the bilinear estimate\n$$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq\nC\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| +\n\\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv\n(\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is\nthe usual non-tangential maximal operator. The result is new even in the case\nof real symmetric coefficients, and generalizes the analogous result of\nDahlberg for harmonic functions on Lipschitz graph domains.\n\n", "human_text": "  We consider divergence form elliptic operators $L=-\\dv A(x)\\nabla$, defined\nin $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$,\nwhere the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly\nelliptic, complex and $t$-independent. Using recently obtained results\nconcerning the boundedness and invertibility of layer potentials associated to\nsuch operators, we show that if $Lu=0$ in $\\mathbb{R}^{n+1}_+$, then for any\nvector-valued ${\\bf v} \\in W^{1,2}_{loc},$ we have the bilinear estimate\n$$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq\nC\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| +\n\\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv\n(\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is\nthe usual non-tangential maximal operator. The result is new even in the case\nof real symmetric coefficients, and generalizes the analogous result of\nDahlberg for harmonic functions on Lipschitz graph domains.\n", "machine_text": "  We analyze the boundedness and invertibility of layer potentials associated to divergence form complex elliptic operators $L=-\\dv A(x)\\nabla$, where $A$ is a $L^{\\infty}$ coefficient matrix of size $(n+1)\\times(n+1)$, uniform elliptic and $t$-independent in $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$. Using the aforementioned results, we establish a new bilinear estimate for any ${\\bf v} \\in W^{1,2}_{loc}$. This is $$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq\nC\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| +\n\\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv\n(\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is the standard non-tangential maximal operator. This estimate can be applied for solutions of $Lu=0$ in $\\mathbb{R}^{n+1}_+$, and it is novel even when the coefficients are real and symmetric. Furthermore, it is a generalization of the analogous result by Dahlberg for harmonic functions on Lipschitz graph domains.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0839}
{"prompt": "Rephrase the abstract of an article with title 'First proper motions of thin dust filaments at the Galactic Center'.\n  Context: L'-band (3.8 micron) images of the Galactic Center show a large\nnumber of thin filaments in the mini-spiral, located west of the mini-cavity\nand along the inner edge of the Northern Arm. One possible mechanism that could\nproduce such structures is the interaction of a central wind with the\nmini-spiral. Additionally, we identify similar features that appear to be\nassociated with stars. Aims: We present the first proper motion measurements of\nthe thin dust filaments observed in the central parsec around SgrA* and\ninvestigate possible mechanisms that could be responsible for the observed\nmotions. Methods: The observations have been carried out using the NACO\nadaptive optics system at the ESO VLT. The images have been transformed to a\ncommon coordinate system and features of interest were extracted. Then a\ncross-correlation technique could be performed in order to determine the\noffsets between the features with respect to their position in the reference\nepoch. Results: We derive the proper motions of a number of filaments and 2\ncometary shaped dusty sources close (in projection) to SgrA*. We show that the\nshape and the motion of the filaments does not agree with a purely Keplerian\nmotion of the gas in the potential of the supermassive black hole at the\nposition of SgrA*. Therefore, additional mechanisms must be responsible for\ntheir formation and motion. We argue that the properties of the filaments are\nprobably related to an outflow from the disk of young mass-losing stars around\nSgrA*. In part, the outflow may originate from the black hole itself. We also\npresent some evidence and theoretical considerations that the outflow may be\ncollimated.\n\n", "human_text": "  Context: L'-band (3.8 micron) images of the Galactic Center show a large\nnumber of thin filaments in the mini-spiral, located west of the mini-cavity\nand along the inner edge of the Northern Arm. One possible mechanism that could\nproduce such structures is the interaction of a central wind with the\nmini-spiral. Additionally, we identify similar features that appear to be\nassociated with stars. Aims: We present the first proper motion measurements of\nthe thin dust filaments observed in the central parsec around SgrA* and\ninvestigate possible mechanisms that could be responsible for the observed\nmotions. Methods: The observations have been carried out using the NACO\nadaptive optics system at the ESO VLT. The images have been transformed to a\ncommon coordinate system and features of interest were extracted. Then a\ncross-correlation technique could be performed in order to determine the\noffsets between the features with respect to their position in the reference\nepoch. Results: We derive the proper motions of a number of filaments and 2\ncometary shaped dusty sources close (in projection) to SgrA*. We show that the\nshape and the motion of the filaments does not agree with a purely Keplerian\nmotion of the gas in the potential of the supermassive black hole at the\nposition of SgrA*. Therefore, additional mechanisms must be responsible for\ntheir formation and motion. We argue that the properties of the filaments are\nprobably related to an outflow from the disk of young mass-losing stars around\nSgrA*. In part, the outflow may originate from the black hole itself. We also\npresent some evidence and theoretical considerations that the outflow may be\ncollimated.\n", "machine_text": "  This paper presents the first proper motion measurements of thin dust filaments observed in the central parsec around the supermassive black hole SgrA*. We show that the shape and motion of the filaments does not match the expected Keplerian motion in the gravitational potential of SgrA*. Using the NACO adaptive optics system at the ESO VLT, we measure the offsets between features with respect to their position in a reference epoch in order to determine the proper motions of filaments and two sources close to SgrA*. We propose that the formation and motion of the filaments may be related to an outflow coming from a disk of young mass-losing stars and/or the black hole itself, which could be collimated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3675}
{"prompt": "Rephrase the abstract of an article with title 'Extended Optical Model Analyses of Elastic Scattering and Fusion Cross\n  Section Data for the 7Li+208Pb System at Near-Coulomb-Barrier Energies using\n  the Folding Potential'.\n  Simultaneous $\\chi^{2}$ analyses previously made for elastic scattering and\nfusion cross section data for the $^{6}$Li+$^{208}$Pb system is extended to the\n$^{7}$Li+$^{208}$Pb system at near-Coulomb-barrier energies based on the\nextended optical model approach, in which the polarization potential is\ndecomposed into direct reaction (DR) and fusion parts. Use is made of the\ndouble folding potential as a bare potential. It is found that the experimental\nelastic scattering and fusion data are well reproduced without introducing any\nnormalization factor for the double folding potential and that both the DR and\nfusion parts of the polarization potential determined from the $\\chi^{2}$\nanalyses satisfy separately the dispersion relation. Further, we find that the\nreal part of the fusion portion of the polarization potential is attractive\nwhile that of the DR part is repulsive except at energies far below the Coulomb\nbarrier energy. A comparison is made of the present results with those obtained\nfrom the Continuum Discretized Coupled Channel (CDCC) calculations and a\nprevious study based on the conventional optical model with a double folding\npotential. We also compare the present results for the $^7$Li+$^{208}$Pb system\nwith the analysis previously made for the $^{6}$Li+$^{208}$Pb system.\n\n", "human_text": "  Simultaneous $\\chi^{2}$ analyses previously made for elastic scattering and\nfusion cross section data for the $^{6}$Li+$^{208}$Pb system is extended to the\n$^{7}$Li+$^{208}$Pb system at near-Coulomb-barrier energies based on the\nextended optical model approach, in which the polarization potential is\ndecomposed into direct reaction (DR) and fusion parts. Use is made of the\ndouble folding potential as a bare potential. It is found that the experimental\nelastic scattering and fusion data are well reproduced without introducing any\nnormalization factor for the double folding potential and that both the DR and\nfusion parts of the polarization potential determined from the $\\chi^{2}$\nanalyses satisfy separately the dispersion relation. Further, we find that the\nreal part of the fusion portion of the polarization potential is attractive\nwhile that of the DR part is repulsive except at energies far below the Coulomb\nbarrier energy. A comparison is made of the present results with those obtained\nfrom the Continuum Discretized Coupled Channel (CDCC) calculations and a\nprevious study based on the conventional optical model with a double folding\npotential. We also compare the present results for the $^7$Li+$^{208}$Pb system\nwith the analysis previously made for the $^{6}$Li+$^{208}$Pb system.\n", "machine_text": "\nThe advanced optical model is employed to analyze dynamically the simultaneous $\\chi^2$ for both elastic scattering and fusion cross section data for $^7$Li+$^{208}$Pb at near-Coulomb-barrier energies. A double folding potential is used as the bare potential and no normalization is needed to explain the experimental data. The decomposition of the polarization potential into direct reaction (DR) and fusion parts indicates that the fusion part is attractive while the DR part is repulsive, apart from energies beneath the Coulomb barrier. We compare the current study with CDCC calculations and an earlier optical model study using a double folding potential. Additionally, the current results are contrasted with the previous analysis on the $^6$Li+$^{208}$Pb system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0586}
{"prompt": "Rephrase the abstract of an article with title 'The Reliability on the Direction of the Incident Neutrino for the Fully\n  Contained Events and Partially Contained Events due to QEL in the\n  Super-Kamiokande'.\n  In the SK analysis of the neutrino events for [Fully Contained Events] and\n[Partially Contained Events] on their zenith angle distribution, it is assumed\nthat the zenith angle of the incident neutrino is the same as that of the\ndetected charged lepton. In the present paper, we examine the validity of [the\nSK assumption on the direction] of the incident neutrinos. Concretely speaking,\nwe analyze muon-like events due to QEL. For the purpose, we develop [Time\nSequential Monte Carlo Simulation] to extract the conclusion on the validity of\nthe SK assumption. In our [Time Sequential Simulation], we simulate every\nphysical process concerned as exactly as possible without any approximation.\n  From the comparison between the zenith angle distributon of the emitted muons\nunder [the SK assumption on the direction] and the corresponding one obtained\nunder our [Time Sequential Simulation], it is concluded that the measurement of\nthe direction of the incident neutrino for the neutrino events occurring inside\nthe detector in the SK analysis turns out to be unreliable, which holds\nirrespective of the existence and/or non-existence of the neutrino oscillation.\n\n", "human_text": "  In the SK analysis of the neutrino events for [Fully Contained Events] and\n[Partially Contained Events] on their zenith angle distribution, it is assumed\nthat the zenith angle of the incident neutrino is the same as that of the\ndetected charged lepton. In the present paper, we examine the validity of [the\nSK assumption on the direction] of the incident neutrinos. Concretely speaking,\nwe analyze muon-like events due to QEL. For the purpose, we develop [Time\nSequential Monte Carlo Simulation] to extract the conclusion on the validity of\nthe SK assumption. In our [Time Sequential Simulation], we simulate every\nphysical process concerned as exactly as possible without any approximation.\n  From the comparison between the zenith angle distributon of the emitted muons\nunder [the SK assumption on the direction] and the corresponding one obtained\nunder our [Time Sequential Simulation], it is concluded that the measurement of\nthe direction of the incident neutrino for the neutrino events occurring inside\nthe detector in the SK analysis turns out to be unreliable, which holds\nirrespective of the existence and/or non-existence of the neutrino oscillation.\n", "machine_text": "\nIn this article, we analyze the validity of the SK assumption that the direction of the incident neutrino is the same as that of the detected charged lepton for Fully Contained Events and Partially Contained Events due to QEL. We develop a Time Sequential Monte Carlo Simulation to simulate every physical process concerned in order to determine the accuracy of this SK assumption. By comparing the zenith angle distribution of the emitted muons under the SK assumption and the one produced by the Time Sequential Simulation, we conclude that the measurement of the direction of the incident neutrino for the events occurring inside the detector in the SK analysis is not reliable, regardless of whether or not neutrino oscillation exists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.019}
{"prompt": "Rephrase the abstract of an article with title 'Tight binding formulation of the dielectric response in semiconductor\n  nanocrystals'.\n  We report on a theoretical derivation of the electronic dielectric response\nof semiconductor nanocrystals using a tight-binding framework. Extending to the\nnanoscale the Hanke and Sham approach [Phys. Rev. B 12, 4501 (1975)] developed\nfor bulk semiconductors, we show how local field effects can be included in the\nstudy of confined systems. A great advantage of this scheme is that of being\nformulated in terms of localized orbitals and thus it requires very few\ncomputational resources and times. Applications to the optical and screening\nproperties of semiconductor nanocrystals are presented here and discussed.\nResults concerning the absorption cross section, the static polarizability and\nthe screening function of InAs (direct gap) and Si (indirect gap) nanocrystals\ncompare well to both first principles results and experimental data. We also\nshow that the present scheme allows us to easily go beyond the continuum\ndielectric model, based on the Clausius-Mossotti equation, which is frequently\nused to include the nanocrystal surface polarization. Our calculations indicate\nthat the continuum dielectric model, used in conjunction with a size dependent\ndielectric constant, underestimates the nanocrystal polarizability, leading to\nexceedingly strong surface polarization fields.\n\n", "human_text": "  We report on a theoretical derivation of the electronic dielectric response\nof semiconductor nanocrystals using a tight-binding framework. Extending to the\nnanoscale the Hanke and Sham approach [Phys. Rev. B 12, 4501 (1975)] developed\nfor bulk semiconductors, we show how local field effects can be included in the\nstudy of confined systems. A great advantage of this scheme is that of being\nformulated in terms of localized orbitals and thus it requires very few\ncomputational resources and times. Applications to the optical and screening\nproperties of semiconductor nanocrystals are presented here and discussed.\nResults concerning the absorption cross section, the static polarizability and\nthe screening function of InAs (direct gap) and Si (indirect gap) nanocrystals\ncompare well to both first principles results and experimental data. We also\nshow that the present scheme allows us to easily go beyond the continuum\ndielectric model, based on the Clausius-Mossotti equation, which is frequently\nused to include the nanocrystal surface polarization. Our calculations indicate\nthat the continuum dielectric model, used in conjunction with a size dependent\ndielectric constant, underestimates the nanocrystal polarizability, leading to\nexceedingly strong surface polarization fields.\n", "machine_text": "\nThis article presents a method for calculating the optical and screening properties of semiconductor nanocrystals using a tight-binding approach. This approach enables the inclusion of local field effects due to the confinement of nanocrystals. Applications to absorption, polarizability and screening functions of InAs and Si nanocrystals show good agreement with first-principles and experimental results. In addition, this method permits examination of the continuum dielectric model commonly employed to account for nanocrystal surface polarization. The differences between this model, which uses a size-dependent dielectric constant, and the approach of this article, which considers local polarization fields, are discussed. Our calculations suggest that the continuum dielectric model underestimates the nanocrystal polarizability, leading to notably strong surface polarization fields.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2163}
{"prompt": "Rephrase the abstract of an article with title 'A study of the evolution of the accretion disk of V2051 Oph through two\n  outburst cycles'.\n  We follow the changes in the structure of the accretion disk of the dwarf\nnova V2051 Oph along two separate outbursts in order to investigate the causes\nof its recurrent outbursts. We apply eclipse mapping techniques to a set of\nlight curves covering a normal (July 2000) and a low-amplitude (August 2002)\noutburst to derive maps of the disk surface brightness distribution at\ndifferent phases along the outburst cycles. The sequence of eclipse maps of the\n2000 July outburst reveal that the disk shrinks at outburst onset while an\nuneclipsed component of 13 per cent of the total light develops. The derived\nradial intensity distributions suggest the presence of an outward-moving\nheating wave during rise and of an inward-moving cooling wave during decline.\nThe inferred speed of the outward-moving heating wave is ~ 1.6 km/s, while the\nspeed of the cooling wave is a fraction of that. A comparison of the measured\ncooling wave velocity on consecutive nights indicates that the cooling wave\naccelerates as it travels towards disk center, in contradiction with the\nprediction of the disk instability model. From the inferred speed of the\nheating wave we derive a viscosity parameter alpha_{hot} ~ 0.13, comparable to\nthe measured viscosity parameter in quiescence. The 2002 August outburst had\nlower amplitude (\\Delta B ~ 0.8 mag) and the disk at outburst maximum was\nsmaller than on 2000 July. For an assumed distance of 92 pc, we find that along\nboth outbursts the disk brightness temperatures remain below the minimum\nexpected according to the disk instability model. The results suggest that the\noutbursts of V2051 Oph are caused by bursts of increased mass transfer from the\nmass-donor star.\n\n", "human_text": "  We follow the changes in the structure of the accretion disk of the dwarf\nnova V2051 Oph along two separate outbursts in order to investigate the causes\nof its recurrent outbursts. We apply eclipse mapping techniques to a set of\nlight curves covering a normal (July 2000) and a low-amplitude (August 2002)\noutburst to derive maps of the disk surface brightness distribution at\ndifferent phases along the outburst cycles. The sequence of eclipse maps of the\n2000 July outburst reveal that the disk shrinks at outburst onset while an\nuneclipsed component of 13 per cent of the total light develops. The derived\nradial intensity distributions suggest the presence of an outward-moving\nheating wave during rise and of an inward-moving cooling wave during decline.\nThe inferred speed of the outward-moving heating wave is ~ 1.6 km/s, while the\nspeed of the cooling wave is a fraction of that. A comparison of the measured\ncooling wave velocity on consecutive nights indicates that the cooling wave\naccelerates as it travels towards disk center, in contradiction with the\nprediction of the disk instability model. From the inferred speed of the\nheating wave we derive a viscosity parameter alpha_{hot} ~ 0.13, comparable to\nthe measured viscosity parameter in quiescence. The 2002 August outburst had\nlower amplitude (\\Delta B ~ 0.8 mag) and the disk at outburst maximum was\nsmaller than on 2000 July. For an assumed distance of 92 pc, we find that along\nboth outbursts the disk brightness temperatures remain below the minimum\nexpected according to the disk instability model. The results suggest that the\noutbursts of V2051 Oph are caused by bursts of increased mass transfer from the\nmass-donor star.\n", "machine_text": "\nThis article examines the alterations to the accretion disk of the dwarf nova V2051 Oph over two separate outbursts. Employing eclipse mapping analysis on\nlight curves from a normal (July 2000) and a low-amplitude (August 2002) outburst, we create maps of the disk surface brightness evolution and trace the motion of heating and cooling waves. Our determinations illustrate that the outward-moving heating wave moved at a rate of ~1.6 km/s, while the inward-cooling wave was much slower, and accelerates as it proceeds towards the middle of the disk. Results imply the outburst of V2051 Oph is activated by augmentations to the mass from the mass donor star, as the disk brightness temperatures remain lower than expected according to the disk instability model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2442}
{"prompt": "Rephrase the abstract of an article with title 'Staggered Heavy Baryon Chiral Perturbation Theory'.\n  Although taste violations significantly affect the results of staggered\ncalculations of pseudoscalar and heavy-light mesonic quantities, those entering\nstaggered calculations of baryonic quantities have not been quantified. Here I\ndevelop staggered chiral perturbation theory in the light-quark baryon sector\nby mapping the Symanzik action into heavy baryon chiral perturbation theory.\nFor 2+1 dynamical quark flavors, the masses of flavor-symmetric nucleons are\ncalculated to third order in partially quenched and fully dynamical staggered\nchiral perturbation theory. To this order the expansion includes the leading\nchiral logarithms, which come from loops with virtual decuplet-like states, as\nwell as terms the order of the cubed pion mass, which come from loops with\nvirtual octet-like states. Taste violations enter through the meson propagators\nin loops and tree-level terms the order of the squared lattice spacing. The\npattern of taste symmetry breaking and the resulting degeneracies and mixings\nare discussed in detail. The resulting chiral forms are appropriate to lattice\nresults obtained with operators already in use and could be used to study the\nrestoration of taste symmetry in the continuum limit. I assume that the fourth\nroot of the fermion determinant can be incorporated in staggered chiral\nperturbation theory using the replica method.\n\n", "human_text": "  Although taste violations significantly affect the results of staggered\ncalculations of pseudoscalar and heavy-light mesonic quantities, those entering\nstaggered calculations of baryonic quantities have not been quantified. Here I\ndevelop staggered chiral perturbation theory in the light-quark baryon sector\nby mapping the Symanzik action into heavy baryon chiral perturbation theory.\nFor 2+1 dynamical quark flavors, the masses of flavor-symmetric nucleons are\ncalculated to third order in partially quenched and fully dynamical staggered\nchiral perturbation theory. To this order the expansion includes the leading\nchiral logarithms, which come from loops with virtual decuplet-like states, as\nwell as terms the order of the cubed pion mass, which come from loops with\nvirtual octet-like states. Taste violations enter through the meson propagators\nin loops and tree-level terms the order of the squared lattice spacing. The\npattern of taste symmetry breaking and the resulting degeneracies and mixings\nare discussed in detail. The resulting chiral forms are appropriate to lattice\nresults obtained with operators already in use and could be used to study the\nrestoration of taste symmetry in the continuum limit. I assume that the fourth\nroot of the fermion determinant can be incorporated in staggered chiral\nperturbation theory using the replica method.\n", "machine_text": "In this article, I investigate the role of taste violations in the results of calculations involving staggered baryonic quantities, presenting a mapping of the Symanzik action into heavy baryon chiral perturbation theory. By calculating the masses of flavor-symmetric nucleons to the third order in both partially quenched and fully dynamical staggered chiral perturbation theory for two plus one dynamical quark flavors, I explain the effects of taste symmetry breaking, the resultant degeneracies, and mixings. The resulting chiral forms are applicable to lattice results obtained with currently used operators, and could be used to analyze the restoration of taste symmetry in the continuum limit. An attempt is made to incorporate the fourth root of the fermion determinant into staggered chiral perturbation theory through the replica method.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.149}
{"prompt": "Rephrase the abstract of an article with title 'Phase Spaces in Special Relativity: Towards Eliminating Gravitational\n  Singularities'.\n  This paper shows one way to construct phase spaces in special relativity by\nexpanding Minkowski Space. These spaces appear to indicate that we can dispense\nwith gravitational singularities. The key mathematical ideas in the present\napproach are to include a complex phase factor, such as, e^{i\\phi} in the\nLorentz transformation and to use both the proper time and the proper mass as\nparameters. To develop the most general case, a complex parameter \\sigma=s+im,\nis introduced, where s is the proper time, and m is the proper mass, and \\sigma\nand {\\sigma}/{|\\sigma|} are used to parameterize the position of a particle (or\nreference frame) in space-time-matter phase space. A new reference variable,\nu={m}/{r}, is needed (in addition to velocity), and assumed to be bounded by 0\nand {c^{2}}/{G}=1, in geometrized units. Several results are derived: The\nequation E=mc^2 apparently needs to be modified to\nE^2={s^2c^{10}}/{G^2}+m^2c^4, but a simpler (invariant) parameter is the\n\"energy to length\" ratio, which is {c^4}/{G} for any spherical region of\nspace-time-matter. The generalized \"momentum vector\" becomes completely\n\"masslike\" for u\\approx 0.79, which we think indicates the existence of a\nmaximal gravity field. Thus, gravitational singularities do not occur. Instead,\nas u approaches 1 matter is apparently simply crushed into free space. In the\nlast section of this paper we attempt some further generalizations of the phase\nspace ideas developed in this paper.\n\n", "human_text": "  This paper shows one way to construct phase spaces in special relativity by\nexpanding Minkowski Space. These spaces appear to indicate that we can dispense\nwith gravitational singularities. The key mathematical ideas in the present\napproach are to include a complex phase factor, such as, e^{i\\phi} in the\nLorentz transformation and to use both the proper time and the proper mass as\nparameters. To develop the most general case, a complex parameter \\sigma=s+im,\nis introduced, where s is the proper time, and m is the proper mass, and \\sigma\nand {\\sigma}/{|\\sigma|} are used to parameterize the position of a particle (or\nreference frame) in space-time-matter phase space. A new reference variable,\nu={m}/{r}, is needed (in addition to velocity), and assumed to be bounded by 0\nand {c^{2}}/{G}=1, in geometrized units. Several results are derived: The\nequation E=mc^2 apparently needs to be modified to\nE^2={s^2c^{10}}/{G^2}+m^2c^4, but a simpler (invariant) parameter is the\n\"energy to length\" ratio, which is {c^4}/{G} for any spherical region of\nspace-time-matter. The generalized \"momentum vector\" becomes completely\n\"masslike\" for u\\approx 0.79, which we think indicates the existence of a\nmaximal gravity field. Thus, gravitational singularities do not occur. Instead,\nas u approaches 1 matter is apparently simply crushed into free space. In the\nlast section of this paper we attempt some further generalizations of the phase\nspace ideas developed in this paper.\n", "machine_text": "\nThis article investigates the possibility of constructing phase spaces in special relativity via expanding Minkowski Space. Complex phase factors such as e^{i\\phi} in the Lorentz transformation and the use of both proper time and proper mass as parameters are included to construct the most general case. A new reference variable u={m}/{r}, along with bounded velocity are used to parameterize the position of a particle in the space-time-matter phase space. Equations derived indicate that the E=mc^2 formula needs to be modified, yet a simpler (invariant) parameter is the \"energy to length\" ratio becomes {c^4}/{G}. Furthermore, maximal gravity fields are observed when u\\approx 0.79 instead of a singularity occurring. The article concludes by posing some questions for further generalization on the specified phase space ideas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2043}
{"prompt": "Rephrase the abstract of an article with title 'Quantum simulation of interacting high-dimensional systems: the\n  influence of noise'.\n  We consider the simulation of interacting high-dimensional systems using\npairwise interacting qubits. The main tool in this context is the generation of\neffective many-body interactions, and we examine a number of different\nprotocols for obtaining them. These methods include the usage of higher-order\nprocesses (commutator method), unitary conjugation or graph state encoding, as\nwell as teleportation based approaches. We illustrate and compare these methods\nin detail and analyze the time cost for simulation. In the second part of the\narticle, we investigate the influence of noise on the simulation process. We\nconcentrate on errors in the interaction Hamiltonians and consider two generic\nnoise models, (i) timing errors in pairwise interactions and (ii) noisy\npairwise interactions described by Master equations of Lindblad form. We\nanalyze and compare the effect of noise for the different simulation methods\nand propose a way to significantly reduce the influence of noise by making use\nof entanglement purification together with a teleportation based protocol.\n\n", "human_text": "  We consider the simulation of interacting high-dimensional systems using\npairwise interacting qubits. The main tool in this context is the generation of\neffective many-body interactions, and we examine a number of different\nprotocols for obtaining them. These methods include the usage of higher-order\nprocesses (commutator method), unitary conjugation or graph state encoding, as\nwell as teleportation based approaches. We illustrate and compare these methods\nin detail and analyze the time cost for simulation. In the second part of the\narticle, we investigate the influence of noise on the simulation process. We\nconcentrate on errors in the interaction Hamiltonians and consider two generic\nnoise models, (i) timing errors in pairwise interactions and (ii) noisy\npairwise interactions described by Master equations of Lindblad form. We\nanalyze and compare the effect of noise for the different simulation methods\nand propose a way to significantly reduce the influence of noise by making use\nof entanglement purification together with a teleportation based protocol.\n", "machine_text": "\nThis article examines the simulation of high-dimensional systems that interact with one another, employing qubits as our main tool. We study a variety of methods of creating effective many-body interactions, including higher-order processes (commutator method), unitary conjugation, graph state encoding, and teleportation based approaches. We evaluate and compare the time taken for each of these methods, and investigate how noise can affect the simulation. We explore two generic noise models: timing errors in pairwise interactions, and noisy pairwise interactions described by Master equations of the Lindblad form. We evaluate the impact of noise on the different simulation methods, and suggest a way to combat noise by combining entanglement purification with a teleportation-based protocol.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0154}
{"prompt": "Rephrase the abstract of an article with title 'Route to Lambda in conformally coupled phantom cosmology'.\n  In this letter we investigate acceleration in the flat cosmological model\nwith a conformally coupled phantom field and we show that acceleration is its\ngeneric feature. We reduce the dynamics of the model to a 3-dimensional\ndynamical system and analyze it on a invariant 2-dimensional submanifold. Then\nthe concordance FRW model with the cosmological constant $\\Lambda$ is a global\nattractor situated on a 2-dimensional invariant space. We also study the\nbehaviour near this attractor, which can be approximated by the dynamics of the\nlinearized part of the system. We demonstrate that trajectories of the\nconformally coupled phantom scalar field with a simple quadratic potential\ncrosses the cosmological constant barrier infinitely many times in the phase\nspace. The universal behaviour of the scalar field and its potential is also\ncalculated. We conclude that the phantom scalar field conformally coupled to\ngravity gives a natural dynamical mechanism of concentration of the equation of\nstate coefficient around the magical value $w_{\\text{eff}}=-1$. We demonstrate\nroute to Lambda through the infinite times crossing the $w_{\\text{eff}}=-1$\nphantom divide.\n\n", "human_text": "  In this letter we investigate acceleration in the flat cosmological model\nwith a conformally coupled phantom field and we show that acceleration is its\ngeneric feature. We reduce the dynamics of the model to a 3-dimensional\ndynamical system and analyze it on a invariant 2-dimensional submanifold. Then\nthe concordance FRW model with the cosmological constant $\\Lambda$ is a global\nattractor situated on a 2-dimensional invariant space. We also study the\nbehaviour near this attractor, which can be approximated by the dynamics of the\nlinearized part of the system. We demonstrate that trajectories of the\nconformally coupled phantom scalar field with a simple quadratic potential\ncrosses the cosmological constant barrier infinitely many times in the phase\nspace. The universal behaviour of the scalar field and its potential is also\ncalculated. We conclude that the phantom scalar field conformally coupled to\ngravity gives a natural dynamical mechanism of concentration of the equation of\nstate coefficient around the magical value $w_{\\text{eff}}=-1$. We demonstrate\nroute to Lambda through the infinite times crossing the $w_{\\text{eff}}=-1$\nphantom divide.\n", "machine_text": "\nWe analyze acceleration in the flat cosmological model with a conformally coupled phantom field to explore the route to Lambda in this type of cosmology. We reduce the model to a 3-dimensional dynamical system and study the behavior on an invariant 2-dimensional submanifold, finding that the concordance FRW model with the cosmological constant $\\Lambda$ is a global attractor situated on the 2-dimensional space. By examining the system near this attractor, we find that trajectories of the conformally coupled phantom scalar field with a simple quadratic potential cross the cosmological constant barrier infinitely many times in the phase space, giving a dynamical mechanism of concentration of the equation of state coefficient around the value of $w_{\\text{eff}}=-1$. We thus demonstrate a route to Lambda through the infinite times crossings of the $w_{\\text{eff}}=-1$ phantom divide.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1651}
{"prompt": "Rephrase the abstract of an article with title 'Vortices in Bose-Einstein Condensates: Theory'.\n  Vortices are pervasive in nature, representing the breakdown of laminar fluid\nflow and hence playing a key role in turbulence. The fluid rotation associated\nwith a vortex can be parameterized by the circulation $\\Gamma=\\oint {\\rm d}{\\bf\nr}\\cdot{\\bf v}({\\bf r})$ about the vortex, where ${\\bf v}({\\bf r})$ is the\nfluid velocity field. While classical vortices can take any value of\ncirculation, superfluids are irrotational, and any rotation or angular momentum\nis constrained to occur through vortices with quantized circulation. Quantized\nvortices also play a key role in the dissipation of transport in superfluids.\nIn BECs quantized vortices have been observed in several forms, including\nsingle vortices, vortex lattices, and vortex pairs and rings. The recent\nobservation of quantized vortices in a fermionic gas was taken as a clear\nsignature of the underlying condensation and superfluidity of fermion pairs. In\naddition to BECs, quantized vortices also occur in superfluid Helium, nonlinear\noptics, and type-II superconductors.\n\n", "human_text": "  Vortices are pervasive in nature, representing the breakdown of laminar fluid\nflow and hence playing a key role in turbulence. The fluid rotation associated\nwith a vortex can be parameterized by the circulation $\\Gamma=\\oint {\\rm d}{\\bf\nr}\\cdot{\\bf v}({\\bf r})$ about the vortex, where ${\\bf v}({\\bf r})$ is the\nfluid velocity field. While classical vortices can take any value of\ncirculation, superfluids are irrotational, and any rotation or angular momentum\nis constrained to occur through vortices with quantized circulation. Quantized\nvortices also play a key role in the dissipation of transport in superfluids.\nIn BECs quantized vortices have been observed in several forms, including\nsingle vortices, vortex lattices, and vortex pairs and rings. The recent\nobservation of quantized vortices in a fermionic gas was taken as a clear\nsignature of the underlying condensation and superfluidity of fermion pairs. In\naddition to BECs, quantized vortices also occur in superfluid Helium, nonlinear\noptics, and type-II superconductors.\n", "machine_text": "This article presents a theoretical overview of the role of vortices in Bose-Einstein condensates (BECs). It discusses the circulation of fluid surrounding a vortex, the quantization of vortices in superfluids, and their wide occurrence. It examines the observation of single vortices, vortex lattices, and vortex pairs and rings in BECs, as well as the observation of quantized vortices in a fermionic gas indicating the resultant condensation and superfluidity of fermion pairs. It then considers other fields involving quantized vortices, such as superfluid Helium, nonlinear optics, and type-II superconductors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0146}
{"prompt": "Rephrase the abstract of an article with title 'Phase Transitions in the Coloring of Random Graphs'.\n  We consider the problem of coloring the vertices of a large sparse random\ngraph with a given number of colors so that no adjacent vertices have the same\ncolor. Using the cavity method, we present a detailed and systematic analytical\nstudy of the space of proper colorings (solutions).\n  We show that for a fixed number of colors and as the average vertex degree\n(number of constraints) increases, the set of solutions undergoes several phase\ntransitions similar to those observed in the mean field theory of glasses.\nFirst, at the clustering transition, the entropically dominant part of the\nphase space decomposes into an exponential number of pure states so that beyond\nthis transition a uniform sampling of solutions becomes hard. Afterward, the\nspace of solutions condenses over a finite number of the largest states and\nconsequently the total entropy of solutions becomes smaller than the annealed\none. Another transition takes place when in all the entropically dominant\nstates a finite fraction of nodes freezes so that each of these nodes is\nallowed a single color in all the solutions inside the state. Eventually, above\nthe coloring threshold, no more solutions are available. We compute all the\ncritical connectivities for Erdos-Renyi and regular random graphs and determine\ntheir asymptotic values for large number of colors.\n  Finally, we discuss the algorithmic consequences of our findings. We argue\nthat the onset of computational hardness is not associated with the clustering\ntransition and we suggest instead that the freezing transition might be the\nrelevant phenomenon. We also discuss the performance of a simple local Walk-COL\nalgorithm and of the belief propagation algorithm in the light of our results.\n\n", "human_text": "  We consider the problem of coloring the vertices of a large sparse random\ngraph with a given number of colors so that no adjacent vertices have the same\ncolor. Using the cavity method, we present a detailed and systematic analytical\nstudy of the space of proper colorings (solutions).\n  We show that for a fixed number of colors and as the average vertex degree\n(number of constraints) increases, the set of solutions undergoes several phase\ntransitions similar to those observed in the mean field theory of glasses.\nFirst, at the clustering transition, the entropically dominant part of the\nphase space decomposes into an exponential number of pure states so that beyond\nthis transition a uniform sampling of solutions becomes hard. Afterward, the\nspace of solutions condenses over a finite number of the largest states and\nconsequently the total entropy of solutions becomes smaller than the annealed\none. Another transition takes place when in all the entropically dominant\nstates a finite fraction of nodes freezes so that each of these nodes is\nallowed a single color in all the solutions inside the state. Eventually, above\nthe coloring threshold, no more solutions are available. We compute all the\ncritical connectivities for Erdos-Renyi and regular random graphs and determine\ntheir asymptotic values for large number of colors.\n  Finally, we discuss the algorithmic consequences of our findings. We argue\nthat the onset of computational hardness is not associated with the clustering\ntransition and we suggest instead that the freezing transition might be the\nrelevant phenomenon. We also discuss the performance of a simple local Walk-COL\nalgorithm and of the belief propagation algorithm in the light of our results.\n", "machine_text": "\nWe present a detailed and systematic analysis of the space of proper colorings (solutions) to a random graph with a given number of colors, and no adjacent vertices having the same color. Using the cavity method, we show that with increasing average vertex degree, the set of solutions undergoes several phase transitions which are similar to those seen in the mean field theory of glasses. Firstly, there is a clustering transition, where the most entropically dominant part of the phase space divides into an exponential number of pure states, making uniform sampling of solutions difficult. Thereafter, the space of solutions becomes concentrated into a finite number of the largest states, reducing the total entropy of solutions compared to the annealed one. Additionally, a freezing transition happens when a finite fraction of nodes freeze in the most entropically dominant states, with each node being given one color in all solutions in the state. Finally, above the coloring threshold, no further solutions are available. We compute the critical connectivities for Erdos-Renyi and regular random graphs, determining their asymptotic values for a high number of colors. We discuss the algorithmic consequences of our findings, arguing that the onset of computational complexity is not closely connected to the clustering transition. We evaluate the performance of a simple local Walk-COL algorithm and the belief propagation approach in the light of our results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1269}
{"prompt": "Rephrase the abstract of an article with title 'Multiperiodicity in the newly discovered mid-late Be star V2104 Cygni'.\n  We obtained the first long, homogenous time-series of V2104Cyg, consisting of\n679 datapoints, with the uvbybeta photometers of Sierra Nevada and San Pedro\nMartir Observatories with the aim to detect and subsequently interpret the\nintrinsic frequencies of this previously unstudied variable star, which turned\nout to be a Be star. We try to figure out its place among the variable B stars\non the upper Main Sequence. In order to obtain additional information on\nphysical parameters we collected a few spectra with the ELODIE and FIES\ninstruments. We searched for frequencies in the uvby passbands using 2\ndifferent frequency analysis methods and used the S/N>4 criterion to select the\nsignificant periodicities. We obtained an estimate of the physical parameters\nof the underlying B star of spectral type between B5 and B7, by correcting for\nthe presence of a circumstellar disk, using a formalism based on the strenght\nof the Halpha line emission. We detected 3 independent frequencies with\namplitudes below 0.01mag, f1 = 4.7126 c/d, f2 = 2.2342 c/d and f3 = 4.671 c/d,\nand discovered that V2104Cyg is a Be star. The fast rotation (vsini=290+/-10\nkm/s, and 27<i<45) hampered the investigation of the associated pulsational\nparameters l. Nevertheless, the most plausible explanation for the observed\nvariability of this mid-late type Be star is a non-radial pulsation model. This\npaper is based on observations obtained at the Observatorio Astronomico\nNacional San Pedro Martir (Mexico), Observatorio de Sierra Nevada (Spain),\nObservatoire de Haute Provence (France), and on observations made with the\nNordic Optical Telescope, Observatorio Roque de los Muchachos, La Palma, Spain.\n\n", "human_text": "  We obtained the first long, homogenous time-series of V2104Cyg, consisting of\n679 datapoints, with the uvbybeta photometers of Sierra Nevada and San Pedro\nMartir Observatories with the aim to detect and subsequently interpret the\nintrinsic frequencies of this previously unstudied variable star, which turned\nout to be a Be star. We try to figure out its place among the variable B stars\non the upper Main Sequence. In order to obtain additional information on\nphysical parameters we collected a few spectra with the ELODIE and FIES\ninstruments. We searched for frequencies in the uvby passbands using 2\ndifferent frequency analysis methods and used the S/N>4 criterion to select the\nsignificant periodicities. We obtained an estimate of the physical parameters\nof the underlying B star of spectral type between B5 and B7, by correcting for\nthe presence of a circumstellar disk, using a formalism based on the strenght\nof the Halpha line emission. We detected 3 independent frequencies with\namplitudes below 0.01mag, f1 = 4.7126 c/d, f2 = 2.2342 c/d and f3 = 4.671 c/d,\nand discovered that V2104Cyg is a Be star. The fast rotation (vsini=290+/-10\nkm/s, and 27<i<45) hampered the investigation of the associated pulsational\nparameters l. Nevertheless, the most plausible explanation for the observed\nvariability of this mid-late type Be star is a non-radial pulsation model. This\npaper is based on observations obtained at the Observatorio Astronomico\nNacional San Pedro Martir (Mexico), Observatorio de Sierra Nevada (Spain),\nObservatoire de Haute Provence (France), and on observations made with the\nNordic Optical Telescope, Observatorio Roque de los Muchachos, La Palma, Spain.\n", "machine_text": "\nWe investigated the previously unstudied variable star V2104 Cygni using two different frequency analysis methods to detect and interpret its intrinsic frequencies. We obtained 679 datapoints with the uvbybeta photometers of the Sierra Nevada and San Pedro Martir Observatories, as well as a few spectra with the ELODIE and FIES instruments. We employed a S/N>4 criterion to identify significant periodicities, which revealed 3 independent frequencies of amplitudes lower than 0.01mag. Our findings have led us to estimate the underlying B star spectral type between B5 and B7, via corrections to the strength of the Halpha line emission in the presence of a circumstellar disk. The star's rapid rotation of up to 290 +/- 10 km/s (27 < i < 45) has prevented us from examining its associated pulsational parameters. The most plausible explanation for the detected variability of this mid-late type Be star is a non-radial pulsation model. Supporting data for this study were acquired from the San Pedro Martir, Sierra Nevada, and Haute Provence Observatories, as well as the Nordic Optical Telescope, and Observatorio Roque de los Muchachos, in La Palma, Spain.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2943}
{"prompt": "Rephrase the abstract of an article with title 'On Cuspidal Representations of General Linear Groups over Discrete\n  Valuation Rings'.\n  We define a new notion of cuspidality for representations of $\\GL_n$ over a\nfinite quotient $\\Oh_k$ of the ring of integers $\\Oh$ of a non-Archimedean\nlocal field $F$ using geometric and infinitesimal induction functors, which\ninvolve automorphism groups $G_\\lambda$ of torsion $\\Oh$\\nobreakdash-modules.\nWhen $n$ is a prime, we show that this notion of cuspidality is equivalent to\nstrong cuspidality, which arises in the construction of supercuspidal\nrepresentations of $\\GL_n(F)$. We show that strongly cuspidal representations\nshare many features of cuspidal representations of finite general linear\ngroups. In the function field case, we show that the construction of the\nrepresentations of $\\GL_n(\\Oh_k)$ for $k\\geq 2$ for all $n$ is equivalent to\nthe construction of the representations of all the groups $G_\\lambda$. A\nfunctional equation for zeta functions for representations of $\\GL_n(\\Oh_k)$ is\nestablished for representations which are not contained in an infinitesimally\ninduced representation. All the cuspidal representations for $\\GL_4(\\Oh_2)$ are\nconstructed. Not all these representations are strongly cuspidal.\n\n", "human_text": "  We define a new notion of cuspidality for representations of $\\GL_n$ over a\nfinite quotient $\\Oh_k$ of the ring of integers $\\Oh$ of a non-Archimedean\nlocal field $F$ using geometric and infinitesimal induction functors, which\ninvolve automorphism groups $G_\\lambda$ of torsion $\\Oh$\\nobreakdash-modules.\nWhen $n$ is a prime, we show that this notion of cuspidality is equivalent to\nstrong cuspidality, which arises in the construction of supercuspidal\nrepresentations of $\\GL_n(F)$. We show that strongly cuspidal representations\nshare many features of cuspidal representations of finite general linear\ngroups. In the function field case, we show that the construction of the\nrepresentations of $\\GL_n(\\Oh_k)$ for $k\\geq 2$ for all $n$ is equivalent to\nthe construction of the representations of all the groups $G_\\lambda$. A\nfunctional equation for zeta functions for representations of $\\GL_n(\\Oh_k)$ is\nestablished for representations which are not contained in an infinitesimally\ninduced representation. All the cuspidal representations for $\\GL_4(\\Oh_2)$ are\nconstructed. Not all these representations are strongly cuspidal.\n", "machine_text": "\nWe present a new definition of cuspidality for representations of $\\GL_n$ over discrete valuation rings of a non-Archimedean local field $F$. With this, we connect strongly cuspidal representations of $\\GL_n(F)$ with a definition for cuspidal representations of finite general linear groups. In the function field case, we also demonstrate how the representations of $\\GL_n(\\Oh_k)$ for $k\\geq 2$ and all $n$ are linked to the representations of the groups $G_\\lambda$. Furthermore, we provide a functional equation for zeta functions for those representations that are not induced from those of $G_\\lambda$. Lastly, we establish that all the cuspidal representations for $\\GL_4(\\Oh_2)$ have been constructed, not all of which are strongly cuspidal.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0058}
{"prompt": "Rephrase the abstract of an article with title 'Characterizing the Low-Redshift Intergalactic Medium towards PKS1302-102'.\n  We present a detailed analysis of the intergalactic metal-line absorption\nsystems in the archival HST/STIS and FUSE ultraviolet spectra of the\nlow-redshift quasar PKS1302-102 (z_QSO = 0.2784). We supplement the archive\ndata with CLOUDY ionization models and a survey of galaxies in the quasar\nfield. There are 15 strong Lya absorbers with column densities logN_HI > 14. Of\nthese, six are associated with at least CIII 977 absorption (logN(C^++) > 13);\nthis implies a redshift density dN_CIII/dz = 36+13/-9 (68% confidence limits)\nfor the five detections with rest equivalent width W_r > 50 mA. Two systems\nshow OVI 1031,1037 absorption in addition to CIII (logN(O^+5) > 14). One is a\npartial Lyman limit system (logN_HI = 17) with associated CIII, OVI, and SiIII\n1206 absorption. There are three tentative OVI systems that do not have CIII\ndetected. For one OVI doublet with both lines detected at 3 sigma with W_r > 50\nmA, dN_OVI/dz = 7+9/-4. We also search for OVI doublets without Lya absorption\nbut identify none. From CLOUDY modeling, these metal-line systems have\nmetallicities spanning the range -4 < [M/H] < -0.3. The two OVI systems with\nassociated CIII absorption cannot be single-phase, collisionally-ionized media\nbased on the relative abundances of the metals and kinematic arguments. From\nthe galaxy survey, we discover that the absorption systems are in a diverse set\nof galactic environments. Each metal-line system has at least one galaxy within\n500 km/s and 600 h^-1 kpc with L > 0.1 L_*.\n\n", "human_text": "  We present a detailed analysis of the intergalactic metal-line absorption\nsystems in the archival HST/STIS and FUSE ultraviolet spectra of the\nlow-redshift quasar PKS1302-102 (z_QSO = 0.2784). We supplement the archive\ndata with CLOUDY ionization models and a survey of galaxies in the quasar\nfield. There are 15 strong Lya absorbers with column densities logN_HI > 14. Of\nthese, six are associated with at least CIII 977 absorption (logN(C^++) > 13);\nthis implies a redshift density dN_CIII/dz = 36+13/-9 (68% confidence limits)\nfor the five detections with rest equivalent width W_r > 50 mA. Two systems\nshow OVI 1031,1037 absorption in addition to CIII (logN(O^+5) > 14). One is a\npartial Lyman limit system (logN_HI = 17) with associated CIII, OVI, and SiIII\n1206 absorption. There are three tentative OVI systems that do not have CIII\ndetected. For one OVI doublet with both lines detected at 3 sigma with W_r > 50\nmA, dN_OVI/dz = 7+9/-4. We also search for OVI doublets without Lya absorption\nbut identify none. From CLOUDY modeling, these metal-line systems have\nmetallicities spanning the range -4 < [M/H] < -0.3. The two OVI systems with\nassociated CIII absorption cannot be single-phase, collisionally-ionized media\nbased on the relative abundances of the metals and kinematic arguments. From\nthe galaxy survey, we discover that the absorption systems are in a diverse set\nof galactic environments. Each metal-line system has at least one galaxy within\n500 km/s and 600 h^-1 kpc with L > 0.1 L_*.\n", "machine_text": "\nWe uncover the makeup of the low-redshift intergalactic medium (IGM) in the direction of quasar PKS1302-102 (z_QSO = 0.2784) using archival HST/STIS and FUSE ultraviolet spectra. We determine that there are 15 Ly\u03b1-absorbing systems with column densities logN_HI > 14, six of which contain CIII 977 intergalactic metal absorption (logN(C^++) > 13) and two of which contain both OVI 1031, 1037 and CIII absorption (logN(O^+5) > 14). Additionally, we detect three tentatively OVI systems that lack associated CIII absorption. Performing CLOUDY ionization modeling, these metal-line systems have metallicities spanning -4 < [M/H] < -0.3. Our analysis of these metal-line absorbers suggest the presence of multiple-phase, photo-ionized media which is further supported by a survey of the galaxies in the quasar field. Each metal-line system has at least one luminous galaxy within 500 km/s and 600 h^-1 kpc of the quasar.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1285}
{"prompt": "Rephrase the abstract of an article with title 'Matter-Wave Bright Solitons with a Finite Background in Spinor\n  Bose-Einstein Condensates'.\n  We investigate dynamical properties of bright solitons with a finite\nbackground in the F=1 spinor Bose-Einstein condensate (BEC), based on an\nintegrable spinor model which is equivalent to the matrix nonlinear\nSchr\\\"{o}dinger equation with a self-focusing nonlineality. We apply the\ninverse scattering method formulated for nonvanishing boundary conditions. The\nresulting soliton solutions can be regarded as a generalization of those under\nvanishing boundary conditions. One-soliton solutions are derived in an explicit\nmanner. According to the behaviors at the infinity, they are classified into\ntwo kinds, domain-wall (DW) type and phase-shift (PS) type. The DW-type implies\nthe ferromagnetic state with nonzero total spin and the PS-type implies the\npolar state, where the total spin amounts to zero. We also discuss two-soliton\ncollisions. In particular, the spin-mixing phenomenon is confirmed in a\ncollision involving the DW-type. The results are consistent with those of the\nprevious studies for bright solitons under vanishing boundary conditions and\ndark solitons. As a result, we establish the robustness and the usefulness of\nthe multiple matter-wave solitons in the spinor BECs.\n\n", "human_text": "  We investigate dynamical properties of bright solitons with a finite\nbackground in the F=1 spinor Bose-Einstein condensate (BEC), based on an\nintegrable spinor model which is equivalent to the matrix nonlinear\nSchr\\\"{o}dinger equation with a self-focusing nonlineality. We apply the\ninverse scattering method formulated for nonvanishing boundary conditions. The\nresulting soliton solutions can be regarded as a generalization of those under\nvanishing boundary conditions. One-soliton solutions are derived in an explicit\nmanner. According to the behaviors at the infinity, they are classified into\ntwo kinds, domain-wall (DW) type and phase-shift (PS) type. The DW-type implies\nthe ferromagnetic state with nonzero total spin and the PS-type implies the\npolar state, where the total spin amounts to zero. We also discuss two-soliton\ncollisions. In particular, the spin-mixing phenomenon is confirmed in a\ncollision involving the DW-type. The results are consistent with those of the\nprevious studies for bright solitons under vanishing boundary conditions and\ndark solitons. As a result, we establish the robustness and the usefulness of\nthe multiple matter-wave solitons in the spinor BECs.\n", "machine_text": "This paper examines the dynamics of bright solitons with finite background in spinor Bose-Einstein Condensates (BECs) that are modeled as a matrix nonlinear Schr\\\"{o}dinger equation with self-focusing nonlinearity. The inverse scattering method is employed to study soliton solutions that have been extended from vanishing boundary conditions. These solitons are classified into two types termed 'domain-wall' (DW) or 'phase-shift' (PS) depending on their behavior at infinity. The DW type corresponds to a ferromagnetic state with a non-zero total spin, while the PS type carries a zero total spin meaning a polar state. The collisions of two solitons are further researched and the spin-mixing is confirmed in a collision involving a DW type. Moreover, the robustness and the usefulness of solitons in spinor BECs are emphasized.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0082}
{"prompt": "Rephrase the abstract of an article with title 'Nonlocal Excitation Spectra in 2D Doped Hubbard Model'.\n  Single-particle excitation spectra of the two-dimensional Hubbard model on\nthe square lattice near half filling and at zero temperature are investigated\non the basis of the self-consistent projection operator method. The method\nguarantees a high accuracy of the spectra with high energy and high momentum\nresolutions. It takes into account long-range intersite correlations as well as\nthe strong on-site correlations. Effects of nonlocal excitations are clarified\nby comparing the results with those of the single-site approximation. The\ncalculated spectra verify the quantum Monte-Carlo results for finite\ntemperatures. The spectra at the Fermi level yield a hole-like Fermi surface in\nthe underdoped region and an electron-like Fermi surface in the overdoped\nregion. From a numerical analysis of the momentum dependent effective mass and\nself-energy, it is concluded that a marginal Fermi-liquid like state persists\neven at finite doping concentrations in the strongly correlated region because\na van Hove singularity is pinned to the Fermi surface. It is also found that a\nkink structure appears in the quasiparticle energy band in the same region. The\nkink is shown to be caused by a mixing between the quasiparticle band and an\nexcitation band with strong short-range antiferromagnetic correlations. These\nresults suggest an explanation for some of the unusual properties of the normal\nstate in high-$T_{\\rm c}$ cuprates.\n\n", "human_text": "  Single-particle excitation spectra of the two-dimensional Hubbard model on\nthe square lattice near half filling and at zero temperature are investigated\non the basis of the self-consistent projection operator method. The method\nguarantees a high accuracy of the spectra with high energy and high momentum\nresolutions. It takes into account long-range intersite correlations as well as\nthe strong on-site correlations. Effects of nonlocal excitations are clarified\nby comparing the results with those of the single-site approximation. The\ncalculated spectra verify the quantum Monte-Carlo results for finite\ntemperatures. The spectra at the Fermi level yield a hole-like Fermi surface in\nthe underdoped region and an electron-like Fermi surface in the overdoped\nregion. From a numerical analysis of the momentum dependent effective mass and\nself-energy, it is concluded that a marginal Fermi-liquid like state persists\neven at finite doping concentrations in the strongly correlated region because\na van Hove singularity is pinned to the Fermi surface. It is also found that a\nkink structure appears in the quasiparticle energy band in the same region. The\nkink is shown to be caused by a mixing between the quasiparticle band and an\nexcitation band with strong short-range antiferromagnetic correlations. These\nresults suggest an explanation for some of the unusual properties of the normal\nstate in high-$T_{\\rm c}$ cuprates.\n", "machine_text": "\nThe self-consistent projection operator method is used to explore the single-particle excitation spectra of the two-dimensional Hubbard model at half filling and zero temperature. By assessing the effects of nonlocal excitations, the obtained spectra validate the accuracy of quantum Monte-Carlo results for finite temperatures. It is found that the Fermi surface in the doping region changes from hole-like to electron-like and the kink structure appears in the quasiparticle energy band due to a mixing between the quasiparticle band and an excitation band with strong short-range antiferromagnetic correlations. The study provides a possible explanation for the anomalous properties observed in the normal state of high-$T_{\\rm c}$ cuprates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0581}
{"prompt": "Rephrase the abstract of an article with title 'Grain Retention and Formation of Planetesimals near the Snow Line in\n  MRI-driven Turbulent Protoplanetary Disks'.\n  The first challenge in the formation of both terrestrial planets and the\ncores of gas giants is the retention of grains in protoplanetary disks. In most\nregions of these disks, gas attains sub-Keplerian speeds as a consequence of a\nnegative pressure gradient. Hydrodynamic drag leads to orbital decay and\ndepletion of the solid material in the disk, with characteristic timescales as\nshort as only a few hundred years for meter-sized objects at 1 AU. In this\npaper, we suggest a particle retention mechanism which promotes the\naccumulation of grains and the formation of planetesimals near the water\nsublimation front or ``snow line.'' This model is based on the assumption that,\nin the regions most interesting for planet formation, the viscous evolution of\nthe disk is due to turbulence driven by the magneto-rotational instability\n(MRI) in the surface layers of the disk. The depth to which MRI effectively\ngenerates turbulence is a strong function of the grain size and abundance. A\nsharp increase in the grain-to-gas density ratio across the snow line reduces\nthe column depth of the active layer. As the disk evolves towards a\nquasi-steady-state, this change in the active layer creates a local maximum in\nradial distribution of the gas surface density and pressure, causing the gas to\nrotate at super-Keplerian speed and halting the inward migration of grains.\nThis senario presents a robust process for grain retention which may aid in the\nformation of proto-gas-giant cores preferentially near the snow line.\n\n", "human_text": "  The first challenge in the formation of both terrestrial planets and the\ncores of gas giants is the retention of grains in protoplanetary disks. In most\nregions of these disks, gas attains sub-Keplerian speeds as a consequence of a\nnegative pressure gradient. Hydrodynamic drag leads to orbital decay and\ndepletion of the solid material in the disk, with characteristic timescales as\nshort as only a few hundred years for meter-sized objects at 1 AU. In this\npaper, we suggest a particle retention mechanism which promotes the\naccumulation of grains and the formation of planetesimals near the water\nsublimation front or ``snow line.'' This model is based on the assumption that,\nin the regions most interesting for planet formation, the viscous evolution of\nthe disk is due to turbulence driven by the magneto-rotational instability\n(MRI) in the surface layers of the disk. The depth to which MRI effectively\ngenerates turbulence is a strong function of the grain size and abundance. A\nsharp increase in the grain-to-gas density ratio across the snow line reduces\nthe column depth of the active layer. As the disk evolves towards a\nquasi-steady-state, this change in the active layer creates a local maximum in\nradial distribution of the gas surface density and pressure, causing the gas to\nrotate at super-Keplerian speed and halting the inward migration of grains.\nThis senario presents a robust process for grain retention which may aid in the\nformation of proto-gas-giant cores preferentially near the snow line.\n", "machine_text": "\nThis paper proposes a mechanism for the retention of solid, grain-sized material in protostellar disks and the eventual formation of planetesimals, preferentially occurring at the water sublimation front, or snow line. This mechanism, based on turbulence driven by the magneto-rotational instability (MRI), is rooted in the fact that the disk's column depth of the active layer is a strong function of the grain size and abundance. With a sharp increase in the grain-to-gas ratio at the snow line, the active layer reduces, resulting in a local maximum of gas surface density and pressure. The gas moves at super-Keplerian velocities, effectively stagnating the inward migration of grains and potentially promoting the growth of proto-gas-giants cores in this already denser region. This model provides a robust environment for particle retention, facilitating the formation of planetesimals.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1272}
{"prompt": "Rephrase the abstract of an article with title 'Old Main-Sequence Turnoff Photometry in the Small Magellanic Cloud. I.\n  Constraints on the Star Formation History in Different Fields'.\n  We present ground-based B and R-band color-magnitude diagrams (CMDs),\nreaching the oldest main-sequence turnoffs with good photometric accuracy for\ntwelve fields in the Small Magellanic Cloud (SMC). Our fields, located between\n~1 and ~4 degrees from the center of the galaxy, are situated in different\nparts of the SMC such as the \"Wing'' area, and towards the West and South. In\nthis paper we perform a first analysis of the stellar content in our SMC fields\nthrough comparison with theoretical isochrones and color functions (CFs). We\nfind that the underlying spheroidally distributed population is composed of\nboth intermediate-age and old stars and that its age composition does not show\nstrong galacto-centric gradients. The three fields situated toward the east, in\nthe Wing region, show very active current star formation. However, only in the\neastern field closest to the center do we find an enhancement of recent star\nformation with respect to a constant SFR(t). The fields corresponding to the\nwestern side of the SMC present a much less populated young MS, and the CF\nanalysis indicates that the SFR(t) greatly diminished around 2 Gyr ago in these\nparts. Field smc0057, the closest to the center of the galaxy and located in\nthe southern part, shows recent star formation, while the rest of the southern\nfields present few bright MS stars. The structure of the red clump in all the\nCMDs is consistent with the large amount of intermediate-age stars inferred\nfrom the CMDs and color functions. None of the SMC fields presented here are\ndominated by old stellar populations, a fact that is in agreement with the lack\nof a conspicuous horizontal branch in all these SMC CMDs. This could indicate\nthat a disk population is ruling over a possible old halo in all the observed\nfields.\n\n", "human_text": "  We present ground-based B and R-band color-magnitude diagrams (CMDs),\nreaching the oldest main-sequence turnoffs with good photometric accuracy for\ntwelve fields in the Small Magellanic Cloud (SMC). Our fields, located between\n~1 and ~4 degrees from the center of the galaxy, are situated in different\nparts of the SMC such as the \"Wing'' area, and towards the West and South. In\nthis paper we perform a first analysis of the stellar content in our SMC fields\nthrough comparison with theoretical isochrones and color functions (CFs). We\nfind that the underlying spheroidally distributed population is composed of\nboth intermediate-age and old stars and that its age composition does not show\nstrong galacto-centric gradients. The three fields situated toward the east, in\nthe Wing region, show very active current star formation. However, only in the\neastern field closest to the center do we find an enhancement of recent star\nformation with respect to a constant SFR(t). The fields corresponding to the\nwestern side of the SMC present a much less populated young MS, and the CF\nanalysis indicates that the SFR(t) greatly diminished around 2 Gyr ago in these\nparts. Field smc0057, the closest to the center of the galaxy and located in\nthe southern part, shows recent star formation, while the rest of the southern\nfields present few bright MS stars. The structure of the red clump in all the\nCMDs is consistent with the large amount of intermediate-age stars inferred\nfrom the CMDs and color functions. None of the SMC fields presented here are\ndominated by old stellar populations, a fact that is in agreement with the lack\nof a conspicuous horizontal branch in all these SMC CMDs. This could indicate\nthat a disk population is ruling over a possible old halo in all the observed\nfields.\n", "machine_text": "\nIn this paper, we analyze the stellar content of twelve fields in the Small Magellanic Cloud (SMC), located between ~1 and ~4 degrees from the center of the galaxy, by analyzing ground-based B and R-band color-magnitude diagrams (CMDs) reaching the oldest main-sequence turnoffs. Our analysis, including a comparison with theoretical isochrones and color functions, finds that the underlying spheroidal population in the SMC is composed of both intermediate-age and old stars. While the three fields from the Wing region show very active current star formation, the fields from the West and South have a much less populated young main-sequence, with a strong depletion of star formation at around 2 Gyr ago. Further, the red clump in all CMDs is consistent with the large amount of intermediate-age stars. This could indicate that a disk population has overruled any possible old halo in all the observed fields.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1151}
{"prompt": "Rephrase the abstract of an article with title 'Correlated modulation between the redshifted Fe K alpha line and the\n  continuum emission in NGC 3783'.\n  It has been suggested that X-ray observations of rapidly variable Seyfert\ngalaxies may hold the key to probe the gas orbital motions in the innermost\nregions of accretion discs around black holes and, thus, trace flow patterns\nunder the effect of the hole strong gravitational field. We explore this\npossibility analizing XMM-Newton observations of the seyfert 1 galaxy NGC 3783.\nA detiled time-resolved spectral analysis is performed down to the shortest\npossible time-scales (few ks) using \"excess maps\" and cross-correlating light\ncurves in different energy bands. In addition to a constant core of the Fe K\nalpha line, we detected a variable and redshifted Fe K alpha emission feature\nbetween 5.3-6.1 keV. The line exhibits a modulation on a time-scale of 27 ks\nthat is similar to and in phase with a modulation of the 0.3-10 keV source\ncontinuum. The time-scale of the correlated variability of the redshifted Fe\nline and continuum agrees with the local dynamical time-scale of the accretion\ndisc at 10 r_g around a black hole of 10^7 M_sun. Given the shape of the\nredshfted line emission and the overall X-ray variability pattern, the line is\nlikely to arise from the relativistic region near the black hole.\n\n", "human_text": "  It has been suggested that X-ray observations of rapidly variable Seyfert\ngalaxies may hold the key to probe the gas orbital motions in the innermost\nregions of accretion discs around black holes and, thus, trace flow patterns\nunder the effect of the hole strong gravitational field. We explore this\npossibility analizing XMM-Newton observations of the seyfert 1 galaxy NGC 3783.\nA detiled time-resolved spectral analysis is performed down to the shortest\npossible time-scales (few ks) using \"excess maps\" and cross-correlating light\ncurves in different energy bands. In addition to a constant core of the Fe K\nalpha line, we detected a variable and redshifted Fe K alpha emission feature\nbetween 5.3-6.1 keV. The line exhibits a modulation on a time-scale of 27 ks\nthat is similar to and in phase with a modulation of the 0.3-10 keV source\ncontinuum. The time-scale of the correlated variability of the redshifted Fe\nline and continuum agrees with the local dynamical time-scale of the accretion\ndisc at 10 r_g around a black hole of 10^7 M_sun. Given the shape of the\nredshfted line emission and the overall X-ray variability pattern, the line is\nlikely to arise from the relativistic region near the black hole.\n", "machine_text": "\nThe X-ray emission of the Seyfert 1 galaxy NGC 3783 has been closely inspected with XMM-Newton in an effort to probe, through orbital motions, the innermost regions around the black hole. Our analysis revealed a time-variable and redshifted Fe K line emission that is correlated to the source continuum on a time-scale of 27 ks. This value agrees with the local dynamical time-scale of the black hole disc at 10 r_g. The line shape and overall X-ray pattern suggest the origin of the line likely lies in the vicinity of the black hole, under its large gravitational field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0226}
{"prompt": "Rephrase the abstract of an article with title 'The chemical composition of the circumstellar envelopes around yellow\n  hypergiant stars'.\n  The yellow hypergiant stars (YHGs) are extremely luminous and massive objects\nwhose general properties are poorly known. Only two of this kind of star show\nmassive circumstellar envelopes, IRC+10420 and AFGL2343. We aim to study the\nchemistry of the circumstellar envelopes around these two sources, by\ncomparison with well known AGB stars and protoplanetary nebulae. We also\nestimate the abundances of the observed molecular species. We have performed\nsingle-dish observations of different transitions for twelve molecular species.\nWe have compared the ratio of the intensities of the molecular transitions and\nof the estimated abundances in AFGL2343 and IRC+10420 with those in O-rich and\nC-rich AGB stars and protoplanetary nebulae. Both YHGs, AFGL2343, and\nIRC+10420, have been found to have an O-rich chemistry similar to that in\nO-rich AGB stars, though for AFGL2343 the emission of most molecules compared\nwith 13CO lines is relatively weak. Clear differences with the other evolved\nsources appear when we compare the line intensity corrected for distance and\nthe profile widths which are, respectively, very intense and very wide in YHGs.\nThe abundances obtained for IRC+10420 agree with those found in AGB stars, but\nin general those found in AFGL2343, except for 13CO, are too low. This\napparently low molecular abundance in AFGL2343 could be due to the fact that\nthese molecules are present only in an inner region of the shell where the mass\nis relatively low.\n\n", "human_text": "  The yellow hypergiant stars (YHGs) are extremely luminous and massive objects\nwhose general properties are poorly known. Only two of this kind of star show\nmassive circumstellar envelopes, IRC+10420 and AFGL2343. We aim to study the\nchemistry of the circumstellar envelopes around these two sources, by\ncomparison with well known AGB stars and protoplanetary nebulae. We also\nestimate the abundances of the observed molecular species. We have performed\nsingle-dish observations of different transitions for twelve molecular species.\nWe have compared the ratio of the intensities of the molecular transitions and\nof the estimated abundances in AFGL2343 and IRC+10420 with those in O-rich and\nC-rich AGB stars and protoplanetary nebulae. Both YHGs, AFGL2343, and\nIRC+10420, have been found to have an O-rich chemistry similar to that in\nO-rich AGB stars, though for AFGL2343 the emission of most molecules compared\nwith 13CO lines is relatively weak. Clear differences with the other evolved\nsources appear when we compare the line intensity corrected for distance and\nthe profile widths which are, respectively, very intense and very wide in YHGs.\nThe abundances obtained for IRC+10420 agree with those found in AGB stars, but\nin general those found in AFGL2343, except for 13CO, are too low. This\napparently low molecular abundance in AFGL2343 could be due to the fact that\nthese molecules are present only in an inner region of the shell where the mass\nis relatively low.\n", "machine_text": "\nThe current study focuses on the chemistry of the circumstellar envelopes that surround two of the rare and luminous yellow hypergiant stars (YHGs): IRC+10420 and AFGL2343. We consider the ratios of the intensities of various molecular transitions as well as the estimated abundances in both the YHGs and compare it to those found in O-rich and C-rich AGB stars and protoplanetary nebulae. From our single-dish observations for twelve molecular species, we have found that these two YHGs have an O-rich chemistry that is similar to that of O-rich AGB stars. However, the line intensities of most molecules are relatively weak in AFGL2343 than in 13CO lines, and the line intensity corrected for distance and profile widths are high in YHGs compared to the evolved sources. Moreover, the observed abundances for IRC+ 10420 correspond with those found in AGB stars whereas AFGL2343 has lower concentrations of these molecules, except for 13CO. This can possibly be attributed to the fact that these molecules are present only in the inner parts of the shell, where the mass is lower.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1639}
{"prompt": "Rephrase the abstract of an article with title 'Parametric Learning and Monte Carlo Optimization'.\n  This paper uncovers and explores the close relationship between Monte Carlo\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\ncontributions. First, we prove that MCO is mathematically identical to a broad\nclass of PL problems. This identity potentially provides a new application\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\nfor blackbox optimization. Immediate sampling transforms the original BO\nproblem into an MCO problem. Accordingly, by combining these first two\ncontributions, we can apply all PL techniques to BO. In our third contribution\nwe validate this way of improving BO by demonstrating that cross-validation and\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\nignore the relationship between the sample point locations and the associated\nvalues of the integrand; only the values of the integrand at those locations\nare considered. We demonstrate that one can exploit the sample location\ninformation using PL techniques, for example by forming a fit of the sample\nlocations to the associated values of the integrand. This provides an\nadditional way to apply PL techniques to improve MCO.\n\n", "human_text": "  This paper uncovers and explores the close relationship between Monte Carlo\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\ncontributions. First, we prove that MCO is mathematically identical to a broad\nclass of PL problems. This identity potentially provides a new application\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\nfor blackbox optimization. Immediate sampling transforms the original BO\nproblem into an MCO problem. Accordingly, by combining these first two\ncontributions, we can apply all PL techniques to BO. In our third contribution\nwe validate this way of improving BO by demonstrating that cross-validation and\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\nignore the relationship between the sample point locations and the associated\nvalues of the integrand; only the values of the integrand at those locations\nare considered. We demonstrate that one can exploit the sample location\ninformation using PL techniques, for example by forming a fit of the sample\nlocations to the associated values of the integrand. This provides an\nadditional way to apply PL techniques to improve MCO.\n", "machine_text": "This article examines the interplay between Monte Carlo Optimization (MCO) of a parametric integral, Parametric Learning (PL), and 'blackbox'/'oracle'-based optimization (BO). We observe four main contributions: (1) we prove the mathematical equivalence of MCO and a number of PL problems, thus providing an additional application field for PL; (2) we develop an original version of the Probability Collectives (PC) algorithm for BO, 'immediate sampling', which transforms BO into MCO; (3) we show how cross-validation and bagging can be used to enhance immediate sampling; and (4) we investigate how fitting a model to the sample point locations combined with their associated integrand values can lead to improvements in MCO.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1274}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of the Spin-Transfer-Torque Vector in Magnetic Tunnel\n  Junctions'.\n  Spin-polarized currents can transfer spin angular momentum to a ferromagnet,\ngenerating a torque that can efficiently reorient its magnetization. Achieving\nquantitative measurements of the spin-transfer-torque vector in magnetic tunnel\njunctions (MTJs) is important for understanding fundamental mechanisms\naffecting spin-dependent tunneling, and for developing magnetic memories and\nnanoscale microwave oscillators. Here we present direct measurements of both\nthe magnitude and direction of the spin torque in Co60Fe20B20/MgO/Co60Fe20B20\nMTJs. At low bias V, the differential torque vector d{tau}/dV lies in the plane\ndefined by the electrode magnetizations, and its magnitude is in excellent\nagreement with a prediction for highly-spin-polarized tunneling. With\nincreasing bias, the in-plane component d{tau}_{parallel}/dV remains large, in\nstriking contrast to the decreasing magnetoresistance ratio. The differential\ntorque vector also rotates out of the plane under bias; we measure a\nperpendicular component tau_{perp}(V) with bias dependence proportional to V^2\nfor low V, that becomes as large as 30% of the in-plane torque.\n\n", "human_text": "  Spin-polarized currents can transfer spin angular momentum to a ferromagnet,\ngenerating a torque that can efficiently reorient its magnetization. Achieving\nquantitative measurements of the spin-transfer-torque vector in magnetic tunnel\njunctions (MTJs) is important for understanding fundamental mechanisms\naffecting spin-dependent tunneling, and for developing magnetic memories and\nnanoscale microwave oscillators. Here we present direct measurements of both\nthe magnitude and direction of the spin torque in Co60Fe20B20/MgO/Co60Fe20B20\nMTJs. At low bias V, the differential torque vector d{tau}/dV lies in the plane\ndefined by the electrode magnetizations, and its magnitude is in excellent\nagreement with a prediction for highly-spin-polarized tunneling. With\nincreasing bias, the in-plane component d{tau}_{parallel}/dV remains large, in\nstriking contrast to the decreasing magnetoresistance ratio. The differential\ntorque vector also rotates out of the plane under bias; we measure a\nperpendicular component tau_{perp}(V) with bias dependence proportional to V^2\nfor low V, that becomes as large as 30% of the in-plane torque.\n", "machine_text": "\nThe effects of spin-polarized currents on the reorientation of the magnetization of ferromagnets are substantial. To understand and exploit their influence, it is necessary to quantify the spin-transfer-torque vector in magnetic tunnel junctions (MTJs). Herein, accurate measurements of both the magnitude and direction of this torque in Co60Fe20B20/MgO/Co60Fe20B20 MTJs have been made and compared to predictions for highly-spin-polarized tunneling. The in-plane component d{tau}_{parallel}/dV remains large, even when the bias voltage is increased; a perpendicular component tau_{perp}(V) with a bias dependence proportional to V^2, which can reach 30 percent of the in-plane torque, has also been measured. These findings present an essential step towards understanding the mechanisms underlying spin-dependent tunneling and exploiting them for the development of future applications such as memory cells and nanoscale microwave oscillators.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4207}
{"prompt": "Rephrase the abstract of an article with title 'Are collisions with neutral hydrogen important for modelling the Second\n  Solar Spectrum of Ti I and Ca II ?'.\n  The physical interpretation of scattering line polarization offers a novel\ndiagnostic window for exploring the thermal and magnetic structure of the quiet\nregions of the solar atmosphere. Here we evaluate the impact of isotropic\ncollisions with neutral hydrogen atoms on the scattering polarization signals\nof the 13 lines of multiplet 42 of Ti I and on those of the K line and of the\nIR triplet of Ca II, with emphasis on the collisional transfer rates between\nnearby J-levels. To this end, we calculate the linear polarization produced by\nscattering processes considering realistic multilevel models and solving the\nstatistical equilibrium equations for the multipolar components of the atomic\ndensity matrix. We confirm that the lower levels of the 13 lines of multiplet\n42 of Ti I are completely depolarized by elastic collisions. We find that\nupper-level collisional depolarization turns out to have an unnoticeable impact\non the emergent linear polarization amplitudes, except for the ${\\lambda 4536$\nline for which it is possible to notice a rather small depolarization caused by\nthe collisional transfer rates. Concerning the Ca II lines, we show that the\ncollisional rates play no role on the polarization of the upper level of the K\nline, while they have a rather small depolarizing effect on the atomic\npolarization of the metastable lower levels of the Ca II IR triplet.\n\n", "human_text": "  The physical interpretation of scattering line polarization offers a novel\ndiagnostic window for exploring the thermal and magnetic structure of the quiet\nregions of the solar atmosphere. Here we evaluate the impact of isotropic\ncollisions with neutral hydrogen atoms on the scattering polarization signals\nof the 13 lines of multiplet 42 of Ti I and on those of the K line and of the\nIR triplet of Ca II, with emphasis on the collisional transfer rates between\nnearby J-levels. To this end, we calculate the linear polarization produced by\nscattering processes considering realistic multilevel models and solving the\nstatistical equilibrium equations for the multipolar components of the atomic\ndensity matrix. We confirm that the lower levels of the 13 lines of multiplet\n42 of Ti I are completely depolarized by elastic collisions. We find that\nupper-level collisional depolarization turns out to have an unnoticeable impact\non the emergent linear polarization amplitudes, except for the ${\\lambda 4536$\nline for which it is possible to notice a rather small depolarization caused by\nthe collisional transfer rates. Concerning the Ca II lines, we show that the\ncollisional rates play no role on the polarization of the upper level of the K\nline, while they have a rather small depolarizing effect on the atomic\npolarization of the metastable lower levels of the Ca II IR triplet.\n", "machine_text": "This article investigates the significance of scattering line polarization for exploring the quiet regions of the solar atmosphere. By utilizing multilevel models and calculating the linear polarization produced by scattering processes, we assess the effect of collisions with neutral hydrogen on the thirteen lines in multiplet 42 of Ti I and on the K line and IR triplet of Ca II, focusing on the exchange of energy levels caused by these collisions. Though this depolarization affects the ${\\lambda 4536$ line of Ti I significantly, its effect on the other lines is minimal. We also find that the depolarization of the Ca II lines is barely noticeable. This research offers further understanding of the thermal and magnetic structure of the quiet regions of the solar atmosphere.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1968}
{"prompt": "Rephrase the abstract of an article with title 'Imaging the Cosmic Matter Distribution using Gravitational Lensing of\n  Pregalactic HI'.\n  21-cm emission from neutral hydrogen during and before the epoch of cosmic\nreionisation is gravitationally lensed by material at all lower redshifts.\nLow-frequency radio observations of this emission can be used to reconstruct\nthe projected mass distribution of foreground material, both light and dark. We\ncompare the potential imaging capabilities of such 21-cm lensing with those of\nfuture galaxy lensing surveys. We use the Millennium Simulation to simulate\nlarge-area maps of the lensing convergence with the noise, resolution and\nredshift-weighting achievable with a variety of idealised observation\nprogrammes. We find that the signal-to-noise of 21-cm lens maps can far exceed\nthat of any map made using galaxy lensing. If the irreducible noise limit can\nbe reached with a sufficiently large radio telescope, the projected convergence\nmap provides a high-fidelity image of the true matter distribution, allowing\nthe dark matter halos of individual galaxies to be viewed directly, and giving\na wealth of statistical and morphological information about the relative\ndistributions of mass and light. For instrumental designs like that planned for\nthe Square Kilometer Array (SKA), high-fidelity mass imaging may be possible\nnear the resolution limit of the core array of the telescope.\n\n", "human_text": "  21-cm emission from neutral hydrogen during and before the epoch of cosmic\nreionisation is gravitationally lensed by material at all lower redshifts.\nLow-frequency radio observations of this emission can be used to reconstruct\nthe projected mass distribution of foreground material, both light and dark. We\ncompare the potential imaging capabilities of such 21-cm lensing with those of\nfuture galaxy lensing surveys. We use the Millennium Simulation to simulate\nlarge-area maps of the lensing convergence with the noise, resolution and\nredshift-weighting achievable with a variety of idealised observation\nprogrammes. We find that the signal-to-noise of 21-cm lens maps can far exceed\nthat of any map made using galaxy lensing. If the irreducible noise limit can\nbe reached with a sufficiently large radio telescope, the projected convergence\nmap provides a high-fidelity image of the true matter distribution, allowing\nthe dark matter halos of individual galaxies to be viewed directly, and giving\na wealth of statistical and morphological information about the relative\ndistributions of mass and light. For instrumental designs like that planned for\nthe Square Kilometer Array (SKA), high-fidelity mass imaging may be possible\nnear the resolution limit of the core array of the telescope.\n", "machine_text": "This paper investigates the potential of using 21-cm emissions from neutral hydrogen during and before the epoch of cosmic reionisation to reconstruct the projected mass distribution of foreground material, both light and dark, via gravitational lensing. Using the Millennium Simulation, large-area maps of the lensing convergence with realistic noise, resolution, and redshift-weighting achievable with a variety of idealised observation programmes are simulated. Results suggest that the signal-to-noise of 21-cm lens maps can be larger than those of maps made with galaxy lensing. Additionally, if the irreducible noise limit can be achieved with a large enough telescope, a high-fidelity image of the true matter distribution can be obtained, making it possible to view individual galaxies' dark matter halos and gain insight into the relative distributions of mass and light. Finally, mass imaging near the resolution limit of the core array of the Square Kilometer Array (SKA) is possible.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0849}
{"prompt": "Rephrase the abstract of an article with title 'The Common Origin of Linear and Nonlinear Chiral Multiplets in N=4\n  Mechanics'.\n  Elaborating on previous work (hep-th/0605211, hep-th/0611247), we show how\nthe linear and nonlinear chiral multiplets of N=4 supersymmetric mechanics with\nthe off-shell content (2,4,2) can be obtained by gauging three distinct\ntwo-parameter isometries of the ``root'' (4,4,0) multiplet actions. In\nparticular, two different gauge groups, one abelian and one non-abelian, lead,\nalbeit in a disguised form in the second case, to the same (unique) nonlinear\nchiral multiplet. This provides an evidence that no other nonlinear chiral N=4\nmultiplets exist. General sigma model type actions are discussed, together with\nthe restricted potential terms coming from the Fayet-Iliopoulos terms\nassociated with abelian gauge superfields. As in our previous work, we use the\nmanifestly supersymmetric language of N=4, d=1 harmonic superspace. A novel\npoint is the necessity to use in parallel the \\lambda and \\tau gauge frames,\nwith the ``bridges'' between these two frames playing a crucial role. It is the\nN=4 harmonic analyticity which, though being non-manifest in the \\tau frame,\ngives rise to both linear and nonlinear chirality constraints.\n\n", "human_text": "  Elaborating on previous work (hep-th/0605211, hep-th/0611247), we show how\nthe linear and nonlinear chiral multiplets of N=4 supersymmetric mechanics with\nthe off-shell content (2,4,2) can be obtained by gauging three distinct\ntwo-parameter isometries of the ``root'' (4,4,0) multiplet actions. In\nparticular, two different gauge groups, one abelian and one non-abelian, lead,\nalbeit in a disguised form in the second case, to the same (unique) nonlinear\nchiral multiplet. This provides an evidence that no other nonlinear chiral N=4\nmultiplets exist. General sigma model type actions are discussed, together with\nthe restricted potential terms coming from the Fayet-Iliopoulos terms\nassociated with abelian gauge superfields. As in our previous work, we use the\nmanifestly supersymmetric language of N=4, d=1 harmonic superspace. A novel\npoint is the necessity to use in parallel the \\lambda and \\tau gauge frames,\nwith the ``bridges'' between these two frames playing a crucial role. It is the\nN=4 harmonic analyticity which, though being non-manifest in the \\tau frame,\ngives rise to both linear and nonlinear chirality constraints.\n", "machine_text": "\nThis paper reveals the shared origin of linear and nonlinear chiral multiplets in N=4 mechanics with the (2,4,2) off-shell content. By gauging two distinct two-parameter isometries of the (4,4,0) multiplet action--one abelian, the other non-abelian--we uncover disguises of the same (unique) nonlinear chiral multiplet. This lends support to the idea that no other nonlinear N=4 chiral multiplets exist. We employ the language of N=4, d=1 harmonic superspace, using simultaneously the \\lambda and \\tau gauge frames, with the interconnections between them playing a vital role. As it turns out, it is the underlying N=4 harmonic analyticity that supplies both linear and nonlinear chirality constraints in the \\tau gauge, in spite of its non-manifest structure. Our approach additionally touches upon the possible sigma model type actions featuring restricted potential forms, followed by the discussion of their associated Fayet-Iliopoulos terms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0706}
{"prompt": "Rephrase the abstract of an article with title 'Stretching Homopolymers'.\n  Force induced stretching of polymers is important in a variety of contexts.\nWe have used theory and simulations to describe the response of homopolymers,\nwith $N$ monomers, to force ($f$) in good and poor solvents. In good solvents\nand for {{sufficiently large}} $N$ we show, in accord with scaling predictions,\nthat the mean extension along the $f$ axis $<Z>\\sim f$ for small $f$, and\n$<Z>\\sim f^{{2/3}}$ (the Pincus regime) for intermediate values of $f$. The\ntheoretical predictions for $\\la Z\\ra$ as a function of $f$ are in excellent\nagreement with simulations for N=100 and 1600. However, even with N=1600, the\nexpected Pincus regime is not observed due to the the breakdown of the\nassumptions in the blob picture for finite $N$. {{We predict the Pincus scaling\nin a good solvent will be observed for $N\\gtrsim 10^5$}}. The force-dependent\nstructure factors for a polymer in a poor solvent show that there are a\nhierarchy of structures, depending on the nature of the solvent. For a weakly\nhydrophobic polymer, various structures (ideal conformations, self-avoiding\nchains, globules, and rods) emerge on distinct length scales as $f$ is varied.\nA strongly hydrophobic polymer remains globular as long as $f$ is less than a\ncritical value $f_c$. Above $f_c$, an abrupt first order transition to a\nrod-like structure occurs. Our predictions can be tested using single molecule\nexperiments.\n\n", "human_text": "  Force induced stretching of polymers is important in a variety of contexts.\nWe have used theory and simulations to describe the response of homopolymers,\nwith $N$ monomers, to force ($f$) in good and poor solvents. In good solvents\nand for {{sufficiently large}} $N$ we show, in accord with scaling predictions,\nthat the mean extension along the $f$ axis $<Z>\\sim f$ for small $f$, and\n$<Z>\\sim f^{{2/3}}$ (the Pincus regime) for intermediate values of $f$. The\ntheoretical predictions for $\\la Z\\ra$ as a function of $f$ are in excellent\nagreement with simulations for N=100 and 1600. However, even with N=1600, the\nexpected Pincus regime is not observed due to the the breakdown of the\nassumptions in the blob picture for finite $N$. {{We predict the Pincus scaling\nin a good solvent will be observed for $N\\gtrsim 10^5$}}. The force-dependent\nstructure factors for a polymer in a poor solvent show that there are a\nhierarchy of structures, depending on the nature of the solvent. For a weakly\nhydrophobic polymer, various structures (ideal conformations, self-avoiding\nchains, globules, and rods) emerge on distinct length scales as $f$ is varied.\nA strongly hydrophobic polymer remains globular as long as $f$ is less than a\ncritical value $f_c$. Above $f_c$, an abrupt first order transition to a\nrod-like structure occurs. Our predictions can be tested using single molecule\nexperiments.\n", "machine_text": "\nThe properties of homopolymers when exposed to external force are of tremendous importance. To provide deeper insight, we have studied this using theoretical and computational approaches. Our results show that increasing the number of monomers, $N$, beyond a certain value, along with appropriate solvent conditions, allows for extension to follow a scaling of $<Z>\\sim f$ and $<Z>\\sim f^{{2/3}}$, respectively, for small and intermediate values of force ($f$). Corresponding to these regimes, simulations from N=100 to 1600 showcase excellent agreement which however, does not interpret for lower N. {{We predict, however, that the scaling behaviour should be firmly established for $N\\gtrsim 10^5$ in good solvent conditions.}} Moreover, the force-dependent structure factors for poor solvents exhibit a hierarchical arrangement of structures upon varying the force -- from ideal conformations, globules to rod-like structures. Hints of a first order transition from globular to rod-like structures can be experienced when the force is greater than its critical value $f_c$. Our findings may potentially be verified experimentally.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3029}
{"prompt": "Rephrase the abstract of an article with title 'The XMM-SSC survey of hard-spectrum XMM-Newton sources 1: optically\n  bright sources'.\n  We present optical and X-ray data for a sample of serendipitous XMM-Newton\nsources that are selected to have 0.5-2 keV vs 2-4.5 keV X-ray hardness ratios\nwhich are harder than the X-ray background. The sources have 2-4.5 keV X-ray\nflux >= 10^-14 cgs, and in this paper we examine a subsample of 42 optically\nbright (r < 21) sources; this subsample is 100 per cent spectroscopically\nidentified. All but one of the optical counterparts are extragalactic, and we\nargue that the single exception, a Galactic M star, is probably a coincidental\nassociation. The X-ray spectra are consistent with heavily absorbed power laws\n(21.8 < log NH < 23.4), and all of them appear to be absorbed AGN. The majority\nof the sources show only narrow emission lines in their optical spectra,\nimplying that they are type-2 AGN. Only a small fraction of the sources (7/42)\nshow broad optical emission lines, and all of these have NH < 10^23 cm^-2. This\nimplies that ratios of X-ray absorption to optical/UV extinction equivalent to\n> 100 times the Galactic gas-to-dust ratio are rare in AGN absorbers (at most a\nfew percent of the population), and may be restricted to broad absorption-line\nQSOs. Seven objects appear to have an additional soft X-ray component in\naddition to the heavily absorbed power law. We consider the implications of our\nresults in the light of the AGN unified scheme. We find that the soft\ncomponents in narrow-line objects are consistent with the unified scheme\nprovided that > 4 per cent of broad-line AGN have ionised absorbers that\nattenuate their soft X-ray flux by >50 per cent. In at least one of the X-ray\nabsorbed, broad-line AGN in our sample the X-ray spectrum requires an ionised\nabsorber, consistent with this picture.\n\n", "human_text": "  We present optical and X-ray data for a sample of serendipitous XMM-Newton\nsources that are selected to have 0.5-2 keV vs 2-4.5 keV X-ray hardness ratios\nwhich are harder than the X-ray background. The sources have 2-4.5 keV X-ray\nflux >= 10^-14 cgs, and in this paper we examine a subsample of 42 optically\nbright (r < 21) sources; this subsample is 100 per cent spectroscopically\nidentified. All but one of the optical counterparts are extragalactic, and we\nargue that the single exception, a Galactic M star, is probably a coincidental\nassociation. The X-ray spectra are consistent with heavily absorbed power laws\n(21.8 < log NH < 23.4), and all of them appear to be absorbed AGN. The majority\nof the sources show only narrow emission lines in their optical spectra,\nimplying that they are type-2 AGN. Only a small fraction of the sources (7/42)\nshow broad optical emission lines, and all of these have NH < 10^23 cm^-2. This\nimplies that ratios of X-ray absorption to optical/UV extinction equivalent to\n> 100 times the Galactic gas-to-dust ratio are rare in AGN absorbers (at most a\nfew percent of the population), and may be restricted to broad absorption-line\nQSOs. Seven objects appear to have an additional soft X-ray component in\naddition to the heavily absorbed power law. We consider the implications of our\nresults in the light of the AGN unified scheme. We find that the soft\ncomponents in narrow-line objects are consistent with the unified scheme\nprovided that > 4 per cent of broad-line AGN have ionised absorbers that\nattenuate their soft X-ray flux by >50 per cent. In at least one of the X-ray\nabsorbed, broad-line AGN in our sample the X-ray spectrum requires an ionised\nabsorber, consistent with this picture.\n", "machine_text": "This research examines the optical and X-ray data of 42 serendipitously discovered  XMM-Newton sources whose X-ray hardness ratio is higher than the average X-ray background. All of these sources have 2-4.5 keV X-ray fluxes of at least 10^-14 cgs, and their optical counterparts are all found to be extragalactic apart from one Milky Way M star which likely has negligible connection. The X-ray spectra are consistent with heavily absorbed power law emission, hinting at a population of type-2 AGN. Amongst this sample, seven sources have a distinct secondary soft X-ray component, which is consistent with the AGN unified model if > 4 per cent of broad-line AGN features an ionised absorber that reduces their soft X-ray flux by more than half. In support of this, one of the X-ray absorbed, broad-line AGN in the sample clearly has an ionised absorber.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2971}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic Evolution of Black Holes and Spheroids. II: Scaling Relations at\n  z=0.36'.\n  We combine Hubble Space Telescope images of a sample of 20 Seyfert galaxies\nat z=0.36 with spectroscopic information from the Keck Telescope to determine\nthe black hole mass - spheroid luminosity relation (M-L), the Fundamental Plane\n(FP) of the host galaxies and the M-sigma relation. Assuming pure luminosity\nevolution, we find that the host spheroids had smaller luminosity and stellar\nvelocity dispersion than today for a fixed M. The offsets correspond to Delta\nlog L_B,0=0.40+-0.11+-0.15 (Delta log M = 0.51+-0.14+-0.19) and Delta log sigma\n= 0.13+-0.03+-0.05 (Delta log M = 0.54+-0.12+-0.21), respectively for the M-L\nand M-sigma relation. A detailed analysis of known systematic errors and\nselection effects shows that they cannot account for the observed offset. The\ndata are inconsistent with pure luminosity evolution and the existence of\nuniversal and tight scaling relations. To obey the three local scaling\nrelations by z=0 the distant spheroids have to grow their stellar mass by\napproximately 60% (\\Delta log M_sph=0.20+-0.14) in the next 4 billion years.\nThe measured evolution can be expressed as M/ M_sph ~ (1+z)^{1.5+-1.0}. Based\non the disturbed morphologies of a fraction of the sample (6/20) we suggest\ncollisional mergers with disk-dominated systems as evolutionary mechanism.\n\n", "human_text": "  We combine Hubble Space Telescope images of a sample of 20 Seyfert galaxies\nat z=0.36 with spectroscopic information from the Keck Telescope to determine\nthe black hole mass - spheroid luminosity relation (M-L), the Fundamental Plane\n(FP) of the host galaxies and the M-sigma relation. Assuming pure luminosity\nevolution, we find that the host spheroids had smaller luminosity and stellar\nvelocity dispersion than today for a fixed M. The offsets correspond to Delta\nlog L_B,0=0.40+-0.11+-0.15 (Delta log M = 0.51+-0.14+-0.19) and Delta log sigma\n= 0.13+-0.03+-0.05 (Delta log M = 0.54+-0.12+-0.21), respectively for the M-L\nand M-sigma relation. A detailed analysis of known systematic errors and\nselection effects shows that they cannot account for the observed offset. The\ndata are inconsistent with pure luminosity evolution and the existence of\nuniversal and tight scaling relations. To obey the three local scaling\nrelations by z=0 the distant spheroids have to grow their stellar mass by\napproximately 60% (\\Delta log M_sph=0.20+-0.14) in the next 4 billion years.\nThe measured evolution can be expressed as M/ M_sph ~ (1+z)^{1.5+-1.0}. Based\non the disturbed morphologies of a fraction of the sample (6/20) we suggest\ncollisional mergers with disk-dominated systems as evolutionary mechanism.\n", "machine_text": "\nUsing a sample of 20 Seyfert galaxies at z=0.36 combined with Hubble Space Telescope (HST) imaging and spectroscopic information from the Keck Telescope, we investigate the cosmic evolution of black holes and host spheroids by determining the black hole mass-luminosity (M-L) relation, the Fundamental Plane and the M-sigma relation. We find that the host spheroids present less luminosity and stellar velocity dispersion than today assuming pure luminosity evolution. This suggests an increase in stellar mass of approximately 60% in the next 4 billion years to obey the three local scaling relations. Systematic errors and selection effects cannot explain the observed offset. We conclude that the measured evolution can be expressed by M/M_sph ~ (1+z)^{1.5+-1.0}, and hypothesise possible incursion from collisional mergers with disk-dominated systems as the dominant evolutionary mechanism.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0519}
{"prompt": "Rephrase the abstract of an article with title 'How tight is the Lieb-Oxford bound?'.\n  Density-functional theory requires ever better exchange-correlation (xc)\nfunctionals for the ever more precise description of many-body effects on\nelectronic structure. Universal constraints on the xc energy are important\ningredients in the construction of improved functionals. Here we investigate\none such universal property of xc functionals: the Lieb-Oxford lower bound on\nthe exchange-correlation energy, $E_{xc}[n] \\ge -C \\int d^3r n^{4/3}$, where\n$C\\leq C_{LO}=1.68$. To this end, we perform a survey of available exact or\nnear-exact data on xc energies of atoms, ions, molecules, solids, and some\nmodel Hamiltonians (the electron liquid, Hooke's atom and the Hubbard model).\nAll physically realistic density distributions investigated are consistent with\nthe tighter limit $C \\leq 1$. For large classes of systems one can obtain\nclass-specific (but not fully universal) similar bounds. The Lieb-Oxford bound\nwith $C_{LO}=1.68$ is a key ingredient in the construction of modern xc\nfunctionals, and a substantial change in the prefactor $C$ will have\nconsequences for the performance of these functionals.\n\n", "human_text": "  Density-functional theory requires ever better exchange-correlation (xc)\nfunctionals for the ever more precise description of many-body effects on\nelectronic structure. Universal constraints on the xc energy are important\ningredients in the construction of improved functionals. Here we investigate\none such universal property of xc functionals: the Lieb-Oxford lower bound on\nthe exchange-correlation energy, $E_{xc}[n] \\ge -C \\int d^3r n^{4/3}$, where\n$C\\leq C_{LO}=1.68$. To this end, we perform a survey of available exact or\nnear-exact data on xc energies of atoms, ions, molecules, solids, and some\nmodel Hamiltonians (the electron liquid, Hooke's atom and the Hubbard model).\nAll physically realistic density distributions investigated are consistent with\nthe tighter limit $C \\leq 1$. For large classes of systems one can obtain\nclass-specific (but not fully universal) similar bounds. The Lieb-Oxford bound\nwith $C_{LO}=1.68$ is a key ingredient in the construction of modern xc\nfunctionals, and a substantial change in the prefactor $C$ will have\nconsequences for the performance of these functionals.\n", "machine_text": "\nThis paper examines the accuracy of the universal Lieb-Oxford lower bound on the exchange-correlation energy, $E_{xc}[n] \\ge -C \\int d^3r n^{4/3}$. To achieve this, we analyze available exact and nearly exact data on xc energies of atoms, ions, molecules, solids, and some model Hamiltonians. We determine that all observed physical density distributions are in line with the tighter limit of $C \\leq 1$. In addition, we find that for a variety of systems, a specific but not strictly universal bounded value can be assigned. The Lieb-Oxford bound, with a value of $C_{LO}=1.68$, is applied to the development of modern xc functionals, and for that reason any major change in the pre-factor of $C$ will affect the performance of these functionals.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2987}
{"prompt": "Rephrase the abstract of an article with title 'The Discovery of an Active Galactic Nucleus in the Late-type Galaxy NGC\n  3621: Spitzer Spectroscopic Observations'.\n  We report the discovery of an Active Galactic Nucleus (AGN) in the nearby SAd\ngalaxy NGC 3621 using Spitzer high spectral resolution observations. These\nobservations reveal the presence of [NeV] 14 um and 24 um emission which is\ncentrally concentrated and peaks at the position of the near-infrared nucleus.\nUsing the [NeV] line luminosity, we estimate that the nuclear bolometric\nluminosity of the AGN is ~ 5 X 10^41 ergs s^-1, which corresponds based on the\nEddington limit to a lower mass limit of the black hole of ~ 4 X 10^3 Msun.\nUsing an order of magnitude estimate for the bulge mass based on the Hubble\ntype of the galaxy, we find that this lower mass limit does not put a strain on\nthe well-known relationship between the black hole mass and the host galaxy's\nstellar velocity dispersion established in predominantly early-type galaxies.\nMutli-wavelength follow-up observations of NGC 3621 are required to obtain more\nprecise estimates of the bulge mass, black hole mass, accretion rate, and\nnuclear bolometric luminosity. The discovery reported here adds to the growing\nevidence that a black hole can form and grow in a galaxy with no or minimal\nbulge.\n\n", "human_text": "  We report the discovery of an Active Galactic Nucleus (AGN) in the nearby SAd\ngalaxy NGC 3621 using Spitzer high spectral resolution observations. These\nobservations reveal the presence of [NeV] 14 um and 24 um emission which is\ncentrally concentrated and peaks at the position of the near-infrared nucleus.\nUsing the [NeV] line luminosity, we estimate that the nuclear bolometric\nluminosity of the AGN is ~ 5 X 10^41 ergs s^-1, which corresponds based on the\nEddington limit to a lower mass limit of the black hole of ~ 4 X 10^3 Msun.\nUsing an order of magnitude estimate for the bulge mass based on the Hubble\ntype of the galaxy, we find that this lower mass limit does not put a strain on\nthe well-known relationship between the black hole mass and the host galaxy's\nstellar velocity dispersion established in predominantly early-type galaxies.\nMutli-wavelength follow-up observations of NGC 3621 are required to obtain more\nprecise estimates of the bulge mass, black hole mass, accretion rate, and\nnuclear bolometric luminosity. The discovery reported here adds to the growing\nevidence that a black hole can form and grow in a galaxy with no or minimal\nbulge.\n", "machine_text": "\nSpitzer high resolution spectroscopic observations have led to the discovery of an Active Galactic Nucleus (AGN) in the nearby SAd galaxy NGC3621. These observations indicate the presence of [NeV] 14 and 24 um emissions, which peak at the near-infrared nucleus. Through analysis of the [NeV] line luminosity, nuclear bolometric luminosity is estimated to be ~5X10^41 ergs s^-1. Taking into account the Hubble type of the galaxy, this leads to a lower mass limit for the black hole of ~4X10^3 Msun, which is consistent with the established correlation of black hole mass to stellar velocity dispersion in predominantly early-type galaxies. In order further investigate this AGN, additional follow-up multi-wavelength observations are necessary to accurately measure the bulge mass, black hole mass, rate of accretion, and nuclear bolometric luminosity. This discovery supports the idea that black holes can form and develop in galaxies containing minimal or no bulge.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.105}
{"prompt": "Rephrase the abstract of an article with title 'Configuration Space Methods and Time Ordering for Scalar Propagators in\n  (Anti and) de Sitter Spacetimes'.\n  In this master thesis a configuration space method presented by C. Dullemond\nand E. van Beveren for computing all propagators of a scalar field (Wightman,\nHadamard and Schwinger functions,retarded, advanced and Feynman propagator) is\nreviewed for four-dimensional Minkowski and Anti de Sitter spacetime AdS_4.\nThis method is then applied for AdS_d as well as de Sitter spacetime dS_d of\narbitrary dimension d, obtaining results in agreement with the literature. The\nadvantages of the method are that it needs neither mode summation nor analytic\ncontinuation from euclidean time, while delivering the propagators above\nincluding (i-epsilon)-prescription, plus as a nice bonus the conformal\ndimension of a corresponding CFT field. General properties of the considered\nspacetimes (namely various coordinate systems and their metrics, chordal\ndistances, relations between conformal dimensions \\Delta and the mass m of the\nscalar field, geodesics and the invariance of time ordering) are also examined\nand compiled from various sources, providing an overview of geometrical\nproperties of AdS and dS spacetimes.\n\n", "human_text": "  In this master thesis a configuration space method presented by C. Dullemond\nand E. van Beveren for computing all propagators of a scalar field (Wightman,\nHadamard and Schwinger functions,retarded, advanced and Feynman propagator) is\nreviewed for four-dimensional Minkowski and Anti de Sitter spacetime AdS_4.\nThis method is then applied for AdS_d as well as de Sitter spacetime dS_d of\narbitrary dimension d, obtaining results in agreement with the literature. The\nadvantages of the method are that it needs neither mode summation nor analytic\ncontinuation from euclidean time, while delivering the propagators above\nincluding (i-epsilon)-prescription, plus as a nice bonus the conformal\ndimension of a corresponding CFT field. General properties of the considered\nspacetimes (namely various coordinate systems and their metrics, chordal\ndistances, relations between conformal dimensions \\Delta and the mass m of the\nscalar field, geodesics and the invariance of time ordering) are also examined\nand compiled from various sources, providing an overview of geometrical\nproperties of AdS and dS spacetimes.\n", "machine_text": "This thesis reviews a configuration space method presented by C. Dullemond and\nE. van Beveren for computing all propagators of a scalar field in four-dimensional Minkowski and Anti de Sitter spacetimes AdS_4. Subsequently, this method is further applied to AdS_d and de Sitter dS_d for arbitrary dimension d, where the results agree with prior works. As a bonus, the conformal dimensions of the corresponding CFT fields are derived. Moreover, through assembling facts from various sources, the investigation compiles general geometric properties of AdS and dS spacetime into an overview, such as various coordinates, metrics, chordal distances, connections between conformal dimensions \\Delta and the scalar field's mass m, geodesic as well as the invariance of time ordering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1887}
{"prompt": "Rephrase the abstract of an article with title 'Radion Phenomenology in Realistic Warped Space Models'.\n  We investigate the phenomenology of the Randall-Sundrum radion in realistic\nmodels of electroweak symmetry breaking with bulk gauge and fermion fields,\nsince the radion may turn out to be the lightest particle in such models. We\ncalculate the coupling of the radion in such scenarios to bulk fermion and\ngauge modes. Special attention needs to be devoted to the coupling to massless\ngauge fields (photon, gluon), since it is well known that loop effects may be\nimportant for these fields. We also present a detailed explanation of these\ncouplings from the CFT interpretation. We then use these couplings to determine\nthe radion branching fractions and discuss some of the discovery potential of\nthe LHC for the radion. We find that the gamma-gamma signal is enhanced over\nmost of the range of the radion mass over the gamma-gamma signal of a SM Higgs,\nas long as the RS scale is sufficiently low. However, the signal significance\ndepends strongly on free parameters that characterize the magnitude of bare\nbrane-localized kinetic terms for the massless gauge fields. In the absence of\nsuch terms, the signal can be be enhanced over the traditional RS1 models\n(where all standard model fields are localized on the IR brane), but the signal\ncan also be reduced compared to RS1 if the brane localized terms are sizeable.\nWe also show that for larger radion masses, where the gamma-gamma signal is no\nlonger significant, one can use the usual 4 lepton signal to discover the\nradion.\n\n", "human_text": "  We investigate the phenomenology of the Randall-Sundrum radion in realistic\nmodels of electroweak symmetry breaking with bulk gauge and fermion fields,\nsince the radion may turn out to be the lightest particle in such models. We\ncalculate the coupling of the radion in such scenarios to bulk fermion and\ngauge modes. Special attention needs to be devoted to the coupling to massless\ngauge fields (photon, gluon), since it is well known that loop effects may be\nimportant for these fields. We also present a detailed explanation of these\ncouplings from the CFT interpretation. We then use these couplings to determine\nthe radion branching fractions and discuss some of the discovery potential of\nthe LHC for the radion. We find that the gamma-gamma signal is enhanced over\nmost of the range of the radion mass over the gamma-gamma signal of a SM Higgs,\nas long as the RS scale is sufficiently low. However, the signal significance\ndepends strongly on free parameters that characterize the magnitude of bare\nbrane-localized kinetic terms for the massless gauge fields. In the absence of\nsuch terms, the signal can be be enhanced over the traditional RS1 models\n(where all standard model fields are localized on the IR brane), but the signal\ncan also be reduced compared to RS1 if the brane localized terms are sizeable.\nWe also show that for larger radion masses, where the gamma-gamma signal is no\nlonger significant, one can use the usual 4 lepton signal to discover the\nradion.\n", "machine_text": "\nWe explore the implications of Randall-Sundrum radion in realistic warped space models, which include bulk gauge and fermion fields. We focus on the coupling of the radion to massless gauge fields (such as photons and gluons) due to the possibility of loop effects. We explain the couplings from the viewpoint of the conformal field theory. Using the obtained couplings, we calculate the radion decay branching fractions and the possibility for its detection at the LHC. In particular, we find that gamma spectra from the radion is enhanced from the ones from the Standard Model Higgs when the Randall-Sundrum scale is low. This signal can be amplified or suppressed depending on the size of the brane-localized kinetic terms. We depict the possibility to discover the radion through the four lepton channel in the case of larger radion masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3844}
{"prompt": "Rephrase the abstract of an article with title 'Molecular line intensities as measures of cloud masses - II. Conversion\n  factors for specific galaxy types'.\n  We present theoretically-established values of the CO-to-H2 and C-to-H2\nconversion factors that may be used to estimate the gas masses of external\ngalaxies. We consider four distinct galaxy types, represented by M51, NGC 6946,\nM82 and SMC N27. The physical parameters that best represent the conditions\nwithin the molecular clouds in each of the galaxy types are estimated using a\nchi^2 analysis of several observed atomic fine structure and CO rotational\nlines. This analysis is explored over a wide range of density, radiation field,\nextinction, and other relevant parameters. Using these estimated physical\nconditions in methods that we have previously established, CO-to-H2 conversion\nfactors are then computed for CO transitions up to J=9-8. For the conventional\nCO(1-0) transition, the computed conversion factor varies significantly below\nand above the canonical value for the Milky Way in the four galaxy types\nconsidered. Since atomic carbon emission is now frequently used as a probe of\nexternal galaxies, we also present, for the first time, the C-to-H2 conversion\nfactor for this emission in the four galaxy types considered.\n\n", "human_text": "  We present theoretically-established values of the CO-to-H2 and C-to-H2\nconversion factors that may be used to estimate the gas masses of external\ngalaxies. We consider four distinct galaxy types, represented by M51, NGC 6946,\nM82 and SMC N27. The physical parameters that best represent the conditions\nwithin the molecular clouds in each of the galaxy types are estimated using a\nchi^2 analysis of several observed atomic fine structure and CO rotational\nlines. This analysis is explored over a wide range of density, radiation field,\nextinction, and other relevant parameters. Using these estimated physical\nconditions in methods that we have previously established, CO-to-H2 conversion\nfactors are then computed for CO transitions up to J=9-8. For the conventional\nCO(1-0) transition, the computed conversion factor varies significantly below\nand above the canonical value for the Milky Way in the four galaxy types\nconsidered. Since atomic carbon emission is now frequently used as a probe of\nexternal galaxies, we also present, for the first time, the C-to-H2 conversion\nfactor for this emission in the four galaxy types considered.\n", "machine_text": "This article provides theoretical predictions of conversion factors for gas mass\nquantification in four different galaxy types. We use chi-squared analysis to\nestimate physical parameters-- such as density, radiation field, and extinction--\nthat represent the conditions within the clouds of each galaxy type. Using\nmethods established in a prior paper, we then calculate CO-to-H2 and C-to-H2\nconversion factors which may be significantly different from the canonical value\n applicable to the Milky Way. This investigation is establishing a new framework\n for mass estimation for external galaxies expressed through CO and C emission.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2603}
{"prompt": "Rephrase the abstract of an article with title 'L'Univers en expansion et probl\\`emes d'\\'energie'.\n  In this paper we first construct a mathematical model for the Universe\nexpansion that started up with the original Big Bang. Next, we discuss the\nproblematic of the mechanical and physical laws invariance regarding the\nspatial frame exchanges. We then prove the (theoretical) existence of a\nvariable metric $g_t$, depending on time and satisfying to a simplified\nEinstein equation, so that all free ordinary trajectories are geodesics. This\nis done by considering the classical Galileo-Newtonian space and time relation,\nby using generalized Newtonian principles and adding the approved physical new\nones (as covariance principle, Mach principle, the Einstein equivalence\nprinciple ...) in order to establish a new cosmological model of the dynamical\nUniverse as being $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$, where $B_e(O,t)$\nis the Euclidean ball of radius $t$ in $\\mathbb R^3$. The cosmological metric\n$g_t$ is totally determined, at time $t$, by the mass energy distribution\n$E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove\nthat the total and global cosmological energy distribution $E_t(X)$ satisfies\nto the wave equation whose solutions are characterized by pseudo-frequencies\ndepending on time and related to the spectrum of the Dirichlet problem on the\nunit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\\Delta$. Our model is\nconsistent in the sense that all Newtonian and classical physical laws are\nvalid as particular cases in classical situations. Then, we show that all basic\nresults of Modern Physics are still valid without using the second postulate of\nspecial relativity nor the uncertainty principle.\n\n", "human_text": "  In this paper we first construct a mathematical model for the Universe\nexpansion that started up with the original Big Bang. Next, we discuss the\nproblematic of the mechanical and physical laws invariance regarding the\nspatial frame exchanges. We then prove the (theoretical) existence of a\nvariable metric $g_t$, depending on time and satisfying to a simplified\nEinstein equation, so that all free ordinary trajectories are geodesics. This\nis done by considering the classical Galileo-Newtonian space and time relation,\nby using generalized Newtonian principles and adding the approved physical new\nones (as covariance principle, Mach principle, the Einstein equivalence\nprinciple ...) in order to establish a new cosmological model of the dynamical\nUniverse as being $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$, where $B_e(O,t)$\nis the Euclidean ball of radius $t$ in $\\mathbb R^3$. The cosmological metric\n$g_t$ is totally determined, at time $t$, by the mass energy distribution\n$E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove\nthat the total and global cosmological energy distribution $E_t(X)$ satisfies\nto the wave equation whose solutions are characterized by pseudo-frequencies\ndepending on time and related to the spectrum of the Dirichlet problem on the\nunit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\\Delta$. Our model is\nconsistent in the sense that all Newtonian and classical physical laws are\nvalid as particular cases in classical situations. Then, we show that all basic\nresults of Modern Physics are still valid without using the second postulate of\nspecial relativity nor the uncertainty principle.\n", "machine_text": "\nIn this article, we analyze the expanding Universe and the related energy problems. To begin, we develop a mathematical model for the Universe's growth starting with the Big Bang. Then, we address issues regarding the invariance of mechanical and physical laws when dealing with spatial frames exchanges. To demonstrate the (theoretical) existence of a variable metric, which depends on time and abides by a simplified Einstein equation, allowing all ordinary trajectories to be geodesics, we utilize classical Galileo-Newtonian space time relations in addition to approved physical new applications such as the Covariance Principle, Mach Principle, and the Einstein Equivalence Principle. We present a new cosmological model of the dynamic Universe as $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$ alongside the cosmological metric $g_t$ which is at a current time $t$ totally determined by the mass energy distribution $E_t(X)$ on $B_e(O,t)$. Furthermore, we explore the phenomenon of blackholes and prove that the overall cosmological energy distribution $E_t(X)$ accords with a wave equation with solutions characterized by pseudo-frequencies subject to the Dirichlet problem on the unit ball $B_e(O,1)$ and the Laplace-Beltrami Operator -$\\Delta$. With this, we can ascertain that all Newtonian and classical physical laws are applicable in classical circumstances, and all core tenets of Modern Physics remain valid without utilizing the second postulate of special relativity or the uncertainty principle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1248}
{"prompt": "Rephrase the abstract of an article with title 'Using force covariance to derive effective stochastic interactions in\n  dissipative particle dynamics'.\n  There exist methods for determining effective conservative interactions in\ncoarse grained particle based mesoscopic simulations. The resulting models can\nbe used to capture thermal equilibrium behavior, but in the model system we\nstudy do not correctly represent transport properties. In this article we\nsuggest the use of force covariance to determine the full functional form of\ndissipative and stochastic interactions. We show that a combination of the\nradial distribution function and a force covariance function can be used to\ndetermine all interactions in dissipative particle dynamics. Furthermore we use\nthe method to test if the effective interactions in dissipative particle\ndynamics (DPD) can be adjusted to produce a force covariance consistent with a\nprojection of a microscopic Lennard-Jones simulation. The results indicate that\nthe DPD ansatz may not be consistent with the underlying microscopic dynamics.\nWe discuss how this result relates to theoretical studies reported in the\nliterature.\n\n", "human_text": "  There exist methods for determining effective conservative interactions in\ncoarse grained particle based mesoscopic simulations. The resulting models can\nbe used to capture thermal equilibrium behavior, but in the model system we\nstudy do not correctly represent transport properties. In this article we\nsuggest the use of force covariance to determine the full functional form of\ndissipative and stochastic interactions. We show that a combination of the\nradial distribution function and a force covariance function can be used to\ndetermine all interactions in dissipative particle dynamics. Furthermore we use\nthe method to test if the effective interactions in dissipative particle\ndynamics (DPD) can be adjusted to produce a force covariance consistent with a\nprojection of a microscopic Lennard-Jones simulation. The results indicate that\nthe DPD ansatz may not be consistent with the underlying microscopic dynamics.\nWe discuss how this result relates to theoretical studies reported in the\nliterature.\n", "machine_text": "\nThis paper explores a technique for deriving full, effective dissipative and stochastic interactions in mesoscopic simulations by utilizing force covariance. We demonstrate that a combination of the radial distribution function and a force covariance function can be employed to ascertain all interactions in dissipative particle dynamics. Examining the effectiveness of the method, we use the force covariance approach to assess whether the effective interactions of dissipative particle dynamics (DPD) are suitable to reflect the projection of a microscopic Lennard-Jones simulation. Our findings signify that, while the DPD model may correctly reproduce equilibrium behavior, it is not aligned with the underlying microscopic dynamics. We also comment on the connection of this outcome to results from other technical research in literature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3324}
{"prompt": "Rephrase the abstract of an article with title 'Solutions of fractional reaction-diffusion equations in terms of the\n  H-function'.\n  This paper deals with the investigation of the solution of an unified\nfractional reaction-diffusion equation associated with the Caputo derivative as\nthe time-derivative and Riesz-Feller fractional derivative as the\nspace-derivative. The solution is derived by the application of the Laplace and\nFourier transforms in closed form in terms of the H-function. The results\nderived are of general nature and include the results investigated earlier by\nmany authors, notably by Mainardi et al. (2001, 2005) for the fundamental\nsolution of the space-time fractional diffusion equation, and Saxena et al.\n(2006a, b) for fractional reaction- diffusion equations. The advantage of using\nRiesz-Feller derivative lies in the fact that the solution of the fractional\nreaction-diffusion equation containing this derivative includes the fundamental\nsolution for space-time fractional diffusion, which itself is a generalization\nof neutral fractional diffusion, space-fractional diffusion, and\ntime-fractional diffusion. These specialized types of diffusion can be\ninterpreted as spatial probability density functions evolving in time and are\nexpressible in terms of the H-functions in compact form.\n\n", "human_text": "  This paper deals with the investigation of the solution of an unified\nfractional reaction-diffusion equation associated with the Caputo derivative as\nthe time-derivative and Riesz-Feller fractional derivative as the\nspace-derivative. The solution is derived by the application of the Laplace and\nFourier transforms in closed form in terms of the H-function. The results\nderived are of general nature and include the results investigated earlier by\nmany authors, notably by Mainardi et al. (2001, 2005) for the fundamental\nsolution of the space-time fractional diffusion equation, and Saxena et al.\n(2006a, b) for fractional reaction- diffusion equations. The advantage of using\nRiesz-Feller derivative lies in the fact that the solution of the fractional\nreaction-diffusion equation containing this derivative includes the fundamental\nsolution for space-time fractional diffusion, which itself is a generalization\nof neutral fractional diffusion, space-fractional diffusion, and\ntime-fractional diffusion. These specialized types of diffusion can be\ninterpreted as spatial probability density functions evolving in time and are\nexpressible in terms of the H-functions in compact form.\n", "machine_text": "This article explores methods for finding solutions to fractional reaction-diffusion equations utilising Laplace and Fourier transforms and the H-function. These solutions encompass previous research conducted by Mainardi et al. (2001, 2005) and Saxena et al. (2006a, b). Moreover, the advantage of utilising a Riesz-Feller derivative can be seen in the obtainment of solutions which incorporate a fundamental space-time fractional diffusion, as well as generalised neutral fractional, space-fractional and time-fractional diffusion. These types of diffusion can be interpreted as shifting spatial probability densities and can be expressed in terms of the H-function succinctly.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0329}
{"prompt": "Rephrase the abstract of an article with title 'Truecluster matching'.\n  Cluster matching by permuting cluster labels is important in many clustering\ncontexts such as cluster validation and cluster ensemble techniques. The\nclassic approach is to minimize the euclidean distance between two cluster\nsolutions which induces inappropriate stability in certain settings. Therefore,\nwe present the truematch algorithm that introduces two improvements best\nexplained in the crisp case. First, instead of maximizing the trace of the\ncluster crosstable, we propose to maximize a chi-square transformation of this\ncrosstable. Thus, the trace will not be dominated by the cells with the largest\ncounts but by the cells with the most non-random observations, taking into\naccount the marginals. Second, we suggest a probabilistic component in order to\nbreak ties and to make the matching algorithm truly random on random data. The\ntruematch algorithm is designed as a building block of the truecluster\nframework and scales in polynomial time. First simulation results confirm that\nthe truematch algorithm gives more consistent truecluster results for unequal\ncluster sizes. Free R software is available.\n\n", "human_text": "  Cluster matching by permuting cluster labels is important in many clustering\ncontexts such as cluster validation and cluster ensemble techniques. The\nclassic approach is to minimize the euclidean distance between two cluster\nsolutions which induces inappropriate stability in certain settings. Therefore,\nwe present the truematch algorithm that introduces two improvements best\nexplained in the crisp case. First, instead of maximizing the trace of the\ncluster crosstable, we propose to maximize a chi-square transformation of this\ncrosstable. Thus, the trace will not be dominated by the cells with the largest\ncounts but by the cells with the most non-random observations, taking into\naccount the marginals. Second, we suggest a probabilistic component in order to\nbreak ties and to make the matching algorithm truly random on random data. The\ntruematch algorithm is designed as a building block of the truecluster\nframework and scales in polynomial time. First simulation results confirm that\nthe truematch algorithm gives more consistent truecluster results for unequal\ncluster sizes. Free R software is available.\n", "machine_text": "The infamous truematch algorithm offers two main improvements to traditional cluster matching techniques. First, it maximizes the chi-square transformation of a crosstable rather than solely relying on the trace. This leads to a more comprehensive assessment of the clusters, as it factors in all entries of the crosstable and utilizes the marginal values. Second, it provides a probabilistic solution to breaking ties in the matching process, allowing truly random matchup results when needed. In addition, it is designed to work within the truecluster framework and runs in polynomial time. Initial simulation results show that truematch produces more reliable results. Free R software is available.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4302}
{"prompt": "Rephrase the abstract of an article with title 'Dual Field Theories In (d-1)+1 Emergent Spacetimes From A Unifying Field\n  Theory In d+2 Spacetime'.\n  According to Two-Time Physics, there is more to space-time than can be\ngarnered with the ordinary formulation of physics. Two-Time Physics has shown\nthat the Standard Model of Particles and Forces is successfully reproduced by a\ntwo-time field theory in 4 space and 2 time dimensions projected as a\nholographic image on an emergent spacetime in 3+1 dimensions. Among the\nsuccesses of this approach is the resolution of the strong CP problem of QCD as\nan outcome of the restrictions imposed by the higher symmetry structures in 4+2\ndimensions. In this paper we launch a program to construct the duals of the\nStandard Model as other holographic images of the same 4+2 dimensional theory\non a variety of emergent spacetimes in 3+1 dimensions. These dual field\ntheories are obtained as a family of gauge choices in the master 4+2 field\ntheory. In the present paper we deal with some of the simpler gauge choices\nwhich lead to interacting Klein-Gordon field theories for the conformal scalar\nwith a predicted SO(d,2) symmetry in a variety of interesting curved spacetimes\nin (d-1)+1 dimensions. More challenging and more interesting gauge choices\n(including some that relate to mass) which are left to future work are also\noutlined. Through this approach we discover a new realm of previously\nunexplored dualities and hidden symmetries that exist both in the macroscopic\nand microscopic worlds, at the classical and quantum levels. Such phenomena\npredicted by 2T-physics can in principle be confirmed both by theory and\nexperiment. 1T-physics can be used to analyze the predictions but in most\ninstances gives no clue that the predicted phenomena exist in the first place.\nThis point of view suggests a new paradigm for the construction of a\nfundamental theory that is likely to impact on the quest for unification.\n\n", "human_text": "  According to Two-Time Physics, there is more to space-time than can be\ngarnered with the ordinary formulation of physics. Two-Time Physics has shown\nthat the Standard Model of Particles and Forces is successfully reproduced by a\ntwo-time field theory in 4 space and 2 time dimensions projected as a\nholographic image on an emergent spacetime in 3+1 dimensions. Among the\nsuccesses of this approach is the resolution of the strong CP problem of QCD as\nan outcome of the restrictions imposed by the higher symmetry structures in 4+2\ndimensions. In this paper we launch a program to construct the duals of the\nStandard Model as other holographic images of the same 4+2 dimensional theory\non a variety of emergent spacetimes in 3+1 dimensions. These dual field\ntheories are obtained as a family of gauge choices in the master 4+2 field\ntheory. In the present paper we deal with some of the simpler gauge choices\nwhich lead to interacting Klein-Gordon field theories for the conformal scalar\nwith a predicted SO(d,2) symmetry in a variety of interesting curved spacetimes\nin (d-1)+1 dimensions. More challenging and more interesting gauge choices\n(including some that relate to mass) which are left to future work are also\noutlined. Through this approach we discover a new realm of previously\nunexplored dualities and hidden symmetries that exist both in the macroscopic\nand microscopic worlds, at the classical and quantum levels. Such phenomena\npredicted by 2T-physics can in principle be confirmed both by theory and\nexperiment. 1T-physics can be used to analyze the predictions but in most\ninstances gives no clue that the predicted phenomena exist in the first place.\nThis point of view suggests a new paradigm for the construction of a\nfundamental theory that is likely to impact on the quest for unification.\n", "machine_text": "\nTwo-Time Physics opens the possibility for a more in-depth description of the space-time by allowing the Standard Model of Particles and Forces to be successfully expressed as a two-time field theory. This approach provides a resolution for the strong CP problem of QCD, found through its higher dimensional symmetry structures. As a part of this paper, a process is described to build the duals of the Standard Model using the same four and two dimensional theory as holographic images. Particularly, the effects of a variety of interesting curved spacetimes in (d-1)+1 dimensions are studied in order to demonstrate the effects of simpler gauge choices made while creating the master 4+2 dimensional field theory. The result is the establishment of Klein-Gordon field theories with SO(d,2) symmetry. Furthermore, more challenging and more intricate gauge choices, such as those related to mass, are proposed for future work. This progression suggests a new framework of dualities and hidden symmetries found both in the macroscopic and microscopic universes and at the classical and quantum levels. Through this, One-Time Physics may be used to confirm the 2T-physics predictions through theory and experiment, providing a distinct approach toward the unification of theories.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2834}
{"prompt": "Rephrase the abstract of an article with title 'Jet-breaks in the X-ray Light-Curves of Swift GRB Afterglows'.\n  In the set of 236 GRB afterglows observed by Swift between January 2005 and\nMarch 2007, we identify 30 X-ray light-curves whose power-law fall-off exhibit\na steepening (\"break\") at 0.1-10 day after trigger, to a decay steeper than\nt^{-1.5}. For most of these afterglows, the X-ray spectral slope and the decay\nindices before and after the break can be accommodated by the standard jet\nmodel although a different origin of the breaks cannot be ruled out. In\naddition, there are 27 other afterglows whose X-ray light-curves may also\nexhibit a late break to a steep decay, but the evidence is not that compelling.\n  The X-ray emissions of 38 afterglows decay slower than t^{-1.5} until after 3\nday, half of them exhibiting such a slow decay until after 10 day.\n  Therefore, the fraction of well-monitored Swift afterglows with potential\njet-breaks is around 60 percent, whether we count only the strongest cases for\neach type or all of them. This fraction is comparable to the 75 percent of\npre-Swift afterglows whose optical light-curves displayed similar breaks at ~1\nday.\n  The properties of the prompt emission of Swift afterglows with light-curve\nbreaks show the same correlations (peak energy of GRB spectrum with the burst\nisotropic output and with burst collimated output) as previously found for\npre-Swift optical afterglows with light-curve breaks (the Amati and Ghirlanda\nrelations, respectively). However, we find that Ghirlanda relation is largely a\nconsequence of Amati's and that the use of the jet-break time leads to a\nstronger Ghirlanda correlation only when the few outliers to the Amati relation\nare included.\n\n", "human_text": "  In the set of 236 GRB afterglows observed by Swift between January 2005 and\nMarch 2007, we identify 30 X-ray light-curves whose power-law fall-off exhibit\na steepening (\"break\") at 0.1-10 day after trigger, to a decay steeper than\nt^{-1.5}. For most of these afterglows, the X-ray spectral slope and the decay\nindices before and after the break can be accommodated by the standard jet\nmodel although a different origin of the breaks cannot be ruled out. In\naddition, there are 27 other afterglows whose X-ray light-curves may also\nexhibit a late break to a steep decay, but the evidence is not that compelling.\n  The X-ray emissions of 38 afterglows decay slower than t^{-1.5} until after 3\nday, half of them exhibiting such a slow decay until after 10 day.\n  Therefore, the fraction of well-monitored Swift afterglows with potential\njet-breaks is around 60 percent, whether we count only the strongest cases for\neach type or all of them. This fraction is comparable to the 75 percent of\npre-Swift afterglows whose optical light-curves displayed similar breaks at ~1\nday.\n  The properties of the prompt emission of Swift afterglows with light-curve\nbreaks show the same correlations (peak energy of GRB spectrum with the burst\nisotropic output and with burst collimated output) as previously found for\npre-Swift optical afterglows with light-curve breaks (the Amati and Ghirlanda\nrelations, respectively). However, we find that Ghirlanda relation is largely a\nconsequence of Amati's and that the use of the jet-break time leads to a\nstronger Ghirlanda correlation only when the few outliers to the Amati relation\nare included.\n", "machine_text": "\nThis article discusses the observation of 236 GRB afterglows out of which 30 have their X-ray light-curves exhibiting an abrupt steepening (\"break\") anywhere between 0.1 and 10 days after the trigger. It is argued that majority of these can be attributed to a standard jet model, however, other possibilities are yet to be ruled out. Meanwhile, 27 other afterglows appear to display a similar break, even though the evidence is not that convincing. It is theorized then, that the fraction of well-monitored Swift afterglows with potential jet-breaks should be around 60 percent, comparable to the 75 percent of those prior to Swift studied using 1 day optical light-curves breaks. Further, the correlation between the peak energy of GRB spectrum for isotropic and collimated output with the jet-breaker time is explored, indicating an amended version of the previously established Amati and Ghirlanda relations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1015}
{"prompt": "Rephrase the abstract of an article with title 'X-ray detection of the substellar twin 2MASS J11011926-7732383 AB'.\n  2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star\nforming region, is a rare wide-separation brown dwarf binary. XMM-Newton and\nChandra observations of 2M1101AB have allowed us to examine the influence of\nphysical parameters (mass, bolometric luminosity and effective temperature) on\nX-ray emission from a coeval pair of substellar objects. The spatial resolution\nof XMM-Newton is not sufficient to separate contributions from the two\ncomponents in the binary. The X-ray source detected with XMM-Newton has a\ncolumn density compatible with the infrared extinction of component A. On the\nother hand, the binary is resolved with Chandra, and the bulk of the X-ray\nemission is clearly associated with the photospherically cooler component B.\nThese apparently contradictory results point at strong variability of 2M1101's\nX-ray emission. Combined with previous sensitive X-ray observations from\nlow-mass members of ChaI, we find a decline of X-ray luminosity with decreasing\n(sub)stellar mass that is typical for star forming regions. 2M1101B is the\ncoolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in\nX-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members,\nand therefore relatively luminous. Most bona fide brown dwarfs of Cha I have\nremained below the sensitivity limits of available X-ray observations, because\nof their low luminosity associated with higher age.\n\n", "human_text": "  2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star\nforming region, is a rare wide-separation brown dwarf binary. XMM-Newton and\nChandra observations of 2M1101AB have allowed us to examine the influence of\nphysical parameters (mass, bolometric luminosity and effective temperature) on\nX-ray emission from a coeval pair of substellar objects. The spatial resolution\nof XMM-Newton is not sufficient to separate contributions from the two\ncomponents in the binary. The X-ray source detected with XMM-Newton has a\ncolumn density compatible with the infrared extinction of component A. On the\nother hand, the binary is resolved with Chandra, and the bulk of the X-ray\nemission is clearly associated with the photospherically cooler component B.\nThese apparently contradictory results point at strong variability of 2M1101's\nX-ray emission. Combined with previous sensitive X-ray observations from\nlow-mass members of ChaI, we find a decline of X-ray luminosity with decreasing\n(sub)stellar mass that is typical for star forming regions. 2M1101B is the\ncoolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in\nX-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members,\nand therefore relatively luminous. Most bona fide brown dwarfs of Cha I have\nremained below the sensitivity limits of available X-ray observations, because\nof their low luminosity associated with higher age.\n", "machine_text": "\nUsing X-ray detection methods, we have studied the twin brown dwarf 2MASS J11011926-7732383 AB (hereafter 2M1101AB) present in the Cha I star formation region. XMM-Newton and Chandra data are used to observe the influence on X-ray emission of physical parameters (mass, bolometric luminosity, and effective temperature) for this coeval pair of substellar bodies. Although the XMM-Newton resolution is not adequate to distinguish contributions from the two components of the binary, the column density of the X-ray source detected with it is analogous to the infrared extinction of component A. Also, Chandra can resolve the binary and suggests that the bulk of the X-ray emission is related to the photospherically cooler component B. These seemingly discrepant conclusions appear to be indicates of the X-ray emission's intense variability. When combined with formerly conducted sensitive X-ray surveys of low-mass members of Cha I, it can be understood that X-ray luminosity slowly declines as (sub)stellar mass decreases, as is regularly seen in star formation regions. 2M1101B, the coolest (M8.25 type) and least massive brown dwarf in Cha I thus far detected in X-rays, is also one of the youngest (~ 1 Myr) substellar members of Cha I and therefore relatively luminous. Most bona fide brown dwarfs of Cha I have remained out of reach of the sensitivity limits of available X-ray observations due to the combination of their low luminosity and higher age.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2301}
{"prompt": "Rephrase the abstract of an article with title 'Geometrical properties of local dynamics in Hamiltonian systems: the\n  Generalized Alignment Index (GALI) method'.\n  We investigate the detailed dynamics of multidimensional Hamiltonian systems\nby studying the evolution of volume elements formed by unit deviation vectors\nabout their orbits. The behavior of these volumes is strongly influenced by the\nregular or chaotic nature of the motion, the number of deviation vectors, their\nlinear (in)dependence and the spectrum of Lyapunov exponents. The different\ntime evolution of these volumes can be used to identify rapidly and efficiently\nthe nature of the dynamics, leading to the introduction of quantities that\nclearly distinguish between chaotic behavior and quasiperiodic motion on\n$N$-dimensional tori. More specifically we introduce the Generalized Alignment\nIndex of order $k$ (GALI$_k$) as the volume of a generalized parallelepiped,\nwhose edges are $k$ initially linearly independent unit deviation vectors from\nthe studied orbit whose magnitude is normalized to unity at every time step.\nThe GALI$_k$ is a generalization of the Smaller Alignment Index (SALI)\n(GALI$_2$ $\\propto$ SALI). However, GALI$_k$ provides significantly more\ndetailed information on the local dynamics, allows for a faster and clearer\ndistinction between order and chaos than SALI and works even in cases where the\nSALI method is inconclusive.\n\n", "human_text": "  We investigate the detailed dynamics of multidimensional Hamiltonian systems\nby studying the evolution of volume elements formed by unit deviation vectors\nabout their orbits. The behavior of these volumes is strongly influenced by the\nregular or chaotic nature of the motion, the number of deviation vectors, their\nlinear (in)dependence and the spectrum of Lyapunov exponents. The different\ntime evolution of these volumes can be used to identify rapidly and efficiently\nthe nature of the dynamics, leading to the introduction of quantities that\nclearly distinguish between chaotic behavior and quasiperiodic motion on\n$N$-dimensional tori. More specifically we introduce the Generalized Alignment\nIndex of order $k$ (GALI$_k$) as the volume of a generalized parallelepiped,\nwhose edges are $k$ initially linearly independent unit deviation vectors from\nthe studied orbit whose magnitude is normalized to unity at every time step.\nThe GALI$_k$ is a generalization of the Smaller Alignment Index (SALI)\n(GALI$_2$ $\\propto$ SALI). However, GALI$_k$ provides significantly more\ndetailed information on the local dynamics, allows for a faster and clearer\ndistinction between order and chaos than SALI and works even in cases where the\nSALI method is inconclusive.\n", "machine_text": "\nWe analyze the dynamical characteristics of Hamiltonian systems in multiple dimensions by examining changes in the volume of a unit deviance vector around its orbit. This volume is heavily influenced by the regularity or chaoticity of the motion, the number of deviance vectors, their linear dependency and the spectrum of its Lyapunov exponents. The fluctuating shape of this volume can be used to quickly categorize the nature of the system, leading to the development of measures that allow for a clear distinction between chaos and quasiperiodic motion on N-dimensional tori. In particular, we introduce the Generalized Alignment Index of order k (GALI$_k$), which is the volume of a generalized parallelepiped included with k initially independent unit deviance vectors of size normalized to one at each time step. This GALI$_k$ index is an extension of the Smaller Alignment Index (SALI) and provides a deeper analysis of the local dynamics. It is more efficient in distinguishing between order and chaos than SALI and can be applied even when SALI yields inconclusive results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3155}
{"prompt": "Rephrase the abstract of an article with title 'Finite-size effects in roughness distribution scaling'.\n  We study numerically finite-size corrections in scaling relations for\nroughness distributions of various interface growth models. The most common\nrelation, which considers the average roughness $<w_2>$ as scaling factor, is\nnot obeyed in the steady states of a group of ballistic-like models in 2+1\ndimensions, even when very large system sizes are considered. On the other\nhand, good collapse of the same data is obtained with a scaling relation that\ninvolves the root mean square fluctuation of the roughness, which can be\nexplained by finite-size effects on second moments of the scaling functions. We\nalso obtain data collapse with an alternative scaling relation that accounts\nfor the effect of the intrinsic width, which is a constant correction term\npreviously proposed for the scaling of $<w_2>$. This illustrates how\nfinite-size corrections can be obtained from roughness distributions scaling.\nHowever, we discard the usual interpretation that the intrinsic width is a\nconsequence of high surface steps by analyzing data of restricted\nsolid-on-solid models with various maximal height differences between\nneighboring columns. We also observe that large finite-size corrections in the\nroughness distributions are usually accompanied by huge corrections in height\ndistributions and average local slopes, as well as in estimates of scaling\nexponents. The molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1\ndimensions is a case example in which none of the proposed scaling relations\nworks properly, while the other measured quantities do not converge to the\nexpected asymptotic values. Thus, although roughness distributions are clearly\nbetter than other quantities to determine the universality class of a growing\nsystem, it is not the final solution for this task.\n\n", "human_text": "  We study numerically finite-size corrections in scaling relations for\nroughness distributions of various interface growth models. The most common\nrelation, which considers the average roughness $<w_2>$ as scaling factor, is\nnot obeyed in the steady states of a group of ballistic-like models in 2+1\ndimensions, even when very large system sizes are considered. On the other\nhand, good collapse of the same data is obtained with a scaling relation that\ninvolves the root mean square fluctuation of the roughness, which can be\nexplained by finite-size effects on second moments of the scaling functions. We\nalso obtain data collapse with an alternative scaling relation that accounts\nfor the effect of the intrinsic width, which is a constant correction term\npreviously proposed for the scaling of $<w_2>$. This illustrates how\nfinite-size corrections can be obtained from roughness distributions scaling.\nHowever, we discard the usual interpretation that the intrinsic width is a\nconsequence of high surface steps by analyzing data of restricted\nsolid-on-solid models with various maximal height differences between\nneighboring columns. We also observe that large finite-size corrections in the\nroughness distributions are usually accompanied by huge corrections in height\ndistributions and average local slopes, as well as in estimates of scaling\nexponents. The molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1\ndimensions is a case example in which none of the proposed scaling relations\nworks properly, while the other measured quantities do not converge to the\nexpected asymptotic values. Thus, although roughness distributions are clearly\nbetter than other quantities to determine the universality class of a growing\nsystem, it is not the final solution for this task.\n", "machine_text": "\nIn this article, we investigate numerically the finite-size effects that affect the scaling behavior of roughness distributions in different interface growth models. Contrary to the usual assumption that the average roughness $<w_2>$ is a suitable scaling factor, we observe that this result is not valid for a variety of ballistic-like models in 2+1 dimensions, even when large system sizes are considered. To explain this phenomenon, we propose a scaling relation that involves the root mean square fluctuation of the roughness, which successfully collapses the data. We also find that accounting for the constant intrinsic width correction term significantly improves the scaling of $<w_2>$. Moreover, our study disproves the conventional assertion that intrinsic width originates from high surface steps by analyzing data from restricted solid-on-solid models with a range of maximal height variations between neighbor columns. Finally, we find that finite size corrections in roughness distributions are often coupled with sizable corrections in height distributions, average local slopes, and estimates of scaling exponents. As a case example, we analyze the molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1 dimensions, and find that none of the proposed scaling relations yield satisfactory results. Our findings demonstrate that roughness distributions are superior tools for determining the universality class of a growing system, though they cannot provide a definite solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1307}
{"prompt": "Rephrase the abstract of an article with title 'Finite determination of regular (a,b)-modules'.\n  The concept of (a,b)-module comes from the study the Gauss-Manin lattices of\nan isolated singularity of a germ of an holomorphic function. It is a very\nsimple ''abstract algebraic structure'', but very rich, whose prototype is the\nformal completion of the Brieskorn-module of an isolated singularity. The aim\nof this article is to prove a very basic theorem on regular (a,b)-modules\nshowing that a given regular (a,b)-module is completely characterized by some\n''finite order jet'' of its structure. Moreover a very simple bound for such a\nsufficient order is given in term of the rank and of two very simple invariants\n: the regularity order which count the number of times you need to apply \\\n$b^{-1}.a \\simeq \\partial_z.z$ in order to reach a simple pole (a,b)-module.\nThe second invariant is the ''width'' which corresponds, in the simple pole\ncase, to the maximal integral difference between to eigenvalues of $b^{-1}.a$\n  (the logarithm of the monodromy). In the computation of examples this theorem\nis quite helpfull because it tells you at which power of $b$ in the expansions\nyou may stop without loosing any information.\n\n", "human_text": "  The concept of (a,b)-module comes from the study the Gauss-Manin lattices of\nan isolated singularity of a germ of an holomorphic function. It is a very\nsimple ''abstract algebraic structure'', but very rich, whose prototype is the\nformal completion of the Brieskorn-module of an isolated singularity. The aim\nof this article is to prove a very basic theorem on regular (a,b)-modules\nshowing that a given regular (a,b)-module is completely characterized by some\n''finite order jet'' of its structure. Moreover a very simple bound for such a\nsufficient order is given in term of the rank and of two very simple invariants\n: the regularity order which count the number of times you need to apply \\\n$b^{-1}.a \\simeq \\partial_z.z$ in order to reach a simple pole (a,b)-module.\nThe second invariant is the ''width'' which corresponds, in the simple pole\ncase, to the maximal integral difference between to eigenvalues of $b^{-1}.a$\n  (the logarithm of the monodromy). In the computation of examples this theorem\nis quite helpfull because it tells you at which power of $b$ in the expansions\nyou may stop without loosing any information.\n", "machine_text": " This article investigates a basic theorem regarding regular (a,b)-modules, which determines that a given regular (a,b)-module is entirely specified by a 'finite order jet' of its structure. A simple bound for this sufficient order is explained--in terms of rank and two basic invariants--the regularity order, which counts the number of times the operator $\\partial_z.z$ must be applied in order to achieve a simple pole (a, b)-module; and the 'width' which, in the case of a simple pole, is the largest integral difference between the eigenvalues of $b^{-1}.a$ (the logarithm of the monodromy). This theorem proves helpful in the computation of examples as it specifies up to which power of $b$ in an expansion must be taken into account to not lose any information.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2995}
{"prompt": "Rephrase the abstract of an article with title 'A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman\n  Break Galaxy at z=3.07'.\n  We report the detection of CO(3-2) emission from a bright, gravitationally\nlensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07\nusing the Plateau de Bure Interferometer. This is only the second detection of\nmolecular gas emission from an LBG and yields an intrinsic molecular gas mass\nof (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG\nindicates that it comprises two components separated by ~2 kpc. The CO emission\nis unresolved, and appears to be centered on the intrinsically fainter (and\nalso less highly magnified) of the two UV components. The width of the CO line\nindicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc.\nEmploying mid-infrared observations from Spitzer we derive a stellar mass of\n~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the\nmolecular gas will be consumed in ~40 Myr. The gas fractions, star-formation\nefficiencies and line widths suggests that LBGJ213512 is a high-redshift,\ngas-rich analog of a local luminous infrared galaxy. This galaxy has a similar\ngas-to-dynamical mass fraction as observed in the submillimeter-selected\npopulation, although the gas surface density and star-formation efficiency is a\nfactor of 3x less, suggesting less vigorous activity. We discuss the\nuncertainties in our conclusions arising from adopting a CO-to-H2 conversion\nfactor appropriate for either the Milky Way or local luminous infrared\ngalaxies. These observations demonstrate that current facilities, when aided by\nfortuitous gravitational magnification, can study 'ordinary' galaxies at\nhigh-redshift and so act as pathfinders for ALMA.\n\n", "human_text": "  We report the detection of CO(3-2) emission from a bright, gravitationally\nlensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07\nusing the Plateau de Bure Interferometer. This is only the second detection of\nmolecular gas emission from an LBG and yields an intrinsic molecular gas mass\nof (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG\nindicates that it comprises two components separated by ~2 kpc. The CO emission\nis unresolved, and appears to be centered on the intrinsically fainter (and\nalso less highly magnified) of the two UV components. The width of the CO line\nindicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc.\nEmploying mid-infrared observations from Spitzer we derive a stellar mass of\n~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the\nmolecular gas will be consumed in ~40 Myr. The gas fractions, star-formation\nefficiencies and line widths suggests that LBGJ213512 is a high-redshift,\ngas-rich analog of a local luminous infrared galaxy. This galaxy has a similar\ngas-to-dynamical mass fraction as observed in the submillimeter-selected\npopulation, although the gas surface density and star-formation efficiency is a\nfactor of 3x less, suggesting less vigorous activity. We discuss the\nuncertainties in our conclusions arising from adopting a CO-to-H2 conversion\nfactor appropriate for either the Milky Way or local luminous infrared\ngalaxies. These observations demonstrate that current facilities, when aided by\nfortuitous gravitational magnification, can study 'ordinary' galaxies at\nhigh-redshift and so act as pathfinders for ALMA.\n", "machine_text": "\nWe use the Plateau de Bure Interferometer to detect CO(3-2) emission from a bright, gravitationally magnified Lyman Break Galaxy, LBGJ213512.73-010143, at z=3.07. This is the second detection of molecular gas from an LBG, from which we infer an intrinsic molecular gas mass of (2.4+/-0.4)x10^9 Mo. Through lens reconstruction of the UV morphology of the LBG, we find two components separated by ~2 kpc; CO emission appears to be centered on the fainter UV component. The velocity width of the line indicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc. Using analysis of mid-infrared observations from Spitzer, we determine the stellar mass to be ~(6+/-2)x10^9 Mo, and the star-formation rate to be ~60 Mo/yr; this suggests the molecular gas could be consumed in ~40 Myr. Our study reveals the Cosmic Eye to be a high-redshift, gas-rich analog of a local luminous infrared galaxy, though with a lower gas fraction, gas surface density and star-formation efficiency than submillimeter-selected galaxies. This observation serves as an example of how current facilities, augmented by gravitational magnification, can study 'ordinary' galaxies at high-redshift, foreshadowing the capabilities of ALMA.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1721}
{"prompt": "Rephrase the abstract of an article with title 'Measuring energy dependent polarization in soft gamma-rays using Compton\n  scattering in PoGOLite'.\n  Linear polarization in X- and gamma-rays is an important diagnostic of many\nastrophysical sources, foremost giving information about their geometry,\nmagnetic fields, and radiation mechanisms. However, very few X-ray polarization\nmeasurements have been made, and then only mono-energetic detections, whilst\nseveral objects are assumed to have energy dependent polarization signatures.\nIn this paper we investigate whether detection of energy dependent polarization\nfrom cosmic sources is possible using the Compton technique, in particular with\nthe proposed PoGOLite balloon-experiment, in the 25-100 keV range. We use\nGeant4 simulations of a PoGOLite model and input photon spectra based on Cygnus\nX-1 and accreting magnetic pulsars (100 mCrab). Effective observing times of 6\nand 35 hours were simulated, corresponding to a standard and a long duration\nflight respectively. Both smooth and sharp energy variations of the\npolarization are investigated and compared to constant polarization signals\nusing chi-square statistics. We can reject constant polarization, with energy,\nfor the Cygnus X-1 spectrum (in the hard state), if the reflected component is\nassumed to be completely polarized, whereas the distinction cannot be made for\nweaker polarization. For the accreting pulsar, constant polarization can be\nrejected in the case of polarization in a narrow energy band with at least 50%\npolarization, and similarly for a negative step distribution from 30% to 0%\npolarization.\n\n", "human_text": "  Linear polarization in X- and gamma-rays is an important diagnostic of many\nastrophysical sources, foremost giving information about their geometry,\nmagnetic fields, and radiation mechanisms. However, very few X-ray polarization\nmeasurements have been made, and then only mono-energetic detections, whilst\nseveral objects are assumed to have energy dependent polarization signatures.\nIn this paper we investigate whether detection of energy dependent polarization\nfrom cosmic sources is possible using the Compton technique, in particular with\nthe proposed PoGOLite balloon-experiment, in the 25-100 keV range. We use\nGeant4 simulations of a PoGOLite model and input photon spectra based on Cygnus\nX-1 and accreting magnetic pulsars (100 mCrab). Effective observing times of 6\nand 35 hours were simulated, corresponding to a standard and a long duration\nflight respectively. Both smooth and sharp energy variations of the\npolarization are investigated and compared to constant polarization signals\nusing chi-square statistics. We can reject constant polarization, with energy,\nfor the Cygnus X-1 spectrum (in the hard state), if the reflected component is\nassumed to be completely polarized, whereas the distinction cannot be made for\nweaker polarization. For the accreting pulsar, constant polarization can be\nrejected in the case of polarization in a narrow energy band with at least 50%\npolarization, and similarly for a negative step distribution from 30% to 0%\npolarization.\n", "machine_text": "\nThis paper studies the possibility of detecting and measuring changes in linear polarization of different X- and gamma-ray spectral energy ranges that arise from multiple astrophysical sources. Of particular interest is the PoGOLite balloon-experiment and the 25-100 keV range of radiation. Using Geant4 simulations, we analyze hypothetical photon spectra based on Cygnus X-1 and accreting magnetic pulsars, with effective times of 6 and 35 hours which correspond to a standard and long duration flight. We compare simulated energy-dependent and constant polarization signals to identify any departures from the constant polarization scenario. Results of the comparative analysis indicated that, in the case of Cygnus X-1, energy-dependent polarization can be detected when the reflected component is assumed to be completely polarized. Inversely, the simulated spectra of accreting pulsars, depending on the degree of polarization, could enable rejection of constant polarization in the case of an energy concentrated signal with at least 50% polarization, and for a decrease from 30% to 0%.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1603}
{"prompt": "Rephrase the abstract of an article with title 'The metallicity distributions in high-latitudes with SDSS'.\n  We present metallicities and their variations with different parameters for\n36 high-latitude fields covering Galactic longitudes 0<l<360. The metallicities\nfor relatively short vertical distances (z<2.5 kpc) show systematic\nfluctuations with Galactic longitude, similar to those of the thick-disc\nscaleheight, which may be interpreted as indicating a common origin, viz., the\nflare effect of the disc. This suggestion is supported by the metallicity\nvariations which we find as functions of radial distance. The metallicity\nvariation at larger vertical distances (6.5<z<9.5 kpc) is small but monotonic.\nThree different vertical metallicity gradients could be detected:\nd[M/H]/dz=-0.22(+/-0.03), d[M/H]/dz=-0.38 (+/-0.06), and d[M/H]/dz=-0.08\n(+/-0.07) dex/kpc for the intervals z<3, 3<z<5, and 5<z<10 kpc, respectively.\nSince our data cover the whole Galactic longitude interval, the resulting\nmetallicity gradients can be interpreted as properties of the larger-scale\nGalaxy. The first gradient confirms the dissipational formation of the disc at\nshort z-distances. The steeper gradient corresponds to the transition region\nbetween different population components of the Galaxy, and finally, the lowest\nvalue provides an adequate description of the inner-halo metallicity gradient.\n\n", "human_text": "  We present metallicities and their variations with different parameters for\n36 high-latitude fields covering Galactic longitudes 0<l<360. The metallicities\nfor relatively short vertical distances (z<2.5 kpc) show systematic\nfluctuations with Galactic longitude, similar to those of the thick-disc\nscaleheight, which may be interpreted as indicating a common origin, viz., the\nflare effect of the disc. This suggestion is supported by the metallicity\nvariations which we find as functions of radial distance. The metallicity\nvariation at larger vertical distances (6.5<z<9.5 kpc) is small but monotonic.\nThree different vertical metallicity gradients could be detected:\nd[M/H]/dz=-0.22(+/-0.03), d[M/H]/dz=-0.38 (+/-0.06), and d[M/H]/dz=-0.08\n(+/-0.07) dex/kpc for the intervals z<3, 3<z<5, and 5<z<10 kpc, respectively.\nSince our data cover the whole Galactic longitude interval, the resulting\nmetallicity gradients can be interpreted as properties of the larger-scale\nGalaxy. The first gradient confirms the dissipational formation of the disc at\nshort z-distances. The steeper gradient corresponds to the transition region\nbetween different population components of the Galaxy, and finally, the lowest\nvalue provides an adequate description of the inner-halo metallicity gradient.\n", "machine_text": "We investigate the metallicity distributions in high-latitudes with the Sloan Digital Sky Survey (SDSS). Data covers Galactic longitudes 0<l<360. We observe significant fluctuations in metallicity at z<2.5 kpc, similar to those in the thick-disc scaleheight, as a result of the Galactic flare effect. Additionally, our results suggest three different vertical metallicity gradients of d[M/H]/dz=-0.22(+/-0.03), d[M/H]/dz=-0.38 (+/-0.06), and d[M/H]/dz=-0.08 (+/-0.07) dex/kpc for z<3, 3<z<5, and 5<z<10 kpc, respectively. Our data indicates the dissipational formation of the disc at short distances, a transition between different population components of the Galaxy, and a low value to describe the inner-halo metallicity gradient.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3477}
{"prompt": "Rephrase the abstract of an article with title 'Neutral Networks of Sequence to Shape Maps'.\n  In this paper we present a novel framework for sequence to shape maps. These\ncombinatorial maps realize exponentially many shapes, and have preimages which\ncontain extended connected subgraphs of diameter n (neutral networks). We prove\nthat all basic properties of RNA folding maps also hold for combinatorial maps.\nOur construction is as follows: suppose we are given a graph $H$ over the $\\{1\n>...,n\\}$ and an alphabet of nucleotides together with a symmetric relation\n$\\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of\nlength n is the maximal H subgraph in which all pairs of nucleotides incident\nto H-edges satisfy $\\mathcal{R}$. Our main result is to prove the existence of\nat least $\\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes\nthat have a preimage with diameter $n$ and a connected component of size at\nleast $(\\frac{1+\\sqrt{5}}{2})^n+(\\frac{1-\\sqrt{5}}{2})^n$. Furthermore, we show\nthat there exists a certain subset of shapes which carries a natural graph\nstructure. In this graph any two shapes are connected by a path of shapes with\nrespective neutral networks of distance one. We finally discuss our results and\nprovide a comparison with RNA folding maps.\n\n", "human_text": "  In this paper we present a novel framework for sequence to shape maps. These\ncombinatorial maps realize exponentially many shapes, and have preimages which\ncontain extended connected subgraphs of diameter n (neutral networks). We prove\nthat all basic properties of RNA folding maps also hold for combinatorial maps.\nOur construction is as follows: suppose we are given a graph $H$ over the $\\{1\n>...,n\\}$ and an alphabet of nucleotides together with a symmetric relation\n$\\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of\nlength n is the maximal H subgraph in which all pairs of nucleotides incident\nto H-edges satisfy $\\mathcal{R}$. Our main result is to prove the existence of\nat least $\\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes\nthat have a preimage with diameter $n$ and a connected component of size at\nleast $(\\frac{1+\\sqrt{5}}{2})^n+(\\frac{1-\\sqrt{5}}{2})^n$. Furthermore, we show\nthat there exists a certain subset of shapes which carries a natural graph\nstructure. In this graph any two shapes are connected by a path of shapes with\nrespective neutral networks of distance one. We finally discuss our results and\nprovide a comparison with RNA folding maps.\n", "machine_text": "\nThis article proposes a framework to generate a wide range of shapes, known as sequence to shape maps, using an input combination of graphs, nucleotides and a symmetrical relation $\\mathcal{R}$. These shapes have preimages that contain connected subgraphs of length n (neutral networks) and our proof shows that properties of RNA folding maps remain consistent. Our method involves taking a graph $H$ with elements from the $\\{1,..., n\\}$ set and exploiting the combination of base pairing rules and the symmetric relation $\\mathcal{R}$ to perceive the sequence shape. We observe that the number of such shapes is at least $\\sqrt{2}^{n-1}$ with preimages with diameter of n and connection components of size $\\frac{1+\\sqrt{5}}{2} ^n + \\frac{1- \\sqrt{5}}{2}^n$. We conclude with evidence to support a natural graph structure among the shapes and how they are connected by a path of neutral networks. Finally, we compare our findings with those of the RNA folding maps.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.076}
{"prompt": "Rephrase the abstract of an article with title 'Interplay between thermal percolation and jamming upon dimer adsorption\n  on binary alloys'.\n  Using Monte Carlo simulations we study jamming and percolation processes upon\nthe random sequential adsorption of dimers on binary alloys with different\ndegrees of structural order. We obtain the equimolar mixtures used as\nsubstrates by applying the isomorphism between an alloy and the Ising model\n(conserved order parameter). The annealing temperature $T$ of the mixture then\nis a continuous parameter that characterizes the different sets of substrates,\nshaping the deposition process. As the alloy undergoes an order-disorder phase\ntransition at the Onsager critical temperature ($T_{c}$), the jamming and\npercolating properties of the dimers deposited over the substrate are subjected\nto non-trivial changes. These are reflected in a density-temperature phase\ndiagram with three well-defined regions. We find that for $T < T^* = 1.22\nT_{c}$ the occurrence of jamming prevents the onset of percolating clusters,\nwhile percolation is possible for $T > T^{*}$. Particular attention is focused\nclose to $T^{*}$, where the interplay between jamming and percolation restricts\nfluctuations, forcing exponents seemingly different from the standard\npercolation universality class. By analogy with a thermal transition, we study\nthe onset of percolation by using the {\\it temperature} (in this case, the\nsubstrate annealing temperature) as a control parameter. By proposing thermal\nscaling Ansatzes we analyze the behavior of the percolation threshold and its\nthermally induced fluctuations. Also, the fractal dimension of the percolating\ncluster is determined. Based on these measurements and the excellent data\ncollapsing, we conclude that the universality class of standard percolation is\npreserved for all temperatures.\n\n", "human_text": "  Using Monte Carlo simulations we study jamming and percolation processes upon\nthe random sequential adsorption of dimers on binary alloys with different\ndegrees of structural order. We obtain the equimolar mixtures used as\nsubstrates by applying the isomorphism between an alloy and the Ising model\n(conserved order parameter). The annealing temperature $T$ of the mixture then\nis a continuous parameter that characterizes the different sets of substrates,\nshaping the deposition process. As the alloy undergoes an order-disorder phase\ntransition at the Onsager critical temperature ($T_{c}$), the jamming and\npercolating properties of the dimers deposited over the substrate are subjected\nto non-trivial changes. These are reflected in a density-temperature phase\ndiagram with three well-defined regions. We find that for $T < T^* = 1.22\nT_{c}$ the occurrence of jamming prevents the onset of percolating clusters,\nwhile percolation is possible for $T > T^{*}$. Particular attention is focused\nclose to $T^{*}$, where the interplay between jamming and percolation restricts\nfluctuations, forcing exponents seemingly different from the standard\npercolation universality class. By analogy with a thermal transition, we study\nthe onset of percolation by using the {\\it temperature} (in this case, the\nsubstrate annealing temperature) as a control parameter. By proposing thermal\nscaling Ansatzes we analyze the behavior of the percolation threshold and its\nthermally induced fluctuations. Also, the fractal dimension of the percolating\ncluster is determined. Based on these measurements and the excellent data\ncollapsing, we conclude that the universality class of standard percolation is\npreserved for all temperatures.\n", "machine_text": "\nUsing Monte Carlo simulations, we analyze the effects of order and disorder on the jamming and percolating processes resulting from the random sequential adsorption of dimers on binary alloys. Equimolar mixtures are obtained by applying the Ising model and the substrate annealing temperature $T$ is used to characterize the different types of substrates. At the Onsager critical temperature ($T_{c}$), changes in jamming and percolation features are produced, visible in a density-temperature phase diagram with three distinct regions. We find that jamming phenomena prevailing when $T < T^{*} = 1.22 T_{c}$ hinder the emergence of percolating clusters, and only become possible when $T > T^{*}$. Furthermore, at values close to $T^{*}$, fluctuations are restrained due to the interplay between jamming and percolation, presenting different exponents than those of the standard percolation universality class. By analyzing the threshold of percolation through thermal scaling Ansatzes, together with the fractal dimension of the percolating cluster, it is concluded that the universality class of standard percolation is preserved for all temperatures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0562}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic Streaming Field at Low Redshift'.\n  We study the expansion of the nearby Universe using a sample of Type Ia\nsupernovae at redshifts below 0.08. These supernovae allow peculiar velocities\nto be measured at unprecedented precision. We have investigated in detail the\npossibility of a varying Hubble constant with redshift and found no evidence of\na monopole term for the nearby Universe. A large scale streaming motion is\nfound at an amplitude of about $340^{63}_{-71}$ km/sec, aligned in the\ndirection of $(l_0, b_0) = (312^{\\rm o}.0^{13.5}_{-7.4}, 25^{\\rm\no}.7^{8.0}_{-9.2})$, which is close to the direction of the center of Shapley\nsupercluster of galaxies. The large scale streaming motion is best fit by a\nfunction involving a strong bipolar term. The streaming velocity field extends\nfrom the lowest redshift ($\\sim 0.007$) to beyond 0.025 and likely out to even\nhigher redshifts. The velocity field at redshift below 0.01 can be equally well\ndescribed by a dipole field or by the same bipolar streaming velocity field\nthat reaches out to beyond $z \\sim 0.025$. We are also able to deduce a robust\nestimate of the random velocity component of the peculiar velocity field.\nWithin the volume of redshift below 0.01 (weighted average redshift of $\\sim$\n0.067), this thermal component is found to be about 270 km/sec. After\ncorrecting this smooth streaming motion, we are able to significantly improve\nthe Hubble expansion fits of these supernovae. The CMAGIC method gives a\ndramatic decrease of $\\chi^2$ from 90 to 63 for 69 degrees of freedom, and\nyields a residual scatter of only 0.12 magnitude; the maximum light method\ngives also a moderate improvement.\n\n", "human_text": "  We study the expansion of the nearby Universe using a sample of Type Ia\nsupernovae at redshifts below 0.08. These supernovae allow peculiar velocities\nto be measured at unprecedented precision. We have investigated in detail the\npossibility of a varying Hubble constant with redshift and found no evidence of\na monopole term for the nearby Universe. A large scale streaming motion is\nfound at an amplitude of about $340^{63}_{-71}$ km/sec, aligned in the\ndirection of $(l_0, b_0) = (312^{\\rm o}.0^{13.5}_{-7.4}, 25^{\\rm\no}.7^{8.0}_{-9.2})$, which is close to the direction of the center of Shapley\nsupercluster of galaxies. The large scale streaming motion is best fit by a\nfunction involving a strong bipolar term. The streaming velocity field extends\nfrom the lowest redshift ($\\sim 0.007$) to beyond 0.025 and likely out to even\nhigher redshifts. The velocity field at redshift below 0.01 can be equally well\ndescribed by a dipole field or by the same bipolar streaming velocity field\nthat reaches out to beyond $z \\sim 0.025$. We are also able to deduce a robust\nestimate of the random velocity component of the peculiar velocity field.\nWithin the volume of redshift below 0.01 (weighted average redshift of $\\sim$\n0.067), this thermal component is found to be about 270 km/sec. After\ncorrecting this smooth streaming motion, we are able to significantly improve\nthe Hubble expansion fits of these supernovae. The CMAGIC method gives a\ndramatic decrease of $\\chi^2$ from 90 to 63 for 69 degrees of freedom, and\nyields a residual scatter of only 0.12 magnitude; the maximum light method\ngives also a moderate improvement.\n", "machine_text": "\nUsing supernovae at redshifts up to 0.08, we observe peculiar velocities with unprecedented precision. Investigations suggest a substantial streaming motion with an amplitude of approximately 340 km/s in the direction of $(l_0, b_0)=(312^{\\rm o}.0^{13.5}_{-7.4}, 25^{\\rm o}.7^{8.0}_{-9.2})$, which is near to the Shapley supercluster of galaxies. Visually, the velocity field appears to be a bipolar form which extends from 0.007 to $z\\sim 0.025$ and likely beyond. Further, there is an estimated 270 km/s random component to the field inside the volume at 0.01. The CMAGIC and maximum light metrics show considerable improvements in the Hubble expansion measurements following the correction of this streaming motion, with a decrease in $\\chi^2$ from 90 to 63 and a residual scatter of 0.12 magnitude.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0368}
{"prompt": "Rephrase the abstract of an article with title 'Comparison of dust-to-gas ratios in luminous, ultraluminous, and\n  hyperluminous infrared galaxies'.\n  The dust-to-gas ratios in three different samples of luminous, ultraluminous,\nand hyperluminous infrared galaxies are calculated by modelling their radio to\nsoft X-ray spectral energy distributions using composite models which account\nfor the photoionizing radiation from HII regions, starbursts, or AGNs, and for\nshocks. The models are limited to a set which broadly reproduces the mid-IR\nfine structure line ratios of local, IR bright, starburst galaxies. The results\nshow that two types of clouds contribute to the IR emission. Those\ncharacterized by low shock velocities and low preshock densities explain the\nfar-IR dust emission, while those with higher velocities and densities\ncontribute to mid-IR dust emission. An AGN is found in nearly all of the\nultraluminous IR galaxies and in half of the luminous IR galaxies of the\nsample. High IR luminosities depend on dust-to-gas ratios of about 0.1 by mass,\nhowever, most hyperluminous IR galaxies show dust-to-gas ratios much lower than\nthose calculated for the luminous and ultraluminous IR galaxies.\n\n", "human_text": "  The dust-to-gas ratios in three different samples of luminous, ultraluminous,\nand hyperluminous infrared galaxies are calculated by modelling their radio to\nsoft X-ray spectral energy distributions using composite models which account\nfor the photoionizing radiation from HII regions, starbursts, or AGNs, and for\nshocks. The models are limited to a set which broadly reproduces the mid-IR\nfine structure line ratios of local, IR bright, starburst galaxies. The results\nshow that two types of clouds contribute to the IR emission. Those\ncharacterized by low shock velocities and low preshock densities explain the\nfar-IR dust emission, while those with higher velocities and densities\ncontribute to mid-IR dust emission. An AGN is found in nearly all of the\nultraluminous IR galaxies and in half of the luminous IR galaxies of the\nsample. High IR luminosities depend on dust-to-gas ratios of about 0.1 by mass,\nhowever, most hyperluminous IR galaxies show dust-to-gas ratios much lower than\nthose calculated for the luminous and ultraluminous IR galaxies.\n", "machine_text": "This study investigates the dust-to-gas ratio in different types of luminous, ultraluminous, and hyperluminous infrared galaxies. Through modelling the radio to soft X-ray spectral energy distributions, two types of clouds are discovered to contribute to the infrared emission; those with low shock velocities and low preshock densities and those with high velocities and densities. The results indicate that AGN's are present in nearly all of the ultraluminous and half of the luminous IR galaxies, while high IR luminosities rely on dust-to-gas ratios of 0.1 by mass. However, dust-to-gas ratios in hyper luminous IR galaxies are found to be significantly lower than those of luminous and ultraluminous IR galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3519}
{"prompt": "Rephrase the abstract of an article with title 'The RMS Survey: 13CO observations of candidate massive YSOs in the\n  southern hemisphere'.\n  Abridged: The Red MSX Source (RMS) survey is an ongoing multi-wavelength\nobservational programme designed to return a large, well-selected sample of\nmassive young stellar objects (MYSOs). Here we present 13CO observations made\ntowards 854 MYSOs candidates located in the 3rd and 4th quadrants. We detected\n13CO emission towards a total of 751 of the 854 RMS sources observed (~88%). In\ntotal 2185 emission components are detected above 3$\\sigma$ level. Multiple\nemission profiles are observed towards the majority of these sources - 455\nsources (~60%) - with an average of ~4 molecular clouds along the line of\nsight. These multiple emission features make it difficult to assign a kinematic\nvelocity to many of our sample. We have used archival CS (J=2-1) and maser\nvelocities to resolved the component multiplicity towards 82 sources and have\nderived a criterion which is used to identify the most likely component for a\nfurther 202 multiple component sources. Combined with the single component\ndetections we have obtained unambiguous kinematic velocities towards 580\nsources (~80% of the detections). The 171 sources for which we have not been\nable to determine the kinematic velocity will require additional line data.\nUsing the rotation curve of Brand and Blitz (1993) and their radial velocities\nwe calculate kinematic distances for all components detected.\n\n", "human_text": "  Abridged: The Red MSX Source (RMS) survey is an ongoing multi-wavelength\nobservational programme designed to return a large, well-selected sample of\nmassive young stellar objects (MYSOs). Here we present 13CO observations made\ntowards 854 MYSOs candidates located in the 3rd and 4th quadrants. We detected\n13CO emission towards a total of 751 of the 854 RMS sources observed (~88%). In\ntotal 2185 emission components are detected above 3$\\sigma$ level. Multiple\nemission profiles are observed towards the majority of these sources - 455\nsources (~60%) - with an average of ~4 molecular clouds along the line of\nsight. These multiple emission features make it difficult to assign a kinematic\nvelocity to many of our sample. We have used archival CS (J=2-1) and maser\nvelocities to resolved the component multiplicity towards 82 sources and have\nderived a criterion which is used to identify the most likely component for a\nfurther 202 multiple component sources. Combined with the single component\ndetections we have obtained unambiguous kinematic velocities towards 580\nsources (~80% of the detections). The 171 sources for which we have not been\nable to determine the kinematic velocity will require additional line data.\nUsing the rotation curve of Brand and Blitz (1993) and their radial velocities\nwe calculate kinematic distances for all components detected.\n", "machine_text": "\nThis research presents 13CO observations of 854 candidate massive young stellar objects (MYSOs) located in the third and fourth quadrants of the southern hemisphere. The RMS survey reveals emission of the molecule in 751 of these sources, yielding a total of 2185 detectable components with a signal-to-noise ratio of at least 3. The majority of sources (455, or 60%) display multiple emission profiles in line with the assessment that a large number of molecular clouds exist along their line of sight. A criterion is applied to pinpoint single components out of these multiples, allowing for the derivation of kinematic velocities in an estimated 580 sources, or ~80% of the detections. Utilizing the Brand an Blitz (1993) data for rotation curves and radial velocities, individual kinematic distances are calculated for the detected components. On the other hand, further lines may be required to clarify the kinematic characteristics of the other 171 sources.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4597}
{"prompt": "Rephrase the abstract of an article with title 'Planets around evolved intermediate-mass stars. I. Two substellar\n  companions in the open clusters NGC 2423 and NGC 4349'.\n  Context. Many efforts are being made to characterize extrasolar planetary\nsystems and unveil the fundamental mechanisms of planet formation. An important\naspect of the problem, which remains largely unknown, is to understand how the\nplanet formation process depends on the mass of the parent star. In particular,\nas most planets discovered to date orbit a solar-mass primary, little is known\nabout planet formation around more massive stars. Aims. To investigate this\npoint, we present first results from a radial velocity planet search around red\ngiants in the clump of intermediate-age open clusters. We choose clusters\nharbouring red giants with masses between 1.5 and 4 M_sun, using the well-known\ncluster parameters to accurately determine the stellar masses. We are therefore\nexploring a poorly-known domain of primary masses, which will bring new\ninsights into the properties of extrasolar planetary systems. Methods. We are\nfollowing a sample of about 115 red giants with the Coralie and HARPS\nspectrographs to obtain high-precision radial velocity (RV) measurements and\ndetect giant planets around these stars. We use bisector and activity index\ndiagnostics to distinguish between planetary-induced RV variations and stellar\nphotospheric jitter. Results. We present the discoveries of a giant planet and\na brown dwarf in the open clusters NGC 2423 and NGC 4349, orbiting the 2.4\nM_sun-star NGC2423 No3 (TYC 5409-2156-1) and the 3.9 M_sun-star NGC4349 No127\n(TYC 8975-2606-1). These low-mass companions have orbital periods of 714 and\n678 days and minimum masses of 10.6 and 19.8 M_jup, respectively. Combined with\nthe other known planetary systems, these detections indicate that the frequency\nof massive planets is higher around intermediate-mass stars, and therefore\nprobably scales with the mass of the protoplanetary disk.\n\n", "human_text": "  Context. Many efforts are being made to characterize extrasolar planetary\nsystems and unveil the fundamental mechanisms of planet formation. An important\naspect of the problem, which remains largely unknown, is to understand how the\nplanet formation process depends on the mass of the parent star. In particular,\nas most planets discovered to date orbit a solar-mass primary, little is known\nabout planet formation around more massive stars. Aims. To investigate this\npoint, we present first results from a radial velocity planet search around red\ngiants in the clump of intermediate-age open clusters. We choose clusters\nharbouring red giants with masses between 1.5 and 4 M_sun, using the well-known\ncluster parameters to accurately determine the stellar masses. We are therefore\nexploring a poorly-known domain of primary masses, which will bring new\ninsights into the properties of extrasolar planetary systems. Methods. We are\nfollowing a sample of about 115 red giants with the Coralie and HARPS\nspectrographs to obtain high-precision radial velocity (RV) measurements and\ndetect giant planets around these stars. We use bisector and activity index\ndiagnostics to distinguish between planetary-induced RV variations and stellar\nphotospheric jitter. Results. We present the discoveries of a giant planet and\na brown dwarf in the open clusters NGC 2423 and NGC 4349, orbiting the 2.4\nM_sun-star NGC2423 No3 (TYC 5409-2156-1) and the 3.9 M_sun-star NGC4349 No127\n(TYC 8975-2606-1). These low-mass companions have orbital periods of 714 and\n678 days and minimum masses of 10.6 and 19.8 M_jup, respectively. Combined with\nthe other known planetary systems, these detections indicate that the frequency\nof massive planets is higher around intermediate-mass stars, and therefore\nprobably scales with the mass of the protoplanetary disk.\n", "machine_text": "\nThis paper presents the results of a survey for extrasolar planets orbiting intermediate-mass stars in two open clusters, NGC 2423 and NGC 4349. The observations were taken with the Coralie and HARPS spectrographs to obtain high precision radial velocity measurements and search for giant planets. In total, 115 red giants were studied, with masses between 1.5-4 solar masses. After assessing any stellar jitter, two low-mass companions were detected, a giant planet and a brown dwarf, each with a distinct orbital period and minimum mass. These findings add to the current knowledge of extrasolar planetary systems, revealing that the frequency of massive planets is larger around intermediate-mass stars. This implies a higher likelihood of more planetary masses forming in proportion to the mass of a protoplanetary disk.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2174}
{"prompt": "Rephrase the abstract of an article with title 'Unifying Evolutionary and Network Dynamics'.\n  Many important real-world networks manifest \"small-world\" properties such as\nscale-free degree distributions, small diameters, and clustering. The most\ncommon model of growth for these networks is \"preferential attachment\", where\nnodes acquire new links with probability proportional to the number of links\nthey already have. We show that preferential attachment is a special case of\nthe process of molecular evolution. We present a new single-parameter model of\nnetwork growth that unifies varieties of preferential attachment with the\nquasispecies equation (which models molecular evolution), and also with the\nErdos-Renyi random graph model. We suggest some properties of evolutionary\nmodels that might be applied to the study of networks. We also derive the form\nof the degree distribution resulting from our algorithm, and we show through\nsimulations that the process also models aspects of network growth. The\nunification allows mathematical machinery developed for evolutionary dynamics\nto be applied in the study of network dynamics, and vice versa.\n\n", "human_text": "  Many important real-world networks manifest \"small-world\" properties such as\nscale-free degree distributions, small diameters, and clustering. The most\ncommon model of growth for these networks is \"preferential attachment\", where\nnodes acquire new links with probability proportional to the number of links\nthey already have. We show that preferential attachment is a special case of\nthe process of molecular evolution. We present a new single-parameter model of\nnetwork growth that unifies varieties of preferential attachment with the\nquasispecies equation (which models molecular evolution), and also with the\nErdos-Renyi random graph model. We suggest some properties of evolutionary\nmodels that might be applied to the study of networks. We also derive the form\nof the degree distribution resulting from our algorithm, and we show through\nsimulations that the process also models aspects of network growth. The\nunification allows mathematical machinery developed for evolutionary dynamics\nto be applied in the study of network dynamics, and vice versa.\n", "machine_text": "\nThis article unifies the dynamics of networks and of molecular evolution through a single-parameter model. This model combines the preferential attachment network growth process with the quasispecies equation (a model for molecular evolution) and the Erdos-Renyi random graph model. We discuss the resulting implications for both evolutionary and network dynamics and show how mathematical tools from one realm can be applied to the other. We determine and simulate the form of the degree distribution of the unified model and show that it also models aspects of network growth. Our work provides a bridge for connecting two seemingly disparate spheres of study and allows for new insights into the complexities of growth dynamics in networks.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1811}
{"prompt": "Rephrase the abstract of an article with title 'G-convergence and homogenization of viscoelastic flows'.\n  The paper is devoted to homogenization of two-phase incompressible\nviscoelastic flows with disordered microstructure. We study two cases. In the\nfirst case, both phases are modeled as Kelvin-Voight viscoelastic materials. In\nthe second case, one phase is a Kelvin-Voight material, and the other is a\nviscous Newtonian fluid. The microscale system contains the conservation of\nmass and balance of momentum equations. The inertial terms in the momentum\nequation incorporate the actual interface advected by the flow. In the\nconstitutive equations, a frozen interface is employed. The interface geometry\nis arbitrary: we do not assume periodicity, statistical homogeneity or scale\nseparation. The problem is homogenized using G-convergence and oscillating test\nfunctions. Since the microscale system is not parabolic, previously known\nconstructions of the test functions do not work here. The test functions\ndeveloped in the paper are non-local in time and satisfy divergence-free\nconstraint exactly. The latter feature enables us to avoid working with\npressure directly. We show that the effective medium is a single phase\nviscoelastic material that is not necessarily of Kelvin-Voight type. The\neffective constitutive equation contains a long memory viscoelastic term, as\nwell as instantaneous elastic and viscous terms.\n\n", "human_text": "  The paper is devoted to homogenization of two-phase incompressible\nviscoelastic flows with disordered microstructure. We study two cases. In the\nfirst case, both phases are modeled as Kelvin-Voight viscoelastic materials. In\nthe second case, one phase is a Kelvin-Voight material, and the other is a\nviscous Newtonian fluid. The microscale system contains the conservation of\nmass and balance of momentum equations. The inertial terms in the momentum\nequation incorporate the actual interface advected by the flow. In the\nconstitutive equations, a frozen interface is employed. The interface geometry\nis arbitrary: we do not assume periodicity, statistical homogeneity or scale\nseparation. The problem is homogenized using G-convergence and oscillating test\nfunctions. Since the microscale system is not parabolic, previously known\nconstructions of the test functions do not work here. The test functions\ndeveloped in the paper are non-local in time and satisfy divergence-free\nconstraint exactly. The latter feature enables us to avoid working with\npressure directly. We show that the effective medium is a single phase\nviscoelastic material that is not necessarily of Kelvin-Voight type. The\neffective constitutive equation contains a long memory viscoelastic term, as\nwell as instantaneous elastic and viscous terms.\n", "machine_text": "\nThis paper investigates the homogenization of two-phase incompressible\nviscoelastic flows with arbitrary interface geometries, like periodicity, statistical homogeneity, or scale separation. Utilizing G-convergence and oscillating test functions, customarily non-local in time, that satisfy divergence-free constraints, we arrive at an effective medium in the form of a single phase viscoelastic material, which may not be of the Kelvin-Voight type. The resultant effective constitutive equation retains a long memory viscoelastic term as well as instantaneous elastic and viscous terms. This novel approach accounts for the conservation of mass and momentum equations, coupled with the interface advection of the flow.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1088}
{"prompt": "Rephrase the abstract of an article with title 'Identifying Dark Matter Burners in the Galactic center'.\n  If the supermassive black hole (SMBH) at the center of our Galaxy grew\nadiabatically, then a dense \"spike\" of dark matter is expected to have formed\naround it. Assuming that dark matter is composed primarily of weakly\ninteracting massive particles (WIMPs), a star orbiting close enough to the SMBH\ncan capture WIMPs at an extremely high rate. The stellar luminosity due to\nannihilation of captured WIMPs in the stellar core may be comparable to or even\nexceed the luminosity of the star due to thermonuclear burning. The model thus\npredicts the existence of unusual stars, i.e. \"WIMP burners\", in the vicinity\nof an adiabatically grown SMBH. We find that the most efficient WIMP burners\nare stars with degenerate electron cores, e.g. white dwarfs (WD) or degenerate\ncores with envelopes. If found, such stars would provide evidence for the\nexistence of particle dark matter and could possibly be used to establish its\ndensity profile. In our previous paper we computed the luminosity from WIMP\nburning for a range of dark matter spike density profiles, degenerate core\nmasses, and distances from the SMBH. Here we compare our results with the\nobserved stars closest to the Galactic center and find that they could be\nconsistent with WIMP burners in the form of degenerate cores with envelopes. We\nalso cross-check the WIMP burner hypothesis with the EGRET observed flux of\ngamma-rays from the Galactic center, which imposes a constraint on the dark\nmatter spike density profile and annihilation cross-section. We find that the\nEGRET data is consistent with the WIMP burner hypothesis. New high precision\nmeasurements by GLAST will confirm or set stringent limits on a dark matter\nspike at the Galactic center, which will in turn support or set stringent\nlimits on the existence of WIMP burners at the Galactic center.\n\n", "human_text": "  If the supermassive black hole (SMBH) at the center of our Galaxy grew\nadiabatically, then a dense \"spike\" of dark matter is expected to have formed\naround it. Assuming that dark matter is composed primarily of weakly\ninteracting massive particles (WIMPs), a star orbiting close enough to the SMBH\ncan capture WIMPs at an extremely high rate. The stellar luminosity due to\nannihilation of captured WIMPs in the stellar core may be comparable to or even\nexceed the luminosity of the star due to thermonuclear burning. The model thus\npredicts the existence of unusual stars, i.e. \"WIMP burners\", in the vicinity\nof an adiabatically grown SMBH. We find that the most efficient WIMP burners\nare stars with degenerate electron cores, e.g. white dwarfs (WD) or degenerate\ncores with envelopes. If found, such stars would provide evidence for the\nexistence of particle dark matter and could possibly be used to establish its\ndensity profile. In our previous paper we computed the luminosity from WIMP\nburning for a range of dark matter spike density profiles, degenerate core\nmasses, and distances from the SMBH. Here we compare our results with the\nobserved stars closest to the Galactic center and find that they could be\nconsistent with WIMP burners in the form of degenerate cores with envelopes. We\nalso cross-check the WIMP burner hypothesis with the EGRET observed flux of\ngamma-rays from the Galactic center, which imposes a constraint on the dark\nmatter spike density profile and annihilation cross-section. We find that the\nEGRET data is consistent with the WIMP burner hypothesis. New high precision\nmeasurements by GLAST will confirm or set stringent limits on a dark matter\nspike at the Galactic center, which will in turn support or set stringent\nlimits on the existence of WIMP burners at the Galactic center.\n", "machine_text": "\nAn investigation has been conducted to identify objects within the vicinity of the supermassive black hole at the center of the Galaxy that, if consistent with the model of an adiabatically grown SMBH, could provide proof of particle dark matter. It has been hypothesized that stars sufficiently close to the SMBH will capture weakly interactive massive particles (WIMPs), leading to the formation of a dark matter spike and the production of stellar luminosity due to the annihilation of captured WIMPs in the stellar core. Accordingly, if discovered, these stars could act as evidence of dark matter and potentially define the density distribution of the spike. Our study has compared the predicted luminosity from WIMP burning with observed stars close to the Galactic center and, additionally, used the gamma-ray flux from the Galactic center as reported by EGRET to constrain both the dark matter density profile and annihilation cross-section. This anaylysis demonstrates that the EGRET data is consistent with the WIMP burner hypothesis. Further, upcoming high precision measurements from GLAST will indeed bolster our understanding of the aforementioned structure as well as the amount of evidence for these anomalous stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1324}
{"prompt": "Rephrase the abstract of an article with title 'Quantifying social group evolution'.\n  The rich set of interactions between individuals in the society results in\ncomplex community structure, capturing highly connected circles of friends,\nfamilies, or professional cliques in a social network. Thanks to frequent\nchanges in the activity and communication patterns of individuals, the\nassociated social and communication network is subject to constant evolution.\nOur knowledge of the mechanisms governing the underlying community dynamics is\nlimited, but is essential for a deeper understanding of the development and\nself-optimisation of the society as a whole. We have developed a new algorithm\nbased on clique percolation, that allows, for the first time, to investigate\nthe time dependence of overlapping communities on a large scale and as such, to\nuncover basic relationships characterising community evolution. Our focus is on\nnetworks capturing the collaboration between scientists and the calls between\nmobile phone users. We find that large groups persist longer if they are\ncapable of dynamically altering their membership, suggesting that an ability to\nchange the composition results in better adaptability. The behaviour of small\ngroups displays the opposite tendency, the condition for stability being that\ntheir composition remains unchanged. We also show that the knowledge of the\ntime commitment of the members to a given community can be used for estimating\nthe community's lifetime. These findings offer a new view on the fundamental\ndifferences between the dynamics of small groups and large institutions.\n\n", "human_text": "  The rich set of interactions between individuals in the society results in\ncomplex community structure, capturing highly connected circles of friends,\nfamilies, or professional cliques in a social network. Thanks to frequent\nchanges in the activity and communication patterns of individuals, the\nassociated social and communication network is subject to constant evolution.\nOur knowledge of the mechanisms governing the underlying community dynamics is\nlimited, but is essential for a deeper understanding of the development and\nself-optimisation of the society as a whole. We have developed a new algorithm\nbased on clique percolation, that allows, for the first time, to investigate\nthe time dependence of overlapping communities on a large scale and as such, to\nuncover basic relationships characterising community evolution. Our focus is on\nnetworks capturing the collaboration between scientists and the calls between\nmobile phone users. We find that large groups persist longer if they are\ncapable of dynamically altering their membership, suggesting that an ability to\nchange the composition results in better adaptability. The behaviour of small\ngroups displays the opposite tendency, the condition for stability being that\ntheir composition remains unchanged. We also show that the knowledge of the\ntime commitment of the members to a given community can be used for estimating\nthe community's lifetime. These findings offer a new view on the fundamental\ndifferences between the dynamics of small groups and large institutions.\n", "machine_text": "\nBy leveraging a new clique percolation algorithm, this article investigates the temporal evolution of social and communication networks, allowing us to gain insights into the mechanisms which shape communities. Applying the technique to networks which capture the collaboration between scientists and the calls between mobile phone users, we identify the conditions which lead to the stability and adaptability in large and small social groups. Additionally, we quantitatively show that the level of engagement of the individuals involved can be used to estimate the lifespan of a community. Our results provide a new way of understanding the differences between the evolutionary trajectories of large organizations and small clusters of people.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0744}
{"prompt": "Rephrase the abstract of an article with title 'Interior Point Decoding for Linear Vector Channels'.\n  In this paper, a novel decoding algorithm for low-density parity-check (LDPC)\ncodes based on convex optimization is presented. The decoding algorithm, called\ninterior point decoding, is designed for linear vector channels. The linear\nvector channels include many practically important channels such as inter\nsymbol interference channels and partial response channels. It is shown that\nthe maximum likelihood decoding (MLD) rule for a linear vector channel can be\nrelaxed to a convex optimization problem, which is called a relaxed MLD\nproblem. The proposed decoding algorithm is based on a numerical optimization\ntechnique so called interior point method with barrier function. Approximate\nvariations of the gradient descent and the Newton methods are used to solve the\nconvex optimization problem. In a decoding process of the proposed algorithm, a\nsearch point always lies in the fundamental polytope defined based on a\nlow-density parity-check matrix. Compared with a convectional joint message\npassing decoder, the proposed decoding algorithm achieves better BER\nperformance with less complexity in the case of partial response channels in\nmany cases.\n\n", "human_text": "  In this paper, a novel decoding algorithm for low-density parity-check (LDPC)\ncodes based on convex optimization is presented. The decoding algorithm, called\ninterior point decoding, is designed for linear vector channels. The linear\nvector channels include many practically important channels such as inter\nsymbol interference channels and partial response channels. It is shown that\nthe maximum likelihood decoding (MLD) rule for a linear vector channel can be\nrelaxed to a convex optimization problem, which is called a relaxed MLD\nproblem. The proposed decoding algorithm is based on a numerical optimization\ntechnique so called interior point method with barrier function. Approximate\nvariations of the gradient descent and the Newton methods are used to solve the\nconvex optimization problem. In a decoding process of the proposed algorithm, a\nsearch point always lies in the fundamental polytope defined based on a\nlow-density parity-check matrix. Compared with a convectional joint message\npassing decoder, the proposed decoding algorithm achieves better BER\nperformance with less complexity in the case of partial response channels in\nmany cases.\n", "machine_text": "In this article, a novel scheme of decoding Low-Density Parity-Check (LDPC) using convex optimization instead of Maximum Likelihood Decoding (MLD), referred to as Interior Point Decoding (IPD), is proposed. It is designed for linear vector channels, such as Inter Symbol Interference (ISI) and Partial Response (PR) channels. MLD for linear vector channels is converted into a convex, optimisation problem referred to as Relaxed MLD. This problem is solved with an Interior Point Method Barrier Function and its approximate variations, the Gradient Descent and Newton Method. IPD search for points in a fundamental polytope determined by the low-density parity-check matrix. It has shown that IPD exhibits a better Bit Error Rate (BER) performance with lesser complexities when compared to the Joint Message Passing Decoder, in the case of Partial Response channels.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.399}
{"prompt": "Rephrase the abstract of an article with title 'Hamiltonian Theory of Adiabatic Motion of Relativistic Charged Particles'.\n  A general Hamiltonian theory for the adiabatic motion of relativistic charged\nparticles confined by slowly-varying background electromagnetic fields is\npresented based on a unified Lie-transform perturbation analysis in extended\nphase space (which includes energy and time as independent coordinates) for all\nthree adiabatic invariants. First, the guiding-center equations of motion for a\nrelativistic particle are derived from the particle Lagrangian. Covariant\naspects of the resulting relativistic guiding-center equations of motion are\ndiscussed and contrasted with previous works. Next, the second and third\ninvariants for the bounce motion and drift motion, respectively, are obtained\nby successively removing the bounce phase and the drift phase from the\nguiding-center Lagrangian. First-order corrections to the second and third\nadiabatic invariants for a relativistic particle are derived. These results\nsimplify and generalize previous works to all three adiabatic motions of\nrelativistic magnetically-trapped particles.\n\n", "human_text": "  A general Hamiltonian theory for the adiabatic motion of relativistic charged\nparticles confined by slowly-varying background electromagnetic fields is\npresented based on a unified Lie-transform perturbation analysis in extended\nphase space (which includes energy and time as independent coordinates) for all\nthree adiabatic invariants. First, the guiding-center equations of motion for a\nrelativistic particle are derived from the particle Lagrangian. Covariant\naspects of the resulting relativistic guiding-center equations of motion are\ndiscussed and contrasted with previous works. Next, the second and third\ninvariants for the bounce motion and drift motion, respectively, are obtained\nby successively removing the bounce phase and the drift phase from the\nguiding-center Lagrangian. First-order corrections to the second and third\nadiabatic invariants for a relativistic particle are derived. These results\nsimplify and generalize previous works to all three adiabatic motions of\nrelativistic magnetically-trapped particles.\n", "machine_text": "\nThis article presents a comprehensive Hamiltonian theory for the adiabatic motion of relativistic charged particles confined by slowly changing electromagnetic fields. An extended Lie-transform perturbation analysis is used to obtain the equations of motion in the extended phase space that transforms energy and time into independent coordinates for all three adiabatic invariants. The relativistic particle Lagrangian is applied to derive the guiding-center equations of motion, which are discussed with regards to their covariant properties compared to existing works. The second and third adiabatic invariants of the bounce motion and drift motion, respectively, are obtained by successive removal of the bounce and drift phases from the guiding-center's Lagrangian. The paper finally derives first-order corrections to the second and third adiabatic invariants of the relativistic particle, which simplify and generalize previous works to encompass all three types of adiabatic motion of magnetically-trapped particles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1925}
{"prompt": "Rephrase the abstract of an article with title 'The generator coordinate method in time-dependent density-functional\n  theory: memory made simple'.\n  The generator coordinate (GC) method is a variational approach to the quantum\nmany-body problem in which interacting many-body wave functions are constructed\nas superpositions of (generally nonorthogonal) eigenstates of auxiliary\nHamiltonians containing a deformation parameter. This paper presents a\ntime-dependent extension of the GC method as a new approach to improve existing\napproximations of the exchange-correlation (XC) potential in time-dependent\ndensity-functional theory (TDDFT). The time-dependent GC method is shown to be\na conceptually and computationally simple tool to build memory effects into any\nexisting adiabatic XC potential. As an illustration, the method is applied to\ndriven parametric oscillations of two interacting electrons in a harmonic\npotential (Hooke's atom). It is demonstrated that a proper choice of\ntime-dependent generator coordinates in conjunction with the adiabatic\nlocal-density approximation reproduces the exact linear and nonlinear\ntwo-electron dynamics quite accurately, including features associated with\ndouble excitations that cannot be captured by TDDFT in the adiabatic\napproximation.\n\n", "human_text": "  The generator coordinate (GC) method is a variational approach to the quantum\nmany-body problem in which interacting many-body wave functions are constructed\nas superpositions of (generally nonorthogonal) eigenstates of auxiliary\nHamiltonians containing a deformation parameter. This paper presents a\ntime-dependent extension of the GC method as a new approach to improve existing\napproximations of the exchange-correlation (XC) potential in time-dependent\ndensity-functional theory (TDDFT). The time-dependent GC method is shown to be\na conceptually and computationally simple tool to build memory effects into any\nexisting adiabatic XC potential. As an illustration, the method is applied to\ndriven parametric oscillations of two interacting electrons in a harmonic\npotential (Hooke's atom). It is demonstrated that a proper choice of\ntime-dependent generator coordinates in conjunction with the adiabatic\nlocal-density approximation reproduces the exact linear and nonlinear\ntwo-electron dynamics quite accurately, including features associated with\ndouble excitations that cannot be captured by TDDFT in the adiabatic\napproximation.\n", "machine_text": "\nIn this paper, we propose a novel method based on the generator coordinate (GC) approach to incorporate memory effects into any existing approximation of the exchange-correlation (XC) potential in time-dependent density-functional theory (TDDFT). This time-dependent GC method is proven to be simpler in implementation than other approaches, and is used to study the driven parametric oscillations of two interacting electrons in a harmonic potential (Hooke's atom). Our results suggest that a suitable choice of time-dependent generator coordinates combined with the adiabatic local-density approximation accurately reproduces the exact dynamics of this system, including the occurrence of double excitations which are not captured by traditional TDDFT in adiabatic approximation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2855}
{"prompt": "Rephrase the abstract of an article with title 'Microscopic theory of quantum dot interactions with quantum light: local\n  field effect'.\n  A theory of both linear and nonlinear electromagnetic response of a single QD\nexposed to quantum light, accounting the depolarization induced local--field\nhas been developed. Based on the microscopic Hamiltonian accounting for the\nelectron--hole exchange interaction, an effective two--body Hamiltonian has\nbeen derived and expressed in terms of the incident electric field, with a\nseparate term describing the QD depolarization. The quantum equations of motion\nhave been formulated and solved with the Hamiltonian for various types of the\nQD excitation, such as Fock qubit, coherent fields, vacuum state of\nelectromagnetic field and light with arbitrary photonic state distribution. For\na QD exposed to coherent light, we predict the appearance of two oscillatory\nregimes in the Rabi effect separated by the bifurcation. In the first regime,\nthe standard collapse--revivals phenomenon do not reveal itself and the QD\npopulation inversion is found to be negative, while in the second one, the\ncollapse--revivals picture is found to be strongly distorted as compared with\nthat predicted by the standard Jaynes-Cummings model. %The model developed can\neasily be extended to %%electromagnetic excitation. For the case of QD\ninteraction with arbitrary quantum light state in the linear regime, it has\nbeen shown that the local field induce a fine structure of the absorbtion\nspectrum. Instead of a single line with frequency corresponding to which the\nexciton transition frequency, a duplet is appeared with one component shifted\nby the amount of the local field coupling parameter. It has been demonstrated\nthe strong light--mater coupling regime arises in the weak-field limit. A\nphysical interpretation of the predicted effects has been proposed.\n\n", "human_text": "  A theory of both linear and nonlinear electromagnetic response of a single QD\nexposed to quantum light, accounting the depolarization induced local--field\nhas been developed. Based on the microscopic Hamiltonian accounting for the\nelectron--hole exchange interaction, an effective two--body Hamiltonian has\nbeen derived and expressed in terms of the incident electric field, with a\nseparate term describing the QD depolarization. The quantum equations of motion\nhave been formulated and solved with the Hamiltonian for various types of the\nQD excitation, such as Fock qubit, coherent fields, vacuum state of\nelectromagnetic field and light with arbitrary photonic state distribution. For\na QD exposed to coherent light, we predict the appearance of two oscillatory\nregimes in the Rabi effect separated by the bifurcation. In the first regime,\nthe standard collapse--revivals phenomenon do not reveal itself and the QD\npopulation inversion is found to be negative, while in the second one, the\ncollapse--revivals picture is found to be strongly distorted as compared with\nthat predicted by the standard Jaynes-Cummings model. %The model developed can\neasily be extended to %%electromagnetic excitation. For the case of QD\ninteraction with arbitrary quantum light state in the linear regime, it has\nbeen shown that the local field induce a fine structure of the absorbtion\nspectrum. Instead of a single line with frequency corresponding to which the\nexciton transition frequency, a duplet is appeared with one component shifted\nby the amount of the local field coupling parameter. It has been demonstrated\nthe strong light--mater coupling regime arises in the weak-field limit. A\nphysical interpretation of the predicted effects has been proposed.\n", "machine_text": "\nThis article presents a microscopic theory of quantum dot (QD) interactions with quantum light that considers the local-field-induced depolarization. A two-body Hamiltonian has been derived and expressed in terms of the incident electric field, with a separate term describing the depolarization effect of the QD. Through the equations of motion, this theory has been applied to the study of various types of excitations within the QD, such as a Fock qubit, coherent fields, vacuum state electromagnetic field light and arbitrary photonic state distributions.\n\nResults show the appearance of two oscillatory regimes in the Rabi effect when a QD is exposed to coherent light, separated by a bifurcation effect. The first regime does not reveal the standard collapse-revival phenomenon, with a negative population inversion, while the second regime greatly distorts the expected collapse-revival as compared to thestandard Jaynes-Cummings model. Moreover, in the linear regime, the local field induces a split in the absorbtion spectrum, usually dominated by a single line corresponding to the exciton transition frequency, and a shift of one component due to the local field coupling parameter. It has also been demonstrated that a strong light-matter coupling arises in a weak-field limit. Physical interpretation and further implications of the derived results are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0267}
{"prompt": "Rephrase the abstract of an article with title 'Detection of two-sided alternatives in a Brownian motion model'.\n  This work examines the problem of sequential detection of a change in the\ndrift of a Brownian motion in the case of two-sided alternatives. Applications\nto real life situations in which two-sided changes can occur are discussed.\nTraditionally, 2-CUSUM stopping rules have been used for this problem due to\ntheir asymptotically optimal character as the mean time between false alarms\ntends to $\\infty$. In particular, attention has focused on 2-CUSUM harmonic\nmean rules due to the simplicity in calculating their first moments. In this\npaper, we derive closed-form expressions for the first moment of a general\n2-CUSUM stopping rule. We use these expressions to obtain explicit upper and\nlower bounds for it. Moreover, we derive an expression for the rate of change\nof this first moment as one of the threshold parameters changes. Based on these\nexpressions we obtain explicit upper and lower bounds to this rate of change.\nUsing these expressions we are able to find the best 2-CUSUM stopping rule with\nrespect to the extended Lorden criterion. In fact, we demonstrate not only the\nexistence but also the uniqueness of the best 2-CUSUM stopping both in the case\nof a symmetric change and in the case of a non-symmetric case. Furthermore, we\ndiscuss the existence of a modification of the 2-CUSUM stopping rule that has a\nstrictly better performance than its classical 2-CUSUM counterpart for small\nvalues of the mean time between false alarms. We conclude with a discussion on\nthe open problem of strict optimality in the case of two-sided alternatives.\n\n", "human_text": "  This work examines the problem of sequential detection of a change in the\ndrift of a Brownian motion in the case of two-sided alternatives. Applications\nto real life situations in which two-sided changes can occur are discussed.\nTraditionally, 2-CUSUM stopping rules have been used for this problem due to\ntheir asymptotically optimal character as the mean time between false alarms\ntends to $\\infty$. In particular, attention has focused on 2-CUSUM harmonic\nmean rules due to the simplicity in calculating their first moments. In this\npaper, we derive closed-form expressions for the first moment of a general\n2-CUSUM stopping rule. We use these expressions to obtain explicit upper and\nlower bounds for it. Moreover, we derive an expression for the rate of change\nof this first moment as one of the threshold parameters changes. Based on these\nexpressions we obtain explicit upper and lower bounds to this rate of change.\nUsing these expressions we are able to find the best 2-CUSUM stopping rule with\nrespect to the extended Lorden criterion. In fact, we demonstrate not only the\nexistence but also the uniqueness of the best 2-CUSUM stopping both in the case\nof a symmetric change and in the case of a non-symmetric case. Furthermore, we\ndiscuss the existence of a modification of the 2-CUSUM stopping rule that has a\nstrictly better performance than its classical 2-CUSUM counterpart for small\nvalues of the mean time between false alarms. We conclude with a discussion on\nthe open problem of strict optimality in the case of two-sided alternatives.\n", "machine_text": "\nIn this study, we analyze the problem of detecting a shift in the random drift of a Brownian motion in the event of two-sided alternatives. Although the 2-CUSUM stopping rules have shown superior performance for this task over the years due to their asymptotic optimality, the calculation of their first moments is complex. Our research aids in these calculations by finding closed-form expressions for the first moment of a general two-sided CUSUM stopping rule, and derived upper and lower bounds for it. We also offer an expression for the change rate of the first moment and provide upper and lower bounds. Comparisons to the extended Lorden criterion demonstrate the existence and uniqueness of the best two-sided CUSUM rule in both symmetric and non-symmetric cases. Furthermore, we suggest a modification of the conventional two-sided CUSUM stopping rule that offers improved performance in the event of small time between false alarms. Ultimately, we raise the issue of finding a strictly optimal approach in the case of two-sided alternatives.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3094}
{"prompt": "Rephrase the abstract of an article with title 'Phenomenology with Massive Neutrinos'.\n  The current status and some perspectives of the phenomenology of massive\nneutrinos is reviewed. We start with the phenomenology of neutrino oscillations\nin vacuum and in matter. We summarize the results of neutrino experiments using\nsolar, atmospheric, reactor and accelerator neutrino beams. We update the\nleptonic parameters derived from the three-neutrino oscillation interpretation\nof this data. We describe the method and present results on our understanding\nof the solar and atmospheric neutrino fluxes by direct extraction from the\ncorresponding neutrino event rates. We present some tests of different forms of\nnew physics which induce new sources of leptonic flavor transitions in vacuum\nand in matter which can be performed with the present neutrino data. The aim\nand potential of future neutrino experiments and facilities to further advance\nin these fronts is also briefly summarized. Last, the implications of the LSND\nobservations are discussed, and the status of extended models which could\naccommodate all flavor-mixing signals is presented in the light of the recent\nresults from MiniBooNE.\n\n", "human_text": "  The current status and some perspectives of the phenomenology of massive\nneutrinos is reviewed. We start with the phenomenology of neutrino oscillations\nin vacuum and in matter. We summarize the results of neutrino experiments using\nsolar, atmospheric, reactor and accelerator neutrino beams. We update the\nleptonic parameters derived from the three-neutrino oscillation interpretation\nof this data. We describe the method and present results on our understanding\nof the solar and atmospheric neutrino fluxes by direct extraction from the\ncorresponding neutrino event rates. We present some tests of different forms of\nnew physics which induce new sources of leptonic flavor transitions in vacuum\nand in matter which can be performed with the present neutrino data. The aim\nand potential of future neutrino experiments and facilities to further advance\nin these fronts is also briefly summarized. Last, the implications of the LSND\nobservations are discussed, and the status of extended models which could\naccommodate all flavor-mixing signals is presented in the light of the recent\nresults from MiniBooNE.\n", "machine_text": "This article reviews the current state of the phenomenology of massive neutrinos. We examine the phenomenon of neutrino oscillation in both vacuum and in matter, and then present the leptonic parameters derived from the three-neutrino oscillation interpretation of the data obtained from the solar, atmospheric, reactor and accelerator neutrino beams. The article further explores the potential role of new physics in inducing leptonic flavor transitions in both matter and vacuum, and examines the implications of the LSND observations. The article also outlines the aims and possibilities of future neutrino experiments and facilities in furthering our understanding of these topics, and has also presented the updated results of MiniBooNE on the status of extended models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.18}
{"prompt": "Rephrase the abstract of an article with title 'Charm-quark fragmentation with an effective coupling constant'.\n  We use a recently proposed non-perturbative model, based on an effective\nstrong coupling constant and free from tunable parameters, to study c-flavoured\nhadron production in e+e- annihilation. Charm-quark production is described in\nthe framework of perturbative fragmentation functions, with NLO coefficient\nfunctions, NLL non-singlet DGLAP evolution and NNLL large-x resummation. We\nmodel hadronization effects by means of the effective coupling constant in the\nNNLO approximation and compare our results with experimental data taken at the\nZ0 pole and at the Upsilon(4S) resonance. We find that, within the experimental\nand theoretical uncertainties, our model is able to give a reasonable\ndescription of D*+-meson spectra from ALEPH for x<1-Lambda/m_c. More serious\ndiscrepancies are instead present when comparing with D and D^* data from BELLE\nand CLEO in x-space. Within the errors, our model is nonetheless capable of\nreproducing the first ten Mellin moments of all considered data sets. However,\nthe fairly large theoretical uncertainties call for a full NNLO/NNLL analysis.\n\n", "human_text": "  We use a recently proposed non-perturbative model, based on an effective\nstrong coupling constant and free from tunable parameters, to study c-flavoured\nhadron production in e+e- annihilation. Charm-quark production is described in\nthe framework of perturbative fragmentation functions, with NLO coefficient\nfunctions, NLL non-singlet DGLAP evolution and NNLL large-x resummation. We\nmodel hadronization effects by means of the effective coupling constant in the\nNNLO approximation and compare our results with experimental data taken at the\nZ0 pole and at the Upsilon(4S) resonance. We find that, within the experimental\nand theoretical uncertainties, our model is able to give a reasonable\ndescription of D*+-meson spectra from ALEPH for x<1-Lambda/m_c. More serious\ndiscrepancies are instead present when comparing with D and D^* data from BELLE\nand CLEO in x-space. Within the errors, our model is nonetheless capable of\nreproducing the first ten Mellin moments of all considered data sets. However,\nthe fairly large theoretical uncertainties call for a full NNLO/NNLL analysis.\n", "machine_text": "\nA non-perturbative model, with an effective strong coupling constant and devoid of adjustable parameters, is used to explore the charm-quark fragmentation in e+e\u2212 annihilation. Perturbative fragmentation functions, containing NLO coefficient functions, NLL non-singlet DGLAP evolution, and NNLL large-x resummation, are employed in this model. We utilize the effective coupling constant in the NNLO approximation to investigate the hadronization effects and compare our results to experimental data from the Z0 pole and the Upsilon(4S) resonance. Generally, our model agrees well with D*+-meson spectra from ALEPH. However, discrepancies were found when compared to D and D* data from BELLE and CLEO. Even so, our model is able to reproduce the first 10 Mellin moments of the data sets within the respective uncertainty limits. Although there are visible improvements in our analysis, a comprehensive NNLO/NNLL analysis is still necessary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2357}
{"prompt": "Rephrase the abstract of an article with title 'The Calibration and Data Products of the Galaxy Evolution Explorer'.\n  We describe the calibration status and data products pertaining to the GR2\nand GR3 data releases of the Galaxy Evolution Explorer (GALEX). These releases\nhave identical pipeline calibrations that are significantly improved over the\nGR1 data release. GALEX continues to survey the sky in the Far Ultraviolet\n(FUV, ~154 nm) and Near Ultraviolet (NUV, ~232 nm) bands, providing\nsimultaneous imaging with a pair of photon counting, microchannel plate, delay\nline readout detectors. These 1.25 degree field-of-view detectors are\nwell-suited to ultraviolet observations because of their excellent red\nrejection and negligible background. A dithered mode of observing and photon\nlist output pose complex requirements on the data processing pipeline,\nentangling detector calibrations and aspect reconstruction algorithms. Recent\nimprovements have achieved photometric repeatability of 0.05 and 0.03 mAB in\nthe FUV and NUV, respectively. We have detected a long term drift of order 1%\nFUV and 6% NUV over the mission. Astrometric precision is of order 0.5\" RMS in\nboth bands. In this paper we provide the GALEX user with a broad overview of\nthe calibration issues likely to be confronted in the current release.\nImprovements are likely as the GALEX mission continues into an extended phase\nwith a healthy instrument, no consumables, and increased opportunities for\nguest investigations.\n\n", "human_text": "  We describe the calibration status and data products pertaining to the GR2\nand GR3 data releases of the Galaxy Evolution Explorer (GALEX). These releases\nhave identical pipeline calibrations that are significantly improved over the\nGR1 data release. GALEX continues to survey the sky in the Far Ultraviolet\n(FUV, ~154 nm) and Near Ultraviolet (NUV, ~232 nm) bands, providing\nsimultaneous imaging with a pair of photon counting, microchannel plate, delay\nline readout detectors. These 1.25 degree field-of-view detectors are\nwell-suited to ultraviolet observations because of their excellent red\nrejection and negligible background. A dithered mode of observing and photon\nlist output pose complex requirements on the data processing pipeline,\nentangling detector calibrations and aspect reconstruction algorithms. Recent\nimprovements have achieved photometric repeatability of 0.05 and 0.03 mAB in\nthe FUV and NUV, respectively. We have detected a long term drift of order 1%\nFUV and 6% NUV over the mission. Astrometric precision is of order 0.5\" RMS in\nboth bands. In this paper we provide the GALEX user with a broad overview of\nthe calibration issues likely to be confronted in the current release.\nImprovements are likely as the GALEX mission continues into an extended phase\nwith a healthy instrument, no consumables, and increased opportunities for\nguest investigations.\n", "machine_text": "\nThis paper outlines the GR2 and GR3 data releases of the Galaxy Evolution Explorer (GALEX) which have seen improvements in the pipeline calibration of the Far Ultraviolet (FUV) and Near Ultraviolet (NUV) bands. Using its 1.25 degree field-of-view detectors, GALEX surveys the sky and provides photometric repeatability of 0.05 and 0.03 mAB in the FUV and NUV bands respectively, along with astrometric precision of 0.5\" RMS in both bands. Additionally, the mission has seen a steady 1% FUV and 6% NUV drift over its run. As the GALEX mission continues into the extended phase, this paper outlines the calibration issues that users may encounter, with the hopes of further improvements as the instrument is kept healthy and guest investigations are enabled.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0755}
{"prompt": "Rephrase the abstract of an article with title 'Linked by Loops: Network Structure and Switch Integration in Complex\n  Dynamical Systems'.\n  Simple nonlinear dynamical systems with multiple stable stationary states are\noften taken as models for switchlike biological systems. This paper considers\nthe interaction of multiple such simple multistable systems when they are\nembedded together into a larger dynamical \"supersystem.\" Attention is focused\non the network structure of the resulting set of coupled differential\nequations, and the consequences of this structure on the propensity of the\nembedded switches to act independently versus cooperatively. Specifically, it\nis argued that both larger average and larger variance of the node degree\ndistribution lead to increased switch independence. Given the frequency of\nempirical observations of high variance degree distributions (e.g., power-law)\nin biological networks, it is suggested that the results presented here may aid\nin identifying switch-integrating subnetworks as comparatively homogenous,\nlow-degree, substructures. Potential applications to ecological problems such\nas the relationship of stability and complexity are also briefly discussed.\n\n", "human_text": "  Simple nonlinear dynamical systems with multiple stable stationary states are\noften taken as models for switchlike biological systems. This paper considers\nthe interaction of multiple such simple multistable systems when they are\nembedded together into a larger dynamical \"supersystem.\" Attention is focused\non the network structure of the resulting set of coupled differential\nequations, and the consequences of this structure on the propensity of the\nembedded switches to act independently versus cooperatively. Specifically, it\nis argued that both larger average and larger variance of the node degree\ndistribution lead to increased switch independence. Given the frequency of\nempirical observations of high variance degree distributions (e.g., power-law)\nin biological networks, it is suggested that the results presented here may aid\nin identifying switch-integrating subnetworks as comparatively homogenous,\nlow-degree, substructures. Potential applications to ecological problems such\nas the relationship of stability and complexity are also briefly discussed.\n", "machine_text": "\nThis paper investigates the influence of a network's structure on the functioning of multiple identical but interconnected simple nonlinear dynamical systems exhibiting multiple stable stationary states, which are commonly used for modeling switch-like behavior in biological systems. It is shown that both an increase in the average degree and higher variance in the degree distribution across the nodes result in a higher tendency of the switches to act independently instead of cooperatively. Given the common occurrence of power-law degree distributions in biological networks, this paper proposes that the finding might help to identify any subnetworks that integrate the switches as comparatively low-degree and homogenous structures. In addition, the potential applications of these results to address ecological issues such as the integration of complexity and stability are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.364}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical Objects for Cohomologically Expanding Maps'.\n  The goal of this paper is to construct invariant dynamical objects for a (not\nnecessarily invertible) smooth self map of a compact manifold. We prove a\nresult that takes advantage of differences in rates of expansion in the terms\nof a sheaf cohomological long exact sequence to create unique lifts of finite\ndimensional invariant subspaces of one term of the sequence to invariant\nsubspaces of the preceding term. This allows us to take invariant cohomological\nclasses and under the right circumstances construct unique currents of a given\ntype, including unique measures of a given type, that represent those classes\nand are invariant under pullback. A dynamically interesting self map may have a\nplethora of invariant measures, so the uniquess of the constructed currents is\nimportant. It means that if local growth is not too big compared to the growth\nrate of the cohomological class then the expanding cohomological class gives\nsufficient \"marching orders\" to the system to prohibit the formation of any\nother such invariant current of the same type (say from some local dynamical\nsubsystem). Because we use subsheaves of the sheaf of currents we give\nconditions under which a subsheaf will have the same cohomology as the sheaf\ncontaining it. Using a smoothing argument this allows us to show that the sheaf\ncohomology of the currents under consideration can be canonically identified\nwith the deRham cohomology groups. Our main theorem can be applied in both the\nsmooth and holomorphic setting.\n\n", "human_text": "  The goal of this paper is to construct invariant dynamical objects for a (not\nnecessarily invertible) smooth self map of a compact manifold. We prove a\nresult that takes advantage of differences in rates of expansion in the terms\nof a sheaf cohomological long exact sequence to create unique lifts of finite\ndimensional invariant subspaces of one term of the sequence to invariant\nsubspaces of the preceding term. This allows us to take invariant cohomological\nclasses and under the right circumstances construct unique currents of a given\ntype, including unique measures of a given type, that represent those classes\nand are invariant under pullback. A dynamically interesting self map may have a\nplethora of invariant measures, so the uniquess of the constructed currents is\nimportant. It means that if local growth is not too big compared to the growth\nrate of the cohomological class then the expanding cohomological class gives\nsufficient \"marching orders\" to the system to prohibit the formation of any\nother such invariant current of the same type (say from some local dynamical\nsubsystem). Because we use subsheaves of the sheaf of currents we give\nconditions under which a subsheaf will have the same cohomology as the sheaf\ncontaining it. Using a smoothing argument this allows us to show that the sheaf\ncohomology of the currents under consideration can be canonically identified\nwith the deRham cohomology groups. Our main theorem can be applied in both the\nsmooth and holomorphic setting.\n", "machine_text": "This article explores the construction of uniquely determined dynamical objects that are invariant under the pullback action of a (not necessarily invertible) smooth self-map of a compact manifold. Taking advantage of differences in expansion rates between terms inside of a sheaf cohomological long exact sequence, we are able to lift finite-dimensional invariant subspaces from one term to the preceding one, which then allows for the formation of unique invariant currents and measures of a given type. We also discuss conditions for which the subsheaf cohomology of these currents is identical to the sheaf cohomology, as well as conditions to canonically identify the sheaf cohomology of the currents to the deRham cohomology groups. Our theorem can be applied to both smooth and holomorphic settings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0069}
{"prompt": "Rephrase the abstract of an article with title 'Weight structures vs. $t$-structures; weight filtrations, spectral\n  sequences, and complexes (for motives and in general)'.\n  This paper is dedicated to triangulated categories endowed with weight\nstructures (a new notion; D. Pauksztello has independently introduced them as\nco-t-structures). This axiomatizes the properties of stupid truncations of\ncomplexes in $K(B)$. We also construct weight structures for Voevodsky's\ncategories of motives and for various categories of spectra. A weight structure\n$w$ defines Postnikov towers of objects; these towers are canonical and\nfunctorial 'up to morphisms that are zero on cohomology'. For $Hw$ being the\nheart of $w$ (in $DM_{gm}$ we have $Hw=Chow$) we define a canonical\nconservative 'weakly exact' functor $t$ from our $C$ to a certain weak category\nof complexes $K_w(Hw)$. For any (co)homological functor $H:C\\to A$ for an\nabelian $A$ we construct a weight spectral sequence $T:H(X^i[j])\\implies\nH(X[i+j])$ where $(X^i)=t(X)$; it is canonical and functorial starting from\n$E_2$. This spectral sequences specializes to the 'usual' (Deligne's) weight\nspectral sequences for 'classical' realizations of motives and to\nAtiyah-Hirzebruch spectral sequences for spectra. Under certain restrictions,\nwe prove that $K_0(C)\\cong K_0(Hw)$ and $K_0(End C)\\cong K_0(End Hw)$.\n  The definition of a weight structure is almost dual to those of a\nt-structure; yet several properties differ. One can often construct a certain\n$t$-structure which is 'adjacent' to $w$ and vice versa. This is the case for\nthe Voevodsky's $DM^{eff}_-$ (one obtains certain new Chow weight and\nt-structures for it; the heart of the latter is 'dual' to $Chow^{eff}$) and for\nthe stable homotopy category. The Chow t-structure is closely related to\nunramified cohomology.\n\n", "human_text": "  This paper is dedicated to triangulated categories endowed with weight\nstructures (a new notion; D. Pauksztello has independently introduced them as\nco-t-structures). This axiomatizes the properties of stupid truncations of\ncomplexes in $K(B)$. We also construct weight structures for Voevodsky's\ncategories of motives and for various categories of spectra. A weight structure\n$w$ defines Postnikov towers of objects; these towers are canonical and\nfunctorial 'up to morphisms that are zero on cohomology'. For $Hw$ being the\nheart of $w$ (in $DM_{gm}$ we have $Hw=Chow$) we define a canonical\nconservative 'weakly exact' functor $t$ from our $C$ to a certain weak category\nof complexes $K_w(Hw)$. For any (co)homological functor $H:C\\to A$ for an\nabelian $A$ we construct a weight spectral sequence $T:H(X^i[j])\\implies\nH(X[i+j])$ where $(X^i)=t(X)$; it is canonical and functorial starting from\n$E_2$. This spectral sequences specializes to the 'usual' (Deligne's) weight\nspectral sequences for 'classical' realizations of motives and to\nAtiyah-Hirzebruch spectral sequences for spectra. Under certain restrictions,\nwe prove that $K_0(C)\\cong K_0(Hw)$ and $K_0(End C)\\cong K_0(End Hw)$.\n  The definition of a weight structure is almost dual to those of a\nt-structure; yet several properties differ. One can often construct a certain\n$t$-structure which is 'adjacent' to $w$ and vice versa. This is the case for\nthe Voevodsky's $DM^{eff}_-$ (one obtains certain new Chow weight and\nt-structures for it; the heart of the latter is 'dual' to $Chow^{eff}$) and for\nthe stable homotopy category. The Chow t-structure is closely related to\nunramified cohomology.\n", "machine_text": "This article explores weight structures, which are a new kind of triangulated category, focusing on the relationship between them and t-structures, and how these understandings can be applied to various categories including Voevodsky's categories of motives and spectra. These weight structures allow for the construction of towers of objects and canonically conservative weakly exact functors from a category $C$ to weak categories of complexes. A weight spectral sequence is also defined that generalizes the Deligne spectral sequence for classical realizations of motives and the Atiyah-Hirzebruch spectral sequence for spectra. Further, some duality statements are presented between categories and $K$-groups. Lastly, the article examines cases in which a weight structure and an adjacent t-structure is formed, such as in Voevodsky's $DM^{eff}_-$ and the stable homotopy category.\n\nThis paper considers weight structures, a new notion of triangulated categories, in contrast to related $t$-structures. Through applications in Voevodsky's categories of motives and spectra, this article explores the nature of these weight structures, detailing how the construction of towers of objects and weight spectral sequences are made possible. Weakly exact functors are also defined, and duality is demonstrated between categories and $K$-groups. The examination of the relationship between a weight structure and an adjacent t-structure is discussed in Voevodsky's $DM^{eff}_-$ and the stable homotopy category.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.4003}
{"prompt": "Rephrase the abstract of an article with title 'Gas-grain chemistry in cold interstellar cloud cores with a microscopic\n  Monte Carlo approach to surface chemistry'.\n  AIM: We have recently developed a microscopic Monte Carlo approach to study\nsurface chemistry on interstellar grains and the morphology of ice mantles. The\nmethod is designed to eliminate the problems inherent in the rate-equation\nformalism to surface chemistry. Here we report the first use of this method in\na chemical model of cold interstellar cloud cores that includes both gas-phase\nand surface chemistry. The surface chemical network consists of a small number\nof diffusive reactions that can produce molecular oxygen, water, carbon\ndioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation\nis started by running a gas-phase model including accretion onto grains but no\nsurface chemistry or evaporation. The starting surface consists of either flat\nor rough olivine. We introduce the surface chemistry of the three species H, O\nand CO in an iterative manner using our stochastic technique. Under the\nconditions of the simulation, only atomic hydrogen can evaporate to a\nsignificant extent. Although it has little effect on other gas-phase species,\nthe evaporation of atomic hydrogen changes its gas-phase abundance, which in\nturn changes the flux of atomic hydrogen onto grains. The effect on the surface\nchemistry is treated until convergence occurs. We neglect all non-thermal\ndesorptive processes. RESULTS: We determine the mantle abundances of assorted\nmolecules as a function of time through 2x10^5 yr. Our method also allows\ndetermination of the abundance of each molecule in specific monolayers. The\nmantle results can be compared with observations of water, carbon dioxide,\ncarbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than\na slight underproduction of mantle CO, our results are in very good agreement\nwith observations.\n\n", "human_text": "  AIM: We have recently developed a microscopic Monte Carlo approach to study\nsurface chemistry on interstellar grains and the morphology of ice mantles. The\nmethod is designed to eliminate the problems inherent in the rate-equation\nformalism to surface chemistry. Here we report the first use of this method in\na chemical model of cold interstellar cloud cores that includes both gas-phase\nand surface chemistry. The surface chemical network consists of a small number\nof diffusive reactions that can produce molecular oxygen, water, carbon\ndioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation\nis started by running a gas-phase model including accretion onto grains but no\nsurface chemistry or evaporation. The starting surface consists of either flat\nor rough olivine. We introduce the surface chemistry of the three species H, O\nand CO in an iterative manner using our stochastic technique. Under the\nconditions of the simulation, only atomic hydrogen can evaporate to a\nsignificant extent. Although it has little effect on other gas-phase species,\nthe evaporation of atomic hydrogen changes its gas-phase abundance, which in\nturn changes the flux of atomic hydrogen onto grains. The effect on the surface\nchemistry is treated until convergence occurs. We neglect all non-thermal\ndesorptive processes. RESULTS: We determine the mantle abundances of assorted\nmolecules as a function of time through 2x10^5 yr. Our method also allows\ndetermination of the abundance of each molecule in specific monolayers. The\nmantle results can be compared with observations of water, carbon dioxide,\ncarbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than\na slight underproduction of mantle CO, our results are in very good agreement\nwith observations.\n", "machine_text": "\nThis paper describes the development and initial application of a microscopic Monte Carlo approach to model surface chemistry in cold interstellar cloud cores. The technique eliminates the issues encountered by the rate-equation formalism in simulating surface chemistry. The surface chemical network combines three diffusive reactions of H, O, and CO to produce molecules such as molecular oxygen, water, carbon dioxide, formaldehyde, methanol and various radicals. Starting with either a flat or rough olivine surface and using a gas-phase model including accretion onto grains but no surface chemistry or evaporation, we considered the effects of atomic hydrogen evaporation and its impact on the gas-phase abundance and flux onto grains. Our simulations demonstrate agreement with observations of water, CO2, CO, and methanol ices in W33A and Elias 16, with only slight underproduction of mantle CO. This technique should enable further advances in the understanding of gas-grain chemistry in interstellar clouds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2704}
{"prompt": "Rephrase the abstract of an article with title 'An Abelian two-Higgs model of strongly correlated electrons: phase\n  structure, strengthening of phase transition and QCD at finite density'.\n  We investigate non-perturbative features of a three-dimensional Abelian Higgs\nmodel with singly- and doubly-charged scalar fields coupled to a single compact\nAbelian gauge field. The model is pretending to describe various planar systems\nof strongly correlated electrons such as high-Tc superconductivity in the\noverdoped regime and exotic materials possessing excitations with\nfractionalized quantum numbers. The complicated phase structure of the model is\nstudied thoroughly using numerical tools and analytical arguments. In the\nthree-dimensional space of coupling parameters we identify the Fermi liquid,\nthe spin gap, the superconductor and the strange metallic phases. The behavior\nof three kinds of topological defects -- holon and spinon vortices and\nmonopoles - is explored in various phases. We also observe a new effect, the\nstrong enhancement of the phase transition strength reflected in a lower order\nof the transition: at sufficiently strong gauge coupling the two second order\nphase transitions -- corresponding to spinon-pair and holon condensation lines\n- join partially in the phase diagram and become a first order phase transition\nin that region. The last observation may have an analogue in Quantum\nChromodynamics at non-zero temperature and finite baryon density. We argue that\nat sufficiently large baryon density the finite-temperature transition between\nthe (3-flavor paired) color superconducting phase and the quark-gluon plasma\nphases should be much stronger compared with the transition between 2-flavor\npaired and 3-flavor paired superconducting phases.\n\n", "human_text": "  We investigate non-perturbative features of a three-dimensional Abelian Higgs\nmodel with singly- and doubly-charged scalar fields coupled to a single compact\nAbelian gauge field. The model is pretending to describe various planar systems\nof strongly correlated electrons such as high-Tc superconductivity in the\noverdoped regime and exotic materials possessing excitations with\nfractionalized quantum numbers. The complicated phase structure of the model is\nstudied thoroughly using numerical tools and analytical arguments. In the\nthree-dimensional space of coupling parameters we identify the Fermi liquid,\nthe spin gap, the superconductor and the strange metallic phases. The behavior\nof three kinds of topological defects -- holon and spinon vortices and\nmonopoles - is explored in various phases. We also observe a new effect, the\nstrong enhancement of the phase transition strength reflected in a lower order\nof the transition: at sufficiently strong gauge coupling the two second order\nphase transitions -- corresponding to spinon-pair and holon condensation lines\n- join partially in the phase diagram and become a first order phase transition\nin that region. The last observation may have an analogue in Quantum\nChromodynamics at non-zero temperature and finite baryon density. We argue that\nat sufficiently large baryon density the finite-temperature transition between\nthe (3-flavor paired) color superconducting phase and the quark-gluon plasma\nphases should be much stronger compared with the transition between 2-flavor\npaired and 3-flavor paired superconducting phases.\n", "machine_text": "This paper examines non-perturbative qualities of an Abelian Higgs model made out of singleton and double charged scalar fields, plus a single restricted Abelian gauge field. These components together can represent various examples of strongly correlated electronic systems, such as the high temperature superconductivity found in the overdoped regime and various materials possessing fractional quantum numbers. Through the use of analytical systems, as well as numerical facilitation, this article looks into the complicated phase structure of the model, locating peculiar features like Fermi Liquid, Spin Gap, Superconductor, and Strange Metallic Phases, as well as holon, spinon vortices, and monopoles. Additionally, the study came to note a radical intensification of the phase transition strength, converging to an initially second order transition eventually becoming the first order. The same phenomenon may occur in Quantum Chromodynamics when the temperature is nonzero, yet with a finite density of baryons. Thus, at a high enough baryon density, the change from a 2-flavor superconducting space to the 3-flavor one should yield a larger phase transition strength than usual.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1528}
{"prompt": "Rephrase the abstract of an article with title 'Meta-nematic transitions in a bilayer system: Application to the bilayer\n  ruthenate'.\n  It was suggested that the two consecutive metamagnetic transitions and the\nlarge residual resistivity discovered in Sr$_3$Ru$_2$O$_7$ can be understood\nvia the nematic order and its domains in a single layer system. However, a\nrecently reported anisotropy between two longitudinal resistivities induced by\ntilting the magnetic field away from the c-axis cannot be explained within the\nsingle layer nematic picture. To fill the gap in our understanding within the\nnematic order scenario, we investigate the effects of bilayer coupling and\nin-plane magnetic field on the electronic nematic phases in a bilayer system.\nWe propose that the in-plane magnetic field in the bilayer system modifies the\nenergetics of the domain formation, since it breaks the degeneracy of two\ndifferent nematic orientations. Thus the system reveals a pure nematic phase\nwith a resistivity anisotropy in the presence of an in-plane magnetic field. In\naddition to the nematic phase, the bilayer coupling opens a novel route to a\nhidden nematic phase that preserves the x-y symmetry of the Fermi surfaces.\n\n", "human_text": "  It was suggested that the two consecutive metamagnetic transitions and the\nlarge residual resistivity discovered in Sr$_3$Ru$_2$O$_7$ can be understood\nvia the nematic order and its domains in a single layer system. However, a\nrecently reported anisotropy between two longitudinal resistivities induced by\ntilting the magnetic field away from the c-axis cannot be explained within the\nsingle layer nematic picture. To fill the gap in our understanding within the\nnematic order scenario, we investigate the effects of bilayer coupling and\nin-plane magnetic field on the electronic nematic phases in a bilayer system.\nWe propose that the in-plane magnetic field in the bilayer system modifies the\nenergetics of the domain formation, since it breaks the degeneracy of two\ndifferent nematic orientations. Thus the system reveals a pure nematic phase\nwith a resistivity anisotropy in the presence of an in-plane magnetic field. In\naddition to the nematic phase, the bilayer coupling opens a novel route to a\nhidden nematic phase that preserves the x-y symmetry of the Fermi surfaces.\n", "machine_text": "This paper explores the effects of bilayer coupling and in-plane magnetic field on meta-nematic transitions in a bilayer system, as it pertains to the bilayer ruthenate Sr$_3$Ru$_2$O$_7$. We hypothesize that the in-plane magnetic field in the bilayer system creates a pure nematic phase with a resistivity anisotropy when it impacts the energetics of domain formation by breaking the degeneracy of two different nematic orientations. Additionally, we postulate that bilayer coupling opens a pathway to a previously undiscovered nematic phase which preserves the x-y symmetry of the Fermi surfaces.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1069}
{"prompt": "Rephrase the abstract of an article with title 'Nonleptonic two-body B-decays including axial-vector mesons in the final\n  state'.\n  We present a systematic study of exclusive charmless nonleptonic two-body B\ndecays including axial-vector mesons in the final state. We calculate branching\nratios of B\\to PA, VA and AA decays, where A, V and P denote an axial-vector, a\nvector and a pseudoscalar meson, respectively. We assume naive factorization\nhypothesis and use the improved version of the nonrelativistic ISGW quark model\nfor form factors in B\\to A transitions. We include contributions that arise\nfrom the effective \\Delta B=1 weak Hamiltonian H_{eff}. The respective\nfactorized amplitude of these decays are explicitly showed and their penguin\ncontributions are classified. We find that decays B^-to a_1^0\\pi^-,\\barB^0\\to\na_1^{\\pm}\\pi^{\\mp}, B^-\\to a_1^-\\bar K^0, \\bar B^0\\to a_1^+K^-, \\bar B^0\\to\nf_1\\bar K^0, B^-\\to f_1K^-, B^-\\to K_1^-(1400)\\etap, B^-\\to b_1^-\\bar K^{0},\nand \\bar B^0\\to b_1^+\\pi^-(K^-) have branching ratios of the order of 10^{-5}.\nWe also study the dependence of branching ratios for B \\to K_1P(V,A) decays\n(K_1=K_1(1270),K_1(1400)) with respect to the mixing angle between K_A and K_B.\n\n", "human_text": "  We present a systematic study of exclusive charmless nonleptonic two-body B\ndecays including axial-vector mesons in the final state. We calculate branching\nratios of B\\to PA, VA and AA decays, where A, V and P denote an axial-vector, a\nvector and a pseudoscalar meson, respectively. We assume naive factorization\nhypothesis and use the improved version of the nonrelativistic ISGW quark model\nfor form factors in B\\to A transitions. We include contributions that arise\nfrom the effective \\Delta B=1 weak Hamiltonian H_{eff}. The respective\nfactorized amplitude of these decays are explicitly showed and their penguin\ncontributions are classified. We find that decays B^-to a_1^0\\pi^-,\\barB^0\\to\na_1^{\\pm}\\pi^{\\mp}, B^-\\to a_1^-\\bar K^0, \\bar B^0\\to a_1^+K^-, \\bar B^0\\to\nf_1\\bar K^0, B^-\\to f_1K^-, B^-\\to K_1^-(1400)\\etap, B^-\\to b_1^-\\bar K^{0},\nand \\bar B^0\\to b_1^+\\pi^-(K^-) have branching ratios of the order of 10^{-5}.\nWe also study the dependence of branching ratios for B \\to K_1P(V,A) decays\n(K_1=K_1(1270),K_1(1400)) with respect to the mixing angle between K_A and K_B.\n", "machine_text": "This paper looks at non-leptonic, two-body B decay that end in axial-vector mesons. We use the naive factorization hypothesis and an upgraded nonrelativistic ISGW quark model with the effective $\\Delta B=1$ weak Hamiltonian as our theoretical framework to calculate branching ratios. We describe the resulting decays B$^-$ to $\\alpha_1^0\\pi^-$, $\\overline{B^0}$ to $\\alpha_1^{\\pm}\\pi^{\\mp}$, $B^-\\to \\alpha_1^-\\overline{K^0}$, $\\overline{B^0}$ to $\\alpha_1^+K^-$, $\\overline{B^0}$ to ${f_1}\\overline{K^0}$,$ B^-\\to {f_1}K^-$, $B^-\\to K_1^-\\eta'$, $B^-\\to {b_1}^-\\overline{K^0}$, and $\\overline{B^0}$ to ${b^+_1}\\pi^-$ to be of the order of $10^{-5}$. We examine the dependence of the $B^-\\to K_1P(V,A)$ decays (K_1=K_1(1270),K_1(1400)) on the mixing angle achievable between K_A and K_B.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1181}
{"prompt": "Rephrase the abstract of an article with title 'On the nature of two superconducting transitions in the specific heat of\n  PrOs$_4$Sb$_{12}$: Effects of crystal grinding'.\n  Specific heat, dc- and ac-magnetic susceptibility are reported for a large\nsingle crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room\ntemperature effective paramagnetic moment of the crystal was consistent with\nthe Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The\ncrystal showed two distinct anomalies in the specific heat and an overall\ndiscontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at\n$T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at\n$T_{c2}$ was very sharp, consistent with a good quality of the crystal. We\nobserved a shoulder in $\\chi$' and two peaks in $\\chi$'' below $T_{c1}$.\nHowever, there were no signatures in $\\chi$' of the lower temperature\ntransition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which\nsuppresses the upper superconducting transition in both the specific heat and\nmagnetic susceptibility. $\\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in\nthe powdered sample. Existing data on ground, polished, and sliced crystals\nsuggests the existence of a length scale of order 100 $\\mu$, characterizing the\nhigher temperature superconducting phase.\n\n", "human_text": "  Specific heat, dc- and ac-magnetic susceptibility are reported for a large\nsingle crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room\ntemperature effective paramagnetic moment of the crystal was consistent with\nthe Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The\ncrystal showed two distinct anomalies in the specific heat and an overall\ndiscontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at\n$T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at\n$T_{c2}$ was very sharp, consistent with a good quality of the crystal. We\nobserved a shoulder in $\\chi$' and two peaks in $\\chi$'' below $T_{c1}$.\nHowever, there were no signatures in $\\chi$' of the lower temperature\ntransition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which\nsuppresses the upper superconducting transition in both the specific heat and\nmagnetic susceptibility. $\\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in\nthe powdered sample. Existing data on ground, polished, and sliced crystals\nsuggests the existence of a length scale of order 100 $\\mu$, characterizing the\nhigher temperature superconducting phase.\n", "machine_text": "\nThe physical properties of a large single crystal of PrOs$_4$Sb$_{12}$, such as specific heat, dc- and ac-magnetic susceptibility, were studied and exhibited two distinct anomalies in the specific heat, as well as an overall discontinuity of more than 1000 mJ/K$^2$mol. The upper transition (at $T_{c1}$) showed a rounded shape, while the lower one, at $T_{c2}$, presented a very sharp anomaly. The magnetic susceptibility showed two peaks below $T_{c1}$, however, no signatures of the lower temperature transition were observed. It was discovered PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding and this suppression of the upper transition was observed in both the specific heat and magnetic susceptibility of the powdered sample, showing a decrease in $\\Delta C/T_{c}$ to 140 mJ/K$^2$ mol. Existing data on grinding, polishing, and slicing single crystals indicates the existence of a length scale of about 100 $\\mu$, imparticular for its higher temperature superconducting phase.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4659}
{"prompt": "Rephrase the abstract of an article with title 'Spectral study on the dips of Cir X-1'.\n  We present X-ray spectral analyses of low mass X-ray binary Cir X-1 during\nX-ray dips, using the Rossi X-ray Timing Explorer (RXTE) data. Each dip was\ndivided into several segments, and the spectrum of each segment was fitted with\na three-component blackbody model, in which two components are affected by\npartial covering and the third one is unaffected. A Gaussian emission line is\nalso included in the spectral model to represent the Fe Ka line at ~ 6.4 keV.\nThe fitted temperatures of the two partially covered components are about 2 keV\nand 1 keV, while the uncovered component has a temperature of ~ 0.5-0.6 keV.\nThe equivalent blackbody emission radius of the hottest component is the\nsmallest and that of the coolest component is the biggest. During dips, the\nfluxes of the two hot components are linearly correlated, while that of the\nthird component doesn't show any significant variation. The Fe line flux\nremains constant within errors during the short dips. However, during the long\ndips the line flux changes significantly and is positively correlated with the\nfluxes of the two hot components. These results suggest: (1) the temperature of\nthe X-ray emitting region decreases with radius, (2) the Fe Ka line emitting\nregion is close to the hot continuum emitting region, and (3) the size of the\nFe line emitting region is bigger than the size of the obscuring matters\ncausing short dips but smaller than the sizes of those causing long dips.\n\n", "human_text": "  We present X-ray spectral analyses of low mass X-ray binary Cir X-1 during\nX-ray dips, using the Rossi X-ray Timing Explorer (RXTE) data. Each dip was\ndivided into several segments, and the spectrum of each segment was fitted with\na three-component blackbody model, in which two components are affected by\npartial covering and the third one is unaffected. A Gaussian emission line is\nalso included in the spectral model to represent the Fe Ka line at ~ 6.4 keV.\nThe fitted temperatures of the two partially covered components are about 2 keV\nand 1 keV, while the uncovered component has a temperature of ~ 0.5-0.6 keV.\nThe equivalent blackbody emission radius of the hottest component is the\nsmallest and that of the coolest component is the biggest. During dips, the\nfluxes of the two hot components are linearly correlated, while that of the\nthird component doesn't show any significant variation. The Fe line flux\nremains constant within errors during the short dips. However, during the long\ndips the line flux changes significantly and is positively correlated with the\nfluxes of the two hot components. These results suggest: (1) the temperature of\nthe X-ray emitting region decreases with radius, (2) the Fe Ka line emitting\nregion is close to the hot continuum emitting region, and (3) the size of the\nFe line emitting region is bigger than the size of the obscuring matters\ncausing short dips but smaller than the sizes of those causing long dips.\n", "machine_text": "\nThis paper investigates the X-ray spectral features of the low-mass X-ray binary Cir X-1 during periods of immersion known as 'dips'. For each dip, multiple segments were analysed with a 3-component blackbody model - two of which are partially blocked by matter- with a Gaussian emission line included to represent the Fe Ka line of 6.4 keV. Results showed the steep temperature separation of 2 and 1 KeV between the two blocked components and the 0.5-0.6 KeV of the uncovered component. In addition, the fluxes of the two hotter components displayed linear correlation in dips, but no variation for the third component. Variation in the Fe Ka line flux was only present during long dips, having a positive relation with the hot fluxes. This suggests decreasing temperatures with radius; a close proximity of the Fe Ka line to the hot continuum; and a larger Fe Ka line than those of obscuring material causing the short dips, but smaller than the size of obscuring material responsible for long dips.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.401}
{"prompt": "Rephrase the abstract of an article with title 'Regularization of spherical and axisymmetric evolution codes in\n  numerical relativity'.\n  Several interesting astrophysical phenomena are symmetric with respect to the\nrotation axis, like the head-on collision of compact bodies, the collapse\nand/or accretion of fields with a large variety of geometries, or some forms of\ngravitational waves. Most current numerical relativity codes, however, can not\ntake advantage of these symmetries due to the fact that singularities in the\nadapted coordinates, either at the origin or at the axis of symmetry, rapidly\ncause the simulation to crash. Because of this regularity problem it has become\ncommon practice to use full-blown Cartesian three-dimensional codes to simulate\naxi-symmetric systems. In this work we follow a recent idea idea of Rinne and\nStewart and present a simple procedure to regularize the equations both in\nspherical and axi-symmetric spaces. We explicitly show the regularity of the\nevolution equations, describe the corresponding numerical code, and present\nseveral examples clearly showing the regularity of our evolutions.\n\n", "human_text": "  Several interesting astrophysical phenomena are symmetric with respect to the\nrotation axis, like the head-on collision of compact bodies, the collapse\nand/or accretion of fields with a large variety of geometries, or some forms of\ngravitational waves. Most current numerical relativity codes, however, can not\ntake advantage of these symmetries due to the fact that singularities in the\nadapted coordinates, either at the origin or at the axis of symmetry, rapidly\ncause the simulation to crash. Because of this regularity problem it has become\ncommon practice to use full-blown Cartesian three-dimensional codes to simulate\naxi-symmetric systems. In this work we follow a recent idea idea of Rinne and\nStewart and present a simple procedure to regularize the equations both in\nspherical and axi-symmetric spaces. We explicitly show the regularity of the\nevolution equations, describe the corresponding numerical code, and present\nseveral examples clearly showing the regularity of our evolutions.\n", "machine_text": "This paper considers the potential impact of regularizing numerical relativity codes that analyze spherical and axisymmetric mutations. We discuss the regularity issues resulting from using adapted coordinates to simulate axisymmetric systems, and elucidate a new approach proposed by Rinne and Stewart. We then demonstrate how this idea can be applied to regularize the equations both in spherical and axisymmetric spaces. To illustrate the regularity of our approaches, numerical codes and examples are provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0923}
{"prompt": "Rephrase the abstract of an article with title 'Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in\n  hypre and PETSc'.\n  We describe our software package Block Locally Optimal Preconditioned\nEigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as\na stand-alone serial library, as an external package to PETSc (``Portable,\nExtensible Toolkit for Scientific Computation'', a general purpose suite of\ntools for the scalable solution of partial differential equations and related\nproblems developed by Argonne National Laboratory), and is also built into {\\it\nhypre} (``High Performance Preconditioners'', scalable linear solvers package\ndeveloped by Lawrence Livermore National Laboratory). The present BLOPEX\nrelease includes only one solver--the Locally Optimal Block Preconditioned\nConjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it\nhypre} provides users with advanced high-quality parallel preconditioners for\nlinear systems, in particular, with domain decomposition and multigrid\npreconditioners. With BLOPEX, the same preconditioners can now be efficiently\nused for symmetric eigenvalue problems. PETSc facilitates the integration of\nindependently developed application modules with strict attention to component\ninteroperability, and makes BLOPEX extremely easy to compile and use with\npreconditioners that are available via PETSc. We present the LOBPCG algorithm\nin BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability\nof BLOPEX by testing it on a number of distributed and shared memory parallel\nsystems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron\nworkstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition\nand {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,\nthe standard 7-point finite-difference approximation of the 3-D Laplacian, with\nthe problem size in the range $10^5-10^8$.\n\n", "human_text": "  We describe our software package Block Locally Optimal Preconditioned\nEigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as\na stand-alone serial library, as an external package to PETSc (``Portable,\nExtensible Toolkit for Scientific Computation'', a general purpose suite of\ntools for the scalable solution of partial differential equations and related\nproblems developed by Argonne National Laboratory), and is also built into {\\it\nhypre} (``High Performance Preconditioners'', scalable linear solvers package\ndeveloped by Lawrence Livermore National Laboratory). The present BLOPEX\nrelease includes only one solver--the Locally Optimal Block Preconditioned\nConjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it\nhypre} provides users with advanced high-quality parallel preconditioners for\nlinear systems, in particular, with domain decomposition and multigrid\npreconditioners. With BLOPEX, the same preconditioners can now be efficiently\nused for symmetric eigenvalue problems. PETSc facilitates the integration of\nindependently developed application modules with strict attention to component\ninteroperability, and makes BLOPEX extremely easy to compile and use with\npreconditioners that are available via PETSc. We present the LOBPCG algorithm\nin BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability\nof BLOPEX by testing it on a number of distributed and shared memory parallel\nsystems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron\nworkstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition\nand {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,\nthe standard 7-point finite-difference approximation of the 3-D Laplacian, with\nthe problem size in the range $10^5-10^8$.\n", "machine_text": "We present the software package BLOPEX, which is available as a stand-alone serial library as well as an external package for PETSc and integrated into hypre. It includes the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) algorithm for symmetric eigenvalue problems. We demonstrate the scalability of BLOPEX by testing it on various distributed and shared memory computers which use PETSc domain decomposition and hypre multigrid preconditioners. We examine the performance of BLOPEX on the standard 7-point finite-difference approximation of the 3-D Laplacian with problem sizes ranging from $10^5$ to $10^8$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2626}
{"prompt": "Rephrase the abstract of an article with title 'Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity'.\n  A generalized geometric method is developed for constructing exact solutions\nof gravitational field equations in Einstein theory and generalizations. First,\nwe apply the formalism of nonholonomic frame deformations (formally considered\nfor nonholonomic manifolds and Finsler spaces) when the gravitational field\nequations transform into systems of nonlinear partial differential equations\nwhich can be integrated in general form. The new classes of solutions are\ndefined by generic off-diagonal metrics depending on integration functions on\none, two and three (or three and four) variables if we consider four (or five)\ndimensional spacetimes. Second, we use a general scheme when one (two)\nparameter families of exact solutions are defined by any source-free solutions\nof Einstein's equations with one (two) Killing vector field(s). A successive\niteration procedure results in new classes of solutions characterized by an\ninfinite number of parameters for a non-Abelian group involving arbitrary\nfunctions on one variable. Five classes of exact off-diagonal solutions are\nconstructed in vacuum Einstein and in string gravity describing solitonic\npp-wave interactions. We explore possible physical consequences of such\nsolutions derived from primary Schwarzschild or pp-wave metrics.\n\n", "human_text": "  A generalized geometric method is developed for constructing exact solutions\nof gravitational field equations in Einstein theory and generalizations. First,\nwe apply the formalism of nonholonomic frame deformations (formally considered\nfor nonholonomic manifolds and Finsler spaces) when the gravitational field\nequations transform into systems of nonlinear partial differential equations\nwhich can be integrated in general form. The new classes of solutions are\ndefined by generic off-diagonal metrics depending on integration functions on\none, two and three (or three and four) variables if we consider four (or five)\ndimensional spacetimes. Second, we use a general scheme when one (two)\nparameter families of exact solutions are defined by any source-free solutions\nof Einstein's equations with one (two) Killing vector field(s). A successive\niteration procedure results in new classes of solutions characterized by an\ninfinite number of parameters for a non-Abelian group involving arbitrary\nfunctions on one variable. Five classes of exact off-diagonal solutions are\nconstructed in vacuum Einstein and in string gravity describing solitonic\npp-wave interactions. We explore possible physical consequences of such\nsolutions derived from primary Schwarzschild or pp-wave metrics.\n", "machine_text": "\nIn this article, we develop a geometric approach to constructing exact solutions for gravity consisting of Einstein theory and its generalizations. Specifically, nonholonomic frame deformations are used to transform the gravitational field equations into sets of nonlinear partial differential equations which can be solved in general form. These solutions can be generically characterized by metrics depending on integration functions involving one, two, three, or four variables. Moreover, exact solutions with a parameter family may be obtained by source-free solutions of Einstein's equations with at least one Killing vector field. Additionally, a successive iteration procedure creates new classes of solutions specified by an infinite number of parameters with a non-Abelian group related to arbitrary functions of one variable. Finally, five classes of exact off-diagonal solutions are generated in vacuum Einstein and string gravity describing solitonic pp-wave interactions emerging from the primary Schwarzschild or pp-wave metrics. The potential physical implications of these solutions are also investigated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3986}
{"prompt": "Rephrase the abstract of an article with title 'Hypersurfaces in H^{n+1} and conformally invariant equations: the\n  generalized Christoffel and Nirenberg problems'.\n  Our first objective in this paper is to give a natural formulation of the\nChristoffel problem for hypersurfaces in $H^{n+1}$, by means of the hyperbolic\nGauss map and the notion of hyperbolic curvature radii for hypersurfaces. Our\nsecond objective is to provide an explicit equivalence of this Christoffel\nproblem with the famous problem of prescribing scalar curvature on $\\S^n$ for\nconformal metrics, posed by Nirenberg and Kazdan-Warner. This construction lets\nus translate into the hyperbolic setting the known results for the scalar\ncurvature problem, and also provides a hypersurface theory interpretation of\nsuch an intrinsic problem from conformal geometry. Our third objective is to\nplace the above result into a more general framework. Specifically, we will\nshow how the problem of prescribing the hyperbolic Gauss map and a given\nfunction of the hyperbolic curvature radii in $H^{n+1}$ is strongly related to\nsome important problems on conformally invariant PDEs in terms of the Schouten\ntensor. This provides a bridge between the theory of conformal metrics on\n$\\S^n$ and the theory of hypersurfaces with prescribed hyperbolic Gauss map in\n$\\H^{n+1}$. The fourth objective is to use the above correspondence to prove\nthat for a wide family of Weingarten functionals $W(\\k_1,..., \\k_n)$, the only\ncompact immersed hypersurfaces in $H^{n+1}$ on which $W$ is constant are round\nspheres.\n\n", "human_text": "  Our first objective in this paper is to give a natural formulation of the\nChristoffel problem for hypersurfaces in $H^{n+1}$, by means of the hyperbolic\nGauss map and the notion of hyperbolic curvature radii for hypersurfaces. Our\nsecond objective is to provide an explicit equivalence of this Christoffel\nproblem with the famous problem of prescribing scalar curvature on $\\S^n$ for\nconformal metrics, posed by Nirenberg and Kazdan-Warner. This construction lets\nus translate into the hyperbolic setting the known results for the scalar\ncurvature problem, and also provides a hypersurface theory interpretation of\nsuch an intrinsic problem from conformal geometry. Our third objective is to\nplace the above result into a more general framework. Specifically, we will\nshow how the problem of prescribing the hyperbolic Gauss map and a given\nfunction of the hyperbolic curvature radii in $H^{n+1}$ is strongly related to\nsome important problems on conformally invariant PDEs in terms of the Schouten\ntensor. This provides a bridge between the theory of conformal metrics on\n$\\S^n$ and the theory of hypersurfaces with prescribed hyperbolic Gauss map in\n$\\H^{n+1}$. The fourth objective is to use the above correspondence to prove\nthat for a wide family of Weingarten functionals $W(\\k_1,..., \\k_n)$, the only\ncompact immersed hypersurfaces in $H^{n+1}$ on which $W$ is constant are round\nspheres.\n", "machine_text": "In the present paper, we investigate the relationship between hypersurfaces in hyperbolic space $H^{n+1}$ and conformally invariant equations. Through a hyperbolic Gauss map and the notion of hyperbolic curvature radii,we formulate the Christoffel problem. This direct connection also allows us to make a direct comparison between the scalar curvature problem posed by Nirenberg and Kazdan-Warner on the $\\mathbb{S}^n$ manifold, and provide an insight into its hypersurface interpretation. Additionally, this serves as a bridge to link the theory of hypersurfaces with prescribed hyperbolic Gauss map in $H^{n+1}$ with some important problems in conformally invariant PDEs regarding the Schouten tensor. We further analyse this relationship to prove that certain Weingarten functionals are constant only on round spheres among all compactly immersed hypersurfaces in $H^{n+1}$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2314}
{"prompt": "Rephrase the abstract of an article with title 'Thermal Stability of Metallic Single-Walled Carbon Nanotubes: An O(N)\n  Tight-Binding Molecular Dynamics Simulation Study'.\n  Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to\ninvestigate the thermal stability of (10,10) metallic Single-Walled Carbon\nNanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial\ndirection. Velocity Verlet algorithm along with the canonical ensemble\nmolecular dynamics (NVT) is used to simulate the tubes at the targeted\ntemperatures. The effects of slow and rapid temperature increases on the\nphysical characteristics, structural stability and the energetics of the tube\nare investigated and compared. Simulations are carried out starting from room\ntemperature and the temperature is raised in steps of 300K. Stability of the\nsimulated metallic SWCNT is examined at each step before it is heated to higher\ntemperatures. First indication of structural deformation is observed at 600K.\nFor higher heat treatments the deformations are more pronounced and the bond\nbreaking temperature is reached around 2500K. Gradual (slow) heating and\nthermal equilibrium (fast heating) methods give the value of radial thermal\nexpansion coefficient in the temperature range between 300K-600K as\n0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both\nmethods give the same value of 0.089x10^{-5}(1/K). The ratio of the total\nenergy per atom with respect to temperature is found to be 3x10^{-4} eV/K.\n\n", "human_text": "  Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to\ninvestigate the thermal stability of (10,10) metallic Single-Walled Carbon\nNanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial\ndirection. Velocity Verlet algorithm along with the canonical ensemble\nmolecular dynamics (NVT) is used to simulate the tubes at the targeted\ntemperatures. The effects of slow and rapid temperature increases on the\nphysical characteristics, structural stability and the energetics of the tube\nare investigated and compared. Simulations are carried out starting from room\ntemperature and the temperature is raised in steps of 300K. Stability of the\nsimulated metallic SWCNT is examined at each step before it is heated to higher\ntemperatures. First indication of structural deformation is observed at 600K.\nFor higher heat treatments the deformations are more pronounced and the bond\nbreaking temperature is reached around 2500K. Gradual (slow) heating and\nthermal equilibrium (fast heating) methods give the value of radial thermal\nexpansion coefficient in the temperature range between 300K-600K as\n0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both\nmethods give the same value of 0.089x10^{-5}(1/K). The ratio of the total\nenergy per atom with respect to temperature is found to be 3x10^{-4} eV/K.\n", "machine_text": "\nUsing the Order(N) Tight-Binding Molecular Dynamics Simulation, the thermal stability of a (10,10) metallic Single-Walled Carbon Nanotube (SWCNT) is investigated. After applying the periodic boundary conditions (PBC) in axial direction and the Velocity Verlet algorithm along with the canonical ensemble molecular dynamics (NVT), simulations of the SWCNT were performed at increasing temperatures, starting from 300K and expanding in steps of 300K. The effects on the physical characteristics, structural stability, and energetics when the temperature was raised in both slow and rapid increments were studied. Signs of deformation occurred at 600K, while bond breaking was found at 2500K. Thermal expansion coefficient between 300K-600K was measured as 0.31 x 10^(-5) (1/K) when temperatures were increased slowly and 0.089 x 10^(-5) (1/K) when heated quickly and over 600K both methods yielded the same result. Additionally, a ratio of total energy per atom to temperature was obtained, of 3 x 10^(-4) eV/K.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1625}
{"prompt": "Rephrase the abstract of an article with title 'Matter density perturbations and effective gravitational constant in\n  modified gravity models of dark energy'.\n  We derive the equation of matter density perturbations on sub-horizon scales\nfor a general Lagrangian density f(R, phi, X) that is a function of a Ricci\nscalar R, a scalar field phi and a kinetic term X=-(nabla phi)^2/2. This is\nuseful to constrain modified gravity dark energy models from observations of\nlarge-scale structure and weak lensing. We obtain the solutions for the matter\nperturbation delta_m as well as the gravitational potential Phi for some\nanalytically solvable models. In a f(R) dark energy model with the Lagrangian\ndensity f(R)=alpha R^{1+m}-Lambda, the growth rates of perturbations exhibit\nnotable differences from those in the standard Einstein gravity unless m is\nvery close to 0. In scalar-tensor models with the Lagrangian density\nf=F(phi)R+2p(phi,X) we relate the models with coupled dark energy scenarios in\nthe Einstein frame and reproduce the equations of perturbations known in the\ncurrent literature by making a conformal transformation. We also estimate the\nevolution of perturbations in both Jordan and Einstein frames when the energy\nfraction of dark energy is constant during the matter-dominated epoch.\n\n", "human_text": "  We derive the equation of matter density perturbations on sub-horizon scales\nfor a general Lagrangian density f(R, phi, X) that is a function of a Ricci\nscalar R, a scalar field phi and a kinetic term X=-(nabla phi)^2/2. This is\nuseful to constrain modified gravity dark energy models from observations of\nlarge-scale structure and weak lensing. We obtain the solutions for the matter\nperturbation delta_m as well as the gravitational potential Phi for some\nanalytically solvable models. In a f(R) dark energy model with the Lagrangian\ndensity f(R)=alpha R^{1+m}-Lambda, the growth rates of perturbations exhibit\nnotable differences from those in the standard Einstein gravity unless m is\nvery close to 0. In scalar-tensor models with the Lagrangian density\nf=F(phi)R+2p(phi,X) we relate the models with coupled dark energy scenarios in\nthe Einstein frame and reproduce the equations of perturbations known in the\ncurrent literature by making a conformal transformation. We also estimate the\nevolution of perturbations in both Jordan and Einstein frames when the energy\nfraction of dark energy is constant during the matter-dominated epoch.\n", "machine_text": "\nWe present an investigation of matter density perturbations and the effective gravitational constant in modified gravity models of dark energy. The analysis focuses on the sub-horizon scales by deriving an equation from a general Lagrangian density depending on Ricci scalar R, a scalar field phi and a kinetic term X. This allows us to constraint potential observations of large-scale structure and weak lensing. We determine the matter perturbations, delta_m, and the gravitational potential Phi for a class of analytically solvable models, specifically a f(R) dark energy model with a Lagrangian density of alpha R^{1+m}-Lambda. Furthermore, scalar-tensor models with the Lagrangian density f=F(phi)R+2p(phi,X) are related to coupled dark energy scenarios in the Einstein frame, and a conformal transformation produces the same perturbations found within the current literature. Finally, we estimate the evolution of perturbations in both Jordan and Einstein frames when dark energy energy fraction is kept constant during the matter-dominated epoch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1032}
{"prompt": "Rephrase the abstract of an article with title 'Ab initio statistical mechanics of surface adsorption and desorption: I.\n  H$_2$O on MgO (001) at low coverage'.\n  We present a general computational scheme based on molecular dynamics (m.d.)\nsimulation for calculating the chemical potential of adsorbed molecules in\nthermal equilibrium on the surface of a material. The scheme is based on the\ncalculation of the mean force in m.d. simulations in which the height of a\nchosen molecule above the surface is constrained, and subsequent integration of\nthe mean force to obtain the potential of mean force and hence the chemical\npotential. The scheme is valid at any coverage and temperature, so that in\nprinciple it allows the calculation of the chemical potential as a function of\ncoverage and temperature. It avoids all statistical mechanical approximations,\nexcept for the use of classical statistical mechanics for the nuclei, and\nassumes nothing in advance about the adsorption sites. From the chemical\npotential, the absolute desorption rate of the molecules can be computed,\nprovided the equilibration rate on the surface is faster than the desorption\nrate. We apply the theory by {\\em ab initio} m.d. simulation to the case of\nH$_2$O on MgO (001) in the low-coverage limit, using the Perdew-Burke-Ernzerhof\n(PBE) form of exchange-correlation. The calculations yield an {\\em ab initio}\nvalue of the Polanyi-Wigner frequency prefactor, which is more than two orders\nof magnitude greater than the value of $10^{13}$ s$^{-1}$ often assumed in the\npast. Provisional comparison with experiment suggests that the PBE adsorption\nenergy may be too low, but the extension of the calculations to higher\ncoverages is needed before firm conclusions can be drawn. The possibility of\nincluding quantum nuclear effects by using path-integral simulations is noted.\n\n", "human_text": "  We present a general computational scheme based on molecular dynamics (m.d.)\nsimulation for calculating the chemical potential of adsorbed molecules in\nthermal equilibrium on the surface of a material. The scheme is based on the\ncalculation of the mean force in m.d. simulations in which the height of a\nchosen molecule above the surface is constrained, and subsequent integration of\nthe mean force to obtain the potential of mean force and hence the chemical\npotential. The scheme is valid at any coverage and temperature, so that in\nprinciple it allows the calculation of the chemical potential as a function of\ncoverage and temperature. It avoids all statistical mechanical approximations,\nexcept for the use of classical statistical mechanics for the nuclei, and\nassumes nothing in advance about the adsorption sites. From the chemical\npotential, the absolute desorption rate of the molecules can be computed,\nprovided the equilibration rate on the surface is faster than the desorption\nrate. We apply the theory by {\\em ab initio} m.d. simulation to the case of\nH$_2$O on MgO (001) in the low-coverage limit, using the Perdew-Burke-Ernzerhof\n(PBE) form of exchange-correlation. The calculations yield an {\\em ab initio}\nvalue of the Polanyi-Wigner frequency prefactor, which is more than two orders\nof magnitude greater than the value of $10^{13}$ s$^{-1}$ often assumed in the\npast. Provisional comparison with experiment suggests that the PBE adsorption\nenergy may be too low, but the extension of the calculations to higher\ncoverages is needed before firm conclusions can be drawn. The possibility of\nincluding quantum nuclear effects by using path-integral simulations is noted.\n", "machine_text": "This article introduces a computational approach, based on molecular dynamics (m.d.) simulations, for determining the chemical potential of molecules adsorbed onto solid surfaces. The method allows for the calculation of adsorption and desorption from any coverage and temperature without any pre-assumed statistical mechanics approximations of adsorption sites. To demonstrate the technique, ab initio m.d. simulations of H$_2$O on MgO (001) are performed at low coverage. Results suggest that the PBE exchange-correlation form accurately captures the adsorption energy, however this needs to be further tested by increasing coverage. Moreover, the Polanyi-Wigner frequency prefactor is found to be two orders of magnitude larger than typically assumed prior. In addition, the method allows for the incorporation of quantum nuclear effects via path-integral simulations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1}
{"prompt": "Rephrase the abstract of an article with title 'Dust Formation and He II 4686 emission in the Dense Shell of the\n  Peculiar Type Ib Supernova 2006jc'.\n  We present evidence for the formation of dust grains in an unusual Type Ib SN\nbased on late-time spectra of SN 2006jc. The progenitor suffered an LBV-like\noutburst just 2 yr earlier, and we propose that the dust formation is a\nconsequence of the SN blast wave overtaking that LBV-like shell. The key\nevidence for dust formation is (a) the appearance of a red/near-IR continuum\nsource fit by 1600 K graphite grains, and (b) fading of the redshifted sides of\nHe I emission lines, yielding progressively more asymmetric blueshifted lines\nas dust obscures receding material. This provides the strongest case yet for\ndust formation in any SN Ib/c. Both developments occurred between 51 and 75 d\nafter peak, while other SNe observed to form dust did so after a few hundred\ndays. Geometric considerations indicate that dust formed in the dense swept-up\nshell between the forward and reverse shocks, and not in the freely expanding\nSN ejecta. Rapid cooling leading to dust formation may have been aided by\nextremely high shell densities, as indicated by He I line ratios. The brief\nepoch of dust formation is accompanied by He II 4686 emission and enhanced\nX-ray emission. These clues suggest that the unusual dust formation in this\nobject was not due to properties of the SN itself, but instead -- like most\npeculiarities of SN 2006jc -- was a consequence of the dense environment\ncreated by an LBV-like eruption 2 yr before the SN.\n\n", "human_text": "  We present evidence for the formation of dust grains in an unusual Type Ib SN\nbased on late-time spectra of SN 2006jc. The progenitor suffered an LBV-like\noutburst just 2 yr earlier, and we propose that the dust formation is a\nconsequence of the SN blast wave overtaking that LBV-like shell. The key\nevidence for dust formation is (a) the appearance of a red/near-IR continuum\nsource fit by 1600 K graphite grains, and (b) fading of the redshifted sides of\nHe I emission lines, yielding progressively more asymmetric blueshifted lines\nas dust obscures receding material. This provides the strongest case yet for\ndust formation in any SN Ib/c. Both developments occurred between 51 and 75 d\nafter peak, while other SNe observed to form dust did so after a few hundred\ndays. Geometric considerations indicate that dust formed in the dense swept-up\nshell between the forward and reverse shocks, and not in the freely expanding\nSN ejecta. Rapid cooling leading to dust formation may have been aided by\nextremely high shell densities, as indicated by He I line ratios. The brief\nepoch of dust formation is accompanied by He II 4686 emission and enhanced\nX-ray emission. These clues suggest that the unusual dust formation in this\nobject was not due to properties of the SN itself, but instead -- like most\npeculiarities of SN 2006jc -- was a consequence of the dense environment\ncreated by an LBV-like eruption 2 yr before the SN.\n", "machine_text": "\nRecent spectroscopy of the peculiar Type Ib SN 2006jc reveals evidence that dust grains were formed in its aftermath. Our proposed explanation is that the SN blast wave crashing against the LBV-like shell expelled from the progenitor two years before, caused the formation of dust. This is strongly attested to by (a) the red/near-IR continuum that can be fitted by the presence of 1600 K graphite grains, and (b) progressive asymmetry in He I emission lines as the receding material gets obscured by the shroud of dust. This is the first convincing proof of dust formation in any SN Ib/c less than a hundred days after peak. Our calculations point to dust formation having taken place in the space between the forward and reverse shocks, where the swept-up shell is denser, rather than in the freely expanding SN ejecta. This is further supported by He I line ratios, He II 4686 emission, and increased X-ray radiation detected during the brief interval of dust formation. Ultimately, the uniqueness of the dust formation event in SN 2006jc can be attributed to the anomalous conditions in the environment at the time of the SN, brought about by the intense LBV-like eruption of its progenitor.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2249}
{"prompt": "Rephrase the abstract of an article with title 'Mass-to-light Ratio of Ly-alpha Emitters: Implications of Ly-alpha\n  Surveys at Redshifts z=5.7, 6.5, 7, and 8.8'.\n  Using a simple method to interpret the luminosity function of Ly-alpha\nemitters, we explore properties of Ly-alpha emitters from 5.7 < z < 8.8 with\nvarious assumptions about metallicity and stellar mass spectra. We constrain a\nmass-to-'observed' light ratio, M_h/L_band. For narrow-band surveys, L_band is\nsimply related to the intrinsic Ly-alpha luminosity with a survival fraction of\nLy-alpha photons, alpha_esc. The mass-to-'bolometric light', M_h/L_bol, can\nalso be deduced, once the metallicity and stellar mass spectrum are given. The\ninferred M_h/L_bol is more sensitive to metallicity than to the mass spectrum.\nWe find the following constraints on a mass-to-light ratio of Ly-alpha emitters\nfrom 5.7 < z < 7: (M_h/L_bol)(alpha_{esc}epsilon^{1/gamma})^{-1}=21-38, 14-26,\nand 9-17 for Z=0, 1/50, and 1 Z_sun, respectively, where epsilon is the 'duty\ncycle' of Ly-alpha emitters, and gamma ~ 2 is a local slope of the cumulative\nluminosity function. Only weak lower limits are obtained for z=8.8. Therefore,\nLy-alpha emitters are consistent with either starburst galaxies M_h/L_bol ~\n0.1-1 with a smaller Ly-alpha survival fraction, alpha_{esc}epsilon^{1/gamma}\n~0.01-0.05, or normal populations (M_h/L_bol ~ 10) if a good fraction of\nLy-alpha photons survived, alpha_{esc}epsilon^{1/gamma} ~ 0.5-1. We find no\nevidence for the end of reionization in the luminosity functions of Ly-alpha\nemitters discovered in the current Ly-alpha surveys, including recent discovery\nof one Ly-alpha emitter at z=7. The data are consistent with no evolution of\nintrinsic properties of Ly-alpha emitters or neutral fraction in the\nintergalactic medium up to z=7. No detection of sources at z=8.8 does not yield\na significant constraint yet. We also show that the lack of detection at z=8.8\ndoes not rule out the high-z galaxies being the origin of the excess NIRB.\n\n", "human_text": "  Using a simple method to interpret the luminosity function of Ly-alpha\nemitters, we explore properties of Ly-alpha emitters from 5.7 < z < 8.8 with\nvarious assumptions about metallicity and stellar mass spectra. We constrain a\nmass-to-'observed' light ratio, M_h/L_band. For narrow-band surveys, L_band is\nsimply related to the intrinsic Ly-alpha luminosity with a survival fraction of\nLy-alpha photons, alpha_esc. The mass-to-'bolometric light', M_h/L_bol, can\nalso be deduced, once the metallicity and stellar mass spectrum are given. The\ninferred M_h/L_bol is more sensitive to metallicity than to the mass spectrum.\nWe find the following constraints on a mass-to-light ratio of Ly-alpha emitters\nfrom 5.7 < z < 7: (M_h/L_bol)(alpha_{esc}epsilon^{1/gamma})^{-1}=21-38, 14-26,\nand 9-17 for Z=0, 1/50, and 1 Z_sun, respectively, where epsilon is the 'duty\ncycle' of Ly-alpha emitters, and gamma ~ 2 is a local slope of the cumulative\nluminosity function. Only weak lower limits are obtained for z=8.8. Therefore,\nLy-alpha emitters are consistent with either starburst galaxies M_h/L_bol ~\n0.1-1 with a smaller Ly-alpha survival fraction, alpha_{esc}epsilon^{1/gamma}\n~0.01-0.05, or normal populations (M_h/L_bol ~ 10) if a good fraction of\nLy-alpha photons survived, alpha_{esc}epsilon^{1/gamma} ~ 0.5-1. We find no\nevidence for the end of reionization in the luminosity functions of Ly-alpha\nemitters discovered in the current Ly-alpha surveys, including recent discovery\nof one Ly-alpha emitter at z=7. The data are consistent with no evolution of\nintrinsic properties of Ly-alpha emitters or neutral fraction in the\nintergalactic medium up to z=7. No detection of sources at z=8.8 does not yield\na significant constraint yet. We also show that the lack of detection at z=8.8\ndoes not rule out the high-z galaxies being the origin of the excess NIRB.\n", "machine_text": "\n\nWe present a method of analyzing luminosity functions of Ly-alpha emitters spanning a range of redshifts from 5.7 to 8.8, in order to demonstrate the constraints on their mass-to-light ratio (M_h/L_band). Our analysis shows that, when considering the survival fraction of Ly-alpha photons (alpha_esc) and the 'duty cycle' of emitters (epsilon), a ratio of M_h/L_bol of 21-38, 14-26, and 9-17 can be derived respectively for three different metallicity scenarios (Z = 0, 1/50, and 1 Z_sun). These results suggest that Ly-alpha emitters are either starburst galaxies, with M_h/L_bol values around 0.1-1 and smaller Ly-alpha survival allowing for alpha_escepsilon^(1/gamma) to be approximately 0.01-0.05, or normal populations, if it is assumed that a large percentage of Ly-alpha photons survived (alpha_escepsilon^(1/gamma) is 0.5-1). Our investigation reveals no strong evidence of reionization and/or evolution of Ly-alpha emitter properties found in recent Ly-alpha surveys, and the absence of sources at z=8.8 provides no significant constraints either. Nevertheless, the data is sufficient to imply that these sources could still be responsible for the observed excess NIRB.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1801}
{"prompt": "Rephrase the abstract of an article with title 'K-band Imaging of strong CaII-absorber host galaxies at z~1'.\n  We present K-band imaging of fields around 30 strong CaII absorption line\nsystems, at 0.7<z<1.1, three of which are confirmed Damped Lyman-alpha systems.\nA significant excess of galaxies is found within 6\"0 (~50kpc) from the absorber\nline-of-sight. The excess galaxies are preferentially luminous compared to the\npopulation of field galaxies. A model in which field galaxies possess a\nluminosity-dependent cross-section for CaII absorption of the form (L/L*)^0.7\nreproduces the observations well. The luminosity-dependent cross-section for\nthe CaII absorbers appears to be significantly stronger than the established\n(L/L*)^0.4 dependence for MgII absorbers. The associated galaxies lie at large\nphysical distances from the CaII-absorbing gas; we find a mean impact parameter\nof 24kpc (H0=70km\\s\\Mpc). Combined with the observed number density of CaII\nabsorbers the large physical separations result in an inferred filling factor\nof only ~10 per cent. The physical origin of the strong CaII absorption remains\nunclear, possible explanations vary from very extended disks of the luminous\ngalaxies to associated dwarf galaxy neighbours, remnants of outflows from the\nluminous galaxies, or tidal debris from cannibalism of smaller galaxies.\n\n", "human_text": "  We present K-band imaging of fields around 30 strong CaII absorption line\nsystems, at 0.7<z<1.1, three of which are confirmed Damped Lyman-alpha systems.\nA significant excess of galaxies is found within 6\"0 (~50kpc) from the absorber\nline-of-sight. The excess galaxies are preferentially luminous compared to the\npopulation of field galaxies. A model in which field galaxies possess a\nluminosity-dependent cross-section for CaII absorption of the form (L/L*)^0.7\nreproduces the observations well. The luminosity-dependent cross-section for\nthe CaII absorbers appears to be significantly stronger than the established\n(L/L*)^0.4 dependence for MgII absorbers. The associated galaxies lie at large\nphysical distances from the CaII-absorbing gas; we find a mean impact parameter\nof 24kpc (H0=70km\\s\\Mpc). Combined with the observed number density of CaII\nabsorbers the large physical separations result in an inferred filling factor\nof only ~10 per cent. The physical origin of the strong CaII absorption remains\nunclear, possible explanations vary from very extended disks of the luminous\ngalaxies to associated dwarf galaxy neighbours, remnants of outflows from the\nluminous galaxies, or tidal debris from cannibalism of smaller galaxies.\n", "machine_text": "We report K-band imaging of observed strong CaII absorption line systems in galaxies at redshifts of 0.7 to 1.1; three of these systems have been confirmed as Damped Lyman-alpha systems. Analysis of these fields reveals an abundance of luminous galaxies located within 50kpc from the line of sight of the absorbers, which contrasts to their prevalence in comparison with field galaxies. It appears that these galaxies have a luminosity-dependent cross-section that is stronger than the one established for MgII absorbers. The impact parameter of the galaxies associated with the absorbers is 24kpc, resulting in a filling factor of only 10%. It is difficult to discern the physical origin of this CaII absorption, but possibilities range from extended disks of luminous galaxies to outflows or tidal debris from smaller galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1355}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical non-axisymmetric instabilities in rotating relativistic stars'.\n  We present new results on dynamical instabilities in rapidly rotating\nneutron-stars. In particular, using numerical simulations in full General\nRelativity, we analyse the effects that the stellar compactness has on the\nthreshold for the onset of the dynamical bar-mode instability, as well as on\nthe appearance of other dynamical instabilities. By using an extrapolation\ntechnique developed and tested in our previous study [1], we explicitly\ndetermine the threshold for a wide range of compactnesses using four sequences\nof models of constant baryonic mass comprising a total of 59 stellar models.\nOur calculation of the threshold is in good agreement with the Newtonian\nprediction and improves the previous post-Newtonian estimates. In addition, we\nfind that for stars with sufficiently large mass and compactness, the m=3\ndeformation is the fastest growing one. For all of the models considered, the\nnon-axisymmetric instability is suppressed on a dynamical timescale with an m=1\ndeformation dominating the final stages of the instability. These results,\ntogether with those presented in [1], suggest that an m=1 deformation\nrepresents a general and late-time feature of non-axisymmetric dynamical\ninstabilities both in full General Relativity and in Newtonian gravity.\n\n", "human_text": "  We present new results on dynamical instabilities in rapidly rotating\nneutron-stars. In particular, using numerical simulations in full General\nRelativity, we analyse the effects that the stellar compactness has on the\nthreshold for the onset of the dynamical bar-mode instability, as well as on\nthe appearance of other dynamical instabilities. By using an extrapolation\ntechnique developed and tested in our previous study [1], we explicitly\ndetermine the threshold for a wide range of compactnesses using four sequences\nof models of constant baryonic mass comprising a total of 59 stellar models.\nOur calculation of the threshold is in good agreement with the Newtonian\nprediction and improves the previous post-Newtonian estimates. In addition, we\nfind that for stars with sufficiently large mass and compactness, the m=3\ndeformation is the fastest growing one. For all of the models considered, the\nnon-axisymmetric instability is suppressed on a dynamical timescale with an m=1\ndeformation dominating the final stages of the instability. These results,\ntogether with those presented in [1], suggest that an m=1 deformation\nrepresents a general and late-time feature of non-axisymmetric dynamical\ninstabilities both in full General Relativity and in Newtonian gravity.\n", "machine_text": "This study presents new findings on the effect of stellar compactness on the non-axisymmetric instabilities of rapidly rotating neutron stars, utilizing numerical simulations in full General Relativity. By extrapolating the results of a previous study, we determine a threshold for the onset of the bar-mode instability for 59 different star models. Our conclusions are in line with the Newtonian expectation and improve previous post-Newtonian estimates. Additionally, we discover that for very massive and compact stars, the fastest-growing deformation is the m=3 mode. We illustrate that further to the Newtonian speculation, an m=1 deformation is bound to be a widespread late-time feature of non-axisymmetric instabilities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1826}
{"prompt": "Rephrase the abstract of an article with title 'A noncommutative Bohnenblust-Spitzer identity for Rota-Baxter algebras\n  solves Bogoliubov's recursion'.\n  The Bogoliubov recursion is a particular procedure appearing in the process\nof renormalization in perturbative quantum field theory. It provides convergent\nexpressions for otherwise divergent integrals. We develop here a theory of\nfunctional identities for noncommutative Rota-Baxter algebras which is shown to\nencode, among others, this process in the context of Connes-Kreimer's Hopf\nalgebra of renormalization. Our results generalize the seminal Cartier-Rota\ntheory of classical Spitzer-type identities for commutative Rota-Baxter\nalgebras. In the classical, commutative, case, these identities can be\nunderstood as deriving from the theory of symmetric functions. Here, we show\nthat an analogous property holds for noncommutative Rota-Baxter algebras. That\nis, we show that functional identities in the noncommutative setting can be\nderived from the theory of noncommutative symmetric functions. Lie idempotents,\nand particularly the Dynkin idempotent play a crucial role in the process.\nTheir action on the pro-unipotent groups such as those of perturbative\nrenormalization is described in detail along the way.\n\n", "human_text": "  The Bogoliubov recursion is a particular procedure appearing in the process\nof renormalization in perturbative quantum field theory. It provides convergent\nexpressions for otherwise divergent integrals. We develop here a theory of\nfunctional identities for noncommutative Rota-Baxter algebras which is shown to\nencode, among others, this process in the context of Connes-Kreimer's Hopf\nalgebra of renormalization. Our results generalize the seminal Cartier-Rota\ntheory of classical Spitzer-type identities for commutative Rota-Baxter\nalgebras. In the classical, commutative, case, these identities can be\nunderstood as deriving from the theory of symmetric functions. Here, we show\nthat an analogous property holds for noncommutative Rota-Baxter algebras. That\nis, we show that functional identities in the noncommutative setting can be\nderived from the theory of noncommutative symmetric functions. Lie idempotents,\nand particularly the Dynkin idempotent play a crucial role in the process.\nTheir action on the pro-unipotent groups such as those of perturbative\nrenormalization is described in detail along the way.\n", "machine_text": "We explore the implications of a noncommutative version of the classic Bohnenblust-Spitzer identity for Rota-Baxter algebras, which encompasses the process of renormalization as found in Connes-Kreimer's Hopf algebra of renormalization. We show that, in a manner analogous to how the commutative setting relies on the theory of symmetric functions, the noncommutative setting has functional identities which derive from the theory of noncommutative symmetric functions. The key role played by the Lie Idempotents, with special attention to the Dynkin Idempotent and the perturbative renormalization pro-unipotent groups, are discussed at length.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1265}
{"prompt": "Rephrase the abstract of an article with title 'Solar-like oscillations in the metal-poor subgiant nu Indi: II. Acoustic\n  spectrum and mode lifetime'.\n  Convection in stars excites resonant acoustic waves which depend on the sound\nspeed inside the star, which in turn depends on properties of the stellar\ninterior. Therefore, asteroseismology is an unrivaled method to probe the\ninternal structure of a star. We made a seismic study of the metal-poor\nsubgiant star nu Indi with the goal of constraining its interior structure. Our\nstudy is based on a time series of 1201 radial velocity measurements spread\nover 14 nights obtained from two sites, Siding Spring Observatory in Australia\nand ESO La Silla Observatory in Chile. The power spectrum of the high precision\nvelocity time series clearly presents several identifiable peaks between 200\nand 500 uHz showing regularity with a large and small spacing of 25.14 +- 0.09\nuHz and 2.96 +- 0.22 uHz at 330 uHz. Thirteen individual modes have been\nidentified with amplitudes in the range 53 to 173 cm/s. The mode damping time\nis estimated to be about 16 days (1-sigma range between 9 and 50 days),\nsubstantially longer than in other stars like the Sun, the alpha Cen system or\nthe giant xi Hya.\n\n", "human_text": "  Convection in stars excites resonant acoustic waves which depend on the sound\nspeed inside the star, which in turn depends on properties of the stellar\ninterior. Therefore, asteroseismology is an unrivaled method to probe the\ninternal structure of a star. We made a seismic study of the metal-poor\nsubgiant star nu Indi with the goal of constraining its interior structure. Our\nstudy is based on a time series of 1201 radial velocity measurements spread\nover 14 nights obtained from two sites, Siding Spring Observatory in Australia\nand ESO La Silla Observatory in Chile. The power spectrum of the high precision\nvelocity time series clearly presents several identifiable peaks between 200\nand 500 uHz showing regularity with a large and small spacing of 25.14 +- 0.09\nuHz and 2.96 +- 0.22 uHz at 330 uHz. Thirteen individual modes have been\nidentified with amplitudes in the range 53 to 173 cm/s. The mode damping time\nis estimated to be about 16 days (1-sigma range between 9 and 50 days),\nsubstantially longer than in other stars like the Sun, the alpha Cen system or\nthe giant xi Hya.\n", "machine_text": "\nAsteroseismology is a powerful tool for understanding the internal structures of stars by measuring the oscillations caused by convection. This study examined nu Indi, a metal-poor subgiant star, to better familiarize ourselves with its interior. Using a time series of 1201 radial velocity measurements, taken over 14 nights at Siding Spring Observatory in Australia and ESO La Silla Observatory in Chile, we identified 13 individual oscillations with amplitudes ranging from 53 to 173 cm/s. The regularity of the oscillations was quickly evident, with a large and small spacing of 25.14 +- 0.09 uHz and 2.96 +- 0.22 uHz at 330 uHz. Additionally, the mode damping time was calculated to be about 16 days, with a 1-sigma range of between 9 and 50 days, significantly higher than that of other stars such as the Sun or alpha Cen.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0795}
{"prompt": "Rephrase the abstract of an article with title 'Graph state generation with noisy mirror-inverting spin chains'.\n  We investigate the influence of noise on a graph state generation scheme\nwhich exploits a mirror inverting spin chain. Within this scheme the spin chain\nis used repeatedly as an entanglement bus (EB) to create multi-partite\nentanglement. The noise model we consider comprises of each spin of this EB\nbeing exposed to independent local noise which degrades the capabilities of the\nEB. Here we concentrate on quantifying its performance as a single-qubit\nchannel and as a mediator of a two-qubit entangling gate, since these are basic\noperations necessary for graph state generation using the EB. In particular,\nfor the single-qubit case we numerically calculate the average channel fidelity\nand whether the channel becomes entanglement breaking, i.e., expunges any\nentanglement the transferred qubit may have with other external qubits. We find\nthat neither local decay nor dephasing noise cause entanglement breaking. This\nis in contrast to local thermal and depolarizing noise where we determine a\ncritical length and critical noise coupling, respectively, at which\nentanglement breaking occurs. The critical noise coupling for local\ndepolarizing noise is found to exhibit a power-law dependence on the chain\nlength. For two qubits we similarly compute the average gate fidelity and\nwhether the ability for this gate to create entanglement is maintained. The\nconcatenation of these noisy gates for the construction of a five qubit linear\ncluster state and a Greenberger-Horne-Zeilinger state indicates that the level\nof noise that can be tolerated for graph state generation is tightly\nconstrained.\n\n", "human_text": "  We investigate the influence of noise on a graph state generation scheme\nwhich exploits a mirror inverting spin chain. Within this scheme the spin chain\nis used repeatedly as an entanglement bus (EB) to create multi-partite\nentanglement. The noise model we consider comprises of each spin of this EB\nbeing exposed to independent local noise which degrades the capabilities of the\nEB. Here we concentrate on quantifying its performance as a single-qubit\nchannel and as a mediator of a two-qubit entangling gate, since these are basic\noperations necessary for graph state generation using the EB. In particular,\nfor the single-qubit case we numerically calculate the average channel fidelity\nand whether the channel becomes entanglement breaking, i.e., expunges any\nentanglement the transferred qubit may have with other external qubits. We find\nthat neither local decay nor dephasing noise cause entanglement breaking. This\nis in contrast to local thermal and depolarizing noise where we determine a\ncritical length and critical noise coupling, respectively, at which\nentanglement breaking occurs. The critical noise coupling for local\ndepolarizing noise is found to exhibit a power-law dependence on the chain\nlength. For two qubits we similarly compute the average gate fidelity and\nwhether the ability for this gate to create entanglement is maintained. The\nconcatenation of these noisy gates for the construction of a five qubit linear\ncluster state and a Greenberger-Horne-Zeilinger state indicates that the level\nof noise that can be tolerated for graph state generation is tightly\nconstrained.\n", "machine_text": "\nIn this work, we explore the consequences of introducing noise onto a proposed graph state generation scheme based on a mirror inverting spin chain. To measure the performance of this chain as a quantum processor, we calculate the average channel fidelity for single qubits, and the average gate fidelity for two-qubit entangling operations. We also evaluate whether these operations maintain the entangling capabilities and become entanglement breaking when exposed to local decaying, dephasing, thermal, and depolarizing noise. Surprisingly, we find that local decay and dephasing noise do not induce entanglement breaking. However, thermal and depolarizing noise are found to lead to a critical length and critical noise coupling respectively, beyond which entanglement breaking occurs. The critical noise coupling for local depolarizing noise is also observed to exhibit a power-law dependence as a function of chain length. In addition, the average gate fidelity of a constructed five qubit linear cluster state and a Greenberger-Horne-Zeilinger state suggest that the noise tolerated for graph state generation is limiting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3584}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of interstellar dust and stardust in the solar neighbourhood'.\n  The abundance evolution of interstellar dust species originating from stellar\nsources and from condensation in molecular clouds in the local interstellar\nmedium of the Milky Way is studied and the input of dust material to the Solar\nSystem is determined. A one-zone chemical evolution model of the Milky Way for\nthe elemental composition of the disk combined with an evolution model for its\ninterstellar dust component similar to that of Dwek (1998) is developed. The\ndust model considers dust-mass return from AGB stars as calculated from\nsynthetic AGB models combined with models for dust condensation in stellar\noutflows. Supernova dust formation is included in a simple parameterized form\nwhich is gauged by observed abundances of presolar dust grains with supernova\norigin. For dust growth in the ISM a simple method is developed for coupling\nthis with disk and dust evolution models. The time evolution of the abundance\nof the following dust species is followed in the model: silicate, carbon,\nsilicon carbide, and iron dust from AGB stars and from SNe as well as silicate,\ncarbon, and iron dust grown in molecular clouds. It is shown that the\ninterstellar dust population is dominated by dust accreted in molecular clouds;\nmost of the dust material entering the Solar System at its formation does not\nshow isotopic abundance anomalies of the refractory elements, i.e.,\ninconspicuous isotopic abundances do not point to a Solar System origin of dust\ngrains. The observed abundance ratios of presolar dust grains formed in SN\nejecta and in AGB star outflows requires that for the ejecta from SNe the\nfraction of refractory elements condensed into dust is 0.15 for carbon dust and\nis quite small ($\\sim10^{-4}$) for other dust species.\n\n", "human_text": "  The abundance evolution of interstellar dust species originating from stellar\nsources and from condensation in molecular clouds in the local interstellar\nmedium of the Milky Way is studied and the input of dust material to the Solar\nSystem is determined. A one-zone chemical evolution model of the Milky Way for\nthe elemental composition of the disk combined with an evolution model for its\ninterstellar dust component similar to that of Dwek (1998) is developed. The\ndust model considers dust-mass return from AGB stars as calculated from\nsynthetic AGB models combined with models for dust condensation in stellar\noutflows. Supernova dust formation is included in a simple parameterized form\nwhich is gauged by observed abundances of presolar dust grains with supernova\norigin. For dust growth in the ISM a simple method is developed for coupling\nthis with disk and dust evolution models. The time evolution of the abundance\nof the following dust species is followed in the model: silicate, carbon,\nsilicon carbide, and iron dust from AGB stars and from SNe as well as silicate,\ncarbon, and iron dust grown in molecular clouds. It is shown that the\ninterstellar dust population is dominated by dust accreted in molecular clouds;\nmost of the dust material entering the Solar System at its formation does not\nshow isotopic abundance anomalies of the refractory elements, i.e.,\ninconspicuous isotopic abundances do not point to a Solar System origin of dust\ngrains. The observed abundance ratios of presolar dust grains formed in SN\nejecta and in AGB star outflows requires that for the ejecta from SNe the\nfraction of refractory elements condensed into dust is 0.15 for carbon dust and\nis quite small ($\\sim10^{-4}$) for other dust species.\n", "machine_text": "\nThis paper develops a model of chemical evolution in the Milky Way disk that combines the elemental composition of its interstellar medium with a one-zone dust component similar to that proposed by Dwek (1998). It examines the abundance of various dust species including silicate, carbon, silicate carbide, and iron dust from stars including asymptotic giant branch stars and supernova, as well as dust grown in molecular clouds. The results demonstrate that the dust population of the interstellar medium is primarily composed of this material accreted in molecular clouds. It is found that the dust which form the Solar System yields insignificant isotopic abundance anomalies of the refractory elements, indicating that most of the dust is not a product of the Solar System's own formation. The observed abundance ratios of presolar dust grains suggest that the fraction of refractory elements condensed into dust is about 0.15 for carbon dust and very small for most other dust species.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1155}
{"prompt": "Rephrase the abstract of an article with title 'The tensor part of the Skyrme energy density functional. I. Spherical\n  nuclei'.\n  We perform a systematic study of the impact of the J^2 tensor term in the\nSkyrme energy functional on properties of spherical nuclei. In the Skyrme\nenergy functional, the tensor terms originate both from zero-range central and\ntensor forces. We build a set of 36 parameterizations, which covers a wide\nrange of the parameter space of the isoscalar and isovector tensor term\ncoupling constants, with a fit protocol very similar to that of the successful\nSLy parameterizations. We analyze the impact of the tensor terms on a large\nvariety of observables in spherical mean-field calculations, such as the\nspin-orbit splittings and single-particle spectra of doubly-magic nuclei, the\nevolution of spin-orbit splittings along chains of semi-magic nuclei, mass\nresiduals of spherical nuclei, and known anomalies of charge radii. Our main\nconclusion is that the currently used central and spin-orbit parts of the\nSkyrme energy density functional are not flexible enough to allow for the\npresence of large tensor terms.\n\n", "human_text": "  We perform a systematic study of the impact of the J^2 tensor term in the\nSkyrme energy functional on properties of spherical nuclei. In the Skyrme\nenergy functional, the tensor terms originate both from zero-range central and\ntensor forces. We build a set of 36 parameterizations, which covers a wide\nrange of the parameter space of the isoscalar and isovector tensor term\ncoupling constants, with a fit protocol very similar to that of the successful\nSLy parameterizations. We analyze the impact of the tensor terms on a large\nvariety of observables in spherical mean-field calculations, such as the\nspin-orbit splittings and single-particle spectra of doubly-magic nuclei, the\nevolution of spin-orbit splittings along chains of semi-magic nuclei, mass\nresiduals of spherical nuclei, and known anomalies of charge radii. Our main\nconclusion is that the currently used central and spin-orbit parts of the\nSkyrme energy density functional are not flexible enough to allow for the\npresence of large tensor terms.\n", "machine_text": "\nThis paper conducts an evaluation of how the J^2 tensor component affects the effects of the Skyrme energy density functional on properties of spherical nuclei. We develop a set of 36 parameterizations, using a fitting process near identical to the successful SLy parameterizations, by considering the effects of isoscalar and isovector tensor term coupling constants. We measure the influence of the tensor terms on shape of spin-orbit splittings and single-particle spectrums of doubly-magic nuclei, shifts in spin-orbit splittings in sequences of semi-magic nuclei, mass anomalies of spherical nuclei, and noticeable inconsistencies in charge radii. Our ultimate realization is that the central and spin-orbit components of the Skyrme energy density functional are not flexible enough to permit for larger tensor terms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0731}
{"prompt": "Rephrase the abstract of an article with title 'Statistical Mechanics of Nonlinear On-line Learning for Ensemble\n  Teachers'.\n  We analyze the generalization performance of a student in a model composed of\nnonlinear perceptrons: a true teacher, ensemble teachers, and the student. We\ncalculate the generalization error of the student analytically or numerically\nusing statistical mechanics in the framework of on-line learning. We treat two\nwell-known learning rules: Hebbian learning and perceptron learning. As a\nresult, it is proven that the nonlinear model shows qualitatively different\nbehaviors from the linear model. Moreover, it is clarified that Hebbian\nlearning and perceptron learning show qualitatively different behaviors from\neach other. In Hebbian learning, we can analytically obtain the solutions. In\nthis case, the generalization error monotonically decreases. The steady value\nof the generalization error is independent of the learning rate. The larger the\nnumber of teachers is and the more variety the ensemble teachers have, the\nsmaller the generalization error is. In perceptron learning, we have to\nnumerically obtain the solutions. In this case, the dynamical behaviors of the\ngeneralization error are non-monotonic. The smaller the learning rate is, the\nlarger the number of teachers is; and the more variety the ensemble teachers\nhave, the smaller the minimum value of the generalization error is.\n\n", "human_text": "  We analyze the generalization performance of a student in a model composed of\nnonlinear perceptrons: a true teacher, ensemble teachers, and the student. We\ncalculate the generalization error of the student analytically or numerically\nusing statistical mechanics in the framework of on-line learning. We treat two\nwell-known learning rules: Hebbian learning and perceptron learning. As a\nresult, it is proven that the nonlinear model shows qualitatively different\nbehaviors from the linear model. Moreover, it is clarified that Hebbian\nlearning and perceptron learning show qualitatively different behaviors from\neach other. In Hebbian learning, we can analytically obtain the solutions. In\nthis case, the generalization error monotonically decreases. The steady value\nof the generalization error is independent of the learning rate. The larger the\nnumber of teachers is and the more variety the ensemble teachers have, the\nsmaller the generalization error is. In perceptron learning, we have to\nnumerically obtain the solutions. In this case, the dynamical behaviors of the\ngeneralization error are non-monotonic. The smaller the learning rate is, the\nlarger the number of teachers is; and the more variety the ensemble teachers\nhave, the smaller the minimum value of the generalization error is.\n", "machine_text": "\nIn this article, we examine the generalization capability of a learner composed of non-linear perceptrons, including a 'true teacher', ensemble teachers, and student. Utilizing the framework of on-line learning, statistical mechanics are used to numerically and analytically identify the student's generalization error. We investigate two major learning rules, Hebbian learning and Perceptron learning, and distinguish them as having fundamentally different behavior from the study of linear models. Applying Hebbian learning, solutions can be obtained analytically, with the generalization error steadily diminishing until it reaches a predetermined steady value that does not vary with changes to the learning rate. The accuracy of the model is found to be inversely proportional to the number of teachers, but increases with the variety of the ensemble teachers. For Perceptron learning, numerical solutions must be obtained, and the results of the model display dynamic non-monotonic behavior. Here, modifying the learning rate will have an inverse effect on the minimum value of the generalization error, but is determined instead by the number of teachers, and the variety of the ensemble teachers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2318}
{"prompt": "Rephrase the abstract of an article with title 'On the Connection between Mass Loss and Evolution of C-rich AGB stars'.\n  The mass loss properties of carbon AGB stars are not very well constrained at\npresent. A variety of empirical or theoretical formulae with different\nparameterisations are available in the literature and the agreement between\nthem is anything but good. These simple mass loss prescriptions are nontheless\nused in many models of stellar evolution without much consideration of their\napplicability in various cases. We present here an on-going project aiming at a\nbetter description of the mass loss, that could be used to improve stellar\nevolution models -- especially the evolution during the TP-AGB phase. As a\nfirst step, we have considered the mass loss evolution during a He-shell flash.\nUsing stellar parameters sampled from a stellar evolutionary track, we have\ncomputed the time evolution of the atmospheric layers and wind acceleration\nregion during a flash event with detailed frequency-dependent\nradiation-hydrodynamical models including dust formation. Based on these\nresults, we have also simulated the subsequent long-term dynamical evolution of\nthe circumstellar envelope (CSE), including the formation of a detached shell.\nWe find that existing simple mass loss prescriptions imply different mass loss\nevolutions compared with our model. The second step of the project deals with\nthe dependence of mass loss on the basic stellar parameters. At the moment we\nare computing a large grid of wind models for C-rich AGB stars. Preliminary\nresults show that simple parameterisations are difficult to obtain in certain\nregions of the parameter space considered, due to strong non-linearities in the\nwind mechanism.\n\n", "human_text": "  The mass loss properties of carbon AGB stars are not very well constrained at\npresent. A variety of empirical or theoretical formulae with different\nparameterisations are available in the literature and the agreement between\nthem is anything but good. These simple mass loss prescriptions are nontheless\nused in many models of stellar evolution without much consideration of their\napplicability in various cases. We present here an on-going project aiming at a\nbetter description of the mass loss, that could be used to improve stellar\nevolution models -- especially the evolution during the TP-AGB phase. As a\nfirst step, we have considered the mass loss evolution during a He-shell flash.\nUsing stellar parameters sampled from a stellar evolutionary track, we have\ncomputed the time evolution of the atmospheric layers and wind acceleration\nregion during a flash event with detailed frequency-dependent\nradiation-hydrodynamical models including dust formation. Based on these\nresults, we have also simulated the subsequent long-term dynamical evolution of\nthe circumstellar envelope (CSE), including the formation of a detached shell.\nWe find that existing simple mass loss prescriptions imply different mass loss\nevolutions compared with our model. The second step of the project deals with\nthe dependence of mass loss on the basic stellar parameters. At the moment we\nare computing a large grid of wind models for C-rich AGB stars. Preliminary\nresults show that simple parameterisations are difficult to obtain in certain\nregions of the parameter space considered, due to strong non-linearities in the\nwind mechanism.\n", "machine_text": "\nIn this paper, we explore how the mass loss from C-rich AGB stars depends on their evolutionary stage. We consider the mass loss evolution during He-shell flashes and the subsequent long-term dynamical evolution of the circumstellar envelope. Our analysis uses detailed frequency-dependent radiation-hydrodynamical models for the flash event and circumstellar envelope, which include dust formation. We discover that existing simple formulae for mass loss do not match the findings of our models. Next, we are calculating a grid of wind models to observe how mass loss depends on the stellar parameters. Early results show that it is not possible to make simple parameterisations due to the irregularity of the wind mechanism in certain regions of parameter space. Ultimately, our goal is to improve stellar evolution models, in particular the TP-AGB phase, with an improved description of mass loss.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2315}
{"prompt": "Rephrase the abstract of an article with title 'Shrinking binary and planetary orbits by Kozai cycles with tidal\n  friction'.\n  At least two arguments suggest that the orbits of a large fraction of binary\nstars and extrasolar planets shrank by 1-2 orders of magnitude after formation:\n(i) the physical radius of a star shrinks by a large factor from birth to the\nmain sequence, yet many main-sequence stars have companions orbiting only a few\nstellar radii away, and (ii) in current theories of planet formation, the\nregion within ~0.1 AU of a protostar is too hot and rarefied for a Jupiter-mass\nplanet to form, yet many \"hot Jupiters\" are observed at such distances. We\ninvestigate orbital shrinkage by the combined effects of secular perturbations\nfrom a distant companion star (Kozai oscillations) and tidal friction. We\nintegrate the relevant equations of motion to predict the distribution of\norbital elements produced by this process. Binary stars with orbital periods of\n0.1 to 10 days, with a median of ~2 d, are produced from binaries with much\nlonger periods (10 d to 10^5 d), consistent with observations indicating that\nmost or all short-period binaries have distant companions (tertiaries). We also\nmake two new testable predictions: (1) For periods between 3 and 10 d, the\ndistribution of the mutual inclination between the inner binary and the\ntertiary orbit should peak strongly near 40 deg and 140 deg. (2) Extrasolar\nplanets whose host stars have a distant binary companion may also undergo this\nprocess, in which case the orbit of the resulting hot Jupiter will typically be\nmisaligned with the equator of its host star.\n\n", "human_text": "  At least two arguments suggest that the orbits of a large fraction of binary\nstars and extrasolar planets shrank by 1-2 orders of magnitude after formation:\n(i) the physical radius of a star shrinks by a large factor from birth to the\nmain sequence, yet many main-sequence stars have companions orbiting only a few\nstellar radii away, and (ii) in current theories of planet formation, the\nregion within ~0.1 AU of a protostar is too hot and rarefied for a Jupiter-mass\nplanet to form, yet many \"hot Jupiters\" are observed at such distances. We\ninvestigate orbital shrinkage by the combined effects of secular perturbations\nfrom a distant companion star (Kozai oscillations) and tidal friction. We\nintegrate the relevant equations of motion to predict the distribution of\norbital elements produced by this process. Binary stars with orbital periods of\n0.1 to 10 days, with a median of ~2 d, are produced from binaries with much\nlonger periods (10 d to 10^5 d), consistent with observations indicating that\nmost or all short-period binaries have distant companions (tertiaries). We also\nmake two new testable predictions: (1) For periods between 3 and 10 d, the\ndistribution of the mutual inclination between the inner binary and the\ntertiary orbit should peak strongly near 40 deg and 140 deg. (2) Extrasolar\nplanets whose host stars have a distant binary companion may also undergo this\nprocess, in which case the orbit of the resulting hot Jupiter will typically be\nmisaligned with the equator of its host star.\n", "machine_text": "This article examines the possibility that binary stars and extrasolar planets experience shrinking orbits by 1-2 orders of magnitude after formation. It suggests that this could be caused by the combined actions of Kozai cycles and tidal friction. To test this hypothesis, the equations of motion were integrated in order to determine the range of orbital elements. It was found that systems with an initial period of 10 days to 10^5 days could produce binaries with periods of 0.1 to 10 days; the majority of these being 2 days. Additionally, two testable predictions were made: (1) For periods between 3 and 10 days, there should be a peak in the distribution of the mutual inclination of the inner binary and tertiary orbits near 40 and 140 degrees. (2) In cases where the host star has a distant binary companion, the resulting hot Jupiter is likely to have an orbit misaligned with the equator of its host star.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4285}
{"prompt": "Rephrase the abstract of an article with title 'Long-Term Evolution of Massive Black Hole Binaries. III. Binary\n  Evolution in Collisional Nuclei'.\n  [Abridged] In galactic nuclei with sufficiently short relaxation times,\nbinary supermassive black holes can evolve beyond their stalling radii via\ncontinued interaction with stars. We study this \"collisional\" evolutionary\nregime using both fully self-consistent N-body integrations and approximate\nFokker-Planck models. The N-body integrations employ particle numbers up to\n0.26M and a direct-summation potential solver; close interactions involving the\nbinary are treated using a new implementation of the Mikkola-Aarseth chain\nregularization algorithm. Even at these large values of N, two-body scattering\noccurs at high enough rates in the simulations that they can not be simply\nscaled to the large-N regime of real galaxies. The Fokker-Planck model is used\nto bridge this gap; it includes, for the first time, binary-induced changes in\nthe stellar density and potential. The Fokker-Planck model is shown to\naccurately reproduce the results of the N-body integrations, and is then\nextended to the much larger N regime of real galaxies. Analytic expressions are\nderived that accurately reproduce the time dependence of the binary semi-major\naxis as predicted by the Fokker-Planck model. Gravitational wave coalescence is\nshown to occur in <10 Gyr in nuclei with velocity dispersions below about 80\nkm/s. Formation of a core results from a competition between ejection of stars\nby the binary and re-supply of depleted orbits via two-body scattering. Mass\ndeficits as large as ~4 times the binary mass are produced before coalescence.\nAfter the two black holes coalesce, a Bahcall-Wolf cusp appears around the\nsingle hole in one relaxation time, resulting in a nuclear density profile\nconsisting of a flat core with an inner, compact cluster, similar to what is\nobserved at the centers of low-luminosity spheroids.\n\n", "human_text": "  [Abridged] In galactic nuclei with sufficiently short relaxation times,\nbinary supermassive black holes can evolve beyond their stalling radii via\ncontinued interaction with stars. We study this \"collisional\" evolutionary\nregime using both fully self-consistent N-body integrations and approximate\nFokker-Planck models. The N-body integrations employ particle numbers up to\n0.26M and a direct-summation potential solver; close interactions involving the\nbinary are treated using a new implementation of the Mikkola-Aarseth chain\nregularization algorithm. Even at these large values of N, two-body scattering\noccurs at high enough rates in the simulations that they can not be simply\nscaled to the large-N regime of real galaxies. The Fokker-Planck model is used\nto bridge this gap; it includes, for the first time, binary-induced changes in\nthe stellar density and potential. The Fokker-Planck model is shown to\naccurately reproduce the results of the N-body integrations, and is then\nextended to the much larger N regime of real galaxies. Analytic expressions are\nderived that accurately reproduce the time dependence of the binary semi-major\naxis as predicted by the Fokker-Planck model. Gravitational wave coalescence is\nshown to occur in <10 Gyr in nuclei with velocity dispersions below about 80\nkm/s. Formation of a core results from a competition between ejection of stars\nby the binary and re-supply of depleted orbits via two-body scattering. Mass\ndeficits as large as ~4 times the binary mass are produced before coalescence.\nAfter the two black holes coalesce, a Bahcall-Wolf cusp appears around the\nsingle hole in one relaxation time, resulting in a nuclear density profile\nconsisting of a flat core with an inner, compact cluster, similar to what is\nobserved at the centers of low-luminosity spheroids.\n", "machine_text": "\nThis paper examines the long-term evolution of supermassive black hole binaries in galactic nuclei with short relaxation times, where the binary is able to progress beyond its stalling point via continued interactions with stars. The study was performed using robust N-body integrations and a novel Fokker-Planck model, which considers binary-induced changes in stellar density. Results indicate that gravitational wave coalescence is likely to occur within 10 Gyr in nuclei with velocity dispersions below 80 km/s, resulting in a density profile of a flat core containing an inner, compact cluster. Moreover, mass deficits up to 4x the binary mass can form prior to coalescence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2745}
{"prompt": "Rephrase the abstract of an article with title 'Variation of fundamental constants: theory and observations'.\n  Review of recent works devoted to the variation of the fundamental constants\nis presented including atomic clocks, quasar absorption spectra, and Oklo\nnatural nuclear reactor data. Assuming linear variation with time we can\ncompare different results. From the quasar absorption spectra:\n  $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$. A combination of this\nresult and the atomic clock results gives the best limt on variation of\n$\\alpha$: $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$. The\nOklo natural reactor gives the best limit on the variation of\n$m_s/\\Lambda_{QCD}$ where $m_s$ is the strange quark mass.\n  Huge enhancement of the relative variation effects happens in transitions\nbetween close atomic, molecular and nuclear energy levels. We suggest several\nnew cases where the levels are very narrow. Large enhancement of the variation\neffects is also possible in cold atomic and molecular collisions near Feshbach\nresonance. Massive bodies (stars or galaxies) can also affect physical\nconstants. They have large scalar charge $S$ proportional to number of\nparticles which produces a Coulomb-like scalar field $U=S/r$. This leads to a\nvariation of the fundamental constants proportional to the gravitational\npotential, e.g. $\\delta \\alpha/ \\alpha = k_\\alpha \\delta (GM/ r c^2)$. We\ncompare different manifestations of this effect.The strongest limit\n  $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$.\n\n", "human_text": "  Review of recent works devoted to the variation of the fundamental constants\nis presented including atomic clocks, quasar absorption spectra, and Oklo\nnatural nuclear reactor data. Assuming linear variation with time we can\ncompare different results. From the quasar absorption spectra:\n  $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$. A combination of this\nresult and the atomic clock results gives the best limt on variation of\n$\\alpha$: $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$. The\nOklo natural reactor gives the best limit on the variation of\n$m_s/\\Lambda_{QCD}$ where $m_s$ is the strange quark mass.\n  Huge enhancement of the relative variation effects happens in transitions\nbetween close atomic, molecular and nuclear energy levels. We suggest several\nnew cases where the levels are very narrow. Large enhancement of the variation\neffects is also possible in cold atomic and molecular collisions near Feshbach\nresonance. Massive bodies (stars or galaxies) can also affect physical\nconstants. They have large scalar charge $S$ proportional to number of\nparticles which produces a Coulomb-like scalar field $U=S/r$. This leads to a\nvariation of the fundamental constants proportional to the gravitational\npotential, e.g. $\\delta \\alpha/ \\alpha = k_\\alpha \\delta (GM/ r c^2)$. We\ncompare different manifestations of this effect.The strongest limit\n  $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$.\n", "machine_text": "This article offers a review of recent research into the potential fluctuations of fundamental constants such as atomic clocks, quasar absorption spectra, and Oklo natural nuclear reactor data. Assessing linear variability with time, comparative studies from quasar absorption data suggest $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$ and the best limit of $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$ came from both quasar absorption data and atomic clocks. The Oklo natural reactor results in the strongest limit on the variantion of $m_s/\\Lambda_{QCD}$ with the strange quark mass. It is also possible for large enhancement of relative variation effects to occur in atomic, molecular and nuclear transitions between close energy levels, in cold atomic and molecular collisions near Feshbach resonance, and in massive bodies such as stars and galaxies whose Coulomb-like scalar field produces a proportionate variation of constants. Following the comparison of these various phenomenon, the strongest limit of $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$ could be inferred.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3704}
{"prompt": "Rephrase the abstract of an article with title 'Comparison of Dissipative Particle Dynamics and Langevin thermostats for\n  out-of-equilibrium simulations of polymeric systems'.\n  In this work we compare and characterize the behavior of Langevin and\nDissipative Particle Dynamics (DPD) thermostats in a broad range of\nnon-equilibrium simulations of polymeric systems. Polymer brushes in relative\nsliding motion, polymeric liquids in Poiseuille and Couette flows, and\nbrush-melt interfaces are used as model systems to analyze the efficiency and\nlimitations of different Langevin and DPD thermostat implementations. Widely\nused coarse-grained bead-spring models under good and poor solvent conditions\nare employed to assess the effects of the thermostats. We considered\nequilibrium, transient, and steady state examples for testing the ability of\nthe thermostats to maintain constant temperature and to reproduce the\nunderlying physical phenomena in non-equilibrium situations. The common\npractice of switching-off the Langevin thermostat in the flow direction is also\ncritically revisited. The efficiency of different weight functions for the DPD\nthermostat is quantitatively analyzed as a function of the solvent quality and\nthe non-equilibrium situation.\n\n", "human_text": "  In this work we compare and characterize the behavior of Langevin and\nDissipative Particle Dynamics (DPD) thermostats in a broad range of\nnon-equilibrium simulations of polymeric systems. Polymer brushes in relative\nsliding motion, polymeric liquids in Poiseuille and Couette flows, and\nbrush-melt interfaces are used as model systems to analyze the efficiency and\nlimitations of different Langevin and DPD thermostat implementations. Widely\nused coarse-grained bead-spring models under good and poor solvent conditions\nare employed to assess the effects of the thermostats. We considered\nequilibrium, transient, and steady state examples for testing the ability of\nthe thermostats to maintain constant temperature and to reproduce the\nunderlying physical phenomena in non-equilibrium situations. The common\npractice of switching-off the Langevin thermostat in the flow direction is also\ncritically revisited. The efficiency of different weight functions for the DPD\nthermostat is quantitatively analyzed as a function of the solvent quality and\nthe non-equilibrium situation.\n", "machine_text": "In this paper, we evaluate and compare the performance of Langevin and Dissipative Particle Dynamics (DPD) thermostats in a range of non-equilibrium simulations involving polymeric systems. We consider simulations to investigate polymer brushes in sliding motion, polymer liquids exposed to Poiseuille and Couette flows, and brush-melt interfaces with bead-spring models that are exposed to varying degrees of solvent quality. We will look at equilibrium, transient, and steady-state situations to assess the capacity of the two thermostats to maintain temperature conditions and to accurately reproduce physical phenomena in out-of-equilibrium conditions. Additionally, we answer the question of whether it is necessary or beneficial to discontinue the Langevin thermostat when running flow simulations. Finally, we provide a quantitative analysis of how various weight functions influence the efficiency of the DPD thermostat in terms of solvent quality and non-equilibrium states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2624}
{"prompt": "Rephrase the abstract of an article with title 'Extremal black holes in D=5: SUSY vs. Gauss-Bonnet corrections'.\n  We analyse near-horizon solutions and compare the results for the black hole\nentropy of five-dimensional spherically symmetric extremal black holes when the\nN=2 SUGRA actions are supplied with two different types of higher-order\ncorrections: (1) supersymmetric completion of gravitational Chern-Simons term,\nand (2) Gauss-Bonnet term. We show that for large BPS black holes lowest order\n\\alpha' corrections to the entropy are the same, but for non-BPS are generally\ndifferent. We pay special attention to the class of prepotentials connected\nwith K3\\times T^2 and T^6 compactifications. For supersymmetric correction we\nfind beside BPS also a set of non-BPS solutions. In the particular case of T^6\ncompactification (equivalent to the heterotic string on $T^4\\times S^1$) we\nfind the (almost) complete set of solutions (with exception of some non-BPS\nsmall black holes), and show that entropy of small black holes is different\nfrom statistical entropy obtained by counting of microstates of heterotic\nstring theory. We also find complete set of solutions for K3\\times T^2 and T^6\ncase when correction is given by Gauss-Bonnet term. Contrary to\nfour-dimensional case, obtained entropy is different from the one with\nsupersymmetric correction. We show that in Gauss-Bonnet case entropy of small\n``BPS'' black holes agrees with microscopic entropy in the known cases.\n\n", "human_text": "  We analyse near-horizon solutions and compare the results for the black hole\nentropy of five-dimensional spherically symmetric extremal black holes when the\nN=2 SUGRA actions are supplied with two different types of higher-order\ncorrections: (1) supersymmetric completion of gravitational Chern-Simons term,\nand (2) Gauss-Bonnet term. We show that for large BPS black holes lowest order\n\\alpha' corrections to the entropy are the same, but for non-BPS are generally\ndifferent. We pay special attention to the class of prepotentials connected\nwith K3\\times T^2 and T^6 compactifications. For supersymmetric correction we\nfind beside BPS also a set of non-BPS solutions. In the particular case of T^6\ncompactification (equivalent to the heterotic string on $T^4\\times S^1$) we\nfind the (almost) complete set of solutions (with exception of some non-BPS\nsmall black holes), and show that entropy of small black holes is different\nfrom statistical entropy obtained by counting of microstates of heterotic\nstring theory. We also find complete set of solutions for K3\\times T^2 and T^6\ncase when correction is given by Gauss-Bonnet term. Contrary to\nfour-dimensional case, obtained entropy is different from the one with\nsupersymmetric correction. We show that in Gauss-Bonnet case entropy of small\n``BPS'' black holes agrees with microscopic entropy in the known cases.\n", "machine_text": "\nIn this article, we present an analysis of near-horizon solutions and compare the results of their black hole entropy in five-dimensional spherically symmetric extremal black holes when different types of higher-order corrections are applied. Specifically, we supply N=2 SUGRA actions with two different types of corrections, namely the gravitational Chern-Simons term supersymmetrically completed and the Gauss-Bonnet term. We demonstrate that for large BPS black holes, the lowest order \\alpha' corrections have the same entropy, however, for non-BPS black holes, they are generally different. Furthermore, we pay special attention to the class of prepotentials connected with the K3\\times T^2 and T^6 compactifications. In the former instance, we obtain both BPS and non-BPS solutions, while in the latter (equivalent to the heterotic string on $T^4\\times S^1$) we find the almost complete set of solutions to the exception of non-BPS small black holes. We show that their entropy is distinct from the statistical entropy arriving from counting the microstates of heterotic string theory. Additionally, we acquire a complete set of solutions when the correction is given by the Gauss-Bonnet term for the two popular compactifications. Contrary to the four-dimensional picture, the obtained entropy does not match with that of the supersymmetric correction. Lastly, for the ``BPS'' small black holes, we observe that in the Gauss-Bonnet case, their entropy complies with its microscopic counterpart in known contexts. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1167}
{"prompt": "Rephrase the abstract of an article with title 'Quantum Theory of Flicker Noise in Metal Films'.\n  Flicker (1/f^gamma) voltage noise spectrum is derived from finite-temperature\nquantum electromagnetic fluctuations produced by elementary charge carriers in\nexternal electric field. It is suggested that deviations of the frequency\nexponent \\gamma from unity, observed in thin metal films, can be attributed to\nquantum backreaction of the conducting medium on the fluctuating field of the\ncharge carrier. This backreaction is described phenomenologically in terms of\nthe effective momentum space dimensionality, D. Using the dimensional\ncontinuation technique, it is shown that the combined action of the photon heat\nbath and external field results in a 1/f^gamma-contribution to the spectral\ndensity of the two-point correlation function of electromagnetic field. The\nfrequency exponent is found to be equal to 1 + delta, where delta = 3 - D is a\nreduction of the momentum space dimensionality. This result is applied to the\ncase of a biased conducting sample, and a general expression for the voltage\npower spectrum is obtained which possesses all characteristic properties of\nobserved flicker noise spectra. The range of validity of this expression covers\nwell the whole measured frequency band. Gauge independence of the power\nspectrum is proved. It is shown that the obtained results naturally resolve the\nproblem of divergence of the total noise power. A detailed comparison with the\nexperimental data on flicker noise measurements in metal films is given.\n\n", "human_text": "  Flicker (1/f^gamma) voltage noise spectrum is derived from finite-temperature\nquantum electromagnetic fluctuations produced by elementary charge carriers in\nexternal electric field. It is suggested that deviations of the frequency\nexponent \\gamma from unity, observed in thin metal films, can be attributed to\nquantum backreaction of the conducting medium on the fluctuating field of the\ncharge carrier. This backreaction is described phenomenologically in terms of\nthe effective momentum space dimensionality, D. Using the dimensional\ncontinuation technique, it is shown that the combined action of the photon heat\nbath and external field results in a 1/f^gamma-contribution to the spectral\ndensity of the two-point correlation function of electromagnetic field. The\nfrequency exponent is found to be equal to 1 + delta, where delta = 3 - D is a\nreduction of the momentum space dimensionality. This result is applied to the\ncase of a biased conducting sample, and a general expression for the voltage\npower spectrum is obtained which possesses all characteristic properties of\nobserved flicker noise spectra. The range of validity of this expression covers\nwell the whole measured frequency band. Gauge independence of the power\nspectrum is proved. It is shown that the obtained results naturally resolve the\nproblem of divergence of the total noise power. A detailed comparison with the\nexperimental data on flicker noise measurements in metal films is given.\n", "machine_text": "This article examines the measurement of flicker voltage noise power spectrum in thin metal films, with the aim of examining the deviation of the frequency exponent \\gamma from the theoretical value of 1. This deviation is attributed to the quantum backreaction of the conducting medium on the fluctuating charge carriers in the external electric field. Results of a dimensional continuation technique are used to explain 1/f^gamma-contribution to the two-point correlation function of electromagnetic fields and ultimately the voltage power spectrum. A general expression for the voltage power spectrum is formulated, and subsequent analysis shows this expression to resolve the divergence of total noise power. A comparison with the experimental data is made and discussed in detail.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2818}
{"prompt": "Rephrase the abstract of an article with title 'Differentially rotating force-free magnetosphere of an aligned rotator:\n  analytical solutions in split-monopole approximation'.\n  In this paper we consider stationary force-free magnetosphere of an aligned\nrotator when plasma in the open field line region rotates differentially due to\npresence of a zone with the accelerating electric field in the polar cap of\npulsar. We study the impact of differential rotation on the current density\ndistribution in the magnetosphere. Using split-monopole approximation we obtain\nanalytical expressions for physical parameters of differentially rotating\nmagnetosphere. We find the range of admitted current density distributions\nunder the requirement that the potential drop in the polar cap is less than the\nvacuum potential drop. We show that the current density distribution could\ndeviate significantly from the ``classical'' Michel distribution and could be\nmade almost constant over the polar cap even when the potential drop in the\naccelerating zone is of the order of 10 per cents of the vacuum potential drop.\nWe argue that differential rotation of the open magnetic field lines could play\nan important role in adjusting between the magnetosphere and the polar cap\ncascade zone and could affect the value of pulsar breaking index.\n\n", "human_text": "  In this paper we consider stationary force-free magnetosphere of an aligned\nrotator when plasma in the open field line region rotates differentially due to\npresence of a zone with the accelerating electric field in the polar cap of\npulsar. We study the impact of differential rotation on the current density\ndistribution in the magnetosphere. Using split-monopole approximation we obtain\nanalytical expressions for physical parameters of differentially rotating\nmagnetosphere. We find the range of admitted current density distributions\nunder the requirement that the potential drop in the polar cap is less than the\nvacuum potential drop. We show that the current density distribution could\ndeviate significantly from the ``classical'' Michel distribution and could be\nmade almost constant over the polar cap even when the potential drop in the\naccelerating zone is of the order of 10 per cents of the vacuum potential drop.\nWe argue that differential rotation of the open magnetic field lines could play\nan important role in adjusting between the magnetosphere and the polar cap\ncascade zone and could affect the value of pulsar breaking index.\n", "machine_text": "\nThis article studies the effects of differentially-rotating magnetospheres on the current density distribution of an aligned rotator. Using split-monopole approximation, analytical expressions of physical parameters of such magnetospheres are derived. The range of current density distribution allowed is explored, with an additional requirement that the potential drop in the polar cap should not exceed the vacuum potential drop. It is suggested that the current density distribution could change significantly from the normal Michel distribution, even when the potential drop in the acceleration zone is of order 10% of the vacuum potential drop. Lastly, the role of differential rotation of open magnetic field lines in adjusting the magnetosphere and polar cap cascade zone, and its impact on the pulsar breaking index are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2141}
{"prompt": "Rephrase the abstract of an article with title 'Observations and Modeling of Line Asymmetries in Chromospheric Flares'.\n  For many years various asymmetrical profiles of different spectral lines\nemitted from solar flares have been frequently observed. These asymmetries or\nline shifts are caused predominantly by vertical mass motions in flaring layers\nand they provide a good diagnostics for plasma flows during solar flares. There\nare many controversial results of observations and theoretical analysis of\nplasma flows in solar chromospheric flares. The main difficulty is the\ninterpretation of line shifts or asymmetries. For many years, methods based on\nbisector techniques were used but they give a reliable results only for some\nspecific conditions and in most cases cannot be applied. The most promising\napproach is to use the non-LTE techniques applied for flaring atmosphere. The\ncalculation of synthetic line profiles is performed with the radiative transfer\ntechniques and the assumed physical conditions correspond to flaring\natmosphere. I will present an overview of different observations and\ninterpretations of line asymmetries in chromospheric flares. I will explain\nwhat we have learnt about the chromospheric evaporation in the frame of\nhydrodynamical models as well as reconnection models. A critical review will be\ndone on the classical methods used to derive Doppler-shifts for optically thick\nchomospheric lines. In particular, details on the new approach for interpreting\nchromospheric line asymmetries based on the non-LTE techniques will be\npresented.\n\n", "human_text": "  For many years various asymmetrical profiles of different spectral lines\nemitted from solar flares have been frequently observed. These asymmetries or\nline shifts are caused predominantly by vertical mass motions in flaring layers\nand they provide a good diagnostics for plasma flows during solar flares. There\nare many controversial results of observations and theoretical analysis of\nplasma flows in solar chromospheric flares. The main difficulty is the\ninterpretation of line shifts or asymmetries. For many years, methods based on\nbisector techniques were used but they give a reliable results only for some\nspecific conditions and in most cases cannot be applied. The most promising\napproach is to use the non-LTE techniques applied for flaring atmosphere. The\ncalculation of synthetic line profiles is performed with the radiative transfer\ntechniques and the assumed physical conditions correspond to flaring\natmosphere. I will present an overview of different observations and\ninterpretations of line asymmetries in chromospheric flares. I will explain\nwhat we have learnt about the chromospheric evaporation in the frame of\nhydrodynamical models as well as reconnection models. A critical review will be\ndone on the classical methods used to derive Doppler-shifts for optically thick\nchomospheric lines. In particular, details on the new approach for interpreting\nchromospheric line asymmetries based on the non-LTE techniques will be\npresented.\n", "machine_text": "\nThis article provides an overview of the asymmetrical profiles of different spectral lines seen in solar flares, as well as the modelings used to explain them. These line shifts can be attributed to vertical mass motions inside the flaring layers, making them a prime candiate to measure plasma flow during a solar flare. While attempts have been made using the bisector technique, most results are not reliable under certain conditions and therefore a non-LTE technique is used to calculate synthetic line profiles that correspond to flaring atmosphere. This article will include an overview on different observations of line asymmetries in chromospheric flares, and discuss data on chromospheric evaporation as well as reconnection models. A critical review of the classical methods for calculating Doppler shifts for optically thick chromospheric lines will be done, with details on the new approach being presented.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2436}
{"prompt": "Rephrase the abstract of an article with title 'Resummation of Large Logarithms in $\\gamma^* \\pi^0 \\to \\gamma $'.\n  In the collinear factorization of the form factor for the transition\n$\\gamma^* \\pi^0 \\to \\gamma$ the hard part contains double log terms as $\\ln^2\nx$ with $x$ as the momentum fraction of partons from 0 to 1. A simple\nexponentiation for resummation leads to divergent results. We study the\nresummation of these $\\ln^2 x$ terms. We show that the $\\ln^2 x$ terms come\npartly from the light-cone wave function(LCWF) and partly from the form factor.\nWe introduce a jet factor to factorize the $\\ln^2 x$ term in the form factor.\nTo handel the $\\ln^2 x$ terms from the LCWF we introduce a nonstandard\nlight-cone wave function(NLCWF) with the gauge links off the light-cone\ndirection. An interesting relation between two wave function is found. With the\nintroduced NLCWF and the jet factor we can re-factorize the form factor and\nobtain a new hard part which does not contain terms with $\\ln^2 x$. Beside the\nrenormalization scale $\\mu$ the introduce NLCWF and jet factor have extra\nscales to characterize their $x$-behaviors. Using the evolutions of the extra\nscales and the relation we can do the resummation perturbatively in sense that\nthe LCWF is the only nonpertubative object in the resumed formula. Our results\nwith some models of LCWF show that there is a significant difference between\nnumerical predictions with the resummation and that without the resummation,\nand the resummed predictions can describe the experimental data.\n\n", "human_text": "  In the collinear factorization of the form factor for the transition\n$\\gamma^* \\pi^0 \\to \\gamma$ the hard part contains double log terms as $\\ln^2\nx$ with $x$ as the momentum fraction of partons from 0 to 1. A simple\nexponentiation for resummation leads to divergent results. We study the\nresummation of these $\\ln^2 x$ terms. We show that the $\\ln^2 x$ terms come\npartly from the light-cone wave function(LCWF) and partly from the form factor.\nWe introduce a jet factor to factorize the $\\ln^2 x$ term in the form factor.\nTo handel the $\\ln^2 x$ terms from the LCWF we introduce a nonstandard\nlight-cone wave function(NLCWF) with the gauge links off the light-cone\ndirection. An interesting relation between two wave function is found. With the\nintroduced NLCWF and the jet factor we can re-factorize the form factor and\nobtain a new hard part which does not contain terms with $\\ln^2 x$. Beside the\nrenormalization scale $\\mu$ the introduce NLCWF and jet factor have extra\nscales to characterize their $x$-behaviors. Using the evolutions of the extra\nscales and the relation we can do the resummation perturbatively in sense that\nthe LCWF is the only nonpertubative object in the resumed formula. Our results\nwith some models of LCWF show that there is a significant difference between\nnumerical predictions with the resummation and that without the resummation,\nand the resummed predictions can describe the experimental data.\n", "machine_text": "This article presents a study of the resummation of the double log terms $\\ln^2 x$ in the collinear factorization of the form factor for the transition $\\gamma^* \\pi^0 \\to \\gamma$. We introduce a nonstandard light-cone wave function and a jet factor to factorize the $\\ln^2 x$ term in the form factor and show that these objects have extra scales to characterize their $x$-behaviors. We then leverage the evolutions of the extra scales and the relation of these two wave functions to do the resummation perturbatively. Our results demonstrate that a significant difference exists between the numerical predictions with and without resummation, and that the resummed values can more accurately fit the available experimental data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3782}
{"prompt": "Rephrase the abstract of an article with title 'Dyson Indices and Hilbert-Schmidt Separability Functions and\n  Probabilities'.\n  A confluence of numerical and theoretical results leads us to conjecture that\nthe Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional\nconvex sets of complex and real two-qubit states (representable by 4 x 4\ndensity matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning\nare the modifications of two ansatze, recently advanced (quant-ph/0609006),\ninvolving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11}\nrho_{44})/(rho_{22} rho_{33}). We, now, set the separability function\nS_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the\ncomplex case -- conforming to a pattern we find, manifesting the Dyson indices\n(1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2}\n(nu). We also investigate the real and complex qubit-qutrit cases. Now, there\nare two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}),\nnu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably\ncoalesce into the product, eta = nu_1 nu_2 = rho_{11} \\rho_{66}}{\\rho_{33}\n\\rho_{44}}, so that the real and complex separability functions are again\nunivariate in nature.\n\n", "human_text": "  A confluence of numerical and theoretical results leads us to conjecture that\nthe Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional\nconvex sets of complex and real two-qubit states (representable by 4 x 4\ndensity matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning\nare the modifications of two ansatze, recently advanced (quant-ph/0609006),\ninvolving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11}\nrho_{44})/(rho_{22} rho_{33}). We, now, set the separability function\nS_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the\ncomplex case -- conforming to a pattern we find, manifesting the Dyson indices\n(1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2}\n(nu). We also investigate the real and complex qubit-qutrit cases. Now, there\nare two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}),\nnu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably\ncoalesce into the product, eta = nu_1 nu_2 = rho_{11} \\rho_{66}}{\\rho_{33}\n\\rho_{44}}, so that the real and complex separability functions are again\nunivariate in nature.\n", "machine_text": "We examine the implications of our conjecture with respect to Dyson indices, \nHilbert-Schmidt separability probabilities, and Beta function ansatze for \nreal and complex two-qubit states, qutrits, and higher-dimensional states. We \nfind that our conjectured relation of separability probabilities to Dyson \nindices is in accord with random matrix theory, as demonstrated in the studies \nof the real and complex qubit-qutrit cases. Moreover, the conjectured \nseparability functions based on Beta functions are further supported in \nnumerical and theoretical analyses, as well as studies involving higher \ndimensional real and complex states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3723}
{"prompt": "Rephrase the abstract of an article with title 'GRB 050410 and GRB 050412: are they really dark GRBs?'.\n  We present a detailed analysis of the prompt and afterglow emission of GRB\n050410 and GRB 050412 detected by Swift for which no optical counterpart was\nobserved. The 15-150 keV energy distribution of the GRB 050410 prompt emission\nshows a peak energy at 53 keV. The XRT light curve of this GRB decays as a\npower law with a slope of alpha=1.06+/-0.04. The spectrum is well reproduced by\nan absorbed power law with a spectral index Gamma_x=2.4+/-0.4 and a low energy\nabsorption N_H=4(+3;-2)x10^21 cm^(-2) which is higher than the Galactic value.\nThe 15-150 keV prompt emission in GRB 050412 is modelled with a hard\n(Gamma=0.7+/-0.2) power law. The XRT light curve follows a broken power law\nwith the first slope alpha_1=0.7+/-0.4, the break time T_break=254(-41;+79) s\nand the second slope alpha_2=2.8(-0.8;+0.5). The spectrum is fitted by a power\nlaw with spectral index Gamma_x=1.3+/-0.2 which is absorbed at low energies by\nthe Galactic column. The GRB 050410 afterglow reveals the expected\ncharacteristics of the third component of the canonical Swift light curve.\nConversely, a complex phenomenology was detected in the GRB 050412 because of\nthe presence of the very early break. The light curve in this case can be\ninterpreted as being the last peak of the prompt emission. The two bursts\npresent tight upper limits for the optical emission, however, neither of them\ncan be clearly classified as dark. For GRB 050410, the suppression of the\noptical afterglow could be attributed to a low density interstellar medium\nsurrounding the burst. For GRB 050412, the evaluation of the darkness is more\ndifficult due to the ambiguity in the extrapolation of the X-ray afterglow\nlight curve.\n\n", "human_text": "  We present a detailed analysis of the prompt and afterglow emission of GRB\n050410 and GRB 050412 detected by Swift for which no optical counterpart was\nobserved. The 15-150 keV energy distribution of the GRB 050410 prompt emission\nshows a peak energy at 53 keV. The XRT light curve of this GRB decays as a\npower law with a slope of alpha=1.06+/-0.04. The spectrum is well reproduced by\nan absorbed power law with a spectral index Gamma_x=2.4+/-0.4 and a low energy\nabsorption N_H=4(+3;-2)x10^21 cm^(-2) which is higher than the Galactic value.\nThe 15-150 keV prompt emission in GRB 050412 is modelled with a hard\n(Gamma=0.7+/-0.2) power law. The XRT light curve follows a broken power law\nwith the first slope alpha_1=0.7+/-0.4, the break time T_break=254(-41;+79) s\nand the second slope alpha_2=2.8(-0.8;+0.5). The spectrum is fitted by a power\nlaw with spectral index Gamma_x=1.3+/-0.2 which is absorbed at low energies by\nthe Galactic column. The GRB 050410 afterglow reveals the expected\ncharacteristics of the third component of the canonical Swift light curve.\nConversely, a complex phenomenology was detected in the GRB 050412 because of\nthe presence of the very early break. The light curve in this case can be\ninterpreted as being the last peak of the prompt emission. The two bursts\npresent tight upper limits for the optical emission, however, neither of them\ncan be clearly classified as dark. For GRB 050410, the suppression of the\noptical afterglow could be attributed to a low density interstellar medium\nsurrounding the burst. For GRB 050412, the evaluation of the darkness is more\ndifficult due to the ambiguity in the extrapolation of the X-ray afterglow\nlight curve.\n", "machine_text": "\nThis article analyses the prompt and afterglow emission of GRB 050410 and GRB 050412, two bursts detected by Swift with no observed optical counterparts. Our analysis examined the 15-150 keV energy distribution of the GRB 050410 prompt emission, which revealed a peak energy at 53 keV, as well as the XRT light curve, the spectrum, and the GRB 050412 afterglow. Although both bursts had tight upper limits for the optical emission, neither of them could be definitively deemed 'dark' GRBs. For GRB 050410, this could be due to the relatively low density of the interstellar medium surrounding the burst, while it was more difficult to determine in GRB 050412 due to the ambiguity in the extrapolation of the X-ray afterglow light curve.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3191}
{"prompt": "Rephrase the abstract of an article with title 'Information-Based Asset Pricing'.\n  A new framework for asset price dynamics is introduced in which the concept\nof noisy information about future cash flows is used to derive the price\nprocesses. In this framework an asset is defined by its cash-flow structure.\nEach cash flow is modelled by a random variable that can be expressed as a\nfunction of a collection of independent random variables called market factors.\nWith each such \"X-factor\" we associate a market information process, the values\nof which are accessible to market agents. Each information process is a sum of\ntwo terms; one contains true information about the value of the market factor;\nthe other represents \"noise\". The noise term is modelled by an independent\nBrownian bridge. The market filtration is assumed to be that generated by the\naggregate of the independent information processes. The price of an asset is\ngiven by the expectation of the discounted cash flows in the risk-neutral\nmeasure, conditional on the information provided by the market filtration. When\nthe cash flows are the dividend payments associated with equities, an explicit\nmodel is obtained for the share-price, and the prices of options on\ndividend-paying assets are derived. Remarkably, the resulting formula for the\nprice of a European call option is of the Black-Scholes-Merton type. The\ninformation-based framework also generates a natural explanation for the origin\nof stochastic volatility.\n\n", "human_text": "  A new framework for asset price dynamics is introduced in which the concept\nof noisy information about future cash flows is used to derive the price\nprocesses. In this framework an asset is defined by its cash-flow structure.\nEach cash flow is modelled by a random variable that can be expressed as a\nfunction of a collection of independent random variables called market factors.\nWith each such \"X-factor\" we associate a market information process, the values\nof which are accessible to market agents. Each information process is a sum of\ntwo terms; one contains true information about the value of the market factor;\nthe other represents \"noise\". The noise term is modelled by an independent\nBrownian bridge. The market filtration is assumed to be that generated by the\naggregate of the independent information processes. The price of an asset is\ngiven by the expectation of the discounted cash flows in the risk-neutral\nmeasure, conditional on the information provided by the market filtration. When\nthe cash flows are the dividend payments associated with equities, an explicit\nmodel is obtained for the share-price, and the prices of options on\ndividend-paying assets are derived. Remarkably, the resulting formula for the\nprice of a European call option is of the Black-Scholes-Merton type. The\ninformation-based framework also generates a natural explanation for the origin\nof stochastic volatility.\n", "machine_text": "This paper introduces a new pricing framework, based on the concept of noisy information about future cash flows and the associated market filtration. The dynamics of asset prices are determined by the expectation of discounted cash flows, conditional on the information provided by the market information process. A model is obtained for share prices, and options on dividend-paying assets are derived from the resulting formulae. This shows that the Black-Scholes-Merton formula applies to this framework, and provides an explanation for the phenomenon of stochastic volatility.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1976}
{"prompt": "Rephrase the abstract of an article with title 'Effective inverse spectral problem for rational Lax matrices and\n  applications'.\n  We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the\ndesingularization of the characteristic polynomial) and some additional data.\nUsing a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu))\nwe provide a residue-formula for the entries of the Lax matrix in terms of\nbases of dual differentials of weights nu and 1-nu respectively. All objects\nare described in the most explicit terms using Theta functions. Via a sequence\nof ``elementary twists'', we construct sequences of Lax matrices sharing the\nsame spectral curve and polar structure and related by conjugations by rational\nmatrices. Particular choices of elementary twists lead to construction of\nsequences of Lax matrices related to finite--band recurrence relations (i.e.\ndifference operators) sharing the same shape. Recurrences of this kind are\nsatisfied by several types of orthogonal and biorthogonal polynomials. The\nrelevance of formulae obtained to the study of the large degree asymptotics for\nthese polynomials is indicated.\n\n", "human_text": "  We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the\ndesingularization of the characteristic polynomial) and some additional data.\nUsing a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu))\nwe provide a residue-formula for the entries of the Lax matrix in terms of\nbases of dual differentials of weights nu and 1-nu respectively. All objects\nare described in the most explicit terms using Theta functions. Via a sequence\nof ``elementary twists'', we construct sequences of Lax matrices sharing the\nsame spectral curve and polar structure and related by conjugations by rational\nmatrices. Particular choices of elementary twists lead to construction of\nsequences of Lax matrices related to finite--band recurrence relations (i.e.\ndifference operators) sharing the same shape. Recurrences of this kind are\nsatisfied by several types of orthogonal and biorthogonal polynomials. The\nrelevance of formulae obtained to the study of the large degree asymptotics for\nthese polynomials is indicated.\n", "machine_text": "This paper provides a method to invert the spectral problem for rational Lax matrices of size R+1, based on the curve of the associated characteristic polynomial and additional data. We make use of twisted Cauchy-like kernels to formulate an integral residue formula to represent the entries of Lax matrices, with all components being expressed in terms of Theta functions. Different elements in the matrix are realized with the aid of 'elementary twists', leading to the construction of sequences of Lax matrices that have the same spectral curve and polar structure, but related by rational conjugations. Our formulae are further used to derive certain finite-band recurrence relations, which are satisfied by various types of orthogonal and biorthogonal polynomials. Such models are relevant to the study of the leading-order behavior of these polynomials at large degree.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.012}
{"prompt": "Rephrase the abstract of an article with title 'Survival of the mm-cm size grain population observed in protoplanetary\n  disks'.\n  Millimeter interferometry provides evidence for the presence of mm to cm size\n\"pebbles\" in the outer parts of disks around pre-main-sequence stars. The\nobservations suggest that large grains are produced relatively early in disk\nevolution (< 1 Myr) and remain at large radii for longer periods of time (5 to\n10 Myr). Simple theoretical estimates of the radial drift time of solid\nparticles, however, imply that they would drift inward over a time scale of\nless than 0.1 Myr. In this paper, we address this conflict between theory and\nobservation, using more detailed theoretical models, including the effects of\nsedimentation, collective drag forces and turbulent viscosity. We find that,\nalthough these effects slow down the radial drift of the dust particles, this\nreduction is not sufficient to explain the observationally determined long\nsurvival time of mm/cm-sized grains in protoplanetary disks. However, if for\nsome reason the gas to dust ratio in the disk is reduced by at least a factor\nof 20 from the canonical value of 100 (for instance through photoevaporation of\nthe gas), then the radial drift time scales become sufficiently large to be in\nagreement with observations.\n\n", "human_text": "  Millimeter interferometry provides evidence for the presence of mm to cm size\n\"pebbles\" in the outer parts of disks around pre-main-sequence stars. The\nobservations suggest that large grains are produced relatively early in disk\nevolution (< 1 Myr) and remain at large radii for longer periods of time (5 to\n10 Myr). Simple theoretical estimates of the radial drift time of solid\nparticles, however, imply that they would drift inward over a time scale of\nless than 0.1 Myr. In this paper, we address this conflict between theory and\nobservation, using more detailed theoretical models, including the effects of\nsedimentation, collective drag forces and turbulent viscosity. We find that,\nalthough these effects slow down the radial drift of the dust particles, this\nreduction is not sufficient to explain the observationally determined long\nsurvival time of mm/cm-sized grains in protoplanetary disks. However, if for\nsome reason the gas to dust ratio in the disk is reduced by at least a factor\nof 20 from the canonical value of 100 (for instance through photoevaporation of\nthe gas), then the radial drift time scales become sufficiently large to be in\nagreement with observations.\n", "machine_text": "\nObservations from millimeter interferometry of pre-main-sequence stars' disks reveal the existence of pebble-sized particles, ranging in size from millimeters to centimeters, which are estimated to remain in the outer parts of these disks for up to 10 million years. This survival rate goes against the predictions of theoretical models of radial drift, which suggest that such particles should drift inwardly within 0.1 million years. This conflict is investigated through advanced theoretical models, incorporating sedimentation, collective drag forces, and turbulent viscosity. It is found that, despite slowing the radial drift somewhat, this alone is not enough to explain the discrepancy between estimates. However, if the gas to dust ratio of the disk was reduced by a factor of 20 (e.g. through photoevaporation), the radial drift time frames become compatible with observations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2332}
{"prompt": "Rephrase the abstract of an article with title 'Separation of the visible and dark matter in the Einstein ring LBG\n  J213512.73-010143'.\n  We model the mass distribution in the recently discovered Einstein ring LBG\nJ213512.73-010143 (the `Cosmic Eye') using archival Hubble Space Telescope\nimaging. We reconstruct the mass density profile of the z=0.73 lens and the\nsurface brightness distribution of the z=3.07 source and find that the observed\nring is best fit with a dual-component lens model consisting of a baryonic\nSersic component nested within a dark matter halo. The dark matter halo has an\ninner slope of 1.42+/-0.23, consistent with CDM simulations after allowing for\nbaryon contraction. The baryonic component has a B-band mass-to-light ratio of\n1.71+0.28-0.38 (solar units) which when evolved to the present day is in\nagreement with local ellipticals. Within the Einstein radius of 0.77'' (5.6\nkpc), the baryons account for (46+/-11)% of the total lens mass. External shear\nfrom a nearby foreground cluster is accurately predicted by the model. The\nreconstructed surface brightness distribution in the source plane clearly shows\ntwo peaks. Through a generalisation of our lens inversion method, we conclude\nthat the redshifts of both peaks are consistent with each other, suggesting\nthat we are seeing structure within a single galaxy.\n\n", "human_text": "  We model the mass distribution in the recently discovered Einstein ring LBG\nJ213512.73-010143 (the `Cosmic Eye') using archival Hubble Space Telescope\nimaging. We reconstruct the mass density profile of the z=0.73 lens and the\nsurface brightness distribution of the z=3.07 source and find that the observed\nring is best fit with a dual-component lens model consisting of a baryonic\nSersic component nested within a dark matter halo. The dark matter halo has an\ninner slope of 1.42+/-0.23, consistent with CDM simulations after allowing for\nbaryon contraction. The baryonic component has a B-band mass-to-light ratio of\n1.71+0.28-0.38 (solar units) which when evolved to the present day is in\nagreement with local ellipticals. Within the Einstein radius of 0.77'' (5.6\nkpc), the baryons account for (46+/-11)% of the total lens mass. External shear\nfrom a nearby foreground cluster is accurately predicted by the model. The\nreconstructed surface brightness distribution in the source plane clearly shows\ntwo peaks. Through a generalisation of our lens inversion method, we conclude\nthat the redshifts of both peaks are consistent with each other, suggesting\nthat we are seeing structure within a single galaxy.\n", "machine_text": "\nThe newly identified Einstein ring LBG J213512.73-010143 (the 'Cosmic Eye') has been explored for its mass distribution using data from the Hubble Space Telescope. Our analysis reveals a dual-component lens made up of both baryonic and dark matter components. The dark matter halo has a central slope that aligns with the parameters produced by CDM simulations, and the baryonic component has a B-band mass-to-light ratio in line with local ellipticals. In addition, the model correctly predicts the external shear from a neighbouring cluster. By generalising an inversion method, we find that the two visible peaks across the light source identify themselves as a single galaxy. Thus, we can assign a mass proportion of 46% (+/- 11%) to the baryons within the Einstein radius of 0.77\" (5.6 kpc).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.172}
{"prompt": "Rephrase the abstract of an article with title 'Common Envelope Evolution Redux'.\n  Common envelopes form in dynamical time scale mass exchange, when the\nenvelope of a donor star engulfs a much denser companion, and the core of the\ndonor plus the dense companion star spiral inward through this dissipative\nenvelope. As conceived by Paczynski and Ostriker, this process must be\nresponsible for the creation of short-period binaries with degenerate\ncomponents, and, indeed, it has proven capable of accounting for short-period\nbinaries containing one white dwarf component. However, attempts to reconstruct\nthe evolutionary histories of close double white dwarfs have proven more\nproblematic, and point to the need for enhanced systemic mass loss, either\nduring the close of the first, slow episode of mass transfer that produced the\nfirst white dwarf, or during the detached phase preceding the final, common\nenvelope episode. The survival of long-period interacting binaries with massive\nwhite dwarfs, such as the recurrent novae T CrB and RS Oph, also presents\ninterpretative difficulties for simple energetic treatments of common envelope\nevolution. Their existence implies that major terms are missing from usual\nformulations of the energy budget for common envelope evolution. The most\nplausible missing energy term is the energy released by recombination in the\ncommon envelope, and, indeed, a simple reformulation the energy budget\nexplicitly including recombination resolves this issue.\n\n", "human_text": "  Common envelopes form in dynamical time scale mass exchange, when the\nenvelope of a donor star engulfs a much denser companion, and the core of the\ndonor plus the dense companion star spiral inward through this dissipative\nenvelope. As conceived by Paczynski and Ostriker, this process must be\nresponsible for the creation of short-period binaries with degenerate\ncomponents, and, indeed, it has proven capable of accounting for short-period\nbinaries containing one white dwarf component. However, attempts to reconstruct\nthe evolutionary histories of close double white dwarfs have proven more\nproblematic, and point to the need for enhanced systemic mass loss, either\nduring the close of the first, slow episode of mass transfer that produced the\nfirst white dwarf, or during the detached phase preceding the final, common\nenvelope episode. The survival of long-period interacting binaries with massive\nwhite dwarfs, such as the recurrent novae T CrB and RS Oph, also presents\ninterpretative difficulties for simple energetic treatments of common envelope\nevolution. Their existence implies that major terms are missing from usual\nformulations of the energy budget for common envelope evolution. The most\nplausible missing energy term is the energy released by recombination in the\ncommon envelope, and, indeed, a simple reformulation the energy budget\nexplicitly including recombination resolves this issue.\n", "machine_text": "\nThis article investigates common envelope evolution, an astrophysical process that occurs when the envelope of a donor star envelops a much denser companion. As proposed by Paczynski and Ostriker, this mass exchange creates short-period binary systems with degenerate components. Reconstructing the evolutionary histories of close double white dwarf systems has been more challenging, as it is likely that enhanced systemic mass loss is needed. The presence of long-period interacting binaries and recurrent novae, such as T CrB and RS Oph, suggests that the energy budget for common envelope evolution may be incomplete. Recombination energy could potentially satisfy the missing energy term and serve to resolve this issue. The research discussed in this article critiques and refines the theoretical formulation of common envelope evolution and the energy budget to account for the complexities of the process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.028}
{"prompt": "Rephrase the abstract of an article with title 'MICS Asia Phase II - Sensitivity to the aerosol module'.\n  In the framework of the model inter-comparison study - Asia Phase II (MICS2),\nwhere eight models are compared over East Asia, this paper studies the\ninfluence of different parameterizations used in the aerosol module on the\naerosol concentrations of sulfate and nitrate in PM10. An intracomparison of\naerosol concentrations is done for March 2001 using different configurations of\nthe aerosol module of one of the model used for the intercomparison. Single\nmodifications of a reference setup for model configurations are performed and\ncompared to a reference case. These modifications concern the size\ndistribution, i.e. the number of sections, and physical processes, i.e.\ncoagulation, condensation/evaporation, cloud chemistry, heterogeneous reactions\nand sea-salt emissions. Comparing monthly averaged concentrations at different\nstations, the importance of each parameterization is first assessed. It is\nfound that sulfate concentrations are little sensitive to sea-salt emissions\nand to whether condensation is computed dynamically or by assuming\nthermodynamic equilibrium. Nitrate concentrations are little sensitive to cloud\nchemistry. However, a very high sensitivity to heterogeneous reactions is\nobserved. Thereafter, the variability of the aerosol concentrations to the use\nof different chemistry transport models (CTMs) and the variability to the use\nof different parameterizations in the aerosol module are compared. For sulfate,\nthe variability to the use of different parameterizations in the aerosol module\nis lower than the variability to the use of different CTMs. However, for\nnitrate, for monthly averaged concentrations averaged over four stations, these\ntwo variabilities have the same order of magnitude.\n\n", "human_text": "  In the framework of the model inter-comparison study - Asia Phase II (MICS2),\nwhere eight models are compared over East Asia, this paper studies the\ninfluence of different parameterizations used in the aerosol module on the\naerosol concentrations of sulfate and nitrate in PM10. An intracomparison of\naerosol concentrations is done for March 2001 using different configurations of\nthe aerosol module of one of the model used for the intercomparison. Single\nmodifications of a reference setup for model configurations are performed and\ncompared to a reference case. These modifications concern the size\ndistribution, i.e. the number of sections, and physical processes, i.e.\ncoagulation, condensation/evaporation, cloud chemistry, heterogeneous reactions\nand sea-salt emissions. Comparing monthly averaged concentrations at different\nstations, the importance of each parameterization is first assessed. It is\nfound that sulfate concentrations are little sensitive to sea-salt emissions\nand to whether condensation is computed dynamically or by assuming\nthermodynamic equilibrium. Nitrate concentrations are little sensitive to cloud\nchemistry. However, a very high sensitivity to heterogeneous reactions is\nobserved. Thereafter, the variability of the aerosol concentrations to the use\nof different chemistry transport models (CTMs) and the variability to the use\nof different parameterizations in the aerosol module are compared. For sulfate,\nthe variability to the use of different parameterizations in the aerosol module\nis lower than the variability to the use of different CTMs. However, for\nnitrate, for monthly averaged concentrations averaged over four stations, these\ntwo variabilities have the same order of magnitude.\n", "machine_text": "This paper investigates the response of sulfate and nitrate aerosol concentrations in PM10 to the parameters of an aerosol module within the framework of Model Inter-Comparison Study (MICS) Asia Phase II. A reference configuration resulted in a comparison of aerosol concentrations in two models. Single variations were then assessed against this reference, such as size distribution, physical processes and various emissions \u2013 with a focus on how these modifications respond to concentrations in PM10. Results yielded little effect from sea-salt emissions but higher sensitivity to heterogeneous reactions, while nitrate was found to be insensitive to cloud chemistry. Finally, investigating the variability of the models, the response of sulfate concentrations was seen to be lower than that of a Chemistry Transport Model, whereas the response of nitrate concentrations was found to be of similar magnitude to the model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.319}
{"prompt": "Rephrase the abstract of an article with title 'Instabilities in the time-dependent neutrino disc in Gamma-Ray Bursts'.\n  We investigate the properties and evolution of accretion tori formed after\nthe coalescence of two compact objects. At these extreme densities and\ntemperatures, the accreting torus is cooled mainly by neutrino emission\nproduced primarily by electron and positron capture on nucleons (beta\nreactions). We solve for the disc structure and its time evolution by\nintroducing a detailed treatment of the equation of state which includes\nphotodisintegration of helium, the condition of beta-equilibrium, and neutrino\nopacities. We self-consistently calculate the chemical equilibrium in the gas\nconsisting of helium, free protons, neutrons and electron-positron pairs and\ncompute the chemical potentials of the species, as well as the electron\nfraction throughout the disc. We find that, for sufficiently large accretion\nrates (> 10 solar masses per second), the inner regions of the disk become\nopaque and develop a viscous and thermal instability. The identification of\nthis instability might be relevant for GRB observations.\n\n", "human_text": "  We investigate the properties and evolution of accretion tori formed after\nthe coalescence of two compact objects. At these extreme densities and\ntemperatures, the accreting torus is cooled mainly by neutrino emission\nproduced primarily by electron and positron capture on nucleons (beta\nreactions). We solve for the disc structure and its time evolution by\nintroducing a detailed treatment of the equation of state which includes\nphotodisintegration of helium, the condition of beta-equilibrium, and neutrino\nopacities. We self-consistently calculate the chemical equilibrium in the gas\nconsisting of helium, free protons, neutrons and electron-positron pairs and\ncompute the chemical potentials of the species, as well as the electron\nfraction throughout the disc. We find that, for sufficiently large accretion\nrates (> 10 solar masses per second), the inner regions of the disk become\nopaque and develop a viscous and thermal instability. The identification of\nthis instability might be relevant for GRB observations.\n", "machine_text": "\nThis paper examines the features and evolution of the accretion tori formed when two compact objects collide. Upon recognizing these extreme temperature and density levels, neutrino radiation produced by electron and positron capture on nuclei (beta reactions) is primarily used to cool the accreting torus. We consider a methodical treatment of the equation of state which involves analyzing the photodisintegration of helium, beta equilibrium, and neutrino opacities in order to ascertain the disc structure and its alterations over time. We expand upon this by evaluating the chemical equilibrium of the gas which is comprised of helium, free protons, neutrons, electron-positron pairs to figure out the chemical potentials of the individual parts and establish the electron fraction throughout the disc. Our findings suggest that for very high accretion rates (exceeding ten solar masses per second), the inner areas of the disc turn out to be opaque and result in a viscous and thermal instability. This form of instability could be useful in aiding the comprehension of GRB phenomena from an observational angle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1325}
{"prompt": "Rephrase the abstract of an article with title 'Synchrotron Radio Emission from a Fast Halo Coronal Mass Ejection'.\n  An interplanetary (IP) type-II-like radio burst is analyzed. It occurred on\n2003 June 17-18 in association with a fast halo coronal mass ejection (CME), an\nM6.8 soft-X-ray (SXR) flare, and produced a solar proton event. Unlike coronal\ntype II bursts and the ma jority of IP type II radio emissions, the IP\ntype-II-like event associated with the fast halo CME on June 17-18 varies\nsmoothly in time and frequency and has a frequency bandwidth that is several\ntimes larger than is typical for coronal and IP type II emissions. Moreover,\nthe frequency change with time is inconsistent with that expected from plasma\nradiation associated with a CME-driven shock. I suggest that this IP\ntype-II-like event, referred to here as an IP type II-S event, is not due to\nplasma radiation but, rather, incoherent synchrotron radiation from\nnear-relativistic electrons entrained in the CME magnetic field, or in the\nsheath region between the shock and the CME driver. This event may be an\nexample of a new and distinct class of interplanetary radio phenomenon.\n\n", "human_text": "  An interplanetary (IP) type-II-like radio burst is analyzed. It occurred on\n2003 June 17-18 in association with a fast halo coronal mass ejection (CME), an\nM6.8 soft-X-ray (SXR) flare, and produced a solar proton event. Unlike coronal\ntype II bursts and the ma jority of IP type II radio emissions, the IP\ntype-II-like event associated with the fast halo CME on June 17-18 varies\nsmoothly in time and frequency and has a frequency bandwidth that is several\ntimes larger than is typical for coronal and IP type II emissions. Moreover,\nthe frequency change with time is inconsistent with that expected from plasma\nradiation associated with a CME-driven shock. I suggest that this IP\ntype-II-like event, referred to here as an IP type II-S event, is not due to\nplasma radiation but, rather, incoherent synchrotron radiation from\nnear-relativistic electrons entrained in the CME magnetic field, or in the\nsheath region between the shock and the CME driver. This event may be an\nexample of a new and distinct class of interplanetary radio phenomenon.\n", "machine_text": "\nThis article studies an interplanetary (IP) type-II-like radio burst which appeared on 2003 June 17-18 in connection to a fast halo coronal mass ejection (CME), an M6.8 soft-X-ray (SXR) flare, and a solar proton event. Unlike typical coronal type II bursts, this type-II-like event varied smoothly in time and frequency and had a frequency bandwidth significantly wider than the norm. Additionally, its frequency shift with time didn't fit with expectations of plasma radiation associated with a CME-driven shock. It is thus hypothesized that this so-called IP type II-S event stems not from plasma radiation, but from synchrotron radiation of near-relativistic electrons caught in the CME magnetic field or the sheath region between the shock and the CME driver. Thus, this event could be representative of an altogether new type of interplanetary radio phenomenon.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3108}
{"prompt": "Rephrase the abstract of an article with title 'Modeling Heterogeneous Materials via Two-Point Correlation Functions: I.\n  Basic Principles'.\n  Heterogeneous materials abound in nature and man-made situations. Examples\ninclude porous media, biological materials, and composite materials. Diverse\nand interesting properties exhibited by these materials result from their\ncomplex microstructures, which also make it difficult to model the materials.\nIn this first part of a series of two papers, we collect the known necessary\nconditions on the standard two-point correlation function S2(r) and formulate a\nnew conjecture. In particular, we argue that given a complete two-point\ncorrelation function space, S2(r) of any statistically homogeneous material can\nbe expressed through a map on a selected set of bases of the function space. We\nprovide new examples of realizable two-point correlation functions and suggest\na set of analytical basis functions. Moreover, we devise an efficient and\nisotropy- preserving construction algorithm, namely, the Lattice-Point\nalgorithm to generate realizations of materials from their two- point\ncorrelation functions based on the Yeong-Torquato technique. Subsequent\nanalysis can be performed on the generated images to obtain desired macroscopic\nproperties. These developments are integrated here into a general scheme that\nenables one to model and categorize heterogeneous materials via two-point\ncorrelation functions.\n\n", "human_text": "  Heterogeneous materials abound in nature and man-made situations. Examples\ninclude porous media, biological materials, and composite materials. Diverse\nand interesting properties exhibited by these materials result from their\ncomplex microstructures, which also make it difficult to model the materials.\nIn this first part of a series of two papers, we collect the known necessary\nconditions on the standard two-point correlation function S2(r) and formulate a\nnew conjecture. In particular, we argue that given a complete two-point\ncorrelation function space, S2(r) of any statistically homogeneous material can\nbe expressed through a map on a selected set of bases of the function space. We\nprovide new examples of realizable two-point correlation functions and suggest\na set of analytical basis functions. Moreover, we devise an efficient and\nisotropy- preserving construction algorithm, namely, the Lattice-Point\nalgorithm to generate realizations of materials from their two- point\ncorrelation functions based on the Yeong-Torquato technique. Subsequent\nanalysis can be performed on the generated images to obtain desired macroscopic\nproperties. These developments are integrated here into a general scheme that\nenables one to model and categorize heterogeneous materials via two-point\ncorrelation functions.\n", "machine_text": "This article presents a new method for modeling heterogeneous materials with two-point correlation functions. Necessary conditions on the two-point correlation function S2(r) are set out, and a conjecture is formulated. Realizable two-point correlation functions and analytical basis functions are provided and a construction algorithm, the Lattice-Point algorithm, is devised to generate materials from two-point correlation functions based on the Yeong-Torquato technique. This technique can be used to categorize and analyze these materials in terms of their macroscopic properties.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2434}
{"prompt": "Rephrase the abstract of an article with title 'The lower mass function of the young open cluster Blanco 1: from 30 Mjup\n  to 3 Mo'.\n  We performed a deep wide field optical survey of the young (~100-150 Myr)\nopen cluster Blanco1 to study its low mass population well down into the brown\ndwarf regime and estimate its mass function over the whole cluster mass\nrange.The survey covers 2.3 square degrees in the I and z-bands down to I ~ z ~\n24 with the CFH12K camera. Considering two different cluster ages (100 and 150\nMyr), we selected cluster member candidates on the basis of their location in\nthe (I,I-z) CMD relative to the isochrones, and estimated the contamination by\nforeground late-type field dwarfs using statistical arguments, infrared\nphotometry and low-resolution optical spectroscopy. We find that our survey\nshould contain about 57% of the cluster members in the 0.03-0.6 Mo mass range,\nincluding 30-40 brown dwarfs. The candidate's radial distribution presents\nevidence that mass segregation has already occured in the cluster. We took it\ninto account to estimate the cluster mass function across the\nstellar/substellar boundary. We find that, between 0.03Mo and 0.6Mo, the\ncluster mass distribution does not depend much on its exact age, and is well\nrepresented by a single power-law, with an index alpha=0.69 +/- 0.15. Over the\nwhole mass domain, from 0.03Mo to 3Mo, the mass function is better fitted by a\nlog-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06. Comparison\nbetween the Blanco1 mass function, other young open clusters' MF, and the\ngalactic disc MF suggests that the IMF, from the substellar domain to the\nhigher mass part, does not depend much on initial conditions. We discuss the\nimplications of this result on theories developed to date to explain the origin\nof the mass distribution.\n\n", "human_text": "  We performed a deep wide field optical survey of the young (~100-150 Myr)\nopen cluster Blanco1 to study its low mass population well down into the brown\ndwarf regime and estimate its mass function over the whole cluster mass\nrange.The survey covers 2.3 square degrees in the I and z-bands down to I ~ z ~\n24 with the CFH12K camera. Considering two different cluster ages (100 and 150\nMyr), we selected cluster member candidates on the basis of their location in\nthe (I,I-z) CMD relative to the isochrones, and estimated the contamination by\nforeground late-type field dwarfs using statistical arguments, infrared\nphotometry and low-resolution optical spectroscopy. We find that our survey\nshould contain about 57% of the cluster members in the 0.03-0.6 Mo mass range,\nincluding 30-40 brown dwarfs. The candidate's radial distribution presents\nevidence that mass segregation has already occured in the cluster. We took it\ninto account to estimate the cluster mass function across the\nstellar/substellar boundary. We find that, between 0.03Mo and 0.6Mo, the\ncluster mass distribution does not depend much on its exact age, and is well\nrepresented by a single power-law, with an index alpha=0.69 +/- 0.15. Over the\nwhole mass domain, from 0.03Mo to 3Mo, the mass function is better fitted by a\nlog-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06. Comparison\nbetween the Blanco1 mass function, other young open clusters' MF, and the\ngalactic disc MF suggests that the IMF, from the substellar domain to the\nhigher mass part, does not depend much on initial conditions. We discuss the\nimplications of this result on theories developed to date to explain the origin\nof the mass distribution.\n", "machine_text": "\nWe conducted a wide-area survey of the young (~100-150 Myr) open cluster, Blanco1, with the CFH12K camera, in order to gain insight into its low-mass population and to measure its mass function across the stellar/substellar boundary. Using this data and a statistical approach, along with infrared photometry and optical spectroscopy, we identified 57% of Blanco1's cluster members in the range 0.03-0.6 Mo, including 30-40 brown dwarfs. Our findings indicate that mass segregation may have occurred in the cluster, and we incorporated this into our analysis of the mass distribution, which was well-fitted by a single power-law with an index of alpha=0.69 +/- 0.15 over the range 0.03Mo to 0.6Mo, and a log-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06 throughout an even greater mass domain from 0.03Mo to 3Mo. Through comparisons of the Blanco1 mass function with those of other young open clusters and the galactic disc, we produced evidence that the initial mass function (IMF) need not be reliant on established conditions. We discussed the implications that this has on various theories concerning the origin of the mass distribution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2102}
{"prompt": "Rephrase the abstract of an article with title 'The Physics Case for the New Muon (g-2) Experiment'.\n  This White Paper briefly reviews the present status of the muon (g-2)\nexperiment and the physics motivation for a new effort. The present comparison\nbetween experiment and theory indicates a tantalizing $3.4 \\sigma$ deviation.\nAn improvement in precision on this comparison by a factor of 2--with the\ncentral value remaining unchanged--will exceed the ``discovery'' threshold,\nwith a sensitivity above $6 \\sigma$. The 2.5-fold reduction improvement goal of\nthe new Brookhaven E969 experiment, along with continued steady reduction of\nthe standard model theory uncertainty, will achieve this more definitive test.\n  Already, the (g-2) result is arguably the most compelling indicator of\nphysics beyond the standard model and, at the very least, it represents a major\nconstraint for speculative new theories such as supersymmetry or extra\ndimensions. In this report, we summarize the present experimental status and\nprovide an up-to-date accounting of the standard model theory, including the\nexpectations for improvement in the hadronic contributions, which dominate the\noverall uncertainty. Our primary focus is on the physics case that motivates\nimproved experimental and theoretical efforts. Accordingly, we give examples of\nspecific new-physics implications in the context of direct searches at the LHC\nas well as general arguments about the role of an improved (g-2) measurement. A\nbrief summary of the plans for an upgraded effort complete the report.\n\n", "human_text": "  This White Paper briefly reviews the present status of the muon (g-2)\nexperiment and the physics motivation for a new effort. The present comparison\nbetween experiment and theory indicates a tantalizing $3.4 \\sigma$ deviation.\nAn improvement in precision on this comparison by a factor of 2--with the\ncentral value remaining unchanged--will exceed the ``discovery'' threshold,\nwith a sensitivity above $6 \\sigma$. The 2.5-fold reduction improvement goal of\nthe new Brookhaven E969 experiment, along with continued steady reduction of\nthe standard model theory uncertainty, will achieve this more definitive test.\n  Already, the (g-2) result is arguably the most compelling indicator of\nphysics beyond the standard model and, at the very least, it represents a major\nconstraint for speculative new theories such as supersymmetry or extra\ndimensions. In this report, we summarize the present experimental status and\nprovide an up-to-date accounting of the standard model theory, including the\nexpectations for improvement in the hadronic contributions, which dominate the\noverall uncertainty. Our primary focus is on the physics case that motivates\nimproved experimental and theoretical efforts. Accordingly, we give examples of\nspecific new-physics implications in the context of direct searches at the LHC\nas well as general arguments about the role of an improved (g-2) measurement. A\nbrief summary of the plans for an upgraded effort complete the report.\n", "machine_text": "This paper reviews the present condition and physics background of the muon (g-2) experiment, noting a noteworthy disagreement between the experiment and theories of 3.4 standard deviations. A new Brookhaven E969 experiment is planned with the aim of determining a more detailed examination of this discrepancy by shrinking the margin of error by up to a factor of two while still preserving the central value. This article also outlines possible theories beyond the Standard Model, and precisely how a more accurate assessment of (g-2) can give greater insight into these theories and findings from the Large Hadron Collider. Ultimately, this paper sketches the plans for a more advanced experiment and offers a compelling case for the physics behind it.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4617}
{"prompt": "Rephrase the abstract of an article with title 'Surface plasmon polaritons and surface phonon polaritons on metallic and\n  semiconducting spheres: Exact and semiclassical descriptions'.\n  We study the interaction of an electromagnetic field with a non-absorbing or\nabsorbing dispersive sphere in the framework of complex angular momentum\ntechniques. We assume that the dielectric function of the sphere presents a\nDrude-like behavior or an ionic crystal behavior modelling metallic and\nsemiconducting materials. We more particularly emphasize and interpret the\nmodifications induced in the resonance spectrum by absorption. We prove that\n\"resonant surface polariton modes\" are generated by a unique surface wave,\ni.e., a surface (plasmon or phonon) polariton, propagating close to the sphere\nsurface. This surface polariton corresponds to a particular Regge pole of the\nelectric part (TM) of the S matrix of the sphere. From the associated Regge\ntrajectory we can construct semiclassically the spectrum of the complex\nfrequencies of the resonant surface polariton modes which can be considered as\nBreit-Wigner-type resonances. Furthermore, by taking into account the Stokes\nphenomenon, we derive an asymptotic expression for the position in the complex\nangular momentum plane of the surface polariton Regge pole. We then describe\nsemiclassically the surface polariton and provide analytical expressions for\nits dispersion relation and its damping in the non-absorbing and absorbing\ncases. In these analytic expressions, we more particularly exhibit\nwell-isolated terms directly linked to absorption. Finally, we explain why the\nphoton-sphere system can be considered as an artificial atom (a ``plasmonic\natom\" or \"phononic atom\") and we briefly discuss the implication of our results\nin the context of the Casimir effect.\n\n", "human_text": "  We study the interaction of an electromagnetic field with a non-absorbing or\nabsorbing dispersive sphere in the framework of complex angular momentum\ntechniques. We assume that the dielectric function of the sphere presents a\nDrude-like behavior or an ionic crystal behavior modelling metallic and\nsemiconducting materials. We more particularly emphasize and interpret the\nmodifications induced in the resonance spectrum by absorption. We prove that\n\"resonant surface polariton modes\" are generated by a unique surface wave,\ni.e., a surface (plasmon or phonon) polariton, propagating close to the sphere\nsurface. This surface polariton corresponds to a particular Regge pole of the\nelectric part (TM) of the S matrix of the sphere. From the associated Regge\ntrajectory we can construct semiclassically the spectrum of the complex\nfrequencies of the resonant surface polariton modes which can be considered as\nBreit-Wigner-type resonances. Furthermore, by taking into account the Stokes\nphenomenon, we derive an asymptotic expression for the position in the complex\nangular momentum plane of the surface polariton Regge pole. We then describe\nsemiclassically the surface polariton and provide analytical expressions for\nits dispersion relation and its damping in the non-absorbing and absorbing\ncases. In these analytic expressions, we more particularly exhibit\nwell-isolated terms directly linked to absorption. Finally, we explain why the\nphoton-sphere system can be considered as an artificial atom (a ``plasmonic\natom\" or \"phononic atom\") and we briefly discuss the implication of our results\nin the context of the Casimir effect.\n", "machine_text": "\nThis paper examines the influence of electromagnetic fields on non-absorbent or absorbent dispersed spheres, exploring Drude-like and ionic crystal behaviours in particular. The observation of resonance spectrums and surface polariton modes are detailed, alongside Breit-Wigner-type resonances and Stokes phenomena. Analytic expressions are provided for the dispersion relation, damping and absorption of surface polaritons. Analogies are made to artificial atoms, and implications for the Casimir effect are outlined.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4212}
{"prompt": "Rephrase the abstract of an article with title 'The Thurston norm via Normal Surfaces'.\n  Given a triangulation of a closed, oriented, irreducible, atoroidal\n3-manifold every oriented, incompressible surface may be isotoped into normal\nposition relative to the triangulation. Such a normal oriented surface is then\nencoded by non-negative integer weights, 14 for each 3-simplex, that describe\nhow many copies of each oriented normal disc type there are. The Euler\ncharacteristic and homology class are both linear functions of the weights.\nThere is a convex polytope in the space of weights, defined by linear equations\ngiven by the combinatorics of the triangulation, whose image under the homology\nmap is the unit ball, B, of the Thurston norm.\n  Applications of this approach include (1) an algorithm to compute B and hence\nthe Thurston norm of any homology class, (2) an explicit exponential bound on\nthe number of vertices of B in terms of the number of simplices in the\ntriangulation, (3) an algorithm to determine the fibred faces of B and hence an\nalgorithm to decide whether a 3-manifold fibres over the circle.\n\n", "human_text": "  Given a triangulation of a closed, oriented, irreducible, atoroidal\n3-manifold every oriented, incompressible surface may be isotoped into normal\nposition relative to the triangulation. Such a normal oriented surface is then\nencoded by non-negative integer weights, 14 for each 3-simplex, that describe\nhow many copies of each oriented normal disc type there are. The Euler\ncharacteristic and homology class are both linear functions of the weights.\nThere is a convex polytope in the space of weights, defined by linear equations\ngiven by the combinatorics of the triangulation, whose image under the homology\nmap is the unit ball, B, of the Thurston norm.\n  Applications of this approach include (1) an algorithm to compute B and hence\nthe Thurston norm of any homology class, (2) an explicit exponential bound on\nthe number of vertices of B in terms of the number of simplices in the\ntriangulation, (3) an algorithm to determine the fibred faces of B and hence an\nalgorithm to decide whether a 3-manifold fibres over the circle.\n", "machine_text": "\nUsing a given triangulation for a closed, orientable, irreducible, atoroidal 3-manifold, we define an encoding of each normal, oriented surface using non-negative integer weights and use this to construct a convex polytope in the relevant space of weights which maps to the unit-ball of the Thurston norm via a linear homology map. This has several applications, including a linear-time algorithm to compute the Thurston norm and intricate upper-bounds on the number of vertices of the polytope in terms of the number of simplices. Moreover, one can efficiently decide if a 3-manifold stems from a fibred face of the polytope in order to determine if the 3-manifold is capable of fibreing over the circle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0673}
{"prompt": "Rephrase the abstract of an article with title 'A Cascade Model for Particle Concentration and Enstrophy in Fully\n  Developed Turbulence with Mass Loading Feedback'.\n  A cascade model is described based on multiplier distributions determined\nfrom 3D direct numerical simulations (DNS) of turbulent particle laden flows,\nwhich include two-way coupling between the phases at global mass loadings equal\nto unity. The governing Eulerian equations are solved using pseudo-spectral\nmethods on up to 512**3 computional grid points. DNS results for particle\nconcentration and enstrophy at Taylor microscale Reynolds numbers in the range\n34 - 170 were used to directly determine multiplier distributions (PDFs) on\nspatial scales 3 times the Kolmogorov length scale. The width of the PDFs,\nwhich is a measure of intermittency, decreases with increasing mass loading\nwithin the local region where the multipliers are measured. The functional form\nof this dependence is not sensitive to Reynolds numbers in the range\nconsidered. A partition correlation probability is included in the cascade\nmodel to account for the observed spatial anticorrelation between particle\nconcentration and enstrophy. Joint probability distribution functions of\nconcentration and enstrophy generated using the cascade model are shown to be\nin excellent agreement with those derived directly from our 3D simulations.\nProbabilities predicted by the cascade model are presented at Reynolds numbers\nwell beyond what is achievable by direct simulation. These results clearly\nindicate that particle mass loading significantly reduces the probabilities of\nhigh particle concentration and enstrophy relative to those resulting from\nunloaded runs. Particle mass density appears to reach a limit at around 100\ntimes the gas density. This approach has promise for significant computational\nsavings in certain applications.\n\n", "human_text": "  A cascade model is described based on multiplier distributions determined\nfrom 3D direct numerical simulations (DNS) of turbulent particle laden flows,\nwhich include two-way coupling between the phases at global mass loadings equal\nto unity. The governing Eulerian equations are solved using pseudo-spectral\nmethods on up to 512**3 computional grid points. DNS results for particle\nconcentration and enstrophy at Taylor microscale Reynolds numbers in the range\n34 - 170 were used to directly determine multiplier distributions (PDFs) on\nspatial scales 3 times the Kolmogorov length scale. The width of the PDFs,\nwhich is a measure of intermittency, decreases with increasing mass loading\nwithin the local region where the multipliers are measured. The functional form\nof this dependence is not sensitive to Reynolds numbers in the range\nconsidered. A partition correlation probability is included in the cascade\nmodel to account for the observed spatial anticorrelation between particle\nconcentration and enstrophy. Joint probability distribution functions of\nconcentration and enstrophy generated using the cascade model are shown to be\nin excellent agreement with those derived directly from our 3D simulations.\nProbabilities predicted by the cascade model are presented at Reynolds numbers\nwell beyond what is achievable by direct simulation. These results clearly\nindicate that particle mass loading significantly reduces the probabilities of\nhigh particle concentration and enstrophy relative to those resulting from\nunloaded runs. Particle mass density appears to reach a limit at around 100\ntimes the gas density. This approach has promise for significant computational\nsavings in certain applications.\n", "machine_text": "\nA cascade model is developed for particle concentration and enstrophy in fully developed turbulence with mass loading feedback, assessed using 3D direct numerical simulations. The governing Eulerian equations are solved using pseudo-spectral methods on up to 512**3 grid points, and the resultant multiplier distributions, which present a measure of intermittency, decrease with increasing mass loading within the local region where the multipliers are measured. A partition correlation probability is proposed to account for the spatial anticorrelation between particle concentration and enstrophy, and joint probability distribution functions of concentration and enstrophy produced by the cascade model are found to correlate closely with those determined directly from the simulations. Probabilities are also predicted at Reynolds numbers well beyond direct simulation capability, indicating that particle mass loading decreases the probability of high concentrations and enstrophy relative to unloaded runs. It is concluded that this model may enable significant computational savings in certain applications, and suggests a particle mass density threshold of around 100 times the gas density.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.181}
{"prompt": "Rephrase the abstract of an article with title 'Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale\n  bar funnelling gas into the nuclear region'.\n  This work is part of the NUGA survey of CO emission in nearby active\ngalaxies. We present observations of NGC4569, a member of the Virgo Cluster. We\nanalyse the molecular gas distribution and kinematics in the central region and\nwe investigate a possible link to the strong starburst present at the nucleus.\n70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is found\nto be concentrated within the inner 800 pc and is distributed along the large\nscale stellar bar seen in near-infrared observations. A hole in the CO\ndistribution coincides with the nucleus where most of the Halpha emission and\nblue light are emitted. The kinematics are modelled in three different ways,\nranging from the purely geometrical to the most physical. This approach allows\nus to constrain progressively the physical properties of the galaxy and\neventually to emerge with a reasonable fit to an analytical model of orbits in\na barred potential. Fitting an axisymmetric model shows that the non-circular\nmotions must be comparable in amplitude to the circular motions (120 km/s).\nFitting a model based on elliptical orbits allows us to identify with\nconfidence the single inner Lindblad resonance (ILR) of the large scale bar.\nFinally, a model based on analytical solutions for the gas particle orbits in a\nweakly barred potential constrained by the ILR radius reproduces the\nobservations well. The mass inflow rate is then estimated and discussed based\non the best fit model solution. The gravitational torques implied by this model\nare able to efficiently funnel the gas inside the ILR down to 300 pc, although\nanother mechanism must take over to fuel the nuclear starburst inside 100 pc.\n\n", "human_text": "  This work is part of the NUGA survey of CO emission in nearby active\ngalaxies. We present observations of NGC4569, a member of the Virgo Cluster. We\nanalyse the molecular gas distribution and kinematics in the central region and\nwe investigate a possible link to the strong starburst present at the nucleus.\n70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is found\nto be concentrated within the inner 800 pc and is distributed along the large\nscale stellar bar seen in near-infrared observations. A hole in the CO\ndistribution coincides with the nucleus where most of the Halpha emission and\nblue light are emitted. The kinematics are modelled in three different ways,\nranging from the purely geometrical to the most physical. This approach allows\nus to constrain progressively the physical properties of the galaxy and\neventually to emerge with a reasonable fit to an analytical model of orbits in\na barred potential. Fitting an axisymmetric model shows that the non-circular\nmotions must be comparable in amplitude to the circular motions (120 km/s).\nFitting a model based on elliptical orbits allows us to identify with\nconfidence the single inner Lindblad resonance (ILR) of the large scale bar.\nFinally, a model based on analytical solutions for the gas particle orbits in a\nweakly barred potential constrained by the ILR radius reproduces the\nobservations well. The mass inflow rate is then estimated and discussed based\non the best fit model solution. The gravitational torques implied by this model\nare able to efficiently funnel the gas inside the ILR down to 300 pc, although\nanother mechanism must take over to fuel the nuclear starburst inside 100 pc.\n", "machine_text": "\nThis work is part of the NUGA survey that examines the presence of molecular gas in nearby galaxies. In this paper, we analyse the observations of NGC4569, located in the Virgo Cluster, to investigate the correlation between the starburst at the nucleus and the molecular gas content. We find that 70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is concentrated in the area of 800 pc or less and is evenly distributed along the long-scale stellar bar in the near-infrared images. The gap in the CO distribution matches the nucleus, where most of the Halpha and blue light emissions arise. To obtain better understanding of the galaxy's physical characteristics, we use three models to measure the kinematics of the gas: a pure geometrical one, one based on elliptical orbits, and one using analytical solutions of orbits in a slightly barred potential. We then calculate the mass inflow rate from the most accurate model. The data suggests that the gravitational tugs from the large scale bar can funnel gas from the inner Lindblad Resonance down to a distance of 300 pc. However, another mechanism may be necessary to fuel the starburst at 100 pc or less.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3662}
{"prompt": "Rephrase the abstract of an article with title 'The dynamics of the early universe and the initial conditions for\n  inflation in a model with radiation and a Chaplygin gas'.\n  The modeling of the early universe is done through the quantization of a\nFriedmann-Robertson-Walker model with positive curvature. The material content\nconsists of two fluids: radiation and Chaplygin gas. The quantization of these\nmodels is made by following the Wheeler and DeWitt's prescriptions. Using the\nSchutz formalism, the time notion is recovered and the Wheeler-DeWitt equation\ntransforms into a time dependent Schr\\\"{o}dinger equation, which rules the\ndynamics of the early universe, under the action of an effective potential\n$V_{ef}$. Using a finite differences method and the Crank-Nicholson scheme, in\na code implemented in the program OCTAVE, we solve the corresponding time\ndependent Schr\\\"{o}dinger equation and obtain the time evolution of a initial\nwave packet. This wave packet satisfies appropriate boundary conditions. The\ncalculation of the tunneling probabilities shows that the universe may emerge\nfrom the Planck era to an inflationary phase. It also shows that, the tunneling\nprobability is a function of the mean energy of the initial wave packet and of\ntwo parameters related to the Chaplygin gas. We also show a comparison between\nthese results and those obtained by the WKB approximation.\n\n", "human_text": "  The modeling of the early universe is done through the quantization of a\nFriedmann-Robertson-Walker model with positive curvature. The material content\nconsists of two fluids: radiation and Chaplygin gas. The quantization of these\nmodels is made by following the Wheeler and DeWitt's prescriptions. Using the\nSchutz formalism, the time notion is recovered and the Wheeler-DeWitt equation\ntransforms into a time dependent Schr\\\"{o}dinger equation, which rules the\ndynamics of the early universe, under the action of an effective potential\n$V_{ef}$. Using a finite differences method and the Crank-Nicholson scheme, in\na code implemented in the program OCTAVE, we solve the corresponding time\ndependent Schr\\\"{o}dinger equation and obtain the time evolution of a initial\nwave packet. This wave packet satisfies appropriate boundary conditions. The\ncalculation of the tunneling probabilities shows that the universe may emerge\nfrom the Planck era to an inflationary phase. It also shows that, the tunneling\nprobability is a function of the mean energy of the initial wave packet and of\ntwo parameters related to the Chaplygin gas. We also show a comparison between\nthese results and those obtained by the WKB approximation.\n", "machine_text": "\nA Friedmann-Robertson-Walker model with positive curvature is employed to understand the dynamics of the early universe and the initial conditions for inflation. This particular model contains two fluids, radiation and a Chaplygin gas, and is quantized using the Wheeler-DeWitt prescriptions. The Schutz formalism permits the transformation of the Wheeler-DeWitt equation into a time-dependent Schr\\\"{o}dinger equation, the dynamics of which can be described by an effective potential $V_{ef}$. Using a code implemented in OCTAVE and finite differences method, the time-dependent Schr\\\"{o}dinger equation can be solved and the time evolution of an initial wave packet determined. The wave packet satisfies appropriate boundary conditions and the calculation of tunneling probabilities shows that the universe may transition from the Planck era to an inflationary phase. The tunneling probability can further be affected by the mean energy of the initial wave packet and two parameters related to the Chaplygin gas, and these results are verified by the WKB approximation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2585}
{"prompt": "Rephrase the abstract of an article with title 'A Systematic Study of the Final Masses of Gas Giant Planets'.\n  We construct an analytic model for the rate of gas accretion onto a planet\nembedded in a protoplanetary disk as a function of planetary mass, disk\nviscosity, disk scale height, and unperturbed surface density in order to study\nthe long-term accretion and final masses of gas giant planets. We first derive\nan analytical formula for surface density profile near the planetary orbit from\nconsiderations of the balance of force and the dynamical stability. Using it in\nthe empirical formula linking surface density with gas accretion rate that is\nderived based on hydrodynamic simulations of Tanigawa and Watanabe (2002, ApJ\n586, 506), we then simulate the mass evolution of gas giant planets in\nviscously-evolving disks. We finally determine the final mass as a function of\nsemi-major axis of the planet. We find that the disk can be divided into three\nregions characterized by different processes by which the final mass is\ndetermined. In the inner region, the planet grows quickly and forms a deep gap\nto suppress the growth by itself before disk dissipation. The final mass of the\nplanet in this region is found to increase with the semi-major axis in a\nsimilar way to the mass given by the viscous condition for gap opening, but the\nformer is larger by a factor of approximately 10 than the latter. In the\nintermediate region, viscous diffusion of the disk gas limits the gas accretion\nbefore the planet form a deep gap. The final mass can be up to the disk mass,\nwhen disk viscous evolution occurs faster than disk evaporation. In the outer\nregion, planets capture only tiny amounts of gas within the lifetime of the\ndisk to form Neptune-like planets. We derive analytic formulae for the final\nmasses in the different regions and the locations of the boundaries, which are\nhelpful to gain a systematic understanding of the masses of gas giant planets.\n\n", "human_text": "  We construct an analytic model for the rate of gas accretion onto a planet\nembedded in a protoplanetary disk as a function of planetary mass, disk\nviscosity, disk scale height, and unperturbed surface density in order to study\nthe long-term accretion and final masses of gas giant planets. We first derive\nan analytical formula for surface density profile near the planetary orbit from\nconsiderations of the balance of force and the dynamical stability. Using it in\nthe empirical formula linking surface density with gas accretion rate that is\nderived based on hydrodynamic simulations of Tanigawa and Watanabe (2002, ApJ\n586, 506), we then simulate the mass evolution of gas giant planets in\nviscously-evolving disks. We finally determine the final mass as a function of\nsemi-major axis of the planet. We find that the disk can be divided into three\nregions characterized by different processes by which the final mass is\ndetermined. In the inner region, the planet grows quickly and forms a deep gap\nto suppress the growth by itself before disk dissipation. The final mass of the\nplanet in this region is found to increase with the semi-major axis in a\nsimilar way to the mass given by the viscous condition for gap opening, but the\nformer is larger by a factor of approximately 10 than the latter. In the\nintermediate region, viscous diffusion of the disk gas limits the gas accretion\nbefore the planet form a deep gap. The final mass can be up to the disk mass,\nwhen disk viscous evolution occurs faster than disk evaporation. In the outer\nregion, planets capture only tiny amounts of gas within the lifetime of the\ndisk to form Neptune-like planets. We derive analytic formulae for the final\nmasses in the different regions and the locations of the boundaries, which are\nhelpful to gain a systematic understanding of the masses of gas giant planets.\n", "machine_text": "\nThis paper focuses on understanding how the final mass of gas giant planets is determined in protoplanetary disks. To address this issue, we construct an analytical model which relates the rate of gas accretion onto a planet to the planetary mass, disk viscosity, disk scale height and unperturbed surface density in the disk. Furthermore, utilizing an empirical formula relating surface density and gas accretion rate derived from hydrodynamical simulations of Tanigawa and Watanabe (2002), we carry out a series of simulations analyzing the mass evolution of gas giant planets in viscous disks. Our results indicate that the disk can be divided into three regions, each with its own process for determining the planet's final mass. In the inner region, the planet rapidly reaches a limit before the disk dissipates, with the final mass larger than the mass given by the viscous condition for gap-opening by a factor of 10. In the intermediate region, the gas accretion onto the planet is limited by viscous diffusion while in the outer region, planets capture only minimal amounts of gas to form Neptune-like planets. We provide analytical formulae for the final masses and the boundaries in these regions, allowing for a systematic understanding of the masses of gas giant planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4343}
{"prompt": "Rephrase the abstract of an article with title 'The power of choice in network growth'.\n  The \"power of choice\" has been shown to radically alter the behavior of a\nnumber of randomized algorithms. Here we explore the effects of choice on\nmodels of tree and network growth. In our models each new node has k randomly\nchosen contacts, where k > 1 is a constant. It then attaches to whichever one\nof these contacts is most desirable in some sense, such as its distance from\nthe root or its degree. Even when the new node has just two choices, i.e., when\nk=2, the resulting network can be very different from a random graph or tree.\nFor instance, if the new node attaches to the contact which is closest to the\nroot of the tree, the distribution of depths changes from Poisson to a\ntraveling wave solution. If the new node attaches to the contact with the\nsmallest degree, the degree distribution is closer to uniform than in a random\ngraph, so that with high probability there are no nodes in the network with\ndegree greater than O(log log N). Finally, if the new node attaches to the\ncontact with the largest degree, we find that the degree distribution is a\npower law with exponent -1 up to degrees roughly equal to k, with an\nexponential cutoff beyond that; thus, in this case, we need k >> 1 to see a\npower law over a wide range of degrees.\n\n", "human_text": "  The \"power of choice\" has been shown to radically alter the behavior of a\nnumber of randomized algorithms. Here we explore the effects of choice on\nmodels of tree and network growth. In our models each new node has k randomly\nchosen contacts, where k > 1 is a constant. It then attaches to whichever one\nof these contacts is most desirable in some sense, such as its distance from\nthe root or its degree. Even when the new node has just two choices, i.e., when\nk=2, the resulting network can be very different from a random graph or tree.\nFor instance, if the new node attaches to the contact which is closest to the\nroot of the tree, the distribution of depths changes from Poisson to a\ntraveling wave solution. If the new node attaches to the contact with the\nsmallest degree, the degree distribution is closer to uniform than in a random\ngraph, so that with high probability there are no nodes in the network with\ndegree greater than O(log log N). Finally, if the new node attaches to the\ncontact with the largest degree, we find that the degree distribution is a\npower law with exponent -1 up to degrees roughly equal to k, with an\nexponential cutoff beyond that; thus, in this case, we need k >> 1 to see a\npower law over a wide range of degrees.\n", "machine_text": "\n\nThe effects of introducing choice into tree and network growth models are studied in this paper. At each step, the newly introduced node connects to one of its k randomly chosen contacts, chosen based on some criterion, such as distance to the root or degree. We find that even when k=2, the resulting network has notable differences from a regular random graph or tree. For instance, if the new node attaches to the nearest contact to the root, we observe an alteration of the depths distribution from Poisson to a traveling wave solution. Additionally, when the node attaches to the contact with the smallest degree, we observe the degree distribution is closer to uniform than in a random graph, and when the node attaches to the largest degree, the degree distribution is a power law with exponent -1 up until k degrees, followed by an exponential cutoff. Consequently, large k values are necessary to observe a power law over a wide degree range.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1882}
{"prompt": "Rephrase the abstract of an article with title 'Constraining dark energy via baryon acoustic oscillations in the\n  (an)isotropic light-cone power spectrum'.\n  The measurement of the scale of the baryon acoustic oscillations (BAO) in the\ngalaxy power spectrum as a function of redshift is a promising method to\nconstrain the equation-of-state parameter of the dark energy w. To measure the\nscale of the BAO precisely, a substantial volume of space must be surveyed. We\ntest whether light-cone effects are important and whether the scaling relations\nused to compensate for an incorrect reference cosmology are in this case\nsufficiently accurate. We investigate the degeneracies in the cosmological\nparameters and the benefits of using the two-dimensional anisotropic power\nspectrum. Finally, we estimate the uncertainty with which w can be measured by\nproposed surveys at redshifts of about z=3 and z=1, respectively.\n  In the simulated survey we find that light-cone effects are small and that\nthe simple scaling relations used to correct for the cosmological distortion\nwork fairly well even for large survey volumes. The analysis of the\ntwo-dimensional anisotropic power spectra enables an independent determination\nto be made of the apparent scale of the BAO, perpendicular and parallel to the\nline of sight. This is essential for two-parameter w-models, such as the\nredshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for\nthe matter and baryon density and Delta(H_0)=5% for the Hubble constant, we\nestimate that the BAO measurements of future surveys around z=3 and z=1 will be\nable to constrain, independently of other cosmological probes, a constant w to\n~ 12% and ~ 11% (68% c.l.), respectively.\n\n", "human_text": "  The measurement of the scale of the baryon acoustic oscillations (BAO) in the\ngalaxy power spectrum as a function of redshift is a promising method to\nconstrain the equation-of-state parameter of the dark energy w. To measure the\nscale of the BAO precisely, a substantial volume of space must be surveyed. We\ntest whether light-cone effects are important and whether the scaling relations\nused to compensate for an incorrect reference cosmology are in this case\nsufficiently accurate. We investigate the degeneracies in the cosmological\nparameters and the benefits of using the two-dimensional anisotropic power\nspectrum. Finally, we estimate the uncertainty with which w can be measured by\nproposed surveys at redshifts of about z=3 and z=1, respectively.\n  In the simulated survey we find that light-cone effects are small and that\nthe simple scaling relations used to correct for the cosmological distortion\nwork fairly well even for large survey volumes. The analysis of the\ntwo-dimensional anisotropic power spectra enables an independent determination\nto be made of the apparent scale of the BAO, perpendicular and parallel to the\nline of sight. This is essential for two-parameter w-models, such as the\nredshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for\nthe matter and baryon density and Delta(H_0)=5% for the Hubble constant, we\nestimate that the BAO measurements of future surveys around z=3 and z=1 will be\nable to constrain, independently of other cosmological probes, a constant w to\n~ 12% and ~ 11% (68% c.l.), respectively.\n", "machine_text": "\nBaryon acoustic oscillations (BAO) of the galaxy power spectrum could be used to\ntightly constrain the properties of dark energy given an observed large enough\nspace volume. This study examines projected light-cone effects and the use of\nscaling relations for an incorrect cosmological reference. Furthermore, the\ncosmological degeneracies and the use of anisotropic two-dimensional power\nspectra are explored. The goodness of the measurements depended highly on the\nassumed values of matter and baryon density, as well as the Hubble rate. The\nBAO data from upcoming surveys around redshifts z=3 and z=1 were used to\nestimate that a constant dark energy equation-of-state w can be constrained to\n~12% and ~11% at the 68% c.l., respectively; when Planck priors and a Delta(H_0)\nof 5% are used.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0354}
{"prompt": "Rephrase the abstract of an article with title 'Positivity and almost positivity of biharmonic Green's functions under\n  Dirichlet boundary conditions'.\n  In general, for higher order elliptic equations and boundary value problems\nlike the biharmonic equation and the linear clamped plate boundary value\nproblem neither a maximum principle nor a comparison principle or --\nequivalently -- a positivity preserving property is available. The problem is\nrather involved since the clamped boundary conditions prevent the boundary\nvalue problem {from} being reasonably written as a system of second order\nboundary value problems.\n  It is shown that, on the other hand, for bounded smooth domains $\\Omega\n\\subset\\mathbb{R}^n$, the negative part of the corresponding Green's function\nis \"small\" when compared with its singular positive part, provided $n\\ge 3$.\n  Moreover, the biharmonic Green's function in balls $B\\subset\\mathbb{R}^n$\nunder Dirichlet (i.e. clamped) boundary conditions is known explicitly and is\npositive. It has been known for some time that positivity is preserved under\nsmall regular perturbations of the domain, if $n=2$. In the present paper, such\na stability result is proved for $n\\ge 3$. Keywords: Biharmonic Green's\nfunctions, positivity, almost positivity, blow-up procedure.\n\n", "human_text": "  In general, for higher order elliptic equations and boundary value problems\nlike the biharmonic equation and the linear clamped plate boundary value\nproblem neither a maximum principle nor a comparison principle or --\nequivalently -- a positivity preserving property is available. The problem is\nrather involved since the clamped boundary conditions prevent the boundary\nvalue problem {from} being reasonably written as a system of second order\nboundary value problems.\n  It is shown that, on the other hand, for bounded smooth domains $\\Omega\n\\subset\\mathbb{R}^n$, the negative part of the corresponding Green's function\nis \"small\" when compared with its singular positive part, provided $n\\ge 3$.\n  Moreover, the biharmonic Green's function in balls $B\\subset\\mathbb{R}^n$\nunder Dirichlet (i.e. clamped) boundary conditions is known explicitly and is\npositive. It has been known for some time that positivity is preserved under\nsmall regular perturbations of the domain, if $n=2$. In the present paper, such\na stability result is proved for $n\\ge 3$. Keywords: Biharmonic Green's\nfunctions, positivity, almost positivity, blow-up procedure.\n", "machine_text": "\nThis paper examines the positivity and near-positivity of biharmonic Green's function with Dirichlet boundary conditions. When higher order elliptic equations and boundary value problems such as the biharmonic equation and the linear clamped plate boundary value problem are considered, a maximum principle, comparison principle, or positivity are not available. This is due to the clamped boundary conditions not allowing the boundary value problem to be thoroughly written as a system of second order boundary value problems. It is revealed, however, that for bounded domains $\\Omega\\subset\\mathbb{R}^n$, with $n\\ge 3$, the negative portion of the Green's function is minor compared to its singular positive portion. Additionally, the biharmonic Green's function for balls $B\\subset\\mathbb{R}^n$ has been proven to be positive under Dirichlet boundary conditions, and is known explicitly. It has been known for some time that the perturbations of the domain in two-dimensions lead to positivity being preserved, and the present study shows this to be true for any $n\\ge 3$ as well.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3301}
{"prompt": "Rephrase the abstract of an article with title 'Radial density profiles of time-delay lensing galaxies'.\n  We present non-parametric radial mass profiles for ten QSO strong lensing\ngalaxies. Five of the galaxies have profiles close to $\\rho(r)\\propto r^{-2}$,\nwhile the rest are closer to r^{-1}, consistent with an NFW profile. The former\nare all relatively isolated early-types and dominated by their stellar light.\nThe latter --though the modeling code did not know this-- are either in\nclusters, or have very high mass-to-light, suggesting dark-matter dominant\nlenses (one is a actually pair of merging galaxies). The same models give\n$H_0^{-1} = 15.2_{-1.7}^{+2.5}\\Gyr$ ($H_0 = 64_{-9}^{+8} \\legacy$), consistent\nwith a previous determination. When tested on simulated lenses taken from a\ncosmological hydrodynamical simulation, our modeling pipeline recovers both H_0\nand $\\rho(r)$ within estimated uncertainties. Our result is contrary to some\nrecent claims that lensing time delays imply either a low H_0 or galaxy\nprofiles much steeper than r^{-2}. We diagnose these claims as resulting from\nan invalid modeling approximation: that small deviations from a power-law\nprofile have a small effect on lensing time-delays. In fact, as we show using\nusing both perturbation theory and numerical computation from a\ngalaxy-formation simulation, a first-order perturbation of an isothermal lens\ncan produce a zeroth-order change in the time delays.\n\n", "human_text": "  We present non-parametric radial mass profiles for ten QSO strong lensing\ngalaxies. Five of the galaxies have profiles close to $\\rho(r)\\propto r^{-2}$,\nwhile the rest are closer to r^{-1}, consistent with an NFW profile. The former\nare all relatively isolated early-types and dominated by their stellar light.\nThe latter --though the modeling code did not know this-- are either in\nclusters, or have very high mass-to-light, suggesting dark-matter dominant\nlenses (one is a actually pair of merging galaxies). The same models give\n$H_0^{-1} = 15.2_{-1.7}^{+2.5}\\Gyr$ ($H_0 = 64_{-9}^{+8} \\legacy$), consistent\nwith a previous determination. When tested on simulated lenses taken from a\ncosmological hydrodynamical simulation, our modeling pipeline recovers both H_0\nand $\\rho(r)$ within estimated uncertainties. Our result is contrary to some\nrecent claims that lensing time delays imply either a low H_0 or galaxy\nprofiles much steeper than r^{-2}. We diagnose these claims as resulting from\nan invalid modeling approximation: that small deviations from a power-law\nprofile have a small effect on lensing time-delays. In fact, as we show using\nusing both perturbation theory and numerical computation from a\ngalaxy-formation simulation, a first-order perturbation of an isothermal lens\ncan produce a zeroth-order change in the time delays.\n", "machine_text": "\nThrough this study, we investigate the mass profiles of 10 quasar strong lensing galaxies. Five of the galaxies have density profiles that are similar to $r^{-2}$ while the other five are close to $r^{-1}$, which is similar to the NFW profile. The former lens samples are mainly isolated early-type galaxies with higher stellar mass, while the latter ones are either in clusters or have a high mass-to-light ratio, indicating that they are dominated by dark matter. Furthermore, the same models give an estimated value for the Hubble constant ($H_0$) of 64 $\\pm$ 9 (km/s)/Mpc. To determine accuracy, the same model was applied to simulated lenses from cosmological hydrodynamic simulations and it was observed that the calculated $H_0$ and radial density profiles were consistent with the expected results. This implies that several recent studies that suggested low values for $H_0$ and profiles much steeper than $r^{-2}$ may have used an inappropriate modeling approximation. Additionally, our analysis demonstrates that perturbations of an isothermal lens can lead to changes in time-delays at a zeroth order.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3267}
{"prompt": "Rephrase the abstract of an article with title 'A Unified Approach to Energy-Efficient Power Control in Large CDMA\n  Systems'.\n  A unified approach to energy-efficient power control is proposed for\ncode-division multiple access (CDMA) networks. The approach is applicable to a\nlarge family of multiuser receivers including the matched filter, the\ndecorrelator, the linear minimum mean-square error (MMSE) receiver, and the\n(nonlinear) optimal detectors. It exploits the linear relationship that has\nbeen shown to exist between the transmit power and the output\nsignal-to-interference-plus-noise ratio (SIR) in the large-system limit. It is\nshown that, for this family of receivers, when users seek to selfishly maximize\ntheir own energy efficiency, the Nash equilibrium is SIR-balanced. In addition,\na unified power control (UPC) algorithm for reaching the Nash equilibrium is\nproposed. The algorithm adjusts the user's transmit powers by iteratively\ncomputing the large-system multiuser efficiency, which is independent of\ninstantaneous spreading sequences. The convergence of the algorithm is proved\nfor the matched filter, the decorrelator, and the MMSE receiver, and is\ndemonstrated by means of simulation for an optimal detector. Moreover, the\nperformance of the algorithm in finite-size systems is studied and compared\nwith that of a conventional power control scheme, in which user powers depend\non the instantaneous spreading sequences.\n\n", "human_text": "  A unified approach to energy-efficient power control is proposed for\ncode-division multiple access (CDMA) networks. The approach is applicable to a\nlarge family of multiuser receivers including the matched filter, the\ndecorrelator, the linear minimum mean-square error (MMSE) receiver, and the\n(nonlinear) optimal detectors. It exploits the linear relationship that has\nbeen shown to exist between the transmit power and the output\nsignal-to-interference-plus-noise ratio (SIR) in the large-system limit. It is\nshown that, for this family of receivers, when users seek to selfishly maximize\ntheir own energy efficiency, the Nash equilibrium is SIR-balanced. In addition,\na unified power control (UPC) algorithm for reaching the Nash equilibrium is\nproposed. The algorithm adjusts the user's transmit powers by iteratively\ncomputing the large-system multiuser efficiency, which is independent of\ninstantaneous spreading sequences. The convergence of the algorithm is proved\nfor the matched filter, the decorrelator, and the MMSE receiver, and is\ndemonstrated by means of simulation for an optimal detector. Moreover, the\nperformance of the algorithm in finite-size systems is studied and compared\nwith that of a conventional power control scheme, in which user powers depend\non the instantaneous spreading sequences.\n", "machine_text": "\nThis paper presents a unified power control algorithm for maximizing energy-efficiency in large CDMA networks. This approach is applicable to a range of multiuser receivers, including the matched filter, decorrelator, linear minimum mean-square error receiver, and optimal detectors. It exploits the linear relation between power and output signal-to-interference-plus-noise ratio in large systems, demonstrating that selfish users will seek SIR-balanced equilibriums. The power control algorithm is shown to converge for the matched filter, decorrelator, and MMSE receiver when calculating multiuser efficiency through the iterative process, free from the user's instantaneous spreading sequences. Its performance is tested and compared to conventional power control in finite-size systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3881}
{"prompt": "Rephrase the abstract of an article with title 'Nonequilibrium spin-dependent phenomena in mesoscopic\n  superconductor-normal metal tunnel structures'.\n  We analyze the broad range of spin-dependent nonequilibrium transport\nproperties of hybrid systems composed of a normal region tunnel coupled to two\nsuperconductors with exchange fields induced by the proximity to thin\nferromagnetic layers and highlight its functionalities. By calculating the\nquasiparticle distribution functions in the normal region we find that they are\nspin-dependent and strongly sensitive to the relative angle between exchange\nfields in the two superconductors. The impact of inelastic collisions on their\nproperties is addressed. As a result, the electric current flowing through the\nsystem is found to be strongly dependent on the relative angle between exchange\nfields, giving rise to a huge value of magnetoresistance. Moreover, the current\npresents a complete spin-polarization in a wide range of bias voltages, even in\nthe quasiequilibrium case. In the nonequilibrium limit we parametrize the\ndistributions with an ``effective`` temperature, which turns out to be strongly\nspin-dependent, though quite sensitive to inelastic collisions. By tunnel\ncoupling the normal region to an additional superconducting electrode we show\nthat it is possible to implement a spin-polarized current source of both spin\nspecies, depending on the bias voltages applied.\n\n", "human_text": "  We analyze the broad range of spin-dependent nonequilibrium transport\nproperties of hybrid systems composed of a normal region tunnel coupled to two\nsuperconductors with exchange fields induced by the proximity to thin\nferromagnetic layers and highlight its functionalities. By calculating the\nquasiparticle distribution functions in the normal region we find that they are\nspin-dependent and strongly sensitive to the relative angle between exchange\nfields in the two superconductors. The impact of inelastic collisions on their\nproperties is addressed. As a result, the electric current flowing through the\nsystem is found to be strongly dependent on the relative angle between exchange\nfields, giving rise to a huge value of magnetoresistance. Moreover, the current\npresents a complete spin-polarization in a wide range of bias voltages, even in\nthe quasiequilibrium case. In the nonequilibrium limit we parametrize the\ndistributions with an ``effective`` temperature, which turns out to be strongly\nspin-dependent, though quite sensitive to inelastic collisions. By tunnel\ncoupling the normal region to an additional superconducting electrode we show\nthat it is possible to implement a spin-polarized current source of both spin\nspecies, depending on the bias voltages applied.\n", "machine_text": "\nWe explore the wide array of spin-dependent, non-equilibrium transport phenomena in systems that feature a normal region coupled to two superconductors where exchange fields are generated by their proximity to thin ferromagnetic layers. By calculating the quasiparticle distribution functions in the normal region, we observe that they possess spin-dependence, as well as being highly sensitive to the angle between the exchange fields of the two superconductors. We also examine the effect of inelastic collisions on these properties. Our results show that the current that flows through the system is strongly affected by the relative angle between exchange fields, resulting in an exceedingly high value of magnetoresistance. Furthermore, the current is completely spin-polarized within a large range of bias voltages, even in the quasi-equilibrium situation. In the non-equilibrium limit, we use an ``effective`` temperature to characterize the distributions and find that it is spin-dependent, though quite susceptible to inelastic collisions. Lastly, by connecting the normal region to an extra superconducting electrode, we establish that it is possible to produce spin-polarized current sources of either spin species, depending on the applied bias voltages.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0152}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of Phase-Space Density in Dark Matter Halos'.\n  The evolution of the phase-space density profile in dark matter (DM) halos is\ninvestigated by means of constrained simulations, designed to control the\nmerging history of a given DM halo. Halos evolve through a series of quiescent\nphases of a slow accretion intermitted by violent events of major mergers. In\nthe quiescent phases the density of the halo closely follows the NFW profile\nand the phase-space density profile, Q(r), is given by the Taylor & Navarro\npower law, r^{-beta}, where beta ~ 1.9 and stays remarkably stable over the\nHubble time. Expressing the phase-space density by the NFW parameters, Q(r)=Qs\n(r/Rs)^{-beta}, the evolution of Q is determined by Qs. We have found that the\neffective mass surface density within Rs, Sigma_s = rhos Rs, remains constant\nthroughout the evolution of a given DM halo along the main branch of its\nmerging tree. This invariance entails that Qs ~ Rs^{-5/2} and Q(r) ~\nSigma_s^{-1/2} Rs^{-5/2} (r/ Rs)^{-beta}. It follows that the phase-space\ndensity remains constant, in the sense of Qs=const., in the quiescent phases\nand it decreases as Rs^{-5/2} in the violent ones. The physical origin of the\nNFW density profile and the phase-space density power law is still unknown.\nYet, the numerical experiments show that halos recover these relations after\nthe violent phases. The major mergers drive Rs to increase and Qs to decrease\ndiscontinuously while keeping Qs Rs^{5/2} = const. The virial equilibrium in\nthe quiescent phases implies that a DM halos evolves along a sequence of NFW\nprofiles with constant energy per unit volume (i.e., pressure) within Rs.\n\n", "human_text": "  The evolution of the phase-space density profile in dark matter (DM) halos is\ninvestigated by means of constrained simulations, designed to control the\nmerging history of a given DM halo. Halos evolve through a series of quiescent\nphases of a slow accretion intermitted by violent events of major mergers. In\nthe quiescent phases the density of the halo closely follows the NFW profile\nand the phase-space density profile, Q(r), is given by the Taylor & Navarro\npower law, r^{-beta}, where beta ~ 1.9 and stays remarkably stable over the\nHubble time. Expressing the phase-space density by the NFW parameters, Q(r)=Qs\n(r/Rs)^{-beta}, the evolution of Q is determined by Qs. We have found that the\neffective mass surface density within Rs, Sigma_s = rhos Rs, remains constant\nthroughout the evolution of a given DM halo along the main branch of its\nmerging tree. This invariance entails that Qs ~ Rs^{-5/2} and Q(r) ~\nSigma_s^{-1/2} Rs^{-5/2} (r/ Rs)^{-beta}. It follows that the phase-space\ndensity remains constant, in the sense of Qs=const., in the quiescent phases\nand it decreases as Rs^{-5/2} in the violent ones. The physical origin of the\nNFW density profile and the phase-space density power law is still unknown.\nYet, the numerical experiments show that halos recover these relations after\nthe violent phases. The major mergers drive Rs to increase and Qs to decrease\ndiscontinuously while keeping Qs Rs^{5/2} = const. The virial equilibrium in\nthe quiescent phases implies that a DM halos evolves along a sequence of NFW\nprofiles with constant energy per unit volume (i.e., pressure) within Rs.\n", "machine_text": "\nThrough constrained simulations, this study examines the evolution of the phase-space density profile in dark matter halos. Quiescent phases of slow accretion and sporadic major mergers reveal that the phase-space density follows a Taylor & Navarro power law which is remarkably stable over time (r^{-beta}, where beta ~ 1.9). Changes in the phase-space density is attributed to the effective mass surface density (\u03a3_s) within the halo radius (Rs) remains constant, leading to Qs ~ Rs^-5/2 and Q(r) ~ Sigma_s^-1/2 Rs^-5/2 (r/ Rs)^-beta. Violent phases of major mergers drive Rs to increase and Qs to decrease discontinuously while keeping Qs Rs^5/2 = constant. In the quiescent phases, the virial equilibrium of DM halos dictate that a given halo evolves along a sequence of NFW profiles with a constant energy per unit volume (i.e., pressure) within the limits of Rs.\n", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0006}
{"prompt": "Rephrase the abstract of an article with title 'Cryptoplanet update'.\n  We have had several talks recently reviewing 11 years of exoplanet\ndiscoveries through radial velocity variations, or from transits, or from\nmicrolensing. More than 200 exoplanets have been found, including some around\npulsars that we do not discuss here.\n  My physical definition for a planet is a roughly spherical, self-gravitating\nbody more massive than 10**26 g formed from the leftover material in a\nprotostellar disk after the protostar forms. Radiation from the protostar\npushes the inner wall of the disk outward. The material agglomerates and forms\nplanets in radial sequence. The outer planets are formed slowly by classical\ndynamical mechanisms acting in the snow zone. Planets have dense cores because\nof agglomeration.\n  Not one of the exoplanets discovered thus far is a planet. They are\ncryptoplanets formed from matter ejected by protostars. When protostars have\nexcessive infall at high latitudes, they partially balance angular momentum\nthrough outflow at the equator as they spin up. The ejected matter is trapped\nin the magnetic torus formed between the star and the disk, like a tokamak. The\ntokamak eventully reconnects and magnetic compression forms self-gravitating\nremnants trapped and compressed by a closed spherical magnetic field,\nspheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They\ncan merge with each other or fall into the star or be ejected. They can grow by\naccreting gas. They have a low density core and abundances characteristic of\nthe protostar. Their masses, radii, densities, and orbits are random, and are\ninconsistent with the parameters for planets. They tend to have lower density\nthan planets.\n\n", "human_text": "  We have had several talks recently reviewing 11 years of exoplanet\ndiscoveries through radial velocity variations, or from transits, or from\nmicrolensing. More than 200 exoplanets have been found, including some around\npulsars that we do not discuss here.\n  My physical definition for a planet is a roughly spherical, self-gravitating\nbody more massive than 10**26 g formed from the leftover material in a\nprotostellar disk after the protostar forms. Radiation from the protostar\npushes the inner wall of the disk outward. The material agglomerates and forms\nplanets in radial sequence. The outer planets are formed slowly by classical\ndynamical mechanisms acting in the snow zone. Planets have dense cores because\nof agglomeration.\n  Not one of the exoplanets discovered thus far is a planet. They are\ncryptoplanets formed from matter ejected by protostars. When protostars have\nexcessive infall at high latitudes, they partially balance angular momentum\nthrough outflow at the equator as they spin up. The ejected matter is trapped\nin the magnetic torus formed between the star and the disk, like a tokamak. The\ntokamak eventully reconnects and magnetic compression forms self-gravitating\nremnants trapped and compressed by a closed spherical magnetic field,\nspheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They\ncan merge with each other or fall into the star or be ejected. They can grow by\naccreting gas. They have a low density core and abundances characteristic of\nthe protostar. Their masses, radii, densities, and orbits are random, and are\ninconsistent with the parameters for planets. They tend to have lower density\nthan planets.\n", "machine_text": "\nThis article provides an update on the discoveries of exoplanets over the last 11 years. A physical definition of a planet as an object made of the leftover material from a protostellar disk is described, noting their radial sequence formation and dense cores. After careful inspection, it is concluded that none of the exoplanets discovered thus far are planets in the traditional sense, instead being cryptoplanets formed by matter ejected by protostars. Their characteristics of mass, radius, orbit and density are random, making them different to planets. This article offers an analysis of this phenomena, how they can merge or become ejected, and how they differ in density to planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.286}
{"prompt": "Rephrase the abstract of an article with title 'Is the Concentration of Dark Matter Halos at Virialization Universal ?'.\n  Several recent studies suggest a correlation between dark matter halo mass\nand the shape of the density profile. We re-analyze simulations from Ricotti\n(2003) in which such a correlation was proposed. We use a standard analysis of\nthe halo density profiles and compare the old simulations to new ones performed\nwith Gadget2, including higher resolution runs. We confirm Ricotti's result\nthat, at virialization, the central log slopes alpha, at 5%-10% of the virial\nradius are correlated with the halo mass and that the halo concentration is a\nuniversal constant. Our results do not contradict the majority of published\npapers: when using a split power law to fit the density profiles, due to the\nalpha-concentration degeneracy, the fits are consistent with halos having a\nuniversal shape with alpha=1 or 1.5 and concentrations that depend on the mass,\nin agreement with results published elsewhere.\n  Recently, several groups have found no evidence for convergence of the inner\nhalo profile to a constant power law. The choice of a split power law\nparameterization used in this letter is motivated by the need to compare our\nresults to previous ones and is formally valid because we are not able to\nresolve regions where the slope of the fitting function reaches its asymptotic\nconstant value. Using a non-parameterized technique, we also show that the\ndensity profiles of dwarf galaxies at z ~ 10 have a log slope shallower than\n0.5 within 5% of the virial radius.\n\n", "human_text": "  Several recent studies suggest a correlation between dark matter halo mass\nand the shape of the density profile. We re-analyze simulations from Ricotti\n(2003) in which such a correlation was proposed. We use a standard analysis of\nthe halo density profiles and compare the old simulations to new ones performed\nwith Gadget2, including higher resolution runs. We confirm Ricotti's result\nthat, at virialization, the central log slopes alpha, at 5%-10% of the virial\nradius are correlated with the halo mass and that the halo concentration is a\nuniversal constant. Our results do not contradict the majority of published\npapers: when using a split power law to fit the density profiles, due to the\nalpha-concentration degeneracy, the fits are consistent with halos having a\nuniversal shape with alpha=1 or 1.5 and concentrations that depend on the mass,\nin agreement with results published elsewhere.\n  Recently, several groups have found no evidence for convergence of the inner\nhalo profile to a constant power law. The choice of a split power law\nparameterization used in this letter is motivated by the need to compare our\nresults to previous ones and is formally valid because we are not able to\nresolve regions where the slope of the fitting function reaches its asymptotic\nconstant value. Using a non-parameterized technique, we also show that the\ndensity profiles of dwarf galaxies at z ~ 10 have a log slope shallower than\n0.5 within 5% of the virial radius.\n", "machine_text": "\nThis study examines the relationship between dark matter halo mass and its density profile at the time of virialization, based on simulations by Ricotti (2003). Analysis of data generated by both Gadget2 and higher resolution runs leads to confirmation of Ricotti's hypothesis that, at the time of virialization, a universal constant concentration of halos can be correlated with their mass. This result is consistent with other papers that use split power law parameterization to fit the density profiles, which reveals an alpha-concentration degeneracy that suggests a universal shape of the halo with specific alpha values (1 or 1.5) and concentrations that are dependent on its mass. Additionally, a non-parameterized technique is employed to show that the density profiles of dwarf galaxies at z ~ 10 generally have a log slope softer than 0.5 within the central 5% of the virial radius.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0856}
{"prompt": "Rephrase the abstract of an article with title 'SubmilliJansky Transients in Archival Radio Observations'.\n  [ABRIDGED] We report the results of a 944-epoch survey for transient sources\nwith archival data from the Very Large Array spanning 22 years with a typical\nepoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a\nsingle field of view with a full-width at half-maximum of 8.6' and 5.1',\nrespectively, and achieved a typical point-source detection threshold at the\nbeam center of ~300 microJy per epoch. Ten transient sources were detected with\na significance threshold such that only one false positive would be expected.\nOf these transients, eight were detected in only a single epoch. Two transients\nwere too faint to be detected in individual epochs but were detected in\ntwo-month averages. None of the ten transients was detected in longer-term\naverages or associated with persistent emission in the deep image produced from\nthe combination of all epochs. The cumulative rate for the short timescale\nradio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2\nyr^-1, where the uncertainty is due to the unknown duration of the transients,\n20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/-\n0.4 transient per square degrees above a flux density of 370 microJy. Two\ntransients are associated with galaxies at z=0.040 and z=0.249. These may be\nsimilar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB\n980428. Six transients have no counterparts in the optical or infrared (R=27,\nKs=18). The hosts and progenitors of these transients are unknown.\n\n", "human_text": "  [ABRIDGED] We report the results of a 944-epoch survey for transient sources\nwith archival data from the Very Large Array spanning 22 years with a typical\nepoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a\nsingle field of view with a full-width at half-maximum of 8.6' and 5.1',\nrespectively, and achieved a typical point-source detection threshold at the\nbeam center of ~300 microJy per epoch. Ten transient sources were detected with\na significance threshold such that only one false positive would be expected.\nOf these transients, eight were detected in only a single epoch. Two transients\nwere too faint to be detected in individual epochs but were detected in\ntwo-month averages. None of the ten transients was detected in longer-term\naverages or associated with persistent emission in the deep image produced from\nthe combination of all epochs. The cumulative rate for the short timescale\nradio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2\nyr^-1, where the uncertainty is due to the unknown duration of the transients,\n20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/-\n0.4 transient per square degrees above a flux density of 370 microJy. Two\ntransients are associated with galaxies at z=0.040 and z=0.249. These may be\nsimilar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB\n980428. Six transients have no counterparts in the optical or infrared (R=27,\nKs=18). The hosts and progenitors of these transients are unknown.\n", "machine_text": "\nWe present results from a 944-epoch survey of archival data from the Very Large Array taken over 22 years, featuring a single field of view with a full-width at half-maximum of 8.6' and 5.1' at 5 and 8.4 GHz, respectively. The point-source detection threshold at the beam center is approximately 300 microJy per epoch. Ten transient sources were discovered, most of which were only detected once - two were only detected in two-month averages. The cumulative rate of short timescale radio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2 yr^-1. These transients were not found in any long-term averages or persistent emission in the image formed by all epochs. Two transients were associated with galaxies at redshifts 0.040 and 0.249 and may be similar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB 980428. The host and progenitor of the remaining six transients is as yet unknown.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3158}
{"prompt": "Rephrase the abstract of an article with title 'Hydrodynamic Limit for a Particle System with degenerate rates'.\n  We study the hydrodynamic limit for some conservative particle systems with\ndegenerate rates, namely with nearest neighbor exchange rates which vanish for\ncertain configurations. These models belong to the class of {\\sl kinetically\nconstrained lattice gases} (KCLG) which have been introduced and intensively\nstudied in physics literature as simple models for the liquid/glass transition.\nDue to the degeneracy of rates for KCLG there exists {\\sl blocked\nconfigurations} which do not evolve under the dynamics and in general the\nhyperplanes of configurations with a fixed number of particles can be\ndecomposed into different irreducible sets. As a consequence, both the Entropy\nand Relative Entropy method cannot be straightforwardly applied to prove the\nhydrodynamic limit. In particular, some care should be put when proving the One\nand Two block Lemmas which guarantee local convergence to equilibrium. We show\nthat, for initial profiles smooth enough and bounded away from zero and one,\nthe macroscopic density profile for our KCLG evolves under the diffusive time\nscaling according to the porous medium equation. Then we prove the same result\nfor more general profiles for a slightly perturbed dynamics obtained by adding\njumps of the Symmetric Simple Exclusion. The role of the latter is to remove\nthe degeneracy of rates and at the same time they are properly slowed down in\norder not to change the macroscopic behavior. The equilibrium fluctuations and\nthe magnitude of the spectral gap for this perturbed model are also obtained.\n\n", "human_text": "  We study the hydrodynamic limit for some conservative particle systems with\ndegenerate rates, namely with nearest neighbor exchange rates which vanish for\ncertain configurations. These models belong to the class of {\\sl kinetically\nconstrained lattice gases} (KCLG) which have been introduced and intensively\nstudied in physics literature as simple models for the liquid/glass transition.\nDue to the degeneracy of rates for KCLG there exists {\\sl blocked\nconfigurations} which do not evolve under the dynamics and in general the\nhyperplanes of configurations with a fixed number of particles can be\ndecomposed into different irreducible sets. As a consequence, both the Entropy\nand Relative Entropy method cannot be straightforwardly applied to prove the\nhydrodynamic limit. In particular, some care should be put when proving the One\nand Two block Lemmas which guarantee local convergence to equilibrium. We show\nthat, for initial profiles smooth enough and bounded away from zero and one,\nthe macroscopic density profile for our KCLG evolves under the diffusive time\nscaling according to the porous medium equation. Then we prove the same result\nfor more general profiles for a slightly perturbed dynamics obtained by adding\njumps of the Symmetric Simple Exclusion. The role of the latter is to remove\nthe degeneracy of rates and at the same time they are properly slowed down in\norder not to change the macroscopic behavior. The equilibrium fluctuations and\nthe magnitude of the spectral gap for this perturbed model are also obtained.\n", "machine_text": "We explore the hydrodynamic limit of a specific particle system which features degenerate rates, also known as 'kinetically constrained lattice gases'. These models are known to comprise configurations that are 'blocked', unable to evolve under the dynamics. It is more difficult to prove the hydrodynamic limit with the Entropy and Relative Entropy methods due to the presence of such blocked  configurations. We show that when the initial profile is sufficiently smooth and bounded away from 0 and 1, the density profile of this KCLG evolves according to the porous medium equation under a diffusive time scaling. Additionally, we provide a perturbed dynamics achieved by introducing jumps for the Symmetric Simple Exclusion into the model and analyse the magnitude of the equilibrium fluctuations and the size of the spectral gap.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2242}
{"prompt": "Rephrase the abstract of an article with title 'A Three-Stage Search for Supermassive Black Hole Binaries in LISA Data'.\n  Gravitational waves from the inspiral and coalescence of supermassive\nblack-hole (SMBH) binaries with masses ~10^6 Msun are likely to be among the\nstrongest sources for the Laser Interferometer Space Antenna (LISA). We\ndescribe a three-stage data-analysis pipeline designed to search for and\nmeasure the parameters of SMBH binaries in LISA data. The first stage uses a\ntime-frequency track-search method to search for inspiral signals and provide a\ncoarse estimate of the black-hole masses m_1, m_2 and of the coalescence time\nof the binary t_c. The second stage uses a sequence of matched-filter template\nbanks, seeded by the first stage, to improve the measurement accuracy of the\nmasses and coalescence time. Finally, a Markov Chain Monte Carlo search is used\nto estimate all nine physical parameters of the binary. Using results from the\nsecond stage substantially shortens the Markov Chain burn-in time and allows us\nto determine the number of SMBH-binary signals in the data before starting\nparameter estimation. We demonstrate our analysis pipeline using simulated data\nfrom the first LISA Mock Data Challenge. We discuss our plan for improving this\npipeline and the challenges that will be faced in real LISA data analysis.\n\n", "human_text": "  Gravitational waves from the inspiral and coalescence of supermassive\nblack-hole (SMBH) binaries with masses ~10^6 Msun are likely to be among the\nstrongest sources for the Laser Interferometer Space Antenna (LISA). We\ndescribe a three-stage data-analysis pipeline designed to search for and\nmeasure the parameters of SMBH binaries in LISA data. The first stage uses a\ntime-frequency track-search method to search for inspiral signals and provide a\ncoarse estimate of the black-hole masses m_1, m_2 and of the coalescence time\nof the binary t_c. The second stage uses a sequence of matched-filter template\nbanks, seeded by the first stage, to improve the measurement accuracy of the\nmasses and coalescence time. Finally, a Markov Chain Monte Carlo search is used\nto estimate all nine physical parameters of the binary. Using results from the\nsecond stage substantially shortens the Markov Chain burn-in time and allows us\nto determine the number of SMBH-binary signals in the data before starting\nparameter estimation. We demonstrate our analysis pipeline using simulated data\nfrom the first LISA Mock Data Challenge. We discuss our plan for improving this\npipeline and the challenges that will be faced in real LISA data analysis.\n", "machine_text": "This paper presents a multi-stage, data-driven approach to investigate and measure supermassive binary black-hole systems in data from the Laser Interferometer Space Antenna (LISA). Using the first LISA Mock Data Challenge, the proposed three-stage pipeline combines a time-frequency track search, a matched-filter template bank, and a Markov Chain Monte Carlo search to estimate all nine physical parameters of the binary. Additionally, improved measurement accuracy from the second stage is leveraged to reduce the burn-in time for the Markov Chain process. Future plans to enhance and refine the pipeline for implementation in real LISA analysis are also discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2447}
{"prompt": "Rephrase the abstract of an article with title 'The magnetic fields of large Virgo Cluster spirals'.\n  Because of its proximity the Virgo Cluster is an excellent target for\nstudying interactions of galaxies with the cluster environment. Both the\nhigh-velocity tidal interactions and effects of ram pressure stripping by the\nintracluster gas can be investigated. Optical and/or \\ion{H}{i} observations do\nnot always show effects of weak interactions between galaxies and their\nencounters with the cluster medium. For this reason we searched for possible\nanomalies in the magnetic field structure in Virgo Cluster spirals which could\nbe attributed to perturbations in their gas distribution and kinematics. Five\nangularly large Virgo Cluster spiral galaxies (NGC 4501, NGC 4438, NGC 4535,\nNGC 4548 and NGC 4654) were the targets for a sensitive total power and\npolarization study using the 100-m radio telescope in Effelsberg at 4.85 GHz.\nFor two objects polarization data at higher frequencies have been obtained\nallowing Faraday rotation analysis. Distorted magnetic field structures were\nidentified in all galaxies. Interaction-induced magnetized outflows were found\nin NGC 4438 (due to nuclear activity) and NGC 4654 (a combination of tidal\ntails and ram pressure effects). Almost all objects (except the anaemic NGC\n4548) exhibit distortions in polarized radio continuum attributable to\ninfluence of the ambient gas. For some galaxies they agree with observations of\nother species, but sometimes (NGC 4535) the magnetic field is the only tracer\nof the interaction with the cluster environment. The cluster environment\nclearly affects the evolution of the galaxies due to ram pressure and tidal\neffects. Magnetic fields provide a very long-lasting memory of past\ninteractions. Therefore, they are a good tracer of weak interactions which are\ndifficult to detect by other observations.\n\n", "human_text": "  Because of its proximity the Virgo Cluster is an excellent target for\nstudying interactions of galaxies with the cluster environment. Both the\nhigh-velocity tidal interactions and effects of ram pressure stripping by the\nintracluster gas can be investigated. Optical and/or \\ion{H}{i} observations do\nnot always show effects of weak interactions between galaxies and their\nencounters with the cluster medium. For this reason we searched for possible\nanomalies in the magnetic field structure in Virgo Cluster spirals which could\nbe attributed to perturbations in their gas distribution and kinematics. Five\nangularly large Virgo Cluster spiral galaxies (NGC 4501, NGC 4438, NGC 4535,\nNGC 4548 and NGC 4654) were the targets for a sensitive total power and\npolarization study using the 100-m radio telescope in Effelsberg at 4.85 GHz.\nFor two objects polarization data at higher frequencies have been obtained\nallowing Faraday rotation analysis. Distorted magnetic field structures were\nidentified in all galaxies. Interaction-induced magnetized outflows were found\nin NGC 4438 (due to nuclear activity) and NGC 4654 (a combination of tidal\ntails and ram pressure effects). Almost all objects (except the anaemic NGC\n4548) exhibit distortions in polarized radio continuum attributable to\ninfluence of the ambient gas. For some galaxies they agree with observations of\nother species, but sometimes (NGC 4535) the magnetic field is the only tracer\nof the interaction with the cluster environment. The cluster environment\nclearly affects the evolution of the galaxies due to ram pressure and tidal\neffects. Magnetic fields provide a very long-lasting memory of past\ninteractions. Therefore, they are a good tracer of weak interactions which are\ndifficult to detect by other observations.\n", "machine_text": "\nThrough observations of the 100-m radio telescope in Effelsberg at 4.85 GHz, this study examined possible anomalies in the magnetic fields of five large Virgo Cluster spiral galaxies (NGC 4501, NGC 4438, NGC 4535, NGC 4548 and NGC 4654). Distorted magnetic field structures were found in all galaxies and interaction-induced magnetized outflows detected in two of them. Magnetic fields are useful for tracing weak interactions that are not evidenced by other observations, including ram pressure and tidal effects from the nearby Virgo Cluster that affect the galaxies' evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4586}
{"prompt": "Rephrase the abstract of an article with title 'The impact of accretion disk winds on the X-ray spectrum of AGN: Part 1\n  - XSCORT'.\n  (abridged) The accretion disk in AGN is expected to produce strong outflows,\nin particular a UV-line driven wind. Despite providing a good fit to the data,\ncurrent spectral models of the X-ray spectrum of AGN observed through an\naccretion disk wind are ad-hoc in their treatment of the properties of the wind\nmaterial. In order to address these limitations we adopt a numerical\ncomputation method that links a series of radiative transfer calculations,\nincorporating the effect of a global velocity field in a self-consistent manner\n(XSCORT). We present a series of example spectra from the XSCORT code that\nallow us to examine the shape of AGN X-ray spectra seen through a wind, for a\nrange of velocity and density distributions, total column densities and initial\nionization parameters. These detailed spectral models clearly show considerable\ncomplexity and structure that is strongly affected by all these factors. The\npresence of sharp features in the XSCORT spectra contrasts strongly with both\nthe previous models and with the smooth nature of the observed X-ray spectra of\nAGN with soft X-ray excesses, demonstrating that accretion disk winds are\nunlikely to be the origin of this mysterious spectral feature. The most\nsignificant parameter affecting the presence of the sharp features in the\nmodels is the terminal velocity of the wind. Increasing the terminal velocity\nof the absorbing material to ~c, and hence dramatically increasing the velocity\ndispersion across the wind, could potentially remove these features resulting\nin a spectrum similar to the previous models. Such a fast moving outflow cannot\nbe associated with a radiatively driven accretion disk wind, however the\npresence of a highly relativistic jet may provide an origin for such material.\n\n", "human_text": "  (abridged) The accretion disk in AGN is expected to produce strong outflows,\nin particular a UV-line driven wind. Despite providing a good fit to the data,\ncurrent spectral models of the X-ray spectrum of AGN observed through an\naccretion disk wind are ad-hoc in their treatment of the properties of the wind\nmaterial. In order to address these limitations we adopt a numerical\ncomputation method that links a series of radiative transfer calculations,\nincorporating the effect of a global velocity field in a self-consistent manner\n(XSCORT). We present a series of example spectra from the XSCORT code that\nallow us to examine the shape of AGN X-ray spectra seen through a wind, for a\nrange of velocity and density distributions, total column densities and initial\nionization parameters. These detailed spectral models clearly show considerable\ncomplexity and structure that is strongly affected by all these factors. The\npresence of sharp features in the XSCORT spectra contrasts strongly with both\nthe previous models and with the smooth nature of the observed X-ray spectra of\nAGN with soft X-ray excesses, demonstrating that accretion disk winds are\nunlikely to be the origin of this mysterious spectral feature. The most\nsignificant parameter affecting the presence of the sharp features in the\nmodels is the terminal velocity of the wind. Increasing the terminal velocity\nof the absorbing material to ~c, and hence dramatically increasing the velocity\ndispersion across the wind, could potentially remove these features resulting\nin a spectrum similar to the previous models. Such a fast moving outflow cannot\nbe associated with a radiatively driven accretion disk wind, however the\npresence of a highly relativistic jet may provide an origin for such material.\n", "machine_text": "\nThis paper employs the XSCORT code to examine the impact that an accretion disk wind has on the X-ray spectrum of AGN. Results from the study show that for a range of velocity, density distributions, total column densities and initial ionization parameters, the spectra of AGN with soft X-ray excesses seen through an accretion disk wind, involve substantial complexity and structure. Notably, the presence of sharp features produced by the XSCORT code contrasts sharply with the smooth nature of the observed X-ray spectra of AGN, casting doubt on the ability of accretion disk winds to produce soft X-ray excesses. Further study suggests that a terminal velocity of roughly the speed of light would need to be involved in order to remove these features, but that such an outflow cannot likely be associated with a radiatively driven accretion disk wind. Suggesting that a highly relativistic jet may be a more suitable source for the material.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1885}
{"prompt": "Rephrase the abstract of an article with title 'Molecular Line Emission from Massive Protostellar Disks: Predictions for\n  ALMA and the EVLA'.\n  We compute the molecular line emission of massive protostellar disks by\nsolving the equation of radiative transfer through the cores and disks produced\nby the recent radiation-hydrodynamic simulations of Krumholz, Klein, & McKee.\nWe find that in several representative lines the disks show brightness\ntemperatures of hundreds of Kelvin over velocity channels ~10 km s^-1 wide,\nextending over regions hundreds of AU in size. We process the computed\nintensities to model the performance of next-generation radio and submillimeter\ntelescopes. Our calculations show that observations using facilities such as\nthe EVLA and ALMA should be able to detect massive protostellar disks and\nmeasure their rotation curves, at least in the nearest massive star-forming\nregions. They should also detect significant sub-structure and non-axisymmetry\nin the disks, and in some cases may be able to detect star-disk velocity\noffsets of a few km s^-1, both of which are the result of strong gravitational\ninstability in massive disks. We use our simulations to explore the strengths\nand weaknesses of different observational techniques, and we also discuss how\nobservations of massive protostellar disks may be used to distinguish between\nalternative models of massive star formation.\n\n", "human_text": "  We compute the molecular line emission of massive protostellar disks by\nsolving the equation of radiative transfer through the cores and disks produced\nby the recent radiation-hydrodynamic simulations of Krumholz, Klein, & McKee.\nWe find that in several representative lines the disks show brightness\ntemperatures of hundreds of Kelvin over velocity channels ~10 km s^-1 wide,\nextending over regions hundreds of AU in size. We process the computed\nintensities to model the performance of next-generation radio and submillimeter\ntelescopes. Our calculations show that observations using facilities such as\nthe EVLA and ALMA should be able to detect massive protostellar disks and\nmeasure their rotation curves, at least in the nearest massive star-forming\nregions. They should also detect significant sub-structure and non-axisymmetry\nin the disks, and in some cases may be able to detect star-disk velocity\noffsets of a few km s^-1, both of which are the result of strong gravitational\ninstability in massive disks. We use our simulations to explore the strengths\nand weaknesses of different observational techniques, and we also discuss how\nobservations of massive protostellar disks may be used to distinguish between\nalternative models of massive star formation.\n", "machine_text": "\nWe use next-generation radio and submillimeter telescopes such as the EVLA and ALMA to detect molecular line emission from massive protostellar disks. By running radiation-hydrodynamic simulations of the disks, we determine that the brightness temperatures of the disk core could be up to hundreds of Kelvin, extending over velocity channels of 10 km s-1 and regions of hundreds of AU. Based on our findings, we predict that these observations should be capable of detecting the massive protostellar disks and their rotational curves in nearby star-forming regions. Additionally, we predict that non-axisymmetry and substructure should be detectable, as well as velocity offsets between the stars and disks of several km s^-1, caused by strong gravitational instability. Our simulations aid in exploring the effectiveness of different observation techniques and comparing alternative models of massive star formation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0536}
{"prompt": "Rephrase the abstract of an article with title 'On a generalised model for time-dependent variance with long-term memory'.\n  The ARCH process (R. F. Engle, 1982) constitutes a paradigmatic generator of\nstochastic time series with time-dependent variance like it appears on a wide\nbroad of systems besides economics in which ARCH was born. Although the ARCH\nprocess captures the so-called \"volatility clustering\" and the asymptotic\npower-law probability density distribution of the random variable, it is not\ncapable to reproduce further statistical properties of many of these time\nseries such as: the strong persistence of the instantaneous variance\ncharacterised by large values of the Hurst exponent (H > 0.8), and asymptotic\npower-law decay of the absolute values self-correlation function. By means of\nconsidering an effective return obtained from a correlation of past returns\nthat has a q-exponential form we are able to fix the limitations of the\noriginal model. Moreover, this improvement can be obtained through the correct\nchoice of a sole additional parameter, $q_{m}$. The assessment of its validity\nand usefulness is made by mimicking daily fluctuations of SP500 financial\nindex.\n\n", "human_text": "  The ARCH process (R. F. Engle, 1982) constitutes a paradigmatic generator of\nstochastic time series with time-dependent variance like it appears on a wide\nbroad of systems besides economics in which ARCH was born. Although the ARCH\nprocess captures the so-called \"volatility clustering\" and the asymptotic\npower-law probability density distribution of the random variable, it is not\ncapable to reproduce further statistical properties of many of these time\nseries such as: the strong persistence of the instantaneous variance\ncharacterised by large values of the Hurst exponent (H > 0.8), and asymptotic\npower-law decay of the absolute values self-correlation function. By means of\nconsidering an effective return obtained from a correlation of past returns\nthat has a q-exponential form we are able to fix the limitations of the\noriginal model. Moreover, this improvement can be obtained through the correct\nchoice of a sole additional parameter, $q_{m}$. The assessment of its validity\nand usefulness is made by mimicking daily fluctuations of SP500 financial\nindex.\n", "machine_text": "This paper proposes a generalised ARCH model with long-term memory to capture and reproduce the time-dependent variance, volatility clustering and power-law probability density distribution of stochastic time series. The model also offers the ability to accurately reproduce the strong persistence of the instantaneous variance as shown by large values of the Hurst exponent and the asymptotic power-law decay of the absolute values self-correlation function. This is accomplished through the introduction of a single effective return parameter, $q_{m}$, obtained from the correlation of past returns with a q-exponential form. This model is applied in the context of the daily fluctuations of the SP500 financial index to assess its validity and usefulness.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3248}
{"prompt": "Rephrase the abstract of an article with title 'The Black Hole Binary Nova Scorpii 1994 (GRO J1655-40): An improved\n  chemical analysis'.\n  The chemical analysis of secondary stars of low mass X-ray binaries provides\nan opportunity to study the formation processes of compact objects, either\nblack holes or neutron stars. Following the discovery of overabundances of\n$\\alpha$-elements in the HIRES/Keck spectrum of the secondary star of Nova\nScorpii 1994 (Israelian et al. 1999), we obtained UVES/VLT high-resolution\nspectroscopy with the aim of performing a detailed abundance analysis of this\nsecondary star. Using a $\\chi2$-minimization procedure and a grid of synthetic\nspectra, we derive the stellar parameters and atmospheric abundances of O, Mg,\nAl, Ca, Ti, Fe and Ni, using a new UVES spectrum and the HIRES spectrum.The\nabundances of Al, Ca, Ti, Fe and Ni seem to be consistent with solar values,\nwhereas Na, and especially O, Mg, Si and S are significantly enhanced in\ncomparison with Galactic trends of these elements. A comparison with\nspherically and non-spherically symmetric supernova explosion models may\nprovide stringent constraints to the model parameters as mass-cut and the\nexplosion energy, in particular from the relative abundances of Si, S, Ca, Ti,\nFe and Ni. Most probably the black hole in this system formed in a hypernova\nexplosion of a 30--35 \\Msun progenitor star with a mass-cut in the range 2--3.5\n\\Msun. However, these models produce abundances of Al and Na almost ten times\nhigher than the observed values.\n\n", "human_text": "  The chemical analysis of secondary stars of low mass X-ray binaries provides\nan opportunity to study the formation processes of compact objects, either\nblack holes or neutron stars. Following the discovery of overabundances of\n$\\alpha$-elements in the HIRES/Keck spectrum of the secondary star of Nova\nScorpii 1994 (Israelian et al. 1999), we obtained UVES/VLT high-resolution\nspectroscopy with the aim of performing a detailed abundance analysis of this\nsecondary star. Using a $\\chi2$-minimization procedure and a grid of synthetic\nspectra, we derive the stellar parameters and atmospheric abundances of O, Mg,\nAl, Ca, Ti, Fe and Ni, using a new UVES spectrum and the HIRES spectrum.The\nabundances of Al, Ca, Ti, Fe and Ni seem to be consistent with solar values,\nwhereas Na, and especially O, Mg, Si and S are significantly enhanced in\ncomparison with Galactic trends of these elements. A comparison with\nspherically and non-spherically symmetric supernova explosion models may\nprovide stringent constraints to the model parameters as mass-cut and the\nexplosion energy, in particular from the relative abundances of Si, S, Ca, Ti,\nFe and Ni. Most probably the black hole in this system formed in a hypernova\nexplosion of a 30--35 \\Msun progenitor star with a mass-cut in the range 2--3.5\n\\Msun. However, these models produce abundances of Al and Na almost ten times\nhigher than the observed values.\n", "machine_text": "\nThis article examines the chemical composition of the secondary stars in low mass X-ray binary systems, to gain insight into the formation of black holes and neutron stars. Through UVES/VLT spectroscopy and the HIRES spectrum of Nova Scorpii 1994's secondary star (Israelian et al. 1999), we derive the atmospheric abundances of O, Mg, Al, Ca, Ti, Fe, and Ni using the $\\chi2$-minimization procedure and grid of synthetic spectra. The majority of the elements share similarities with solar values, while Na and primarily O, Mg, Si, and S have significantly augmented as compared to Galactic trends. We analyze existing supernova explosion models to constrain their parameters, such as the mass-cut and the explosion energy, in relation to relative abundances of elements like Si, S, Ca, Ti, Fe and Ni. Results indicate that a hypernova explosion of a 30-35 \\Msun progenitor star with a mass-cut between 2-3.5 \\Msun, is likely the formation process of the black hole. However, the output of these models vastly overestimates the concentrations of Al and Na that are found in the observed spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2693}
{"prompt": "Rephrase the abstract of an article with title 'Clustered Star Formation in the Small Magellanic Cloud. A Spitzer/IRAC\n  View of the Star-Forming Region NGC 602/N 90'.\n  We present Spitzer/IRAC photometry on the star-forming HII region N 90,\nrelated to the young stellar association NGC 602 in the Small Magellanic Cloud.\nOur photometry revealed bright mid-infrared sources, which we classify with the\nuse of a scheme based on templates and models of red sources in the Milky Way,\nand criteria recently developed from the Spitzer Survey of the SMC for the\nselection of candidate Young Stellar Objects (YSOs). We detected 57 sources in\nall four IRAC channels in a 6.2' x 4.8' field-of-view centered on N 90; 22 of\nthese sources are classified as candidate YSOs. We compare the locations of\nthese objects with the position of optical sources recently found in the same\nregion with high-resolution HST/ACS imaging of NGC 602, and we find that 17\ncandidate YSOs have one or more optical counterparts. All of these optical\nsources are identified as pre-main sequence stars, indicating, thus, ongoing\nclustered star formation events in the region. The positions of the detected\nYSOs and their related PMS clusters give a clear picture of the current star\nformation in N 90, according to which the young stellar association\nphoto-ionizes the surrounding interstellar medium, revealing the HII nebula,\nand triggering sequential star formation events mainly along the eastern and\nsouthern rims of the formed cavity of the parental molecular cloud.\n\n", "human_text": "  We present Spitzer/IRAC photometry on the star-forming HII region N 90,\nrelated to the young stellar association NGC 602 in the Small Magellanic Cloud.\nOur photometry revealed bright mid-infrared sources, which we classify with the\nuse of a scheme based on templates and models of red sources in the Milky Way,\nand criteria recently developed from the Spitzer Survey of the SMC for the\nselection of candidate Young Stellar Objects (YSOs). We detected 57 sources in\nall four IRAC channels in a 6.2' x 4.8' field-of-view centered on N 90; 22 of\nthese sources are classified as candidate YSOs. We compare the locations of\nthese objects with the position of optical sources recently found in the same\nregion with high-resolution HST/ACS imaging of NGC 602, and we find that 17\ncandidate YSOs have one or more optical counterparts. All of these optical\nsources are identified as pre-main sequence stars, indicating, thus, ongoing\nclustered star formation events in the region. The positions of the detected\nYSOs and their related PMS clusters give a clear picture of the current star\nformation in N 90, according to which the young stellar association\nphoto-ionizes the surrounding interstellar medium, revealing the HII nebula,\nand triggering sequential star formation events mainly along the eastern and\nsouthern rims of the formed cavity of the parental molecular cloud.\n", "machine_text": "\nWe examine the mid-infrared emission of the star-forming HII region N 90,\nassociated with the young stellar association NGC 602 in the Small Magellanic\nCloud, using Spitzer/IRAC photometry. We classify 57 sources in a 6.2' x 4.8'\nfield-of-view centered on N 90, of which 22 are identified as Young Stellar Objects.  Comparing these possible YSOs to optical sources registered with high-resolution HST/ACS observations, we pinpoint 17 young stars that are suggestive of ongoing clustered star formation events in the region.  Our survey reveals a pattern of sequential star formation at the edges of a parental molecular cloud cavity, ionized by the growing NGC 602 association.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3359}
{"prompt": "Rephrase the abstract of an article with title 'The Physical Nature of Polar Broad Absorption Line Quasars'.\n  It has been shown based on radio variability arguments that some BALQSOs\n(broad absorption line quasars) are viewed along the polar axis (orthogonal to\naccretion disk) in the recent article of Zhou et al. These arguments are based\non the brightness temperature, $T_{b}$ exceeding $10^{12} ^{\\circ}$ K which\nleads to the well-known inverse Compton catastrophe unless the radio jet is\nrelativistic and is viewed along its axis. In this letter, we expand the Zhou\net al sample of polar BALQSOs to the entire SDSS DR5. In the process, we\nclarify a mistake in their calculation of brightness temperature. The expanded\nsample of high $T_{b}$ BALQSOS, has an inordinately large fraction of LoBALQSOs\n(low ionization BALQSOs). We consider this an important clue to understanding\nthe nature of the polar BALQSOs. This is expected in the polar BALQSO\nanalytical/numerical models of Punsly in which LoBALQSOs occur when the line of\nsight is very close to the polar axis, where the outflow density is the\nhighest.\n\n", "human_text": "  It has been shown based on radio variability arguments that some BALQSOs\n(broad absorption line quasars) are viewed along the polar axis (orthogonal to\naccretion disk) in the recent article of Zhou et al. These arguments are based\non the brightness temperature, $T_{b}$ exceeding $10^{12} ^{\\circ}$ K which\nleads to the well-known inverse Compton catastrophe unless the radio jet is\nrelativistic and is viewed along its axis. In this letter, we expand the Zhou\net al sample of polar BALQSOs to the entire SDSS DR5. In the process, we\nclarify a mistake in their calculation of brightness temperature. The expanded\nsample of high $T_{b}$ BALQSOS, has an inordinately large fraction of LoBALQSOs\n(low ionization BALQSOs). We consider this an important clue to understanding\nthe nature of the polar BALQSOs. This is expected in the polar BALQSO\nanalytical/numerical models of Punsly in which LoBALQSOs occur when the line of\nsight is very close to the polar axis, where the outflow density is the\nhighest.\n", "machine_text": "\nBy examining a larger sample of polar Broad Absorption Line Quasars (BALQSOs) from the SDSS DR5, this paper aims to provide an explantion to the underlying physical nature of these celestial bodies. The argument put forward by Zhou et al, based on the radio variability of some BALQSOs, was that these objects are viewed in a polar orientation relative to their accretion disks. This paper verifies the calculation of brightness temperature, $T_{b}$, made by Zhou et al., and then extends this knowledge to an entire sample of polar BALQSOs. In doing so, we observe an exaggerated number of LoBALQSOs (low ionization BALQSOs) in this group. This is seen as a key piece of evidence to understanding the nature of polar BALQSOs, as it supports the prediction of polar BALQSO analytical and numerical models put forward by Punsly, where LoBALQSOs tend to present in environments where the line of sight is close to the polar axis and the outflow density is high.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2407}
{"prompt": "Rephrase the abstract of an article with title 'The discovery of a massive supercluster at z=0.9 in the UKIDSS DXS'.\n  We analyse the first publicly released deep field of the UKIDSS Deep\neXtragalactic Survey (DXS) to identify candidate galaxy over-densities at z~1\nacross ~1 sq. degree in the ELAIS-N1 field. Using I-K, J-K and K-3.6um colours\nwe identify and spectroscopically follow-up five candidate structures with\nGemini/GMOS and confirm they are all true over-densities with between five and\nnineteen members each. Surprisingly, all five structures lie in a narrow\nredshift range at z=0.89+/-0.01, although they are spread across 30Mpc on the\nsky. We also find a more distant over-density at z=1.09 in one of the\nspectroscopic survey regions. These five over-dense regions lying in a narrow\nredshift range indicate the presence of a supercluster in this field and by\ncomparing with mock cluster catalogs from N-body simulations we discuss the\nlikely properties of this structure. Overall, we show that the properties of\nthis supercluster are similar to the well-studied Shapley and Hercules\nsuperclusters at lower redshift.\n\n", "human_text": "  We analyse the first publicly released deep field of the UKIDSS Deep\neXtragalactic Survey (DXS) to identify candidate galaxy over-densities at z~1\nacross ~1 sq. degree in the ELAIS-N1 field. Using I-K, J-K and K-3.6um colours\nwe identify and spectroscopically follow-up five candidate structures with\nGemini/GMOS and confirm they are all true over-densities with between five and\nnineteen members each. Surprisingly, all five structures lie in a narrow\nredshift range at z=0.89+/-0.01, although they are spread across 30Mpc on the\nsky. We also find a more distant over-density at z=1.09 in one of the\nspectroscopic survey regions. These five over-dense regions lying in a narrow\nredshift range indicate the presence of a supercluster in this field and by\ncomparing with mock cluster catalogs from N-body simulations we discuss the\nlikely properties of this structure. Overall, we show that the properties of\nthis supercluster are similar to the well-studied Shapley and Hercules\nsuperclusters at lower redshift.\n", "machine_text": "\nA comprehensive analysis of the initial UKIDSS Deep eXtragalactic Survey (DXS) data of the ELAIS-N1 field revealed candidate galaxy over-densities at z~1 within an area of one square degree. By utilizing I-K, J-K, and K-3.6um colour indices the five structures were further spectroscopically observed at the Gemini/GMOS and confirmed to be real over-densities having up to nineteen members each. Strikingly, they are located in a very precise redshift range (z=0.89+/-0.01), but spread across a 30Mpc distance on the sky. What is more, a sixth over-density was identified at z=1.09. Comparisons with a mock cluster catalog from N-body simulations indicate that the supercluster discovered in the ELAIS-N1 Field has similar characteristics to the Shapley and Hercules superclusters at lower redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.009}
{"prompt": "Rephrase the abstract of an article with title 'Recent progresses in the simulation of small-scale magnetic fields'.\n  New high-resolution observations reveal that small-scale magnetic flux\nconcentrations have a delicate substructure on a spatial scale of 0.1''. Its\nbasic structure can be interpreted in terms of a magnetic flux sheet or tube\nthat vertically extends through the ambient weak-field or field-free atmosphere\nwith which it is in mechanical equilibrium. A more refined interpretation comes\nfrom new three-dimensional magnetohydrodynamic simulations that are capable of\nreproducing the corrugated shape of magnetic flux concentrations and their\nsignature in the visible continuum. Furthermore it is shown that the\ncharacteristic asymmetric shape of the contrast profile of facular granules is\nan effect of radiative transfer across the rarefied atmosphere of the magnetic\nflux concentration. I also discuss three-dimensional radiation\nmagnetohydrodynamic simulations of the integral layers from the top of the\nconvection zone to the mid-chromosphere. They show a highly dynamic\nchromospheric magnetic field, marked by rapidly moving filaments of stronger\nthan average magnetic field that form in the compression zone downstream and\nalong propagating shock fronts. The simulations confirm the picture of flux\nconcentrations that strongly expand through the photosphere into a more\nhomogeneous, space filling chromospheric field. Future directions in the\nsimulation of small-scale magnetic fields are indicated by a few examples of\nvery recent work.\n\n", "human_text": "  New high-resolution observations reveal that small-scale magnetic flux\nconcentrations have a delicate substructure on a spatial scale of 0.1''. Its\nbasic structure can be interpreted in terms of a magnetic flux sheet or tube\nthat vertically extends through the ambient weak-field or field-free atmosphere\nwith which it is in mechanical equilibrium. A more refined interpretation comes\nfrom new three-dimensional magnetohydrodynamic simulations that are capable of\nreproducing the corrugated shape of magnetic flux concentrations and their\nsignature in the visible continuum. Furthermore it is shown that the\ncharacteristic asymmetric shape of the contrast profile of facular granules is\nan effect of radiative transfer across the rarefied atmosphere of the magnetic\nflux concentration. I also discuss three-dimensional radiation\nmagnetohydrodynamic simulations of the integral layers from the top of the\nconvection zone to the mid-chromosphere. They show a highly dynamic\nchromospheric magnetic field, marked by rapidly moving filaments of stronger\nthan average magnetic field that form in the compression zone downstream and\nalong propagating shock fronts. The simulations confirm the picture of flux\nconcentrations that strongly expand through the photosphere into a more\nhomogeneous, space filling chromospheric field. Future directions in the\nsimulation of small-scale magnetic fields are indicated by a few examples of\nvery recent work.\n", "machine_text": "\nRecent progress in the simulation of small-scale magnetic fields has explored the intricate substructures on a scale of 0.1''. It appears that magnetic flux concentrations can extend in a vertical fashion through the atmosphere, resulting in a mechanical equilibrium with the surrounding field-free atmosphere. Advanced three-dimensional magnetohydrodynamic simulations have been able to recreate the curved shapes of these flux concentrations, as well as the asymmetric profile of the associated facular granules caused by radiative transfer. Models now also extend to encompass the full range of layers from the convection zone to the mid-chromosphere, signifying a dynamic chromospheric magnetic field marked by filaments of high field strength propagating within the compression zone along with shock fronts. As such, magnetic flux concentrations appear to expand through the photosphere and into a more homogeneous chromospheric field. Finally, this paper will touch upon recent works to give prospective directions for future simulations of small-scale magnetic fields.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1848}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of the Atmospheric Muon Charge Ratio at TeV Energies with\n  MINOS'.\n  The 5.4 kton MINOS far detector has been taking charge-separated cosmic ray\nmuon data since the beginning of August, 2003 at a depth of 2070\nmeters-water-equivalent in the Soudan Underground Laboratory, Minnesota, USA.\nThe data with both forward and reversed magnetic field running configurations\nwere combined to minimize systematic errors in the determination of the\nunderground muon charge ratio. When averaged, two independent analyses find the\ncharge ratio underground to be 1.374 +/- 0.004 (stat.) +0.012 -0.010(sys.).\nUsing the map of the Soudan rock overburden, the muon momenta as measured\nunderground were projected to the corresponding values at the surface in the\nenergy range 1-7 TeV. Within this range of energies at the surface, the MINOS\ndata are consistent with the charge ratio being energy independent at the two\nstandard deviation level. When the MINOS results are compared with measurements\nat lower energies, a clear rise in the charge ratio in the energy range 0.3 --\n1.0 TeV is apparent. A qualitative model shows that the rise is consistent with\nan increasing contribution of kaon decays to the muon charge ratio.\n\n", "human_text": "  The 5.4 kton MINOS far detector has been taking charge-separated cosmic ray\nmuon data since the beginning of August, 2003 at a depth of 2070\nmeters-water-equivalent in the Soudan Underground Laboratory, Minnesota, USA.\nThe data with both forward and reversed magnetic field running configurations\nwere combined to minimize systematic errors in the determination of the\nunderground muon charge ratio. When averaged, two independent analyses find the\ncharge ratio underground to be 1.374 +/- 0.004 (stat.) +0.012 -0.010(sys.).\nUsing the map of the Soudan rock overburden, the muon momenta as measured\nunderground were projected to the corresponding values at the surface in the\nenergy range 1-7 TeV. Within this range of energies at the surface, the MINOS\ndata are consistent with the charge ratio being energy independent at the two\nstandard deviation level. When the MINOS results are compared with measurements\nat lower energies, a clear rise in the charge ratio in the energy range 0.3 --\n1.0 TeV is apparent. A qualitative model shows that the rise is consistent with\nan increasing contribution of kaon decays to the muon charge ratio.\n", "machine_text": "\nThe 5.4 kton MINOS detector located at the Soudan Underground Laboratory in Minnesota, USA has been observing cosmic ray muons since August 2003 at a depth of 2070 meters-water-equivalent. Reversing the magnetic field allowed two analyses to be combined and thereby reduced systematic errors while determining the charge ratio of underground muons, measured to be 1.374 +/- 0.004 (stat.) +0.012 -0.010(sys.). Further analysis of the resulting data, in the energy range 1-7 TeV, showed the charge ratio is consistent with being energy independent at the two standard deviation level. Comparing the MINOS measurements to those at lower energies reveals a rise in the charge ratio between 0.3-1.0 TeV, possibly due to increasing kaon decays contributing to the charge ratio.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3815}
{"prompt": "Rephrase the abstract of an article with title 'Non-resonant and Resonant X-ray Scattering Studies on Multiferroic\n  TbMn2O5'.\n  Comprehensive x-ray scattering studies, including resonant scattering at Mn\nL-edge, Tb L- and M-edges, were performed on single crystals of TbMn2O5. X-ray\nintensities were observed at a forbidden Bragg position in the ferroelectric\nphases, in addition to the lattice and the magnetic modulation peaks.\nTemperature dependences of their intensities and the relation between the\nmodulation wave vectors provide direct evidences of exchange striction induced\nferroelectricity. Resonant x-ray scattering results demonstrate the presence of\nmultiple magnetic orders by exhibiting their different temperature dependences.\nThe commensurate-to-incommensurate phase transition around 24 K is attributed\nto discommensuration through phase slipping of the magnetic orders in spin\nfrustrated geometries. We proposed that the low temperature incommensurate\nphase consists of the commensurate magnetic domains separated by anti-phase\ndomain walls which reduce spontaneous polarizations abruptly at the transition.\n\n", "human_text": "  Comprehensive x-ray scattering studies, including resonant scattering at Mn\nL-edge, Tb L- and M-edges, were performed on single crystals of TbMn2O5. X-ray\nintensities were observed at a forbidden Bragg position in the ferroelectric\nphases, in addition to the lattice and the magnetic modulation peaks.\nTemperature dependences of their intensities and the relation between the\nmodulation wave vectors provide direct evidences of exchange striction induced\nferroelectricity. Resonant x-ray scattering results demonstrate the presence of\nmultiple magnetic orders by exhibiting their different temperature dependences.\nThe commensurate-to-incommensurate phase transition around 24 K is attributed\nto discommensuration through phase slipping of the magnetic orders in spin\nfrustrated geometries. We proposed that the low temperature incommensurate\nphase consists of the commensurate magnetic domains separated by anti-phase\ndomain walls which reduce spontaneous polarizations abruptly at the transition.\n", "machine_text": "\nIn this article, non-resonant and resonant x-ray scattering techniques were applied to single crystals of TbMn2O5 to gain a comprehensive understanding of its properties. Several intensities were detected at forbidden Bragg positions in the ferroelectric phases, as well as lattice and magnetism modulation peaks. Temperature dependent intensity of the peaks and the wave vector connection showed clear proof of exchange striction induced ferroelectricity. Through resonant scattering at Mn L-edge, Tb L- and M-edges, multiple magnetic orders with different temperature dependences were revealed. The transformation from a commensurate to incommensurate phase at 24 K is caused by discommensuration through spin frustration by the phase slipping of the magnetic orders. It is proposed that the low temperature incommensurate phase is formed by the separation of commensurate magnetic domains with anti-phased domain walls significantly reducing the spontaneous polarizations at the transition.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0533}
{"prompt": "Rephrase the abstract of an article with title 'Age constraints in the double pulsar system J0737-3039'.\n  We investigate the age constraints that can be placed on the double pulsar\nsystem using models for the spin-down of the first-born 22.7-ms pulsar A and\nthe 2.77-s pulsar B with characteristic ages of 210 and 50 Myr respectively.\nStandard models assuming dipolar spin-down of both pulsars suggest that the\ntime since the formation of B is ~50 Myr, i.e. close to B's characteristic age.\nHowever, adopting models which account for the impact of A's relativistic wind\non B's spin-down we find that the formation of B took place either 80 or 180\nMyr ago, depending the interaction mechanism. Formation 80 Myr ago, closer to\nB's characteristic age, would result in the contribution from J0737-3039 to the\ninferred coalescence rates for double neutron star binaries increasing by 40%.\nThe 180 Myr age is closer to A's characteristic age and would be consistent\nwith the most recent estimates of the coalescence rate. The new age constraints\ndo not significantly impact recent estimates of the kick velocity, tilt angle\nbetween pre and post-supernova orbital planes or pre-supernova mass of B's\nprogenitor.\n\n", "human_text": "  We investigate the age constraints that can be placed on the double pulsar\nsystem using models for the spin-down of the first-born 22.7-ms pulsar A and\nthe 2.77-s pulsar B with characteristic ages of 210 and 50 Myr respectively.\nStandard models assuming dipolar spin-down of both pulsars suggest that the\ntime since the formation of B is ~50 Myr, i.e. close to B's characteristic age.\nHowever, adopting models which account for the impact of A's relativistic wind\non B's spin-down we find that the formation of B took place either 80 or 180\nMyr ago, depending the interaction mechanism. Formation 80 Myr ago, closer to\nB's characteristic age, would result in the contribution from J0737-3039 to the\ninferred coalescence rates for double neutron star binaries increasing by 40%.\nThe 180 Myr age is closer to A's characteristic age and would be consistent\nwith the most recent estimates of the coalescence rate. The new age constraints\ndo not significantly impact recent estimates of the kick velocity, tilt angle\nbetween pre and post-supernova orbital planes or pre-supernova mass of B's\nprogenitor.\n", "machine_text": "\nWe study the age of the double pulsar system J0737-3039 based on the spin-down of the first-born 22.7-ms pulsar A and the 2.77-s pulsar B, whose characteristic ages are 210 and 50 Myr, respectively. Conventional models for dipolar spin-down of two pulsars suggest that B has only been around for ~50 Myr, close to its characteristic age. Nevertheless, we look into models that take into account the influence of A's relativistic wind on B's spin-down, which reveals that B could have been born 80 or 180 Myr ago depending on which interaction mechanism applies. An 80-Myr age would be closer to the characteristic age of B, while the 180-Myr age would match the recent estimates of coalescence rate. Furthermore, the new age limits have minimal impact on the estimates of kick velocity, pre-supernova mass of B's progenitor, and tilt angle between the pre- and post-supernova orbital planes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3269}
{"prompt": "Rephrase the abstract of an article with title 'Numerical propagation of high energy cosmic rays in the Galaxy I:\n  technical issues'.\n  We present the results of a numerical simulation of propagation of cosmic\nrays with energy above $10^{15}$ eV in a complex magnetic field, made in\ngeneral of a large scale component and a turbulent component. Several\nconfigurations are investigated that may represent specific aspects of a\nrealistic magnetic field of the Galaxy, though the main purpose of this\ninvestigation is not to achieve a realistic description of the propagation in\nthe Galaxy, but rather to assess the role of several effects that define the\ncomplex problem of propagation. Our simulations of Cosmic Rays in the Galaxy\nwill be presented in Paper II. We identified several effects that are difficult\nto interpret in a purely diffusive approach and that play a crucial role in the\npropagation of cosmic rays in the complex magnetic field of the Galaxy. We\ndiscuss at length the problem of the extrapolation of our results to much lower\nenergies where data are available on the confinement time of cosmic rays in the\nGalaxy. The confinement time and its dependence on particles' rigidity are\ncrucial ingredients for 1) relating the source spectrum to the observed cosmic\nray spectrum; 2) quantifying the production of light elements by spallation; 3)\npredicting the anisotropy as a function of energy.\n\n", "human_text": "  We present the results of a numerical simulation of propagation of cosmic\nrays with energy above $10^{15}$ eV in a complex magnetic field, made in\ngeneral of a large scale component and a turbulent component. Several\nconfigurations are investigated that may represent specific aspects of a\nrealistic magnetic field of the Galaxy, though the main purpose of this\ninvestigation is not to achieve a realistic description of the propagation in\nthe Galaxy, but rather to assess the role of several effects that define the\ncomplex problem of propagation. Our simulations of Cosmic Rays in the Galaxy\nwill be presented in Paper II. We identified several effects that are difficult\nto interpret in a purely diffusive approach and that play a crucial role in the\npropagation of cosmic rays in the complex magnetic field of the Galaxy. We\ndiscuss at length the problem of the extrapolation of our results to much lower\nenergies where data are available on the confinement time of cosmic rays in the\nGalaxy. The confinement time and its dependence on particles' rigidity are\ncrucial ingredients for 1) relating the source spectrum to the observed cosmic\nray spectrum; 2) quantifying the production of light elements by spallation; 3)\npredicting the anisotropy as a function of energy.\n", "machine_text": "\nIn this paper, we discuss the numerical simulation of high energy cosmic ray (above $10^{15}$ eV) propagation through a complex magnetic field composed of a large-scale component and a turbulent component in order to explore potential relevant effects to the problem. We identify a number of effects that are difficult to interpret in a diffusive approach while making an important contribution to Cosmic Ray diffusion in the complex field of the Galaxy. We further assess the effect of this simulation on confinement time of cosmic rays and its dependence on particle rigidity, which is integral in determining source spectra, light element production by spallation, and anisotropy in cosmic ray propagation. These results will be presented and discussed in detail in subsequent paper.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1972}
{"prompt": "Rephrase the abstract of an article with title 'The Unique Type Ib Supernova 2005bf at Nebular Phases: A Possible Birth\n  Event of A Strongly Magnetized Neutron Star'.\n  Late phase nebular spectra and photometry of Type Ib Supernova (SN) 2005bf\ntaken by the Subaru telescope at ~ 270 and ~ 310 days since the explosion are\npresented. Emission lines ([OI]6300, 6363, [CaII]7291, 7324, [FeII]7155) show\nthe blueshift of ~ 1,500 - 2,000 km s-1. The [OI] doublet shows a doubly-peaked\nprofile. The line luminosities can be interpreted as coming from a blob or jet\ncontaining only ~ 0.1 - 0.4 Msun, in which ~ 0.02 - 0.06 Msun is 56Ni\nsynthesized at the explosion. To explain the blueshift, the blob should either\nbe of unipolar moving at the center-of-mass velocity v ~ 2,000 - 5,000 km s-1,\nor suffer from self-absorption within the ejecta as seen in SN 1990I. In both\ninterpretations, the low-mass blob component dominates the optical output both\nat the first peak (~ 20 days) and at the late phase (~ 300 days). The low\nluminosity at the late phase (the absolute R magnitude M_R ~ -10.2 mag at ~ 270\ndays) sets the upper limit for the mass of 56Ni < ~ 0.08 Msun, which is in\ncontradiction to the value necessary to explain the second, main peak\nluminosity (M_R ~ -18.3 mag at ~ 40 days). Encountered by this difficulty in\nthe 56Ni heating model, we suggest an alternative scenario in which the heating\nsource is a newly born, strongly magnetized neutron star (a magnetar) with the\nsurface magnetic field Bmag ~ 10^{14-15} gauss and the initial spin period P0 ~\n10 ms. Then, SN 2005bf could be a link between normal SNe Ib/c and an X-Ray\nFlash associated SN 2006aj, connected in terms of Bmag and/or P0.\n\n", "human_text": "  Late phase nebular spectra and photometry of Type Ib Supernova (SN) 2005bf\ntaken by the Subaru telescope at ~ 270 and ~ 310 days since the explosion are\npresented. Emission lines ([OI]6300, 6363, [CaII]7291, 7324, [FeII]7155) show\nthe blueshift of ~ 1,500 - 2,000 km s-1. The [OI] doublet shows a doubly-peaked\nprofile. The line luminosities can be interpreted as coming from a blob or jet\ncontaining only ~ 0.1 - 0.4 Msun, in which ~ 0.02 - 0.06 Msun is 56Ni\nsynthesized at the explosion. To explain the blueshift, the blob should either\nbe of unipolar moving at the center-of-mass velocity v ~ 2,000 - 5,000 km s-1,\nor suffer from self-absorption within the ejecta as seen in SN 1990I. In both\ninterpretations, the low-mass blob component dominates the optical output both\nat the first peak (~ 20 days) and at the late phase (~ 300 days). The low\nluminosity at the late phase (the absolute R magnitude M_R ~ -10.2 mag at ~ 270\ndays) sets the upper limit for the mass of 56Ni < ~ 0.08 Msun, which is in\ncontradiction to the value necessary to explain the second, main peak\nluminosity (M_R ~ -18.3 mag at ~ 40 days). Encountered by this difficulty in\nthe 56Ni heating model, we suggest an alternative scenario in which the heating\nsource is a newly born, strongly magnetized neutron star (a magnetar) with the\nsurface magnetic field Bmag ~ 10^{14-15} gauss and the initial spin period P0 ~\n10 ms. Then, SN 2005bf could be a link between normal SNe Ib/c and an X-Ray\nFlash associated SN 2006aj, connected in terms of Bmag and/or P0.\n", "machine_text": "\nThis article presents late phase spectroscopic and photometric observations of the Type Ib supernova (SN) 2005bf made with the Subaru telescope. Emission lines have been detected with blueshifts of 1,500-2,000 km/s. The line luminosities suggest that a blob or jet containing ~ 0.1-0.4 M_sun of material was driven out near the center-of-mass velocity of ~2,000-5,000 km/s. This, combined with the low optical output at the late phase of these observations would limit the amount of synthesized 56Ni to ~0.08 M_sun. This value contradicts the amount needed to explain the main peak luminosity. An alternative scenario is then proposed to explain the late phase observations; a newly born, strongly magnetized neutron star (magnetar) with a surface magnetic field of ~10^14-15 gauss and an initial spin period of ~10 ms could serve as the heating source. This would link SN 2005bf to seemingly unrelated X-ray Flash events such as SN 2006aj.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2713}
{"prompt": "Rephrase the abstract of an article with title 'A New Tool for Seismology--the Cumulative Spectral Power'.\n  The power spectral density (PSD) function is commonly used to specify\nseismometer performance. It is derived from the FFT of acceleration and\ncorrection is made for the transfer function of the instrument that generated\nthe data. As with any such spectrum of density (`per Hz') type, the noise\ninherent to a PSD is large. This article illustrates the value of a function\nthat is derived from the PSD and for which the influence of noise is\nsignificantly reduced. Called the cumulative spectral power (CSP), it is\nobtained from the PSD through the noise-reducing process of integration. The\nmaximum of the CSP (corresponding to the longest graphed value of the period)\nprovides a means for estimating the total vibrational power of the earth. The\npresent author has significantly simplified the process of PSD generation. Thus\nroutine graphing is straightforwared-of first the FFT, followed by the\ngeneration of both a PSD and its associated CSP. The unique properties of the\nCSP make it valuable for the study of a variety of earth dynamics. For example,\nthe strking simplicity of a CSP graph generated from a record containing a\nstrong teleseismic earthquake is undoubtedly important to the development and\nrefinement of any viable theory of earthquake dynamics.\n\n", "human_text": "  The power spectral density (PSD) function is commonly used to specify\nseismometer performance. It is derived from the FFT of acceleration and\ncorrection is made for the transfer function of the instrument that generated\nthe data. As with any such spectrum of density (`per Hz') type, the noise\ninherent to a PSD is large. This article illustrates the value of a function\nthat is derived from the PSD and for which the influence of noise is\nsignificantly reduced. Called the cumulative spectral power (CSP), it is\nobtained from the PSD through the noise-reducing process of integration. The\nmaximum of the CSP (corresponding to the longest graphed value of the period)\nprovides a means for estimating the total vibrational power of the earth. The\npresent author has significantly simplified the process of PSD generation. Thus\nroutine graphing is straightforwared-of first the FFT, followed by the\ngeneration of both a PSD and its associated CSP. The unique properties of the\nCSP make it valuable for the study of a variety of earth dynamics. For example,\nthe strking simplicity of a CSP graph generated from a record containing a\nstrong teleseismic earthquake is undoubtedly important to the development and\nrefinement of any viable theory of earthquake dynamics.\n", "machine_text": "\n\nThis article explores the benefits of a new approach to understanding seismic activity that can reduce the noise inherent to Power Spectral Density (PSD) functions. Called the Cumulative Spectral Power (CSP), it utilizes an integration process that reduces the impact of noise on the data. Its maximum value (corresponding to the longest graphed period) provides an estimate of the level of earth vibrations. This author has streamlined the process of PSD generation, making it easy to graph both PSD and CSP. Furthermore, CSP graphing is useful for examining diverse earth dynamics such as teleseismic earthquakes, and its simplicity is a beneficial tool for refining the relevant theories.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.11}
{"prompt": "Rephrase the abstract of an article with title 'Linkage between Accretion Disks and Blazars'.\n  The magnetic field in an accretion disk is estimated assuming that all of the\nangular momentum within prescribed accretion disk radii is removed by a jet.\nThe magnetic field estimated at the base of the jet is extrapolated to the\nblazar emission region using a model for a relativistic axisymmetric jet\ncombined with some simplifying assumptions based on the relativistic nature of\nthe flow. The extrapolated magnetic field is compared with estimates based upon\nthe synchrotron and inverse Compton emission from three blazars, MKN 501, MKN\n421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self-\nCompton models are inconsistent with the magnetic fields extrapolated in this\nway. However, in two cases inverse Compton models in which a substantial part\nof the soft photon field is generated locally agree well, mainly because these\nmodels imply magnetic field strengths which are closer to being consistent with\nPoynting flux dominated jets. This comparison is based on estimating the mass\naccretion rate from the jet energy flux. Further comparisons along these lines\nwill be facilitated by independent estimates of the mass accretion rate in\nblazars and by more detailed models for jet propagation near the black hole.\n\n", "human_text": "  The magnetic field in an accretion disk is estimated assuming that all of the\nangular momentum within prescribed accretion disk radii is removed by a jet.\nThe magnetic field estimated at the base of the jet is extrapolated to the\nblazar emission region using a model for a relativistic axisymmetric jet\ncombined with some simplifying assumptions based on the relativistic nature of\nthe flow. The extrapolated magnetic field is compared with estimates based upon\nthe synchrotron and inverse Compton emission from three blazars, MKN 501, MKN\n421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self-\nCompton models are inconsistent with the magnetic fields extrapolated in this\nway. However, in two cases inverse Compton models in which a substantial part\nof the soft photon field is generated locally agree well, mainly because these\nmodels imply magnetic field strengths which are closer to being consistent with\nPoynting flux dominated jets. This comparison is based on estimating the mass\naccretion rate from the jet energy flux. Further comparisons along these lines\nwill be facilitated by independent estimates of the mass accretion rate in\nblazars and by more detailed models for jet propagation near the black hole.\n", "machine_text": "\nThis article examines the relationship between accretion disks and blazars. Magnetic field strength is calculated at the base of the jet and extrapolated to the blazar emission area, based on a relativistic axisymmetric jet model and some relativistic flow assumptions. This extrapolated magnetic field is then compared to the estimated fields formed by synchrotron self-Compton and inverse Compton models. The energy flux of the jet is used to estimate the mass accretion rate, and it is found with pure synchrotron self-Compton models that the field strengths are inconsistent. However, with models incorporating local production of soft photons, a closer agreement is found, primarily due to the fact that these models imply magnetic field strengths that are more similar to those with Poynting flux dominated jets. To further analyze the link between accretion disks and blazars, more detailed models for jet propagation and independent estimation of the mass accretion rate will be required.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2636}
{"prompt": "Rephrase the abstract of an article with title 'Charge and spin stripe in La$_{2-x}$Sr$_{x}$NiO$_{4}$ (x=1/3,1/2)'.\n  Electronic structure of stripe ordered La$_{2-x}$Sr$_{x}$NiO$_{4}$ is\ninvestigated. The system with x=1/3 is insulator, in LSDA+U calculations, and\nshows charge and spin stripe, consistent with the experimental results. Highly\ncorrelated system of x=1/2 is studied by using exact diagonalization of\nmulti-orbital many body Hamiltonian derived from LDA calculations and including\non-site and inter-site Coulomb interactions. The fluctuation of the residual\nspin on Ni$^{3+}$ (hole) site couples with the charge fluctuation between\nNi$^{3+}$ and Ni$^{2+}$ states and this correlation lowers the total energy.\nThe resultant ground state is insulator with charge and spin stripe of the\nenergy gap 0.9eV, consistent with observed one. The on-site Coulomb interaction\nstabilizes integral valency of each Ni ion (Ni$^{3+}$ and Ni$^{2+}$), but does\nnot induce the charge order. Two quantities, inter-site Coulomb interaction and\nanisotropy of hopping integrals, play an important role to form the charge and\nspin stripe order in a system of x=1/2.\n\n", "human_text": "  Electronic structure of stripe ordered La$_{2-x}$Sr$_{x}$NiO$_{4}$ is\ninvestigated. The system with x=1/3 is insulator, in LSDA+U calculations, and\nshows charge and spin stripe, consistent with the experimental results. Highly\ncorrelated system of x=1/2 is studied by using exact diagonalization of\nmulti-orbital many body Hamiltonian derived from LDA calculations and including\non-site and inter-site Coulomb interactions. The fluctuation of the residual\nspin on Ni$^{3+}$ (hole) site couples with the charge fluctuation between\nNi$^{3+}$ and Ni$^{2+}$ states and this correlation lowers the total energy.\nThe resultant ground state is insulator with charge and spin stripe of the\nenergy gap 0.9eV, consistent with observed one. The on-site Coulomb interaction\nstabilizes integral valency of each Ni ion (Ni$^{3+}$ and Ni$^{2+}$), but does\nnot induce the charge order. Two quantities, inter-site Coulomb interaction and\nanisotropy of hopping integrals, play an important role to form the charge and\nspin stripe order in a system of x=1/2.\n", "machine_text": "\nThe electronic structure of La$_{2-x}$Sr$_{x}$NiO$_{4}$ with x=1/3 and 1/2 has been studied to investigate the charge and spin stripe order. For x=1/3, the results from LSDA+U calculations show that the system is an insulator and has both the charge and spin stripe structure, consistent with experimental findings. With x=1/2, an exact diagonalization of a multi-orbital many body Hamiltonian derived from LDA, including on-site and inter-site Coulomb interactions, yields a ground state of an insulator with an energy gap of 0.9eV and charge and spin stripe order. It was found that the on-site Coulomb interaction is essential to ensure integral valency of each Ni ion, though it does not directly trigger the charge order. Instead, the inter-site Coulomb interaction and the anisotropy of hopping integrals are both pertinent to the structure of charge and spin stripe order in the system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3323}
{"prompt": "Rephrase the abstract of an article with title 'Projectile Fragmentation of $^{86}$Kr at 64 MeV/nucleon'.\n  We measured fragmentation cross sections produced using the primary beam of\n$^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross\nsections were obtained by integrating the momentum distributions of isotopes\nwith 25<Z<36 measured using the RIPS fragment separator at RIKEN. The\ncross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend\non the fragment masses, contrary to the simple geometrical models. We compared\nthe extracted cross sections to EPAX; an empirical parameterization of\nfragmentation cross sections. Predictions from current EPAX parameterization\nseverely overestimate the production cross sections of very neutron-rich\nisotopes. Attempts to obtain another set of EPAX parameters specific to the\nreaction studied here, to extrapolate the neutron-rich nuclei more accurately\nhave not been very successful, suggesting that accurate predictions of\nproduction cross sections of nuclei far from the valley of stability require\ninformation of nuclear properties which are not present in EPAX.\n\n", "human_text": "  We measured fragmentation cross sections produced using the primary beam of\n$^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross\nsections were obtained by integrating the momentum distributions of isotopes\nwith 25<Z<36 measured using the RIPS fragment separator at RIKEN. The\ncross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend\non the fragment masses, contrary to the simple geometrical models. We compared\nthe extracted cross sections to EPAX; an empirical parameterization of\nfragmentation cross sections. Predictions from current EPAX parameterization\nseverely overestimate the production cross sections of very neutron-rich\nisotopes. Attempts to obtain another set of EPAX parameters specific to the\nreaction studied here, to extrapolate the neutron-rich nuclei more accurately\nhave not been very successful, suggesting that accurate predictions of\nproduction cross sections of nuclei far from the valley of stability require\ninformation of nuclear properties which are not present in EPAX.\n", "machine_text": "\nWe conducted an experiment to measure the fragmentation cross sections created by a 64 MeV/nucleon primary beam of $^{86}$Kr nuclei, when impacting upon a $^9$Be and $^{181}$Ta target. We collected data on isotopes in the range 25<Z<36, using the RIPS fragment separator at RIKEN. Our results showed a discrepancy between geometrical predictions and the actual cross-section ratios, and were compared with EPAX; an empirical parameterization for fragmentation cross sections. This comparison suggested that present EPAX formulations tend to overestimate cross sections for highly neutron-rich isotopes. Further analysis via an alternative EPAX parameterization proved unsuccessful, suggesting that accurate predictions for these cross sections require data that EPAX does not supply.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4313}
{"prompt": "Rephrase the abstract of an article with title 'The Nonperiodic Anyon Model and the Fractional Quantum Hall Effect'.\n  The lowest-Landau-level anyon model becomes nonperiodic in the statistics\nparameter when the finite size of the attached flux tubes is taken into\naccount. The finite-size effects cause the inverse proportional relation\nbetween the critical filling factor and the statistics parameter to be\nnonperiodically continued in the screening regime, where the fluxes are\nanti-parallel to the external magnetic field -- at critical filling, the\nexternal magnetic field is entirely screened by the mean magnetic field\nassociated with the flux tubes. A clustering argument is proposed to select\nparticular values of the statistics parameter. In this way, IQHE and FQHE\nfillings are obtained in terms of gapped nondegenerate LLL-anyonic wave\nfunctions. Jain's series are reproduced without the need to populate higher\nLandau levels. New FQHE series are proposed, like, in particular, the\nparticle-hole complementary series of the Laughlin one. For fast-rotating\nBose-Einstein condensates, a corresponding clustering argument yields\nparticular fractional filling series.\n\n", "human_text": "  The lowest-Landau-level anyon model becomes nonperiodic in the statistics\nparameter when the finite size of the attached flux tubes is taken into\naccount. The finite-size effects cause the inverse proportional relation\nbetween the critical filling factor and the statistics parameter to be\nnonperiodically continued in the screening regime, where the fluxes are\nanti-parallel to the external magnetic field -- at critical filling, the\nexternal magnetic field is entirely screened by the mean magnetic field\nassociated with the flux tubes. A clustering argument is proposed to select\nparticular values of the statistics parameter. In this way, IQHE and FQHE\nfillings are obtained in terms of gapped nondegenerate LLL-anyonic wave\nfunctions. Jain's series are reproduced without the need to populate higher\nLandau levels. New FQHE series are proposed, like, in particular, the\nparticle-hole complementary series of the Laughlin one. For fast-rotating\nBose-Einstein condensates, a corresponding clustering argument yields\nparticular fractional filling series.\n", "machine_text": " The Nonperiodic Anyon Model is examined to explain the Fractional Quantum Hall Effect (FQHE) in terms of LLL-anyonic wave functions. Taking into account the finite size of flux tubes, the model establishes an inverse proportional relation between the critical filling factor and the parameter of statistical exchange. When the fluxes are anti-parallel to the external magnetic field and critical filling is achieved, the external magnetic field is completely shielded by the mean magnetic field associated with the flux tubes. Utilizing the clustering argument, values for the statistical parameter can be chosen to ensure the fillings match those proposed by Jain's series, as well as new FQHE series like the particle-hole complementary to the Laughlin one. This same clustering argument can be used to produce particular fractional filling series in fast-rotating Bose-Einstein condensates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2474}
{"prompt": "Rephrase the abstract of an article with title 'Results of the IGEC-2 search for gravitational wave bursts during 2005'.\n  The network of resonant bar detectors of gravitational waves resumed\ncoordinated observations within the International Gravitational Event\nCollaboration (IGEC-2). Four detectors are taking part in this collaboration:\nALLEGRO, AURIGA, EXPLORER and NAUTILUS. We present here the results of the\nsearch for gravitational wave bursts over 6 months during 2005, when IGEC-2 was\nthe only gravitational wave observatory in operation. The network data analysis\nimplemented is based on a time coincidence search among AURIGA, EXPLORER and\nNAUTILUS, keeping the data from ALLEGRO for follow-up studies. With respect to\nthe previous IGEC 1997-2000 observations, the amplitude sensitivity of the\ndetectors to bursts improved by a factor about 3 and the sensitivity bandwidths\nare wider, so that the data analysis was tuned considering a larger class of\ndetectable waveforms. Thanks to the higher duty cycles of the single detectors,\nwe decided to focus the analysis on three-fold observation, so to ensure the\nidentification of any single candidate of gravitational waves (gw) with high\nstatistical confidence. The achieved false detection rate is as low as 1 per\ncentury. No candidates were found.\n\n", "human_text": "  The network of resonant bar detectors of gravitational waves resumed\ncoordinated observations within the International Gravitational Event\nCollaboration (IGEC-2). Four detectors are taking part in this collaboration:\nALLEGRO, AURIGA, EXPLORER and NAUTILUS. We present here the results of the\nsearch for gravitational wave bursts over 6 months during 2005, when IGEC-2 was\nthe only gravitational wave observatory in operation. The network data analysis\nimplemented is based on a time coincidence search among AURIGA, EXPLORER and\nNAUTILUS, keeping the data from ALLEGRO for follow-up studies. With respect to\nthe previous IGEC 1997-2000 observations, the amplitude sensitivity of the\ndetectors to bursts improved by a factor about 3 and the sensitivity bandwidths\nare wider, so that the data analysis was tuned considering a larger class of\ndetectable waveforms. Thanks to the higher duty cycles of the single detectors,\nwe decided to focus the analysis on three-fold observation, so to ensure the\nidentification of any single candidate of gravitational waves (gw) with high\nstatistical confidence. The achieved false detection rate is as low as 1 per\ncentury. No candidates were found.\n", "machine_text": "\nThe International Gravitational Event Collaboration (IGEC-2) utilized the internationally recognized network of resonant bar detectors to coordinate observations of gravitational wave bursts over a 6-month period in 2005. These four detectors - ALLEGRO, AURIGA, EXPLORER and NAUTILUS - had improved sensitivities over IGEC 1997-2000 observations, due to enhanced duty cycles and wider bandwidths. The data analysis focused on threefold observation to ensure a strong statistical confidence if a candidate of gravitational waves were to be found. A false detection rate of 1 per century was achieved, yet no candidate events were located.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0688}
{"prompt": "Rephrase the abstract of an article with title 'The power of quantum systems on a line'.\n  We study the computational strength of quantum particles (each of finite\ndimensionality) arranged on a line. First, we prove that it is possible to\nperform universal adiabatic quantum computation using a one-dimensional quantum\nsystem (with 9 states per particle). This might have practical implications for\nexperimentalists interested in constructing an adiabatic quantum computer.\nBuilding on the same construction, but with some additional technical effort\nand 12 states per particle, we show that the problem of approximating the\nground state energy of a system composed of a line of quantum particles is\nQMA-complete; QMA is a quantum analogue of NP. This is in striking contrast to\nthe fact that the analogous classical problem, namely, one-dimensional\nMAX-2-SAT with nearest neighbor constraints, is in P. The proof of the\nQMA-completeness result requires an additional idea beyond the usual techniques\nin the area: Not all illegal configurations can be ruled out by local checks,\nso instead we rule out such illegal configurations because they would, in the\nfuture, evolve into a state which can be seen locally to be illegal. Our\nconstruction implies (assuming the quantum Church-Turing thesis and that\nquantum computers cannot efficiently solve QMA-complete problems) that there\nare one-dimensional systems which take an exponential time to relax to their\nground states at any temperature, making them candidates for being\none-dimensional spin glasses.\n\n", "human_text": "  We study the computational strength of quantum particles (each of finite\ndimensionality) arranged on a line. First, we prove that it is possible to\nperform universal adiabatic quantum computation using a one-dimensional quantum\nsystem (with 9 states per particle). This might have practical implications for\nexperimentalists interested in constructing an adiabatic quantum computer.\nBuilding on the same construction, but with some additional technical effort\nand 12 states per particle, we show that the problem of approximating the\nground state energy of a system composed of a line of quantum particles is\nQMA-complete; QMA is a quantum analogue of NP. This is in striking contrast to\nthe fact that the analogous classical problem, namely, one-dimensional\nMAX-2-SAT with nearest neighbor constraints, is in P. The proof of the\nQMA-completeness result requires an additional idea beyond the usual techniques\nin the area: Not all illegal configurations can be ruled out by local checks,\nso instead we rule out such illegal configurations because they would, in the\nfuture, evolve into a state which can be seen locally to be illegal. Our\nconstruction implies (assuming the quantum Church-Turing thesis and that\nquantum computers cannot efficiently solve QMA-complete problems) that there\nare one-dimensional systems which take an exponential time to relax to their\nground states at any temperature, making them candidates for being\none-dimensional spin glasses.\n", "machine_text": "\nWe investigate the potential of quantum particles arranged in a line to perform universal adiabatic quantum computing. With nine states per particle, we prove this to be possible. This finding has possible applications for those looking to build adiabatic quantum computers. By adding some more technical effort and increasing the number of states to twelve, we demonstrate that state energy approximation becomes QMA-complete. This is in stark comparison to the analogous classical problem, which is contained in P. To prove this, the usual methods are not sufficient and so we had to find an additional way - ruling out all illegal configurations by accounting for how they will evolve in the future. Our results show that, if the quantum Church-Turing thesis is accepted and quantum computers cannot efficiently solve QMA-complete problems, one-dimensional systems that take exponential time to reach their ground state may appear as one-dimensional spin glasses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4077}
{"prompt": "Rephrase the abstract of an article with title 'Host Galaxy Bulge Predictors of Supermassive Black Hole Mass'.\n  A variety of host galaxy (bulge) parameters are examined in order to\ndetermine their predictive power in ascertaining the masses of the supermassive\nblack holes (SMBH) at the centers of the galaxies. Based on a sample of 23\nnearby galaxies, comprised of both elliptical galaxies and spiral/lenticular\nbulges, we identify a strong correlation between the bulge gravitational\nbinding energy ($E_g$), as traced by the stellar light profile, and the SMBH\nmass ($M_{\\bullet}$), such that $M_{\\bullet} \\propto E_g^{0.6}$. The scatter\nabout the relationship indicates that this is as strong a predictor of\n$M_{\\bullet}$ as the velocity dispersion ($\\sigma$), for the elliptical galaxy\nsubsample. Improved mass-to-light ratios, obtained with IFU spectroscopy and\nI-band photometry by the SAURON group, were used for those sample galaxies\nwhere available, resulting in an energy predictor with the same slope, but with\nreduced scatter. Alternative $M_{\\bullet}$ predictors such as the gravitational\npotential and the bulge mass are also explored, but these are found to be\ninferior when compared with both the bulge gravitational binding energy and\nbulge velocity dispersion predictors, for the full galaxy sample.\n\n", "human_text": "  A variety of host galaxy (bulge) parameters are examined in order to\ndetermine their predictive power in ascertaining the masses of the supermassive\nblack holes (SMBH) at the centers of the galaxies. Based on a sample of 23\nnearby galaxies, comprised of both elliptical galaxies and spiral/lenticular\nbulges, we identify a strong correlation between the bulge gravitational\nbinding energy ($E_g$), as traced by the stellar light profile, and the SMBH\nmass ($M_{\\bullet}$), such that $M_{\\bullet} \\propto E_g^{0.6}$. The scatter\nabout the relationship indicates that this is as strong a predictor of\n$M_{\\bullet}$ as the velocity dispersion ($\\sigma$), for the elliptical galaxy\nsubsample. Improved mass-to-light ratios, obtained with IFU spectroscopy and\nI-band photometry by the SAURON group, were used for those sample galaxies\nwhere available, resulting in an energy predictor with the same slope, but with\nreduced scatter. Alternative $M_{\\bullet}$ predictors such as the gravitational\npotential and the bulge mass are also explored, but these are found to be\ninferior when compared with both the bulge gravitational binding energy and\nbulge velocity dispersion predictors, for the full galaxy sample.\n", "machine_text": "\nBy using a sample of 23 nearby elliptical galaxies and spiral/lenticular bulges, it has been found that there is an influential correlation between the mass of the supermassive black hole (SMBH) and the gravitational binding energy of the bulge, as measured by the stellar light profiles. It was revealed that $M_{\\bullet}$ corresponds directly to $E_g^{0.6}$, with a scatter that suggests this is as reliable a predictor as the bulge's velocity dispersion, at least in the case of ellipticals. Even so, alternative $M_{\\bullet}$ predictors such as the gravitational potential and the bulge mass were observed to be weaker when comparing across the entire sample population. With the aid of IFU spectroscopy and I-band photometry by the SAURON group, new mass-to-light ratios were used for some of the galaxies, leading to an energy predictor with an identical slope but with reduced deviation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1165}
{"prompt": "Rephrase the abstract of an article with title 'Direct determination of the epicycle frequency in the galactic disk, and\n  the derived rotation velocity V0'.\n  We present a method which allows a direct measurement of the epicycle\nfrequency $\\kappa$ in the galactic disk, using the large database on open\nclusters completed by our group. The observed velocity vector (amplitude and\ndirection) of the clusters in the galactic plane is derived from the catalog\ndata. In the epicycle approximation, this velocity is the sum of the circular\nvelocity, described by the galactic rotation curve, and of a residual velocity,\nwhich has a direction that rotates with the frequency $\\kappa$. If for some\nreason the clusters are formed with non-random initial perturbation velocity\ndirection (measured for instance with respect to the direction of circular\nrotation), then a plot of the orientation angle of the residual velocity as a\nfunction of age reveals the epicycle frequency. The data analysis confirms that\nthis is the case; due to the non-random initial velocities, it is possible to\nmeasure $\\kappa$ for different galactic radii. Our analysis considers that the\neffect of the arms on the stellar orbits is small (the Galactic potential is\nmainly axis-symmetric); in this sense our results do not depend on any specific\nmodel of the spiral structure, like the existence of a given number of spiral\narms, or on a particular choice of the radius of corotation. The values of\n$\\kappa$ provide constraints on the rotation velocity of the disk and on its\nminimum beyond the solar radius; in particular, $V_0$ is found to be 226 $\\pm$\n15 kms$^{-1}$ even if the short scale (R$_0$ = 7.5 kpc) of the galaxy is\nadopted. The mesured $\\kappa$ at the solar radius is 42$\\pm$4\nkms$^{-1}$kpc$^{-1}$.\n\n", "human_text": "  We present a method which allows a direct measurement of the epicycle\nfrequency $\\kappa$ in the galactic disk, using the large database on open\nclusters completed by our group. The observed velocity vector (amplitude and\ndirection) of the clusters in the galactic plane is derived from the catalog\ndata. In the epicycle approximation, this velocity is the sum of the circular\nvelocity, described by the galactic rotation curve, and of a residual velocity,\nwhich has a direction that rotates with the frequency $\\kappa$. If for some\nreason the clusters are formed with non-random initial perturbation velocity\ndirection (measured for instance with respect to the direction of circular\nrotation), then a plot of the orientation angle of the residual velocity as a\nfunction of age reveals the epicycle frequency. The data analysis confirms that\nthis is the case; due to the non-random initial velocities, it is possible to\nmeasure $\\kappa$ for different galactic radii. Our analysis considers that the\neffect of the arms on the stellar orbits is small (the Galactic potential is\nmainly axis-symmetric); in this sense our results do not depend on any specific\nmodel of the spiral structure, like the existence of a given number of spiral\narms, or on a particular choice of the radius of corotation. The values of\n$\\kappa$ provide constraints on the rotation velocity of the disk and on its\nminimum beyond the solar radius; in particular, $V_0$ is found to be 226 $\\pm$\n15 kms$^{-1}$ even if the short scale (R$_0$ = 7.5 kpc) of the galaxy is\nadopted. The mesured $\\kappa$ at the solar radius is 42$\\pm$4\nkms$^{-1}$kpc$^{-1}$.\n", "machine_text": "\nWe have developed a technique for direct determination of the epicycle frequency $\\kappa$ in the galactic disk from a large database of open clusters. From the catalog data, we evaluated the observed velocity vector (direction and magnitude) of the clusters in the galactic plane. For large-scale asymmetric structures as galaxies, the residual velocity in the disk has a direction rotating with the frequency $\\kappa$ and the circular velocity is in determined by the galactic rotation curve. By observing any non-random initial velocities in the clusters, plot of the orientation angle of the velocity as a function of age reveals the epicycle frequency. Analysis of the data confirmed this non-random direction and enabled us to measure $\\kappa$ for different galactic radii. Our results are independent of Galactic arm models, such as the number of spiral arms or the particular choice of the radius of corotation. We obtained results indicating a minimum rotation velocity beyond the solar radius of 226 $\\pm$ 15 kms$^{-1}$ and a $\\kappa$ of 42 $\\pm$ 4 kms$^{-1}$kpc$^{-1}$ at the solar radius.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1811}
{"prompt": "Rephrase the abstract of an article with title 'Molecular opacities for low-mass metal-poor AGB stars undergoing the\n  Third Dredge Up'.\n  The concomitant overabundances of C, N and s-process elements are commonly\nascribed to the complex interplay of nucleosynthesis, mixing and mass loss\ntaking place in Asymptotic Giant Branch stars. At low metallicity, the\nenhancement of C and/or N may be up to 1000 times larger than the original iron\ncontent and significantly affects the stellar structure and its evolution. For\nthis reason, the interpretation of the already available and still growing\namount of data concerning C-rich metal-poor stars belonging to our Galaxy as\nwell as to dwarf spheroidal galaxies would require reliable AGB stellar models\nfor low and very low metallicities. In this paper we address the question of\ncalculation and use of appropriate opacity coefficients, which take into\naccount the C enhancement caused by the third dredge up. A possible N\nenhancement, caused by the cool bottom process or by the engulfment of protons\ninto the convective zone generated by a thermal pulse and the subsequent huge\nthird dredge up, is also considered. Basing on up-to-date stellar models, we\nillustrate the changes induced by the use of these opacity on the physical and\nchemical properties expected for these stars.\n\n", "human_text": "  The concomitant overabundances of C, N and s-process elements are commonly\nascribed to the complex interplay of nucleosynthesis, mixing and mass loss\ntaking place in Asymptotic Giant Branch stars. At low metallicity, the\nenhancement of C and/or N may be up to 1000 times larger than the original iron\ncontent and significantly affects the stellar structure and its evolution. For\nthis reason, the interpretation of the already available and still growing\namount of data concerning C-rich metal-poor stars belonging to our Galaxy as\nwell as to dwarf spheroidal galaxies would require reliable AGB stellar models\nfor low and very low metallicities. In this paper we address the question of\ncalculation and use of appropriate opacity coefficients, which take into\naccount the C enhancement caused by the third dredge up. A possible N\nenhancement, caused by the cool bottom process or by the engulfment of protons\ninto the convective zone generated by a thermal pulse and the subsequent huge\nthird dredge up, is also considered. Basing on up-to-date stellar models, we\nillustrate the changes induced by the use of these opacity on the physical and\nchemical properties expected for these stars.\n", "machine_text": "This article examines the effect of C and/or N enhancement on the stellar structure and evolution of low-metallicity stars in the Asymptotic Giant Branch phase. In particular, we focus on the usage of appropriate opacity coefficients, to account for the potential C enrichment caused by the third dredge up, and the possible N enrichment due to a cool bottom process or by the ingestion of protons into the convective zone post-thermal pulse. Through calculation of up-to-date stellar models, our paper illustrates the changes manifested in the physical and chemical characteristics of these stars due to the adjusted opacities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.21}
{"prompt": "Rephrase the abstract of an article with title 'Virtual Photon Emission from Quark-Gluon Plasma'.\n  We recently proposed an empirical approach for the Landau-Pomeranchuk-Migdal\n(LPM) effects in photon emission from the quark gluon plasma as a function of\nphoton mass. This approach was based on Generalized Emission Functions (GEF)\nfor photon emission, derived at a fixed temperature and strong coupling\nconstant. In the present work, we have extended the LPM calculations for\nseveral temperatures and strong coupling strengths. The integral equations for\n(${\\bf \\tilde{f}(\\tilde{p}_\\perp)}$) and ($\\tilde{g}({\\bf \\tilde{p}_\\perp})$)\nare solved by the iterations method for the variable set\n\\{$p_0,q_0,Q^2,T,\\alpha_s$\\}, considering bremsstrahlung and $\\bf aws$\nprocesses. We generalize the dynamical scaling variables, $x_T$, $x_L$, for\nbremsstrahlung and {\\bf aws} processes which are now functions of variables\n$p_0,q_0,Q^2,T,\\alpha_s$. The GEF introduced earlier, $g^b_T$, $g^a_T$,\n$g^b_L$, $g^a_L$, are also generalized for any temperatures and coupling\nstrengths. From this, the imaginary part of the photon polarization tensor as a\nfunction of photon mass and energy can be calculated as a one dimensional\nintegral over these GEF and parton distribution functions in the plasma.\nHowever, for phenomenological studies of experimental data, one needs a simple\nempirical formula without involving parton momentum integrations. Therefore, we\npresent a phenomenological formula for imaginary photon polarization tensor as\na function of \\{$q_0,Q^2,T,\\alpha_s$\\} that includes bremsstrahlung and $\\bf\naws$ mechanisms along with LPM effects.\n\n", "human_text": "  We recently proposed an empirical approach for the Landau-Pomeranchuk-Migdal\n(LPM) effects in photon emission from the quark gluon plasma as a function of\nphoton mass. This approach was based on Generalized Emission Functions (GEF)\nfor photon emission, derived at a fixed temperature and strong coupling\nconstant. In the present work, we have extended the LPM calculations for\nseveral temperatures and strong coupling strengths. The integral equations for\n(${\\bf \\tilde{f}(\\tilde{p}_\\perp)}$) and ($\\tilde{g}({\\bf \\tilde{p}_\\perp})$)\nare solved by the iterations method for the variable set\n\\{$p_0,q_0,Q^2,T,\\alpha_s$\\}, considering bremsstrahlung and $\\bf aws$\nprocesses. We generalize the dynamical scaling variables, $x_T$, $x_L$, for\nbremsstrahlung and {\\bf aws} processes which are now functions of variables\n$p_0,q_0,Q^2,T,\\alpha_s$. The GEF introduced earlier, $g^b_T$, $g^a_T$,\n$g^b_L$, $g^a_L$, are also generalized for any temperatures and coupling\nstrengths. From this, the imaginary part of the photon polarization tensor as a\nfunction of photon mass and energy can be calculated as a one dimensional\nintegral over these GEF and parton distribution functions in the plasma.\nHowever, for phenomenological studies of experimental data, one needs a simple\nempirical formula without involving parton momentum integrations. Therefore, we\npresent a phenomenological formula for imaginary photon polarization tensor as\na function of \\{$q_0,Q^2,T,\\alpha_s$\\} that includes bremsstrahlung and $\\bf\naws$ mechanisms along with LPM effects.\n", "machine_text": "\nWe have developed a novel empirical approach for calculating the Landau-Pomeranchuk-Migdal (LPM) effects on virtual photon emission from quark-gluon plasma. To do this, we have extended the original model of generalized emission functions (GEF) to account for different temperatures and strong coupling strengths. In addition, the dynamical scaling variable $x_T$ and $x_L$ have been generalized to include the parameters $p_0, q_0, Q^2, T,   \\alpha_s$. Moreover, the GEF, $g^b_T, g^a_T, g^b_L, g^a_L$, have also been adapted for varying temperatures and couplings. This allows us to calculate the imaginary part of the photon polarization tensor as a function of photon mass and energy. To which end, we have put forth a phenomenological formula for the imaginary photon polarization tensor as a function of \\{$q_0, Q^2, T, \\alpha_s$\\}, to simplify experimental investigations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3676}
{"prompt": "Rephrase the abstract of an article with title 'Matched Filtering of Numerical Relativity Templates of Spinning Binary\n  Black Holes'.\n  Tremendous progress has been made towards the solution of the\nbinary-black-hole problem in numerical relativity. The waveforms produced by\nnumerical relativity will play a role in gravitational wave detection as either\ntest-beds for analytic template banks or as template banks themselves. As the\nparameter space explored by numerical relativity expands, the importance of\nquantifying the effect that each parameter has on first the detection of\ngravitational waves and then the parameter estimation of their sources\nincreases. In light of this, we present a study of equal-mass, spinning\nbinary-black-hole evolutions through matched filtering techniques commonly used\nin data analysis. We study how the match between two numerical waveforms varies\nwith numerical resolution, initial angular momentum of the black holes and the\ninclination angle between the source and the detector. This study is limited by\nthe fact that the spinning black-hole-binaries are oriented axially and the\nwaveforms only contain approximately two and a half orbits before merger. We\nfind that for detection purposes, spinning black holes require the inclusion of\nthe higher harmonics in addition to the dominant mode, a condition that becomes\nmore important as the black-hole-spins increase. In addition, we conduct a\npreliminary investigation of how well a template of fixed spin and inclination\nangle can detect target templates of arbitrary spin and inclination for the\naxial case considered here.\n\n", "human_text": "  Tremendous progress has been made towards the solution of the\nbinary-black-hole problem in numerical relativity. The waveforms produced by\nnumerical relativity will play a role in gravitational wave detection as either\ntest-beds for analytic template banks or as template banks themselves. As the\nparameter space explored by numerical relativity expands, the importance of\nquantifying the effect that each parameter has on first the detection of\ngravitational waves and then the parameter estimation of their sources\nincreases. In light of this, we present a study of equal-mass, spinning\nbinary-black-hole evolutions through matched filtering techniques commonly used\nin data analysis. We study how the match between two numerical waveforms varies\nwith numerical resolution, initial angular momentum of the black holes and the\ninclination angle between the source and the detector. This study is limited by\nthe fact that the spinning black-hole-binaries are oriented axially and the\nwaveforms only contain approximately two and a half orbits before merger. We\nfind that for detection purposes, spinning black holes require the inclusion of\nthe higher harmonics in addition to the dominant mode, a condition that becomes\nmore important as the black-hole-spins increase. In addition, we conduct a\npreliminary investigation of how well a template of fixed spin and inclination\nangle can detect target templates of arbitrary spin and inclination for the\naxial case considered here.\n", "machine_text": "\nThis paper carries out a detailed investigation into the effects of numerical resolution, black hole spin, and inclination angle on the detectability of equal-mass, spinning binary black holes using matched filtering techniques, commonly employed in data analysis. Results from our study suggest that higher harmonics are necessary for accurate detection of spinning binary black holes and can become increasingly important as their spins increase. We also present a preliminary analysis on how well a template of fixed spin and inclination can detect signals of arbitrary spin and inclination by sticking to the axial case scanned in this research. Our findings demonstrate the importance of the parameter space explored by numerical relativity and its implications for the detection of gravitational waves and the subsequent parameter estimation of their sources.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3829}
{"prompt": "Rephrase the abstract of an article with title 'Reexamining the Einstein-Podolsky-Rosen experiment, photon correlation\n  and Bell's inequality'.\n  The purpose of this article is to show that the introduction of hidden\nvariables to describe individual events is fully consistent with the\nstatistical predictions of quantum theory. We illustrate the validity of this\nassertion by discussing two fundamental experiments on correlated photons which\nare believed to behave ``violently non-classical''. Our considerations carry\nover to correlated pairs of neutral particles of spin one-half in a singlet\nstate. Much in the spirit of Einstein's conviction we come to the conclusion\nthat the state vector of a system does not provide an exhaustive description of\nthe individual physical system. We also briefly discuss an experiment on\n``quantum teleportation'' and demonstrate that our completely local approach\nleads to a full understanding of the experiment indicating the absence of any\nteleportation phenomenon. We caution that the indiscriminated use of the term\n``Quantum Theory'' tends to obscure distinct differences between the quantum\nmechanics of massive particles and the propagation of photons. It is emphasized\nthat the properties of polarizers, beam splitters, halfwave plates etc. used in\nphoton-correlation experiments are defined by the laws of classical optics.\nHence, understanding the outcome of those experiments requires a well-founded\ninterconnection between classical and quantum electrodynamics free from\nunnecessary hypotheses.\n\n", "human_text": "  The purpose of this article is to show that the introduction of hidden\nvariables to describe individual events is fully consistent with the\nstatistical predictions of quantum theory. We illustrate the validity of this\nassertion by discussing two fundamental experiments on correlated photons which\nare believed to behave ``violently non-classical''. Our considerations carry\nover to correlated pairs of neutral particles of spin one-half in a singlet\nstate. Much in the spirit of Einstein's conviction we come to the conclusion\nthat the state vector of a system does not provide an exhaustive description of\nthe individual physical system. We also briefly discuss an experiment on\n``quantum teleportation'' and demonstrate that our completely local approach\nleads to a full understanding of the experiment indicating the absence of any\nteleportation phenomenon. We caution that the indiscriminated use of the term\n``Quantum Theory'' tends to obscure distinct differences between the quantum\nmechanics of massive particles and the propagation of photons. It is emphasized\nthat the properties of polarizers, beam splitters, halfwave plates etc. used in\nphoton-correlation experiments are defined by the laws of classical optics.\nHence, understanding the outcome of those experiments requires a well-founded\ninterconnection between classical and quantum electrodynamics free from\nunnecessary hypotheses.\n", "machine_text": "\nThis article explores the notion that introducing hidden variables can still abide by the statistical predictions of quantum theory. This is shown by two pivotal experiments with correlated photons, where their behavior is deemed 'violently non-classical'. The conclusion reached is similar to Einstein's persuasion - that the expression of a system's state is not a sufficient explanation of its physical state. The experiment of quantum teleportation is then briefly looked into, and it is concluded that a classical approach can be a complete understanding of the outcome, where no teleportation has occurred. Attention is also drawn to the potential of overlooking the differences between quantum mechanics for massive particles, and the behavior of photons. Classical electrodynamics is looked to as the answer, and this requires a link between the two ideas without any speculative ideas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2568}
{"prompt": "Rephrase the abstract of an article with title 'Chemical and Dynamical Properties of the Stellar Halo'.\n  The difference in density profiles of the contributions from different\ndensity peaks to dark matter halos results in certain expectations about the\nMilky Way's stellar halo. We cut our simulated halo stars into two populations:\nthose forming before/during the last major merger, and those accreted after the\nlast major merger. The former population are more centrally located at z=0,\nwhile stars forming in low mass late forming proto-galaxies are spread through\nthe halo. A difference in observed binding energy distinguishes these two\npopulations. We look at possible chemical abundance signatures of the two\npopulations. We also show that galaxies forming in isolated low sigma peaks\nwill form from primordial material. Thus, even though the oldest stars are\ncentrally concentrated as they originated in the early collapsing, densest\nregions, primordial stars would be found distributed throughout the halo. Thus,\nthe lack of observed metal free stars can be taken as directly constraining the\nPopulation III IMF, and the lowest metallicity observed stars can be\ninterpreted as holding clues to the chemical yields of Pop III stars.\n\n", "human_text": "  The difference in density profiles of the contributions from different\ndensity peaks to dark matter halos results in certain expectations about the\nMilky Way's stellar halo. We cut our simulated halo stars into two populations:\nthose forming before/during the last major merger, and those accreted after the\nlast major merger. The former population are more centrally located at z=0,\nwhile stars forming in low mass late forming proto-galaxies are spread through\nthe halo. A difference in observed binding energy distinguishes these two\npopulations. We look at possible chemical abundance signatures of the two\npopulations. We also show that galaxies forming in isolated low sigma peaks\nwill form from primordial material. Thus, even though the oldest stars are\ncentrally concentrated as they originated in the early collapsing, densest\nregions, primordial stars would be found distributed throughout the halo. Thus,\nthe lack of observed metal free stars can be taken as directly constraining the\nPopulation III IMF, and the lowest metallicity observed stars can be\ninterpreted as holding clues to the chemical yields of Pop III stars.\n", "machine_text": "\nThis study investigates the chemical signatures and dynamical properties of the Milky Way's stellar halo. We analyze simulated halo stars divided into two different populations: those that formed before/during the last major merger, and those that came from accretion of substructures after that event. Comparing the binding energy of stars within the two groups shows that the former are mainly located closer to the center at z=0, whereas those originating in small scale merging structures are spread through the halo. We also explore what possible chemical abundance signatures these two populations may exhibit. Additionally, it is predicted that primordial stars are spread throughout the halo, while the oldest stars are still mainly situated in the early collapsing, densest regions. Our findings lend support to the notion that the lack of metal-free stars indicates a constraint on the Population III initial mass function, and that the lowest metallicity stars may hold clues to the chemical yields of Population III stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0347}
{"prompt": "Rephrase the abstract of an article with title 'Massive gravity and structure formation'.\n  We study the growth of cosmological perturbations in the model of\nLorentz-violating massive gravity. The Friedman equation in this model acquires\nan unconventional term due to the Lorentz-breaking condensates which has the\nequation of state w = -1 / (3 gamma) with gamma being a free parameter taking\nvalues outside of the range [0,1/3]. Apart from the standard contributions, the\nperturbations above the Friedmann background contain an extra piece which is\nproportional to an arbitrary function theta(x) of the space coordinates. This\nfunction appears as an integration constant and corresponds to a\nnon-propagating scalar mode which may, however, become dynamical with the\naccount of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1\nthe ``anomalous'' perturbations grow slower than the standard ones and thus the\nmodel is compatible with observations. Whether the model is experimentally\nacceptable at other values of \\gamma depends on the value of the function\ntheta(x) at the beginning of the radiation-dominated epoch.\n\n", "human_text": "  We study the growth of cosmological perturbations in the model of\nLorentz-violating massive gravity. The Friedman equation in this model acquires\nan unconventional term due to the Lorentz-breaking condensates which has the\nequation of state w = -1 / (3 gamma) with gamma being a free parameter taking\nvalues outside of the range [0,1/3]. Apart from the standard contributions, the\nperturbations above the Friedmann background contain an extra piece which is\nproportional to an arbitrary function theta(x) of the space coordinates. This\nfunction appears as an integration constant and corresponds to a\nnon-propagating scalar mode which may, however, become dynamical with the\naccount of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1\nthe ``anomalous'' perturbations grow slower than the standard ones and thus the\nmodel is compatible with observations. Whether the model is experimentally\nacceptable at other values of \\gamma depends on the value of the function\ntheta(x) at the beginning of the radiation-dominated epoch.\n", "machine_text": "We investigate structure formation in the context of massive gravity which violates Lorentz symmetry. The equations governing this system produce an unusual term with an equation of state w = -1 / (3 gamma) for the Friedman equation. Additionally, perturbations above the Friedmann background contain an extra contribution that is proportional to a non-propagating scalar mode. Depending on the value of gamma, this mode may or may not be dynamical. For gamma between -1 and 0, the extra terms produce perturbations that grow slower than expected, making the model compatible with observations. To fully elucidate whether this model is experimentally viable, the values of the scalar mode theta(x) must be evaluated at the beginning of the radiation-dominated epoch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1301}
{"prompt": "Rephrase the abstract of an article with title 'A possible explanation why the Theta+ is seen in some experiments and\n  not in others'.\n  To understand the whole set of positive and null data on the\nTheta+(1530)-production, we suggest the hypothesis that multiquark hadrons are\nmainly generated from many-quark states, which emerge either as short-term\nhadron fluctuations, or as hadron remnants in hard processes. This approach\nallows us to describe both non-observation of the Theta+ in current null\nexperiments and peculiar features of its production in positive experiments.\nFurther, we are able to propose new experiments that might be decisive for the\nproblem of the Theta+ existence. Distributions of the Theta+ in such\nexperiments can give important information both on higher Fock components of\nconventional hadrons and about structure and hadronization properties of hadron\nremnants produced in hard processes. We also explain that description of\nmultiquark hadrons may require a modified form of the constituent quark model,\nwith quark masses and couplings being intermediate between their values for the\nfamiliar constituent quarks and the current ones.\n\n", "human_text": "  To understand the whole set of positive and null data on the\nTheta+(1530)-production, we suggest the hypothesis that multiquark hadrons are\nmainly generated from many-quark states, which emerge either as short-term\nhadron fluctuations, or as hadron remnants in hard processes. This approach\nallows us to describe both non-observation of the Theta+ in current null\nexperiments and peculiar features of its production in positive experiments.\nFurther, we are able to propose new experiments that might be decisive for the\nproblem of the Theta+ existence. Distributions of the Theta+ in such\nexperiments can give important information both on higher Fock components of\nconventional hadrons and about structure and hadronization properties of hadron\nremnants produced in hard processes. We also explain that description of\nmultiquark hadrons may require a modified form of the constituent quark model,\nwith quark masses and couplings being intermediate between their values for the\nfamiliar constituent quarks and the current ones.\n", "machine_text": "\nThis article attempts to explain the mixed results on the Theta+(1530) detected in some experiments, while not seen in others. We suggest that multiquark hadrons are formed by many different quark states, and could be present in short-lived fluctuations or left over as remnants of hard processes. This notion can account for the inconsistencies between both outcomes. Moreover, new experiments which might be decisive in understanding the Theta+ can be proposed focusing on its distributions within them. Additionally, understanding multiquark hadrons might necessitate modifications of the traditional quark model with updated couplings and masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3045}
{"prompt": "Rephrase the abstract of an article with title 'A very massive runaway star from Cygnus OB2'.\n  Aims: We analyze the available information on the star BD+43 3654 to\ninvestigate the possibility that it may have had its origin in the massive OB\nassociation Cygnus OB2.\n  Methods: We present new spectroscopic observations allowing a reliable\nspectral classification of the star, and discuss existing MSX observations of\nits associated bow shock and astrometric information not previously studied.\n  Results: Our observations reveal that BD+43 3654 is a very early and luminous\nstar of spectral type O4If, with an estimated mass of (70 +/- 15) solar masses\nand an age of about 1.6 Myr. The high spatial resolution of the MSX\nobservations allows us to determine its direction of motion in the plane of the\nsky by means of the symmetry axis of the well-defined bow shock, which matches\nwell the orientation expected from the proper motion. Tracing back its path\nacross the sky we find that BD+43 3654 was located near the central, densest\nregion of Cygnus OB2 at a time in the past similar to its estimated age.\n  Conclusions: BD+43 3654 turns out to be one of the three most massive runaway\nstars known, and it most likely formed in the central region of Cygnus OB2. A\nrunaway formation mechanism by means of dynamical ejection is consistent with\nour results.\n\n", "human_text": "  Aims: We analyze the available information on the star BD+43 3654 to\ninvestigate the possibility that it may have had its origin in the massive OB\nassociation Cygnus OB2.\n  Methods: We present new spectroscopic observations allowing a reliable\nspectral classification of the star, and discuss existing MSX observations of\nits associated bow shock and astrometric information not previously studied.\n  Results: Our observations reveal that BD+43 3654 is a very early and luminous\nstar of spectral type O4If, with an estimated mass of (70 +/- 15) solar masses\nand an age of about 1.6 Myr. The high spatial resolution of the MSX\nobservations allows us to determine its direction of motion in the plane of the\nsky by means of the symmetry axis of the well-defined bow shock, which matches\nwell the orientation expected from the proper motion. Tracing back its path\nacross the sky we find that BD+43 3654 was located near the central, densest\nregion of Cygnus OB2 at a time in the past similar to its estimated age.\n  Conclusions: BD+43 3654 turns out to be one of the three most massive runaway\nstars known, and it most likely formed in the central region of Cygnus OB2. A\nrunaway formation mechanism by means of dynamical ejection is consistent with\nour results.\n", "machine_text": "\nThis paper presents new spectroscopic and existing MSX observations of the massive runaway star BD+43 3654. Our observations reveal that it is an O4If star with an estimated mass of 70 (+/- 15) solar masses and an age of about 1.6 million years. Its well-defined bow shock, seen in MSX observations, reveals an orientation in the plane of the sky that is concordant with its proper motion. Backtracking its path across the sky, its origins can be traced to the densest region of the Cygnus OB2 association at a time similar to its estimated age. BD+43 3654 is thus one of the three most massive runaway stars known and its formation could have been caused by dynamical ejection.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0676}
{"prompt": "Rephrase the abstract of an article with title 'Progenitors of Long Gamma-ray Bursts'.\n  Pinpointing the progenitors of long duration gamma-ray bursts (LGRBs) remains\nan extremely important question, although it is now clear that at least a\nfraction of LGRBs originate in the core collapse of massive stars in type Ic\nsupernovae, the pathways to the production of these stars, and their initial\nmasses, remain uncertain. Rotation is thought to be vital in the creation of\nLGRBs, and it is likely that black hole creation is also necessary. We suggest\nthat these two constraints can be met if the GRB progenitors are very massive\nstars (>20 solar masses) and are formed in tight binary systems. Using simple\nmodels we compare the predictions of this scenario with observations and find\nthat the location of GRBs on their host galaxies are suggestive of\nmain-sequence masses in excess of 20 solar masses, while 50% of the known\ncompact binary systems may have been sufficiently close to have had the\nnecessary rotation rates for GRB creation. Thus, massive stars in compact\nbinaries are a likely channel for at least some fraction of LGRBs.\n\n", "human_text": "  Pinpointing the progenitors of long duration gamma-ray bursts (LGRBs) remains\nan extremely important question, although it is now clear that at least a\nfraction of LGRBs originate in the core collapse of massive stars in type Ic\nsupernovae, the pathways to the production of these stars, and their initial\nmasses, remain uncertain. Rotation is thought to be vital in the creation of\nLGRBs, and it is likely that black hole creation is also necessary. We suggest\nthat these two constraints can be met if the GRB progenitors are very massive\nstars (>20 solar masses) and are formed in tight binary systems. Using simple\nmodels we compare the predictions of this scenario with observations and find\nthat the location of GRBs on their host galaxies are suggestive of\nmain-sequence masses in excess of 20 solar masses, while 50% of the known\ncompact binary systems may have been sufficiently close to have had the\nnecessary rotation rates for GRB creation. Thus, massive stars in compact\nbinaries are a likely channel for at least some fraction of LGRBs.\n", "machine_text": "\nThe elusive nature of the progenitors of long duration gamma-ray bursts (LGRBs) has been an intriguing mystery for some time. Much of the current thinking suggests that these blasts originate from the core collapse of massive stars in type Ic supernovae, but the details of their formation, initial masses and pathways remain unknown. Experts believe that, in order for LGRBs to be produced, rapid rotation and the formation of a black hole are both necessary. Therefore, this paper proposes that progenitors of this type of gamma-ray burst could be composed of very massive stars (>20 solar masses) within tight binary systems. Through the use of simple models, this hypothesis is compared to observations and it appears that the GRB locations on their host galaxies are indicative of main-sequence masses that surpass 20 solar masses, while up to 50% of binary systems were thought to have close enough proximity to have the appropriate velocity for GRB production. Consequently, massive stars in binary systems are believed to be a primary publisher of at least a portion of LGRBs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1899}
{"prompt": "Rephrase the abstract of an article with title 'Discovery of Two Spectroscopically Peculiar, Low-Luminosity Quasars at\n  z~4'.\n  We report the discovery of two low-luminosity quasars at z~4, both of which\nshow prominent N IV] 1486A emission. This line is extremely rare in quasar\nspectra at any redshift; detecting it in two out of a sample of 23 objects\n(i.e., ~ 9% of the sample) is intriguing and is likely due to the\nlow-luminosity, high-redshift quasar sample we are studying. This is still a\npoorly explored regime, where contributions from associated, early starbursts\nmay be significant. One interpretation of this line posits photoionization by\nvery massive young stars. Seeing N IV] 1486A emission in a high-redshift quasar\nmay thus be understood in the context of co-formation and early co-evolution of\ngalaxies and their supermassive black holes. Alternatively, we may be seeing a\nphenomenon related to the early evolution of quasar broad emission line\nregions. The non-detection (and possibly even broad absorption) of N V 1240A\nline in the spectrum of one of these quasars may support that interpretation.\nThese two objects may signal a new faint quasar population or an early AGN\nevolutionary stage at high redshifts.\n\n", "human_text": "  We report the discovery of two low-luminosity quasars at z~4, both of which\nshow prominent N IV] 1486A emission. This line is extremely rare in quasar\nspectra at any redshift; detecting it in two out of a sample of 23 objects\n(i.e., ~ 9% of the sample) is intriguing and is likely due to the\nlow-luminosity, high-redshift quasar sample we are studying. This is still a\npoorly explored regime, where contributions from associated, early starbursts\nmay be significant. One interpretation of this line posits photoionization by\nvery massive young stars. Seeing N IV] 1486A emission in a high-redshift quasar\nmay thus be understood in the context of co-formation and early co-evolution of\ngalaxies and their supermassive black holes. Alternatively, we may be seeing a\nphenomenon related to the early evolution of quasar broad emission line\nregions. The non-detection (and possibly even broad absorption) of N V 1240A\nline in the spectrum of one of these quasars may support that interpretation.\nThese two objects may signal a new faint quasar population or an early AGN\nevolutionary stage at high redshifts.\n", "machine_text": "\nWe present the discovery of two unusual, low-luminosity quasars at redshift z~4 which show a prominent N IV] 1486A emission line. Finding such a feature in two out of 23 objects in our sample (8.6%) is particularly remarkable as this line is ordinarily rarely seen in quasar spectra regardless of redshift. This uncommon observation may be indicative of starbursts in associated, early galaxies. Alternatively, we may be witnessing the early stages of quasar broad emission line region evolution. The finding of no N V 1240A line in one of these quasars may provide evidence for the latter. Together, these objects could point to either a new population of faint quasars or to an AGN evolutionary phase in its infancy at high redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3638}
{"prompt": "Rephrase the abstract of an article with title 'Vortex trapping in suddenly connected Bose-Josephson junctions'.\n  We investigate the problem of vortex trapping in cyclically coupled\nBose-Josephson junctions. Starting with $N$ independent BECs we couple the\ncondensates through Josephson links and allow the system to reach a stable\ncirculation by adding a dissipative term in our semiclassical equations of\nmotion. The central question we address is what is the probability to trap a\nvortex with winding number $m$. Our numerical simulations reveal that the final\ndistribution of winding numbers is narrower than the initial distribution of\ntotal phases, indicating an increased probability for no-vortex configurations.\nFurther, the nonlinearity of the problem manifests itself in the somewhat\ncounter-intuitive result that it is possible to obtain a non-zero circulation\nstarting with zero total phase around the loop. The final width of the\ndistribution of winding numbers for $N$ sites scales as $\\lambda N^{\\alpha}$,\nwhere $\\alpha=0.47\\pm 0.01$ and $\\lambda <0.67$ (value predicted for the\ninitial distribution) indicating a shrinking of the final distribution. The\nactual value of $\\lambda$ is found to depend on the strength of dissipation.\n\n", "human_text": "  We investigate the problem of vortex trapping in cyclically coupled\nBose-Josephson junctions. Starting with $N$ independent BECs we couple the\ncondensates through Josephson links and allow the system to reach a stable\ncirculation by adding a dissipative term in our semiclassical equations of\nmotion. The central question we address is what is the probability to trap a\nvortex with winding number $m$. Our numerical simulations reveal that the final\ndistribution of winding numbers is narrower than the initial distribution of\ntotal phases, indicating an increased probability for no-vortex configurations.\nFurther, the nonlinearity of the problem manifests itself in the somewhat\ncounter-intuitive result that it is possible to obtain a non-zero circulation\nstarting with zero total phase around the loop. The final width of the\ndistribution of winding numbers for $N$ sites scales as $\\lambda N^{\\alpha}$,\nwhere $\\alpha=0.47\\pm 0.01$ and $\\lambda <0.67$ (value predicted for the\ninitial distribution) indicating a shrinking of the final distribution. The\nactual value of $\\lambda$ is found to depend on the strength of dissipation.\n", "machine_text": "\nWe investigate the behaviour of trapping vortices in the junctions of Bose-Josephson\nsystems which have been suddenly connected. We study this by designing a semiclassical\nmodel consisting of independently evolved $N$ BECs which are coupled together in\nloops by Josephson junctions and a dissipative term. This model is then used to calculate\nthe probability of having a vortex of winding number $m$ present in the final state.\nOur simulations suggest that the final winding numbers are more restricted than the\ninitial total phases, making an absence of vortices more likely. Counter-intuitively,\nnon-zero circulation can occur even when the initial total phase is zero. Furthermore,\nthe width of the final distribution of winding numbers appears to scale as $\\lambda N^{\\alpha}$\nwith $\\alpha=0.47\\pm 0.01$ and $\\lambda <0.67$ (the predicted value of the initial\ndistribution), showing that the sizes of the distribution tend to shrink. It was observed\nthat the value of $\\lambda$ is dependent on the strength of the dissipation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2431}
{"prompt": "Rephrase the abstract of an article with title 'Chromohydrodynamical instabilities induced by relativistic jets'.\n  We study the properties of the chromohydrodynamical instabilities induced by\na relativistic jet that crosses the quark-gluon plasma. Assuming that the jet\nof particles and the plasma can be described using a hydrodynamical approach,\nwe derive and discuss the dispersion laws for the unstable collective modes. In\nour analysis the chromohydrodynamical equations for the collective modes are\ntackled in the linear response approximation. Such an approximation, valid for\nshort time scales, allows to study in a straightforward way the dependence of\nthe dispersion laws of the collective modes on the velocity of the jet, on the\nmagnitude of the momentum of the collective mode and on the angle between these\ntwo quantities. We find that unstable modes arise for velocity of the jet\nlarger than the speed of the sound of the plasma and only modes with momenta\nsmaller than a certain values are unstable. Moreover, for ultrarelativistic\nvelocities of the jet the longitudinal mode becomes stable and the most\nunstable modes correspond to relative angles between the velocity of the jet\nand momentum of the collective mode larger than $\\sim \\pi/8$. Our results\nsuggest an alternative mechanism for the description of the jet quenching\nphenomenon, where the jet crossing the plasma loses energy exciting colored\nunstable modes.\n\n", "human_text": "  We study the properties of the chromohydrodynamical instabilities induced by\na relativistic jet that crosses the quark-gluon plasma. Assuming that the jet\nof particles and the plasma can be described using a hydrodynamical approach,\nwe derive and discuss the dispersion laws for the unstable collective modes. In\nour analysis the chromohydrodynamical equations for the collective modes are\ntackled in the linear response approximation. Such an approximation, valid for\nshort time scales, allows to study in a straightforward way the dependence of\nthe dispersion laws of the collective modes on the velocity of the jet, on the\nmagnitude of the momentum of the collective mode and on the angle between these\ntwo quantities. We find that unstable modes arise for velocity of the jet\nlarger than the speed of the sound of the plasma and only modes with momenta\nsmaller than a certain values are unstable. Moreover, for ultrarelativistic\nvelocities of the jet the longitudinal mode becomes stable and the most\nunstable modes correspond to relative angles between the velocity of the jet\nand momentum of the collective mode larger than $\\sim \\pi/8$. Our results\nsuggest an alternative mechanism for the description of the jet quenching\nphenomenon, where the jet crossing the plasma loses energy exciting colored\nunstable modes.\n", "machine_text": "\nWe investigate the effects of a relativistic jet crossing quark-gluon plasma on the chromohydrodynamics instabilities. We examine this issue by looking into the hydrodynamic equations describing the jet and the plasma, in the linear response approximation. This is valid over short time scales, and allows us to investigate how the velocity of the jet, magnitude of the collective mode momentum, and the angle between them, changes the dispersion laws. We find that for jet velocities larger than the sound speed of the plasma, and for momenta smaller than a certain value, instabilities arise. Additionally, in the case of ultrarelativistic jet velocity, longitudinal modes become stable, and the most unstable modes have an angle between the jet velocity and its momentum greater than around $\\pi/8$. Our results hint at a novel method to explain jet quenching, in which the jet would lose energy exciting colored instabilities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1047}
{"prompt": "Rephrase the abstract of an article with title 'Physical Properties of Weak MgII Absorbers at z~2'.\n  We present the results of photoionization modeling of nine weak MgII (W_r<0.3\nAng) quasar absorption line systems with redshifts 1.4<z<2.4 obtained with the\nUltraviolet and Visual Echelle Spectrograph on the Very Large Telescope. These\nsystems have been chosen because they provide access to a regime of red-shift\nspace that previous weak MgII studies have not looked at. The densities,\nmetallicities, Doppler parameters, and column densities of these systems are\ncompared to those of other weak MgII systems at lower redshift. There is no\nsignificant statistical variation in the properties of the absorbers over the\nredshift range 0.4<z<2.4. The number density per unit redshift is known to\ndecrease for weak MgII absorbers between z~1 and z~2 by a greater amount than\npredicted from cosmological effects and changes in the extragalactic ionizing\nbackground alone. We suggest that, because the physical properties of the\nabsorber population are not seen to change significantly across this range,\nthat the evolution in dN/dz is due to a decrease in the activity that gives\nrise to weak MgII absorption, and not due to a change in the processes that\nform weak MgII absorbers. The presence of separate, but aligned (in velocity)\nlow and high density clouds in all single cloud weak MgII absorbers provides an\nimportant diagnostic of their geometry. We discuss possible origins in dwarf\ngalaxies and in extragalactic analogs to high velocity clouds.\n\n", "human_text": "  We present the results of photoionization modeling of nine weak MgII (W_r<0.3\nAng) quasar absorption line systems with redshifts 1.4<z<2.4 obtained with the\nUltraviolet and Visual Echelle Spectrograph on the Very Large Telescope. These\nsystems have been chosen because they provide access to a regime of red-shift\nspace that previous weak MgII studies have not looked at. The densities,\nmetallicities, Doppler parameters, and column densities of these systems are\ncompared to those of other weak MgII systems at lower redshift. There is no\nsignificant statistical variation in the properties of the absorbers over the\nredshift range 0.4<z<2.4. The number density per unit redshift is known to\ndecrease for weak MgII absorbers between z~1 and z~2 by a greater amount than\npredicted from cosmological effects and changes in the extragalactic ionizing\nbackground alone. We suggest that, because the physical properties of the\nabsorber population are not seen to change significantly across this range,\nthat the evolution in dN/dz is due to a decrease in the activity that gives\nrise to weak MgII absorption, and not due to a change in the processes that\nform weak MgII absorbers. The presence of separate, but aligned (in velocity)\nlow and high density clouds in all single cloud weak MgII absorbers provides an\nimportant diagnostic of their geometry. We discuss possible origins in dwarf\ngalaxies and in extragalactic analogs to high velocity clouds.\n", "machine_text": "\nBy studying nine weak MgII quasar absorption line systems at redshifts of 1.4-2.4 with the Ultraviolet and Visual Echelle Spectrograph on the Very Large Telescope, we investigate whether there are differences in the physical properties of weak MgII absorbers at varying redshifts. Our results show that the densities, metallicities, Doppler parameters, and column densities remain the same across redshifts 0.4-2.4. The number of weak MgII absorbers decreases from z~1 to z~2, however, because the physical properties do not change significantly, the decrease may be attributed to a decrease in activity rather than a change in formation process. We find evidence for multiple, velocity aligned clouds in single cloud weak MgII absorbers, which could be of extragalactic origin, such as dwarf galaxies or high velocity clouds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2036}
{"prompt": "Rephrase the abstract of an article with title 'Accurate QCD predictions for heavy-quark jets at the Tevatron and LHC'.\n  Heavy-quark jets are important in many of today's collider studies and\nsearches, yet predictions for them are subject to much larger uncertainties\nthan for light jets. This is because of strong enhancements in higher orders\nfrom large logarithms, ln(p_t/m_Q). We propose a new definition of heavy-quark\njets, which is free of final-state logarithms to all orders and such that all\ninitial-state collinear logarithms can be resummed into the heavy-quark parton\ndistributions. Heavy-jet spectra can then be calculated in the massless\napproximation, which is simpler than a massive calculation and reduces the\ntheoretical uncertainties by a factor of three. This provides the first ever\naccurate predictions for inclusive b- and c-jets, and the latter have\nsignificant discriminatory power for the intrinsic charm content of the proton.\nThe techniques introduced here could be used to obtain heavy-flavour jet\nresults from existing massless next-to-leading order calculations for a wide\nrange of processes. We also discuss the experimental applicability of our\nflavoured jet definition.\n\n", "human_text": "  Heavy-quark jets are important in many of today's collider studies and\nsearches, yet predictions for them are subject to much larger uncertainties\nthan for light jets. This is because of strong enhancements in higher orders\nfrom large logarithms, ln(p_t/m_Q). We propose a new definition of heavy-quark\njets, which is free of final-state logarithms to all orders and such that all\ninitial-state collinear logarithms can be resummed into the heavy-quark parton\ndistributions. Heavy-jet spectra can then be calculated in the massless\napproximation, which is simpler than a massive calculation and reduces the\ntheoretical uncertainties by a factor of three. This provides the first ever\naccurate predictions for inclusive b- and c-jets, and the latter have\nsignificant discriminatory power for the intrinsic charm content of the proton.\nThe techniques introduced here could be used to obtain heavy-flavour jet\nresults from existing massless next-to-leading order calculations for a wide\nrange of processes. We also discuss the experimental applicability of our\nflavoured jet definition.\n", "machine_text": "This article presents a new definition of heavy-quark jets which eliminates large logarithmic uncertainties in their predictions, as well as simplifying calculations. We have demonstrated that this gives better accuracy and uncertainty estimates for b- and c-jets. Methods arising from this work have applications in a range of processes and could have exciting implications for gauging the intrinsic charm content of the proton. Additionally, we have covered the practical uses of this flavoured jet definition in an experimental setting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2999}
{"prompt": "Rephrase the abstract of an article with title 'Les espaces de Berkovich sont excellents'.\n  In this paper, we first study the local rings of a Berkovich analytic space\nfrom the point of view of commutative algebra. We show that those rings are\nexcellent ; we introduce the notion of a an analytically separable extension of\nnon-archimedean complete fields (it includes the case of the finite separable\nextensions, and also the case of any complete extension of a perfect complete\nnon-archimedean field) and show that the usual commutative algebra properties\n(Rm, Sm, Gorenstein, Cohen-Macaulay, Complete Intersection) are stable under\nanalytically separable ground field extensions; we also establish a GAGA\nprinciple with respect to those properties for any finitely generated scheme\nover an affinoid algebra.\n  A second part of the paper deals with more global geometric notions : we\ndefine, show the existence and establish basic properties of the irreducible\ncomponents of analytic space ; we define, show the existence and establish\nbasic properties of its normalization ; and we study the behaviour of\nconnectedness and irreducibility with respect to base change.\n\n", "human_text": "  In this paper, we first study the local rings of a Berkovich analytic space\nfrom the point of view of commutative algebra. We show that those rings are\nexcellent ; we introduce the notion of a an analytically separable extension of\nnon-archimedean complete fields (it includes the case of the finite separable\nextensions, and also the case of any complete extension of a perfect complete\nnon-archimedean field) and show that the usual commutative algebra properties\n(Rm, Sm, Gorenstein, Cohen-Macaulay, Complete Intersection) are stable under\nanalytically separable ground field extensions; we also establish a GAGA\nprinciple with respect to those properties for any finitely generated scheme\nover an affinoid algebra.\n  A second part of the paper deals with more global geometric notions : we\ndefine, show the existence and establish basic properties of the irreducible\ncomponents of analytic space ; we define, show the existence and establish\nbasic properties of its normalization ; and we study the behaviour of\nconnectedness and irreducibility with respect to base change.\n", "machine_text": "This article examines Berkovich spaces with respect to commutative algebra and local rings. It is demonstrated that these rings are excellent and we introduce and investigate the concept of analytically separable extensions, which includes finite separable extensions as well as complete extensions of perfect fields. Properties such as Rm, Sm, Gorenstein, Cohen-Macaulay, and Complete Intersection are discussed, alongside a GAGA principle applied to finitely generated schemes over an affinoid algebra. Additionally, the global geometric notions of irreducible components of an analytic space and its normalization are explored, along with their connections to base change in terms of connectedness and irreducibility. In summary, the results obtained demonstrate that Berkovich spaces are indeed excellent.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0666}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of Newtonian fluid slip using a torsional ultrasonic\n  oscillator'.\n  The composite torsional ultrasonic oscillator, a versatile experimental\nsystem, can be used to investigate slip of Newtonian fluid at a smooth surface.\nA rigorous analysis of slip-dependent damping for the oscillator is presented.\nInitially, the phenomenon of finite surface slip and the slip length are\nconsidered for a half-space of Newtonian fluid in contact with a smooth,\noscillating solid surface. Definitions are revisited and clarified in light of\ninconsistencies in the literature. We point out that, in general oscillating\nflows, Navier's slip length b is a complex number. An intuitive velocity\ndiscontinuity parameter of unrestricted phase is used to describe the effect of\nslip on measurement of viscous shear damping. The analysis is applied to the\ncomposite oscillator and preliminary experimental work for a 40 kHz oscillator\nis presented. The Non-Slip Boundary Condition (NSBC) has been verified for a\nhydrophobic surface in water to within ~60 nm of |b|=0 nm. Experiments were\ncarried out at shear rate amplitudes between 230 and 6800 /s, corresponding to\nlinear displacement amplitudes between 3.2 and 96 nm.\n\n", "human_text": "  The composite torsional ultrasonic oscillator, a versatile experimental\nsystem, can be used to investigate slip of Newtonian fluid at a smooth surface.\nA rigorous analysis of slip-dependent damping for the oscillator is presented.\nInitially, the phenomenon of finite surface slip and the slip length are\nconsidered for a half-space of Newtonian fluid in contact with a smooth,\noscillating solid surface. Definitions are revisited and clarified in light of\ninconsistencies in the literature. We point out that, in general oscillating\nflows, Navier's slip length b is a complex number. An intuitive velocity\ndiscontinuity parameter of unrestricted phase is used to describe the effect of\nslip on measurement of viscous shear damping. The analysis is applied to the\ncomposite oscillator and preliminary experimental work for a 40 kHz oscillator\nis presented. The Non-Slip Boundary Condition (NSBC) has been verified for a\nhydrophobic surface in water to within ~60 nm of |b|=0 nm. Experiments were\ncarried out at shear rate amplitudes between 230 and 6800 /s, corresponding to\nlinear displacement amplitudes between 3.2 and 96 nm.\n", "machine_text": "\nUsing the efficient and convenient torsional ultrasonic oscillator, this article provides an in-depth assessment of Newtonian fluid slips across a smooth surface. An updated examination of the Navier's slip length is undertaken, revealing the complexity of this phenomenon across oscillating flows. The Non-Slip Boundary Condition (NSBC) is explored through experiments with a 40 kHz oscillator and a hydrophobic surface in water, with results demonstrating slips within 60 nm of |b|=0 nm. Shear rate amplitudes between 230 and 6800 /s, revealing linear displacement amplitudes between 3.2 and 96 nm, further give insight into Newtonian fluid slip.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3498}
{"prompt": "Rephrase the abstract of an article with title 'Scalability and Optimisation of a Committee of Agents Using Genetic\n  Algorithm'.\n  A population of committees of agents that learn by using neural networks is\nimplemented to simulate the stock market. Each committee of agents, which is\nregarded as a player in a game, is optimised by continually adapting the\narchitecture of the agents using genetic algorithms. The committees of agents\nbuy and sell stocks by following this procedure: (1) obtain the current price\nof stocks; (2) predict the future price of stocks; (3) and for a given price\ntrade until all the players are mutually satisfied. The trading of stocks is\nconducted by following these rules: (1) if a player expects an increase in\nprice then it tries to buy the stock; (2) else if it expects a drop in the\nprice, it sells the stock; (3)and the order in which a player participates in\nthe game is random. The proposed procedure is implemented to simulate trading\nof three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear\nrelationship between the number of players and agents versus the computational\ntime to run the complete simulation is observed. It is also found that no\nplayer has a monopolistic advantage.\n\n", "human_text": "  A population of committees of agents that learn by using neural networks is\nimplemented to simulate the stock market. Each committee of agents, which is\nregarded as a player in a game, is optimised by continually adapting the\narchitecture of the agents using genetic algorithms. The committees of agents\nbuy and sell stocks by following this procedure: (1) obtain the current price\nof stocks; (2) predict the future price of stocks; (3) and for a given price\ntrade until all the players are mutually satisfied. The trading of stocks is\nconducted by following these rules: (1) if a player expects an increase in\nprice then it tries to buy the stock; (2) else if it expects a drop in the\nprice, it sells the stock; (3)and the order in which a player participates in\nthe game is random. The proposed procedure is implemented to simulate trading\nof three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear\nrelationship between the number of players and agents versus the computational\ntime to run the complete simulation is observed. It is also found that no\nplayer has a monopolistic advantage.\n", "machine_text": "This study presents an algorithm for scalability and optimisation of a committee of agents through the use of a genetic algorithm. Neural networks are used to teach the population of agents to simulate the stock market. This study focuses on testing the trading of certain stocks and its agents as they try to purchase or sell stocks following three principles: obtaining the current stock price, predicting the future stock price and trading until both parties are mutually satisfied. In a research experiment, it was found that the number of players and agents had a linear relationship with the time needed to run the simulation and that none of the players had an unfair advantage.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1757}
{"prompt": "Rephrase the abstract of an article with title 'The LuckyCam Survey for Very Low Mass Binaries II: 13 new M4.5-M6.0\n  Binaries'.\n  We present results from a high-angular-resolution survey of 78 very low mass\n(VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15\narcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new\nbinary systems range in separation between 0.18 arcsec and 1.3 arcsec. The\ndistance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with\nprevious results. 9 of the new binary systems have orbital radii > 10 AU,\nincluding a new wide VLM binary with 27 AU projected orbital separation. One of\nthe new systems forms two components of a 2300 AU separation triple system. We\nfind that the orbital radius distribution of the binaries with V-K < 6.5 in\nthis survey appears to be different from that of redder (lower-mass) objects,\nsuggesting a possible rapid change in the orbital radius distribution at around\nthe M5 spectral type. The target sample was also selected to investigate X-ray\nactivity among VLM binaries. There is no detectable correlation between excess\nX-Ray emission and the frequency and binary properties of the VLM systems.\n\n", "human_text": "  We present results from a high-angular-resolution survey of 78 very low mass\n(VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15\narcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new\nbinary systems range in separation between 0.18 arcsec and 1.3 arcsec. The\ndistance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with\nprevious results. 9 of the new binary systems have orbital radii > 10 AU,\nincluding a new wide VLM binary with 27 AU projected orbital separation. One of\nthe new systems forms two components of a 2300 AU separation triple system. We\nfind that the orbital radius distribution of the binaries with V-K < 6.5 in\nthis survey appears to be different from that of redder (lower-mass) objects,\nsuggesting a possible rapid change in the orbital radius distribution at around\nthe M5 spectral type. The target sample was also selected to investigate X-ray\nactivity among VLM binaries. There is no detectable correlation between excess\nX-Ray emission and the frequency and binary properties of the VLM systems.\n", "machine_text": "\nThis survey of 78 VLM binary systems has uncovered 21 binary systems, 13 of which are new discoveries. The new binaries have separations ranging from 0.18 arcsec to 1.3 arcsec after correcting for distance. The resulting binary fraction is 13.5%, which is in agreement with prior work. Notably, 9 of these newly discovered binaries have orbital radii > 10 AU, including one system that has a projected 27 AU separation. Furthermore, the orbital radius distribution of binaries with V-K < 6.5 appears to differ from that of lower-mass systems, suggesting a dramatic change at the M5 spectral type. Finally, there was no correlation found between X-ray emission and the frequency and parameters of the VLM systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1812}
{"prompt": "Rephrase the abstract of an article with title 'The Dynamics-Based Approach to Studying Terrestrial Exoplanets'.\n  One of the great quests of astronomy is to obtain the spectrum of a\nterrestrial planet orbiting within the habitable zone of its star, and the\ndominant challenge in doing so is to isolate the light of the planet from that\nof the star. Dynamics-based methods separate these signals temporally, whereas\nimaging techniques do so spatially. In light of the overwhelming dominance of\ndynamics-based methods over the past decade, we challenge the notion that\nspectra of terrestrial planets necessarily require extreme imaging methods. We\nadvocate that some resources be committed to refining the proven technologies\nof radial-velocity measurements, transit photometry, and occultation\nspectroscopy (i.e. emergent infrared spectra obtained at secondary eclipse). We\nsee a particularly attractive opportunity in M-dwarfs, for which the habitable\nzone is close to the star, increasing the probability and frequency of\ntransits, and the amplitude of the induced radial-velocity variation. Such\nplanets could be discovered by a dedicated ground-based transit survey of the\n10,000 nearest M-dwarfs. The favorable planet-star contrast ratio would make\nthese planets ideal targets for the study of their atmospheres with the\ntechnique of occultation spectroscopy.\n\n", "human_text": "  One of the great quests of astronomy is to obtain the spectrum of a\nterrestrial planet orbiting within the habitable zone of its star, and the\ndominant challenge in doing so is to isolate the light of the planet from that\nof the star. Dynamics-based methods separate these signals temporally, whereas\nimaging techniques do so spatially. In light of the overwhelming dominance of\ndynamics-based methods over the past decade, we challenge the notion that\nspectra of terrestrial planets necessarily require extreme imaging methods. We\nadvocate that some resources be committed to refining the proven technologies\nof radial-velocity measurements, transit photometry, and occultation\nspectroscopy (i.e. emergent infrared spectra obtained at secondary eclipse). We\nsee a particularly attractive opportunity in M-dwarfs, for which the habitable\nzone is close to the star, increasing the probability and frequency of\ntransits, and the amplitude of the induced radial-velocity variation. Such\nplanets could be discovered by a dedicated ground-based transit survey of the\n10,000 nearest M-dwarfs. The favorable planet-star contrast ratio would make\nthese planets ideal targets for the study of their atmospheres with the\ntechnique of occultation spectroscopy.\n", "machine_text": "\nExoplanets are of particular fascination to astronomers due to the possibility of them being habitable. To obtain the spectrum of a terrestrial planet orbiting in the habitable zone of its star is a great feat, however the challenge of isolating the light of the planet from that of its star still persists. In the last decade, dynamics-based methods, as opposed to imaging techniques, have facilitated this endeavor significantly. We propose that more focused efforts be given to technologies such as radial-velocity measurements, transit photometry, and occultation spectroscopy in order to obtain spectra of exoplanets. M-dwarfs, which have a habitable zone close to their star, have seen a rise in transits and radial-velocity variations, making them prime candidates for studying the atmospheres of terrestrial planets with occultation spectroscopy. A dedicated ground-based transit survey of the 10,000 nearest M-dwarfs, with their favorable planet-star contrast ratio, could consequently fulfill this quest.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1047}
{"prompt": "Rephrase the abstract of an article with title 'Coronal ion-cyclotron beam instabilities within the multi-fluid\n  description'.\n  Spectroscopic observations and theoretical models suggest resonant\nwave-particle interactions, involving high-frequency ion-cyclotron waves, as\nthe principal mechanism for heating and accelerating ions in the open coronal\nholes. However, the mechanism responsible for the generation of the\nion-cyclotron waves remains unclear. One possible scenario is that ion beams\noriginating from small-scale reconnection events can drive micro-instabilities\nthat constitute a possible source for the excitation of ion-cyclotron waves. In\norder to study ion beam-driven electromagnetic instabilities, the multi-fluid\nmodel in the low-beta coronal plasma is used. While neglecting the electron\ninertia this model allows one to take into account ion-cyclotron wave effects\nthat are absent from the one-fluid MHD model. Realistic models of density and\ntemperature as well as a 2-D analytical magnetic field model are used to define\nthe background plasma in the open-field funnel region of a polar coronal hole.\nConsidering the WKB approximation, a Fourier plane-wave linear mode analysis is\nemployed in order to derive the dispersion relation. Ray-tracing theory is used\nto compute the ray path of the unstable wave as well as the evolution of the\ngrowth rate of the wave while propagating in the coronal funnel. We demonstrate\nthat, in typical coronal holes conditions and assuming realistic values of the\nbeam velocity, the free energy provided by the ion beam propagating parallel\nthe ambient field can drive micro-instabilities through resonant ion-cyclotron\nexcitation.\n\n", "human_text": "  Spectroscopic observations and theoretical models suggest resonant\nwave-particle interactions, involving high-frequency ion-cyclotron waves, as\nthe principal mechanism for heating and accelerating ions in the open coronal\nholes. However, the mechanism responsible for the generation of the\nion-cyclotron waves remains unclear. One possible scenario is that ion beams\noriginating from small-scale reconnection events can drive micro-instabilities\nthat constitute a possible source for the excitation of ion-cyclotron waves. In\norder to study ion beam-driven electromagnetic instabilities, the multi-fluid\nmodel in the low-beta coronal plasma is used. While neglecting the electron\ninertia this model allows one to take into account ion-cyclotron wave effects\nthat are absent from the one-fluid MHD model. Realistic models of density and\ntemperature as well as a 2-D analytical magnetic field model are used to define\nthe background plasma in the open-field funnel region of a polar coronal hole.\nConsidering the WKB approximation, a Fourier plane-wave linear mode analysis is\nemployed in order to derive the dispersion relation. Ray-tracing theory is used\nto compute the ray path of the unstable wave as well as the evolution of the\ngrowth rate of the wave while propagating in the coronal funnel. We demonstrate\nthat, in typical coronal holes conditions and assuming realistic values of the\nbeam velocity, the free energy provided by the ion beam propagating parallel\nthe ambient field can drive micro-instabilities through resonant ion-cyclotron\nexcitation.\n", "machine_text": "\nThis article investigates the effect of ion-cyclotron micro-instabilities, caused by the resonance between ion-cyclotron waves and high-energy ion beams originating from small-scale reconnection events, on the open-field region of a polar coronal hole. Using the multi-fluid model, the WKB Fourier plane-wave linear mode analysis, and ray-tracing theory, this study is able to demonstrate that the free energy of the propagating ion beams is a potential source of ion-cyclotron waves in coronal holes under typical conditions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0752}
{"prompt": "Rephrase the abstract of an article with title 'Some Comments around The Examples against The Generalized Jacobian\n  Conjecture'.\n  We have studied a faded problem, the Jacobian Conjecture ~:\n  \\noindent\n  {\\sf The Jacobian Conjecture $(JC_n)$}~:\n  If $f_1, \\cdots, f_n$ are elements in a polynomial ring $k[X_1, \\cdots, X_n]$\nover a field $k$ of characteristic $0$ such that the Jacobian $\\det(\\partial\nf_i/ \\partial X_j) $ is a nonzero constant, then $k[f_1, \\cdots, f_n] = k[X_1,\n\\cdots, X_n]$.\n  For this purpose, we generalize it to the following form~:\n  \\noindent\n  {\\sf The Generalized Jacobian Conjecture $(GJC)$}~:\n  {\\it Let $\\varphi : S \\rightarrow T$ be an unramified homomorphism of\nNoetherian domains with $T^\\times = \\varphi(S^\\times)$. Assume that $T$ is a\nfactorial domain and that $S$ is a simply connected normal domain. Then\n$\\varphi$ is an isomorphism. }\n  For the consistency of our discussion, we raise some serious (or idiot)\nquestions and some comments concerning the examples appeared in the papers\npublished by the certain excellent mathematicians (though we are unwilling to\ndeal with them). Since the existence of such examples would be against our\noriginal target Conjecture$(GJC)$, we have to dispute their arguments about the\nexistence of their respective (so called) counter-examples. Our conclusion is\nthat they are not perfect counter-examples as are shown explicitly.\n\n", "human_text": "  We have studied a faded problem, the Jacobian Conjecture ~:\n  \\noindent\n  {\\sf The Jacobian Conjecture $(JC_n)$}~:\n  If $f_1, \\cdots, f_n$ are elements in a polynomial ring $k[X_1, \\cdots, X_n]$\nover a field $k$ of characteristic $0$ such that the Jacobian $\\det(\\partial\nf_i/ \\partial X_j) $ is a nonzero constant, then $k[f_1, \\cdots, f_n] = k[X_1,\n\\cdots, X_n]$.\n  For this purpose, we generalize it to the following form~:\n  \\noindent\n  {\\sf The Generalized Jacobian Conjecture $(GJC)$}~:\n  {\\it Let $\\varphi : S \\rightarrow T$ be an unramified homomorphism of\nNoetherian domains with $T^\\times = \\varphi(S^\\times)$. Assume that $T$ is a\nfactorial domain and that $S$ is a simply connected normal domain. Then\n$\\varphi$ is an isomorphism. }\n  For the consistency of our discussion, we raise some serious (or idiot)\nquestions and some comments concerning the examples appeared in the papers\npublished by the certain excellent mathematicians (though we are unwilling to\ndeal with them). Since the existence of such examples would be against our\noriginal target Conjecture$(GJC)$, we have to dispute their arguments about the\nexistence of their respective (so called) counter-examples. Our conclusion is\nthat they are not perfect counter-examples as are shown explicitly.\n", "machine_text": "\nWe have studied the Jacobian Conjecture, which states that if $f_1, \\cdots, f_n$ are elements in a polynomial ring $k[X_1, \\cdots, X_n]$\nover a field $k$ of characteristic $0$ such that the Jacobian $\\det(\\partial\nf_i/ \\partial X_j) $ is a nonzero constant, then $k[f_1, \\cdots, f_n] = k[X_1,\n\\cdots, X_n]$. In addition, to further investigate it, we generalized the ground problem to\nthe Generalized Jacobian Conjecture. This conjecture states that any unramified homomorphism of Noetherian domains, where the domain $T$ is\nfactorial and $S$ is simply connected and normal, is an isomorphism. In light of this, we brought up some questions and comments regarding the presented counter-examples. After examining them closely, we have come to the conclusion that these examples are not valid counter-examples to the Generalized Jacobian Conjecture.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1138}
{"prompt": "Rephrase the abstract of an article with title 'QCD in One Dimension at Nonzero Chemical Potential'.\n  Using an integration formula recently derived by Conrey, Farmer and\nZirnbauer, we calculate the expectation value of the phase factor of the\nfermion determinant for the staggered lattice QCD action in one dimension. We\nshow that the chemical potential can be absorbed into the quark masses; the\ntheory is in the same chiral symmetry class as QCD in three dimensions at zero\nchemical potential. In the limit of a large number of colors and fixed number\nof lattice points, chiral symmetry is broken spontaneously, and our results are\nin agreement with expressions based on a chiral Lagrangian. In this limit, the\neigenvalues of the Dirac operator are correlated according to random matrix\ntheory for QCD in three dimensions. The discontinuity of the chiral condensate\nis due to an alternative to the Banks-Casher formula recently discovered for\nQCD in four dimensions at nonzero chemical potential. The effect of temperature\non the average phase factor is discussed in a schematic random matrix model.\n\n", "human_text": "  Using an integration formula recently derived by Conrey, Farmer and\nZirnbauer, we calculate the expectation value of the phase factor of the\nfermion determinant for the staggered lattice QCD action in one dimension. We\nshow that the chemical potential can be absorbed into the quark masses; the\ntheory is in the same chiral symmetry class as QCD in three dimensions at zero\nchemical potential. In the limit of a large number of colors and fixed number\nof lattice points, chiral symmetry is broken spontaneously, and our results are\nin agreement with expressions based on a chiral Lagrangian. In this limit, the\neigenvalues of the Dirac operator are correlated according to random matrix\ntheory for QCD in three dimensions. The discontinuity of the chiral condensate\nis due to an alternative to the Banks-Casher formula recently discovered for\nQCD in four dimensions at nonzero chemical potential. The effect of temperature\non the average phase factor is discussed in a schematic random matrix model.\n", "machine_text": "\nWe utilize a recently established integration formula by Conrey, Farmer and Zirnbauer to estimate the expectation value of the phase factor of the staggered lattice QCD action in one dimension when a chemical potential is present. We determine that it is possible to incorporate the chemical potential into the quark masses in the same manner as for the QCD in three dimensions when the chemical potential is zero. At higher numbers of colors and a constant number of lattice points, chiral symmetry is spontaneously broken and the results are found to coincide with the effects related to a chiral Lagrangian. The eigenvalues of the Dirac operator are found to obey the random matrix theory for the QCD in three dimensions too. The discontinuity in the chiral condensate is a consequence of an alternative to the Banks-Casher formula which was recently found to pertain to QCD in four dimensions and a nonzero chemical potential. The influence of temperature on the average phase factor is explored in a schematic random matrix model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1111}
{"prompt": "Rephrase the abstract of an article with title 'Analysis of random Boolean networks using the average sensitivity'.\n  In this work we consider random Boolean networks that provide a general model\nfor genetic regulatory networks. We extend the analysis of James Lynch who was\nable to proof Kauffman's conjecture that in the ordered phase of random\nnetworks, the number of ineffective and freezing gates is large, where as in\nthe disordered phase their number is small. Lynch proved the conjecture only\nfor networks with connectivity two and non-uniform probabilities for the\nBoolean functions. We show how to apply the proof to networks with arbitrary\nconnectivity $K$ and to random networks with biased Boolean functions. It turns\nout that in these cases Lynch's parameter $\\lambda$ is equivalent to the\nexpectation of average sensitivity of the Boolean functions used to construct\nthe network. Hence we can apply a known theorem for the expectation of the\naverage sensitivity. In order to prove the results for networks with biased\nfunctions, we deduct the expectation of the average sensitivity when only\nfunctions with specific connectivity and specific bias are chosen at random.\n\n", "human_text": "  In this work we consider random Boolean networks that provide a general model\nfor genetic regulatory networks. We extend the analysis of James Lynch who was\nable to proof Kauffman's conjecture that in the ordered phase of random\nnetworks, the number of ineffective and freezing gates is large, where as in\nthe disordered phase their number is small. Lynch proved the conjecture only\nfor networks with connectivity two and non-uniform probabilities for the\nBoolean functions. We show how to apply the proof to networks with arbitrary\nconnectivity $K$ and to random networks with biased Boolean functions. It turns\nout that in these cases Lynch's parameter $\\lambda$ is equivalent to the\nexpectation of average sensitivity of the Boolean functions used to construct\nthe network. Hence we can apply a known theorem for the expectation of the\naverage sensitivity. In order to prove the results for networks with biased\nfunctions, we deduct the expectation of the average sensitivity when only\nfunctions with specific connectivity and specific bias are chosen at random.\n", "machine_text": "This article examines the use of average sensitivity to analyze random Boolean networks. This extends upon prior work by James Lynch to prove Kauffman's conjecture; that in random networks, few ineffective and freezing gates exist in the ordered phase, and many in the disordered phase. Setting $\\lambda$ as the expectation of average sensitivity, we use Lynch's proof to analyze networks with arbitrary connectivity and biased Boolean functions. We further deduce the expectation of average sensitivity when a specific connectivity and bias of functions are randomly chosen.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0197}
{"prompt": "Rephrase the abstract of an article with title 'Geometry of Time, Axiom of Choice and Neuro-Biological Quantum Zeno\n  Effect'.\n  Role of axiom of choice in quantum measurement is highlighted by suggesting\nthat the conscious observer chooses the outcome from a mixed state. Further, in\na periodically repeating universe, these outcomes must be pre-recorded within\nthe non-physical conscious observers, which precludes free will. Free will\nhowever exists in a universe with open time, It is suggested that psychology's\nbinding problem is connected with Cantor's original definition of set.\nInfluence of consciousness on material outcome through quantum processes is\ndiscussed and interesting constraints derived. For example, it is predicted\nthat quantum mechanical brain states should get frozen if monitored at\nsufficiently small space-time intervals - a neuro-biological version of the so\ncalled quantum zeno effect, which has been verified in domain of micro-physics.\nExistence of a very small micro-mini-black-hole in brain is predicted as a\nspace-time structural interface between consciousness and brain, whose\nvaporization explains mass-loss reported in weighing experiments, conducting\nduring the moments of death.\n\n", "human_text": "  Role of axiom of choice in quantum measurement is highlighted by suggesting\nthat the conscious observer chooses the outcome from a mixed state. Further, in\na periodically repeating universe, these outcomes must be pre-recorded within\nthe non-physical conscious observers, which precludes free will. Free will\nhowever exists in a universe with open time, It is suggested that psychology's\nbinding problem is connected with Cantor's original definition of set.\nInfluence of consciousness on material outcome through quantum processes is\ndiscussed and interesting constraints derived. For example, it is predicted\nthat quantum mechanical brain states should get frozen if monitored at\nsufficiently small space-time intervals - a neuro-biological version of the so\ncalled quantum zeno effect, which has been verified in domain of micro-physics.\nExistence of a very small micro-mini-black-hole in brain is predicted as a\nspace-time structural interface between consciousness and brain, whose\nvaporization explains mass-loss reported in weighing experiments, conducting\nduring the moments of death.\n", "machine_text": "This article discusses the role of the axiom of choice in quantum measurement, proposing that conscious observers select the outcome from a mixed state. Furthermore, the implications for a periodically repeating universe and notions of free will are proposed. In addition, a connection is proposed between Cantor's original definition of a set and the psychology binding problem. The article also examines the effect of consciousness on material outcomes through quantum processes, deriving interesting constraints, including the potential for a neuro-biological version of the quantum zeno effect. Lastly, the article suggests a hypothesis wherein a micro-mini black hole in the brain acts as a space-time interface between consciousness and the brain and is the source of mass-loss in the moment of death.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1054}
{"prompt": "Rephrase the abstract of an article with title 'Aromatic emission from the ionised mane of the Horsehead nebula'.\n  We study the evolution of the Aromatic Infrared Bands (AIBs) emitters across\nthe illuminated edge of the Horsehead nebula and especially their survival and\nproperties in the HII region. We present spectral mapping observations taken\nwith the Infrared Spectrograph (IRS) at wavelengths 5.2-38 microns. A strong\nAIB at 11.3 microns is detected in the HII region, relative to the other AIBs\nat 6.2, 7.7 and 8.6 microns. The intensity of this band appears to be\ncorrelated with the intensity of the [NeII] at 12.8 microns and of Halpha,\nwhich shows that the emitters of the 11.3 microns band are located in the\nionised gas. The survival of PAHs in the HII region could be due to the\nmoderate intensity of the radiation field (G0 about 100) and the lack of\nphotons with energy above about 25eV. The enhancement of the intensity of the\n11.3 microns band in the HII region, relative to the other AIBs can be\nexplained by the presence of neutral PAHs. Our observations highlight a\ntransition region between ionised and neutral PAHs observed with ideal\nconditions in our Galaxy. A scenario where PAHs can survive in HII regions and\nbe significantly neutral could explain the detection of a prominent 11.3\nmicrons band in other Spitzer observations.\n\n", "human_text": "  We study the evolution of the Aromatic Infrared Bands (AIBs) emitters across\nthe illuminated edge of the Horsehead nebula and especially their survival and\nproperties in the HII region. We present spectral mapping observations taken\nwith the Infrared Spectrograph (IRS) at wavelengths 5.2-38 microns. A strong\nAIB at 11.3 microns is detected in the HII region, relative to the other AIBs\nat 6.2, 7.7 and 8.6 microns. The intensity of this band appears to be\ncorrelated with the intensity of the [NeII] at 12.8 microns and of Halpha,\nwhich shows that the emitters of the 11.3 microns band are located in the\nionised gas. The survival of PAHs in the HII region could be due to the\nmoderate intensity of the radiation field (G0 about 100) and the lack of\nphotons with energy above about 25eV. The enhancement of the intensity of the\n11.3 microns band in the HII region, relative to the other AIBs can be\nexplained by the presence of neutral PAHs. Our observations highlight a\ntransition region between ionised and neutral PAHs observed with ideal\nconditions in our Galaxy. A scenario where PAHs can survive in HII regions and\nbe significantly neutral could explain the detection of a prominent 11.3\nmicrons band in other Spitzer observations.\n", "machine_text": "\nWe explore the emission of Aromatic Infrared Bands (AIBs) across the illuminated edge of the Horsehead nebula, especially their existence and characteristics in the HII region. Our study includes spectral mapping conducted with the Infrared Spectrograph at wavelengths of 5.2 - 38 microns. An intense AIB of 11.3 microns is detected in the HII region compared to the other AIBs at 6.2, 7.7, and 8.6 microns. The intensity of this particular band appears to correlate with the intensity of [NeII] at 12.8 microns and Halpha, which implies the emitter of the 11.3 micron band is located within the ionised gas. This finding could be accounted for by the average-intensity radiation field (G0 about 100) and little photons of energy over 25eV. We reason the intensification of the 11.3 micron band in the HII region relative to the other AIBs could stem from the availability of neutral PAHs. Our observations highlight a transitory area between ionised and neutral PAHs witnessed in our Galaxy under proper conditions. A scenario in which PAHs can survive in HII regions and substantially remain neutral could explain the noticeable 11.3 micron band noticed in many other Spitzer observations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.151}
{"prompt": "Rephrase the abstract of an article with title 'Principal Component Analysis and Automatic Relevance Determination in\n  Damage Identification'.\n  This paper compares two neural network input selection schemes, the Principal\nComponent Analysis (PCA) and the Automatic Relevance Determination (ARD) based\non Mac-Kay's evidence framework. The PCA takes all the input data and projects\nit onto a lower dimension space, thereby reduc-ing the dimension of the input\nspace. This input reduction method often results with parameters that have\nsignificant influence on the dynamics of the data being diluted by those that\ndo not influence the dynamics of the data. The ARD selects the most relevant\ninput parameters and discards those that do not contribute significantly to the\ndynamics of the data being modelled. The ARD sometimes results with important\ninput parameters being discarded thereby compromising the dynamics of the data.\nThe PCA and ARD methods are implemented together with a Multi-Layer-Perceptron\n(MLP) network for fault identification in structures and the performance of the\ntwo methods is as-sessed. It is observed that ARD and PCA give similar\naccu-racy levels when used as input-selection schemes. There-fore, the choice\nof input-selection scheme is dependent on the nature of the data being\nprocessed.\n\n", "human_text": "  This paper compares two neural network input selection schemes, the Principal\nComponent Analysis (PCA) and the Automatic Relevance Determination (ARD) based\non Mac-Kay's evidence framework. The PCA takes all the input data and projects\nit onto a lower dimension space, thereby reduc-ing the dimension of the input\nspace. This input reduction method often results with parameters that have\nsignificant influence on the dynamics of the data being diluted by those that\ndo not influence the dynamics of the data. The ARD selects the most relevant\ninput parameters and discards those that do not contribute significantly to the\ndynamics of the data being modelled. The ARD sometimes results with important\ninput parameters being discarded thereby compromising the dynamics of the data.\nThe PCA and ARD methods are implemented together with a Multi-Layer-Perceptron\n(MLP) network for fault identification in structures and the performance of the\ntwo methods is as-sessed. It is observed that ARD and PCA give similar\naccu-racy levels when used as input-selection schemes. There-fore, the choice\nof input-selection scheme is dependent on the nature of the data being\nprocessed.\n", "machine_text": "\nThis research examines the performance of Principal Component Analysis (PCA) and Automatic Relevance Determination (ARD) when utilized in combination with a Multi-Layer-Perceptron (MLP) network for determining damage in a structure. PCA offers reduction of input data dimension by projecting it to a lower dimension space, which could lead to important influencing parameters being diluted by those that don't effect the data's dynamics. Conversely, ARD selects the most relevant input parameters while limiting the effect of parameters that don't notably influence the dynamics. It was observed the ARD and PCA provided similar accuracy levels, meaning the choice of which scheme to use is dependent on the data's nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1672}
{"prompt": "Rephrase the abstract of an article with title 'Ray-tracing and physical-optics analysis of the aperture efficiency in a\n  radio telescope'.\n  The performance of telescope systems working at microwave or visible/IR\nwavelengths is typically described in terms of different parameters according\nto the wavelength range. Most commercial ray tracing packages have been\nspecifically designed for use with visible/IR systems and thus, though very\nflexible and sophisticated, do not provide the appropriate parameters to fully\ndescribe microwave antennas, and thus to compare with specifications. In this\nwork we demonstrate that the Strehl ratio is equal to the phase efficiency when\nthe apodization factor is taken into account. The phase efficiency is the most\ncritical contribution to the aperture efficiency of an antenna, and the most\ndifficult parameter to optimize during the telescope design. The equivalence\nbetween the Strehl ratio and the phase efficiency gives the designer/user of\nthe telescope the opportunity to use the faster commercial ray-tracing software\nto optimize the design. We also discuss the results of several tests performed\nto check the validity of this relationship that we carried out using a\nray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3,\napplied to three different telescope designs that span a factor of $\\simeq 10\nin terms of D/lambda. The maximum measured discrepancy between phase efficiency\nand Strehl ratio varies between $\\simeq 0.4 and 1.9 up to an offset angle of\n>40 beams, depending on the optical configuration, but it is always less than\n0.5 where the Strehl ratio is >0.95.\n\n", "human_text": "  The performance of telescope systems working at microwave or visible/IR\nwavelengths is typically described in terms of different parameters according\nto the wavelength range. Most commercial ray tracing packages have been\nspecifically designed for use with visible/IR systems and thus, though very\nflexible and sophisticated, do not provide the appropriate parameters to fully\ndescribe microwave antennas, and thus to compare with specifications. In this\nwork we demonstrate that the Strehl ratio is equal to the phase efficiency when\nthe apodization factor is taken into account. The phase efficiency is the most\ncritical contribution to the aperture efficiency of an antenna, and the most\ndifficult parameter to optimize during the telescope design. The equivalence\nbetween the Strehl ratio and the phase efficiency gives the designer/user of\nthe telescope the opportunity to use the faster commercial ray-tracing software\nto optimize the design. We also discuss the results of several tests performed\nto check the validity of this relationship that we carried out using a\nray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3,\napplied to three different telescope designs that span a factor of $\\simeq 10\nin terms of D/lambda. The maximum measured discrepancy between phase efficiency\nand Strehl ratio varies between $\\simeq 0.4 and 1.9 up to an offset angle of\n>40 beams, depending on the optical configuration, but it is always less than\n0.5 where the Strehl ratio is >0.95.\n", "machine_text": "\nThis paper investigates the relationship between aperture efficiency, obtained from the Strehl ratio and the phase efficiency in different radio telescope designs. The idea being that a commercial ray-tracing software can be used to optimize the design. To test this proposition, different tunnel designs spanning a factor of $\\simeq 10 in terms of D/lambda were simulated with ZEMAX and GRASP9.3. Results indicate that there is a difference between phase efficiency and Strehl ratio of approximately 0.4 to 1.9 up to an offset angle of 40 beams, depending on the design specifics. Notwithstanding this, discrepancies between Strehl ratio and phase efficiency were always less than 0.5 when Strehl ratio was greater than 0.95.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3379}
{"prompt": "Rephrase the abstract of an article with title 'A unified projection formalism for the Al-Pd-Mn quasicrystal\n  Xi-approximants and their metadislocations'.\n  The approximants xi, xi' and xi'_n of the quasicrystal Al-Mn-Pd display most\ninteresting plastic properties as for example phason-induced deformation\nprocesses (Klein, H., Audier, M., Boudard, M., de Boissieu, M., Beraha, L., and\nDuneau, M., 1996, Phil. Mag. A, 73, 309.) or metadislocations (Klein, H.,\nFeuerbacher, M., Schall, P., and Urban, K., 1999, Phys. Rev. Lett., 82, 3468.).\nHere we demonstrate that the phases and their deformed or defected states can\nbe described by a simple projection formalism in three-dimensional space - not\nas usual in four to six dimensions. With the method we can interpret\nmicrostructures observed with electron microscopy as phasonic phase boundaries.\nFurthermore we determine the metadislocations of lowest energy and relate them\nuniquely to experimentally observed ones. Since moving metadislocations in the\nxi'-phase can create new phason-planes, we suggest a dislocation induced phase\ntransition from xi' to xi'_n. The methods developed in this paper can as well\nbe used for various other complex metallic alloys.\n\n", "human_text": "  The approximants xi, xi' and xi'_n of the quasicrystal Al-Mn-Pd display most\ninteresting plastic properties as for example phason-induced deformation\nprocesses (Klein, H., Audier, M., Boudard, M., de Boissieu, M., Beraha, L., and\nDuneau, M., 1996, Phil. Mag. A, 73, 309.) or metadislocations (Klein, H.,\nFeuerbacher, M., Schall, P., and Urban, K., 1999, Phys. Rev. Lett., 82, 3468.).\nHere we demonstrate that the phases and their deformed or defected states can\nbe described by a simple projection formalism in three-dimensional space - not\nas usual in four to six dimensions. With the method we can interpret\nmicrostructures observed with electron microscopy as phasonic phase boundaries.\nFurthermore we determine the metadislocations of lowest energy and relate them\nuniquely to experimentally observed ones. Since moving metadislocations in the\nxi'-phase can create new phason-planes, we suggest a dislocation induced phase\ntransition from xi' to xi'_n. The methods developed in this paper can as well\nbe used for various other complex metallic alloys.\n", "machine_text": "This study examines the plastic properties of Al-Mn-Pd approximants xi, xi' and xi'_n of the quasicrystal. It is demonstrated that these phases, as well as their deformed or defected states, can be understood using a projection formalism in three-dimensional space, unlike previously used four to six-dimensional methods. This formalism is then used to explain microstructures observed in electron microscopy, and to determine the most energetically favorable metadislocations in relation to experimentally observed ones. In addition, the notion of a dislocation-induced phase transition from xi' to xi'n is proposed. Lastly, the methods employed in this article can be applied to study other complex metallic alloys.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1428}
{"prompt": "Rephrase the abstract of an article with title 'Annotations to a certain passage of Descartes for finding the quadrature\n  of the circle'.\n  Translation from the Latin of \"Annotationes in locum quendam Cartesii ad\ncirculi quadraturam spectantem\" (1763).\n  The passage Euler is referring to is the \"Excerpta\" in part 6, p. 6 of\nDescartes' 1701 \"Opuscula posthuma\".\n  Before reading this paper I had not heard of the \"quadratrix\" before, and I\nrecommend learning a bit about it before reading this. I found Thomas Heath, \"A\nhistory of Greek mathematics\", vol. I, chapter VII to be helpful, in particular\npp. 226-230. The quadratrix is a \"mechanical curve\" that can be used to rectify\nthe circle. The usual problem of squaring the circle is to construct a square\nwith the same area (or perimeter) as a given circle, in a finite number of\nsteps using compass and straightedge. Descartes worked in the reverse\ndirection: from a given square he constructed the radius of a circle with the\nsame perimeter, but in an infinite number of steps.\n  In this paper Euler reconstructs Descartes' argument and develops some\nconsequences of it. Euler finds that \\[ \\sum_{n=0}^\\infty \\frac{1}{2^n} \\tan\n\\frac{1}{2^n}\\phi = \\frac{1}{\\phi} - 2\\cot 2\\phi. \\] Integrating this yields \\[\n\\prod_{n=1}^\\infty \\sec \\frac{1}{2^n} \\phi = \\frac{2\\phi}{\\sin 2\\phi}. \\]\n  I'd like to thank Davide Crippa from the University of Paris 7 for some\nhelpful back and forth about this paper.\n  One of the only citations to this paper that I have found is in Pietro\nFerroni, De calculo integralium exercitatio mathematica, Allegrini, Florence,\n1792, pp. xxi--xxiii. The full text of it is available on Google Books.\n\n", "human_text": "  Translation from the Latin of \"Annotationes in locum quendam Cartesii ad\ncirculi quadraturam spectantem\" (1763).\n  The passage Euler is referring to is the \"Excerpta\" in part 6, p. 6 of\nDescartes' 1701 \"Opuscula posthuma\".\n  Before reading this paper I had not heard of the \"quadratrix\" before, and I\nrecommend learning a bit about it before reading this. I found Thomas Heath, \"A\nhistory of Greek mathematics\", vol. I, chapter VII to be helpful, in particular\npp. 226-230. The quadratrix is a \"mechanical curve\" that can be used to rectify\nthe circle. The usual problem of squaring the circle is to construct a square\nwith the same area (or perimeter) as a given circle, in a finite number of\nsteps using compass and straightedge. Descartes worked in the reverse\ndirection: from a given square he constructed the radius of a circle with the\nsame perimeter, but in an infinite number of steps.\n  In this paper Euler reconstructs Descartes' argument and develops some\nconsequences of it. Euler finds that \\[ \\sum_{n=0}^\\infty \\frac{1}{2^n} \\tan\n\\frac{1}{2^n}\\phi = \\frac{1}{\\phi} - 2\\cot 2\\phi. \\] Integrating this yields \\[\n\\prod_{n=1}^\\infty \\sec \\frac{1}{2^n} \\phi = \\frac{2\\phi}{\\sin 2\\phi}. \\]\n  I'd like to thank Davide Crippa from the University of Paris 7 for some\nhelpful back and forth about this paper.\n  One of the only citations to this paper that I have found is in Pietro\nFerroni, De calculo integralium exercitatio mathematica, Allegrini, Florence,\n1792, pp. xxi--xxiii. The full text of it is available on Google Books.\n", "machine_text": "This paper examines the Latin \u201cAnnotationes in locum quendam Cartesii ad circuli quadraturam spectantem\u201d by Leonhard Euler, originally published in 1763. It reviews a passage from Descartes\u2019 \u201cOpuscula posthuma\u201d, in which he utilizes the \u201cquadratrix\u201d, a \u201cmechanical curve\u201d, to rectify the circle. He reverses the traditional problem of squaring the circle \u2013 instead of constructing a square with the same area or perimeter of a given circle in a finite number of steps, he is attempting to construct the radius of a circle with the same perimeter using an infinite number of steps. Euler reconstructs Descartes' argument, ultimately deducing two equations, one of which when integrated, yields a formula derived from said argument. The bibliographic reference of this paper is Pietro Ferroni\u2019s \u201cDe calculo integralium exercitatio mathematica\u201d, published in 1792.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3423}
{"prompt": "Rephrase the abstract of an article with title 'A Covariant Holographic Entanglement Entropy Proposal'.\n  With an aim towards understanding the time-dependence of entanglement entropy\nin generic quantum field theories, we propose a covariant generalization of the\nholographic entanglement entropy proposal of hep-th/0603001. Apart from\nproviding several examples of possible covariant generalizations, we study a\nparticular construction based on light-sheets, motivated in similar spirit to\nthe covariant entropy bound underlying the holographic principle. In\nparticular, we argue that the entanglement entropy associated with a specified\nregion on the boundary in the context of the AdS/CFT correspondence is given by\nthe area of a co-dimension two bulk surface with vanishing expansions of null\ngeodesics. We demonstrate our construction with several examples to illustrate\nits reduction to the holographic entanglement entropy proposal in static\nspacetimes. We further show how this proposal may be used to understand the\ntime evolution of entanglement entropy in a time varying QFT state dual to a\ncollapsing black hole background. Finally, we use our proposal to argue that\nthe Euclidean wormhole geometries with multiple boundaries should be regarded\nas states in a non-interacting but entangled set of QFTs, one associated to\neach boundary.\n\n", "human_text": "  With an aim towards understanding the time-dependence of entanglement entropy\nin generic quantum field theories, we propose a covariant generalization of the\nholographic entanglement entropy proposal of hep-th/0603001. Apart from\nproviding several examples of possible covariant generalizations, we study a\nparticular construction based on light-sheets, motivated in similar spirit to\nthe covariant entropy bound underlying the holographic principle. In\nparticular, we argue that the entanglement entropy associated with a specified\nregion on the boundary in the context of the AdS/CFT correspondence is given by\nthe area of a co-dimension two bulk surface with vanishing expansions of null\ngeodesics. We demonstrate our construction with several examples to illustrate\nits reduction to the holographic entanglement entropy proposal in static\nspacetimes. We further show how this proposal may be used to understand the\ntime evolution of entanglement entropy in a time varying QFT state dual to a\ncollapsing black hole background. Finally, we use our proposal to argue that\nthe Euclidean wormhole geometries with multiple boundaries should be regarded\nas states in a non-interacting but entangled set of QFTs, one associated to\neach boundary.\n", "machine_text": "\nThis work provides a framework for analyzing the time-dependent entanglement entropy in generic quantum field theories. In line with the underlying covariant entropy bound behind the holographic principle, our proposal contains several covariant generalizations meant to evaluate the entanglement entropy associated with a certain boundary region. Specifically, we provide a construction which involves the area of a co-dimension two bulk surface with vanishing expansions of null geodesics, in accordance with the AdS/CFT correspondence. Through examples, we illustrate how this covarientized version of the holographic entanglement entropy proposal works in static spacetimes, as well as in a collapsing black hole background. Additionally, we comment on the idea of considering Euclidean wormhole geometries with multiple boundaries as states induced by a set of non-interacting but entangled QFTs, each corresponding to one of the boundaries.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0016}
{"prompt": "Rephrase the abstract of an article with title 'The scalar wave equation in a non-commutative spherically symmetric\n  space-time'.\n  Recent work in the literature has studied a version of non-commutative\nSchwarzschild black holes where the effects of non-commutativity are described\nby a mass function depending on both the radial variable r and a\nnon-commutativity parameter theta. The present paper studies the asymptotic\nbehaviour of solutions of the zero-rest-mass scalar wave equation in such a\nmodified Schwarzschild space-time in a neighbourhood of spatial infinity. The\nanalysis is eventually reduced to finding solutions of an inhomogeneous\nEuler--Poisson--Darboux equation, where the parameter theta affects explicitly\nthe functional form of the source term. Interestingly, for finite values of\ntheta, there is full qualitative agreement with general relativity: the\nconformal singularity at spacelike infinity reduces in a considerable way the\ndifferentiability class of scalar fields at future null infinity. In the\nphysical space-time, this means that the scalar field has an asymptotic\nbehaviour with a fall-off going on rather more slowly than in flat space-time.\n\n", "human_text": "  Recent work in the literature has studied a version of non-commutative\nSchwarzschild black holes where the effects of non-commutativity are described\nby a mass function depending on both the radial variable r and a\nnon-commutativity parameter theta. The present paper studies the asymptotic\nbehaviour of solutions of the zero-rest-mass scalar wave equation in such a\nmodified Schwarzschild space-time in a neighbourhood of spatial infinity. The\nanalysis is eventually reduced to finding solutions of an inhomogeneous\nEuler--Poisson--Darboux equation, where the parameter theta affects explicitly\nthe functional form of the source term. Interestingly, for finite values of\ntheta, there is full qualitative agreement with general relativity: the\nconformal singularity at spacelike infinity reduces in a considerable way the\ndifferentiability class of scalar fields at future null infinity. In the\nphysical space-time, this means that the scalar field has an asymptotic\nbehaviour with a fall-off going on rather more slowly than in flat space-time.\n", "machine_text": "This article investigates the relationship between the scalar wave equation and a modified Schwarzschild space-time in a non-commutative geometry. Solutions to the equation are analyzed near spatial infinity, and the investigation concludes that if theta is finite, then the field's asymptotic behavior is reduced in class due to the conformal singularity at spacelike infinity, resulting in a slower fall-off than what is seen in flat space-time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0242}
{"prompt": "Rephrase the abstract of an article with title '2-Frame flow dynamics and hyperbolic rank rigidity in nonpositive\n  curvature'.\n  This paper presents hyperbolic rank rigidity results for rank 1,\nnonpositively curved spaces. Let $M$ be a compact, rank 1 manifold with\nnonpositive sectional curvature and suppose that along every geodesic in $M$\nthere is a parallel vector field making curvature $-a^2$ with the geodesic\ndirection. We prove that $M$ has constant curvature equal to $-a^2$ if $M$ is\nodd dimensional, or if $M$ is even dimensional and has sectional curvature\npinched as follows: $-\\Lambda^2 < K < -\\lambda^2$ where $\\lambda/\\Lambda >\n>.93$. When $-a^2$ is the upper curvature bound this gives a shorter proof of\nthe hyperbolic rank rigidity theorem of Hamenst\\\"{a}dt, subject to the pinching\ncondition in even dimension; in all other cases it is a new result. We also\npresent a rigidity result using only an assumption on maximal Lyapunov\nexponents in direct analogy with work done by Connell. The proof of the main\ntheorem is simplified considerably by assuming strict negative curvature; in\nfact, in all dimensions but 7 and 8 it is then an immediate consequence of\nergodicity of the $(dim(M)-1)$-frame flow. In these exceptional dimensions,\nrecourse to the dynamics of the 2-frame flow must be made and the scheme of\nproof developed there can be generalized to deal with rank 1, nonpositively\ncurved spaces.\n\n", "human_text": "  This paper presents hyperbolic rank rigidity results for rank 1,\nnonpositively curved spaces. Let $M$ be a compact, rank 1 manifold with\nnonpositive sectional curvature and suppose that along every geodesic in $M$\nthere is a parallel vector field making curvature $-a^2$ with the geodesic\ndirection. We prove that $M$ has constant curvature equal to $-a^2$ if $M$ is\nodd dimensional, or if $M$ is even dimensional and has sectional curvature\npinched as follows: $-\\Lambda^2 < K < -\\lambda^2$ where $\\lambda/\\Lambda >\n>.93$. When $-a^2$ is the upper curvature bound this gives a shorter proof of\nthe hyperbolic rank rigidity theorem of Hamenst\\\"{a}dt, subject to the pinching\ncondition in even dimension; in all other cases it is a new result. We also\npresent a rigidity result using only an assumption on maximal Lyapunov\nexponents in direct analogy with work done by Connell. The proof of the main\ntheorem is simplified considerably by assuming strict negative curvature; in\nfact, in all dimensions but 7 and 8 it is then an immediate consequence of\nergodicity of the $(dim(M)-1)$-frame flow. In these exceptional dimensions,\nrecourse to the dynamics of the 2-frame flow must be made and the scheme of\nproof developed there can be generalized to deal with rank 1, nonpositively\ncurved spaces.\n", "machine_text": "\nThis paper investigates rank 1, nonpositively curved spaces by exploring hyperbolic rank rigidity results. We assume that along each geodesic in the compact, rank 1 manifold $M$ with nonpositive sectional curvature there is a parallel vector field that causes curvature to equal $-a^2$ in the direction of the geodesic. The results of this paper indicate that if $M$ is of odd dimension, or if it is even and the sectional curvature is pinched to be between -$\\Lambda^2$ and -$\\lambda^2$ (where $\\lambda / \\Lambda > 0.93$), the curvature of $M$ will be constant and equal to $-a^2$. This research confirms the result of Hyperbolic Rank Rigidity Theorem by Hamenst\\\"{a}dt when bounded from above by $-a^2$, and also provides a new result in other scenarios. We provide a rigidity result with only an assumption on maximal Lyapunov exponents similar to a previous work by Connell. The proof of the major theorem is simplified by assuming negative curvature, and outside of dimensions 7 and 8 the proof relies solely on ergodicity of the $(dim(M)-1)$-frame flow. For these 2 exceptional dimensions the 2-frame flow is used instead to develop a scheme for generalizing the result.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1853}
{"prompt": "Rephrase the abstract of an article with title 'Role of Dynamical Research in the Detection and Characterization of\n  Exoplanets'.\n  (Abridged) The discovery of extrasolar planetary systems revealed an\nunexpected diversity of planetary systems that has revolutionized planet\nformation theory. A strong program of theoretical research is essential to\nmaximize both the discovery potential and the scientific returns of future\nobservational programs, so as to achieve a deeper understanding of the\nformation and evolution of planetary systems. We outline three broad categories\nof theoretical research: detailed studies of specific planetary systems,\ntesting planet formation models by comparing their predictions to the observed\nexoplanet population, and detailed modeling of specific physical processes. We\ndescribe how such theoretical research plays an important role in analyzing\nobservations for a wide range detection methods and contributes to\nunderstanding the Earth's place in the universe and the potential for\nEarth-like life beyond our solar system. In this white paper, we suggest how to\nmaximize the scientific return of future exoplanet observations. Our\nrecommendations include a strong theory program, support for multiple\nobservational programs that will study a diverse set of planets and stars,\nsignificant observing time devoted to follow-up observations, and healthy\ncollaboration between observers and theorists.\n\n", "human_text": "  (Abridged) The discovery of extrasolar planetary systems revealed an\nunexpected diversity of planetary systems that has revolutionized planet\nformation theory. A strong program of theoretical research is essential to\nmaximize both the discovery potential and the scientific returns of future\nobservational programs, so as to achieve a deeper understanding of the\nformation and evolution of planetary systems. We outline three broad categories\nof theoretical research: detailed studies of specific planetary systems,\ntesting planet formation models by comparing their predictions to the observed\nexoplanet population, and detailed modeling of specific physical processes. We\ndescribe how such theoretical research plays an important role in analyzing\nobservations for a wide range detection methods and contributes to\nunderstanding the Earth's place in the universe and the potential for\nEarth-like life beyond our solar system. In this white paper, we suggest how to\nmaximize the scientific return of future exoplanet observations. Our\nrecommendations include a strong theory program, support for multiple\nobservational programs that will study a diverse set of planets and stars,\nsignificant observing time devoted to follow-up observations, and healthy\ncollaboration between observers and theorists.\n", "machine_text": "This paper examines the role of dynamical research in detection and characterization of exoplanets. The discovery of planetary systems outside our Solar System has ushered a new era of planet formation theory. To maximize discovery potential and the scientific returns of observational programs, dynamical research should be incorporated. The three main categories of theoretical research discussed here are studies of individual planetary systems, testing of planet formation models, and modeling of physical processes. The paper also discusses the advantages of incorporating dynamical research in locating life-bearing exoplanets, and how this can be achieved through support for multiple observational programs, follow-up observations, and collaboration between observers and theorists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2781}
{"prompt": "Rephrase the abstract of an article with title 'Optimal Occulter Design for Finding Extrasolar Planets'.\n  One proposed method for finding terrestrial planets around nearby stars is to\nuse two spacecraft--a telescope and a specially shaped occulter that is\nspecifically designed to prevent all but a tiny fraction of the starlight from\ndiffracting into the telescope. As the cost and observing cadence for such a\nmission will be driven largely by the separation between the two spacecraft, it\nis critically important to design an occulter that can meet the observing goals\nwhile flying as close to the telescope as possible. In this paper, we explore\nthis tradeoff between separation and occulter diameter. More specifically, we\npresent a method for designing the shape of the outer edge of an occulter that\nis as small as possible and gives a shadow that is deep enough and large enough\nfor a 4m telescope to survey the habitable zones of many stars for Earth-like\nplanets. In particular, we show that in order for a 4m telescope to detect in\nbroadband visible light a planet 0.06 arcseconds from a star shining $10^{10}$\ntimes brighter than the planet requires a specially-shaped occulter 50m in\ndiameter positioned about $72,000$ km in front of the telescope.\n\n", "human_text": "  One proposed method for finding terrestrial planets around nearby stars is to\nuse two spacecraft--a telescope and a specially shaped occulter that is\nspecifically designed to prevent all but a tiny fraction of the starlight from\ndiffracting into the telescope. As the cost and observing cadence for such a\nmission will be driven largely by the separation between the two spacecraft, it\nis critically important to design an occulter that can meet the observing goals\nwhile flying as close to the telescope as possible. In this paper, we explore\nthis tradeoff between separation and occulter diameter. More specifically, we\npresent a method for designing the shape of the outer edge of an occulter that\nis as small as possible and gives a shadow that is deep enough and large enough\nfor a 4m telescope to survey the habitable zones of many stars for Earth-like\nplanets. In particular, we show that in order for a 4m telescope to detect in\nbroadband visible light a planet 0.06 arcseconds from a star shining $10^{10}$\ntimes brighter than the planet requires a specially-shaped occulter 50m in\ndiameter positioned about $72,000$ km in front of the telescope.\n", "machine_text": "\nThis paper focuses on an optimized design of an occulter that would enable a 4m telescope to search the habitable zones of numerous stars for Earth-like exoplanets. A key factor in the cost and success of this kind of mission will be the separation between the telescope and the occulter, meaning it is essential to devise an occulter that is small enough to be positioned close to the telescope yet deep and broad enough to effectively block starlight. We show that in order to detect a planet 0.06 arcseconds away from a star of 10 billion times brighter, the occulter requires a shape tailored for this size, 50 meters in diameter, and would have to fly around 72,000 km from the telescope.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3488}
{"prompt": "Rephrase the abstract of an article with title 'Metal Cooling in Simulations of Cosmic Structure Formation'.\n  The addition of metals to any gas can significantly alter its evolution by\nincreasing the rate of radiative cooling. In star-forming environments,\nenhanced cooling can potentially lead to fragmentation and the formation of\nlow-mass stars, where metal-free gas-clouds have been shown not to fragment.\nAdding metal cooling to numerical simulations has traditionally required a\nchoice between speed and accuracy. We introduce a method that uses the\nsophisticated chemical network of the photoionization software, Cloudy, to\ninclude radiative cooling from a complete set of metals up to atomic number 30\n(Zn) that can be used with large-scale three-dimensional hydrodynamic\nsimulations. Our method is valid over an extremely large temperature range (10\nK < T < 10^8 K), up to hydrogen number densities of 10^12 cm^-3. At this\ndensity, a sphere of 1 Msun has a radius of roughly 40 AU. We implement our\nmethod in the adaptive mesh refinement (AMR) hydrodynamic/N-body code, Enzo.\nUsing cooling rates generated with this method, we study the physical\nconditions that led to the transition from Population III to Population II star\nformation. While C, O, Fe, and Si have been previously shown to make the\nstrongest contribution to the cooling in low-metallicity gas, we find that up\nto 40% of the metal cooling comes from fine-structure emission by S, when solar\nabundance patterns are present. At metallicities, Z > 10^-4 Zsun, regions of\ndensity and temperature exist where gas is both thermally unstable and has a\ncooling time less than its dynamical time. We identify these doubly unstable\nregions as the most inducive to fragmentation. At high redshifts, the CMB\ninhibits efficient cooling at low temperatures and, thus, reduces the size of\nthe doubly unstable regions, making fragmentation more difficult.\n\n", "human_text": "  The addition of metals to any gas can significantly alter its evolution by\nincreasing the rate of radiative cooling. In star-forming environments,\nenhanced cooling can potentially lead to fragmentation and the formation of\nlow-mass stars, where metal-free gas-clouds have been shown not to fragment.\nAdding metal cooling to numerical simulations has traditionally required a\nchoice between speed and accuracy. We introduce a method that uses the\nsophisticated chemical network of the photoionization software, Cloudy, to\ninclude radiative cooling from a complete set of metals up to atomic number 30\n(Zn) that can be used with large-scale three-dimensional hydrodynamic\nsimulations. Our method is valid over an extremely large temperature range (10\nK < T < 10^8 K), up to hydrogen number densities of 10^12 cm^-3. At this\ndensity, a sphere of 1 Msun has a radius of roughly 40 AU. We implement our\nmethod in the adaptive mesh refinement (AMR) hydrodynamic/N-body code, Enzo.\nUsing cooling rates generated with this method, we study the physical\nconditions that led to the transition from Population III to Population II star\nformation. While C, O, Fe, and Si have been previously shown to make the\nstrongest contribution to the cooling in low-metallicity gas, we find that up\nto 40% of the metal cooling comes from fine-structure emission by S, when solar\nabundance patterns are present. At metallicities, Z > 10^-4 Zsun, regions of\ndensity and temperature exist where gas is both thermally unstable and has a\ncooling time less than its dynamical time. We identify these doubly unstable\nregions as the most inducive to fragmentation. At high redshifts, the CMB\ninhibits efficient cooling at low temperatures and, thus, reduces the size of\nthe doubly unstable regions, making fragmentation more difficult.\n", "machine_text": "This paper presents a method to incorporate metal cooling into numerical simulations of cosmic structure formation. Leveraging the sophisticated chemical network of the photoionization software Cloudy, cooling rates are generated across a temperature range of 10 K to 10^8 K and up to a hydrogen number density of 10^12 cm^-3. When implementing these rates in the adaptive mesh refinement (AMR) hydrodynamic/N-body code Enzo, the authors investigate physical conditions that led to the transition from Population III to Population II star formation. Results show that including metals up to a certain atomic number (Zn) increases the rate of radiative cooling and can potentially lead to fragmentation and the formation of low-mass stars from regions of certain density and temperature. In addition, up to 40% of the cooling can come from fine-structure emission by S when solar abundance patterns are present. The CMB inhibits efficient cooling at high redshifts, making fragmentation more difficult in doubly unstable regions than at lower redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0754}
{"prompt": "Rephrase the abstract of an article with title 'Parametrized Post-Newtonian Expansion of Chern-Simons Gravity'.\n  We investigate the weak-field, post-Newtonian expansion to the solution of\nthe field equations in Chern-Simons gravity with a perfect fluid source. In\nparticular, we study the mapping of this solution to the parameterized\npost-Newtonian formalism to 1 PN order in the metric. We find that the PPN\nparameters of Chern-Simons gravity are identical to those of general\nrelativity, with the exception of the inclusion of a new term that is\nproportional to the Chern-Simons coupling parameter and the curl of the PPN\nvector potentials. We also find that the new term is naturally enhanced by the\nnon-linearity of spacetime and we provide a physical interpretation for it. By\nmapping this correction to the gravito-electro-magnetic framework, we study the\ncorrections that this new term introduces to the acceleration of point\nparticles and the frame-dragging effect in gyroscopic precession. We find that\nthe Chern-Simons correction to these classical predictions could be used by\ncurrent and future experiments to place bounds on intrinsic parameters of\nChern-Simons gravity and, thus, string theory.\n\n", "human_text": "  We investigate the weak-field, post-Newtonian expansion to the solution of\nthe field equations in Chern-Simons gravity with a perfect fluid source. In\nparticular, we study the mapping of this solution to the parameterized\npost-Newtonian formalism to 1 PN order in the metric. We find that the PPN\nparameters of Chern-Simons gravity are identical to those of general\nrelativity, with the exception of the inclusion of a new term that is\nproportional to the Chern-Simons coupling parameter and the curl of the PPN\nvector potentials. We also find that the new term is naturally enhanced by the\nnon-linearity of spacetime and we provide a physical interpretation for it. By\nmapping this correction to the gravito-electro-magnetic framework, we study the\ncorrections that this new term introduces to the acceleration of point\nparticles and the frame-dragging effect in gyroscopic precession. We find that\nthe Chern-Simons correction to these classical predictions could be used by\ncurrent and future experiments to place bounds on intrinsic parameters of\nChern-Simons gravity and, thus, string theory.\n", "machine_text": "\nWe examine the weak field, post-Newtonian expansion of Chern-Simons gravity, allowing interactions with a perfect fluid source. In particular, we analyze the mapping of this solution to the Parameterized Post-Newtonian (PPN) formalism to 1 PN order on the metric. Our results demonstrate that the PPN parameters of Chern-Simons gravity are identical to those of general relativity, with the exception of a new term introduced by the Chern-Simons coupling parameter and the curl of the PPN vector potentials. This new term is further enhanced by the nonlinearity of spacetime. Connecting this correction to the gravito-electromagnetic framework, we explore how it modifies the acceleration of point particles and the frame dragging effect in gyroscopic precession. Our findings suggest that modern and future experiments have the capability to detect these corrections and, as a result, place constraints on intrinsic Chern-Simons parameters and string theory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0299}
{"prompt": "Rephrase the abstract of an article with title 'Exploring the Variable Sky with the Sloan Digital Sky Survey'.\n  We quantify the variability of faint unresolved optical sources using a\ncatalog based on multiple SDSS imaging observations. The catalog covers SDSS\nStripe 82, and contains 58 million photometric observations in the SDSS ugriz\nsystem for 1.4 million unresolved sources. In each photometric bandpass we\ncompute various low-order lightcurve statistics and use them to select and\nstudy variable sources. We find that 2% of unresolved optical sources brighter\nthan g=20.5 appear variable at the 0.05 mag level (rms) simultaneously in the g\nand r bands. The majority (2/3) of these variable sources are low-redshift (<2)\nquasars, although they represent only 2% of all sources in the adopted\nflux-limited sample. We find that at least 90% of quasars are variable at the\n0.03 mag level (rms) and confirm that variability is as good a method for\nfinding low-redshift quasars as is the UV excess color selection (at high\nGalactic latitudes). We analyze the distribution of lightcurve skewness for\nquasars and find that is centered on zero. We find that about 1/4 of the\nvariable stars are RR Lyrae stars, and that only 0.5% of stars from the main\nstellar locus are variable at the 0.05 mag level. The distribution of\nlightcurve skewness in the g-r vs. u-g color-color diagram on the main stellar\nlocus is found to be bimodal (with one mode consistent with Algol-like\nbehavior). Using over six hundred RR Lyrae stars, we demonstrate rich halo\nsubstructure out to distances of 100 kpc. We extrapolate these results to\nexpected performance by the Large Synoptic Survey Telescope and estimate that\nit will obtain well-sampled 2% accurate, multi-color lightcurves for ~2 million\nlow-redshift quasars, and will discover at least 50 million variable stars.\n\n", "human_text": "  We quantify the variability of faint unresolved optical sources using a\ncatalog based on multiple SDSS imaging observations. The catalog covers SDSS\nStripe 82, and contains 58 million photometric observations in the SDSS ugriz\nsystem for 1.4 million unresolved sources. In each photometric bandpass we\ncompute various low-order lightcurve statistics and use them to select and\nstudy variable sources. We find that 2% of unresolved optical sources brighter\nthan g=20.5 appear variable at the 0.05 mag level (rms) simultaneously in the g\nand r bands. The majority (2/3) of these variable sources are low-redshift (<2)\nquasars, although they represent only 2% of all sources in the adopted\nflux-limited sample. We find that at least 90% of quasars are variable at the\n0.03 mag level (rms) and confirm that variability is as good a method for\nfinding low-redshift quasars as is the UV excess color selection (at high\nGalactic latitudes). We analyze the distribution of lightcurve skewness for\nquasars and find that is centered on zero. We find that about 1/4 of the\nvariable stars are RR Lyrae stars, and that only 0.5% of stars from the main\nstellar locus are variable at the 0.05 mag level. The distribution of\nlightcurve skewness in the g-r vs. u-g color-color diagram on the main stellar\nlocus is found to be bimodal (with one mode consistent with Algol-like\nbehavior). Using over six hundred RR Lyrae stars, we demonstrate rich halo\nsubstructure out to distances of 100 kpc. We extrapolate these results to\nexpected performance by the Large Synoptic Survey Telescope and estimate that\nit will obtain well-sampled 2% accurate, multi-color lightcurves for ~2 million\nlow-redshift quasars, and will discover at least 50 million variable stars.\n", "machine_text": "\nWe analyze the changes in flux of faint, unresolved optical sources in the SDSS Stripe 82 by monitoring their photometric brightness across the SDSS ugriz bands. Our catalog collected 1.4 million observations and identified that 2% of these sources brighter than g=20.5 demonstrated a 0.05 mag (rms) variation simultaneously in both the g and r bands. Of these sources, two-thirds were found to be low-redshift quasars, although they only constitute 2% of all sources in the flux-limited sample. We establish that, at the 0.03 mag level, over 90% of quasars are variable and thus variability serves as a viable indicator for the selection of low-redshift quasars at high galactic latitudes. Further examinations of the quasar lightcurve skewness prove it is centered at zero. We also observe that roughly a quarter of the variable stars are RR Lyrae stars, and that only 0.5% of the sources in the main stellar locus demonstrate 0.05 mag of variability. Using over 600 RR Lyrae stars, we have detected halo substructures out to distances of 100 kpc. Predictions made by the Large Synoptic Survey Telescope estimate it will detect 2 million low-redshift quasars that display 0.02 mag (rms) variability, in addition to a total of 50 million variable stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0655}
{"prompt": "Rephrase the abstract of an article with title 'The infrared environments of masers associated with star formation'.\n  The near infrared (1-2um) and the thermal infrared (3-25um) trace many of the\nenvironments in which masers are thought to reside, including shocks, outflows,\naccretion disks, and the dense medium near protostars. After a number of recent\nsurveys it has been found that there is a higher detection rate of mid-IR\nemission towards masers than cm radio continuum emission from UC HII regions,\nand that the mid-IR emission is actually more closely cospatial to the maser\nlocations. A high percentage of water and methanol masers that are not\ncoincident with the UC HII regions in massive star forming regions are likely\nto be tracing outflows and extremely young high mass stars before the onset of\nthe UC HII region phase. After a decade of groundwork supporting the hypothesis\nthat linarly distributed class II methanol masers may generally trace accretion\ndisks around young massive stars, compelling evidence is mounting that these\nmasers may generally be associated with outflows instead. Substantiation of\nthis claim comes from recent outflow surveys and high angular resolution mid-IR\nimaging of the maser environments.\n\n", "human_text": "  The near infrared (1-2um) and the thermal infrared (3-25um) trace many of the\nenvironments in which masers are thought to reside, including shocks, outflows,\naccretion disks, and the dense medium near protostars. After a number of recent\nsurveys it has been found that there is a higher detection rate of mid-IR\nemission towards masers than cm radio continuum emission from UC HII regions,\nand that the mid-IR emission is actually more closely cospatial to the maser\nlocations. A high percentage of water and methanol masers that are not\ncoincident with the UC HII regions in massive star forming regions are likely\nto be tracing outflows and extremely young high mass stars before the onset of\nthe UC HII region phase. After a decade of groundwork supporting the hypothesis\nthat linarly distributed class II methanol masers may generally trace accretion\ndisks around young massive stars, compelling evidence is mounting that these\nmasers may generally be associated with outflows instead. Substantiation of\nthis claim comes from recent outflow surveys and high angular resolution mid-IR\nimaging of the maser environments.\n", "machine_text": "This article explores the relationships between interstellar masers and the infrared emission coming from star formation regions. Recent surveys have found that mid-IR emission is more likely to be detected in association with masers than cm radio continuum emission from UC HII regions. Additionally, a high percentage of water and methanol masers coincident with massive star forming regions are likely to trace outflows and very young high-mass stars before the UC HII region phase. This hypothesis is supported by outflow surveys and mid-IR imaging with high angular resolution of maser environments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.39}
{"prompt": "Rephrase the abstract of an article with title 'Sulphur abundances from the SI near-infrared triplet at 1045 nm'.\n  context : Unlike silicon and calcium, sulphur is an alpha-element which does\nnot form dust. Some of the available observations of the evolution of sulphur\nwith metallicity indicate an increased scatter of sulphur to iron ratios at low\nmetallicities or even a bimodal distribution, with some stars showing constant\nS/Fe at all metallicities and others showing an increasing S/Fe ratio with\ndecreasing metallicity. In metal-poor stars SI lines of Multiplet 1 at 920 nm\nare not yet too weak to permit to measure the sulphur abundance A(S), however\nin ground-based observations they are severely affected by telluric lines. aims\n: We investigate the possibility to measure sulphur abundances from SI Mult. 3\nat 1045 nm lines, which lie in the near infra-red. These are slightly weaker\nthan those of Mult. 1, but lie in a range not affected by telluric lines.\nmethod We investigate the lines of Mult.3 in the Sun (G2V), Procyon (F5V), HD\n33256 (F5V), HD 25069 (G9V) and epsilon Eri (HD 22049, K2V). For the Sun and\nProcyon the analysis has been performed with CO5BOLD 3D hydrodynamical model\natmospheres, for the other three stars, for which hydrodynamical simulations\nare not available, the analysis has been performed using 1D model atmospheres.\nresults For our sample of stars we find a global agreement of A(S) from lines\nof different multiplets. conclusions : Our results suggest that the infrared\nlines of Mult. 3 are a viable indicator of the sulphur abundance which, because\nof the intrinsic strength of this multiplet, should be suitable to study the\ntrend of [S/Fe] at low metallicities.\n\n", "human_text": "  context : Unlike silicon and calcium, sulphur is an alpha-element which does\nnot form dust. Some of the available observations of the evolution of sulphur\nwith metallicity indicate an increased scatter of sulphur to iron ratios at low\nmetallicities or even a bimodal distribution, with some stars showing constant\nS/Fe at all metallicities and others showing an increasing S/Fe ratio with\ndecreasing metallicity. In metal-poor stars SI lines of Multiplet 1 at 920 nm\nare not yet too weak to permit to measure the sulphur abundance A(S), however\nin ground-based observations they are severely affected by telluric lines. aims\n: We investigate the possibility to measure sulphur abundances from SI Mult. 3\nat 1045 nm lines, which lie in the near infra-red. These are slightly weaker\nthan those of Mult. 1, but lie in a range not affected by telluric lines.\nmethod We investigate the lines of Mult.3 in the Sun (G2V), Procyon (F5V), HD\n33256 (F5V), HD 25069 (G9V) and epsilon Eri (HD 22049, K2V). For the Sun and\nProcyon the analysis has been performed with CO5BOLD 3D hydrodynamical model\natmospheres, for the other three stars, for which hydrodynamical simulations\nare not available, the analysis has been performed using 1D model atmospheres.\nresults For our sample of stars we find a global agreement of A(S) from lines\nof different multiplets. conclusions : Our results suggest that the infrared\nlines of Mult. 3 are a viable indicator of the sulphur abundance which, because\nof the intrinsic strength of this multiplet, should be suitable to study the\ntrend of [S/Fe] at low metallicities.\n", "machine_text": "\nIn this study, we analyse the possibility of measuring sulphur abundance (A(S)) from the near-infrared triplet of Silicon (SI) at 1045 nm. Unlike Silicon and Calcium, sulphur does not form dust, which results in an increased scatter of sulphur-to-iron ratios seen in observations of low metallicities or a bimodal distribution seen in some stars. Given that the lines of Multiplet 1 at 920 nm are affected by telluric lines when observed from the ground, Multiplet 3 at 1045 nm, which is located in a range that is clear from such contamination, is considered here. Our sample is composed of the Sun (G2V), Procyon (F5V), HD 33256 (F5V), HD 25069 (G9V) and epsilon Eri (HD 22049, K2V). For the Sun and Procyon, the analysis is conducted with CO5BOLD 3D hydrodynamical model atmospheres, while for the other three stars, 1D models are employed. Ultimately, we discover that the infrared lines of Mult.3 are a reliable instrument of A(S) measurement and can be useful in analysing the evolution of [S/Fe] at low metallicities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2335}
{"prompt": "Rephrase the abstract of an article with title 'Derivations and skew derivations of the Grassmann algebras'.\n  Surprisingly, skew derivations rather than ordinary derivations are more\nbasic (important) object in study of the Grassmann algebras. Let $\\L_n =\nK\\lfloor x_1, ..., x_n\\rfloor$ be the Grassmann algebra over a commutative ring\n$K$ with ${1/2}\\in K$, and $\\d$ be a skew $K$-derivation of $\\L_n$. It is\nproved that $\\d$ is a unique sum $\\d = \\d^{ev} +\\d^{od}$ of an even and odd\nskew derivation. Explicit formulae are given for $\\d^{ev}$ and $\\d^{od}$ via\nthe elements $\\d (x_1), ..., \\d (x_n)$. It is proved that the set of all even\nskew derivations of $\\L_n$ coincides with the set of all the inner skew\nderivations. Similar results are proved for derivations of $\\L_n$. In\nparticular, $\\Der_K(\\L_n)$ is a faithful but not simple $\\Aut_K(\\L_n)$-module\n(where $K$ is reduced and $n\\geq 2$). All differential and skew differential\nideals of $\\L_n$ are found. It is proved that the set of generic normal\nelements of $\\L_n$ that are not units forms a single $\\Aut_K(\\L_n)$-orbit\n(namely, $\\Aut_K(\\L_n)x_1$) if $n$ is even and two orbits (namely,\n$\\Aut_K(\\L_n)x_1$ and $\\Aut_K(\\L_n)(x_1+x_2... x_n)$) if $n$ is odd.\n\n", "human_text": "  Surprisingly, skew derivations rather than ordinary derivations are more\nbasic (important) object in study of the Grassmann algebras. Let $\\L_n =\nK\\lfloor x_1, ..., x_n\\rfloor$ be the Grassmann algebra over a commutative ring\n$K$ with ${1/2}\\in K$, and $\\d$ be a skew $K$-derivation of $\\L_n$. It is\nproved that $\\d$ is a unique sum $\\d = \\d^{ev} +\\d^{od}$ of an even and odd\nskew derivation. Explicit formulae are given for $\\d^{ev}$ and $\\d^{od}$ via\nthe elements $\\d (x_1), ..., \\d (x_n)$. It is proved that the set of all even\nskew derivations of $\\L_n$ coincides with the set of all the inner skew\nderivations. Similar results are proved for derivations of $\\L_n$. In\nparticular, $\\Der_K(\\L_n)$ is a faithful but not simple $\\Aut_K(\\L_n)$-module\n(where $K$ is reduced and $n\\geq 2$). All differential and skew differential\nideals of $\\L_n$ are found. It is proved that the set of generic normal\nelements of $\\L_n$ that are not units forms a single $\\Aut_K(\\L_n)$-orbit\n(namely, $\\Aut_K(\\L_n)x_1$) if $n$ is even and two orbits (namely,\n$\\Aut_K(\\L_n)x_1$ and $\\Aut_K(\\L_n)(x_1+x_2... x_n)$) if $n$ is odd.\n", "machine_text": "The study of Grassmann Algebras has revealed the fundamental nature of skew derivations over ordinary derivations. Taking $\\mathcal{L}_n = K \\langle x_1,\\cdots,x_n \\rangle$ as a Grassmann Algebra over a commutative ring $K$ where $\\frac{1}{2} \\in K$, and any skew $K$-derivation $\\delta$ being the sum $\\delta = \\delta^{ev} + \\delta^{od}$ of an even and odd skew derivation, formulae are given to find $\\delta_{ev}$ and $\\delta_{od}$ to in terms of $\\delta (x_1),\\cdots,\\delta (x_n)$. Furthermore, it has been deduced that the set of all even skew derivations of $\\mathcal{L}_n$ coincide with the set of inner skew derivations. Results analogous to this have been found for derivations of $\\mathcal{L}_n$. Additionally, all differential and skew differential ideals of $\\mathcal{L}_n$ have been discovered. Finally, it has been elucidated that the set of all generic normal non-unit elements in $\\mathcal{L}_n$ forms a single orbit when $n$ is even, or two orbits when $n$ is odd.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.385}
{"prompt": "Rephrase the abstract of an article with title 'Antiferromagnetic Spin Fluctuations in the Metallic Phase of\n  Quasi-Two-Dimensional Organic Superconductors'.\n  We give a quantitative analysis of the previously published nuclear magnetic\nresonance (NMR) experiments in the k-(ET)2X family of organic charge transfer\nsalts by using the phenomenological spin fluctuation model of Moriya, and\nMillis, Monien and Pines (M-MMP). For temperatures above T_nmr ~ 50 K, the\nmodel gives a good quantitative description of the data in the metallic phases\nof several k-(ET)2X materials. These materials display antiferromagnetic\ncorrelation lengths which increase with decreasing temperature and grow to\nseveral lattice constants by T_nmr. It is shown that the fact that the\ndimensionless Korringa ratio is much larger than unity is inconsistent with a\nbroad class of theoretical models (such as dynamical mean-field theory) which\nneglects spatial correlations and/or vertex corrections. For materials close to\nthe Mott insulating phase the nuclear spin relaxation rate, the Knight shift\nand the Korringa ratio all decrease significantly with decreasing temperature\nbelow T_nmr. This cannot be described by the M-MMP model and the most natural\nexplanation is that a pseudogap, similar to that observed in the underdoped\ncuprate superconductors, opens up in the density of states below T_nmr. Such a\npseudogap has recently been predicted to occur in the dimerised organic charge\ntransfer salts materials by the resonating valence bond (RVB) theory. We\npropose specific new experiments on organic superconductors to elucidate these\nissues. For example, measurements to see if high magnetic fields or high\npressures can be used to close the pseudogap would be extremely valuable.\n\n", "human_text": "  We give a quantitative analysis of the previously published nuclear magnetic\nresonance (NMR) experiments in the k-(ET)2X family of organic charge transfer\nsalts by using the phenomenological spin fluctuation model of Moriya, and\nMillis, Monien and Pines (M-MMP). For temperatures above T_nmr ~ 50 K, the\nmodel gives a good quantitative description of the data in the metallic phases\nof several k-(ET)2X materials. These materials display antiferromagnetic\ncorrelation lengths which increase with decreasing temperature and grow to\nseveral lattice constants by T_nmr. It is shown that the fact that the\ndimensionless Korringa ratio is much larger than unity is inconsistent with a\nbroad class of theoretical models (such as dynamical mean-field theory) which\nneglects spatial correlations and/or vertex corrections. For materials close to\nthe Mott insulating phase the nuclear spin relaxation rate, the Knight shift\nand the Korringa ratio all decrease significantly with decreasing temperature\nbelow T_nmr. This cannot be described by the M-MMP model and the most natural\nexplanation is that a pseudogap, similar to that observed in the underdoped\ncuprate superconductors, opens up in the density of states below T_nmr. Such a\npseudogap has recently been predicted to occur in the dimerised organic charge\ntransfer salts materials by the resonating valence bond (RVB) theory. We\npropose specific new experiments on organic superconductors to elucidate these\nissues. For example, measurements to see if high magnetic fields or high\npressures can be used to close the pseudogap would be extremely valuable.\n", "machine_text": "We examine the NMR experiments done on the k-(ET)2X organic materials and demonstrate that above temperatures of 50 K, the antiferromagnetic spin fluctuations are present and the M-MMP phenomenological spin fluctuation model describes the data well. Near the Mott insulating phase, the Korringa ratio becomes much greater than one and suggests vertex corrections or spatial correlations are being neglected. Below 50 K, the Knight shift and Korringa ratio decline, signaling the opening of a pseudogap akin to that observed in the underdoped cuprate superconductors. We suggest experiments to prove the presence of a pseudogap and explore potential methods of closing it altogether.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1382}
{"prompt": "Rephrase the abstract of an article with title 'The Average Kinetic Energy of the Heavy Quark in $\\Lambda_b$ in the\n  Bethe-Salpeter Equation Approach'.\n  In the previous paper, based on the $SU(2)_{f}\\times SU(2)_{s}$ heavy quark\nsymmetries of the QCD Lagrangian in the heavy quark limit, the Bethe-Salpeter\nequation for the heavy baryon $\\Lambda_b$ was established with the picture that\n$\\Lambda_b$ is composed of a heavy quark and a scalar light diquark. In the\npresent work, we apply this model to calculate $\\mu_\\pi^2$ for $\\Lambda_b$, the\naverage kinetic energy of the heavy quark inside $\\Lambda_{b}$. This quantity\nis particularly interesting since it can be measured in experiments and since\nit contributes to the inclusive semileptonic decays of $\\Lambda_b$ when\ncontributions from higher order terms in $1/M_b$ expansions are taken into\naccount and consequently influences the determination of the\nCabibbo-Kobayashi-Maskawa matrix elements $V_{ub}$ and $V_{cb}$. We find that\n$\\mu_\\pi^2$ for $\\Lambda_b$ is $0.25GeV^2$ $\\sim$ $0.95GeV^2$, depending on the\nparameters in the model including the light diquark mass and the interaction\nstrength between the heavy quark and the light diquark in the kernel of the BS\nequation. We also find that this result is consistent with the value of\n$\\mu_\\pi^2$ for $\\Lambda_b$ which is derived from the experimental value of\n$\\mu_\\pi^2$ for the $B$ meson with the aid of the heavy quark effective theory.\n\n", "human_text": "  In the previous paper, based on the $SU(2)_{f}\\times SU(2)_{s}$ heavy quark\nsymmetries of the QCD Lagrangian in the heavy quark limit, the Bethe-Salpeter\nequation for the heavy baryon $\\Lambda_b$ was established with the picture that\n$\\Lambda_b$ is composed of a heavy quark and a scalar light diquark. In the\npresent work, we apply this model to calculate $\\mu_\\pi^2$ for $\\Lambda_b$, the\naverage kinetic energy of the heavy quark inside $\\Lambda_{b}$. This quantity\nis particularly interesting since it can be measured in experiments and since\nit contributes to the inclusive semileptonic decays of $\\Lambda_b$ when\ncontributions from higher order terms in $1/M_b$ expansions are taken into\naccount and consequently influences the determination of the\nCabibbo-Kobayashi-Maskawa matrix elements $V_{ub}$ and $V_{cb}$. We find that\n$\\mu_\\pi^2$ for $\\Lambda_b$ is $0.25GeV^2$ $\\sim$ $0.95GeV^2$, depending on the\nparameters in the model including the light diquark mass and the interaction\nstrength between the heavy quark and the light diquark in the kernel of the BS\nequation. We also find that this result is consistent with the value of\n$\\mu_\\pi^2$ for $\\Lambda_b$ which is derived from the experimental value of\n$\\mu_\\pi^2$ for the $B$ meson with the aid of the heavy quark effective theory.\n", "machine_text": "  This study focuses on the average kinetic energy of the heavy quark within the context of the $\\Lambda_b$ baryon, as determined by the Bethe-Salpeter equation formulated in the framework of the $SU(2)_{f} \\times SU(2)_{s}$ heavy quark symmetries of QCD. This quantity, $\\mu_\\pi^2$, can be extracted from experimental data and is important since it contributes to the inclusive semileptonic decays of $\\Lambda_b$ in the calculation of Cabibbo-Kobayashi-Maskawa matrix elements $V_{ub}$ and $V_{cb}$. Through our research, we conclude that $\\mu_\\pi^2$ for $\\Lambda_b$ ranges between $0.25-0.95GeV^2$, all depending on the light diquark mass and the interactions between the heavy quark and the light diquark. This result is consistent with the value of $\\mu_\\pi^2$ for $\\Lambda_b$ derived through the heavy quark effective theory from the experimental value of $\\mu_\\pi^2$ for the $B$ meson.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1379}
{"prompt": "Rephrase the abstract of an article with title 'Non-topological solitons in field theories with kinetic self-coupling'.\n  We investigate some fundamental features of a class of non-linear\nrelativistic lagrangian field theories with kinetic self-coupling. We focus our\nattention upon theories admitting static, spherically symmetric solutions in\nthree space dimensions which are finite-energy and stable. We determine general\nconditions for the existence and stability of these non-topological soliton\nsolutions. In particular, we perform a linear stability analysis that goes\nbeyond the usual Derrick-like criteria. On the basis of these considerations we\nobtain a complete characterization of the soliton-supporting members of the\naforementioned class of non-linear field theories. We then classify the family\nof soliton-supporting theories according to the central and asymptotic\nbehaviors of the soliton field, and provide illustrative explicit examples of\nmodels belonging to each of the corresponding sub-families. In the present work\nwe restrict most of our considerations to one and many-components scalar\nmodels. We show that in these cases the finite-energy static spherically\nsymmetric solutions are stable against charge-preserving perturbations,\nprovided that the vacuum energy of the model vanishes and the energy density is\npositive definite. We also discuss briefly the extension of the present\napproach to models involving other types of fields, but a detailed study of\nthis more general scenario will be addressed in a separate publication.\n\n", "human_text": "  We investigate some fundamental features of a class of non-linear\nrelativistic lagrangian field theories with kinetic self-coupling. We focus our\nattention upon theories admitting static, spherically symmetric solutions in\nthree space dimensions which are finite-energy and stable. We determine general\nconditions for the existence and stability of these non-topological soliton\nsolutions. In particular, we perform a linear stability analysis that goes\nbeyond the usual Derrick-like criteria. On the basis of these considerations we\nobtain a complete characterization of the soliton-supporting members of the\naforementioned class of non-linear field theories. We then classify the family\nof soliton-supporting theories according to the central and asymptotic\nbehaviors of the soliton field, and provide illustrative explicit examples of\nmodels belonging to each of the corresponding sub-families. In the present work\nwe restrict most of our considerations to one and many-components scalar\nmodels. We show that in these cases the finite-energy static spherically\nsymmetric solutions are stable against charge-preserving perturbations,\nprovided that the vacuum energy of the model vanishes and the energy density is\npositive definite. We also discuss briefly the extension of the present\napproach to models involving other types of fields, but a detailed study of\nthis more general scenario will be addressed in a separate publication.\n", "machine_text": "\nIn this work, we study the properties of a class of relativistic lagrangian field \ntheories with kinetic self-coupling that hosts spherically symmetric, finite-energy \nnon-topological soliton solutions in three space dimensions and analyze their\nstability. We first derive conditions required for such solitons to exist and be\nstable, going beyond standard Derrick-like criteria. Following this, we classify\nthese solutions by the central and asymptotic behaviors of the field and provide\nexamples of the various sub-families. In particular, we discuss the stability\nof one- and multi-component scalar models with a vanishing vacuum energy and a \npositive definite energy density against charge-preserving perturbations. A more \nin-depth analysis of the general case is provided in a future publication.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0112}
{"prompt": "Rephrase the abstract of an article with title 'Kinematics of hypervelocity stars in the triaxial halo of the Milky Way'.\n  Hypervelocity stars (HVSs) ejected by the massive black hole at the Galactic\ncenter have unique kinematic properties compared to other halo stars. Their\ntrajectories will deviate from being exactly radial because of the asymmetry of\nthe Milky Way potential produced by the flattened disk and the triaxial dark\nmatter halo, causing a change of angular momentum that can be much larger than\nthe initial small value at injection. We study the kinematics of HVSs and\npropose an estimator of dark halo triaxiality that is determined only by\ninstantaneous position and velocity vectors of HVSs at large Galactocentric\ndistances (r>~50kpc). We show that, in the case of a substantially triaxial\nhalo, the distribution of deflection angles (the angle between the stellar\nposition and velocity vector) for HVSs on bound orbits is spread uniformly over\nthe range 10--180deg. Future astrometric and deep wide-field surveys should\nmeasure the positions and velocities of a significant number of HVSs, and\nprovide useful constraints on the shape of the Galactic dark matter halo.\n\n", "human_text": "  Hypervelocity stars (HVSs) ejected by the massive black hole at the Galactic\ncenter have unique kinematic properties compared to other halo stars. Their\ntrajectories will deviate from being exactly radial because of the asymmetry of\nthe Milky Way potential produced by the flattened disk and the triaxial dark\nmatter halo, causing a change of angular momentum that can be much larger than\nthe initial small value at injection. We study the kinematics of HVSs and\npropose an estimator of dark halo triaxiality that is determined only by\ninstantaneous position and velocity vectors of HVSs at large Galactocentric\ndistances (r>~50kpc). We show that, in the case of a substantially triaxial\nhalo, the distribution of deflection angles (the angle between the stellar\nposition and velocity vector) for HVSs on bound orbits is spread uniformly over\nthe range 10--180deg. Future astrometric and deep wide-field surveys should\nmeasure the positions and velocities of a significant number of HVSs, and\nprovide useful constraints on the shape of the Galactic dark matter halo.\n", "machine_text": "\nThe instantaneous positions and velocities of Hypervelocity Stars (HVSs) ejected from the Galactic Center provide insight into the asymmetrical potential of the Milky Way, and allow us to estimate the triaxiality of its dark matter halo. By studying the trajectories of these stars at large Galactocentric distances (r>~50kpc) and their deviation from being radial, we can measure the magnitude of the change in angular momentum caused by the asymmetry of the Milky Way's flattened disk and triaxial dark matter halo. We propose an estimator of dark halo triaxiality based on the deflection angles (the angle between the star's position and velocity vector) of HVSs on bound orbits. Our findings indicate that, in the case of a triaxial halo, the distribution of these angles is spread uniformly between 10 and 180 degrees. Future surveys with precise astrometric and wide-field measurements of the positions and velocities of HVSs will provide important constraints for the shape of the Galactic dark halo.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3514}
{"prompt": "Rephrase the abstract of an article with title 'On the freezing of variables in random constraint satisfaction problems'.\n  The set of solutions of random constraint satisfaction problems (zero energy\ngroundstates of mean-field diluted spin glasses) undergoes several structural\nphase transitions as the amount of constraints is increased. This set first\nbreaks down into a large number of well separated clusters. At the freezing\ntransition, which is in general distinct from the clustering one, some\nvariables (spins) take the same value in all solutions of a given cluster. In\nthis paper we study the critical behavior around the freezing transition, which\nappears in the unfrozen phase as the divergence of the sizes of the\nrearrangements induced in response to the modification of a variable. The\nformalism is developed on generic constraint satisfaction problems and applied\nin particular to the random satisfiability of boolean formulas and to the\ncoloring of random graphs. The computation is first performed in random tree\nensembles, for which we underline a connection with percolation models and with\nthe reconstruction problem of information theory. The validity of these results\nfor the original random ensembles is then discussed in the framework of the\ncavity method.\n\n", "human_text": "  The set of solutions of random constraint satisfaction problems (zero energy\ngroundstates of mean-field diluted spin glasses) undergoes several structural\nphase transitions as the amount of constraints is increased. This set first\nbreaks down into a large number of well separated clusters. At the freezing\ntransition, which is in general distinct from the clustering one, some\nvariables (spins) take the same value in all solutions of a given cluster. In\nthis paper we study the critical behavior around the freezing transition, which\nappears in the unfrozen phase as the divergence of the sizes of the\nrearrangements induced in response to the modification of a variable. The\nformalism is developed on generic constraint satisfaction problems and applied\nin particular to the random satisfiability of boolean formulas and to the\ncoloring of random graphs. The computation is first performed in random tree\nensembles, for which we underline a connection with percolation models and with\nthe reconstruction problem of information theory. The validity of these results\nfor the original random ensembles is then discussed in the framework of the\ncavity method.\n", "machine_text": "\nThis paper examines the structural modifications in the set of solutions of random constraint satisfaction problems as the amount of constraints increases. In particular, it looks at the behavior around the freezing transition, where variables take the same value in the different clusters of a given solution. This is compared with percolation models and the reconstruction problem of information theory. An analysis is done of the random tree ensembles, and then the validity of these results for the original random constraint satisfaction problem is discussed by using the cavity method.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2147}
{"prompt": "Rephrase the abstract of an article with title 'Geodesics for Efficient Creation and Propagation of Order along Ising\n  Spin Chains'.\n  Experiments in coherent nuclear and electron magnetic resonance, and optical\nspectroscopy correspond to control of quantum mechanical ensembles, guiding\nthem from initial to final target states by unitary transformations. The\ncontrol inputs (pulse sequences) that accomplish these unitary transformations\nshould take as little time as possible so as to minimize the effects of\nrelaxation and decoherence and to optimize the sensitivity of the experiments.\nHere we give efficient syntheses of various unitary transformations on Ising\nspin chains of arbitrary length. The efficient realization of the unitary\ntransformations presented here is obtained by computing geodesics on a sphere\nunder a special metric. We show that contrary to the conventional belief, it is\npossible to propagate a spin order along an Ising spin chain with coupling\nstrength J (in units of Hz), significantly faster than 1/(2J) per step. The\nmethods presented here are expected to be useful for immediate and future\napplications involving control of spin dynamics in coherent spectroscopy and\nquantum information processing.\n\n", "human_text": "  Experiments in coherent nuclear and electron magnetic resonance, and optical\nspectroscopy correspond to control of quantum mechanical ensembles, guiding\nthem from initial to final target states by unitary transformations. The\ncontrol inputs (pulse sequences) that accomplish these unitary transformations\nshould take as little time as possible so as to minimize the effects of\nrelaxation and decoherence and to optimize the sensitivity of the experiments.\nHere we give efficient syntheses of various unitary transformations on Ising\nspin chains of arbitrary length. The efficient realization of the unitary\ntransformations presented here is obtained by computing geodesics on a sphere\nunder a special metric. We show that contrary to the conventional belief, it is\npossible to propagate a spin order along an Ising spin chain with coupling\nstrength J (in units of Hz), significantly faster than 1/(2J) per step. The\nmethods presented here are expected to be useful for immediate and future\napplications involving control of spin dynamics in coherent spectroscopy and\nquantum information processing.\n", "machine_text": "\nThe current study looks at creating and propagating order along Ising spin chains using geodesics, affording the possibility of ultra-fast control over quantum mechanical ensembles by reducing the time it takes for unitary transformations. Results suggest that it is possible to spread a spin order along an Ising spin chain at speeds much faster than initially thought -- 1/2J Hz per step -- opening up new possibilities for controlling spin dynamics in coherent spectroscopy and quantum information processing. Experiments demonstrate the efficacy of the synthesized unitary transformations and these methods are expected to lead to further applications.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0378}
{"prompt": "Rephrase the abstract of an article with title 'Metal and molecule cooling in simulations of structure formation'.\n  Cooling is the main process leading to the condensation of gas in the dark\nmatter potential wells and consequently to star and structure formation. In a\nmetal-free environment, the main available coolants are H, He, H$_2$ and HD;\nonce the gas is enriched with metals, these also become important in defining\nthe cooling properties of the gas. We discuss the implementation in Gadget-2 of\nmolecular and metal cooling at temperatures lower that $\\rm10^4 K$, following\nthe time dependent properties of the gas and pollution from stellar evolution.\nWe have checked the validity of our scheme comparing the results of some test\nruns with previous calculations of cosmic abundance evolution and structure\nformation, finding excellent agreement. We have also investigated the relevance\nof molecule and metal cooling in some specific cases, finding that inclusion of\nHD cooling results in a higher clumping factor of the gas at high redshifts,\nwhile metal cooling at low temperatures can have a significant impact on the\nformation and evolution of cold objects.\n\n", "human_text": "  Cooling is the main process leading to the condensation of gas in the dark\nmatter potential wells and consequently to star and structure formation. In a\nmetal-free environment, the main available coolants are H, He, H$_2$ and HD;\nonce the gas is enriched with metals, these also become important in defining\nthe cooling properties of the gas. We discuss the implementation in Gadget-2 of\nmolecular and metal cooling at temperatures lower that $\\rm10^4 K$, following\nthe time dependent properties of the gas and pollution from stellar evolution.\nWe have checked the validity of our scheme comparing the results of some test\nruns with previous calculations of cosmic abundance evolution and structure\nformation, finding excellent agreement. We have also investigated the relevance\nof molecule and metal cooling in some specific cases, finding that inclusion of\nHD cooling results in a higher clumping factor of the gas at high redshifts,\nwhile metal cooling at low temperatures can have a significant impact on the\nformation and evolution of cold objects.\n", "machine_text": "\nThis article explores the role of metal and molecular cooling in simulations of structure formation. We present an implementation in the Gadget-2 code of cooling from these two sources at temperatures lower than 10,000 K, taking into account the processing of the gas due to stellar evolution. The results of our scheme are compared with past results from cosmic abundance evolution and structure formation, finding a strong correlation. Additionally, we investigate the effects of HD cooling on the clumping of gas at high redshifts and the impact of metal cooling on the formation and evolution of cold objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2182}
{"prompt": "Rephrase the abstract of an article with title 'Matrix Exponential-Based Closures for the Turbulent Subgrid-Scale Stress\n  Tensor'.\n  Two approaches for closing the turbulence subgrid-scale stress tensor in\nterms of matrix exponentials are introduced and compared. The first approach is\nbased on a formal solution of the stress transport equation in which the\nproduction terms can be integrated exactly in terms of matrix exponentials.\nThis formal solution of the subgrid-scale stress transport equation is shown to\nbe useful to explore special cases, such as the response to constant velocity\ngradient, but neglecting pressure-strain correlations and diffusion effects.\nThe second approach is based on an Eulerian-Lagrangian change of variables,\ncombined with the assumption of isotropy for the conditionally averaged\nLagrangian velocity gradient tensor and with the `Recent Fluid Deformation'\n(RFD) approximation. It is shown that both approaches lead to the same basic\nclosure in which the stress tensor is expressed as the product of the matrix\nexponential of the resolved velocity gradient tensor multiplied by its\ntranspose. Short-time expansions of the matrix exponentials are shown to\nprovide an eddy-viscosity term and particular quadratic terms, and thus allow a\nreinterpretation of traditional eddy-viscosity and nonlinear stress closures.\nThe basic feasibility of the matrix-exponential closure is illustrated by\nimplementing it successfully in Large Eddy Simulation of forced isotropic\nturbulence. The matrix-exponential closure employs the drastic approximation of\nentirely omitting the pressure-strain correlation and other `nonlinear\nscrambling' terms. But unlike eddy-viscosity closures, the matrix exponential\napproach provides a simple and local closure that can be derived directly from\nthe stress transport equation with the production term, and using physically\nmotivated assumptions about Lagrangian decorrelation and upstream isotropy.\n\n", "human_text": "  Two approaches for closing the turbulence subgrid-scale stress tensor in\nterms of matrix exponentials are introduced and compared. The first approach is\nbased on a formal solution of the stress transport equation in which the\nproduction terms can be integrated exactly in terms of matrix exponentials.\nThis formal solution of the subgrid-scale stress transport equation is shown to\nbe useful to explore special cases, such as the response to constant velocity\ngradient, but neglecting pressure-strain correlations and diffusion effects.\nThe second approach is based on an Eulerian-Lagrangian change of variables,\ncombined with the assumption of isotropy for the conditionally averaged\nLagrangian velocity gradient tensor and with the `Recent Fluid Deformation'\n(RFD) approximation. It is shown that both approaches lead to the same basic\nclosure in which the stress tensor is expressed as the product of the matrix\nexponential of the resolved velocity gradient tensor multiplied by its\ntranspose. Short-time expansions of the matrix exponentials are shown to\nprovide an eddy-viscosity term and particular quadratic terms, and thus allow a\nreinterpretation of traditional eddy-viscosity and nonlinear stress closures.\nThe basic feasibility of the matrix-exponential closure is illustrated by\nimplementing it successfully in Large Eddy Simulation of forced isotropic\nturbulence. The matrix-exponential closure employs the drastic approximation of\nentirely omitting the pressure-strain correlation and other `nonlinear\nscrambling' terms. But unlike eddy-viscosity closures, the matrix exponential\napproach provides a simple and local closure that can be derived directly from\nthe stress transport equation with the production term, and using physically\nmotivated assumptions about Lagrangian decorrelation and upstream isotropy.\n", "machine_text": "This article presents two approaches for deriving the closure of the turbulent\nsubgrid-scale stress tensor in terms of matrix exponentials. The first approach\nemploys a formal solution of the stress transport equation, integrating the\nproduction terms exactly as matrix exponentials. While this method enables\nexploring special cases, it fails to account for pressure-strain correlations\nor diffusion effects. The second approach is based on an Eulerian-Lagrangian\nanalysis, assuming isotropy of the conditionally averaged Lagrangian velocity\ngradient tensor and using the RFD approximation. Results for both approaches\nmanifest as the product of the matrix exponential of the resolved velocity\ngradient tensor and its transpose. Short-time expansions of the matrix\nexponentials allow for the interpretative reexpression of traditional eddy-viscosity\nand nonlinear stress closures. An implementation of the matrix-exponential\nclosure was successful in Large Eddy Simulations of forced isotropic\nturbulence, though this method drastically omits the pressure-strain correlation\nas well as other nonlinear scrambling terms. The matrix-exponential closure\nprovides a local and physically motivated solution of the subgrid-scale stress\ntransport equation, derived directly from its production term.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3781}
{"prompt": "Rephrase the abstract of an article with title 'Integrable systems and complex geometry'.\n  In this paper, we discuss an interaction between complex geometry and\nintegrable systems. Section 1 reviews the classical results on integrable\nsystems. New examples of integrable systems, which have been discovered, are\nbased on the Lax representation of the equations of motion. These systems can\nbe realized as straight line motions on a Jacobi variety of a so-called\nspectral curve. In section 2, we study a Lie algebra theoretical method leading\nto integrable systems and we apply the method to several problems. In section\n3, we discuss the concept of the algebraic complete integrability (a.c.i.) of\nhamiltonian systems. Algebraic integrability means that the system is\ncompletely integrable in the sens of the phase space being folited by tori,\nwhich in addition are real parts of a complex algebraic tori (abelian\nvarieties). The method is devoted to illustrate how to decide about the a.c.i.\nof hamiltonian systems and is applied to some examples. Finally, in section 4\nwe study an a.c.i. in the generalized sense which appears as covering of a.c.i.\nsystem. The manifold invariant by the complex flow is covering of abelian\nvariety.\n\n", "human_text": "  In this paper, we discuss an interaction between complex geometry and\nintegrable systems. Section 1 reviews the classical results on integrable\nsystems. New examples of integrable systems, which have been discovered, are\nbased on the Lax representation of the equations of motion. These systems can\nbe realized as straight line motions on a Jacobi variety of a so-called\nspectral curve. In section 2, we study a Lie algebra theoretical method leading\nto integrable systems and we apply the method to several problems. In section\n3, we discuss the concept of the algebraic complete integrability (a.c.i.) of\nhamiltonian systems. Algebraic integrability means that the system is\ncompletely integrable in the sens of the phase space being folited by tori,\nwhich in addition are real parts of a complex algebraic tori (abelian\nvarieties). The method is devoted to illustrate how to decide about the a.c.i.\nof hamiltonian systems and is applied to some examples. Finally, in section 4\nwe study an a.c.i. in the generalized sense which appears as covering of a.c.i.\nsystem. The manifold invariant by the complex flow is covering of abelian\nvariety.\n", "machine_text": "\nThis article explores the interplay between integrable systems and complex geometry. We begin by revising classical findings about integrable systems and explicating the Lax representation which describes them. Subsequently, a Lie algebra theoretical approach to integration of systems is applied to various problems. Following this, the concept of algebraic complete integrability (a.c.i.) of hamiltonian systems is discussed. Through this, it is explained how to determine the a.c.i. of a system and representative examples are presented. Lastly, a generalised a.c.i. that forms a covering of abelian varieties is analysed. The related complex flows are then examined in terms of the resulting invariant manifold.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1579}
{"prompt": "Rephrase the abstract of an article with title 'Extrasolar planet taxonomy: a new statistical approach'.\n  In this paper we present the guidelines for an extrasolar planet taxonomy.\nThe discovery of an increasing number of extrasolar planets showing a vast\nvariety of planetary parameters, like Keplerian orbital elements and\nenvironmental parameters, like stellar masses, spectral types, metallicity\netc., prompts the development of a planetary taxonomy. In this work via\nprincipal component analysis followed by hierarchical clustering analysis, we\nreport the definition of five robust groups of planets. We also discuss the\nphysical relevance of such analysis, which may provide a valid basis for\ndisentangling the role of the several physical parameters involved in the\nprocesses of planet formation and subsequent evolution. For instance, we were\nable to divide the hot Jupiters into two main groups on the basis of their\nstellar masses and metallicities. Moreover, for some groups, we find strong\ncorrelations between metallicity, semi-major axis and eccentricity. The\nimplications of these findings are discussed.\n\n", "human_text": "  In this paper we present the guidelines for an extrasolar planet taxonomy.\nThe discovery of an increasing number of extrasolar planets showing a vast\nvariety of planetary parameters, like Keplerian orbital elements and\nenvironmental parameters, like stellar masses, spectral types, metallicity\netc., prompts the development of a planetary taxonomy. In this work via\nprincipal component analysis followed by hierarchical clustering analysis, we\nreport the definition of five robust groups of planets. We also discuss the\nphysical relevance of such analysis, which may provide a valid basis for\ndisentangling the role of the several physical parameters involved in the\nprocesses of planet formation and subsequent evolution. For instance, we were\nable to divide the hot Jupiters into two main groups on the basis of their\nstellar masses and metallicities. Moreover, for some groups, we find strong\ncorrelations between metallicity, semi-major axis and eccentricity. The\nimplications of these findings are discussed.\n", "machine_text": "\nThis research provides a new statistical approach for classifying extrasolar planets. By utilizing principal component analysis and hierarchical clustering, we have managed to find five distinct groups of planets. We can see the importance of environmental parameters such as stellar masses and gas composition on the classification of these groups. Furthermore, we discovered strong correlations between properties such as density, semi-major axis, and eccentricity. These correlations and their effects on the formation and evolution of these planets will be discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.091}
{"prompt": "Rephrase the abstract of an article with title 'The Mira variable S Ori: Relationships between the photosphere,\n  molecular layer, dust shell, and SiO maser shell at 4 epochs'.\n  We present the first multi-epoch study that includes concurrent mid-infrared\nand radio interferometry of an oxygen-rich Mira star. We obtained mid-infrared\ninterferometry of S Ori with VLTI/MIDI at four epochs between December 2004 and\nDecember 2005. We concurrently observed v=1, J=1-0 (43.1 GHz), and v=2, J=1-0\n(42.8 GHz) SiO maser emission toward S Ori with the VLBA at three epochs. The\nMIDI data are analyzed using self-excited dynamic model atmospheres including\nmolecular layers, complemented by a radiative transfer model of the\ncircumstellar dust shell. The VLBA data are reduced to the spatial structure\nand kinematics of the maser spots. The modeling of our MIDI data results in\nphase-dependent continuum photospheric angular diameters between about 7.9 mas\n(Phase 0.55) and 9.7 mas (Phase 1.16). The dust shell can best be modeled with\nAl2O3 grains using phase-dependent inner boundary radii between 1.8 and 2.4\nphotospheric radii. The dust shell appears to be more compact with greater\noptical depth near visual minimum, and more extended with lower optical depth\nafter visual maximum. The ratios of the SiO maser ring radii to the\nphotospheric radii are between about 1.9 and 2.4. The maser spots mark the\nregion of the molecular atmospheric layers just beyond the steepest decrease in\nthe mid-infrared model intensity profile. Their velocity structure indicates a\nradial gas expansion. Al2O3 dust grains and SiO maser spots form at relatively\nsmall radii of 1.8-2.4 photospheric radii. Our results suggest increased mass\nloss and dust formation close to the surface near the minimum visual phase,\nwhen Al2O3 dust grains are co-located with the molecular gas and the SiO maser\nshells, and a more expanded dust shell after visual maximum. Silicon does not\nappear to be bound in dust, as our data show no sign of silicate grains.\n\n", "human_text": "  We present the first multi-epoch study that includes concurrent mid-infrared\nand radio interferometry of an oxygen-rich Mira star. We obtained mid-infrared\ninterferometry of S Ori with VLTI/MIDI at four epochs between December 2004 and\nDecember 2005. We concurrently observed v=1, J=1-0 (43.1 GHz), and v=2, J=1-0\n(42.8 GHz) SiO maser emission toward S Ori with the VLBA at three epochs. The\nMIDI data are analyzed using self-excited dynamic model atmospheres including\nmolecular layers, complemented by a radiative transfer model of the\ncircumstellar dust shell. The VLBA data are reduced to the spatial structure\nand kinematics of the maser spots. The modeling of our MIDI data results in\nphase-dependent continuum photospheric angular diameters between about 7.9 mas\n(Phase 0.55) and 9.7 mas (Phase 1.16). The dust shell can best be modeled with\nAl2O3 grains using phase-dependent inner boundary radii between 1.8 and 2.4\nphotospheric radii. The dust shell appears to be more compact with greater\noptical depth near visual minimum, and more extended with lower optical depth\nafter visual maximum. The ratios of the SiO maser ring radii to the\nphotospheric radii are between about 1.9 and 2.4. The maser spots mark the\nregion of the molecular atmospheric layers just beyond the steepest decrease in\nthe mid-infrared model intensity profile. Their velocity structure indicates a\nradial gas expansion. Al2O3 dust grains and SiO maser spots form at relatively\nsmall radii of 1.8-2.4 photospheric radii. Our results suggest increased mass\nloss and dust formation close to the surface near the minimum visual phase,\nwhen Al2O3 dust grains are co-located with the molecular gas and the SiO maser\nshells, and a more expanded dust shell after visual maximum. Silicon does not\nappear to be bound in dust, as our data show no sign of silicate grains.\n", "machine_text": "This work presents a comprehensive, four-epoch study of the red giant oxygen-rich star, S Ori, employing mid-infrared interferometry with VLTI/MIDI and radio interferometry with the VLBA to measure the photospheric, molecular layer, dust shell, and SiO maser shell properties. Our results suggest a large increase in mass loss and dust formation close to the photospheric surface near the minimum visual phase, with Al2O3 dust grains co-located with the molecular gas and SiO maser shells, and a more expanded dust shell after visual maximum. While silicon appears to be mostly in a gaseous form, we find no evidence of silicate grains.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4614}
{"prompt": "Rephrase the abstract of an article with title 'The Angular-Diameter-Distance-Maximum and Its Redshift as Constraints on\n  $\\Lambda \\neq 0$ FLRW Models'.\n  The plethora of recent cosmologically relevant data has indicated that our\nuniverse is very well fit by a standard Friedmann-Lema\\^{i}tre-Robertson-Walker\n(FLRW) model, with $\\Omega_{M} \\approx 0.27$ and $\\Omega_{\\Lambda} \\approx\n0.73$ -- or, more generally, by nearly flat FLRW models with parameters close\nto these values. Additional independent cosmological information, particularly\nthe maximum of the angular-diameter (observer-area) distance and the redshift\nat which it occurs, would improve and confirm these results, once sufficient\nprecise Supernovae Ia data in the range $1.5 < z < 1.8$ become available. We\nobtain characteristic FLRW closed functional forms for $C = C(z)$ and\n$\\hat{M}_0 = \\hat{M}_0(z)$, the angular-diameter distance and the density per\nsource counted, respectively, when $\\Lambda \\neq 0$, analogous to those we have\nfor $\\Lambda = 0$. More importantly, we verify that for flat FLRW models\n$z_{max}$ -- as is already known but rarely recognized -- the redshift of\n$C_{max}$, the maximum of the angular-diameter-distance, uniquely gives\n$\\Omega_{\\Lambda}$, the amount of vacuum energy in the universe, independently\nof $H_0$, the Hubble parameter. For non-flat models determination of both\n$z_{max}$ and $C_{max}$ gives both $\\Omega_{\\Lambda}$ and $\\Omega_M$, the\namount of matter in the universe, as long as we know $H_0$ independently.\nFinally, determination of $C_{max}$ automatically gives a very simple\nobservational criterion for whether or not the universe is flat -- presuming\nthat it is FLRW.\n\n", "human_text": "  The plethora of recent cosmologically relevant data has indicated that our\nuniverse is very well fit by a standard Friedmann-Lema\\^{i}tre-Robertson-Walker\n(FLRW) model, with $\\Omega_{M} \\approx 0.27$ and $\\Omega_{\\Lambda} \\approx\n0.73$ -- or, more generally, by nearly flat FLRW models with parameters close\nto these values. Additional independent cosmological information, particularly\nthe maximum of the angular-diameter (observer-area) distance and the redshift\nat which it occurs, would improve and confirm these results, once sufficient\nprecise Supernovae Ia data in the range $1.5 < z < 1.8$ become available. We\nobtain characteristic FLRW closed functional forms for $C = C(z)$ and\n$\\hat{M}_0 = \\hat{M}_0(z)$, the angular-diameter distance and the density per\nsource counted, respectively, when $\\Lambda \\neq 0$, analogous to those we have\nfor $\\Lambda = 0$. More importantly, we verify that for flat FLRW models\n$z_{max}$ -- as is already known but rarely recognized -- the redshift of\n$C_{max}$, the maximum of the angular-diameter-distance, uniquely gives\n$\\Omega_{\\Lambda}$, the amount of vacuum energy in the universe, independently\nof $H_0$, the Hubble parameter. For non-flat models determination of both\n$z_{max}$ and $C_{max}$ gives both $\\Omega_{\\Lambda}$ and $\\Omega_M$, the\namount of matter in the universe, as long as we know $H_0$ independently.\nFinally, determination of $C_{max}$ automatically gives a very simple\nobservational criterion for whether or not the universe is flat -- presuming\nthat it is FLRW.\n", "machine_text": "Recent research has investigated the universe as a Friedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) model, supported by a wealth of cosmologically significant data. This model strongly indicates a flat FLRW universe nearly equal parts matter and vacuum energy -- $\\Omega_{M} \\approx 0.27$, $\\Omega_{\\Lambda} \\approx 0.73$. While more precise data from Supernovae Ia in the range $1.5 < z < 1.8$ would support these findings, another independent cosmological metric also offers potential benefits. Determining the maximum value of the angular-diameter-distance -- its value for $\\Lambda \\neq 0$ or $\\Lambda = 0$ -- and the redshift at which this occurs has been identified as an appropriate measure. When $\\Lambda = 0$ and the FLRW model is flat, the redshift of maximum angular-diameter-distance gives a unique value for $\\Omega_{\\Lambda}$ without the need to factor in the Hubble parameter. By including the redshift, this measure can also determine values for $\\Omega_M$ and $\\Omega_{\\Lambda}$ for non-flat FLRW models provided the value for the Hubble parameter is determined independently. Ultimately, with an understanding of the maximum angular-diameter-distance and its redshift, it is possible to determine the flatness of the universe given a Friedmann-Lema\\^{i}tre-Robertson-Walker model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1846}
{"prompt": "Rephrase the abstract of an article with title 'Relativistic Effects in Extreme Mass Ratio Gravitational Wave Bursts'.\n  Extreme mass ratio bursts (EMRBs) have been proposed as a possible source for\nfuture space-borne gravitational wave detectors, such as the Laser\nInterferometer Space Antenna (LISA). These events are characterized by\nlong-period, nearly-radial orbits of compact objects around a central massive\nblack hole. The gravitational radiation emitted during such events consists of\na short burst, corresponding to periapse passage, followed by a longer, silent\ninterval. In this paper we investigate the impact of including relativistic\ncorrections to the description of the compact object's trajectory via a\ngeodesic treatment, as well as including higher-order multipole corrections in\nthe waveform calculation. The degree to which the relativistic corrections are\nimportant depends on the EMRB's orbital parameters. We find that relativistic\nEMRBs (v_{max}}/c > 0.25) are not rare and actually account for approximately\nhalf of the events in our astrophysical model. The relativistic corrections\ntend to significantly change the waveform amplitude and phase relative to a\nNewtonian description, although some of this dephasing could be mimicked by\nparameter errors. The dephasing over several bursts could be of particular\nimportance not only to gravitational wave detection, but also to parameter\nestimation, since it is highly correlated to the spin of the massive black\nhole. Consequently, we postulate that if a relativistic EMRB is detected, such\ndephasing might be used to probe the relativistic character of the massive\nblack hole and obtain information about its spin.\n\n", "human_text": "  Extreme mass ratio bursts (EMRBs) have been proposed as a possible source for\nfuture space-borne gravitational wave detectors, such as the Laser\nInterferometer Space Antenna (LISA). These events are characterized by\nlong-period, nearly-radial orbits of compact objects around a central massive\nblack hole. The gravitational radiation emitted during such events consists of\na short burst, corresponding to periapse passage, followed by a longer, silent\ninterval. In this paper we investigate the impact of including relativistic\ncorrections to the description of the compact object's trajectory via a\ngeodesic treatment, as well as including higher-order multipole corrections in\nthe waveform calculation. The degree to which the relativistic corrections are\nimportant depends on the EMRB's orbital parameters. We find that relativistic\nEMRBs (v_{max}}/c > 0.25) are not rare and actually account for approximately\nhalf of the events in our astrophysical model. The relativistic corrections\ntend to significantly change the waveform amplitude and phase relative to a\nNewtonian description, although some of this dephasing could be mimicked by\nparameter errors. The dephasing over several bursts could be of particular\nimportance not only to gravitational wave detection, but also to parameter\nestimation, since it is highly correlated to the spin of the massive black\nhole. Consequently, we postulate that if a relativistic EMRB is detected, such\ndephasing might be used to probe the relativistic character of the massive\nblack hole and obtain information about its spin.\n", "machine_text": "This study investigates the influence of relativistic corrections when describing extreme mass ratio bursts (EMRBs) that can be observed by future space-borne gravitational wave detectors, such as the Laser Interferometer Space Antenna (LISA). We found that the relativistic effects can drastically alter the amplitude and phase of the waveforms in contrast to those of a Newtonian description. We also propose that identifying and measuring the dephasing across multiple EMRBs could be used to measure the spin of the central massive black hole, allowing us to probe its relativistic character.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2612}
{"prompt": "Rephrase the abstract of an article with title 'A novel quasi-exactly solvable spin chain with nearest-neighbors\n  interactions'.\n  In this paper we study a novel spin chain with nearest-neighbors interactions\ndepending on the sites coordinates, which in some sense is intermediate between\nthe Heisenberg chain and the spin chains of Haldane-Shastry type. We show that\nwhen the number of spins is sufficiently large both the density of sites and\nthe strength of the interaction between consecutive spins follow the Gaussian\nlaw. We develop an extension of the standard freezing trick argument that\nenables us to exactly compute a certain number of eigenvalues and their\ncorresponding eigenfunctions. The eigenvalues thus computed are all integers,\nand in fact our numerical studies evidence that these are the only integer\neigenvalues of the chain under consideration. This fact suggests that this\nchain can be regarded as a finite-dimensional analog of the class of\nquasi-exactly solvable Schroedinger operators, which has been extensively\nstudied in the last two decades. We have applied the method of moments to study\nsome statistical properties of the chain's spectrum, showing in particular that\nthe density of eigenvalues follows a Wigner-like law. Finally, we emphasize\nthat, unlike the original freezing trick, the extension thereof developed in\nthis paper can be applied to spin chains whose associated dynamical spin model\nis only quasi-exactly solvable.\n\n", "human_text": "  In this paper we study a novel spin chain with nearest-neighbors interactions\ndepending on the sites coordinates, which in some sense is intermediate between\nthe Heisenberg chain and the spin chains of Haldane-Shastry type. We show that\nwhen the number of spins is sufficiently large both the density of sites and\nthe strength of the interaction between consecutive spins follow the Gaussian\nlaw. We develop an extension of the standard freezing trick argument that\nenables us to exactly compute a certain number of eigenvalues and their\ncorresponding eigenfunctions. The eigenvalues thus computed are all integers,\nand in fact our numerical studies evidence that these are the only integer\neigenvalues of the chain under consideration. This fact suggests that this\nchain can be regarded as a finite-dimensional analog of the class of\nquasi-exactly solvable Schroedinger operators, which has been extensively\nstudied in the last two decades. We have applied the method of moments to study\nsome statistical properties of the chain's spectrum, showing in particular that\nthe density of eigenvalues follows a Wigner-like law. Finally, we emphasize\nthat, unlike the original freezing trick, the extension thereof developed in\nthis paper can be applied to spin chains whose associated dynamical spin model\nis only quasi-exactly solvable.\n", "machine_text": "In this article, we look at a novel spin chain with nearest-neighbor interactions that falls between Heisenberg's chain and the spin chains of the Haldane-Shastry type. We demonstrate that when the number of spins is large enough, the locations of the sites and the interaction strengths can follow a Gaussian distribution. We introduce an advanced version of the freezing trick technique which helps us to precisely ascertain an array of eigenvalues and connected eigenfunctions. This is remarkable since the resultant eigenvalues are integers, hinting at the possibility of this chain being a finite-dimensional variant of the quasi-exactly solvable Schroedinger operators. Furthermore, we apply the method of moments to learn some of the statistical properties of the chain's spectrum, particularly showing that the eigenvalues follow a Wigner-type law. Finally, we emphasize that different from the original freezing trick, the improved approach developed here can be applied to spin chains whose dynamics only offer a quasi-exact solvability.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3046}
{"prompt": "Rephrase the abstract of an article with title 'Very High Energy Gamma-ray Radiation from the Stellar-mass Black Hole\n  Cygnus X-1'.\n  We report on the results from the observations in very high energy band (VHE,\nE_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The\nobservations were performed with the MAGIC telescope, for a total of 40 hours\nduring 26 nights, spanning the period between June and November 2006. Searches\nfor steady gamma-ray signals yielded no positive result and upper limits to the\nintegral flux ranging between 1 and 2% of the Crab nebula flux, depending on\nthe energy, have been established. We also analyzed each observation night\nindependently, obtaining evidence of gamma-ray signals at the 4.0 standard\ndeviations (sigma) significance level (3.2 sigma after trial correction) for\n154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41\nUTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search\nfor faster-varying signals within a night resulted in an excess with a\nsignificance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT\nbetween 22h17 and 23h41 UTC. The measured excess is compatible with a\npoint-like source at the position of Cygnus X-1, and excludes the nearby radio\nnebula powered by its relativistic jet. The differential energy spectrum is\nwell fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x\n10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of\nVHE emission from a stellar-mass black hole, and therefore from a confirmed\naccreting X-ray binary.\n\n", "human_text": "  We report on the results from the observations in very high energy band (VHE,\nE_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The\nobservations were performed with the MAGIC telescope, for a total of 40 hours\nduring 26 nights, spanning the period between June and November 2006. Searches\nfor steady gamma-ray signals yielded no positive result and upper limits to the\nintegral flux ranging between 1 and 2% of the Crab nebula flux, depending on\nthe energy, have been established. We also analyzed each observation night\nindependently, obtaining evidence of gamma-ray signals at the 4.0 standard\ndeviations (sigma) significance level (3.2 sigma after trial correction) for\n154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41\nUTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search\nfor faster-varying signals within a night resulted in an excess with a\nsignificance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT\nbetween 22h17 and 23h41 UTC. The measured excess is compatible with a\npoint-like source at the position of Cygnus X-1, and excludes the nearby radio\nnebula powered by its relativistic jet. The differential energy spectrum is\nwell fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x\n10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of\nVHE emission from a stellar-mass black hole, and therefore from a confirmed\naccreting X-ray binary.\n", "machine_text": "\nIn this paper, we present the results of the observations of the stellar-mass black hole Cygnus X-1 in the very high energy (VHE, E_gamma > 100 GeV) gamma-ray band. The observations were conducted with the MAGIC telescope over 26 nights between June and November 2006 for a total of 40 hours. Although overall no significant gamma-ray signals were identified, a 4.0 standard deviations (sigma) significance level (3.2 sigma after trial correction) for 154 minutes effective on-time (EOT) was observed on September 24th between 20h58 and 23h41 UTC, coinciding with an X-ray flare documented by RXTE, Swift and INTEGRAL. Furthermore, 79 minutes EOT during this period provided excess with a significance of 4.9 sigma (4.1 sigma after trial correction). The measured excess matches a point-like source at the position of Cygnus X-1, indicating a potential emission of VHE radiation from this stellar-mass black hole system. The differential energy spectrum agrees with an unbroken power-law with a rate of dN/(dA dt dE) = (2.3+- 0.6) x 10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. These findings provide the first evidence of VHE gamma-rays from a confirmed accreting X-ray binary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1505}
{"prompt": "Rephrase the abstract of an article with title 'Detailed Spectral Analysis of the Type Ib Supernova 1999dn. Paper I:\n  Hydrogen-free Models'.\n  We present spectral fits to five epochs of the typical Type Ib supernova\n1999dn using the generalized, non-LTE, stellar atmospheres code PHOENIX. Our\ngoal is threefold: to determine basic physical properties of the supernova\nejecta, such as velocity, temperature, and density gradients; to reproduce He I\nabsorption lines by invoking non-thermal excitation; and, to investigate\npossible spectral signatures of hydrogen, especially a feature around 6200\nAngstrom, which has been attributed to high velocity $H_\\alpha$. Our models\nassume an atmosphere with uniform composition devoid of any hydrogen. Our model\nspectra fit the observed spectra well, successfully reproducing most of the\nfeatures, including the prominent He I absorptions. The most plausible\nalternative to $H_\\alpha$ as the source of the 6200 Angstrom feature is a blend\nof Fe II and Si II lines, which can be made stronger to fit the observed\nfeature better by increasing the metallicity of the ejecta. High-metallicity\nmodels fit well at early epochs, but not as well as solar-metallicity models\nafter maximum light. While this blend of metal lines is a reasonable\nexplanation of the source of the 6200 Angstrom feature, it is still important\nto investigate hydrogen as the source; therefore, a second paper will present\nmodels that include a thin shell of hydrogen around the main composition\nstructure.\n\n", "human_text": "  We present spectral fits to five epochs of the typical Type Ib supernova\n1999dn using the generalized, non-LTE, stellar atmospheres code PHOENIX. Our\ngoal is threefold: to determine basic physical properties of the supernova\nejecta, such as velocity, temperature, and density gradients; to reproduce He I\nabsorption lines by invoking non-thermal excitation; and, to investigate\npossible spectral signatures of hydrogen, especially a feature around 6200\nAngstrom, which has been attributed to high velocity $H_\\alpha$. Our models\nassume an atmosphere with uniform composition devoid of any hydrogen. Our model\nspectra fit the observed spectra well, successfully reproducing most of the\nfeatures, including the prominent He I absorptions. The most plausible\nalternative to $H_\\alpha$ as the source of the 6200 Angstrom feature is a blend\nof Fe II and Si II lines, which can be made stronger to fit the observed\nfeature better by increasing the metallicity of the ejecta. High-metallicity\nmodels fit well at early epochs, but not as well as solar-metallicity models\nafter maximum light. While this blend of metal lines is a reasonable\nexplanation of the source of the 6200 Angstrom feature, it is still important\nto investigate hydrogen as the source; therefore, a second paper will present\nmodels that include a thin shell of hydrogen around the main composition\nstructure.\n", "machine_text": "\nWe present the analysis of the Type Ib supernova 1999dn in five epochs through non-LTE stellar atmosphere spectra based on PHOENIX. The objective of this study is threefold: to compute the ejecta physical parameters such as temperature, density, and velocity; to reproduce the He I absorption lines by non-thermal excitation; and to explore the possible presence of hydrogen, primarily through a feature around 6200 Angstrom that has been attributed to high velocity H$_\\alpha$. All models have a uniform composition with no hydrogen. The results show our models fit the observations, accurately reproducing most of the features including He I absorptions. We consider the combination of Fe II and Si II lines as a stronger substitute for H$_\\alpha$ as a source for the 6200 Angstrom feature, which we can achieve by increasing the metallicity viewpoint. High metallicity models match early epochs, though not as optimal than solar metallicity models after the maximum brightness is attained. In addition, a further investigation of hydrogen as a potential source of the 6200 Angstrom feature will be addressed in our second paper with models involving a thin shell of hydrogen surrounding the main composition.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4086}
{"prompt": "Rephrase the abstract of an article with title 'Impact of Ion Clearing Electrodes on Beam Dynamics in DAFNE'.\n  Presently clearing electrodes are being considered as a possible cure of\ne-cloud driven problems in existing and future colliders. 'Invisible'\nelectrodes, made of a thin highly resistive layer pasted on a dielectric plate,\nhave been proposed as one of design solutions for the e-cloud clearing. For the\nfirst time such electrodes were successfully used in the electron-positron\naccumulator (EPA) of LEP. Similar electrodes had been using for a long time for\nion clearing purposes in the DAFNE electron ring. Theoretical considerations\nand experimental measurements at DAFNE have revealed a substantial contribution\nof the ion clearing electrodes (ICE) to the machine broad-band impedance giving\nrise to several harmful effects degrading the collider performance. In this\npaper we discuss the impact of the electrodes on DAFNE beam dynamics, show the\nresults of ICE wake field and impedance calculations and compare them with\navailable experimental data. We also describe the procedure of ICE removal from\nthe wiggler sections of the electron ring that has resulted in remarkable\nimprovements in terms of beam dynamics and geometric luminosity.\n\n", "human_text": "  Presently clearing electrodes are being considered as a possible cure of\ne-cloud driven problems in existing and future colliders. 'Invisible'\nelectrodes, made of a thin highly resistive layer pasted on a dielectric plate,\nhave been proposed as one of design solutions for the e-cloud clearing. For the\nfirst time such electrodes were successfully used in the electron-positron\naccumulator (EPA) of LEP. Similar electrodes had been using for a long time for\nion clearing purposes in the DAFNE electron ring. Theoretical considerations\nand experimental measurements at DAFNE have revealed a substantial contribution\nof the ion clearing electrodes (ICE) to the machine broad-band impedance giving\nrise to several harmful effects degrading the collider performance. In this\npaper we discuss the impact of the electrodes on DAFNE beam dynamics, show the\nresults of ICE wake field and impedance calculations and compare them with\navailable experimental data. We also describe the procedure of ICE removal from\nthe wiggler sections of the electron ring that has resulted in remarkable\nimprovements in terms of beam dynamics and geometric luminosity.\n", "machine_text": "This paper examines the effect of the ion clearing electrodes in the DAFNE electron ring. We analyze the theoretical models and the experimental data concerning the contribution of ICE to the machine broad-band impedance. We observe that these electrodes lead to several negative consequences for the overall performance of the collider. We report on our investigation of the ICE wake field and impedance calculations, as well as on the effects of the ICE removal from the electron's wiggler sections. This resulted in an improvement of the beam dynamics, luminosity and overall performance of the collider.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1223}
{"prompt": "Rephrase the abstract of an article with title 'Room temperature spin polarized magnetic semiconductor'.\n  Alternating layers of granular Iron (Fe) and Titanium dioxide\n(TiO$_{2-\\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$)\nsubstrates in low oxygen chamber pressure using a controlled pulsed laser\nablation deposition technique. The total thickness of the film was about 200\nnm. The films show ferromagnetic behavior for temperatures ranging from 4 to\n$400 ^oK$. The layered film structure was characterized as p-type magnetic\nsemiconductor at $300 ^oK$ with a carrier density of the order of $10^{20}\n/cm^3$. The undoped pure TiO$_{2-\\delta}$ film was characterized as an n-type\nmagnetic semiconductor. The hole carriers were excited at the interface between\nthe granular Fe and TiO$_{2-\\delta}$ layers similar to holes excited in the\nmetal/n-type semiconductor interface commonly observed in\nMetal-Oxide-Semiconductor (MOS) devices. The holes at the interface were\npolarized in an applied magnetic field raising the possibility that these\ngranular MOS structures can be utilized for practical spintronic device\napplications.\n\n", "human_text": "  Alternating layers of granular Iron (Fe) and Titanium dioxide\n(TiO$_{2-\\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$)\nsubstrates in low oxygen chamber pressure using a controlled pulsed laser\nablation deposition technique. The total thickness of the film was about 200\nnm. The films show ferromagnetic behavior for temperatures ranging from 4 to\n$400 ^oK$. The layered film structure was characterized as p-type magnetic\nsemiconductor at $300 ^oK$ with a carrier density of the order of $10^{20}\n/cm^3$. The undoped pure TiO$_{2-\\delta}$ film was characterized as an n-type\nmagnetic semiconductor. The hole carriers were excited at the interface between\nthe granular Fe and TiO$_{2-\\delta}$ layers similar to holes excited in the\nmetal/n-type semiconductor interface commonly observed in\nMetal-Oxide-Semiconductor (MOS) devices. The holes at the interface were\npolarized in an applied magnetic field raising the possibility that these\ngranular MOS structures can be utilized for practical spintronic device\napplications.\n", "machine_text": "\nThis paper details a method of pulsed laser ablation deposition utilized to construct an alternating layer thickness of granular Iron and Titanium dioxide on a Lanthanum aluminate substrate, yielding a total thickness of approximately 200 nm. Upon analysis, the composed film structure was classified as a p-type magnetic semiconductor at 300 K, demonstrating ferromagnetic behaviour from 4 to 400 K, and with a carrier density of 10$^{20}$/cm$^3$. The undoped Titanium dioxide film showed characteristics of an n-type magnetic semiconductor. The holes present at the interface between the Iron and Titanium dioxide layers reacted to an applied magnetic field, implying the potential for spintronic applications.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2993}
{"prompt": "Rephrase the abstract of an article with title 'Dimer Models, Free Fermions and Super Quantum Mechanics'.\n  This note relates topics in statistical mechanics, graph theory and\ncombinatorics, lattice quantum field theory, super quantum mechanics and string\ntheory. We give a precise relation between the dimer model on a graph embedded\non a torus and the massless free Majorana fermion living on the same lattice. A\nloop expansion of the fermion determinant is performed, where the loops turn\nout to be compositions of two perfect matchings. These loop states are sorted\ninto co-chain groups using categorification techniques similar to the ones used\nfor categorifying knot polynomials. The Euler characteristic of the resulting\nco-chain complex recovers the Newton polynomial of the dimer model. We\nre-interpret this system as supersymmetric quantum mechanics, where\nconfigurations with vanishing net winding number form the ground states.\nFinally, we make use of the quiver gauge theory - dimer model correspondence to\nobtain an interpretation of the loops in terms of the physics of D-branes\nprobing a toric Calabi-Yau singularity.\n\n", "human_text": "  This note relates topics in statistical mechanics, graph theory and\ncombinatorics, lattice quantum field theory, super quantum mechanics and string\ntheory. We give a precise relation between the dimer model on a graph embedded\non a torus and the massless free Majorana fermion living on the same lattice. A\nloop expansion of the fermion determinant is performed, where the loops turn\nout to be compositions of two perfect matchings. These loop states are sorted\ninto co-chain groups using categorification techniques similar to the ones used\nfor categorifying knot polynomials. The Euler characteristic of the resulting\nco-chain complex recovers the Newton polynomial of the dimer model. We\nre-interpret this system as supersymmetric quantum mechanics, where\nconfigurations with vanishing net winding number form the ground states.\nFinally, we make use of the quiver gauge theory - dimer model correspondence to\nobtain an interpretation of the loops in terms of the physics of D-branes\nprobing a toric Calabi-Yau singularity.\n", "machine_text": "\nThis article examines the overlapping intersections between statistical mechanics, graph theory and combinatorics, lattice quantum field theory, super quantum mechanics and string theory. Using the dimer model on a graph embedded on a torus and the massless, free Majorana fermion living on the same lattice, a loop expansion of the fermion determinant is determined. The loops are then classified into co-chain groups through categorification, with the Euler characteristic of the resulting co-chain complex being identical to the Newton polynomial of the dimer model. Exploring the same system further, configuration with vanishing net winding number were found to form the ground states suggesting a connection to supersymmetric quantum mechanics. With the use of the quiver gauge theory - dimer model correspondence, furthermore, this article reveals how the loops are in fact related to the physics of the D-branes probing a toric Calabi-Yau singularity.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1645}
{"prompt": "Rephrase the abstract of an article with title 'Diversity-Multiplexing Tradeoff via Asymptotic Analysis of Large MIMO\n  Systems'.\n  Diversity-multiplexing tradeoff (DMT) presents a compact framework to compare\nvarious MIMO systems and channels in terms of the two main advantages they\nprovide (i.e. high data rate and/or low error rate). This tradeoff was\ncharacterized asymptotically (SNR-> infinity) for i.i.d. Rayleigh fading\nchannel by Zheng and Tse [1]. The asymptotic DMT overestimates the finite-SNR\none [2]. In this paper, using the recent results on the asymptotic (in the\nnumber of antennas) outage capacity distribution, we derive and analyze the\nfinite-SNR DMT for a broad class of channels (not necessarily Rayleigh fading).\nBased on this, we give the convergence conditions for the asymptotic DMT to be\napproached by the finite-SNR one. The multiplexing gain definition is shown to\naffect critically the convergence point: when the multiplexing gain is defined\nvia the mean (ergodic) capacity, the convergence takes place at realistic SNR\nvalues. Furthermore, in this case the diversity gain can also be used to\nestimate the outage probability with reasonable accuracy. The multiplexing gain\ndefinition via the high-SNR asymptote of the mean capacity (as in [1]) results\nin very slow convergence for moderate to large systems (as 1/ln(SNR)^2) and,\nhence, the asymptotic DMT cannot be used at realistic SNR values. For this\ndefinition, the high-SNR threshold increases exponentially in the number of\nantennas and in the multiplexing gain. For correlated keyhole channel, the\ndiversity gain is shown to decrease with correlation and power imbalance of the\nchannel. While the SNR-asymptotic DMT of Zheng and Tse does not capture this\neffect, the size-asymptotic DMT does.\n\n", "human_text": "  Diversity-multiplexing tradeoff (DMT) presents a compact framework to compare\nvarious MIMO systems and channels in terms of the two main advantages they\nprovide (i.e. high data rate and/or low error rate). This tradeoff was\ncharacterized asymptotically (SNR-> infinity) for i.i.d. Rayleigh fading\nchannel by Zheng and Tse [1]. The asymptotic DMT overestimates the finite-SNR\none [2]. In this paper, using the recent results on the asymptotic (in the\nnumber of antennas) outage capacity distribution, we derive and analyze the\nfinite-SNR DMT for a broad class of channels (not necessarily Rayleigh fading).\nBased on this, we give the convergence conditions for the asymptotic DMT to be\napproached by the finite-SNR one. The multiplexing gain definition is shown to\naffect critically the convergence point: when the multiplexing gain is defined\nvia the mean (ergodic) capacity, the convergence takes place at realistic SNR\nvalues. Furthermore, in this case the diversity gain can also be used to\nestimate the outage probability with reasonable accuracy. The multiplexing gain\ndefinition via the high-SNR asymptote of the mean capacity (as in [1]) results\nin very slow convergence for moderate to large systems (as 1/ln(SNR)^2) and,\nhence, the asymptotic DMT cannot be used at realistic SNR values. For this\ndefinition, the high-SNR threshold increases exponentially in the number of\nantennas and in the multiplexing gain. For correlated keyhole channel, the\ndiversity gain is shown to decrease with correlation and power imbalance of the\nchannel. While the SNR-asymptotic DMT of Zheng and Tse does not capture this\neffect, the size-asymptotic DMT does.\n", "machine_text": "\nThe tradeoff between data rate and error rate is encapsulated in the concept of diversity-multiplexing tradeoff (DMT). While this tradeoff has been characterized asymptotically (in SNR) for Independent and Identically Distributed (i.i.d.) Rayleigh fading channel by Zheng and Tse [1], this paper makes an effort to extend the asymptotic analysis to a broad class of channels, including those which are not necessarily Rayleigh fading. Using the existing results of the asymptotic outage capacity distributions,this paper explores the finite SNR DMT which is expected to be a more accurate representation than its asymptotic counterpart. Moreover, the definition of multiplexing gain affects the speed of convergence of the finite SNR DMT to its asymptotic version. The outline of conditions under which the asymptotic DMT converges to the finite SNR one are especially useful when the multiplexing gain is defined via the mean (ergodic) capacity, converging at feasible SNR values. Furthermore, this paper highlights the effects of scenarios such as correlation and power imbalance, which are expected to reduce the diversity gain for correlated keyhole channels. All these scenarios are not captured by the SNR-asymptotic DMT of Zheng and Tse but are elucidated by the size-asymptotic DMT.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1336}
{"prompt": "Rephrase the abstract of an article with title 'Super Star Cluster NGC1705-1: A Local Analogue to the Birthsite of\n  Long-duration Gamma-ray Bursts'.\n  Recent observations suggest that global properties of the host galaxies for\nlong-duration gamma-ray bursts (GRBs) are particularly well-suited for creating\nthe massive star progenitors of these GRBs. Motivated by the hypothesis that\nmassive young star clusters located in metal-poor, low-metallicity galaxies are\na natural birthsite for GRB progenitors, we present a comparison study of the\nISM properties along the sightline toward the super star cluster, NGC1705-1,\nand those in distant GRB hosts. Using the same set of metal transitions in the\nUV and applying known ISM structures in NGC1705, we find that NGC1705-1\nresembles distant GRB host galaxies in its high neutral gas column, low\nmolecular gas fraction, low metallicity, alpha-element enhancement,and low dust\ndepletion. The lack of molecular gas is due to the enhanced UV radiation field\nin the starburst environment, consistent with the expectations for GRB\nprogenitors. In addition, the known presence of dense neutral gas clouds at\nr<500 pc from NGC1705-1 provides a natural reservoir of C^+, Si^+, and Fe^+\nions that may be subsequently excited by the afterglow UV radiation field to\nproduce excited lines commonly seen in GRB host ISM. We further argue that the\napparent offset in the velocity profiles of low- and high-ionization\ntransitions from absorption-line observations alone already offers important\nclues for related starburst episodes in GRB host galaxies. Our study shows that\na statistical comparison between the ISM around star clusters and high-redshift\nGRB progenitors is important for identifying the key physical parameters that\nfacilitate the formation of GRBs.\n\n", "human_text": "  Recent observations suggest that global properties of the host galaxies for\nlong-duration gamma-ray bursts (GRBs) are particularly well-suited for creating\nthe massive star progenitors of these GRBs. Motivated by the hypothesis that\nmassive young star clusters located in metal-poor, low-metallicity galaxies are\na natural birthsite for GRB progenitors, we present a comparison study of the\nISM properties along the sightline toward the super star cluster, NGC1705-1,\nand those in distant GRB hosts. Using the same set of metal transitions in the\nUV and applying known ISM structures in NGC1705, we find that NGC1705-1\nresembles distant GRB host galaxies in its high neutral gas column, low\nmolecular gas fraction, low metallicity, alpha-element enhancement,and low dust\ndepletion. The lack of molecular gas is due to the enhanced UV radiation field\nin the starburst environment, consistent with the expectations for GRB\nprogenitors. In addition, the known presence of dense neutral gas clouds at\nr<500 pc from NGC1705-1 provides a natural reservoir of C^+, Si^+, and Fe^+\nions that may be subsequently excited by the afterglow UV radiation field to\nproduce excited lines commonly seen in GRB host ISM. We further argue that the\napparent offset in the velocity profiles of low- and high-ionization\ntransitions from absorption-line observations alone already offers important\nclues for related starburst episodes in GRB host galaxies. Our study shows that\na statistical comparison between the ISM around star clusters and high-redshift\nGRB progenitors is important for identifying the key physical parameters that\nfacilitate the formation of GRBs.\n", "machine_text": "\nRecent findings demonstrate that the galaxies which host long-duration gamma-ray bursts (GRBs) are highly suitable for the formation of massive stars which give rise to the GRBs. To find out how well the interstellar medium (ISM) characteristics along the line of sight of the Super Star Cluster, NGC1705-1, aligns with that of distant GRB hosts, we conducted a comparison study. We looked at the same set of metal transitions in the UV and used related ISM structures in NGC1705-1. We noted that the UV radiation field in the starburst environment is the cause of lack of molecular gas and the other ISM traits in NGC1705-1 resemble that of distant GRB hosts with high neutral gas column, low molecular gas fraction, low metallicity, alpha-element enhancement as well as low dust depletion. Furthermore, we concurred that the afterglow UV radiation from the GRB excites C^+, Si^+ and Fe^+ ions in the neutral gas clouds located at a distance of 500 pc from NGC1705-1, producing excited lines commonly observed in GRB host ISM. We concluded that a comparative assessment of star clusters and high-redshift GRB progenitors is a promising method to identify the eminent physical properties essential to the GRB\u2019s emergence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2364}
{"prompt": "Rephrase the abstract of an article with title 'Dark Energy and Gravity'.\n  I review the problem of dark energy focusing on the cosmological constant as\nthe candidate and discuss its implications for the nature of gravity. Part 1\nbriefly overviews the currently popular `concordance cosmology' and summarises\nthe evidence for dark energy. It also provides the observational and\ntheoretical arguments in favour of the cosmological constant as the candidate\nand emphasises why no other approach really solves the conceptual problems\nusually attributed to the cosmological constant. Part 2 describes some of the\napproaches to understand the nature of the cosmological constant and attempts\nto extract the key ingredients which must be present in any viable solution. I\nargue that (i)the cosmological constant problem cannot be satisfactorily solved\nuntil gravitational action is made invariant under the shift of the matter\nlagrangian by a constant and (ii) this cannot happen if the metric is the\ndynamical variable. Hence the cosmological constant problem essentially has to\ndo with our (mis)understanding of the nature of gravity. Part 3 discusses an\nalternative perspective on gravity in which the action is explicitly invariant\nunder the above transformation. Extremizing this action leads to an equation\ndetermining the background geometry which gives Einstein's theory at the lowest\norder with Lanczos-Lovelock type corrections. (Condensed abstract).\n\n", "human_text": "  I review the problem of dark energy focusing on the cosmological constant as\nthe candidate and discuss its implications for the nature of gravity. Part 1\nbriefly overviews the currently popular `concordance cosmology' and summarises\nthe evidence for dark energy. It also provides the observational and\ntheoretical arguments in favour of the cosmological constant as the candidate\nand emphasises why no other approach really solves the conceptual problems\nusually attributed to the cosmological constant. Part 2 describes some of the\napproaches to understand the nature of the cosmological constant and attempts\nto extract the key ingredients which must be present in any viable solution. I\nargue that (i)the cosmological constant problem cannot be satisfactorily solved\nuntil gravitational action is made invariant under the shift of the matter\nlagrangian by a constant and (ii) this cannot happen if the metric is the\ndynamical variable. Hence the cosmological constant problem essentially has to\ndo with our (mis)understanding of the nature of gravity. Part 3 discusses an\nalternative perspective on gravity in which the action is explicitly invariant\nunder the above transformation. Extremizing this action leads to an equation\ndetermining the background geometry which gives Einstein's theory at the lowest\norder with Lanczos-Lovelock type corrections. (Condensed abstract).\n", "machine_text": "\nThis article reviews the problem of dark energy and its implications for the nature of gravity, with the cosmological constant as the leading candidate. We first explore the concordance cosmology, and review the evidence for dark energy as well as the theoretical and observational arguments in favor of the cosmological constant. We then outline some possible approaches towards understanding the nature of the cosmological constant and extracting the key ingredients that must be incorporated in a viable solution. Finally, we discuss an alternative perspective on gravity in which the action is efficiently invariant under the shift of the matter lagrangian. This leads to a background equation. Evaluating this equation leads to Einstein's theory at the lowest order, with Lanczos-Lovelock type corrections.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2533}
{"prompt": "Rephrase the abstract of an article with title 'A Close Look at Star Formation around Active Galactic Nuclei'.\n  We analyse star formation in the nuclei of 9 Seyfert galaxies at spatial\nresolutions down to 0.085arcsec, corresponding to length scales of less than\n10pc in some objects. Our data were taken mostly with the near infrared\nadaptive optics integral field spectrograph SINFONI. The stellar light profiles\ntypically have size scales of a few tens of parsecs. In two cases there is\nunambiguous kinematic evidence for stellar disks on these scales. In the\nnuclear regions there appear to have been recent - but no longer active -\nstarbursts in the last 10-300Myr. The stellar luminosity is less than a few\npercent of the AGN in the central 10pc, whereas on kiloparsec scales the\nluminosities are comparable. The surface stellar luminosity density follows a\nsimilar trend in all the objects, increasing steadily at smaller radii up to\n10^{13}L_sun/kpc^2 in the central few parsecs, where the mass surface density\nexceeds 10^4M_sun/pc^2. The intense starbursts were probably Eddington limited\nand hence inevitably short-lived, implying that the starbursts occur in\nmultiple short bursts. The data hint at a delay of 50--100Myr between the onset\nof star formation and subsequent fuelling of the black hole. We discuss whether\nthis may be a consequence of the role that stellar ejecta could play in\nfuelling the black hole. While a significant mass is ejected by OB winds and\nsupernovae, their high velocity means that very little of it can be accreted.\nOn the other hand winds from AGB stars ultimately dominate the total mass loss,\nand they can also be accreted very efficiently because of their slow speeds.\n\n", "human_text": "  We analyse star formation in the nuclei of 9 Seyfert galaxies at spatial\nresolutions down to 0.085arcsec, corresponding to length scales of less than\n10pc in some objects. Our data were taken mostly with the near infrared\nadaptive optics integral field spectrograph SINFONI. The stellar light profiles\ntypically have size scales of a few tens of parsecs. In two cases there is\nunambiguous kinematic evidence for stellar disks on these scales. In the\nnuclear regions there appear to have been recent - but no longer active -\nstarbursts in the last 10-300Myr. The stellar luminosity is less than a few\npercent of the AGN in the central 10pc, whereas on kiloparsec scales the\nluminosities are comparable. The surface stellar luminosity density follows a\nsimilar trend in all the objects, increasing steadily at smaller radii up to\n10^{13}L_sun/kpc^2 in the central few parsecs, where the mass surface density\nexceeds 10^4M_sun/pc^2. The intense starbursts were probably Eddington limited\nand hence inevitably short-lived, implying that the starbursts occur in\nmultiple short bursts. The data hint at a delay of 50--100Myr between the onset\nof star formation and subsequent fuelling of the black hole. We discuss whether\nthis may be a consequence of the role that stellar ejecta could play in\nfuelling the black hole. While a significant mass is ejected by OB winds and\nsupernovae, their high velocity means that very little of it can be accreted.\nOn the other hand winds from AGB stars ultimately dominate the total mass loss,\nand they can also be accreted very efficiently because of their slow speeds.\n", "machine_text": "\nWe have conducted an extensive study of star formation around Active Galactic Nuclei with data taken from the near infrared adaptive optics integral field spectrograph SINFONI. Our results show stellar light profiles of a few tens of parsecs with evidence for recent but inactive starbursts 10-300 million years ago. The stellar luminosity in the central 10pc is much lower than the AGN, but comparable on larger scales. Our analysis reveals a steadily increasing surface stellar luminosity density of up to 10^13L_sun/kpc^2 in the central few parsecs and a mass surface density of 10^4M_sun/pc^2. We postulate that the starbursts were likely Eddington limited and hence had relatively short lifespans, with a possible delay of 50-100 million years between the onset of star formation and subsequent fuelling of the black hole. The role of stellar ejecta in this process is discussed, suggesting that while a significant mass is ejected from OB winds and supernovae, AGB stars provide the largest mass loss at a slow enough speed to be accreted efficiently.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1374}
{"prompt": "Rephrase the abstract of an article with title 'Daemons and DAMA: Their Celestial-Mechanics Interrelations'.\n  The assumption of the capture by the Solar System of the electrically charged\nPlanckian DM objects (daemons) from the galactic disk is confirmed not only by\nthe St.Petersburg (SPb) experiments detecting particles with V<30 km/s. Here\nthe daemon approach is analyzed considering the positive model independent\nresult of the DAMA/NaI experiment. We explain the maximum in DAMA signals\nobserved in the May-June period to be associated with the formation behind the\nSun of a trail of daemons that the Sun captures into elongated orbits as it\nmoves to the apex. The range of significant 2-6-keV DAMA signals fits well the\niodine nuclei elastically knocked out of the NaI(Tl) scintillator by particles\nfalling on the Earth with V=30-50 km/s from strongly elongated heliocentric\norbits. The half-year periodicity of the slower daemons observed in SPb\noriginates from the transfer of particles that are deflected through ~90 deg\ninto near-Earth orbits each time the particles cross the outer reaches of the\nSun which had captured them. Their multi-loop (cross-like) trajectories\ntraverse many times the Earth's orbit in March and September, which increases\nthe probability for the particles to enter near-Earth orbits during this time.\nCorroboration of celestial mechanics calculations with observations yields\n~1e-19 cm2 for the cross section of daemon interaction with the solar matter.\n\n", "human_text": "  The assumption of the capture by the Solar System of the electrically charged\nPlanckian DM objects (daemons) from the galactic disk is confirmed not only by\nthe St.Petersburg (SPb) experiments detecting particles with V<30 km/s. Here\nthe daemon approach is analyzed considering the positive model independent\nresult of the DAMA/NaI experiment. We explain the maximum in DAMA signals\nobserved in the May-June period to be associated with the formation behind the\nSun of a trail of daemons that the Sun captures into elongated orbits as it\nmoves to the apex. The range of significant 2-6-keV DAMA signals fits well the\niodine nuclei elastically knocked out of the NaI(Tl) scintillator by particles\nfalling on the Earth with V=30-50 km/s from strongly elongated heliocentric\norbits. The half-year periodicity of the slower daemons observed in SPb\noriginates from the transfer of particles that are deflected through ~90 deg\ninto near-Earth orbits each time the particles cross the outer reaches of the\nSun which had captured them. Their multi-loop (cross-like) trajectories\ntraverse many times the Earth's orbit in March and September, which increases\nthe probability for the particles to enter near-Earth orbits during this time.\nCorroboration of celestial mechanics calculations with observations yields\n~1e-19 cm2 for the cross section of daemon interaction with the solar matter.\n", "machine_text": "This article discusses the relationship between daemons and celestial mechanics as it pertains to the DAMA/NaI experiment which observed the maximum signal in the May-June period. It suggests that this maximum is caused by a trail of daemons that become elongated orbits as the Sun moves, falling on the Earth with a velocity of 30-50 km/s. These daemons are observed in the St. Petersburg experiment and their half-year periodicity is caused by their crossing of the outer reaches of the Sun which capture them. Consequently, celestial mechanics calculations corroborated with observations have produced a cross-section of daemon interaction with the solar matter to be ~1e-19 cm2.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0982}
{"prompt": "Rephrase the abstract of an article with title 'Electronic structure of barium titanate : an abinitio DFT study'.\n  First principle calculations were performed to study the ground state\nelectronic properties of Barium titanate within the density functional theory\n(DFT). In our DFT computations, we used Vosko-Wilk-Nusair correlation energy\nfunctional and generalized gradient approximation (GGA) exchange and\ncorrelation energy functional as suggested by Perdew and Wang (PWGGA). The band\nstructure, total density of states (DOS) and partial DOS have been\nsystematically conducted to investigate the electronic configuration of this\nprototype ferroelectric perovskits compound. The band gap was 1.92 eV within\nour approach, and the quasi-flat band at -17 eV and -10 eV were attributed to\nthe O 2s and Ba 5p states respectively, which was in good agreement with the\ncorresponding total DOS and partial DOS. From the DOS investigation, it can be\nseen that the Ti eg state intended to interact with the oxygen octahedral\norbitals to form the p-d hybridization. Moreover the strong p-d overlap and\nbonding can be observed in the electronic density redistribution along the\ndifferent crystalline planes with respect to the corresponding space group, and\nthe electronic isodense have been shown along the (001), (100), (110) and (111)\ncrystal planes. From these electronic density maps, the strong bonding between\nTi and O atoms can even be observed in the (111) crystalline plane.\n\n", "human_text": "  First principle calculations were performed to study the ground state\nelectronic properties of Barium titanate within the density functional theory\n(DFT). In our DFT computations, we used Vosko-Wilk-Nusair correlation energy\nfunctional and generalized gradient approximation (GGA) exchange and\ncorrelation energy functional as suggested by Perdew and Wang (PWGGA). The band\nstructure, total density of states (DOS) and partial DOS have been\nsystematically conducted to investigate the electronic configuration of this\nprototype ferroelectric perovskits compound. The band gap was 1.92 eV within\nour approach, and the quasi-flat band at -17 eV and -10 eV were attributed to\nthe O 2s and Ba 5p states respectively, which was in good agreement with the\ncorresponding total DOS and partial DOS. From the DOS investigation, it can be\nseen that the Ti eg state intended to interact with the oxygen octahedral\norbitals to form the p-d hybridization. Moreover the strong p-d overlap and\nbonding can be observed in the electronic density redistribution along the\ndifferent crystalline planes with respect to the corresponding space group, and\nthe electronic isodense have been shown along the (001), (100), (110) and (111)\ncrystal planes. From these electronic density maps, the strong bonding between\nTi and O atoms can even be observed in the (111) crystalline plane.\n", "machine_text": "\nA theoretical density functional theory study was conducted to gain further insights into the electronic configuration of Barium titanate. The Vosko-Wilk-Nusair correlation energy functional combined with a generalized gradient approximation (GGA) exchange and correlation energy functional was used for the computations. The results obtained showed a band gap of 1.92 eV, along with quasi-flat bands at -17 eV and -10 eV due to the O 2s and Ba 5p states, respectively. Further, a p-d hybridization between Ti eg and oxygen octahedral orbitals was observed from the total density of states (DOS) and partial DOS analysis. Additionally, the electronic density redistribution along the different crystalline planes was used to show strong p-d overlap and bonding, and even strong bonding between the Ti and O atoms in the (111) crystalline plane was observed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2695}
{"prompt": "Rephrase the abstract of an article with title 'X-ray source counts in the COSMOS field'.\n  We present the analysis of the source counts in the XMM-COSMOS survey using\ndata of the first year of XMM-Newton observations. The survey covers ~2 deg^2\nwithin the region of sky bounded by 9^h57.5^m<R.A.<10^h03.5^m;\n1^d27.5^m<DEC<2^d57.5^m with a total net integration time of 504 ks. Using a\nmaximum likelihood algorithm we detected a total of 1390 sources at least in\none band. Using Monte Carlo simulations to estimate the sky coverage we\nproduced the logN-logS relations. These relations have been then derived in the\n0.5--2 keV, 2--10 keV and 5--10 keV energy bands, down to flux limits of\n7.2x10^-16 erg cm^-2 s^-1, 4.0x10^-15 erg cm^-2 s^-1 and 9.7x10^-15 erg cm^-2\ns^-1, respectively. These relations have been compared to previous X-ray survey\nand to the most recent X-ray background model finding an excellent agreement.\nThe slightly different normalizations observed in the source counts of COSMOS\nand previous surveys can be largely explained as a combination of low counting\nstatistics and cosmic variance introduced by the large scale structure.\n\n", "human_text": "  We present the analysis of the source counts in the XMM-COSMOS survey using\ndata of the first year of XMM-Newton observations. The survey covers ~2 deg^2\nwithin the region of sky bounded by 9^h57.5^m<R.A.<10^h03.5^m;\n1^d27.5^m<DEC<2^d57.5^m with a total net integration time of 504 ks. Using a\nmaximum likelihood algorithm we detected a total of 1390 sources at least in\none band. Using Monte Carlo simulations to estimate the sky coverage we\nproduced the logN-logS relations. These relations have been then derived in the\n0.5--2 keV, 2--10 keV and 5--10 keV energy bands, down to flux limits of\n7.2x10^-16 erg cm^-2 s^-1, 4.0x10^-15 erg cm^-2 s^-1 and 9.7x10^-15 erg cm^-2\ns^-1, respectively. These relations have been compared to previous X-ray survey\nand to the most recent X-ray background model finding an excellent agreement.\nThe slightly different normalizations observed in the source counts of COSMOS\nand previous surveys can be largely explained as a combination of low counting\nstatistics and cosmic variance introduced by the large scale structure.\n", "machine_text": "\nThe results of an XMM-Newton survey of the COSMOS field, measuring X-ray source counts, are presented in this article. This survey covers a ~2 deg^2 region of the sky over a total integration time of 504 ks and identified a total of 1390 sources. A Monte Carlo simulation was used to construct the logN-logS relations in the 0.5-2, 2-10 and 5-10 keV energy bands, with corresponding flux limits of 7.2x10^-16, 4.0x10^-15, and 9.7x10^-15 erg cm^-2 s^-1, respectively. The resulting counts were found to be consistent with previous X-ray surveys and the latest X-ray background modeling. The discrepancy between the source counts in COSMOS and those in the previously conducted surveys is likely the result of the combination of low-counting statistics and effects of cosmic variance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2293}
{"prompt": "Rephrase the abstract of an article with title 'Plasma effects in a micromachined floating-gate high-electron-mobility\n  transistor'.\n  We study plasma effects in a micromachined high-electron mobility transistor\n(HEMT) with the microcantilever serving as the gate using the developed a\nmodel. The model accounts for mechanical motion of the microcantilever and\nspatio-temporal variations (plasma effects) of the two-dimensional electron\ngas(2DEG) system in the transistor channel. The microcantilever mechanical\nmotion is described in the point-mass approximation. The hydrodynamic electron\ntransport model is used to describe distributed electron plasma phenomena in\nthe 2DEG system. Using the developed model, we calculated the response function\ncharacterizing the amplitude microcantilever oscillations and the output\nelectric signal as functions of the signal frequency and the bias voltage for\nthe devices with different parameters. We find the voltage dependences of the\nfrequency of the mechanical resonance and its damping. In particular, it is\ndemonstrated that the amplitudes of the mechanical oscillations and output\nelectric signal exhibit pronounced maxima at the bias voltages close to the\nvoltage of the 2DEG channel depletion followed by a steep drop with further\nincrease in the bias voltage.\n\n", "human_text": "  We study plasma effects in a micromachined high-electron mobility transistor\n(HEMT) with the microcantilever serving as the gate using the developed a\nmodel. The model accounts for mechanical motion of the microcantilever and\nspatio-temporal variations (plasma effects) of the two-dimensional electron\ngas(2DEG) system in the transistor channel. The microcantilever mechanical\nmotion is described in the point-mass approximation. The hydrodynamic electron\ntransport model is used to describe distributed electron plasma phenomena in\nthe 2DEG system. Using the developed model, we calculated the response function\ncharacterizing the amplitude microcantilever oscillations and the output\nelectric signal as functions of the signal frequency and the bias voltage for\nthe devices with different parameters. We find the voltage dependences of the\nfrequency of the mechanical resonance and its damping. In particular, it is\ndemonstrated that the amplitudes of the mechanical oscillations and output\nelectric signal exhibit pronounced maxima at the bias voltages close to the\nvoltage of the 2DEG channel depletion followed by a steep drop with further\nincrease in the bias voltage.\n", "machine_text": "\nIn this article, we have developed a model to understand plasma effects in a micromachined High Electron Mobility Transistor (HEMT) with a microcantilever serving as the gate. The model takes into consideration the mechanical movement of the microcantilever, as well as the spatial and temporal variations of the Two-Dimensional Electron Gas (2DEG) system present in the transistor channel. To describe the microcantilever motion, the point-mass approximation was adopted. A hydrodynamic electron transport model was used to mimic plasma phenomena in the 2DEG. Using the model, we studied the response of the microcantilever oscillations and output signal as functions of signal frequency and bias voltage for various device parameters. We also analyzed voltage dependences of resonance frequency and its damping. We found that the signal amplitudes and microcantilever oscillations exhibit maxima at voltages close to the depletion voltage, followed by a steep drop as the bias voltage increases.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2082}
{"prompt": "Rephrase the abstract of an article with title 'The Clusters AgeS Experiment (CASE). I. V209 omega Cen - An Eclipsing\n  Post-Common Envelope Binary in the Globular Cluster omega Cen'.\n  We use photometric and spectroscopic observations of the detached eclipsing\nbinary V209 omega Cen to derive the masses, radii, and luminosities of the\ncomponent stars. The system exhibits total eclipses and, based on the measured\nsystemic velocity and the derived distance, is a member of the globular cluster\nomega Cen. We obtain 0.945 +/- 0.043 Msun, 0.983 +/- 0.015 Rsun and 6.68 +/-\n0.88 Lsun for the cooler, but larger and more luminous primary component. The\nsecondary component has 0.144 +/- 0.008 Msun, 0.425 +/- 0.008 Rsun and 2.26 +/-\n0.28 Lsun. The effective temperatures are estimated at 9370 K for the primary\nand at 10866 K for the secondary. On the color-magnitude diagram of the\ncluster, the primary component occupies a position between the tip of the blue\nstraggler region and the extended horizontal branch while the secondary\ncomponent is located close to the red border of the area occupied by hot\nsubdwarfs. However, its radius is too large and its effective temperature is\ntoo low for it to be an sdB star. We propose a scenario leading to the\nformation of a system with such unusual properties with the primary component\n``re-born'' from a former white dwarf which accreted a new envelope through\nmass transfer from its companion. The secondary star has lost most of its\nenvelope while starting its ascent onto the sub-giant branch. It failed to\nignite helium in its core and is currently powered by a hydrogen burning shell.\n\n", "human_text": "  We use photometric and spectroscopic observations of the detached eclipsing\nbinary V209 omega Cen to derive the masses, radii, and luminosities of the\ncomponent stars. The system exhibits total eclipses and, based on the measured\nsystemic velocity and the derived distance, is a member of the globular cluster\nomega Cen. We obtain 0.945 +/- 0.043 Msun, 0.983 +/- 0.015 Rsun and 6.68 +/-\n0.88 Lsun for the cooler, but larger and more luminous primary component. The\nsecondary component has 0.144 +/- 0.008 Msun, 0.425 +/- 0.008 Rsun and 2.26 +/-\n0.28 Lsun. The effective temperatures are estimated at 9370 K for the primary\nand at 10866 K for the secondary. On the color-magnitude diagram of the\ncluster, the primary component occupies a position between the tip of the blue\nstraggler region and the extended horizontal branch while the secondary\ncomponent is located close to the red border of the area occupied by hot\nsubdwarfs. However, its radius is too large and its effective temperature is\ntoo low for it to be an sdB star. We propose a scenario leading to the\nformation of a system with such unusual properties with the primary component\n``re-born'' from a former white dwarf which accreted a new envelope through\nmass transfer from its companion. The secondary star has lost most of its\nenvelope while starting its ascent onto the sub-giant branch. It failed to\nignite helium in its core and is currently powered by a hydrogen burning shell.\n", "machine_text": "\nIn this study, photometric and spectroscopic observations were conducted on V209 omega Cen, an eclipsing binary system in the globular cluster omega Cen. By analyzing the results, it was determined that both component stars possess masses of 0.945 +/- 0.043 Msun and 0.144 +/- 0.008 Msun, radii of 0.983 +/- 0.015 Rsun and 0.425 +/- 0.008 Rsun, and luminosities of 6.68 +/- 0.88 Lsun and 2.26 +/- 0.28 Lsun, respectively. Additionally, the cooler primary component has an effective temperature measurement of 9370 K, and the hotter secondary component has 10866 K. The positions of both stars within the cluster's colour-magnitude diagram are discussed. We then propose an alternative explanation for the unusual properties of the binary system, postulating that the primary star was previously a white dwarf that gained an additional envelope from the secondary star and then ``re-birthed'' with the secondary star losing majority of its own envelope while it started its climb up the subgiant branch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3507}
{"prompt": "Rephrase the abstract of an article with title 'Effective Theory for Trapped Few-Fermion Systems'.\n  We apply the general principles of effective field theories to the\nconstruction of effective interactions suitable for few- and many-body\ncalculations in a no-core shell model framework. We calculate the spectrum of\nsystems with three and four two-component fermions in a harmonic trap. In the\nunitary limit, we find that three-particle results are within 10% of known\nsemi-analytical values even in small model spaces. The method is very general,\nand can be readily extended to other regimes, more particles, different species\n(e.g., protons and neutrons in nuclear physics), or more-component fermions (as\nwell as bosons). As an illustration, we present calculations of the\nlowest-energy three-fermion states away from the unitary limit and find a\npossible inversion of parity in the ground state in the limit of trap size\nlarge compared to the scattering length. Furthermore, we investigate the lowest\npositive-parity states for four fermions, although we are limited by the\ndimensions we can currently handle in this case.\n\n", "human_text": "  We apply the general principles of effective field theories to the\nconstruction of effective interactions suitable for few- and many-body\ncalculations in a no-core shell model framework. We calculate the spectrum of\nsystems with three and four two-component fermions in a harmonic trap. In the\nunitary limit, we find that three-particle results are within 10% of known\nsemi-analytical values even in small model spaces. The method is very general,\nand can be readily extended to other regimes, more particles, different species\n(e.g., protons and neutrons in nuclear physics), or more-component fermions (as\nwell as bosons). As an illustration, we present calculations of the\nlowest-energy three-fermion states away from the unitary limit and find a\npossible inversion of parity in the ground state in the limit of trap size\nlarge compared to the scattering length. Furthermore, we investigate the lowest\npositive-parity states for four fermions, although we are limited by the\ndimensions we can currently handle in this case.\n", "machine_text": "We present a theory for the trapped few-fermion systems that successfully constructs effective interactions in order to carry out few- and many-body calculations. We analyze the spectrum of three- and four-particle systems in a confinement, finding agreement with known semi-analytical values in the unitary limit. We extend this method to other scenarios, with different species and more components, as demonstrated by calculations of low-energy states away from the unitary limit and the possible inversion of parity in the ground state. Additionally, we explore the lowest positive-parity states of four fermions, although this may be limited by current computational dimensions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4335}
{"prompt": "Rephrase the abstract of an article with title 'Orbifoldes speciales et classification bimeromorphe des varietes\n  kaehleriennes compactes'.\n  This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\\it\ncategory} of geometric orbifolds. These interpolate between (compact K\\\" ahler)\nmanifolds and such manifolds with logarithmic structure. These geometric\norbifolds are considered from the point of view of their geometry, and thus\nequipped with the usual invariants of varieties: morphisms and bimeromorphic\nmaps, differential forms, fundamental groups and universal covers, fields of\ndefinition and rational points. The most elementary properties, directly\nadapted from the case of varieties without orbifold structure, are established\nhere. The arguments of [Ca01] can then be directly adapted to extend the main\nstructure results to this orbifold category. We hope to come back to deeper\naspects later. The motivation is that the natural frame for the theory of\nclassification of compact K\\\" ahler (and complex projective) manifolds includes\nat least the category of orbifolds, as shown in [Ca01] by the fonctorial\ndecomposition of {\\it special} manifolds as tower of orbifolds with either\n$\\kappa_+=-\\infty$ or $\\kappa=0$, and also, seemingly, by the minimal model\nprogram, in which most proofs work only after the adjunction of a \"boundary\".\n  Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds\nextension properties not satisfied in the category of varieties without\norbifold structure, permitting to express invariants of the total space from\nthose of the generic fibre and of the base. For example, the natural sequence\nof fundamental groups is exact there; also the total space is special if so are\nthe generic fibre and the base. This makes this category suitable to lift\nproperties from orbifolds having either $\\kappa_+=-\\infty$ or $\\kappa=0$ to\nthose which are special.\n\n", "human_text": "  This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\\it\ncategory} of geometric orbifolds. These interpolate between (compact K\\\" ahler)\nmanifolds and such manifolds with logarithmic structure. These geometric\norbifolds are considered from the point of view of their geometry, and thus\nequipped with the usual invariants of varieties: morphisms and bimeromorphic\nmaps, differential forms, fundamental groups and universal covers, fields of\ndefinition and rational points. The most elementary properties, directly\nadapted from the case of varieties without orbifold structure, are established\nhere. The arguments of [Ca01] can then be directly adapted to extend the main\nstructure results to this orbifold category. We hope to come back to deeper\naspects later. The motivation is that the natural frame for the theory of\nclassification of compact K\\\" ahler (and complex projective) manifolds includes\nat least the category of orbifolds, as shown in [Ca01] by the fonctorial\ndecomposition of {\\it special} manifolds as tower of orbifolds with either\n$\\kappa_+=-\\infty$ or $\\kappa=0$, and also, seemingly, by the minimal model\nprogram, in which most proofs work only after the adjunction of a \"boundary\".\n  Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds\nextension properties not satisfied in the category of varieties without\norbifold structure, permitting to express invariants of the total space from\nthose of the generic fibre and of the base. For example, the natural sequence\nof fundamental groups is exact there; also the total space is special if so are\nthe generic fibre and the base. This makes this category suitable to lift\nproperties from orbifolds having either $\\kappa_+=-\\infty$ or $\\kappa=0$ to\nthose which are special.\n", "machine_text": "In this article, we present a study of special geometric orbifolds, and the\nclassification of compact K\\\" ahler varieties within this orbifold category. We\ndefine the bimeromorphic category of such orbifolds, along with their\ninvariants, such as morphisms, differential forms, fundamental groups and\nuniversal covers, fields of definition, and rational points. Additionally, we\ndiscuss how properties of these orbifolds can be extended from those without\norbifold structure, and review the concept of special manifolds being composed\nas towers of orbifolds. We then provide a classification of compact K\\\" ahler\nvarieties through this bimeromorphic category of geometric orbifolds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0737}
{"prompt": "Rephrase the abstract of an article with title 'A Panchromatic Study of the Globular Cluster NGC 1904. I: The Blue\n  Straggler Population'.\n  By combining high-resolution (HST-WFPC2) and wide-field ground based (2.2m\nESO-WFI) and space (GALEX) observations, we have collected a multi-wavelength\nphotometric data base (ranging from the far UV to the near infrared) of the\ngalactic globular cluster NGC1904 (M79). The sample covers the entire cluster\nextension, from the very central regions up to the tidal radius. In the present\npaper such a data set is used to study the BSS population and its radial\ndistribution. A total number of 39 bright ($m_{218}\\le 19.5$) BSS has been\ndetected, and they have been found to be highly segregated in the cluster core.\nNo significant upturn in the BSS frequency has been observed in the outskirts\nof NGC 1904, in contrast to other clusters (M 3, 47 Tuc, NGC 6752, M 5) studied\nwith the same technique. Such evidences, coupled with the large radius of\navoidance estimated for NGC 1904 ($r_{avoid}\\sim 30$ core radii), indicate that\nthe vast majority of the cluster heavy stars (binaries) has already sunk to the\ncore. Accordingly, extensive dynamical simulations suggest that BSS formed by\nmass transfer activity in primordial binaries evolving in isolation in the\ncluster outskirts represent only a negligible (0--10%) fraction of the overall\npopulation.\n\n", "human_text": "  By combining high-resolution (HST-WFPC2) and wide-field ground based (2.2m\nESO-WFI) and space (GALEX) observations, we have collected a multi-wavelength\nphotometric data base (ranging from the far UV to the near infrared) of the\ngalactic globular cluster NGC1904 (M79). The sample covers the entire cluster\nextension, from the very central regions up to the tidal radius. In the present\npaper such a data set is used to study the BSS population and its radial\ndistribution. A total number of 39 bright ($m_{218}\\le 19.5$) BSS has been\ndetected, and they have been found to be highly segregated in the cluster core.\nNo significant upturn in the BSS frequency has been observed in the outskirts\nof NGC 1904, in contrast to other clusters (M 3, 47 Tuc, NGC 6752, M 5) studied\nwith the same technique. Such evidences, coupled with the large radius of\navoidance estimated for NGC 1904 ($r_{avoid}\\sim 30$ core radii), indicate that\nthe vast majority of the cluster heavy stars (binaries) has already sunk to the\ncore. Accordingly, extensive dynamical simulations suggest that BSS formed by\nmass transfer activity in primordial binaries evolving in isolation in the\ncluster outskirts represent only a negligible (0--10%) fraction of the overall\npopulation.\n", "machine_text": "\nThis study examines the blue straggler population of the globular cluster NGC 1904 (M79) using a multifaceted data collection. The photometric data - ranging from ultraviolet to near infrared - was sourced from both high resolution HST-WFPC2 and ground/space based 2.2m ESO-WFI and GALEX instruments. After analysing the entire cluster in this way, a total of 39 notably bright blue stragglers ($m_{218}\\le 19.5$) have been distinguished with a highly concentrated distribution in the core region. Contrary to other globular clusters (M 3, 47 Tuc, NGC 6752, M 5) that have been studied with the same method, no major increase in the frequency of blue stragglers in the outer regions of NGC 1904 was observed. This, combined with a comparatively large radius of avoidance ($r_{avoid}\\sim 30$ core radii), leads to the conclusion that dynamic processes of a primordial binary system only make up a minuscule (0-10%) proportion of the overall blue straggler population of NGC 1904.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1393}
{"prompt": "Rephrase the abstract of an article with title 'Bond breaking with auxiliary-field quantum Monte Carlo'.\n  Bond stretching mimics different levels of electron correlation and provides\na challenging testbed for approximate many-body computational methods. Using\nthe recently developed phaseless auxiliary-field quantum Monte Carlo (AF QMC)\nmethod, we examine bond stretching in the well-studied molecules BH and N$_2$,\nand in the H$_{50}$ chain. To control the sign/phase problem, the phaseless AF\nQMC method constrains the paths in the auxiliary-field path integrals with an\napproximate phase condition that depends on a trial wave function. With single\nSlater determinants from unrestricted Hartree-Fock (UHF) as trial wave\nfunction, the phaseless AF QMC method generally gives better overall accuracy\nand a more uniform behavior than the coupled cluster CCSD(T) method in mapping\nthe potential-energy curve. In both BH and N$_2$, we also study the use of\nmultiple-determinant trial wave functions from multi-configuration\nself-consistent-field (MCSCF) calculations. The increase in computational cost\nversus the gain in statistical and systematic accuracy are examined. With such\ntrial wave functions, excellent results are obtained across the entire region\nbetween equilibrium and the dissociation limit.\n\n", "human_text": "  Bond stretching mimics different levels of electron correlation and provides\na challenging testbed for approximate many-body computational methods. Using\nthe recently developed phaseless auxiliary-field quantum Monte Carlo (AF QMC)\nmethod, we examine bond stretching in the well-studied molecules BH and N$_2$,\nand in the H$_{50}$ chain. To control the sign/phase problem, the phaseless AF\nQMC method constrains the paths in the auxiliary-field path integrals with an\napproximate phase condition that depends on a trial wave function. With single\nSlater determinants from unrestricted Hartree-Fock (UHF) as trial wave\nfunction, the phaseless AF QMC method generally gives better overall accuracy\nand a more uniform behavior than the coupled cluster CCSD(T) method in mapping\nthe potential-energy curve. In both BH and N$_2$, we also study the use of\nmultiple-determinant trial wave functions from multi-configuration\nself-consistent-field (MCSCF) calculations. The increase in computational cost\nversus the gain in statistical and systematic accuracy are examined. With such\ntrial wave functions, excellent results are obtained across the entire region\nbetween equilibrium and the dissociation limit.\n", "machine_text": "\nThe bond breaking process has been tested using the auxiliary-field quantum Monte Carlo method, where paths in the path integrals are controlled with an approximate phase condition based on a trial wave function. Single Slater determinants from unrestricted Hartree-Fock calculations and multiple-determinant trial wave functions from multi-configuration self-consistent-field method were used to provide an assessment of the accuracy improvement with the increase of computational cost. This was tested using BH and N$_{2}$ molecules and the H$_{50}$ chain as examples. Ultimately it was found that these trial wave functions yielded excellent results across the entire period from the equilibrium point to the dissociation limit.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2827}
{"prompt": "Rephrase the abstract of an article with title 'Origin of magnetoelectric behavior in BiFeO$_3$'.\n  The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of\naccurate density functional calculations. The structural, electronic, magnetic,\nand ferroelectric properties of BiFeO$_3$ are predicted correctly without\nincluding strong correlation effect in the calculation. Moreover, the\nexperimentally-observed elongation of cubic perovskite-like lattice along the\n[111] direction is correctly reproduced. At high pressure we predicted a\npressure-induced structural transition and the total energy calculations at\nexpanded lattice show two lower energy ferroelectric phases, closer in energy\nto the ground state phase. Band-structure calculations show that BiFeO$_3$ will\nbe an insulator in A- and G-type antiferromagnetic phases and a metal in other\nmagnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using\nvarious tools and electron localization function analysis shows that\nstereochemically active lone-pair electrons at the Bi sites are responsible for\ndisplacements of the Bi atoms from the centro-symmetric to the\nnoncentrosymmetric structure and hence the ferroelectricity. A large\nferroelectric polarization (88.7 $\\mu$C/cm$^{2}$) is predicted in accordance\nwith recent experimental findings. The net polarization is found to mainly ($>$\n98%) originate from Bi atoms. Moreover the large scatter in experimentally\nreported polarization values is due to the large anisotropy in the spontaneous\npolarization.\n\n", "human_text": "  The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of\naccurate density functional calculations. The structural, electronic, magnetic,\nand ferroelectric properties of BiFeO$_3$ are predicted correctly without\nincluding strong correlation effect in the calculation. Moreover, the\nexperimentally-observed elongation of cubic perovskite-like lattice along the\n[111] direction is correctly reproduced. At high pressure we predicted a\npressure-induced structural transition and the total energy calculations at\nexpanded lattice show two lower energy ferroelectric phases, closer in energy\nto the ground state phase. Band-structure calculations show that BiFeO$_3$ will\nbe an insulator in A- and G-type antiferromagnetic phases and a metal in other\nmagnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using\nvarious tools and electron localization function analysis shows that\nstereochemically active lone-pair electrons at the Bi sites are responsible for\ndisplacements of the Bi atoms from the centro-symmetric to the\nnoncentrosymmetric structure and hence the ferroelectricity. A large\nferroelectric polarization (88.7 $\\mu$C/cm$^{2}$) is predicted in accordance\nwith recent experimental findings. The net polarization is found to mainly ($>$\n98%) originate from Bi atoms. Moreover the large scatter in experimentally\nreported polarization values is due to the large anisotropy in the spontaneous\npolarization.\n", "machine_text": "\nThis paper aims to reveal the source of magnetoelectric behavior in BiFeO$_3$ by investigating the structural, electronic, magnetic, and ferroelectric properties of this material. Accurate density functional calculations without strong correlation effects are used to reproduce the observed cuboctahedral lattice expansion in the [111] direction, as well as a pressure-induced structural transition. Band-structure calculations predict that BiFeO$_3$ is an insulator in an A- and G-type antiferromagnetic phase and a metal in other magnetic configurations. Results from the electron localization function analysis indicate that the ferroelectricity is caused by sterically active lone-pair electrons at the Bi sites. A large ferroelectric polarization of 88.7 $\\mu$C/cm$^{2}$ is expected from this research, which is in agreement with recent experimental findings. Moreover, the large variations in the ferroelectric polarization are due to the anisotropy in the spontaneous polarization.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.046}
{"prompt": "Rephrase the abstract of an article with title 'Polarizabilities of Intermediate Sized Lithium Clusters From\n  Density-Functional Theory'.\n  We present a detailed investigation of static dipole polarizability of\nlithium clusters containing up to 22 atoms. We first build a database of\nlithium clusters by optimizing several candidate structures for the ground\nstate geometry for each size. The full polarizability tensor is determined for\nabout 5-6 isomers of each cluster size using the finite-field method. All\ncalculations are performed using large Gaussian basis sets, and within the\ngeneralized gradient approximation to the density functional theory, as\nimplemented in the NRLMOL suite of codes. The average polarizability per atom\nvaries from 11 to 9 Angstrom^3, within the 8-22 size range and show smoother\ndecrease with increase in cluster size than the experimental values. While the\naverage polarizability exhibits a relatively weak dependence on cluster\nconformation, significant changes in the degree of anisotropy of the\npolarizability tensor are observed. Interestingly, in addition to the expected\neven odd (0 and 1 $\\mu_B$) magnetic states, our results show several cases\nwhere clusters with an odd number of Li atoms exhibit elevated spin states\n(e.g. 3 $\\mu_B$).\n\n", "human_text": "  We present a detailed investigation of static dipole polarizability of\nlithium clusters containing up to 22 atoms. We first build a database of\nlithium clusters by optimizing several candidate structures for the ground\nstate geometry for each size. The full polarizability tensor is determined for\nabout 5-6 isomers of each cluster size using the finite-field method. All\ncalculations are performed using large Gaussian basis sets, and within the\ngeneralized gradient approximation to the density functional theory, as\nimplemented in the NRLMOL suite of codes. The average polarizability per atom\nvaries from 11 to 9 Angstrom^3, within the 8-22 size range and show smoother\ndecrease with increase in cluster size than the experimental values. While the\naverage polarizability exhibits a relatively weak dependence on cluster\nconformation, significant changes in the degree of anisotropy of the\npolarizability tensor are observed. Interestingly, in addition to the expected\neven odd (0 and 1 $\\mu_B$) magnetic states, our results show several cases\nwhere clusters with an odd number of Li atoms exhibit elevated spin states\n(e.g. 3 $\\mu_B$).\n", "machine_text": "This article delves into the analysis of the polarizability of lithium clusters with up to 22 atoms. A database of geometrical structures was created and the finite-field method was applied to determine the full polarizability tensor for each size. The results from density functional theory (in the form of Gaussian basis sets and the NRLMOL suite of codes) show that the average polarizability per atom declines from 11 to 9 Angstrom^3 in the 8-22 size range and is smoother than the experimentally obtained values. Additionally, changes in the degree of anisotropy of the polarizability in different conformations were observed while some cases with an odd atom number show elevated spin states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0555}
{"prompt": "Rephrase the abstract of an article with title 'Quasi-periodic oscillations, charge and the gravitomagnetic theory'.\n  A new model for the explanation of the high frequency quasi-periodic\noscillations (QPOs) in pulsars, black holes and white dwarfs is presented.\nThree circular tori are assumed to be present around the star: an inner torus\nwith charge $Q_i$, an outer torus with charge $Q_o$ and a torus with\nelectrically neutral mass $m_m$ in the middle, whereas the star bears a charge\n$Q_s$ ($Q_o$ and $Q_s$ have the same sign, $Q_i$ the opposite one). The\nfrequency $\\nu_m$ of the mass current is approximately given by the Kepler\nfrequency, whereas the frequencies of $Q_i$ and $Q_o$, $\\nu_i$ and $\\nu_o$,\nrespectively, are calculated from classical mechanics and Coulomb's law.\n  For the explanation of the low frequency QPOs in pulsars and black holes a\nspecial interpretation of the gravitomagnetic theory may be essential. From the\nlatter theory four new gravitomagnetic precession frequencies are deduced,\nwhich may be identified with the observed low frequency QPOs.\n  Predictions of the presented model are compared with observed high frequency\nand low frequency QPOs of the pulsars SAX J1808.4--3658, XTE J1807--294, IGR\nJ00291+5934, SGR 1806--20 and the black hole XTE J1550--564. In addition,\ncharge flow near the pole of pulsars may explain frequency drift of burst\noscillations. Moreover, charge flow at the equator of SAX J1808.4--3658 may be\nthe cause of the enigmatic 410 kHz QPO. Furthermore, the Lense-Thirring\nfrequency is discussed and a modified formula is compared with data of the\npulsars.\n  Contrary to pulsars and black holes, the low frequency QPOs of white dwarfs\nmight be attributed to electromagnetic precession frequencies, deduced in this\nwork. Predictions are compared with data of the dwarf nova VW Hyi.\n\n", "human_text": "  A new model for the explanation of the high frequency quasi-periodic\noscillations (QPOs) in pulsars, black holes and white dwarfs is presented.\nThree circular tori are assumed to be present around the star: an inner torus\nwith charge $Q_i$, an outer torus with charge $Q_o$ and a torus with\nelectrically neutral mass $m_m$ in the middle, whereas the star bears a charge\n$Q_s$ ($Q_o$ and $Q_s$ have the same sign, $Q_i$ the opposite one). The\nfrequency $\\nu_m$ of the mass current is approximately given by the Kepler\nfrequency, whereas the frequencies of $Q_i$ and $Q_o$, $\\nu_i$ and $\\nu_o$,\nrespectively, are calculated from classical mechanics and Coulomb's law.\n  For the explanation of the low frequency QPOs in pulsars and black holes a\nspecial interpretation of the gravitomagnetic theory may be essential. From the\nlatter theory four new gravitomagnetic precession frequencies are deduced,\nwhich may be identified with the observed low frequency QPOs.\n  Predictions of the presented model are compared with observed high frequency\nand low frequency QPOs of the pulsars SAX J1808.4--3658, XTE J1807--294, IGR\nJ00291+5934, SGR 1806--20 and the black hole XTE J1550--564. In addition,\ncharge flow near the pole of pulsars may explain frequency drift of burst\noscillations. Moreover, charge flow at the equator of SAX J1808.4--3658 may be\nthe cause of the enigmatic 410 kHz QPO. Furthermore, the Lense-Thirring\nfrequency is discussed and a modified formula is compared with data of the\npulsars.\n  Contrary to pulsars and black holes, the low frequency QPOs of white dwarfs\nmight be attributed to electromagnetic precession frequencies, deduced in this\nwork. Predictions are compared with data of the dwarf nova VW Hyi.\n", "machine_text": "\nThis paper presents a theoretical model for explaining the high frequency quasi-periodic oscillations (QPOs) in pulsars, black holes and white dwarfs. The model incorporates three circular tori around the star, where two carry charge and the third houses an electrically neutral mass. The given theory also proposes a new interpretation to the gravitomagnetic theory in order to explain low-frequency QPOs in pulsars and black holes. Furthermore, the effect of charge flow is contemplated to explain the frequency drifts of burst oscillations and the 410 kHz QPO in the pulsar SAX J1808.4--3658. In addition, the Lense-Thirring frequency and a modified formula derived from it are compared with data from pulsars. Lastly, for white dwarf stars, low frequency QPOs are suggested to stem from electromagnetic precession frequencies developed in the theory. Predictions from the model are compared to the data from the dwarf nova VW Hyi.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0313}
{"prompt": "Rephrase the abstract of an article with title 'Radiatively broken symmetries of nonhierarchical neutrinos'.\n  Symmetry-based ideas, such as the quark-lepton complementarity (QLC)\nprinciple and the tri-bimaximal mixing (TBM) scheme, have been proposed to\nexplain the observed mixing pattern of neutrinos. We argue that such symmetry\nrelations need to be imposed at a high scale $\\Lambda \\sim 10^{12}$ GeV\ncharacterizing the large masses of right-handed neutrinos required to implement\nthe seesaw mechanism. For nonhierarchical neutrinos, renormalisation group\nevolution down to a laboratory energy scale $\\lambda \\sim 10^3$ GeV tends to\nradiatively break these symmetries at a significant level and spoil the mixing\npattern predicted by them. However, for Majorana neutrinos, suitable\nconstraints on the extra phases $\\alpha_{2,3}$ enable the retention of those\nhigh scale mixing patterns at laboratory energies. We examine this issue within\nthe Minimal Supersymmetric Standard Model (MSSM) and demonstrate the fact\nposited above for two versions of QLC and two versions of TBM. The appropriate\nconstraints are worked out for all these four cases. Specifically, a preference\nfor $\\alpha_2 \\approx \\pi$ (i.e. $m_1 \\approx -m_2$) emerges in each case. We\nalso show how a future accurate measurement of $\\theta_{13}$ may enable some\ndiscrimination among these four cases in spite of renormalization group\nevolution.\n\n", "human_text": "  Symmetry-based ideas, such as the quark-lepton complementarity (QLC)\nprinciple and the tri-bimaximal mixing (TBM) scheme, have been proposed to\nexplain the observed mixing pattern of neutrinos. We argue that such symmetry\nrelations need to be imposed at a high scale $\\Lambda \\sim 10^{12}$ GeV\ncharacterizing the large masses of right-handed neutrinos required to implement\nthe seesaw mechanism. For nonhierarchical neutrinos, renormalisation group\nevolution down to a laboratory energy scale $\\lambda \\sim 10^3$ GeV tends to\nradiatively break these symmetries at a significant level and spoil the mixing\npattern predicted by them. However, for Majorana neutrinos, suitable\nconstraints on the extra phases $\\alpha_{2,3}$ enable the retention of those\nhigh scale mixing patterns at laboratory energies. We examine this issue within\nthe Minimal Supersymmetric Standard Model (MSSM) and demonstrate the fact\nposited above for two versions of QLC and two versions of TBM. The appropriate\nconstraints are worked out for all these four cases. Specifically, a preference\nfor $\\alpha_2 \\approx \\pi$ (i.e. $m_1 \\approx -m_2$) emerges in each case. We\nalso show how a future accurate measurement of $\\theta_{13}$ may enable some\ndiscrimination among these four cases in spite of renormalization group\nevolution.\n", "machine_text": "\nWe examine the issue of how radiative corrections at low energy scales may cause breaking of symmetries, such as the quark-lepton complementarity (QLC) and the tri-bimaximal mixing (TBM), that are proposed to explain the observed mixing pattern of neutrinos. Our investigation is conducted within the context of the Minimal Supersymmetric Standard Model (MSSM) for nonhierarchical neutrinos. We find that the appropriate choice of extra phases $\\alpha_{2,3}$ can retain the high scale mixing patterns which would otherwise be spoiled by the radiative corrections. Further, measuring the angle $\\theta_{13}$ at a future point in time may enable distinction between the different symmetry-based models even after the radiative breaking of the symmetries.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3735}
{"prompt": "Rephrase the abstract of an article with title 'A Pair of Bootes: A New Milky Way Satellite'.\n  As part of preparations for a southern sky search for faint Milky Way dwarf\ngalaxy satellites, we report the discovery of a stellar overdensity in the\nSloan Digital Sky Survey Data Release 5, lying at an angular distance of only\n1.5 degrees from the recently discovered Bo{\\\"o}tes dwarf. The overdensity was\ndetected well above statistical noise by employing a sophisticated data mining\nalgorithm and does not correspond to any catalogued object. Overlaid isochrones\nusing stellar population synthesis models show that the color-magnitude diagram\nof that region has the signature of an old (12 Gyr), metal-poor (${\\rm\nFe/H}\\approx-2.0$) stellar population at a tentative distance of 60 kpc,\nevidently the same heliocentric distance as the Bo\\\"otes dwarf. We estimate the\nnew object to have a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a\nhalf-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc) placing it in an\napparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies,\noccupied only by another recently discovered Milky Way Satellite, Coma\nBerenices.\n\n", "human_text": "  As part of preparations for a southern sky search for faint Milky Way dwarf\ngalaxy satellites, we report the discovery of a stellar overdensity in the\nSloan Digital Sky Survey Data Release 5, lying at an angular distance of only\n1.5 degrees from the recently discovered Bo{\\\"o}tes dwarf. The overdensity was\ndetected well above statistical noise by employing a sophisticated data mining\nalgorithm and does not correspond to any catalogued object. Overlaid isochrones\nusing stellar population synthesis models show that the color-magnitude diagram\nof that region has the signature of an old (12 Gyr), metal-poor (${\\rm\nFe/H}\\approx-2.0$) stellar population at a tentative distance of 60 kpc,\nevidently the same heliocentric distance as the Bo\\\"otes dwarf. We estimate the\nnew object to have a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a\nhalf-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc) placing it in an\napparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies,\noccupied only by another recently discovered Milky Way Satellite, Coma\nBerenices.\n", "machine_text": "\nWe have uncovered a new Milky Way satellite, located within 1.5 degrees of the existing Bo{\\\"o}tes dwarf, during a survey of the southern sky for faint galaxy satellites. A sophisticated data mining algorithm was used to detect the stellar overdensity and verify that it does not correspond to any previously catalogued object. Analysis of the color-magnitude diagram for the region with stellar population synthesis models suggests that the new object has a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a half-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc). This places it in a previously empty forty to one-hundred parsec void between globular clusters and dwarf galaxies, occupied by only one other Milky Way satellite- Coma Berenices.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1378}
{"prompt": "Rephrase the abstract of an article with title 'Sample eigenvalue based detection of high dimensional signals in white\n  noise using relatively few samples'.\n  We present a mathematically justifiable, computationally simple, sample\neigenvalue based procedure for estimating the number of high-dimensional\nsignals in white noise using relatively few samples. The main motivation for\nconsidering a sample eigenvalue based scheme is the computational simplicity\nand the robustness to eigenvector modelling errors which are can adversely\nimpact the performance of estimators that exploit information in the sample\neigenvectors.\n  There is, however, a price we pay by discarding the information in the sample\neigenvectors; we highlight a fundamental asymptotic limit of sample eigenvalue\nbased detection of weak/closely spaced high-dimensional signals from a limited\nsample size. This motivates our heuristic definition of the effective number of\nidentifiable signals which is equal to the number of \"signal\" eigenvalues of\nthe population covariance matrix which exceed the noise variance by a factor\nstrictly greater than 1+sqrt(Dimensionality of the system/Sample size). The\nfundamental asymptotic limit brings into sharp focus why, when there are too\nfew samples available so that the effective number of signals is less than the\nactual number of signals, underestimation of the model order is unavoidable (in\nan asymptotic sense) when using any sample eigenvalue based detection scheme,\nincluding the one proposed herein. The analysis reveals why adding more sensors\ncan only exacerbate the situation. Numerical simulations are used to\ndemonstrate that the proposed estimator consistently estimates the true number\nof signals in the dimension fixed, large sample size limit and the effective\nnumber of identifiable signals in the large dimension, large sample size limit.\n\n", "human_text": "  We present a mathematically justifiable, computationally simple, sample\neigenvalue based procedure for estimating the number of high-dimensional\nsignals in white noise using relatively few samples. The main motivation for\nconsidering a sample eigenvalue based scheme is the computational simplicity\nand the robustness to eigenvector modelling errors which are can adversely\nimpact the performance of estimators that exploit information in the sample\neigenvectors.\n  There is, however, a price we pay by discarding the information in the sample\neigenvectors; we highlight a fundamental asymptotic limit of sample eigenvalue\nbased detection of weak/closely spaced high-dimensional signals from a limited\nsample size. This motivates our heuristic definition of the effective number of\nidentifiable signals which is equal to the number of \"signal\" eigenvalues of\nthe population covariance matrix which exceed the noise variance by a factor\nstrictly greater than 1+sqrt(Dimensionality of the system/Sample size). The\nfundamental asymptotic limit brings into sharp focus why, when there are too\nfew samples available so that the effective number of signals is less than the\nactual number of signals, underestimation of the model order is unavoidable (in\nan asymptotic sense) when using any sample eigenvalue based detection scheme,\nincluding the one proposed herein. The analysis reveals why adding more sensors\ncan only exacerbate the situation. Numerical simulations are used to\ndemonstrate that the proposed estimator consistently estimates the true number\nof signals in the dimension fixed, large sample size limit and the effective\nnumber of identifiable signals in the large dimension, large sample size limit.\n", "machine_text": "\nWe explore the feasibility of a mathematically sound and computationally simple eigenvalue based method for estimating the number of high-dimensional signals present in an additive white noise environment, when the number of available samples is relatively low. This procedure exploits eigenvalues from the population covariance matrix as an indicator of signal presence, as a way to overcome potential errors which could arise from eigenvector modelling. However, a fundamental limit is uncovered with the estimator, due to its incapacity to detect weak signals or close signals in the same frequency range. We define the effective number of identifiable signals equal to the 'signal' eigenvalues which surpass the noise variance multiplied by a factor greater than 1+\u221a(Dimensionality of system/Sample size). Numerical experiments validate that the estimator correctly presents the true patterns of signal presence when in a large sample size/dimensionality scenario and the effective number of signals in a large dimension/sample size environment.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2605}
{"prompt": "Rephrase the abstract of an article with title 'Relating two standard notions of secrecy'.\n  Two styles of definitions are usually considered to express that a security\nprotocol preserves the confidentiality of a data s. Reachability-based secrecy\nmeans that s should never be disclosed while equivalence-based secrecy states\nthat two executions of a protocol with distinct instances for s should be\nindistinguishable to an attacker. Although the second formulation ensures a\nhigher level of security and is closer to cryptographic notions of secrecy,\ndecidability results and automatic tools have mainly focused on the first\ndefinition so far.\n  This paper initiates a systematic investigation of the situations where\nsyntactic secrecy entails strong secrecy. We show that in the passive case,\nreachability-based secrecy actually implies equivalence-based secrecy for\ndigital signatures, symmetric and asymmetric encryption provided that the\nprimitives are probabilistic. For active adversaries, we provide sufficient\n(and rather tight) conditions on the protocol for this implication to hold.\n\n", "human_text": "  Two styles of definitions are usually considered to express that a security\nprotocol preserves the confidentiality of a data s. Reachability-based secrecy\nmeans that s should never be disclosed while equivalence-based secrecy states\nthat two executions of a protocol with distinct instances for s should be\nindistinguishable to an attacker. Although the second formulation ensures a\nhigher level of security and is closer to cryptographic notions of secrecy,\ndecidability results and automatic tools have mainly focused on the first\ndefinition so far.\n  This paper initiates a systematic investigation of the situations where\nsyntactic secrecy entails strong secrecy. We show that in the passive case,\nreachability-based secrecy actually implies equivalence-based secrecy for\ndigital signatures, symmetric and asymmetric encryption provided that the\nprimitives are probabilistic. For active adversaries, we provide sufficient\n(and rather tight) conditions on the protocol for this implication to hold.\n", "machine_text": "\nThis paper investigates the way in which reachability-based secrecy may be related to equivalence-based secrecy. It is determined that reachability-based secrecy implies equivalence-based secrecy for digital signatures, symmetric and asymmetric encryption, when the primitives used are probabilistic. Additionally, for active adversaries, there are sufficient conditions that help reach the same result. The study focuses on the ways in which reachability-based secrecy can ensure strong security, and provides decidability results and automatic tools to help.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0502}
{"prompt": "Rephrase the abstract of an article with title 'The Millennium Galaxy Catalogue: the B-band attenuation of bulge and\n  disc light and the implied cosmic dust and stellar mass densities'.\n  Based on our sample of 10095 galaxies with bulge-disc decompositions we\nderive the empirical B-band internal attenuation--inclination relation for\ngalaxy discs and their associated central bulges. Our results agree well with\nthe independently derived dust models of Tuffs et al., leading to a direct\nconstraint on the mean opacity of spiral discs of Tau_B^f = 3.8 +/- 0.7\n(central face-on B-band opacity). Depending on inclination, the B-band\nattenuation correction varies from 0.2 -- 1.1 mag for discs and from 0.8 -- 2.6\nmag for bulges. We find that, overall, 37 per cent of all B-band photons\nproduced in discs in the nearby universe are absorbed by dust, a figure that\nrises to 71 per cent for bulge photons. The severity of internal dust\nextinction is such that one must incorporate internal dust corrections in all\noptical studies of large galaxy samples. This is particularly pertinent for\noptical HST comparative evolutionary studies as the dust properties will also\nbe evolving. We use the new results to revise our recent estimates of the\nspheroid and disc luminosity functions. From our best fitting dust models we\nderive a redshift zero cosmic dust density of rho_{dust} ~ (5.3 +/- 1.7) x\n10^5, h M_{odot} Mpc^-3. This implies that (0.0083 +/- 0.0027), h per cent of\nthe baryons in the Universe are in the form of dust and (11.9 +/- 1.7), h per\ncent (Salpeter-`lite' IMF) are in the form of stars (~58 per cent reside in\ngalaxy discs, ~10 per cent in red elliptical galaxies, ~29 per cent in\nclassical galaxy bulges and the remainder in low luminosity blue spheroid\nsystems/components). [Abridged]\n\n", "human_text": "  Based on our sample of 10095 galaxies with bulge-disc decompositions we\nderive the empirical B-band internal attenuation--inclination relation for\ngalaxy discs and their associated central bulges. Our results agree well with\nthe independently derived dust models of Tuffs et al., leading to a direct\nconstraint on the mean opacity of spiral discs of Tau_B^f = 3.8 +/- 0.7\n(central face-on B-band opacity). Depending on inclination, the B-band\nattenuation correction varies from 0.2 -- 1.1 mag for discs and from 0.8 -- 2.6\nmag for bulges. We find that, overall, 37 per cent of all B-band photons\nproduced in discs in the nearby universe are absorbed by dust, a figure that\nrises to 71 per cent for bulge photons. The severity of internal dust\nextinction is such that one must incorporate internal dust corrections in all\noptical studies of large galaxy samples. This is particularly pertinent for\noptical HST comparative evolutionary studies as the dust properties will also\nbe evolving. We use the new results to revise our recent estimates of the\nspheroid and disc luminosity functions. From our best fitting dust models we\nderive a redshift zero cosmic dust density of rho_{dust} ~ (5.3 +/- 1.7) x\n10^5, h M_{odot} Mpc^-3. This implies that (0.0083 +/- 0.0027), h per cent of\nthe baryons in the Universe are in the form of dust and (11.9 +/- 1.7), h per\ncent (Salpeter-`lite' IMF) are in the form of stars (~58 per cent reside in\ngalaxy discs, ~10 per cent in red elliptical galaxies, ~29 per cent in\nclassical galaxy bulges and the remainder in low luminosity blue spheroid\nsystems/components). [Abridged]\n", "machine_text": "\nBy analyzing 10095 galaxies with bulge and disc components, this investigation offers an empirical correlation between the internal B-band attenuation and inclination of a galaxy. Aligning well with the dust models of Tuffs et al., this connection leads to a reliable estimate of the face-on opacity of spiral discs (Tau_B^f = 3.8 +/- 0.7). The attenuation varies significantly from disc to disc, ranging from 0.2 - 1.1 mag, and from 0.8 - 2.6 mag for the bulges. It is found that an astonishing 37% of all B-band photons produced in discs are absorbed by dust, increasing to 71% for photons originating from bulges. Consequently, studies of large galaxy samples must all incorporate internal dust models. Applying the new findings, the redshift 0 cosmic dust density is calculated, revealing that 0.0083 +/- 0.0027 of baryons in the universe are in the form of dust. Similarly, the data provides an exact amount of stellar matter in any form, with 11.9 +/- 1.7% being attributed to stars, the majority of which reside in galaxy discs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.214}
{"prompt": "Rephrase the abstract of an article with title 'Magnetically-driven explosions of rapidly-rotating white dwarfs\n  following Accretion-Induced Collapse'.\n  We present 2D multi-group flux-limited diffusion magnetohydrodynamics (MHD)\nsimulations of the Accretion-Induced Collapse (AIC) of a rapidly-rotating white\ndwarf. We focus on the dynamical role of MHD processes after the formation of a\nmillisecond-period protoneutron star. We find that including magnetic fields\nand stresses can lead to a powerful explosion with an energy of a few Bethe,\nrather than a weak one of at most 0.1 Bethe, with an associated ejecta mass of\n~0.1Msun, instead of a few 0.001Msun. The core is spun down by ~30% within\n500ms after bounce, and the rotational energy extracted from the core is\nchanneled into magnetic energy that generates a strong magnetically-driven\nwind, rather than a weak neutrino-driven wind. Baryon loading of the ejecta,\nwhile this wind prevails, precludes it from becoming relativistic. This\nsuggests that a GRB is not expected to emerge from such AICs during the early\nprotoneutron star phase, except in the unlikely event that the massive white\ndwarf has sufficient mass to lead to black hole formation. In addition, we\npredict both negligible 56Ni-production (that should result in an\noptically-dark, adiabatically-cooled explosion) and the ejection of 0.1Msun of\nmaterial with an electron fraction of 0.1-0.2. Such pollution by neutron-rich\nnuclei puts strong constraints on the possible rate of such AICs. Moreover,\nbeing free from ``fallback,'' such highly-magnetized millisecond-period\nprotoneutron stars may later become magnetars, and the magnetically-driven\nwinds may later transition to Poynting-flux-dominated, relativistic winds,\neventually detectable as GRBs at cosmological distances. However, the low\nexpected event rate of AICs will constrain them to be, at best, a small subset\nof GRB and/or magnetar progenitors.\n\n", "human_text": "  We present 2D multi-group flux-limited diffusion magnetohydrodynamics (MHD)\nsimulations of the Accretion-Induced Collapse (AIC) of a rapidly-rotating white\ndwarf. We focus on the dynamical role of MHD processes after the formation of a\nmillisecond-period protoneutron star. We find that including magnetic fields\nand stresses can lead to a powerful explosion with an energy of a few Bethe,\nrather than a weak one of at most 0.1 Bethe, with an associated ejecta mass of\n~0.1Msun, instead of a few 0.001Msun. The core is spun down by ~30% within\n500ms after bounce, and the rotational energy extracted from the core is\nchanneled into magnetic energy that generates a strong magnetically-driven\nwind, rather than a weak neutrino-driven wind. Baryon loading of the ejecta,\nwhile this wind prevails, precludes it from becoming relativistic. This\nsuggests that a GRB is not expected to emerge from such AICs during the early\nprotoneutron star phase, except in the unlikely event that the massive white\ndwarf has sufficient mass to lead to black hole formation. In addition, we\npredict both negligible 56Ni-production (that should result in an\noptically-dark, adiabatically-cooled explosion) and the ejection of 0.1Msun of\nmaterial with an electron fraction of 0.1-0.2. Such pollution by neutron-rich\nnuclei puts strong constraints on the possible rate of such AICs. Moreover,\nbeing free from ``fallback,'' such highly-magnetized millisecond-period\nprotoneutron stars may later become magnetars, and the magnetically-driven\nwinds may later transition to Poynting-flux-dominated, relativistic winds,\neventually detectable as GRBs at cosmological distances. However, the low\nexpected event rate of AICs will constrain them to be, at best, a small subset\nof GRB and/or magnetar progenitors.\n", "machine_text": "\nThis research examines the power of magnetohydrodynamics (MHD) when applied to rapidly-rotating white dwarf stars going through Accretion-Induced Collapse (AIC). Our simulations, using 2D multi-group flux-limited diffusion MHD, find that including MHD processes can create an explosion with a power of a few Bethe - up from a mere 0.1Bethe - and an ejecta mass of ~0.1Msun, compared to 0.001Msun without the addition of magnetic fields and stresses. The core is substantially spun down and the rotational energy is channeled into magnetic energy, producing a strong magnetically-driven wind instead of a weak one driven by neutrinos. This wind has too much baryon load to become relativistic, suggesting an unlikely GRB event to emerge. Our study also predicts low production of 56Ni, likely making this an optically-dark, adiabatically-cooled explosion, as well as an ejection of neutron-rich nuclei. We suggest that such highly-magnetized millisecond-period protoneutron stars may later form into magnetars, and that their magnetically-driven winds may transition to Poynting-flux-dominated, potentially detectable GRBs at cosmological distances. Nevertheless, the expectation of a low rate of AICs will limit them to a miniscule subset of GRB and/or magnetar progenitors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3678}
{"prompt": "Rephrase the abstract of an article with title 'Characterization of open cluster remnants'.\n  Despite progress in the theoretical knowledge of open cluster remnants and\nthe growing search for observational identifications in recent years, open\nquestions still remain. The methods used to analyze open cluster remnants and\ncriteria to define them as physical systems are not homogeneous. In this work\nwe present a systematic method for studying these objects that provides a view\nof their properties and allows their characterization. Eighteen remnant\ncandidates are analyzed by means of photometric and proper motion data. These\ndata provide information on objects and their fields. We establish criteria for\ncharacterizing open cluster remnants, taking observational uncertainties into\naccount. 2MASS J and H photometry is employed (i) to study structural\nproperties of the objects by means of radial stellar density profiles, (ii) to\ntest for any similarity between objects and fields with a statistical\ncomparison method applied to the distributions of stars in the CMDs, and (iii)\nto obtain ages, reddening values, and distances from the CMD, taking an index\nof isochrone fit into account. The UCAC2 proper motions allowed an objective\ncomparison between objects and large solid angle offset fields. The objective\nanalysis based on the present methods indicates 13 open-cluster remnants in the\nsample. Evidence of the presence of binary stars is found, as expected for\ndynamically evolved systems. Finally, we infer possible evolutionary stages\namong remnants from the structure, proper motion, and CMD distributions. The\nlow stellar statistics for individual objects is overcome by means of the\nconstruction of composite proper motion and CMD diagrams. The distributions of\nremnants in the composite diagrams resemble the single-star and unresolved\nbinary star distributions of open clusters.\n\n", "human_text": "  Despite progress in the theoretical knowledge of open cluster remnants and\nthe growing search for observational identifications in recent years, open\nquestions still remain. The methods used to analyze open cluster remnants and\ncriteria to define them as physical systems are not homogeneous. In this work\nwe present a systematic method for studying these objects that provides a view\nof their properties and allows their characterization. Eighteen remnant\ncandidates are analyzed by means of photometric and proper motion data. These\ndata provide information on objects and their fields. We establish criteria for\ncharacterizing open cluster remnants, taking observational uncertainties into\naccount. 2MASS J and H photometry is employed (i) to study structural\nproperties of the objects by means of radial stellar density profiles, (ii) to\ntest for any similarity between objects and fields with a statistical\ncomparison method applied to the distributions of stars in the CMDs, and (iii)\nto obtain ages, reddening values, and distances from the CMD, taking an index\nof isochrone fit into account. The UCAC2 proper motions allowed an objective\ncomparison between objects and large solid angle offset fields. The objective\nanalysis based on the present methods indicates 13 open-cluster remnants in the\nsample. Evidence of the presence of binary stars is found, as expected for\ndynamically evolved systems. Finally, we infer possible evolutionary stages\namong remnants from the structure, proper motion, and CMD distributions. The\nlow stellar statistics for individual objects is overcome by means of the\nconstruction of composite proper motion and CMD diagrams. The distributions of\nremnants in the composite diagrams resemble the single-star and unresolved\nbinary star distributions of open clusters.\n", "machine_text": "This article presents a systematic characterization of open cluster remnants. Photometric and proper motion data are used to obtain structural properties, ages, reddening values and distances, as well as evidence for the presence of binary stars. Criteria for defining these objects as physical systems are established. These analyses shed light on potential evolutionary stages of open clusters and enable the detection of thirteen searchable open cluster remnants. Statistical comparison and composite diagrams are used to overcome the limitations of small stellar samples. These diagrams resemble the distributions of single-star and unresolved binary star systems in open clusters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1159}
{"prompt": "Rephrase the abstract of an article with title 'Atomic Electric Dipole Moments: The Schiff Theorem and Its Corrections'.\n  Searches for the permanent electric dipole moments (EDMs) of diamagnetic\natoms provide powerful probes of CP-violating hadronic and semileptonic\ninteractions. The theoretical interpretation of such experiments, however,\nrequires careful implementation of a well-known theorem by Schiff that implies\na vanishing net EDM for an atom built entirely from point-like, nonrelativistic\nconstituents that interact only electrostatically. Any experimental observation\nof a nonzero atomic EDM would result from corrections to the point-like,\nnonrelativistic, electrostatic assumption. We reformulate Schiff's theorem at\nthe operator level and delineate the electronic and nuclear operators whose\natomic matrix elements generate corrections to \"Schiff screening\". We obtain a\nform for the operator responsible for the leading correction associated with\nfinite nuclear size -- the so-called \"Schiff moment\" operator -- and observe\nthat it differs from the corresponding operator used in previous Schiff moment\ncomputations. We show that the more general Schiff moment operator reduces to\nthe previously employed operator only under certain approximations that are not\ngenerally justified. We also identify other corrections to Schiff screening\nthat may not be included properly in previous theoretical treatments. We\ndiscuss practical considerations for obtaining a complete computation of\ncorrections to Schiff screening in atomic EDM calculations.\n\n", "human_text": "  Searches for the permanent electric dipole moments (EDMs) of diamagnetic\natoms provide powerful probes of CP-violating hadronic and semileptonic\ninteractions. The theoretical interpretation of such experiments, however,\nrequires careful implementation of a well-known theorem by Schiff that implies\na vanishing net EDM for an atom built entirely from point-like, nonrelativistic\nconstituents that interact only electrostatically. Any experimental observation\nof a nonzero atomic EDM would result from corrections to the point-like,\nnonrelativistic, electrostatic assumption. We reformulate Schiff's theorem at\nthe operator level and delineate the electronic and nuclear operators whose\natomic matrix elements generate corrections to \"Schiff screening\". We obtain a\nform for the operator responsible for the leading correction associated with\nfinite nuclear size -- the so-called \"Schiff moment\" operator -- and observe\nthat it differs from the corresponding operator used in previous Schiff moment\ncomputations. We show that the more general Schiff moment operator reduces to\nthe previously employed operator only under certain approximations that are not\ngenerally justified. We also identify other corrections to Schiff screening\nthat may not be included properly in previous theoretical treatments. We\ndiscuss practical considerations for obtaining a complete computation of\ncorrections to Schiff screening in atomic EDM calculations.\n", "machine_text": "\nInvestigations into the longevity of electric dipole moments (EDMs) of diamagnetic atoms prove as dependable measures of CP-violating hadronic and semi-leptonic interactions. As such, interpretation of the results of these experiments necessitate cautious enforcement of the widely observed theorem devised by Schiff, postulating a lack of a permanent EDM in an atom made entirely of point- like non- relativistic constituents interacting only electrostatically. Conversely, any perceived non-zero atomic EDM would trace back to deviations in the point-like, non-relativistic, electrostatic theory. We herein restate Schiff's theorem on the operator level and compile a distribution of atomic matrix elements from both electronic and nuclear operators tending to invalidate the suggestive \"Schiff screening\". We also enunciate a pattern for the frontrunner of such deviations -- the \"Schiff moment\" operator, which varies in contrast to the already utilized operators in earlier Schiff moment estimations. We demonstrate that the more general Schiff moment operator defaults to prior use operators only under certain tolerances that are often not reasonable. Additionally, we distinguish other alterations to Schiff screening that may not have been previously involved in theoretical dealings. We further intend to decorate a comprehensive analysis of corrections to Schiff screening in atomic EDM estimations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1681}
{"prompt": "Rephrase the abstract of an article with title 'Sterile neutrino oscillations after first MiniBooNE results'.\n  In view of the recent results from the MiniBooNE experiment we revisit the\nglobal neutrino oscillation fit to short-baseline neutrino data by adding one\nor two sterile neutrinos with eV-scale masses to the three Standard Model\nneutrinos, and for the first time we consider also the global fit with three\nsterile neutrinos. Four-neutrino oscillations of the (3+1) type have been only\nmarginally allowed before the recent MiniBooNE results, and become even more\ndisfavored with the new data (at the level of $4\\sigma$). In the framework of\nso-called (3+2) five-neutrino mass schemes we find severe tension between\nappearance and disappearance experiments at the level of more than $3\\sigma$,\nand hence no satistfactory fit to the global data is possible in (3+2) schemes.\nThis tension remains also when a third sterile neutrino is added, and the\nquality of the global fit does not improve significantly in a (3+3) scheme. It\nshould be noted, however, that in models with more than one sterile neutrino\nthe MiniBooNE results are in perfect agreement with the LSND appearance\nevidence, thanks to the possibility of CP violation available in such\noscillation schemes. Furthermore, if disappearance data are not taken into\naccount (3+2) oscillations provide an excellent fit to the full MiniBooNE\nspectrum including the event excess at low energies.\n\n", "human_text": "  In view of the recent results from the MiniBooNE experiment we revisit the\nglobal neutrino oscillation fit to short-baseline neutrino data by adding one\nor two sterile neutrinos with eV-scale masses to the three Standard Model\nneutrinos, and for the first time we consider also the global fit with three\nsterile neutrinos. Four-neutrino oscillations of the (3+1) type have been only\nmarginally allowed before the recent MiniBooNE results, and become even more\ndisfavored with the new data (at the level of $4\\sigma$). In the framework of\nso-called (3+2) five-neutrino mass schemes we find severe tension between\nappearance and disappearance experiments at the level of more than $3\\sigma$,\nand hence no satistfactory fit to the global data is possible in (3+2) schemes.\nThis tension remains also when a third sterile neutrino is added, and the\nquality of the global fit does not improve significantly in a (3+3) scheme. It\nshould be noted, however, that in models with more than one sterile neutrino\nthe MiniBooNE results are in perfect agreement with the LSND appearance\nevidence, thanks to the possibility of CP violation available in such\noscillation schemes. Furthermore, if disappearance data are not taken into\naccount (3+2) oscillations provide an excellent fit to the full MiniBooNE\nspectrum including the event excess at low energies.\n", "machine_text": "In light of recent outcomes from the MiniBooNE endeavor, we reexamine the worldwide neutrino oscillation fit of short-range neutrino information by including one or two sterile neutrinos with eV-scale masses to the three Standard Model neutrinos, and furthermore, consider the global fit with three sterile neutrinos for the first time. Prior to the currentMiniBooNE results, four-neutrino oscillations of the (3+1) type had just been slightly approved, and become much less desirable with the new data (at a 4-sigma level). In the setting of so-called (3+2) five-neutrino mass models we observe an extreme discrepancy between perceived and vanishing trials at a sum of 3-sigma or better, correspondingly, no satisfactory fit to the total information can be accomplished in (3+2) frames. This pressure stays unaltered when a third sterile neutrino is incorporated and the nature of the overall fit does not noticeable improve in a(3+3) plan. In any case, it should be noticed that in models with in excess of one sterile neutrino the MiniBooNE outcomes coordinate perfectly with the LSND appearance proof, because of the presence of CP violation accessible in such oscillation plans. Moreover, if vanishing information isn't thought about,(3+2) oscillations give a superb fit to the complete MiniBooNE range including the occasion abundance at low energies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0107}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological perturbations in Palatini modified gravity'.\n  Two approaches to the study of cosmological density perturbations in modified\ntheories of Palatini gravity have recently been discussed. These utilise,\nrespectively, a generalisation of Birkhoff's theorem and a direct linearization\nof the gravitational field equations. In this paper these approaches are\ncompared and contrasted. The general form of the gravitational lagrangian for\nwhich the two frameworks yield identical results in the long-wavelength limit\nis derived. This class of models includes the case where the lagrangian is a\npower-law of the Ricci curvature scalar. The evolution of density perturbations\nin theories of the type $f(R)=R-c /R^ b$ is investigated numerically. It is\nfound that the results obtained by the two methods are in good agreement on\nsufficiently large scales when the values of the parameters (b,c) are\nconsistent with current observational constraints. However, this agreement\nbecomes progressively poorer for models that differ significantly from the\nstandard concordance model and as smaller scales are considered.\n\n", "human_text": "  Two approaches to the study of cosmological density perturbations in modified\ntheories of Palatini gravity have recently been discussed. These utilise,\nrespectively, a generalisation of Birkhoff's theorem and a direct linearization\nof the gravitational field equations. In this paper these approaches are\ncompared and contrasted. The general form of the gravitational lagrangian for\nwhich the two frameworks yield identical results in the long-wavelength limit\nis derived. This class of models includes the case where the lagrangian is a\npower-law of the Ricci curvature scalar. The evolution of density perturbations\nin theories of the type $f(R)=R-c /R^ b$ is investigated numerically. It is\nfound that the results obtained by the two methods are in good agreement on\nsufficiently large scales when the values of the parameters (b,c) are\nconsistent with current observational constraints. However, this agreement\nbecomes progressively poorer for models that differ significantly from the\nstandard concordance model and as smaller scales are considered.\n", "machine_text": "\nThis paper provides a comparison of two different ways to understand cosmological density perturbations in Palatini modified gravity. The first involves a generalization of Birkhoff's theorem and the second is through a linearization of the gravitational field equations. The findings are used to determine a general form for the gravitational lagrangian that produces the same results for the long wave limit. Additionally, the perturbation evolution for a certain type of lagrangian (with parameters b and c) is calculated, with results that match up to the observational data. It is also noted that these results don't hold up for models deviating greatly from the standard concordance model and on increasingly smaller scales.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0232}
{"prompt": "Rephrase the abstract of an article with title 'Systematic analysis of a spin-susceptibility representation of the\n  pairing interaction in the 2D Hubbard model'.\n  A dynamic cluster quantum Monte Carlo algorithm is used to study a spin\nsusceptibility representation of the pairing interaction for the\ntwo-dimensional Hubbard model with an on-site Coulomb interaction equal to the\nbandwidth for various doping levels. We find that the pairing interaction is\nwell approximated by ${3/2}\\Ub(T)^2\\chi(K-K')$ with an effective temperature\nand doping dependent coupling $\\Ub(T)$ and the numerically calculated spin\nsusceptibility $\\chi(K-K')$. We show that at low temperatures, $\\Ub$ may be\naccurately determined from a corresponding spin susceptibility based\ncalculation of the single-particle self-energy. We conclude that the strength\nof the d-wave pairing interaction, characterized by the mean-field transition\ntemperature, can be determined from a knowledge of the dressed spin\nsusceptibility and the nodal quasiparticle spectral weight. This has important\nimplications with respect to the questions of whether spin fluctuations are\nresponsible for pairing in the high-T$_c$ cuprates.\n\n", "human_text": "  A dynamic cluster quantum Monte Carlo algorithm is used to study a spin\nsusceptibility representation of the pairing interaction for the\ntwo-dimensional Hubbard model with an on-site Coulomb interaction equal to the\nbandwidth for various doping levels. We find that the pairing interaction is\nwell approximated by ${3/2}\\Ub(T)^2\\chi(K-K')$ with an effective temperature\nand doping dependent coupling $\\Ub(T)$ and the numerically calculated spin\nsusceptibility $\\chi(K-K')$. We show that at low temperatures, $\\Ub$ may be\naccurately determined from a corresponding spin susceptibility based\ncalculation of the single-particle self-energy. We conclude that the strength\nof the d-wave pairing interaction, characterized by the mean-field transition\ntemperature, can be determined from a knowledge of the dressed spin\nsusceptibility and the nodal quasiparticle spectral weight. This has important\nimplications with respect to the questions of whether spin fluctuations are\nresponsible for pairing in the high-T$_c$ cuprates.\n", "machine_text": "\n\nThis work utilizes a dynamic cluster quantum Monte Carlo algorithm to analyze the spin susceptibility representation of the pairing interaction in the two-dimensional Hubbard model with an on-site Coulomb interaction equal to the bandwidth for different doping levels. It was determined that the pairing interaction is approximately ${3/2}\\Ub(T)^2\\chi(K-K')$ with a temperature and doping dependent coupling $\\Ub(T)$ and the numerically calculated spin susceptibility $\\chi(K-K')$. Low temperatures were found to be accurately expressed in terms of the single-particle self-energy when the spin susceptibility was incorporated. Our findings suggest that the strength of d-wave pairing, which is marked by the mean-field transition temperature, can be established through the use of dressed spin susceptibility and the nodal quasiparticle spectral weight. As a result, these studies have crucial implications in regards to the question of whether spin fluctuations are responsible for pairing in the high-T$_c$ cuprates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0241}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic rays and the primordial gas'.\n  One of the most outstanding problems in the gravitational collapse scenario\nof early structure formation is the cooling of primordial gas to allow for\nsmall mass objects to form. As the neutral primordial gas is a poor radiator at\ntemperatures (T\\le10^4\\unit{K}), molecular hydrogen is needed for further\ncooling down to temperatures (T\\sim100\\unit{K}). The formation of molecular\nhydrogen is catalyzed by the presence of free electrons, which could be\nprovided by the ionization due to an early population of cosmic rays. In order\nto investigate this possibility we developed a code to study the effects of\nionizing cosmic rays on the thermal and chemical evolution of primordial gas.\nWe found that cosmic rays can provide enough free electrons needed for the\nformation of molecular hydrogen, and therefore can increase the cooling ability\nof such primordial gas under following conditions: A dissociating photon flux\nwith (F<10^{-18}\\unit{erg cm^{-2} Hz^{-1} s^{-1}}), initial temperature of the\ngas (\\sim10^{3}\\unit{K}), total gas number densities (n\\ge1\\unit{cm^{-3}}),\nCosmic ray sources with (\\dot{\\epsilon}_{CR}>10^{-33}\\unit{erg cm^{-3}\ns^{-1}}).\n\n", "human_text": "  One of the most outstanding problems in the gravitational collapse scenario\nof early structure formation is the cooling of primordial gas to allow for\nsmall mass objects to form. As the neutral primordial gas is a poor radiator at\ntemperatures (T\\le10^4\\unit{K}), molecular hydrogen is needed for further\ncooling down to temperatures (T\\sim100\\unit{K}). The formation of molecular\nhydrogen is catalyzed by the presence of free electrons, which could be\nprovided by the ionization due to an early population of cosmic rays. In order\nto investigate this possibility we developed a code to study the effects of\nionizing cosmic rays on the thermal and chemical evolution of primordial gas.\nWe found that cosmic rays can provide enough free electrons needed for the\nformation of molecular hydrogen, and therefore can increase the cooling ability\nof such primordial gas under following conditions: A dissociating photon flux\nwith (F<10^{-18}\\unit{erg cm^{-2} Hz^{-1} s^{-1}}), initial temperature of the\ngas (\\sim10^{3}\\unit{K}), total gas number densities (n\\ge1\\unit{cm^{-3}}),\nCosmic ray sources with (\\dot{\\epsilon}_{CR}>10^{-33}\\unit{erg cm^{-3}\ns^{-1}}).\n", "machine_text": "\nThis study examines the possible role of cosmic rays in the thermal and chemical evolution of primordial gas. It is proposed that an early population of cosmic rays may introduce enough free electrons to enable the formation of molecular hydrogen, therefore cooling the gas to temperatures as low as 100K. A code was developed to simulate these effects, with findings that cosmic rays can help with cooling under specific conditions, for example an intensity of dissociating photons less than 10^(-18)erg cm^(-2) s^(-1), an initial temperature of ~ 10^3 K, number densities greater than or equal to 1 cm^(-3) and cosmic ray sources producing a rate greater than 10^(-33) erg cm^(-3) s^(-1).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4541}
{"prompt": "Rephrase the abstract of an article with title 'Yield design formulation for porous media subjected to flow, using\n  approximate pressure field. Calcul \\`a la rupture en pr\\'esence d'un\n  \\'ecoulement : formulation cin\\'ematique avec un champ de pression approch\\'e'.\n  Yield design formulation for porous media subjected to flow, using\napproximate pressure field. We attempt here to use the kinematic method of\nyield design in the case of a porous medium subjected to flow (with or without\nfree surface), without looking for the exact solution of the pressure field.\nThe method proposed here is based on the use of approximate pressure fields. In\nthis paper, we show how, under different conditions concerning the yield\ncriterion and the velocity field, the use of such approximate fields allows to\nobtain a necessary condition for stability without having to find the real\npressure field. Nous cherchons ici \\`a utiliser la m\\'ethode cin\\'ematique du\ncalcul \\`a la rupture dans le cas d'un milieu poreux soumis \\`a un \\'ecoulement\navec ou sans surface libre sans conna\\^itre la solution exacte du champ de\npression. La m\\'ethode propos\\'ee ici repose sur l'utilisation de champs de\npression approch\\'es par d\\'efaut. Nous montrerons comment sous certaines\nconditions portant sur le crit\\`ere de r\\'esistance et sur le champ de vitesse\nutilis\\'e, l'utilisation de tels champs de pression approch\\'es permet\nd'obtenir une condition n\\'ecessaire de stabilit\\'e sans avoir \\`a d\\'eterminer\nexactement l'\\'ecoulement.\n\n", "human_text": "  Yield design formulation for porous media subjected to flow, using\napproximate pressure field. We attempt here to use the kinematic method of\nyield design in the case of a porous medium subjected to flow (with or without\nfree surface), without looking for the exact solution of the pressure field.\nThe method proposed here is based on the use of approximate pressure fields. In\nthis paper, we show how, under different conditions concerning the yield\ncriterion and the velocity field, the use of such approximate fields allows to\nobtain a necessary condition for stability without having to find the real\npressure field. Nous cherchons ici \\`a utiliser la m\\'ethode cin\\'ematique du\ncalcul \\`a la rupture dans le cas d'un milieu poreux soumis \\`a un \\'ecoulement\navec ou sans surface libre sans conna\\^itre la solution exacte du champ de\npression. La m\\'ethode propos\\'ee ici repose sur l'utilisation de champs de\npression approch\\'es par d\\'efaut. Nous montrerons comment sous certaines\nconditions portant sur le crit\\`ere de r\\'esistance et sur le champ de vitesse\nutilis\\'e, l'utilisation de tels champs de pression approch\\'es permet\nd'obtenir une condition n\\'ecessaire de stabilit\\'e sans avoir \\`a d\\'eterminer\nexactement l'\\'ecoulement.\n", "machine_text": "This paper presents a yield design formulation for porous media subjected to flow, using approximate pressure field instead of the exact pressure field.  We describe how under certain conditions concerning the yield criterion and the velocity field, the approximate fields enable to obtain a necessary condition for stability. This kinematic method allows us a better understanding of different aspect of the flow in such porous media. \n\nCe document pr\\'esente une formulation du calcul \\`a la rupture pour un milieu poreux soumis \\`a un \\'ecoulement, en utilisant un champ de pression approch\\'e au lieu du champ de pression exact.  Nous expliquons comment dans certaines conditions concernant le crit\\`ere de r\\'esistance et le champ de vitesse, les champs de pression approximatifs permettent d'obtenir une condition n\\'ecessaire de stabilit\\'e. Cette m\\'ethode cin\\'ematique nous offre une meilleure compr\\'ehension des diff\\'erents aspects de l'\\'ecoulement dans un milieu poreux.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2364}
{"prompt": "Rephrase the abstract of an article with title 'Precision measurements of large scale structure with future type Ia\n  supernova surveys'.\n  Type Ia supernovae are currently the best known standard candles at\ncosmological distances. In addition to providing a powerful probe of dark\nenergy they are an ideal source of information about the peculiar velocity\nfield of the local universe. Even with the very small number of supernovae\npresently available it has been possible to measure the dipole and quadrupole\nof the local velocity field out to z~0.025. With future continuous all-sky\nsurveys like the LSST project the luminosity distances of tens of thousands of\nnearby supernovae will be measured accurately. This will allow for a\ndetermination of the local velocity structure of the universe as a function of\nredshift with unprecedented accuracy, provided the redshifts of the host\ngalaxies are known. Using catalogues of mock surveys we estimate that future\nlow redshift supernova surveys will be able to probe sigma-8 to a precision of\nroughly 5% at 95% C.L. This is comparable to the precision in future galaxy and\nweak lensing surveys and with a relatively modest observational effort it will\nprovide a crucial cross-check on future measurements of the matter power\nspectrum.\n\n", "human_text": "  Type Ia supernovae are currently the best known standard candles at\ncosmological distances. In addition to providing a powerful probe of dark\nenergy they are an ideal source of information about the peculiar velocity\nfield of the local universe. Even with the very small number of supernovae\npresently available it has been possible to measure the dipole and quadrupole\nof the local velocity field out to z~0.025. With future continuous all-sky\nsurveys like the LSST project the luminosity distances of tens of thousands of\nnearby supernovae will be measured accurately. This will allow for a\ndetermination of the local velocity structure of the universe as a function of\nredshift with unprecedented accuracy, provided the redshifts of the host\ngalaxies are known. Using catalogues of mock surveys we estimate that future\nlow redshift supernova surveys will be able to probe sigma-8 to a precision of\nroughly 5% at 95% C.L. This is comparable to the precision in future galaxy and\nweak lensing surveys and with a relatively modest observational effort it will\nprovide a crucial cross-check on future measurements of the matter power\nspectrum.\n", "machine_text": "\nThe rigorous determination of cosmological parameters such as dark energy and the measurement of large-scale structure quantities like sigma-8 require highly accurate probes of peculiar velocities in the universe. Type Ia supernova surveys promise to provide just such results. Based on a small number of supernovae presently available, it is already possible to measure the dipole and quadrupole of the local velocity field out to z ~ 0.025. With an upcoming continuous all-sky survey like the Large Synoptic Survey Telescope (LSST), various luminosity distances of the surrounding supernovae can be accurately recorded. This will allow for higher precision characterizations of local velocity fields of the universe, given that the host galaxy's redshifts are known. Utilizing mock catalogues from survey projections, it can be estimated that a future supernova survey has the ability to measure sigma-8 with a roughly 5% precision at 95%C.L. This level of performance is nearly comparable to upcoming galaxy and weak lensing surveys, requiring relatively little observation effort for such a major confirmation of the matter power spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0979}
{"prompt": "Rephrase the abstract of an article with title 'Notes on Liouville Theory at c<=1'.\n  The continuation of the Liouville conformal field theory to c<=1 is\nconsidered. The viability of an interpretation involving a timelike boson which\nis the conformal factor for two-dimensional asymptotically de Sitter geometries\nis examined. The conformal bootstrap leads to a three-point function with a\nunique analytic factor which is the same as that which appears along with the\nfusion coefficients in the minimal models. A corresponding non-analytic factor\nproduces a well-defined metric on fields only when the central charge is\nrestricted to those of the topological minimal models, and when the conformal\ndimensions satisfy h>(c-1)/24. However, the theories considered here have a\ncontinuous spectrum which excludes the degenerate representations appearing in\nthe minimal models. The c=1 theory has been investigated previously using\nsimilar techniques, and is identical to a non-rational CFT which arises as a\nlimit of unitary minimal models. When coupled to unitary matter fields, the\nnon-unitary theories with c<=-2 produce string amplitudes which are similar to\nthose of the minimal string.\n\n", "human_text": "  The continuation of the Liouville conformal field theory to c<=1 is\nconsidered. The viability of an interpretation involving a timelike boson which\nis the conformal factor for two-dimensional asymptotically de Sitter geometries\nis examined. The conformal bootstrap leads to a three-point function with a\nunique analytic factor which is the same as that which appears along with the\nfusion coefficients in the minimal models. A corresponding non-analytic factor\nproduces a well-defined metric on fields only when the central charge is\nrestricted to those of the topological minimal models, and when the conformal\ndimensions satisfy h>(c-1)/24. However, the theories considered here have a\ncontinuous spectrum which excludes the degenerate representations appearing in\nthe minimal models. The c=1 theory has been investigated previously using\nsimilar techniques, and is identical to a non-rational CFT which arises as a\nlimit of unitary minimal models. When coupled to unitary matter fields, the\nnon-unitary theories with c<=-2 produce string amplitudes which are similar to\nthose of the minimal string.\n", "machine_text": "In this article, the aspects of Liouville Theory in relation to c<=1 are discussed. The analysis includes an examination of whether an interpretation with a timelike boson coincides with two-dimensional de Sitter asymptotic geometry. The conformal bootstrap further leads to a singular three-point function. Adding a metric on fields brings the conformal charge to the degenerate values of the topological minimal models. Regarding the continuous spectrum, the methods employed here differ compared to those of the minimal models. Prior studies of c=1 theory have demonstrted that it is analogous to a non-rational CFT, which arises in the limit of the unitary minimal models. Additionally, coupling the non-unitary theories with c<=-2 to unitary matter fields have resulted in string amplitudes reminiscent of the minimal strings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0365}
{"prompt": "Rephrase the abstract of an article with title 'A Finite Element framework for computation of protein normal modes and\n  mechanical response'.\n  A coarse-grained computational procedure based on the Finite Element Method\nis proposed to calculate the normal modes and mechanical response of proteins\nand their supramolecular assemblies. Motivated by the elastic network model,\nproteins are modeled as homogeneous isotropic elastic solids with volume\ndefined by their solvent-excluded surface. The discretized Finite Element\nrepresentation is obtained using a surface simplification algorithm that\nfacilitates the generation of models of arbitrary prescribed spatial\nresolution. The procedure is applied to compute the normal modes of a mutant of\nT4 phage lysozyme and of filamentous actin, as well as the critical Euler\nbuckling load of the latter when subject to axial compression. Results compare\nfavorably with all-atom normal mode analysis, the Rotation Translation Blocks\nprocedure, and experiment. The proposed methodology establishes a computational\nframework for the calculation of protein mechanical response that facilitates\nthe incorporation of specific atomic-level interactions into the model,\nincluding aqueous-electrolyte-mediated electrostatic effects. The procedure is\nequally applicable to proteins with known atomic coordinates as it is to\nelectron density maps of proteins, protein complexes, and supramolecular\nassemblies of unknown atomic structure.\n\n", "human_text": "  A coarse-grained computational procedure based on the Finite Element Method\nis proposed to calculate the normal modes and mechanical response of proteins\nand their supramolecular assemblies. Motivated by the elastic network model,\nproteins are modeled as homogeneous isotropic elastic solids with volume\ndefined by their solvent-excluded surface. The discretized Finite Element\nrepresentation is obtained using a surface simplification algorithm that\nfacilitates the generation of models of arbitrary prescribed spatial\nresolution. The procedure is applied to compute the normal modes of a mutant of\nT4 phage lysozyme and of filamentous actin, as well as the critical Euler\nbuckling load of the latter when subject to axial compression. Results compare\nfavorably with all-atom normal mode analysis, the Rotation Translation Blocks\nprocedure, and experiment. The proposed methodology establishes a computational\nframework for the calculation of protein mechanical response that facilitates\nthe incorporation of specific atomic-level interactions into the model,\nincluding aqueous-electrolyte-mediated electrostatic effects. The procedure is\nequally applicable to proteins with known atomic coordinates as it is to\nelectron density maps of proteins, protein complexes, and supramolecular\nassemblies of unknown atomic structure.\n", "machine_text": "This article presents a Finite Element framework for obtaining the normal modes and mechanical responses of proteins and assemblies of proteins. Motivated by the Elastic Network model, these proteins are modeled as uniform and anisotropic elastic solids with volume defined by their solvent-excluded surface. A surface simplification algorithm is used to represent the Finite Element structure which aids in generating models of various spatial resolutions. The procedure is applied to a T4 phage lysozyme mutant and a filamentous actin to determine their normal modes as well as the critical Euler buckling load when subject to axial compression. The results of this method favorably compare with experimental data, Rotation Translation Blocks and all-atom normal mode analyses. This procedure can incorporate atomic-level interactions, such as aqueous-electrolyte-mediated electrostatics, and can be usedon proteins with or without known atomic coordinates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0634}
{"prompt": "Rephrase the abstract of an article with title 'The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\n  Serpens YSO Population As Observed With IRAC and MIPS'.\n  We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy\nobservations of the Serpens star-forming region. In particular we present a set\nof criteria for isolating bona fide young stellar objects, YSO's, from the\nextensive background contamination by extra-galactic objects. We then discuss\nthe properties of the resulting high confidence set of YSO's. We find 235 such\nobjects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An\nadditional set of 51 lower confidence YSO's outside this area is identified\nfrom the MIPS data combined with 2MASS photometry. We describe two sets of\nresults, color-color diagrams to compare our observed source properties with\nthose of theoretical models for star/disk/envelope systems and our own modeling\nof the subset of our objects that appear to be star+disks. These objects\nexhibit a very wide range of disk properties, from many that can be fit with\nactively accreting disks to some with both passive disks and even possibly\ndebris disks. We find that the luminosity function of YSO's in Serpens extends\ndown to at least a few x .001 Lsun or lower for an assumed distance of 260 pc.\nThe lower limit may be set by our inability to distinguish YSO's from\nextra-galactic sources more than by the lack of YSO's at very low luminosities.\nA spatial clustering analysis shows that the nominally less-evolved YSO's are\nmore highly clustered than the later stages and that the background\nextra-galactic population can be fit by the same two-point correlation function\nas seen in other extra-galactic studies. We also present a table of matches\nbetween several previous infrared and X-ray studies of the Serpens YSO\npopulation and our Spitzer data set.\n\n", "human_text": "  We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy\nobservations of the Serpens star-forming region. In particular we present a set\nof criteria for isolating bona fide young stellar objects, YSO's, from the\nextensive background contamination by extra-galactic objects. We then discuss\nthe properties of the resulting high confidence set of YSO's. We find 235 such\nobjects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An\nadditional set of 51 lower confidence YSO's outside this area is identified\nfrom the MIPS data combined with 2MASS photometry. We describe two sets of\nresults, color-color diagrams to compare our observed source properties with\nthose of theoretical models for star/disk/envelope systems and our own modeling\nof the subset of our objects that appear to be star+disks. These objects\nexhibit a very wide range of disk properties, from many that can be fit with\nactively accreting disks to some with both passive disks and even possibly\ndebris disks. We find that the luminosity function of YSO's in Serpens extends\ndown to at least a few x .001 Lsun or lower for an assumed distance of 260 pc.\nThe lower limit may be set by our inability to distinguish YSO's from\nextra-galactic sources more than by the lack of YSO's at very low luminosities.\nA spatial clustering analysis shows that the nominally less-evolved YSO's are\nmore highly clustered than the later stages and that the background\nextra-galactic population can be fit by the same two-point correlation function\nas seen in other extra-galactic studies. We also present a table of matches\nbetween several previous infrared and X-ray studies of the Serpens YSO\npopulation and our Spitzer data set.\n", "machine_text": "\nThis work presents an analysis of the c2d Spitzer Legacy observations of the star-forming region of Serpens. We propose criteria to distinguish genuine young stellar objects, YSOs, from the contamination by extra-galactic sources. Using these criteria, we record 286 YSOs in total, 7.5% of which have been identified by previous infrared and X-ray studies. We further analyse the colors of the observed sources and compare them with those of theoretical star/disk/envelope models. Objects that appear to be stars plus disks, to the extent of our observational capacity, demonstrate a diverse range of disk properties from active disks to passive disks and even debris disks. We also observe that the luminosity function of YSOs in Serpens extends at least to 0.001 Lsun or lower for a 260-pc distance. Additionally, we observe that less evolved YSOs tend to be more clustered from a spatial correlation analysis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0009}
{"prompt": "Rephrase the abstract of an article with title 'Red Sequence Cluster Finding in the Millennium Simulation'.\n  We investigate halo mass selection properties of red-sequence cluster finders\nusing galaxy populations of the Millennium Simulation (MS). A clear red\nsequence exists for MS galaxies in massive halos at redshifts z < 1, and we use\nthis knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h\nprojections of the simulated volume. At low redshift (z=0.4), we find that 90%\nof the clusters found have galaxy membership dominated by a single, real-space\nhalo, and that 10% are blended systems for which no single halo contributes a\nmajority of a cluster's membership. At z=1, the fraction of blends increases to\n22%, as weaker redshift evolution in observed color extends the comoving length\nprobed by a fixed range of color. Other factors contributing to the increased\nblending at high-z include broadening of the red sequence and confusion from a\nlarger number of intermediate mass halos hosting bright red galaxies of\nmagnitude similar to those in higher mass halos. Our method produces catalogs\nof cluster candidates whose halo mass selection function, p(M|\\Ngal,z), is\ncharacterized by a bimodal log-normal model with a dominant component that\nreproduces well the real-space distribution, and a redshift-dependent tail that\nis broader and displaced by a factor ~2 lower in mass. We discuss implications\nfor X-ray properties of optically selected clusters and offer ideas for\nimproving both mock catalogs and cluster-finding in future surveys.\n\n", "human_text": "  We investigate halo mass selection properties of red-sequence cluster finders\nusing galaxy populations of the Millennium Simulation (MS). A clear red\nsequence exists for MS galaxies in massive halos at redshifts z < 1, and we use\nthis knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h\nprojections of the simulated volume. At low redshift (z=0.4), we find that 90%\nof the clusters found have galaxy membership dominated by a single, real-space\nhalo, and that 10% are blended systems for which no single halo contributes a\nmajority of a cluster's membership. At z=1, the fraction of blends increases to\n22%, as weaker redshift evolution in observed color extends the comoving length\nprobed by a fixed range of color. Other factors contributing to the increased\nblending at high-z include broadening of the red sequence and confusion from a\nlarger number of intermediate mass halos hosting bright red galaxies of\nmagnitude similar to those in higher mass halos. Our method produces catalogs\nof cluster candidates whose halo mass selection function, p(M|\\Ngal,z), is\ncharacterized by a bimodal log-normal model with a dominant component that\nreproduces well the real-space distribution, and a redshift-dependent tail that\nis broader and displaced by a factor ~2 lower in mass. We discuss implications\nfor X-ray properties of optically selected clusters and offer ideas for\nimproving both mock catalogs and cluster-finding in future surveys.\n", "machine_text": "\nWe analyze the power of red sequence cluster finders on an array of galaxies from the Millennium Simulation (MS). We find that for low redshifts (z=0.4) the majority of clusters identified had a single halo with the remaining 10% questioning whether any single halo had credit for majority of the cluster's membership. Far with redshift (z=1), this increased to 22%, thus more challenging the red sequence cluster finder. This was mainly due to weaker red shift evolution of color and further confusion due to larger number of intermediate halos with bright red galaxies of magnitude similar to those in higher mass halos. We then developed a model that would describe a bimodal log-normal shaped mass selection function (p(M|\\Ngal,z)) which reproduced the real space distribution. We also investigated the effect on X-ray properties of optically selected clusters and suggest approaches to better improve the current mock catalogs being used.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0211}
{"prompt": "Rephrase the abstract of an article with title 'Phase resolved measurements of stimulated emission'.\n  The development of the semiconductor quantum cascade laser (QCL) [1] has\nenabled bright coherent sources operating at frequencies between the optical\n(>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for\nfundamental science investigations [2-5] as well as for applications [6].\nHowever, detailed information about the internal processes in QCLs and their\nultrafast dynamics are needed for their further development towards high output\npower, longer wavelengths and stable pulsed operation. We introduce a novel\napproach to study the gain and dynamics of a terahertz (THz) QCL [7] using\nphase resolved measurements of the stimulated emission. This is enabled by\ndirect recording of the emitted electric field with <100 fs time resolution.\nFor the case of the THz QCL we demonstrate the validity of the quantum\nmechanical description of the laser. We show for the first time the real\nbandwidth of the terahertz gain medium, the current dependence of this gain,\nand the losses associated with the wave propagation in the laser waveguide.\n\n", "human_text": "  The development of the semiconductor quantum cascade laser (QCL) [1] has\nenabled bright coherent sources operating at frequencies between the optical\n(>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for\nfundamental science investigations [2-5] as well as for applications [6].\nHowever, detailed information about the internal processes in QCLs and their\nultrafast dynamics are needed for their further development towards high output\npower, longer wavelengths and stable pulsed operation. We introduce a novel\napproach to study the gain and dynamics of a terahertz (THz) QCL [7] using\nphase resolved measurements of the stimulated emission. This is enabled by\ndirect recording of the emitted electric field with <100 fs time resolution.\nFor the case of the THz QCL we demonstrate the validity of the quantum\nmechanical description of the laser. We show for the first time the real\nbandwidth of the terahertz gain medium, the current dependence of this gain,\nand the losses associated with the wave propagation in the laser waveguide.\n", "machine_text": "This study presents a novel phase-resolved measurements technique for the understanding of THz quantum cascade lasers. It provides detailed knowledge of the gain and dynamics of these lasers, linked to their ultrafast responses and internal processes. By recording the emitted electric fields with less than 100 femtoseconds resolution, information is gathered on the bandwidth of the THz laser\u2019s gain medium, its current dependence of the gain, and the waveguide losses associated. This research is expected to benefit the further development of these lasers towards improved output power, extended wavelengths and more reliable pulsed operations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2296}
{"prompt": "Rephrase the abstract of an article with title 'Multi-Color Photometry of the Galactic Globular Cluster M75 = NGC 6864.\n  A New Sensitive Metallicity Indicator and the Position of the Horizontal\n  Branch in UV'.\n  We carry out and analyze new multi-color photometry of the Galactic globular\ncluster (GC) M75 in UBVI and focus on the brighter sequences of the color-\nmagnitude diagram (CMD), with particular emphasis on their location in U-based\nCMD. Specifically, we study the level both of the horizontal (HB) and red giant\nbranches (RGB) relative to the main-sequence turnoff (TO) in the U magnitude.\nAlong with the presented photometry of M75, we use our collection of\nphotometric data on GCs belonging to the metal-poor range, [Fe/H]zw<-1.1 dex,\nobtained from observations with different equipment, but calibrated by standard\nstars situated in the observed cluster fields. We confirm our earlier finding,\nand extend it to a larger magnitude range.We demonstrate that DeltaU_{TO}^{BHB}\nexpressing the difference in U magnitude between the TO point and the level of\nthe blue HB, near its red boundary, of the metal-poor GCs observed with the\nEMMI camera of the NTT/ESO telescope is about 0.4-0.5 mag smaller as compared\nto GCs observed with the 100\" telescope and 1.3 m Warsaw telescope of the Las\nCampanas Observatory. At the same time, Delta U_{TO}^{RGB}, the difference in U\nmagnitude between the TO and RGB inflection (brightest) points, does not show\nsuch an apparent dependence on the characteristics of U filters used, but it\ndepends on cluster metallicity. We have shown, for the first time, the\ndependence of the parameter DeltaU_{TO}^{RGB} on [Fe/H] and have estimated its\nanalytical expression, by assuming a linear relation between the parameter and\nmetallicity. Its slope, Delta U_{TO}^{RGB}/Delta [Fe/H]~1.2 mag/dex, is approx.\na factor of two steeper than that of the dependence of the RGB bump position in\nthe V magnitude on metallicity. The asymptotic giant branch (AGB) clump and\nfeatures of the RGB luminosity function (LF) of M75 are also discussed.\n\n", "human_text": "  We carry out and analyze new multi-color photometry of the Galactic globular\ncluster (GC) M75 in UBVI and focus on the brighter sequences of the color-\nmagnitude diagram (CMD), with particular emphasis on their location in U-based\nCMD. Specifically, we study the level both of the horizontal (HB) and red giant\nbranches (RGB) relative to the main-sequence turnoff (TO) in the U magnitude.\nAlong with the presented photometry of M75, we use our collection of\nphotometric data on GCs belonging to the metal-poor range, [Fe/H]zw<-1.1 dex,\nobtained from observations with different equipment, but calibrated by standard\nstars situated in the observed cluster fields. We confirm our earlier finding,\nand extend it to a larger magnitude range.We demonstrate that DeltaU_{TO}^{BHB}\nexpressing the difference in U magnitude between the TO point and the level of\nthe blue HB, near its red boundary, of the metal-poor GCs observed with the\nEMMI camera of the NTT/ESO telescope is about 0.4-0.5 mag smaller as compared\nto GCs observed with the 100\" telescope and 1.3 m Warsaw telescope of the Las\nCampanas Observatory. At the same time, Delta U_{TO}^{RGB}, the difference in U\nmagnitude between the TO and RGB inflection (brightest) points, does not show\nsuch an apparent dependence on the characteristics of U filters used, but it\ndepends on cluster metallicity. We have shown, for the first time, the\ndependence of the parameter DeltaU_{TO}^{RGB} on [Fe/H] and have estimated its\nanalytical expression, by assuming a linear relation between the parameter and\nmetallicity. Its slope, Delta U_{TO}^{RGB}/Delta [Fe/H]~1.2 mag/dex, is approx.\na factor of two steeper than that of the dependence of the RGB bump position in\nthe V magnitude on metallicity. The asymptotic giant branch (AGB) clump and\nfeatures of the RGB luminosity function (LF) of M75 are also discussed.\n", "machine_text": "\nWe present a comprehensive analysis of multi-color photometry of the Galactic globular cluster (GC) M75, with a focus on the brighter sequences of the color-magnitude diagram (CMD) in U-based CMD. We use our own photometric data on GCs of [Fe/H]zw<-1.1 dex observed with different equipment, as well as present the new photometry results of M75. We demonstrate that Delta U_{TO}^{BHB} - the difference in U magnitude between the Turnoff point and the level of the blue Horizontal Branch near its red boundary - is about 0.4-0.5 mag smaller when observed with the EMMI camera of the NTT/ESO telescope than when observed with the 100\" telescope and 1.3 m Warsaw telescope of the Las Campanas Observatory. We also show, for the first time, the dependence between metallicity of the cluster and the parameter DeltaU_{TO}^{RGB}, the difference in U magnitude between the TO and RGB inflection points, with a slope of 1.2 mag/dex. Additionally, the asymptotic giant branch (AGB) clump and features of the RGB luminosity function (LF) of M75 are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2445}
{"prompt": "Rephrase the abstract of an article with title 'Dynamics of Baryons from String Theory and Vector Dominance'.\n  We consider a holographic model of QCD from string theory, a la Sakai and\nSugimoto, and study baryons. In this model, mesons are collectively realized as\na five-dimensional \\$U(N_F)=U(1)\\times SU(N_F)$ Yang-Mills field and baryons\nare classically identified as $SU(N_F)$ solitons with a unit Pontryagin number\nand $N_c$ electric charges. The soliton is shown to be very small in the large\n't Hooft coupling limit, allowing us to introduce an effective field ${\\cal\nB}$. Its coupling to the mesons are dictated by the soliton structure, and\nconsists of a direct magnetic coupling to the $SU(N_F)$ field strength as well\nas a minimal coupling to the $U(N_F)$ gauge field. Upon the dimensional\nreduction, this effective action reproduces all interaction terms between\nnucleons and an infinite tower of mesons in a manner consistent with the large\n$N_c$ expansion. We further find that all electromagnetic interactions, as\ninferred from the same effective action via a holographic prescription, are\nmediated by an infinite tower of vector mesons, rendering the baryon\nelectromagnetic form factors completely vector-dominated as well. We estimate\nnucleon-meson couplings and also the anomalous magnetic moments, which compare\nwell with nature.\n\n", "human_text": "  We consider a holographic model of QCD from string theory, a la Sakai and\nSugimoto, and study baryons. In this model, mesons are collectively realized as\na five-dimensional \\$U(N_F)=U(1)\\times SU(N_F)$ Yang-Mills field and baryons\nare classically identified as $SU(N_F)$ solitons with a unit Pontryagin number\nand $N_c$ electric charges. The soliton is shown to be very small in the large\n't Hooft coupling limit, allowing us to introduce an effective field ${\\cal\nB}$. Its coupling to the mesons are dictated by the soliton structure, and\nconsists of a direct magnetic coupling to the $SU(N_F)$ field strength as well\nas a minimal coupling to the $U(N_F)$ gauge field. Upon the dimensional\nreduction, this effective action reproduces all interaction terms between\nnucleons and an infinite tower of mesons in a manner consistent with the large\n$N_c$ expansion. We further find that all electromagnetic interactions, as\ninferred from the same effective action via a holographic prescription, are\nmediated by an infinite tower of vector mesons, rendering the baryon\nelectromagnetic form factors completely vector-dominated as well. We estimate\nnucleon-meson couplings and also the anomalous magnetic moments, which compare\nwell with nature.\n", "machine_text": "\nIn this research article, we examine baryonic behavior in a model of QCD from string theory created by Sakai and Sugimoto. We discover that mesons can form a unit five-dimensional \\$U(N_F) = U(1) \\times SU(N_F)$ Yang-Mills field, and baryons are classically represented as solitons with one Pontryagin number and electric charges that are equivalent to $N_c$. In the large 't Hooft coupling limit, the soliton is found to be quite small, allowing us to introduce an effective field $\\cal{B}$. This effective field connects to the mesons based on the structure of the soliton, and comes in the form of a direct magnetic connection to the $SU(N_F)$ power and a minimal connection to the $U(N_F)$ guide field. After dimension reduction, this analytic equation matches with all interaction terms between nucleons and an infinite amount of mesons in a way that is consistent with a large $N_c$ growth. Additionally, we found that all electromagnetic connections, resolved from the effective action with a holographic formula, are conveyed by an infinite number of vector mesons, which makes the baryon electromagnetic field factors completely vector-dominated. We estimate nucleon-meson attachments and anomalous magnetic moments, compared to nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2632}
{"prompt": "Rephrase the abstract of an article with title 'RNA polymerase motors on DNA track: effects of traffic congestion on RNA\n  synthesis'.\n  RNA polymerase (RNAP) is an enzyme that synthesizes a messenger RNA (mRNA)\nstrand which is complementary to a single-stranded DNA template. From the\nperspective of physicists, an RNAP is a molecular motor that utilizes chemical\nenergy input to move along the track formed by a ssDNA. In some circumstances,\nwhich are described in this paper, a large number of RNAPs move simultaneously\nalong the same track. We refer to such collective movements of the RNAPs as\nRNAP traffic because of the similarities between the collective dynamics of the\nRNAPs on ssDNA track and that of vehicles in highway traffic. In this paper we\ndevelop a theoretical model for RNAP traffic by incorporating the steric\ninteractions between RNAPs as well as the mechano-chemical cycle of individual\nRNAPs during the elongation of the mRNA. By a combination of analytical and\nnumerical techniques, we calculate the rates of mRNA synthesis and the average\ndensity profile of the RNAPs on the ssDNA track. We also suggest novel\nexperiments for testing our theoretical predictions.\n\n", "human_text": "  RNA polymerase (RNAP) is an enzyme that synthesizes a messenger RNA (mRNA)\nstrand which is complementary to a single-stranded DNA template. From the\nperspective of physicists, an RNAP is a molecular motor that utilizes chemical\nenergy input to move along the track formed by a ssDNA. In some circumstances,\nwhich are described in this paper, a large number of RNAPs move simultaneously\nalong the same track. We refer to such collective movements of the RNAPs as\nRNAP traffic because of the similarities between the collective dynamics of the\nRNAPs on ssDNA track and that of vehicles in highway traffic. In this paper we\ndevelop a theoretical model for RNAP traffic by incorporating the steric\ninteractions between RNAPs as well as the mechano-chemical cycle of individual\nRNAPs during the elongation of the mRNA. By a combination of analytical and\nnumerical techniques, we calculate the rates of mRNA synthesis and the average\ndensity profile of the RNAPs on the ssDNA track. We also suggest novel\nexperiments for testing our theoretical predictions.\n", "machine_text": "\nThis study investigates the behaviour of an ensemble of RNA polymerase enzymes that move along a single-stranded DNA template. Drawing parallels between the collective dynamics of the enzymes and highway traffic, we refer to this collective movement of the enzymes as 'RNAP traffic'. To elucidate the effects of crowded flows on RNA synthesis, we construct a theoretical model that incorporates steric interactions between the enzymes as well as individual motor cycles. Using analytical and numerical tools, our investigations analyze the rate of mRNA synthesis and average density profile of these enzymes, on the DNA track, as well as suggest experiments for testing the theoretical predictions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2115}
{"prompt": "Rephrase the abstract of an article with title 'Unicast and Multicast Qos Routing with Soft Constraint Logic Programming'.\n  We present a formal model to represent and solve the unicast/multicast\nrouting problem in networks with Quality of Service (QoS) requirements. To\nattain this, first we translate the network adapting it to a weighted graph\n(unicast) or and-or graph (multicast), where the weight on a connector\ncorresponds to the multidimensional cost of sending a packet on the related\nnetwork link: each component of the weights vector represents a different QoS\nmetric value (e.g. bandwidth, cost, delay, packet loss). The second step\nconsists in writing this graph as a program in Soft Constraint Logic\nProgramming (SCLP): the engine of this framework is then able to find the best\npaths/trees by optimizing their costs and solving the constraints imposed on\nthem (e.g. delay < 40msec), thus finding a solution to QoS routing problems.\nMoreover, c-semiring structures are a convenient tool to model QoS metrics. At\nlast, we provide an implementation of the framework over scale-free networks\nand we suggest how the performance can be improved.\n\n", "human_text": "  We present a formal model to represent and solve the unicast/multicast\nrouting problem in networks with Quality of Service (QoS) requirements. To\nattain this, first we translate the network adapting it to a weighted graph\n(unicast) or and-or graph (multicast), where the weight on a connector\ncorresponds to the multidimensional cost of sending a packet on the related\nnetwork link: each component of the weights vector represents a different QoS\nmetric value (e.g. bandwidth, cost, delay, packet loss). The second step\nconsists in writing this graph as a program in Soft Constraint Logic\nProgramming (SCLP): the engine of this framework is then able to find the best\npaths/trees by optimizing their costs and solving the constraints imposed on\nthem (e.g. delay < 40msec), thus finding a solution to QoS routing problems.\nMoreover, c-semiring structures are a convenient tool to model QoS metrics. At\nlast, we provide an implementation of the framework over scale-free networks\nand we suggest how the performance can be improved.\n", "machine_text": "\nIn this article, we develop a formal model for unicast and multicast routing of Quality of Service (QoS) requirements. To accomplish our goal, we first translate the network into a weighted graph or and-or graph, depending on whether it is a unicast or multicast. The weights of the connectors represent the multi-dimensional costs associated with each network link in terms of QoS metrics such as bandwidth, cost, and packet loss. We represent this graph using Soft Constraint Logic Programming (SCLP) and use the built-in engine to find the best paths/trees by optimizing their associated costs and fulfilling the imposed constraints. Additionally, we make use of c-semiring structures, enabling us to model the QoS metrics accurately. Finally, we provide an implementation for scale-free networks  and offer suggestions for improving performance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1783}
{"prompt": "Rephrase the abstract of an article with title 'Confining ensemble of dyons'.\n  We construct the integration measure over the moduli space of an arbitrary\nnumber of N kinds of dyons of the pure SU(N) gauge theory at finite\ntemperatures. The ensemble of dyons governed by the measure is mathematically\ndescribed by a (supersymmetric) quantum field theory that is exactly solvable\nand is remarkable for a number of striking features: 1) The free energy has the\nminimum corresponding to the zero average Polyakov line, as expected in the\nconfining phase; 2)The correlation function of two Polyakov lines exhibits a\nlinear potential between static quarks in any N-ality non-zero representation,\nwith a calculable string tension roughly independent of temperature; 3) The\naverage spatial Wilson loop falls off exponentially with its area and the same\nstring tension; 4) At a critical temperature the ensemble of dyons rearranges\nand de-confines; 5)The estimated ratio of the critical temperature to the\nsquare root of the string tension is in excellent agreement with the lattice\ndata.\n\n", "human_text": "  We construct the integration measure over the moduli space of an arbitrary\nnumber of N kinds of dyons of the pure SU(N) gauge theory at finite\ntemperatures. The ensemble of dyons governed by the measure is mathematically\ndescribed by a (supersymmetric) quantum field theory that is exactly solvable\nand is remarkable for a number of striking features: 1) The free energy has the\nminimum corresponding to the zero average Polyakov line, as expected in the\nconfining phase; 2)The correlation function of two Polyakov lines exhibits a\nlinear potential between static quarks in any N-ality non-zero representation,\nwith a calculable string tension roughly independent of temperature; 3) The\naverage spatial Wilson loop falls off exponentially with its area and the same\nstring tension; 4) At a critical temperature the ensemble of dyons rearranges\nand de-confines; 5)The estimated ratio of the critical temperature to the\nsquare root of the string tension is in excellent agreement with the lattice\ndata.\n", "machine_text": "\nWe present the integration measure over the moduli space of various sorts of dyons in a pure SU(N) gauge theory at finite temperatures. This ensemble of dyons is mathematically described by a (supersymmetric) quantum field theory that can be solved exactly. We observe several remarkable characteristics: one, the free energy has a minimum corresponding to the average Polyakov line as expected in the confining phase; two, the correlation between two Polyakov lines exhibits a linear potential between static quarks in any N-ality non-zero representation with a calculable string tension largely independent of the temperature; three, the average spatial Wilson loop falls off exponentially with the area and the same string tension; four, at a critical temperature the dyons rearrange and disconfine; five, the relative ratio of the critical temperature to the square root of the string tension is in high agreement with lattice data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3181}
{"prompt": "Rephrase the abstract of an article with title 'Modules over operads and functors'.\n  In the theory of operads we consider functors of generalized symmetric powers\ndefined by sums of coinvariant modules under actions of symmetric groups. One\nobserves classically that the construction of symmetric functors provides an\nisomorphism from the category of symmetric modules to a subcategory of the\ncategory of functors on the base category. The purpose of this book is to\nobtain a similar relationship for functors on a category of algebras over an\noperad.\n  We observe that right modules over operads, symmetric modules equipped with a\nright operad action, give rise to functors on categories of algebras and we\nprove that this construction yields an embedding of categories. Then we check\nthat right modules over operads form a model category. In addition we prove\nthat weak-equivalences of right modules correspond to pointwise\nweak-equivalences at the functor level. As a conclusion, we obtain that right\nmodules over operads supply good models for the homotopy of associated functors\non algebras over operads.\n\n", "human_text": "  In the theory of operads we consider functors of generalized symmetric powers\ndefined by sums of coinvariant modules under actions of symmetric groups. One\nobserves classically that the construction of symmetric functors provides an\nisomorphism from the category of symmetric modules to a subcategory of the\ncategory of functors on the base category. The purpose of this book is to\nobtain a similar relationship for functors on a category of algebras over an\noperad.\n  We observe that right modules over operads, symmetric modules equipped with a\nright operad action, give rise to functors on categories of algebras and we\nprove that this construction yields an embedding of categories. Then we check\nthat right modules over operads form a model category. In addition we prove\nthat weak-equivalences of right modules correspond to pointwise\nweak-equivalences at the functor level. As a conclusion, we obtain that right\nmodules over operads supply good models for the homotopy of associated functors\non algebras over operads.\n", "machine_text": "\nThis paper is devoted to investigating the relationships between functors on categories of algebras over operads and right modules over operads. We start by proving that right modules over operads give rise to functors on categories of algebras, and we demonstrate that this construction yields an embedding of categories. We then go further and show that right modules over operads form a model category. This notion allows us to investigate the correspondence between weak-equivalences of right modules and point-wise weak-equivalences at the functor level. We ultimately conclude that right modules over operads supply accurate models for the homotopy of their associated functors on algebras over operads.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.309}
{"prompt": "Rephrase the abstract of an article with title 'Entanglement transformations using separable operations'.\n  We study conditions for the deterministic transformation\n$\\ket{\\psi}\\longrightarrow\\ket{\\phi}$ of a bipartite entangled state by a\nseparable operation. If the separable operation is a local operation with\nclassical communication (LOCC), Nielsen's majorization theorem provides\nnecessary and sufficient conditions. For the general case we derive a necessary\ncondition in terms of products of Schmidt coefficients, which is equivalent to\nthe Nielsen condition when either of the two factor spaces is of dimension 2,\nbut is otherwise weaker. One implication is that no separable operation can\nreverse a deterministic map produced by another separable operation, if one\nexcludes the case where the Schmidt coefficients of $\\ket{\\psi}$ and are the\nsame as those of $\\ket{\\phi}$. The question of sufficient conditions in the\ngeneral separable case remains open. When the Schmidt coefficients of\n$\\ket{\\psi}$ are the same as those of $\\ket{\\phi}$, we show that the Kraus\noperators of the separable transformation restricted to the supports of\n$\\ket{\\psi}$ on the factor spaces are proportional to unitaries. When that\nproportionality holds and the factor spaces have equal dimension, we find\nconditions for the deterministic transformation of a collection of several full\nSchmidt rank pure states $\\ket{\\psi_j}$ to pure states $\\ket{\\phi_j}$.\n\n", "human_text": "  We study conditions for the deterministic transformation\n$\\ket{\\psi}\\longrightarrow\\ket{\\phi}$ of a bipartite entangled state by a\nseparable operation. If the separable operation is a local operation with\nclassical communication (LOCC), Nielsen's majorization theorem provides\nnecessary and sufficient conditions. For the general case we derive a necessary\ncondition in terms of products of Schmidt coefficients, which is equivalent to\nthe Nielsen condition when either of the two factor spaces is of dimension 2,\nbut is otherwise weaker. One implication is that no separable operation can\nreverse a deterministic map produced by another separable operation, if one\nexcludes the case where the Schmidt coefficients of $\\ket{\\psi}$ and are the\nsame as those of $\\ket{\\phi}$. The question of sufficient conditions in the\ngeneral separable case remains open. When the Schmidt coefficients of\n$\\ket{\\psi}$ are the same as those of $\\ket{\\phi}$, we show that the Kraus\noperators of the separable transformation restricted to the supports of\n$\\ket{\\psi}$ on the factor spaces are proportional to unitaries. When that\nproportionality holds and the factor spaces have equal dimension, we find\nconditions for the deterministic transformation of a collection of several full\nSchmidt rank pure states $\\ket{\\psi_j}$ to pure states $\\ket{\\phi_j}$.\n", "machine_text": "\nThis paper explores the possibility of using separable operations to transform one bipartite entangled state $\\ket{\\psi}$ into another $\\ket{\\phi}$. If the separable operation is a local operation with classical communication (LOCC), Nielsen's theorem states the necessary and sufficient conditions for the transformation to occur. When this isn't the case, we show that at least one necessary condition requires that products of the Schmidt coefficients of $\\ket{\\psi}$ and $\\ket{\\phi}$ be equal. As a result, it is not possible to use separable operations to reverse the transformation by another separable operation unless the Schmidt coefficients of $\\ket{\\psi}$ and $\\ket{\\phi}$ are the same. Furthermore, we examine the situation when the Schmidt coefficients are equal, deriving conditions for the deterministic transformation of a collection of several full Schmidt rank pure states $\\ket{\\psi_j}$ to pure states $\\ket{\\phi_j}$. Finally, we also present sufficient conditions for the general separable transformation, although further research is still necessary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0369}
{"prompt": "Rephrase the abstract of an article with title 'Equivalence of three-dimensional spacetimes'.\n  A solution to the equivalence problem in three-dimensional gravity is given\nand a practically useful method to obtain a coordinate invariant description of\nlocal geometry is presented. The method is a nontrivial adaptation of Karlhede\ninvariant classification of spacetimes of general relativity. The local\ngeometry is completely determined by the curvature tensor and a finite number\nof its covariant derivatives in a frame where the components of the metric are\nconstants. The results are presented in the framework of real two-component\nspinors in three-dimensional spacetimes, where the algebraic classifications of\nthe Ricci and Cotton-York spinors are given and their isotropy groups and\ncanonical forms are determined. As an application we discuss Goedel-type\nspacetimes in three-dimensional General Relativity. The conditions for local\nspace and time homogeneity are derived and the equivalence of three-dimensional\nGoedel-type spacetimes is studied and the results are compared with previous\nworks on four-dimensional Goedel-type spacetimes.\n\n", "human_text": "  A solution to the equivalence problem in three-dimensional gravity is given\nand a practically useful method to obtain a coordinate invariant description of\nlocal geometry is presented. The method is a nontrivial adaptation of Karlhede\ninvariant classification of spacetimes of general relativity. The local\ngeometry is completely determined by the curvature tensor and a finite number\nof its covariant derivatives in a frame where the components of the metric are\nconstants. The results are presented in the framework of real two-component\nspinors in three-dimensional spacetimes, where the algebraic classifications of\nthe Ricci and Cotton-York spinors are given and their isotropy groups and\ncanonical forms are determined. As an application we discuss Goedel-type\nspacetimes in three-dimensional General Relativity. The conditions for local\nspace and time homogeneity are derived and the equivalence of three-dimensional\nGoedel-type spacetimes is studied and the results are compared with previous\nworks on four-dimensional Goedel-type spacetimes.\n", "machine_text": "This paper examines the equivalency problem concerning three-dimensional spacetimes. We provide a workable, coordinate-invariant approach to delineate the local structure of a given space. Our approach is based on Karlhede's invariant characterization of spacetime, the curvature tensor, and the Cotton-York spinors; the algebraic classification of these elements being integral to the formulation. We discuss a particular type of spacetime, Goedel-type, in the context of three-dimensional General Relativity, with the view of determining homogeneity in both space and time. These results are then contrasted with similar studies of four-dimensional Goedel-type spacetimes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0758}
{"prompt": "Rephrase the abstract of an article with title 'The Blazhko behaviour of RR Geminorum II -- long-term photometric\n  results'.\n  Context. RR Gem is one of the few Blazhko RR Lyrae that has photometric\nobservations available extended enough to study the long-term courses of its\npulsation and modulation properties in detail.\n  Aims. We investigate the pulsation and modulation properties and the\nrelations between them in RR Gem using photometric observations from the past\n70 years in order to gain further insight into the nature of the Blazhko\nmodulation.\n  Methods. We studied the photographic, photoelectric, and CCD light curves\nobtained at the Konkoly Observatory and other authors' published maxima\nobservations. Detailed analysis of the light curves, maximum brightness, and\nO-C data are carried out.\n  Results. RR Gem showed modulation most of the time it was observed. The\nmodulation amplitude showed strong variations from the undetectable level (less\nthan 0.04 mag in maximum brightness) to about 0.20 mag. The amplitudes of the\namplitude and phase modulations showed parallel changes, thus the total 'power'\nof the modulation have changed during the past 70 years. Parallel changes in\nthe pulsation and modulation periods occur with a d P_mod / d P_puls = 1.6 +/-\n0.8 * 10^3 ratio. We also detected 0.05-0.1 mag changes in the mean maximum\nbrightness and mean pulsation amplitude.\n\n", "human_text": "  Context. RR Gem is one of the few Blazhko RR Lyrae that has photometric\nobservations available extended enough to study the long-term courses of its\npulsation and modulation properties in detail.\n  Aims. We investigate the pulsation and modulation properties and the\nrelations between them in RR Gem using photometric observations from the past\n70 years in order to gain further insight into the nature of the Blazhko\nmodulation.\n  Methods. We studied the photographic, photoelectric, and CCD light curves\nobtained at the Konkoly Observatory and other authors' published maxima\nobservations. Detailed analysis of the light curves, maximum brightness, and\nO-C data are carried out.\n  Results. RR Gem showed modulation most of the time it was observed. The\nmodulation amplitude showed strong variations from the undetectable level (less\nthan 0.04 mag in maximum brightness) to about 0.20 mag. The amplitudes of the\namplitude and phase modulations showed parallel changes, thus the total 'power'\nof the modulation have changed during the past 70 years. Parallel changes in\nthe pulsation and modulation periods occur with a d P_mod / d P_puls = 1.6 +/-\n0.8 * 10^3 ratio. We also detected 0.05-0.1 mag changes in the mean maximum\nbrightness and mean pulsation amplitude.\n", "machine_text": "\nThe study explored the pulsation and modulation properties as well as the connection between them in RR Gem over a timespan of 70 years. A detailed analysis of the light curves, maximum brightness and O-C data was conducted. It was found that RR Gem was mostly modulated, with the total 'power' of the modulation changing over the observed time period. Changes in the modulation and pulsation periods were also observed and displayed a ratio of 1.6 +/- 0.8 * 10^3. As well as this, small changes in the mean maximum brightness and pulsation amplitude were detected.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3337}
{"prompt": "Rephrase the abstract of an article with title 'The impact of radio feedback from active galactic nuclei in cosmological\n  simulations: Formation of disk galaxies'.\n  In this paper, we present a new implementation of feedback due to active\ngalactic nuclei (AGN) in cosmological simulations of galaxy formation. We\nassume that a fraction of jet energy, which is generated by an AGN, is\ntransferred to the surrounding gas as thermal energy. Combining a theoretical\nmodel of mass accretion onto black holes with a multiphase description of\nstar-forming gas, we self-consistently follow evolution of both galaxies and\ntheir central black holes. The novelty in our model is that we consider two\ndistinct accretion modes: standard radiatively efficient thin accretion disks\nand radiatively inefficient accretion flows which we will generically refer to\nas RIAFs; motivated by theoretical models for jet production in accretion\ndisks, we assume that only the RIAF is responsible for the AGN feedback. We\nfind that, after an initial episode of bursting star formation, the accretion\nrate onto the central black hole drops so that the accretion disk switches to a\nRIAF structure. At this point, the feedback from the AGN becomes efficient and\nslightly suppresses star formation in the galactic disk and almost completely\nhalts star formation in the bulge. As a result, the nucleus becomes a\nstochastically fuelled low-luminosity AGN (Seyfert galaxy) with recurrent\nshort-lived episodes of activity after the star bursts. Our model predicts\nseveral properties of the low-luminosity AGN including the bolometric\nluminosity, jet powers, the effect on kpc-scale of the radio jet and the AGN\nlifetime, which are in broad agreement with observations of Seyfert galaxies\nand their radio activity. We also find that the mass ratios between the central\nblack hole and the the host spheroid at z = 0 are ~10^{-3} regardless of the\nstrength of either supernova feedback or AGN feedback. (abridged)\n\n", "human_text": "  In this paper, we present a new implementation of feedback due to active\ngalactic nuclei (AGN) in cosmological simulations of galaxy formation. We\nassume that a fraction of jet energy, which is generated by an AGN, is\ntransferred to the surrounding gas as thermal energy. Combining a theoretical\nmodel of mass accretion onto black holes with a multiphase description of\nstar-forming gas, we self-consistently follow evolution of both galaxies and\ntheir central black holes. The novelty in our model is that we consider two\ndistinct accretion modes: standard radiatively efficient thin accretion disks\nand radiatively inefficient accretion flows which we will generically refer to\nas RIAFs; motivated by theoretical models for jet production in accretion\ndisks, we assume that only the RIAF is responsible for the AGN feedback. We\nfind that, after an initial episode of bursting star formation, the accretion\nrate onto the central black hole drops so that the accretion disk switches to a\nRIAF structure. At this point, the feedback from the AGN becomes efficient and\nslightly suppresses star formation in the galactic disk and almost completely\nhalts star formation in the bulge. As a result, the nucleus becomes a\nstochastically fuelled low-luminosity AGN (Seyfert galaxy) with recurrent\nshort-lived episodes of activity after the star bursts. Our model predicts\nseveral properties of the low-luminosity AGN including the bolometric\nluminosity, jet powers, the effect on kpc-scale of the radio jet and the AGN\nlifetime, which are in broad agreement with observations of Seyfert galaxies\nand their radio activity. We also find that the mass ratios between the central\nblack hole and the the host spheroid at z = 0 are ~10^{-3} regardless of the\nstrength of either supernova feedback or AGN feedback. (abridged)\n", "machine_text": "\nThis paper investigates the impacts of feedback from active galactic nuclei (AGNs) in cosmological simulations of galaxy formation. We present a model which takes into account the mass-accretion into central black holes as well as multi-phase star formation within the gas to describe the evolution of both galaxies and the said black holes. A novel component of the model is that it acknowledges two modes of accretion: the usual thin, radiatively-efficient flows and alternatively, radiatively-inefficient flows referred to as RIAFs. It is assumed that only the latter produces the AGN feedback. Results show that subsequent to a burst of star formation, the rate of mass accretion declines and the flow of accretion transitions to a RIAF. This coincides with when the AGN feedback starts to diminish star formation in the galactic disks and brings star formation in the bulge almost to a halt. Our model predicts certain attributes of low-luminosity AGNs which match observations of Seyfert galaxies, such as bolometric luminosities and jet powers. Interestingly, an examination of the mass ratio of central black holes to the parent spheroid indicates that the ratio is almost the same regardless of the presence of either supernova feedback or AGN feedback.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1218}
{"prompt": "Rephrase the abstract of an article with title 'Weak decays of 4He-Lambda'.\n  We measured the lifetime and the mesonic and non-mesonic decay rates of the\n4He-Lambda hypernucleus. The hypernuclei were created using a 750 MeV/c\nmomentum K- beam on a liquid 4He target by the reaction 4He(K-,pi-)4He-Lambda.\nThe 4He-Lambda lifetime was directly measured using protons from Lambda p -> n\np non-mesonic decay (also referred to as proton-stimulated decay) and was found\nto have a value of tau = 245 +/- 24 ps. The mesonic decay rates were determined\nfrom the observed numbers of pi-'s and pi0's as Gamma_pi-/Gamma_tot = 0.270 +/-\n0.024 and Gamma_pi0/Gamma_tot = 0.564 +/- 0.036, respectively, and the values\nof the proton- and neutron-stimulated decay rates were extracted as\nGamma_p/Gamma_tot = 0.169 +/- 0.019 and Gamma_n/Gamma_tot <= 0.032 (95% CL),\nrespectively. The effects of final-state interactions and possible 3-body\nLambda N N decay contributions were studied in the context of a simple model of\nnucleon-stimulated decay. Nucleon-nucleon coincidence events were observed and\nwere used in the determination of the non-mesonic branching fractions. The\nimplications of the results of this analysis were considered for the empirical\nDelta I = 1/2 rule and the decay rates of the 4H-Lambda hypernucleus.\n\n", "human_text": "  We measured the lifetime and the mesonic and non-mesonic decay rates of the\n4He-Lambda hypernucleus. The hypernuclei were created using a 750 MeV/c\nmomentum K- beam on a liquid 4He target by the reaction 4He(K-,pi-)4He-Lambda.\nThe 4He-Lambda lifetime was directly measured using protons from Lambda p -> n\np non-mesonic decay (also referred to as proton-stimulated decay) and was found\nto have a value of tau = 245 +/- 24 ps. The mesonic decay rates were determined\nfrom the observed numbers of pi-'s and pi0's as Gamma_pi-/Gamma_tot = 0.270 +/-\n0.024 and Gamma_pi0/Gamma_tot = 0.564 +/- 0.036, respectively, and the values\nof the proton- and neutron-stimulated decay rates were extracted as\nGamma_p/Gamma_tot = 0.169 +/- 0.019 and Gamma_n/Gamma_tot <= 0.032 (95% CL),\nrespectively. The effects of final-state interactions and possible 3-body\nLambda N N decay contributions were studied in the context of a simple model of\nnucleon-stimulated decay. Nucleon-nucleon coincidence events were observed and\nwere used in the determination of the non-mesonic branching fractions. The\nimplications of the results of this analysis were considered for the empirical\nDelta I = 1/2 rule and the decay rates of the 4H-Lambda hypernucleus.\n", "machine_text": "\nIn this work, we quantified the lifetime and the mesonic and non-mesonic decay rates of 4He-Lambda hypernuclei. These hypernuclei were created through the reaction 4He(K-,\u03c0-)4He-Lambda at 750 MeV/c momentum. The lifetime of the 4He-Lambda hypernucleus was measured directly, given a value of \u03c4 = 245 \u00b1 24 ps. Further, the mesonic decay rates were quantified based on the number of pions and pion-zeros collected in the data, producing Gamma_\u03c0-/Gamma_tot = 0.270 \u00b1 0.024 and Gamma_\u03c00 / Gamma_tot = 0.564 \u00b1 0.036 respectively. The proton- and neutron-stimulated decay rates were further calculated from the data as Gamma_p / Gamma_tot = 0.169 \u00b1 0.019 and Gamma_n / Gamma_tot \u2264 0.032 (95% CL) respectively. The effects of the final-state interactions and possible three-body Lambda N N decay contributions are studied using a model of nucleon-stimulated decay. Furthermore, nucleon-nucleon coincidence events observed were used to draw inferences on the non-mesonic branching fractions. We also consider the implications of this study on the empirical Delta I = 1/2 rule and the decay rates of 4H-Lambda hypernucleus.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3311}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of Dust in Primordial Supernova Remnants: Can Dust Grains\n  Formed in the Ejecta Survive and be Injected into the Early Interstellar\n  Medium?'.\n  We investigate the evolution of dust that formed at Population III supernova\n(SN) explosions and its processing through the collisions with the reverse\nshocks resulting from the interaction of the SN ejecta with the ambient medium.\nIn particular, we investigate the transport of the shocked dust within the SN\nremnant (SNR), and its effect on the chemical composition, the size\ndistribution, and the total mass of dust surviving in SNR. We find that the\nevolution of the reverse shock, and hence its effect on the processing of the\ndust depends on the thickness of the envelope retained by the progenitor star.\nFurthermore, the transport and survival of the dust grains depend on their\ninitial radius, a_{ini}, and composition: For Type II SNRs expanding into the\ninterstellar medium (ISM) with a density of n_{H,0}=1 cm^{-3}, small grains\nwith a_{ini} < ~ 0.05 micron are completely destroyed by sputtering in the\npostshock flow, while grains with a_{ini}= 0.05--0.2 micron are trapped into\nthe dense shell behind the forward shock. Very large grains of a_{ini} > ~ 0.2\nmicron are ejected into the ISM without decreasing their sizes significantly.\nWe find that the total mass fraction of dust that is destroyed by the reverse\nshock ranges from 0.2 to 1.0, depending on the energy of the explosion and the\ndensity of the ambient ISM. The results of our calculations have significant\nimpact on the abundance pattern of subsequent generation of stars that form in\nthe dense shell of primordial SNRs.\n\n", "human_text": "  We investigate the evolution of dust that formed at Population III supernova\n(SN) explosions and its processing through the collisions with the reverse\nshocks resulting from the interaction of the SN ejecta with the ambient medium.\nIn particular, we investigate the transport of the shocked dust within the SN\nremnant (SNR), and its effect on the chemical composition, the size\ndistribution, and the total mass of dust surviving in SNR. We find that the\nevolution of the reverse shock, and hence its effect on the processing of the\ndust depends on the thickness of the envelope retained by the progenitor star.\nFurthermore, the transport and survival of the dust grains depend on their\ninitial radius, a_{ini}, and composition: For Type II SNRs expanding into the\ninterstellar medium (ISM) with a density of n_{H,0}=1 cm^{-3}, small grains\nwith a_{ini} < ~ 0.05 micron are completely destroyed by sputtering in the\npostshock flow, while grains with a_{ini}= 0.05--0.2 micron are trapped into\nthe dense shell behind the forward shock. Very large grains of a_{ini} > ~ 0.2\nmicron are ejected into the ISM without decreasing their sizes significantly.\nWe find that the total mass fraction of dust that is destroyed by the reverse\nshock ranges from 0.2 to 1.0, depending on the energy of the explosion and the\ndensity of the ambient ISM. The results of our calculations have significant\nimpact on the abundance pattern of subsequent generation of stars that form in\nthe dense shell of primordial SNRs.\n", "machine_text": "\nWe explore the fate of the dust that is produced through Population III supernova (SN) explosions in addition to its processing by reverse shocks from the SN ejecta's interaction with the ambient environment. We focus on the transport of the dust within the SN remnant (SNR), its effects on the composition, size and total mass that survives within the SNR. We observe changes in the reverse shock based on the thickness of the progenitor star's envelope, with the transport and endurance of the dust grains depending on their initial size and composition. Our research shows that small grains with an initial size of under 0.05 microns are obliterated in the postshock flow while grains with a size between 0.05-0.2 microns are caught in the dense layer behind the forward shock. Very large grains with an initial size of 0.2 microns or above are released into the interstellar medium (ISM) without a dramatic decrease in size. We compute the total mass fraction of dust that is destroyed by the reverse shock, varying between 0.2 and 1.0, contingent on the energy of the explosion and ISM density. Our findings could have a considerable effect on the abundance pattern of the stars formed in primordial SNRs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0383}
{"prompt": "Rephrase the abstract of an article with title 'Displacement of the Sun from the Galactic Plane'.\n  We have carried out a comparative statistical study for the displacement of\nthe Sun from the Galactic plane (z_\\odot) following three different methods.\nThe study has been done using a sample of 537 young open clusters (YOCs) with\nlog(Age) < 8.5 lying within a heliocentric distance of 4 kpc and 2030 OB stars\nobserved up to a distance of 1200 pc, all of them have distance information. We\ndecompose the Gould Belt's member in a statistical sense before investigating\nthe variation in the z_\\odot estimation with different upper cut-off limits in\nthe heliocentric distance and distance perpendicular to the Galactic plane. We\nfound z_\\odot varies in a range of ~ 13 - 20 pc from the analys is of YOCs and\n~ 6 - 18 pc from the OB stars. A significant scatter in the z_\\odot obtained\ndue to different cut-off values is noticed for the OB stars although no such\ndeviation is seen for the YOCs. We also determined scale heights of\n56.9(+3.8)(-3.4} and 61.4(+2.7)(-2.4) pc for the distribution of YOCs and OB\nstars respectively.\n\n", "human_text": "  We have carried out a comparative statistical study for the displacement of\nthe Sun from the Galactic plane (z_\\odot) following three different methods.\nThe study has been done using a sample of 537 young open clusters (YOCs) with\nlog(Age) < 8.5 lying within a heliocentric distance of 4 kpc and 2030 OB stars\nobserved up to a distance of 1200 pc, all of them have distance information. We\ndecompose the Gould Belt's member in a statistical sense before investigating\nthe variation in the z_\\odot estimation with different upper cut-off limits in\nthe heliocentric distance and distance perpendicular to the Galactic plane. We\nfound z_\\odot varies in a range of ~ 13 - 20 pc from the analys is of YOCs and\n~ 6 - 18 pc from the OB stars. A significant scatter in the z_\\odot obtained\ndue to different cut-off values is noticed for the OB stars although no such\ndeviation is seen for the YOCs. We also determined scale heights of\n56.9(+3.8)(-3.4} and 61.4(+2.7)(-2.4) pc for the distribution of YOCs and OB\nstars respectively.\n", "machine_text": "\nWe conducted an empirical study examining the Sun's displacement from the Galactic plane (z_\\odot) using three analytical methods. Our sample comprised of 537 young open clusters (YOCs) with an age logarithm of less than 8.5 and located within a heliocentric distance of 4 kpc, as well as 2030 OB stars observed up to a distance of 1200 pc and possessing distance information. We split the members of the Gould Belt into statistical subsections before analyzing z_\\odot for variation in line with different maximum values in the heliocentric distance and perpendicular distance to the Galactic plane. The z_\\odot for YOCs averaged between 13 and 20 pc, whilst for OB stars it fluctuated between 6 and 18 pc. There was a conspicuous inconsistency in the z_\\odot from the OB star analysis due to different limit values, while no such effect was noticed utilizing YOCs. Additionally, we identified scale heights of 56.9(+3.8)(-3.4) pc and 61.4(+2.7)(-2.4) pc for the distributions of YOCs and OB stars respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.095}
{"prompt": "Rephrase the abstract of an article with title 'Non-Parametric Field Estimation using Randomly Deployed, Noisy, Binary\n  Sensors'.\n  The reconstruction of a deterministic data field from binary-quantized noisy\nobservations of sensors which are randomly deployed over the field domain is\nstudied. The study focuses on the extremes of lack of deterministic control in\nthe sensor deployment, lack of knowledge of the noise distribution, and lack of\nsensing precision and reliability. Such adverse conditions are motivated by\npossible real-world scenarios where a large collection of low-cost, crudely\nmanufactured sensors are mass-deployed in an environment where little can be\nassumed about the ambient noise. A simple estimator that reconstructs the\nentire data field from these unreliable, binary-quantized, noisy observations\nis proposed. Technical conditions for the almost sure and integrated mean\nsquared error (MSE) convergence of the estimate to the data field, as the\nnumber of sensors tends to infinity, are derived and their implications are\ndiscussed. For finite-dimensional, bounded-variation, and\nSobolev-differentiable function classes, specific integrated MSE decay rates\nare derived. For the first and third function classes these rates are found to\nbe minimax order optimal with respect to infinite precision sensing and known\nnoise distribution.\n\n", "human_text": "  The reconstruction of a deterministic data field from binary-quantized noisy\nobservations of sensors which are randomly deployed over the field domain is\nstudied. The study focuses on the extremes of lack of deterministic control in\nthe sensor deployment, lack of knowledge of the noise distribution, and lack of\nsensing precision and reliability. Such adverse conditions are motivated by\npossible real-world scenarios where a large collection of low-cost, crudely\nmanufactured sensors are mass-deployed in an environment where little can be\nassumed about the ambient noise. A simple estimator that reconstructs the\nentire data field from these unreliable, binary-quantized, noisy observations\nis proposed. Technical conditions for the almost sure and integrated mean\nsquared error (MSE) convergence of the estimate to the data field, as the\nnumber of sensors tends to infinity, are derived and their implications are\ndiscussed. For finite-dimensional, bounded-variation, and\nSobolev-differentiable function classes, specific integrated MSE decay rates\nare derived. For the first and third function classes these rates are found to\nbe minimax order optimal with respect to infinite precision sensing and known\nnoise distribution.\n", "machine_text": "\nThis investigation examines the capability of estimating a deterministic field given unreliable, noisily-quantized, binary observations obtained from randomly deployed sensors. The primary focus is on strict conditions which make it impossible to know the noise distribution and guarantee the accuracy of the sensing precision and reliability. Real-world applications may involve deploying a wide array of economical, crudely produced sensors in environments with minimal to no data on the surrounding noise. This paper presents a simple way to reconstruct the entire data field from the aforementioned conditions. Among the details discussed are the strong convergence parameters of the estimator when the number of sensors is large, and integrated MSE decay rates for certain function classes. Additionally, for two of these classes, the decay rates are found to be optimally optimal with respect to known noise and infinite accuracy sensing.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0685}
{"prompt": "Rephrase the abstract of an article with title 'Path Integral Methods in the Su-Schrieffer-Heeger Polaron Problem'.\n  I propose a path integral description of the Su-Schrieffer-Heeger\nHamiltonian, both in one and two dimensions, after mapping the real space model\nonto the time scale. While the lattice degrees of freedom are classical\nfunctions of time and are integrated out exactly, the electron particle paths\nare treated quantum mechanically. The method accounts for the variable range of\nthe electronic hopping processes. The free energy of the system and its\ntemperature derivatives are computed by summing at any $T$ over the ensemble of\nrelevant particle paths which mainly contribute to the total partition\nfunction. In the low $T$ regime, the {\\it heat capacity over T} ratio shows un\nupturn peculiar to a glass-like behavior. This feature is more sizeable in the\nsquare lattice than in the linear chain as the overall hopping potential\ncontribution to the total action is larger in higher dimensionality. The\neffects of the electron-phonon anharmonic interactions on the phonon subsystem\nare studied by the path integral cumulant expansion method.\n\n", "human_text": "  I propose a path integral description of the Su-Schrieffer-Heeger\nHamiltonian, both in one and two dimensions, after mapping the real space model\nonto the time scale. While the lattice degrees of freedom are classical\nfunctions of time and are integrated out exactly, the electron particle paths\nare treated quantum mechanically. The method accounts for the variable range of\nthe electronic hopping processes. The free energy of the system and its\ntemperature derivatives are computed by summing at any $T$ over the ensemble of\nrelevant particle paths which mainly contribute to the total partition\nfunction. In the low $T$ regime, the {\\it heat capacity over T} ratio shows un\nupturn peculiar to a glass-like behavior. This feature is more sizeable in the\nsquare lattice than in the linear chain as the overall hopping potential\ncontribution to the total action is larger in higher dimensionality. The\neffects of the electron-phonon anharmonic interactions on the phonon subsystem\nare studied by the path integral cumulant expansion method.\n", "machine_text": "\nThe goal of this article is to employ path integral methods to study the Su-Schrieffer-Heeger polaron problem. The time and real space components of the Hamiltonian are both taken into account, with the electron particle paths being treated quantum mechanically and the lattice degrees of freedom integrated out exactly. By summing over a range of relevant particle paths which form the total partition function, the free energy and its temperature derivatives can be calculated. At low temperatures, the heat capacity over T ratio displays a growth pattern characteristic of glass-like behaviour, with the effects of electron-phonon anharmonic interactions explored by the cumulant expansion method. The square lattice, due to its larger overall hopping potential contribution, is found to show the strongest glass-like behaviour.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1428}
{"prompt": "Rephrase the abstract of an article with title 'Asymptotic Behavior of Total Times For Jobs That Must Start Over If a\n  Failure Occurs'.\n  Many processes must complete in the presence of failures. Different systems\nrespond to task failure in different ways. The system may resume a failed task\nfrom the failure point (or a saved checkpoint shortly before the failure\npoint), it may give up on the task and select a replacement task from the ready\nqueue, or it may restart the task. The behavior of systems under the first two\nscenarios is well documented, but the third ({\\em RESTART}) has resisted\ndetailed analysis. In this paper we derive tight asymptotic relations between\nthe distribution of {\\em task times} without failures to the {\\em total time}\nwhen including failures, for any failure distribution. In particular, we show\nthat if the task time distribution has an unbounded support then the total time\ndistribution $H$ is always heavy-tailed. Asymptotic expressions are given for\nthe tail of $H$ in various scenarios. The key ingredients of the analysis are\nthe Cram\\'er--Lundberg asymptotics for geometric sums and integral asymptotics,\nthat in some cases are obtained via Tauberian theorems and in some cases by\nbare-hand calculations.\n\n", "human_text": "  Many processes must complete in the presence of failures. Different systems\nrespond to task failure in different ways. The system may resume a failed task\nfrom the failure point (or a saved checkpoint shortly before the failure\npoint), it may give up on the task and select a replacement task from the ready\nqueue, or it may restart the task. The behavior of systems under the first two\nscenarios is well documented, but the third ({\\em RESTART}) has resisted\ndetailed analysis. In this paper we derive tight asymptotic relations between\nthe distribution of {\\em task times} without failures to the {\\em total time}\nwhen including failures, for any failure distribution. In particular, we show\nthat if the task time distribution has an unbounded support then the total time\ndistribution $H$ is always heavy-tailed. Asymptotic expressions are given for\nthe tail of $H$ in various scenarios. The key ingredients of the analysis are\nthe Cram\\'er--Lundberg asymptotics for geometric sums and integral asymptotics,\nthat in some cases are obtained via Tauberian theorems and in some cases by\nbare-hand calculations.\n", "machine_text": "\nThis paper examines the asymptotic behavior of total time when taking into account task failures. Two common ways of responding to failed tasks, resuming from a failure point or selecting a replacement task, are extensively documented. However, the paper focuses on a third alternative, referred to as RESTART, which has resisted detailed analysis until now. This work provides new insights into task time distributions, with heavy-tailed distributions observed when the initial task time has an unbounded support. The analysis combines Cram\u00e9r-Lundberg asymptotics with integral asymptotics, which sometimes requires the use of Tauberian theorems or direct calculations. Results are included for various scenarios.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0403}
{"prompt": "Rephrase the abstract of an article with title '$2\\times250$ GeV CLIC $\\gamma\\gamma$ Collider Based on its Drive Beam\n  FEL'.\n  CLIC is a linear $e^+e^-$ ($\\gamma\\gamma$) collider project which uses a\ndrive beam to accelerate the main beam. The drive beam provides RF power for\neach corresponding unit of the main linac through energy extracting RF\nstructures. CLIC has a wide range of center-of-mass energy options from 150 GeV\nto 3 TeV. The present paper contains optimization of Free Electron Laser (FEL)\nusing one bunch of CLIC drive beam in order to provide polarized light\namplification using appropriate wiggler and luminosity spectrum of\n$\\gamma\\gamma$ collider for $E_{cm}$=0.5 TeV. Then amplified laser can be\nconverted to a polarized high-energy $\\gamma$ beam at the Conversion point\n(CP-prior to electron positron interaction point) in the process of Compton\nbackscattering. At the CP a powerful laser pulse (FEL) focused to main linac\nelectrons (positrons). Here this scheme described and it is show that CLIC\ndrive beam parameters satisfy the requirement of FEL additionally essential\nundulator parameters has been defined. Achievable $\\gamma\\gamma$ luminosity is\nabove $10^{34}$.\n\n", "human_text": "  CLIC is a linear $e^+e^-$ ($\\gamma\\gamma$) collider project which uses a\ndrive beam to accelerate the main beam. The drive beam provides RF power for\neach corresponding unit of the main linac through energy extracting RF\nstructures. CLIC has a wide range of center-of-mass energy options from 150 GeV\nto 3 TeV. The present paper contains optimization of Free Electron Laser (FEL)\nusing one bunch of CLIC drive beam in order to provide polarized light\namplification using appropriate wiggler and luminosity spectrum of\n$\\gamma\\gamma$ collider for $E_{cm}$=0.5 TeV. Then amplified laser can be\nconverted to a polarized high-energy $\\gamma$ beam at the Conversion point\n(CP-prior to electron positron interaction point) in the process of Compton\nbackscattering. At the CP a powerful laser pulse (FEL) focused to main linac\nelectrons (positrons). Here this scheme described and it is show that CLIC\ndrive beam parameters satisfy the requirement of FEL additionally essential\nundulator parameters has been defined. Achievable $\\gamma\\gamma$ luminosity is\nabove $10^{34}$.\n", "machine_text": "\nThis paper investigates the feasibility of using the CLIC Drive Beam FEL to realize a $2\\times250$ GeV centre-of-mass energy $\\gamma\\gamma$ collider. By using one bunch of the CLIC drive beam, the authors optimize a Free Electron Laser (FEL) to provide polarized light amplification. An appropriate wiggler and luminosity spectrum is obtained for a 0.5 TeV collision energy. The amplified laser can then be converted to a polarized high-energy $\\gamma$ beam at the Conversion point, prior to the electron-positron interaction point, via Compton backscattering. This paper identifies the essential CLIC Drive Beam and undulator parameters, and goes on to demonstrate that the CLIC Drive Beam parameters meet the demands of the FEL. An envisaged $\\gamma\\gamma$ luminosity of greater than $10^{34}$ can be achieved.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2583}
{"prompt": "Rephrase the abstract of an article with title 'Wide Field Surveys and Astronomical Discovery Space'.\n  I review the status of science with wide field surveys. For many decades\nsurveys have been the backbone of astronomy, and the main engine of discovery,\nas we have mapped the sky at every possible wavelength. Surveys are an\nefficient use of resources. They are important as a fundamental resource; to\nmap intrinsically large structures; to gain the necessary statistics to address\nsome problems; and to find very rare objects. I summarise major recent wide\nfield surveys - 2MASS, SDSS, 2dfGRS, and UKIDSS - and look at examples of the\nexciting science they have produced, covering the structure of the Milky Way,\nthe measurement of cosmological parameters, the creation of a new field\nstudying substellar objects, and the ionisation history of the Universe. I then\nlook briefly at upcoming projects in the optical-IR survey arena - VISTA,\nPanSTARRS, WISE, and LSST. Finally I ask, now we have opened up essentially all\nwavelength windows, whether the exploration of survey discovery space is ended.\nI examine other possible axes of discovery space, and find them mostly to be\ntoo expensive to explore or otherwise unfruitful, with two exceptions : the\nfirst is the time axis, which we have only just begun to explore properly; and\nthe second is the possibility of neutrino astrophysics.\n\n", "human_text": "  I review the status of science with wide field surveys. For many decades\nsurveys have been the backbone of astronomy, and the main engine of discovery,\nas we have mapped the sky at every possible wavelength. Surveys are an\nefficient use of resources. They are important as a fundamental resource; to\nmap intrinsically large structures; to gain the necessary statistics to address\nsome problems; and to find very rare objects. I summarise major recent wide\nfield surveys - 2MASS, SDSS, 2dfGRS, and UKIDSS - and look at examples of the\nexciting science they have produced, covering the structure of the Milky Way,\nthe measurement of cosmological parameters, the creation of a new field\nstudying substellar objects, and the ionisation history of the Universe. I then\nlook briefly at upcoming projects in the optical-IR survey arena - VISTA,\nPanSTARRS, WISE, and LSST. Finally I ask, now we have opened up essentially all\nwavelength windows, whether the exploration of survey discovery space is ended.\nI examine other possible axes of discovery space, and find them mostly to be\ntoo expensive to explore or otherwise unfruitful, with two exceptions : the\nfirst is the time axis, which we have only just begun to explore properly; and\nthe second is the possibility of neutrino astrophysics.\n", "machine_text": "This article reviews the progress of wide field surveys in astronomy and their use as the primary engine of discovery in mapping the sky. I review the major wide field surveys of the past two decades - 2MASS, SDSS, 2dfGRS, and UKIDSS - and the science they've allowed us to explore. I then look at upcoming projects that may contribute to future astronomical discoveries. Finally, I consider whether the exploration of survey discovery space has ended and assess other possible ways to extend astronomical discovery, including the use of time and the possibility of neutrino astrophysics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0809}
{"prompt": "Rephrase the abstract of an article with title 'Ground-state long-range order in quasi-one-dimensional Heisenberg\n  quantum antiferromagnets: High-order coupled-cluster calculations'.\n  We investigate the ground-state magnetic long-range order of\nquasi-one-dimensional quantum Heisenberg antiferromagnets for spin quantum\nnumbers s=1/2 and s=1. We use the coupled cluster method to calculate the\nsublattice magnetization in dependence on the inter-chain coupling. We find\nthat for the unfrustrated spin-1/2 system an infinitesimal inter-chain coupling\nis sufficient to stabilize magnetic long-range order, which is in agreement\nwith results obtained by some other methods. For s=1 we find that a finite\ninter-chain coupling of about 10% of the in-chain coupling is necessary to\nstabilize magnetic long-range order. Furthermore, we consider a quasi\none-dimensional spin-1/2 system, where a frustrating next-nearest neighbor\nin-chain coupling is included. We find that for stronger frustration also a\nfinite inter-chain coupling is necessary to have magnetic long-range order in\nthe ground state, where the strength of the inter-chain coupling necessary to\nestablish magnetic long-range order is related to the size of the spin gap of\nthe isolated chain.\n\n", "human_text": "  We investigate the ground-state magnetic long-range order of\nquasi-one-dimensional quantum Heisenberg antiferromagnets for spin quantum\nnumbers s=1/2 and s=1. We use the coupled cluster method to calculate the\nsublattice magnetization in dependence on the inter-chain coupling. We find\nthat for the unfrustrated spin-1/2 system an infinitesimal inter-chain coupling\nis sufficient to stabilize magnetic long-range order, which is in agreement\nwith results obtained by some other methods. For s=1 we find that a finite\ninter-chain coupling of about 10% of the in-chain coupling is necessary to\nstabilize magnetic long-range order. Furthermore, we consider a quasi\none-dimensional spin-1/2 system, where a frustrating next-nearest neighbor\nin-chain coupling is included. We find that for stronger frustration also a\nfinite inter-chain coupling is necessary to have magnetic long-range order in\nthe ground state, where the strength of the inter-chain coupling necessary to\nestablish magnetic long-range order is related to the size of the spin gap of\nthe isolated chain.\n", "machine_text": "We present research focusing on the magnetic long-range order at the ground-state of quasi-one-dimensional quantum Heisenberg antiferromagnets for spin quantum numbers s=1/2 and s=1. Using the coupled cluster method, we determine the sublattice magnetization in function of the inter-chain coupling. Results show that an enormously small inter-chain coupling is effective in establishing long-range order for the unfrustrated spin-1/2 system. For spin s=1, however, an inter-chain coupling of 10% of the in-chain coupling is necessary to give stability to the magnetic order. Moreover, we consider the case of a quasi one-dimensional spin-1/2 system where a frustrating next-nearest neighbor in-chain coupling is also included. We observe that for stronger frustration, a finite inter-chain coupling is needed for magnetic long-range order; this amounts to the spin gap of the isolated chain.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3582}
{"prompt": "Rephrase the abstract of an article with title 'Particle Motion in Rapidly Oscillating Potentials: The Role of the\n  Potential's Initial Phase'.\n  Rapidly oscillating potentials with a vanishing time average have been used\nfor a long time to trap charged particles in source-free regions. It has been\nargued that the motion of a particle in such a potential can be approximately\ndescribed by a time independent effective potential, which does not depend upon\nthe initial phase of the oscillating potential. However, here we show that the\nmotion of a particle and its trapping condition significantly depend upon this\ninitial phase for arbitrarily high frequencies of the potential's oscillation.\nWe explain this novel phenomenon by showing that the motion of a particle is\ndetermined by the effective potential stated in the literature only if its\ninitial conditions are transformed according to a transformation which we show\nto significantly depend on the potential's initial phase for arbitrarily high\nfrequencies. We confirm our theoretical findings by numerical simulations.\nFurther, we demonstrate that the found phenomenon offers new ways to manipulate\nthe dynamics of particles which are trapped by rapidly oscillating potentials.\nFinally, we propose a simple experiment to verify the theoretical findings of\nthis work.\n\n", "human_text": "  Rapidly oscillating potentials with a vanishing time average have been used\nfor a long time to trap charged particles in source-free regions. It has been\nargued that the motion of a particle in such a potential can be approximately\ndescribed by a time independent effective potential, which does not depend upon\nthe initial phase of the oscillating potential. However, here we show that the\nmotion of a particle and its trapping condition significantly depend upon this\ninitial phase for arbitrarily high frequencies of the potential's oscillation.\nWe explain this novel phenomenon by showing that the motion of a particle is\ndetermined by the effective potential stated in the literature only if its\ninitial conditions are transformed according to a transformation which we show\nto significantly depend on the potential's initial phase for arbitrarily high\nfrequencies. We confirm our theoretical findings by numerical simulations.\nFurther, we demonstrate that the found phenomenon offers new ways to manipulate\nthe dynamics of particles which are trapped by rapidly oscillating potentials.\nFinally, we propose a simple experiment to verify the theoretical findings of\nthis work.\n", "machine_text": "\nStudies of rapid oscillations in source-free areas often utilise a vanishing time average potential to capture charged particles. It has been hypothesised that a particle's motion in such circumstances can be predicted from a static, phase-insensitive effective potential. This study unveils a new phenomenon and reveals that a particle's motion and trapping conditions are in fact very dependent on their initial phase, even for very high frequencies. We explain this through a transformation according to the potential's initial phase, which has not previously been considered. Our theory is backed up with numerical simulations, as well as suggesting a simple experiment to test our claims. This finding could lead to innovative ways of manipulating the dynamics of particles subject to intense oscillations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2737}
{"prompt": "Rephrase the abstract of an article with title 'Central limit theorems in linear structural error-in-variables models\n  with explanatory variables in the domain of attraction of the normal law'.\n  Linear structural error-in-variables models with univariate observations are\nrevisited for studying modified least squares estimators of the slope and\nintercept. New marginal central limit theorems (CLT's) are established for\nthese estimators, assuming the existence of four moments for the measurement\nerrors and that the explanatory variables are in the domain of attraction of\nthe normal law. The latter condition for the explanatory variables is used the\nfirst time, and is so far the most general in this context. It is also optimal,\nor nearly optimal, for our CLT's. Moreover, due to the obtained CLT's being in\nStudentized and self-normalized forms to begin with, they are a priori nearly,\nor completely, data-based, and free of unknown parameters of the joint\ndistribution of the error and explanatory variables. Consequently, they lead to\na variety of readily available, or easily derivable, large-sample approximate\nconfidence intervals (CI's) for the slope and intercept. In contrast, in\nrelated CLT's in the literature so far, the variances of the limiting normal\ndistributions, in general, are complicated and depend on various, typically\nunknown, moments of the error and explanatory variables. Thus, the\ncorresponding CI's for the slope and intercept in the literature, unlike those\nof the present paper, are available only under some additional model\nassumptions.\n\n", "human_text": "  Linear structural error-in-variables models with univariate observations are\nrevisited for studying modified least squares estimators of the slope and\nintercept. New marginal central limit theorems (CLT's) are established for\nthese estimators, assuming the existence of four moments for the measurement\nerrors and that the explanatory variables are in the domain of attraction of\nthe normal law. The latter condition for the explanatory variables is used the\nfirst time, and is so far the most general in this context. It is also optimal,\nor nearly optimal, for our CLT's. Moreover, due to the obtained CLT's being in\nStudentized and self-normalized forms to begin with, they are a priori nearly,\nor completely, data-based, and free of unknown parameters of the joint\ndistribution of the error and explanatory variables. Consequently, they lead to\na variety of readily available, or easily derivable, large-sample approximate\nconfidence intervals (CI's) for the slope and intercept. In contrast, in\nrelated CLT's in the literature so far, the variances of the limiting normal\ndistributions, in general, are complicated and depend on various, typically\nunknown, moments of the error and explanatory variables. Thus, the\ncorresponding CI's for the slope and intercept in the literature, unlike those\nof the present paper, are available only under some additional model\nassumptions.\n", "machine_text": "This article examines the modified least squares estimators of the slope and intercept in linear structural error-in-variables models with univariate observations. Central limit theorems are established, assuming the measurement errors have four moments and the explanatory variables are in the domain of attraction of the normal law. The CLT's are already in the forms of a Studentized and self-normalized distribution and provide a range of efficient, data-based approximate confidence intervals for the slope and intercept, free of unknown parameters of the joint distribution of the error and explanatory variables. As such, these CI's are an improvement on the related CLT's in the literature which depend on various, unknown, moments of the errors and the explanatory variables.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0826}
{"prompt": "Rephrase the abstract of an article with title 'An invariance principle for semimartingale reflecting Brownian motions\n  in domains with piecewise smooth boundaries'.\n  Semimartingale reflecting Brownian motions (SRBMs) living in the closures of\ndomains with piecewise smooth boundaries are of interest in applied probability\nbecause of their role as heavy traffic approximations for some stochastic\nnetworks. In this paper, assuming certain conditions on the domains and\ndirections of reflection, a perturbation result, or invariance principle, for\nSRBMs is proved. This provides sufficient conditions for a process that\nsatisfies the definition of an SRBM, except for small random perturbations in\nthe defining conditions, to be close in distribution to an SRBM. A crucial\ningredient in the proof of this result is an oscillation inequality for\nsolutions of a perturbed Skorokhod problem. We use the invariance principle to\nshow weak existence of SRBMs under mild conditions. We also use the invariance\nprinciple, in conjunction with known uniqueness results for SRBMs, to give some\nsufficient conditions for validating approximations involving (i) SRBMs in\nconvex polyhedrons with a constant reflection vector field on each face of the\npolyhedron, and (ii) SRBMs in bounded domains with piecewise smooth boundaries\nand possibly nonconstant reflection vector fields on the boundary surfaces.\n\n", "human_text": "  Semimartingale reflecting Brownian motions (SRBMs) living in the closures of\ndomains with piecewise smooth boundaries are of interest in applied probability\nbecause of their role as heavy traffic approximations for some stochastic\nnetworks. In this paper, assuming certain conditions on the domains and\ndirections of reflection, a perturbation result, or invariance principle, for\nSRBMs is proved. This provides sufficient conditions for a process that\nsatisfies the definition of an SRBM, except for small random perturbations in\nthe defining conditions, to be close in distribution to an SRBM. A crucial\ningredient in the proof of this result is an oscillation inequality for\nsolutions of a perturbed Skorokhod problem. We use the invariance principle to\nshow weak existence of SRBMs under mild conditions. We also use the invariance\nprinciple, in conjunction with known uniqueness results for SRBMs, to give some\nsufficient conditions for validating approximations involving (i) SRBMs in\nconvex polyhedrons with a constant reflection vector field on each face of the\npolyhedron, and (ii) SRBMs in bounded domains with piecewise smooth boundaries\nand possibly nonconstant reflection vector fields on the boundary surfaces.\n", "machine_text": "This article examines the features of semimartingale reflecting Brownian\nmotions (SRBMs) that exist within the boundaries of domains with piecewise\nsmooth edges. An invariance principle is presented which can be applied to\nensure adequate conditions for SRBMs, with the exception of small random\nvariations in the defining parameters. This perturbation result is used to\nassess the existence of SRBMs under certain conditions, as well as for\nvalidating approximations with either SRBMs in convex polyhedrons or in bounded\ndomains with piecewise smooth boundaries. An important factor in the proof of\nthe invariance principle is a type of oscillation inequality associated with\nthe perturbed Skorokhod problem.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0405}
{"prompt": "Rephrase the abstract of an article with title 'Evidence for a jet contribution to the optical/infrared light of neutron\n  star X-ray binaries'.\n  Optical/near-infrared (optical/NIR; OIR) light from low-mass neutron star\nX-ray binaries (NSXBs) in outburst is traditionally thought to be thermal\nemission from the accretion disc. Here we present a comprehensive collection of\nquasi-simultaneous OIR and X-ray data from 19 low-magnetic field NSXBs,\nincluding new observations of three sources: 4U 0614+09, LMC X-2 and GX 349+2.\nThe average radio-OIR spectrum for NSXBs is alpha ~ +0.2 (where L_nu propto\nnu^alpha) at least at high luminosities when the radio jet is detected. This is\ncomparable to, but slightly more inverted than the alpha ~ 0.0 found for black\nhole X-ray binaries. The OIR spectra and relations between OIR and X-ray fluxes\nare compared to those expected if the OIR emission is dominated by thermal\nemission from an X-ray or viscously heated disc, or synchrotron emission from\nthe inner regions of the jets. We find that thermal emission due to X-ray\nreprocessing can explain all the data except at high luminosities for some\nNSXBs, namely the atolls and millisecond X-ray pulsars (MSXPs). Optically thin\nsynchrotron emission from the jets (with an observed OIR spectral index of\nalpha_thin < 0) dominate the NIR light above L_x ~ 10^36 erg/s and the optical\nabove L_x ~ 10^37 erg/s in these systems. For NSXB Z-sources, the OIR\nobservations can be explained by X-ray reprocessing alone, although synchrotron\nemission may make a low level contribution to the NIR, and could dominate the\nOIR in one or two cases.\n\n", "human_text": "  Optical/near-infrared (optical/NIR; OIR) light from low-mass neutron star\nX-ray binaries (NSXBs) in outburst is traditionally thought to be thermal\nemission from the accretion disc. Here we present a comprehensive collection of\nquasi-simultaneous OIR and X-ray data from 19 low-magnetic field NSXBs,\nincluding new observations of three sources: 4U 0614+09, LMC X-2 and GX 349+2.\nThe average radio-OIR spectrum for NSXBs is alpha ~ +0.2 (where L_nu propto\nnu^alpha) at least at high luminosities when the radio jet is detected. This is\ncomparable to, but slightly more inverted than the alpha ~ 0.0 found for black\nhole X-ray binaries. The OIR spectra and relations between OIR and X-ray fluxes\nare compared to those expected if the OIR emission is dominated by thermal\nemission from an X-ray or viscously heated disc, or synchrotron emission from\nthe inner regions of the jets. We find that thermal emission due to X-ray\nreprocessing can explain all the data except at high luminosities for some\nNSXBs, namely the atolls and millisecond X-ray pulsars (MSXPs). Optically thin\nsynchrotron emission from the jets (with an observed OIR spectral index of\nalpha_thin < 0) dominate the NIR light above L_x ~ 10^36 erg/s and the optical\nabove L_x ~ 10^37 erg/s in these systems. For NSXB Z-sources, the OIR\nobservations can be explained by X-ray reprocessing alone, although synchrotron\nemission may make a low level contribution to the NIR, and could dominate the\nOIR in one or two cases.\n", "machine_text": "This article provides evidence for a contribution from jets to the OIR light of low-magnetic field neutron star X-ray binaries. By analyzing quasi-simultaneous OIR and X-ray data from 19 different sources, we found that the radio-OIR spectrum for NSXBs is alpha ~ +0.2, even at high luminosities where the radio jet is detected. Optically thin synchrotron emission from the jets dominates the NIR light above L_x ~ 10^36 erg/s and the optical above L_x ~ 10^37 erg/s from atolls and millisecond X-ray pulsars, while X-ray reprocessing is the only source of OIR emission in Z-sources, with synchrotron emission potentially making a low level contribution to the NIR.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3611}
{"prompt": "Rephrase the abstract of an article with title 'El universo de Einstein: 1905 - annus mirabilis - 2005'.\n  Year 2005 was the World Year of Physics, and it was commemorated worldwide as\nthe 100th anniversary of Albert Einstein's legendary works in which the\nfoundations of at least three areas of modern physics were laid: statistical\nmechanics, quantum mechanics and special relativity. These works turned year\n1905 in what deservedly was called the \"miraculous year\" (annus mirabilis) of\nEinstein. However, the influence of this great mind was not limited to science.\nAs it is well known, his fingerprint remains engraved in many aspects of our\ndaily life. Because of that, in this work we have tried to cover almost all the\nsubjects in which Einstein was involved during the last century and, of course,\ntry and reveal the future projection his actions will have in this new century\nthat has just begun. Among the subjects covered in the volume one can find the\npossible connection between Einstein and the artistic vanguard movement, his\nreligiosity, his days in Argentina, the Nobel Prize, the Einstein-Freud\ncorrespondence, his pacifism and the nuclear energy, science and politics under\nthe Second Empire and the Weimar Republic, and even a description of his\npatents and experiments, the studies performed to search for \"built-in\"\nfeatures in his brain and the doubts many had regarding whether Einstein was a\ngenius or a crank. Also included are essays on Einstein and Borges, philosophy\nand relativity, Mach's principle, the relation among science, arts and\nhumanities, and, closer to Einstein's own theoretical research, the twin\nparadox, chance and quantum mechanics, the arrow of time, gravitational lenses,\nstring theory, holography and black holes, gravitomagnetism, superconductivity,\ngravitational waves, the photoelectric effect and the alternative theories for\ngravitation.\n\n", "human_text": "  Year 2005 was the World Year of Physics, and it was commemorated worldwide as\nthe 100th anniversary of Albert Einstein's legendary works in which the\nfoundations of at least three areas of modern physics were laid: statistical\nmechanics, quantum mechanics and special relativity. These works turned year\n1905 in what deservedly was called the \"miraculous year\" (annus mirabilis) of\nEinstein. However, the influence of this great mind was not limited to science.\nAs it is well known, his fingerprint remains engraved in many aspects of our\ndaily life. Because of that, in this work we have tried to cover almost all the\nsubjects in which Einstein was involved during the last century and, of course,\ntry and reveal the future projection his actions will have in this new century\nthat has just begun. Among the subjects covered in the volume one can find the\npossible connection between Einstein and the artistic vanguard movement, his\nreligiosity, his days in Argentina, the Nobel Prize, the Einstein-Freud\ncorrespondence, his pacifism and the nuclear energy, science and politics under\nthe Second Empire and the Weimar Republic, and even a description of his\npatents and experiments, the studies performed to search for \"built-in\"\nfeatures in his brain and the doubts many had regarding whether Einstein was a\ngenius or a crank. Also included are essays on Einstein and Borges, philosophy\nand relativity, Mach's principle, the relation among science, arts and\nhumanities, and, closer to Einstein's own theoretical research, the twin\nparadox, chance and quantum mechanics, the arrow of time, gravitational lenses,\nstring theory, holography and black holes, gravitomagnetism, superconductivity,\ngravitational waves, the photoelectric effect and the alternative theories for\ngravitation.\n", "machine_text": "\nThis year marks the 100th anniversary of the exceptional contributions of Albert Einstein to modern physics, specifically statistical mechanics, quantum mechanics, and special relativity. His accomplishments have been rightfully dubbed the 'miraculous year' of Einstein. His influence has extended beyond science, and this work is intended to explore his influence and legacy throughout the last century as well as hint at the future projection of his impact into this new century. Examining a variety of topics such as Einstein and the artistic vanguard movement, his religiosity, his time spent in Argentina, the Nobel Prize, the Einstein-Freud correspondence, his pacifism, nuclear energy, and many of his experimental studies, the differences between genius and crank, Einstein and Borges, philosophy and relativity, Mach\u2019s principle, the relation between science, arts, and humanities, and more, this work illuminates a comprehensive view of the universe of Einstein.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4266}
{"prompt": "Rephrase the abstract of an article with title 'A Symplectic Test of the L-Functions Ratios Conjecture'.\n  Recently Conrey, Farmer and Zirnbauer conjectured formulas for the averages\nover a family of ratios of products of shifted L-functions. Their L-functions\nRatios Conjecture predicts both the main and lower order terms for many\nproblems, ranging from n-level correlations and densities to mollifiers and\nmoments to vanishing at the central point. There are now many results showing\nagreement between the main terms of number theory and random matrix theory;\nhowever, there are very few families where the lower order terms are known.\nThese terms often depend on subtle arithmetic properties of the family, and\nprovide a way to break the universality of behavior. The L-functions Ratios\nConjecture provides a powerful and tractable way to predict these terms. We\ntest a specific case here, that of the 1-level density for the symplectic\nfamily of quadratic Dirichlet characters arising from even fundamental\ndiscriminants d \\le X. For test functions supported in (-1/3, 1/3) we calculate\nall the lower order terms up to size O(X^{-1/2+epsilon}) and observe perfect\nagreement with the conjecture (for test functions supported in (-1, 1) we show\nagreement up to errors of size O(X^{-epsilon}) for any epsilon). Thus for this\nfamily and suitably restricted test functions, we completely verify the Ratios\nConjecture's prediction for the 1-level density.\n\n", "human_text": "  Recently Conrey, Farmer and Zirnbauer conjectured formulas for the averages\nover a family of ratios of products of shifted L-functions. Their L-functions\nRatios Conjecture predicts both the main and lower order terms for many\nproblems, ranging from n-level correlations and densities to mollifiers and\nmoments to vanishing at the central point. There are now many results showing\nagreement between the main terms of number theory and random matrix theory;\nhowever, there are very few families where the lower order terms are known.\nThese terms often depend on subtle arithmetic properties of the family, and\nprovide a way to break the universality of behavior. The L-functions Ratios\nConjecture provides a powerful and tractable way to predict these terms. We\ntest a specific case here, that of the 1-level density for the symplectic\nfamily of quadratic Dirichlet characters arising from even fundamental\ndiscriminants d \\le X. For test functions supported in (-1/3, 1/3) we calculate\nall the lower order terms up to size O(X^{-1/2+epsilon}) and observe perfect\nagreement with the conjecture (for test functions supported in (-1, 1) we show\nagreement up to errors of size O(X^{-epsilon}) for any epsilon). Thus for this\nfamily and suitably restricted test functions, we completely verify the Ratios\nConjecture's prediction for the 1-level density.\n", "machine_text": "\nThis article assesses the validity of the L-functions Ratios Conjecture concerning the 1-level density of the symplectic family of quadratic Dirichlet characters from even discriminants d, each of which is less than or equal to X. We calculate the lower order terms up to size O(X^{-1/2 + epsilon}) and observe perfect agreement with the Conjecture for test functions supported in [-1/3, 1/3]. Regarding test functions supported in [-1, 1], we demonstrate agreement with the Conjecture up to O(X^{-epsilon}), where epsilon is an arbitrarily small value. Our results suggest that the Ratios Conjecture effectively predicts the lower order terms of the 1-level density in this case, and thereby affirms the universality of behavior.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0927}
{"prompt": "Rephrase the abstract of an article with title 'Strange Nucleon Form Factors from $ep$ and $\\nu p$ Elastic Scattering'.\n  The recent parity-violating $ep$ forward-scattering elastic asymmetry data\nfrom Jefferson Lab (HAPPEx and G0), when combined with the $\\nu p$ elastic\ncross section data from Brookhaven (E734), permit an extraction of the\nstrangeness contribution to the vector and axial nucleon form factors for\nmomentum transfers in the range $0.45 < Q^2 < 1.0$ GeV$^2$. These results,\ncombined with the recent determination of the strange vector form factors at\n$Q^2 = 0.1$ GeV$^2$ (SAMPLE, HAPPEx, PVA4, G0) have been interpreted in terms\nof $uuds\\bar{s}$ configurations very different from the kaon-loop\nconfigurations usually associated with strangeness in the nucleon. New\nexperiments are being proposed to improve the state of our knowledge of the\n$\\nu p$ elastic cross section -- these new experiments will push the range of\n$Q^2$ to much lower values, and greatly increase the precision of the $\\nu p$\nelastic data. One outcome of this can be a measurement of the strangeness\ncontribution to the nucleon spin, $\\Delta s$. Nuclear targets (e.g. C or Ar)\nare to be used in these neutrino experiments, and so a deep understanding of\nthe nuclear physics, particularly in regard to final state effects, is needed\nbefore the potential of these precision experiments can be fully realized.\n\n", "human_text": "  The recent parity-violating $ep$ forward-scattering elastic asymmetry data\nfrom Jefferson Lab (HAPPEx and G0), when combined with the $\\nu p$ elastic\ncross section data from Brookhaven (E734), permit an extraction of the\nstrangeness contribution to the vector and axial nucleon form factors for\nmomentum transfers in the range $0.45 < Q^2 < 1.0$ GeV$^2$. These results,\ncombined with the recent determination of the strange vector form factors at\n$Q^2 = 0.1$ GeV$^2$ (SAMPLE, HAPPEx, PVA4, G0) have been interpreted in terms\nof $uuds\\bar{s}$ configurations very different from the kaon-loop\nconfigurations usually associated with strangeness in the nucleon. New\nexperiments are being proposed to improve the state of our knowledge of the\n$\\nu p$ elastic cross section -- these new experiments will push the range of\n$Q^2$ to much lower values, and greatly increase the precision of the $\\nu p$\nelastic data. One outcome of this can be a measurement of the strangeness\ncontribution to the nucleon spin, $\\Delta s$. Nuclear targets (e.g. C or Ar)\nare to be used in these neutrino experiments, and so a deep understanding of\nthe nuclear physics, particularly in regard to final state effects, is needed\nbefore the potential of these precision experiments can be fully realized.\n", "machine_text": "\nEvidence from Jefferson Lab's proton-electron (HAPPEx and G0) parity-violating forward-scattering asymmetry measurements, in conjunction with neutrino-proton elastic cross section observation from Brookhaven's E734 project, has offered the opportunity to assess the strangeness contribution of the nucleon vector and axial form factors in the range of 0.45 to 1.0 GeV$^2$. These results, combined with the strange vector form factors found from other studies (SAMPLE, HAPPEx, PVA4 and G0) have reportedly been established by configurations of the $uuds\\bar{s}$ variety that are unlike the typical kaon-loop configurations linked to nucleon strangeness. To advance our knowledge of the $\\nu p$ elastic cross section, new experiments targeting lower $Q^2$ values with heightened precision are in the works. If successful, they will bring the ability to measure the strangeness fraction of nucleon spins, $\\Delta s$. Understanding how the quantities in the nucleus interact and affect the final state is paramount to maximize output of said experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1115}
{"prompt": "Rephrase the abstract of an article with title 'Influence of an external magnetic field on the decoherence of a central\n  spin coupled to an antiferromagnetic environment'.\n  Using the spin wave approximation, we study the decoherence dynamics of a\ncentral spin coupled to an antiferromagnetic environment under the application\nof an external global magnetic field. The external magnetic field affects the\ndecoherence process through its effect on the antiferromagnetic environment. It\nis shown explicitly that the decoherence factor which displays a Gaussian decay\nwith time depends on the strength of the external magnetic field and the\ncrystal anisotropy field in the antiferromagnetic environment. When the values\nof the external magnetic field is increased to the critical field point at\nwhich the spin-flop transition (a first-order quantum phase transition) happens\nin the antiferromagnetic environment, the decoherence of the central spin\nreaches its highest point. This result is consistent with several recent\nquantum phase transition witness studies. The influences of the environmental\ntemperature on the decoherence behavior of the central spin are also\ninvestigated.\n\n", "human_text": "  Using the spin wave approximation, we study the decoherence dynamics of a\ncentral spin coupled to an antiferromagnetic environment under the application\nof an external global magnetic field. The external magnetic field affects the\ndecoherence process through its effect on the antiferromagnetic environment. It\nis shown explicitly that the decoherence factor which displays a Gaussian decay\nwith time depends on the strength of the external magnetic field and the\ncrystal anisotropy field in the antiferromagnetic environment. When the values\nof the external magnetic field is increased to the critical field point at\nwhich the spin-flop transition (a first-order quantum phase transition) happens\nin the antiferromagnetic environment, the decoherence of the central spin\nreaches its highest point. This result is consistent with several recent\nquantum phase transition witness studies. The influences of the environmental\ntemperature on the decoherence behavior of the central spin are also\ninvestigated.\n", "machine_text": "\nWe explore the effects of an external global magnetic field on the decoherence dynamics of a spin located in an antiferromagnetic environment. Our calculations, based on the spin wave approximation, reveal that the decoherence rate, quantified through a Gaussian decay function, is influenced by both the field strength and the anisotropy of the antiferromagnetic environment. The critical field strength at which the spin-flop transition in the antiferromagnetic environment occurs marks the peak of the central spin decoherence, providing results that corroborate recent quantum phase transition witness studies. We additionally consider the impact of temperature on the decoherence of the central spin.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0934}
{"prompt": "Rephrase the abstract of an article with title 'Asymmetric superconductivity in metallic systems'.\n  Different types of superfluid ground states have been investigated in systems\nof two species of fermions with Fermi surfaces that do not match. This study is\nrelevant for cold atomic systems, condensed matter physics and quark matter. In\nthis paper we consider this problem in the case the fermionic quasi-particles\ncan transmute into one another and only their total number is conserved. We use\na BCS approximation to study superconductivity in two-band metallic systems\nwith inter and intra-band interactions. Tuning the hybridization between the\nbands varies the mismatch of the Fermi surfaces and produces different\ninstabilities. For inter-band attractive interactions we find a first order\nnormal-superconductor and a homogeneous metastable phase with gapless\nexcitations. In the case of intra-band interactions, the transition from the\nsuperconductor to the normal state as hybridization increases is continuous and\nassociated with a quantum critical point. The case when both interactions are\npresent is also considered.\n\n", "human_text": "  Different types of superfluid ground states have been investigated in systems\nof two species of fermions with Fermi surfaces that do not match. This study is\nrelevant for cold atomic systems, condensed matter physics and quark matter. In\nthis paper we consider this problem in the case the fermionic quasi-particles\ncan transmute into one another and only their total number is conserved. We use\na BCS approximation to study superconductivity in two-band metallic systems\nwith inter and intra-band interactions. Tuning the hybridization between the\nbands varies the mismatch of the Fermi surfaces and produces different\ninstabilities. For inter-band attractive interactions we find a first order\nnormal-superconductor and a homogeneous metastable phase with gapless\nexcitations. In the case of intra-band interactions, the transition from the\nsuperconductor to the normal state as hybridization increases is continuous and\nassociated with a quantum critical point. The case when both interactions are\npresent is also considered.\n", "machine_text": "This article explores the science of asymmetric superconductivity in metallic systems using a BCS approximation. We consider a two-band system of fermions with interactions between intra- and inter-bands. The hybridization between the bands is varied and we investigate the instabilities it produces. We find that for inter-band attractive interactions, a normal-superconductor transition is present, as well as a homogenous metastable phase with gapless excitations. In the case of intra-band interactions, the transition from the superconductor to the normal state is continuous, related to a quantum critical point. Results are presented for the situation in which both intra- and inter-band interactions are present.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1201}
{"prompt": "Rephrase the abstract of an article with title 'Analytic models of plausible gravitational lens potentials'.\n  Gravitational lenses on galaxy scales are plausibly modelled as having\nellipsoidal symmetry and a universal dark matter density profile, with a Sersic\nprofile to describe the distribution of baryonic matter. Predicting all lensing\neffects requires knowledge of the total lens potential: in this work we give\nanalytic forms for that of the above hybrid model. Emphasising that complex\nlens potentials can be constructed from simpler components in linear\ncombination, we provide a recipe for attaining elliptical symmetry in either\nprojected mass or lens potential. We also provide analytic formulae for the\nlens potentials of Sersic profiles for integer and half-integer index. We then\npresent formulae describing the gravitational lensing effects due to\nsmoothly-truncated universal density profiles in cold dark matter model. For\nour isolated haloes the density profile falls off as radius to the minus fifth\nor seventh power beyond the tidal radius, functional forms that allow all\norders of lens potential derivatives to be calculated analytically, while\nensuring a non-divergent total mass. We show how the observables predicted by\nthis profile differ from that of the original infinite-mass NFW profile.\nExpressions for the gravitational flexion are highlighted. We show how\ndecreasing the tidal radius allows stripped haloes to be modelled, providing a\nframework for a fuller investigation of dark matter substructure in galaxies\nand clusters. Finally we remark on the need for finite mass halo profiles when\ndoing cosmological ray-tracing simulations, and the need for readily-calculable\nhigher order derivatives of the lens potential when studying catastrophes in\nstrong lenses.\n\n", "human_text": "  Gravitational lenses on galaxy scales are plausibly modelled as having\nellipsoidal symmetry and a universal dark matter density profile, with a Sersic\nprofile to describe the distribution of baryonic matter. Predicting all lensing\neffects requires knowledge of the total lens potential: in this work we give\nanalytic forms for that of the above hybrid model. Emphasising that complex\nlens potentials can be constructed from simpler components in linear\ncombination, we provide a recipe for attaining elliptical symmetry in either\nprojected mass or lens potential. We also provide analytic formulae for the\nlens potentials of Sersic profiles for integer and half-integer index. We then\npresent formulae describing the gravitational lensing effects due to\nsmoothly-truncated universal density profiles in cold dark matter model. For\nour isolated haloes the density profile falls off as radius to the minus fifth\nor seventh power beyond the tidal radius, functional forms that allow all\norders of lens potential derivatives to be calculated analytically, while\nensuring a non-divergent total mass. We show how the observables predicted by\nthis profile differ from that of the original infinite-mass NFW profile.\nExpressions for the gravitational flexion are highlighted. We show how\ndecreasing the tidal radius allows stripped haloes to be modelled, providing a\nframework for a fuller investigation of dark matter substructure in galaxies\nand clusters. Finally we remark on the need for finite mass halo profiles when\ndoing cosmological ray-tracing simulations, and the need for readily-calculable\nhigher order derivatives of the lens potential when studying catastrophes in\nstrong lenses.\n", "machine_text": "\nThis study explores the potential of elliptic, hybrid models of galactic gravitational lensing that combine a universal dark matter density profile with a Sersic profile for the baryonic matter distribution. To this end, analytic forms for the lens potentials of these models are derived, and a recipe for elliptic symmetry in either the projected mass or lens potential is developed. Additionally formulae describing the gravitational lensing effects of differently truncated universal cold dark matter are provided and taken compared to the infinite-mass NFW profile. Furthermore, the application of these models to stripped halo profiles and their implications for cosmological ray-tracing simulations and investigating catastrophic lensing effects are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0682}
{"prompt": "Rephrase the abstract of an article with title 'Discrete Thermodynamics of Lasers'.\n  The paper offers a discrete thermodynamic model of lasers. Laser is an open\nsystem; its equilibrium is based on a balance of two thermodynamic forces, one\nrelated to the incoming pumping power and another to the emitted light. The\nbasic expression for such equilibrium is a logistic map, graphical solutions to\nwhich are pitchfork bifurcation diagrams. As pumping force increases, the\nrelative populations on the ground and lasing branches tend to zero and unity\ncorrespondingly. An interesting feature of this model is the line spectrum of\nthe up and down transitions between the branches beyond bifurcation point. Even\nin a simple case of 2-level laser with only 2 possible transition types (up and\ndown), the spectra look like sets of the line packets, starting well before the\npopulation inversion. This effect is an independent confirmation of the\nEinstein's prohibition on practical realization of 2-level laser. Multilevel\nlasers may be approached by employing the idea of thermodynamic activity for\nthe emitting atoms. Considering coefficient of thermodynamic activity of the\nlasing level atoms to be proportional to the ratio of life times on the upper\nand lasing (the 3d) levels, one can derive a new basic map for the multilevel\nlaser system. For a modest ratio only of 0.01, spontaneous transitions between\nlevels are pushed to the area beyond population inversion, opening a space for\nthe functioning of laser.\n\n", "human_text": "  The paper offers a discrete thermodynamic model of lasers. Laser is an open\nsystem; its equilibrium is based on a balance of two thermodynamic forces, one\nrelated to the incoming pumping power and another to the emitted light. The\nbasic expression for such equilibrium is a logistic map, graphical solutions to\nwhich are pitchfork bifurcation diagrams. As pumping force increases, the\nrelative populations on the ground and lasing branches tend to zero and unity\ncorrespondingly. An interesting feature of this model is the line spectrum of\nthe up and down transitions between the branches beyond bifurcation point. Even\nin a simple case of 2-level laser with only 2 possible transition types (up and\ndown), the spectra look like sets of the line packets, starting well before the\npopulation inversion. This effect is an independent confirmation of the\nEinstein's prohibition on practical realization of 2-level laser. Multilevel\nlasers may be approached by employing the idea of thermodynamic activity for\nthe emitting atoms. Considering coefficient of thermodynamic activity of the\nlasing level atoms to be proportional to the ratio of life times on the upper\nand lasing (the 3d) levels, one can derive a new basic map for the multilevel\nlaser system. For a modest ratio only of 0.01, spontaneous transitions between\nlevels are pushed to the area beyond population inversion, opening a space for\nthe functioning of laser.\n", "machine_text": "This article studies the thermodynamic aspects of lasers. The equilibrium of the open system is determined by two thermodynamic forces, the incoming pumping power and the emitted light. The logistic map is used to express this equilibrium, which reveals pitchfork bifurcation diagrams when graphed. As the pumping force increases, there is a corresponding decrease in the relative populations of the ground levels and the lasing branches. An interesting observation of this model is the spectrum of up and down transitions between the branches beyond the bifurcation point. With just two transition types (up and down) of two-level lasers, it is impossible to practically bring into effect. Multilevel lasers are discussed by introducing the concept of thermodynamic activity to the emitting atoms. By doing so, the concept of population inversion is pushed beyond the scope of spontaneous transitions between levels, which creates a chance for the system to function as a laser.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1289}
{"prompt": "Rephrase the abstract of an article with title 'Probing the Impact of Stellar Duplicity on Planet Occurrence with\n  Spectroscopic and Imaging Observations'.\n  Although it is commonly agreed that the presence of a close stellar companion\nis likely to affect planet formation and evolution, the precise effects and\ntheir actual impact on planet occurrence and properties are still debated. In\nparticular, observational constraints are sparse, a consequence of the\ndiscrimination against close binaries in Doppler planet searches. To bring\nobservational constraints on the occurrence and properties of planets in\nbinaries and multiple stars, we have been conducting two dedicated observing\nprograms using both adaptive optics imaging and radial-velocity monitoring. In\nthis chapter we explain our approach and present preliminary results from these\ntwo programs. A simplified statistical analysis of the data from our VLT/NACO\nimaging survey brings the first observational evidence that the occurrence of\nplanets is reduced in binaries closer than ~120 AU. On the radial-velocity\nside, current results confirm that the use of two-dimensional correlation\nallows to search for circumprimary giant planets in many types of spectroscopic\nbinaries. Definitive results from our ongoing planet search in spectroscopic\nbinaries should yield important constraints on the closest binaries susceptible\nof hosting circumprimary giant planets.\n\n", "human_text": "  Although it is commonly agreed that the presence of a close stellar companion\nis likely to affect planet formation and evolution, the precise effects and\ntheir actual impact on planet occurrence and properties are still debated. In\nparticular, observational constraints are sparse, a consequence of the\ndiscrimination against close binaries in Doppler planet searches. To bring\nobservational constraints on the occurrence and properties of planets in\nbinaries and multiple stars, we have been conducting two dedicated observing\nprograms using both adaptive optics imaging and radial-velocity monitoring. In\nthis chapter we explain our approach and present preliminary results from these\ntwo programs. A simplified statistical analysis of the data from our VLT/NACO\nimaging survey brings the first observational evidence that the occurrence of\nplanets is reduced in binaries closer than ~120 AU. On the radial-velocity\nside, current results confirm that the use of two-dimensional correlation\nallows to search for circumprimary giant planets in many types of spectroscopic\nbinaries. Definitive results from our ongoing planet search in spectroscopic\nbinaries should yield important constraints on the closest binaries susceptible\nof hosting circumprimary giant planets.\n", "machine_text": "\nInvestigations into the influence of stellar multiplicity on planet presence and characteristics have been marred by a lack of observational data. In an effort to bring observational evidence to this field, two programs utilizing adaptive optics imaging and radial-velocity monitoring have been initiated. In this chapter, the restructuring of the approach and the preliminary outcomes of these two projects are reported. Analysis of the findings from VLT/NACO imaging survey offer the first individual proof that the existence of planets is lessened in binaries closer than ~120 AU. Additionally, on the radial-velocity side, recent results underscore the use of two-dimensional correlation to search for planets orbiting the primary star in various forms of spectroscopic binaries. The pursuing conclusion of the survey of planets in spectroscopic binaries is set to bring crucial information on the closest binaries capable of holding circumprimary giant planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3173}
{"prompt": "Rephrase the abstract of an article with title 'Three Particle Correlations from STAR'.\n  Two-particle correlations have shown modification to the away-side shape in\ncentral Au+Au collisions relative to $pp$, d+Au and peripheral Au+Au\ncollisions. Different scenarios can explain this modification including: large\nangle gluon radiation, jets deflected by transverse flow, path length dependent\nenergy loss, Cerenkov gluon radiation of fast moving particles, and conical\nflow generated by hydrodynamic Mach-cone shock-waves. Three-particle\ncorrelations have the power to distinguish the scenarios with conical emission,\nconical flow and Cerenkov radiation, from other scenarios. In addition, the\ndependence of the observed shapes on the $p_T$ of the associated particles can\nbe used to distinguish conical emission from a sonic boom (Mach-cone) and from\nQCD-Cerenkov radiation. We present results from STAR on 3-particle azimuthal\ncorrelations for a high $p_T$ trigger particle with two softer particles.\nResults are shown for $pp$, d+Au and high statistics Au+Au collisions at\n$\\sqrt{s_{NN}}$=200 GeV. An important aspect of the analysis is the subtraction\nof combinatorial backgrounds. Systematic uncertainties due to this subtraction\nand the flow harmonics v2 and v4 are investigated in detail. The implications\nof the results for the presence or absence of conical flow from Mach-cones are\ndiscussed.\n\n", "human_text": "  Two-particle correlations have shown modification to the away-side shape in\ncentral Au+Au collisions relative to $pp$, d+Au and peripheral Au+Au\ncollisions. Different scenarios can explain this modification including: large\nangle gluon radiation, jets deflected by transverse flow, path length dependent\nenergy loss, Cerenkov gluon radiation of fast moving particles, and conical\nflow generated by hydrodynamic Mach-cone shock-waves. Three-particle\ncorrelations have the power to distinguish the scenarios with conical emission,\nconical flow and Cerenkov radiation, from other scenarios. In addition, the\ndependence of the observed shapes on the $p_T$ of the associated particles can\nbe used to distinguish conical emission from a sonic boom (Mach-cone) and from\nQCD-Cerenkov radiation. We present results from STAR on 3-particle azimuthal\ncorrelations for a high $p_T$ trigger particle with two softer particles.\nResults are shown for $pp$, d+Au and high statistics Au+Au collisions at\n$\\sqrt{s_{NN}}$=200 GeV. An important aspect of the analysis is the subtraction\nof combinatorial backgrounds. Systematic uncertainties due to this subtraction\nand the flow harmonics v2 and v4 are investigated in detail. The implications\nof the results for the presence or absence of conical flow from Mach-cones are\ndiscussed.\n", "machine_text": "\nResults from the STAR experiment on 3-particle correlations in $pp$, d+Au and Au+Au collisions at $\\sqrt{s_{NN}}$=200 GeV are discussed. Through comparison of the away-side shape in central Au+Au, relative to $pp$, d+Au and peripheral Au+Au collisions, several scenarios are proposed to explain the modification of two-particle correlations including: gluon radiation, jet deflection, energy loss, and conical flow. Three-particle correlations are used to differentiate these scenarios to determine if a Mach-cone conical flow is present. The $p_T$ dependence of the observed shapes is used to distinguish conical emission from sonic booms and Cerenkov radiation. The combinatorial backgrounds and flow harmonics v2 and v4 are studied in detail, with the implications of the results for the presence of conical flow discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.022}
{"prompt": "Rephrase the abstract of an article with title 'New Integral Representations of Whittaker Functions for Classical Lie\n  Groups'.\n  We propose integral representations of the Whittaker functions for the\nclassical Lie algebras sp(2l), so(2l) and so(2l+1). These integral\nrepresentations generalize the integral representation of gl(l+1)-Whittaker\nfunctions first introduced by Givental. One of the salient features of the\nGivental representation is its recursive structure with respect to the rank of\nthe Lie algebra gl(l+1). The proposed generalization of the Givental\nrepresentation to the classical Lie algebras retains this property. It was\nshown elsewhere that the integral recursion operator for gl(l+1)-Whittaker\nfunction in the Givental representation coincides with a degeneration of the\nBaxter Q-operator for $\\hat{gl(l+1)}$-Toda chains. We construct Q-operator for\naffine Lie algebras $\\hat{so(2l)}$, $\\hat{so(2l+1)}$ and a twisted form of\n$\\hat{gl(2l)}$. We demonstrate that the relation between recursion integral\noperators of the generalized Givental representation and degenerate Q-operators\nremains valid for all classical Lie algebras.\n\n", "human_text": "  We propose integral representations of the Whittaker functions for the\nclassical Lie algebras sp(2l), so(2l) and so(2l+1). These integral\nrepresentations generalize the integral representation of gl(l+1)-Whittaker\nfunctions first introduced by Givental. One of the salient features of the\nGivental representation is its recursive structure with respect to the rank of\nthe Lie algebra gl(l+1). The proposed generalization of the Givental\nrepresentation to the classical Lie algebras retains this property. It was\nshown elsewhere that the integral recursion operator for gl(l+1)-Whittaker\nfunction in the Givental representation coincides with a degeneration of the\nBaxter Q-operator for $\\hat{gl(l+1)}$-Toda chains. We construct Q-operator for\naffine Lie algebras $\\hat{so(2l)}$, $\\hat{so(2l+1)}$ and a twisted form of\n$\\hat{gl(2l)}$. We demonstrate that the relation between recursion integral\noperators of the generalized Givental representation and degenerate Q-operators\nremains valid for all classical Lie algebras.\n", "machine_text": "\nThis article introduces integral representations of Whittaker functions for the classical Lie algebras sp(2l), so(2l) and so(2l+1). These representations are an extension of Givental's integral representation of gl(l+1)-Whittaker functions that has the special property of being recursive in nature. It was previously shown that the gl(l+1) integral recursion operator is connected to the Baxter Q-operator of the corresponding affine Lie algebra. We demonstrate this connection by constructing Q-operators for $\\hat{so(2l)}$, $\\hat{so(2l+1)}$ and a twisted version of $\\hat{gl(2l)}$. Our results suggest that the link between recursion integral operators and degenerated Q-operators for classical Lie algebras is generalizable.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2886}
{"prompt": "Rephrase the abstract of an article with title 'Detection of Emission from the CN Radical in the Cloverleaf Quasar at\n  z=2.56'.\n  We report the detection of CN(N=3-2) emission towards the Cloverleaf quasar\n(z=2.56) based on observations with the IRAM Plateau de Bure Interferometer.\nThis is the first clear detection of emission from this radical at high\nredshift. CN emission is a tracer of dense molecular hydrogen gas (n(H2) > 10^4\ncm^{-3}) within star-forming molecular clouds, in particular in regions where\nthe clouds are affected by UV radiation. The HCN/CN intensity ratio can be used\nas a diagnostic for the relative importance of photodissociation regions (PDRs)\nin a source, and as a sensitive probe of optical depth, the radiation field,\nand photochemical processes. We derive a lensing-corrected CN(N=3-2) line\nluminosity of L'(CN(3-2) = (4.5 +/- 0.5) x 10^9 K km/s pc^2. The ratio between\nCN luminosity and far-infrared luminosity falls within the scatter of the same\nrelationship found for low-z (ultra-) luminous infrared galaxies. Combining our\nnew results with CO(J=3-2) and HCN(J=1-0) measurements from the literature and\nassuming thermal excitation for all transitions, we find a CO/CN luminosity\nratio of 9.3 +/- 1.9 and a HCN/CN luminosity ratio of 0.95 +/- 0.15. However,\nwe find that the CN(N=3-2) line is likely only subthermally excited, implying\nthat those ratios may only provide upper limits for the intrinsic 1-0 line\nluminosity ratios. We conclude that, in combination with other molecular gas\ntracers like CO, HCN, and HCO+, CN is an important probe of the physical\nconditions and chemical composition of dense molecular environments at high\nredshift.\n\n", "human_text": "  We report the detection of CN(N=3-2) emission towards the Cloverleaf quasar\n(z=2.56) based on observations with the IRAM Plateau de Bure Interferometer.\nThis is the first clear detection of emission from this radical at high\nredshift. CN emission is a tracer of dense molecular hydrogen gas (n(H2) > 10^4\ncm^{-3}) within star-forming molecular clouds, in particular in regions where\nthe clouds are affected by UV radiation. The HCN/CN intensity ratio can be used\nas a diagnostic for the relative importance of photodissociation regions (PDRs)\nin a source, and as a sensitive probe of optical depth, the radiation field,\nand photochemical processes. We derive a lensing-corrected CN(N=3-2) line\nluminosity of L'(CN(3-2) = (4.5 +/- 0.5) x 10^9 K km/s pc^2. The ratio between\nCN luminosity and far-infrared luminosity falls within the scatter of the same\nrelationship found for low-z (ultra-) luminous infrared galaxies. Combining our\nnew results with CO(J=3-2) and HCN(J=1-0) measurements from the literature and\nassuming thermal excitation for all transitions, we find a CO/CN luminosity\nratio of 9.3 +/- 1.9 and a HCN/CN luminosity ratio of 0.95 +/- 0.15. However,\nwe find that the CN(N=3-2) line is likely only subthermally excited, implying\nthat those ratios may only provide upper limits for the intrinsic 1-0 line\nluminosity ratios. We conclude that, in combination with other molecular gas\ntracers like CO, HCN, and HCO+, CN is an important probe of the physical\nconditions and chemical composition of dense molecular environments at high\nredshift.\n", "machine_text": "\nWe have detected the presence of CN(N=3-2) emission from the Cloverleaf quasar (z=2.56) for the first time, by utilizing the IRAM Plateau de Bure Interferometer. This emission is a tracer of high density molecular hydrogen clouds, in particular those affected by UV radiation. We can therefore assess the importance of photodissociation regions, radiation field strength and photochemical processes by investigating the HCN/CN intensity ratio. Our findings suggest a CN(N=3-2) line luminosity of L'(CN(3-2) = (4.5 +/- 0.5) x 10^9 K km/s pc^2 when accounting for lensing. This ratio lies within the range of those observed for low-z (ultra-luminous) infrared galaxies. Combining our results with other indicators, such as CO(J=3-2), HCN(J=1-0) etc, indicates a CO/CN luminosity ratio of 9.3 +/- 1.9 and HCN/CN luminosity ratio of 0.95 +/- 0.15. We hypothesize that the CN(N=3-2) line is mostly sub-thermally excited, thus implying these ratios could be significantly higher than found in this analysis. Overall, CN is a sensitive tool to study the physical conditions and chemical compositions of dense molecular environments at high redshifts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3338}
{"prompt": "Rephrase the abstract of an article with title 'Computer simulation of model cohesive powders: influence of assembling\n  procedure and contact laws on low consolidation states'.\n  The structure and mechanical properties of a simple two-dimensional model of\na cohesive powder are investigated by molecular dynamics simulations.\nMicromechanical ingredients involve elasticity, friction, a short range\nattraction and, possibly, rolling resistance (RR) in contacts. The\nmicrostructure of the cohesive packing varies according to the assembling\nprocedure, from rather densely packed if isolated particles are directly\ncompressed to much looser if the formation of large aggregates is allowed prior\nto compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure\nP, acting on grains of diameter $a$, to maximum tensile contact force F0. At\nlow P* the final structure depends on the level of velocity fluctuations at the\nearly stages of cluster aggregation. With RR the coordination number approaches\n2 in the limit of low initial velocities or large rolling friction. The force\nnetwork generally comprises small hyperstatic clusters with forces of the order\nof F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly\nrearranges into force chain-like patterns. Density correlations witness a\nfractal structure, with dimension Df, up to some density-dependent blob size.\nWIth RR Df coincides with the ballistic aggregation result, despite a possibly\ndifferent connectivity. Possible effects of some parameters on material\nstrength are evoked.\n\n", "human_text": "  The structure and mechanical properties of a simple two-dimensional model of\na cohesive powder are investigated by molecular dynamics simulations.\nMicromechanical ingredients involve elasticity, friction, a short range\nattraction and, possibly, rolling resistance (RR) in contacts. The\nmicrostructure of the cohesive packing varies according to the assembling\nprocedure, from rather densely packed if isolated particles are directly\ncompressed to much looser if the formation of large aggregates is allowed prior\nto compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure\nP, acting on grains of diameter $a$, to maximum tensile contact force F0. At\nlow P* the final structure depends on the level of velocity fluctuations at the\nearly stages of cluster aggregation. With RR the coordination number approaches\n2 in the limit of low initial velocities or large rolling friction. The force\nnetwork generally comprises small hyperstatic clusters with forces of the order\nof F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly\nrearranges into force chain-like patterns. Density correlations witness a\nfractal structure, with dimension Df, up to some density-dependent blob size.\nWIth RR Df coincides with the ballistic aggregation result, despite a possibly\ndifferent connectivity. Possible effects of some parameters on material\nstrength are evoked.\n", "machine_text": "\nMolecular dynamics simulations are used to study the composition and mechanical properties of a simplified two-dimensional model of a cohesive powder. The characteristics of the cohesive packaging depend on the particular procedure used for assembly, from denser structures when isolated particles are compressed to looser ones when large aggregates are combined prior to pressing. Essential in governing the behavior of the microstructure is the ratio of applied pressure acting on the grains of size $ a$ to the maximum tension of the contact force, given as ($P^*=F_a/F_0$). At lower $P^*$, the velocity fluctuations during the early phases of cluster aggregation determines how the microstructure develops. If rolling resistance is accounted for the final coordination number adapts to two when initial velocity is low or there is a considerable rolling friction. The pattern of contact forces shows small hyperstatic clusters linked by unstressed arms. As $P^*$ is increased, there is a restructuring towards force chain-like architecture. The density of the material presents fractal behavior which is determined by the density and blob size. The effects of some parameters on the strength of the cohesive material are also studied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3295}
{"prompt": "Rephrase the abstract of an article with title 'Reply to comment on \"Essence of intrinsic tunnelling: Distinguishing\n  intrinsic features from artefacts'.\n  The recent PRB, henceforth referred as Ref.[1], experimentally resolves the\nintrinsic shape of the c-axis current-voltage characteristics (IVC) of HTSC and\ndemonstrates that at sufficiently high heat loads the heating-induced IVC\nnonlinearities exceed the intrinsic ones so radically that the latter might be\nsafely ignored.\n  The author of the comment fails to take account of the experimental findings\nby Ref.[1] and seeks to cast doubt on all its conclusions through reference to\na brush-like IVC, which is claimed to be free of heating. I will show that this\nclaim lacks substantiation; indeed it can be stated with certainty that the IVC\nis not free from heating. I will further show that the data selected for this\ncomment make it possible to explore for the first time the effect of\ntemperature on a range of loads where the genuine response is not hidden by\nheating and to demonstrate for the first time that $R(T)$ of the same sample is\nresponsible for a rich variety of IVC behaviours taken above and below $T_c$ at\nbath temperatures spanned over 180K. Thus these data in fact provide strong\nnovel evidence in favour of the major conclusions by Ref.[1], in particular the\nextrinsic cause of the key findings by intrinsic tunnelling spectroscopy.\n\n", "human_text": "  The recent PRB, henceforth referred as Ref.[1], experimentally resolves the\nintrinsic shape of the c-axis current-voltage characteristics (IVC) of HTSC and\ndemonstrates that at sufficiently high heat loads the heating-induced IVC\nnonlinearities exceed the intrinsic ones so radically that the latter might be\nsafely ignored.\n  The author of the comment fails to take account of the experimental findings\nby Ref.[1] and seeks to cast doubt on all its conclusions through reference to\na brush-like IVC, which is claimed to be free of heating. I will show that this\nclaim lacks substantiation; indeed it can be stated with certainty that the IVC\nis not free from heating. I will further show that the data selected for this\ncomment make it possible to explore for the first time the effect of\ntemperature on a range of loads where the genuine response is not hidden by\nheating and to demonstrate for the first time that $R(T)$ of the same sample is\nresponsible for a rich variety of IVC behaviours taken above and below $T_c$ at\nbath temperatures spanned over 180K. Thus these data in fact provide strong\nnovel evidence in favour of the major conclusions by Ref.[1], in particular the\nextrinsic cause of the key findings by intrinsic tunnelling spectroscopy.\n", "machine_text": "\nIn this article, the author refutes a comment on an earlier PRB paper (Ref.[1]) which argued for the existence of intrinsic features of the c-axis current-voltage characteristics (IVC) of high-temperature superconducting (HTSC) materials at high heat loads, which Ref.[1] had suggested to be negligible. The author will demonstrate that the comment's IVC shape was indeed caused by heating, disproving the claim that it is intrinsic, and will present data which establishes that temperature has a strong effect on the range of loads which cannot be masked by heating, thus providing evidence to support Ref.[1]'s major conclusions. This data will therefore further the understandings of intrinsic tunnelling spectroscopy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0594}
{"prompt": "Rephrase the abstract of an article with title 'Ab initio wavefunction based methods for excited states in solids:\n  correlation corrections to the band structure of ionic oxides'.\n  Ab initio wavefunction based methods are applied to the study of electron\ncorrelation effects on the band structure of oxide systems. We choose MgO as a\nprototype closed-shell ionic oxide. Our analysis is based on a local\nHamiltonian approach and performed on finite fragments cut from the infinite\nsolid. Localized Wannier functions and embedding potentials are obtained from\nprior periodic Hartree-Fock (HF) calculations. We investigate the role of\nvarious electron correlation effects in reducing the HF band gap and modifying\nthe band widths. On-site and nearest-neighbor charge relaxation as well as\nlong-range polarization effects are calculated. Whereas correlation effects are\nessential for computing accurate band gaps, we found that they produce smaller\nchanges on the HF band widths, at least for this material. Surprisingly, a\nbroadening effect is obtained for the O 2p valence bands. The ab initio data\nare in good agreement with the energy gap and band width derived from\nthermoreflectance and x-ray photoemission experiments. The results show that\nthe wavefunction based approach applied here allows for well controlled\napproximations and a transparent identification of the microscopic processes\nwhich determine the electronic band structure.\n\n", "human_text": "  Ab initio wavefunction based methods are applied to the study of electron\ncorrelation effects on the band structure of oxide systems. We choose MgO as a\nprototype closed-shell ionic oxide. Our analysis is based on a local\nHamiltonian approach and performed on finite fragments cut from the infinite\nsolid. Localized Wannier functions and embedding potentials are obtained from\nprior periodic Hartree-Fock (HF) calculations. We investigate the role of\nvarious electron correlation effects in reducing the HF band gap and modifying\nthe band widths. On-site and nearest-neighbor charge relaxation as well as\nlong-range polarization effects are calculated. Whereas correlation effects are\nessential for computing accurate band gaps, we found that they produce smaller\nchanges on the HF band widths, at least for this material. Surprisingly, a\nbroadening effect is obtained for the O 2p valence bands. The ab initio data\nare in good agreement with the energy gap and band width derived from\nthermoreflectance and x-ray photoemission experiments. The results show that\nthe wavefunction based approach applied here allows for well controlled\napproximations and a transparent identification of the microscopic processes\nwhich determine the electronic band structure.\n", "machine_text": "\nWe explore the role of electron correlation effects on the band structure of oxide systems, namely MgO, through applying ab initio wavefunction based methods. Our approach consists of a local Hamiltonian approach and is performed on finite fragments cut from the infinite solid. Through using localized Wannier functions and embedding potentials obtained from prior periodic Hartree-Fock (HF) calculations, we calculate on-site, nearest-neighbor charge relaxation, and long-range polarization effects in order to examine their impact on diminishing the HF band gap and modifying the band widths. We find that correlation effects are essential for obtaining accurate band gap data, but make less of an impact on HF band widths. Intriguingly, we observe a broadening effect for O 2p valence bands. Our data align with energy gap and band width measurements through thermoreflectance and x-ray photoemission experiments, implying wavefunction based methods are capable of accurately approximating the electronic band structure while identifying its determining processes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1906}
{"prompt": "Rephrase the abstract of an article with title 'Spatially resolved kinematics and stellar populations of brightest\n  cluster and group galaxies'.\n  We present an examination of the kinematics and stellar populations of a\nsample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies\n(BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise\nGemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these\ngalaxies and use Lick indices to determine ages, metallicities and\nalpha-element abundance ratios out to at least their effective radii. We find\nthat the BGGs and BCGs have very uniform masses, central ages and central\nmetallicities. Examining the radial dependence of their stellar populations, we\nfind no significant velocity dispersion, age, or alpha-enhancement gradients.\nHowever, we find a wide range of metallicity gradients, suggesting a variety of\nformation mechanisms. The range of metallicity gradients observed is surprising\ngiven the homogeneous environment these galaxies probe and their uniform\ncentral stellar populations. However, our results are inconsistent with any\nsingle model of galaxy formation and emphasize the need for more theoretical\nunderstanding of both the origins of metallicity gradients and galaxy formation\nitself. We postulate two possible physical causes for the different formation\nmechanisms.\n\n", "human_text": "  We present an examination of the kinematics and stellar populations of a\nsample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies\n(BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise\nGemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these\ngalaxies and use Lick indices to determine ages, metallicities and\nalpha-element abundance ratios out to at least their effective radii. We find\nthat the BGGs and BCGs have very uniform masses, central ages and central\nmetallicities. Examining the radial dependence of their stellar populations, we\nfind no significant velocity dispersion, age, or alpha-enhancement gradients.\nHowever, we find a wide range of metallicity gradients, suggesting a variety of\nformation mechanisms. The range of metallicity gradients observed is surprising\ngiven the homogeneous environment these galaxies probe and their uniform\ncentral stellar populations. However, our results are inconsistent with any\nsingle model of galaxy formation and emphasize the need for more theoretical\nunderstanding of both the origins of metallicity gradients and galaxy formation\nitself. We postulate two possible physical causes for the different formation\nmechanisms.\n", "machine_text": "\nThis study examines the kinematics and stellar characteristics of a collection of three Brightest Group Galaxies (BGGs) and three Brightest Cluster Galaxies (BCGs) that are located in X-ray emitting clusters and groups. Applying high signal-to-noise spectra originating from the Gemini/GMOS, we compute the ages, metallicities, and abundance ratios of the sample galaxies up to their effective radii. We find that the BGGs and BCGs share similar bodies in terms of mass, central ages, and central levels of metallicity. By analyzing the variation of stellar elements over the radial parameter, we detect no substantial changes in velocity, age, or alpha-enhanced concentrations. Yet, the metallicity displayed significant scale difference, pointing to an assortment of formation mechanisms. This range of metallicity gradients opposes the unified state of the surveyed galaxies, indicating a need for more theories that would explain the origins of metallicity gradients and the general concept of galaxy formation. Ultimately, we introduce two prospective causes for the various formations mechanisms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3097}
{"prompt": "Rephrase the abstract of an article with title 'The Distance Geometry of Music'.\n  We demonstrate relationships between the classic Euclidean algorithm and many\nother fields of study, particularly in the context of music and distance\ngeometry. Specifically, we show how the structure of the Euclidean algorithm\ndefines a family of rhythms which encompass over forty timelines\n(\\emph{ostinatos}) from traditional world music. We prove that these\n\\emph{Euclidean rhythms} have the mathematical property that their onset\npatterns are distributed as evenly as possible: they maximize the sum of the\nEuclidean distances between all pairs of onsets, viewing onsets as points on a\ncircle. Indeed, Euclidean rhythms are the unique rhythms that maximize this\nnotion of \\emph{evenness}. We also show that essentially all Euclidean rhythms\nare \\emph{deep}: each distinct distance between onsets occurs with a unique\nmultiplicity, and these multiplicies form an interval $1,2,...,k-1$. Finally,\nwe characterize all deep rhythms, showing that they form a subclass of\ngenerated rhythms, which in turn proves a useful property called shelling. All\nof our results for musical rhythms apply equally well to musical scales. In\naddition, many of the problems we explore are interesting in their own right as\ndistance geometry problems on the circle; some of the same problems were\nexplored by Erd\\H{o}s in the plane.\n\n", "human_text": "  We demonstrate relationships between the classic Euclidean algorithm and many\nother fields of study, particularly in the context of music and distance\ngeometry. Specifically, we show how the structure of the Euclidean algorithm\ndefines a family of rhythms which encompass over forty timelines\n(\\emph{ostinatos}) from traditional world music. We prove that these\n\\emph{Euclidean rhythms} have the mathematical property that their onset\npatterns are distributed as evenly as possible: they maximize the sum of the\nEuclidean distances between all pairs of onsets, viewing onsets as points on a\ncircle. Indeed, Euclidean rhythms are the unique rhythms that maximize this\nnotion of \\emph{evenness}. We also show that essentially all Euclidean rhythms\nare \\emph{deep}: each distinct distance between onsets occurs with a unique\nmultiplicity, and these multiplicies form an interval $1,2,...,k-1$. Finally,\nwe characterize all deep rhythms, showing that they form a subclass of\ngenerated rhythms, which in turn proves a useful property called shelling. All\nof our results for musical rhythms apply equally well to musical scales. In\naddition, many of the problems we explore are interesting in their own right as\ndistance geometry problems on the circle; some of the same problems were\nexplored by Erd\\H{o}s in the plane.\n", "machine_text": "\nWe explore the relationship between Euclidean algorithms, music, and distance geometry. Specifically, we show how Euclidean algorithms can be used to create a family of rhythmic timelines, called Euclidean rhythms, that have the mathematical property of evenly distributed beat onsets. Evenness is defined as maximizing the sum of Euclidean distances between all pairs of onsets, treating onsets as points on a circle. In addition, Euclidean rhythms are shown to be deep - each distinct distance between onsets occurs with a unique multiplicity. We also characterize all deep rhythms, proving that they form a subclass of generated rhythms and demonstrating a useful property called shelling. Furthermore, many of the problems we explore are interesting from a distance geometry point of view, having been previously investigated by Erd\\H{o}s. These results can be applied to musical scales as well as rhythms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4085}
{"prompt": "Rephrase the abstract of an article with title 'Evaporation of buffer gas-thermalized anions out of a multipole rf ion\n  trap'.\n  We identify plain evaporation of ions as the fundamental loss mechanism out\nof a multipole ion trap. Using thermalized negative Cl- ions we find that the\nevaporative loss rate is proportional to a Boltzmann factor. This thermodynamic\ndescription sheds new light on the dynamics of particles in time-varying\nconfining potentials. It specifically allows us to extract the effective depth\nof the ion trap as the activation energy for evaporation. As a function of the\nrf amplitude we find two distinct regimes related to the stability of motion of\nthe trapped ions. For low amplitudes the entire trap allows for stable motion\nand the trap depth increases with the rf field. For larger rf amplitudes,\nhowever, rapid energy transfer from the field to the ion motion can occur at\nlarge trap radii, which leads to a reduction of the effective trapping volume.\nIn this regime the trap depth decreases again with increasing rf amplitude. We\ngive an analytical parameterization of the trap depth for various multipole\ntraps that allows predictions of the most favorable trapping conditions.\n\n", "human_text": "  We identify plain evaporation of ions as the fundamental loss mechanism out\nof a multipole ion trap. Using thermalized negative Cl- ions we find that the\nevaporative loss rate is proportional to a Boltzmann factor. This thermodynamic\ndescription sheds new light on the dynamics of particles in time-varying\nconfining potentials. It specifically allows us to extract the effective depth\nof the ion trap as the activation energy for evaporation. As a function of the\nrf amplitude we find two distinct regimes related to the stability of motion of\nthe trapped ions. For low amplitudes the entire trap allows for stable motion\nand the trap depth increases with the rf field. For larger rf amplitudes,\nhowever, rapid energy transfer from the field to the ion motion can occur at\nlarge trap radii, which leads to a reduction of the effective trapping volume.\nIn this regime the trap depth decreases again with increasing rf amplitude. We\ngive an analytical parameterization of the trap depth for various multipole\ntraps that allows predictions of the most favorable trapping conditions.\n", "machine_text": "This investigation reveals the source and nature of thermal ion evaporation out of\na multipole ion trap. Results indicate that the evaporation rate is connected to\na Boltzmann factor, with an activation energy as an adjustable trap parameter.\nA dependence of the effective trap volume on the amplitude of the applied rf trapping\nfield and an analytical parametersation of the trap depth are also outlined, thus\naiding in determining the most favorable trapping conditions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0224}
{"prompt": "Rephrase the abstract of an article with title 'Almost Product Evaluation of Hankel Determinants'.\n  An extensive literature exists describing various techniques for the\nevaluation of Hankel determinants. The prevailing methods such as Dodgson\ncondensation, continued fraction expansion, LU decomposition, all produce\nproduct formulas when they are applicable. We mention the classic case of the\nHankel determinants with binomial entries ${3k+2 \\choose k}$ and those with\nentries ${3k \\choose k}$; both of these classes of Hankel determinants have\nproduct form evaluations. The intermediate case, ${3k+1 \\choose k}$ has not\nbeen evaluated. There is a good reason for this: these latter determinants do\nnot have product form evaluations.\n  In this paper we evaluate the Hankel determinant of ${3k+1 \\choose k}$. The\nevaluation is a sum of a small number of products, an almost product.\n  The method actually provides more, and as applications, we present the\nsalient points for the evaluation of a number of other Hankel determinants with\npolynomial entries, along with product and almost product form evaluations at\nspecial points.\n\n", "human_text": "  An extensive literature exists describing various techniques for the\nevaluation of Hankel determinants. The prevailing methods such as Dodgson\ncondensation, continued fraction expansion, LU decomposition, all produce\nproduct formulas when they are applicable. We mention the classic case of the\nHankel determinants with binomial entries ${3k+2 \\choose k}$ and those with\nentries ${3k \\choose k}$; both of these classes of Hankel determinants have\nproduct form evaluations. The intermediate case, ${3k+1 \\choose k}$ has not\nbeen evaluated. There is a good reason for this: these latter determinants do\nnot have product form evaluations.\n  In this paper we evaluate the Hankel determinant of ${3k+1 \\choose k}$. The\nevaluation is a sum of a small number of products, an almost product.\n  The method actually provides more, and as applications, we present the\nsalient points for the evaluation of a number of other Hankel determinants with\npolynomial entries, along with product and almost product form evaluations at\nspecial points.\n", "machine_text": "This paper examines the almost product evaluation of Hankel determinants in order to find a product form evaluation for the intermediate case of ${3k+1 \\choose k}$. This Hankel determinant has not yet been evaluated due to its lack of product form evaluations. The method used in this paper offers a sum of a small number of products, referred to as an almost product, and thus provides an evaluation. Furthermore, the method demonstrates the salient points for the evaluation of other Hankel determinants with polynomial entries, as well as product and almost product form evaluations at special points.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3398}
{"prompt": "Rephrase the abstract of an article with title 'Deformed Wigner crystal in a one-dimensional quantum dot'.\n  The spatial Fourier spectrum of the electron density distribution in a finite\n1D system and the distribution function of electrons over single-particle\nstates are studied in detail to show that there are two universal features in\ntheir behavior, which characterize the electron ordering and the deformation of\nWigner crystal by boundaries. The distribution function has a $\\delta$-like\nsingularity at the Fermi momentum $k_F$. The Fourier spectrum of the density\nhas a step-like form at the wavevector $2k_F$, with the harmonics being absent\nor vanishing above this threshold. These features are found by calculations\nusing exact diagonalization method. They are shown to be caused by Wigner\nordering of electrons, affected by the boundaries. However the common Luttinger\nliquid model with open boundaries fails to capture these features, because it\noverestimates the deformation of the Wigner crystal. An improvement of the\nLuttinger liquid model is proposed which allows one to describe the above\nfeatures correctly. It is based on the corrected form of the density operator\nconserving the particle number.\n\n", "human_text": "  The spatial Fourier spectrum of the electron density distribution in a finite\n1D system and the distribution function of electrons over single-particle\nstates are studied in detail to show that there are two universal features in\ntheir behavior, which characterize the electron ordering and the deformation of\nWigner crystal by boundaries. The distribution function has a $\\delta$-like\nsingularity at the Fermi momentum $k_F$. The Fourier spectrum of the density\nhas a step-like form at the wavevector $2k_F$, with the harmonics being absent\nor vanishing above this threshold. These features are found by calculations\nusing exact diagonalization method. They are shown to be caused by Wigner\nordering of electrons, affected by the boundaries. However the common Luttinger\nliquid model with open boundaries fails to capture these features, because it\noverestimates the deformation of the Wigner crystal. An improvement of the\nLuttinger liquid model is proposed which allows one to describe the above\nfeatures correctly. It is based on the corrected form of the density operator\nconserving the particle number.\n", "machine_text": "A study of the electron ordering and deformation of the Wigner crystal in a one-dimensional quantum dot is presented. By examining the spatial Fourier spectrum of the electron density distribution and the distribution function of electrons across single-particle states, two distinct features of the system are determined. These include a $\\delta$-like singularity at the Fermi momentum $k_F$ in the distribution function and a step-like form at the wavevector $2k_F$, with final harmonics being completely absent or vanishing. These features are established via calculations generated from a exact diagonalization method. It is emphasized that their presence arises from the Wigner ordering of electrons, which is influenced by the boundaries. A modification of the Luttinger liquid model that incorporates a corrected version of the density operator preserving particle number is proposed. This refinement enables one to accurately account for the two dynamic characteristics associated with the system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1445}
{"prompt": "Rephrase the abstract of an article with title 'TrES-3: A Nearby, Massive, Transiting Hot Jupiter in a 31-Hour Orbit'.\n  We describe the discovery of a massive transiting hot Jupiter with a very\nshort orbital period (1.30619 d), which we name TrES-3. From spectroscopy of\nthe host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +-\n0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We\nestimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal\nvariation of our high-precision radial velocity measurements. This variation\nhas a period and phase consistent with our transit photometry. Our spectra show\nno evidence of line bisector variations that would indicate a blended eclipsing\nbinary star. From detailed modeling of our B and z photometry of the 2.5%-deep\ntransits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary\nradius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of\nthe known transiting exoplanets, facilitating studies of orbital decay and mass\nloss due to evaporation, and making it an excellent target for future studies\nof infrared emission and reflected starlight.\n\n", "human_text": "  We describe the discovery of a massive transiting hot Jupiter with a very\nshort orbital period (1.30619 d), which we name TrES-3. From spectroscopy of\nthe host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +-\n0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We\nestimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal\nvariation of our high-precision radial velocity measurements. This variation\nhas a period and phase consistent with our transit photometry. Our spectra show\nno evidence of line bisector variations that would indicate a blended eclipsing\nbinary star. From detailed modeling of our B and z photometry of the 2.5%-deep\ntransits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary\nradius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of\nthe known transiting exoplanets, facilitating studies of orbital decay and mass\nloss due to evaporation, and making it an excellent target for future studies\nof infrared emission and reflected starlight.\n", "machine_text": "\nThis paper presents the discovery of TrES-3, a close, massive hot Jupiter with an orbit that completes one rotation every 31 hours. We have conducted spectroscopy of the star GSC 03089-00929 to determine its properties, including an effective temperature of 5720 +/- 150 K, a stellar logg of 4.6 +/- 0.3 and a rotational velocity of less than 2 km/s. Our radial velocity measurements indicate a planetary mass of 1.92 +/- 0.23 Jupiter masses. Our photometric analysis of the 2.5%-deep transits reveals a stellar radius of 0.802 +/- 0.046 solar radii and a planetary radius of 1.295 +/- 0.081 Jupiter radii. The short orbital period of the planet presents new opportunities for investigating orbital decay and evaporation, as well as infrared emission and reflected starlight.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2004}
{"prompt": "Rephrase the abstract of an article with title 'Fractal dimension of domain walls in two-dimensional Ising spin glasses'.\n  We study domain walls in 2d Ising spin glasses in terms of a minimum-weight\npath problem. Using this approach, large systems can be treated exactly. Our\nfocus is on the fractal dimension $d_f$ of domain walls, which describes via\n$<\\ell >\\simL^{d_f}$ the growth of the average domain-wall length with %%\nsystems size $L\\times L$. %% 20.07.07 OM %% Exploring systems up to L=320 we\nyield $d_f=1.274(2)$ for the case of Gaussian disorder, i.e. a much higher\naccuracy compared to previous studies. For the case of bimodal disorder, where\nmany equivalent domain walls exist due to the degeneracy of this model, we\nobtain a true lower bound $d_f=1.095(2)$ and a (lower) estimate $d_f=1.395(3)$\nas upper bound. Furthermore, we study the distributions of the domain-wall\nlengths. Their scaling with system size can be described also only by the\nexponent $d_f$, i.e. the distributions are monofractal. Finally, we investigate\nthe growth of the domain-wall width with system size (``roughness'') and find a\nlinear behavior.\n\n", "human_text": "  We study domain walls in 2d Ising spin glasses in terms of a minimum-weight\npath problem. Using this approach, large systems can be treated exactly. Our\nfocus is on the fractal dimension $d_f$ of domain walls, which describes via\n$<\\ell >\\simL^{d_f}$ the growth of the average domain-wall length with %%\nsystems size $L\\times L$. %% 20.07.07 OM %% Exploring systems up to L=320 we\nyield $d_f=1.274(2)$ for the case of Gaussian disorder, i.e. a much higher\naccuracy compared to previous studies. For the case of bimodal disorder, where\nmany equivalent domain walls exist due to the degeneracy of this model, we\nobtain a true lower bound $d_f=1.095(2)$ and a (lower) estimate $d_f=1.395(3)$\nas upper bound. Furthermore, we study the distributions of the domain-wall\nlengths. Their scaling with system size can be described also only by the\nexponent $d_f$, i.e. the distributions are monofractal. Finally, we investigate\nthe growth of the domain-wall width with system size (``roughness'') and find a\nlinear behavior.\n", "machine_text": "\nWe investigate the properties of domain walls in two-dimensional Ising spin glasses by implementing minimum-weight path approaches to analyse systems of up to 320 sizes. The fractal dimension of these domain walls is reported as $d_f=1.274(2)$ for the cases of Gaussian disorder and $d_f=1.095(2)$ for the bimodal disorder. Moreover, the distribution of domain-wall lengths show scaling with system size and can be explained by the same fractal exponent $d_f$, pointing to a monofractal nature. Furthermore, the growth of the domain-wall width with the system size is linear.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2004}
{"prompt": "Rephrase the abstract of an article with title 'Link concordance, homology cobordism, and Hirzebruch-type defects from\n  iterated p-covers'.\n  We obtain new invariants of topological link concordance and homology\ncobordism of 3-manifolds from Hirzebruch-type intersection form defects of\ntowers of iterated p-covers. Our invariants can extract geometric information\nfrom an arbitrary depth of the derived series of the fundamental group, and can\ndetect torsion which is invisible via signature invariants. Applications\nillustrating these features include the following: (1) There are infinitely\nmany homology equivalent rational 3-spheres which are indistinguishable via\nmultisignatures, eta-invariants, and L2-signatures but have distinct homology\ncobordism types. (2) There is an infinite family of 2-torsion (amphichiral)\nknots, including the figure eight knot, with non-slice iterated Bing doubles;\nas a special case, we give the first proof of the conjecture that the Bing\ndouble of the figure eight knot is not slice. (3) There exist infinitely many\ntorsion elements at any depth of the Cochran-Orr-Teichner filtration of link\nconcordance.\n\n", "human_text": "  We obtain new invariants of topological link concordance and homology\ncobordism of 3-manifolds from Hirzebruch-type intersection form defects of\ntowers of iterated p-covers. Our invariants can extract geometric information\nfrom an arbitrary depth of the derived series of the fundamental group, and can\ndetect torsion which is invisible via signature invariants. Applications\nillustrating these features include the following: (1) There are infinitely\nmany homology equivalent rational 3-spheres which are indistinguishable via\nmultisignatures, eta-invariants, and L2-signatures but have distinct homology\ncobordism types. (2) There is an infinite family of 2-torsion (amphichiral)\nknots, including the figure eight knot, with non-slice iterated Bing doubles;\nas a special case, we give the first proof of the conjecture that the Bing\ndouble of the figure eight knot is not slice. (3) There exist infinitely many\ntorsion elements at any depth of the Cochran-Orr-Teichner filtration of link\nconcordance.\n", "machine_text": "This article examines new methods for determining the link concordance, homology cobordism, and Hirzebruch-type intersection form defects of towers of iterated p-covers. We illustrate our methods to show that there is a vast range of results, including detection of infinitely many homology equivalent rational 3-spheres which are indistinguishable through multisignatures, eta-invariants, and L2-signatures, and the proof of the conjecture that the Bing double of the figure eight knot is not slice. In addition, our invariants are able to detect torsion which is not visible through signature invariants, illustrating the presence of infinitely many torsion elements at any depth of the Cochran-Orr-Teichner filtration of link concordance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0088}
{"prompt": "Rephrase the abstract of an article with title 'Spin 1/2 Fermions in the Unitary Limit.I'.\n  This report concerns the energy of a zero-temperature many-body system of\nspin 1/2 fermions interacting via a two-body potential with a free space\ninfinite scattering length and zero effective range; the Unitary limit. Given\nthe corresponding phase-shift $\\delta(k)=\\pi/2$ a one-term separable potential\nis obtained by inverse scattering assuming a momentum cut-off $\\Lambda$ such\nthat $\\delta(k)=0$ for $k>\\Lambda$. The \\it effective \\rm interaction in the\nmany-body system is calculated in a pp-ladder approximation with Pauli-blocking\nbut neglecting mean-field (dispersion) corrections; effective mass $m^{*}=1$.\nUsing only the zero relative momentum component of this interaction the total\nenergy is $\\xi=4/9$ (in units of the fermigas), a result reported by several\nprevious authors. Integrating the momentum dependent interaction over the Fermi\nsea this energy is revised to $\\xi=0.24.$ This result is independent of density\nand of the cut-off $\\Lambda$ if $\\Lambda > \\sim 3k_{f}$.\n  With $m^{*}\\neq 1$ there is however a strong dependence on this cut-off.\n  Including hh-ladders estimates give $\\xi=0.4\\leftrightarrow 0.6$, but a\nreliable result would in this case require a Green's function calculation.\n\n", "human_text": "  This report concerns the energy of a zero-temperature many-body system of\nspin 1/2 fermions interacting via a two-body potential with a free space\ninfinite scattering length and zero effective range; the Unitary limit. Given\nthe corresponding phase-shift $\\delta(k)=\\pi/2$ a one-term separable potential\nis obtained by inverse scattering assuming a momentum cut-off $\\Lambda$ such\nthat $\\delta(k)=0$ for $k>\\Lambda$. The \\it effective \\rm interaction in the\nmany-body system is calculated in a pp-ladder approximation with Pauli-blocking\nbut neglecting mean-field (dispersion) corrections; effective mass $m^{*}=1$.\nUsing only the zero relative momentum component of this interaction the total\nenergy is $\\xi=4/9$ (in units of the fermigas), a result reported by several\nprevious authors. Integrating the momentum dependent interaction over the Fermi\nsea this energy is revised to $\\xi=0.24.$ This result is independent of density\nand of the cut-off $\\Lambda$ if $\\Lambda > \\sim 3k_{f}$.\n  With $m^{*}\\neq 1$ there is however a strong dependence on this cut-off.\n  Including hh-ladders estimates give $\\xi=0.4\\leftrightarrow 0.6$, but a\nreliable result would in this case require a Green's function calculation.\n", "machine_text": "  This article reviews the energy levels of spin-1/2 fermions when interacting through a two-body potential with an infinite scattering length and zero effective range, otherwise known as the Unitary limit. Using a single term separable potential with a momentum cut-off of $\\Lambda$, the many-body system is calculated with Pauli blocking, neglecting any mean-field corrections or changes in mass. The energy is reported as $\\xi = 4/9$, a result independently offered by previous work, but revised to $\\xi = 0.24$ when integrating the momentum dependent interaction with the Fermi sea. Additionally, consideration of hh-ladders provide suggested energy estimates of $\\xi = 0.4$ to 0.6, though a Green's function calculation would be required for a successful and reliable outcome.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0944}
{"prompt": "Rephrase the abstract of an article with title 'Casimir effect in a 6D warped flux compactification model'.\n  We discuss Casimir effect of a massless, minimally coupled scalar field in a\n6D warped flux compactification model and its implications for the hierarchy\nand cosmological constant problems, which are longstanding puzzles in\nphenomenology and cosmology. Due to the scale invariance of the background\ntheory, the 4D effective theory contains a volume modulus. To stabilize the\nmodulus, we consider one-loop corrections to the effective potential by the\nCasimir effect. The one-loop effective potential for the volume modulus has a\nform which is very similar to Coleman-Weinberg potential. We evaluate\ncoefficients appearing in the effective potential by employing zeta function\nregularization and heat kernel analysis. The volume modulus is stabilized for\nsmaller degrees of warping, below a critical value, which depends on deficit\nangle of the reference brane. After stabilizing the modulus, it is possible to\nobtain observed values of the mass ratio between the fundamental energy scales\nand a tiny effective cosmological constant (though its sign is negative). The\ndegree of warping should be tuned to be close to the critical value, not as\nseverely as the original fine-tuning.\n\n", "human_text": "  We discuss Casimir effect of a massless, minimally coupled scalar field in a\n6D warped flux compactification model and its implications for the hierarchy\nand cosmological constant problems, which are longstanding puzzles in\nphenomenology and cosmology. Due to the scale invariance of the background\ntheory, the 4D effective theory contains a volume modulus. To stabilize the\nmodulus, we consider one-loop corrections to the effective potential by the\nCasimir effect. The one-loop effective potential for the volume modulus has a\nform which is very similar to Coleman-Weinberg potential. We evaluate\ncoefficients appearing in the effective potential by employing zeta function\nregularization and heat kernel analysis. The volume modulus is stabilized for\nsmaller degrees of warping, below a critical value, which depends on deficit\nangle of the reference brane. After stabilizing the modulus, it is possible to\nobtain observed values of the mass ratio between the fundamental energy scales\nand a tiny effective cosmological constant (though its sign is negative). The\ndegree of warping should be tuned to be close to the critical value, not as\nseverely as the original fine-tuning.\n", "machine_text": "\nThis paper examines the Casimir effect for a 6D warped flux compactification model and its possible resolution to some long-standing problems. Specifically, the massless and minimally coupled scalar field is conceptually consistent with a 4D effective theory, which has a volume modulus that must be stabilised. We use a combination of zeta function regularisation and heat-kernel calculations to evaluate the one-loop effective potential of the modulus and find that it is analogous to Coleman-Weinberg potential. When the tuning of the degree of warping is close to the critical value, we can observe the desired mass ratio between two basic energies and a small, but negative, effective cosmological constant. This situation is a much less stringent fine-tuning than earlier models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3623}
{"prompt": "Rephrase the abstract of an article with title 'High Sensitivity Array Observations of the $z = 4.4$ QSO BRI 1335-0417'.\n  We present sensitive phase-referenced VLBI results on the radio continuum\nemission from the $z=4.4$ QSO BRI 1335--0417. The observations were carried out\nat 1.4 GHz using the High Sensitivity Array (HSA). Our sensitive VLBI image at\n$189 \\times 113$ mas ($1.25 \\times 0.75$ kpc) resolution shows continuum\nemission in BRI 1335--0417 with a total flux density of $208 \\pm 46 \\mu$Jy,\nconsistent with the flux density measured with the VLA. The size of the source\nat FWHM is $255 \\times 138$ mas ($1.7 \\times 0.9$ kpc) and the derived\nintrinsic brightness temperature is $\\sim 3.5\\times 10^4$ K. No continuum\nemission is detected at the full VLBI resolution ($32 \\times 7$ mas, $211\n\\times 46$ pc), with a 4$\\sigma$ point source upper limit of 34 $\\mu$Jy\nbeam$^{-1}$, or an upper limit to the intrinsic brightness temperature of\n$5.6\\times 10^5$ K. The highest angular resolution with at least a 4.5$\\sigma$\ndetection of the radio continuum emission is $53 \\times 27$ mas ($0.35 \\times\n0.18$ kpc). At this resolution, the image shows a continuum feature in BRI\n1335--0417 with a size of $64 \\times 35$ mas ($0.42 \\times 0.23$ kpc) at FWHM,\nand intrinsic brightness temperature of $\\sim 2\\times 10^5$ K. The extent of\nthe observed continuum sources at 1.4 GHz and the derived brightness\ntemperatures show that the radio emission (and thus presumably the far-infrared\nemission) in BRI 1335--0417 is powered by a major starburst, with a massive\nstar formation rate of order a few thousand M_{\\odot} {\\rm yr}^{-1}$. Moreover,\nthe absence of any compact high-brightness temperature source suggests that\nthere is no radio-loud AGN in this $z=4.4$ QSO.\n\n", "human_text": "  We present sensitive phase-referenced VLBI results on the radio continuum\nemission from the $z=4.4$ QSO BRI 1335--0417. The observations were carried out\nat 1.4 GHz using the High Sensitivity Array (HSA). Our sensitive VLBI image at\n$189 \\times 113$ mas ($1.25 \\times 0.75$ kpc) resolution shows continuum\nemission in BRI 1335--0417 with a total flux density of $208 \\pm 46 \\mu$Jy,\nconsistent with the flux density measured with the VLA. The size of the source\nat FWHM is $255 \\times 138$ mas ($1.7 \\times 0.9$ kpc) and the derived\nintrinsic brightness temperature is $\\sim 3.5\\times 10^4$ K. No continuum\nemission is detected at the full VLBI resolution ($32 \\times 7$ mas, $211\n\\times 46$ pc), with a 4$\\sigma$ point source upper limit of 34 $\\mu$Jy\nbeam$^{-1}$, or an upper limit to the intrinsic brightness temperature of\n$5.6\\times 10^5$ K. The highest angular resolution with at least a 4.5$\\sigma$\ndetection of the radio continuum emission is $53 \\times 27$ mas ($0.35 \\times\n0.18$ kpc). At this resolution, the image shows a continuum feature in BRI\n1335--0417 with a size of $64 \\times 35$ mas ($0.42 \\times 0.23$ kpc) at FWHM,\nand intrinsic brightness temperature of $\\sim 2\\times 10^5$ K. The extent of\nthe observed continuum sources at 1.4 GHz and the derived brightness\ntemperatures show that the radio emission (and thus presumably the far-infrared\nemission) in BRI 1335--0417 is powered by a major starburst, with a massive\nstar formation rate of order a few thousand M_{\\odot} {\\rm yr}^{-1}$. Moreover,\nthe absence of any compact high-brightness temperature source suggests that\nthere is no radio-loud AGN in this $z=4.4$ QSO.\n", "machine_text": "\nUsing the High Sensitivity Array (HSA) at 1.4 GHz, we conducted highly-sensitive phase-referenced VLBI observations of the $z = 4.4$ QSO BRI 1335-0417. Our results revealed a total recorded flux density of $208 \\pm 46 \\mu$Jy and source size at the FWHM measure of $255 \\times 138$ mas ($1.7 \\times 0.9$ kpc). Through the image at the highest angular resolution, the detected continuum source's size was measured to be $64 \\times 35$ mas ($0.42 \\times 0.23$ kpc) with an intrinsic brightness temperature of $\\sim 2\\times 10^5$ K. As the radio emission was found to have no high-brightness temperature source, it is believed that this $z=4.4$ QSO has no radio-loud AGN and is instead being powered by a starburst with a star formation rate of a few thousand M_{\\odot} yr$^{-1}$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0899}
{"prompt": "Rephrase the abstract of an article with title 'Orbital magnetization and its effects in spin-chiral ferromagnetic\n  Kagome lattice'.\n  Recently, Berry phase in the semiclassical dynamical of Bloch electrons has\nbeen found to make a correction to the phase-space density of states and a\ngeneral multi-band formula for finite-temperature orbital magnetization has\nbeen given [Phys. Rev. Lett. \\textbf{97}, 026603 (2006)], where the orbital\nmagnetization $\\mathcal{M}$ consists of two parts, i.e., the conventional part\n$M_{c}$ and the Berry-phase correction part $M_{\\Omega}$. Using this general\nformula, we theoretically investigate the orbital magnetization and its effects\non thermoelectric transport and magnetic susceptibility properties of the\ntwo-dimensional \\textit{kagom\\'{e}} lattice with spin anisotropies included.\nThe study in this paper is highly interesting by the occurrence of nonzero\nChern number in the lattice. The spin chirality parameter $\\phi$ (see text)\nresults in profound effects on the orbital magnetization properties. It is\nfound that the two parts in orbital magnetization opposite each other. In\nparticular, we show that $M_{c}$ and $M_{\\Omega}$ yield the paramagnetic and\ndiamagnetic responses, respectively. It is further shown that the orbital\nmagnetization displays fully different behavior in the metallic and insulating\nregions, which is due to the different roles $M_{c}$ and $M_{\\Omega}$ play in\nthese two regions. The anomalous Nernst conductivity is also calculated, which\ndisplays a peak-valley structure as a function of the electron Fermi energy.\n\n", "human_text": "  Recently, Berry phase in the semiclassical dynamical of Bloch electrons has\nbeen found to make a correction to the phase-space density of states and a\ngeneral multi-band formula for finite-temperature orbital magnetization has\nbeen given [Phys. Rev. Lett. \\textbf{97}, 026603 (2006)], where the orbital\nmagnetization $\\mathcal{M}$ consists of two parts, i.e., the conventional part\n$M_{c}$ and the Berry-phase correction part $M_{\\Omega}$. Using this general\nformula, we theoretically investigate the orbital magnetization and its effects\non thermoelectric transport and magnetic susceptibility properties of the\ntwo-dimensional \\textit{kagom\\'{e}} lattice with spin anisotropies included.\nThe study in this paper is highly interesting by the occurrence of nonzero\nChern number in the lattice. The spin chirality parameter $\\phi$ (see text)\nresults in profound effects on the orbital magnetization properties. It is\nfound that the two parts in orbital magnetization opposite each other. In\nparticular, we show that $M_{c}$ and $M_{\\Omega}$ yield the paramagnetic and\ndiamagnetic responses, respectively. It is further shown that the orbital\nmagnetization displays fully different behavior in the metallic and insulating\nregions, which is due to the different roles $M_{c}$ and $M_{\\Omega}$ play in\nthese two regions. The anomalous Nernst conductivity is also calculated, which\ndisplays a peak-valley structure as a function of the electron Fermi energy.\n", "machine_text": "\nThis paper examines the orbital magnetization and its consequences on the thermoelectric transport and magnetization features of a two-dimensional Kagome lattice with spin anisotropy present. In addition to a conventional term, the orbital magnetization consists of a correction made by a Berry phase in the Bloch electrons' semi-classical dynamics. We demonstrate that there is an opposition in behavior between the two orbital magnetization pieces; $M_{c}$ and $M_{\\Omega}$ displaying a paramagnetic and diamagnetic response respectively. We also show that change in the spin chirality parameter $\\phi$ has a profound effect on the orbital magnetization property, further demonstrating the peculiarity of its behavior depending on whether the system is in a metallic or insulating region. Finally, the anomalous Nernst conductivity is computed and gives distinct peak-valley structure when the electron Fermi energy is changed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3305}
{"prompt": "Rephrase the abstract of an article with title 'Stability of the superconducting state in YBa_2Cu_3O_7'.\n  The nonadiabatic Heisenberg model (NHM) proposed as an extension of the\nHeisenberg model makes a contribution to the eigenstate problem of\nsuperconductivity. The Hamiltonian H^n derived within this group-theoretical\nmodel has superconducting eigenstates if and only if the considered material\npossesses a narrow, roughly half-filled \"superconducting\" energy band of\nspecial symmetry in its band structure. This paper shows that the\nhigh-temperature superconductor YBa_2Cu_3O_7 possesses such a superconducting\nband. This new result together with previous observations about other\nsuperconductors and non-superconductors corroborates the theoretical evidence\nwithin the NHM that stable superconducting states are connected with\nsuperconducting bands. It is proposed that the type of superconductivity, i.e.,\nwhether the material is a conventional low-T_c or a high-T_c superconductor, is\ndetermined by the energetically lowest boson excitations that carry the crystal\nspin 1*hbar and are sufficiently stable to transport this crystal spin-angular\nmomentum through the crystal. This mechanism provides the electron-phonon\nmechanism that enters the BCS theory in conventional superconductors.\n\n", "human_text": "  The nonadiabatic Heisenberg model (NHM) proposed as an extension of the\nHeisenberg model makes a contribution to the eigenstate problem of\nsuperconductivity. The Hamiltonian H^n derived within this group-theoretical\nmodel has superconducting eigenstates if and only if the considered material\npossesses a narrow, roughly half-filled \"superconducting\" energy band of\nspecial symmetry in its band structure. This paper shows that the\nhigh-temperature superconductor YBa_2Cu_3O_7 possesses such a superconducting\nband. This new result together with previous observations about other\nsuperconductors and non-superconductors corroborates the theoretical evidence\nwithin the NHM that stable superconducting states are connected with\nsuperconducting bands. It is proposed that the type of superconductivity, i.e.,\nwhether the material is a conventional low-T_c or a high-T_c superconductor, is\ndetermined by the energetically lowest boson excitations that carry the crystal\nspin 1*hbar and are sufficiently stable to transport this crystal spin-angular\nmomentum through the crystal. This mechanism provides the electron-phonon\nmechanism that enters the BCS theory in conventional superconductors.\n", "machine_text": "This paper examines the stability of the superconducting state in YBa_2Cu_3O_7. It is shown that the material possesses a narrow, roughly half-filled energy band of special symmetry. Through the nonadiabatic Heisenberg model and its ensuing Hamiltonian, this band is identified with the eigenstate problem of superconductivity. This discovery establishes that the symmetrical nature of the energy band is a prerequisite for stable superconducting states. The proposed mechanism for superconductivity suggests that the type of superconductivity, as well as its critical temperature, is determined by the energetically lowest excitations that transport crystal spin-angular momentum. This provides a framework for the electron-phonon mechanism central to the BCS theory of conventional superconductors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.211}
{"prompt": "Rephrase the abstract of an article with title 'Fifteen Years of High-Resolution Radio Imaging of Supernova 1987A'.\n  Supernova 1987A in the Large Magellanic Cloud provides a spectacularly\ndetailed view of the aftermath of a core-collapse explosion. The supernova\nejecta initially coasted outward at more than 10% of the speed of light, but in\n1990 were observed to decelerate rapidly as they began to encounter dense\ncircumstellar material expelled by the progenitor star. The resulting shock has\nsubsequently produced steadily brightening radio synchrotron emission, which is\nresolved by the Australia Telescope Compact Array (ATCA) into an expanding\nlimb-brightened shell. Here we present 15 years of ATCA imaging of Supernova\n1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio\nremnant has accelerated in its expansion over this period, from approx 3600\nkm/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of\nthe evolving X-ray shell have been ~15% smaller than the corresponding radio\nvalues, but a simultaneous Fourier analysis of both radio and X-ray data\neliminates this discrepancy, and yields a current diameter for the shell in\nboth wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is\nseen in radio images at all ATCA epochs: the eastern and western rims have\nhigher fluxes than the northern and southern regions, indicating that most of\nthe radio emission comes from the equatorial plane of the system, where the\nprogenitor star's circumstellar wind is thought to be densest. The eastern lobe\nis brighter than and further from the supernova site than the western lobe,\nsuggesting an additional asymmetry in the initial distribution of supernova\nejecta.\n\n", "human_text": "  Supernova 1987A in the Large Magellanic Cloud provides a spectacularly\ndetailed view of the aftermath of a core-collapse explosion. The supernova\nejecta initially coasted outward at more than 10% of the speed of light, but in\n1990 were observed to decelerate rapidly as they began to encounter dense\ncircumstellar material expelled by the progenitor star. The resulting shock has\nsubsequently produced steadily brightening radio synchrotron emission, which is\nresolved by the Australia Telescope Compact Array (ATCA) into an expanding\nlimb-brightened shell. Here we present 15 years of ATCA imaging of Supernova\n1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio\nremnant has accelerated in its expansion over this period, from approx 3600\nkm/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of\nthe evolving X-ray shell have been ~15% smaller than the corresponding radio\nvalues, but a simultaneous Fourier analysis of both radio and X-ray data\neliminates this discrepancy, and yields a current diameter for the shell in\nboth wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is\nseen in radio images at all ATCA epochs: the eastern and western rims have\nhigher fluxes than the northern and southern regions, indicating that most of\nthe radio emission comes from the equatorial plane of the system, where the\nprogenitor star's circumstellar wind is thought to be densest. The eastern lobe\nis brighter than and further from the supernova site than the western lobe,\nsuggesting an additional asymmetry in the initial distribution of supernova\nejecta.\n", "machine_text": "\nFor the past 15 years, the Australia Telescope Compact Array has observed the aftermath of Supernova 1987A located in the Large Magellanic Cloud, by making high-resolution radio imaging of this spectacular core-collapse explosion. The initial expansion of the ejecta was exceptionally high and fast, but in 1990 the deceleration began due to dense circumstellar material expelled from the progenitor star, resulting in brightening radio synchrotron emission, discernable by the ATCA. We discuss that the remnant has been accelerating in its expansion, from about 3600 km/s in 1992 to about 5200 km/s by the end of 2006, the X-ray shell printed 15% smaller than the corresponding radio values, but a Fourier analysis of both reveals a diameter of 1.7 arcsec. An asymmetric brightness distribution occurred in the images at all ATCA epochs, where the eastern rim is brighter and further from the supernova site than the western lobe, indicating an uneven initial distribution of the supernova ejecta.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0057}
{"prompt": "Rephrase the abstract of an article with title 'A multi band study of the optically dark GRB 051028'.\n  Observations were made of the optical afterglow of GRB 051028 with the Lulin\nobservatory's 1.0 m telescope and the WIDGET robotic telescope system. R band\nphotometric data points were obtained on 2005 October 28 (UT), or 0.095-0.180\ndays after the burst. There is a possible plateau in the optical light curve\naround 0.1 days after the burst; the light curve resembles optically bright\nafterglows (e.g. GRB 041006, GRB 050319, GRB060605) in shape of the light curve\nbut not in brightness. The brightness of the GRB 051028 afterglow is 3\nmagnitudes fainter than that of one of the dark events, GRB 020124. Optically\ndark GRBs have been attributed to dust extinction within the host galaxy or\nhigh redshift. However, the spectrum analysis of the X-rays implies that there\nis no significant absorption by the host galaxy. Furthermore, according to the\nmodel theoretical calculation of the Ly$\\alpha$ absorption to find the limit of\nGRB 051028's redshift, the expected $R$ band absorption is not high enough to\nexplain the darkness of the afterglow. While the present results disfavor\neither the high-redshift hypothesis or the high extinction scenario for\noptically dark bursts, they are consistent with the possibility that the\nbrightness of the optical afterglow, intrinsically dark.\n\n", "human_text": "  Observations were made of the optical afterglow of GRB 051028 with the Lulin\nobservatory's 1.0 m telescope and the WIDGET robotic telescope system. R band\nphotometric data points were obtained on 2005 October 28 (UT), or 0.095-0.180\ndays after the burst. There is a possible plateau in the optical light curve\naround 0.1 days after the burst; the light curve resembles optically bright\nafterglows (e.g. GRB 041006, GRB 050319, GRB060605) in shape of the light curve\nbut not in brightness. The brightness of the GRB 051028 afterglow is 3\nmagnitudes fainter than that of one of the dark events, GRB 020124. Optically\ndark GRBs have been attributed to dust extinction within the host galaxy or\nhigh redshift. However, the spectrum analysis of the X-rays implies that there\nis no significant absorption by the host galaxy. Furthermore, according to the\nmodel theoretical calculation of the Ly$\\alpha$ absorption to find the limit of\nGRB 051028's redshift, the expected $R$ band absorption is not high enough to\nexplain the darkness of the afterglow. While the present results disfavor\neither the high-redshift hypothesis or the high extinction scenario for\noptically dark bursts, they are consistent with the possibility that the\nbrightness of the optical afterglow, intrinsically dark.\n", "machine_text": "This article presents a multi-band analysis of GRB 051028's optically dark afterglow, utilizing the Lulin observatory's 1.0m telescope and the WIDGET robotic telescope system. Upon measuring R-band photometric data points on zero-point-nine-five and one-point-eight days after the burst, a plateau in the optical light curve was identified. While its shape was reminiscent of optically bright afterglows, the magnitude was three magnitudes fainter than that of GRB 020124. Examining the spectrum analysis of X-rays, no significant host-galaxy absorption was inferred. Further computational modelling of the Ly$\\alpha$ absorption could not confirm a high redshift. These results dispelled both the high-redshift and the high-extinction hypotheses on the optically dark burst, leading to the conclusion that the afterglow was, intrinsically, dim.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0561}
{"prompt": "Rephrase the abstract of an article with title 'Spectrum of cosmic rays, produced in supernova remnants'.\n  Nonlinear kinetic theory of cosmic ray (CR) acceleration in supernova\nremnants is employed to calculate CR spectra. The magnetic field in SNRs is\nassumed to be significantly amplified by the efficiently accelerating nuclear\nCR component. It is shown that the calculated CR spectra agree in a\nsatisfactory way with the existing measurements up to the energy $10^{17}$ eV.\nThe power law spectrum of protons extends up to the energy $3\\times 10^{15}$ eV\nwith a subsequent exponential cutoff. It gives a natural explanation for the\nobserved knee in the Galactic CR spectrum. The maximum energy of the\naccelerated nuclei is proportional to their charge number $Z$. Therefore the\nbreak in the Galactic CR spectrum is the result of the contribution of\nprogressively heavier species in the overall CR spectrum so that at $10^{17}$\neV the CR spectrum is dominated by iron group nuclei. It is shown that this\ncomponent plus a suitably chosen extragalactic CR component can give a\nconsistent description for the entire Galactic CR spectrum.\n\n", "human_text": "  Nonlinear kinetic theory of cosmic ray (CR) acceleration in supernova\nremnants is employed to calculate CR spectra. The magnetic field in SNRs is\nassumed to be significantly amplified by the efficiently accelerating nuclear\nCR component. It is shown that the calculated CR spectra agree in a\nsatisfactory way with the existing measurements up to the energy $10^{17}$ eV.\nThe power law spectrum of protons extends up to the energy $3\\times 10^{15}$ eV\nwith a subsequent exponential cutoff. It gives a natural explanation for the\nobserved knee in the Galactic CR spectrum. The maximum energy of the\naccelerated nuclei is proportional to their charge number $Z$. Therefore the\nbreak in the Galactic CR spectrum is the result of the contribution of\nprogressively heavier species in the overall CR spectrum so that at $10^{17}$\neV the CR spectrum is dominated by iron group nuclei. It is shown that this\ncomponent plus a suitably chosen extragalactic CR component can give a\nconsistent description for the entire Galactic CR spectrum.\n", "machine_text": "\nAn analysis of nonlinear kinetic theory and observations of cosmic rays (CRs) reveals the behavior of CRs produced by supernova remnants. The magnetic field in the supernova remnants is believed to be amplified by the accelerated nuclear CR component, allowing for calculations that result in CR spectra that are consistent with existing energy measurements of up to $10^{17}$ eV. The observational components consist of a power law spectrum of protons extending up to $3\\times 10^{15}$ eV, providing gravitational evidence for the 'knee' in the Galactic CR spectrum. Additionally, the maximum energy of the accelerated nuclei is proportional to their charge number, exhibiting a break in the Galactic CR spectrum from the contribution of more massive species. Combining these components with an appropriate extragalactic CR component can enable a comprehensive description of the overall Galactic CR spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1715}
{"prompt": "Rephrase the abstract of an article with title 'Orbital liquid in ferromagnetic manganites: The orbital Hubbard model\n  for $e_g$ electrons'.\n  We have analyzed the symmetry properties and the ground state of an orbital\nHubbard model with two orbital flavors, describing a partly filled\nspin-polarized $e_g$ band on a cubic lattice, as in ferromagnetic manganites.\nWe demonstrate that the off-diagonal hopping responsible for transitions\nbetween $x^2-y^2$ and $3z^2-r^2$ orbitals, and the absence of SU(2) invariance\nin orbital space, have important implications. One finds that superexchange\ncontributes in all orbital ordered states, the Nagaoka theorem does not apply,\nand the kinetic energy is much enhanced as compared with the spin case.\nTherefore, orbital ordered states are harder to stabilize in the Hartree-Fock\napproximation (HFA), and the onset of a uniform ferro-orbital polarization and\nantiferro-orbital instability are similar to each other, unlike in spin case.\nNext we formulate a cubic (gauge) invariant slave boson approach using the\norbitals with complex coefficients. In the mean-field approximation it leads to\nthe renormalization of the kinetic energy, and provides a reliable estimate for\nthe ground state energy of the disordered state. Using this approach one finds\nthat the HFA fails qualitatively in the regime of large Coulomb repulsion\n$U\\to\\infty$ -- the orbital order is unstable, and instead a strongly\ncorrelated orbital liquid with disordered orbitals is realized at any electron\nfilling.\n\n", "human_text": "  We have analyzed the symmetry properties and the ground state of an orbital\nHubbard model with two orbital flavors, describing a partly filled\nspin-polarized $e_g$ band on a cubic lattice, as in ferromagnetic manganites.\nWe demonstrate that the off-diagonal hopping responsible for transitions\nbetween $x^2-y^2$ and $3z^2-r^2$ orbitals, and the absence of SU(2) invariance\nin orbital space, have important implications. One finds that superexchange\ncontributes in all orbital ordered states, the Nagaoka theorem does not apply,\nand the kinetic energy is much enhanced as compared with the spin case.\nTherefore, orbital ordered states are harder to stabilize in the Hartree-Fock\napproximation (HFA), and the onset of a uniform ferro-orbital polarization and\nantiferro-orbital instability are similar to each other, unlike in spin case.\nNext we formulate a cubic (gauge) invariant slave boson approach using the\norbitals with complex coefficients. In the mean-field approximation it leads to\nthe renormalization of the kinetic energy, and provides a reliable estimate for\nthe ground state energy of the disordered state. Using this approach one finds\nthat the HFA fails qualitatively in the regime of large Coulomb repulsion\n$U\\to\\infty$ -- the orbital order is unstable, and instead a strongly\ncorrelated orbital liquid with disordered orbitals is realized at any electron\nfilling.\n", "machine_text": "\nAn investigation was conducted examining the symmetry properties and the ground state of an orbital Hubbard model consisting of two orbitals partly filled with spin-polarized electrons on a cubic lattice, similar to ferromagnetic manganites. Found that due to the off-diagonal hopping for transitions between $x^2-y^2$ and $3z^2-r^2$ orbitals and the lack of SU(2) invariance in orbital space, superexchange contributes to all orbital ordered states, the Nagaoka theorem does not apply, and the kinetic energy is enhanced in comparison to the spin case. This makes orbital ordered states harder to stabilize in the Hartree-Fock approximation and the onset of ferro-orbital and antiferro-orbital polarizations are alike, unlike in spin cases. Subsequently, a cubic-gauge invariant slave boson approach is formulated with orbitals containing complex coefficients in mean-field approximation which gives accurate estimates of the ground-state energy of disordered states. Results show that in the regime of high Coulomb repulsion the orbital order is unstable, leading instead to a highly correlated orbital liquid with random orbitals at any electron filling.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1766}
{"prompt": "Rephrase the abstract of an article with title 'Emergence of spatiotemporal chaos driven by far-field breakup of spiral\n  waves in the plankton ecological systems'.\n  Alexander B. Medvinsky \\emph{et al} [A. B. Medvinsky, I. A. Tikhonova, R. R.\nAliev, B.-L. Li, Z.-S. Lin, and H. Malchow, Phys. Rev. E \\textbf{64}, 021915\n(2001)] and Marcus R. Garvie \\emph{et al} [M. R. Garvie and C. Trenchea, SIAM\nJ. Control. Optim. \\textbf{46}, 775-791 (2007)] shown that the minimal\nspatially extended reaction-diffusion model of phytoplankton-zooplankton can\nexhibit both regular, chaotic behavior, and spatiotemporal patterns in a patchy\nenvironment. Based on that, the spatial plankton model is furtherly\ninvestigated by means of computer simulations and theoretical analysis in the\npresent paper when its parameters would be expected in the case of mixed\nTuring-Hopf bifurcation region. Our results show that the spiral waves exist in\nthat region and the spatiotemporal chaos emerge, which arise from the far-field\nbreakup of the spiral waves over large ranges of diffusion coefficients of\nphytoplankton and zooplankton. Moreover, the spatiotemporal chaos arising from\nthe far-field breakup of spiral waves does not gradually involve the whole\nspace within that region. Our results are confirmed by means of computation\nspectra and nonlinear bifurcation of wave trains. Finally, we give some\nexplanations about the spatially structured patterns from the community level.\n\n", "human_text": "  Alexander B. Medvinsky \\emph{et al} [A. B. Medvinsky, I. A. Tikhonova, R. R.\nAliev, B.-L. Li, Z.-S. Lin, and H. Malchow, Phys. Rev. E \\textbf{64}, 021915\n(2001)] and Marcus R. Garvie \\emph{et al} [M. R. Garvie and C. Trenchea, SIAM\nJ. Control. Optim. \\textbf{46}, 775-791 (2007)] shown that the minimal\nspatially extended reaction-diffusion model of phytoplankton-zooplankton can\nexhibit both regular, chaotic behavior, and spatiotemporal patterns in a patchy\nenvironment. Based on that, the spatial plankton model is furtherly\ninvestigated by means of computer simulations and theoretical analysis in the\npresent paper when its parameters would be expected in the case of mixed\nTuring-Hopf bifurcation region. Our results show that the spiral waves exist in\nthat region and the spatiotemporal chaos emerge, which arise from the far-field\nbreakup of the spiral waves over large ranges of diffusion coefficients of\nphytoplankton and zooplankton. Moreover, the spatiotemporal chaos arising from\nthe far-field breakup of spiral waves does not gradually involve the whole\nspace within that region. Our results are confirmed by means of computation\nspectra and nonlinear bifurcation of wave trains. Finally, we give some\nexplanations about the spatially structured patterns from the community level.\n", "machine_text": "This paper investigates the emergence of spatiotemporal chaos driven by far-field breakup of spiral waves in a reaction-diffusion plankton model. Through computer simulations and theoretical analysis, the authors show that this model can exhibit both regular and chaotic behavior, as well as spatiotemporal patterns, in the case of mixed Turing-Hopf bifurcation. The results suggest that spatiotemporal chaos arising from the far-field breakup of spiral waves does not involve the entire region, and confirm this notion by means of computation spectra and nonlinear bifurcation of wave trains. Finally, explanations for the spatially structured patterns from a community level are also given.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0322}
{"prompt": "Rephrase the abstract of an article with title 'Planetary embryos and planetesimals residing in thin debris disks'.\n  We consider constraints on the planetesimal population residing in the disks\nof AU Microscopii, Beta Pictoris and Fomalhaut taking into account their\nobserved thicknesses and normal disk opacities. We estimate that bodies of\nradius 5, 180 and 70 km are responsible for initiating the collisional cascade\naccounting for the dust production for AU-Mic, Beta-Pic and Fomalhaut's disks,\nrespectively, at break radii from the star where their surface brightness\nprofiles change slope. Larger bodies, of radius 1000km and with surface density\nof order 0.01 g/cm^2, are required to explain the thickness of these disks\nassuming that they are heated by gravitational stirring. A comparison between\nthe densities of the two sizes suggests the size distribution in the largest\nbodies is flatter than that observed in the Kuiper belt. AU Mic's disk requires\nthe shallowest size distribution for bodies with radius greater than 10km\nsuggesting that the disk contains planetary embryos experiencing a stage of\nrunaway growth.\n\n", "human_text": "  We consider constraints on the planetesimal population residing in the disks\nof AU Microscopii, Beta Pictoris and Fomalhaut taking into account their\nobserved thicknesses and normal disk opacities. We estimate that bodies of\nradius 5, 180 and 70 km are responsible for initiating the collisional cascade\naccounting for the dust production for AU-Mic, Beta-Pic and Fomalhaut's disks,\nrespectively, at break radii from the star where their surface brightness\nprofiles change slope. Larger bodies, of radius 1000km and with surface density\nof order 0.01 g/cm^2, are required to explain the thickness of these disks\nassuming that they are heated by gravitational stirring. A comparison between\nthe densities of the two sizes suggests the size distribution in the largest\nbodies is flatter than that observed in the Kuiper belt. AU Mic's disk requires\nthe shallowest size distribution for bodies with radius greater than 10km\nsuggesting that the disk contains planetary embryos experiencing a stage of\nrunaway growth.\n", "machine_text": "\nThe present study investigates the nature and characteristics of large planetary embryos and planetesimals present in thin debris disks found around three sources (AU Microscopii, Beta Pictoris and Fomalhaut). We analyse the opacity and thickness of the disks, the surface brightness profiles, and the requirements for the size of the largest bodies these disks contain. It is determined that the maximum radius of these particles appears to be 5, 180, and 70 km respectively for the three disks, and that bodies with radius of 1000km and with surface density of 0.01 g/cm^2 would be necessary to explain the thickness of the disks assuming that they are heated by gravitational stirring. Further comparison of the densities of the two sizes implicates that the size distribution amongst the bodies with radius more than 10km is flatter than the one observed in the Kuiper belt. For AU Mic's disk, the shallowest size distribution for the bodies with highest radius is suggested, indicating that the planet may contain embryos resulting from runaway growth.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1325}
{"prompt": "Rephrase the abstract of an article with title 'The Dynamical State fo the Starless Dense Core FeSt 1-457: A Pulsating\n  Globule?'.\n  High resolution molecular line observations of CS, HCO+, C18O and N2H+ were\nobtained toward the starless globule FeSt 1-457 in order to investigate its\nkinematics and chemistry. The HCO+ and CS spectra show clear self-reversed and\nasymmetric profiles across the face of the globule. The sense of the observed\nasymmetry is indicative of the global presence of expansion motions in the\nouter layers of the globule. These motions appear to be subsonic and\nsignificantly below the escape velocity of the globule. Comparison of our\nobservations with near-infrared extinction data indicate that the globule is\ngravitationally bound. Taken together these considerations lead us to suggest\nthat the observed expansion has its origin in an oscillatory motion of the\nouter layers of the globule which itself is likely in a quasi-stable state near\nhydrostatic equilibrium. Analysis of the observed linewidths of CO and N2H+\nconfirm that thermal pressure is the dominant component of the cloud's internal\nsupport. A simple calculation suggests that the dominant mode of pulsation\nwould be an l = 2 mode with a period of 0.3 Myr. Deformation of the globule due\nto the large amplitude l = 2 oscillation may be responsible for the\ndouble-peaked structure of the core detected in high resolution extinction\nmaps. Detailed comparison of the molecular-line observations and extinction\ndata provides evidence for significant depletion of C18O and perhaps HCO+ while\nN2H+ may be undepleted to a cloud depth of about 40 magnitudes of visual\nextinction.\n\n", "human_text": "  High resolution molecular line observations of CS, HCO+, C18O and N2H+ were\nobtained toward the starless globule FeSt 1-457 in order to investigate its\nkinematics and chemistry. The HCO+ and CS spectra show clear self-reversed and\nasymmetric profiles across the face of the globule. The sense of the observed\nasymmetry is indicative of the global presence of expansion motions in the\nouter layers of the globule. These motions appear to be subsonic and\nsignificantly below the escape velocity of the globule. Comparison of our\nobservations with near-infrared extinction data indicate that the globule is\ngravitationally bound. Taken together these considerations lead us to suggest\nthat the observed expansion has its origin in an oscillatory motion of the\nouter layers of the globule which itself is likely in a quasi-stable state near\nhydrostatic equilibrium. Analysis of the observed linewidths of CO and N2H+\nconfirm that thermal pressure is the dominant component of the cloud's internal\nsupport. A simple calculation suggests that the dominant mode of pulsation\nwould be an l = 2 mode with a period of 0.3 Myr. Deformation of the globule due\nto the large amplitude l = 2 oscillation may be responsible for the\ndouble-peaked structure of the core detected in high resolution extinction\nmaps. Detailed comparison of the molecular-line observations and extinction\ndata provides evidence for significant depletion of C18O and perhaps HCO+ while\nN2H+ may be undepleted to a cloud depth of about 40 magnitudes of visual\nextinction.\n", "machine_text": "\nResearchers conducted molecular line observations of the starless globule FeSt 1-457 in order to analyze its kinematics and chemical properties. The self-reversed and asymmetric profiles of the HCO+ and CS spectra across the face of the globule were noticed, suggesting the presence of expansion motions in the globule's outer layers. It was also determined that these motions were subsonic and below the escape velocity, indicating that the globule is gravitationally bound. After comparing the observations to near-infrared extinction data, it was suggested that the observed expansion has its roots in an oscillatory motion amd the globule is in a quasi-stable state near hydrostatic equilibrium. The analysis of the observed linewidths concluded that thermal pressure is the primary internal support mechanism of the cloud. A calculation suggested that the dominant oscillation period is around 0.3 Myr, potentially accounting for the double-peaked structure of the core in the high resolution extinction maps. Lastly, comparisons between the molecular-line observations and extinction data have revealed potential evidence for depletion of C18O and HCO+, and possibly no depletion for N2H+ up to 40 magnitudes of visual extinction.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0328}
{"prompt": "Rephrase the abstract of an article with title 'Gravitational waves from galaxy encounters'.\n  We discuss the emission of gravitational radiation produced in encounters of\ndark matter galactic halos. To this aim we perform a number of numerical\nsimulations of typical galaxy mergers, computing the associated gravitational\nradiation waveforms as well as the energy released in the processes. Our\nsimulations yield dimensionless gravitational wave amplitudes of the order of\n$10^{-13}$ and gravitational wave frequencies of the order of $10^{-16}$ Hz,\nwhen the galaxies are located at a distance of 10 Mpc. These values are of the\nsame order as those arising in the gravitational radiation originated by strong\nvariations of the gravitational field in the early Universe, and therefore,\nsuch gravitational waves cannot be directly observed by ground-based detectors.\nWe discuss the feasibility of an indirect detection by means of the B-mode\npolarization of the Cosmic Microwave Background (CMB) induced by such waves.\nOur results show that the gravitational waves from encounters of dark matter\ngalactic halos leave much too small an imprint on the CMB polarization to be\nactually observed with ongoing and future missions.\n\n", "human_text": "  We discuss the emission of gravitational radiation produced in encounters of\ndark matter galactic halos. To this aim we perform a number of numerical\nsimulations of typical galaxy mergers, computing the associated gravitational\nradiation waveforms as well as the energy released in the processes. Our\nsimulations yield dimensionless gravitational wave amplitudes of the order of\n$10^{-13}$ and gravitational wave frequencies of the order of $10^{-16}$ Hz,\nwhen the galaxies are located at a distance of 10 Mpc. These values are of the\nsame order as those arising in the gravitational radiation originated by strong\nvariations of the gravitational field in the early Universe, and therefore,\nsuch gravitational waves cannot be directly observed by ground-based detectors.\nWe discuss the feasibility of an indirect detection by means of the B-mode\npolarization of the Cosmic Microwave Background (CMB) induced by such waves.\nOur results show that the gravitational waves from encounters of dark matter\ngalactic halos leave much too small an imprint on the CMB polarization to be\nactually observed with ongoing and future missions.\n", "machine_text": "\nWe investigate the gravitational waves produced in collisions of dark matter-filled galactic halos. Our numerical simulations investigate the energy output and associated gravitational radiation waveforms. We observe that, for galaxies located 10 Mpc away, the amplitudes of the gravitational waves range from around $10^{-13}$ and the frequencies from around $10^{-16}$ Hz, values similar to those theorized for the waves spawned in the primordial universe. As such, the waves cannot be recorded directly by terrestrial detectors. We explore the possibility of an indirect detection via the B-mode polarization of the Cosmic Microwave Background triggered by the waves. Ultimately, our results show that the imprint of gravitational waves from galaxy encounters is too weak to be observed by ongoing or upcoming missions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3009}
{"prompt": "Rephrase the abstract of an article with title 'Efficient method for detection of periodic orbits in chaotic maps and\n  flows'.\n  An algorithm for detecting unstable periodic orbits in chaotic systems [Phys.\nRev. E, 60 (1999), pp. 6172-6175] which combines the set of stabilising\ntransformations proposed by Schmelcher and Diakonos [Phys. Rev. Lett., 78\n(1997), pp. 4733-4736] with a modified semi-implicit Euler iterative scheme and\nseeding with periodic orbits of neighbouring periods, has been shown to be\nhighly efficient when applied to low-dimensional system. The difficulty in\napplying the algorithm to higher dimensional systems is mainly due to the fact\nthat the number of stabilising transformations grows extremely fast with\nincreasing system dimension. In this thesis, we construct stabilising\ntransformations based on the knowledge of the stability matrices of already\ndetected periodic orbits (used as seeds). The advantage of our approach is in a\nsubstantial reduction of the number of transformations, which increases the\nefficiency of the detection algorithm, especially in the case of\nhigh-dimensional systems. The performance of the new approach is illustrated by\nits application to the four-dimensional kicked double rotor map, a\nsix-dimensional system of three coupled H\\'enon maps and to the\nKuramoto-Sivashinsky system in the weakly turbulent regime.\n\n", "human_text": "  An algorithm for detecting unstable periodic orbits in chaotic systems [Phys.\nRev. E, 60 (1999), pp. 6172-6175] which combines the set of stabilising\ntransformations proposed by Schmelcher and Diakonos [Phys. Rev. Lett., 78\n(1997), pp. 4733-4736] with a modified semi-implicit Euler iterative scheme and\nseeding with periodic orbits of neighbouring periods, has been shown to be\nhighly efficient when applied to low-dimensional system. The difficulty in\napplying the algorithm to higher dimensional systems is mainly due to the fact\nthat the number of stabilising transformations grows extremely fast with\nincreasing system dimension. In this thesis, we construct stabilising\ntransformations based on the knowledge of the stability matrices of already\ndetected periodic orbits (used as seeds). The advantage of our approach is in a\nsubstantial reduction of the number of transformations, which increases the\nefficiency of the detection algorithm, especially in the case of\nhigh-dimensional systems. The performance of the new approach is illustrated by\nits application to the four-dimensional kicked double rotor map, a\nsix-dimensional system of three coupled H\\'enon maps and to the\nKuramoto-Sivashinsky system in the weakly turbulent regime.\n", "machine_text": "This thesis presents an improved method for detecting periodic orbits in chaotic maps and flows. It combines the stabilising transformations proposed by Schmelcher and Diakonos with a modified semi-implicit Euler iterative scheme and seeding with periodic orbits of neighbouring periods. This technique is highly efficient when applied to low-dimensional systems, but can be difficult to apply to higher-dimensional systems due to the rapid growth of the number of required stabilising transformations. To address this challenge, the thesis introduces a novel approach which relies on the knowledge of stability matrices of already-detected periodic orbits to reduce the number of transformations and increase the efficiency of the detection algorithm. The efficacy of this approach is demonstrated by its application to a four-dimensional kicked double rotor map, a six-dimensional system of three coupled H\u00e9non maps, and the Kuramoto-Sivashinsky system in a weakly turbulent regime.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.194}
{"prompt": "Rephrase the abstract of an article with title 'Optimizing future imaging survey of galaxies to confront dark energy and\n  modified gravity models'.\n  We consider the extent to which future imaging surveys of galaxies can\ndistinguish between dark energy and modified gravity models for the origin of\nthe cosmic acceleration. Dynamical dark energy models may have similar\nexpansion rates as models of modified gravity, yet predict different growth of\nstructure histories. We parameterize the cosmic expansion by the two\nparameters, $w_0$ and $w_a$, and the linear growth rate of density fluctuations\nby Linder's $\\gamma$, independently. Dark energy models generically predict\n$\\gamma \\approx 0.55$, while the DGP model $\\gamma \\approx 0.68$. To determine\nif future imaging surveys can constrain $\\gamma$ within 20 percent (or\n$\\Delta\\gamma<0.1$), we perform the Fisher matrix analysis for a weak lensing\nsurvey such as the on-going Hyper Suprime-Cam (HSC) project. Under the\ncondition that the total observation time is fixed, we compute the Figure of\nMerit (FoM) as a function of the exposure time $\\texp$. We find that the\ntomography technique effectively improves the FoM, which has a broad peak\naround $\\texp\\simeq {\\rm several}\\sim 10$ minutes; a shallow and wide survey is\npreferred to constrain the $\\gamma$ parameter. While $\\Delta\\gamma < 0.1$\ncannot be achieved by the HSC weak-lensing survey alone, one can improve the\nconstraints by combining with a follow-up spectroscopic survey like WFMOS\nand/or future CMB observations.\n\n", "human_text": "  We consider the extent to which future imaging surveys of galaxies can\ndistinguish between dark energy and modified gravity models for the origin of\nthe cosmic acceleration. Dynamical dark energy models may have similar\nexpansion rates as models of modified gravity, yet predict different growth of\nstructure histories. We parameterize the cosmic expansion by the two\nparameters, $w_0$ and $w_a$, and the linear growth rate of density fluctuations\nby Linder's $\\gamma$, independently. Dark energy models generically predict\n$\\gamma \\approx 0.55$, while the DGP model $\\gamma \\approx 0.68$. To determine\nif future imaging surveys can constrain $\\gamma$ within 20 percent (or\n$\\Delta\\gamma<0.1$), we perform the Fisher matrix analysis for a weak lensing\nsurvey such as the on-going Hyper Suprime-Cam (HSC) project. Under the\ncondition that the total observation time is fixed, we compute the Figure of\nMerit (FoM) as a function of the exposure time $\\texp$. We find that the\ntomography technique effectively improves the FoM, which has a broad peak\naround $\\texp\\simeq {\\rm several}\\sim 10$ minutes; a shallow and wide survey is\npreferred to constrain the $\\gamma$ parameter. While $\\Delta\\gamma < 0.1$\ncannot be achieved by the HSC weak-lensing survey alone, one can improve the\nconstraints by combining with a follow-up spectroscopic survey like WFMOS\nand/or future CMB observations.\n", "machine_text": "\nThe objective of this research is to analyze the capability of imaging surveys of galaxies in distinguishing between dark energy and modified gravity explanations for the emergence of cosmic acceleration. We divide properties of the universe's evolutionary history into two parameters, $w_0$ and $w_a$, and the rate of growth of density disparities by Linder's $\\gamma$. Dark energy models generally show $\\gamma \\approx 0.55$ and the DGP model is signified by $\\gamma \\approx 0.68$. We utilize the Fisher Matrix technique to assess a survey such as the Hyper Suprime-Cam (HSC) project to determine if its observations of $\\gamma$ can be constrained to within 20%. Results from tomography help to raise the FoM, and its peak is at an exposure time of several minutes for a wide and shallow survey. In order to reach $\\Delta\\gamma < 0.1$ it is necessary to employ additional surveys such as WFMOS or upcoming CMB studies in combination with the HSC survey.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2949}
{"prompt": "Rephrase the abstract of an article with title 'Ramsey interferometry with a two-level Tonks-Girardeau gas'.\n  We propose a generalization of the Tonks-Girardeau model that describes a\ncoherent gas of cold two-level Bosons which interact with two external fields\nin a Ramsey interferometer. They also interact among themselves by contact\ncollisions with interchange of momentum and internal state. We study the\ncorresponding Ramsey fringes and the quantum projection noise which,\nessentially unaffected by the interactions, remains that for ideal Bosons. The\ndual system of this gas, an ideal gas of two-level Fermions coupled by the\ninteraction with the separated fields, produces the same fringes and noise\nfluctuations. The cases of time-separated and spatially-separated fields are\nstudied. For spatially separated fields the fringes may be broadened slightly\nby increasing the number of particles, but only for large particle numbers far\nfrom present experiments with Tonks-Girardeau gases. The uncertainty in the\ndetermination of the atomic transition frequency diminishes, essentially with\nthe inverse root of the particle number.\n\n", "human_text": "  We propose a generalization of the Tonks-Girardeau model that describes a\ncoherent gas of cold two-level Bosons which interact with two external fields\nin a Ramsey interferometer. They also interact among themselves by contact\ncollisions with interchange of momentum and internal state. We study the\ncorresponding Ramsey fringes and the quantum projection noise which,\nessentially unaffected by the interactions, remains that for ideal Bosons. The\ndual system of this gas, an ideal gas of two-level Fermions coupled by the\ninteraction with the separated fields, produces the same fringes and noise\nfluctuations. The cases of time-separated and spatially-separated fields are\nstudied. For spatially separated fields the fringes may be broadened slightly\nby increasing the number of particles, but only for large particle numbers far\nfrom present experiments with Tonks-Girardeau gases. The uncertainty in the\ndetermination of the atomic transition frequency diminishes, essentially with\nthe inverse root of the particle number.\n", "machine_text": "This article presents a new, generalized model of the Tonks-Girardeau gas, which consists of cold two-level Bosons interacting with external fields and among themselves in a Ramsey interferometer. We analyze the quantum effects and resulting Ramsey fringes and quantum projection noise, showing that these effects remain largely unaltered in the presence of interactions. Additionally, we examine the behavior of the dual system - an ideal gas of two-level Fermions interacting with fields - and empirically deduce that the number of particles generally does not have a great impact on the broadening of fringes. Lastly, we demonstrate that precision in the measurement of atomic transition frequency increases with the inverse root of the number of particles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3746}
{"prompt": "Rephrase the abstract of an article with title 'Spitzer Mid-to-Far-Infrared Flux Densities of Distant Galaxies'.\n  We study the infrared (IR) properties of high-redshift galaxies using deep\nSpitzer 24, 70, and 160 micron data. Our primary interest is to improve the\nconstraints on the total IR luminosities, L(IR), of these galaxies. We combine\nthe Spitzer data in the southern Extended Chandra Deep Field with a\nK-band-selected galaxy sample and photometric redshifts from the\nMultiwavelength Survey by Yale-Chile. We used a stacking analysis to measure\nthe average 70 and 160 micron flux densities of 1.5 < z < 2.5 galaxies as a\nfunction of 24 micron flux density, X-ray activity, and rest-frame near-IR\ncolor. Galaxies with 1.5 < z < 2.5 and S(24)=53-250 micro-Jy have L(IR) derived\nfrom their average 24-160 micron flux densities within factors of 2-3 of those\nderived from the 24 micron flux densities only. However, L(IR) derived from the\naverage 24-160 micron flux densities for galaxies with S(24) > 250 micro-Jy and\n1.5 < z < 2.5 are lower than those derived using only the 24 micron flux\ndensity by factors of 2-10. Galaxies with S(24) > 250 micro-Jy have S(70)/S(24)\nflux ratios comparable to sources with X-ray detections or red rest-frame IR\ncolors, suggesting that warm dust possibly heated by AGN may contribute to the\nhigh 24 micron emission. Based on the average 24-160 micron flux densities,\nnearly all 24 micron-selected galaxies at 1.5 < z < 2.5 have L(IR) < 6 x 10^12\nsolar luminosities, which if attributed to star formation corresponds to < 1000\nsolar masses per year. This suggests that high redshift galaxies may have\nsimilar star formation efficiencies and feedback processes as local analogs.\nObjects with L(IR) > 6 x 10^12 solar luminosities are quite rare, with a\nsurface density ~ 30 +/- 10 per sq. deg, corresponding to ~ 2 +/- 1 x 10^-6\nMpc^-3 over 1.5 < z < 2.5.\n\n", "human_text": "  We study the infrared (IR) properties of high-redshift galaxies using deep\nSpitzer 24, 70, and 160 micron data. Our primary interest is to improve the\nconstraints on the total IR luminosities, L(IR), of these galaxies. We combine\nthe Spitzer data in the southern Extended Chandra Deep Field with a\nK-band-selected galaxy sample and photometric redshifts from the\nMultiwavelength Survey by Yale-Chile. We used a stacking analysis to measure\nthe average 70 and 160 micron flux densities of 1.5 < z < 2.5 galaxies as a\nfunction of 24 micron flux density, X-ray activity, and rest-frame near-IR\ncolor. Galaxies with 1.5 < z < 2.5 and S(24)=53-250 micro-Jy have L(IR) derived\nfrom their average 24-160 micron flux densities within factors of 2-3 of those\nderived from the 24 micron flux densities only. However, L(IR) derived from the\naverage 24-160 micron flux densities for galaxies with S(24) > 250 micro-Jy and\n1.5 < z < 2.5 are lower than those derived using only the 24 micron flux\ndensity by factors of 2-10. Galaxies with S(24) > 250 micro-Jy have S(70)/S(24)\nflux ratios comparable to sources with X-ray detections or red rest-frame IR\ncolors, suggesting that warm dust possibly heated by AGN may contribute to the\nhigh 24 micron emission. Based on the average 24-160 micron flux densities,\nnearly all 24 micron-selected galaxies at 1.5 < z < 2.5 have L(IR) < 6 x 10^12\nsolar luminosities, which if attributed to star formation corresponds to < 1000\nsolar masses per year. This suggests that high redshift galaxies may have\nsimilar star formation efficiencies and feedback processes as local analogs.\nObjects with L(IR) > 6 x 10^12 solar luminosities are quite rare, with a\nsurface density ~ 30 +/- 10 per sq. deg, corresponding to ~ 2 +/- 1 x 10^-6\nMpc^-3 over 1.5 < z < 2.5.\n", "machine_text": "\nUsing data from Spitzer's 24, 70 and 160 micron bands, we studied the infrared characteristics of high-redshift galaxies in the southern Extended Chandra Deep Field in connection with K-band-selected galaxies, Multiwavelength Survey by Yale-Chile photometric redshift data, and X-ray activity. Through stacking analysis, we determined the average 70 and 160 micron flux densities for galaxies with 1.5 < z < 2.5, both with respect to the 24 micron flux density and for red rest-frame infrared colours and X-ray detections. Our results indicate that galaxies in this redshift range with S(24) = 0.053-0.250 micro-Jy showed L(IR) values similar to those of 24 micron flux densities. However, those with S(24) > 0.250 micro-Jy had higher S(70)/S(24) flux ratios, possibly due to emission from hot dust heated by AGN. Lastly, our analysis suggests that star-forming galaxies have star-formation efficiencies and feedback mechanisms comparable to our galaxy's local counterparts, with L(IR) < 6 x 10^12 solar luminosities corresponding to <1000 solar masses per year. Such galaxies appear to be rare, at surface densities approximately 30 +/- 10 per square degree and a volume density of ~2 +/- 1 x 10^-6 Mpc^-3 over 1.5 < z < 2.5.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2164}
{"prompt": "Rephrase the abstract of an article with title 'The Equivariant cohomology theory of twisted generalized complex\n  manifolds'.\n  It has been shown recently by Kapustin and Tomasiello that the mathematical\nnotion of Hamiltonian actions on twisted generalized K\\\"ahler manifolds is in\nperfect agreement with the physical notion of general $(2,2)$ gauged sigma\nmodels with three-form fluxes. In this article, we study the twisted\nequivariant cohomology theory of Hamiltonian actions on $H$-twisted generalized\ncomplex manifolds. If the manifold satisfies the\n$\\bar{\\partial}\\partial$-lemma, we establish the equivariant formality theorem.\nIf in addition, the manifold satisfies the generalized K\\\"ahler condition, we\nprove the Kirwan injectivity in this setting. We then consider the Hamiltonian\naction of a torus on an $H$-twisted generalized Calabi-Yau manifold and extend\nto this case the Duistermaat-Heckman theorem for the push-forward measure.\n  As a side result, we show in this paper that the generalized K\\\"ahler\nquotient of a generalized K\\\"ahler vector space can never have a\n(cohomologically) non-trivial twisting. This gives a negative answer to a\nquestion asked by physicists whether one can construct $(2,2)$ gauged linear\nsigma models with non-trivial fluxes.\n\n", "human_text": "  It has been shown recently by Kapustin and Tomasiello that the mathematical\nnotion of Hamiltonian actions on twisted generalized K\\\"ahler manifolds is in\nperfect agreement with the physical notion of general $(2,2)$ gauged sigma\nmodels with three-form fluxes. In this article, we study the twisted\nequivariant cohomology theory of Hamiltonian actions on $H$-twisted generalized\ncomplex manifolds. If the manifold satisfies the\n$\\bar{\\partial}\\partial$-lemma, we establish the equivariant formality theorem.\nIf in addition, the manifold satisfies the generalized K\\\"ahler condition, we\nprove the Kirwan injectivity in this setting. We then consider the Hamiltonian\naction of a torus on an $H$-twisted generalized Calabi-Yau manifold and extend\nto this case the Duistermaat-Heckman theorem for the push-forward measure.\n  As a side result, we show in this paper that the generalized K\\\"ahler\nquotient of a generalized K\\\"ahler vector space can never have a\n(cohomologically) non-trivial twisting. This gives a negative answer to a\nquestion asked by physicists whether one can construct $(2,2)$ gauged linear\nsigma models with non-trivial fluxes.\n", "machine_text": "\nIn this paper, we analyze the equivariant cohomology of twisted generalized complex manifolds subjected to Hamiltonian actions - a notion compatible with the physical theory of $(2,2)$ gauged sigma models with three-form fluxes according to Kapustin and Tomasiello. We establish an equivariant formality theorem and Kirwan Injectivity if the manifold satisfies the $\\bar{\\partial}\\partial$-lemma, and the generalized K\\\"ahler condition, respectively. Furthermore, we extend the Duistermaat-Heckman theorem to the case of an $H$-twisted generalized Calabi-Yau manifold acted upon by a torus. As a secondary outcome of this, we prove that the generalized K\\\"ahler quotient of a generalized K\\\"ahler vector space does not have a (cohomologically) non-trivial twisting, yielding a negative answer to a query about gauged linear sigma models with non-trivial fluxes voiced by physicists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2804}
{"prompt": "Rephrase the abstract of an article with title 'Star formation in Perseus: III. Outflows'.\n  We present a search for outflows towards 51 submillimetre cores in Perseus.\nWith consistently derived outflow properties from a large homogeneous dataset\nwithin one molecular cloud we can investigate further the mass dependence and\ntime evolution of protostellar mass loss. Of the 51 cores, 37 show broad\nlinewings indicative of molecular outflows. In 13 cases, the linewings could be\ndue to confusion with neighbouring flows but 9 of those sources also have\nnear-infrared detections confirming their protostellar nature. The total\nfraction of protostars in our sample is 65%. All but four outflow detections\nare confirmed as protostellar by Spitzer IR detections and only one Spitzer\nsource has no outflow, showing that outflow maps at this sensitivity are\nequally good at identifying protostars as Spitzer. Outflow momentum flux\ncorrelates both with source luminosity and with core mass but there is\nconsiderable scatter even within this one cloud despite the homogeneous\ndataset. We fail to confirm the result of Bontemps et al. (1996) that Class I\nsources show lower momentum fluxes on average than Class 0 sources, with a KS\ntest showing a significant probability that the momentum fluxes for both Class\n0s and Class Is are drawn from the same distribution. We find that outflow\npower may not show a simple decline between the Class 0 to Class I stages. Our\nsample includes low momentum flux, low-luminosity Class 0 sources, possibly at\na very early evolutionary stage. If the only mass loss from the core were due\nto outflows, cores would last for 10^5-10^8 years, longer than current\nestimates of 1.5-4 x 10^5 years for the mean lifetime for the embedded phase.\nAdditional mechanisms for removing mass from protostellar cores may be\nnecessary.\n\n", "human_text": "  We present a search for outflows towards 51 submillimetre cores in Perseus.\nWith consistently derived outflow properties from a large homogeneous dataset\nwithin one molecular cloud we can investigate further the mass dependence and\ntime evolution of protostellar mass loss. Of the 51 cores, 37 show broad\nlinewings indicative of molecular outflows. In 13 cases, the linewings could be\ndue to confusion with neighbouring flows but 9 of those sources also have\nnear-infrared detections confirming their protostellar nature. The total\nfraction of protostars in our sample is 65%. All but four outflow detections\nare confirmed as protostellar by Spitzer IR detections and only one Spitzer\nsource has no outflow, showing that outflow maps at this sensitivity are\nequally good at identifying protostars as Spitzer. Outflow momentum flux\ncorrelates both with source luminosity and with core mass but there is\nconsiderable scatter even within this one cloud despite the homogeneous\ndataset. We fail to confirm the result of Bontemps et al. (1996) that Class I\nsources show lower momentum fluxes on average than Class 0 sources, with a KS\ntest showing a significant probability that the momentum fluxes for both Class\n0s and Class Is are drawn from the same distribution. We find that outflow\npower may not show a simple decline between the Class 0 to Class I stages. Our\nsample includes low momentum flux, low-luminosity Class 0 sources, possibly at\na very early evolutionary stage. If the only mass loss from the core were due\nto outflows, cores would last for 10^5-10^8 years, longer than current\nestimates of 1.5-4 x 10^5 years for the mean lifetime for the embedded phase.\nAdditional mechanisms for removing mass from protostellar cores may be\nnecessary.\n", "machine_text": "\nIn this paper, we explore the mass dependence, time evolution, and degree of outflows associated with star formation in the Perseus molecular cloud. We surveyed 51 submillimetre cores and 37 of those showed evidence of protostellar outflows in their broad linewings - with 13 of those potentially being false positives due to confusion with neighbouring flows. Near-infrared detections further confirmed that 65 percent of the cores are protostars. Comparing our results to Spitzer infrared detections, outflow maps at this same sensitivity were found to be just as good as Spitzer in identifying protostars. Outflow momentum flux displays correlations with core mass and source luminosity, but with a large degree of scatter. Furthermore, our results did not provide strong evidence for the Bontemps et al. (1996) assertion of lower momentum fluxes for Class I sources in comparison to Class 0 sources. Lastly, our sample also included low momentum flux, low-luminosity Class 0 sources potentially signifying an early stage of star formation - a stage that may last longer than the current lifetime estimates for the embedded phase. Our findings suggest that additional mechanisms may be necessary for the removal of mass from protostellar cores.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1724}
{"prompt": "Rephrase the abstract of an article with title '3D Radiative Hydrodynamics for Disk Stability Simulations: A Proposed\n  Testing Standard and New Results'.\n  Recent three-dimensional radiative hydrodynamics simulations of\nprotoplanetary disks report disparate disk behaviors, and these differences\ninvolve the importance of convection to disk cooling, the dependence of disk\ncooling on metallicity, and the stability of disks against fragmentation and\nclump formation. To guarantee trustworthy results, a radiative physics\nalgorithm must demonstrate the capability to handle both the high and low\noptical depth regimes. We develop a test suite that can be used to demonstrate\nan algorithm's ability to relax to known analytic flux and temperature\ndistributions, to follow a contracting slab, and to inhibit or permit\nconvection appropriately. We then show that the radiative algorithm employed by\nMeji\\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al.\n(2006) and Cai et al. (2007, in prep.) pass these tests with reasonable\naccuracy. In addition, we discuss a new algorithm that couples flux-limited\ndiffusion with vertical rays, we apply the test suite, and we discuss the\nresults of evolving the Boley et al. (2006) disk with this new routine.\nAlthough the outcome is significantly different in detail with the new\nalgorithm, we obtain the same qualitative answers. Our disk does not cool fast\ndue to convection, and it is stable to fragmentation. We find an effective\n$\\alpha\\approx 10^{-2}$. In addition, transport is dominated by low-order\nmodes.\n\n", "human_text": "  Recent three-dimensional radiative hydrodynamics simulations of\nprotoplanetary disks report disparate disk behaviors, and these differences\ninvolve the importance of convection to disk cooling, the dependence of disk\ncooling on metallicity, and the stability of disks against fragmentation and\nclump formation. To guarantee trustworthy results, a radiative physics\nalgorithm must demonstrate the capability to handle both the high and low\noptical depth regimes. We develop a test suite that can be used to demonstrate\nan algorithm's ability to relax to known analytic flux and temperature\ndistributions, to follow a contracting slab, and to inhibit or permit\nconvection appropriately. We then show that the radiative algorithm employed by\nMeji\\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al.\n(2006) and Cai et al. (2007, in prep.) pass these tests with reasonable\naccuracy. In addition, we discuss a new algorithm that couples flux-limited\ndiffusion with vertical rays, we apply the test suite, and we discuss the\nresults of evolving the Boley et al. (2006) disk with this new routine.\nAlthough the outcome is significantly different in detail with the new\nalgorithm, we obtain the same qualitative answers. Our disk does not cool fast\ndue to convection, and it is stable to fragmentation. We find an effective\n$\\alpha\\approx 10^{-2}$. In addition, transport is dominated by low-order\nmodes.\n", "machine_text": "\nThe results of three-dimensional radiative hydrodynamics simulations of protoplanetary disks show various disparate disk behaviors, producing varying results on the role of convection in cooling, the disk's metal content and its stability against clump formation and fragmentation. To ensure valid outcomes, a radiative physics algorithm is proposed and tested to demonstrate the capacity to produce expected flux and temperature distributions, follow a contracting slab of material and either facilitate or inhibit convection as required. Using the test results, we evaluate two distinct radiative algorithms from Meji\\'a (2004) and Boley et al. (2006), and Cai et al. (2006) and Cai et al. (2007, in prep.), and present a new algorithm combining flux-limited diffusion and vertical rays. We show that the new algorithm produces qualitatively similar results - that convection does not play a major part in cooling and the disk is stable - but with some different quantitative details. This supports an effective $\\alpha\\approx 10^{-2}$ for the disk, with transport mainly dominated by low-order modes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2532}
{"prompt": "Rephrase the abstract of an article with title 'Deaconstructing Functions on Quadratic Surfaces into Multipoles'.\n  Any homogeneous polynomial $P(x, y, z)$ of degree $d$, being restricted to a\nunit sphere $S^2$, admits essentially a unique representation of the form\n$\\lambda + \\sum_{k = 1}^d [\\prod_{j = 1}^k L_{kj}]$, where $L_{kj}$'s are\nlinear forms in $x, y$ and $z$ and $\\lambda$ is a real number. The coefficients\nof these linear forms, viewed as 3D vectors, are called \\emph{multipole}\nvectors of $P$. In this paper we consider similar multipole representations of\npolynomial and analytic functions on other quadratic surfaces $Q(x, y, z) = c$,\nreal and complex. Over the complex numbers, the above representation is not\nunique, although the ambiguity is essentially finite. We investigate the\ncombinatorics that depicts this ambiguity. We link these results with some\nclassical theorems of harmonic analysis, theorems that describe decompositions\nof functions into sums of spherical harmonics. We extend these classical\ntheorems (which rely on our understanding of the Laplace operator\n$\\Delta_{S^2}$) to more general differential operators $\\Delta_Q$ that are\nconstructed with the help of the quadratic form $Q(x, y, z)$. Then we introduce\nmodular spaces of multipoles. We study their intricate geometry and topology\nusing methods of algebraic geometry and singularity theory. The multipole\nspaces are ramified over vector or projective spaces, and the compliments to\nthe ramification sets give rise to a rich family of $K(\\pi, 1)$-spaces, where\n$\\pi$ runs over a variety of modified braid groups.\n\n", "human_text": "  Any homogeneous polynomial $P(x, y, z)$ of degree $d$, being restricted to a\nunit sphere $S^2$, admits essentially a unique representation of the form\n$\\lambda + \\sum_{k = 1}^d [\\prod_{j = 1}^k L_{kj}]$, where $L_{kj}$'s are\nlinear forms in $x, y$ and $z$ and $\\lambda$ is a real number. The coefficients\nof these linear forms, viewed as 3D vectors, are called \\emph{multipole}\nvectors of $P$. In this paper we consider similar multipole representations of\npolynomial and analytic functions on other quadratic surfaces $Q(x, y, z) = c$,\nreal and complex. Over the complex numbers, the above representation is not\nunique, although the ambiguity is essentially finite. We investigate the\ncombinatorics that depicts this ambiguity. We link these results with some\nclassical theorems of harmonic analysis, theorems that describe decompositions\nof functions into sums of spherical harmonics. We extend these classical\ntheorems (which rely on our understanding of the Laplace operator\n$\\Delta_{S^2}$) to more general differential operators $\\Delta_Q$ that are\nconstructed with the help of the quadratic form $Q(x, y, z)$. Then we introduce\nmodular spaces of multipoles. We study their intricate geometry and topology\nusing methods of algebraic geometry and singularity theory. The multipole\nspaces are ramified over vector or projective spaces, and the compliments to\nthe ramification sets give rise to a rich family of $K(\\pi, 1)$-spaces, where\n$\\pi$ runs over a variety of modified braid groups.\n", "machine_text": "This paper explores the idea of breaking down homogeneous polynomial and analytic functions defined on quadratic surfaces into their multipole vector components. We discuss how this approach relates to classical harmonic analysis and the associated Laplace operator and more general differential operators related to the shape of the quadratic surface. Investigating the geometry and topology of the multipole spaces, we employ analytic geometry and singularity theory to delve further into these spaces which feature a variety of modified braid groups.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1174}
{"prompt": "Rephrase the abstract of an article with title 'A novel method for evaluating the critical nucleus and the surface\n  tension in systems with first order phase transition'.\n  We introduce a novel method for calculating the size of the critical nucleus\nand the value of the surface tension in systems with first order phase\ntransition. The method is based on classical nucleation theory, and it consists\nin studying the thermodynamics of a sphere of given radius embedded in a frozen\nmetastable surrounding. The frozen configuration creates a pinning field on the\nsurface of the free sphere. The pinning field forces the sphere to stay in the\nmetastable phase as long as its size is smaller than the critical nucleus. We\ntest our method in two first-order systems, both on a two-dimensional lattice:\na system where the parameter tuning the transition is the magnetic field, and a\nsecond system where the tuning parameter is the temperature. In both cases the\nresults are satisfying. Unlike previous techniques, our method does not require\nan infinite volume limit to compute the surface tension, and it therefore gives\nreliable estimates even by using relatively small systems. However, our method\ncannot be used at, or close to, the critical point, i.e. at coexistence, where\nthe critical nucleus becomes infinitely large.\n\n", "human_text": "  We introduce a novel method for calculating the size of the critical nucleus\nand the value of the surface tension in systems with first order phase\ntransition. The method is based on classical nucleation theory, and it consists\nin studying the thermodynamics of a sphere of given radius embedded in a frozen\nmetastable surrounding. The frozen configuration creates a pinning field on the\nsurface of the free sphere. The pinning field forces the sphere to stay in the\nmetastable phase as long as its size is smaller than the critical nucleus. We\ntest our method in two first-order systems, both on a two-dimensional lattice:\na system where the parameter tuning the transition is the magnetic field, and a\nsecond system where the tuning parameter is the temperature. In both cases the\nresults are satisfying. Unlike previous techniques, our method does not require\nan infinite volume limit to compute the surface tension, and it therefore gives\nreliable estimates even by using relatively small systems. However, our method\ncannot be used at, or close to, the critical point, i.e. at coexistence, where\nthe critical nucleus becomes infinitely large.\n", "machine_text": "This paper presents a novel approach for evaluating the size of the critical nucleus and the surface tension in systems that exhibit a first order phase transition. Our technique is based on the thermodynamics of a sphere of given radius encapsulated in a frozen metastable surrounding, and the exterior pinning field that it creates remains until the radius of the sphere is larger than the critical nucleus' size. We have tested our method in two systems under two different parameters - the magnetic field and temperature, both in a two-dimensional lattice - where we obtained satisfactory results. One advantage of our method is that it does not need an infinite volume limit to be accurate, since it obtains reliable results even in relatively small systems. On the contrary, it cannot be used at or close to the critical point, since the critical nucleus would become infinitely large at this stage.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1519}
{"prompt": "Rephrase the abstract of an article with title 'The Stueckelberg Extension and Milli Weak and Milli Charge Dark Matter'.\n  A overview is given of the recent developments in the $U(1)_X$ Stueckelberg\nextensions of the Standard Model and of MSSM where all the Standard Model\nparticles are neutral under the $U(1)_X$ but an axion which is absorbed is\ncharged under both $U(1)_X$ and $U(1)_Y$ and acts as the connector field\ncoupling the Standard Model sector with the Stueckelberg sector. Coupled with\nthe usual Higgs mechanism that breaks the $SU(2)_L\\times U(1)_Y$ gauge\nsymmetry, this scenario produces mixings in the neutral gauge boson sector\ngenerating an extra $Z'$ boson. The couplings of the extra $Z'$ to the Standard\nModel particles are milli weak but its couplings to the hidden sector matter,\ndefined as matter that couples only to the gauge field of $U(1)_X$, can be of\nnormal electro-weak strength. It is shown that such extensions, aside from the\npossibility of leading to a sharp $Z' $ resonance, lead to two new types of\ndark matter: milli weak (or extra weak) and milli charged. An analysis of the\nrelic density shows that the WMAP-3 constraints can be satisfied for either of\nthese scenarios. The types of models discussed could arise as possible field\npoint limit of certain Type IIB orientifold string models.\n\n", "human_text": "  A overview is given of the recent developments in the $U(1)_X$ Stueckelberg\nextensions of the Standard Model and of MSSM where all the Standard Model\nparticles are neutral under the $U(1)_X$ but an axion which is absorbed is\ncharged under both $U(1)_X$ and $U(1)_Y$ and acts as the connector field\ncoupling the Standard Model sector with the Stueckelberg sector. Coupled with\nthe usual Higgs mechanism that breaks the $SU(2)_L\\times U(1)_Y$ gauge\nsymmetry, this scenario produces mixings in the neutral gauge boson sector\ngenerating an extra $Z'$ boson. The couplings of the extra $Z'$ to the Standard\nModel particles are milli weak but its couplings to the hidden sector matter,\ndefined as matter that couples only to the gauge field of $U(1)_X$, can be of\nnormal electro-weak strength. It is shown that such extensions, aside from the\npossibility of leading to a sharp $Z' $ resonance, lead to two new types of\ndark matter: milli weak (or extra weak) and milli charged. An analysis of the\nrelic density shows that the WMAP-3 constraints can be satisfied for either of\nthese scenarios. The types of models discussed could arise as possible field\npoint limit of certain Type IIB orientifold string models.\n", "machine_text": "This article explores the Stueckelberg extension of the Standard Model and MSSM, which includes an axion connecting the Standard Model and Stueckelberg sectors when combined with the usual Higgs mechanism. As a result, an extra $Z'$ boson is created with interactions that are a fraction weaker than the Standard Model's, yet of regular electro-weak strength with hidden sector matter. It is demonstrated how this structure can satisfy WMAP-3 constraints and lead to two distinct dark matter forms: milli weak and milli charged. Furthermore, this could arise as the field point limit of certain Type IIB orientifold string models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2924}
{"prompt": "Rephrase the abstract of an article with title 'The continuum radio emission from the Sy 1.5 galaxy NGC 5033'.\n  We present new continuum VLA observations of the nearby Sy 1.5 galaxy NGC\n5033, made at 4.9 and 8.4 GHz on 8 April 2003. Combined with VLA archival\nobservations at 1.4 and 4.9 GHz made on 7 August 1993, 29 August 1999, and 31\nOctober 1999, we sample the galaxy radio emission at scales ranging from the\nnuclear regions (<~ 100 pc) to the outer regions of the disk (~ 40 kpc). The\nhigh-resolution VLA images show a core-jet structure for the Sy 1.5 nucleus.\nWhile the core has a moderately steep non-thermal radio spectrum (S_\\nu ~\n\\nu^\\alpha; \\alpha_{1.5}^{4.9} \\approx -0.4), the inner kpc region shows a\nsteeper spectrum (\\alpha_{1.5}^{8.4} \\approx -0.9). This latter spectrum is\ntypical of galaxies where energy losses are high, indicating that the escape\nrate of cosmic ray electrons in NGC 5033 is low. The nucleus contributes little\nto the total 1.4 GHz radio power of NGC 5033 and, based on the radio to\nfar-infrared (FIR) relation, it appears that the radio and far-infrared\nemission from NGC 5033 are dominated by a starburst that during the last 10 Myr\nproduced stars at a rate of ~2.8 M_sun/yr, yielding a supernova (type Ib/c and\nII) rate of 0.045 #/yr. This supernova rate corresponds to about 1 SN event\nevery 22 yr. Finally, from our deep 8.4 GHz VLA-D image, we suggest the\nexistence of a radio spur in NGC 5033, which could have been due to a hot\nsuperbubble formed as a consequence of sequential supernova explosions\noccurring during the lifetime of a giant molecular cloud.\n\n", "human_text": "  We present new continuum VLA observations of the nearby Sy 1.5 galaxy NGC\n5033, made at 4.9 and 8.4 GHz on 8 April 2003. Combined with VLA archival\nobservations at 1.4 and 4.9 GHz made on 7 August 1993, 29 August 1999, and 31\nOctober 1999, we sample the galaxy radio emission at scales ranging from the\nnuclear regions (<~ 100 pc) to the outer regions of the disk (~ 40 kpc). The\nhigh-resolution VLA images show a core-jet structure for the Sy 1.5 nucleus.\nWhile the core has a moderately steep non-thermal radio spectrum (S_\\nu ~\n\\nu^\\alpha; \\alpha_{1.5}^{4.9} \\approx -0.4), the inner kpc region shows a\nsteeper spectrum (\\alpha_{1.5}^{8.4} \\approx -0.9). This latter spectrum is\ntypical of galaxies where energy losses are high, indicating that the escape\nrate of cosmic ray electrons in NGC 5033 is low. The nucleus contributes little\nto the total 1.4 GHz radio power of NGC 5033 and, based on the radio to\nfar-infrared (FIR) relation, it appears that the radio and far-infrared\nemission from NGC 5033 are dominated by a starburst that during the last 10 Myr\nproduced stars at a rate of ~2.8 M_sun/yr, yielding a supernova (type Ib/c and\nII) rate of 0.045 #/yr. This supernova rate corresponds to about 1 SN event\nevery 22 yr. Finally, from our deep 8.4 GHz VLA-D image, we suggest the\nexistence of a radio spur in NGC 5033, which could have been due to a hot\nsuperbubble formed as a consequence of sequential supernova explosions\noccurring during the lifetime of a giant molecular cloud.\n", "machine_text": "\nObservations made using the Very Large Array at 1.4 and 4.9 GHz on 8 April 2003 and 7 August 1993, 29 August 1999, and 31 October 1999 indicate the presence of a core-jet structure in the Sy 1.5 galaxy NGC 5033. At the nucleus, the radio spectrum is moderately steep. Further away, in the inner kpc region, a steeper spectrum was detected, which is typical of galaxies where high energy losses are experienced. This suggests that the escape rate of cosmic ray electrons from NGC 5033 may be low. An analysis of the radio to far infrared relation revealed that the radio and far infrared emission from NGC 5033 are likely driven by a starburst event over the past 10 million years, with a supernova type Ib/c and II rate of 0.045 per year. A deep 8.4 GHz VLA-D image also pointed to the possible existence of a radio spur in NGC 5033, possibly as a result of hot superbubbles caused by successive supernovae in a giant molecular cloud.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0918}
{"prompt": "Rephrase the abstract of an article with title 'Spectral analysis of Swift long GRBs with known redshift'.\n  We study the spectral and energetics properties of 47 long-duration gamma-ray\nbursts (GRBs) with known redshift, all of them detected by the Swift satellite.\nDue to the narrow energy range (15-150 keV) of the Swift-BAT detector, the\nspectral fitting is reliable only for fitting models with 2 or 3 parameters. As\nhigh uncertainty and correlation among the errors is expected, a careful\nanalysis of the errors is necessary. We fit both the power law (PL, 2\nparameters) and cut--off power law (CPL, 3 parameters) models to the\ntime-integrated spectra of the 47 bursts, and present the corresponding\nparameters, their uncertainties, and the correlations among the uncertainties.\nThe CPL model is reliable only for 29 bursts for which we estimate the nuf_nu\npeak energy Epk. For these GRBs, we calculate the energy fluence and the rest-\nframe isotropic-equivalent radiated energy, Eiso, as well as the propagated\nuncertainties and correlations among them. We explore the distribution of our\nhomogeneous sample of GRBs on the rest-frame diagram E'pk vs Eiso. We confirm a\nsignificant correlation between these two quantities (the \"Amati\" relation) and\nwe verify that, within the uncertainty limits, no outliers are present. We also\nfit the spectra to a Band model with the high energy power law index frozen to\n-2.3, obtaining a rather good agreement with the \"Amati\" relation of non-Swift\nGRBs.\n\n", "human_text": "  We study the spectral and energetics properties of 47 long-duration gamma-ray\nbursts (GRBs) with known redshift, all of them detected by the Swift satellite.\nDue to the narrow energy range (15-150 keV) of the Swift-BAT detector, the\nspectral fitting is reliable only for fitting models with 2 or 3 parameters. As\nhigh uncertainty and correlation among the errors is expected, a careful\nanalysis of the errors is necessary. We fit both the power law (PL, 2\nparameters) and cut--off power law (CPL, 3 parameters) models to the\ntime-integrated spectra of the 47 bursts, and present the corresponding\nparameters, their uncertainties, and the correlations among the uncertainties.\nThe CPL model is reliable only for 29 bursts for which we estimate the nuf_nu\npeak energy Epk. For these GRBs, we calculate the energy fluence and the rest-\nframe isotropic-equivalent radiated energy, Eiso, as well as the propagated\nuncertainties and correlations among them. We explore the distribution of our\nhomogeneous sample of GRBs on the rest-frame diagram E'pk vs Eiso. We confirm a\nsignificant correlation between these two quantities (the \"Amati\" relation) and\nwe verify that, within the uncertainty limits, no outliers are present. We also\nfit the spectra to a Band model with the high energy power law index frozen to\n-2.3, obtaining a rather good agreement with the \"Amati\" relation of non-Swift\nGRBs.\n", "machine_text": "\nIn this study, 47 gamma-ray bursts (GRBs) that were observed by Swift were analyzed spectrally and energetically. These GRBs all had redshift known, granting better insight into the details of their composition. To begin, models with two and three parameters were used to fit the narrow-range Swift-BAT 15-150 keV detected spectra. A careful analysis of errors and their correlations was done. Further, results from both the power law and cut-off power law models were studied. In addition, energies and their fluences in the rest-frame were calculated for those with the CPL model. This homogeneous sample was compared to the \u201cAmati\u201d relation among non-Swift GRBs, which showed significant correlation between the peak energy E'pk and the radiated energy Eiso. Lastly, a band model with power law index frozen to -2.3 fit was used to further compare to the \u201cAmati\u201d relation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0791}
{"prompt": "Rephrase the abstract of an article with title 'Detection of a 1258 Hz high-amplitude kilohertz quasi-periodic\n  oscillation in the ultra-compact X-ray binary 1A 1246-588'.\n  We have observed the ultra-compact low-mass X-ray binary (LMXB) 1A 1246-588\nwith the Rossi X-ray Timing Explorer (RXTE). In this manuscript we report the\ndiscovery of a kilohertz quasi-periodic oscillation (QPO) in 1A 1246-588. The\nkilohertz QPO was only detected when the source was in a soft high-flux state\nreminiscent of the lower banana branch in atoll sources. Only one kilohertz QPO\npeak is detected at a relatively high frequency of 1258+-2 Hz and at a single\ntrial significance of more than 7 sigma. Kilohertz QPOs with a higher frequency\nhave only been found on two occasions in 4U 0614+09. Furthermore, the frequency\nis higher than that found for the lower kilohertz QPO in any source, strongly\nsuggesting that the QPO is the upper of the kilohertz QPO pair often found in\nLMXBs. The full-width at half maximum is 25+-4 Hz, making the coherence the\nhighest found for an upper kilohertz QPO. From a distance estimate of ~6 kpc\nfrom a radius expansion burst we derive that 1A 1246-588 is at a persistent\nflux of ~0.2-0.3 per cent of the Eddington flux, hence 1A 1246-588 is one of\nthe weakest LMXBs for which a kilohertz QPO has been detected. The\nroot-mean-square (rms) amplitude in the 5-60 keV band is 27+-3 per cent, this\nis the highest for any kilohertz QPO source so far, in line with the general\nanti-correlation between source luminosity and rms amplitude of the kilohertz\nQPO peak identified before. Using the X-ray spectral information we produce a\ncolour-colour diagram. The source behaviour in this diagram provides further\nevidence for the atoll nature of the source.\n\n", "human_text": "  We have observed the ultra-compact low-mass X-ray binary (LMXB) 1A 1246-588\nwith the Rossi X-ray Timing Explorer (RXTE). In this manuscript we report the\ndiscovery of a kilohertz quasi-periodic oscillation (QPO) in 1A 1246-588. The\nkilohertz QPO was only detected when the source was in a soft high-flux state\nreminiscent of the lower banana branch in atoll sources. Only one kilohertz QPO\npeak is detected at a relatively high frequency of 1258+-2 Hz and at a single\ntrial significance of more than 7 sigma. Kilohertz QPOs with a higher frequency\nhave only been found on two occasions in 4U 0614+09. Furthermore, the frequency\nis higher than that found for the lower kilohertz QPO in any source, strongly\nsuggesting that the QPO is the upper of the kilohertz QPO pair often found in\nLMXBs. The full-width at half maximum is 25+-4 Hz, making the coherence the\nhighest found for an upper kilohertz QPO. From a distance estimate of ~6 kpc\nfrom a radius expansion burst we derive that 1A 1246-588 is at a persistent\nflux of ~0.2-0.3 per cent of the Eddington flux, hence 1A 1246-588 is one of\nthe weakest LMXBs for which a kilohertz QPO has been detected. The\nroot-mean-square (rms) amplitude in the 5-60 keV band is 27+-3 per cent, this\nis the highest for any kilohertz QPO source so far, in line with the general\nanti-correlation between source luminosity and rms amplitude of the kilohertz\nQPO peak identified before. Using the X-ray spectral information we produce a\ncolour-colour diagram. The source behaviour in this diagram provides further\nevidence for the atoll nature of the source.\n", "machine_text": "We report the detection of a high-amplitude kilohertz quasi-periodic oscillation (QPO) from the ulta-compact low-mass X-ray binary (LMXB) 1A 1246-588. This QPO was detected when the source was in a soft, high-flux state and had a peak frequency of 1258+-2 Hz and a single trial significance of more than 7 sigma. The coherence and amplitude of this QPO is also higher than has been seen in any other source, suggesting that this is the upper QPO of a kilohertz pair. We estimate that the persistent flux of 1A 1246-588 is ~0.2-0.3 percent of the Eddington flux, making it one of the weakest LMXBs in which a kilohertz QPO has been detected. The root-mean-square (rms) amplitude is extremely high at 27+-3 percent. The colour-colour diagram of the source provides further evidence for its atoll nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1741}
{"prompt": "Rephrase the abstract of an article with title 'Sparticle Spectra and LHC Signatures for Large Volume String\n  Compactifications'.\n  We study the supersymmetric particle spectra and LHC collider observables for\nthe large-volume string models with a fundamental scale of 10^{11} GeV that\narise in moduli-fixed string compactifications with branes and fluxes. The\npresence of magnetic fluxes on the brane world volume, required for chirality,\nperturb the soft terms away from those previously computed in the dilute-flux\nlimit. We use the difference in high-scale gauge couplings to estimate the\nmagnitude of this perturbation and study the potential effects of the magnetic\nfluxes by generating many random spectra with the soft terms perturbed around\nthe dilute flux limit. Even with a 40% variation in the high-scale soft terms\nthe low-energy spectra take a clear and predictive form. The resulting spectra\nare broadly similar to those arising on the SPS1a slope, but more degenerate.\nIn their minimal version the models predict the ratios of gaugino masses to be\nM_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage\nmediation. Among the scalars, the squarks tend to be lighter and the sleptons\nheavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC\ndata for the random spectra in order to study the range of collider\nphenomenology that can occur. We perform a detailed mass reconstruction on one\nexample large-volume string model spectrum. 100 fb^{-1} of integrated\nluminosity is sufficient to discriminate the model from mSUGRA and aspects of\nthe sparticle spectrum can be accurately reconstructed.\n\n", "human_text": "  We study the supersymmetric particle spectra and LHC collider observables for\nthe large-volume string models with a fundamental scale of 10^{11} GeV that\narise in moduli-fixed string compactifications with branes and fluxes. The\npresence of magnetic fluxes on the brane world volume, required for chirality,\nperturb the soft terms away from those previously computed in the dilute-flux\nlimit. We use the difference in high-scale gauge couplings to estimate the\nmagnitude of this perturbation and study the potential effects of the magnetic\nfluxes by generating many random spectra with the soft terms perturbed around\nthe dilute flux limit. Even with a 40% variation in the high-scale soft terms\nthe low-energy spectra take a clear and predictive form. The resulting spectra\nare broadly similar to those arising on the SPS1a slope, but more degenerate.\nIn their minimal version the models predict the ratios of gaugino masses to be\nM_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage\nmediation. Among the scalars, the squarks tend to be lighter and the sleptons\nheavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC\ndata for the random spectra in order to study the range of collider\nphenomenology that can occur. We perform a detailed mass reconstruction on one\nexample large-volume string model spectrum. 100 fb^{-1} of integrated\nluminosity is sufficient to discriminate the model from mSUGRA and aspects of\nthe sparticle spectrum can be accurately reconstructed.\n", "machine_text": "\nWe explore the superparticle spectra and LHC signature outputs for large-scale string models in moduli-fixed string compactifications with branes and fluxes, with a cutting-edge laboratory energy level of 10^{11} GeV. Magnetic fluxes on the brane plane perturb the soft terms away from what was previously computed in the dilute-flux limit. Through an analysis of high-scale gauge couplings, we gauge the active impact of the magnetic fluxes and generate an abundance of random spectra with the soft terms adjusted around the dilute-flux limit. Despite the presence of a 40% variation in the high-scale soft terms, the low-energy spectra exhibit a clear and uniform pattern. The minimal models predict ratios of gaugino masses to be M_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, differing from both mSUGRA and mirage mediation. Squark scalars are lighter and the sleptons heavier than comparable mSUGRA models. We create 10 fb^{-1} of simulated data from the random spectra with which to study the scope of the collider phenomenology, with the example large-volume string model spectrum subjected to a detailed mass reconstruction. With a mere 100 fb^{-1} of integrated luminosity, the model is distinguishable from mSUGRA, and certain aspects of the sparticle spectrum can be accurately reconstructed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3403}
{"prompt": "Rephrase the abstract of an article with title 'A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA\n  Networks with Delay Constraints'.\n  A game-theoretic framework is used to study the effect of constellation size\non the energy efficiency of wireless networks for M-QAM modulation. A\nnon-cooperative game is proposed in which each user seeks to choose its\ntransmit power (and possibly transmit symbol rate) as well as the constellation\nsize in order to maximize its own utility while satisfying its delay\nquality-of-service (QoS) constraint. The utility function used here measures\nthe number of reliable bits transmitted per joule of energy consumed, and is\nparticularly suitable for energy-constrained networks. The best-response\nstrategies and Nash equilibrium solution for the proposed game are derived. It\nis shown that in order to maximize its utility (in bits per joule), a user must\nchoose the lowest constellation size that can accommodate the user's delay\nconstraint. Using this framework, the tradeoffs among energy efficiency, delay,\nthroughput and constellation size are also studied and quantified. The effect\nof trellis-coded modulation on energy efficiency is also discussed.\n\n", "human_text": "  A game-theoretic framework is used to study the effect of constellation size\non the energy efficiency of wireless networks for M-QAM modulation. A\nnon-cooperative game is proposed in which each user seeks to choose its\ntransmit power (and possibly transmit symbol rate) as well as the constellation\nsize in order to maximize its own utility while satisfying its delay\nquality-of-service (QoS) constraint. The utility function used here measures\nthe number of reliable bits transmitted per joule of energy consumed, and is\nparticularly suitable for energy-constrained networks. The best-response\nstrategies and Nash equilibrium solution for the proposed game are derived. It\nis shown that in order to maximize its utility (in bits per joule), a user must\nchoose the lowest constellation size that can accommodate the user's delay\nconstraint. Using this framework, the tradeoffs among energy efficiency, delay,\nthroughput and constellation size are also studied and quantified. The effect\nof trellis-coded modulation on energy efficiency is also discussed.\n", "machine_text": "A game-theoretic perspective is applied to evaluate the influence of the size of a transmission\nconstellation on the energy efficiency of M-QAM modulation in CDMA networks with time-delay specifications. A non-cooperative game provides an environment wherein each user can select the transmission power and possible symbol rate, as well as the constellation size that maximizes their own utility, as long as their Quality-of-Service (QoS) delay requirements are fulfilled. This utility is calculated in terms of reliable bits per energy joule used and makes the framework appropriate for energy-tight networks. The advantageousness of a constellation and the Nash equilibrium, along with best-response strategies, were all determined. Results suggested that the user should choose the smallest constellation that can meet their delay instruction if they want to maximize the utility (bits per joule). This framework also allows for an examination of the relations between energy efficiency, delay, constellation size and throughput and provides understanding for the effect of trellis-coded modulation on energy efficiency.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3878}
{"prompt": "Rephrase the abstract of an article with title 'Ordering phenomena in quasi one-dimensional organic conductors'.\n  Low-dimensional organic conductors could establish themselves as model\nsystems for the investigation of the physics in reduced dimensions. In the\nmetallic state of a one-dimensional solid, Fermi-liquid theory breaks down and\nspin and charge degrees of freedom become separated. But the metallic phase is\nnot stable in one dimension: as the temperature is reduced, the electronic\ncharge and spin tend to arrange themselves in an ordered fashion due to strong\ncorrelations. The competition of the different interactions is responsible for\nwhich broken-symmetry ground state is eventually realized in a specific\ncompound and which drives the system towards an insulating state.\n  Here we review the various ordering phenomena and how they can be identified\nby optic and magnetic measurements. While the final results might look very\nsimilar in the case of a charge density wave and a charge-ordered metal, for\ninstance, the physical cause is completely different. When density waves form,\na gap opens in the density of states at the Fermi energy due to nesting of the\none-dimension Fermi surface sheets. When a one-dimensional metal becomes a\ncharge-ordered Mott insulator, on the other hand, the short-range Coulomb\nrepulsion localizes the charge on the lattice sites and even causes certain\ncharge patterns.\n  We try to point out the similarities and conceptional differences of these\nphenomena and give an example for each of them. Particular emphasis will be put\non collective phenomena which are inherently present as soon as ordering breaks\nthe symmetry of the system.\n\n", "human_text": "  Low-dimensional organic conductors could establish themselves as model\nsystems for the investigation of the physics in reduced dimensions. In the\nmetallic state of a one-dimensional solid, Fermi-liquid theory breaks down and\nspin and charge degrees of freedom become separated. But the metallic phase is\nnot stable in one dimension: as the temperature is reduced, the electronic\ncharge and spin tend to arrange themselves in an ordered fashion due to strong\ncorrelations. The competition of the different interactions is responsible for\nwhich broken-symmetry ground state is eventually realized in a specific\ncompound and which drives the system towards an insulating state.\n  Here we review the various ordering phenomena and how they can be identified\nby optic and magnetic measurements. While the final results might look very\nsimilar in the case of a charge density wave and a charge-ordered metal, for\ninstance, the physical cause is completely different. When density waves form,\na gap opens in the density of states at the Fermi energy due to nesting of the\none-dimension Fermi surface sheets. When a one-dimensional metal becomes a\ncharge-ordered Mott insulator, on the other hand, the short-range Coulomb\nrepulsion localizes the charge on the lattice sites and even causes certain\ncharge patterns.\n  We try to point out the similarities and conceptional differences of these\nphenomena and give an example for each of them. Particular emphasis will be put\non collective phenomena which are inherently present as soon as ordering breaks\nthe symmetry of the system.\n", "machine_text": "  This review provides an overview of the ordering phenomena in quasi one-dimensional organic conductors and how they can be identified through optical and magnetic measurements. It focuses on the differences between charge density waves and charge-ordered metal and gives an example of each type. It also emphasizes the collective effects that arise when the symmetry of a system is broken by ordering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2135}
{"prompt": "Rephrase the abstract of an article with title 'Affine Structures on a Ringed Space and Schemes'.\n  In this paper we will first introduce the notion of affine structures on a\nringed space and then obtain several properties. Affine structures on a ringed\nspace, arising mainly from complex analytical spaces of algebraic schemes over\nnumber fields, behave like differential structures on a smooth manifold.\n  As one does for differential manifolds, we will use pseudogroups of affine\ntransformations to define affine atlases on a ringed space. An atlas on a space\nis said to be an affine structure if it is maximal. An affine structure is\nadmissible if there is a sheaf on the underlying space such that they are\ncoincide on all affine charts, which are in deed affine open sets of a scheme.\nIn a rigour manner, a scheme is defined to be a ringed space with a specified\naffine structure if the affine structures are in action in some special cases\nsuch as analytical spaces of algebraic schemes. Particularly, by the whole of\naffine structures on a space, we will obtain respectively necessary and\nsufficient conditions that two spaces are homeomorphic and that two schemes are\nisomorphic, which are the two main theorems of the paper. It follows that the\nwhole of affine structures on a space and a scheme, as local data, encode and\nreflect the global properties of the space and the scheme, respectively.\n\n", "human_text": "  In this paper we will first introduce the notion of affine structures on a\nringed space and then obtain several properties. Affine structures on a ringed\nspace, arising mainly from complex analytical spaces of algebraic schemes over\nnumber fields, behave like differential structures on a smooth manifold.\n  As one does for differential manifolds, we will use pseudogroups of affine\ntransformations to define affine atlases on a ringed space. An atlas on a space\nis said to be an affine structure if it is maximal. An affine structure is\nadmissible if there is a sheaf on the underlying space such that they are\ncoincide on all affine charts, which are in deed affine open sets of a scheme.\nIn a rigour manner, a scheme is defined to be a ringed space with a specified\naffine structure if the affine structures are in action in some special cases\nsuch as analytical spaces of algebraic schemes. Particularly, by the whole of\naffine structures on a space, we will obtain respectively necessary and\nsufficient conditions that two spaces are homeomorphic and that two schemes are\nisomorphic, which are the two main theorems of the paper. It follows that the\nwhole of affine structures on a space and a scheme, as local data, encode and\nreflect the global properties of the space and the scheme, respectively.\n", "machine_text": "  In this article, we investigate affine structures on a ringed space and schemes. We explore the behavior of affine structures on a space resulting from analytical spaces of algebraic schemes over number fields. Pseudogroups of affine transformations are utilized to define affine atlases on a space, and maximal atlas will determine an affine structure. Admissible affine structures can be recognized by the coincidence of a sheaf on the underlying space. We give necessary and sufficient conditions for two spaces to be homeomorphic and two schemes to be isomorphic using the affine structures as local data. The global properties of the space and the scheme are encoded and reflected through their respective affine structures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0579}
{"prompt": "Rephrase the abstract of an article with title 'Chaos and Symmetry in String Cosmology'.\n  We review the recently discovered interplay between chaos and symmetry in the\ngeneral inhomogeneous solution of many string-related Einstein-matter systems\nin the vicinity of a cosmological singularity. The\nBelinsky-Khalatnikov-Lifshitz-type chaotic behaviour is found, for many\nEinstein-matter models (notably those related to the low-energy limit of\nsuperstring theory and M-theory), to be connected with certain\n(infinite-dimensional) hyperbolic Kac-Moody algebras. In particular, the\nbilliard chambers describing the asymptotic cosmological behaviour of pure\nEinstein gravity in spacetime dimension d+1, or the metric-three-form system of\n11-dimensional supergravity, are found to be identical to the Weyl chambers of\nthe Lorentzian Kac-Moody algebras AE_d, or E_{10}, respectively. This suggests\nthat these Kac-Moody algebras are hidden symmetries of the corresponding\nmodels. There even exists some evidence of a hidden equivalence between the\ngeneral solution of the Einstein-three-form system and a null geodesic in the\ninfinite dimensional coset space E_{10} / K(E_{10}), where K(E_{10}) is the\nmaximal compact subgroup of E_{10}.\n\n", "human_text": "  We review the recently discovered interplay between chaos and symmetry in the\ngeneral inhomogeneous solution of many string-related Einstein-matter systems\nin the vicinity of a cosmological singularity. The\nBelinsky-Khalatnikov-Lifshitz-type chaotic behaviour is found, for many\nEinstein-matter models (notably those related to the low-energy limit of\nsuperstring theory and M-theory), to be connected with certain\n(infinite-dimensional) hyperbolic Kac-Moody algebras. In particular, the\nbilliard chambers describing the asymptotic cosmological behaviour of pure\nEinstein gravity in spacetime dimension d+1, or the metric-three-form system of\n11-dimensional supergravity, are found to be identical to the Weyl chambers of\nthe Lorentzian Kac-Moody algebras AE_d, or E_{10}, respectively. This suggests\nthat these Kac-Moody algebras are hidden symmetries of the corresponding\nmodels. There even exists some evidence of a hidden equivalence between the\ngeneral solution of the Einstein-three-form system and a null geodesic in the\ninfinite dimensional coset space E_{10} / K(E_{10}), where K(E_{10}) is the\nmaximal compact subgroup of E_{10}.\n", "machine_text": "\n\nIn this article, we examine the intricate relationship between chaos and symmetry demonstrated by the inhomogeneous solutions of Einstein-matter systems associated with string theory and M-theory. Using the Belinsky-Khalatnikov-Lifshitz framework, we determine the extent of the chaotic behavior of these systems near the cosmological singularity. Our analysis reveals a connection between the chaotic settings arising from the respective systems and certain infinite-dimensional hyperbolic Kac-Moody algebras. We find that the billiard chambers describing the asymptotic cosmological behavior of Einstein gravity in d+1 dimensions and the metric-three-form system of 11-dimensional supergravity are the same as the Weyl chambers of the Lorentzian Kac-Moody algebras AE_d and E_{10}, respectively. This bolsters the idea that these Kac-Moody algebras serve as hidden symmetries of the corresponding models. Moreover, there is some evidence of a hidden similarity between the general solution of the Einstein-three-form system and a null geodesic in the infinite dimensional E_{10} / K(E_{10}) coset space.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1457}
{"prompt": "Rephrase the abstract of an article with title 'Applicability of layered sine-Gordon models to layered superconductors:\n  II. The case of magnetic coupling'.\n  In this paper, we propose a quantum field theoretical renormalization group\napproach to the vortex dynamics of magnetically coupled layered\nsuperconductors, to supplement our earlier investigations on the\nJosephson-coupled case. We construct a two-dimensional multi-layer sine-Gordon\ntype model which we map onto a gas of topological excitations. With a special\nchoice of the mass matrix for our field theoretical model, vortex dominated\nproperties of magnetically coupled layered superconductors can be described.\nThe well known interaction potentials of fractional flux vortices are\nconsistently obtained from our field-theoretical analysis, and the physical\nparameters (vortex fugacity and temperature parameter) are also identified. We\nanalyse the phase structure of the multi-layer sine--Gordon model by a\ndifferential renormalization group method for the magnetically coupled case\nfrom first principles. The dependence of the transition temperature on the\nnumber of layers is found to be in agreement with known results based on other\nmethods.\n\n", "human_text": "  In this paper, we propose a quantum field theoretical renormalization group\napproach to the vortex dynamics of magnetically coupled layered\nsuperconductors, to supplement our earlier investigations on the\nJosephson-coupled case. We construct a two-dimensional multi-layer sine-Gordon\ntype model which we map onto a gas of topological excitations. With a special\nchoice of the mass matrix for our field theoretical model, vortex dominated\nproperties of magnetically coupled layered superconductors can be described.\nThe well known interaction potentials of fractional flux vortices are\nconsistently obtained from our field-theoretical analysis, and the physical\nparameters (vortex fugacity and temperature parameter) are also identified. We\nanalyse the phase structure of the multi-layer sine--Gordon model by a\ndifferential renormalization group method for the magnetically coupled case\nfrom first principles. The dependence of the transition temperature on the\nnumber of layers is found to be in agreement with known results based on other\nmethods.\n", "machine_text": "\nThis paper examines the feasibility of a two-dimensional multi-layer sine-Gordon model to describe the vortex dynamics of magnetically coupled layered superconductors. We apply a quantum field theoretical renormalization group approach to study the phase structure of the model, with parameters that include the vortex fugacity and temperature. Results from this analysis correspond to the interaction potentials and transition temperatures expected for fractional flux vortices, and agree with previously established theoretical evidence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0578}
{"prompt": "Rephrase the abstract of an article with title 'Spitzer Quasar and ULIRG Evolution Study (QUEST): II. The Spectral\n  Energy Distributions of Palomar-Green Quasars'.\n  This is the second paper studying the QSOs in the spitzer QUEST sample.\nPreviously we presented new PAH measurements and argued that most of the\nobserved far infrared (FIR) radiation is due to star-forming activity. Here we\npresent spectral energy distributions (SEDs) by supplementing our data with\noptical, NIR and FIR observations. We define two sub-groups of ``weak FIR'' and\n``strong FIR'' QSOs, and a third group of FIR non-detections. Assuming a\nstarburst origin for the FIR, we obtain ``intrinsic'' AGN SEDs by subtracting a\nstarburst template from the mean SEDs. The resulting SEDs are remarkably\nsimilar for all groups. They show three distinct peaks corresponding to two\nsilicate emission features and a 3mic bump that we interpret as the signature\nof the hottest AGN dust. They also display drops beyond 20mic that we interpret\nas the signature of the minimum temperature (about 200K) dust. This component\nmust be optically thin to explain the silicate emission and the slope of the\nlong wavelength continuum. We discuss the merits of an alternative model where\nmost of the FIR emission is due to AGN heating. Such models are unlikely to\nexplain the properties of our QSOs but they cannot be ruled out for more\nluminous objects. We also find correlations between the luminosity at 5100A and\ntwo infrared starburst indicators: L(60mic) and L(PAH 7.7mic). The correlation\nof L(5100A) with L(60mic) can be used to measure the relative growth rates and\nlifetimes of the black hole and the new stars.\n\n", "human_text": "  This is the second paper studying the QSOs in the spitzer QUEST sample.\nPreviously we presented new PAH measurements and argued that most of the\nobserved far infrared (FIR) radiation is due to star-forming activity. Here we\npresent spectral energy distributions (SEDs) by supplementing our data with\noptical, NIR and FIR observations. We define two sub-groups of ``weak FIR'' and\n``strong FIR'' QSOs, and a third group of FIR non-detections. Assuming a\nstarburst origin for the FIR, we obtain ``intrinsic'' AGN SEDs by subtracting a\nstarburst template from the mean SEDs. The resulting SEDs are remarkably\nsimilar for all groups. They show three distinct peaks corresponding to two\nsilicate emission features and a 3mic bump that we interpret as the signature\nof the hottest AGN dust. They also display drops beyond 20mic that we interpret\nas the signature of the minimum temperature (about 200K) dust. This component\nmust be optically thin to explain the silicate emission and the slope of the\nlong wavelength continuum. We discuss the merits of an alternative model where\nmost of the FIR emission is due to AGN heating. Such models are unlikely to\nexplain the properties of our QSOs but they cannot be ruled out for more\nluminous objects. We also find correlations between the luminosity at 5100A and\ntwo infrared starburst indicators: L(60mic) and L(PAH 7.7mic). The correlation\nof L(5100A) with L(60mic) can be used to measure the relative growth rates and\nlifetimes of the black hole and the new stars.\n", "machine_text": "\nIn this second paper on the QUEST sample of Quasars (QSOs), we focus on their Spectral Energy Distributions (SEDs). We supplement our data with observations in optical, NIR and FIR. We identify two categories of QSOs as \u201cweak FIR\u201d and \u201cstrong FIR\u201d and a third category of QSOs without FIR detections. We assume the far infrared (FIR) emission is primarily due to star-forming activity and are able to remove a starburst template from the mean SED to obtain an \u201cintrinsic\u201d SED for the AGNs. The resulting SEDs for all 3 groups show the same three distinct peaks, two silicate emission features and a 3mic bump. We interpret these as the signature of the hottest AGN dust. Additionally, drops beyond 20mic are observed, which we interpret as the signature of the minimum temperature (approximately 200K) dust. We analyze the merits of an alternative model where most of the FIR is due to AGN heating and discuss the correlations between luminosity at 5100A and two infrared starburst indicators: L(60mic) and L(PAH 7.7mic).  This can be used to measure the relative growth rates and lifetimes of the black hole and the new stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0818}
{"prompt": "Rephrase the abstract of an article with title 'A Catalog of Star Cluster Candidates in M33'.\n  We present a new catalog of star cluster candidates in the nearby spiral\ngalaxy M33. It is based on eight existing catalogs wherein we have\ncross-referenced identifications and endeavored to resolve inconsistencies\nbetween them. Our catalog contains 451 candidates of which 255 are confirmed\nclusters based on HST and high resolution ground-based imaging. The catalog\ncontains precise cluster positions (RA and Dec), magnitudes and colors in the\nUBVRIJHKs filters, metallicities, radial velocities, masses and ages, where\navailable, and galactocentric distances for each cluster. The color\ndistribution of the M33 clusters appears to be similar to those in the Large\nMagellanic Cloud with major peaks at (B-V)o~0.15, and (B-V)o~0.65. The\nintrinsic colors are correlated with cluster ages, which range from 10^{7.5} to\n10^{10.3} years. The age distribution of the star clusters supports the notion\nof rapid cluster disruption with a slope of alpha=-1.09 +/- 0.07 in the\ndN_{cluster}/dt ~ t^{alpha} relation. In addition, comparison to theoretical\nsingle stellar population models suggests the presence of an age-metallicity\nrelation among these clusters with younger clusters being more metal-rich.\nAnalysis of the radial distribution of the clusters yields some evidence that\nyounger clusters (age <~ 1 Gyr) may be more concentrated toward the center of\nM33 than older ones. A similar comparison with the radial profile of the M33\nfield stars shows the clusters to be more centrally concentrated at the greater\nthan 99.9% confidence level. Possible reasons for this are presented and\ndiscussed; however, the overwhelming conclusion seems to be that a more\ncomplete and thorough cluster search is needed covering at least 4 square\ndegrees centered on M33.\n\n", "human_text": "  We present a new catalog of star cluster candidates in the nearby spiral\ngalaxy M33. It is based on eight existing catalogs wherein we have\ncross-referenced identifications and endeavored to resolve inconsistencies\nbetween them. Our catalog contains 451 candidates of which 255 are confirmed\nclusters based on HST and high resolution ground-based imaging. The catalog\ncontains precise cluster positions (RA and Dec), magnitudes and colors in the\nUBVRIJHKs filters, metallicities, radial velocities, masses and ages, where\navailable, and galactocentric distances for each cluster. The color\ndistribution of the M33 clusters appears to be similar to those in the Large\nMagellanic Cloud with major peaks at (B-V)o~0.15, and (B-V)o~0.65. The\nintrinsic colors are correlated with cluster ages, which range from 10^{7.5} to\n10^{10.3} years. The age distribution of the star clusters supports the notion\nof rapid cluster disruption with a slope of alpha=-1.09 +/- 0.07 in the\ndN_{cluster}/dt ~ t^{alpha} relation. In addition, comparison to theoretical\nsingle stellar population models suggests the presence of an age-metallicity\nrelation among these clusters with younger clusters being more metal-rich.\nAnalysis of the radial distribution of the clusters yields some evidence that\nyounger clusters (age <~ 1 Gyr) may be more concentrated toward the center of\nM33 than older ones. A similar comparison with the radial profile of the M33\nfield stars shows the clusters to be more centrally concentrated at the greater\nthan 99.9% confidence level. Possible reasons for this are presented and\ndiscussed; however, the overwhelming conclusion seems to be that a more\ncomplete and thorough cluster search is needed covering at least 4 square\ndegrees centered on M33.\n", "machine_text": "\nThis paper presents a catalog of 451 star cluster candidates in M33, 255 of which have been confirmed through HST and high resolution ground-based imaging. Our catalog includes precise data for each cluster such as positions, magnitudes and colors, metallicities, radial velocities, masses and ages, and galactocentric distances. The color distribution of the M33 clusters appears similar to those of the large Magellanic Cloud, where major peaks are located at B-V of 0.15 and 0.65. Additionally, results from this analysis indicate a correlation between the clusters' ages and intrinsic colors with younger clusters tending to be more metal-rich. The radial profile of the M33 clusters is also more concentrated than that of the field stars, suggesting that a more comprehensive search of the area is needed; we discuss potential reasons for this conclusion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1576}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical models with a general anisotropy profile'.\n  Both numerical simulations and observational evidence indicate that the outer\nregions of galaxies and dark matter haloes are typically mildly to\nsignificantly radially anisotropic. The inner regions can be significantly\nnon-isotropic, depending on the dynamical formation and evolution processes. In\nan attempt to break the lack of simple dynamical models that can reproduce this\nbehaviour, we explore a technique to construct dynamical models with an\narbitrary density and an arbitrary anisotropy profile. We outline a general\nconstruction method and propose a more practical approach based on a\nparameterized anisotropy profile. This approach consists of fitting the density\nof the model with a set of dynamical components, each of which have the same\nanisotropy profile. Using this approach we avoid the delicate fine-tuning\ndifficulties other fitting techniques typically encounter when constructing\nradially anisotropic models. We present a model anisotropy profile that\ngeneralizes the Osipkov-Merritt profile, and that can represent any smooth\nmonotonic anisotropy profile. Based on this model anisotropy profile, we\nconstruct a very general seven-parameter set of dynamical components for which\nthe most important dynamical properties can be calculated analytically. We use\nthe results to look for simple one-component dynamical models that generate\nsimple potential-density pairs while still supporting a flexible anisotropy\nprofile. We present families of Plummer and Hernquist models in which the\nanisotropy at small and large radii can be chosen as free parameters. We also\ngeneralize these two families to a three-parameter family that\nself-consistently generates the set of Veltmann potential-density pairs.\n(Abridged...)\n\n", "human_text": "  Both numerical simulations and observational evidence indicate that the outer\nregions of galaxies and dark matter haloes are typically mildly to\nsignificantly radially anisotropic. The inner regions can be significantly\nnon-isotropic, depending on the dynamical formation and evolution processes. In\nan attempt to break the lack of simple dynamical models that can reproduce this\nbehaviour, we explore a technique to construct dynamical models with an\narbitrary density and an arbitrary anisotropy profile. We outline a general\nconstruction method and propose a more practical approach based on a\nparameterized anisotropy profile. This approach consists of fitting the density\nof the model with a set of dynamical components, each of which have the same\nanisotropy profile. Using this approach we avoid the delicate fine-tuning\ndifficulties other fitting techniques typically encounter when constructing\nradially anisotropic models. We present a model anisotropy profile that\ngeneralizes the Osipkov-Merritt profile, and that can represent any smooth\nmonotonic anisotropy profile. Based on this model anisotropy profile, we\nconstruct a very general seven-parameter set of dynamical components for which\nthe most important dynamical properties can be calculated analytically. We use\nthe results to look for simple one-component dynamical models that generate\nsimple potential-density pairs while still supporting a flexible anisotropy\nprofile. We present families of Plummer and Hernquist models in which the\nanisotropy at small and large radii can be chosen as free parameters. We also\ngeneralize these two families to a three-parameter family that\nself-consistently generates the set of Veltmann potential-density pairs.\n(Abridged...)\n", "machine_text": "\nWe present a method of constructing dynamical models with an arbitrary density and anisotropy profile in order to reproduce observed radial anisotropy in galaxies and dark matter haloes. A parameterized anisotropy profile is proposed, which generalizes the Osipkov-Merritt profile and can represent any smooth monotonic anisotropy profile. Using the proposed model, a seven-parameter set of dynamical components can be constructed and dynamical properties can be calculated analytically. Through the study of simple one-component dynamical models, we construct families of Plummer and Hernquist models which include flexible anisotropy profiles of small and large radii as potntial parameters. In addition, a three-parameter family generalizes these models, generating Veltmann potential-density pairs self-consistently.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4109}
{"prompt": "Rephrase the abstract of an article with title 'Two branches of neutron stars - reconciling a 2M_sun pulsar and SN1987A'.\n  The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the\nmaximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max,\ndue to a kaon condensation in the stellar core, implies collapse of a too\nmassive deleptonized protoneutron star into a black hole. This would naturally\nexplain the lack of a neutron star in the SN1987A remnant. On the other hand,\nrecent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This\ncontradicts the original Bethe-Brown model, but can be reconciled within\nscenarios proposed in the present Letter. We consider two types of dense matter\nmodels with high-density softening, due to a transition from a non-strange\nN-phase of matter to a strangeness carrying phase S: kaon condensation and\ndeconfinement of quarks. Two scenarios of neutron star formation in stellar\ncore collapse are considered. In the first scenario, realized in sufficiently\nhot and dense supernova cores, nucleation of an S-phase is sufficiently rapid\nso as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the\nsecond scenario, nucleation of the S-phase at neutron star birth is too slow to\nmaterialize, and the star becomes cold without forming an S-phase core. Then,\nstellar mass can increase via accretion, until central density \\rho_crit is\nreached, and the S phase forms. This N branch of neutron stars ends at\nM=M_crit. We select several models of N-phase satifying the necessary condition\nM^N_max > 2M_sun and combine them with models of kaon condensation and quark\ndeconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun,\nwhich is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark\ndeconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and\nPSR J0751+1807.\n\n", "human_text": "  The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the\nmaximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max,\ndue to a kaon condensation in the stellar core, implies collapse of a too\nmassive deleptonized protoneutron star into a black hole. This would naturally\nexplain the lack of a neutron star in the SN1987A remnant. On the other hand,\nrecent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This\ncontradicts the original Bethe-Brown model, but can be reconciled within\nscenarios proposed in the present Letter. We consider two types of dense matter\nmodels with high-density softening, due to a transition from a non-strange\nN-phase of matter to a strangeness carrying phase S: kaon condensation and\ndeconfinement of quarks. Two scenarios of neutron star formation in stellar\ncore collapse are considered. In the first scenario, realized in sufficiently\nhot and dense supernova cores, nucleation of an S-phase is sufficiently rapid\nso as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the\nsecond scenario, nucleation of the S-phase at neutron star birth is too slow to\nmaterialize, and the star becomes cold without forming an S-phase core. Then,\nstellar mass can increase via accretion, until central density \\rho_crit is\nreached, and the S phase forms. This N branch of neutron stars ends at\nM=M_crit. We select several models of N-phase satifying the necessary condition\nM^N_max > 2M_sun and combine them with models of kaon condensation and quark\ndeconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun,\nwhich is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark\ndeconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and\nPSR J0751+1807.\n", "machine_text": "\nThis study examines the discord between SN1987A and the confirmed pulsar PSR J0751+1807, which suggests a maximum mass of cold neutron stars of 1.5M_sun due to kaon condensing in the stellar core. In contrast, the evaluation of PSR J0751+1807 gives a value greater than 2M_sun. Through evaluation of two models of dense matter with high-density softening, kaon condensation and deconfinement of quarks, this research proposes two scenarios of neutron star formation. In the first, the S-phase forms rapidly in the supernova core, giving a maximum mass of 1.5M_sun, which is invalidated by PSR J0751+1807. In the second, nucleation of the S-phase at neutron star birth is too slow and it remains a non-strange N-phase. Consequently, stellar mass can increase beyond the critical value of 2M_sun via accretion. This N-phase model reconciles SN1987A and PSR J0751+1807, resolving the existing conflict between the two.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4594}
{"prompt": "Rephrase the abstract of an article with title 'Construction of type ${\\rm II_1}$ factors with prescribed countable\n  fundamental group'.\n  In the context of Free Probability Theory, we study two different\nconstructions that provide new examples of factors of type ${\\rm II_1}$ with\nprescribed fundamental group. First we investigate state-preserving group\nactions on the almost periodic free Araki-Woods factors satisfying both a\ncondition of mixing and a condition of free malleability in the sense of Popa.\nTypical examples are given by the free Bogoliubov shifts. Take an ICC $w$-rigid\ngroup $G$ such that $\\mathcal{F}(L(G)) = \\{1\\}$ (e.g. $G = \\Z^2 \\rtimes \\SL(2,\n\\Z)$). For any countable subgroup $S \\subset \\R^*_+$, we show that there exists\nan action of $G$ on $L(\\F_\\infty)$ such that $L(\\F_\\infty) \\rtimes G$ is a type\n${\\rm II_1}$ factor and its fundamental group is $S$. The second construction\nis based on a free product. Take $(B(H), \\psi)$ any factor of type ${\\rm I}$\nendowed with a faithful normal state and denote by $\\Gamma \\subset \\R^*_+$ the\nsubgroup generated by the point spectrum of $\\psi$. We show that the\ncentralizer $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ is a type ${\\rm II_1}$ factor\nand its fundamental group is $\\Gamma$. Our proofs rely on Popa's\ndeformation/rigidity strategy using his intertwining-by-bimodules technique.\n\n", "human_text": "  In the context of Free Probability Theory, we study two different\nconstructions that provide new examples of factors of type ${\\rm II_1}$ with\nprescribed fundamental group. First we investigate state-preserving group\nactions on the almost periodic free Araki-Woods factors satisfying both a\ncondition of mixing and a condition of free malleability in the sense of Popa.\nTypical examples are given by the free Bogoliubov shifts. Take an ICC $w$-rigid\ngroup $G$ such that $\\mathcal{F}(L(G)) = \\{1\\}$ (e.g. $G = \\Z^2 \\rtimes \\SL(2,\n\\Z)$). For any countable subgroup $S \\subset \\R^*_+$, we show that there exists\nan action of $G$ on $L(\\F_\\infty)$ such that $L(\\F_\\infty) \\rtimes G$ is a type\n${\\rm II_1}$ factor and its fundamental group is $S$. The second construction\nis based on a free product. Take $(B(H), \\psi)$ any factor of type ${\\rm I}$\nendowed with a faithful normal state and denote by $\\Gamma \\subset \\R^*_+$ the\nsubgroup generated by the point spectrum of $\\psi$. We show that the\ncentralizer $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ is a type ${\\rm II_1}$ factor\nand its fundamental group is $\\Gamma$. Our proofs rely on Popa's\ndeformation/rigidity strategy using his intertwining-by-bimodules technique.\n", "machine_text": "\nThis article explores two separate constructions of type ${\\rm II_1}$ factors having a prescribed countable fundamental group. The first involves group actions on almost periodic free Araki-Woods factors that meet two conditions: mixing and free malleability, as defined by Popa. When the group $G$ chosen is an ICC $w$-rigid group with trivial centralizer (e.g. $G = \\Z^2 \\rtimes \\SL(2,\\Z)$), there will be an action on $L(\\F_\\infty)$ that forms a type ${\\rm II_1}$ factor with fundamental group $S$, where $S$ is an arbitrary countable subgroup of $\\R^*_+$. The other construction involves a free product of factors, such that for a factor $B(H)$ of type ${\\rm I}$ with a normal faithful state $\\psi$, the centralizer of the free product $(L(G) \\ast B(H))^{\\tau \\ast \\psi}$ turns out to be a type ${\\rm II_1}$ factor with fundamental group $\\Gamma$, which is the subgroup of $\\R^*_+$ generated by the point spectrum of $\\psi$. The techniques of Popa's deformation/rigidity strategy and intertwining- by -bimodules are the main instruments for the proof.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3502}
{"prompt": "Rephrase the abstract of an article with title 'INTEGRAL high energy monitoring of the X-ray burster KS 1741-293'.\n  KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module\nof the Mir space station and identified as an X-ray burster, has not been\ndetected in the hard X band until the advent of the INTEGRAL observatory.\nMoreover this source has been recently object of scientific discussion, being\nalso associated to a nearby extended radio source that in principle could be\nthe supernova remnant produced by the accretion induced collapse in the binary\nsystem. Our long term monitoring with INTEGRAL, covering the period from\nFebruary 2003 to May 2005, confirms that KS 1741-293 is transient in soft and\nhard X band. When the source is active, from a simultaneous JEM-X and IBIS data\nanalysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by\na two component model, a multiple blackbody for the soft emission and a\nComptonized or a cut-off power law model for the hard component. Finally, by\nthe detection of two X-ray bursters with JEM-X, we confirm the bursting nature\nof KS 1741-293, including this source in the class of the hard tailed X-ray\nbursters.\n\n", "human_text": "  KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module\nof the Mir space station and identified as an X-ray burster, has not been\ndetected in the hard X band until the advent of the INTEGRAL observatory.\nMoreover this source has been recently object of scientific discussion, being\nalso associated to a nearby extended radio source that in principle could be\nthe supernova remnant produced by the accretion induced collapse in the binary\nsystem. Our long term monitoring with INTEGRAL, covering the period from\nFebruary 2003 to May 2005, confirms that KS 1741-293 is transient in soft and\nhard X band. When the source is active, from a simultaneous JEM-X and IBIS data\nanalysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by\na two component model, a multiple blackbody for the soft emission and a\nComptonized or a cut-off power law model for the hard component. Finally, by\nthe detection of two X-ray bursters with JEM-X, we confirm the bursting nature\nof KS 1741-293, including this source in the class of the hard tailed X-ray\nbursters.\n", "machine_text": "\nThe INTEGRAL observatory's high-energy monitoring of the X-ray burster KS 1741-293 has revealed that this source is transient in the soft and hard X bands. The time period examined being February 2003 - May 2005, a two component model has successfully fit the JEM-X and IBIS data from 5 - 100 keV. This includes a multiple blackbody for the soft emission and a cut-off power law model for the hard component. The data has contributed to a new classification for KS 1741-293, confirming its identity as a hard-tailed X-ray burster.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0832}
{"prompt": "Rephrase the abstract of an article with title 'c2d Spitzer IRS Spectra of Disks around T Tauri Stars. III. [Ne II], [Fe\n  I], and H_2 gas-phase lines'.\n  We present a survey of mid-infrared gas-phase lines toward a sample of 76\ncircumstellar disks around low mass pre-main sequence stars from the Spitzer\n\"Cores to Disks\" legacy program. We report the first detections of [Ne II] and\n[Fe I] toward classical T Tauri stars in ~20% respectively ~9% of our sources.\nThe observed [Ne II] line fluxes and upper limits are consistent with [Ne II]\nexcitation in an X-ray irradiated disk around stars with X-ray luminosities\nL_X=10^{29}-10^{31} erg s^{-1}. [Fe I] is detected at ~10^-5-10^-4 L_Sun, but\nno [S I] or [Fe II] is detected down to ~10^{-6} L_Sun. The [Fe I] detections\nindicate the presence of gas-rich disks with masses of >~0.1 M_J. No H_2 0-0\nS(0) and S(1) disk emission is detected, except for S(1) toward one source.\nThese data give upper limits on the warm (T~100-200K) gas mass of a few Jovian\nmasses, consistent with recent T Tauri disk models which include gas heating by\nstellar radiation. Compact disk emission of hot (T>~500K) gas is observed\nthrough the H_2 0-0 S(2) and/or S(3) lines toward ~8% of our sources. The line\nfluxes are, however, higher by more than an order of magnitude than those\npredicted by recent disk models, even when X-ray and excess UV radiation are\nincluded. Similarly the [Ne II]/H_2 0-0 S(2) ratios for these sources are lower\nthan predicted, consistent with the presence of an additional hot molecular gas\ncomponent not included in current disk models. Oblique shocks of stellar winds\ninteracting with the disk can explain many aspects of the hot gas emission, but\nare inconsistent with the non-detection of [S I] and [Fe II] lines.\n\n", "human_text": "  We present a survey of mid-infrared gas-phase lines toward a sample of 76\ncircumstellar disks around low mass pre-main sequence stars from the Spitzer\n\"Cores to Disks\" legacy program. We report the first detections of [Ne II] and\n[Fe I] toward classical T Tauri stars in ~20% respectively ~9% of our sources.\nThe observed [Ne II] line fluxes and upper limits are consistent with [Ne II]\nexcitation in an X-ray irradiated disk around stars with X-ray luminosities\nL_X=10^{29}-10^{31} erg s^{-1}. [Fe I] is detected at ~10^-5-10^-4 L_Sun, but\nno [S I] or [Fe II] is detected down to ~10^{-6} L_Sun. The [Fe I] detections\nindicate the presence of gas-rich disks with masses of >~0.1 M_J. No H_2 0-0\nS(0) and S(1) disk emission is detected, except for S(1) toward one source.\nThese data give upper limits on the warm (T~100-200K) gas mass of a few Jovian\nmasses, consistent with recent T Tauri disk models which include gas heating by\nstellar radiation. Compact disk emission of hot (T>~500K) gas is observed\nthrough the H_2 0-0 S(2) and/or S(3) lines toward ~8% of our sources. The line\nfluxes are, however, higher by more than an order of magnitude than those\npredicted by recent disk models, even when X-ray and excess UV radiation are\nincluded. Similarly the [Ne II]/H_2 0-0 S(2) ratios for these sources are lower\nthan predicted, consistent with the presence of an additional hot molecular gas\ncomponent not included in current disk models. Oblique shocks of stellar winds\ninteracting with the disk can explain many aspects of the hot gas emission, but\nare inconsistent with the non-detection of [S I] and [Fe II] lines.\n", "machine_text": "\nIn this study, we have surveyed mid-infrared gas-phase lines in 76 circumstellar disks of low-mass pre-main sequence stars as part of the Spitzer \"Cores to Disks\" program. This is the first detection of [Ne II] and [Fe I] in ~20% and ~9% of these systems, respectively. The [Ne II] line emission suggests that these disks are x-ray-irradiated and the [Fe I] fluxes imply the presence of gas-rich disks with masses > 0.1 M_J. Additionally, H_2 0-0 S(2) and S(3) lines were detected from a few sources at much higher intensities than predicted by current disk models. To explain this emission, we suggest the presence of interceding shocks from a stellar wind is required and cannot be explained by the non-detections of [S I] and [Fe II] lines.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2305}
{"prompt": "Rephrase the abstract of an article with title 'A Cross-disciplinary Framework for the Description of Contextually\n  Mediated Change'.\n  We present a mathematical framework (referred to as Context-driven\nActualization of Potential, or CAP) for describing how entities change over\ntime under the influence of a context. The approach facilitates comparison of\nchange of state of entities studied in different disciplines. Processes are\nseen to differ according to the degree of nondeterminism, and the degree to\nwhich they are sensitive to, internalize, and depend upon a particular context.\nOur analysis suggests that the dynamical evolution of a quantum entity\ndescribed by the Schrodinger equation is not fundamentally different from\nchange provoked by a measurement often referred to as collapse, but a limiting\ncase, with only one way to collapse. The biological transition to coded\nreplication is seen as a means of preserving structure in the fact of\ncontext-driven change, and sextual replication as a means of increasing\npotentiality thus enhancing diversity through interaction with context. The\nframework sheds light on concepts like selection and fitness, reveals how\nexceptional Darwinian evolution is as a means of 'change of state', and\nclarifies in what sense culture, and the creative process underlying it, are\nDarwinian.\n\n", "human_text": "  We present a mathematical framework (referred to as Context-driven\nActualization of Potential, or CAP) for describing how entities change over\ntime under the influence of a context. The approach facilitates comparison of\nchange of state of entities studied in different disciplines. Processes are\nseen to differ according to the degree of nondeterminism, and the degree to\nwhich they are sensitive to, internalize, and depend upon a particular context.\nOur analysis suggests that the dynamical evolution of a quantum entity\ndescribed by the Schrodinger equation is not fundamentally different from\nchange provoked by a measurement often referred to as collapse, but a limiting\ncase, with only one way to collapse. The biological transition to coded\nreplication is seen as a means of preserving structure in the fact of\ncontext-driven change, and sextual replication as a means of increasing\npotentiality thus enhancing diversity through interaction with context. The\nframework sheds light on concepts like selection and fitness, reveals how\nexceptional Darwinian evolution is as a means of 'change of state', and\nclarifies in what sense culture, and the creative process underlying it, are\nDarwinian.\n", "machine_text": "This article presents a framework for examining how entities change over time based on their respective contexts. We refer to this approach as Context-driven Actualization of Potential (CAP). This framework facilitates an understanding of the differences in how state-changes occur in different disciplines. For instance, our analysis posits that the dynamical evolution of quantum entities, as described by the Schrodinger equation, is not distinct from the changes by measurement (or, the 'collapse'), but merely a limiting case. Additionally, our framework offers insights into concepts such as selection and fitness, demonstrating how exceptional Darwinian evolution is as a means of state-change. Lastly, it reveals the connections between culture, and the creative processes that embody it, and Darwinian principles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0156}
{"prompt": "Rephrase the abstract of an article with title 'Laplacian spectra of complex networks and random walks on them: Are\n  scale-free architectures really important?'.\n  We study the Laplacian operator of an uncorrelated random network and, as an\napplication, consider hopping processes (diffusion, random walks, signal\npropagation, etc.) on networks. We develop a strict approach to these problems.\nWe derive an exact closed set of integral equations, which provide the averages\nof the Laplacian operator's resolvent. This enables us to describe the\npropagation of a signal and random walks on the network. We show that the\ndetermining parameter in this problem is the minimum degree $q_m$ of vertices\nin the network and that the high-degree part of the degree distribution is not\nthat essential. The position of the lower edge of the Laplacian spectrum\n$\\lambda_c$ appears to be the same as in the regular Bethe lattice with the\ncoordination number $q_m$. Namely, $\\lambda_c>0$ if $q_m>2$, and $\\lambda_c=0$\nif $q_m\\leq2$. In both these cases the density of eigenvalues\n$\\rho(\\lambda)\\to0$ as $\\lambda\\to\\lambda_c+0$, but the limiting behaviors near\n$\\lambda_c$ are very different. In terms of a distance from a starting vertex,\nthe hopping propagator is a steady moving Gaussian, broadening with time. This\npicture qualitatively coincides with that for a regular Bethe lattice. Our\nanalytical results include the spectral density $\\rho(\\lambda)$ near\n$\\lambda_c$ and the long-time asymptotics of the autocorrelator and the\npropagator.\n\n", "human_text": "  We study the Laplacian operator of an uncorrelated random network and, as an\napplication, consider hopping processes (diffusion, random walks, signal\npropagation, etc.) on networks. We develop a strict approach to these problems.\nWe derive an exact closed set of integral equations, which provide the averages\nof the Laplacian operator's resolvent. This enables us to describe the\npropagation of a signal and random walks on the network. We show that the\ndetermining parameter in this problem is the minimum degree $q_m$ of vertices\nin the network and that the high-degree part of the degree distribution is not\nthat essential. The position of the lower edge of the Laplacian spectrum\n$\\lambda_c$ appears to be the same as in the regular Bethe lattice with the\ncoordination number $q_m$. Namely, $\\lambda_c>0$ if $q_m>2$, and $\\lambda_c=0$\nif $q_m\\leq2$. In both these cases the density of eigenvalues\n$\\rho(\\lambda)\\to0$ as $\\lambda\\to\\lambda_c+0$, but the limiting behaviors near\n$\\lambda_c$ are very different. In terms of a distance from a starting vertex,\nthe hopping propagator is a steady moving Gaussian, broadening with time. This\npicture qualitatively coincides with that for a regular Bethe lattice. Our\nanalytical results include the spectral density $\\rho(\\lambda)$ near\n$\\lambda_c$ and the long-time asymptotics of the autocorrelator and the\npropagator.\n", "machine_text": "\nWe investigate the Laplacian spectra and random walks of complex networks by deriving and analyzing a closed set of integral equations which give us averages of the Laplacian operator's resolvent. We examine the integral values and parameters of the network, concluding that the minimum degree of a vertex is a key factor. We find that the lower edge of the Laplacian spectrum is the same as that of a regular Bethe lattice, indicating a steady moving Gaussian of the hopping propagator. Furthermore, the long time asymptotic for the autocorrelator and the propagator are indicated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1176}
{"prompt": "Rephrase the abstract of an article with title 'Space of Quantum Theory Representations of Natural Numbers, Integers,\n  and Rational Numbers'.\n  This paper extends earlier work on quantum theory representations of natural\nnumbers N, integers I, and rational numbers Ra to describe a space of these\nrepresentations and transformations on the space. The space is parameterized by\n4-tuple points in a parameter set. Each point, (k,m,h,g), labels a specific\nrepresentation of X = N, I, Ra as a Fock space F^{X}_{k,m,h} of states of\nfinite length strings of qukits q and a string state basis B^{X}_{k,m,h,g}. The\npair (m,h) locates the q string in a square integer lattice I \\times I, k is\nthe q base, and the function g fixes the gauge or basis states for each q. Maps\non the parameter set induce transformations on on the representation space.\nThere are two shifts, a base change operator W_{k',k}, and a basis or gauge\ntransformation function U_{k}. The invariance of the axioms and theorems for N,\nI, and Ra under any transformation is discussed along with the dependence of\nthe properties of W_{k',k} on the prime factors of k' and k. This suggests that\none consider prime number q's, q_{2}, q_{3}, q_{5}, etc. as elementary and the\nbase k q's as composites of the prime number q's.\n\n", "human_text": "  This paper extends earlier work on quantum theory representations of natural\nnumbers N, integers I, and rational numbers Ra to describe a space of these\nrepresentations and transformations on the space. The space is parameterized by\n4-tuple points in a parameter set. Each point, (k,m,h,g), labels a specific\nrepresentation of X = N, I, Ra as a Fock space F^{X}_{k,m,h} of states of\nfinite length strings of qukits q and a string state basis B^{X}_{k,m,h,g}. The\npair (m,h) locates the q string in a square integer lattice I \\times I, k is\nthe q base, and the function g fixes the gauge or basis states for each q. Maps\non the parameter set induce transformations on on the representation space.\nThere are two shifts, a base change operator W_{k',k}, and a basis or gauge\ntransformation function U_{k}. The invariance of the axioms and theorems for N,\nI, and Ra under any transformation is discussed along with the dependence of\nthe properties of W_{k',k} on the prime factors of k' and k. This suggests that\none consider prime number q's, q_{2}, q_{3}, q_{5}, etc. as elementary and the\nbase k q's as composites of the prime number q's.\n", "machine_text": "This paper presents a space of quantum theory representations of the natural numbers N, integers I and rational numbers Ra. This space is parameterized by parameters denoted by 4-tuple points (k,m,h,g). Each point of the space labels a specific Fock space F^{X}_{k,m,h} of states with finite length strings of qukits q and a string state basis B^{X}_{k,m,h,g}. Maps on the parameter set result in transformations on the representation space, consisting of shifts, a base change operator W_{k',k}, and a basis or gauge transformation function U_{k}. The invariance of the properties of the natural, integer and rational numbers under any of these transformations is discussed, with an emphasis on the effect of prime factors on the operation of W_{k',k}. Under this light, the paper suggests that one should consider the prime number q's (e.g., q_{2}, q_{3}, q_{5}) as elemental and k q's as composites of these primes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3574}
{"prompt": "Rephrase the abstract of an article with title 'Geometry of PT-symmetric quantum mechanics'.\n  Recently, much research has been carried out on Hamiltonians that are not\nHermitian but are symmetric under space-time reflection, that is, Hamiltonians\nthat exhibit PT symmetry. Investigations of the Sturm-Liouville eigenvalue\nproblem associated with such Hamiltonians have shown that in many cases the\nentire energy spectrum is real and positive and that the eigenfunctions form an\northogonal and complete basis. Furthermore, the quantum theories determined by\nsuch Hamiltonians have been shown to be consistent in the sense that the\nprobabilities are positive and the dynamical trajectories are unitary. However,\nthe geometrical structures that underlie quantum theories formulated in terms\nof such Hamiltonians have hitherto not been fully understood. This paper\nstudies in detail the geometric properties of a Hilbert space endowed with a\nparity structure and analyses the characteristics of a PT-symmetric Hamiltonian\nand its eigenstates. A canonical relationship between a PT-symmetric operator\nand a Hermitian operator is established. It is shown that the quadratic form\ncorresponding to the parity operator, in particular, gives rise to a natural\npartition of the Hilbert space into two halves corresponding to states having\npositive and negative PT norm. The indefiniteness of the norm can be\ncircumvented by introducing a symmetry operator C that defines a positive\ndefinite inner product by means of a CPT conjugation operation.\n\n", "human_text": "  Recently, much research has been carried out on Hamiltonians that are not\nHermitian but are symmetric under space-time reflection, that is, Hamiltonians\nthat exhibit PT symmetry. Investigations of the Sturm-Liouville eigenvalue\nproblem associated with such Hamiltonians have shown that in many cases the\nentire energy spectrum is real and positive and that the eigenfunctions form an\northogonal and complete basis. Furthermore, the quantum theories determined by\nsuch Hamiltonians have been shown to be consistent in the sense that the\nprobabilities are positive and the dynamical trajectories are unitary. However,\nthe geometrical structures that underlie quantum theories formulated in terms\nof such Hamiltonians have hitherto not been fully understood. This paper\nstudies in detail the geometric properties of a Hilbert space endowed with a\nparity structure and analyses the characteristics of a PT-symmetric Hamiltonian\nand its eigenstates. A canonical relationship between a PT-symmetric operator\nand a Hermitian operator is established. It is shown that the quadratic form\ncorresponding to the parity operator, in particular, gives rise to a natural\npartition of the Hilbert space into two halves corresponding to states having\npositive and negative PT norm. The indefiniteness of the norm can be\ncircumvented by introducing a symmetry operator C that defines a positive\ndefinite inner product by means of a CPT conjugation operation.\n", "machine_text": "This article analyzes the geometrical aspects of quantum mechanics when the Hamiltonian is not Hermitian, yet symmetric under space-time reflection, i.e. PT-symmetric. The spectrum of associated eigenvalues of the Sturm-Liouville problem have been shown to have only real and positive energies and the basis of these eigenfunctions form an orthogonal and full set. Consequently, the probability of these quantum theories are positive and the dynamical trajectories remain unitary. This paper studies the properties of a Hilbert space consisting of a parity structure and examines the features of the PT-symmetric Hamiltonian and its eigenstates. Results indicate a connection between the PT-symmetric operator and a Hermitian operator, and how the quadratic form of the parity operator divides the Hilbert space into two halves according to states having a positive or negative PT norm. This can be solved by using a symmetry operator C in order to introduce a positive definite inner product through a CPT conjugation operation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2959}
{"prompt": "Rephrase the abstract of an article with title 'Growth window and possible mechanism of millimeter-thick single-walled\n  carbon nanotube forests'.\n  Our group recently reproduced the water-assisted growth method, so-called\n\"super growth\", of millimeter-thick single-walled carbon nanotube (SWNT)\nforests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this\ncurrent work, a parametric study was carried out on both reaction and catalyst\nconditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm)\nyielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3\nsupport enhanced the activity of Fe, Co, and Ni catalysts. The growth window\nfor the rapid SWNT growth was narrow, however. Optimum amount of added H2O\nincreased the SWNT growth rate but further addition of H2O degraded both the\nSWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT\ngrowth, but again, further addition decreased both the SWNT growth rate and\nquality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly\nenhances the SWNT growth rate by supplying the carbon source to the catalyst\nnanoparticles. The origin of the narrow window for rapid SWNT growth will also\nbe discussed.\n\n", "human_text": "  Our group recently reproduced the water-assisted growth method, so-called\n\"super growth\", of millimeter-thick single-walled carbon nanotube (SWNT)\nforests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this\ncurrent work, a parametric study was carried out on both reaction and catalyst\nconditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm)\nyielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3\nsupport enhanced the activity of Fe, Co, and Ni catalysts. The growth window\nfor the rapid SWNT growth was narrow, however. Optimum amount of added H2O\nincreased the SWNT growth rate but further addition of H2O degraded both the\nSWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT\ngrowth, but again, further addition decreased both the SWNT growth rate and\nquality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly\nenhances the SWNT growth rate by supplying the carbon source to the catalyst\nnanoparticles. The origin of the narrow window for rapid SWNT growth will also\nbe discussed.\n", "machine_text": "\nA recent study explored the optimal parameters for the successful growth of millimeter-thick single-walled carbon nanotube (SWNT) forests using C2H4/ H2/ H2O/ Ar reactant gas and a Fe/ Al2O3 catalyst. Results from this study determined that SWNTs grow best with a thin layer of Fe catalyst when the catalyst is supported on Al2O3, pointing to Al2O3 support as a means to boost the activity of Fe, Co, and Ni catalysts. However, the parameters to achieve a rapid growth rate of SWNTs were found to be narrow. Increasing the amount of added H2O can increase the SWNT growth rate, but its quality suffers when increased beyond optimal amounts. Similarly, H2 is essential for rapid growth, but its addition has the same negative effects as H2O once an optimal threshold is exceeded. Al2O3 was speculated to boost the SWNT growth rate by providing the carbon source for the catalyst nanoparticles. Additionally, the mechanisms responsible for the narrow growth window for SWNTs were addressed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1903}
{"prompt": "Rephrase the abstract of an article with title 'k-dependent SU(4) model of high-temperature superconductivity and its\n  coherent-state solutions'.\n  We extend the SU(4) model [1-5] for high-Tc superconductivity to an SU(4)k\nmodel that permits explicit momentum (k) dependence in predicted observables.\nWe derive and solve gap equations that depend on k, temperature, and doping\nfrom the SU(4)k coherent states, and show that the new SU(4)k model reduces to\nthe original SU(4) model for observables that do not depend explicitly on\nmomentum. The results of the SU(4)k model are relevant for experiments such as\nARPES that detect explicitly k-dependent properties. The present SU(4)k model\ndescribes quantitatively the pseudogap temperature scale and may explain why\nthe ARPES-measured T* along the anti-nodal direction is larger than other\nmeasurements that do not resolve momentum. It also provides an immediate\nmicroscopic explanation for Fermi arcs observed in the pseudogap region. In\naddition, the model leads to a prediction that even in the underdoped regime,\nthere exist doping-dependent windows around nodal points in the k-space, where\nantiferromagnetism may be completely suppressed for all doping fractions,\npermitting pure superconducting states to exist.\n\n", "human_text": "  We extend the SU(4) model [1-5] for high-Tc superconductivity to an SU(4)k\nmodel that permits explicit momentum (k) dependence in predicted observables.\nWe derive and solve gap equations that depend on k, temperature, and doping\nfrom the SU(4)k coherent states, and show that the new SU(4)k model reduces to\nthe original SU(4) model for observables that do not depend explicitly on\nmomentum. The results of the SU(4)k model are relevant for experiments such as\nARPES that detect explicitly k-dependent properties. The present SU(4)k model\ndescribes quantitatively the pseudogap temperature scale and may explain why\nthe ARPES-measured T* along the anti-nodal direction is larger than other\nmeasurements that do not resolve momentum. It also provides an immediate\nmicroscopic explanation for Fermi arcs observed in the pseudogap region. In\naddition, the model leads to a prediction that even in the underdoped regime,\nthere exist doping-dependent windows around nodal points in the k-space, where\nantiferromagnetism may be completely suppressed for all doping fractions,\npermitting pure superconducting states to exist.\n", "machine_text": "This paper presents an extended SU(4) model for high-temperature superconductivity which considers the momentum (k)-dependence of the model's predicted observables. We solve for gap equations that depend on k, temperature, and doping using SU(4)k coherent states and show that the new model reduces to the original model for non-k-dependent observables. Our results have relevance for experiments such as ARPES that measure k-dependent properties. Furthermore, the model quantitatively describes the pseudogap temperature scale and might explain why the temperature T* of ARPES-measured values along the anti-nodal direction is higher than other non-momentum-resolving measurements. Additionally, the model proposes that in underdoped regions, there exist doping-related windows around nodal points in the k-space that might enable the complete suppression of antiferromagnetism, to form purely superconducting states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0818}
{"prompt": "Rephrase the abstract of an article with title 'The Detection and Characterization of cm Radio Continuum Emission from\n  the Low-mass Protostar L1014-IRS'.\n  Observations by the Cores to Disk Legacy Team with the Spitzer Space\nTelescope have identified a low luminosity, mid-infrared source within the\ndense core, Lynds 1014, which was previously thought to harbor no internal\nsource. Followup near-infrared and submillimeter interferometric observations\nhave confirmed the protostellar nature of this source by detecting scattered\nlight from an outflow cavity and a weak molecular outflow. In this paper, we\nreport the detection of cm continuum emission with the VLA. The emission is\ncharacterized by a quiescent, unresolved 90 uJy 6 cm source within 0.2\" of the\nSpitzer source. The spectral index of the quiescent component is $\\alpha =\n0.37\\pm 0.34$ between 6 cm and 3.6 cm. A factor of two increase in 6 cm\nemission was detected during one epoch and circular polarization was marginally\ndetected at the $5\\sigma$ level with Stokes {V/I} $= 48 \\pm 16$% . We have\nsearched for 22 GHz H2O maser emission toward L1014-IRS, but no masers were\ndetected during 7 epochs of observations between June 2004 and December 2006.\nL1014-IRS appears to be a low-mass, accreting protostar which exhibits cm\nemission from a thermal jet or a wind, with a variable non-thermal emission\ncomponent. The quiescent cm radio emission is noticeably above the correlation\nof 3.6 cm and 6 cm luminosity versus bolometric luminosity, indicating more\nradio emission than expected. We characterize the cm continuum emission in\nterms of observations of other low-mass protostars, including updated\ncorrelations of centimeter continuum emission with bolometric luminosity and\noutflow force, and discuss the implications of recent larger distance estimates\non the physical attributes of the protostar and dense molecular core.\n\n", "human_text": "  Observations by the Cores to Disk Legacy Team with the Spitzer Space\nTelescope have identified a low luminosity, mid-infrared source within the\ndense core, Lynds 1014, which was previously thought to harbor no internal\nsource. Followup near-infrared and submillimeter interferometric observations\nhave confirmed the protostellar nature of this source by detecting scattered\nlight from an outflow cavity and a weak molecular outflow. In this paper, we\nreport the detection of cm continuum emission with the VLA. The emission is\ncharacterized by a quiescent, unresolved 90 uJy 6 cm source within 0.2\" of the\nSpitzer source. The spectral index of the quiescent component is $\\alpha =\n0.37\\pm 0.34$ between 6 cm and 3.6 cm. A factor of two increase in 6 cm\nemission was detected during one epoch and circular polarization was marginally\ndetected at the $5\\sigma$ level with Stokes {V/I} $= 48 \\pm 16$% . We have\nsearched for 22 GHz H2O maser emission toward L1014-IRS, but no masers were\ndetected during 7 epochs of observations between June 2004 and December 2006.\nL1014-IRS appears to be a low-mass, accreting protostar which exhibits cm\nemission from a thermal jet or a wind, with a variable non-thermal emission\ncomponent. The quiescent cm radio emission is noticeably above the correlation\nof 3.6 cm and 6 cm luminosity versus bolometric luminosity, indicating more\nradio emission than expected. We characterize the cm continuum emission in\nterms of observations of other low-mass protostars, including updated\ncorrelations of centimeter continuum emission with bolometric luminosity and\noutflow force, and discuss the implications of recent larger distance estimates\non the physical attributes of the protostar and dense molecular core.\n", "machine_text": "In this paper, we present the findings of an investigation using the VLA and Spitzer Space Telescope to characterize cm radio continuum emission from the low-luminosity, mid-infrared protostar located within the Lynds 1014 dense core. The emission is comprised of a quiescent, unresolved component with a spectral index of $\\alpha = 0.37\\pm 0.34$ between the 6 cm and 3.6 cm bands, and a component that has been found to increase in strength in the 6 cm band during one epoch of observation. Circular polarization was also detected at a 5$\\sigma$ level. Despite no 22 GHz H2O maser emission being detected, the cm radio emission from L1014-IRS exceeds expectations according to established 3.6 cm and 6 cm luminosity versus bolometric luminosity correlations. We compare the emission from L1014-IRS with other low-mass protostars, and discuss the implications of the updated distance measurements on the core and protostar.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1747}
{"prompt": "Rephrase the abstract of an article with title 'Monoid generalizations of the Richard Thompson groups'.\n  The groups G_{k,1} of Richard Thompson and Graham Higman can be generalized\nin a natural way to monoids, that we call M_{k,1}, and to inverse monoids,\ncalled Inv_{k,1}; this is done by simply generalizing bijections to partial\nfunctions or partial injective functions. The monoids M_{k,1} have connections\nwith circuit complexity (studied in another paper). Here we prove that M_{k,1}\nand Inv_{k,1} are congruence-simple for all k. Their Green relations J and D\nare characterized: M_{k,1} and Inv_{k,1} are J-0-simple, and they have k-1\nnon-zero D-classes. They are submonoids of the multiplicative part of the Cuntz\nalgebra O_k. They are finitely generated, and their word problem over any\nfinite generating set is in P. Their word problem is coNP-complete over certain\ninfinite generating sets.\n  Changes in this version: Section 4 has been thoroughly revised, and errors\nhave been corrected; however, the main results of Section 4 do not change.\nSections 1, 2, and 3 are unchanged, except for the proof of Theorem 2.3, which\nwas incomplete; a complete proof was published in the Appendix of reference\n[6], and is also given here.\n\n", "human_text": "  The groups G_{k,1} of Richard Thompson and Graham Higman can be generalized\nin a natural way to monoids, that we call M_{k,1}, and to inverse monoids,\ncalled Inv_{k,1}; this is done by simply generalizing bijections to partial\nfunctions or partial injective functions. The monoids M_{k,1} have connections\nwith circuit complexity (studied in another paper). Here we prove that M_{k,1}\nand Inv_{k,1} are congruence-simple for all k. Their Green relations J and D\nare characterized: M_{k,1} and Inv_{k,1} are J-0-simple, and they have k-1\nnon-zero D-classes. They are submonoids of the multiplicative part of the Cuntz\nalgebra O_k. They are finitely generated, and their word problem over any\nfinite generating set is in P. Their word problem is coNP-complete over certain\ninfinite generating sets.\n  Changes in this version: Section 4 has been thoroughly revised, and errors\nhave been corrected; however, the main results of Section 4 do not change.\nSections 1, 2, and 3 are unchanged, except for the proof of Theorem 2.3, which\nwas incomplete; a complete proof was published in the Appendix of reference\n[6], and is also given here.\n", "machine_text": "\nThis work investigates the natural generalization of the groups G_{k,1} of Richard Thompson and Graham Higman to monoids, called M_{k,1}, and to inverse monoids, called Inv_{k,1}. This research shows that these monoids and inverse monoids are both congruence-simple and J-0-simple when all k are considered. Furthermore, they possess k-1 nontrivial D-classes. Connections to the multiplicative part of the Cuntz algebra O_k, as well as finite and infinite generating sets, are explored. Results show that the word problem for M_{k,1} and Inv_{k,1} is decidable for any finite generating set, and for certain infinite sets is coNP-complete. Revised Section 4 of the paper is included, correcting errors, though the main results for this section remain unchanged, as does Sections 1, 2 and 3 with the exception of Theorem 2.3, which has been revised to the proof included in reference [6].", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0189}
{"prompt": "Rephrase the abstract of an article with title 'Ionized nebulae surrounding brightest cluster galaxies'.\n  We present IFU observations of six emission-line nebulae that surround the\ncentral galaxy of cool core clusters. Qualitatively similar nebulae are\nobserved in cool core clusters even when the dynamics and possibly formation\nand excitation source are different. Evidence for a nearby secondary galaxy\ndisturbing a nebula, as well as AGN and starburst driven outflows are presented\nas possible formation mechanisms. One nebula has a rotation velocity of the\nsame amplitude as the underlying molecular reservoir, which implies that the\nexcitation or formation of a nebula does not require any disturbance of the\nmolecular reservoir within the central galaxy. Bulk flows and velocity shears\nof a few hundred km/s are seen across all nebulae. The majority lack any\nordered rotation, their configurations are not stable so the nebulae must be\nconstantly reshaping, dispersing and reforming. The dimmer nebulae are\nco-spatial with dust features whilst the more luminous are not. Significant\nvariation in the ionization state of the gas is seen in all nebulae through the\nnon-uniform [NII]/H_alpha ratio. There is no correlation between the line ratio\nand H_alpha surface brightness, but regions with excess blue or UV light have\nlower line ratios. This implies that UV from massive, young stars act in\ncombination with an underlying heating source that produces the observed\nlow-ionization spectra.\n\n", "human_text": "  We present IFU observations of six emission-line nebulae that surround the\ncentral galaxy of cool core clusters. Qualitatively similar nebulae are\nobserved in cool core clusters even when the dynamics and possibly formation\nand excitation source are different. Evidence for a nearby secondary galaxy\ndisturbing a nebula, as well as AGN and starburst driven outflows are presented\nas possible formation mechanisms. One nebula has a rotation velocity of the\nsame amplitude as the underlying molecular reservoir, which implies that the\nexcitation or formation of a nebula does not require any disturbance of the\nmolecular reservoir within the central galaxy. Bulk flows and velocity shears\nof a few hundred km/s are seen across all nebulae. The majority lack any\nordered rotation, their configurations are not stable so the nebulae must be\nconstantly reshaping, dispersing and reforming. The dimmer nebulae are\nco-spatial with dust features whilst the more luminous are not. Significant\nvariation in the ionization state of the gas is seen in all nebulae through the\nnon-uniform [NII]/H_alpha ratio. There is no correlation between the line ratio\nand H_alpha surface brightness, but regions with excess blue or UV light have\nlower line ratios. This implies that UV from massive, young stars act in\ncombination with an underlying heating source that produces the observed\nlow-ionization spectra.\n", "machine_text": "\nOur IFU observations of emission-line nebulae that encircle the central galaxy\nof cooler core clusters suggest that several different phenomena may be at work in their formation. Such nebulae can develop due to AGN and starburst-powered outflows, with the presence of a neighboring galaxy to provide disruption. We have also established that rotation of the same amplitude as the underlying molecular reservoir might cause the excitation or formation of one of the nebulae, implying lack of disturbance of the central galaxy. The nebulae also demonstrate bulk flows and velocity shears up to several hundred km/s, and are likely constantly being reshaped and reformed due to their unsteady configurational states. Moreover, our results suggest that the varying ionization states of gas in the nebulae, particularly their [NII]/H_alpha ratios, are likely caused by a combination of UV from massive, young stars, in conjunction with an underlying heating source.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0661}
{"prompt": "Rephrase the abstract of an article with title 'Dark energy constraints from cosmic shear power spectra: impact of\n  intrinsic alignments on photometric redshift requirements'.\n  Cosmic shear constrains cosmology by exploiting the apparent alignments of\npairs of galaxies due to gravitational lensing by intervening mass clumps.\nHowever galaxies may become (intrinsically) aligned with each other, and with\nnearby mass clumps, during their formation. This effect needs to be\ndisentangled from the cosmic shear signal to place constraints on cosmology. We\nuse the linear intrinsic alignment model as a base and compare it to an\nalternative model and data. If intrinsic alignments are ignored then the dark\nenergy equation of state is biased by ~50 per cent. We examine how the number\nof tomographic redshift bins affects uncertainties on cosmological parameters\nand find that when intrinsic alignments are included two or more times as many\nbins are required to obtain 80 per cent of the available information. We\ninvestigate how the degradation in the dark energy figure of merit depends on\nthe photometric redshift scatter. Previous studies have shown that lensing does\nnot place stringent requirements on the photometric redshift uncertainty, so\nlong as the uncertainty is well known. However, if intrinsic alignments are\nincluded the requirements become a factor of three tighter. These results are\nquite insensitive to the fraction of catastrophic outliers, assuming that this\nfraction is well known. We show the effect of uncertainties in photometric\nredshift bias and scatter. Finally we quantify how priors on the intrinsic\nalignment model would improve dark energy constraints.\n\n", "human_text": "  Cosmic shear constrains cosmology by exploiting the apparent alignments of\npairs of galaxies due to gravitational lensing by intervening mass clumps.\nHowever galaxies may become (intrinsically) aligned with each other, and with\nnearby mass clumps, during their formation. This effect needs to be\ndisentangled from the cosmic shear signal to place constraints on cosmology. We\nuse the linear intrinsic alignment model as a base and compare it to an\nalternative model and data. If intrinsic alignments are ignored then the dark\nenergy equation of state is biased by ~50 per cent. We examine how the number\nof tomographic redshift bins affects uncertainties on cosmological parameters\nand find that when intrinsic alignments are included two or more times as many\nbins are required to obtain 80 per cent of the available information. We\ninvestigate how the degradation in the dark energy figure of merit depends on\nthe photometric redshift scatter. Previous studies have shown that lensing does\nnot place stringent requirements on the photometric redshift uncertainty, so\nlong as the uncertainty is well known. However, if intrinsic alignments are\nincluded the requirements become a factor of three tighter. These results are\nquite insensitive to the fraction of catastrophic outliers, assuming that this\nfraction is well known. We show the effect of uncertainties in photometric\nredshift bias and scatter. Finally we quantify how priors on the intrinsic\nalignment model would improve dark energy constraints.\n", "machine_text": "\nThe gravitational lensing effect of intervening spots of mass can be discerned by observing the alignment of far-flung galaxies. However, this cosmic shear signal may be contaminated by the alignment of the galaxies themselves, which needs to be factored out in order to place certain constrictions on our cosmology. We discuss two models in this area and investigate the impact of intrinsic alignments on the number of necessary tomographic redshift bins and the robustness of dark energy constraints. With the inclusion of intrinsic alignments, dark energy biases can reach as high as 50 percent. Furthermore, we find that unless the photometric redshift uncertainty is increased by a factor of three, the dark energy figure of merit will decline. Lastly, we analyze how prior knowledge of the intrinsic alignment model may improve the accuracy of the final result.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0166}
{"prompt": "Rephrase the abstract of an article with title 'A Class of LDPC Erasure Distributions with Closed-Form Threshold\n  Expression'.\n  In this paper, a family of low-density parity-check (LDPC) degree\ndistributions, whose decoding threshold on the binary erasure channel (BEC)\nadmits a simple closed form, is presented. These degree distributions are a\nsubset of the check regular distributions (i.e. all the check nodes have the\nsame degree), and are referred to as $p$-positive distributions. It is given\nproof that the threshold for a $p$-positive distribution is simply expressed by\n$[\\lambda'(0)\\rho'(1)]^{-1}$. Besides this closed form threshold expression,\nthe $p$-positive distributions exhibit three additional properties. First, for\ngiven code rate, check degree and maximum variable degree, they are in some\ncases characterized by a threshold which is extremely close to that of the best\nknown check regular distributions, under the same set of constraints. Second,\nthe threshold optimization problem within the $p$-positive class can be solved\nin some cases with analytic methods, without using any numerical optimization\ntool. Third, these distributions can achieve the BEC capacity. The last\nproperty is shown by proving that the well-known binomial degree distributions\nbelong to the $p$-positive family.\n\n", "human_text": "  In this paper, a family of low-density parity-check (LDPC) degree\ndistributions, whose decoding threshold on the binary erasure channel (BEC)\nadmits a simple closed form, is presented. These degree distributions are a\nsubset of the check regular distributions (i.e. all the check nodes have the\nsame degree), and are referred to as $p$-positive distributions. It is given\nproof that the threshold for a $p$-positive distribution is simply expressed by\n$[\\lambda'(0)\\rho'(1)]^{-1}$. Besides this closed form threshold expression,\nthe $p$-positive distributions exhibit three additional properties. First, for\ngiven code rate, check degree and maximum variable degree, they are in some\ncases characterized by a threshold which is extremely close to that of the best\nknown check regular distributions, under the same set of constraints. Second,\nthe threshold optimization problem within the $p$-positive class can be solved\nin some cases with analytic methods, without using any numerical optimization\ntool. Third, these distributions can achieve the BEC capacity. The last\nproperty is shown by proving that the well-known binomial degree distributions\nbelong to the $p$-positive family.\n", "machine_text": "This paper presents a particular class of low-density parity-check (LDPC) degree distributions, referred to as $p$-positive distributions, for which the decoding threshold on the binary erasure channel (BEC) admits a simple closed-form expression. It is demonstrated that $[\\lambda'(0)\\rho'(1)]^{-1}$ viz. the expression of the threshold for a $p$-positive distribution. The $p$-positive distributions also possess a number of desirable properties i.e. a threshold close to best known check regular distributions in certain cases, optimization of threshold within the class using analytic methods, and the capacity-achievability property, which is established by including the well-known binomial degree distributions in the $p$-positive family.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1612}
{"prompt": "Rephrase the abstract of an article with title 'Scaling Laws of Cognitive Networks'.\n  We consider a cognitive network consisting of n random pairs of cognitive\ntransmitters and receivers communicating simultaneously in the presence of\nmultiple primary users. Of interest is how the maximum throughput achieved by\nthe cognitive users scales with n. Furthermore, how far these users must be\nfrom a primary user to guarantee a given primary outage. Two scenarios are\nconsidered for the network scaling law: (i) when each cognitive transmitter\nuses constant power to communicate with a cognitive receiver at a bounded\ndistance away, and (ii) when each cognitive transmitter scales its power\naccording to the distance to a considered primary user, allowing the cognitive\ntransmitter-receiver distances to grow. Using single-hop transmission, suitable\nfor cognitive devices of opportunistic nature, we show that, in both scenarios,\nwith path loss larger than 2, the cognitive network throughput scales linearly\nwith the number of cognitive users. We then explore the radius of a primary\nexclusive region void of cognitive transmitters. We obtain bounds on this\nradius for a given primary outage constraint. These bounds can help in the\ndesign of a primary network with exclusive regions, outside of which cognitive\nusers may transmit freely. Our results show that opportunistic secondary\nspectrum access using single-hop transmission is promising.\n\n", "human_text": "  We consider a cognitive network consisting of n random pairs of cognitive\ntransmitters and receivers communicating simultaneously in the presence of\nmultiple primary users. Of interest is how the maximum throughput achieved by\nthe cognitive users scales with n. Furthermore, how far these users must be\nfrom a primary user to guarantee a given primary outage. Two scenarios are\nconsidered for the network scaling law: (i) when each cognitive transmitter\nuses constant power to communicate with a cognitive receiver at a bounded\ndistance away, and (ii) when each cognitive transmitter scales its power\naccording to the distance to a considered primary user, allowing the cognitive\ntransmitter-receiver distances to grow. Using single-hop transmission, suitable\nfor cognitive devices of opportunistic nature, we show that, in both scenarios,\nwith path loss larger than 2, the cognitive network throughput scales linearly\nwith the number of cognitive users. We then explore the radius of a primary\nexclusive region void of cognitive transmitters. We obtain bounds on this\nradius for a given primary outage constraint. These bounds can help in the\ndesign of a primary network with exclusive regions, outside of which cognitive\nusers may transmit freely. Our results show that opportunistic secondary\nspectrum access using single-hop transmission is promising.\n", "machine_text": "\nIn this paper, we investigate the scaling laws of a cognitive network with n simultaneous pairs of cognitive transmitters and receivers in the presence of multiple primary users. Specifically, we consider how the network throughput, as well as the radius of a primary exclusive region outside of which cognitive users can avoid causing interference, vary with the number of cognitive users. We analyze two scenarios, with either a static or a scaled power, and show that, with a path-loss larger than 2, the throughput scales linearly and can be guaranteed with a minimum distance to primary users at a given outage constraint. The results suggest that single-hop transmission can be used to provide an efficient and feasible means of secondary spectrum access.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2353}
{"prompt": "Rephrase the abstract of an article with title 'Algebraic charge liquids'.\n  High temperature superconductivity emerges in the cuprate compounds upon\nchanging the electron density of an insulator in which the electron spins are\nantiferromagnetically ordered. A key characteristic of the superconductor is\nthat electrons can be extracted from them at zero energy only if their momenta\ntake one of four specific values (the `nodal points'). A central enigma has\nbeen the evolution of the zero energy electrons in the metallic state between\nthe antiferromagnet and the superconductor, and recent experiments yield\napparently contradictory results. The oscillation of the resistance in this\nmetal as a function of magnetic field indicate that the zero energy electrons\ncarry momenta which lie on elliptical `Fermi pockets', while ejection of\nelectrons by high intensity light indicates that the zero energy electrons have\nmomenta only along arc-like regions. We present a theory of new states of\nmatter, which we call `algebraic charge liquids', which arise naturally between\nthe antiferromagnet and the superconductor, and reconcile these observations.\nOur theory also explains a puzzling dependence of the density of\nsuperconducting electrons on the total electron density, and makes a number of\nunique predictions for future experiments.\n\n", "human_text": "  High temperature superconductivity emerges in the cuprate compounds upon\nchanging the electron density of an insulator in which the electron spins are\nantiferromagnetically ordered. A key characteristic of the superconductor is\nthat electrons can be extracted from them at zero energy only if their momenta\ntake one of four specific values (the `nodal points'). A central enigma has\nbeen the evolution of the zero energy electrons in the metallic state between\nthe antiferromagnet and the superconductor, and recent experiments yield\napparently contradictory results. The oscillation of the resistance in this\nmetal as a function of magnetic field indicate that the zero energy electrons\ncarry momenta which lie on elliptical `Fermi pockets', while ejection of\nelectrons by high intensity light indicates that the zero energy electrons have\nmomenta only along arc-like regions. We present a theory of new states of\nmatter, which we call `algebraic charge liquids', which arise naturally between\nthe antiferromagnet and the superconductor, and reconcile these observations.\nOur theory also explains a puzzling dependence of the density of\nsuperconducting electrons on the total electron density, and makes a number of\nunique predictions for future experiments.\n", "machine_text": "Recent experiments on the high temperature cuprate superconductors have uncovered apparently contradictory results regarding the charge and momentum of the zero energy electrons in the metallic state between the antiferromagnet and the superconductor. This paper introduces a theory of novel states of matter, called 'algebraic charge liquids', which explain these discrepancies and explore the dependence of the density of the superconducting electrons on the total electron density. We identify a number of unique predictions for further experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2187}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical models and the phase ordering kinetics of the s=1 spinor\n  condensate'.\n  The $s=1$ spinor Bose condensate at zero temperature supports ferromagnetic\nand polar phases that combine magnetic and superfluid ordering. We investigate\nthe formation of magnetic domains at finite temperature and magnetic field in\ntwo dimensions in an optical trap. We study the general ground state phase\ndiagram of a spin-1 system and focus on a phase that has a magnetic Ising order\nparameter and numerically determine the nature of the finite temperature\nsuperfluid and magnetic phase transitions. We then study three different\ndynamical models: model A, which has no conserved quantities, model F, which\nhas a conserved second sound mode and the Gross-Pitaevskii (GP) equation which\nhas a conserved density and magnetization. We find the dynamic critical\nexponent to be the same for models A and F ($z=2$) but different for GP ($z\n\\approx 3$). Externally imposed magnetization conservation in models A and F\nyields the value $z \\approx 3$, which demonstrates that the only conserved\ndensity relevant to domain formation is the magnetization density.\n\n", "human_text": "  The $s=1$ spinor Bose condensate at zero temperature supports ferromagnetic\nand polar phases that combine magnetic and superfluid ordering. We investigate\nthe formation of magnetic domains at finite temperature and magnetic field in\ntwo dimensions in an optical trap. We study the general ground state phase\ndiagram of a spin-1 system and focus on a phase that has a magnetic Ising order\nparameter and numerically determine the nature of the finite temperature\nsuperfluid and magnetic phase transitions. We then study three different\ndynamical models: model A, which has no conserved quantities, model F, which\nhas a conserved second sound mode and the Gross-Pitaevskii (GP) equation which\nhas a conserved density and magnetization. We find the dynamic critical\nexponent to be the same for models A and F ($z=2$) but different for GP ($z\n\\approx 3$). Externally imposed magnetization conservation in models A and F\nyields the value $z \\approx 3$, which demonstrates that the only conserved\ndensity relevant to domain formation is the magnetization density.\n", "machine_text": "\nThis article explores the process of domain formation at finite temperature and magnetic field in two-dimensional optical traps of $s=1$ spinor Bose condensates. Through researching the fundamental ground state phase diagrams and modeling through three different approaches, we investigate the role of different conserved quantities. We find that the dynamic critical exponent for model A and F is equal to $z=2$, but differs for GP with $z \\approx 3$. An inclusion of externally imposed magnetization conservation for models A and F yields the same value of $z \\approx 3$, suggesting that magnetization density is the only conserved quantity relevant to domain formation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.344}
{"prompt": "Rephrase the abstract of an article with title 'Dark Matter in Gauge Mediation from Emergent Supersymmetry'.\n  We investigated the viability of neutralino dark matter in the gauge\nmediation from emergent supersymmetry proposal. In this proposal, supersymmetry\nis broken at Planck scale and consequently, the gravitino is superheavy and\ncompletely decouples from the low energy theory. Squarks and sleptons obtain\ntheir soft masses dominantly through gauge mediation with other mechanisms\nhighly suppressed. The lightest supersymmetric partner, in contrast to\ntraditional gauge mediation, is a neutralino which is also a dark matter\ncandidate. By explicit calculation of the low energy spectra, the parameter\nspace was constrained using the WMAP observed relic density of dark matter,\nLEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic\nB-meson decays. We found that the model has intriguing hybrid features such as\na nearly gauge-mediated spectrum (the exception being the superheavy gravitino)\nbut with a dominant mSUGRA-like bino-stau coannihilation channel and at large\n$\\tan \\beta$, A-resonance-like annihilation.\n\n", "human_text": "  We investigated the viability of neutralino dark matter in the gauge\nmediation from emergent supersymmetry proposal. In this proposal, supersymmetry\nis broken at Planck scale and consequently, the gravitino is superheavy and\ncompletely decouples from the low energy theory. Squarks and sleptons obtain\ntheir soft masses dominantly through gauge mediation with other mechanisms\nhighly suppressed. The lightest supersymmetric partner, in contrast to\ntraditional gauge mediation, is a neutralino which is also a dark matter\ncandidate. By explicit calculation of the low energy spectra, the parameter\nspace was constrained using the WMAP observed relic density of dark matter,\nLEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic\nB-meson decays. We found that the model has intriguing hybrid features such as\na nearly gauge-mediated spectrum (the exception being the superheavy gravitino)\nbut with a dominant mSUGRA-like bino-stau coannihilation channel and at large\n$\\tan \\beta$, A-resonance-like annihilation.\n", "machine_text": " In this article, we explored the feasibility of a dark matter candidate, the neutralino, through the gauge mediation derived from the emergence of supersymmetry. This approach dictated that the gravitino was incredibly massive and therefore decoupled the low energy theory. The soft masses are primarily derived from gauge mediation, and not other means, creating an interesting hybrid of features including a nearly gauge-mediated spectrum with a large mSUGRA-like bino-stau coannihilation channel, and also with a possible A-resonance-like annihilation near large $\\tan \\beta$. We constrained our parameter space using WMAP dark matter relic density data, LEP2 Higgs mass bound, and a number of collider and exotic B-meson decay bounds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2258}
{"prompt": "Rephrase the abstract of an article with title 'Novel technique for monitoring the performance of the LAT instrument on\n  board the GLAST satellite'.\n  The Gamma-ray Large Area Space Telescope (GLAST) is an observatory designed\nto perform gamma-ray astronomy in the energy range 20 MeV to 300 GeV, with\nsupporting measurements for gamma-ray bursts from 10 keV to 25 MeV. GLAST will\nbe launched at the end of 2007, opening a new and important window on a wide\nvariety of high energy astrophysical phenomena . The main instrument of GLAST\nis the Large Area Telescope (LAT), which provides break-through high-energy\nmeasurements using techniques typically used in particle detectors for collider\nexperiments. The LAT consists of 16 identical towers in a four-by-four grid,\neach one containing a pair conversion tracker and a hodoscopic crystal\ncalorimeter, all covered by a segmented plastic scintillator anti-coincidence\nshield. The scientific return of the instrument depends very much on how\naccurately we know its performance, and how well we can monitor it and correct\npotential problems promptly. We report on a novel technique that we are\ndeveloping to help in the characterization and monitoring of LAT by using the\npower of classification trees to pinpoint in a short time potential problems in\nthe recorded data. The same technique could also be used to evaluate the effect\non the overall LAT performance produced by potential instrumental problems.\n\n", "human_text": "  The Gamma-ray Large Area Space Telescope (GLAST) is an observatory designed\nto perform gamma-ray astronomy in the energy range 20 MeV to 300 GeV, with\nsupporting measurements for gamma-ray bursts from 10 keV to 25 MeV. GLAST will\nbe launched at the end of 2007, opening a new and important window on a wide\nvariety of high energy astrophysical phenomena . The main instrument of GLAST\nis the Large Area Telescope (LAT), which provides break-through high-energy\nmeasurements using techniques typically used in particle detectors for collider\nexperiments. The LAT consists of 16 identical towers in a four-by-four grid,\neach one containing a pair conversion tracker and a hodoscopic crystal\ncalorimeter, all covered by a segmented plastic scintillator anti-coincidence\nshield. The scientific return of the instrument depends very much on how\naccurately we know its performance, and how well we can monitor it and correct\npotential problems promptly. We report on a novel technique that we are\ndeveloping to help in the characterization and monitoring of LAT by using the\npower of classification trees to pinpoint in a short time potential problems in\nthe recorded data. The same technique could also be used to evaluate the effect\non the overall LAT performance produced by potential instrumental problems.\n", "machine_text": "This paper describes a new technique for monitoring the performance of the Large Area Telescope (LAT) instrument on board the Gamma-ray Large Area Space Telescope (GLAST) satellite. The LAT instrument consists of 16 towers in a four-by-four grid containing a pair conversion tracker, a hodoscopic crystal calorimeter, and a segmented plastic scintillator anti-coincidence shield. In order to ensure that the LAT performs optimally and that any potential problems with the instrument can be promptly located and addressed, this paper outlines a method using the power of classification trees to accurately identify any potential issues with the recorded data. The technique described in this article also provides insight into the effect of potential instrumental problems on the overall LAT performance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1544}
{"prompt": "Rephrase the abstract of an article with title 'Synergistic Effects of MoDTC and ZDTP on Frictional Behaviour of\n  Tribofilms at the Nanometer Scale'.\n  The layered structure and the rheological properties of anti-wear films,\ngenerated in a rolling/sliding contact from lubricants containing zinc\ndialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC)\nadditives, have been studied by dynamic nanoindentation experiments coupled\nwith a simple modelling of the stiffness measurements. Local nano-friction\nexperiments were conducted with the same device in order to determine the\nevolution of the friction coefficient as a function of the applied pressure for\nthe different lubricant formulations. For the MoDTC film, the applied pressure\nin the friction test remains low (<0.5 GPa) and the apparent friction\ncoefficient is high ($\\mu$ > 0.4). For the tribofilms containing MoDTC together\nwith ZDTP, which permits the applied pressure to increase up to a few GPa\nthrough some accommodation process, a very low friction domain appears (0.01 <\n$\\mu$ < 0.05), located a few nanometers below the surface of the tribofilm.\nThis low friction coefficient is attributed to the presence of MoS2 planes\nsliding over each other in a favourable configuration obtained when the\npressure is sufficiently high, which is made possible by the presence of ZDTP.\n\n", "human_text": "  The layered structure and the rheological properties of anti-wear films,\ngenerated in a rolling/sliding contact from lubricants containing zinc\ndialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC)\nadditives, have been studied by dynamic nanoindentation experiments coupled\nwith a simple modelling of the stiffness measurements. Local nano-friction\nexperiments were conducted with the same device in order to determine the\nevolution of the friction coefficient as a function of the applied pressure for\nthe different lubricant formulations. For the MoDTC film, the applied pressure\nin the friction test remains low (<0.5 GPa) and the apparent friction\ncoefficient is high ($\\mu$ > 0.4). For the tribofilms containing MoDTC together\nwith ZDTP, which permits the applied pressure to increase up to a few GPa\nthrough some accommodation process, a very low friction domain appears (0.01 <\n$\\mu$ < 0.05), located a few nanometers below the surface of the tribofilm.\nThis low friction coefficient is attributed to the presence of MoS2 planes\nsliding over each other in a favourable configuration obtained when the\npressure is sufficiently high, which is made possible by the presence of ZDTP.\n", "machine_text": "\nThe interactions between the components in lubricants containing zinc dialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC) that create anti-wear films were evaluated using dynamic nanoindentation and friction tests in the nanometer scale. Results showed that a low friction coefficient (0.01 < $\\mu$ < 0.05) is obtained when the two additives are present. This is due to the favourable configuration of MoS2 planes sliding over each other when the pressure is sufficiently high, which is enabled by the presence of ZDTP. Through nanoindentation experiments and a simple stiffness measurement model, the layered structure and rheological properties can also be observed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0338}
{"prompt": "Rephrase the abstract of an article with title 'On the geometry of generalized Gaussian distributions'.\n  In this paper we consider the space of those probability distributions which\nmaximize the $q$-R\\'enyi entropy. These distributions have the same parameter\nspace for every $q$, and in the $q=1$ case these are the normal distributions.\nSome methods to endow this parameter space with Riemannian metric is presented:\nthe second derivative of the $q$-R\\'enyi entropy, Tsallis-entropy and the\nrelative entropy give rise to a Riemannian metric, the Fisher-information\nmatrix is a natural Riemannian metric, and there are some geometrically\nmotivated metrics which were studied by Siegel, Calvo and Oller, Lovri\\'c,\nMin-Oo and Ruh. These metrics are different therefore our differential\ngeometrical calculations based on a unified metric, which covers all the above\nmentioned metrics among others. We also compute the geometrical properties of\nthis metric, the equation of the geodesic line with some special solutions, the\nRiemann and Ricci curvature tensors and scalar curvature. Using the\ncorrespondence between the volume of the geodesic ball and the scalar curvature\nwe show how the parameter $q$ modulates the statistical distinguishability of\nclose points. We show that some frequently used metric in quantum information\ngeometry can be easily recovered from classical metrics.\n\n", "human_text": "  In this paper we consider the space of those probability distributions which\nmaximize the $q$-R\\'enyi entropy. These distributions have the same parameter\nspace for every $q$, and in the $q=1$ case these are the normal distributions.\nSome methods to endow this parameter space with Riemannian metric is presented:\nthe second derivative of the $q$-R\\'enyi entropy, Tsallis-entropy and the\nrelative entropy give rise to a Riemannian metric, the Fisher-information\nmatrix is a natural Riemannian metric, and there are some geometrically\nmotivated metrics which were studied by Siegel, Calvo and Oller, Lovri\\'c,\nMin-Oo and Ruh. These metrics are different therefore our differential\ngeometrical calculations based on a unified metric, which covers all the above\nmentioned metrics among others. We also compute the geometrical properties of\nthis metric, the equation of the geodesic line with some special solutions, the\nRiemann and Ricci curvature tensors and scalar curvature. Using the\ncorrespondence between the volume of the geodesic ball and the scalar curvature\nwe show how the parameter $q$ modulates the statistical distinguishability of\nclose points. We show that some frequently used metric in quantum information\ngeometry can be easily recovered from classical metrics.\n", "machine_text": "This paper examines the geometrical properties of probability distributions that maximize the $q$-R\\'enyi entropy. Such distributions contain the normal distributions as a special case ($q=1$). We provide methods to equip the parameter space of these distributions with a Riemannian metric, which includes the second derivative of the $q$-R\\'enyi entropy, Tsallis-entropy, the relative entropy, the Fisher-information matrix, and geometrically motivated metrics studied by Siegel, Calvo and Oller, Lovri\\'c, Min-Oo, and Ruh. We calculate the geometrical features of this unified metric, including the equation of its geodesic lines and the Riemann and Ricci curvature tensors and scalar curvature. Then we demonstrate how these calculations can be used to show how the parameter $q$ affects the statistical distinguishability of nearby points. Furthermore, we reveal the relationship between the classical metrics and the metrics used in the field of quantum information geometry.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0606}
{"prompt": "Rephrase the abstract of an article with title 'Relaxation dynamics in fluids of platelike colloidal particles'.\n  The relaxation dynamics of a model fluid of platelike colloidal particles is\ninvestigated by means of a phenomenological dynamic density functional theory.\nThe model fluid approximates the particles within the Zwanzig model of\nrestricted orientations. The driving force for time-dependence is expressed\ncompletely by gradients of the local chemical potential which in turn is\nderived from a density functional -- hydrodynamic interactions are not taken\ninto account. These approximations are expected to lead to qualitatively\nreliable results for low densities as those within the isotropic-nematic\ntwo-phase region. The formalism is applied to model an initially spatially\nhomogeneous stable or metastable isotropic fluid which is perturbed by\nswitching a two-dimensional array of Gaussian laser beams. Switching on the\nlaser beams leads to an accumulation of colloidal particles in the beam\ncenters. If the initial chemical potential and the laser power are large enough\na preferred orientation of particles occurs breaking the symmetry of the laser\npotential. After switching off the laser beams again the system can follow\ndifferent relaxation paths: It either relaxes back to the homogeneous isotropic\nstate or it forms an approximately elliptical high-density core which is\nelongated perpendicular to the dominating orientation in order to minimize the\nsurface free energy. For large supersaturations of the initial isotropic fluid\nthe high-density cores of neighboring laser beams of the two-dimensional array\nmerge into complex superstructures.\n\n", "human_text": "  The relaxation dynamics of a model fluid of platelike colloidal particles is\ninvestigated by means of a phenomenological dynamic density functional theory.\nThe model fluid approximates the particles within the Zwanzig model of\nrestricted orientations. The driving force for time-dependence is expressed\ncompletely by gradients of the local chemical potential which in turn is\nderived from a density functional -- hydrodynamic interactions are not taken\ninto account. These approximations are expected to lead to qualitatively\nreliable results for low densities as those within the isotropic-nematic\ntwo-phase region. The formalism is applied to model an initially spatially\nhomogeneous stable or metastable isotropic fluid which is perturbed by\nswitching a two-dimensional array of Gaussian laser beams. Switching on the\nlaser beams leads to an accumulation of colloidal particles in the beam\ncenters. If the initial chemical potential and the laser power are large enough\na preferred orientation of particles occurs breaking the symmetry of the laser\npotential. After switching off the laser beams again the system can follow\ndifferent relaxation paths: It either relaxes back to the homogeneous isotropic\nstate or it forms an approximately elliptical high-density core which is\nelongated perpendicular to the dominating orientation in order to minimize the\nsurface free energy. For large supersaturations of the initial isotropic fluid\nthe high-density cores of neighboring laser beams of the two-dimensional array\nmerge into complex superstructures.\n", "machine_text": "\nThis paper explores the fluid dynamics of platelike colloidal particles using\na phenomonological dynamic density functional theory. In this model, the driving\nforce behind the time-dependent behavior of the system is based on local\nchemical potential gradients, while hydrodynamic effects are excluded. Using\nthis approach, this paper looks at how a homogenous and stable isotropic fluid\nof colloidal particles interacts with a two-dimensional array of beam lasers.\nThe main effects of the laser beams are that the colloidal particles will\naccumulate in the center of the beam, and that a preferred orientation in the\nparticles breaks the symmetry of the beam. After the laser is switched off, the\nparticles will either relax and return to the initial homogenous state, or form\na high-density core that is elongated perpendicular to the dominant orientation\nto minimize surface free energy. Under certain conditions, high-density cores\nof neighboring lasers can merge, forming complex superstructures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0104}
{"prompt": "Rephrase the abstract of an article with title 'Network statistics on early English Syntax: Structural criteria'.\n  This paper includes a reflection on the role of networks in the study of\nEnglish language acquisition, as well as a collection of practical criteria to\nannotate free-speech corpora from children utterances. At the theoretical\nlevel, the main claim of this paper is that syntactic networks should be\ninterpreted as the outcome of the use of the syntactic machinery. Thus, the\nintrinsic features of such machinery are not accessible directly from (known)\nnetwork properties. Rather, what one can see are the global patterns of its use\nand, thus, a global view of the power and organization of the underlying\ngrammar. Taking a look into more practical issues, the paper examines how to\nbuild a net from the projection of syntactic relations. Recall that, as opposed\nto adult grammars, early-child language has not a well-defined concept of\nstructure. To overcome such difficulty, we develop a set of systematic criteria\nassuming constituency hierarchy and a grammar based on lexico-thematic\nrelations. At the end, what we obtain is a well defined corpora annotation that\nenables us i) to perform statistics on the size of structures and ii) to build\na network from syntactic relations over which we can perform the standard\nmeasures of complexity. We also provide a detailed example.\n\n", "human_text": "  This paper includes a reflection on the role of networks in the study of\nEnglish language acquisition, as well as a collection of practical criteria to\nannotate free-speech corpora from children utterances. At the theoretical\nlevel, the main claim of this paper is that syntactic networks should be\ninterpreted as the outcome of the use of the syntactic machinery. Thus, the\nintrinsic features of such machinery are not accessible directly from (known)\nnetwork properties. Rather, what one can see are the global patterns of its use\nand, thus, a global view of the power and organization of the underlying\ngrammar. Taking a look into more practical issues, the paper examines how to\nbuild a net from the projection of syntactic relations. Recall that, as opposed\nto adult grammars, early-child language has not a well-defined concept of\nstructure. To overcome such difficulty, we develop a set of systematic criteria\nassuming constituency hierarchy and a grammar based on lexico-thematic\nrelations. At the end, what we obtain is a well defined corpora annotation that\nenables us i) to perform statistics on the size of structures and ii) to build\na network from syntactic relations over which we can perform the standard\nmeasures of complexity. We also provide a detailed example.\n", "machine_text": "\nThis article explores the potential utility of network statistics in exploring early English syntax. With an emphasis on structural criteria, the paper assesses the possibility of using networks to analyze the language production of children. It proposes that networks can capture global patterns of grammatical usage as opposed to intrinsic features of grammar, allowing for the creation and analysis of a corpus of annotated texts. Guidelines are provided for building networks using projections of syntactic relations in early language, along with a methodology for completing the annotation process in a way that equips statisticians to do research on the size of structures, as well as assess the overall complexity presented. An example is given to illustrate the steps taken.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3708}
{"prompt": "Rephrase the abstract of an article with title 'One- and two-component bottle-brush polymers: simulations compared to\n  theoretical predictions'.\n  Scaling predictions and results from self-consistent field calculations for\nbottle-brush polymers with a rigid backbone and flexible side chains under good\nsolvent conditions are summarized and their validity and applicability is\nassessed by a comparison with Monte Carlo simulations of a simple lattice\nmodel. It is shown that under typical conditions, as they are also present in\nexperiments, only a rather weak stretching of the side chains is realized, and\nthen the scaling predictions based on the extension of the Daoud-Cotton blob\npicture are not applicable.\n  Also two-component bottle brush polymers are considered, where two types\n(A,B) of side chains are grafted, assuming that monomers of different kind\nrepel each other. In this case, variable solvent quality is allowed for, such\nthat for poor solvent conditions rather dense cylinder-like structures result.\nTheories predict ``Janus Cylinder''-type phase separation along the backbone in\nthis case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth\nmethod (PERM) then are restricted to rather short side chain length.\nNevertheless, evidence is obtained that the phase separation between an A-rich\npart of the cylindrical molecule and a B-rich part can only occur locally. The\ncorrelation length of this microphase separation can be controlled by the\nsolvent quality. This lack of a phase transition is interpreted by an analogy\nwith models for ferromagnets in one space dimension.\n\n", "human_text": "  Scaling predictions and results from self-consistent field calculations for\nbottle-brush polymers with a rigid backbone and flexible side chains under good\nsolvent conditions are summarized and their validity and applicability is\nassessed by a comparison with Monte Carlo simulations of a simple lattice\nmodel. It is shown that under typical conditions, as they are also present in\nexperiments, only a rather weak stretching of the side chains is realized, and\nthen the scaling predictions based on the extension of the Daoud-Cotton blob\npicture are not applicable.\n  Also two-component bottle brush polymers are considered, where two types\n(A,B) of side chains are grafted, assuming that monomers of different kind\nrepel each other. In this case, variable solvent quality is allowed for, such\nthat for poor solvent conditions rather dense cylinder-like structures result.\nTheories predict ``Janus Cylinder''-type phase separation along the backbone in\nthis case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth\nmethod (PERM) then are restricted to rather short side chain length.\nNevertheless, evidence is obtained that the phase separation between an A-rich\npart of the cylindrical molecule and a B-rich part can only occur locally. The\ncorrelation length of this microphase separation can be controlled by the\nsolvent quality. This lack of a phase transition is interpreted by an analogy\nwith models for ferromagnets in one space dimension.\n", "machine_text": "\nThis study looks at the theoretical predictions and scaling predictions regarding bottle-brush polymers with a rigid backbone and flexible side chains in good solvent conditions. Self-consistent field calculations and Monte Carlo simulations of a simple lattice model are used in order to assess the validity and applicability of these predictions. Results show that the predicted stretching of side chains is relatively low and they may not accurately apply in typical experimental conditions. Two-component bottle brush polymers with two types (A,B) of side chains that repel each other are also analyzed. Poor solvent conditions are found to create cylinder-like structures and theories suggest Janus Cylinder-type phase separation in this case. Monte Carlo simulations using the pruned-enriched Rosenbluth method (PERM) suggest the lack of phase transition with correlation length that can be controlled by solvent quality. This is explained through an analogy of one-dimensional ferromagnetic models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1124}
{"prompt": "Rephrase the abstract of an article with title 'The Leo Elliptical NGC 3379: A Metal-Poor Halo Emerges'.\n  We have used the ACS camera on HST to obtain (V,I) photometry for 5300\nred-giant stars in the halo of the dominant Leo-group member NGC 3379, a galaxy\nusually regarded as a classic normal giant elliptical. We use this sample of\nstars to derive the metallicity distribution function (MDF) for its outer-halo\nfield stars 33 kpc from the galaxy center. The MDF is distinctly unlike all the\nother E galaxies for which we have similar data (including the Local Group\ndwarf ellipticals, the intermediate-luminosity NGC 3377, and the giant NGC\n5128). First, the MDF for the NGC 3379 outer halo is broad and flat, with many\nstars at every interval in [m/H]. Second, we see a metallicity gradient across\nour ACS field such that in its outermost region the blue, low-metallicity stars\n([m/H] < -0.7) are beginning to dominate and the higher-metallicity stars are\nrapidly diminishing. Our target field is centered at a projected distance about\nequal to 12 R_e, twice as far out in units of effective radius as in any of the\nother galaxies that we have surveyed. If NGC 3379 is indeed representative of\nlarge E/S0 galaxies, we predict that such galaxies in general will reveal\ndiffuse low-metallicity subpopulations, but that photometry at radii r ~ 10 -\n15 R_e will be necessary to see the faint low-metallicity component clearly.\n\n", "human_text": "  We have used the ACS camera on HST to obtain (V,I) photometry for 5300\nred-giant stars in the halo of the dominant Leo-group member NGC 3379, a galaxy\nusually regarded as a classic normal giant elliptical. We use this sample of\nstars to derive the metallicity distribution function (MDF) for its outer-halo\nfield stars 33 kpc from the galaxy center. The MDF is distinctly unlike all the\nother E galaxies for which we have similar data (including the Local Group\ndwarf ellipticals, the intermediate-luminosity NGC 3377, and the giant NGC\n5128). First, the MDF for the NGC 3379 outer halo is broad and flat, with many\nstars at every interval in [m/H]. Second, we see a metallicity gradient across\nour ACS field such that in its outermost region the blue, low-metallicity stars\n([m/H] < -0.7) are beginning to dominate and the higher-metallicity stars are\nrapidly diminishing. Our target field is centered at a projected distance about\nequal to 12 R_e, twice as far out in units of effective radius as in any of the\nother galaxies that we have surveyed. If NGC 3379 is indeed representative of\nlarge E/S0 galaxies, we predict that such galaxies in general will reveal\ndiffuse low-metallicity subpopulations, but that photometry at radii r ~ 10 -\n15 R_e will be necessary to see the faint low-metallicity component clearly.\n", "machine_text": "\nUsing the ACS camera on the Hubble Space Telescope, photometry of over 5,000 red-giant stars in the outer halo of NGC 3379, a classic normal giant elliptical and member of the Leo-group, was obtained. After compiling the metallicity distribution function (MDF) for the field stars located 33kpc from the galaxy center, distinctive properties of NGC 3379's outer halo emerged. The MDF was broad and flat, with metal-poor stars dominating in the outermost region. With our ACS field centered at a projected distance equivalent to 12 effective radii, we believe that giant E/S0 galaxies in general will have low-metallicity subpopulations, but that in order to observe them more distant photometry will be required.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1995}
{"prompt": "Rephrase the abstract of an article with title 'Search for pulsation among suspected A-type binaries and the new\n  multiperiodic Delta Scuti star HD217860'.\n  We have explored a sample of suspected A-type binaries in a systematic way,\nboth spectroscopically and photometrically. Due to their location in the H-R\ndiagram, indications of pulsation and/or chemical peculiarities among these\nsuspected binary (or multiple) systems may be found. High-resolution\nspectroscopy obtained with the ELODIE and MUSICOS spectrographs was used in\ncombination with a few nights of differential CCD photometry in order to search\nfor pulsation(s). Of the 32 investigated targets, eight are spectroscopic\nbinaries, one of which is a close binary also showing eclipses, and three have\nbeen identified as Delta Scuti pulsators with rapid line-profile variations.\nAmong the latter stars, HD 217860 reveals interesting multiperiodic photometric\nand spectroscopic variations, with up to eight frequencies common to two large\nphotometric data sets. We suggest that at least one radial overtone mode is\nexcited among the two most dominant frequencies. We furthermore found evidence\nfor a strong modulation of the amplitude(s) and/or the (radial) frequency\ncontent of this intriguing Delta Scuti star.\n\n", "human_text": "  We have explored a sample of suspected A-type binaries in a systematic way,\nboth spectroscopically and photometrically. Due to their location in the H-R\ndiagram, indications of pulsation and/or chemical peculiarities among these\nsuspected binary (or multiple) systems may be found. High-resolution\nspectroscopy obtained with the ELODIE and MUSICOS spectrographs was used in\ncombination with a few nights of differential CCD photometry in order to search\nfor pulsation(s). Of the 32 investigated targets, eight are spectroscopic\nbinaries, one of which is a close binary also showing eclipses, and three have\nbeen identified as Delta Scuti pulsators with rapid line-profile variations.\nAmong the latter stars, HD 217860 reveals interesting multiperiodic photometric\nand spectroscopic variations, with up to eight frequencies common to two large\nphotometric data sets. We suggest that at least one radial overtone mode is\nexcited among the two most dominant frequencies. We furthermore found evidence\nfor a strong modulation of the amplitude(s) and/or the (radial) frequency\ncontent of this intriguing Delta Scuti star.\n", "machine_text": "\nThis study conducted an extensive investigation of suspected A-type binary systems, using high-resolution spectroscopy from ELODIE and MUSICOS and CCD photometry, to search for pulsations. Out of the 32 objects surveyed, 8 were spectroscopic binaries, one of which is a close binary exhibiting eclipses, and 3 were classified as Delta Scuti pulsators. One star in particular, HD 217860, was found to contain multiple periodic photometric and spectroscopic variations, with up to eight frequencies present in two large photometric datasets. This Delta Scuti star also showed signs of amplitude and/or frequency modulation. It is suspected that radial overtone modes are exciting the two strongest frequencies detected.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4587}
{"prompt": "Rephrase the abstract of an article with title 'And in the Darkness Bind Them: Equatorial Rings, B[e] Supergiants, and\n  the Waists of Bipolar Nebulae'.\n  We report the discovery of two new circumstellar ring nebulae in the western\nCarina Nebula. The brighter object, SBW1, resembles a lidless staring eye and\nencircles a B1.5 Iab supergiant. Its size is identical to the inner ring around\nSN1987A, but SBW1's low N abundance indicates that the star didn't pass through\na RSG phase. The fainter object, SBW2, is a more distorted ring, is N-rich, and\nhas a central star that seems to be invisible. We discuss these two new nebulae\nin context with rings around SN1987A, Sher25, HD168625, RY Scuti, WeBo1, SuWt2,\nand others. The ring bearers fall into two groups: Five rings surround hot\nsupergiants, and all except for the one known binary are carbon copies of the\nring around SN1987A. We propose a link between these rings and B[e]\nsupergiants, where the rings derive from the same material in an earlier B[e]\nphase. The remaining four rings surround evolved intermediate-mass stars; all\nmembers of this ring fellowship are close binaries, hinting that binary\ninteractions govern the forging of such rings. We estimate that there may be\nseveral thousand more dark rings in the Galaxy, but we are scarcely aware of\ntheir existence due to selection effects. The lower-mass objects might be the\nequatorial density enhancements often invoked to bind the waists of bipolar\nPNe.\n\n", "human_text": "  We report the discovery of two new circumstellar ring nebulae in the western\nCarina Nebula. The brighter object, SBW1, resembles a lidless staring eye and\nencircles a B1.5 Iab supergiant. Its size is identical to the inner ring around\nSN1987A, but SBW1's low N abundance indicates that the star didn't pass through\na RSG phase. The fainter object, SBW2, is a more distorted ring, is N-rich, and\nhas a central star that seems to be invisible. We discuss these two new nebulae\nin context with rings around SN1987A, Sher25, HD168625, RY Scuti, WeBo1, SuWt2,\nand others. The ring bearers fall into two groups: Five rings surround hot\nsupergiants, and all except for the one known binary are carbon copies of the\nring around SN1987A. We propose a link between these rings and B[e]\nsupergiants, where the rings derive from the same material in an earlier B[e]\nphase. The remaining four rings surround evolved intermediate-mass stars; all\nmembers of this ring fellowship are close binaries, hinting that binary\ninteractions govern the forging of such rings. We estimate that there may be\nseveral thousand more dark rings in the Galaxy, but we are scarcely aware of\ntheir existence due to selection effects. The lower-mass objects might be the\nequatorial density enhancements often invoked to bind the waists of bipolar\nPNe.\n", "machine_text": "In this article, the discovery of two unique circumstellar rings in the western Carina Nebula is reported. These rings, labelled SBW1 and SBW2, differ in composition and age and encircle stars of different mass. Further examination of these two discoveries alongside a sample of other well-known rings reveals two categories: those around hot supergiants, and those around evolved intermediate mass stars in binary systems. The relationship between B[e] supergiants and the former group, as well as the possibility of thousands more dark rings in the Milky Way, is suggested. Finally, the possible connection between these rings and the equatorial density enhancements often invoked to bind the waists of bipolar planetary nebulae is discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3054}
{"prompt": "Rephrase the abstract of an article with title 'Fourier analysis of active-region plage'.\n  We study the dynamical interaction of the solar chromosphere with the\ntransition region in mossy and non-mossy active-region plage. We carefully\nalign image sequences taken with the Transition Region And Coronal Explorer\n(TRACE) in the ultraviolet passbands around 1550, 1600, and 1700 A and the\nextreme ultraviolet passbands at 171 and 195 A. We compute Fourier\nphase-difference spectra that are spatially averaged separately over mossy and\nnon-mossy plage to study temporal modulations as a function of temporal\nfrequency. The 1550 versus 171 A comparison shows zero phase difference in\nnon-mossy plage. In mossy plage, the phase differences between all UV and EUV\npassbands show pronounced upward trends with increasing frequency, which\nabruptly changes into zero phase difference beyond 4-6 mHz. The phase\ndifference between the 171 and 195 A sequences exhibits a shallow dip below 3\nmHz and then also turns to zero phase difference beyond this value. We\nattribute the various similarities between the UV and EUV diagnostics that are\nevident in the phase-difference diagrams to the contribution of the C IV\nresonance lines in the 1550 and 1600 A passbands. The strong upward trend at\nthe lower frequencies indicates the presence of upward-traveling disturbances.\nIt points to correspondence between the lower chromosphere and the upper\ntransition region, perhaps by slow-mode magnetosonic disturbances, or by a\nconnection between chromospheric and coronal heating mechanisms. The transition\nfrom this upward trend to zero phase difference at higher frequencies is due to\nthe intermittent obscuration by fibrils that occult the foot points of hot\nloops, which are bright in the EUV and C IV lines, in oscillatory manner.\n\n", "human_text": "  We study the dynamical interaction of the solar chromosphere with the\ntransition region in mossy and non-mossy active-region plage. We carefully\nalign image sequences taken with the Transition Region And Coronal Explorer\n(TRACE) in the ultraviolet passbands around 1550, 1600, and 1700 A and the\nextreme ultraviolet passbands at 171 and 195 A. We compute Fourier\nphase-difference spectra that are spatially averaged separately over mossy and\nnon-mossy plage to study temporal modulations as a function of temporal\nfrequency. The 1550 versus 171 A comparison shows zero phase difference in\nnon-mossy plage. In mossy plage, the phase differences between all UV and EUV\npassbands show pronounced upward trends with increasing frequency, which\nabruptly changes into zero phase difference beyond 4-6 mHz. The phase\ndifference between the 171 and 195 A sequences exhibits a shallow dip below 3\nmHz and then also turns to zero phase difference beyond this value. We\nattribute the various similarities between the UV and EUV diagnostics that are\nevident in the phase-difference diagrams to the contribution of the C IV\nresonance lines in the 1550 and 1600 A passbands. The strong upward trend at\nthe lower frequencies indicates the presence of upward-traveling disturbances.\nIt points to correspondence between the lower chromosphere and the upper\ntransition region, perhaps by slow-mode magnetosonic disturbances, or by a\nconnection between chromospheric and coronal heating mechanisms. The transition\nfrom this upward trend to zero phase difference at higher frequencies is due to\nthe intermittent obscuration by fibrils that occult the foot points of hot\nloops, which are bright in the EUV and C IV lines, in oscillatory manner.\n", "machine_text": "\nBy applying Fourier analysis, we examine the dynamic relationship between the chromosphere and the transition region of active-region plage, whether it is mossy or non-mossy. We utilize image sequences gathered by the Transition Region And Coronal Explorer (TRACE) in different ultraviolet and extreme ultraviolet passbands. The results of this analysis show that in the non-mossy plage, there is a zero phase difference between 1550 and 171 A. For mossy plage, there is an inclined trend in the phase difference spectra when the frequency rises, with no phase difference beyond the 4-6 mHz rate. The phase difference diagrams between 171 and 195 A is unusually shallow at 3 mHz and then again turns to no phase difference afterwards. We believe that the same resemblance between the UV and EUV bands are credited to the collaboration of the C IV resonance lines in 1550 and 1600 A, whereas the steep incline in the low frequencies make evident the presence of upward-travelling disturbances. This trend turning to zero phase difference at greater frequencies is likely due to the obscuration of the hot loop's foot points by oscillating fibrils in the higher frequencies. With these results, it may be suggested that there is a connection between chromospheric and coronal heating mechanisms that involves the slow-mode magnetosonic disturbance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2014}
{"prompt": "Rephrase the abstract of an article with title 'Charmless B decays to a scalar meson and a vector meson'.\n  The hadronic charmless B decays into a scalar meson and a vector meson are\nstudied within the framework of QCD factorization. The main results are: (i)\nThe decay rates for the $f_0(980)K^{*-}$ and $f_0(980)\\ov K^{*0}$ modes depend\non the $f_0-\\sigma$ mixing angle $\\theta$. The experimental measurements can be\naccommodated for $\\theta\\approx 20^\\circ$. (ii) If the $a_0(980)$ is a $q\\bar\nq$ bound state, the predicted branching ratios for the channels $a_0^+\\rho^-$\nand $a_0^0\\rho^-$ will be very large, of order $30\\times 10^{-6}$ and $23\\times\n10^{-6}$, respectively. If the observation of or the experimental limit on\ntheses two modes is much smaller than the expectation of $\\sim 25\\times\n10^{-6}$, this could hint at a four-quark nature for the $a_0(980)$. (iii) For\nthe $a_0(1450)$ channels, $a_0^+(1450)\\rho^-$ and $a_0^0(1450)\\rho^-$ are found\nto have branching ratios of order $16\\times 10^{-6}$ and $22\\times 10^{-6}$,\nrespectively. A measurement of them at the predicted level will favor the\n$q\\bar q$ structure for the $a_0(1450)$. (iv) Contrary to the naive expectation\nthat $\\Gamma(B^-\\to a_0^0\\rho^-)\\sim {1\\over 2}\\Gamma(\\bar B^0\\to\na_0^+\\rho^-)$, we found that they have comparable rates due to additional\ncontributions to the $a_0\\rho^-$ mode from the $a_0^0$ emission. (v) The\npredicted central value of $Br(\\bar B^0\\to\\ov K^{*0}_0(1430)\\phi)$ is larger\nthan experiment, though it can be accommodated within theoretical errors. The\ndecays $B\\to K^{*}_0(1430)\\rho$ are expected to have rates substantially larger\nthan that of $B\\to K^{*}_0(1430)\\pi$ owing to the constructive (destructive)\ninterference between the $a_4$ and $a_6$ penguin terms in the former (latter).\nExperimentally, it is thus important to check if the $B\\to K^{*}_0\\rho$ modes\nare enhanced relative to the corresponding $K_0^*\\pi$ channels.\n\n", "human_text": "  The hadronic charmless B decays into a scalar meson and a vector meson are\nstudied within the framework of QCD factorization. The main results are: (i)\nThe decay rates for the $f_0(980)K^{*-}$ and $f_0(980)\\ov K^{*0}$ modes depend\non the $f_0-\\sigma$ mixing angle $\\theta$. The experimental measurements can be\naccommodated for $\\theta\\approx 20^\\circ$. (ii) If the $a_0(980)$ is a $q\\bar\nq$ bound state, the predicted branching ratios for the channels $a_0^+\\rho^-$\nand $a_0^0\\rho^-$ will be very large, of order $30\\times 10^{-6}$ and $23\\times\n10^{-6}$, respectively. If the observation of or the experimental limit on\ntheses two modes is much smaller than the expectation of $\\sim 25\\times\n10^{-6}$, this could hint at a four-quark nature for the $a_0(980)$. (iii) For\nthe $a_0(1450)$ channels, $a_0^+(1450)\\rho^-$ and $a_0^0(1450)\\rho^-$ are found\nto have branching ratios of order $16\\times 10^{-6}$ and $22\\times 10^{-6}$,\nrespectively. A measurement of them at the predicted level will favor the\n$q\\bar q$ structure for the $a_0(1450)$. (iv) Contrary to the naive expectation\nthat $\\Gamma(B^-\\to a_0^0\\rho^-)\\sim {1\\over 2}\\Gamma(\\bar B^0\\to\na_0^+\\rho^-)$, we found that they have comparable rates due to additional\ncontributions to the $a_0\\rho^-$ mode from the $a_0^0$ emission. (v) The\npredicted central value of $Br(\\bar B^0\\to\\ov K^{*0}_0(1430)\\phi)$ is larger\nthan experiment, though it can be accommodated within theoretical errors. The\ndecays $B\\to K^{*}_0(1430)\\rho$ are expected to have rates substantially larger\nthan that of $B\\to K^{*}_0(1430)\\pi$ owing to the constructive (destructive)\ninterference between the $a_4$ and $a_6$ penguin terms in the former (latter).\nExperimentally, it is thus important to check if the $B\\to K^{*}_0\\rho$ modes\nare enhanced relative to the corresponding $K_0^*\\pi$ channels.\n", "machine_text": "In this work, the decay of charmless B mesons to a scalar meson and a vector meson are analyzed using the QCD factorization approach. It is found that the decays $f_0(980)K^{*-}$ and $f_0(980)\\ov K^{*0}$ depend on the $f_0-\\sigma$ mixing angle, and experimental results suggest $\\theta\\approx 20^\\circ$. Additionally, the $a_0(980)$ could have a four-quark nature if the observed or predicted $a_0^+\\rho^-$ and $a_0^0\\rho^-$ branching ratios, which are estimated to be approximately $30\\times 10^{-6}$ and $23\\times 10^{-6}$ respectively, were found to be much smaller than expected. Moreover, measured decay rates of $a_0^+(1450)\\rho^-$ and $a_0^0(1450)\\rho^-$ of around $16\\times 10^{-6}$ and $22\\times 10^{-6}$, respectively, are expected to support the $q\\bar q$ structure for the $a_0(1450)$. Finally, the $B\\to K^{*}_0(1430)\\rho$ mode is found to have a substantial rate due to constructive interference between the $a_4$ and $a_6$ penguin terms and should be checked against the $B\\to K^{*}_0(1430)\\pi$ channels.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3079}
{"prompt": "Rephrase the abstract of an article with title 'Iron abundances of B-type post-Asymptotic Giant Branch stars in globular\n  clusters: Barnard 29 in M 13 and ROA 5701 in omega Cen'.\n  High resolution optical and ultraviolet spectra of two B-type post-Asymptotic\nGiant Branch (post-AGB) stars in globular clusters, Barnard 29 in M 13 and ROA\n5701 in omega Cen, have been analysed using model atmosphere techniques. The\noptical spectra have been obtained with FEROS on the ESO 2.2-m telescope and\nthe 2d-Coud\\'e spectrograph on the 2.7-m McDonald telescope, while the\nultraviolet observations are from the GHRS on the HST. Abundances of light\nelements (C, N, O, Mg, Al and S) plus Fe have been determined from the optical\nspectra, while the ultraviolet data provide additional Fe abundance estimates\nfrom Fe III absorption lines in the 1875-1900 {\\AA} wavelength region. A\ngeneral metal underabundance relative to young B-type stars is found for both\nBarnard 29 and ROA 5701. These results are consistent with the metallicities of\nthe respective clusters, as well as with previous studies of the objects. The\nderived abundance patterns suggest that the stars have not undergone a gas-dust\nseparation, contrary to previous suggestions, although they may have evolved\nfrom the AGB before the onset of the third dredge-up. However, the Fe\nabundances derived from the HST spectra are lower than those expected from the\nmetallicities of the respective clusters, by 0.5 dex for Barnard 29 and 0.8 dex\nfor ROA 5701. A similar systematic underabundance is also found for other\nB-type stars in environments of known metallicity, such as the Magellanic\nClouds. These results indicate that the Fe III ultraviolet lines may yield\nabundance values which are systematically too low by typically 0.6 dex and\nhence such estimates should be treated with caution.\n\n", "human_text": "  High resolution optical and ultraviolet spectra of two B-type post-Asymptotic\nGiant Branch (post-AGB) stars in globular clusters, Barnard 29 in M 13 and ROA\n5701 in omega Cen, have been analysed using model atmosphere techniques. The\noptical spectra have been obtained with FEROS on the ESO 2.2-m telescope and\nthe 2d-Coud\\'e spectrograph on the 2.7-m McDonald telescope, while the\nultraviolet observations are from the GHRS on the HST. Abundances of light\nelements (C, N, O, Mg, Al and S) plus Fe have been determined from the optical\nspectra, while the ultraviolet data provide additional Fe abundance estimates\nfrom Fe III absorption lines in the 1875-1900 {\\AA} wavelength region. A\ngeneral metal underabundance relative to young B-type stars is found for both\nBarnard 29 and ROA 5701. These results are consistent with the metallicities of\nthe respective clusters, as well as with previous studies of the objects. The\nderived abundance patterns suggest that the stars have not undergone a gas-dust\nseparation, contrary to previous suggestions, although they may have evolved\nfrom the AGB before the onset of the third dredge-up. However, the Fe\nabundances derived from the HST spectra are lower than those expected from the\nmetallicities of the respective clusters, by 0.5 dex for Barnard 29 and 0.8 dex\nfor ROA 5701. A similar systematic underabundance is also found for other\nB-type stars in environments of known metallicity, such as the Magellanic\nClouds. These results indicate that the Fe III ultraviolet lines may yield\nabundance values which are systematically too low by typically 0.6 dex and\nhence such estimates should be treated with caution.\n", "machine_text": "\nHigh resolution spectroscopic observations of two B-type post-Asymptotic Giant Branch (post-AGB) stars in globular clusters, Barnard 29 in M 13 and ROA 5701 in omega Cen have been made in both the optical and ultraviolet wavelengths. Using model atmosphere techniques, abundances of light element like C, N, O, Mg, Al and S, plus Fe have been determined from the optical spectra, while additional Fe abundance estimates were derived from Fe III absorption lines in the 1875-1900 {\\AA} wavelength range obtained from the GHRS on the HST. Both stars had abundances which were lower than those of young B-type stars, thus in agreement with the metallicity of the two respective clusters. However, the Fe abundances derived from the HST spectra were lower than expected from the clusters' metallicities, by 0.5 dex for Barnard 29 and 0.8 dex for ROA 5701. This same systematic underabundance was also found among other B-type stars, suggesting that the Fe III ultraviolet lines may be yielding values which are too low by circa 0.6 dex and thus must be treated with caution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2196}
{"prompt": "Rephrase the abstract of an article with title 'Symmetric and asymmetric solitons in linearly coupled Bose-Einstein\n  condensates trapped in optical lattices'.\n  We study spontaneous symmetry breaking in a system of two parallel\nquasi-one-dimensional traps, equipped with optical lattices (OLs) and filled\nwith a Bose-Einstein condensate (BEC). The cores are linearly coupled by\ntunneling. Analysis of the corresponding system of linearly coupled\nGross-Pitaevskii equations (GPEs) reveals that spectral bandgaps of the single\nGPE split into subgaps. Symmetry breaking in two-component BEC solitons is\nstudied in cases of the attractive (AA) and repulsive (RR) nonlinearity in both\ntraps; the mixed situation, with repulsion in one trap and attraction in the\nother (RA), is considered too. In all the cases, stable asymmetric solitons are\nfound, bifurcating from symmetric or antisymmetric ones (and destabilizing\nthem), in the AA and RR systems, respectively. In either case, bi-stability is\npredicted, with a nonbifurcating stable branch, either antisymmetric or\nsymmetric, coexisting with asymmetric ones. Solitons destabilized by the\nbifurcation tend to rearrange themselves into their stable asymmetric\ncounterparts. The impact of a phase mismatch, between the OLs in the two cores\nis also studied. Also considered is a related model, for a binary BEC in a\nsingle-core trap with the OL, assuming that the two species (representing\ndifferent spin states of the same atom) are coupled by linear interconversion.\nIn that case, the symmetry-breaking bifurcations in the AA and RR models switch\ntheir character, if the inter-species nonlinear interaction becomes stronger\nthan the intra-species nonlinearity.\n\n", "human_text": "  We study spontaneous symmetry breaking in a system of two parallel\nquasi-one-dimensional traps, equipped with optical lattices (OLs) and filled\nwith a Bose-Einstein condensate (BEC). The cores are linearly coupled by\ntunneling. Analysis of the corresponding system of linearly coupled\nGross-Pitaevskii equations (GPEs) reveals that spectral bandgaps of the single\nGPE split into subgaps. Symmetry breaking in two-component BEC solitons is\nstudied in cases of the attractive (AA) and repulsive (RR) nonlinearity in both\ntraps; the mixed situation, with repulsion in one trap and attraction in the\nother (RA), is considered too. In all the cases, stable asymmetric solitons are\nfound, bifurcating from symmetric or antisymmetric ones (and destabilizing\nthem), in the AA and RR systems, respectively. In either case, bi-stability is\npredicted, with a nonbifurcating stable branch, either antisymmetric or\nsymmetric, coexisting with asymmetric ones. Solitons destabilized by the\nbifurcation tend to rearrange themselves into their stable asymmetric\ncounterparts. The impact of a phase mismatch, between the OLs in the two cores\nis also studied. Also considered is a related model, for a binary BEC in a\nsingle-core trap with the OL, assuming that the two species (representing\ndifferent spin states of the same atom) are coupled by linear interconversion.\nIn that case, the symmetry-breaking bifurcations in the AA and RR models switch\ntheir character, if the inter-species nonlinear interaction becomes stronger\nthan the intra-species nonlinearity.\n", "machine_text": "\nWe analyze the effects of symmetry breaking on solitons in a dual system of\nlinearly coupled traps containing a Bose-Einstein condensate (BEC), which are\nfilled with optical lattices. We use the Gross-Pitaevskii equations to\ninvestigate the situation in both cases of attractive and repulsive\nnonlinearities, as well as for the combination of repulsive and attractive\ninteractions. As a result, stable asymmetric solitons are found in all cases,\nemerging from symmetric or antisymmetric solitons during the bifurcation\nprocess, and coexisting with the formerly stable configuration. Additionally,\nthe impact of a phase mismatch between the optical lattices in the two\ntraps is reviewed. We also consider the relation between binary BECs in a\nsingle-core trap, involving transitions between two species within the same\natom, and the relative strength of intra- and inter-species nonlinear\ninteractions. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0364}
{"prompt": "Rephrase the abstract of an article with title 'Exciting the Magnetosphere of the Magnetar CXOU J164710.2-455216 in\n  Westerlund 1'.\n  We describe XMM-Newton observations taken 4.3 days prior to and 1.5 days\nsubsequent to two remarkable events that were detected with Swift on 2006\nSeptember 21 from the candidate magnetar CXOU J164710.2-455216: (1) a 20 ms\nburst with an energy of 1e37 erg (15-150 keV), and (2) a rapid spin-down\n(glitch) with a fractionap period change of 1e-4. We find that the luminosity\nof the pulsar increased by a factor of 100 in the interval between\nobservations, from 1e33 to 1e35 erg/s (0.5-8.0 keV), and that its spectrum\nhardened. The pulsed count rate increased by a factor of 10 (0.5-8.0 keV), but\nthe fractional rms amplitude of the pulses decreased from 65 to 11 per cent,\nand their profile changed from being single-peaked to exhibiting three peaks.\nSimilar changes have been observed from other magnetars in response to\noutbursts, such as that of 1E 2259+586 in 2002 June. We suggest that a plastic\ndeformation of the neutron star's crust induced a very slight twist in the\nexternal magnetic field, which in turn generated currents in the magnetosphere\nthat were the direct cause of the X-ray outburst.\n\n", "human_text": "  We describe XMM-Newton observations taken 4.3 days prior to and 1.5 days\nsubsequent to two remarkable events that were detected with Swift on 2006\nSeptember 21 from the candidate magnetar CXOU J164710.2-455216: (1) a 20 ms\nburst with an energy of 1e37 erg (15-150 keV), and (2) a rapid spin-down\n(glitch) with a fractionap period change of 1e-4. We find that the luminosity\nof the pulsar increased by a factor of 100 in the interval between\nobservations, from 1e33 to 1e35 erg/s (0.5-8.0 keV), and that its spectrum\nhardened. The pulsed count rate increased by a factor of 10 (0.5-8.0 keV), but\nthe fractional rms amplitude of the pulses decreased from 65 to 11 per cent,\nand their profile changed from being single-peaked to exhibiting three peaks.\nSimilar changes have been observed from other magnetars in response to\noutbursts, such as that of 1E 2259+586 in 2002 June. We suggest that a plastic\ndeformation of the neutron star's crust induced a very slight twist in the\nexternal magnetic field, which in turn generated currents in the magnetosphere\nthat were the direct cause of the X-ray outburst.\n", "machine_text": "\nXMM-Newton observed CXOU J164710.2-455216, a candidate magnetar, in the Westerlund 1 region, four days before and one and a half days after two remarkable events detected by Swift on 2006 September 21. These included a 20 ms burst with an energy of 1e37 erg (15-150 keV), and a rapid spin-down (glitch) with a fractional period change of 1e-4. The pulsar's luminosity increased by a factor of 100 between the two observations, its spectrum hardened, and the count rate of its pulses rose by a factor of 10. Its fractional rms amplitude decreased from 65 to 11 per cent, and its pulse profile went from single-peaked to exhibiting three peaks. This behavior is similar to that of other magnetars in response to outbursts, such as that of 1E 2259+586 in 2002 June. It is suggested that a plastic deformation of the neutron star's crust led to a tiny twist in its external magnetic field, creating currents in the magnetosphere that were the direct cause of the X-ray outburst.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.163}
{"prompt": "Rephrase the abstract of an article with title 'Boutroux curves with external field: equilibrium measures without a\n  minimization problem'.\n  The nonlinear steepest descent method for rank-two systems relies on the\nnotion of g-function. The applicability of the method ranges from orthogonal\npolynomials (and generalizations) to Painleve transcendents, and integrable\nwave equations (KdV, NonLinear Schroedinger, etc.).\n  For the case of asymptotics of generalized orthogonal polynomials with\nrespect to varying complex weights we can recast the requirements for the\nCauchy-transform of the equilibrium measure into a problem of algebraic\ngeometry and harmonic analysis and completely solve the existence and\nuniqueness issue without relying on the minimization of a functional. This\naddresses and solves also the issue of the ``free boundary problem'',\ndetermining implicitly the curves where the zeroes of the orthogonal\npolynomials accumulate in the limit of large degrees and the support of the\nmeasure. The relevance to the quasi--linear Stokes phenomenon for Painleve\nequations is indicated. A numerical algorithm to find these curves in some\ncases is also explained.\n  Technical note: the animations included in the file can be viewed using\nAcrobat Reader 7 or higher. Mac users should also install a QuickTime plugin\ncalled Flip4Mac. Linux users can extract the embedded animations and play them\nwith an external program like VLC or MPlayer. All trademarks are owned by the\nrespective companies.\n\n", "human_text": "  The nonlinear steepest descent method for rank-two systems relies on the\nnotion of g-function. The applicability of the method ranges from orthogonal\npolynomials (and generalizations) to Painleve transcendents, and integrable\nwave equations (KdV, NonLinear Schroedinger, etc.).\n  For the case of asymptotics of generalized orthogonal polynomials with\nrespect to varying complex weights we can recast the requirements for the\nCauchy-transform of the equilibrium measure into a problem of algebraic\ngeometry and harmonic analysis and completely solve the existence and\nuniqueness issue without relying on the minimization of a functional. This\naddresses and solves also the issue of the ``free boundary problem'',\ndetermining implicitly the curves where the zeroes of the orthogonal\npolynomials accumulate in the limit of large degrees and the support of the\nmeasure. The relevance to the quasi--linear Stokes phenomenon for Painleve\nequations is indicated. A numerical algorithm to find these curves in some\ncases is also explained.\n  Technical note: the animations included in the file can be viewed using\nAcrobat Reader 7 or higher. Mac users should also install a QuickTime plugin\ncalled Flip4Mac. Linux users can extract the embedded animations and play them\nwith an external program like VLC or MPlayer. All trademarks are owned by the\nrespective companies.\n", "machine_text": "\nThis paper examines the utilization of the nonlinear steepest descent method for rank-two systems in the context of generalized orthogonal polynomials with regard to varying complex weights. By recasting the requirement for the Cauchy-transform of the equilibrium measure into a problem of algebraic geometry and harmonic analysis, a solution for the issue of existence and uniqueness is presented with the elimination of a minimization problem. In addition, this also tackles and solves the issue of the \"free boundary problem\" to discern implicit curves for the zeroes of orthogonal polynomials to accumulate in larger degrees and the support of the measure. Lastly, the relevance of the quasi-linear Stokes phenomenon for Painleve equations is outlined, and a numerical algorithm is provided to locate the curves in some cases. Technical instructions are provided for viewing the associated animations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3062}
{"prompt": "Rephrase the abstract of an article with title 'First study of the gluon-quark-antiquark static potential in SU(3)\n  Lattice QCD'.\n  We study the long distance interaction for hybrid hadrons, with a static\ngluon, a quark and an antiquark with lattice QCD techniques. A Wilson loop\nadequate to the static hybrid three-body system is developed and, using a 24^3\nx 48 periodic lattice with beta=6.2 and a ~ 0.075 fm, two different geometries\nfor the gluon-quark segment and the gluon-antiquark segment are investigated.\nWhen these segments are perpendicular, the static potential is compatible with\nconfinement realized with a pair of fundamental strings, one linking the gluon\nto the quark and another linking the same gluon to the antiquark. When the\nsegments are parallel and superposed, the total string tension is larger and\nagrees with the Casimir Scaling measured by Bali. This can be interpreted with\na type-II superconductor analogy for the confinement in QCD, with repulsion of\nthe fundamental strings and with the string tension of the first topological\nexcitation of the string (the adjoint string) larger than the double of the\nfundamental string tension.\n\n", "human_text": "  We study the long distance interaction for hybrid hadrons, with a static\ngluon, a quark and an antiquark with lattice QCD techniques. A Wilson loop\nadequate to the static hybrid three-body system is developed and, using a 24^3\nx 48 periodic lattice with beta=6.2 and a ~ 0.075 fm, two different geometries\nfor the gluon-quark segment and the gluon-antiquark segment are investigated.\nWhen these segments are perpendicular, the static potential is compatible with\nconfinement realized with a pair of fundamental strings, one linking the gluon\nto the quark and another linking the same gluon to the antiquark. When the\nsegments are parallel and superposed, the total string tension is larger and\nagrees with the Casimir Scaling measured by Bali. This can be interpreted with\na type-II superconductor analogy for the confinement in QCD, with repulsion of\nthe fundamental strings and with the string tension of the first topological\nexcitation of the string (the adjoint string) larger than the double of the\nfundamental string tension.\n", "machine_text": "\nUsing a lattice QCD approach, this is the first study of the static potential of a three-body system made of a gluon, a quark and an antiquark for hybrid hadrons. Through comparing two geometries for the gluon-quark and gluon-antiquark segments, namely when they are perpendicular and when they are parallel and superposed, it is observed that the string tension follows Casimir scaling. Its interpretation suggests the possibility of a type-II superconductor analogy for the confinement in QCD. This indicates a repulsion of the fundamental strings and a string tension for the first topological excitation (adjoint string) higher than twice the fundamental string tension.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2156}
{"prompt": "Rephrase the abstract of an article with title 'Study of Di-Pion Transitions Among Upsilon(3S), Upsilon(2S), and\n  Upsilon(1S) States'.\n  We present measurements of decay matrix elements for hadronic transitions of\nthe form Upsilon(nS) -> pi pi Upsilon(mS) where (n, m) = (3, 1), (2, 1), and\n(3, 2). We reconstruct charged and neutral pion modes with the final state\nUpsilon decaying to either mu+mu- or e+e-. Dalitz plot distributions for the\ntwelve decay modes are fit individually as well as jointly assuming isospin\nsymmetry, thereby measuring the matrix elements of the decay amplitude. We\nobserve and account for the anomaly previously noted in the di-pion invariant\nmass distribution for the Upsilon(3S) -> pi pi Upsilon(1S) transition and\nobtain good descriptions of the dynamics of the decay using the most general\ndecay amplitude allowed by partial conservation of the axial-vector current\n(PCAC) considerations. The fits further indicate that the Upsilon(2S) -> pi pi\nUpsilon(1S) and Upsilon(3S) -> pi pi Upsilon(2S) transitions also show the\npresence of terms in the decay amplitude that were previously ignored, although\nat a relatively suppressed level.\n\n", "human_text": "  We present measurements of decay matrix elements for hadronic transitions of\nthe form Upsilon(nS) -> pi pi Upsilon(mS) where (n, m) = (3, 1), (2, 1), and\n(3, 2). We reconstruct charged and neutral pion modes with the final state\nUpsilon decaying to either mu+mu- or e+e-. Dalitz plot distributions for the\ntwelve decay modes are fit individually as well as jointly assuming isospin\nsymmetry, thereby measuring the matrix elements of the decay amplitude. We\nobserve and account for the anomaly previously noted in the di-pion invariant\nmass distribution for the Upsilon(3S) -> pi pi Upsilon(1S) transition and\nobtain good descriptions of the dynamics of the decay using the most general\ndecay amplitude allowed by partial conservation of the axial-vector current\n(PCAC) considerations. The fits further indicate that the Upsilon(2S) -> pi pi\nUpsilon(1S) and Upsilon(3S) -> pi pi Upsilon(2S) transitions also show the\npresence of terms in the decay amplitude that were previously ignored, although\nat a relatively suppressed level.\n", "machine_text": "\nIn this study, we measure the transition matrix elements of hadronic decays of the form Upsilon(nS) to pi pi Upsilon(mS) for (n, m) = (3, 1), (2, 1), and (3, 2). The decay modes were reconstructed using decay products of mu+mu- and e+e- final states of the Upsilon, and were characterized by separate Dalitz plot distributions for each mode, which were fit both separately and jointly under the assumption of isospin symmetry. These fits revealed the previously observed anomaly in the di-pion invariant mass of the Upsilon(3S) -> pi pi Upsilon(1S) transition and suggest the presence of ignored terms in the Upsilon(2S) -> pi pi Upsilon(1S) and Upsilon(3S) -> pi pi Upsilon(2S) transitions, albeit at a lower level. The expansion of the decay rate was consistent with the conservation principles of the axial-vector current.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2317}
{"prompt": "Rephrase the abstract of an article with title 'Results on axion physics from the CAST Experiment at CERN'.\n  Axions are expected to be produced in the sun via the Primakoff process. They\nmay be detected through the inverse process in the laboratory, under the\ninfluence of a strong magnetic field, giving rise to X-rays of energies in the\nrange of a few keV. Such an Axion detector is the CERN Axion Solar Telescope\n(CAST), collecting data since 2003. Results have been published, pushing the\naxion-photon coupling g$_{a\\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at\n95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of\nmagnitude lower than previous experimental limits and surpassed for the first\ntime limits set from astrophysical arguments based on the energy-loss concept.\nThe experiment is currently exploring axion masses in the range of 0.02 eV $<\nm_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass\nexplored will be extended up to the limit of 1.1 eV, testing for the first time\nthe region of theoretical axion models with the axion helioscope method.\n\n", "human_text": "  Axions are expected to be produced in the sun via the Primakoff process. They\nmay be detected through the inverse process in the laboratory, under the\ninfluence of a strong magnetic field, giving rise to X-rays of energies in the\nrange of a few keV. Such an Axion detector is the CERN Axion Solar Telescope\n(CAST), collecting data since 2003. Results have been published, pushing the\naxion-photon coupling g$_{a\\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at\n95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of\nmagnitude lower than previous experimental limits and surpassed for the first\ntime limits set from astrophysical arguments based on the energy-loss concept.\nThe experiment is currently exploring axion masses in the range of 0.02 eV $<\nm_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass\nexplored will be extended up to the limit of 1.1 eV, testing for the first time\nthe region of theoretical axion models with the axion helioscope method.\n", "machine_text": "\nThe CERN Axion Solar Telescope (CAST) is an Axion detector that has been in operation since 2003, seeking to detect Axions produced in the sun via the Primakoff process. Results from CAST have since been published, revealing a limit of 10$^{-10}$ GeV$^{-1}$ on the axion-photon coupling g$_{a\\gamma}$ at 95% CL, for axion masses up to 0.02 eV. This surpasses all prior experiments, as well as astrophysical limits based on energy-loss concept by nearly a magnitude. The next run of the experiment, currently in preparation, will expand the search up to 1.1 eV, testing theoretical axion models via the axion helioscope method for the first time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0637}
{"prompt": "Rephrase the abstract of an article with title 'Electrical excitation of shock and soliton-like waves in two-dimensional\n  electron channels'.\n  We study electrical excitation of nonlinear plasma waves in heterostructures\nwith two-dimensional electron channels and with split gates, and the\npropagation of these waves using hydrodynamic equations for electron transport\ncoupled with two-dimensional Poisson equation for self-consistent electric\npotential. The term related to electron collisions with impurities and phonons\nas well as the term associated with viscosity are included into the\nhydrodynamic equations. We demonstrate the formation of shock and soliton-like\nwaves as a result of the evolution of strongly nonuniform initial electron\ndensity distribution. It is shown that the shock wave front and the shape of\nsoliton-like pulses pronouncedly depend on the coefficient of viscosity, the\nthickness of the gate layer and the nonuniformity of the donor distribution\nalong the channel. The electron collisions result in damping of the shock and\nsoliton-like waves, while they do not markedly affect the thickness of the\nshock wave front.\n\n", "human_text": "  We study electrical excitation of nonlinear plasma waves in heterostructures\nwith two-dimensional electron channels and with split gates, and the\npropagation of these waves using hydrodynamic equations for electron transport\ncoupled with two-dimensional Poisson equation for self-consistent electric\npotential. The term related to electron collisions with impurities and phonons\nas well as the term associated with viscosity are included into the\nhydrodynamic equations. We demonstrate the formation of shock and soliton-like\nwaves as a result of the evolution of strongly nonuniform initial electron\ndensity distribution. It is shown that the shock wave front and the shape of\nsoliton-like pulses pronouncedly depend on the coefficient of viscosity, the\nthickness of the gate layer and the nonuniformity of the donor distribution\nalong the channel. The electron collisions result in damping of the shock and\nsoliton-like waves, while they do not markedly affect the thickness of the\nshock wave front.\n", "machine_text": "This investigation seeks to gain a better understanding of electrical excitation of electrically driven plasma waves in two-dimensional electron channels and their propagation patterns. Hydrodynamic equations of electron transport are used along with a two-dimensional Poisson equation to predict the behaviour of shock and soliton-like waves resulting from strongly nonuniform initial electron density distributions of the channel. Our findings suggest that the nature of the shock wave front and the shape of the soliton-like pulses depend on certain factors such as the coefficient of viscosity, the thickness of the gate layer, and the nonuniformity of donor distributions along the channel. It is observed that electron collisions with impurities and phonons induce damping of the aforementioned waves, however have only minimal effect on the thickness of the shock wave front.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2111}
{"prompt": "Rephrase the abstract of an article with title 'Instanton Induced Neutrino Majorana Masses in CFT Orientifolds with\n  MSSM-like spectra'.\n  Recently it has been shown that string instanton effects may give rise to\nneutrino Majorana masses in certain classes of semi-realistic string\ncompactifications. In this paper we make a systematic search for supersymmetric\nMSSM-like Type II Gepner orientifold constructions admitting boundary states\nassociated with instantons giving rise to neutrino Majorana masses and other L-\nand/or B-violating operators. We analyze the zero mode structure of D-brane\ninstantons on general type II orientifold compactifications, and show that only\ninstantons with O(1) symmetry can have just the two zero modes required to\ncontribute to the 4d superpotential. We however discuss how the addition of\nfluxes and/or possible non-perturbative extensions of the orientifold\ncompactifications would allow also instantons with $Sp(2)$ and U(1) symmetries\nto generate such superpotentials. In the context of Gepner orientifolds with\nMSSM-like spectra, we find no models with O(1) instantons with just the\nrequired zero modes to generate a neutrino mass superpotential. On the other\nhand we find a number of models in one particular orientifold of the Gepner\nmodel $(2,4,22,22)$ with $Sp(2)$ instantons with a few extra uncharged\nnon-chiral zero modes which could be easily lifted by the mentioned effects. A\nfew more orientifold examples are also found under less stringent constraints\non the zero modes. This class of $Sp(2)$ instantons have the interesting\nproperty that R-parity conservation is automatic and the flavour structure of\nthe neutrino Majorana mass matrices has a simple factorized form.\n\n", "human_text": "  Recently it has been shown that string instanton effects may give rise to\nneutrino Majorana masses in certain classes of semi-realistic string\ncompactifications. In this paper we make a systematic search for supersymmetric\nMSSM-like Type II Gepner orientifold constructions admitting boundary states\nassociated with instantons giving rise to neutrino Majorana masses and other L-\nand/or B-violating operators. We analyze the zero mode structure of D-brane\ninstantons on general type II orientifold compactifications, and show that only\ninstantons with O(1) symmetry can have just the two zero modes required to\ncontribute to the 4d superpotential. We however discuss how the addition of\nfluxes and/or possible non-perturbative extensions of the orientifold\ncompactifications would allow also instantons with $Sp(2)$ and U(1) symmetries\nto generate such superpotentials. In the context of Gepner orientifolds with\nMSSM-like spectra, we find no models with O(1) instantons with just the\nrequired zero modes to generate a neutrino mass superpotential. On the other\nhand we find a number of models in one particular orientifold of the Gepner\nmodel $(2,4,22,22)$ with $Sp(2)$ instantons with a few extra uncharged\nnon-chiral zero modes which could be easily lifted by the mentioned effects. A\nfew more orientifold examples are also found under less stringent constraints\non the zero modes. This class of $Sp(2)$ instantons have the interesting\nproperty that R-parity conservation is automatic and the flavour structure of\nthe neutrino Majorana mass matrices has a simple factorized form.\n", "machine_text": "\nIn this article, we explored the possibilities for the emergence of Majorana masses for neutrinos in orientifolds of string theory, with MSSM-like spectra. We conducted a systematic search for supersymmetric type II Gepner orientifold models, admitting such instanton-induced Majorana masses, as well as other lepton- and baryon-violating operators. We investigated zero mode properties of D-brane instantons in general type II orientifold compactifications, and discovered that for the Majorana mass inducing instantons, only those with O(1) symmetry possess the necessary two zero modes. Further developments, such as the addition of fluxes and/or non-perturbative extensions of the orientifolds, may enable instantons with Sp(2) and U(1) symmetries to be incorporated. We investigated orientifolds with MSSM-like spectra, but were unable to identify any models with O(1) instantons that fulfil the zero mode requirements. We did, however, find a number of models with Sp(2) instantons that can induce Majorana masses, in one particular orientifold of the Gepner model $(2,4,22,22)$. This also means that there is an automatic R-parity conservation, as well as a convenient flavour structure in the Majorana mass matrices. In addition, we presented a few more examples of orientifold models when less stringent constraints on the zero modes are applied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1079}
{"prompt": "Rephrase the abstract of an article with title 'The Advantages of Four Dimensions for Composite Higgs Models'.\n  We examine the relationship between little Higgs and 5d composite models with\nidentical symmetry structures. By performing an \"extreme\" deconstruction, one\ncan reduce any warped composite model to a little Higgs theory on a handful of\nsites. This allows us to use 4d intuition and the powerful constraints of\nnonlinear sigma models to elucidate obscure points in the original setup. We\nfind that the finiteness of the Higgs potential in 5d is due to the same\ncollective symmetry breaking as in the little Higgs. We compare a 4d and a 5d\nmodel with the same symmetry to the data. Reviewing the constraints on models\nrelated to the Minimal Composite Higgs (hep-ph/0412089), we see that it has\ndifficulty in producing acceptable values for S, T, and m_{top} simultaneously.\nBy contrast, in a global analysis, the Minimal Moose with custodial symmetry is\nviable in a large region of its parameter space and suffers from no numeric\ntunings. We conjecture that this result is generic for 4d and 5d models with\nidentical symmetries. The data will less strongly constrain the little theory.\n\n", "human_text": "  We examine the relationship between little Higgs and 5d composite models with\nidentical symmetry structures. By performing an \"extreme\" deconstruction, one\ncan reduce any warped composite model to a little Higgs theory on a handful of\nsites. This allows us to use 4d intuition and the powerful constraints of\nnonlinear sigma models to elucidate obscure points in the original setup. We\nfind that the finiteness of the Higgs potential in 5d is due to the same\ncollective symmetry breaking as in the little Higgs. We compare a 4d and a 5d\nmodel with the same symmetry to the data. Reviewing the constraints on models\nrelated to the Minimal Composite Higgs (hep-ph/0412089), we see that it has\ndifficulty in producing acceptable values for S, T, and m_{top} simultaneously.\nBy contrast, in a global analysis, the Minimal Moose with custodial symmetry is\nviable in a large region of its parameter space and suffers from no numeric\ntunings. We conjecture that this result is generic for 4d and 5d models with\nidentical symmetries. The data will less strongly constrain the little theory.\n", "machine_text": "\nIn this paper, we examine the connections between the little Higgs and 5d composite models which share identical symmetry structures. We adopt an ''extreme\" deconstruction which helps reduce any warped composite model to a little Higgs theory on a handful of sites. This approach aids in understanding obscure points in the original model setup. Furthermore, we find that the finiteness of the Higgs potential in 5d is generated by the same collective symmetry breaking seen in the little Higgs framework. \n\nWe then compare a 4d and a 5d model with the same symmetries to the real-world data. After reviewing the constraints imposed by the Minimal Composite Higgs (hep-ph/0412089), we observe that it has difficulty simultaneously producing acceptable values for S, T and m_{top}. On the other hand, the Minimal Moose with custodial symmetry is viable in a relatively large area of its parameter space, with no numeric tunings required. Our results suggest that this result is generalizable to any 4d or 5d model sharing the same symmetries. This implies that the observational data constrains the theory less tightly when expressed as a little Higgs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.138}
{"prompt": "Rephrase the abstract of an article with title 'National Scientific Facilities and Their Science Impact on\n  Non-Biomedical Research'.\n  H-index, proposed by Hirsch is a good indicator of the impact of a\nscientist's research. When evaluating departments, institutions or labs, the\nimportance of h-index can be further enhanced when properly calibrated for\nsize. Particularly acute is the issue of federally funded facilities whose\nnumber of actively publishing scientists frequently dwarfs that of academic\ndepartments. Recently Molinari and Molinari developed a methodology that shows\nthe h-index has a universal growth rate for large numbers of papers, allowing\nfor meaningful comparisons between institutions.\n  An additional challenge when comparing large institutions is that fields have\ndistinct internal cultures, with different typical rates of publication and\ncitation; biology is more highly cited than physics, which is more highly cited\nthan engineering. For this reason, this study has focused on the physical\nsciences, engineering, and technology, and has excluded bio-medical research.\nComparisons between individual disciplines are reported here to provide\ncontextual framework. Generally, it was found that the universal growth rate of\nMolinari and Molinari holds well across all the categories considered,\ntestifying to the robustness of both their growth law and our results.\n  The overall goal here is to set the highest standard of comparison for\nfederal investment in science; comparisons are made with the nations preeminent\nprivate and public institutions. We find that many among the national\nfacilities compare favorably in research impact with the nations leading\nuniversities.\n\n", "human_text": "  H-index, proposed by Hirsch is a good indicator of the impact of a\nscientist's research. When evaluating departments, institutions or labs, the\nimportance of h-index can be further enhanced when properly calibrated for\nsize. Particularly acute is the issue of federally funded facilities whose\nnumber of actively publishing scientists frequently dwarfs that of academic\ndepartments. Recently Molinari and Molinari developed a methodology that shows\nthe h-index has a universal growth rate for large numbers of papers, allowing\nfor meaningful comparisons between institutions.\n  An additional challenge when comparing large institutions is that fields have\ndistinct internal cultures, with different typical rates of publication and\ncitation; biology is more highly cited than physics, which is more highly cited\nthan engineering. For this reason, this study has focused on the physical\nsciences, engineering, and technology, and has excluded bio-medical research.\nComparisons between individual disciplines are reported here to provide\ncontextual framework. Generally, it was found that the universal growth rate of\nMolinari and Molinari holds well across all the categories considered,\ntestifying to the robustness of both their growth law and our results.\n  The overall goal here is to set the highest standard of comparison for\nfederal investment in science; comparisons are made with the nations preeminent\nprivate and public institutions. We find that many among the national\nfacilities compare favorably in research impact with the nations leading\nuniversities.\n", "machine_text": "This study investigates the impact of national scientific facilities on non-biomedical research using the h-index proposed by Hirsch. With the goal of providing the highest standard of comparison for federal investment in science, data from physical sciences, engineering and technology were considered, excluding the biomedicine field. Molinari and Molinari developed a method to allow for meaningful comparisons between institutions and a universal growth rate for large numbers of papers was found to be consistent across all categories. Comparisons between individual disciplines were made and the results showed that many of the national facilities compare favorably with universities in terms of research impact.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1797}
{"prompt": "Rephrase the abstract of an article with title 'A twisted FZZ-like dual for the two-dimensional black hole'.\n  We review and study the duality between string theory formulated on a curved\nexact background (the two dimensional black hole) and string theory in flat\nspace with a tachyon-like potential. We generalize previous results in this\nsubject by discussing a twisted version of the\nFateev-Zamolodchikov-Zamolodchikov conjecture. This duality is shown to hold at\nthe level of N-point correlation functions on the sphere topology, and connects\ntree-level string amplitudes in the Euclidean version of the 2D black hole (x\ntime) to correlation functions in a non-linear sigma-model in flat space but in\npresence of a tachyon wall potential and a linear dilaton. The dual CFT\ncorresponds to the perturbed 2D quantum gravity coupled to c<1 matter (x time),\nwhere the operator that describes the tachyon-like potential can be seen as a\nn=2 momentum mode perturbation, while the usual sine-Liouville operator would\ncorrespond to the vortex sector n =1. We show how the sine-Liouville\ninteraction term arises through a twisting of the marginal deformation\nintroduced here, and discuss such 'twisting' as a non-trivial realization of\nthe symmetries of the theory. After briefly reviewing the computation of\ncorrelation functions in sine-Liouville CFT, we give a precise prescription for\ncomputing correlation functions in the twisted model. To show the new version\nof the correspondence we make use of a formula recently proven by S. Ribault\nand J. Teschner, which connects the correlation functions in the\nWess-Zumino-Witten theory to correlation functions in the Liouville theory.\nConversely, the duality discussed here can be thought of as a free field\nrealization of such remarkable formula.\n\n", "human_text": "  We review and study the duality between string theory formulated on a curved\nexact background (the two dimensional black hole) and string theory in flat\nspace with a tachyon-like potential. We generalize previous results in this\nsubject by discussing a twisted version of the\nFateev-Zamolodchikov-Zamolodchikov conjecture. This duality is shown to hold at\nthe level of N-point correlation functions on the sphere topology, and connects\ntree-level string amplitudes in the Euclidean version of the 2D black hole (x\ntime) to correlation functions in a non-linear sigma-model in flat space but in\npresence of a tachyon wall potential and a linear dilaton. The dual CFT\ncorresponds to the perturbed 2D quantum gravity coupled to c<1 matter (x time),\nwhere the operator that describes the tachyon-like potential can be seen as a\nn=2 momentum mode perturbation, while the usual sine-Liouville operator would\ncorrespond to the vortex sector n =1. We show how the sine-Liouville\ninteraction term arises through a twisting of the marginal deformation\nintroduced here, and discuss such 'twisting' as a non-trivial realization of\nthe symmetries of the theory. After briefly reviewing the computation of\ncorrelation functions in sine-Liouville CFT, we give a precise prescription for\ncomputing correlation functions in the twisted model. To show the new version\nof the correspondence we make use of a formula recently proven by S. Ribault\nand J. Teschner, which connects the correlation functions in the\nWess-Zumino-Witten theory to correlation functions in the Liouville theory.\nConversely, the duality discussed here can be thought of as a free field\nrealization of such remarkable formula.\n", "machine_text": "\nWe explore the accepted string theory notion that curved backgrounds and flat space theory with a tachyon-like potential are dual to each other. This duality can be demonstrated at the level of N-point correlation functions on the sphere topology and the equal coupling of tree-level string amplitudes in the Euclidean 2D black hole (x-time) to correlation functions in a non-linear sigma-model in flat space but with a tachyon wall potential and linear dilaton. Furthermore, the dual CFT corresponds to quantum gravity coupled to C<1 matter (x time), where the tachyon-like potential is seen as an n=2 momentum mode perturbation and sine-Liouville operator as an n=1 vortex sector. In order to show how the sine-Liouville interaction arises, twisting of the marginal deformation is carried out. We then display the formula found and proven by S. Ribault and J. Teschner to connect the correlation functions of Wess-Zumino-Witten theory to Liouville theory. This duality that is discussed may be viewed as a free field realization of this formula.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0036}
{"prompt": "Rephrase the abstract of an article with title 'Towards an exact adaptive algorithm for the determinant of a rational\n  matrix'.\n  In this paper we propose several strategies for the exact computation of the\ndeterminant of a rational matrix. First, we use the Chinese Remaindering\nTheorem and the rational reconstruction to recover the rational determinant\nfrom its modular images. Then we show a preconditioning for the determinant\nwhich allows us to skip the rational reconstruction process and reconstruct an\ninteger result. We compare those approaches with matrix preconditioning which\nallow us to treat integer instead of rational matrices. This allows us to\nintroduce integer determinant algorithms to the rational determinant problem.\nIn particular, we discuss the applicability of the adaptive determinant\nalgorithm of [9] and compare it with the integer Chinese Remaindering scheme.\nWe present an analysis of the complexity of the strategies and evaluate their\nexperimental performance on numerous examples. This experience allows us to\ndevelop an adaptive strategy which would choose the best solution at the run\ntime, depending on matrix properties. All strategies have been implemented in\nLinBox linear algebra library.\n\n", "human_text": "  In this paper we propose several strategies for the exact computation of the\ndeterminant of a rational matrix. First, we use the Chinese Remaindering\nTheorem and the rational reconstruction to recover the rational determinant\nfrom its modular images. Then we show a preconditioning for the determinant\nwhich allows us to skip the rational reconstruction process and reconstruct an\ninteger result. We compare those approaches with matrix preconditioning which\nallow us to treat integer instead of rational matrices. This allows us to\nintroduce integer determinant algorithms to the rational determinant problem.\nIn particular, we discuss the applicability of the adaptive determinant\nalgorithm of [9] and compare it with the integer Chinese Remaindering scheme.\nWe present an analysis of the complexity of the strategies and evaluate their\nexperimental performance on numerous examples. This experience allows us to\ndevelop an adaptive strategy which would choose the best solution at the run\ntime, depending on matrix properties. All strategies have been implemented in\nLinBox linear algebra library.\n", "machine_text": "\nThis article presents various techniques to accurately calculate the determinant of a rational matrix, primarily by utilizing the Chinese Remaindering Theorem and the rational reconstruction, as well as matrix preconditioning. We also evaluate the side-by-side performance of the adaptive determinant algorithm with the integer Chinese Remaindering scheme. To gain a better evaluation, complexity analysis and multiple examples are used in order to develop a scheme to efficiently decide which method to use, depending on the properties of the matrix. These techniques have been implemented in the LinBox linear algebra library.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0014}
{"prompt": "Rephrase the abstract of an article with title 'Supersymmetry versus Gauge Symmetry on the Heterotic Landscape'.\n  One of the goals of the landscape program in string theory is to extract\ninformation about the space of string vacua in the form of statistical\ncorrelations between phenomenological features that are otherwise uncorrelated\nin field theory. Such correlations would thus represent predictions of string\ntheory that hold independently of a vacuum-selection principle. In this paper,\nwe study statistical correlations between two features which are likely to be\ncentral to any potential description of nature at high energy scales: gauge\nsymmetries and spacetime supersymmetry. We analyze correlations between these\ntwo kinds of symmetry within the context of perturbative heterotic string\nvacua, and find a number of striking features. We find, for example, that the\ndegree of spacetime supersymmetry is strongly correlated with the probabilities\nof realizing certain gauge groups, with unbroken supersymmetry at the string\nscale tending to favor gauge-group factors with larger rank. We also find that\nnearly half of the heterotic landscape is non-supersymmetric and yet\ntachyon-free at tree level; indeed, less than a quarter of the tree-level\nheterotic landscape exhibits any supersymmetry at all at the string scale.\n\n", "human_text": "  One of the goals of the landscape program in string theory is to extract\ninformation about the space of string vacua in the form of statistical\ncorrelations between phenomenological features that are otherwise uncorrelated\nin field theory. Such correlations would thus represent predictions of string\ntheory that hold independently of a vacuum-selection principle. In this paper,\nwe study statistical correlations between two features which are likely to be\ncentral to any potential description of nature at high energy scales: gauge\nsymmetries and spacetime supersymmetry. We analyze correlations between these\ntwo kinds of symmetry within the context of perturbative heterotic string\nvacua, and find a number of striking features. We find, for example, that the\ndegree of spacetime supersymmetry is strongly correlated with the probabilities\nof realizing certain gauge groups, with unbroken supersymmetry at the string\nscale tending to favor gauge-group factors with larger rank. We also find that\nnearly half of the heterotic landscape is non-supersymmetric and yet\ntachyon-free at tree level; indeed, less than a quarter of the tree-level\nheterotic landscape exhibits any supersymmetry at all at the string scale.\n", "machine_text": "\nThe aim of the research presented in this paper is to investigate how two significant elements of the string theory landscape \u2013 gauge groups and spacetime supersymmetry \u2013 are connected. By analyzing correlations between the two in the context of perturbative heterotic string vacua, several surprising outcomes have been revealed. For instance, there is a relationship between the amount of supersymmetry and the chance of certain gauge groups being realized, with enhanced supersymmetry tending to result in larger-ranked gauge groups. Additionally, almost half of the heterotic landscape is non-supersymmetric yet tachyon-free at tree level; we found that only a small fraction of the landscape displayed supersymmetry at the string level.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.132}
{"prompt": "Rephrase the abstract of an article with title '(2+1)-Einstein spacetimes of finite type'.\n  The aim of this survey is to give an overview on the geometry of Einstein\nmaximal globally hyperbolic 2+1 spacetimes of arbitrary curvature, conatining a\ncomplete Cauchy surface of finite type. In particular a specialization to the\nfinite type case of the canonicla Wick rotation-rescaling theory, previously\ndeveloped by the authors, is provided. This includes, for arbitrary curvatures,\nparameterizations in terms of suitable measured geodesic laminations on open\nhyperbolic surfaces of finite type. The same geometric objects also\nparameterize complex projective structures on the surfaces. The coincidence of\nsuch parameter space is explained by means of geometric correlations between\nspacetimes of different curvatures and projective surfaces realized via\ncanonical WR-rescaling along the cosmological times. We also specialize on AdS\ncase mostly referring to recent results achieved by other authors. In\nparticular we describe maximal causal extensions of AdS globally hyperbolic\nspacetimes and an AdS approach to the theory of earthquakes for hyperbolic\nsurfaces of finite type. A general earthquake theorem is proved for the so\ncalled enhanced Teichmuller space. The case of spacetimes with conical timelike\nsingularities is also treated.\n\n", "human_text": "  The aim of this survey is to give an overview on the geometry of Einstein\nmaximal globally hyperbolic 2+1 spacetimes of arbitrary curvature, conatining a\ncomplete Cauchy surface of finite type. In particular a specialization to the\nfinite type case of the canonicla Wick rotation-rescaling theory, previously\ndeveloped by the authors, is provided. This includes, for arbitrary curvatures,\nparameterizations in terms of suitable measured geodesic laminations on open\nhyperbolic surfaces of finite type. The same geometric objects also\nparameterize complex projective structures on the surfaces. The coincidence of\nsuch parameter space is explained by means of geometric correlations between\nspacetimes of different curvatures and projective surfaces realized via\ncanonical WR-rescaling along the cosmological times. We also specialize on AdS\ncase mostly referring to recent results achieved by other authors. In\nparticular we describe maximal causal extensions of AdS globally hyperbolic\nspacetimes and an AdS approach to the theory of earthquakes for hyperbolic\nsurfaces of finite type. A general earthquake theorem is proved for the so\ncalled enhanced Teichmuller space. The case of spacetimes with conical timelike\nsingularities is also treated.\n", "machine_text": "This article provides an overview of the geometry of (2+1)-Einstein maximal globally hyperbolic spacetimes with arbitrary curvature, whose Cauchy surfaces are of finite type. It includes the finite type version of the canonical Wick rotation-rescaling theory that provides parameterizations in terms of measured geodesic laminations on open hyperbolic surfaces of finite type as well as parameterizations that align with the corresponding complex projective structures on the surface. The results are also specialized to the AdS case involving the description of maximal causal extensions of AdS globally hyperbolic spacetimes, an AdS-based theory of earthquakes for the finite type hyperbolic surfaces, and a general earthquake theorem in the enhanced Teichmuller space, as well as the analysis of spacetimes with conical timelike singularities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2152}
{"prompt": "Rephrase the abstract of an article with title 'The Monitor project: JW 380 -- a 0.26, 0.15 Msol pre main sequence\n  eclipsing binary in the Orion Nebula Cluster'.\n  We report the discovery of a low-mass (0.26 +/- 0.02, 0.15 +/- 0.01 Msol)\npre-main-sequence eclipsing binary with a 5.3 day orbital period. JW 380 was\ndetected as part of a high-cadence time-resolved photometric survey (the\nMonitor project) using the 2.5m Isaac Newton Telescope and Wide Field Camera\nfor a survey of a single field in the Orion Nebula Cluster (ONC) region in V\nand i bands. The star is assigned a 99 per cent membership probability from\nproper motion measurements, and radial velocity observations indicate a\nsystemic velocity within 1 sigma of that of the ONC. Modelling of the combined\nlight and radial velocity curves of the system gave stellar radii of 1.19 +0.04\n-0.18 Rsol and 0.90 +0.17 -0.03 Rsol for the primary and secondary, with a\nsignificant third light contribution which is also visible as a third peak in\nthe cross-correlation functions used to derive radial velocities. The masses\nand radii appear to be consistent with stellar models for 2-3 Myr age from\nseveral authors, within the present observational errors. These observations\nprobe an important region of mass-radius parameter space, where there are\ncurrently only a handful of known pre-main-sequence eclipsing binary systems\nwith precise measurements available in the literature.\n\n", "human_text": "  We report the discovery of a low-mass (0.26 +/- 0.02, 0.15 +/- 0.01 Msol)\npre-main-sequence eclipsing binary with a 5.3 day orbital period. JW 380 was\ndetected as part of a high-cadence time-resolved photometric survey (the\nMonitor project) using the 2.5m Isaac Newton Telescope and Wide Field Camera\nfor a survey of a single field in the Orion Nebula Cluster (ONC) region in V\nand i bands. The star is assigned a 99 per cent membership probability from\nproper motion measurements, and radial velocity observations indicate a\nsystemic velocity within 1 sigma of that of the ONC. Modelling of the combined\nlight and radial velocity curves of the system gave stellar radii of 1.19 +0.04\n-0.18 Rsol and 0.90 +0.17 -0.03 Rsol for the primary and secondary, with a\nsignificant third light contribution which is also visible as a third peak in\nthe cross-correlation functions used to derive radial velocities. The masses\nand radii appear to be consistent with stellar models for 2-3 Myr age from\nseveral authors, within the present observational errors. These observations\nprobe an important region of mass-radius parameter space, where there are\ncurrently only a handful of known pre-main-sequence eclipsing binary systems\nwith precise measurements available in the literature.\n", "machine_text": "This investigation presents JW 380, a newly detected binary located within the Orion Nebula Cluster. The system has a combined mass of 0.26 and 0.15 Msol and an orbital period of 5.3 days. The Monitor project was utilized for the discovery of this binary via time-resolved photometry (V and i bands) with the Isaac Newton Telescope and Wide Field Camera. Additionally, radial velocity observations from the cross-correlation functions measured the systemic velocity, which is within 1 sigma of that of the ONC. Modelling of the data showed stellar radii of 1.19 and 0.90 Rsol and gave an age estimate of 2-3 Myr. This study's findings add to the small number of pre-main-sequence eclipsing binaries with precise measurements in the literature by providing additional evidence in the mass-radius parameter space.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2325}
{"prompt": "Rephrase the abstract of an article with title 'Positronium Groundstate in Relativistic Schroedinger Theory'.\n  The usefulness of the Relativistic Schr\\\"odinger Theory (RST) is studied in\nthe field of atomic physics. As a concrete demonstration, the positronium\ngroundstate is considered in great detail; especially the groundstate energy\n$E_0$ is worked out in the non-relativistic approximation and under neglection\nof the magnetic interactions between the positron and the electron. The\ncorresponding RST prediction $(E_0\\simeq -6,48 [eV])$ misses the analogous\nconventional Schr\\\"odinger result $(E_0\\simeq -6,80 [eV])$ but is closer to the\nlatter than the corresponding Hartree approximation $(-2,65 [eV])$. The missing\nbinding energy of $6,80-6,48=0,32 [eV]$ can be attributed to the approximative\nuse of an SO(3) symmetric interaction potential which in RST, however, is\nactually only SO(2) invariant against rotations around the z-axis. It is\nexpected that, with the correct use of an anisotropic interaction potential due\nto the SO(2) symmetry, the RST predictions will come even closer to the\nconventional Schr\\\"odinger result, where however the mathematical structure of\nRST relies on exotic (i.e. double-valued) wave functions and on the\ncorresponding unconventional interaction potentials (e.g. Struve-Neumann\npotential).\n\n", "human_text": "  The usefulness of the Relativistic Schr\\\"odinger Theory (RST) is studied in\nthe field of atomic physics. As a concrete demonstration, the positronium\ngroundstate is considered in great detail; especially the groundstate energy\n$E_0$ is worked out in the non-relativistic approximation and under neglection\nof the magnetic interactions between the positron and the electron. The\ncorresponding RST prediction $(E_0\\simeq -6,48 [eV])$ misses the analogous\nconventional Schr\\\"odinger result $(E_0\\simeq -6,80 [eV])$ but is closer to the\nlatter than the corresponding Hartree approximation $(-2,65 [eV])$. The missing\nbinding energy of $6,80-6,48=0,32 [eV]$ can be attributed to the approximative\nuse of an SO(3) symmetric interaction potential which in RST, however, is\nactually only SO(2) invariant against rotations around the z-axis. It is\nexpected that, with the correct use of an anisotropic interaction potential due\nto the SO(2) symmetry, the RST predictions will come even closer to the\nconventional Schr\\\"odinger result, where however the mathematical structure of\nRST relies on exotic (i.e. double-valued) wave functions and on the\ncorresponding unconventional interaction potentials (e.g. Struve-Neumann\npotential).\n", "machine_text": "\nThis research evaluates the effectiveness of the Relativistic Schr\\\"odinger Theory (RST) when applied to atomic physics by analyzing the positronium groundstate. The study neglects any magnetic interactions between the positron and the electron. The RST prediction on the groundstate energy, which approximately equates to -6,48 eV, deviates from the conventional Schr\\\"odinger Theory\u2019s calculation of -6,80 eV by 0.32 eV. This discrepancy is attributed to the use of a SO(3) symmetric interaction potential instead of the anisotropic one due to the SO(2) symmetry which would be more accurate for RST. This suggests that, with the correct and more precise use of the interaction potential, the RST results will likely be closer to the conventional results, taking into account the exotic, double-valued wave functions and the relevant unconventional interaction potentials such as the Struve-Neumann potential.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.381}
{"prompt": "Rephrase the abstract of an article with title 'A fundamental explanation for the tiny value of the cosmological\n  constant'.\n  We will look for an implementation of new symmetries in the space-time\nstructure and their cosmological implications. This search will allow us to\nfind a unified vision for electrodynamics and gravitation. We will attempt to\ndevelop a heuristic model of the electromagnetic nature of the electron, so\nthat the influence of the gravitational field on the electrodynamics at very\nlarge distances leads to a reformulation of our comprehension of the space-\ntime structure at quantum level through the elimination of the classical idea\nof rest. This will lead us to a modification of the relativistic theory by\nintroducing the idea about a universal minimum limit of speed in the space-\ntime. Such a limit, unattainable by the particles, represents a preferred frame\nassociated with a universal background field (a vacuum energy), enabling a\nfundamental understanding of the quantum uncertainties. The structure of\nspace-time becomes extended due to such a vacuum energy density, which leads to\na negative pressure at the cosmological scales as an anti-gravity, playing the\nrole of the cosmological constant. The tiny values of the vacuum energy density\nand the cosmological constant will be successfully obtained, being in agreement\nwith current observational results.\n\n", "human_text": "  We will look for an implementation of new symmetries in the space-time\nstructure and their cosmological implications. This search will allow us to\nfind a unified vision for electrodynamics and gravitation. We will attempt to\ndevelop a heuristic model of the electromagnetic nature of the electron, so\nthat the influence of the gravitational field on the electrodynamics at very\nlarge distances leads to a reformulation of our comprehension of the space-\ntime structure at quantum level through the elimination of the classical idea\nof rest. This will lead us to a modification of the relativistic theory by\nintroducing the idea about a universal minimum limit of speed in the space-\ntime. Such a limit, unattainable by the particles, represents a preferred frame\nassociated with a universal background field (a vacuum energy), enabling a\nfundamental understanding of the quantum uncertainties. The structure of\nspace-time becomes extended due to such a vacuum energy density, which leads to\na negative pressure at the cosmological scales as an anti-gravity, playing the\nrole of the cosmological constant. The tiny values of the vacuum energy density\nand the cosmological constant will be successfully obtained, being in agreement\nwith current observational results.\n", "machine_text": "\nWe propose to analyse the influence that the gravitational field has on electrodynamics in extreme distances. Our target is to create a heuristic framework of the electromagnetic character of the electron, in an attempt to substitute the traditional misconception of rest. Such a substitution will necessitate the installment of a correlation of a universal speed constraint in the space-time. This speed cannot be accomplished by any particle, instead supporting a background force, or a vacuum energy, making clear the mutability of quantum discrepancies. The space-time will reposition with the assistance of a vacuum energy density, inducing a negative pressure at the cosmological levels, as a counteracting force to the gravitational action, referred to as the cosmological constant. Finally, we expect that the small sum of the vacuum energy density and the yet lower cosmological constant, will align with the actual observational evidence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4315}
{"prompt": "Rephrase the abstract of an article with title 'Two-loop world-sheet corrections in AdS_5 x S^5 superstring'.\n  We initiate the computation of the 2-loop quantum AdS_5 x S^5 string\ncorrections on the example of a certain string configuration in S^5 related by\nan analytic continuation to a folded rotating string in AdS_5 in the ``long\nstring'' limit. The 2-loop term in the energy of the latter should represent\nthe subleading strong-coupling correction to the cusp anomalous dimension and\nthus provide a further check of recent conjectures about the exact structure of\nthe Bethe ansatz underlying the AdS/CFT duality. We use the conformal gauge and\nseveral choices of the \\kappa-symmetry gauge. While we are unable to verify the\ncancellation of 2d UV divergences we compute the bosonic contribution to the\neffective action and also determine the non-trivial finite part of the\nfermionic contribution. Both the bosonic and the fermionic contributions to the\nstring energy happen to be proportional to the Catalan's constant. The\nresulting value for 2-loop superstring prediction for the subleading\ncoefficient a_2 in the scaling function matches the numerical value found in\nhep-th/0611135 from the BES equation.\n\n", "human_text": "  We initiate the computation of the 2-loop quantum AdS_5 x S^5 string\ncorrections on the example of a certain string configuration in S^5 related by\nan analytic continuation to a folded rotating string in AdS_5 in the ``long\nstring'' limit. The 2-loop term in the energy of the latter should represent\nthe subleading strong-coupling correction to the cusp anomalous dimension and\nthus provide a further check of recent conjectures about the exact structure of\nthe Bethe ansatz underlying the AdS/CFT duality. We use the conformal gauge and\nseveral choices of the \\kappa-symmetry gauge. While we are unable to verify the\ncancellation of 2d UV divergences we compute the bosonic contribution to the\neffective action and also determine the non-trivial finite part of the\nfermionic contribution. Both the bosonic and the fermionic contributions to the\nstring energy happen to be proportional to the Catalan's constant. The\nresulting value for 2-loop superstring prediction for the subleading\ncoefficient a_2 in the scaling function matches the numerical value found in\nhep-th/0611135 from the BES equation.\n", "machine_text": "\nWe explore two-loop quantum corrections associated with AdS_5 x S^5 superstrings for a particular string configuration, related to a folded rotating string in AdS_5 in the ``long string'' limit. By employing the conformal gauge and various \\kappa-symmetry gauge choices, we ascertain the bosonic contribution to the effective action and the non-zero finite portion of the fermionic contribution. Notably, the bosonic and fermionic contributions to the string energy both amount to the Catalan's constant. The resultant value for the two-loop superstring prediction for the subleading coefficient a_2 in the scaling function aligns with the numerical value determined from the BES equation in hep-th/0611135. This provides further confirmation of the exact structure of the Bethe ansatz underlying AdS/CFT duality.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3638}
{"prompt": "Rephrase the abstract of an article with title 'Surface Structure in an Accretion Disk Annulus with Comparable Radiation\n  and Gas Pressure'.\n  We have employed a 3-d energy-conserving radiation MHD code to simulate the\nvertical structure and thermodynamics of a shearing box whose parameters were\nchosen so that the radiation and gas pressures would be comparable. The upper\nlayers of this disk segment are magnetically-dominated, creating conditions\nappropriate for both photon bubble and Parker instabilities. We find little\nevidence for photon bubbles, even though the simulation has enough spatial\nresolution to see them and their predicted growth rates are high. On the other\nhand, there is strong evidence for Parker instabilities, and they appear to\ndominate the evolution of the magnetically supported surface layers. The disk\nphotosphere is complex, with large density inhomogeneities at both the\nscattering and effective (thermalization) photospheres of the evolving\nhorizontally-averaged structure. Both the dominant magnetic support and the\ninhomogeneities are likely to have strong effects on the spectrum and\npolarization of thermal photons emerging from the disk atmosphere. The\ninhomogeneities are also large enough to affect models of reflection spectra\nfrom the atmospheres of accretion disks.\n\n", "human_text": "  We have employed a 3-d energy-conserving radiation MHD code to simulate the\nvertical structure and thermodynamics of a shearing box whose parameters were\nchosen so that the radiation and gas pressures would be comparable. The upper\nlayers of this disk segment are magnetically-dominated, creating conditions\nappropriate for both photon bubble and Parker instabilities. We find little\nevidence for photon bubbles, even though the simulation has enough spatial\nresolution to see them and their predicted growth rates are high. On the other\nhand, there is strong evidence for Parker instabilities, and they appear to\ndominate the evolution of the magnetically supported surface layers. The disk\nphotosphere is complex, with large density inhomogeneities at both the\nscattering and effective (thermalization) photospheres of the evolving\nhorizontally-averaged structure. Both the dominant magnetic support and the\ninhomogeneities are likely to have strong effects on the spectrum and\npolarization of thermal photons emerging from the disk atmosphere. The\ninhomogeneities are also large enough to affect models of reflection spectra\nfrom the atmospheres of accretion disks.\n", "machine_text": "\nWe have used a 3-dimensional radiation magnetohydrodynamic code to investigate the vertical structure and thermodynamics of a disk annular segment where both the gas pressure and radiation pressure would be of similar magnitude. Our results indicate strong evidence of Parker instabilities as the dominant magnetic support in the upper layers of the disc, resulting in a complex photosphere with significant density variations at the scattering and thermalization photospheres. Such inhomogeneities could significantly change both the spectrum and polarization of thermal photons emerging from the disk atmosphere, as well as impacting models used to predict their reflection spectra.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0314}
{"prompt": "Rephrase the abstract of an article with title 'Co-orbital Oligarchy'.\n  We present a systematic examination of the changes in semi-major axis caused\nby the mutual interactions of a group of massive bodies orbiting a central star\nin the presence of eccentricity dissipation. For parameters relevant to the\noligarchic stage of planet formation, dynamical friction keeps the typical\neccentricities small and prevents orbit crossing. Interactions at impact\nparameters greater than several Hill radii cause the protoplanets to repel each\nother; if the impact parameter is instead much less than the Hill radius, the\nprotoplanets shift slightly in semi-major axis but remain otherwise\nunperturbed. If the orbits of two or more protoplanets are separated by less\nthan a Hill radius, they are each pushed towards an equilibrium spacing between\ntheir neighbors and can exist as a stable co-orbital system. In the\nshear-dominated oligarchic phase of planet formation we show that the feeding\nzones contain several oligarchs instead of only one. Growth of the protoplanets\nin the oligarchic phase drives the disk to an equilibrium configuration that\ndepends on the mass ratio of protoplanets to planetesimals, $\\Sigma/\\sigma$.\nEarly in the oligarchic phase, when $\\Sigma/\\sigma$ is low, the spacing between\nrows of co-orbital oligarchs are about 5 Hill radii wide, rather than the 10\nHill radii cited in the literature. It is likely that at the end of oligarchy\nthe average number of co-orbital oligarchs is greater than unity. In the outer\nsolar system this raises the disk mass required to form the ice giants. In the\ninner solar system this lowers the mass of the final oligarchs and requires\nmore giant impacts than previously estimated. This result provides additional\nevidence that Mars is not an untouched leftover from the oligarchic phase, but\nmust be composed of several oligarchs assembled through giant impacts.\n\n", "human_text": "  We present a systematic examination of the changes in semi-major axis caused\nby the mutual interactions of a group of massive bodies orbiting a central star\nin the presence of eccentricity dissipation. For parameters relevant to the\noligarchic stage of planet formation, dynamical friction keeps the typical\neccentricities small and prevents orbit crossing. Interactions at impact\nparameters greater than several Hill radii cause the protoplanets to repel each\nother; if the impact parameter is instead much less than the Hill radius, the\nprotoplanets shift slightly in semi-major axis but remain otherwise\nunperturbed. If the orbits of two or more protoplanets are separated by less\nthan a Hill radius, they are each pushed towards an equilibrium spacing between\ntheir neighbors and can exist as a stable co-orbital system. In the\nshear-dominated oligarchic phase of planet formation we show that the feeding\nzones contain several oligarchs instead of only one. Growth of the protoplanets\nin the oligarchic phase drives the disk to an equilibrium configuration that\ndepends on the mass ratio of protoplanets to planetesimals, $\\Sigma/\\sigma$.\nEarly in the oligarchic phase, when $\\Sigma/\\sigma$ is low, the spacing between\nrows of co-orbital oligarchs are about 5 Hill radii wide, rather than the 10\nHill radii cited in the literature. It is likely that at the end of oligarchy\nthe average number of co-orbital oligarchs is greater than unity. In the outer\nsolar system this raises the disk mass required to form the ice giants. In the\ninner solar system this lowers the mass of the final oligarchs and requires\nmore giant impacts than previously estimated. This result provides additional\nevidence that Mars is not an untouched leftover from the oligarchic phase, but\nmust be composed of several oligarchs assembled through giant impacts.\n", "machine_text": "\nThis paper examines how mutual interactions of multiple large bodies orbiting a central star, in the presence of eccentricity dissipation, cause changes in the semi-major axis. For the conditions pertinent to the oligarchic stage of planet formation, dynamical friction keeps the eccentricities small, reducing collision risks. If protoplanets move away from each other at a distance much greater than their Hill radius, they should remain relatively unperturbed. When two or more orbits are within a Hill radius from each other, the protoplanets are drawn towards equilibrium spacing between each other, thus creating a stable configuration of co-orbital oligarchs. We demonstrate that during the oligarchic phase of planet formation, each feeding zone contains several oligarchs instead of the single one previously thought. This finding has implications in the outer solar system, increasing the mass of the disk required to form the ice giants. In the inner solar system, this requires more giant impacts than anticipated to form fewer, final oligarchs. This suggests that Mars is not a pristine vestige of the oligarchic phase; it more likely is composed of multiple oligarchs that merged through giant impacts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1079}
{"prompt": "Rephrase the abstract of an article with title 'Fuzzy Extra Dimensions: Dimensional Reduction, Dynamical Generation and\n  Renormalizability'.\n  We examine gauge theories defined in higher dimensions where theextra\ndimensions form a fuzzy (finite matrix) manifold. First we reinterpret these\ngauge theories as four-dimensional theories with Kaluza-Klein modes and then we\nperform a generalized \\`a la Forgacs-Manton dimensional reduction. We emphasize\nsome striking features emerging in the later case such as (i) the appearance of\nnon-abelian gauge theories in four dimensions starting from an abelian gauge\ntheory in higher dimensions, (ii) the fact that the spontaneous symmetry\nbreaking of the theory takes place entirely in the extra dimensions and (iii)\nthe renormalizability of the theory both in higher as well as in four\ndimensions. Then reversing the above approach we present a renormalizable four\ndimensional SU(N) gauge theory with a suitable multiplet of scalar fields,\nwhich via spontaneous symmetry breaking dynamically develops extra dimensions\nin the form of a fuzzy sphere. We explicitly find the tower of massive\nKaluza-Klein modes consistent with an interpretation as gauge theory on $M^4\n\\times S^2$, the scalars being interpreted as gauge fields on $S^2$. Depending\non the parameters of the model the low-energy gauge group can be of the form\n$SU(n_1) \\times SU(n_2) \\times U(1)$.\n\n", "human_text": "  We examine gauge theories defined in higher dimensions where theextra\ndimensions form a fuzzy (finite matrix) manifold. First we reinterpret these\ngauge theories as four-dimensional theories with Kaluza-Klein modes and then we\nperform a generalized \\`a la Forgacs-Manton dimensional reduction. We emphasize\nsome striking features emerging in the later case such as (i) the appearance of\nnon-abelian gauge theories in four dimensions starting from an abelian gauge\ntheory in higher dimensions, (ii) the fact that the spontaneous symmetry\nbreaking of the theory takes place entirely in the extra dimensions and (iii)\nthe renormalizability of the theory both in higher as well as in four\ndimensions. Then reversing the above approach we present a renormalizable four\ndimensional SU(N) gauge theory with a suitable multiplet of scalar fields,\nwhich via spontaneous symmetry breaking dynamically develops extra dimensions\nin the form of a fuzzy sphere. We explicitly find the tower of massive\nKaluza-Klein modes consistent with an interpretation as gauge theory on $M^4\n\\times S^2$, the scalars being interpreted as gauge fields on $S^2$. Depending\non the parameters of the model the low-energy gauge group can be of the form\n$SU(n_1) \\times SU(n_2) \\times U(1)$.\n", "machine_text": "\nThis paper looks into the properties of gauge theories defined in more than four dimensions, where the extra dimensions take the form of a fuzzy (finite matrix) manifold. We compare this to the well-known Kaluza-Klein views of lower-dimensional gauge theories, noting multiple key differences. These include effectively non-abelian gauge theories arising from higher-dimensional abelian theories, the emergence of spontaneous symmetry breaking in the extra dimensions, and the renormalizability of both higher- and lower-dimensional theories. Then we explore the inversion of this approach, with a renormalizable four-dimensional $SU(N)$ gauge theory whose symmetry breaking generates a fuzzy sphere of extra dimensions by way of extra scalar fields. This generates a corresponding tower of massive Kaluza-Klein modes, with the scalars themselves representing the gauge fields on the sphere. With suitable parameterization, the resulting low-energy gauge group can become $SU(n_1) \\times SU(n_2) \\times U(1)$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.288}
{"prompt": "Rephrase the abstract of an article with title 'Combining Weak Lensing Tomography with Halo Clustering to Probe Dark\n  Energy'.\n  Two methods of constraining the properties of dark energy are weak lensing\ntomography and cluster counting. Uncertainties in mass calibration of clusters\ncan be reduced by using the properties of halo clustering (the clustering of\nclusters). However, within a single survey, weak lensing and halo clustering\nprobe the same density fluctuations. We explore the question of whether this\ninformation can be used twice -- once in weak lensing and then again in halo\nclustering to calibrate cluster masses -- or whether the combined dark energy\nconstraints are weaker than the sum of the individual constraints. For a survey\nlike the Dark Energy Survey (DES), we find that the cosmic shearing of source\ngalaxies at high redshifts is indeed highly correlated with halo clustering at\nlower redshifts. Surprisingly, this correlation does not degrade cosmological\nconstraints for a DES-like survey, and in fact, constraints are marginally\nimproved since the correlations themselves act as additional observables. This\nconsiderably simplifies the analysis for a DES-like survey: when weak lensing\nand halo clustering are treated as independent experiments, the combined dark\nenergy constraints (cluster counts included) are accurate if not slightly\nconservative. Our findings mirror those of Takada and Bridle, who investigated\ncorrelations between the cosmic shear and cluster counts.\n\n", "human_text": "  Two methods of constraining the properties of dark energy are weak lensing\ntomography and cluster counting. Uncertainties in mass calibration of clusters\ncan be reduced by using the properties of halo clustering (the clustering of\nclusters). However, within a single survey, weak lensing and halo clustering\nprobe the same density fluctuations. We explore the question of whether this\ninformation can be used twice -- once in weak lensing and then again in halo\nclustering to calibrate cluster masses -- or whether the combined dark energy\nconstraints are weaker than the sum of the individual constraints. For a survey\nlike the Dark Energy Survey (DES), we find that the cosmic shearing of source\ngalaxies at high redshifts is indeed highly correlated with halo clustering at\nlower redshifts. Surprisingly, this correlation does not degrade cosmological\nconstraints for a DES-like survey, and in fact, constraints are marginally\nimproved since the correlations themselves act as additional observables. This\nconsiderably simplifies the analysis for a DES-like survey: when weak lensing\nand halo clustering are treated as independent experiments, the combined dark\nenergy constraints (cluster counts included) are accurate if not slightly\nconservative. Our findings mirror those of Takada and Bridle, who investigated\ncorrelations between the cosmic shear and cluster counts.\n", "machine_text": "\nIn this article, we investigate if the information from two methods of constraining dark energy - weak lensing tomography and cluster counting - can be used in tandem to refine mass calibration of clusters. We analyze a survey similar to the Dark Energy Survey (DES) to determine if it is possible to combine cosmic shearing of high redshift source galaxies with halo clustering at lower redshifts without degrading cosmological constraints. Surprisingly, our findings show that when weak lensing and halo clustering are treated independently, the combined dark energy constraints are even slightly better than the sum of individual constraints. Our results echo those proposed by Takada and Bridle examining correlations between cosmic shear and cluster counts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2395}
{"prompt": "Rephrase the abstract of an article with title 'The photospheric environment of a solar pore with light bridge'.\n  Pores are one of the various features forming in the photosphere by the\nemergence of magnetic field onto the solar surface. They lie at the border\nbetween tiny magnetic elements and larger sunspots. Light bridges, in such\nstructures, are bright features separating umbral areas in two or more\nirregular regions. Commonly, light bridges indicate that a the merging of\nmagnetic regions or, conversely, the breakup of the area is underway. We\ninvestigate the velocity structure of a solar pore (AR10812) with light bridge,\nand of the quiet solar photosphere nearby, analyzing high spatial and spectral\nresolution images. The pore area has been observed with the Interferometric\nBI-dimensional Spectrometer (IBIS) at the Dunn Solar Telescope, acquiring\nmonochromatic images in the Ca II 854.2 nm line and in the Fe I 709.0 nm line\nas well as G-band and broad-band images. We also computed the Line of Sight\n(LoS) velocity field associated to the Fe I and Fe II photospheric lines. The\namplitude of the LoS velocity fluctuations, inside the pore, is smaller than\nthat observed in the quiet granulation near the active region. We computed the\nazimuthal average LoS velocity and derived its radial profile. The whole pore\nis characterized by a downward velocity -200 m/s and by an annular downflow\nstructure with an average velocity of -350 m/s with respect to the nearby quiet\nsun. The light bridge inside the pore, when observed in the broad-band channel\nof IBIS and in the red wing of Ca II 854.2 nm line, shows an elongated dark\nstructure running along its axis, that we explain with a semi-analytical model.\nIn the highest resolution LoS velocity images the light bridge shows a profile\nconsistent with a convective roll: a weak upflow, 50-100m/s, in correspondence\nof the dark lane, flanked by a downflow, -(200-300) m/s.\n\n", "human_text": "  Pores are one of the various features forming in the photosphere by the\nemergence of magnetic field onto the solar surface. They lie at the border\nbetween tiny magnetic elements and larger sunspots. Light bridges, in such\nstructures, are bright features separating umbral areas in two or more\nirregular regions. Commonly, light bridges indicate that a the merging of\nmagnetic regions or, conversely, the breakup of the area is underway. We\ninvestigate the velocity structure of a solar pore (AR10812) with light bridge,\nand of the quiet solar photosphere nearby, analyzing high spatial and spectral\nresolution images. The pore area has been observed with the Interferometric\nBI-dimensional Spectrometer (IBIS) at the Dunn Solar Telescope, acquiring\nmonochromatic images in the Ca II 854.2 nm line and in the Fe I 709.0 nm line\nas well as G-band and broad-band images. We also computed the Line of Sight\n(LoS) velocity field associated to the Fe I and Fe II photospheric lines. The\namplitude of the LoS velocity fluctuations, inside the pore, is smaller than\nthat observed in the quiet granulation near the active region. We computed the\nazimuthal average LoS velocity and derived its radial profile. The whole pore\nis characterized by a downward velocity -200 m/s and by an annular downflow\nstructure with an average velocity of -350 m/s with respect to the nearby quiet\nsun. The light bridge inside the pore, when observed in the broad-band channel\nof IBIS and in the red wing of Ca II 854.2 nm line, shows an elongated dark\nstructure running along its axis, that we explain with a semi-analytical model.\nIn the highest resolution LoS velocity images the light bridge shows a profile\nconsistent with a convective roll: a weak upflow, 50-100m/s, in correspondence\nof the dark lane, flanked by a downflow, -(200-300) m/s.\n", "machine_text": "\nA solar pore with a light bridge, located on the boundary between small magnetic elements and bigger sunspots, was studied using high resolution images from the Interferometric BI-dimensional Spectrometer (IBIS). This area was observed using monochromatic images in the Ca II 854.2 nm line and in the Fe I 709.0 nm line, as well as G-band and broad-band images. The fluctuations in Line of Sight velocity observed inside the pore were smaller than in a quiet photosphere nearby. Azimuthal average LoS velocity was then measured showing a downward velocity of -200 m/s and an annular downward flow of -350 m/s relative to the near quiet sun. Further examination of the light bridge with the broad-band channel of IBIS and the red wing of Ca II 854.2 nm line revealed the presence of an elongated dark structure along its axis, realised as a convective roll representing a weak upflow of 50-100 m/s flanked by a downflow of -(200-300) m/s.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3776}
{"prompt": "Rephrase the abstract of an article with title 'Quantum Fields on the Groenewold-Moyal Plane: C, P, T and CPT'.\n  We show that despite the inherent non-locality of quantum field theories on\nthe Groenewold-Moyal (GM) plane, one can find a class of ${\\bf C}$, ${\\bf P}$,\n${\\bf T}$ and ${\\bf CPT}$ invariant theories. In particular, these are theories\nwithout gauge fields or with just gauge fields and no matter fields. We also\nshow that in the presence of gauge fields, one can have a field theory where\nthe Hamiltonian is ${\\bf C}$ and ${\\bf T}$ invariant while the $S$-matrix\nviolates ${\\bf P}$ and ${\\bf CPT}$.\n  In non-abelian gauge theories with matter fields such as the electro-weak and\n$QCD$ sectors of the standard model of particle physics, ${\\bf C}$, ${\\bf P}$,\n${\\bf T}$ and the product of any pair of them are broken while ${\\bf CPT}$\nremains intact for the case $\\theta^{0i} =0$. (Here $x^{\\mu} \\star x^{\\nu} -\nx^{\\nu} \\star x^{\\mu} = i \\theta^{\\mu \\nu}$, $x^{\\mu}$: coordinate functions,\n$\\theta^{\\mu \\nu} = -\\theta^{\\nu \\mu}=$ constant.) When $\\theta^{0i} \\neq 0$,\nit contributes to breaking also ${\\bf P}$ and ${\\bf CPT}$. It is known that the\n$S$-matrix in a non-abelian theory depends on $\\theta^{\\mu \\nu}$ only through\n$\\theta^{0i}$. The $S$-matrix is frame dependent. It breaks (the identity\ncomponent of the) Lorentz group. All the noncommutative effects vanish if the\nscattering takes place in the center-of-mass frame, or any frame where\n$\\theta^{0i}P^{\\textrm{in}}_{i} = 0$, but not otherwise. ${\\bf P}$ and ${\\bf\nCPT}$ are good symmetries of the theory in this special case.\n\n", "human_text": "  We show that despite the inherent non-locality of quantum field theories on\nthe Groenewold-Moyal (GM) plane, one can find a class of ${\\bf C}$, ${\\bf P}$,\n${\\bf T}$ and ${\\bf CPT}$ invariant theories. In particular, these are theories\nwithout gauge fields or with just gauge fields and no matter fields. We also\nshow that in the presence of gauge fields, one can have a field theory where\nthe Hamiltonian is ${\\bf C}$ and ${\\bf T}$ invariant while the $S$-matrix\nviolates ${\\bf P}$ and ${\\bf CPT}$.\n  In non-abelian gauge theories with matter fields such as the electro-weak and\n$QCD$ sectors of the standard model of particle physics, ${\\bf C}$, ${\\bf P}$,\n${\\bf T}$ and the product of any pair of them are broken while ${\\bf CPT}$\nremains intact for the case $\\theta^{0i} =0$. (Here $x^{\\mu} \\star x^{\\nu} -\nx^{\\nu} \\star x^{\\mu} = i \\theta^{\\mu \\nu}$, $x^{\\mu}$: coordinate functions,\n$\\theta^{\\mu \\nu} = -\\theta^{\\nu \\mu}=$ constant.) When $\\theta^{0i} \\neq 0$,\nit contributes to breaking also ${\\bf P}$ and ${\\bf CPT}$. It is known that the\n$S$-matrix in a non-abelian theory depends on $\\theta^{\\mu \\nu}$ only through\n$\\theta^{0i}$. The $S$-matrix is frame dependent. It breaks (the identity\ncomponent of the) Lorentz group. All the noncommutative effects vanish if the\nscattering takes place in the center-of-mass frame, or any frame where\n$\\theta^{0i}P^{\\textrm{in}}_{i} = 0$, but not otherwise. ${\\bf P}$ and ${\\bf\nCPT}$ are good symmetries of the theory in this special case.\n", "machine_text": "\nThis research presents a class of quantum field theories that are invariant under the transformations ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and ${\\bf CPT}$, despite their nonlocal nature when developed on the Groenewold-Moyal (GM) plane. We consider theories that contain either no gauge fields, or contain both gauge fields and no matter fields. We also demonstrate that in the presence of gauge fields, it is possible to have a field theory where the Hamiltonian is symmetric under ${\\bf C}$ and ${\\bf T}$, while the $S$-matrix violates both ${\\bf P}$ and ${\\bf CPT}$. For non-abelian gauge theories with matter fields, such as the electro-weak and $QCD$ sectors of the standard model of particle physics, the ${\\bf C}$, ${\\bf P}$, ${\\bf T}$ and any pairs of them are broken, while ${\\bf CPT}$ remains intact in the case of $\\theta^{0i}=0$. When $\\theta^{0i} \\neq 0$, it also contributes to breaking both ${\\bf P} $ and ${\\bf CPT}$. It is known that the $S$-matrix in a non-abelian theory depends solely on $\\theta^{0i}$. Moreover, this $S$-matrix is frame dependent; meaning it breaks the identity component of the Lorentz group. All the noncommutative effects cease to exist when the scattering takes place in the center-of-mass frame, or any other frame where $\\theta^{0i}P^{\\textrm{in}}_{i} = 0$. By contrast, in this special case both ${\\bf P}$ and ${\\bf CPT}$ are seen to be good symmetries of the theory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1259}
{"prompt": "Rephrase the abstract of an article with title 'Diffuse HI Disks in Isolated Galaxies'.\n  In order to investigate the contribution of diffuse components to their total\nHI emission, we have obtained high precision HI line flux densities with the\n100m Green Bank Telescope for a sample of 100 isolated spiral and irregular\ngalaxies which we have previously observed with the 43m telescope. A comparison\nof the observed HI line fluxes obtained with the two different telescopes,\ncharacterized by half-power beam widths of 9 arcmin and 21 arcmin respectively,\nexploits a ``beam matching'' technique to yield a statistical determination of\nthe occurrence of diffuse HI components in their disks. A simple model of the\nHI distribution within a galaxy well describes ~75 % of the sample and accounts\nfor all of the HI line flux density. The remaining galaxies are approximately\nevenly divided into two categories: ones which appear to possess a\nsignificantly more extensive HI distribution than the model predicts, and ones\nfor which the HI distribution is more centrally concentrated than predicted.\nExamples of both extremes can be found in the literature but little attention\nhas been paid to the centrally concentrated HI systems. Our sample has\ndemonstrated that galaxies do not commonly possess extended regions of low\nsurface brightness HI gas which is not accounted for by our current\nunderstanding of the structure of HI disks. Eight HI-rich companions to the\ntarget objects are identified, and a set of extragalactic HI line flux density\ncalibrators is presented.\n\n", "human_text": "  In order to investigate the contribution of diffuse components to their total\nHI emission, we have obtained high precision HI line flux densities with the\n100m Green Bank Telescope for a sample of 100 isolated spiral and irregular\ngalaxies which we have previously observed with the 43m telescope. A comparison\nof the observed HI line fluxes obtained with the two different telescopes,\ncharacterized by half-power beam widths of 9 arcmin and 21 arcmin respectively,\nexploits a ``beam matching'' technique to yield a statistical determination of\nthe occurrence of diffuse HI components in their disks. A simple model of the\nHI distribution within a galaxy well describes ~75 % of the sample and accounts\nfor all of the HI line flux density. The remaining galaxies are approximately\nevenly divided into two categories: ones which appear to possess a\nsignificantly more extensive HI distribution than the model predicts, and ones\nfor which the HI distribution is more centrally concentrated than predicted.\nExamples of both extremes can be found in the literature but little attention\nhas been paid to the centrally concentrated HI systems. Our sample has\ndemonstrated that galaxies do not commonly possess extended regions of low\nsurface brightness HI gas which is not accounted for by our current\nunderstanding of the structure of HI disks. Eight HI-rich companions to the\ntarget objects are identified, and a set of extragalactic HI line flux density\ncalibrators is presented.\n", "machine_text": "\nBy using the 100m Green Bank Telescope and 43m telescope to observe a collection of 100 isolated spiral and irregular galaxies, this study surveys their HI emission to determine the proportion of diffuse components in their disk. Comparing the HI line flux densities obtained by the two telescopes reveals the degree to which galaxies have an extended low surface brightness HI gas that observational models do not take into account. Results show that in ~75% of the sample, current models are appropriate in accurately accounting for HI distributions. The remaining galaxies, however, could have either a significantly greater HI distribution or a more concentrated one than the models prescribe. Additionally, HI-rich companions to the target objects are found and a set of HI line flux density calibrators are established.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2299}
{"prompt": "Rephrase the abstract of an article with title 'Strong atom-field coupling for Bose-Einstein condensates in an optical\n  cavity on a chip'.\n  An optical cavity enhances the interaction between atoms and light, and the\nrate of coherent atom-photon coupling can be made larger than all decoherence\nrates of the system. For single atoms, this strong coupling regime of cavity\nquantum electrodynamics (cQED) has been the subject of spectacular experimental\nadvances, and great efforts have been made to control the coupling rate by\ntrapping and cooling the atom towards the motional ground state, which has been\nachieved in one dimension so far. For N atoms, the three-dimensional ground\nstate of motion is routinely achieved in atomic Bose-Einstein condensates\n(BECs), but although first experiments combining BECs and optical cavities have\nbeen reported recently, coupling BECs to strong-coupling cavities has remained\nan elusive goal. Here we report such an experiment, which is made possible by\ncombining a new type of fibre-based cavity with atom chip technology. This\nallows single-atom cQED experiments with a simplified setup and realizes the\nnew situation of N atoms in a cavity each of which is identically and strongly\ncoupled to the cavity mode. Moreover, the BEC can be positioned\ndeterministically anywhere within the cavity and localized entirely within a\nsingle antinode of the standing-wave cavity field. This gives rise to a\ncontrolled, tunable coupling rate, as we confirm experimentally. We study the\nheating rate caused by a cavity transmission measurement as a function of the\ncoupling rate and find no measurable heating for strongly coupled BECs. The\nspectrum of the coupled atoms-cavity system, which we map out over a wide range\nof atom numbers and cavity-atom detunings, shows vacuum Rabi splittings\nexceeding 20 gigahertz, as well as an unpredicted additional splitting which we\nattribute to the atomic hyperfine structure.\n\n", "human_text": "  An optical cavity enhances the interaction between atoms and light, and the\nrate of coherent atom-photon coupling can be made larger than all decoherence\nrates of the system. For single atoms, this strong coupling regime of cavity\nquantum electrodynamics (cQED) has been the subject of spectacular experimental\nadvances, and great efforts have been made to control the coupling rate by\ntrapping and cooling the atom towards the motional ground state, which has been\nachieved in one dimension so far. For N atoms, the three-dimensional ground\nstate of motion is routinely achieved in atomic Bose-Einstein condensates\n(BECs), but although first experiments combining BECs and optical cavities have\nbeen reported recently, coupling BECs to strong-coupling cavities has remained\nan elusive goal. Here we report such an experiment, which is made possible by\ncombining a new type of fibre-based cavity with atom chip technology. This\nallows single-atom cQED experiments with a simplified setup and realizes the\nnew situation of N atoms in a cavity each of which is identically and strongly\ncoupled to the cavity mode. Moreover, the BEC can be positioned\ndeterministically anywhere within the cavity and localized entirely within a\nsingle antinode of the standing-wave cavity field. This gives rise to a\ncontrolled, tunable coupling rate, as we confirm experimentally. We study the\nheating rate caused by a cavity transmission measurement as a function of the\ncoupling rate and find no measurable heating for strongly coupled BECs. The\nspectrum of the coupled atoms-cavity system, which we map out over a wide range\nof atom numbers and cavity-atom detunings, shows vacuum Rabi splittings\nexceeding 20 gigahertz, as well as an unpredicted additional splitting which we\nattribute to the atomic hyperfine structure.\n", "machine_text": "\nThe strong coupling between atoms and light can be achieved with optical cavities, resulting in single atom experiments that exhibit the coherent atom-photon coupling rate exceeding decoherence rates. Making progress on cavity quantum electrodynamics (cQED) in three dimensions has been hindered by the difficulty in trapping and cooling atoms towards the motional ground state, but has been achievable with a Bose-Einstein condensate (BEC). With the pairing of a new fibre-based cavity and atom chip technology, this experiment presents a simpler setup that demonstrates a strong atom-field coupling for BECs in a cavity on a chip, allowing the BEC to be positioned within the cavity and fully localized within a sole antinode of the standing-wave. Through a transmission measurement, no noticeable heating takes place for the BEC at strong coupling. The spectrum of the coupled atoms-cavity system was mapped with a wide range of atom numbers and cavity-atom detunings, demonstrating vacuum Rabi splittings exceeding 20 gigahertz and an unexpected additional splitting attributed to the atomic hyperfine structure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.139}
{"prompt": "Rephrase the abstract of an article with title 'On the generalized Freedman-Townsend model'.\n  Consistent interactions that can be added to a free, Abelian gauge theory\ncomprising a finite collection of BF models and a finite set of two-form gauge\nfields (with the Lagrangian action written in first-order form as a sum of\nAbelian Freedman-Townsend models) are constructed from the deformation of the\nsolution to the master equation based on specific cohomological techniques.\nUnder the hypotheses of smoothness in the coupling constant, locality, Lorentz\ncovariance, and Poincare invariance of the interactions, supplemented with the\nrequirement on the preservation of the number of derivatives on each field with\nrespect to the free theory, we obtain that the deformation procedure modifies\nthe Lagrangian action, the gauge transformations as well as the accompanying\nalgebra. The interacting Lagrangian action contains a generalized version of\nnon-Abelian Freedman-Townsend model. The consistency of interactions to all\norders in the coupling constant unfolds certain equations, which are shown to\nhave solutions.\n\n", "human_text": "  Consistent interactions that can be added to a free, Abelian gauge theory\ncomprising a finite collection of BF models and a finite set of two-form gauge\nfields (with the Lagrangian action written in first-order form as a sum of\nAbelian Freedman-Townsend models) are constructed from the deformation of the\nsolution to the master equation based on specific cohomological techniques.\nUnder the hypotheses of smoothness in the coupling constant, locality, Lorentz\ncovariance, and Poincare invariance of the interactions, supplemented with the\nrequirement on the preservation of the number of derivatives on each field with\nrespect to the free theory, we obtain that the deformation procedure modifies\nthe Lagrangian action, the gauge transformations as well as the accompanying\nalgebra. The interacting Lagrangian action contains a generalized version of\nnon-Abelian Freedman-Townsend model. The consistency of interactions to all\norders in the coupling constant unfolds certain equations, which are shown to\nhave solutions.\n", "machine_text": "\nThis paper explores the construction and effects of consistent interactions added to a free, Abelian gauge theory including a finite number of BF models and two-form gauge fields. Using specific cohomological tools such as the master equation and its solution, the hypothesis of smooth coupling constants, locality, Lorentz covariance, Poincare invariance, and the maintenance of the same amount of derivatives with respect to the free theory allows us to create the resulting generalized non-Abelian Freedman-Townsend model, and thereby generate expressions of the corresponding deformed Lagrangian action, gauge transformations, and related algebra. Additionally, consistency conditions of the interactions in each successive power of the coupling constant are achieved by obtaining solutions to a set of equations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3407}
{"prompt": "Rephrase the abstract of an article with title 'Self-Similar Evolution of Cosmic-Ray-Modified Quasi-Parallel Plane\n  Shocks'.\n  Using an improved version of the previously introduced CRASH (Cosmic Ray\nAcceleration SHock) code, we have calculated the time evolution of cosmic-ray\n(CR) modified quasi-parallel plane shocks for Bohm-like diffusion, including\nself-consistent models of Alfven wave drift and dissipation, along with thermal\nleakage injection of CRs. The new simulations follow evolution of the CR\ndistribution to much higher energies than our previous study, providing a\nbetter examination of evolutionary and asymptotic behaviors. The postshock CR\npressure becomes constant after quick initial adjustment, since the evolution\nof the CR partial pressure expressed in terms of a momentum similarity variable\nis self-similar. The shock precursor, which scales as the diffusion length of\nthe highest energy CRs, subsequently broadens approximately linearly with time,\nindependent of diffusion model, so long as CRs continue to be accelerated to\never-higher energies. This means the nonlinear shock structure can be described\napproximately in terms of the similarity variable, x/(u_s t), where u_s is the\nshock speed once the postshock pressure reaches an approximate time asymptotic\nstate. As before, the shock Mach number is the key parameter determining the\nevolution and the CR acceleration efficiency, although finite Alfven wave drift\nand wave energy dissipation in the shock precursor reduce the effective\nvelocity change experienced by CRs, so reduce acceleration efficiency\nnoticeably, thus, providing a second important parameter at low and moderate\nMach numbers.\n\n", "human_text": "  Using an improved version of the previously introduced CRASH (Cosmic Ray\nAcceleration SHock) code, we have calculated the time evolution of cosmic-ray\n(CR) modified quasi-parallel plane shocks for Bohm-like diffusion, including\nself-consistent models of Alfven wave drift and dissipation, along with thermal\nleakage injection of CRs. The new simulations follow evolution of the CR\ndistribution to much higher energies than our previous study, providing a\nbetter examination of evolutionary and asymptotic behaviors. The postshock CR\npressure becomes constant after quick initial adjustment, since the evolution\nof the CR partial pressure expressed in terms of a momentum similarity variable\nis self-similar. The shock precursor, which scales as the diffusion length of\nthe highest energy CRs, subsequently broadens approximately linearly with time,\nindependent of diffusion model, so long as CRs continue to be accelerated to\never-higher energies. This means the nonlinear shock structure can be described\napproximately in terms of the similarity variable, x/(u_s t), where u_s is the\nshock speed once the postshock pressure reaches an approximate time asymptotic\nstate. As before, the shock Mach number is the key parameter determining the\nevolution and the CR acceleration efficiency, although finite Alfven wave drift\nand wave energy dissipation in the shock precursor reduce the effective\nvelocity change experienced by CRs, so reduce acceleration efficiency\nnoticeably, thus, providing a second important parameter at low and moderate\nMach numbers.\n", "machine_text": "\nIn this study, an improved version of the Cosmic Ray Acceleration SHock (CRASH) model has been used to investigate the progression of cosmic-ray (CR) affected quasi-parallel plane shocks. This new version entails an incorporated modeling of Alfven wave drift and dissipation, together with thermal leakage injection of CRs and further analysis of the CR distribution unto much higher energies than that of earlier studies. The results revealed that the pressure exerted by the postshock CR reaches a static state after a brief preliminary period of adjustment and the shock precursor expands incrementally over time, with no reliance on the diffusion model employed so long as CRs continue to be propelled up to higher energies. It was also established that the scale of the nonlinear shock structure can be familiarly represented in terms of the similarity variable (x/(u_s t)), which is contingent on the shock speed and with the Mach number serving as the paramount determinant for shock development and acceleration efficiency. The velocity change created by Alfven wave drift and wave energy dissipation in the precursor, however, lessens the CR optimization noticeably.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3274}
{"prompt": "Rephrase the abstract of an article with title 'CCD BV survey of 42 open clusters'.\n  We present results of a photometric survey whose aim was to derive structural\nand astrophysical parameters for 42 open clusters. While our sample is\ndefinitively not representative of the total open cluster sample in the Galaxy,\nit does cover a wide range of cluster parameters and is uniform enough to allow\nfor simple statistical considerations. BV wide-field CCD photometry was\nobtained for open clusters for which photometric, structural, and dynamical\nevolution parameters were determined. The limiting and core radii were\ndetermined by analyzing radial density profiles. The ages, reddenings, and\ndistances were obtained from the solar metallicity isochrone fitting. The mass\nfunction was used to study the dynamical state of the systems, mass segregation\neffect and to estimate the total mass and number of cluster members. This study\nreports on the first determination of basic parameters for 11 out of 42\nobserved open clusters. The angular sizes for the majority of the observed\nclusters appear to be several times larger than the catalogue data indicate.\nThe core and limiting cluster radii are correlated and the latter parameter is\n3.2 times larger on average. The limiting radius increases with the cluster's\nmass, and both the limiting and core radii decrease in the course of dynamical\nevolution. For dynamically not advanced clusters, the mass function slope is\nsimilar to the universal IMF slope. For more evolved systems, the effect of\nevaporation of low-mass members is clearly visible. The initial mass\nsegregation is present in all the observed young clusters, whereas the\ndynamical mass segregation appears in clusters older than about log(age)=8.\nLow-mass stars are deficient in the cores of clusters older than log(age)=8.5\nand not younger than one relaxation time.\n\n", "human_text": "  We present results of a photometric survey whose aim was to derive structural\nand astrophysical parameters for 42 open clusters. While our sample is\ndefinitively not representative of the total open cluster sample in the Galaxy,\nit does cover a wide range of cluster parameters and is uniform enough to allow\nfor simple statistical considerations. BV wide-field CCD photometry was\nobtained for open clusters for which photometric, structural, and dynamical\nevolution parameters were determined. The limiting and core radii were\ndetermined by analyzing radial density profiles. The ages, reddenings, and\ndistances were obtained from the solar metallicity isochrone fitting. The mass\nfunction was used to study the dynamical state of the systems, mass segregation\neffect and to estimate the total mass and number of cluster members. This study\nreports on the first determination of basic parameters for 11 out of 42\nobserved open clusters. The angular sizes for the majority of the observed\nclusters appear to be several times larger than the catalogue data indicate.\nThe core and limiting cluster radii are correlated and the latter parameter is\n3.2 times larger on average. The limiting radius increases with the cluster's\nmass, and both the limiting and core radii decrease in the course of dynamical\nevolution. For dynamically not advanced clusters, the mass function slope is\nsimilar to the universal IMF slope. For more evolved systems, the effect of\nevaporation of low-mass members is clearly visible. The initial mass\nsegregation is present in all the observed young clusters, whereas the\ndynamical mass segregation appears in clusters older than about log(age)=8.\nLow-mass stars are deficient in the cores of clusters older than log(age)=8.5\nand not younger than one relaxation time.\n", "machine_text": "\nIn this study, we examine 42 open clusters by utilizing wide-field CCD photometry in the BV filter to observe their vivid characteristics. To estimate the clusters' structure and astrophysical parameters, we develop radial density profiles, as well as fitting solar metallicity isochrones to determine the age, reddening, and distance of each. Additionally, we examine the mass function in order to analyze any dynamical state effects, mass segregation, and the total mass and membership in the clusters. We report basic findings for 11 of the 42 open clusters, observing that the angular sizes of the majority of the clusters were 3.2 times larger than the catalogue data indicated, as well as a correlation between the core and limiting radii that increased with the cluster's mass. Furthermore, we see evidence of initial mass segregation in all of the young clusters and dynamical mass segregation in clusters older than approximately 8.5 in log(age) after not less than one relaxation time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1364}
{"prompt": "Rephrase the abstract of an article with title 'Low-dimensional Supersymmetric Lattice Models'.\n  We study and simulate N=2 supersymmetric Wess-Zumino models in one and two\ndimensions. For any choice of the lattice derivative, the theories can be made\nmanifestly supersymmetric by adding appropriate improvement terms corresponding\nto discretizations of surface integrals. In one dimension, our simulations show\nthat a model with the Wilson derivative and the Stratonovitch prescription for\nthis discretization leads to far better results at finite lattice spacing than\nother models with Wilson fermions considered in the literature. In particular,\nwe check that fermionic and bosonic masses coincide and the unbroken Ward\nidentities are fulfilled to high accuracy. Equally good results for the\neffective masses can be obtained in a model with the SLAC derivative (even\nwithout improvement terms).\n  In two dimensions we introduce a non-standard Wilson term in such a way that\nthe discretization errors of the kinetic terms are only of order O(a^2). Masses\nextracted from the corresponding manifestly supersymmetric model prove to\napproach their continuum values much quicker than those from a model containing\nthe standard Wilson term. Again, a comparable enhancement can be achieved in a\ntheory using the SLAC derivative.\n\n", "human_text": "  We study and simulate N=2 supersymmetric Wess-Zumino models in one and two\ndimensions. For any choice of the lattice derivative, the theories can be made\nmanifestly supersymmetric by adding appropriate improvement terms corresponding\nto discretizations of surface integrals. In one dimension, our simulations show\nthat a model with the Wilson derivative and the Stratonovitch prescription for\nthis discretization leads to far better results at finite lattice spacing than\nother models with Wilson fermions considered in the literature. In particular,\nwe check that fermionic and bosonic masses coincide and the unbroken Ward\nidentities are fulfilled to high accuracy. Equally good results for the\neffective masses can be obtained in a model with the SLAC derivative (even\nwithout improvement terms).\n  In two dimensions we introduce a non-standard Wilson term in such a way that\nthe discretization errors of the kinetic terms are only of order O(a^2). Masses\nextracted from the corresponding manifestly supersymmetric model prove to\napproach their continuum values much quicker than those from a model containing\nthe standard Wilson term. Again, a comparable enhancement can be achieved in a\ntheory using the SLAC derivative.\n", "machine_text": "\nWe carry out simulations with N=2 supersymmetric Wess-Zumino models in both one and two dimensions. We employ various lattice derivatives and add improvement terms to maintain supersymmetry. Our simulations in one dimension show that a model with the Wilson derivative and the Stratonovitch discretization gives superior results to any other model with Wilson fermions in the literature. We check that the fermionic and bosonic masses are equal and Ward identities are satisfied. In two dimensions, we introduce a modified Wilson term leading to discretization errors of order O(a^2). Our studies show that the masses gotten from the corresponding supersymmetric model approach their continuum values faster than those from a model with the standard Wilson term. We also observe a comparable increase in performance when employing the SLAC derivative.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2212}
{"prompt": "Rephrase the abstract of an article with title 'Physical properties of the jet in 0836+710 revealed by its transversal\n  structure'.\n  Studying the internal structure of extragalactic jets is crucial for\nunderstanding their physics. The Japanese-led space VLBI project VSOP has\npresented an opportunity for such studies, by reaching baseline lengths of up\nto 36,000 km and resolving structures down to an angular size of $\\approx 0.3$\nmas at 5 GHz. VSOP observations of the jet in 0836+710 at 1.6 and 5 GHz have\nenabled tracing of the radial structure of the flow on scales from 2 mas to 200\nmas along the jet and determination of the wavelengths of individual\noscillatory modes responsible for the formation of the structure observed. We\napply linear stability analysis to identify the oscillatory modes with modes of\nKelvin-Helmholtz instability that match the wavelengths of the structures\nobserved. We find that the jet structure in 0836+710 can be reproduced by the\nhelical surface mode and a combination of the helical and elliptic body modes\nof Kelvin-Helmholtz instability. Our results indicate that the jet is\nsubstantially stratified and different modes of the instability grow inside the\njet at different distances to the jet axis. The helical surface mode can be\ndriven externally, and we discuss the implications of the driving frequency on\nthe physics of the active nucleus in 0836+710.\n\n", "human_text": "  Studying the internal structure of extragalactic jets is crucial for\nunderstanding their physics. The Japanese-led space VLBI project VSOP has\npresented an opportunity for such studies, by reaching baseline lengths of up\nto 36,000 km and resolving structures down to an angular size of $\\approx 0.3$\nmas at 5 GHz. VSOP observations of the jet in 0836+710 at 1.6 and 5 GHz have\nenabled tracing of the radial structure of the flow on scales from 2 mas to 200\nmas along the jet and determination of the wavelengths of individual\noscillatory modes responsible for the formation of the structure observed. We\napply linear stability analysis to identify the oscillatory modes with modes of\nKelvin-Helmholtz instability that match the wavelengths of the structures\nobserved. We find that the jet structure in 0836+710 can be reproduced by the\nhelical surface mode and a combination of the helical and elliptic body modes\nof Kelvin-Helmholtz instability. Our results indicate that the jet is\nsubstantially stratified and different modes of the instability grow inside the\njet at different distances to the jet axis. The helical surface mode can be\ndriven externally, and we discuss the implications of the driving frequency on\nthe physics of the active nucleus in 0836+710.\n", "machine_text": "\nThis study used the Japanese-led VSOP space VLBI project, which extends baseline lengths up to 36,000 km and resolving structures to 0.3 mas, to investigate the transversal structure of extragalactic jet 0836+710 at 1.6 and 5 GHz. A linear stability analysis was applied to the data to identify which of the Kelvin-Helmholtz instabilities could explain the large-scale structures observed in this jet. Our results demonstrate that the stratified jet can be reproduced by both the helical surface and helical/elliptic body modes of instability, with the helical surface mode driving frequency delivering insights into the physics of the active nucleus.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0433}
{"prompt": "Rephrase the abstract of an article with title 'Chromatin Folding in Relation to Human Genome Function'.\n  Three-dimensional (3D) chromatin structure is closely related to genome\nfunction, in particular transcription. However, the folding path of the\nchromatin fiber in the interphase nucleus is unknown. Here, we systematically\nmeasured the 3D physical distance between pairwise labeled genomic positions in\ngene-dense, highly transcribed domains and gene-poor less active areas on\nchromosomes 1 and 11 in G1 nuclei of human primary fibroblasts, using\nfluorescence in situ hybridization. Interpretation of our results and those\npublished by others, based on polymer physics, shows that the folding of the\nchromatin fiber can be described as a polymer in a globular state (GS),\nmaintained by intra-polymer attractive interactions that counteract\nself-avoidance forces. The GS polymer model is able to describe chromatin\nfolding in as well the highly expressed domains as the lowly expressed ones,\nindicating that they differ in Kuhn length and chromatin compaction. Each type\nof genomic domain constitutes an ensemble of relatively compact globular\nfolding states, resulting in a considerable cellto- cell variation between\notherwise identical cells. We present evidence for different polymer folding\nregimes of the chromatin fiber on the length scale of a few mega base pairs and\non that of complete chromosome arms (several tens of Mb). Our results present a\nnovel view on the folding of the chromatin fiber in interphase and open the\npossibility to explore the nature of the intra-chromatin fiber interactions.\n\n", "human_text": "  Three-dimensional (3D) chromatin structure is closely related to genome\nfunction, in particular transcription. However, the folding path of the\nchromatin fiber in the interphase nucleus is unknown. Here, we systematically\nmeasured the 3D physical distance between pairwise labeled genomic positions in\ngene-dense, highly transcribed domains and gene-poor less active areas on\nchromosomes 1 and 11 in G1 nuclei of human primary fibroblasts, using\nfluorescence in situ hybridization. Interpretation of our results and those\npublished by others, based on polymer physics, shows that the folding of the\nchromatin fiber can be described as a polymer in a globular state (GS),\nmaintained by intra-polymer attractive interactions that counteract\nself-avoidance forces. The GS polymer model is able to describe chromatin\nfolding in as well the highly expressed domains as the lowly expressed ones,\nindicating that they differ in Kuhn length and chromatin compaction. Each type\nof genomic domain constitutes an ensemble of relatively compact globular\nfolding states, resulting in a considerable cellto- cell variation between\notherwise identical cells. We present evidence for different polymer folding\nregimes of the chromatin fiber on the length scale of a few mega base pairs and\non that of complete chromosome arms (several tens of Mb). Our results present a\nnovel view on the folding of the chromatin fiber in interphase and open the\npossibility to explore the nature of the intra-chromatin fiber interactions.\n", "machine_text": "\nBy utilizing fluorescence in situ hybridization, this article measured the 3D physical distance between specified genomic positions on chromosomes 1 and 11 of G1 cell nuclei found in human primary fibroblasts. Results, which are based off of polymer physics, demonstrate that chromatin folding is comparable to a polymer in a globular state. This globular state is regulated by attractive interactions which suppress the self-avoidance force exhibited by the chromatin. It was also determined that highly expressed and lowly expressed genomic domains differ regarding the Kuhn length and their chromatin compaction. This results in a range of compact globular folding states across cells. Furthermore, it was revealed that the folding of chromatin is seen on different length scales and can even apply to entire chromosome arms. Altogether, this article explores the intras chromatin fiber folding and provides novel insight into the folding of the chromatin fiber in interphase.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1656}
{"prompt": "Rephrase the abstract of an article with title 'Un Resultat Gravimetrique pour la Renaissance de la Theorie\n  Corpusculaire \"An Experimental Gravimetric Result for the Revival of\n  Corpuscular Theory\"'.\n  The gravitational phenomenon, founded on the assumption of absorption of a\nflux of gravitons through the matter, led to a law of attraction comprising a\nterm of attenuation of gravity. The attenuation effect, which depends on the\ndistribution of mass elements into the Sun, was compared with the relativistic\neffect for the orbital elements of planets. The calculations carried out with\nour modified law of Newton, lead to a perfect agreement for the advance of the\nperihelion of planets, and give an interaction cross section with the matter of\n3.2x10^-17 m2/kg (approximately 10^-40 cm2/nucleon). The effect of attenuation\nduring a solar eclipse will produce a local reduction in the soli-lunar\nattraction of 0.13 microgal. This small variation of gravity during the eclipse\ncan lead to distortions of the geoid of about ten millimetres of which effect\non gravity, estimated at a few microgals, is compatible with the observed\ngravitational anomalies. The gravimetric measurements taken in the area of\nMontreal during the Sun eclipse of May 10, 1994, show the existence of an\nanomaly of 2.4 microgals that coincides perfectly with the period of the\neclipse.\n\n", "human_text": "  The gravitational phenomenon, founded on the assumption of absorption of a\nflux of gravitons through the matter, led to a law of attraction comprising a\nterm of attenuation of gravity. The attenuation effect, which depends on the\ndistribution of mass elements into the Sun, was compared with the relativistic\neffect for the orbital elements of planets. The calculations carried out with\nour modified law of Newton, lead to a perfect agreement for the advance of the\nperihelion of planets, and give an interaction cross section with the matter of\n3.2x10^-17 m2/kg (approximately 10^-40 cm2/nucleon). The effect of attenuation\nduring a solar eclipse will produce a local reduction in the soli-lunar\nattraction of 0.13 microgal. This small variation of gravity during the eclipse\ncan lead to distortions of the geoid of about ten millimetres of which effect\non gravity, estimated at a few microgals, is compatible with the observed\ngravitational anomalies. The gravimetric measurements taken in the area of\nMontreal during the Sun eclipse of May 10, 1994, show the existence of an\nanomaly of 2.4 microgals that coincides perfectly with the period of the\neclipse.\n", "machine_text": "\nBy utilizing the moderated version of Newton's Law of Attraction, with an assumption wherein a flux of gravitons pass through matter, a term describing the attenuation of gravity was observed. This permitted a comparison between the relativistic orbital elements of planets and the observed mass distribution of the Sun. Therein, the findings created an interactions cross section of 3.2x10^-17 m2/kg (nearly 10^-40 cm2/ nucleon) and produced a diminutive variation of gravity during a solar eclipse; estimated at 0.13 microgals. Subsequent analysis elucidated the ways in which this minor adjustments could impact the geoid - evidenced by anticipated deformation of the visage of gravity at around ten millimetres. Moreover, the results of measurements taken in the district encompassing Montreal during the Sun eclipse of May 10, 1994, displayed an anomaly of 2.4 microgals that corroborated exactly with the duration of the eclipse. This serves to corroborate the applicability and success of the corpuscular theory postulated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2581}
{"prompt": "Rephrase the abstract of an article with title 'Line and Mean Opacities for Ultracool Dwarfs and Extrasolar Planets'.\n  Opacities and chemical abundance data are crucial ingredients of ultracool\ndwarf and extrasolar giant planet atmosphere models. We report here on the\ndetailed sources of molecular opacity data employed by our group for this\napplication. We also present tables of Rosseland and Planck mean opacities\nwhich are of use in some studies of the atmospheres, interiors, and evolution\nof planets and brown dwarfs. For the tables presented here we have included the\nopacities of important atomic and molecular species, including the alkali\nelements, pressure induced absorption by hydrogen, and other significant\nopacity sources but neglect opacity from condensates. We report for each\nspecies how we have assembled molecular line data from a combination of public\ndatabases, laboratory data that is not yet in the public databases, and our own\nnumerical calculations. We combine these opacities with abundances computed\nfrom a chemical equilibrium model using recently revised solar abundances to\ncompute mean opacities. The chemical equilibrium calculation accounts for the\nsettling of condensates in a gravitational field, and is applicable to\nultracool dwarf and extrasolar planetary atmospheres, but not circumstellar\ndisks. We find that the inclusion of alkali atomic opacity substantially\nincreases the mean opacities over those currently in the literature at\ndensities relevant to the atmospheres and interiors of giant planets and brown\ndwarfs. We provide our opacity tables for public use and discuss their\nlimitations.\n\n", "human_text": "  Opacities and chemical abundance data are crucial ingredients of ultracool\ndwarf and extrasolar giant planet atmosphere models. We report here on the\ndetailed sources of molecular opacity data employed by our group for this\napplication. We also present tables of Rosseland and Planck mean opacities\nwhich are of use in some studies of the atmospheres, interiors, and evolution\nof planets and brown dwarfs. For the tables presented here we have included the\nopacities of important atomic and molecular species, including the alkali\nelements, pressure induced absorption by hydrogen, and other significant\nopacity sources but neglect opacity from condensates. We report for each\nspecies how we have assembled molecular line data from a combination of public\ndatabases, laboratory data that is not yet in the public databases, and our own\nnumerical calculations. We combine these opacities with abundances computed\nfrom a chemical equilibrium model using recently revised solar abundances to\ncompute mean opacities. The chemical equilibrium calculation accounts for the\nsettling of condensates in a gravitational field, and is applicable to\nultracool dwarf and extrasolar planetary atmospheres, but not circumstellar\ndisks. We find that the inclusion of alkali atomic opacity substantially\nincreases the mean opacities over those currently in the literature at\ndensities relevant to the atmospheres and interiors of giant planets and brown\ndwarfs. We provide our opacity tables for public use and discuss their\nlimitations.\n", "machine_text": "\nIn this paper, we examine the sources of molecular line and mean opacity data utilized when modeling ultracool dwarf and extrasolar planet atmospheres. We additionally provide tables containing the Rosseland and Planck mean opacities, which can be useful for studying the atmospheres, interiors, and evolution of these celestial bodies. The molecular opacities for these models are generated from both publicly available databases, laboratory measurements, and computed values, while elemental abundances used in the mean opacity calculation are computed from a chemical equilibrium model with recently updated solar abundances. We also observe that the opacities of atomic and molecular alkali elements boost mean opacities significantly when applicable to densities of planets\u2019 and brown dwarf atmospheres and interiors. Our resulting opacity tables are publicized and their limitations discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2374}
{"prompt": "Rephrase the abstract of an article with title 'The Elongated Structure of the Hercules dSph from Deep LBT Imaging'.\n  We present a deep, wide-field photometric survey of the newly-discovered\nHercules dwarf spheroidal galaxy, based on data from the Large Binocular\nTelescope. Images in B, V and r were obtained with the Large Binocular Camera\ncovering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This\npermitted the construction of colour-magnitude diagrams that reach\napproximately 1.5 magnitudes below the Hercules main sequence turnoff.\nThree-filter photometry allowed us to preferentially select probable Hercules\nmember stars, and examine the structure of this system at a previously\nunattained level. We find that the Hercules dwarf is highly elongated (3:1),\nconsiderably more so than any other dSph satellite of the Milky Way except the\ndisrupting Sagittarius dwarf. While we cannot rule out that the unusual\nstructure is intrinsic to Hercules as an equilibrium system, our results\nsuggest tidal disruption as a likely cause of this highly elliptical structure.\nGiven the relatively large Galactocentric distance of this system (132 +/- 12\nkpc), signs of tidal disruption would require the Hercules dwarf to be on a\nhighly eccentric orbit around the Milky Way.\n\n", "human_text": "  We present a deep, wide-field photometric survey of the newly-discovered\nHercules dwarf spheroidal galaxy, based on data from the Large Binocular\nTelescope. Images in B, V and r were obtained with the Large Binocular Camera\ncovering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This\npermitted the construction of colour-magnitude diagrams that reach\napproximately 1.5 magnitudes below the Hercules main sequence turnoff.\nThree-filter photometry allowed us to preferentially select probable Hercules\nmember stars, and examine the structure of this system at a previously\nunattained level. We find that the Hercules dwarf is highly elongated (3:1),\nconsiderably more so than any other dSph satellite of the Milky Way except the\ndisrupting Sagittarius dwarf. While we cannot rule out that the unusual\nstructure is intrinsic to Hercules as an equilibrium system, our results\nsuggest tidal disruption as a likely cause of this highly elliptical structure.\nGiven the relatively large Galactocentric distance of this system (132 +/- 12\nkpc), signs of tidal disruption would require the Hercules dwarf to be on a\nhighly eccentric orbit around the Milky Way.\n", "machine_text": "\nUsing high-quality images from the Large Binocular Telescope, we conducted a deep and wide-field photometric survey of the newly-found Hercules dwarf spheroidal galaxy. By mapping a 23' times 23' field, our three-filter photometry revealed colour-magnitude diagrams that extended down to around 1.5 magnitudes below the main sequence turnoff of the Hercules dwarf. Our analysis allowed us to accurately select likely Hercules members and observe the structure of the system at an unprecedented scale. Strikingly, we discovered that compared to other dwarf spheroidal satellite galaxies of the Milky Way, the Hercules dwarf exhibits an extremely elongated shape (3:1). We suggest that its unusual shape is likely due to tidally disruptive forces, being at a relatively high distance from the centre of the Milky Way. This would indicate that the Hercules dwarf is on an eccentric orbit around the Milky Way.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1669}
{"prompt": "Rephrase the abstract of an article with title 'Search for Heavy Neutral MSSM Higgs Bosons with CMS: Reach and\n  Higgs-Mass Precision'.\n  The search for MSSM Higgs bosons will be an important goal at the LHC. We\nanalyze the search reach of the CMS experiment for the heavy neutral MSSM Higgs\nbosons with an integrated luminosity of 30 or 60 fb^-1. This is done by\ncombining the latest results for the CMS experimental sensitivities based on\nfull simulation studies with state-of-the-art theoretical predictions of MSSM\nHiggs-boson properties. The results are interpreted in MSSM benchmark scenarios\nin terms of the parameters tan_beta and the Higgs-boson mass scale, M_A. We\nstudy the dependence of the 5 sigma discovery contours in the M_A-tan_beta\nplane on variations of the other supersymmetric parameters. The largest effects\narise from a change in the higgsino mass parameter mu, which enters both via\nhigher-order radiative corrections and via the kinematics of Higgs decays into\nsupersymmetric particles. While the variation of $\\mu$ can shift the\nprospective discovery reach (and correspondingly the ``LHC wedge'' region) by\nabout Delta tan_beta = 10, we find that the discovery reach is rather stable\nwith respect to the impact of other supersymmetric parameters. Within the\ndiscovery region we analyze the accuracy with which the masses of the heavy\nneutral Higgs bosons can be determined. We find that an accuracy of 1-4% should\nbe achievable, which could make it possible in favourable regions of the MSSM\nparameter space to experimentally resolve the signals of the two heavy MSSM\nHiggs bosons at the LHC.\n\n", "human_text": "  The search for MSSM Higgs bosons will be an important goal at the LHC. We\nanalyze the search reach of the CMS experiment for the heavy neutral MSSM Higgs\nbosons with an integrated luminosity of 30 or 60 fb^-1. This is done by\ncombining the latest results for the CMS experimental sensitivities based on\nfull simulation studies with state-of-the-art theoretical predictions of MSSM\nHiggs-boson properties. The results are interpreted in MSSM benchmark scenarios\nin terms of the parameters tan_beta and the Higgs-boson mass scale, M_A. We\nstudy the dependence of the 5 sigma discovery contours in the M_A-tan_beta\nplane on variations of the other supersymmetric parameters. The largest effects\narise from a change in the higgsino mass parameter mu, which enters both via\nhigher-order radiative corrections and via the kinematics of Higgs decays into\nsupersymmetric particles. While the variation of $\\mu$ can shift the\nprospective discovery reach (and correspondingly the ``LHC wedge'' region) by\nabout Delta tan_beta = 10, we find that the discovery reach is rather stable\nwith respect to the impact of other supersymmetric parameters. Within the\ndiscovery region we analyze the accuracy with which the masses of the heavy\nneutral Higgs bosons can be determined. We find that an accuracy of 1-4% should\nbe achievable, which could make it possible in favourable regions of the MSSM\nparameter space to experimentally resolve the signals of the two heavy MSSM\nHiggs bosons at the LHC.\n", "machine_text": "  An exploration of MSSM heavy neutral Higgs bosons is presented based on the CMS experiment with integrated luminosity of 30 and 60 fb$^{-1}$. Utilizing both the latest experimental sensitivity studies and theoretical predictions of MSSM Higgs-boson characteristics, the search capability is interpreted in terms of the parameters tan$\\beta$ and M$_A$. Examination of the 5 sigma discovery contours with respect to varying other supersymmetric parameters shows that a change in the higgsino mass parameter $\\mu$ can alter the prospective discovery reach (the \"LHC wedge\" region) by around 10 Delta tan$\\beta$. Furthermore, a high-precision measurement of the heavy neutral Higgs boson masses may be feasible and potentially help detect the signals of the two heavy MSSM Higgs bosons at the LHC in favourable regions of the MSSM parameter space.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0619}
{"prompt": "Rephrase the abstract of an article with title 'A de Haas-van Alphen study of the filled skutterudite compounds\n  PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$'.\n  Comprehensive magnetic-field-orientation dependent studies of the\nsusceptibility and de Haas-van Alphen effect have been carried out on single\ncrystals of the filled skutterudites PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$\nusing magnetic fields of up to 40~T. Several peaks are observed in the\nlow-field susceptibility of PrOs$_4$As$_{12}$, corresponding to cascades of\nmetamagnetic transitions separating the low-field antiferromagnetic and\nhigh-field paramagnetic metal (PMM) phases. The de Haas-van Alphen experiments\nshow that the Fermi-surface topologies of PrOs$_4$As$_{12}$ in its PMM phase\nand LaOs$_4$As$_{12}$ are very similar. In addition, they are in reasonable\nagreement with the predictions of bandstructure calculations for\nLaOs$_4$As$_{12}$ on the PrOs$_4$As$_{12}$ lattice. Both observations suggest\nthat the Pr 4$f$ electrons contribute little to the number of itinerant\nquasiparticles in the PMM phase. However, whilst the properties of\nLaOs$_4$As$_{12}$ suggest a conventional nonmagnetic Fermi liquid, the effects\nof direct exchange and electron correlations are detected in the PMM phase of\nPrOs$_4$As$_{12}$. For example, the quasiparticle effective masses in\nPrOs$_4$As$_{12}$ are found to decrease with increasing field, probably\nreflecting the gradual suppression of magnetic fluctuations associated with\nproximity to the low-temperature, low-field antiferromagnetic state.\n\n", "human_text": "  Comprehensive magnetic-field-orientation dependent studies of the\nsusceptibility and de Haas-van Alphen effect have been carried out on single\ncrystals of the filled skutterudites PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$\nusing magnetic fields of up to 40~T. Several peaks are observed in the\nlow-field susceptibility of PrOs$_4$As$_{12}$, corresponding to cascades of\nmetamagnetic transitions separating the low-field antiferromagnetic and\nhigh-field paramagnetic metal (PMM) phases. The de Haas-van Alphen experiments\nshow that the Fermi-surface topologies of PrOs$_4$As$_{12}$ in its PMM phase\nand LaOs$_4$As$_{12}$ are very similar. In addition, they are in reasonable\nagreement with the predictions of bandstructure calculations for\nLaOs$_4$As$_{12}$ on the PrOs$_4$As$_{12}$ lattice. Both observations suggest\nthat the Pr 4$f$ electrons contribute little to the number of itinerant\nquasiparticles in the PMM phase. However, whilst the properties of\nLaOs$_4$As$_{12}$ suggest a conventional nonmagnetic Fermi liquid, the effects\nof direct exchange and electron correlations are detected in the PMM phase of\nPrOs$_4$As$_{12}$. For example, the quasiparticle effective masses in\nPrOs$_4$As$_{12}$ are found to decrease with increasing field, probably\nreflecting the gradual suppression of magnetic fluctuations associated with\nproximity to the low-temperature, low-field antiferromagnetic state.\n", "machine_text": "\nThe properties of the filled skutterudite compounds PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}$ were investigated by employing magnetic field-orientation dependent susceptibility and de Haas-van Alphen measurements up to 40 T. Distinctive peaks in the susceptibility of PrOs$_4$As$_{12}$, which could be ascribed to metamagnetic transitions, divided the low-field antiferromagnetic and high-field paramagnetic metal phases. The de Haas-van Alphen experiments further indicated a remarkable likeness in Fermi-surface topology between PrOs$_4$As$_{12}$ and LaOs$_4$As$_{12}, as well as moderate congruence between measured and bandstructure-calculated values for the lattice of PrOs$_4$As$_{12}. These findings suggest that the 4f electrons of PrOs$_4$As$_{12}$ are not significant to itinerant quasiparticle profile, while LaOs$_4$As$_{12} is more typical of a nonmagnetic Fermi-liquid. Additionally, PrOs$_4$As$_{12} showed specific behaviors of effectual masses, ascribed to the suppression of magnetic fluctuations near its antiferromagnetic behavior.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2767}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical Friction of a Circular-Orbit Perturber in a Gaseous Medium'.\n  We investigate the gravitational wake due to, and dynamical friction on, a\nperturber moving on a circular orbit in a uniform gaseous medium using a\nsemi-analytic method. This work is a straightforward extension of Ostriker\n(1999) who studied the case of a straight-line trajectory. The circular orbit\ncauses the bending of the wake in the background medium along the orbit,\nforming a long trailing tail. The wake distribution is thus asymmetric, giving\nrise to the drag forces in both opposite (azimuthal) and lateral (radial)\ndirections to the motion of the perturber, although the latter does not\ncontribute to orbital decay much. For subsonic motion, the density wake with a\nweak tail is simply a curved version of that in Ostriker and does not exhibit\nthe front-back symmetry. The resulting drag force in the opposite direction is\nremarkably similar to the finite-time, linear-trajectory counterpart. On the\nother hand, a supersonic perturber is able to overtake its own wake, possibly\nmultiple times, and develops a very pronounced tail. The supersonic tail\nsurrounds the perturber in a trailing spiral fashion, enhancing the perturbed\ndensity at the back as well as far front of the perturber. We provide the\nfitting formulae for the drag forces as functions of the Mach number, whose\nazimuthal part is surprisingly in good agreement with the Ostriker's formula,\nprovided Vp t=2 Rp, where Vp and Rp are the velocity and orbital radius of the\nperturber, respectively.\n\n", "human_text": "  We investigate the gravitational wake due to, and dynamical friction on, a\nperturber moving on a circular orbit in a uniform gaseous medium using a\nsemi-analytic method. This work is a straightforward extension of Ostriker\n(1999) who studied the case of a straight-line trajectory. The circular orbit\ncauses the bending of the wake in the background medium along the orbit,\nforming a long trailing tail. The wake distribution is thus asymmetric, giving\nrise to the drag forces in both opposite (azimuthal) and lateral (radial)\ndirections to the motion of the perturber, although the latter does not\ncontribute to orbital decay much. For subsonic motion, the density wake with a\nweak tail is simply a curved version of that in Ostriker and does not exhibit\nthe front-back symmetry. The resulting drag force in the opposite direction is\nremarkably similar to the finite-time, linear-trajectory counterpart. On the\nother hand, a supersonic perturber is able to overtake its own wake, possibly\nmultiple times, and develops a very pronounced tail. The supersonic tail\nsurrounds the perturber in a trailing spiral fashion, enhancing the perturbed\ndensity at the back as well as far front of the perturber. We provide the\nfitting formulae for the drag forces as functions of the Mach number, whose\nazimuthal part is surprisingly in good agreement with the Ostriker's formula,\nprovided Vp t=2 Rp, where Vp and Rp are the velocity and orbital radius of the\nperturber, respectively.\n", "machine_text": "  We explore the changes that occur to the gravitational wake, and ensuing dynamical friction, of a circular-orbiting perturber when moving through a uniform gaseous medium. This research follows-up on the findings of Ostriker (1999) who studied the motion of a perturber via a straight-line pathway. The dynamic effects of a circular orbit are considerable and manifest in the formation of a trailing tail, caused by the curved wake that is pushed through the gaseous medium. This asymmetry imparts angular forces in both directions of the perturber's motion and, although radial forces are not significant as far as orbital decay, there are still observable effects on the density wake. When experiencing subsonic motions, for example, the density wake takes on a curved shape, unique from Ostriker's findings, and the dynamical friction is nearly identical to that of a linear trajectory. Even more distinct, when the perturber surpasses the speed of sound, it has the potential to overtake the wake multiple times; consequentially forming a trailing spiral around the perturber, and consequently increasing the perturbed density both in the front and back of the perturber. We find a general agreement between the formulas for the drag forces as a function of the Mach number, as well as with Ostriker's model, when Vp t=2 Rp, where Vp and Rp refer to the velocity and orbital radius of the perturber, respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0084}
{"prompt": "Rephrase the abstract of an article with title 'Maximally Supersymmetric Planar Yang-Mills Amplitudes at Five Loops'.\n  We present an ansatz for the planar five-loop four-point amplitude in\nmaximally supersymmetric Yang-Mills theory in terms of loop integrals. This\nansatz exploits the recently observed correspondence between integrals with\nsimple conformal properties and those found in the four-point amplitudes of the\ntheory through four loops. We explain how to identify all such integrals\nsystematically. We make use of generalized unitarity in both four and D\ndimensions to determine the coefficients of each of these integrals in the\namplitude. Maximal cuts, in which we cut all propagators of a given integral,\nare an especially effective means for determining these coefficients. The set\nof integrals and coefficients determined here will be useful for computing the\nfive-loop cusp anomalous dimension of the theory which is of interest for\nnon-trivial checks of the AdS/CFT duality conjecture. It will also be useful\nfor checking a conjecture that the amplitudes have an iterative structure\nallowing for their all-loop resummation, whose link to a recent string-side\ncomputation by Alday and Maldacena opens a new venue for quantitative AdS/CFT\ncomparisons.\n\n", "human_text": "  We present an ansatz for the planar five-loop four-point amplitude in\nmaximally supersymmetric Yang-Mills theory in terms of loop integrals. This\nansatz exploits the recently observed correspondence between integrals with\nsimple conformal properties and those found in the four-point amplitudes of the\ntheory through four loops. We explain how to identify all such integrals\nsystematically. We make use of generalized unitarity in both four and D\ndimensions to determine the coefficients of each of these integrals in the\namplitude. Maximal cuts, in which we cut all propagators of a given integral,\nare an especially effective means for determining these coefficients. The set\nof integrals and coefficients determined here will be useful for computing the\nfive-loop cusp anomalous dimension of the theory which is of interest for\nnon-trivial checks of the AdS/CFT duality conjecture. It will also be useful\nfor checking a conjecture that the amplitudes have an iterative structure\nallowing for their all-loop resummation, whose link to a recent string-side\ncomputation by Alday and Maldacena opens a new venue for quantitative AdS/CFT\ncomparisons.\n", "machine_text": "\nWe provide an estimate of the four-point amplitude in maximally supersymmetric Yang-Mills theory at five loops, making use of the correspondence between integrals of simple conformal properties and the four-point amplitudes from the theory at four loops. Detailed steps to identify the mentioned integrals have been outlined. We employ both four- and D-dimensional generalized unitarity to figure out the coefficients of each integral in the amplitude. Maximal cuts have been utilized effectively to accurately determine the coefficients. This set of integrals and coefficients will help to calculate the cusp anomalous dimension at five-loops, and shall be instrumental in verifying the validity of the AdS/CFT duality conjecture. Moreover, it will support a conjecture that the amplitudes possess an iterative structure which will contribute to the all-loop resummation and facilitate the comparison between the string-side computation by Alday and Maldacena and the amplitudes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1864}
{"prompt": "Rephrase the abstract of an article with title 'Spin relaxation due to the Bir-Aronov-Pikus mechanism in intrinsic and\n  $p$-type GaAs quantum wells from a fully microscopic approach'.\n  We study the electron spin relaxation in intrinsic and $p$-type (001) GaAs\nquantum wells by constructing and numerically solving the kinetic spin Bloch\nequations. All the relevant scatterings are explicitly included, especially the\nspin-flip electron-heavy hole exchange scattering which leads to the\nBir-Aronov-Pikus spin relaxation. We show that, due to the neglection of the\nnonlinear terms in the electron-heavy hole exchange scattering in the\nFermi-golden-rule approach, the spin relaxation due to the Bir-Aronov-Pikus\nmechanism is greatly exaggerated at moderately high electron density and low\ntemperature in the literature. We compare the spin relaxation time due to the\nBir-Aronov-Pikus mechanism with that due to the D'yakonov-Perel' mechanism\nwhich is also calculated from the kinetic spin Bloch equations with all the\nscatterings, especially the spin-conserving electron-electron and\nelectron-heavy hole scatterings, included. We find that, in intrinsic quantum\nwells, the effect from the Bir-Aronov-Pikus mechanism is much smaller than that\nfrom the D'yakonov-Perel' mechanism at low temperature, and it is smaller by no\nmore than one order of magnitude at high temperature. In $p$-type quantum\nwells, the spin relaxation due to the Bir-Aronov-Pikus mechanism is also much\nsmaller than the one due to the D'yakonov-Perel' mechanism at low temperature\nand becomes comparable to each other at higher temperature when the hole\ndensity and the width of the quantum well are large enough. We claim that\nunlike in the bulk samples, the Bir-Aronov-Pikus mechanism hardly dominates the\nspin relaxation in two-dimensional samples.\n\n", "human_text": "  We study the electron spin relaxation in intrinsic and $p$-type (001) GaAs\nquantum wells by constructing and numerically solving the kinetic spin Bloch\nequations. All the relevant scatterings are explicitly included, especially the\nspin-flip electron-heavy hole exchange scattering which leads to the\nBir-Aronov-Pikus spin relaxation. We show that, due to the neglection of the\nnonlinear terms in the electron-heavy hole exchange scattering in the\nFermi-golden-rule approach, the spin relaxation due to the Bir-Aronov-Pikus\nmechanism is greatly exaggerated at moderately high electron density and low\ntemperature in the literature. We compare the spin relaxation time due to the\nBir-Aronov-Pikus mechanism with that due to the D'yakonov-Perel' mechanism\nwhich is also calculated from the kinetic spin Bloch equations with all the\nscatterings, especially the spin-conserving electron-electron and\nelectron-heavy hole scatterings, included. We find that, in intrinsic quantum\nwells, the effect from the Bir-Aronov-Pikus mechanism is much smaller than that\nfrom the D'yakonov-Perel' mechanism at low temperature, and it is smaller by no\nmore than one order of magnitude at high temperature. In $p$-type quantum\nwells, the spin relaxation due to the Bir-Aronov-Pikus mechanism is also much\nsmaller than the one due to the D'yakonov-Perel' mechanism at low temperature\nand becomes comparable to each other at higher temperature when the hole\ndensity and the width of the quantum well are large enough. We claim that\nunlike in the bulk samples, the Bir-Aronov-Pikus mechanism hardly dominates the\nspin relaxation in two-dimensional samples.\n", "machine_text": "We investigate the spin relaxation of electrons in (001) GaAs quantum wells, both intrinsic and $p$-type,\nby numerically solving the kinetic spin Bloch equations with all the relevant scatterings accounted for.\nIn particular, the electron-heavy hole exchange scattering, which leads to the Bir-Aronov-Pikus\nspin relaxation, is explicitly included. Our calculations indicate that, if we limit our analyses to the\nFermi-golden-rule approach and neglect the nonlinear terms, the spin relaxation due to the Bir-Aronov-Pikus mechanism\nwill be greatly overestimated at moderate electron density and low temperature.\nWe also study the spin relaxation time due to the D'yakonov-Perel' mechanism and compare it with\nthe one arising from the Bir-Aronov-Pikus mechanism. Our results demonstrate that in intrinsic quantum wells,\nthe effect of the Bir-Aronov-Pikus mechanism is much smaller than that of the D'yakonov-Perel' mechanism\nat low temperature and is no more than one order of magnitude higher at high temperature.\nIn $p$-type quantum wells, the spin relaxation due to Bir-Aronov-Pikus mechanism is much lower than\nthat of the D'yakonov-Perel' mechanism at low temperature, but can become comparable when\nthe hole density and quantum well width are big enough. Thus, contrary to the situation in bulk samples,\nthe Bir-Aronov-Pikus mechanism is not expected to generally dominate the spin relaxation of two-dimensional systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0216}
{"prompt": "Rephrase the abstract of an article with title 'Bond formation and slow heterogeneous dynamics in adhesive spheres with\n  long--ranged repulsion: Quantitative test of Mode Coupling Theory'.\n  A colloidal system of spheres interacting with both a deep and narrow\nattractive potential and a shallow long-ranged barrier exhibits a prepeak in\nthe static structure factor. This peak can be related to an additional\nmesoscopic length scale of clusters and/or voids in the system. Simulation\nstudies of this system have revealed that it vitrifies upon increasing the\nattraction into a gel-like solid at intermediate densities. The dynamics at the\nmesoscopic length scale corresponding to the prepeak represents the slowest\nmode in the system. Using mode coupling theory with all input directly taken\nfrom simulations, we reveal the mechanism for glassy arrest in the system at\n40% packing fraction. The effects of the low-q peak and of polydispersity are\nconsidered in detail. We demonstrate that the local formation of physical bonds\nis the process whose slowing down causes arrest.\n  It remains largely unaffected by the large-scale heterogeneities, and sets\nthe clock for the slow cluster mode. Results from mode-coupling theory without\nadjustable parameters agree semi-quantitatively with the local density\ncorrelators but overestimate the lifetime of the mesoscopic structure (voids).\n\n", "human_text": "  A colloidal system of spheres interacting with both a deep and narrow\nattractive potential and a shallow long-ranged barrier exhibits a prepeak in\nthe static structure factor. This peak can be related to an additional\nmesoscopic length scale of clusters and/or voids in the system. Simulation\nstudies of this system have revealed that it vitrifies upon increasing the\nattraction into a gel-like solid at intermediate densities. The dynamics at the\nmesoscopic length scale corresponding to the prepeak represents the slowest\nmode in the system. Using mode coupling theory with all input directly taken\nfrom simulations, we reveal the mechanism for glassy arrest in the system at\n40% packing fraction. The effects of the low-q peak and of polydispersity are\nconsidered in detail. We demonstrate that the local formation of physical bonds\nis the process whose slowing down causes arrest.\n  It remains largely unaffected by the large-scale heterogeneities, and sets\nthe clock for the slow cluster mode. Results from mode-coupling theory without\nadjustable parameters agree semi-quantitatively with the local density\ncorrelators but overestimate the lifetime of the mesoscopic structure (voids).\n", "machine_text": "\nSimulation studies of a colloidal system of spheres interacting with a deep and narrow attractive potential and a shallow long-ranged barrier have uncovered a prepeak in the static structure factor, suggesting the presence of a mesoscopic length scale of clusters and/or voids. Our analysis using mode coupling theory, without adjustable parameters and taking all input directly from simulations, reveals the mechanism of glassy arrest at 40% packing fraction of the system. We found that the local formation of physical bonds determines the slowing down that causes arrest, suggesting an important role of the low-q peak in the glassy transition. Furthermore, our results demonstrate that the lifetime of the mesoscopic structure (voids) is overestimated by mode-coupling theory, remaining largely unaffected by large-scale heterogeneities and setting the clock for the slow cluster mode.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0637}
{"prompt": "Rephrase the abstract of an article with title 'Opposite magnetic polarity of two photospheric lines in single spectrum\n  of the quiet Sun'.\n  We study the structure of the photospheric magnetic field of the quiet Sun by\ninvestigating weak spectro-polarimetric signals. We took a sequence of Stokes\nspectra of the Fe I 630.15 nm and 630.25 nm lines in a region of quiet Sun near\nthe disk center, using the POLIS spectro-polarimeter at the German VTT on\nTenerife. The line cores of these two lines form at different heights in the\natmosphere. The 3$\\sigma$ noise level of the data is about 1.8 $\\times 10^{-3}\nI_{c}$. We present co-temporal and co-spatial Stokes-$V$ profiles of the Fe I\n630 nm line pair, where the two lines show opposite polarities in a single\nspectrum. We compute synthetic line profiles and reproduce these spectra with a\ntwo-component model atmosphere: a non-magnetic component and a magnetic\ncomponent. The magnetic component consists of two magnetic layers with opposite\npolarity: the upper one moves upwards while the lower one moves downward.\nIn-between, there is a region of enhanced temperature. The Stokes-$V$ line pair\nof opposite polarity in a single spectrum can be understood as a magnetic\nreconnection event in the solar photosphere. We demonstrate that such a\nscenario is realistic, but the solution may not be unique.\n\n", "human_text": "  We study the structure of the photospheric magnetic field of the quiet Sun by\ninvestigating weak spectro-polarimetric signals. We took a sequence of Stokes\nspectra of the Fe I 630.15 nm and 630.25 nm lines in a region of quiet Sun near\nthe disk center, using the POLIS spectro-polarimeter at the German VTT on\nTenerife. The line cores of these two lines form at different heights in the\natmosphere. The 3$\\sigma$ noise level of the data is about 1.8 $\\times 10^{-3}\nI_{c}$. We present co-temporal and co-spatial Stokes-$V$ profiles of the Fe I\n630 nm line pair, where the two lines show opposite polarities in a single\nspectrum. We compute synthetic line profiles and reproduce these spectra with a\ntwo-component model atmosphere: a non-magnetic component and a magnetic\ncomponent. The magnetic component consists of two magnetic layers with opposite\npolarity: the upper one moves upwards while the lower one moves downward.\nIn-between, there is a region of enhanced temperature. The Stokes-$V$ line pair\nof opposite polarity in a single spectrum can be understood as a magnetic\nreconnection event in the solar photosphere. We demonstrate that such a\nscenario is realistic, but the solution may not be unique.\n", "machine_text": "\nIn this study, we used the POLIS spectro-polarimeter located at the German VTT on Tenerife to analyze the structure of the photospheric magnetic field of a quiet Sun region near the disk center. Through Stokes spectra of the Fe I 630.15 nm and 630.25 nm lines with a 3$\\sigma$ noise level of approximately 1.8 $\\times 10^{-3} I_{c}$, it was observed that the two lines in the same spectrum had opposite polarities. This was theorized to be the result of a magnetic reconnection event occurring in the photosphere, which we confirmed through inference of a two-component model atmosphere containing a non-magnetic component, and a magnetic one containing both a lower and higher magnetic field with opposite polarities surrounded by a region of higher temperature. Although this solution is likely, it may not be the only one.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3135}
{"prompt": "Rephrase the abstract of an article with title 'Phenomenology of the nMSSM from colliders to cosmology'.\n  Low energy supersymmetric models provide a solution to the hierarchy problem\nand also have the necessary ingredients to solve two of the most outstanding\nissues in cosmology: the origin of dark matter and baryonic matter. One of the\nmost attractive features of this framework is that the relevant physical\nprocesses are related to interactions at the weak scale and therefore may be\ntested in collider experiments in the near future. This is true for the Minimal\nSupersymmetric Standard Model (MSSM) as well as for its extension with the\naddition of one singlet chiral superfield, the so-called nMSSM. It has been\nrecently shown that within the nMSSM an elegant solution to both the problem of\nbaryogenesis and dark matter may be found, that relies mostly on the mixing of\nthe singlet sector with the Higgs sector of the theory. In this work we review\nthe nMSSM model constraints from cosmology and present the associated collider\nphenomenology at the LHC and the ILC. We show that the ILC will efficiently\nprobe the neutralino, chargino and Higgs sectors, allowing to confront\ncosmological observations with computations based on collider measurements. We\nalso investigate the prospects for a direct detection of dark matter and the\nconstraints imposed by the current bounds of the electron electric dipole\nmoment in this model.\n\n", "human_text": "  Low energy supersymmetric models provide a solution to the hierarchy problem\nand also have the necessary ingredients to solve two of the most outstanding\nissues in cosmology: the origin of dark matter and baryonic matter. One of the\nmost attractive features of this framework is that the relevant physical\nprocesses are related to interactions at the weak scale and therefore may be\ntested in collider experiments in the near future. This is true for the Minimal\nSupersymmetric Standard Model (MSSM) as well as for its extension with the\naddition of one singlet chiral superfield, the so-called nMSSM. It has been\nrecently shown that within the nMSSM an elegant solution to both the problem of\nbaryogenesis and dark matter may be found, that relies mostly on the mixing of\nthe singlet sector with the Higgs sector of the theory. In this work we review\nthe nMSSM model constraints from cosmology and present the associated collider\nphenomenology at the LHC and the ILC. We show that the ILC will efficiently\nprobe the neutralino, chargino and Higgs sectors, allowing to confront\ncosmological observations with computations based on collider measurements. We\nalso investigate the prospects for a direct detection of dark matter and the\nconstraints imposed by the current bounds of the electron electric dipole\nmoment in this model.\n", "machine_text": "The physical properties of low energy supersymmetric models provide potential resolutions to both the hierarchy problem and outstanding issues in cosmology, including dark matter and baryonic matter. These theories are testable in near-future collider experiments, such as the Large Hadron Collider (LHC) and International Linear Collider (ILC), due to the weak-scale interaction parameters. Recently, the Minimal Supersymmetric Standard Model (MSSM) was extended with a singlet chiral superfield, ultimately producing a so-called nMSSM, which presents a viable answer to both baryogenesis and dark matter. This paper reflects on the implications of the nMSSM from cosmology and how it is represented in the LHC and ILC. We discuss how the ILC can verify the neutralino, chargino, and Higgs sectors in the theory, compare them with cosmological hypotheses, and examine prospects for detecting dark matter with further experiments. Also included is an assessment of the current understanding of the electron electric dipole moment when applied to the nMSSM.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0431}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological Symmetry Breaking, Pseudo-scale invariance, Dark Energy and\n  the Standard Model'.\n  The energy density of the universe today may be dominated by the vacuum\nenergy of a slowly rolling scalar field. Making a quantum expansion around such\na time dependent solution is found to break fundamental symmetries of quantum\nfield theory. We call this mechanism cosmological symmetry breaking and argue\nthat it is different from the standard phenomenon of spontaneous symmetry\nbreaking. We illustrate this with a toy scalar field theory, whose action\ndisplays a U(1) symmetry. We identify a symmetry, called pseudo-scale\ninvariance, which sets the cosmological constant exactly equal to zero, both in\nclassical and quantum theory. This symmetry is also broken cosmologically and\nleads to a nonzero vacuum or dark energy. The slow roll condition along with\nthe observed value of dark energy leads to a value of the background scalar\nfield of the order of Planck mass. We also consider a U(1) gauge symmetry\nmodel. Cosmological symmetry breaking, in this case, leads to a non zero mass\nfor the vector field. We also show that a cosmologically broken pseudo-scale\ninvariance can generate a wide range of masses.\n\n", "human_text": "  The energy density of the universe today may be dominated by the vacuum\nenergy of a slowly rolling scalar field. Making a quantum expansion around such\na time dependent solution is found to break fundamental symmetries of quantum\nfield theory. We call this mechanism cosmological symmetry breaking and argue\nthat it is different from the standard phenomenon of spontaneous symmetry\nbreaking. We illustrate this with a toy scalar field theory, whose action\ndisplays a U(1) symmetry. We identify a symmetry, called pseudo-scale\ninvariance, which sets the cosmological constant exactly equal to zero, both in\nclassical and quantum theory. This symmetry is also broken cosmologically and\nleads to a nonzero vacuum or dark energy. The slow roll condition along with\nthe observed value of dark energy leads to a value of the background scalar\nfield of the order of Planck mass. We also consider a U(1) gauge symmetry\nmodel. Cosmological symmetry breaking, in this case, leads to a non zero mass\nfor the vector field. We also show that a cosmologically broken pseudo-scale\ninvariance can generate a wide range of masses.\n", "machine_text": "The cosmological energy density of the present day universe is likely to be dominated by a slowly rolling scalar field, which leads to a breaking of quantum field theory symmetries. We demonstrate this process as 'cosmological symmetry breaking', distinct from the usual spontaneous symmetry breaking. To illustrate our discussion, we consider a scalar field theory with a U(1) symmetry. We identify a 'pseudo-scale invariance' symmetry, which when broken cosmologically, produces a non-zero vacuum or dark energy. Further applying the slow roll condition, we obtain a value of the background field of the order of Planck mass. We also explore a U(1) gauge symmetry model and demonstrate how cosmological symmetry breaking results in a non-zero mass for the vector field. We illustrate how a broken pseudo-scale invariance can generate a wide range of masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2273}
{"prompt": "Rephrase the abstract of an article with title 'Gravitational Wave Signals from Chaotic System: A Point Mass with A Disk'.\n  We study gravitational waves from a particle moving around a system of a\npoint mass with a disk in Newtonian gravitational theory. A particle motion in\nthis system can be chaotic when the gravitational contribution from a surface\ndensity of a disk is comparable with that from a point mass. In such an orbit,\nwe sometimes find that there appears a phase of the orbit in which particle\nmotion becomes to be nearly regular (the so-called ``stagnant motion'') for a\nfinite time interval between more strongly chaotic phases. To study how these\ndifferent chaotic behaviours affect on observation of gravitational waves, we\ninvestigate a correlation of the particle motion and the waves. We find that\nsuch a difference in chaotic motions reflects on the wave forms and energy\nspectra. The character of the waves in the stagnant motion is quite different\nfrom that either in a regular motion or in a more strongly chaotic motion. This\nsuggests that we may make a distinction between different chaotic behaviours of\nthe orbit via the gravitational waves.\n\n", "human_text": "  We study gravitational waves from a particle moving around a system of a\npoint mass with a disk in Newtonian gravitational theory. A particle motion in\nthis system can be chaotic when the gravitational contribution from a surface\ndensity of a disk is comparable with that from a point mass. In such an orbit,\nwe sometimes find that there appears a phase of the orbit in which particle\nmotion becomes to be nearly regular (the so-called ``stagnant motion'') for a\nfinite time interval between more strongly chaotic phases. To study how these\ndifferent chaotic behaviours affect on observation of gravitational waves, we\ninvestigate a correlation of the particle motion and the waves. We find that\nsuch a difference in chaotic motions reflects on the wave forms and energy\nspectra. The character of the waves in the stagnant motion is quite different\nfrom that either in a regular motion or in a more strongly chaotic motion. This\nsuggests that we may make a distinction between different chaotic behaviours of\nthe orbit via the gravitational waves.\n", "machine_text": "\nIn this paper, we study gravitational wave signals originating from a point mass interacting with a disk in a Newtonian gravitational system. The motion of a particle in such a system is likely to be chaotic when the gravitational force of the disk is close to that of the point mass. We observe that in some orbits, the particle motion becomes nearly regular (labelled as 'stagnant motion') for a certain amount of time between each chaotic period. To study the influence chaotic behaviours have on the observation of gravitational waves, we aim to analyse the correlation between the waves and the behaviour of the particle. Our results indicate that each chaotic behaviour involved in the waveforms and energy spectra can be distinguishable. The waveforms generated from the stagnant motion are notably different from that from the more chaotic or regular motion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0719}
{"prompt": "Rephrase the abstract of an article with title 'A Systematic Study of Departures from Chemical Equilibrium in the\n  Atmospheres of Substellar Mass Objects'.\n  We present a systematic study of the spectral consequences of departures from\nchemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler\ndwarfs. The temperature/pressure profiles of the non-equilibrium models are\nfully consistent with the non-equilibrium chemistry. Our grid of\nnon-equilibrium models includes spectra for effective temperatures from 200 K\nto 1800 K, three surface gravities, four possible values of the coefficient of\neddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical\nreaction prescriptions. We find that the non-equilibrium overabundance of CO\ntranslates into flux suppressions in the M ($\\sim4-$5 $\\mu$m) band of at most\n$\\sim$40% between effective temperatures of 600 and 1800 K. The effect is\nlargest around $T_{\\rm eff} \\approx 1100$ K. The underabundance of ammonia due\nto non-equilibrium chemistry translates into flux enhancements of no more than\n$\\sim$20% for the $T_{\\rm eff}$ range from 300 to 1800 K, with the largest\neffects at the lowest values of $T_{\\rm eff}$. The magnitude of the departure\nfrom chemical equilibrium increases with decreasing gravity, with increasing\neddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$\nreaction. Though these effects are modest, they lead to better fits with the\nmeasured T dwarf spectra. Furthermore, the suppression in the M band due to\nnon-equilibrium enhancements in the CO abundance disappears below $\\sim$500 K,\nand is only partial above $\\sim$500 K, preserving the M band flux as a useful\ndiagnostic of cool atmospheres and maintaining its importance for searches for\nbrown dwarfs cooler than T dwarfs.\n\n", "human_text": "  We present a systematic study of the spectral consequences of departures from\nchemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler\ndwarfs. The temperature/pressure profiles of the non-equilibrium models are\nfully consistent with the non-equilibrium chemistry. Our grid of\nnon-equilibrium models includes spectra for effective temperatures from 200 K\nto 1800 K, three surface gravities, four possible values of the coefficient of\neddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical\nreaction prescriptions. We find that the non-equilibrium overabundance of CO\ntranslates into flux suppressions in the M ($\\sim4-$5 $\\mu$m) band of at most\n$\\sim$40% between effective temperatures of 600 and 1800 K. The effect is\nlargest around $T_{\\rm eff} \\approx 1100$ K. The underabundance of ammonia due\nto non-equilibrium chemistry translates into flux enhancements of no more than\n$\\sim$20% for the $T_{\\rm eff}$ range from 300 to 1800 K, with the largest\neffects at the lowest values of $T_{\\rm eff}$. The magnitude of the departure\nfrom chemical equilibrium increases with decreasing gravity, with increasing\neddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$\nreaction. Though these effects are modest, they lead to better fits with the\nmeasured T dwarf spectra. Furthermore, the suppression in the M band due to\nnon-equilibrium enhancements in the CO abundance disappears below $\\sim$500 K,\nand is only partial above $\\sim$500 K, preserving the M band flux as a useful\ndiagnostic of cool atmospheres and maintaining its importance for searches for\nbrown dwarfs cooler than T dwarfs.\n", "machine_text": "\nThis article examines the spectral shifts due to a departure from chemical equilibrium in the atmospheres of L and T dwarfs, and even cooler temperatures. A grid of non-equilibrium models was created for effective temperatures ranging from 200 K to 1800 K, with three different surface gravities, four values of the coefficient of eddy diffusion, and three prescriptions for the CO/CH$_4$ chemical reaction. We discovered that the overabundance of CO results in a 40% reduction of flux in the M ($\\sim4-$5 $\\mu$m) band between effective temperatures of 600 and 1800 K, with the most significant effect at $T_{\\rm eff} \\approx 1100$ K. When looking at the underabundance of ammonia, this yields a maximum of 20% increase in flux across the range of 300 to 1800 K, with the greatest effects at the lowest values of $T_{\\rm eff}$. The magnitude of departure from chemical equilibrium increases in relation to decreased gravity, increased eddy diffusion coefficient, and slower speed of the CO/CH$_4$ reaction. Though small, these effects create better fitted spectra to T dwarf measurements. Additionally, it was determined that the suppression in the M band resulting from non-equilibrium CO enhancements vanishes below 500 K and is only partial above 500 K, keeping the M band valuable for discovering brown dwarfs cooler than T dwarfs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3922}
{"prompt": "Rephrase the abstract of an article with title 'Dynamic response of Ag monolayers adsorbed on Au(100) upon an\n  oscillatory variation of the chemical potential: A Monte Carlo simulation\n  study'.\n  Based on the fact that the underpotential electrochemical deposition of Ag\natoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at\nwell-defined values of the (coexistence) chemical potential ($\\mu_{coex}$), we\nperformed extensive simulations aimed at investigating the hysteretic dynamic\nbehavior of the system close to coexistence upon the application of a periodic\nsignal of the form $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau) $, where\n$\\mu_{o}$ and $\\tau$ are the amplitude and the period of the sweep,\nrespectively. For relatively short periods and small enough amplitudes the\nsystem becomes trapped either at low or high Ag coverage states, as evidenced\nby recording hysteresis loops. This scenario is identified as dynamically\nordered states (DOS), such that the relaxation time $(\\tau_{relax})$ of the\ncorresponding metastable state obeys $\\tau_{relax} > \\tau $. On the other hand,\nby properly increasing $\\mu_{o}$ or/and $\\tau$, one finds that the $Ag$\ncoverage gently follows the external drive (here $\\tau_{relax} < \\tau $) and\nthe system is said to enter into dynamically disordered states (DDS), where\nhysteresis loops show almost symmetric limiting cycles. This symmetry breaking\nbetween limiting cycles driven by an external signal is discussed in terms of\nthe concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and\nDDS, similar to those encountered when a magnetic system is placed in the\npresence of a variable external magnetic field. However, a careful finite-size\nscaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system\ndoes not exhibit true second-order phase transitions but rather a crossover\nbehavior between states. A diagram showing the location of the ordered and\ndisordered states in the $\\mu$ versus $\\tau$ plane is obtained and discussed.\n\n", "human_text": "  Based on the fact that the underpotential electrochemical deposition of Ag\natoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at\nwell-defined values of the (coexistence) chemical potential ($\\mu_{coex}$), we\nperformed extensive simulations aimed at investigating the hysteretic dynamic\nbehavior of the system close to coexistence upon the application of a periodic\nsignal of the form $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau) $, where\n$\\mu_{o}$ and $\\tau$ are the amplitude and the period of the sweep,\nrespectively. For relatively short periods and small enough amplitudes the\nsystem becomes trapped either at low or high Ag coverage states, as evidenced\nby recording hysteresis loops. This scenario is identified as dynamically\nordered states (DOS), such that the relaxation time $(\\tau_{relax})$ of the\ncorresponding metastable state obeys $\\tau_{relax} > \\tau $. On the other hand,\nby properly increasing $\\mu_{o}$ or/and $\\tau$, one finds that the $Ag$\ncoverage gently follows the external drive (here $\\tau_{relax} < \\tau $) and\nthe system is said to enter into dynamically disordered states (DDS), where\nhysteresis loops show almost symmetric limiting cycles. This symmetry breaking\nbetween limiting cycles driven by an external signal is discussed in terms of\nthe concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and\nDDS, similar to those encountered when a magnetic system is placed in the\npresence of a variable external magnetic field. However, a careful finite-size\nscaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system\ndoes not exhibit true second-order phase transitions but rather a crossover\nbehavior between states. A diagram showing the location of the ordered and\ndisordered states in the $\\mu$ versus $\\tau$ plane is obtained and discussed.\n", "machine_text": "\n\nThis study investigated the response of an Ag monolayer on $Au(100)$ to a periodic variation of the chemical potential, $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau)$, with $\\mu_{o}$ and $\\tau$ corresponding to the amplitude and period of the signal sweep, respectively. Using Monte Carlo simulations, the authors discovered that with relatively short $\\tau$ values and low enough $\\mu_{o}$ amplitudes, the system demonstrated a hysteretic behavior that was identified as Dynamically Ordered States (DOS), where the relaxation time of the corresponding metastable state was found to be $\\tau_{relax} > \\tau$. With increasing values of either $\\mu_{o}$ or $\\tau$, however, the Ag coverage gently follows the oscillatory signal which then designates the system to enter the Dynamically Disordered States (DDS) - displaying almost symmetrical limiting cycles. This breaking of symmetry between cycles mediated by the external signal allows us to discuss Dynamic Phase Transitions, analogous to those encountered in magnetic systems placed under changing external magnetic fields. A finite-size scaling analysis revealed the existence of a crossover behavior between DOS and DDS at $T = 300 K$, and the authors produced a diagram showing the location of the two kinds of states in the $(\\mu, \\tau)$ plane.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.447}
{"prompt": "Rephrase the abstract of an article with title 'A remark on the number of steady states in a multiple futile cycle'.\n  The multisite phosphorylation-dephosphorylation cycle is a motif repeatedly\nused in cell signaling. This motif itself can generate a variety of dynamic\nbehaviors like bistability and ultrasensitivity without direct positive\nfeedbacks. In this paper, we study the number of positive steady states of a\ngeneral multisite phosphorylation-dephosphorylation cycle, and how the number\nof positive steady states varies by changing the biological parameters. We show\nanalytically that (1) for some parameter ranges, there are at least n+1 (if n\nis even) or n (if n is odd) steady states; (2) there never are more than 2n-1\nsteady states (in particular, this implies that for n=2, including single\nlevels of MAPK cascades, there are at most three steady states); (3) for\nparameters near the standard Michaelis-Menten quasi-steady state conditions,\nthere are at most n+1 steady states; and (4) for parameters far from the\nstandard Michaelis-Menten quasi-steady state conditions, there is at most one\nsteady state.\n\n", "human_text": "  The multisite phosphorylation-dephosphorylation cycle is a motif repeatedly\nused in cell signaling. This motif itself can generate a variety of dynamic\nbehaviors like bistability and ultrasensitivity without direct positive\nfeedbacks. In this paper, we study the number of positive steady states of a\ngeneral multisite phosphorylation-dephosphorylation cycle, and how the number\nof positive steady states varies by changing the biological parameters. We show\nanalytically that (1) for some parameter ranges, there are at least n+1 (if n\nis even) or n (if n is odd) steady states; (2) there never are more than 2n-1\nsteady states (in particular, this implies that for n=2, including single\nlevels of MAPK cascades, there are at most three steady states); (3) for\nparameters near the standard Michaelis-Menten quasi-steady state conditions,\nthere are at most n+1 steady states; and (4) for parameters far from the\nstandard Michaelis-Menten quasi-steady state conditions, there is at most one\nsteady state.\n", "machine_text": "This paper analyses the number of steady states present in a general multisite phosphorylation-dephosphorylation cycle, while also exploring how the number of steady states may change under different biological parameters. We show that the number of steady states range from n+1 (if n is even) or n (if n is odd) to a maximum of 2n-1. It is also demonstrated that parameters near the standard Michaelis-Menten quasi-steady state conditions result in a maximum of n+1 steady states, while parameters far from the typical conditions lead to one steady state at most.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0036}
{"prompt": "Rephrase the abstract of an article with title 'High-precision astrometry on the VLT/FORS1 at time scales of few days'.\n  We investigate the accuracy of astrometric measurements with the VLT/FORS1\ncamera and consider potential applications. The study is based on two-epoch\n(2000 and 2002/2003) frame series of observations of a selected Galactic Bulge\nsky region that were obtained with FORS1 during four consecutive nights each.\nReductions were carried out with a novel technique that eliminates atmospheric\nimage motion and does not require a distinction between targets and reference\nobjects. The positional astrometric precision was found to be limited only by\nthe accuracy of the determination of the star photocentre, which is typically\n200-300 microarcsec per single measurement for bright unsaturated stars\nB=18-19. Several statistical tests have shown that at time-scales of 1-4 nights\nthe residual noise in measured positions is essentially a white noise with no\nsystematic instrumental signature and no significant deviation from a Gaussian\ndistribution. Some evidence of a good astrometric quality of the VLT for frames\nseparated by two years has also been found. Our data show that the VLT with\nFORS1/2 cameras can be effectively used for astrometric observations of\nplanetary microlensing events and other applications where a high accuracy is\nrequired, that is expected to reach 30-40 microarcsec for a series of 50 frames\n(one hours with R filter).\n\n", "human_text": "  We investigate the accuracy of astrometric measurements with the VLT/FORS1\ncamera and consider potential applications. The study is based on two-epoch\n(2000 and 2002/2003) frame series of observations of a selected Galactic Bulge\nsky region that were obtained with FORS1 during four consecutive nights each.\nReductions were carried out with a novel technique that eliminates atmospheric\nimage motion and does not require a distinction between targets and reference\nobjects. The positional astrometric precision was found to be limited only by\nthe accuracy of the determination of the star photocentre, which is typically\n200-300 microarcsec per single measurement for bright unsaturated stars\nB=18-19. Several statistical tests have shown that at time-scales of 1-4 nights\nthe residual noise in measured positions is essentially a white noise with no\nsystematic instrumental signature and no significant deviation from a Gaussian\ndistribution. Some evidence of a good astrometric quality of the VLT for frames\nseparated by two years has also been found. Our data show that the VLT with\nFORS1/2 cameras can be effectively used for astrometric observations of\nplanetary microlensing events and other applications where a high accuracy is\nrequired, that is expected to reach 30-40 microarcsec for a series of 50 frames\n(one hours with R filter).\n", "machine_text": "\nBy conducting a two-epoch observational study of a Galactic Bulge sky region, we analyze the precision of astrometric measurements by FORS1 on the VLT. To make sure the readings are not impacted by atmospheric image motion, we make use of a special technique and utilize bright, unsaturated stars of magnitude between 18 to 19. Statistical testing reveals that the positional astrometric precision is mainly restricted by the ability to determine star photocenters. We find the residual noise of measured positions is essentially a white noise that follows a Gaussian distribution. After analyzing the data for time-scales of 1-4 nights, we also conclude that there is evidence of a good astrometric quality of the VLT that can reach up to 30-50 microarcsec for 50 frames with a R filter over one hour.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3883}
{"prompt": "Rephrase the abstract of an article with title 'The Mass Assembly History of Spheroidal Galaxies: Did Newly-Formed\n  Systems Arise Via Major Mergers?'.\n  We examine the properties of a morphologically-selected sample of 0.4<z<1.0\nspheroidal galaxies in the GOODS fields in order to ascertain whether their\nincrease in abundance with time arises primarily from mergers. To address this\nquestion we determine scaling relations between the dynamical mass determined\nfrom stellar velocity dispersions, and the stellar mass determined from optical\nand infrared photometry. We exploit these relations across the larger sample\nfor which we have stellar masses in order to construct the first statistically\nrobust estimate of the evolving dynamical mass function over 0<z<1. The trends\nobserved match those seen in the stellar mass functions of Bundy et al. 2005\nregarding the top-down growth in the abundance of spheroidal galaxies. By\nreferencing our dynamical masses to the halo virial mass we compare the growth\nrate in the abundance of spheroidals to that predicted by the assembly of dark\nmatter halos. Our comparisons demonstrate that major mergers do not fully\naccount for the appearance of new spheroidals since z~1 and that additional\nmechanisms, such as morphological transformations, are required to drive the\nobserved evolution.\n\n", "human_text": "  We examine the properties of a morphologically-selected sample of 0.4<z<1.0\nspheroidal galaxies in the GOODS fields in order to ascertain whether their\nincrease in abundance with time arises primarily from mergers. To address this\nquestion we determine scaling relations between the dynamical mass determined\nfrom stellar velocity dispersions, and the stellar mass determined from optical\nand infrared photometry. We exploit these relations across the larger sample\nfor which we have stellar masses in order to construct the first statistically\nrobust estimate of the evolving dynamical mass function over 0<z<1. The trends\nobserved match those seen in the stellar mass functions of Bundy et al. 2005\nregarding the top-down growth in the abundance of spheroidal galaxies. By\nreferencing our dynamical masses to the halo virial mass we compare the growth\nrate in the abundance of spheroidals to that predicted by the assembly of dark\nmatter halos. Our comparisons demonstrate that major mergers do not fully\naccount for the appearance of new spheroidals since z~1 and that additional\nmechanisms, such as morphological transformations, are required to drive the\nobserved evolution.\n", "machine_text": "\nWe investigate the development of spheroidal galaxies in the range of 0<z<1 by examining a group of morphologically-selected 0.4<z<1.0 galaxies found in the GOODS fields. We use the stellar velocity dispersions to discern the dynamical masses of these galaxies and compare them to the stellar masses determined through optical and IR photometry. Our work creates a statistically-robust calculation of the earlier-mentioned evolving dynamical mass function. Results of our analysis reach the same conclusions as those from Bundy et al. in 2005, that spheroidal galaxies have grown in abundance from top-down. Looking at the ratio of spheroidal growth to that of dark matter halos, we have found that major mergers are not enough to explain the appearance of these galaxies in z~1. Consequently, we propose that other mechanisms, such as morphological changes, are accountable for this evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1007}
{"prompt": "Rephrase the abstract of an article with title 'On bounds and algorithms for frequency synchronization for collaborative\n  communication systems'.\n  Cooperative diversity systems are wireless communication systems designed to\nexploit cooperation among users to mitigate the effects of multipath fading. In\nfairly general conditions, it has been shown that these systems can achieve the\ndiversity order of an equivalent MISO channel and, if the node geometry\npermits, virtually the same outage probability can be achieved as that of the\nequivalent MISO channel for a wide range of applicable SNR. However, much of\nthe prior analysis has been performed under the assumption of perfect timing\nand frequency offset synchronization. In this paper, we derive the estimation\nbounds and associated maximum likelihood estimators for frequency offset\nestimation in a cooperative communication system. We show the benefit of\nadaptively tuning the frequency of the relay node in order to reduce estimation\nerror at the destination. We also derive an efficient estimation algorithm,\nbased on the correlation sequence of the data, which has mean squared error\nclose to the Cramer-Rao Bound.\n\n", "human_text": "  Cooperative diversity systems are wireless communication systems designed to\nexploit cooperation among users to mitigate the effects of multipath fading. In\nfairly general conditions, it has been shown that these systems can achieve the\ndiversity order of an equivalent MISO channel and, if the node geometry\npermits, virtually the same outage probability can be achieved as that of the\nequivalent MISO channel for a wide range of applicable SNR. However, much of\nthe prior analysis has been performed under the assumption of perfect timing\nand frequency offset synchronization. In this paper, we derive the estimation\nbounds and associated maximum likelihood estimators for frequency offset\nestimation in a cooperative communication system. We show the benefit of\nadaptively tuning the frequency of the relay node in order to reduce estimation\nerror at the destination. We also derive an efficient estimation algorithm,\nbased on the correlation sequence of the data, which has mean squared error\nclose to the Cramer-Rao Bound.\n", "machine_text": "This article focuses on the issue of frequency synchronization for communication systems based on collaboration. We investigate the theoretical bounds and estimators of frequency offset in such systems and propose a tuning methodology to reduce the error at the receiver. Additionally, a maximum likelihood estimation algorithm based on the correlation sequence of the data is presented and its accuracy is shown to meet the Cramer-Rao bound.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3054}
{"prompt": "Rephrase the abstract of an article with title 'Nonequilibrium Steady States of Matrix Product Form: A Solver's Guide'.\n  We consider the general problem of determining the steady state of stochastic\nnonequilibrium systems such as those that have been used to model (among other\nthings) biological transport and traffic flow. We begin with a broad overview\nof this class of driven diffusive systems - which includes exclusion processes\n- focusing on interesting physical properties, such as shocks and phase\ntransitions. We then turn our attention specifically to those models for which\nthe exact distribution of microstates in the steady state can be expressed in a\nmatrix product form. In addition to a gentle introduction to this matrix\nproduct approach, how it works and how it relates to similar constructions that\narise in other physical contexts, we present a unified, pedagogical account of\nthe various means by which the statistical mechanical calculations of\nmacroscopic physical quantities are actually performed. We also review a number\nof more advanced topics, including nonequilibrium free energy functionals, the\nclassification of exclusion processes involving multiple particle species,\nexistence proofs of a matrix product state for a given model and more\ncomplicated variants of the matrix product state that allow various types of\nparallel dynamics to be handled. We conclude with a brief discussion of open\nproblems for future research.\n\n", "human_text": "  We consider the general problem of determining the steady state of stochastic\nnonequilibrium systems such as those that have been used to model (among other\nthings) biological transport and traffic flow. We begin with a broad overview\nof this class of driven diffusive systems - which includes exclusion processes\n- focusing on interesting physical properties, such as shocks and phase\ntransitions. We then turn our attention specifically to those models for which\nthe exact distribution of microstates in the steady state can be expressed in a\nmatrix product form. In addition to a gentle introduction to this matrix\nproduct approach, how it works and how it relates to similar constructions that\narise in other physical contexts, we present a unified, pedagogical account of\nthe various means by which the statistical mechanical calculations of\nmacroscopic physical quantities are actually performed. We also review a number\nof more advanced topics, including nonequilibrium free energy functionals, the\nclassification of exclusion processes involving multiple particle species,\nexistence proofs of a matrix product state for a given model and more\ncomplicated variants of the matrix product state that allow various types of\nparallel dynamics to be handled. We conclude with a brief discussion of open\nproblems for future research.\n", "machine_text": "This article provides an overview and guide to the calculation of nonequilibrium steady states of matrix product form. We begin by introducing this class of stochastic nonequilibrium systems, which is used to model various phenomena such as biological transport and traffic flow, and discuss their interesting physical properties such as shocks and phase transitions. We then explain the matrix product approach and how it relates to similar methods in other physical contexts, providing a unified view of the means by which the macroscopic physical quantities can be calculated. We also analyse more advanced topics like nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of the matrix product state, and parallel dynamics. Finally, we discuss open problems for future research in this field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1678}
{"prompt": "Rephrase the abstract of an article with title 'Testing Explanations of the $B\\to\\phi K^*$ Polarization Puzzle'.\n  $B\\to\\phi K^*$ ($\\btos$) is three separate decays, one for each polarization\nof the final-state vector mesons (one longitudinal, two transverse). It is\nobserved that the fraction of transverse decays, $\\fT$, and the fraction of\nlongitudinal decays, $\\fL$, are roughly equal: $\\fTfL \\simeq 1$, in opposition\nto the naive expectation that $\\fT \\ll \\fL$. If one requires a single\nexplanation of all polarization puzzles, two possibilities remain within the\nstandard model: penguin annihilation and rescattering. In this paper we examine\nthe predictions of these two explanations for $\\fTfL$ in $\\btod$ decays. In $B\n\\to \\rho\\rho$ decays, only $\\bd \\to \\rho^0\\rho^0$ can possibly exhibit a large\n$\\fTfL$. In B decays related by U-spin, we find two promising possibilities:\n(i) $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$)\nand (ii) $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$\n($\\btod$). The measurement of $\\fTfL$ in these pairs of decays will allow us to\ntest penguin annihilation and rescattering. Finally, it is possible to\ndistinguish penguin annihilation from rescattering by performing a\ntime-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$.\n\n", "human_text": "  $B\\to\\phi K^*$ ($\\btos$) is three separate decays, one for each polarization\nof the final-state vector mesons (one longitudinal, two transverse). It is\nobserved that the fraction of transverse decays, $\\fT$, and the fraction of\nlongitudinal decays, $\\fL$, are roughly equal: $\\fTfL \\simeq 1$, in opposition\nto the naive expectation that $\\fT \\ll \\fL$. If one requires a single\nexplanation of all polarization puzzles, two possibilities remain within the\nstandard model: penguin annihilation and rescattering. In this paper we examine\nthe predictions of these two explanations for $\\fTfL$ in $\\btod$ decays. In $B\n\\to \\rho\\rho$ decays, only $\\bd \\to \\rho^0\\rho^0$ can possibly exhibit a large\n$\\fTfL$. In B decays related by U-spin, we find two promising possibilities:\n(i) $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$)\nand (ii) $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$\n($\\btod$). The measurement of $\\fTfL$ in these pairs of decays will allow us to\ntest penguin annihilation and rescattering. Finally, it is possible to\ndistinguish penguin annihilation from rescattering by performing a\ntime-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$.\n", "machine_text": "\nIn this study, we explore the two potential explanations for the puzzle of the roughly equal fraction of transverse and longitudinal decays of the $B\\to \\phi K^*$ ($\\btos$) correspondences: penguin annihilation and rescattering. We analyze the expected results of each option for $\\fTfL$ in $\\btod$ decays and assess two promising U-spin related pairs of decays, $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$), and  $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$ ($\\btod$). The comparison of these pairs of decays can be used to assess the validity of penguin annihilation and rescattering as an explanation for the observed polarization puzzle. Moreover, the time-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$ decays offers a potential way to discriminate between the two options.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3915}
{"prompt": "Rephrase the abstract of an article with title 'Discovery of two candidate pulsar wind nebulae in very-high-energy gamma\n  rays'.\n  We present the discovery of two very-high-energy gamma-ray sources in an\nongoing systematic search for emission above 100 GeV from pulsar wind nebulae\nin survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov\nTelescopes are ideal tools for searching for extended emission from pulsar wind\nnebulae in the very-high-energy regime. H.E.S.S., with its large field of view\nof 5 degrees and high sensitivity, gives new prospects for the search for these\nobjects. An ongoing systematic search for very-high-energy emission from\nenergetic pulsars over the region of the Galactic plane between -60 degrees < l\n< 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting\ncandidates, the standard H.E.S.S. analysis was applied and a search for\nmulti-wavelength counterparts was performed. We present the discovery of two\nnew candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193.\nH.E.S.S. has proven to be a suitable instrument for pulsar wind nebula\nsearches.\n\n", "human_text": "  We present the discovery of two very-high-energy gamma-ray sources in an\nongoing systematic search for emission above 100 GeV from pulsar wind nebulae\nin survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov\nTelescopes are ideal tools for searching for extended emission from pulsar wind\nnebulae in the very-high-energy regime. H.E.S.S., with its large field of view\nof 5 degrees and high sensitivity, gives new prospects for the search for these\nobjects. An ongoing systematic search for very-high-energy emission from\nenergetic pulsars over the region of the Galactic plane between -60 degrees < l\n< 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting\ncandidates, the standard H.E.S.S. analysis was applied and a search for\nmulti-wavelength counterparts was performed. We present the discovery of two\nnew candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193.\nH.E.S.S. has proven to be a suitable instrument for pulsar wind nebula\nsearches.\n", "machine_text": "\nThis article discusses the results of a systematic survey conducted by the H.E.S.S. telescope array for pulsar wind nebulae (PWNe) emitting gamma rays with energies greater than 100 GeV, from -60 degrees < l < 30 degrees, -2 degrees < b < 2 degrees, in the Galactic plane. We found indications of two new PWNe, HESS J1718-385 and HESS J1809-193, which were then confirmed with a standard H.E.S.S. analysis and search for multi-wavelength counterparts. H.E.S.S.'s large field of view and high sensitivity make it an effective tool for discovering PWNe in the very-high-energy regime. Our study suggests that these discoveries represent a promising future for using H.E.S.S. in searches of this kind.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1605}
{"prompt": "Rephrase the abstract of an article with title 'Wavelet transforms in a critical interface model for Barkhausen noise'.\n  We discuss the application of wavelet transforms to a critical interface\nmodel, which is known to provide a good description of Barkhausen noise in soft\nferromagnets. The two-dimensional version of the model (one-dimensional\ninterface) is considered, mainly in the adiabatic limit of very slow driving.\nOn length scales shorter than a crossover length (which grows with the strength\nof surface tension), the effective interface roughness exponent $\\zeta$ is\n$\\simeq 1.20$, close to the expected value for the universality class of the\nquenched Edwards-Wilkinson model. We find that the waiting times between\navalanches are fully uncorrelated, as the wavelet transform of their\nautocorrelations scales as white noise. Similarly, detrended size-size\ncorrelations give a white-noise wavelet transform. Consideration of finite\ndriving rates, still deep within the intermittent regime, shows the wavelet\ntransform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies.\nThis behavior is ascribed to intra-avalanche correlations.\n\n", "human_text": "  We discuss the application of wavelet transforms to a critical interface\nmodel, which is known to provide a good description of Barkhausen noise in soft\nferromagnets. The two-dimensional version of the model (one-dimensional\ninterface) is considered, mainly in the adiabatic limit of very slow driving.\nOn length scales shorter than a crossover length (which grows with the strength\nof surface tension), the effective interface roughness exponent $\\zeta$ is\n$\\simeq 1.20$, close to the expected value for the universality class of the\nquenched Edwards-Wilkinson model. We find that the waiting times between\navalanches are fully uncorrelated, as the wavelet transform of their\nautocorrelations scales as white noise. Similarly, detrended size-size\ncorrelations give a white-noise wavelet transform. Consideration of finite\ndriving rates, still deep within the intermittent regime, shows the wavelet\ntransform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies.\nThis behavior is ascribed to intra-avalanche correlations.\n", "machine_text": "\nWe make use of wavelet transforms to show how a critical interface model is able to describe Barkhausen noise in soft ferromagnets. For this purpose, the two-dimensional version of the model is used, in the adiabatic limit of slow driving. We observe that when the length scale is shorter than a crossover length, the effective interface roughness exponent $\\zeta$ is near 1.20, close to the expected value for the Edwards-Wilkinson model. Our analysis suggests that the waiting times between avalanches are uncorrelated, as demonstrated by the white noise scaling of the wavelet transform of their autocorrelations. Moreover, size-size correlations with the data detrended also lead to a white-noise wavelet transform. Finite driving rates which remain within the intermittent regime, show a scaling of $1/f^{1.5}$ of the wavelet transform of correlations for intermediate frequencies. This can be determined to be caused by intra-avalanche correlations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1574}
{"prompt": "Rephrase the abstract of an article with title 'Orbits of tori extended by finite groups and their polynomial hulls: the\n  case of connected complex orbits'.\n  Let $V$ be a complex linear space, $G\\subset\\GL(V)$ be a compact group. We\nconsider the problem of description of polynomial hulls $\\wh{Gv}$ for orbits\n$Gv$, $v\\in V$, assuming that the identity component of $G$ is a torus $T$. The\npaper contains a universal construction for orbits which satisfy the inclusion\n$Gv\\subset T^\\bbC v$ and a characterization of pairs $(G,V)$ such that it is\ntrue for a generic $v\\in V$. The hull of a finite union of $T$-orbits in\n$T^\\bbC v$ can be distinguished in $\\clos T^\\bbC v$ by a finite collection of\ninequalities of the type $\\abs{z_1}^{s_1}...\\abs{z_n}^{s_n}\\leq c$. In\nparticular, this is true for $Gv$. If powers in the monomials are independent\nof $v$, $Gv\\subset T^\\bbC v$ for a generic $v$, and either the center of $G$ is\nfinite or $T^\\bbC$ has an open orbit, then the space $V$ and the group $G$ are\nproducts of standard ones; the latter means that $G=S_nT$, where $S_n$ is the\ngroup of all permutations of coordinates and $T$ is either $\\bbT^n$ or\n$\\SU(n)\\cap\\bbT^n$, where $\\bbT^n$ is the torus of all diagonal matrices in\n$\\rU(n)$. The paper also contains a description of polynomial hulls for orbits\nof isotropy groups of bounded symmetric domains. This result is already known,\nbut we formulate it in a different form and supply with a shorter proof.\n\n", "human_text": "  Let $V$ be a complex linear space, $G\\subset\\GL(V)$ be a compact group. We\nconsider the problem of description of polynomial hulls $\\wh{Gv}$ for orbits\n$Gv$, $v\\in V$, assuming that the identity component of $G$ is a torus $T$. The\npaper contains a universal construction for orbits which satisfy the inclusion\n$Gv\\subset T^\\bbC v$ and a characterization of pairs $(G,V)$ such that it is\ntrue for a generic $v\\in V$. The hull of a finite union of $T$-orbits in\n$T^\\bbC v$ can be distinguished in $\\clos T^\\bbC v$ by a finite collection of\ninequalities of the type $\\abs{z_1}^{s_1}...\\abs{z_n}^{s_n}\\leq c$. In\nparticular, this is true for $Gv$. If powers in the monomials are independent\nof $v$, $Gv\\subset T^\\bbC v$ for a generic $v$, and either the center of $G$ is\nfinite or $T^\\bbC$ has an open orbit, then the space $V$ and the group $G$ are\nproducts of standard ones; the latter means that $G=S_nT$, where $S_n$ is the\ngroup of all permutations of coordinates and $T$ is either $\\bbT^n$ or\n$\\SU(n)\\cap\\bbT^n$, where $\\bbT^n$ is the torus of all diagonal matrices in\n$\\rU(n)$. The paper also contains a description of polynomial hulls for orbits\nof isotropy groups of bounded symmetric domains. This result is already known,\nbut we formulate it in a different form and supply with a shorter proof.\n", "machine_text": "This article examines the problem of describing polynomial hulls for orbits $Gv$, $v \\in V$, of a compact group $G \\subset \\GL(V)$, in the case where the identity component of $G$ is a torus $T$. It provides a universal construction for orbits that include $Gv \\subset T^\\bbC v$ and characterizes the pairs of $(G,V)$ where this holds in a generic form. Additionally, it provides a finite collection of inequalities that can be used to distinguish the hull of a finite union of $T$-orbits in $T^\\bbC v$ within the closure of $T^\\bbC v$. If the powers in the monomials do not depend on $v$ and $Gv$ is included in $T^\\bbC v$ for a generic $v$, the space $V$ and the group $G$ are determined as products of standard ones, where $G=S_nT$ is either $\\bbT^n$ or $\\SU(n)\\cap\\bbT^n$ with the torus of all diagonal matrices in $\\rU(n)$. Lastly, this paper also provides a new and more concise description of polynomial hulls for orbits of isotropy groups of bounded symmetric domains.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1095}
{"prompt": "Rephrase the abstract of an article with title 'Einstein in the crossroad of the sciences, arts and humanities'.\n  Western thinking underwent a turning point between 1885 and 1925. Einstein in\n1905 symbolizes the emblematic hinge of this change of direction. To find an\nequivalent phenomenon in the past we need to go back to the period from the XV\ncentury to the XVII century. It was not a mere reform of codes but a new code.\nIn 1905 the perception of reality changed through the introduction of\nrelativism in three levels of the reference systems: the ego-other relation,\nthe world perceived by the senses, and the 'ideal' universe of the concepts. We\nwill try to identify how this change was expressed and developed in the cited\nlevels, both in the physic and nature based sciences, in the social sciences,\nand in literature and fine arts. Today, 100 years after, the 1905's generation\nstill proposes us two options: to live sheltered by the dogma that reassures us\nwith its only and exclusive viewpoint claimed objective, or to dare to live\nwith the multiple, the transient, the relative. The first way led to the worst\nregimes and intolerant ideas of the XX century, the second option throws us\ninto the uncertainty of the creative adventure, but also leads us to the\npossibility of a fairer society in the XXI century.\n\n", "human_text": "  Western thinking underwent a turning point between 1885 and 1925. Einstein in\n1905 symbolizes the emblematic hinge of this change of direction. To find an\nequivalent phenomenon in the past we need to go back to the period from the XV\ncentury to the XVII century. It was not a mere reform of codes but a new code.\nIn 1905 the perception of reality changed through the introduction of\nrelativism in three levels of the reference systems: the ego-other relation,\nthe world perceived by the senses, and the 'ideal' universe of the concepts. We\nwill try to identify how this change was expressed and developed in the cited\nlevels, both in the physic and nature based sciences, in the social sciences,\nand in literature and fine arts. Today, 100 years after, the 1905's generation\nstill proposes us two options: to live sheltered by the dogma that reassures us\nwith its only and exclusive viewpoint claimed objective, or to dare to live\nwith the multiple, the transient, the relative. The first way led to the worst\nregimes and intolerant ideas of the XX century, the second option throws us\ninto the uncertainty of the creative adventure, but also leads us to the\npossibility of a fairer society in the XXI century.\n", "machine_text": "\nIn 1905, the concept of relativism revolutionized the way we perceive reality. In this historic transformation, Einstein symbolizes the pivotal figure connecting the sciences, arts, and humanities. By analyzing the physic and nature based sciences, the social sciences, and literature and fine arts between 1885 and 1925, this paper seeks to understand the shift away from dogma toward the uncertainty of creative adventure. At its core is the adamant belief that taking the second path ultimately leads to more equitable societies. Now, a century later, we are still presented with the same two choices - to stay sheltered in the confines of 'objective' dogma, or to embrace the challenge of multiple, ever-changing perspectives.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0999}
{"prompt": "Rephrase the abstract of an article with title 'GRB blastwaves through wind-shaped circumburst media'.\n  Context:A significant fraction of progenitors for long gamma-ray bursts\n(GRBs) are believed to be massive stars. The investigation of long GRBs\ntherefore requires modeling the propagation of ultra-relativistic blastwaves\nthrough the circumburst medium surrounding massive stars. We simulate the\nexpansion of an isotropic, adiabatic relativistic fireball into the wind-shaped\nmedium around a massive GRB progenitor. The circumburst medium is composed of a\nrealistically stratified stellar wind zone up to its termination shock,\nfollowed by a region of shocked wind characterized by a constant density. Aims:\nWe followed the evolution of the blastwave through all its stages, including\nthe extremely rapid acceleration up to a Lorentz factor 75 flow, its\ndeceleration by interaction with stellar wind, its passage of the wind\ntermination shock, until its propagation through shocked wind. Methods: We used\nthe adaptive mesh refinement versatile advection code to follow the evolution\nof the fireball. Results: We show that the acceleration from purely thermal to\nultra-relativistic kinetic regimes is abrupt and produces an internally\nstructured blastwave. We resolved the structure of this ultra-relativistic\nshell in all stages, thanks to the adaptive mesh. We comment on the dynamical\nroles played by forward and reverse shock pairs in the phase of interaction\nwith the free stellar wind and clearly identify the complex shock-dominated\nstructure created when the shell crosses the terminal shock. Conclusion: We\nshow that in our model where the terminal shock is taken relatively close to\nthe massive star, the phase of self-similar deceleration of Blandford-McKee\ntype can only be produced in the constant density, shocked wind zone.\n\n", "human_text": "  Context:A significant fraction of progenitors for long gamma-ray bursts\n(GRBs) are believed to be massive stars. The investigation of long GRBs\ntherefore requires modeling the propagation of ultra-relativistic blastwaves\nthrough the circumburst medium surrounding massive stars. We simulate the\nexpansion of an isotropic, adiabatic relativistic fireball into the wind-shaped\nmedium around a massive GRB progenitor. The circumburst medium is composed of a\nrealistically stratified stellar wind zone up to its termination shock,\nfollowed by a region of shocked wind characterized by a constant density. Aims:\nWe followed the evolution of the blastwave through all its stages, including\nthe extremely rapid acceleration up to a Lorentz factor 75 flow, its\ndeceleration by interaction with stellar wind, its passage of the wind\ntermination shock, until its propagation through shocked wind. Methods: We used\nthe adaptive mesh refinement versatile advection code to follow the evolution\nof the fireball. Results: We show that the acceleration from purely thermal to\nultra-relativistic kinetic regimes is abrupt and produces an internally\nstructured blastwave. We resolved the structure of this ultra-relativistic\nshell in all stages, thanks to the adaptive mesh. We comment on the dynamical\nroles played by forward and reverse shock pairs in the phase of interaction\nwith the free stellar wind and clearly identify the complex shock-dominated\nstructure created when the shell crosses the terminal shock. Conclusion: We\nshow that in our model where the terminal shock is taken relatively close to\nthe massive star, the phase of self-similar deceleration of Blandford-McKee\ntype can only be produced in the constant density, shocked wind zone.\n", "machine_text": "\nThis article discusses the results of simulated expansion of an isotropic adiabatic relativistic fireball around a massive GRB progenitor from within its wind-shaped circumburst medium. Utilizing the adaptive mesh refinement versatile advection code, we were able to follow the transition from thermal to ultra-relativistic kinetic explosion. We found that the blastwave passed through a forward and reverse shock pair during interaction with the free stellar wind, ultimately creating a complex shock-governed structure when entering the shocked wind region. Ultimately, we show that the self-similar deceleration found in the Blandford-McKee type can only be produced in the constant density atmosphere of the shocked wind zone in our model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2461}
{"prompt": "Rephrase the abstract of an article with title 'Near infrared spectroscopic search for the close orbiting planet HD\n  75289b'.\n  We present a search for the near infrared spectroscopic signature of the\nclose orbiting extrasolar giant planet HD 75289b. We obtained ~230 spectra in\nthe wavelength range 2.18 - 2.19 microns using the Phoenix spectrograph at\nGemini South. By considering the direct spectrum, derived from irradiated model\natmospheres, we search for the absorption profile signature present in the\ncombined star and planet light. Since the planetary spectrum is separated from\nthe stellar spectrum at most phases, we apply a phase dependent orbital model\nand tomographic techniques to search for absorption signatures.\n  Because the absorption signature lies buried in the noise of a single\nexposure we apply a multiline deconvolution to the spectral lines available in\norder to boost the effective S/N ratio of the data. The wavelength coverage of\n80 angstroms is expected to contain ~100 planetary lines, enabling a mean line\nwith S/N ratio of ~800 to be achieved after deconvolution. We are nevertheless\nunable to detect the presence of the planet in the data and carry out further\nsimulations to show that broader wavelength coverage should enable a planet\nlike HD 75289b to be detected with 99.9 per cent (4 sigma) confidence. We\ninvestigate the sensitivity of our method and estimate detection tolerances for\nmismatches between observed and model planetary atmospheres.\n\n", "human_text": "  We present a search for the near infrared spectroscopic signature of the\nclose orbiting extrasolar giant planet HD 75289b. We obtained ~230 spectra in\nthe wavelength range 2.18 - 2.19 microns using the Phoenix spectrograph at\nGemini South. By considering the direct spectrum, derived from irradiated model\natmospheres, we search for the absorption profile signature present in the\ncombined star and planet light. Since the planetary spectrum is separated from\nthe stellar spectrum at most phases, we apply a phase dependent orbital model\nand tomographic techniques to search for absorption signatures.\n  Because the absorption signature lies buried in the noise of a single\nexposure we apply a multiline deconvolution to the spectral lines available in\norder to boost the effective S/N ratio of the data. The wavelength coverage of\n80 angstroms is expected to contain ~100 planetary lines, enabling a mean line\nwith S/N ratio of ~800 to be achieved after deconvolution. We are nevertheless\nunable to detect the presence of the planet in the data and carry out further\nsimulations to show that broader wavelength coverage should enable a planet\nlike HD 75289b to be detected with 99.9 per cent (4 sigma) confidence. We\ninvestigate the sensitivity of our method and estimate detection tolerances for\nmismatches between observed and model planetary atmospheres.\n", "machine_text": "\nIn this study, we perform a near infrared spectroscopic search for the close orbiting extrasolar giant planet HD 75289b. To do so, we use the Phoenix spectrograph at Gemini South to take ~230 spectra in the 2.18 - 2.19 micron wavelength. We compare the combined star and planet light to the direct spectrum of an irradiated model atmosphere in search of an absorption profile signature. We also adapt phase dependent orbital models and tomographic techniques to seek out the detection of absorption signatures. With the multiline deconvolution technique, we increase the signal-to-noise ratio of the data, though no planet signature is observed. Simulations suggest that widening the wavelength coverage can enable the detection of a planet such as HD 75289b with a 4 sigma confidence. In addition, we examine the sensitivity of our method, estimating detection assumptions under mismatched observed and modeled planetary atmospheres.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0272}
{"prompt": "Rephrase the abstract of an article with title 'Dark Matter Annihilation in Substructures Revised'.\n  Upcoming $\\gamma$-ray satellites will search for Dark Matter annihilations in\nMilky Way substructures (or 'clumps'). The prospects for detecting these\nobjects strongly depend on the assumptions made on the distribution of Dark\nMatter in substructures, and on the distribution of substructures in the Milky\nWay halo. By adopting simplified, yet rather extreme, prescriptions for these\nquantities, we compute the number of sources that can be detected with upcoming\nexperiments such as GLAST, and show that, for the most optimistic particle\nphysics setup ($m_\\chi=40$ GeV and annihilation cross section $\\sigma v = 3\n\\times 10^{-26}$ cm$^3$ s$^{-1}$), the result ranges from zero to $\\sim$\nhundred sources, all with mass above $10^{5}M\\odot$. However, for a fiducial DM\ncandidate with mass $m_\\chi=100$ GeV and $\\sigma v = 10^{-26}$ cm$^3$ s$^{-1}$,\nat most a handful of large mass substructures can be detected at $5 \\sigma$,\nwith a 1-year exposure time, by a GLAST-like experiment. Scenarios where\nmicro-clumps (i.e. clumps with mass as small as $10^{-6}M\\odot$) can be\ndetected are severely constrained by the diffuse $\\gamma$-ray background\ndetected by EGRET.\n\n", "human_text": "  Upcoming $\\gamma$-ray satellites will search for Dark Matter annihilations in\nMilky Way substructures (or 'clumps'). The prospects for detecting these\nobjects strongly depend on the assumptions made on the distribution of Dark\nMatter in substructures, and on the distribution of substructures in the Milky\nWay halo. By adopting simplified, yet rather extreme, prescriptions for these\nquantities, we compute the number of sources that can be detected with upcoming\nexperiments such as GLAST, and show that, for the most optimistic particle\nphysics setup ($m_\\chi=40$ GeV and annihilation cross section $\\sigma v = 3\n\\times 10^{-26}$ cm$^3$ s$^{-1}$), the result ranges from zero to $\\sim$\nhundred sources, all with mass above $10^{5}M\\odot$. However, for a fiducial DM\ncandidate with mass $m_\\chi=100$ GeV and $\\sigma v = 10^{-26}$ cm$^3$ s$^{-1}$,\nat most a handful of large mass substructures can be detected at $5 \\sigma$,\nwith a 1-year exposure time, by a GLAST-like experiment. Scenarios where\nmicro-clumps (i.e. clumps with mass as small as $10^{-6}M\\odot$) can be\ndetected are severely constrained by the diffuse $\\gamma$-ray background\ndetected by EGRET.\n", "machine_text": "This paper revised the potential of upcoming $\\gamma$-ray satellites to detect Dark Matter annihilations in Milky Way substructures, taking into account different sources of variables on the subject. We compute the estimated number of sources that can be detected with GLAST and other experiments, depending on the particle physics parameters of the Dark Matter candidate. Our results suggest that for a fiducial DM particle, only a handful of larger masses may be detected with a 1-year exposure time. Furthermore, depending on the assumed parameters, scenarios where micro-clumps can be detected may be severely hindered by the observed gamma-ray background.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2101}
{"prompt": "Rephrase the abstract of an article with title 'Pure inductive limit state and Kolmogorov's property'.\n  Let $(\\clb,\\lambda_t,\\psi)$ be a $C^*$-dynamical system where $(\\lambda_t: t\n\\in \\IT_+)$ be a semigroup of injective endomorphism and $\\psi$ be an\n$(\\lambda_t)$ invariant state on the $C^*$ subalgebra $\\clb$ and $\\IT_+$ is\neither non-negative integers or real numbers. The central aim of this\nexposition is to find a useful criteria for the inductive limit state $\\clb\n\\raro^{\\lambda_t} \\clb$ canonically associated with $\\psi$ to be pure. We\nachieve this by exploring the minimal weak forward and backward Markov\nprocesses associated with the Markov semigroup on the corner von-Neumann\nalgebra of the support projection of the state $\\psi$ to prove that\nKolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition\nfor the inductive state to be pure. As an application of this criteria we find\na sufficient condition for a translation invariant factor state on a one\ndimensional quantum spin chain to be pure. This criteria in a sense complements\ncriteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states.\n\n", "human_text": "  Let $(\\clb,\\lambda_t,\\psi)$ be a $C^*$-dynamical system where $(\\lambda_t: t\n\\in \\IT_+)$ be a semigroup of injective endomorphism and $\\psi$ be an\n$(\\lambda_t)$ invariant state on the $C^*$ subalgebra $\\clb$ and $\\IT_+$ is\neither non-negative integers or real numbers. The central aim of this\nexposition is to find a useful criteria for the inductive limit state $\\clb\n\\raro^{\\lambda_t} \\clb$ canonically associated with $\\psi$ to be pure. We\nachieve this by exploring the minimal weak forward and backward Markov\nprocesses associated with the Markov semigroup on the corner von-Neumann\nalgebra of the support projection of the state $\\psi$ to prove that\nKolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition\nfor the inductive state to be pure. As an application of this criteria we find\na sufficient condition for a translation invariant factor state on a one\ndimensional quantum spin chain to be pure. This criteria in a sense complements\ncriteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states.\n", "machine_text": "This article examines a way to determine whether a certain limit state $\\clb\n\\raro^{\\lambda_t} \\clb$ canonically associated with an $(\\lambda_t)$\ninvariant state $\\psi$ on a $C^*$-dynamical system $(\\clb,\\lambda_t,\\psi)$ is\npure. It studies the minimal weak forward and backward Markov processes arising\nfrom the Markov semigroup linked to the $\\psi$ to show that Kolmogorov's\nproperty [Mo2] of the Markov semigroup is sufficient for the limit state to be\npure. We give a criterion for the purity of a translation invariant factor\nstate on a one-dimensional quantum spin chain, and this is a complement to the\ncriteria established earlier by [BJKW,Mo2] as it goes beyond lattice symmetric\nstates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1987}
{"prompt": "Rephrase the abstract of an article with title 'Fractionally charged excitations on frustrated lattices'.\n  Systems of strongly correlated fermions on certain geometrically frustrated\nlattices at particular filling factors support excitations with fractional\ncharges $\\pm e/2$. We calculate quantum mechanical ground states, low--lying\nexcitations and spectral functions of finite lattices by means of numerical\ndiagonalization. The ground state of the most thoroughfully studied case, the\ncriss-crossed checkerboard lattice, is degenerate and shows long--range order.\nStatic fractional charges are confined by a weak linear force, most probably\nleading to bound states of large spatial extent. Consequently, the\nquasi-particle weight is reduced, which reflects the internal dynamics of the\nfractionally charged excitations. By using an additional parameter, we\nfine--tune the system to a special point at which fractional charges are\nmanifestly deconfined--the so--called Rokhsar--Kivelson point. For a deeper\nunderstanding of the low--energy physics of these models and for numerical\nadvantages, several conserved quantum numbers are identified.\n\n", "human_text": "  Systems of strongly correlated fermions on certain geometrically frustrated\nlattices at particular filling factors support excitations with fractional\ncharges $\\pm e/2$. We calculate quantum mechanical ground states, low--lying\nexcitations and spectral functions of finite lattices by means of numerical\ndiagonalization. The ground state of the most thoroughfully studied case, the\ncriss-crossed checkerboard lattice, is degenerate and shows long--range order.\nStatic fractional charges are confined by a weak linear force, most probably\nleading to bound states of large spatial extent. Consequently, the\nquasi-particle weight is reduced, which reflects the internal dynamics of the\nfractionally charged excitations. By using an additional parameter, we\nfine--tune the system to a special point at which fractional charges are\nmanifestly deconfined--the so--called Rokhsar--Kivelson point. For a deeper\nunderstanding of the low--energy physics of these models and for numerical\nadvantages, several conserved quantum numbers are identified.\n", "machine_text": "\nAt particular filling factors, strongly correlated fermions governing systems on specific\ngeometrically frustrated lattices can exhibit excitations with fractional charges $\\pm e/2$.  To\ninvestigate the ground states, low-lying excitations, and spectral functions of these lattices,\nwe employ numerical diagonalization. Most notably, the criss-crossed checkerboard lattice was found \nto have a degenerate ground state in addition to long-range ordering. These fractional charges \nare shown to be bound by a weak linear force, leading to large-spatial-extent bound states. Thus, \nthe quasi-particle weight is diminished, reflecting the composition of such fractionally charged \nexcitations. By exploiting a primary parameter, we are able to tune the system to a specially \ndefined 'Rokhsar-Kivelson' point at which fractional charges can be definitively identified as being\ndeconfined. Far furthering our perception of the physics pertinent to those systems, several \nconserved quantum numbers are identified.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0521}
{"prompt": "Rephrase the abstract of an article with title 'Cohomology of affine Artin groups and applications'.\n  The result of this paper is the determination of the cohomology of Artin\ngroups of type A_n, B_n and \\tilde{A}_{n} with non-trivial local coefficients.\nThe main result is an explicit computation of the cohomology of the Artin group\nof type B_n with coefficients over the module \\Q[q^{\\pm 1},t^{\\pm 1}]. Here the\nfirst (n-1) standard generators of the group act by (-q)-multiplication, while\nthe last one acts by (-t)-multiplication. The proof uses some technical results\nfrom previous papers plus computations over a suitable spectral sequence. The\nremaining cases follow from an application of Shapiro's lemma, by considering\nsome well-known inclusions: we obtain the rational cohomology of the Artin\ngroup of affine type \\tilde{A}_{n} as well as the cohomology of the classical\nbraid group {Br}_{n} with coefficients in the n-dimensional representation\npresented in \\cite{tong}. The topological counterpart is the explicit\nconstruction of finite CW-complexes endowed with a free action of the Artin\ngroups, which are known to be K(\\pi,1) spaces in some cases (including finite\ntype groups). Particularly simple formulas for the Euler-characteristic of\nthese orbit spaces are derived.\n\n", "human_text": "  The result of this paper is the determination of the cohomology of Artin\ngroups of type A_n, B_n and \\tilde{A}_{n} with non-trivial local coefficients.\nThe main result is an explicit computation of the cohomology of the Artin group\nof type B_n with coefficients over the module \\Q[q^{\\pm 1},t^{\\pm 1}]. Here the\nfirst (n-1) standard generators of the group act by (-q)-multiplication, while\nthe last one acts by (-t)-multiplication. The proof uses some technical results\nfrom previous papers plus computations over a suitable spectral sequence. The\nremaining cases follow from an application of Shapiro's lemma, by considering\nsome well-known inclusions: we obtain the rational cohomology of the Artin\ngroup of affine type \\tilde{A}_{n} as well as the cohomology of the classical\nbraid group {Br}_{n} with coefficients in the n-dimensional representation\npresented in \\cite{tong}. The topological counterpart is the explicit\nconstruction of finite CW-complexes endowed with a free action of the Artin\ngroups, which are known to be K(\\pi,1) spaces in some cases (including finite\ntype groups). Particularly simple formulas for the Euler-characteristic of\nthese orbit spaces are derived.\n", "machine_text": "\nThis paper provides concrete calculations of the cohomology of affine Artin groups of types A_n, B_n, and \\tilde{A}_n with non-trivial local coefficients. The core result demonstrates the cohomology of the B_n Artin group when coefficients are taken from the module \\Q[q^{\\pm 1}, t^{\\pm 1}], where the first (n-1) standard generators act by a (-q)-multiplicative influence, and the last one acts by a (-t)-multiplicative influence. The proof uses technical results from earlier papers, calculations over a certain spectral sequence, and Shapiro's lemma for determining the cohomology for the remaining batches of cases. As an extra outcome of this article, there is the explicit construction of finite CW-complexes that encase a free action of the Artin groups, oftentimes exhibiting K(\\pi,1) space properties. Furthermore, concise formulas are revealed for calculating the Euler-characteristics of these orbit spaces.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2823}
{"prompt": "Rephrase the abstract of an article with title 'Statistical analyses of long-term variability of AGN at high radio\n  frequencies'.\n  We present a study of variability time scales in a large sample of Active\nGalactic Nuclei at several frequencies between 4.8 and 230 GHz. We investigate\nthe differences of various AGN types and frequencies and correlate the measured\ntime scales with physical parameters such as the luminosity and the Lorentz\nfactor. Our sample consists of both high and low polarization quasars, BL\nLacertae objects and radio galaxies. The basis of this work is the 22 GHz, 37\nGHz and 87 GHz monitoring data from the Metsahovi Radio Observatory spanning\nover 25 years. In addition,we used higher 90 GHz and 230 GHz frequency data\nobtained with the SEST-telescope between 1987 and 2003. Further lower frequency\ndata at 4.8 GHz, 8 GHz and 14.5 GHz from the University of Michigan monitoring\nprogramme have been used. We have applied three different statistical methods\nto study the time scales: The structure function, the discrete correlation\nfunction and the Lomb-Scargle periodogram. We discuss also the differences and\nrelative merits of these three methods. Our study reveals that smaller flux\ndensity variations occur in these sources on short time scales of 1-2 years,\nbut larger outbursts happen quite rarely, on the average only once in every 6\nyears. We do not find any significant differences in the time scales between\nthe source classes. The time scales are also only weakly related to the\nluminosity suggesting that the shock formation is caused by jet instabilities\nrather than the central black hole.\n\n", "human_text": "  We present a study of variability time scales in a large sample of Active\nGalactic Nuclei at several frequencies between 4.8 and 230 GHz. We investigate\nthe differences of various AGN types and frequencies and correlate the measured\ntime scales with physical parameters such as the luminosity and the Lorentz\nfactor. Our sample consists of both high and low polarization quasars, BL\nLacertae objects and radio galaxies. The basis of this work is the 22 GHz, 37\nGHz and 87 GHz monitoring data from the Metsahovi Radio Observatory spanning\nover 25 years. In addition,we used higher 90 GHz and 230 GHz frequency data\nobtained with the SEST-telescope between 1987 and 2003. Further lower frequency\ndata at 4.8 GHz, 8 GHz and 14.5 GHz from the University of Michigan monitoring\nprogramme have been used. We have applied three different statistical methods\nto study the time scales: The structure function, the discrete correlation\nfunction and the Lomb-Scargle periodogram. We discuss also the differences and\nrelative merits of these three methods. Our study reveals that smaller flux\ndensity variations occur in these sources on short time scales of 1-2 years,\nbut larger outbursts happen quite rarely, on the average only once in every 6\nyears. We do not find any significant differences in the time scales between\nthe source classes. The time scales are also only weakly related to the\nluminosity suggesting that the shock formation is caused by jet instabilities\nrather than the central black hole.\n", "machine_text": "We have conducted a long-term statistical analysis of variability in a large sample of Active Galactic\nNuclei (AGN) across multiple high radio frequencies. Our sample was composed of various AGN types (high and low polarization quasars, BL Lacertae objects and radio galaxies) and was gathered using the Metsahovi Radio Observatory's 22 GHz, 37 GHz and 87GHz monitoring data from the past 25 years, as well as the data obtained using the SEST-telescope between 1987 and 2003. We also used the University of Michigan monitoring program data at 4.8 GHz, 8 GHz and 14.5 GHz. Three different statistical methods (structure function, discrete correlation function and Lomb-Scargle periodogram) were applied in order to examine the flux density variations of AGN on short timescales, as well as the frequency and physical parameter differences regarding their variability. Results showed that 1-2 year short-timescale fluctuations occur more frequently compared to large outbursts, with an average of once every 6 years. Differing from the hypothesis, there were no significant differences between AGN types and the time scales appeared to be only weakly related to luminosity, suggesting that instability in the jet, rather than the black hole, may be the source of these shock formations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3293}
{"prompt": "Rephrase the abstract of an article with title 'Adiabatic quantum dynamics of a random Ising chain across its quantum\n  critical point'.\n  We present here our study of the adiabatic quantum dynamics of a random Ising\nchain across its quantum critical point. The model investigated is an Ising\nchain in a transverse field with disorder present both in the exchange coupling\nand in the transverse field. The transverse field term is proportional to a\nfunction $\\Gamma(t)$ which, as in the Kibble-Zurek mechanism, is linearly\nreduced to zero in time with a rate $\\tau^{-1}$, $\\Gamma(t)=-t/\\tau$, starting\nat $t=-\\infty$ from the quantum disordered phase ($\\Gamma=\\infty$) and ending\nat $t=0$ in the classical ferromagnetic phase ($\\Gamma=0$). We first analyze\nthe distribution of the gaps -- occurring at the critical point $\\Gamma_c=1$ --\nwhich are relevant for breaking the adiabaticity of the dynamics. We then\npresent extensive numerical simulations for the residual energy $E_{\\rm res}$\nand density of defects $\\rho_k$ at the end of the annealing, as a function of\nthe annealing inverse rate $\\tau$. %for different lenghts of the chain. Both\nthe average $E_{\\rm res}(\\tau)$ and $\\rho_k(\\tau)$ are found to behave\nlogarithmically for large $\\tau$, but with different exponents, $[E_{\\rm\nres}(\\tau)/L]_{\\rm av}\\sim 1/\\ln^{\\zeta}(\\tau)$ with $\\zeta\\approx 3.4$, and\n$[\\rho_k(\\tau)]_{\\rm av}\\sim 1/\\ln^{2}(\\tau)$. We propose a mechanism for\n$1/\\ln^2{\\tau}$-behavior of $[\\rho_k]_{\\rm av}$ based on the Landau-Zener\ntunneling theory and on a Fisher's type real-space renormalization group\nanalysis of the relevant gaps. The model proposed shows therefore a\nparadigmatic example of how an adiabatic quantum computation can become very\nslow when disorder is at play, even in absence of any source of frustration.\n\n", "human_text": "  We present here our study of the adiabatic quantum dynamics of a random Ising\nchain across its quantum critical point. The model investigated is an Ising\nchain in a transverse field with disorder present both in the exchange coupling\nand in the transverse field. The transverse field term is proportional to a\nfunction $\\Gamma(t)$ which, as in the Kibble-Zurek mechanism, is linearly\nreduced to zero in time with a rate $\\tau^{-1}$, $\\Gamma(t)=-t/\\tau$, starting\nat $t=-\\infty$ from the quantum disordered phase ($\\Gamma=\\infty$) and ending\nat $t=0$ in the classical ferromagnetic phase ($\\Gamma=0$). We first analyze\nthe distribution of the gaps -- occurring at the critical point $\\Gamma_c=1$ --\nwhich are relevant for breaking the adiabaticity of the dynamics. We then\npresent extensive numerical simulations for the residual energy $E_{\\rm res}$\nand density of defects $\\rho_k$ at the end of the annealing, as a function of\nthe annealing inverse rate $\\tau$. %for different lenghts of the chain. Both\nthe average $E_{\\rm res}(\\tau)$ and $\\rho_k(\\tau)$ are found to behave\nlogarithmically for large $\\tau$, but with different exponents, $[E_{\\rm\nres}(\\tau)/L]_{\\rm av}\\sim 1/\\ln^{\\zeta}(\\tau)$ with $\\zeta\\approx 3.4$, and\n$[\\rho_k(\\tau)]_{\\rm av}\\sim 1/\\ln^{2}(\\tau)$. We propose a mechanism for\n$1/\\ln^2{\\tau}$-behavior of $[\\rho_k]_{\\rm av}$ based on the Landau-Zener\ntunneling theory and on a Fisher's type real-space renormalization group\nanalysis of the relevant gaps. The model proposed shows therefore a\nparadigmatic example of how an adiabatic quantum computation can become very\nslow when disorder is at play, even in absence of any source of frustration.\n", "machine_text": "\nWe investigate the adiabatic quantum dynamics of a disordered Ising chain at its quantum critical point. This model is composed of an Ising chain in a transverse field with disorder in both the exchange coupling and the transverse field. By applying the Kibble-Zurek mechanism, the transverse field is reducing linearly from infinity to zero with an annealing rate $\\tau^{-1}$, from the quantum disordered phase to the classical ferromagnetic phase. Our study addressed the gap distribution at the critical point $\\Gamma_c=1$, and then moved to simulating the results from the residual energy and the defect density as a function of the inverse annealing rate $\\tau$. From the findings, the average quantities $E_{\\rm res}(\\tau)$ and $\\rho_k(\\tau)$ both have logarithmic behavior with different exponents. We then proposed a mechanism to explain the $1/\\ln^2(\\tau)$ behavior of $[\\rho_k]_{\\rm av}$ through the use of Landau-Zener tunneling theory and a real-space renormalization of the relevant gaps. This model serves as a demonstration of how an adiabatic quantum computation can become slower due to disorder even in the absence of frustration.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1832}
{"prompt": "Rephrase the abstract of an article with title 'Loop Spaces and Langlands Parameters'.\n  We apply the technique of S^1-equivariant localization to sheaves on loop\nspaces in derived algebraic geometry, and obtain a fundamental link between two\nfamilies of categories at the heart of geometric representation theory. Namely,\nwe categorify the well known relationship between free loop spaces, cyclic\nhomology and de Rham cohomology to recover the category of D-modules on a\nsmooth stack X as a localization of the category of S^1-equivariant coherent\nsheaves on its loop space LX. The main observation is that this procedure\nconnects categories of equivariant D-modules on flag varieties with categories\nof equivariant coherent sheaves on the Steinberg variety and its relatives.\nThis provides a direct connection between the geometry of finite and affine\nHecke algebras and braid groups, and a uniform geometric construction of all of\nthe categorical parameters for representations of real and complex reductive\ngroups. This paper forms the first step in a project to apply the geometric\nLanglands program to the complex and real local Langlands programs, which we\ndescribe.\n\n", "human_text": "  We apply the technique of S^1-equivariant localization to sheaves on loop\nspaces in derived algebraic geometry, and obtain a fundamental link between two\nfamilies of categories at the heart of geometric representation theory. Namely,\nwe categorify the well known relationship between free loop spaces, cyclic\nhomology and de Rham cohomology to recover the category of D-modules on a\nsmooth stack X as a localization of the category of S^1-equivariant coherent\nsheaves on its loop space LX. The main observation is that this procedure\nconnects categories of equivariant D-modules on flag varieties with categories\nof equivariant coherent sheaves on the Steinberg variety and its relatives.\nThis provides a direct connection between the geometry of finite and affine\nHecke algebras and braid groups, and a uniform geometric construction of all of\nthe categorical parameters for representations of real and complex reductive\ngroups. This paper forms the first step in a project to apply the geometric\nLanglands program to the complex and real local Langlands programs, which we\ndescribe.\n", "machine_text": " In this work, we apply the S^1-equivariant localization technique to the\nsheaves on loop spaces in derived algebraic geometry, and uncover the intimate\nconnection between two families of categories--those of D-modules on a smooth\nstack X, and of S^1-equivariant coherent sheaves on its loop space LX. By\nstudying the relationship between free loop spaces, cyclic homology, and de\nRham cohomology, we are able to quantitatively connect the geometry of finite\nand affine Hecke algebras, braid groups, and the categorical parameters of\nrepresentations of real and complex reductive groups. Our analysis provides a\nuniform geometric construction of Langlands parameters, and lays the groundwork\nfor applying the Geometric Langlands Program to the local Langlands Program of\nboth the real and complex kind.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0322}
{"prompt": "Rephrase the abstract of an article with title 'Optimal Investment with an Unbounded Random Endowment and Utility-Based\n  Pricing'.\n  This paper studies the problem of maximizing the expected utility of terminal\nwealth for a financial agent with an unbounded random endowment, and with a\nutility function which supports both positive and negative wealth. We prove the\nexistence of an optimal trading strategy within a class of permissible\nstrategies -- those strategies whose wealth process is a supermartingale under\nall pricing measures with finite relative entropy. We give necessary and\nsufficient conditions for the absence of utility-based arbitrage, and for the\nexistence of a solution to the primal problem.\n  We consider two utility-based methods which can be used to price contingent\nclaims. Firstly we investigate marginal utility-based price processes\n(MUBPP's). We show that such processes can be characterized as local\nmartingales under the normalized optimal dual measure for the utility\nmaximizing investor. Finally, we present some new results on utility\nindifference prices, including continuity properties and volume asymptotics for\nthe case of a general utility function, unbounded endowment and unbounded\ncontingent claims.\n\n", "human_text": "  This paper studies the problem of maximizing the expected utility of terminal\nwealth for a financial agent with an unbounded random endowment, and with a\nutility function which supports both positive and negative wealth. We prove the\nexistence of an optimal trading strategy within a class of permissible\nstrategies -- those strategies whose wealth process is a supermartingale under\nall pricing measures with finite relative entropy. We give necessary and\nsufficient conditions for the absence of utility-based arbitrage, and for the\nexistence of a solution to the primal problem.\n  We consider two utility-based methods which can be used to price contingent\nclaims. Firstly we investigate marginal utility-based price processes\n(MUBPP's). We show that such processes can be characterized as local\nmartingales under the normalized optimal dual measure for the utility\nmaximizing investor. Finally, we present some new results on utility\nindifference prices, including continuity properties and volume asymptotics for\nthe case of a general utility function, unbounded endowment and unbounded\ncontingent claims.\n", "machine_text": "\nThis paper explores the problem of optimizing a financial agent's expected utility of terminal wealth when there is an unbounded random endowment and a utility function with the capacity to support both positive and negative wealth. We prove that an optimal trading strategy exists within a prescribed class of strategies with a supermartingale-based wealth process under pricing measures of finite relative entropy. Necessary and sufficient conditions are proposed for utility-based arbitrage avoidance and the solution to the primary problem. Two utility-based approaches, marginal utility-based price processes (MUBPP's) and utility indifference prices, are utilized in the pricing of contingent claims. Characterization of MUBPP's as local martingales under the normalized optimal dual measure for the utility maximizing investor is outlined. Furthermore, properties of utility indifference pricing, such as continuity and volume asymptotics for the context of unbounded endowment and claims, are presented.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0478}
{"prompt": "Rephrase the abstract of an article with title 'Improved constraints on dark energy from Chandra X-ray observations of\n  the largest relaxed galaxy clusters'.\n  We present constraints on the mean matter density, Omega_m, dark energy\ndensity, Omega_de, and the dark energy equation of state parameter, w, using\nChandra measurements of the X-ray gas mass fraction (fgas) in 42 hot (kT>5keV),\nX-ray luminous, dynamically relaxed galaxy clusters spanning the redshift range\n0.05<z<1.1. Using only the fgas data for the 6 lowest redshift clusters at\nz<0.15, for which dark energy has a negligible effect on the measurements, we\nmeasure Omega_m=0.28+-0.06 (68% confidence, using standard priors on the Hubble\nConstant, H_0, and mean baryon density, Omega_bh^2). Analyzing the data for all\n42 clusters, employing only weak priors on H_0 and Omega_bh^2, we obtain a\nsimilar result on Omega_m and detect the effects of dark energy on the\ndistances to the clusters at ~99.99% confidence, with Omega_de=0.86+-0.21 for a\nnon-flat LCDM model. The detection of dark energy is comparable in significance\nto recent SNIa studies and represents strong, independent evidence for cosmic\nacceleration. Systematic scatter remains undetected in the fgas data, despite a\nweighted mean statistical scatter in the distance measurements of only ~5%. For\na flat cosmology with constant w, we measure Omega_m=0.28+-0.06 and\nw=-1.14+-0.31. Combining the fgas data with independent constraints from CMB\nand SNIa studies removes the need for priors on Omega_bh^2 and H_0 and leads to\ntighter constraints: Omega_m=0.253+-0.021 and w=-0.98+-0.07 for the same\nconstant-w model. More general analyses in which we relax the assumption of\nflatness and/or allow evolution in w remain consistent with the cosmological\nconstant paradigm. Our analysis includes conservative allowances for systematic\nuncertainties. The small systematic scatter and tight constraints bode well for\nfuture dark energy studies using the fgas method. (Abridged)\n\n", "human_text": "  We present constraints on the mean matter density, Omega_m, dark energy\ndensity, Omega_de, and the dark energy equation of state parameter, w, using\nChandra measurements of the X-ray gas mass fraction (fgas) in 42 hot (kT>5keV),\nX-ray luminous, dynamically relaxed galaxy clusters spanning the redshift range\n0.05<z<1.1. Using only the fgas data for the 6 lowest redshift clusters at\nz<0.15, for which dark energy has a negligible effect on the measurements, we\nmeasure Omega_m=0.28+-0.06 (68% confidence, using standard priors on the Hubble\nConstant, H_0, and mean baryon density, Omega_bh^2). Analyzing the data for all\n42 clusters, employing only weak priors on H_0 and Omega_bh^2, we obtain a\nsimilar result on Omega_m and detect the effects of dark energy on the\ndistances to the clusters at ~99.99% confidence, with Omega_de=0.86+-0.21 for a\nnon-flat LCDM model. The detection of dark energy is comparable in significance\nto recent SNIa studies and represents strong, independent evidence for cosmic\nacceleration. Systematic scatter remains undetected in the fgas data, despite a\nweighted mean statistical scatter in the distance measurements of only ~5%. For\na flat cosmology with constant w, we measure Omega_m=0.28+-0.06 and\nw=-1.14+-0.31. Combining the fgas data with independent constraints from CMB\nand SNIa studies removes the need for priors on Omega_bh^2 and H_0 and leads to\ntighter constraints: Omega_m=0.253+-0.021 and w=-0.98+-0.07 for the same\nconstant-w model. More general analyses in which we relax the assumption of\nflatness and/or allow evolution in w remain consistent with the cosmological\nconstant paradigm. Our analysis includes conservative allowances for systematic\nuncertainties. The small systematic scatter and tight constraints bode well for\nfuture dark energy studies using the fgas method. (Abridged)\n", "machine_text": "\nUsing Chandra X-ray observations of 42 of the most massive, X-ray luminous, and dynamically relaxed galaxy clusters over a redshift range of 0.05 to 1.1, we have determined constraints on the mean matter density, Omega_m, dark energy density, Omega_de, and the dark energy equation of state parameter, w. Using the 6 lowest redshift clusters, for which the dark energy has a minimal influence, we measure Omega_m to be 0.28 with a 68% confidence interval when applying standard priors on the Hubble Constant, H_0, and the mean baryon density, Omega_bh^2. Furthermore, by analyzing the entire sample for a non-flat LCDM model we detect the effects of dark energy at a very high confidence level. In addition, our fgas data has a weighted mean statistical scatter of just 5%, and combining our results with other studies of CMB and SNIa allows us to remove prior assumptions of Omega_bh and H_0, producing more specific results of Omega_m and w that support the cosmological constant paradigm. This study is remarkable in its precision and accuracy and lays the foundation for future dark energy investigations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0033}
{"prompt": "Rephrase the abstract of an article with title 'Two-sided optimal bounds for Green function of half-spaces for\n  relativistic $\\alpha$-stable process'.\n  The purpose of this paper is to find optimal estimates for the Green function\nof a half-space of {\\it the relativistic $\\alpha$-stable process} with\nparameter $m$ on $\\Rd$ space. This process has an infinitesimal generator of\nthe form $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2},$ where $0<\\alpha<2$, $m>0$, and\nreduces to the isotropic $\\alpha$-stable process for $m=0$. Its potential\ntheory for open bounded sets has been well developed throughout the recent\nyears however almost nothing was known about the behaviour of the process on\nunbounded sets. The present paper is intended to fill this gap and we provide\ntwo-sided sharp estimates for the Green function for a half-space. As a\nbyproduct we obtain some improvements of the estimates known for bounded sets\nspecially for balls. The advantage of these estimates is a clarification of the\nrelationship between the diameter of the ball and the parameter $m$ of the\nprocess.\n  The main result states that the Green function is comparable with the Green\nfunction for the Brownian motion if the points are away from the boundary of a\nhalf-space and their distance is greater than one. On the other hand for the\nremaining points the Green function is somehow related the Green function for\nthe isotropic $\\alpha$-stable process. For example, for $d\\ge3$, it is\ncomparable with the Green function for the isotropic $\\alpha$-stable process,\nprovided that the points are close enough.\n\n", "human_text": "  The purpose of this paper is to find optimal estimates for the Green function\nof a half-space of {\\it the relativistic $\\alpha$-stable process} with\nparameter $m$ on $\\Rd$ space. This process has an infinitesimal generator of\nthe form $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2},$ where $0<\\alpha<2$, $m>0$, and\nreduces to the isotropic $\\alpha$-stable process for $m=0$. Its potential\ntheory for open bounded sets has been well developed throughout the recent\nyears however almost nothing was known about the behaviour of the process on\nunbounded sets. The present paper is intended to fill this gap and we provide\ntwo-sided sharp estimates for the Green function for a half-space. As a\nbyproduct we obtain some improvements of the estimates known for bounded sets\nspecially for balls. The advantage of these estimates is a clarification of the\nrelationship between the diameter of the ball and the parameter $m$ of the\nprocess.\n  The main result states that the Green function is comparable with the Green\nfunction for the Brownian motion if the points are away from the boundary of a\nhalf-space and their distance is greater than one. On the other hand for the\nremaining points the Green function is somehow related the Green function for\nthe isotropic $\\alpha$-stable process. For example, for $d\\ge3$, it is\ncomparable with the Green function for the isotropic $\\alpha$-stable process,\nprovided that the points are close enough.\n", "machine_text": "  This paper focuses on finding optimal estimates for the Green function of  the\nrelativistic $\\alpha$-stable process defined on a half-space. This process\npossesses an infinitesimal generator given by $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2}$\nwhere $0<\\alpha<2$, $m>0$, and the process reduces to the isotropic $\\alpha$-stable\nprocess for $m=0$. Two-sided sharp bounds are provided for the Green function for\nthe half-space, as well as for bounded domains such as balls. These estimates\ncapture the relationship between the diameter of the ball and $m$ of the process.\nIt is found that for points away from the boundary of a half-space and when the\ndistance between them is greater than one, the Green function is comparable to\nthe Green function for the Brownian motion. For points closer to the boundary,\nthe Green function is related to the Green function for the isotropic\n$\\alpha$-stable process. It is found that for $d\\ge3$, it is comparable with the\nGreen function for the isotropic $\\alpha$-stable process if the points are close\nenough.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1175}
{"prompt": "Rephrase the abstract of an article with title 'Simulation of symmetric nuclei and the role of Pauli potential in\n  binding energies and radii'.\n  It is shown that the use of a density dependent effective Pauli potential\ntogether with a nucleon-nucleon interaction potential plays a crucial role to\nreproduce not only the binding energies but also the matter root mean square\nradii of medium mass range spin-isospin saturated nuclei. This study is\nperformed with a semiclassical Monte Carlo many-body simulation within the\ncontext of a simplified nucleon-nucleon interaction to focus on the effect of\nthe genuine correlations due to the fermionic nature of nucleons. The procedure\nobtained is rather robust and it does not depend on the detailed features of\nthe nucleon-nucleon interaction. For nuclei below saturation the density\ndependence may be represented in terms either of the nucleon number, $A$, or\nthe associated Fermi momenta. When testing the simulation procedure for\nidealized \"infinite\" symmetric nuclear matter within the corresponding range of\ndensities, it turns out that finite size effects affect the Pauli potential\nstrength parametrization in systems up to about 120 particles while remaining\napproximately stable for larger systems.\n\n", "human_text": "  It is shown that the use of a density dependent effective Pauli potential\ntogether with a nucleon-nucleon interaction potential plays a crucial role to\nreproduce not only the binding energies but also the matter root mean square\nradii of medium mass range spin-isospin saturated nuclei. This study is\nperformed with a semiclassical Monte Carlo many-body simulation within the\ncontext of a simplified nucleon-nucleon interaction to focus on the effect of\nthe genuine correlations due to the fermionic nature of nucleons. The procedure\nobtained is rather robust and it does not depend on the detailed features of\nthe nucleon-nucleon interaction. For nuclei below saturation the density\ndependence may be represented in terms either of the nucleon number, $A$, or\nthe associated Fermi momenta. When testing the simulation procedure for\nidealized \"infinite\" symmetric nuclear matter within the corresponding range of\ndensities, it turns out that finite size effects affect the Pauli potential\nstrength parametrization in systems up to about 120 particles while remaining\napproximately stable for larger systems.\n", "machine_text": "\nThis study presents the effects of employing a Pauli potential with a density-dependent effective framework to account for the binding energies and root mean square radii of nuclei in a medium mass range. Monte Carlo many-body simulation is used within a simplified nucleon-nucleon interaction to determine the correlations attributable to the fermionic character of nucleons. The method is demonstrated to be agnostic to the details of the nucleon-nucleon interaction. When evaluating the procedure for symmetric nuclear matter at various densities with simulations containing up to 120 nucleons, it is revealed that finite size effects may influence the Pauli potential strength parametrization. However, for larger systems, this effect remains consistent.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0958}
{"prompt": "Rephrase the abstract of an article with title 'Dislocation Dynamics in a Crystal Lattice (Peierls-Nabarro) Relief'.\n  The theory of the dislocation motion in the periodic potential relief of the\ncrystal lattice (the Peierls-Nabarro barriers) is reviewed. On the basis of the\nkink mechanism the temperature dependence of the flow stress is described for a\nwide class of materials. The theory of quantum mechanical dislocation\ntunnelling through the Peierls-Nabarro barriers is extended and compared with\nexperimental data on the plasticity of alkali halides, BCC and HCP metals at\nlow temperatures. The behavior of the flow stress at the range of athermic\nanomalies is modeled by changing the mechanism of the dislocation motion from\nthe thermally activated hopping over the barriers to the quantum tunnelling\nthrough them. Some results of previous calculations are represented in a more\nexplicit convenient for applications form. The pronounced effect of the\nswitching between the normal and the superconducting states on the flow stress\nof metals is explained on the basis of the change in the dissipative properties\nof the electron subsystem affecting the dislocation motion.\n\n", "human_text": "  The theory of the dislocation motion in the periodic potential relief of the\ncrystal lattice (the Peierls-Nabarro barriers) is reviewed. On the basis of the\nkink mechanism the temperature dependence of the flow stress is described for a\nwide class of materials. The theory of quantum mechanical dislocation\ntunnelling through the Peierls-Nabarro barriers is extended and compared with\nexperimental data on the plasticity of alkali halides, BCC and HCP metals at\nlow temperatures. The behavior of the flow stress at the range of athermic\nanomalies is modeled by changing the mechanism of the dislocation motion from\nthe thermally activated hopping over the barriers to the quantum tunnelling\nthrough them. Some results of previous calculations are represented in a more\nexplicit convenient for applications form. The pronounced effect of the\nswitching between the normal and the superconducting states on the flow stress\nof metals is explained on the basis of the change in the dissipative properties\nof the electron subsystem affecting the dislocation motion.\n", "machine_text": "\nThis paper reviews the theory surrounding the motion of dislocations within the periodic potential relief of a crystal lattice, known as the Peierls-Nabarro barriers. Based on the kink mechanism, a description is provided of the invariable temperature dependent flow stress experienced in certain types of materials. The theory of quantum mechanical dislocation tunnelling is expanded on and compared with experimental data exploring the plasticity of alkali halides, BCC and HCP metals at low temperatures. Furthermore, the behaviour of the flow stress between points of athermic anomalies is modelled by switching the mechanism of dislocation movement from one that is thermally activated and jumps over barriers, to tunnelling through them via quantum mechanics. Previous calculations are adjusted in order to make them more applicable in usage, with a specific focus on the perceptible impact on metal flow stress when switching between the normal and superconducting states due to changes in the dissipative properties of the electron subsystem, affecting the dislocation motion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1714}
{"prompt": "Rephrase the abstract of an article with title 'The Kalman--Yakubovich--Popov inequality for passive discrete\n  time-invariant systems'.\n  We consider the Kalman - Yakubovich - Popov (KYP) inequality \\[\n\\begin{pmatrix} X-A^* XA-C^*C & -A^*X B- C^*D\\cr -B^*X A-D^* C & I- B^*X B-D^*D\n\\end{pmatrix} \\ge 0 \\] for contractive operator matrices $ \\begin{pmatrix}\nA&B\\cr C &D \\end{pmatrix}:\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{M}\n\\end{pmatrix}\\to\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{N} \\end{pmatrix}, $\nwhere $\\mathfrak{H},$ $\\mathfrak{M}$, and $\\mathfrak{N}$ are separable Hilbert\nspaces. We restrict ourselves to the solutions $X$ from the operator interval\n$[0, I_\\mathfrak{H}]$. Several equivalent forms of KYP are obtained. Using the\nparametrization of the blocks of contractive operator matrices, the Kre\\u{\\i}n\nshorted operator, and the M\\\"obius representation of the Schur class\noperator-valued function we find several equivalent forms of the KYP\ninequality. Properties of solutions are established and it is proved that the\nminimal solution of the KYP inequality satisfies the corresponding algebraic\nRiccati equation and can be obtained by the iterative procedure with the\nspecial choice of the initial point. In terms of the Kre\\u{\\i}n shorted\noperators a necessary condition and some sufficient conditions for uniqueness\nof the solution are established.\n\n", "human_text": "  We consider the Kalman - Yakubovich - Popov (KYP) inequality \\[\n\\begin{pmatrix} X-A^* XA-C^*C & -A^*X B- C^*D\\cr -B^*X A-D^* C & I- B^*X B-D^*D\n\\end{pmatrix} \\ge 0 \\] for contractive operator matrices $ \\begin{pmatrix}\nA&B\\cr C &D \\end{pmatrix}:\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{M}\n\\end{pmatrix}\\to\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{N} \\end{pmatrix}, $\nwhere $\\mathfrak{H},$ $\\mathfrak{M}$, and $\\mathfrak{N}$ are separable Hilbert\nspaces. We restrict ourselves to the solutions $X$ from the operator interval\n$[0, I_\\mathfrak{H}]$. Several equivalent forms of KYP are obtained. Using the\nparametrization of the blocks of contractive operator matrices, the Kre\\u{\\i}n\nshorted operator, and the M\\\"obius representation of the Schur class\noperator-valued function we find several equivalent forms of the KYP\ninequality. Properties of solutions are established and it is proved that the\nminimal solution of the KYP inequality satisfies the corresponding algebraic\nRiccati equation and can be obtained by the iterative procedure with the\nspecial choice of the initial point. In terms of the Kre\\u{\\i}n shorted\noperators a necessary condition and some sufficient conditions for uniqueness\nof the solution are established.\n", "machine_text": "\nThis paper investigates the Kalman - Yakubovich - Popov (KYP) inequality for contractive operator matrices for passive discrete-time systems. Different forms of the KYP inequality are defined and properties of solutions are studied. We look further into situations where a minimal solution satisfies a corresponding Riccati equation and can be obtained iteratively with a specified initial point. The Krein shorted operator is employed to obtain a necessary condition and some sufficient conditions for the uniqueness of the solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0653}
{"prompt": "Rephrase the abstract of an article with title 'Spin Evolution of Accreting Neutron Stars: Nonlinear Development of the\n  R-mode Instability'.\n  The nonlinear saturation of the r-mode instability and its effects on the\nspin evolution of Low Mass X-ray Binaries (LMXBs) are modeled using the triplet\nof modes at the lowest parametric instability threshold. We solve numerically\nthe coupled equations for the three mode amplitudes in conjunction with the\nspin and temperature evolution equations. We observe that very quickly the mode\namplitudes settle into quasi-stationary states. Once these states are reached,\nthe mode amplitudes can be found algebraically and the system of equations is\nreduced from eight to two equations: spin and temperature evolution.\nEventually, the system may reach thermal equilibrium and either (1) undergo a\ncyclic evolution with a frequency change of at most 10%, (2) evolve toward a\nfull equilibrium state in which the accretion torque balances the gravitational\nradiation emission, or (3) enter a thermogravitational runaway on a very long\ntimescale of about $10^6$ years. Alternatively, a faster thermal runaway\n(timescale of about 100 years) may occur. The sources of damping considered are\nshear viscosity, hyperon bulk viscosity and boundary layer viscosity. We vary\nproprieties of the star such as the hyperon superfluid transition temperature\nT_c, the fraction of the star that is above the threshold for direct URCA\nreactions, and slippage factor, and map the different scenarios we obtain to\nranges of these parameters. For all our bound evolutions the r-mode amplitude\nremains small $\\sim 10^{-5}$. The spin frequency is limited by boundary layer\nviscosity to $\\nu_{max} \\sim 800 Hz [S_{ns}/(M_{1.4} R_6)]^{4/11} T_8^{-2/11}$.\nWe find that for $\\nu > 700$ Hz the r-mode instability would be active for\nabout 1 in 1000 LMXBs and that only the gravitational waves from LMXBs in the\nlocal group of galaxies could be detected by advanced LIGO interferometers.\n\n", "human_text": "  The nonlinear saturation of the r-mode instability and its effects on the\nspin evolution of Low Mass X-ray Binaries (LMXBs) are modeled using the triplet\nof modes at the lowest parametric instability threshold. We solve numerically\nthe coupled equations for the three mode amplitudes in conjunction with the\nspin and temperature evolution equations. We observe that very quickly the mode\namplitudes settle into quasi-stationary states. Once these states are reached,\nthe mode amplitudes can be found algebraically and the system of equations is\nreduced from eight to two equations: spin and temperature evolution.\nEventually, the system may reach thermal equilibrium and either (1) undergo a\ncyclic evolution with a frequency change of at most 10%, (2) evolve toward a\nfull equilibrium state in which the accretion torque balances the gravitational\nradiation emission, or (3) enter a thermogravitational runaway on a very long\ntimescale of about $10^6$ years. Alternatively, a faster thermal runaway\n(timescale of about 100 years) may occur. The sources of damping considered are\nshear viscosity, hyperon bulk viscosity and boundary layer viscosity. We vary\nproprieties of the star such as the hyperon superfluid transition temperature\nT_c, the fraction of the star that is above the threshold for direct URCA\nreactions, and slippage factor, and map the different scenarios we obtain to\nranges of these parameters. For all our bound evolutions the r-mode amplitude\nremains small $\\sim 10^{-5}$. The spin frequency is limited by boundary layer\nviscosity to $\\nu_{max} \\sim 800 Hz [S_{ns}/(M_{1.4} R_6)]^{4/11} T_8^{-2/11}$.\nWe find that for $\\nu > 700$ Hz the r-mode instability would be active for\nabout 1 in 1000 LMXBs and that only the gravitational waves from LMXBs in the\nlocal group of galaxies could be detected by advanced LIGO interferometers.\n", "machine_text": "\nA numerical study was conducted to investigate the nonlinear saturation of the r-mode instability and its effects on the spin evolution of Low Mass X-ray Binaries (LMXBs). By solving the equations for the three mode amplitudes in conjunction with the spin and temperature evolution equations, the system eventually reaches either a cyclic evolution with a frequency change of at most 10%, a full equilibrium state in which the accretion torque balances the gravitational radiation emission, or a thermogravitational runaway. Various sources of damping such as shear viscosity, hyperon bulk viscosity and boundary layer viscosity are considered, along with properties of the star like the hyperon superfluid transition temperature, the fraction of the star that is above the threshold for direct URCA reactions, and slippage factor. Results of the study suggest that for $\\nu > 700$ Hz the r-mode instability would be active for about 1 in 1000 LMXBs, and that only the gravitational waves from LMXBs in the local group of galaxies could be detected by advanced LIGO interferometers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0799}
{"prompt": "Rephrase the abstract of an article with title 'Sensor Networks with Random Links: Topology Design for Distributed\n  Consensus'.\n  In a sensor network, in practice, the communication among sensors is subject\nto:(1) errors or failures at random times; (3) costs; and(2) constraints since\nsensors and networks operate under scarce resources, such as power, data rate,\nor communication. The signal-to-noise ratio (SNR) is usually a main factor in\ndetermining the probability of error (or of communication failure) in a link.\nThese probabilities are then a proxy for the SNR under which the links operate.\nThe paper studies the problem of designing the topology, i.e., assigning the\nprobabilities of reliable communication among sensors (or of link failures) to\nmaximize the rate of convergence of average consensus, when the link\ncommunication costs are taken into account, and there is an overall\ncommunication budget constraint. To consider this problem, we address a number\nof preliminary issues: (1) model the network as a random topology; (2)\nestablish necessary and sufficient conditions for mean square sense (mss) and\nalmost sure (a.s.) convergence of average consensus when network links fail;\nand, in particular, (3) show that a necessary and sufficient condition for both\nmss and a.s. convergence is for the algebraic connectivity of the mean graph\ndescribing the network topology to be strictly positive. With these results, we\nformulate topology design, subject to random link failures and to a\ncommunication cost constraint, as a constrained convex optimization problem to\nwhich we apply semidefinite programming techniques. We show by an extensive\nnumerical study that the optimal design improves significantly the convergence\nspeed of the consensus algorithm and can achieve the asymptotic performance of\na non-random network at a fraction of the communication cost.\n\n", "human_text": "  In a sensor network, in practice, the communication among sensors is subject\nto:(1) errors or failures at random times; (3) costs; and(2) constraints since\nsensors and networks operate under scarce resources, such as power, data rate,\nor communication. The signal-to-noise ratio (SNR) is usually a main factor in\ndetermining the probability of error (or of communication failure) in a link.\nThese probabilities are then a proxy for the SNR under which the links operate.\nThe paper studies the problem of designing the topology, i.e., assigning the\nprobabilities of reliable communication among sensors (or of link failures) to\nmaximize the rate of convergence of average consensus, when the link\ncommunication costs are taken into account, and there is an overall\ncommunication budget constraint. To consider this problem, we address a number\nof preliminary issues: (1) model the network as a random topology; (2)\nestablish necessary and sufficient conditions for mean square sense (mss) and\nalmost sure (a.s.) convergence of average consensus when network links fail;\nand, in particular, (3) show that a necessary and sufficient condition for both\nmss and a.s. convergence is for the algebraic connectivity of the mean graph\ndescribing the network topology to be strictly positive. With these results, we\nformulate topology design, subject to random link failures and to a\ncommunication cost constraint, as a constrained convex optimization problem to\nwhich we apply semidefinite programming techniques. We show by an extensive\nnumerical study that the optimal design improves significantly the convergence\nspeed of the consensus algorithm and can achieve the asymptotic performance of\na non-random network at a fraction of the communication cost.\n", "machine_text": "\nThis paper investigates the challenge of designing the topology of a sensor network to optimise the rate at which average consensus is obtained given the uncertainties in communication failures or errors, power and data rate limits or constraints, and the SNR of links. We show how this problem can be modelled as a constrained convex optimisation and can be solved using semidefinite programming, and demonstrate through extensive numerical research how the optimal topology design can improve the speed of consensus algorithm to approach the performance of a non-random network, but with a significantly lower communication cost. Necessary and sufficient conditions for mss and almost sure convergence of average consensus when links fail are established in the paper, and a pivotal role for the algebraic connectivity of the mean graph in determining such convergence is also highlighted.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0954}
{"prompt": "Rephrase the abstract of an article with title 'Lower order terms in the 1-level density for families of holomorphic\n  cuspidal newforms'.\n  The Katz-Sarnak density conjecture states that, in the limit as the\nconductors tend to infinity, the behavior of normalized zeros near the central\npoint of families of L-functions agree with the N -> oo scaling limits of\neigenvalues near 1 of subgroups of U(N). Evidence for this has been found for\nmany families by studying the n-level densities; for suitably restricted test\nfunctions the main terms agree with random matrix theory. In particular, all\none-parameter families of elliptic curves with rank r over Q(T) and the same\ndistribution of signs of functional equations have the same limiting behavior.\nWe break this universality and find family dependent lower order correction\nterms in many cases; these lower order terms have applications ranging from\nexcess rank to modeling the behavior of zeros near the central point, and\ndepend on the arithmetic of the family. We derive an alternate form of the\nexplicit formula for GL(2) L-functions which simplifies comparisons, replacing\nsums over powers of Satake parameters by sums of the moments of the Fourier\ncoefficients lambda_f(p). Our formula highlights the differences that we expect\nto exist from families whose Fourier coefficients obey different laws (for\nexample, we expect Sato-Tate to hold only for non-CM families of elliptic\ncurves). Further, by the work of Rosen and Silverman we expect lower order\nbiases to the Fourier coefficients in families of elliptic curves with rank\nover Q(T); these biases can be seen in our expansions. We analyze several\nfamilies of elliptic curves and see different lower order corrections,\ndepending on whether or not the family has complex multiplication, a forced\ntorsion point, or non-zero rank over Q(T).\n\n", "human_text": "  The Katz-Sarnak density conjecture states that, in the limit as the\nconductors tend to infinity, the behavior of normalized zeros near the central\npoint of families of L-functions agree with the N -> oo scaling limits of\neigenvalues near 1 of subgroups of U(N). Evidence for this has been found for\nmany families by studying the n-level densities; for suitably restricted test\nfunctions the main terms agree with random matrix theory. In particular, all\none-parameter families of elliptic curves with rank r over Q(T) and the same\ndistribution of signs of functional equations have the same limiting behavior.\nWe break this universality and find family dependent lower order correction\nterms in many cases; these lower order terms have applications ranging from\nexcess rank to modeling the behavior of zeros near the central point, and\ndepend on the arithmetic of the family. We derive an alternate form of the\nexplicit formula for GL(2) L-functions which simplifies comparisons, replacing\nsums over powers of Satake parameters by sums of the moments of the Fourier\ncoefficients lambda_f(p). Our formula highlights the differences that we expect\nto exist from families whose Fourier coefficients obey different laws (for\nexample, we expect Sato-Tate to hold only for non-CM families of elliptic\ncurves). Further, by the work of Rosen and Silverman we expect lower order\nbiases to the Fourier coefficients in families of elliptic curves with rank\nover Q(T); these biases can be seen in our expansions. We analyze several\nfamilies of elliptic curves and see different lower order corrections,\ndepending on whether or not the family has complex multiplication, a forced\ntorsion point, or non-zero rank over Q(T).\n", "machine_text": "\nThis paper confirms evidence for the Katz-Sarnak density conjecture, as many families of L-functions show agreement with the N -> oo scaling limits of eigenvalues near 1 of subgroups of U(N). We find that even for suitably restricted test functions, there can be family dependent lower order correction terms in the 1-level density, which have wide-ranging applications from the theory of excess rank to predicting the behavior of zeros near the central point. We also derive a more suitable explicit formula for GL(2) L-functions which facilitates making comparisons among various families. Notably, this expression shines light on differences in behavior seen by families whose Fourier coefficients follow different laws. We investigate a host of families of elliptic curves and uncover differing lower order corrections that are contingent upon the background features of the family such as complex multiplication, a forced torsion point, and non-zero rank over Q(T).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0924}
{"prompt": "Rephrase the abstract of an article with title 'The interplay of university and industry through the FP5 network'.\n  To improve the quality of life in a modern society it is essential to reduce\nthe distance between basic research and applications, whose crucial roles in\nshaping today's society prompt us to seek their understanding. Existing studies\non this subject, however, have neglected the network character of the\ninteraction between university and industry. Here we use state-of-the-art\nnetwork theory methods to analyze this interplay in the so-called Framework\nProgramme--an initiative which sets out the priorities for the European Union's\nresearch and technological development. In particular we study in the 5th\nFramework Programme (FP5) the role played by companies and scientific\ninstitutions and how they contribute to enhance the relationship between\nresearch and industry. Our approach provides quantitative evidence that while\nfirms are size hierarchically organized, universities and research\norganizations keep the network from falling into pieces, paving the way for an\neffective knowledge transfer.\n\n", "human_text": "  To improve the quality of life in a modern society it is essential to reduce\nthe distance between basic research and applications, whose crucial roles in\nshaping today's society prompt us to seek their understanding. Existing studies\non this subject, however, have neglected the network character of the\ninteraction between university and industry. Here we use state-of-the-art\nnetwork theory methods to analyze this interplay in the so-called Framework\nProgramme--an initiative which sets out the priorities for the European Union's\nresearch and technological development. In particular we study in the 5th\nFramework Programme (FP5) the role played by companies and scientific\ninstitutions and how they contribute to enhance the relationship between\nresearch and industry. Our approach provides quantitative evidence that while\nfirms are size hierarchically organized, universities and research\norganizations keep the network from falling into pieces, paving the way for an\neffective knowledge transfer.\n", "machine_text": "\nIn order to develop a strong economy and maintain a high quality of life, bridging the gap between theory and practical application is essential. Previous studies on this issue, however, have not explored the interplay between university and industry using a network perspective. To fill this gap, we applied the latest network theory methods to study the impact of the 5th Framework Programme of the European Union research and technological advances. Specifically, we analysed the role of companies and scientific institutions to strengthen the link between research and industry. Our results provide quantitative evidence that, despite firms being hierarchically structured by size, universities and research organisations keep the network connected, providing an effective knowledge transfer.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0353}
{"prompt": "Rephrase the abstract of an article with title 'The 74MHz System on the Very Large Array'.\n  The Naval Research Laboratory and the National Radio Astronomy Observatory\ncompleted implementation of a low frequency capability on the VLA at 73.8 MHz\nin 1998. This frequency band offers unprecedented sensitivity (~25 mJy/beam)\nand resolution (~25 arcsec) for low-frequency observations. We review the\nhardware, the calibration and imaging strategies, comparing them to those at\nhigher frequencies, including aspects of interference excision and wide-field\nimaging. Ionospheric phase fluctuations pose the major difficulty in\ncalibrating the array. Over restricted fields of view or at times of extremely\nquiescent ionospheric ``weather'', an angle-invariant calibration strategy can\nbe used. In this approach a single phase correction is devised for each\nantenna, typically via self-calibration. Over larger fields of view or at times\nof more normal ionospheric ``weather'' when the ionospheric isoplanatic patch\nsize is smaller than the field of view, we adopt a field-based strategy in\nwhich the phase correction depends upon location within the field of view. This\nsecond calibration strategy was implemented by modeling the ionosphere above\nthe array using Zernike polynomials. Images of 3C sources of moderate strength\nare provided as examples of routine, angle-invariant calibration and imaging.\nFlux density measurements indicate that the 74 MHz flux scale at the VLA is\nstable to a few percent, and tied to the Baars et al. value of Cygnus A at the\n5 percent level. We also present an example of a wide-field image, devoid of\nbright objects and containing hundreds of weaker sources, constructed from the\nfield-based calibration. We close with a summary of lessons the 74 MHz system\noffers as a model for new and developing low-frequency telescopes. (Abridged)\n\n", "human_text": "  The Naval Research Laboratory and the National Radio Astronomy Observatory\ncompleted implementation of a low frequency capability on the VLA at 73.8 MHz\nin 1998. This frequency band offers unprecedented sensitivity (~25 mJy/beam)\nand resolution (~25 arcsec) for low-frequency observations. We review the\nhardware, the calibration and imaging strategies, comparing them to those at\nhigher frequencies, including aspects of interference excision and wide-field\nimaging. Ionospheric phase fluctuations pose the major difficulty in\ncalibrating the array. Over restricted fields of view or at times of extremely\nquiescent ionospheric ``weather'', an angle-invariant calibration strategy can\nbe used. In this approach a single phase correction is devised for each\nantenna, typically via self-calibration. Over larger fields of view or at times\nof more normal ionospheric ``weather'' when the ionospheric isoplanatic patch\nsize is smaller than the field of view, we adopt a field-based strategy in\nwhich the phase correction depends upon location within the field of view. This\nsecond calibration strategy was implemented by modeling the ionosphere above\nthe array using Zernike polynomials. Images of 3C sources of moderate strength\nare provided as examples of routine, angle-invariant calibration and imaging.\nFlux density measurements indicate that the 74 MHz flux scale at the VLA is\nstable to a few percent, and tied to the Baars et al. value of Cygnus A at the\n5 percent level. We also present an example of a wide-field image, devoid of\nbright objects and containing hundreds of weaker sources, constructed from the\nfield-based calibration. We close with a summary of lessons the 74 MHz system\noffers as a model for new and developing low-frequency telescopes. (Abridged)\n", "machine_text": "\nThis paper reviews the implementation of a low frequency capability on the Very Large Array at 73.8 MHz and its associated hardware, calibration and imaging strategies. Challenges associated with ionospheric phase fluctuation calibration are discussed, as well as strategies for addressing them - angle-invariant and field-based. Examples of routine angle-invariant calibration and imaging are provided, along with a flux density measure of the VLA's 74 MHz flux scale stability and an example of a wide-field image from the field-based calibration. Finally, the paper sumarizes the lessons the 74MHz system offers for new and developing low-frequency telescopes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3088}
