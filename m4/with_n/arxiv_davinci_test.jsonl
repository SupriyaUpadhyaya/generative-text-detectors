{"prompt": "Rephrase the abstract of an article with title 'Physical and Spectral Characteristics of the T8 and Later-Type Dwarfs'.\n  We use new and published near-IR spectra, with synthetic spectra, to derive\nphysical properties of three of the latest-type T dwarfs. A new R~1700 spectrum\nof the T7.5 dwarf HD 3651B, with existing data, allows a detailed comparison to\nthe well-studied and very similar dwarf, Gl 570D. We find that HD 3651B has\nboth higher gravity and metallicity than Gl 570D, with Teff=820-830K, log g=\n5.4-5.5, [m/H]= +0.2 and Kzz=10^4cm^2/s. Its age is 8-12 Gyr and its implied\nmass is 60-70 M_Jup. We perform a similar analyis of the T8 and T7.5 dwarfs\n2MASS J09393548-2448279 and 2MASS J11145133-2618235 using published data,\ncomparing them to the well-studied T8, 2MASS J04151954-0935066. We find that\nthe two dwarfs have the same Teff as the reference dwarf, and similar\ngravities, but lower metallicities. The parameters are Teff=725-775K and [m/H]=\n-0.3; log g=5.3-5.45 for 2MASS J09393548-2448279 and log g=5.0-5.3 for 2MASS\nJ11145133- 261823. The age and mass are ~10Gyr and 60M_Jup for 2MASS\nJ09393548-2448279, and ~5 Gyr and 40M_Jup for 2MASS J11145133-261823. A serious\nlimitation is the incompleteness of the line lists of CH4 and NH3 at lambda\n<1.7um. Spectra of Saturn and Jupiter, and of laboratory CH4 and NH3 gas,\nsuggest that NH3 features in the Y- and J-bands may be useful as indicators of\nthe next cooler spectral type, and not features in the H- and K-bands as\npreviously thought. However large uncertainties remain, as the abundance of NH3\nis likely to be significantly below the chemical equilibrium value, and\ninclusion of laboratory NH3 opacities predicts band shapes that are discrepant\nwith existing data. It is possible that the T spectral class will have to be\nextended to low temperatures around 400K, when water clouds condense in the\natmosphere [abridged].\n\n", "human_text": "  We use new and published near-IR spectra, with synthetic spectra, to derive\nphysical properties of three of the latest-type T dwarfs. A new R~1700 spectrum\nof the T7.5 dwarf HD 3651B, with existing data, allows a detailed comparison to\nthe well-studied and very similar dwarf, Gl 570D. We find that HD 3651B has\nboth higher gravity and metallicity than Gl 570D, with Teff=820-830K, log g=\n5.4-5.5, [m/H]= +0.2 and Kzz=10^4cm^2/s. Its age is 8-12 Gyr and its implied\nmass is 60-70 M_Jup. We perform a similar analyis of the T8 and T7.5 dwarfs\n2MASS J09393548-2448279 and 2MASS J11145133-2618235 using published data,\ncomparing them to the well-studied T8, 2MASS J04151954-0935066. We find that\nthe two dwarfs have the same Teff as the reference dwarf, and similar\ngravities, but lower metallicities. The parameters are Teff=725-775K and [m/H]=\n-0.3; log g=5.3-5.45 for 2MASS J09393548-2448279 and log g=5.0-5.3 for 2MASS\nJ11145133- 261823. The age and mass are ~10Gyr and 60M_Jup for 2MASS\nJ09393548-2448279, and ~5 Gyr and 40M_Jup for 2MASS J11145133-261823. A serious\nlimitation is the incompleteness of the line lists of CH4 and NH3 at lambda\n<1.7um. Spectra of Saturn and Jupiter, and of laboratory CH4 and NH3 gas,\nsuggest that NH3 features in the Y- and J-bands may be useful as indicators of\nthe next cooler spectral type, and not features in the H- and K-bands as\npreviously thought. However large uncertainties remain, as the abundance of NH3\nis likely to be significantly below the chemical equilibrium value, and\ninclusion of laboratory NH3 opacities predicts band shapes that are discrepant\nwith existing data. It is possible that the T spectral class will have to be\nextended to low temperatures around 400K, when water clouds condense in the\natmosphere [abridged].\n", "machine_text": "We have studied the physical and spectral characteristics of three late T-type dwarfs, HD 3651B, 2MASS J09393548-2448279, and 2MASS J11145133-2618235. By comparing these sources to the well-known T8, 2MASS J04151954-0935066, we were able to determine the effective temperatures, gravities, and metallicities of a T7.5 and two T8 dwarfs. We found that the T7.5, HD 3651B, had Teff=820-830K, log g=5.4-5.5, and [m/H]=+0.2, with an age of 8-12 Gyr and an implied mass of 60-70 M_Jup. The two T8s and 2MASS J04151954-0935066 had similar effective temperatures, but lower metallicities of [m/H]=-0.3. We derived ages and implied masses of ~10 Gyr and 60 M_Jup for 2MASS J09393548-2448279, and ~5 Gyr and 40 M_Jup for 2MASS J11145133-261823. Our results indicate that the inclusion of laboratory NH3 opacities may be useful in distinguishing between the very late type classes. However, there are currently still major uncertainties, as the abundance of NH3 is unclear, and may prove to be significantly lower than predicted by chemical equilibrium models. This may suggest that the T spectral class is extended to even cooler temperatures of around 400K [abridged].", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2602}
{"prompt": "Rephrase the abstract of an article with title 'Ongoing Galactic Accretion: Simulations and Observations of Condensed\n  Gas in Hot Halos'.\n  Ongoing accretion onto galactic disks has been recently theorized to progress\nvia the unstable cooling of the baryonic halo into condensed clouds. These\nclouds have been identified as analogous to the High-Velocity Clouds (HVCs)\nobserved in HI in our Galaxy. Here we compare the distribution of HVCs observed\naround our own Galaxy and extra-planar gas around the Andromeda galaxy to these\npossible HVC analogs in a simulation of galaxy formation that naturally\ngenerates these condensed clouds. We find a very good correspondence between\nthese observations and the simulation, in terms of number, angular size,\nvelocity distribution, overall flux and flux distribution of the clouds. We\nshow that condensed cloud accretion only accounts for ~ 0.2 M_solar / year of\nthe current overall Galactic accretion in the simulations. We also find that\nthe simulated halo clouds accelerate and become more massive as they fall\ntoward the disk. The parameter space of the simulated clouds is consistent with\nall of the observed HVC complexes that have distance constraints, except the\nMagellanic Stream which is known to have a different origin. We also find that\nnearly half of these simulated halo clouds would be indistinguishable from\nlower-velocity gas and that this effect is strongest further from the disk of\nthe galaxy, thus indicating a possible missing population of HVCs. These\nresults indicate that the majority of HVCs are consistent with being infalling,\ncondensed clouds that are a remnant of Galaxy formation.\n\n", "human_text": "  Ongoing accretion onto galactic disks has been recently theorized to progress\nvia the unstable cooling of the baryonic halo into condensed clouds. These\nclouds have been identified as analogous to the High-Velocity Clouds (HVCs)\nobserved in HI in our Galaxy. Here we compare the distribution of HVCs observed\naround our own Galaxy and extra-planar gas around the Andromeda galaxy to these\npossible HVC analogs in a simulation of galaxy formation that naturally\ngenerates these condensed clouds. We find a very good correspondence between\nthese observations and the simulation, in terms of number, angular size,\nvelocity distribution, overall flux and flux distribution of the clouds. We\nshow that condensed cloud accretion only accounts for ~ 0.2 M_solar / year of\nthe current overall Galactic accretion in the simulations. We also find that\nthe simulated halo clouds accelerate and become more massive as they fall\ntoward the disk. The parameter space of the simulated clouds is consistent with\nall of the observed HVC complexes that have distance constraints, except the\nMagellanic Stream which is known to have a different origin. We also find that\nnearly half of these simulated halo clouds would be indistinguishable from\nlower-velocity gas and that this effect is strongest further from the disk of\nthe galaxy, thus indicating a possible missing population of HVCs. These\nresults indicate that the majority of HVCs are consistent with being infalling,\ncondensed clouds that are a remnant of Galaxy formation.\n", "machine_text": "This article explores the concept of galactic accretion continuing through the cooling of the baryonic halo, with the condensed clouds formed being comparable with the High-Velocity Clouds (HVCs) observed in the neutral hydrogen around our Galaxy. Results are compared between the simulation of galaxy formation and the observations of HVCs and the extra-planar gas around the Andromeda galaxy. The simulation supports the accretion of the clouds only accounting for ~ 0.2 M_solar / year of the overall galactic accretion. Additionally, the simulation indicates that lower-velocity gas can mask a portion of the clouds, indicating there may be a population of HVCs that is currently unidentified. These discoveries suggest that the majority of HVCs are created as a leftover from Galaxy formation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0357}
{"prompt": "Rephrase the abstract of an article with title 'Mass spectrum of diquarks and mesons in the color--flavor locked phase\n  of dense quark matter'.\n  The spectrum of meson and diquark excitations of dense quark matter is\nconsidered in the framework of the Nambu -- Jona-Lasinio model with three types\nof massless quarks in the presense of a quark number chemical potential $\\mu$.\nWe investigate the effective action of meson- and diquark fields both at\nsufficiently large values of $\\mu>\\mu_c\\approx 330$ MeV, where the\ncolor--flavor locked (CFL) phase is realized, and in the chirally broken phase\nof quark matter ($\\mu<\\mu_c$). In the last case all nine pseudoscalar mesons\nare Nambu -- Goldstone (NG) bosons, whereas the mass of the scalar meson nonet\nis twice the dynamical quark mass. In the chirally broken phase the\npseudoscalar diquarks are not allowed to exist as stable particles, but the\nscalar diquarks might be stable only at a rather strong interaction in the\ndiquark channel. In the case of the CFL phase, all NG bosons of the model are\nrealized as scalar and pseudoscalar diquarks. Moreover, it turns out that\nmassive diquark excitations are unstable for this phase. In particular, for the\nscalar and pseudoscalar octets of diquark resonances a mass value around 230\nMeV was found numerically. In contrast, mesons are stable particles in the CFL\nphase. Their masses lie in the interval 400$\\div$500 MeV for not too large\nvalues of $\\mu>\\mu_c$.\n\n", "human_text": "  The spectrum of meson and diquark excitations of dense quark matter is\nconsidered in the framework of the Nambu -- Jona-Lasinio model with three types\nof massless quarks in the presense of a quark number chemical potential $\\mu$.\nWe investigate the effective action of meson- and diquark fields both at\nsufficiently large values of $\\mu>\\mu_c\\approx 330$ MeV, where the\ncolor--flavor locked (CFL) phase is realized, and in the chirally broken phase\nof quark matter ($\\mu<\\mu_c$). In the last case all nine pseudoscalar mesons\nare Nambu -- Goldstone (NG) bosons, whereas the mass of the scalar meson nonet\nis twice the dynamical quark mass. In the chirally broken phase the\npseudoscalar diquarks are not allowed to exist as stable particles, but the\nscalar diquarks might be stable only at a rather strong interaction in the\ndiquark channel. In the case of the CFL phase, all NG bosons of the model are\nrealized as scalar and pseudoscalar diquarks. Moreover, it turns out that\nmassive diquark excitations are unstable for this phase. In particular, for the\nscalar and pseudoscalar octets of diquark resonances a mass value around 230\nMeV was found numerically. In contrast, mesons are stable particles in the CFL\nphase. Their masses lie in the interval 400$\\div$500 MeV for not too large\nvalues of $\\mu>\\mu_c$.\n", "machine_text": "\nThe Nambu--Jona-Lasinio model, with three types of massless quarks in a quark number chemical potential $\\mu$, is used to study the spectrum of mass excitations of meson and diquark in both the color--flavor locked (CFL) phase of quark matter, for sufficiently large values of $\\mu > \\mu_c \\approx 330 \\ \\text{MeV}$, and in the chirally broken phase, for $\\mu < \\mu_c$. When the quark matter is in the chirally broken state, all nine pseudoscalar mesons appear as Nambu--Goldstone bosons and the scalar meson nonet has twice the mass of their corresponding dynamical quark mass. It was found, in the chirally broken state, that the pseudoscalar diquarks have no stable particles, but the scalar diquarks may be stable if the interaction within the diquark channel is very strong. In the CFL phase, all Nambu--Goldstone bosons, both scalar and pseudoscalar, appear as diquark excitations. However, too large a mass is found for these diquark resonances, with a mass value of 230 MeV. On the contrary, mesons in the CFL phase were found to be stable particles with a mass interval of 400 to 500 MeV, for $\\mu > \\mu_c$. This research probes into the masses of meson and diquark excitations in dense quark matter in the CFL and chirally broken phases.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2666}
{"prompt": "Rephrase the abstract of an article with title 'On the Origin of the Dichotomy of Early-Type Galaxies: The Role of Dry\n  Mergers and AGN Feedback'.\n  Using a semi-analytical model for galaxy formation, combined with a large\nN-body simulation, we investigate the origin of the dichotomy among early-type\ngalaxies. We find that boxy galaxies originate from mergers with a progenitor\nmass ratio $n < 2$ and with a combined cold gas mass fraction $F_{\\rm cold} <\n0.1$. Our model accurately reproduces the observed fraction of boxy systems as\na function of luminosity and halo mass, for both central galaxies and\nsatellites. After correcting for the stellar mass dependence, the properties of\nthe last major merger of early-type galaxies are independent of their halo\nmass. This provides theoretical support for the conjecture of Pasquali et al\n(2007) that the stellar mass of an early-type galaxy is the main parameter that\ngoverns its isophotal shape. We argue that the observed dichotomy of early-type\ngalaxies has a natural explanation within hierarchical structure formation, and\ndoes not require AGN feedback. Rather, we argue that it owes to the fact that\nmore massive systems (i) have more massive progenitors, (ii) assemble later,\nand (iii) have a larger fraction of early-type progenitors. Each of these three\ntrends causes the cold gas mass fraction of the progenitors of more massive\nearly-types to be lower, so that their last major merger was dryer. Finally,\nour model predicts that (i) less than 10 percent of all early-type galaxies\nform in major mergers that involve two early-type progenitors, (ii) more than\n95 percent of all boxy early-type galaxies with $M_* < 2 \\times 10^{10} h^{-1}\n\\Msun$ are satellite galaxies, and (iii) about 70 percent of all low mass\nearly-types do not form a supermassive black hole binary at their last major\nmerger. The latter may help to explain why low mass early-types have central\ncusps, while their massive counterparts have cores.\n\n", "human_text": "  Using a semi-analytical model for galaxy formation, combined with a large\nN-body simulation, we investigate the origin of the dichotomy among early-type\ngalaxies. We find that boxy galaxies originate from mergers with a progenitor\nmass ratio $n < 2$ and with a combined cold gas mass fraction $F_{\\rm cold} <\n0.1$. Our model accurately reproduces the observed fraction of boxy systems as\na function of luminosity and halo mass, for both central galaxies and\nsatellites. After correcting for the stellar mass dependence, the properties of\nthe last major merger of early-type galaxies are independent of their halo\nmass. This provides theoretical support for the conjecture of Pasquali et al\n(2007) that the stellar mass of an early-type galaxy is the main parameter that\ngoverns its isophotal shape. We argue that the observed dichotomy of early-type\ngalaxies has a natural explanation within hierarchical structure formation, and\ndoes not require AGN feedback. Rather, we argue that it owes to the fact that\nmore massive systems (i) have more massive progenitors, (ii) assemble later,\nand (iii) have a larger fraction of early-type progenitors. Each of these three\ntrends causes the cold gas mass fraction of the progenitors of more massive\nearly-types to be lower, so that their last major merger was dryer. Finally,\nour model predicts that (i) less than 10 percent of all early-type galaxies\nform in major mergers that involve two early-type progenitors, (ii) more than\n95 percent of all boxy early-type galaxies with $M_* < 2 \\times 10^{10} h^{-1}\n\\Msun$ are satellite galaxies, and (iii) about 70 percent of all low mass\nearly-types do not form a supermassive black hole binary at their last major\nmerger. The latter may help to explain why low mass early-types have central\ncusps, while their massive counterparts have cores.\n", "machine_text": "\nWe present evidence that the dichotomy among early-type galaxies originates from hierarchical cosmic structure formation and is not driven by AGN feedback. Combining semi-analytical modelling with a large N-body simulation, we show that boxy galaxies are generated via mergers between progenitor galaxies with a mass ratio $n<2$ and a combined cold gas mass fraction $F_{\\rm cold}<0.1$. Our model accurately reproduces the observed fraction of boxy systems situated within a wide range of stellar luminosities and halo mass for both central galaxies and satellites. After accounting for stellar mass dependence, the characteristics of the most recent major merger of early-type galaxies proves to be independent from their halo mass. This supports the idea set forth in Pasquali et al. (2007) that a galaxy's isophotal shape is chiefly affected by its stellar mass. Furthermore, our model predicts that less than 10 percent of all early-type galaxies form in major mergers between two early-type galaxies, that more than 95 percent of all boxy early-type galaxies with stellar mass $M_* < 2 \\times 10^{10} h^{-1} \\Msun$ are satellites, and that roughly 70% of small mass early-type galaxies do not create supermassive black hole binaries in their last major merger. This may explain why low mass early-types have central cusps compared to the cores found in more massive galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0932}
{"prompt": "Rephrase the abstract of an article with title 'Covering Homology'.\n  We introduce the notion of \"covering homology\" of a commutative ring spectrum\nwith respect to certain families of coverings of topological spaces. The\nconstruction of covering homology is extracted from Bokstedt, Hsiang and\nMadsen's topological cyclic homology. In fact covering homology with respect to\nthe family of orientation preserving isogenies of the circle is equal to\ntopological cyclic homology.\n  Our basic tool for the analysis of covering homology is a cofibration\nsequence involving homotopy orbits and a restriction map similar to the\nrestriction map used in Bokstedt, Hsiang and Madsen's construction of\ntopological cyclic homology.\n  Covering homology with respect to families of isogenies of a torus is\nconstructed from iterated topological Hochschild homology. It receives a trace\nmap from iterated algebraic K-theory and the hope is that the rich structure,\nand the calculability of covering homology will make covering homology useful\nin the exploration of J. Rognes' ``red shift conjecture''.\n\n", "human_text": "  We introduce the notion of \"covering homology\" of a commutative ring spectrum\nwith respect to certain families of coverings of topological spaces. The\nconstruction of covering homology is extracted from Bokstedt, Hsiang and\nMadsen's topological cyclic homology. In fact covering homology with respect to\nthe family of orientation preserving isogenies of the circle is equal to\ntopological cyclic homology.\n  Our basic tool for the analysis of covering homology is a cofibration\nsequence involving homotopy orbits and a restriction map similar to the\nrestriction map used in Bokstedt, Hsiang and Madsen's construction of\ntopological cyclic homology.\n  Covering homology with respect to families of isogenies of a torus is\nconstructed from iterated topological Hochschild homology. It receives a trace\nmap from iterated algebraic K-theory and the hope is that the rich structure,\nand the calculability of covering homology will make covering homology useful\nin the exploration of J. Rognes' ``red shift conjecture''.\n", "machine_text": "\nWe propose an innovative method for analyzing homology with regards to coverings of topological spaces; namely, covering homology. This method is related to Bokstedt, Hsiang and Madsen's topological cyclic homology, and when used with a family of orientation preserving isogenies of the circle, yields the same results. We use a cofibration sequence coupled with a restriction map to study the covering homology. In addition, when the family is composed of isogenies of a torus, the concept of iterated topological Hochschild homology comes into play and the objective is to obtain an algebraic K-theory trace map. Our hope is that covering homology will be a useful tool in exploring J. Rognes' red shift conjecture.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0626}
{"prompt": "Rephrase the abstract of an article with title 'The Hot Inter-Galactic Medium and the Cosmic Microwave Background'.\n  The physical characteristics of the Lyman-alpha forest cloud systems are\ncombined with observations on the baryonic mass density of the Universe and\nconstraints from primordial nucleosynthesis to set boundary conditions on the\nIntergalactic Medium (IGM) at the epoch of z=2.5. The Universe is considered a\nclosed system and allowed to expand adiabatically from the epoch when QSOs\nfirst ionized the IGM (5 <= z_on <= 20). The average kinetic energy of a gas is\ncalculated in the region where the gas transitions from relativistic to\nnon-relativistic behavior. All of the above measurements are then used to\ndetermine the thermal history of the IGM in the redshift range 2.5 <= z <=\nz_on. The hot IGM is assumed to inverse Compton scatter photons from the Cosmic\nMicrowave Background (CMBR) and consequently distort the CMBR as seen at the\npresent epoch. The temperature of the IGM at z=2.5 and the epoch z_on are\nadjusted, within the constraints defined above, to give the best overall\nagreement with published data on the temperature of the IGM. We find that the\nmodel of the IGM proposed here does not grossly distort the CMBR, and in fact\nagrees quite closely with the preliminary results from the Cosmic Background\nExplorer (COBE) satellite. However, our model of the IGM cannot explain the\nobserved cosmic x ray background.\n  This paper was originally written in 1990. It was never submitted for\npublication.\n\n", "human_text": "  The physical characteristics of the Lyman-alpha forest cloud systems are\ncombined with observations on the baryonic mass density of the Universe and\nconstraints from primordial nucleosynthesis to set boundary conditions on the\nIntergalactic Medium (IGM) at the epoch of z=2.5. The Universe is considered a\nclosed system and allowed to expand adiabatically from the epoch when QSOs\nfirst ionized the IGM (5 <= z_on <= 20). The average kinetic energy of a gas is\ncalculated in the region where the gas transitions from relativistic to\nnon-relativistic behavior. All of the above measurements are then used to\ndetermine the thermal history of the IGM in the redshift range 2.5 <= z <=\nz_on. The hot IGM is assumed to inverse Compton scatter photons from the Cosmic\nMicrowave Background (CMBR) and consequently distort the CMBR as seen at the\npresent epoch. The temperature of the IGM at z=2.5 and the epoch z_on are\nadjusted, within the constraints defined above, to give the best overall\nagreement with published data on the temperature of the IGM. We find that the\nmodel of the IGM proposed here does not grossly distort the CMBR, and in fact\nagrees quite closely with the preliminary results from the Cosmic Background\nExplorer (COBE) satellite. However, our model of the IGM cannot explain the\nobserved cosmic x ray background.\n  This paper was originally written in 1990. It was never submitted for\npublication.\n", "machine_text": "\nBy examining observations of the baryonic mass density of the Universe, the Lyman-alpha forest cloud systems, and principles of primordial nucleosynthesis, this paper sets up boundary conditions for the Intergalactic Medium (IGM) at the epoch of z=2.5. Considering the Universe as a closed system and allowing it to expand adiabatically since the time when Quasi-Stellar Objects first ionized the IGM (5<=z_on<=20), the average kinetic energy of gas in the region transitioning to non-relativistic behavior is calculated. Combining all of these measurements, the thermal history of the IGM in the redshift range of 2.5<=z<=z_on is determined. This model also assumes that the hot IGM will inverse Compton scatter photons from the Cosmic Microwave Background, thus distorting it. When comparing this model to data from the Cosmic Background Explorer Satellite, there is a close agreement with the CMBR temperature. Unfortunately, this model does not explain the observed cosmic x-ray background. This paper has never been submitted for publication, and was originally written in 1990.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0063}
{"prompt": "Rephrase the abstract of an article with title 'Physical instrumental vetoes for gravitational-wave burst triggers'.\n  We present a robust strategy to \\emph{veto} certain classes of instrumental\nglitches that appear at the output of interferometric gravitational-wave (GW)\ndetectors.This veto method is `physical' in the sense that, in order to veto a\nburst trigger, we make use of our knowledge of the coupling of different\ndetector subsystems to the main detector output. The main idea behind this\nmethod is that the noise in an instrumental channel X can be \\emph{transferred}\nto the detector output (channel H) using the \\emph{transfer function} from X to\nH, provided the noise coupling is \\emph{linear} and the transfer function is\n\\emph{unique}. If a non-stationarity in channel H is causally related to one in\nchannel X, the two have to be consistent with the transfer function. We\nformulate two methods for testing the consistency between the burst triggers in\nchannel X and channel H. One method makes use of the \\emph{null-stream}\nconstructed from channel H and the \\emph{transferred} channel X, and the second\ninvolves cross-correlating the two. We demonstrate the efficiency of the veto\nby `injecting' instrumental glitches in the hardware of the GEO 600 detector.\nThe \\emph{veto safety} is demonstrated by performing GW-like hardware\ninjections. We also show an example application of this method using 5 days of\ndata from the fifth science run of GEO 600. The method is found to have very\nhigh veto efficiency with a very low accidental veto rate.\n\n", "human_text": "  We present a robust strategy to \\emph{veto} certain classes of instrumental\nglitches that appear at the output of interferometric gravitational-wave (GW)\ndetectors.This veto method is `physical' in the sense that, in order to veto a\nburst trigger, we make use of our knowledge of the coupling of different\ndetector subsystems to the main detector output. The main idea behind this\nmethod is that the noise in an instrumental channel X can be \\emph{transferred}\nto the detector output (channel H) using the \\emph{transfer function} from X to\nH, provided the noise coupling is \\emph{linear} and the transfer function is\n\\emph{unique}. If a non-stationarity in channel H is causally related to one in\nchannel X, the two have to be consistent with the transfer function. We\nformulate two methods for testing the consistency between the burst triggers in\nchannel X and channel H. One method makes use of the \\emph{null-stream}\nconstructed from channel H and the \\emph{transferred} channel X, and the second\ninvolves cross-correlating the two. We demonstrate the efficiency of the veto\nby `injecting' instrumental glitches in the hardware of the GEO 600 detector.\nThe \\emph{veto safety} is demonstrated by performing GW-like hardware\ninjections. We also show an example application of this method using 5 days of\ndata from the fifth science run of GEO 600. The method is found to have very\nhigh veto efficiency with a very low accidental veto rate.\n", "machine_text": "\nThis paper introduces a physical strategy to veto different types of instrumental glitches that may appear in the output of interferometric gravitational-wave (GW) detectors. We make use of the knowledge of the linear coupling of different subsystems to the primary output to transfer certain noise from an instrumental channel (X) to the detector output (H). Our proposed methods test the consistency between the bursts in channel X and the transferred channel H by constructing a null-stream, and cross-correlating the two. Our demonstration of the veto efficiency and safety was conducted by 'injecting' instrumental glitches in actual hardware of the GEO 600 detector, as well as performing GW-like hardware injections. Using 5 days of data from the fifth science run of GEO 600, the veto was found to display a high level of efficiency with low chances of accidental veto.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1111}
{"prompt": "Rephrase the abstract of an article with title 'Distance to Orion KL Measured with VERA'.\n  We present the initial results of multi-epoch VLBI observations of the 22 GHz\nH2O masers in the Orion KL region with VERA (VLBI Exploration of Radio\nAstrometry). With the VERA dual-beam receiving system, we have carried out\nphase-referencing VLBI astrometry and successfully detected an annual parallax\nof Orion KL to be 2.29+/-0.10 mas, corresponding to the distance of 437+/-19 pc\nfrom the Sun. The distance to Orion KL is determined for the first time with\nthe annual parallax method in these observations. Although this value is\nconsistent with that of the previously reported, 480+/-80 pc, which is\nestimated from the statistical parallax method using proper motions and radial\nvelocities of the H2O maser features, our new results provide the much more\naccurate value with an uncertainty of only 4%. In addition to the annual\nparallax, we have detected an absolute proper motion of the maser feature,\nsuggesting an outflow motion powered by the radio source I along with the\nsystematic motion of source I itself.\n\n", "human_text": "  We present the initial results of multi-epoch VLBI observations of the 22 GHz\nH2O masers in the Orion KL region with VERA (VLBI Exploration of Radio\nAstrometry). With the VERA dual-beam receiving system, we have carried out\nphase-referencing VLBI astrometry and successfully detected an annual parallax\nof Orion KL to be 2.29+/-0.10 mas, corresponding to the distance of 437+/-19 pc\nfrom the Sun. The distance to Orion KL is determined for the first time with\nthe annual parallax method in these observations. Although this value is\nconsistent with that of the previously reported, 480+/-80 pc, which is\nestimated from the statistical parallax method using proper motions and radial\nvelocities of the H2O maser features, our new results provide the much more\naccurate value with an uncertainty of only 4%. In addition to the annual\nparallax, we have detected an absolute proper motion of the maser feature,\nsuggesting an outflow motion powered by the radio source I along with the\nsystematic motion of source I itself.\n", "machine_text": "\nUsing VERA (VLBI Exploration of Radio Astrometry), multi-epoch VLBI observations of the 22GHz H2O masers in the Orion KL region were initially examined. Through phase-referencing VLBI astrometry, a yearly parallax of 2.29+/-0.10 mas was observed, leading to a distance calculation of 437+/-19 pc from the Sun. Although this is in agreement with the previously established 480+/-80 pc, our results are more accurate with a lower uncertainty of 4%. Furthermore, an absolute proper motion was uncovered indicating a combination of an outflow motion associated with source I and its own systematic motion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3792}
{"prompt": "Rephrase the abstract of an article with title 'HST/ACS Coronagraphic Observations of the Dust Surrounding HD 100546'.\n  We present ACS/HST coronagraphic observations of HD 100546, a B9.5 star, 103\npc away from the sun, taken in the F435W, F606W, and F814W bands. Scattered\nlight is detected up to 14'' from the star. The observations are consistent\nwith the presence of an extended flattened nebula with the same inclination as\nthe inner disk. The well-known ``spiral arms'' are clearly observed and they\ntrail the rotating disk material. Weaker arms never before reported are also\nseen. The inter-arm space becomes brighter, but the structures become more\nneutral in color at longer wavelengths, which is not consistent with models\nthat assume that they are due to the effects of a warped disk. Along the major\ndisk axis, the colors of the scattered-light relative to the star are \\Delta\n(F435W-F606W) ~ 0.0--0.2 mags and \\Delta (F435W-F814W)~0.5--1 mags. To explain\nthese colors, we explore the role of asymmetric scattering, reddening, and\nlarge minimum sizes on ISM-like grains. We conclude each of these hypotheses by\nitself cannot explain the colors. The disk colors are similar to those derived\nfor Kuiper Belt objects, suggesting that the same processes responsible for\ntheir colors may be at work here. We argue that we are observing only the\ngeometrically thick, optically thin envelope of the disk, while the optically\nthick disk responsible for the far-IR emission is undetected. The observed\nspiral arms are then structures on this envelope. The colors indicate that the\nextended nebulosity is not a remnant of the infalling envelope but reprocessed\ndisk material.\n\n", "human_text": "  We present ACS/HST coronagraphic observations of HD 100546, a B9.5 star, 103\npc away from the sun, taken in the F435W, F606W, and F814W bands. Scattered\nlight is detected up to 14'' from the star. The observations are consistent\nwith the presence of an extended flattened nebula with the same inclination as\nthe inner disk. The well-known ``spiral arms'' are clearly observed and they\ntrail the rotating disk material. Weaker arms never before reported are also\nseen. The inter-arm space becomes brighter, but the structures become more\nneutral in color at longer wavelengths, which is not consistent with models\nthat assume that they are due to the effects of a warped disk. Along the major\ndisk axis, the colors of the scattered-light relative to the star are \\Delta\n(F435W-F606W) ~ 0.0--0.2 mags and \\Delta (F435W-F814W)~0.5--1 mags. To explain\nthese colors, we explore the role of asymmetric scattering, reddening, and\nlarge minimum sizes on ISM-like grains. We conclude each of these hypotheses by\nitself cannot explain the colors. The disk colors are similar to those derived\nfor Kuiper Belt objects, suggesting that the same processes responsible for\ntheir colors may be at work here. We argue that we are observing only the\ngeometrically thick, optically thin envelope of the disk, while the optically\nthick disk responsible for the far-IR emission is undetected. The observed\nspiral arms are then structures on this envelope. The colors indicate that the\nextended nebulosity is not a remnant of the infalling envelope but reprocessed\ndisk material.\n", "machine_text": "\nUsing ACS/HST coronagraphic observations in the F435W, F606W, and F814W bands, we observe the dust surrounding HD 100546, a B9.5 star, 103 pc away from the Sun. Measurements out to a distance of 14'' are consistent with the presence of an extended, flat nebula that has the same inclination as the inner disk. The well-known ``spiral arms'' are clearly seen along with other fainter features that have not previously been reported. Interestingly, the brightness of the inter-arm space increases, but the colors of the structures become more neutral as the wavelengths increase, which is not predicted by models of a warped disk. We note a similarity between the colors of the disk and those seen in Kuiper Belt objects and explore a number of hypotheses to explain them, including asymmetric scattering, reddening, and large minimum sizes on ISM-like grains. We conclude that none of these theories can explain the colors alone and suggest that we are only seeing the optically thin envelope of the disk. The colors indicate that this nebulosity is not a remnant of the infalling envelope but reprocessed disk material.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1507}
{"prompt": "Rephrase the abstract of an article with title 'Clustering of Lyman alpha emitters at z ~ 4.5'.\n  We present the clustering properties of 151 Lyman alpha emitting galaxies at\nz ~ 4.5 selected from the Large Area Lyman Alpha (LALA) survey. Our catalog\ncovers an area of 36' x 36' observed with five narrowband filters. We assume\nthat the angular correlation function w(theta) is well represented by a power\nlaw A_w = Theta^(-beta) with slope beta = 0.8, and we find A_w = 6.73 +/- 1.80.\nWe then calculate the correlation length r_0 of the real-space two-point\ncorrelation function xi(r) = (r/r_0)^(-1.8) from A_w through the Limber\ntransformation, assuming a flat, Lambda-dominated universe. Neglecting\ncontamination, we find r_0 = 3.20 +/- 0.42 Mpc/h. Taking into account a\npossible 28% contamination by randomly distributed sources, we find r_0 = 4.61\n+/- 0.6 Mpc/h. We compare these results with the expectations for the\nclustering of dark matter halos at this redshift in a Cold Dark Matter model,\nand find that the measured clustering strength can be reproduced if these\nobjects reside in halos with a minimum mass of 1-2 times 10^11 Solar masses/h.\nOur estimated correlation length implies a bias of b ~ 3.7, similar to that of\nLyman-break galaxies (LBG) at z ~ 3.8-4.9. However, Lyman alpha emitters are a\nfactor of ~ 2-16 rarer than LBGs with a similar bias value and implied host\nhalo mass. Therefore, one plausible scenario seems to be that Lyman alpha\nemitters occupy host halos of roughly the same mass as LBGs, but shine with a\nrelatively low duty cycle of 6-50%.\n\n", "human_text": "  We present the clustering properties of 151 Lyman alpha emitting galaxies at\nz ~ 4.5 selected from the Large Area Lyman Alpha (LALA) survey. Our catalog\ncovers an area of 36' x 36' observed with five narrowband filters. We assume\nthat the angular correlation function w(theta) is well represented by a power\nlaw A_w = Theta^(-beta) with slope beta = 0.8, and we find A_w = 6.73 +/- 1.80.\nWe then calculate the correlation length r_0 of the real-space two-point\ncorrelation function xi(r) = (r/r_0)^(-1.8) from A_w through the Limber\ntransformation, assuming a flat, Lambda-dominated universe. Neglecting\ncontamination, we find r_0 = 3.20 +/- 0.42 Mpc/h. Taking into account a\npossible 28% contamination by randomly distributed sources, we find r_0 = 4.61\n+/- 0.6 Mpc/h. We compare these results with the expectations for the\nclustering of dark matter halos at this redshift in a Cold Dark Matter model,\nand find that the measured clustering strength can be reproduced if these\nobjects reside in halos with a minimum mass of 1-2 times 10^11 Solar masses/h.\nOur estimated correlation length implies a bias of b ~ 3.7, similar to that of\nLyman-break galaxies (LBG) at z ~ 3.8-4.9. However, Lyman alpha emitters are a\nfactor of ~ 2-16 rarer than LBGs with a similar bias value and implied host\nhalo mass. Therefore, one plausible scenario seems to be that Lyman alpha\nemitters occupy host halos of roughly the same mass as LBGs, but shine with a\nrelatively low duty cycle of 6-50%.\n", "machine_text": "\nThis work presents the understanding of the clustering properties of Lyman alpha emitters at a redshift of 4.5, selected from the Large Area Lyman Alpha (LALA) survey. Our findings are based on an analyzed area of 36' x 36', which was observed with five narrowband filters and had an angular correlation function w(theta) fit to a power law with slope beta = 0.8. The Limber transformation, assuming a flat, Lambda-dominated universe, is used to calculate the correlation length r_0 of the real-space two-point correlation function xi(r) from the derived A_w value and discard any contamination, where r_0 = 3.20 +/- 0.42 Mpc/h. The measured clustering strength can be reproduced by Lyman alpha emitters residing in halos with a minimum mass of 1-2 times 10^11 Solar masses/h. The estimated correlation length implies a bias of b ~ 3.7 which is similar to that of Lyman-break galaxies at z ~ 3.8-4.9. However, Lyman alpha emitters are found to be a factor of ~ 2-16 rarer than LBGs. This leads to the possibility that Lyman alpha emitters may occupy host halos of approximately the same mass of LBGs, but shine with a relatively low duty cycle of 6-50%.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0893}
{"prompt": "Rephrase the abstract of an article with title 'Mixed-up trees: the structure of phylogenetic mixtures'.\n  In this paper we apply new geometric and combinatorial methods to the study\nof phylogenetic mixtures. The focus of the geometric approach is to describe\nthe geometry of phylogenetic mixture distributions for the two state random\ncluster model, which is a generalization of the two state symmetric (CFN)\nmodel. In particular, we show that the set of mixture distributions forms a\nconvex polytope and we calculate its dimension; corollaries include a simple\ncriterion for when a mixture of branch lengths on the star tree can mimic the\nsite pattern frequency vector of a resolved quartet tree. Furthermore, by\ncomputing volumes of polytopes we can clarify how ``common'' non-identifiable\nmixtures are under the CFN model. We also present a new combinatorial result\nwhich extends any identifiability result for a specific pair of trees of size\nsix to arbitrary pairs of trees. Next we present a positive result showing\nidentifiability of rates-across-sites models. Finally, we answer a question\nraised in a previous paper concerning ``mixed branch repulsion'' on trees\nlarger than quartet trees under the CFN model.\n\n", "human_text": "  In this paper we apply new geometric and combinatorial methods to the study\nof phylogenetic mixtures. The focus of the geometric approach is to describe\nthe geometry of phylogenetic mixture distributions for the two state random\ncluster model, which is a generalization of the two state symmetric (CFN)\nmodel. In particular, we show that the set of mixture distributions forms a\nconvex polytope and we calculate its dimension; corollaries include a simple\ncriterion for when a mixture of branch lengths on the star tree can mimic the\nsite pattern frequency vector of a resolved quartet tree. Furthermore, by\ncomputing volumes of polytopes we can clarify how ``common'' non-identifiable\nmixtures are under the CFN model. We also present a new combinatorial result\nwhich extends any identifiability result for a specific pair of trees of size\nsix to arbitrary pairs of trees. Next we present a positive result showing\nidentifiability of rates-across-sites models. Finally, we answer a question\nraised in a previous paper concerning ``mixed branch repulsion'' on trees\nlarger than quartet trees under the CFN model.\n", "machine_text": "This article examines how geometric and combinatorial methods can be used to gain greater insight into the structure of phylogenetic mixtures, a model which represents a generalization of the two-state symmetric model. We determine that the set of mixture distributions of this model form a convex polytope and calculate its dimension, offering a simple criterion for determining when a mixture of branch lengths can reproduce the frequency vector of a resolved quartet tree. Using calculations of polytope volumes, we can gain clarity on how common non-identifiable mixtures are under the symmetric model. We present a combinatorial result which extends identifiability results to all pairs of trees of size six or larger, and a positive showing of identifiability for rates across sites models. Lastly, we provide an answer to a previous inquiry into ``mixed-branch repulsion'' on trees larger than quartets under the symmetric model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4328}
{"prompt": "Rephrase the abstract of an article with title 'Quantum mechanical approach to decoherence and relaxation generated by\n  fluctuating environment'.\n  We consider an electrostatic qubit, interacting with a fluctuating charge of\nsingle electron transistor (SET) in the framework of exactly solvable model.\nThe SET plays a role of the fluctuating environment affecting the qubit's\nparameters in a controllable way. We derive the rate equations describing\ndynamics of the entire system for both weak and strong qubit-SET coupling.\nSolving these equation we obtain decoherence and relaxation rates of the qubit,\nas well as the spectral density of the fluctuating qubit's parameters. We found\nthat in the weak coupling regime the decoherence and relaxation rates are\ndirectly related to the spectral density taken at Rabi or at zero frequency,\ndepending on what a particular qubit's parameters is fluctuating. This relation\nholds also in the presence of weak back-action of the qubit on the fluctuating\nenvironment. In the case of strong back-action, such simple relationship no\nlonger holds, even if the qubit-SET coupling is small. It does not hold either\nin the strong-coupling regime, even in the absence of the back-action. In\naddition, we found that our model predicts localization of the qubit in the\nstrong-coupling regime, resembling that of the spin-boson model.\n\n", "human_text": "  We consider an electrostatic qubit, interacting with a fluctuating charge of\nsingle electron transistor (SET) in the framework of exactly solvable model.\nThe SET plays a role of the fluctuating environment affecting the qubit's\nparameters in a controllable way. We derive the rate equations describing\ndynamics of the entire system for both weak and strong qubit-SET coupling.\nSolving these equation we obtain decoherence and relaxation rates of the qubit,\nas well as the spectral density of the fluctuating qubit's parameters. We found\nthat in the weak coupling regime the decoherence and relaxation rates are\ndirectly related to the spectral density taken at Rabi or at zero frequency,\ndepending on what a particular qubit's parameters is fluctuating. This relation\nholds also in the presence of weak back-action of the qubit on the fluctuating\nenvironment. In the case of strong back-action, such simple relationship no\nlonger holds, even if the qubit-SET coupling is small. It does not hold either\nin the strong-coupling regime, even in the absence of the back-action. In\naddition, we found that our model predicts localization of the qubit in the\nstrong-coupling regime, resembling that of the spin-boson model.\n", "machine_text": "\nWe explore the effects of fluctuating environment on an electrostatic qubit through a model of single electron transistor (SET). We look into the dynamics of the qubit to determine its decoherence and relaxation rates, and the spectral density of its fluctuating parameters. In weak-coupled systems, we find the decoherence and relaxation rates are associated with the spectral density at the Rabi frequency or zero frequency depending on the parameter. Even with the back-action of the qubit, this correlation still occurs. In contrast, in strong coupling or when the back-action is strong, the correlation no longer holds. Our model also exhibits localization of the qubit, similar to that of the spin-boson model, when the coupling is strong.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0194}
{"prompt": "Rephrase the abstract of an article with title 'The time evolution of cosmological redshift as a test of dark energy'.\n  The variation of the expansion rate of the Universe with time produces an\nevolution in the cosmological redshift of distant sources (for example quasar\nLyman-$\\alpha$ absorption lines), that might be directly observed by future\nultra stable, high-resolution spectrographs (such as CODEX) coupled to\nextremely large telescopes (such as European Southern Observatory's Extremely\nLarge Telescope, ELT). This would open a new window to explore the physical\nmechanism responsible for the current acceleration of the Universe. We\ninvestigate the evolution of cosmological redshift from a variety of dark\nenergy models, and compare it with simulated data. We perform a Fisher matrix\nanalysis and discuss the prospects for constraining the parameters of these\nmodels and for discriminating among competing candidates. We find that, because\nof parameter degeneracies, and of the inherent technical difficulties involved\nin this kind of observations, the uncertainties on parameter reconstruction can\nbe rather large unless strong external priors are assumed. However, the method\ncould be a valuable complementary cosmological tool, and give important\ninsights on the dynamics of dark energy, not obtainable using other probes.\n\n", "human_text": "  The variation of the expansion rate of the Universe with time produces an\nevolution in the cosmological redshift of distant sources (for example quasar\nLyman-$\\alpha$ absorption lines), that might be directly observed by future\nultra stable, high-resolution spectrographs (such as CODEX) coupled to\nextremely large telescopes (such as European Southern Observatory's Extremely\nLarge Telescope, ELT). This would open a new window to explore the physical\nmechanism responsible for the current acceleration of the Universe. We\ninvestigate the evolution of cosmological redshift from a variety of dark\nenergy models, and compare it with simulated data. We perform a Fisher matrix\nanalysis and discuss the prospects for constraining the parameters of these\nmodels and for discriminating among competing candidates. We find that, because\nof parameter degeneracies, and of the inherent technical difficulties involved\nin this kind of observations, the uncertainties on parameter reconstruction can\nbe rather large unless strong external priors are assumed. However, the method\ncould be a valuable complementary cosmological tool, and give important\ninsights on the dynamics of dark energy, not obtainable using other probes.\n", "machine_text": "\nThis project seeks to explore the physics behind the observed accelerated expansion of the universe by studying the changing cosmological redshift of distant sources over time. With the help of ultra-stable and high-resolution spectrographs coupled to extremely large telescopes such as the ELT, future observation and analysis of the time-variant cosmological redshift could provide valuable insight into the nature of dark energy. Through use of a Fisher matrix analysis, this study looks at the possibility of constraining dark energy models with the time-varying cosmological redshift data, as well as discriminating between different models. The findings indicate that despite parameter degeneracies, assumptions of additional outside information could aide in narrowing the uncertainties of parameter reconstruction. Together with other cosmological tools, this method could serve as a useful secondary tool to better understand the dynamics of dark energy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.235}
{"prompt": "Rephrase the abstract of an article with title 'Analysis of Spitzer Spectra of Irradiated Planets: Evidence for Water\n  Vapor?'.\n  Published mid infrared spectra of transiting planets HD 209458b and HD\n189733b, obtained during secondary eclipse by the InfraRed Spectrograph (IRS)\naboard the Spitzer Space Telescope, are predominantly featureless. In\nparticular these flux ratio spectra do not exhibit an expected feature arising\nfrom water vapor absorption short-ward of 10 um. Here we suggest that, in the\nabsence of flux variability, the spectral data for HD 189733b are inconsistent\nwith 8 um-photometry obtained with Spitzer's InfraRed Array Camera (IRAC),\nperhaps an indication of problems with the challenging reduction of the IRS\nspectra. The IRAC point, along with previously published secondary eclipse\nphotometry for HD 189733b, are in good agreement with a one-dimensional model\nof HD 189733b that clearly shows absorption due to water vapor in the emergent\nspectrum. We are not able to draw firm conclusions regarding the IRS data for\nHD 209458b, but spectra predicted by 1D and 3D atmosphere models fit the data\nadequately, without adjustment of the water abundance or reliance on cloud\nopacity. We argue that the generally good agreement between model spectra and\nIRS spectra of brown dwarfs with atmospheric temperatures similar to these\nhighly irradiated planets lends confidence in the modeling procedure.\n\n", "human_text": "  Published mid infrared spectra of transiting planets HD 209458b and HD\n189733b, obtained during secondary eclipse by the InfraRed Spectrograph (IRS)\naboard the Spitzer Space Telescope, are predominantly featureless. In\nparticular these flux ratio spectra do not exhibit an expected feature arising\nfrom water vapor absorption short-ward of 10 um. Here we suggest that, in the\nabsence of flux variability, the spectral data for HD 189733b are inconsistent\nwith 8 um-photometry obtained with Spitzer's InfraRed Array Camera (IRAC),\nperhaps an indication of problems with the challenging reduction of the IRS\nspectra. The IRAC point, along with previously published secondary eclipse\nphotometry for HD 189733b, are in good agreement with a one-dimensional model\nof HD 189733b that clearly shows absorption due to water vapor in the emergent\nspectrum. We are not able to draw firm conclusions regarding the IRS data for\nHD 209458b, but spectra predicted by 1D and 3D atmosphere models fit the data\nadequately, without adjustment of the water abundance or reliance on cloud\nopacity. We argue that the generally good agreement between model spectra and\nIRS spectra of brown dwarfs with atmospheric temperatures similar to these\nhighly irradiated planets lends confidence in the modeling procedure.\n", "machine_text": "\nThe mid-infrared spectra taken by the InfraRed Spectrograph (IRS) aboard the Spitzer Space Telescope during secondary eclipse of two transiting planets, HD 209458b and HD 189733b, were featureless. While the spectra did not display the absorption expected from water vapor shortward of 10 \u03bcm, one-dimensional models of HD 189733b generated spectra showing absorption from water vapor. Spitzer's InfraRed Array Camera (IRAC) 8 \u03bcm photometry for HD 189733b, in addition to previously published secondary eclipse photometry for this planet, aligns with the model-generated spectra. As for HD 209458b, the model spectra are an adequate fit to the data, indicating that the water abundance does not need to be adjusted or cloud opacity taken into account. The agreement between model spectra and IRS spectra of brown dwarfs with similar temperatures to these highly irradiated planets confirms the accuracy of the modeling procedure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2457}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of the production of charged pions by protons on a tantalum\n  target'.\n  A measurement of the double-differential cross-section for the production of\ncharged pions in proton--tantalum collisions emitted at large angles from the\nincoming beam direction is presented. The data were taken in 2002 with the HARP\ndetector in the T9 beam line of the CERN PS. The pions were produced by proton\nbeams in a momentum range from 3 \\GeVc to 12 \\GeVc hitting a tantalum target\nwith a thickness of 5% of a nuclear interaction length. The angular and\nmomentum range covered by the experiment ($100 \\MeVc \\le p < 800 \\MeVc$ and\n$0.35 \\rad \\le \\theta <2.15 \\rad$) is of particular importance for the design\nof a neutrino factory. The produced particles were detected using a\nsmall-radius cylindrical time projection chamber (TPC) placed in a solenoidal\nmagnet. Track recognition, momentum determination and particle identification\nwere all performed based on the measurements made with the TPC. An elaborate\nsystem of detectors in the beam line ensured the identification of the incident\nparticles. Results are shown for the double-differential cross-sections\n${{\\mathrm{d}^2 \\sigma}} / {{\\mathrm{d}p\\mathrm{d}\\theta}}$ at four incident\nproton beam momenta (3 \\GeVc, 5 \\GeVc, 8 \\GeVc and 12 \\GeVc). In addition, the\npion yields within the acceptance of typical neutrino factory designs are shown\nas a function of beam momentum. The measurement of these yields within a single\nexperiment eliminates most systematic errors in the comparison between rates at\ndifferent beam momenta and between positive and negative pion production.\n\n", "human_text": "  A measurement of the double-differential cross-section for the production of\ncharged pions in proton--tantalum collisions emitted at large angles from the\nincoming beam direction is presented. The data were taken in 2002 with the HARP\ndetector in the T9 beam line of the CERN PS. The pions were produced by proton\nbeams in a momentum range from 3 \\GeVc to 12 \\GeVc hitting a tantalum target\nwith a thickness of 5% of a nuclear interaction length. The angular and\nmomentum range covered by the experiment ($100 \\MeVc \\le p < 800 \\MeVc$ and\n$0.35 \\rad \\le \\theta <2.15 \\rad$) is of particular importance for the design\nof a neutrino factory. The produced particles were detected using a\nsmall-radius cylindrical time projection chamber (TPC) placed in a solenoidal\nmagnet. Track recognition, momentum determination and particle identification\nwere all performed based on the measurements made with the TPC. An elaborate\nsystem of detectors in the beam line ensured the identification of the incident\nparticles. Results are shown for the double-differential cross-sections\n${{\\mathrm{d}^2 \\sigma}} / {{\\mathrm{d}p\\mathrm{d}\\theta}}$ at four incident\nproton beam momenta (3 \\GeVc, 5 \\GeVc, 8 \\GeVc and 12 \\GeVc). In addition, the\npion yields within the acceptance of typical neutrino factory designs are shown\nas a function of beam momentum. The measurement of these yields within a single\nexperiment eliminates most systematic errors in the comparison between rates at\ndifferent beam momenta and between positive and negative pion production.\n", "machine_text": "\nThis paper explores the double-differential cross-section for the production of charged pions generated when protons of momentum between 3 \\GeVc and 12 \\GeVc collide with a tantalum target of 5% nuclear interaction length. The 2002 data was collected with the HARP detector for the T9 line of the CERN PS, with tracks, momentum and particle identification conducted by measurements from the small-radius cylindrical time projection chamber (TPC) located in a solenoidal magnet. Results are displayed for four incident proton beam momenta, and for the generated pion yield coinciding with a neutrino factory design. Through these results, most systematic discrepancies between pion production and different beam momentum, as well as between positive and negative pions, are reduced.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.16}
{"prompt": "Rephrase the abstract of an article with title 'Rotation and activity of pre-main-sequence stars'.\n  We present a study of rotation (vsini) and chromospheric activity (Halpha EW)\nbased on an extensive set of high-resolution optical spectra obtained with MIKE\non the 6.5m Magellan Clay telescope. Our targets are 74 F-M dwarfs in the young\nstellar associations Eta Cha, TW Hydrae, Beta Pic, and Tuc-Hor, spanning ages\nfrom 6 to 30 Myr. While the Halpha EW for most F and G stars are consistent\nwith pure photospheric absorption, most K and M stars show chromospheric\nemission. By comparing Halpha EW in our sample to results in the literature, we\nsee a clear evolutionary sequence: Chromospheric activity declines steadily\nfrom the T Tauri phase to the main sequence. Using activity as an age\nindicator, we find a plausible age range for the Tuc-Hor association of 10-40\nMyr. Between 5 and 30 Myr, we do not see evidence for rotational braking in the\ntotal sample, thus angular momentum is conserved, in contrast to younger stars.\nThis difference indicates a change in the rotational regulation at 5-10 Myr,\npossibly because disk braking cannot operate longer than typical disk\nlifetimes, allowing the objects to spin up. The rotation-activity relation is\nflat in our sample; in contrast to main-sequence stars, there is no linear\ncorrelation for slow rotators. We argue that this is because young stars\ngenerate their magnetic fields in a fundamentally different way from\nmain-sequence stars, and not just the result of a saturated solar-type dynamo.\nBy comparing our rotational velocities with published rotation periods for a\nsubset of stars, we determine ages of 13 (7-20) Myr and 9 (7-17} Myr for the\nEta Cha and TWA associations, respectively, consistent with previous estimates.\nThus we conclude that stellar radii from evolutionary models by Baraffe et al.\n(1998) are in agreement with the observed radii within +-15%. (abridged)\n\n", "human_text": "  We present a study of rotation (vsini) and chromospheric activity (Halpha EW)\nbased on an extensive set of high-resolution optical spectra obtained with MIKE\non the 6.5m Magellan Clay telescope. Our targets are 74 F-M dwarfs in the young\nstellar associations Eta Cha, TW Hydrae, Beta Pic, and Tuc-Hor, spanning ages\nfrom 6 to 30 Myr. While the Halpha EW for most F and G stars are consistent\nwith pure photospheric absorption, most K and M stars show chromospheric\nemission. By comparing Halpha EW in our sample to results in the literature, we\nsee a clear evolutionary sequence: Chromospheric activity declines steadily\nfrom the T Tauri phase to the main sequence. Using activity as an age\nindicator, we find a plausible age range for the Tuc-Hor association of 10-40\nMyr. Between 5 and 30 Myr, we do not see evidence for rotational braking in the\ntotal sample, thus angular momentum is conserved, in contrast to younger stars.\nThis difference indicates a change in the rotational regulation at 5-10 Myr,\npossibly because disk braking cannot operate longer than typical disk\nlifetimes, allowing the objects to spin up. The rotation-activity relation is\nflat in our sample; in contrast to main-sequence stars, there is no linear\ncorrelation for slow rotators. We argue that this is because young stars\ngenerate their magnetic fields in a fundamentally different way from\nmain-sequence stars, and not just the result of a saturated solar-type dynamo.\nBy comparing our rotational velocities with published rotation periods for a\nsubset of stars, we determine ages of 13 (7-20) Myr and 9 (7-17} Myr for the\nEta Cha and TWA associations, respectively, consistent with previous estimates.\nThus we conclude that stellar radii from evolutionary models by Baraffe et al.\n(1998) are in agreement with the observed radii within +-15%. (abridged)\n", "machine_text": "\nWe investigate the correlations between rotation and activity during pre-main-sequence (PMS) stellar evolution by analyzing an extensive set of optically high-resolution spectra of 74 F-M dwarfs in a range of young stellar associations ages 6 to 30 Myr. We observe a clear decline in chromospheric activity as the stars evolve from T Tauri to main sequence stars. Using activity as an age indicator and stellar radii from evolutionary models, we find a consistent age range of 10-40 Myr for the Tuc-Hor association, and 13 (7-20) and 9 (7-17) Myr for the Eta Cha and TWA associations, respectively. Our results indicate angular momentum is conserved between 5-30 Myr and that the rotation-activity relation for young stars is not correlated to lower-rotators like main-sequence stars, likely due to a different magnetic field generation mechanism. In short, we find observed stellar radii are in agreement with predicted radii within +/- 15% over this PMS evolutionary period.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3266}
{"prompt": "Rephrase the abstract of an article with title 'On Classification of Finite Dimensional Complex Filiform Leibniz\n  Algebras (Part 2)'.\n  The paper is devoted to classification problem of finite dimensional complex\nnone Lie filiform Leibniz algebras. Actually, the observations show there are\ntwo resources to get classification of filiform Leibniz algebras. The first of\nthem is naturally graded none Lie filiform Leibniz algebras and the another one\nis naturally graded filiform Lie algebras. Using the first resource we get two\ndisjoint classes of filiform Leibniz algebras. The present paper deals with the\nsecond of the above two classes, the first class has been considered in our\nprevious paper. The algebraic classification here means to specify the\nrepresentatives of the orbits, whereas the geometric classification is the\nproblem of finding generic structural constants in the sense of algebraic\ngeometry. Our main effort in this paper is the algebraic classification. We\nsuggest here an algebraic method based on invariants. Utilizing this method for\nany given low dimensional case all filiform Leibniz algebras can be classified.\nMoreover, the results can be used for geometric classification of orbits of\nsuch algebras.\n\n", "human_text": "  The paper is devoted to classification problem of finite dimensional complex\nnone Lie filiform Leibniz algebras. Actually, the observations show there are\ntwo resources to get classification of filiform Leibniz algebras. The first of\nthem is naturally graded none Lie filiform Leibniz algebras and the another one\nis naturally graded filiform Lie algebras. Using the first resource we get two\ndisjoint classes of filiform Leibniz algebras. The present paper deals with the\nsecond of the above two classes, the first class has been considered in our\nprevious paper. The algebraic classification here means to specify the\nrepresentatives of the orbits, whereas the geometric classification is the\nproblem of finding generic structural constants in the sense of algebraic\ngeometry. Our main effort in this paper is the algebraic classification. We\nsuggest here an algebraic method based on invariants. Utilizing this method for\nany given low dimensional case all filiform Leibniz algebras can be classified.\nMoreover, the results can be used for geometric classification of orbits of\nsuch algebras.\n", "machine_text": "This article is a continuation of our previous study on the classification of finite dimensional complex filiform Leibniz algebras. We explore two main resources in order to obtain a classification of these algebras: naturally graded none Lie filiform Leibniz algebras and naturally graded filiform Lie algebras. From the first resource, two distinct classes of filiform Leibniz algebras are identified. This paper focuses on the second class and an algebraic approach relying on invariants is proposed to carry out the classification. Applying the technique to low dimensional cases results in a systematic classification of filiform Leibniz algebras and the outcomes are also applicable to the geometric classification of the orbits of said algebras.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3885}
{"prompt": "Rephrase the abstract of an article with title 'GLSM's for partial flag manifolds'.\n  In this paper we outline some aspects of nonabelian gauged linear sigma\nmodels. First, we review how partial flag manifolds (generalizing\nGrassmannians) are described physically by nonabelian gauged linear sigma\nmodels, paying attention to realizations of tangent bundles and other aspects\npertinent to (0,2) models. Second, we review constructions of Calabi-Yau\ncomplete intersections within such flag manifolds, and properties of the gauged\nlinear sigma models. We discuss a number of examples of nonabelian GLSM's in\nwhich the Kahler phases are not birational, and in which at least one phase is\nrealized in some fashion other than as a complete intersection, extending\nprevious work of Hori-Tong. We also review an example of an abelian GLSM\nexhibiting the same phenomenon. We tentatively identify the mathematical\nrelationship between such non-birational phases, as examples of Kuznetsov's\nhomological projective duality. Finally, we discuss linear sigma model moduli\nspaces in these gauged linear sigma models. We argue that the moduli spaces\nbeing realized physically by these GLSM's are precisely Quot and hyperquot\nschemes, as one would expect mathematically.\n\n", "human_text": "  In this paper we outline some aspects of nonabelian gauged linear sigma\nmodels. First, we review how partial flag manifolds (generalizing\nGrassmannians) are described physically by nonabelian gauged linear sigma\nmodels, paying attention to realizations of tangent bundles and other aspects\npertinent to (0,2) models. Second, we review constructions of Calabi-Yau\ncomplete intersections within such flag manifolds, and properties of the gauged\nlinear sigma models. We discuss a number of examples of nonabelian GLSM's in\nwhich the Kahler phases are not birational, and in which at least one phase is\nrealized in some fashion other than as a complete intersection, extending\nprevious work of Hori-Tong. We also review an example of an abelian GLSM\nexhibiting the same phenomenon. We tentatively identify the mathematical\nrelationship between such non-birational phases, as examples of Kuznetsov's\nhomological projective duality. Finally, we discuss linear sigma model moduli\nspaces in these gauged linear sigma models. We argue that the moduli spaces\nbeing realized physically by these GLSM's are precisely Quot and hyperquot\nschemes, as one would expect mathematically.\n", "machine_text": "\nThis paper explores the features of nonabelian gauged linear sigma models by focusing on partial flag manifolds. Thus, the paper examines details of the tangent bundles, as well as other components relevant to (0,2) models. Furthermore, the construction of Calabi-Yau complete intersections within such flag manifolds is only the beginning. As far as the gauged linear sigma models themselves, special attention is paid to the examples with non-birational Kahler phases, as well as one abelian example. It is proposed that these non-birational phases are connected to Kuznetsov's homological projective duality. Lastly, the paper discusses linear sigma model moduli spaces in these same gauged linear sigma models, suggesting that Quot and hyperquot schemes are being physically modeled.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1761}
{"prompt": "Rephrase the abstract of an article with title 'The absolute Galois group acts faithfully on the connected components of\n  the moduli space of surfaces of general type'.\n  We show that the Galois group $Gal(\\bar{\\Q} /\\Q)$ operates faithfully on the\nset of connected components of the moduli spaces of surfaces of general type,\nand also that for each element $\\sigma \\in Gal(\\bar{\\Q} /\\Q)$ different from\nthe identity and from complex conjugation, there is a surface of general type\nsuch that $X$ and the Galois conjugate variety $X^{\\sigma}$ have nonisomorphic\nfundamental groups. The result was announced by the second author at the\nAlghero Conference 'Topology of algebraic varieties' in september 2006. Before\nthe present paper was actually written, we received a very interesting preprint\nby Robert Easton and Ravi Vakil (\\cite{e-v}), where it is proven, with a\ncompletely different type of examples, that the Galois group $Gal(\\bar{\\Q}\n/\\Q)$ operates faithfully on the set of irreducible components of the moduli\nspaces of surfaces of general type. We also give other simpler examples of\nsurfaces with nonisomorphic fundamental groups which are Galois conjugate,\nhence have isomorphic algebraic fundamental groups.\n\n", "human_text": "  We show that the Galois group $Gal(\\bar{\\Q} /\\Q)$ operates faithfully on the\nset of connected components of the moduli spaces of surfaces of general type,\nand also that for each element $\\sigma \\in Gal(\\bar{\\Q} /\\Q)$ different from\nthe identity and from complex conjugation, there is a surface of general type\nsuch that $X$ and the Galois conjugate variety $X^{\\sigma}$ have nonisomorphic\nfundamental groups. The result was announced by the second author at the\nAlghero Conference 'Topology of algebraic varieties' in september 2006. Before\nthe present paper was actually written, we received a very interesting preprint\nby Robert Easton and Ravi Vakil (\\cite{e-v}), where it is proven, with a\ncompletely different type of examples, that the Galois group $Gal(\\bar{\\Q}\n/\\Q)$ operates faithfully on the set of irreducible components of the moduli\nspaces of surfaces of general type. We also give other simpler examples of\nsurfaces with nonisomorphic fundamental groups which are Galois conjugate,\nhence have isomorphic algebraic fundamental groups.\n", "machine_text": "\nThe Galois group $Gal(\\bar{\\Q}/\\Q)$ acts faithfully on the set of connected components of the moduli spaces of surfaces of general type. Furthermore, any element $\\sigma \\in Gal(\\bar{\\Q}/\\Q)$ distinct from the identity and complex conjugation corresponds to a surface of general type such that its and its Galois conjugate's fundamental groups are non-isomorphic. Robert Easton and Ravi Vakil (\\cite{e-v}) published a pre-print proving that the same holds for the set of irreducible components of these moduli spaces of surfaces of general type. We also provide simpler examples of surfaces which have non-isomorphic fundamental groups yet are Galois conjugates and have analogous algebraic fundamental groups. The result was first proposed by the second author in the Alghero Conference titled 'Topology of Algebraic Varieties' in September 2006.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1466}
{"prompt": "Rephrase the abstract of an article with title 'High Resolution X-Ray Imaging of the Center of IC342'.\n  We presented the result of a high resolution (FWHM~0.5'') 12 ks Chandra HRC-I\nobservation of the starburst galaxy IC342 taken on 2 April 2006. We identified\n23 X-ray sources within the central 30' x 30' region of IC342. Our HRC-I\nobservation resolved the historical Ultraluminous X-ray sources (ULX), X3, near\nthe nucleus into 2 sources, namely C12 and C13, for the first time. The\nbrighter source C12, with L(0.08-10keV)=(6.66\\pm0.45)\\times10^{38}ergs^-1, was\nspatially extended (~82 pc x 127 pc). From the astrometric registration of the\nX-ray image, C12 was at R.A.=03h:46m:48.43s, decl.=+68d05m47.45s, and was\ncloser to the nucleus than C13. Thus we concluded that source was not an ULX\nand must instead be associated with the nucleus. The fainter source C13, with\nL(0.08-10keV)=(5.1\\pm1.4) x 10^{37}ergs^-1 was consistent with a point source\nand located $6.51'' at P.A. 240 degree of C12.\n  We also analyzed astrometrically corrected optical Hubble Space Telescope and\nradio Very Large Array images, a comparison with the X-ray image showed\nsimilarities in their morphologies. Regions of star formation within the\ncentral region of IC342 were clearly visible in HST H alpha image and this was\nthe region where 3 optical star clusters and correspondingly our detected X-ray\nsource C12 were observed. We found that a predicted X-ray emission from\nstarburst was very close to the observed X-ray luminosity of C12, suggesting\nthat nuclear X-ray emission in IC342 was dominated by starburst. Furthermore,\nwe discussed the possibility of AGN in the nucleus of IC342. Although our data\nwas not enough to give a firm existence of an AGN, it could not be discarded.\n\n", "human_text": "  We presented the result of a high resolution (FWHM~0.5'') 12 ks Chandra HRC-I\nobservation of the starburst galaxy IC342 taken on 2 April 2006. We identified\n23 X-ray sources within the central 30' x 30' region of IC342. Our HRC-I\nobservation resolved the historical Ultraluminous X-ray sources (ULX), X3, near\nthe nucleus into 2 sources, namely C12 and C13, for the first time. The\nbrighter source C12, with L(0.08-10keV)=(6.66\\pm0.45)\\times10^{38}ergs^-1, was\nspatially extended (~82 pc x 127 pc). From the astrometric registration of the\nX-ray image, C12 was at R.A.=03h:46m:48.43s, decl.=+68d05m47.45s, and was\ncloser to the nucleus than C13. Thus we concluded that source was not an ULX\nand must instead be associated with the nucleus. The fainter source C13, with\nL(0.08-10keV)=(5.1\\pm1.4) x 10^{37}ergs^-1 was consistent with a point source\nand located $6.51'' at P.A. 240 degree of C12.\n  We also analyzed astrometrically corrected optical Hubble Space Telescope and\nradio Very Large Array images, a comparison with the X-ray image showed\nsimilarities in their morphologies. Regions of star formation within the\ncentral region of IC342 were clearly visible in HST H alpha image and this was\nthe region where 3 optical star clusters and correspondingly our detected X-ray\nsource C12 were observed. We found that a predicted X-ray emission from\nstarburst was very close to the observed X-ray luminosity of C12, suggesting\nthat nuclear X-ray emission in IC342 was dominated by starburst. Furthermore,\nwe discussed the possibility of AGN in the nucleus of IC342. Although our data\nwas not enough to give a firm existence of an AGN, it could not be discarded.\n", "machine_text": "\nBy carrying out a high-resolution (FWHM~0.5'') Chandra HRC-I observation that was 12 ks long, we observed the starburst galaxy IC342 and identified 23 X-ray sources in a 30' x 30' region within its centre. This X-ray imaging revealed that the historically noted Ultraluminous X-ray source (ULX) X3 near the galactic nucleus was decomposed into two distinct sources, which we named C12 and C13. Source C12, whose luminosity was observed to be (6.66\\pm0.45) x 10^{38}ergs^-1, was seen to be spatially extended with a size of about 82 pc x 127 pc. Analysis of astrometrically corrected optical Hubble Space Telescope and radio Very Large Array images demonstrated that this source was close to the nucleus, with C13 (5.1\\pm1.4) x 10^{37}ergs^-1 was located 6.51'' away, at a position angle of 240 degree. Comparison of X-ray data with the HST H alpha image also showed star formation occurring in the central region, which was where star clusters were observed. Our findings suggested that the observed X-ray luminosity can be explained by starburst, although we did not have enough evidence to firmly determine whether the presence of active galactic nucleus in IC342 can be confirmed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.077}
{"prompt": "Rephrase the abstract of an article with title 'On smooth foliations with Morse singularities'.\n  Let $M$ be a smooth manifold and let $\\F$ be a codimension one, $C^\\infty$\nfoliation on $M$, with isolated singularities of Morse type. The study and\nclassification of pairs $(M,\\F)$ is a challenging (and difficult) problem. In\nthis setting, a classical result due to Reeb \\cite{Reeb} states that a manifold\nadmitting a foliation with exactly two center-type singularities is a sphere.\nIn particular this is true if the foliation is given by a function. Along these\nlines a result due to Eells and Kuiper \\cite{Ku-Ee} classify manifolds having a\nreal-valued function admitting exactly three non-degenerate singular points. In\nthe present paper, we prove a generalization of the above mentioned results. To\ndo this, we first describe the possible arrangements of pairs of singularities\nand the corresponding codimension one invariant sets, and then we give an\nelimination procedure for suitable center-saddle and some saddle-saddle\nconfigurations (of consecutive indices). In the second part, we investigate if\nother classical results, such as Haefliger and Novikov (Compact Leaf) theorems,\nproved for regular foliations, still hold true in presence of singularities. At\nthis purpose, in the singular set, $Sing(\\F)$ of the foliation $\\F$, we\nconsider {\\em{weakly stable}} components, that we define as those components\nadmitting a neighborhood where all leaves are compact. If $Sing(\\F)$ admits\nonly weakly stable components, given by smoothly embedded curves diffeomorphic\nto $S^1$, we are able to extend Haefliger's theorem. Finally, the existence of\na closed curve, transverse to the foliation, leads us to state a Novikov-type\nresult.\n\n", "human_text": "  Let $M$ be a smooth manifold and let $\\F$ be a codimension one, $C^\\infty$\nfoliation on $M$, with isolated singularities of Morse type. The study and\nclassification of pairs $(M,\\F)$ is a challenging (and difficult) problem. In\nthis setting, a classical result due to Reeb \\cite{Reeb} states that a manifold\nadmitting a foliation with exactly two center-type singularities is a sphere.\nIn particular this is true if the foliation is given by a function. Along these\nlines a result due to Eells and Kuiper \\cite{Ku-Ee} classify manifolds having a\nreal-valued function admitting exactly three non-degenerate singular points. In\nthe present paper, we prove a generalization of the above mentioned results. To\ndo this, we first describe the possible arrangements of pairs of singularities\nand the corresponding codimension one invariant sets, and then we give an\nelimination procedure for suitable center-saddle and some saddle-saddle\nconfigurations (of consecutive indices). In the second part, we investigate if\nother classical results, such as Haefliger and Novikov (Compact Leaf) theorems,\nproved for regular foliations, still hold true in presence of singularities. At\nthis purpose, in the singular set, $Sing(\\F)$ of the foliation $\\F$, we\nconsider {\\em{weakly stable}} components, that we define as those components\nadmitting a neighborhood where all leaves are compact. If $Sing(\\F)$ admits\nonly weakly stable components, given by smoothly embedded curves diffeomorphic\nto $S^1$, we are able to extend Haefliger's theorem. Finally, the existence of\na closed curve, transverse to the foliation, leads us to state a Novikov-type\nresult.\n", "machine_text": "This paper is concerned with the study, classification, and elimination of smooth codimension-one foliations on a smooth manifold $M$, with Morse-type isolated singularities. Additionally, the paper seeks to determine if classical results, such as those of Haefliger and Novikov, concerning the existence of non-degenerate singular points and closed transverse curves, respectively, still hold in the presence of singularities. To this end, we first describe the possible configurations of pairs of singularities and the corresponding codimension invariant sets. We then provide an elimination procedure for suitable center-saddle and saddle-saddle configurations. In the second part of the paper, we define weakly stable components of the singular set, $Sing(\\F)$, as those components admitting a neighborhood where all the leaves are compact. If $Sing(\\F)$ contains only such components, which are smoothly embedded curves diffeomorphic to $S^1$, we can prove an extension of Haefliger's theorem. Finally, if the foliation possesses a closed curve, transverse to it, then a Novikov-like result is attained.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0164}
{"prompt": "Rephrase the abstract of an article with title 'Charmless Three-body Decays of B Mesons'.\n  Charmless 3-body decays of B mesons are studied in the framework of the\nfactorization approach. The nonresonant contributions arising from $B\\to\nP_1P_2$ transitions are evaluated using heavy meson chiral perturbation theory\n(HMChPT). The momentum dependence of nonresonant amplitudes is assumed to be in\nthe exponential form $e^{-\\alpha_{NR}} p_B\\cdot(p_i+p_j)}$ so that the HMChPT\nresults are recovered in the soft meson limit $p_i, p_j\\to 0$. In addition, we\nhave identified another large source of the nonresonant signal in the matrix\nelements of scalar densities, e.g. $<K\\bar K|\\bar ss|0>$, which can be\nconstrained from the decay $\\bar B^0\\to K_SK_SK_S$ or $B^-\\to K^-K_SK_S$. The\nintermediate vector meson contributions to 3-body decays are identified through\nthe vector current, while the scalar meson resonances are mainly associated\nwith the scalar density. Their effects are described in terms of the\nBreit-Wigner formalism. Our main results are: (i) All KKK modes are dominated\nby the nonresonant background. The predicted branching ratios of\n$K^+K^-K_{S(L)}$, $K^+K^-K^-$ and $K^-K_SK_S$ modes are consistent with the\ndata within errors. (ii) Although the penguin-dominated $B^0\\to K^+K^-K_{S}$\ndecay is subject to a potentially significant tree pollution, its effective\n$\\sin 2\\beta$ is very similar to that of the $K_SK_SK_S$ mode. However, direct\nCP asymmetry of the former, being of order -4%, is more prominent than the\nlatter. (iii) For $B\\to K\\pi\\pi$ decays, we found sizable nonresonant\ncontributions in $K^-\\pi^+\\pi^-$ and $\\bar K^0\\pi^+\\pi^-$ modes, in agreement\nwith the Belle measurements but larger than the BaBar result.\n\n", "human_text": "  Charmless 3-body decays of B mesons are studied in the framework of the\nfactorization approach. The nonresonant contributions arising from $B\\to\nP_1P_2$ transitions are evaluated using heavy meson chiral perturbation theory\n(HMChPT). The momentum dependence of nonresonant amplitudes is assumed to be in\nthe exponential form $e^{-\\alpha_{NR}} p_B\\cdot(p_i+p_j)}$ so that the HMChPT\nresults are recovered in the soft meson limit $p_i, p_j\\to 0$. In addition, we\nhave identified another large source of the nonresonant signal in the matrix\nelements of scalar densities, e.g. $<K\\bar K|\\bar ss|0>$, which can be\nconstrained from the decay $\\bar B^0\\to K_SK_SK_S$ or $B^-\\to K^-K_SK_S$. The\nintermediate vector meson contributions to 3-body decays are identified through\nthe vector current, while the scalar meson resonances are mainly associated\nwith the scalar density. Their effects are described in terms of the\nBreit-Wigner formalism. Our main results are: (i) All KKK modes are dominated\nby the nonresonant background. The predicted branching ratios of\n$K^+K^-K_{S(L)}$, $K^+K^-K^-$ and $K^-K_SK_S$ modes are consistent with the\ndata within errors. (ii) Although the penguin-dominated $B^0\\to K^+K^-K_{S}$\ndecay is subject to a potentially significant tree pollution, its effective\n$\\sin 2\\beta$ is very similar to that of the $K_SK_SK_S$ mode. However, direct\nCP asymmetry of the former, being of order -4%, is more prominent than the\nlatter. (iii) For $B\\to K\\pi\\pi$ decays, we found sizable nonresonant\ncontributions in $K^-\\pi^+\\pi^-$ and $\\bar K^0\\pi^+\\pi^-$ modes, in agreement\nwith the Belle measurements but larger than the BaBar result.\n", "machine_text": "\nThis article assesses charmless 3-body decays of B mesons employing the factorization approach and heavy meson chiral perturbation theory (HMChPT). The momentum dependence of nonresonant amplitudes is assumed to be in the form of an exponential expression, such that its HMChPT results are maintained in a soft meson limit. Furthermore, the authors identify a major source of nonresonant signals in the matrix elements of scalar densities, such as $<K\\bar K|\\bar ss|0>$, which can be gleaned from the decay $\\bar B^0\\to K_SK_SK_S$ or $B^-\\to K^-K_SK_S$. The results of vector meson contributions to 3-body decays are described with the Breit-Wigner formalism. Concluding results indicate that all KKK modes are largely dominated by nonresonant backgrounds and other subsequent decay modes are subject to a potential tree pollution, resulting in elevated direct CP asymmetries. Additionally, the nonresonant contributions found in $K^-\\pi^+\\pi^-$ and $\\bar K^0\\pi^+\\pi^-$ modes agree with the Belle measurements, yet prove to be more substantial than those of the BaBar result.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1049}
{"prompt": "Rephrase the abstract of an article with title 'ASTROD I Charging Simulation and Disturbances'.\n  ASTROD I is planned as a single spacecraft mission. It will use\ninterferometric and pulse ranging techniques between the spacecraft and ground\nstations, to make high precision measurements of the parameters that describe\nthe solar system, and to test relativistic gravity with improved accuracy. At\nthe heart of the spacecraft is a test mass, which the spacecraft will follow\nusing a drag-free control system. The mission critically depends on maintaining\nthe geodesic motion of the test mass. Charging of the test mass due to cosmic\nrays and solar particles will disturb its geodesic motion. We have modelled the\ncharging process using the GEANT4 toolkit and a simplified, geometrical model\nand estimate that the ASTROD I test mass will charge positively, at a rate of\n24 +/-7 e+/s, due to cosmic ray protons and alpha particles (3He and 4He) at\nsolar minimum. We have used the results of this simulation to estimate the\nmagnitude of disturbances associated with test mass charging, for the\nworst-case scenario, taking into account uncertainties in the model and\npotential charging contributions from minor cosmic-ray components.\n\n", "human_text": "  ASTROD I is planned as a single spacecraft mission. It will use\ninterferometric and pulse ranging techniques between the spacecraft and ground\nstations, to make high precision measurements of the parameters that describe\nthe solar system, and to test relativistic gravity with improved accuracy. At\nthe heart of the spacecraft is a test mass, which the spacecraft will follow\nusing a drag-free control system. The mission critically depends on maintaining\nthe geodesic motion of the test mass. Charging of the test mass due to cosmic\nrays and solar particles will disturb its geodesic motion. We have modelled the\ncharging process using the GEANT4 toolkit and a simplified, geometrical model\nand estimate that the ASTROD I test mass will charge positively, at a rate of\n24 +/-7 e+/s, due to cosmic ray protons and alpha particles (3He and 4He) at\nsolar minimum. We have used the results of this simulation to estimate the\nmagnitude of disturbances associated with test mass charging, for the\nworst-case scenario, taking into account uncertainties in the model and\npotential charging contributions from minor cosmic-ray components.\n", "machine_text": "\nA comprehensive model has been developed to simulate the charging process of the ASTROD I test mass due to cosmic rays and solar particles. Utilizing GEANT4 and a simplified geometrical model, it has been estimated that the test mass will charge positively at a rate of 24 +/-7 e+/s during solar minimum. These results have been used to determine the magnitude of disturbances caused by the charging process on the test mass's geodesic motion, accounting for uncertainties in the model and potential contributions from secondary cosmic-ray components.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3303}
{"prompt": "Rephrase the abstract of an article with title 'Uncovering the Near-IR Dwarf Galaxy Population of the Coma Cluster with\n  Spitzer IRAC'.\n  We present the first results of a Spitzer IRAC (Infrared Array Camera)\nwide-field survey of the Coma cluster. The observations cover two fields of\ndifferent galaxy densities; the first is a 0.733 deg^2 region in the core of\nthe cluster (Coma 1), the second a 0.555 deg^2 off-center region located ~57\narcmin (1.7 Mpc) south-west from the core (Coma 3). The observations, although\nshort 70-90 s exposures, are very sensitive; we detect ~29,200 sources at 3.6\nmicron over the total ~1.3 deg^2 survey area. We construct 3.6 micron galaxy\nluminosity functions (LFs) for each field using selection functions based on\nspectroscopic redshifts. At the bright end, the LFs are well modeled by a\ntraditional Schechter function; [M^star (3.6 micron), alpha_1] = [-25.17,\n-1.18] and [-24.69, -1.30] for Coma 1 and Coma 3 respectively. However, at the\nfaint end (M(3.6 micron) > -20.5), there is a steep increase in the LF slope in\nboth fields indicative of large numbers of red dwarf galaxies. The reality of\nthis population is examined using optical counterparts in SDSS data with\noptical color filtering (g-r<1.3). The steep increase can be modeled with a\npower-law function, with slopes of alpha_2 = -2.18 (Coma 1) and alpha_2 = -2.60\n(Coma 3). A qualitative comparison with optical (B- and R-band) LFs shows that\nwe are likely to be observing a larger population of dwarf galaxies in the\nnear-IR, which may be a low-surface-brightness (LSB) population that IRAC is\nparticularly sensitive to, or a population too red to be detected in existing\noptical surveys down to R~20.\n\n", "human_text": "  We present the first results of a Spitzer IRAC (Infrared Array Camera)\nwide-field survey of the Coma cluster. The observations cover two fields of\ndifferent galaxy densities; the first is a 0.733 deg^2 region in the core of\nthe cluster (Coma 1), the second a 0.555 deg^2 off-center region located ~57\narcmin (1.7 Mpc) south-west from the core (Coma 3). The observations, although\nshort 70-90 s exposures, are very sensitive; we detect ~29,200 sources at 3.6\nmicron over the total ~1.3 deg^2 survey area. We construct 3.6 micron galaxy\nluminosity functions (LFs) for each field using selection functions based on\nspectroscopic redshifts. At the bright end, the LFs are well modeled by a\ntraditional Schechter function; [M^star (3.6 micron), alpha_1] = [-25.17,\n-1.18] and [-24.69, -1.30] for Coma 1 and Coma 3 respectively. However, at the\nfaint end (M(3.6 micron) > -20.5), there is a steep increase in the LF slope in\nboth fields indicative of large numbers of red dwarf galaxies. The reality of\nthis population is examined using optical counterparts in SDSS data with\noptical color filtering (g-r<1.3). The steep increase can be modeled with a\npower-law function, with slopes of alpha_2 = -2.18 (Coma 1) and alpha_2 = -2.60\n(Coma 3). A qualitative comparison with optical (B- and R-band) LFs shows that\nwe are likely to be observing a larger population of dwarf galaxies in the\nnear-IR, which may be a low-surface-brightness (LSB) population that IRAC is\nparticularly sensitive to, or a population too red to be detected in existing\noptical surveys down to R~20.\n", "machine_text": "\nThe Spitzer IRAC (Infrared Array Camera) wide-field survey of the Coma cluster has revealed two fields with varying densities of ~29,200 sources when observed with 70-90 second exposures. Analysis of the 3.6 micron galaxy luminosity functions (LFs) show that both fields have a traditional Schechter function at the bright end, but a steep increase in slope at the faint end (M(3.6 micron) >-20.5), which is more pronounced in the off-center Coma 3 field. Comparison with optical LFs from B- and R-band reveals a larger population of faint dwarf galaxies, which may be low-surface-brightness or too red to be seen in most optical surveys. These findings uncover the near-IR dwarf galaxy population of the Coma cluster.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3681}
{"prompt": "Rephrase the abstract of an article with title 'The substellar mass function in sigma Orionis. II. Optical,\n  near-infrared and IRAC/Spitzer photometry of young cluster brown dwarfs and\n  planetary-mass objects'.\n  We investigate the mass function in the substellar domain down to a few\nJupiter masses in the young sigma Orionis open cluster (3+/-2 Ma, d =\n360^+70_-60 pc). We have performed a deep IJ-band search, covering an area of\n790 arcmin^2 close to the cluster centre. This survey was complemented with an\ninfrared follow-up in the HKs- and Spitzer 3.6-8.0 mum-bands. Using\ncolour-magnitude diagrams, we have selected 49 candidate cluster members in the\nmagnitude interval 16.1 mag < I < 23.0 mag. Accounting for flux excesses at 8.0\nmum and previously known spectral features of youth, 30 objects are bona fide\ncluster members. Four are first identified from our optical-near infrared data.\nEleven have most probable masses below the deuterium burning limit and are\nclassified as planetary-mass object candidates. The slope of the substellar\nmass spectrum (Delta N / Delta M = a M^-alpha) in the mass interval 0.11 Msol M\n< 0.006 Msol is alpha = +0.6+/-0.2. Any opacity mass-limit, if these objects\nform via fragmentation, may lie below 0.006 Msol. The frequency of sigma\nOrionis brown dwarfs with circumsubstellar discs is 47+/-15 %. The continuity\nin the mass function and in the frequency of discs suggests that very low-mass\nstars and substellar objects, even below the deuterium-burning mass limit, may\nshare the same formation mechanism.\n\n", "human_text": "  We investigate the mass function in the substellar domain down to a few\nJupiter masses in the young sigma Orionis open cluster (3+/-2 Ma, d =\n360^+70_-60 pc). We have performed a deep IJ-band search, covering an area of\n790 arcmin^2 close to the cluster centre. This survey was complemented with an\ninfrared follow-up in the HKs- and Spitzer 3.6-8.0 mum-bands. Using\ncolour-magnitude diagrams, we have selected 49 candidate cluster members in the\nmagnitude interval 16.1 mag < I < 23.0 mag. Accounting for flux excesses at 8.0\nmum and previously known spectral features of youth, 30 objects are bona fide\ncluster members. Four are first identified from our optical-near infrared data.\nEleven have most probable masses below the deuterium burning limit and are\nclassified as planetary-mass object candidates. The slope of the substellar\nmass spectrum (Delta N / Delta M = a M^-alpha) in the mass interval 0.11 Msol M\n< 0.006 Msol is alpha = +0.6+/-0.2. Any opacity mass-limit, if these objects\nform via fragmentation, may lie below 0.006 Msol. The frequency of sigma\nOrionis brown dwarfs with circumsubstellar discs is 47+/-15 %. The continuity\nin the mass function and in the frequency of discs suggests that very low-mass\nstars and substellar objects, even below the deuterium-burning mass limit, may\nshare the same formation mechanism.\n", "machine_text": "\nWe investigate the mass function of substellar objects in the young sigma Orionis open cluster, which is 3+/-2 Ma old and is located at a distance of 360^+70_-60 pc. A deep survey was done in the IJ-bands across an area of 790 arcmin^2 centred on the cluster. This was supplemented with infrared follow-up in the HKs- and Spitzer 3.6-8.0 mum-bands. Based on colour-magnitude diagrams, 49 candidate cluster members in the magnitude interval 16.1 mag < I < 23.0 mag were identified. Of these, 30 were verified to be true cluster members, with 11 being below the deuterium burning limit and thus classified as planetary-mass object candidates. The slope of the substellar mass spectrum in the mass range between 0.11 Msol and 0.006 Msol was found to be +0.6+/-0.2, with a high probability of an opacity mass limit below 0.006 Msol if these objects are formed due to fragmentation. Moreover, 47 +/- 15% of the brown dwarfs in the sigma Orionis have been discovered to have circumsubstellar discs. This likely indicates that the formation of both low-mass stars and substellar objects, even below the deuterium-burning mass limit, is subject to the same mechanism.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0922}
{"prompt": "Rephrase the abstract of an article with title 'Analysis on Heavy Quarkonia Transitions with Pion Emission in Terms of\n  the QCD Multipole Expansion and Determination of Mass Spectra of Hybrids'.\n  One of the most important tasks in high energy physics is search for the\nexotic states, such as glueball, hybrid and multi-quark states. The transitions\n$\\psi(ns)\\to \\psi(ms)+\\pi\\pi$ and $\\Upsilon(ns)\\to \\Upsilon(ms)+\\pi\\pi$ attract\ngreat attentions because they may reveal characteristics of hybrids. In this\nwork, we analyze those transition modes in terms of the theoretical framework\nestablished by Yan and Kuang. It is interesting to notice that the intermediate\nstates between the two gluon-emissions are hybrids, therefore by fitting the\ndata, we are able to determine the mass spectra of hybrids. The ground hybrid\nstates are predicted as 4.23 GeV (for charmonium) and 10.79 GeV (for bottonium)\nwhich do not correspond to any states measured in recent experiments, thus it\nmay imply that very possibly, hybrids mix with regular quarkonia to constitute\nphysical states. Comprehensive comparisons of the potentials for hybrids whose\nparameters are obtained in this scenario with the lattice results are\npresented.\n\n", "human_text": "  One of the most important tasks in high energy physics is search for the\nexotic states, such as glueball, hybrid and multi-quark states. The transitions\n$\\psi(ns)\\to \\psi(ms)+\\pi\\pi$ and $\\Upsilon(ns)\\to \\Upsilon(ms)+\\pi\\pi$ attract\ngreat attentions because they may reveal characteristics of hybrids. In this\nwork, we analyze those transition modes in terms of the theoretical framework\nestablished by Yan and Kuang. It is interesting to notice that the intermediate\nstates between the two gluon-emissions are hybrids, therefore by fitting the\ndata, we are able to determine the mass spectra of hybrids. The ground hybrid\nstates are predicted as 4.23 GeV (for charmonium) and 10.79 GeV (for bottonium)\nwhich do not correspond to any states measured in recent experiments, thus it\nmay imply that very possibly, hybrids mix with regular quarkonia to constitute\nphysical states. Comprehensive comparisons of the potentials for hybrids whose\nparameters are obtained in this scenario with the lattice results are\npresented.\n", "machine_text": "\nResearch into exotic states, such as glueball, hybrid and multi-quark states, is one of the most important aspects of high energy physics. Transitions such as $\\psi(ns)\\to \\psi(ms)+\\pi\\pi$ and $\\Upsilon(ns)\\to \\Upsilon(ms)+\\pi\\pi$ provide valuable information about these hybrid states. This study examines these transition modes from the theoretical perspective established by Yan and Kuang, exploring the intermediate states between the two gluon-emissions, and ultimately allowing for the determination of their mass spectra. Through comparisons of potentials for hybrids, obtained via this scenario with lattice results, the mass spectra of the hybrids are predicted as 4.23 GeV (for charmonium) and 10.79 GeV (for bottonium). This differs from what has been measured in recent experiments, potentially signifying that hybrids mix with regular quarkonia to constitute physical states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2074}
{"prompt": "Rephrase the abstract of an article with title 'Dielectric Relaxation and Phase Transition at Cryogenic Temperatures in\n  0.65[Pb(Ni_1/3Nb_2/3)O_3]-0.35PbTiO_3 Ceramics'.\n  Dielectric measurements on 0.65[Pb(Ni_1/3Nb_2/3)O_3]-0.35PbTiO_3 ceramic in\nthe temperature range 90K to 470K shows a relaxor ferroelectric transition\naround 350K with a Vogel-Fulcher freezing temperature of 338K and appearance of\na non-ergodic relaxor ferroelectric phase of tetragonal structure at room\ntemperature. This non-ergodic phase reenters into the relaxor state at low\ntemperatures as evidenced by the appearance of a frequency dependent anomaly in\nthe imaginary part of the dielectric constant around 160K, similar to those\nreported in other relaxor ferroelectric based morphotropic phase boundary\nceramics. The polarization relaxation time for the 160K anomaly also follows\nVogel-Fulcher type temperature dependence. Temperature dependent magnetization\nmeasurements show that this low temperature anomaly is not linked with any\nmagnetic transition. Elastic modulus and low temperature x-ray diffraction\n(XRD) measurements reveal a tetragonal to monoclinic phase transition around\n225K. It is argued that the low temperature dielectric dispersion around 160K\nresults from the freezing of mesoscopic conformally miniaturized monoclinic\ndomains formed inside the parent tetragonal domains below the structural phase\ntransition temperature of 225K.\n\n", "human_text": "  Dielectric measurements on 0.65[Pb(Ni_1/3Nb_2/3)O_3]-0.35PbTiO_3 ceramic in\nthe temperature range 90K to 470K shows a relaxor ferroelectric transition\naround 350K with a Vogel-Fulcher freezing temperature of 338K and appearance of\na non-ergodic relaxor ferroelectric phase of tetragonal structure at room\ntemperature. This non-ergodic phase reenters into the relaxor state at low\ntemperatures as evidenced by the appearance of a frequency dependent anomaly in\nthe imaginary part of the dielectric constant around 160K, similar to those\nreported in other relaxor ferroelectric based morphotropic phase boundary\nceramics. The polarization relaxation time for the 160K anomaly also follows\nVogel-Fulcher type temperature dependence. Temperature dependent magnetization\nmeasurements show that this low temperature anomaly is not linked with any\nmagnetic transition. Elastic modulus and low temperature x-ray diffraction\n(XRD) measurements reveal a tetragonal to monoclinic phase transition around\n225K. It is argued that the low temperature dielectric dispersion around 160K\nresults from the freezing of mesoscopic conformally miniaturized monoclinic\ndomains formed inside the parent tetragonal domains below the structural phase\ntransition temperature of 225K.\n", "machine_text": "\nResearch carried out on a 0.65[Pb(Ni_1/3Nb_2/3)O_3]-0.35PbTiO_3 ceramic sample revealed a ferroelectric relaxor transition at a temperature of 350K - this transition is evidenced by a Vogel-Fulcher freezing temperature of 338K and the emergence of a non-ergodic relaxor ferroelectric phase of tetragonal structure at room temperature. Further dielectric measurements suggests that at low temperatures the sample reenters the relaxor state, evident by the appearance of a frequency-dependent anomaly in the imaginary part of the dielectric constant at around 160K which follows the Vogel-Fulcher type of temperature dependence. The magnetization results indicate that this low temperature dielectric anomaly is not linked to any magnetic transition, while x-ray diffraction (XRD) measurements reveal a structural transition between a tetragonal and monoclinic phase at approx. 225K. It is hypothesized that the conformally miniaturized monoclinic domains formed inside the tetragonal domains during the structural transition are what is causing the low-temperature dielectric dispersion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0982}
{"prompt": "Rephrase the abstract of an article with title 'Modified p-modes in penumbral filaments?'.\n  Aims: The primary objective of this study is to search for and identify wave\nmodes within a sunspot penumbra.\n  Methods: Infrared spectropolarimetric time series data are inverted using a\nmodel comprising two atmospheric components in each spatial pixel. Fourier\nphase difference analysis is performed on the line-of-sight velocities\nretrieved from both components to determine time delays between the velocity\nsignals. In addition, the vertical separation between the signals in the two\ncomponents is calculated from the Stokes velocity response functions.\n  Results: The inversion yields two atmospheric components, one permeated by a\nnearly horizontal magnetic field, the other with a less-inclined magnetic\nfield. Time delays between the oscillations in the two components in the\nfrequency range 2.5-4.5 mHz are combined with speeds of atmospheric wave modes\nto determine wave travel distances. These are compared to expected path lengths\nobtained from response functions of the observed spectral lines in the\ndifferent atmospheric components. Fast-mode (i.e., modified p-mode) waves\nexhibit the best agreement with the observations when propagating toward the\nsunspot at an angle ~50 degrees to the vertical.\n\n", "human_text": "  Aims: The primary objective of this study is to search for and identify wave\nmodes within a sunspot penumbra.\n  Methods: Infrared spectropolarimetric time series data are inverted using a\nmodel comprising two atmospheric components in each spatial pixel. Fourier\nphase difference analysis is performed on the line-of-sight velocities\nretrieved from both components to determine time delays between the velocity\nsignals. In addition, the vertical separation between the signals in the two\ncomponents is calculated from the Stokes velocity response functions.\n  Results: The inversion yields two atmospheric components, one permeated by a\nnearly horizontal magnetic field, the other with a less-inclined magnetic\nfield. Time delays between the oscillations in the two components in the\nfrequency range 2.5-4.5 mHz are combined with speeds of atmospheric wave modes\nto determine wave travel distances. These are compared to expected path lengths\nobtained from response functions of the observed spectral lines in the\ndifferent atmospheric components. Fast-mode (i.e., modified p-mode) waves\nexhibit the best agreement with the observations when propagating toward the\nsunspot at an angle ~50 degrees to the vertical.\n", "machine_text": "\nThe goal of this study is to identify wave activity within sunspot penumbras. To do this, infrared spectropolarimetric data is inverted to form two separate atmospheric layers in each spatial pixel. By computing the Fourier phase differences, as well as vertical separations of the signals in each component, time delays between oscillations in the ranges 2.5-4.5 mHz and the corresponding speed of atmospheric waves are measured. Comparison of these measurements to the shape of response functions for the observed spectral lines indicate that modified p-mode waves are best represented when propagating at an angle of about 50 degrees to the vertical.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0481}
{"prompt": "Rephrase the abstract of an article with title 'Vacuum Energy and Renormalization on the Edge'.\n  The vacuum dependence on boundary conditions in quantum field theories is\nanalysed from a very general viewpoint. From this perspective the\nrenormalization prescriptions not only imply the renormalization of the\ncouplings of the theory in the bulk but also the appearance of a flow in the\nspace of boundary conditions. For regular boundaries this flow has a large\nvariety of fixed points and no cyclic orbit. The family of fixed points\nincludes Neumann and Dirichlet boundary conditions. In one-dimensional field\ntheories pseudoperiodic and quasiperiodic boundary conditions are also RG fixed\npoints. Under these conditions massless bosonic free field theories are\nconformally invariant. Among all fixed points only Neumann boundary conditions\nare infrared stable fixed points. All other conformal invariant boundary\nconditions become unstable under some relevant perturbations. In finite volumes\nwe analyse the dependence of the vacuum energy along the trajectories of the\nrenormalization group flow providing an interesting framework for dark energy\nevolution. On the contrary, the renormalization group flow on the boundary does\nnot affect the leading behaviour of the entanglement entropy of the vacuum in\none-dimensional conformally invariant bosonic theories.\n\n", "human_text": "  The vacuum dependence on boundary conditions in quantum field theories is\nanalysed from a very general viewpoint. From this perspective the\nrenormalization prescriptions not only imply the renormalization of the\ncouplings of the theory in the bulk but also the appearance of a flow in the\nspace of boundary conditions. For regular boundaries this flow has a large\nvariety of fixed points and no cyclic orbit. The family of fixed points\nincludes Neumann and Dirichlet boundary conditions. In one-dimensional field\ntheories pseudoperiodic and quasiperiodic boundary conditions are also RG fixed\npoints. Under these conditions massless bosonic free field theories are\nconformally invariant. Among all fixed points only Neumann boundary conditions\nare infrared stable fixed points. All other conformal invariant boundary\nconditions become unstable under some relevant perturbations. In finite volumes\nwe analyse the dependence of the vacuum energy along the trajectories of the\nrenormalization group flow providing an interesting framework for dark energy\nevolution. On the contrary, the renormalization group flow on the boundary does\nnot affect the leading behaviour of the entanglement entropy of the vacuum in\none-dimensional conformally invariant bosonic theories.\n", "machine_text": "This paper examines the influence of vacuum energy on the boundaries of quantum field theories. It is shown that a variety of conditions such as Neumann, Dirichlet, pseudoperiodic and quasiperiodic boundary conditions can be fixed points in a renormalization group flow. The study then goes further to investigate how massless bosonic free fields are affected by conformal invariance. It is then demonstrated that only Neumann boundary conditions are infrared-stable fixed points, and all other conformal invariant boundary conditions become unstable under certain relevant perturbations. In finite volumes, the dependence of the vacuum energy on the trajectories of the renormalization group flow is studied, offering an interesting perspective on dark energy evolution. Lastly, it is stated that the renormalization group flow on the boundaries does not affect the leading behaviour of the entanglement entropy of the vacuum in one-dimensional conformally invariant bosonic theories.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1084}
{"prompt": "Rephrase the abstract of an article with title 'Relativistic X-ray Lines from the Inner Accretion Disks Around Black\n  Holes'.\n  Relativistic X-ray emission lines from the inner accretion disk around black\nholes are reviewed. Recent observations with the Chandra X-ray Observatory,\nX-ray Multi-Mirror Mission-Newton, and Suzaku are revealing these lines to be\ngood probes of strong gravitational effects. A number of important\nobservational and theoretical developments are highlighted, including evidence\nof black hole spin and effects such as gravitational light bending, the\ndetection of relativistic lines in stellar-mass black holes, and evidence of\norbital-timescale line flux variability. In addition, the robustness of the\nrelativistic disk lines against absorption, scattering, and continuum effects\nis discussed. Finally, prospects for improved measures of black hole spin and\nunderstanding the spin history of supermassive black holes in the context of\nblack hole-galaxy co-evolution are presented. The best data and most rigorous\nresults strongly suggest that relativistic X-ray disk lines can drive future\nexplorations of General Relativity and disk physics.\n\n", "human_text": "  Relativistic X-ray emission lines from the inner accretion disk around black\nholes are reviewed. Recent observations with the Chandra X-ray Observatory,\nX-ray Multi-Mirror Mission-Newton, and Suzaku are revealing these lines to be\ngood probes of strong gravitational effects. A number of important\nobservational and theoretical developments are highlighted, including evidence\nof black hole spin and effects such as gravitational light bending, the\ndetection of relativistic lines in stellar-mass black holes, and evidence of\norbital-timescale line flux variability. In addition, the robustness of the\nrelativistic disk lines against absorption, scattering, and continuum effects\nis discussed. Finally, prospects for improved measures of black hole spin and\nunderstanding the spin history of supermassive black holes in the context of\nblack hole-galaxy co-evolution are presented. The best data and most rigorous\nresults strongly suggest that relativistic X-ray disk lines can drive future\nexplorations of General Relativity and disk physics.\n", "machine_text": "\nThis article reviews evidence of relativistic X-ray emission lines originating from the inner accretion disks surrounding black holes. Recent observations with various space telescopes have revealed these X-ray lines to be a good indicator of the influence of strong gravitational effects. Several noteworthy developments in this field are discussed, including the presence of black hole spin, the detection of relativistic lines in stellar-mass black holes, the effects of gravitational light bending, line flux variability on a timescale of the orbit, and the deduction of the robustness of the relativistic disk lines against absorption, scattering and continuum effects. Moreover, prospects for the improvement of understanding black hole spin as it applies to the co-evolution of black holes and galaxies are explored. The results presented in the article suggest that relativistic X-ray disk lines will be a main driver of future investigations into General Relativity and disk physics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.054}
{"prompt": "Rephrase the abstract of an article with title 'The Mean and Scatter of the Velocity Dispersion-Optical Richness\n  Relation for maxBCG Galaxy Clusters'.\n  The distribution of galaxies in position and velocity around the centers of\ngalaxy clusters encodes important information about cluster mass and structure.\nUsing the maxBCG galaxy cluster catalog identified from imaging data obtained\nin the Sloan Digital Sky Survey, we study the BCG-galaxy velocity correlation\nfunction. By modeling its non-Gaussianity, we measure the mean and scatter in\nvelocity dispersion at fixed richness. The mean velocity dispersion increases\nfrom 202+/-10 km/s for small groups to more than 854+/-102 km/s for large\nclusters. We show the scatter to be at most 40.5+/-3.5%, declining to\n14.9+/-9.4% in the richest bins. We test our methods in the C4 cluster catalog,\na spectroscopic cluster catalog produced from the Sloan Digital Sky Survey DR2\nspectroscopic sample, and in mock galaxy catalogs constructed from N-body\nsimulations. Our methods are robust, measuring the scatter to well within\none-sigma of the true value, and the mean to within 10%, in the mock catalogs.\nBy convolving the scatter in velocity dispersion at fixed richness with the\nobserved richness space density function, we measure the velocity dispersion\nfunction of the maxBCG galaxy clusters. Although velocity dispersion and\nrichness do not form a true mass-observable relation, the relationship between\nvelocity dispersion and mass is theoretically well characterized and has low\nscatter. Thus our results provide a key link between theory and observations up\nto the velocity bias between dark matter and galaxies.\n\n", "human_text": "  The distribution of galaxies in position and velocity around the centers of\ngalaxy clusters encodes important information about cluster mass and structure.\nUsing the maxBCG galaxy cluster catalog identified from imaging data obtained\nin the Sloan Digital Sky Survey, we study the BCG-galaxy velocity correlation\nfunction. By modeling its non-Gaussianity, we measure the mean and scatter in\nvelocity dispersion at fixed richness. The mean velocity dispersion increases\nfrom 202+/-10 km/s for small groups to more than 854+/-102 km/s for large\nclusters. We show the scatter to be at most 40.5+/-3.5%, declining to\n14.9+/-9.4% in the richest bins. We test our methods in the C4 cluster catalog,\na spectroscopic cluster catalog produced from the Sloan Digital Sky Survey DR2\nspectroscopic sample, and in mock galaxy catalogs constructed from N-body\nsimulations. Our methods are robust, measuring the scatter to well within\none-sigma of the true value, and the mean to within 10%, in the mock catalogs.\nBy convolving the scatter in velocity dispersion at fixed richness with the\nobserved richness space density function, we measure the velocity dispersion\nfunction of the maxBCG galaxy clusters. Although velocity dispersion and\nrichness do not form a true mass-observable relation, the relationship between\nvelocity dispersion and mass is theoretically well characterized and has low\nscatter. Thus our results provide a key link between theory and observations up\nto the velocity bias between dark matter and galaxies.\n", "machine_text": "\nWe investigate the relation between velocity dispersion and optical richness for maxBCG galaxy clusters by looking into their distribution of galaxies in terms of position and velocity around the clusters' centers. Utilizing data from the Sloan Digital Sky Survey, we note that the mean velocity dispersion is increasing from 202+/-10 km/s for smaller groups to 854+/-102 km/s for larger clusters. The scatter of this velocity correlation is measured to be within 40.5+/-3.5%, decreasing to 14.9+/-9.4% in the most plentiful bins. We also assess our methods on the C4 cluster catalog and simulation N-body models, confirming that our measurements relatively accurately capture the true values. By blending the scatter in velocity dispersion with the richness of the space density function, the velocity dispersion function of the maxBCG galaxy clusters is calculated. Even though velocity dispersion and richness are circumscribed as a mass-observable relation, it has been explored how their connectivity to masses is not too divergent and has limited scatter. Our findings thus establish a bridge between theory and observation and shed light on the velocity bias between dark matter and galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3614}
{"prompt": "Rephrase the abstract of an article with title 'Numerical simulations of fast and slow coronal mass ejections'.\n  Solar coronal mass ejections (CMEs) show a large variety in their kinematic\nproperties. CMEs originating in active regions and accompanied by strong flares\nare usually faster and accelerated more impulsively than CMEs associated with\nfilament eruptions outside active regions and weak flares. It has been proposed\nmore than two decades ago that there are two separate types of CMEs, fast\n(impulsive) CMEs and slow (gradual) CMEs. However, this concept may not be\nvalid, since the large data sets acquired in recent years do not show two\ndistinct peaks in the CME velocity distribution and reveal that both fast and\nslow CMEs can be accompanied by both weak and strong flares. We present\nnumerical simulations which confirm our earlier analytical result that a\nflux-rope CME model permits describing fast and slow CMEs in a unified manner.\nWe consider a force-free coronal magnetic flux rope embedded in the potential\nfield of model bipolar and quadrupolar active regions. The eruption is driven\nby the torus instability which occurs if the field overlying the flux rope\ndecreases sufficiently rapidly with height. The acceleration profile depends on\nthe steepness of this field decrease, corresponding to fast CMEs for rapid\ndecrease, as is typical of active regions, and to slow CMEs for gentle\ndecrease, as is typical of the quiet Sun. Complex (quadrupolar) active regions\nlead to the fastest CMEs.\n\n", "human_text": "  Solar coronal mass ejections (CMEs) show a large variety in their kinematic\nproperties. CMEs originating in active regions and accompanied by strong flares\nare usually faster and accelerated more impulsively than CMEs associated with\nfilament eruptions outside active regions and weak flares. It has been proposed\nmore than two decades ago that there are two separate types of CMEs, fast\n(impulsive) CMEs and slow (gradual) CMEs. However, this concept may not be\nvalid, since the large data sets acquired in recent years do not show two\ndistinct peaks in the CME velocity distribution and reveal that both fast and\nslow CMEs can be accompanied by both weak and strong flares. We present\nnumerical simulations which confirm our earlier analytical result that a\nflux-rope CME model permits describing fast and slow CMEs in a unified manner.\nWe consider a force-free coronal magnetic flux rope embedded in the potential\nfield of model bipolar and quadrupolar active regions. The eruption is driven\nby the torus instability which occurs if the field overlying the flux rope\ndecreases sufficiently rapidly with height. The acceleration profile depends on\nthe steepness of this field decrease, corresponding to fast CMEs for rapid\ndecrease, as is typical of active regions, and to slow CMEs for gentle\ndecrease, as is typical of the quiet Sun. Complex (quadrupolar) active regions\nlead to the fastest CMEs.\n", "machine_text": "\nUsing numerical models, we demonstrate the connectedness of fast and slow CMEs, which have commonly been assumed to be distinct phenomena. Our simulations indicate that the acceleration profile of a CME is linked to the steepness of the decline in the field strength above the flux rope within the region, where steeper declines are associated with active regions, thus allowing for faster CMEs, while gentler declines, as seen in the quiet Sun, correlate with slower CMEs. Additionally, our results show that the fastest CMEs occur in the most complex active regions, characterized by a quadrupolar magnetic field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.21}
{"prompt": "Rephrase the abstract of an article with title 'Spherically symmetric spacetimes in f(R) gravity theories'.\n  We study both analytically and numerically the gravitational fields of stars\nin f(R) gravity theories. We derive the generalized Tolman-Oppenheimer-Volkov\nequations for these theories and show that in metric f(R) models the\nParameterized Post-Newtonian parameter $\\gamma_{\\rm PPN} = 1/2$ is a robust\noutcome for a large class of boundary conditions set at the center of the star.\nThis result is also unchanged by introduction of dark matter in the Solar\nSystem. We find also a class of solutions with $\\gamma_{\\rm PPN} \\approx 1$ in\nthe metric $f(R)=R-\\mu^4/R$ model, but these solutions turn out to be unstable\nand decay in time. On the other hand, the Palatini version of the theory is\nfound to satisfy the Solar System constraints. We also consider compact stars\nin the Palatini formalism, and show that these models are not inconsistent with\npolytropic equations of state. Finally, we comment on the equivalence between\nf(R) gravity and scalar-tensor theories and show that many interesting Palatini\nf(R) gravity models can not be understood as a limiting case of a\nJordan-Brans-Dicke theory with $\\omega \\to -3/2$.\n\n", "human_text": "  We study both analytically and numerically the gravitational fields of stars\nin f(R) gravity theories. We derive the generalized Tolman-Oppenheimer-Volkov\nequations for these theories and show that in metric f(R) models the\nParameterized Post-Newtonian parameter $\\gamma_{\\rm PPN} = 1/2$ is a robust\noutcome for a large class of boundary conditions set at the center of the star.\nThis result is also unchanged by introduction of dark matter in the Solar\nSystem. We find also a class of solutions with $\\gamma_{\\rm PPN} \\approx 1$ in\nthe metric $f(R)=R-\\mu^4/R$ model, but these solutions turn out to be unstable\nand decay in time. On the other hand, the Palatini version of the theory is\nfound to satisfy the Solar System constraints. We also consider compact stars\nin the Palatini formalism, and show that these models are not inconsistent with\npolytropic equations of state. Finally, we comment on the equivalence between\nf(R) gravity and scalar-tensor theories and show that many interesting Palatini\nf(R) gravity models can not be understood as a limiting case of a\nJordan-Brans-Dicke theory with $\\omega \\to -3/2$.\n", "machine_text": "\nWe explore both analytically and numerically the effects of various f(R) gravity theories on spherically symmetric spacetimes. By deriving the corresponding Tolman-Oppenheimer-Volkov equations, we demonstrate that metric f(R) models lead to a consistent $\\gamma_{\\rm PPN}=1/2$ Parameterized Post-Newtonian parameter, which is unchanged when dark matter is introduced. The same metric model however produces a $\\gamma_{\\rm PPN}\\approx1$ result, which proves to be a short-lived solution. In contrast, our analysis of the Palatini version of the theory complies with experiments done in the Solar System. In assessing compact stars, we discover no discrepancies between the Palatini formalism and the polytropic equations of state. We finally reflect on the parallel between f(R) gravity and scalar-tensor theories, arguing that not all interesting Palatini f(R) models can be presented as a limiting case of a Jordan-Brans-Dicke theory with $\\omega \\to -3/2$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2729}
{"prompt": "Rephrase the abstract of an article with title 'Systematic corrections to the measured cosmological constant as a result\n  of local inhomogeneity'.\n  We calculate the systematic inhomogeneity-induced correction to the\ncosmological constant that one would infer from an analysis of the luminosities\nand redshifts of Type Ia supernovae, assuming a homogeneous universe. The\ncalculation entails a post-Newtonian expansion within the framework of second\norder perturbation theory, wherein we consider the effects of subhorizon\ndensity perturbations in a flat, dust dominated universe. Within this\nformalism, we calculate luminosity distances and redshifts along the past light\ncone of an observer. The resulting luminosity distance-redshift relation is fit\nto that of a homogeneous model in order to deduce the best-fit cosmological\nconstant density Omega_Lambda. We find that the luminosity distance-redshift\nrelation is indeed modified, by a small fraction of order 10^{-5}. When fitting\nthis perturbed relation to that of a homogeneous universe, we find that the\ninferred cosmological constant can be surprisingly large, depending on the\nrange of redshifts sampled. For a sample of supernovae extending from z=0.02\nout to z=0.15, we find that Omega_Lambda=0.004. The value of Omega_Lambda has a\nlarge variance, and its magnitude tends to get larger for smaller redshifts,\nimplying that precision measurements from nearby supernova data will require\ntaking this effect into account. However, we find that this effect is likely\ntoo small to explain the observed value of Omega_Lambda=0.7. There have been\nprevious claims of much larger backreaction effects. By contrast to those\ncalculations, our work is directly related to how observers deduce cosmological\nparameters from astronomical data.\n\n", "human_text": "  We calculate the systematic inhomogeneity-induced correction to the\ncosmological constant that one would infer from an analysis of the luminosities\nand redshifts of Type Ia supernovae, assuming a homogeneous universe. The\ncalculation entails a post-Newtonian expansion within the framework of second\norder perturbation theory, wherein we consider the effects of subhorizon\ndensity perturbations in a flat, dust dominated universe. Within this\nformalism, we calculate luminosity distances and redshifts along the past light\ncone of an observer. The resulting luminosity distance-redshift relation is fit\nto that of a homogeneous model in order to deduce the best-fit cosmological\nconstant density Omega_Lambda. We find that the luminosity distance-redshift\nrelation is indeed modified, by a small fraction of order 10^{-5}. When fitting\nthis perturbed relation to that of a homogeneous universe, we find that the\ninferred cosmological constant can be surprisingly large, depending on the\nrange of redshifts sampled. For a sample of supernovae extending from z=0.02\nout to z=0.15, we find that Omega_Lambda=0.004. The value of Omega_Lambda has a\nlarge variance, and its magnitude tends to get larger for smaller redshifts,\nimplying that precision measurements from nearby supernova data will require\ntaking this effect into account. However, we find that this effect is likely\ntoo small to explain the observed value of Omega_Lambda=0.7. There have been\nprevious claims of much larger backreaction effects. By contrast to those\ncalculations, our work is directly related to how observers deduce cosmological\nparameters from astronomical data.\n", "machine_text": "We present a calculation of the systematic correction that would be applied to observed data on the cosmological constant, given a homogeneous universe model. Our approach uses second-order perturbation theory to examine the influence of subhorizon density fluctuations on the luminosity-distance z relation in a flat, dust-filled universe. We find that the luminosity-distance-z relation is altered by a small proportion--on the order of 10^{-5}. Accounting for this effect when making inferences from local Type Ia supernovae data can lead to a large variation in the resulting Omega_Lambda values. For a sample of supernovae spanning the redshifts 0.02 to 0.15, we deduce Omega_Lambda=0.004. We find that the magnitude of this correction increases as the redshifts decrease, illustrating the need for this effect to be taken into account when making precision measurements at low distances. We conclude that although this variation is significant, it is too small to account for the measured value of Omega_Lambda=0.7. In comparison to other similar findings of major backreaction effects, our work focuses on the application of these effects to observations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1931}
{"prompt": "Rephrase the abstract of an article with title 'Probing the Structure of Gamma-Ray Burst Jets with Steep Decay Phase of\n  their Early X-ray Afterglows'.\n  We show that the jet structure of gamma-ray bursts (GRBs) can be investigated\nwith the tail emission of the prompt GRB. The tail emission which we consider\nis identified as a steep-decay component of the early X-ray afterglow observed\nby the X-ray Telescope onboard Swift. Using a Monte Carlo method, we derive,\nfor the first time, the distribution of the decay index of the GRB tail\nemission for various jet models. The new definitions of the zero of time and\nthe time interval of a fitting region are proposed. These definitions for\nfitting the light curve lead us an unique definition of the decay index, which\nis useful to investigate the structure of the GRB jet. We find that if the GRB\njet has a core-envelope structure, the predicted distribution of the decay\nindex of the tail has a wide scatter and has multiple peaks, which cannot be\nseen for the case of the uniform and the Gaussian jet. Therefore, the decay\nindex distribution tells us the information on the jet structure. Especially,\nif we observe events whose decay index is less than about 2, both the uniform\nand the Gaussian jet models will be disfavored according to our simulation\nstudy.\n\n", "human_text": "  We show that the jet structure of gamma-ray bursts (GRBs) can be investigated\nwith the tail emission of the prompt GRB. The tail emission which we consider\nis identified as a steep-decay component of the early X-ray afterglow observed\nby the X-ray Telescope onboard Swift. Using a Monte Carlo method, we derive,\nfor the first time, the distribution of the decay index of the GRB tail\nemission for various jet models. The new definitions of the zero of time and\nthe time interval of a fitting region are proposed. These definitions for\nfitting the light curve lead us an unique definition of the decay index, which\nis useful to investigate the structure of the GRB jet. We find that if the GRB\njet has a core-envelope structure, the predicted distribution of the decay\nindex of the tail has a wide scatter and has multiple peaks, which cannot be\nseen for the case of the uniform and the Gaussian jet. Therefore, the decay\nindex distribution tells us the information on the jet structure. Especially,\nif we observe events whose decay index is less than about 2, both the uniform\nand the Gaussian jet models will be disfavored according to our simulation\nstudy.\n", "machine_text": "\nAn investigation of the jet structure of gamma-ray bursts (GRBs) can be done\nwith the steep-decay phase of their early X-ray afterglow, based on the effects\nobserved by the X-ray Telescope onboard Swift. A Monte Carlo method is used to\ncalculate the decay index distribution of the GRB tail emission for different\nmodels. We propose new definitions, for the time of zero and the interval to be\nfitted, which allow us to come up with an exclusive definition of the decay\nindex and identify the jet structure. The results demonstrate that if the jet\nstructure has a core-envelope structure, the obtained distribution of the decay\nindex will be broad and have more than one peak. Consequently, if the decay\nindex for a certain event is below 2, we can rule out both uniform and Gaussian\njet models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1055}
{"prompt": "Rephrase the abstract of an article with title 'Theory of Two-Photon Interactions with Broadband Down-Converted Light\n  and Entangled Photons'.\n  When two-photon interactions are induced by down-converted light with a\nbandwidth that exceeds the pump bandwidth, they can obtain a behavior that is\npulse-like temporally, yet spectrally narrow. At low photon fluxes this\nbehavior reflects the time and energy entanglement between the down-converted\nphotons. However, two-photon interactions such as two-photon absorption (TPA)\nand sum-frequency generation (SFG) can exhibit such a behavior even at high\npower levels, as long as the final state (i.e. the atomic level in TPA, or the\ngenerated light in SFG) is narrowband enough. This behavior does not depend on\nthe squeezing properties of the light, is insensitive to linear losses, and has\npotential applications. In this paper we describe analytically this behavior\nfor travelling-wave down-conversion with continuous or pulsed pumping, both for\nhigh- and low-power regimes. For this we derive a quantum-mechanical expression\nfor the down-converted amplitude generated by an arbitrary pump, and formulate\noperators that represent various two-photon interactions induced by broadband\nlight. This model is in excellent agreement with experimental results of TPA\nand SFG with high power down-converted light and with entangled photons [Dayan\net al., Phys. Rev. Lett. 93, 023005 (2004), Dayan et al., Phys. Rev. Lett. 94,\n043602, (2005), Pe'er et al., Phys. Rev. Lett. 94, 073601 (2005)].\n\n", "human_text": "  When two-photon interactions are induced by down-converted light with a\nbandwidth that exceeds the pump bandwidth, they can obtain a behavior that is\npulse-like temporally, yet spectrally narrow. At low photon fluxes this\nbehavior reflects the time and energy entanglement between the down-converted\nphotons. However, two-photon interactions such as two-photon absorption (TPA)\nand sum-frequency generation (SFG) can exhibit such a behavior even at high\npower levels, as long as the final state (i.e. the atomic level in TPA, or the\ngenerated light in SFG) is narrowband enough. This behavior does not depend on\nthe squeezing properties of the light, is insensitive to linear losses, and has\npotential applications. In this paper we describe analytically this behavior\nfor travelling-wave down-conversion with continuous or pulsed pumping, both for\nhigh- and low-power regimes. For this we derive a quantum-mechanical expression\nfor the down-converted amplitude generated by an arbitrary pump, and formulate\noperators that represent various two-photon interactions induced by broadband\nlight. This model is in excellent agreement with experimental results of TPA\nand SFG with high power down-converted light and with entangled photons [Dayan\net al., Phys. Rev. Lett. 93, 023005 (2004), Dayan et al., Phys. Rev. Lett. 94,\n043602, (2005), Pe'er et al., Phys. Rev. Lett. 94, 073601 (2005)].\n", "machine_text": "\nThis paper explores the behavior of two-photon interactions utilizing down-converted light with a bandwidth greater than the pump bandwidth, resulting in a temporally pulse-like and spectrally narrow behavior. When the threshold of low photon flux is reached, the entanglement of the down-converted photons in time and energy is evidenced. Such two-photon interactions such as two-photon absorption (TPA) and sum-frequency generation (SFG) can manifest similarly, as long as the final state is of a narrowband nature. The theory is formulatated with operators for two-photon interactions induced by broadband light, and the presence of linear losses does not affect its validty. To form a better understanding of this behavior, a quantum-mechanical expression for the down-converted amplitude stimulated by an arbitrary pump is derived, valid in both high- and low-power regimes. This model is verified to be in excellent agreement with experimental results of TPA and SFG using high power down-converted light and entangled photons.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2859}
{"prompt": "Rephrase the abstract of an article with title 'New exact solution of Dirac-Coulomb equation with exact boundary\n  condition'.\n  It usually writes the boundary condition of the wave equation in the Coulomb\nfield as a rough form without considering the size of the atomic nucleus. The\nrough expression brings on that the solutions of the Klein-Gordon equation and\nthe Dirac equation with the Coulomb potential are divergent at the origin of\nthe coordinates, also the virtual energies, when the nuclear charges number Z >\n137, meaning the original solutions do not satisfy the conditions for\ndetermining solution. Any divergences of the wave functions also imply that the\nprobability density of the meson or the electron would rapidly increase when\nthey are closing to the atomic nucleus. What it predicts is not a truth that\nthe atom in ground state would rapidly collapse to the neutron-like. We\nconsider that the atomic nucleus has definite radius and write the exact\nboundary condition for the hydrogen and hydrogen-like atom, then newly solve\nthe radial Dirac-Coulomb equation and obtain a new exact solution without any\nmathematical and physical difficulties. Unexpectedly, the K value constructed\nby Dirac is naturally written in the barrier width or the equivalent radius of\nthe atomic nucleus in solving the Dirac equation with the exact boundary\ncondition, and it is independent of the quantum energy. Without any divergent\nwave function and the virtual energies, we obtain a new formula of the energy\nlevels that is different from the Dirac formula of the energy levels in the\nCoulomb field.\n\n", "human_text": "  It usually writes the boundary condition of the wave equation in the Coulomb\nfield as a rough form without considering the size of the atomic nucleus. The\nrough expression brings on that the solutions of the Klein-Gordon equation and\nthe Dirac equation with the Coulomb potential are divergent at the origin of\nthe coordinates, also the virtual energies, when the nuclear charges number Z >\n137, meaning the original solutions do not satisfy the conditions for\ndetermining solution. Any divergences of the wave functions also imply that the\nprobability density of the meson or the electron would rapidly increase when\nthey are closing to the atomic nucleus. What it predicts is not a truth that\nthe atom in ground state would rapidly collapse to the neutron-like. We\nconsider that the atomic nucleus has definite radius and write the exact\nboundary condition for the hydrogen and hydrogen-like atom, then newly solve\nthe radial Dirac-Coulomb equation and obtain a new exact solution without any\nmathematical and physical difficulties. Unexpectedly, the K value constructed\nby Dirac is naturally written in the barrier width or the equivalent radius of\nthe atomic nucleus in solving the Dirac equation with the exact boundary\ncondition, and it is independent of the quantum energy. Without any divergent\nwave function and the virtual energies, we obtain a new formula of the energy\nlevels that is different from the Dirac formula of the energy levels in the\nCoulomb field.\n", "machine_text": "\nIn this article, we build on the existing knowledge of the Dirac-Coulomb equation, which typically entails disregarding the size of the atomic nucleus, to create a new exact solution which accounts for a nucleus of definite size. Previous rough expressions of the boundary condition had resulted in divergent wave functions and virtual energies when the charges of the nucleus are greater than 137. This, in turn, predicted an atom in ground state undergoing a rapid collapse to the state of a neutron-like particle. However, by forming an exact boundary condition for the hydrogen and hydrogen-like atoms, we have generated a solution for the radial Dirac-Coulomb equation which is free of any mathematical or physical difficulties. To our surprise, the K value as determined by Dirac is shown to be ultimately determined by the barrier width or the radius of the nucleus, and is not dependant upon the quantum energy. Consequently, a novel formula for the energy levels in a Coulomb field is produced, differentiating itself from the Dirac formula of the energy levels.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3876}
{"prompt": "Rephrase the abstract of an article with title 'Distortion of Gravitational-Wave Packets Due to their Self-Gravity'.\n  When a source emits a gravity-wave (GW) pulse over a short period of time,\nthe leading edge of the GW signal is redshifted more than the inner boundary of\nthe pulse. The GW pulse is distorted by the gravitational effect of the\nself-energy residing in between these shells. We illustrate this distortion for\nGW pulses from the final plunge of black hole (BH) binaries, leading to the\nevolution of the GW profile as a function of the radial distance from the\nsource. The distortion depends on the total GW energy released and the duration\nof the emission, scaled by the total binary mass, M. The effect should be\nrelevant in finite box simulations where the waveforms are extracted within a\nradius of <~ 100M. For characteristic emission parameters at the final plunge\nbetween binary BHs of arbitrary spins, this effect could distort the simulated\nGW templates for LIGO and LISA by a fraction of 0.001. Accounting for the wave\ndistortion would significantly decrease the waveform extraction errors in\nnumerical simulations.\n\n", "human_text": "  When a source emits a gravity-wave (GW) pulse over a short period of time,\nthe leading edge of the GW signal is redshifted more than the inner boundary of\nthe pulse. The GW pulse is distorted by the gravitational effect of the\nself-energy residing in between these shells. We illustrate this distortion for\nGW pulses from the final plunge of black hole (BH) binaries, leading to the\nevolution of the GW profile as a function of the radial distance from the\nsource. The distortion depends on the total GW energy released and the duration\nof the emission, scaled by the total binary mass, M. The effect should be\nrelevant in finite box simulations where the waveforms are extracted within a\nradius of <~ 100M. For characteristic emission parameters at the final plunge\nbetween binary BHs of arbitrary spins, this effect could distort the simulated\nGW templates for LIGO and LISA by a fraction of 0.001. Accounting for the wave\ndistortion would significantly decrease the waveform extraction errors in\nnumerical simulations.\n", "machine_text": "\nThe compact emission of gravity-waves (GWs) from sources such as binary black holes produces a wavepacket that experiences a redshift at the self-gravitational level due to its own energy. This wavepacket distortion affects the waveform profile as a function of radial separation from the source, with an accuracy dependent on the total energy emitted, emission time, and total binary mass, M. Simulations in finite boxes with waveforms extracted within a radius of <= 100M can be affected by this wave distortion, resulting in errors in the waveform template for LIGO and LISA. Knowing the distortion parameters can help decrease the waveform extraction errors in numerical simulations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1149}
{"prompt": "Rephrase the abstract of an article with title 'Extended Comment on \"One-Range Addition Theorems for Coulomb Interaction\n  Potential and Its Derivatives\" by I. I. Guseinov (Chem. Phys. Vol. 309\n  (2005), pp. 209 - 213)'.\n  Addition theorems are principal tools that express a function $f (\\bm{r} \\pm\n\\bm{r}')$ in terms of products of other functions that only depend on either\n$\\bm{r}$ or $\\bm{r}'$. The best known example of such an addition theorem is\nthe Laplace expansion of the Coulomb potential which possesses a characteristic\ntwo-range form. Guseinov [Chem. Phys. {\\bf 309}, 209 - 213 (2005)] derived\none-range addition theorems for the Coulomb potential via the limit $\\beta \\to\n0$ in previously derived one-range addition theorems for the Yukawa potential\n$\\exp \\bigl(-\\beta | \\bm{r}-\\bm{r}'| \\bigr) /| \\bm{r}-\\bm{r}'|$. At first\nsight, this looks like a remarkable achievement, but from a mathematical point\nof view, Guseinov's work is at best questionable and in some cases\nfundamentally flawed. One-range addition theorems are expansions in terms of\nfunctions that are complete and orthonormal in a given Hilbert space, but\nGuseinov replaced the complete and orthonormal functions by nonorthogonal\nSlater-type functions and rearranged the resulting expansions. This is a\ndangerous operation whose validity must be checked. It is shown that the\none-center limit $\\bm{r}' = \\bm{0}$ of Guseinov's rearranged Yukawa addition\ntheorems as well as of several other addition theorems does not exist.\nMoreover, the Coulomb potential does not belong to any of the Hilbert spaces\nimplicitly used by Guseinov. Accordingly, one-range addition theorems for the\nCoulomb potential diverge in the mean. Instead, these one-range addition\ntheorems have to interpreted as expansions of generalized functions in the\nsense of Schwartz that converge weakly in suitable functionals.\n\n", "human_text": "  Addition theorems are principal tools that express a function $f (\\bm{r} \\pm\n\\bm{r}')$ in terms of products of other functions that only depend on either\n$\\bm{r}$ or $\\bm{r}'$. The best known example of such an addition theorem is\nthe Laplace expansion of the Coulomb potential which possesses a characteristic\ntwo-range form. Guseinov [Chem. Phys. {\\bf 309}, 209 - 213 (2005)] derived\none-range addition theorems for the Coulomb potential via the limit $\\beta \\to\n0$ in previously derived one-range addition theorems for the Yukawa potential\n$\\exp \\bigl(-\\beta | \\bm{r}-\\bm{r}'| \\bigr) /| \\bm{r}-\\bm{r}'|$. At first\nsight, this looks like a remarkable achievement, but from a mathematical point\nof view, Guseinov's work is at best questionable and in some cases\nfundamentally flawed. One-range addition theorems are expansions in terms of\nfunctions that are complete and orthonormal in a given Hilbert space, but\nGuseinov replaced the complete and orthonormal functions by nonorthogonal\nSlater-type functions and rearranged the resulting expansions. This is a\ndangerous operation whose validity must be checked. It is shown that the\none-center limit $\\bm{r}' = \\bm{0}$ of Guseinov's rearranged Yukawa addition\ntheorems as well as of several other addition theorems does not exist.\nMoreover, the Coulomb potential does not belong to any of the Hilbert spaces\nimplicitly used by Guseinov. Accordingly, one-range addition theorems for the\nCoulomb potential diverge in the mean. Instead, these one-range addition\ntheorems have to interpreted as expansions of generalized functions in the\nsense of Schwartz that converge weakly in suitable functionals.\n", "machine_text": "This paper offers an extended analysis of I. I. Guseinov's work on one-range addition theorems for the Coulomb interaction potential and its derivatives. Through the use of previously derived one-range addition theorems for the Yukawa potential with limit $\\beta \\to 0$, Guseinov aimed to understand the function $f (\\bm{r} \\pm \\bm{r}')$ in terms of products of functions depending on either $\\bm{r}$ or $\\bm{r}'$, similar to the famous Laplace expansion of the Coulomb potential. Although Guseinov's approach looks promising, it is found that his conclusions are mathematically questionable and in some cases fundamentally flawed. It is demonstrated that the one-center limit of Guseinov's rearranged Yukawa addition theorems, as well as other addition theorems, do not exist, and the Coulomb potential does not belong to any of the Hilbert spaces used. Therefore, one-range addition theorems for the Coulomb potential diverge in the mean and must be interpreted as expansions of Schwartz's generalized functions that converge weakly in suitable functionals.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1088}
{"prompt": "Rephrase the abstract of an article with title 'The Early Spectrophotometric Evolution of V1186 Scorpii (Nova Scorpii\n  2004 #1)'.\n  We report optical photometry and optical through mid-infrared spectroscopy of\nthe classical nova V1186 Sco. This slowly developing nova had an complex light\ncurve with multiple secondary peaks similar to those seen in PW Vul. The time\nto decline 2 magnitudes, t$_2$, was 20 days but the erratic nature of the light\ncurve makes determination of intrinsic properties based on the decline time\n(e.g., luminosity) problematic, and the often cited MMRD relationship of Della\nValle and Livio (1995) fails to yield a plausible distance. Spectra covering\n0.35 to 35 $\\mu$m were obtained in two separate epochs during the first year of\noutburst. The first set of spectra, taken about 2 months after visible maximum,\nare typical of a CO-type nova with narrow line emission from \\ion{H}{1},\n\\ion{Fe}{2}, \\ion{O}{1} and \\ion{He}{1}. Later data, obtained between 260 and\n380 days after maximum, reveal an emerging nebular spectrum. \\textit{Spitzer}\nspectra show weakening hydrogen recombination emission with the emergence of\n[\\ion{Ne}{2}] (12.81 $\\mu$m) as the strongest line. Strong emission from\n[\\ion{Ne}{3}] (15.56 $\\mu$m) is also detected. Photoionization models with low\neffective temperature sources and only marginal neon enhancement (Ne $\\sim$ 1.3\nNe$_{\\odot}$) are consistent with these IR fine-structure neon lines indicating\nthat V1186 Sco did not occur on a ONeMg white dwarf. In contrast, the slow and\nerratic light curve evolution, spectral development, and photoionization\nanalysis of the ejecta imply the outburst occurred on a low mass CO white\ndwarf. We note that this is the first time strong [\\ion{Ne}{2}] lines have been\ndetected so early in the outburst of a CO nova and suggests that the presence\nof mid-infrared neon lines is not directly indicative of a ONeMg nova event.\n\n", "human_text": "  We report optical photometry and optical through mid-infrared spectroscopy of\nthe classical nova V1186 Sco. This slowly developing nova had an complex light\ncurve with multiple secondary peaks similar to those seen in PW Vul. The time\nto decline 2 magnitudes, t$_2$, was 20 days but the erratic nature of the light\ncurve makes determination of intrinsic properties based on the decline time\n(e.g., luminosity) problematic, and the often cited MMRD relationship of Della\nValle and Livio (1995) fails to yield a plausible distance. Spectra covering\n0.35 to 35 $\\mu$m were obtained in two separate epochs during the first year of\noutburst. The first set of spectra, taken about 2 months after visible maximum,\nare typical of a CO-type nova with narrow line emission from \\ion{H}{1},\n\\ion{Fe}{2}, \\ion{O}{1} and \\ion{He}{1}. Later data, obtained between 260 and\n380 days after maximum, reveal an emerging nebular spectrum. \\textit{Spitzer}\nspectra show weakening hydrogen recombination emission with the emergence of\n[\\ion{Ne}{2}] (12.81 $\\mu$m) as the strongest line. Strong emission from\n[\\ion{Ne}{3}] (15.56 $\\mu$m) is also detected. Photoionization models with low\neffective temperature sources and only marginal neon enhancement (Ne $\\sim$ 1.3\nNe$_{\\odot}$) are consistent with these IR fine-structure neon lines indicating\nthat V1186 Sco did not occur on a ONeMg white dwarf. In contrast, the slow and\nerratic light curve evolution, spectral development, and photoionization\nanalysis of the ejecta imply the outburst occurred on a low mass CO white\ndwarf. We note that this is the first time strong [\\ion{Ne}{2}] lines have been\ndetected so early in the outburst of a CO nova and suggests that the presence\nof mid-infrared neon lines is not directly indicative of a ONeMg nova event.\n", "machine_text": "\nWe present analysis of the optical and mid-infrared spectrophotometric evolution of V1186 Scorpii, a classical nova, during the first year of its outburst. Initial spectra taken shortly after its visible peak show typical CO-type nova features with strong hydrogen, iron, oxygen, and helium emission and a complex light curve behavior akin to PW Vul. Determination of the intrinsic characteristics based on t$_2$ is made difficult due to the instability of the light curve, and no plausible distance can be found from the MMRD relationship. Further examination of the spectra from 260 to 380 days after the outburst peak reveals transition into a nebular spectrum, with considerable weakening of hydrogen emission and the emergence of Ne II (12.81 $\\mu$m) and Ne III (15.56 $\\mu$m) being the strongest lines. Modelling of the photoionization process confirms annealing of a low temperature source and low levels of neon enhancement, contradicting the typical result that classical novae like V1186 Sco occur on ONeMg white dwarfs. This study is of unique significance as strong Ne II lines rarely appear so early during the outburst of a CO nova; further implying that the emissions in the mid-infrared are not only indicative of ONeMg nova events.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0701}
{"prompt": "Rephrase the abstract of an article with title 'Transient behavior of surface plasmon polaritons scattered at a\n  subwavelength groove'.\n  We present a numerical study and analytical model of the optical near-field\ndiffracted in the vicinity of subwavelength grooves milled in silver surfaces.\nThe Green's tensor approach permits computation of the phase and amplitude\ndependence of the diffracted wave as a function of the groove geometry. It is\nshown that the field diffracted along the interface by the groove is equivalent\nto replacing the groove by an oscillating dipolar line source. An analytic\nexpression is derived from the Green's function formalism, that reproduces well\nthe asymptotic surface plasmon polariton (SPP) wave as well as the transient\nsurface wave in the near-zone close to the groove. The agreement between this\nmodel and the full simulation is very good, showing that the transient\n\"near-zone\" regime does not depend on the precise shape of the groove. Finally,\nit is shown that a composite diffractive evanescent wave model that includes\nthe asymptotic SPP can describe the wavelength evolution in this transient\nnear-zone. Such a semi-analytical model may be useful for the design and\noptimization of more elaborate photonic circuits whose behavior in large part\nwill be controlled by surface waves.\n\n", "human_text": "  We present a numerical study and analytical model of the optical near-field\ndiffracted in the vicinity of subwavelength grooves milled in silver surfaces.\nThe Green's tensor approach permits computation of the phase and amplitude\ndependence of the diffracted wave as a function of the groove geometry. It is\nshown that the field diffracted along the interface by the groove is equivalent\nto replacing the groove by an oscillating dipolar line source. An analytic\nexpression is derived from the Green's function formalism, that reproduces well\nthe asymptotic surface plasmon polariton (SPP) wave as well as the transient\nsurface wave in the near-zone close to the groove. The agreement between this\nmodel and the full simulation is very good, showing that the transient\n\"near-zone\" regime does not depend on the precise shape of the groove. Finally,\nit is shown that a composite diffractive evanescent wave model that includes\nthe asymptotic SPP can describe the wavelength evolution in this transient\nnear-zone. Such a semi-analytical model may be useful for the design and\noptimization of more elaborate photonic circuits whose behavior in large part\nwill be controlled by surface waves.\n", "machine_text": "\nThis study presents a numerical and analytical evaluation of the optical near-field behavior emanating from subwavelength grooves etched into silver surfaces. The Green's tensor approach is used to analyze the phase and intensity of the diffracted wave in relation to varying groove geometries. It is discovered that the diffraction field along the interface is analogous to analyzing this kind of field from a vibrating dipolar line source. By combining the Green's function with a semi-analytical model, a description of the transient near-zone regime and its dependence on the wavelength is given. This model may be utilized for constructing photonic circuits and optimizing their performance, as the behavior is largely dependent on the surface waves.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0703}
{"prompt": "Rephrase the abstract of an article with title 'Radio Astrometric Detection and Characterization of Extra-Solar Planets:\n  A White Paper Submitted to the NSF ExoPlanet Task Force'.\n  The extraordinary astrometric accuracy of radio interferometry creates an\nimportant and unique opportunity for the discovery and characterization of\nexo-planets. Currently, the Very Long Baseline Array can routinely achieve\nbetter than 100 microarcsecond accuracy, and can approach 10 microarcsecond\nwith careful calibration. We describe here RIPL, the Radio Interferometric\nPLanet search, a new program with the VLBA and the Green Bank 100 m telescope\nthat will survey 29 low-mass, active stars over 3 years with sub-Jovian planet\nmass sensitivity at 1 AU. An upgrade of the VLBA bandwidth will increase\nastrometric accuracy by an order of magnitude. Ultimately, the colossal\ncollecting area of the Square Kilometer Array could push astrometric accuracy\nto 1 microarcsecond, making detection and characterizaiton of Earth mass\nplanets possible.\n  RIPL and other future radio astrometric planet searches occupy a unique\nvolume in planet discovery and characterization parameter space. The parameter\nspace of astrometric searches gives greater sensitivity to planets at large\nradii than radial velocity searches. For the VLBA and the expanded VLBA, the\ntargets of radio astrometric surveys are by necessity nearby, low-mass, active\nstars, which cannot be studied efficiently through the radial velocity method,\ncoronagraphy, or optical interferometry. For the SKA, detection sensitivity\nwill extend to solar-type stars. Planets discovered through radio astrometric\nmethods will be suitable for characterization through extreme adaptive optics.\n  The complementarity of radio astrometric techniques with other methods\ndemonstrates that radio astrometry can play an important role in the roadmap\nfor exoplanet discovery and characterization.\n\n", "human_text": "  The extraordinary astrometric accuracy of radio interferometry creates an\nimportant and unique opportunity for the discovery and characterization of\nexo-planets. Currently, the Very Long Baseline Array can routinely achieve\nbetter than 100 microarcsecond accuracy, and can approach 10 microarcsecond\nwith careful calibration. We describe here RIPL, the Radio Interferometric\nPLanet search, a new program with the VLBA and the Green Bank 100 m telescope\nthat will survey 29 low-mass, active stars over 3 years with sub-Jovian planet\nmass sensitivity at 1 AU. An upgrade of the VLBA bandwidth will increase\nastrometric accuracy by an order of magnitude. Ultimately, the colossal\ncollecting area of the Square Kilometer Array could push astrometric accuracy\nto 1 microarcsecond, making detection and characterizaiton of Earth mass\nplanets possible.\n  RIPL and other future radio astrometric planet searches occupy a unique\nvolume in planet discovery and characterization parameter space. The parameter\nspace of astrometric searches gives greater sensitivity to planets at large\nradii than radial velocity searches. For the VLBA and the expanded VLBA, the\ntargets of radio astrometric surveys are by necessity nearby, low-mass, active\nstars, which cannot be studied efficiently through the radial velocity method,\ncoronagraphy, or optical interferometry. For the SKA, detection sensitivity\nwill extend to solar-type stars. Planets discovered through radio astrometric\nmethods will be suitable for characterization through extreme adaptive optics.\n  The complementarity of radio astrometric techniques with other methods\ndemonstrates that radio astrometry can play an important role in the roadmap\nfor exoplanet discovery and characterization.\n", "machine_text": "\nAstrometric accuracy approaching 10 microarcseconds through the use of Very\nLong Baseline Arrays (VLBA) and beyond can enable the discovery and  characterization  of  exoplanets.  We  present  RIPL,  the  Radio  Interferometric  Planet Search, a program which will survey 29 low-mass, active stars with the VLBA and the Green Bank 100m Telescope. With the upgrade of the VLBA bandwidth, the astrometric accuracy could improve by an order of magnitude while the Square Kilometer Array (SKA) could potentially achieve an unprecedented 1 microarcsecond detection and characterization of Earth-mass planets.\n\nThe parameter space of radio astrometric searches provides greater sensitivity to planets at larger radii than radial velocity searches. The fact that the VLBA and expanded VLBA are ideal for regions that can not be examined efficiently through the radial velocity method, coronagraphy or optical interferometry makes radio astrometry a unique and vital tool in the roadmap for exoplanet discovery and characterization.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0238}
{"prompt": "Rephrase the abstract of an article with title 'Structures in the Universe and Origin of Galaxies'.\n  The analysis of images (of obtained in various ranges of the lengths of\nwaves) of luminous objects in the Universe by means of a method of multilevel\ndynamic contrasting led author to the conclusions: a) the structures of all\nobservable galaxies represents a complicated constructions which have the\ntendency to self-similarity and made of separate (basic) blocks, which are a\ncoaxially tubular structures and a cartwheel-like structures; b) the majority\nof observable objects in the Universe are luminous butt-ends of almost\ninvisible (of almost completely transparent) of filamentary formations which\nstructures are seen only near to their luminous butt-ends; c) the result of\nanalysis of images of cosmic objects show the structure of many pairs of\ncooperating galaxies point to opportunity of their formation at butt-ends\ngenerated in a place of break of the similar filament; d) the interacting\ngalaxies (M 81 and M 82) show they are butt-ends of sawed off of two branches\nof a treelike filament and their interaction is coming out through this\nfilament; e) as our Universe is in dynamics the processes of formation of\nstars, galaxies and their congestions can go presently by means of a fracturing\nof filaments with a corresponding diameters and of the time for their such\nformation is necessary much less, than along existing standard model.\n\n", "human_text": "  The analysis of images (of obtained in various ranges of the lengths of\nwaves) of luminous objects in the Universe by means of a method of multilevel\ndynamic contrasting led author to the conclusions: a) the structures of all\nobservable galaxies represents a complicated constructions which have the\ntendency to self-similarity and made of separate (basic) blocks, which are a\ncoaxially tubular structures and a cartwheel-like structures; b) the majority\nof observable objects in the Universe are luminous butt-ends of almost\ninvisible (of almost completely transparent) of filamentary formations which\nstructures are seen only near to their luminous butt-ends; c) the result of\nanalysis of images of cosmic objects show the structure of many pairs of\ncooperating galaxies point to opportunity of their formation at butt-ends\ngenerated in a place of break of the similar filament; d) the interacting\ngalaxies (M 81 and M 82) show they are butt-ends of sawed off of two branches\nof a treelike filament and their interaction is coming out through this\nfilament; e) as our Universe is in dynamics the processes of formation of\nstars, galaxies and their congestions can go presently by means of a fracturing\nof filaments with a corresponding diameters and of the time for their such\nformation is necessary much less, than along existing standard model.\n", "machine_text": "\nThis article investigates the structures of observable galaxies in the Universe and their origin. Using a technique of multilevel dynamic contrasting of luminous objects, the author draws the following conclusions: a) galaxies are highly structured and display a tendency towards self-similarity, as well as tightly packed tubular and cartwheel structures; b) most visible elements in the cosmos are the luminous ends of almost invisible filaments, only visible when viewed close up; c) double galaxies which appear to form in pairs originated from the breaking of similar filaments; d) the galaxies M81 and M82 represent the cutting of two branches of what seems to be a treelike filament, with their interaction occurring via the filament; and e) the dynamics of our universe suggests the formation process of stars and galaxies could be fast enough to be a result of fracturing filaments, as opposed to the existing standard model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1448}
{"prompt": "Rephrase the abstract of an article with title 'Hedging our bets: the expected contribution of species to future\n  phylogenetic diversity'.\n  If predictions for species extinctions hold, then the `tree of life' today\nmay be quite different to that in (say) 100 years. We describe a technique to\nquantify how much each species is likely to contribute to future biodiversity,\nas measured by its expected contribution to phylogenetic diversity. Our\napproach considers all possible scenarios for the set of species that will be\nextant at some future time, and weights them according to their likelihood\nunder an independent (but not identical) distribution on species extinctions.\nAlthough the number of extinction scenarios can typically be very large, we\nshow that there is a simple algorithm that will quickly compute this index. The\nmethod is implemented and applied to the prosimian primates as a test case, and\nthe associated species ranking is compared to a related measure (the `Shapley\nindex'). We describe indices for rooted and unrooted trees, and a modification\nthat also includes the focal taxon's probability of extinction, making it\ndirectly comparable to some new conservation metrics.\n\n", "human_text": "  If predictions for species extinctions hold, then the `tree of life' today\nmay be quite different to that in (say) 100 years. We describe a technique to\nquantify how much each species is likely to contribute to future biodiversity,\nas measured by its expected contribution to phylogenetic diversity. Our\napproach considers all possible scenarios for the set of species that will be\nextant at some future time, and weights them according to their likelihood\nunder an independent (but not identical) distribution on species extinctions.\nAlthough the number of extinction scenarios can typically be very large, we\nshow that there is a simple algorithm that will quickly compute this index. The\nmethod is implemented and applied to the prosimian primates as a test case, and\nthe associated species ranking is compared to a related measure (the `Shapley\nindex'). We describe indices for rooted and unrooted trees, and a modification\nthat also includes the focal taxon's probability of extinction, making it\ndirectly comparable to some new conservation metrics.\n", "machine_text": "\nAs we face potential future extinctions of species, we investigate the potential impact it may have on the overall mammalian phylogenetic tree. Our technique considers all possible outcomes of certain species surviving extinction and measures the expected contribution each species will make towards biodiversity in terms of its phylogenetic diversity index. test our method on prosimian primates, in order to analyze the Shapley index, which considers the focal taxons risk of extinction in comparison to other metrics used in conservation. We present an algorithm with pre-calculated values that quickly compute our index for both rooted and unrooted trees.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2649}
{"prompt": "Rephrase the abstract of an article with title 'Minimal size of a barchan dune'.\n  Barchans are dunes of high mobility which have a crescent shape and propagate\nunder conditions of unidirectional wind. However, sand dunes only appear above\na critical size, which scales with the saturation distance of the sand flux [P.\nHersen, S. Douady, and B. Andreotti, Phys. Rev. Lett. {\\bf{89,}} 264301 (2002);\nB. Andreotti, P. Claudin, and S. Douady, Eur. Phys. J. B {\\bf{28,}} 321 (2002);\nG. Sauermann, K. Kroy, and H. J. Herrmann, Phys. Rev. E {\\bf{64,}} 31305\n(2001)]. It has been suggested by P. Hersen, S. Douady, and B. Andreotti, Phys.\nRev. Lett. {\\bf{89,}} 264301 (2002) that this flux fetch distance is itself\nconstant. Indeed, this could not explain the proto size of barchan dunes, which\noften occur in coastal areas of high litoral drift, and the scale of dunes on\nMars. In the present work, we show from three dimensional calculations of sand\ntransport that the size and the shape of the minimal barchan dune depend on the\nwind friction speed and the sand flux on the area between dunes in a field. Our\nresults explain the common appearance of barchans a few tens of centimeter high\nwhich are observed along coasts. Furthermore, we find that the rate at which\ngrains enter saltation on Mars is one order of magnitude higher than on Earth,\nand is relevant to correctly obtain the minimal dune size on Mars.\n\n", "human_text": "  Barchans are dunes of high mobility which have a crescent shape and propagate\nunder conditions of unidirectional wind. However, sand dunes only appear above\na critical size, which scales with the saturation distance of the sand flux [P.\nHersen, S. Douady, and B. Andreotti, Phys. Rev. Lett. {\\bf{89,}} 264301 (2002);\nB. Andreotti, P. Claudin, and S. Douady, Eur. Phys. J. B {\\bf{28,}} 321 (2002);\nG. Sauermann, K. Kroy, and H. J. Herrmann, Phys. Rev. E {\\bf{64,}} 31305\n(2001)]. It has been suggested by P. Hersen, S. Douady, and B. Andreotti, Phys.\nRev. Lett. {\\bf{89,}} 264301 (2002) that this flux fetch distance is itself\nconstant. Indeed, this could not explain the proto size of barchan dunes, which\noften occur in coastal areas of high litoral drift, and the scale of dunes on\nMars. In the present work, we show from three dimensional calculations of sand\ntransport that the size and the shape of the minimal barchan dune depend on the\nwind friction speed and the sand flux on the area between dunes in a field. Our\nresults explain the common appearance of barchans a few tens of centimeter high\nwhich are observed along coasts. Furthermore, we find that the rate at which\ngrains enter saltation on Mars is one order of magnitude higher than on Earth,\nand is relevant to correctly obtain the minimal dune size on Mars.\n", "machine_text": "This research investigates the minimal size of barchan dunes, which are crescent-shaped, highly mobile dunes. Hersen, Douady, and Andreotti found that the size of sand dunes is dependent on the sand flux saturation point, as well as wind friction speed. Three-dimensional calculations of sand transport show that the minimal size of barchans found along coasts is around tens of centimeters high. Additionally, the entry rate for particles into saltation on Mars is found to be one order of magnitude greater than on Earth, and is necessary for obtaining the minimal dune size. The findings from this research determine how the minimal size of barchan dunes depends on sand flux, wind speed, and location.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1778}
{"prompt": "Rephrase the abstract of an article with title 'Quantum Measurement as a Final-State Interaction with a Macroscopic\n  External System'.\n  A small quantum scattering system (the microsystem) is studied in interaction\nwith a large system (the macrosystem) described by unknown stochastic\nvariables. The interaction between the two systems is diagonal for the\nmicrosystem in a certain orthonormal basis, and the interaction gives an\nimprint on the macrosystem. Moreover, the interaction is assumed to involve\nonly small transfers of energy and momentum between the two systems (as\ncompared to typical energies/momenta within the microsystem). The analysis is\ncarried out within scattering theory. Calculated in the conventional way, the\ntransition amplitude for the whole system factorizes. The interaction taking\nplace within the macrosystem is assumed to depend on the stochastic variables\nin such a way that, on the average, no particular basis vector state of the\nmicrosystem is favoured. The density matrix is studied in a formalism which\nincludes generation of the ingoing state and absorption of the final state.\nThen the dependence of the final state on the conventional scattering amplitude\nfor the microsystem is highly non-linear.\n  In the thermodynamic limit of the macrosystem, the density matrix of the\nensemble (of microsystem plus macrosystem) develops into a final state which\ninvolves a set of macroscopically distinguishable states, each with the\nmicrosystem in one of the basis vector states and the macrosystem in an\nentangled state.\n  For an element of the ensemble, i.e., for a single measurement, the result is\ninstead a random walk, where the microsystem ends up in one of the basis vector\nstates (reduction of the wave packet).\n\n", "human_text": "  A small quantum scattering system (the microsystem) is studied in interaction\nwith a large system (the macrosystem) described by unknown stochastic\nvariables. The interaction between the two systems is diagonal for the\nmicrosystem in a certain orthonormal basis, and the interaction gives an\nimprint on the macrosystem. Moreover, the interaction is assumed to involve\nonly small transfers of energy and momentum between the two systems (as\ncompared to typical energies/momenta within the microsystem). The analysis is\ncarried out within scattering theory. Calculated in the conventional way, the\ntransition amplitude for the whole system factorizes. The interaction taking\nplace within the macrosystem is assumed to depend on the stochastic variables\nin such a way that, on the average, no particular basis vector state of the\nmicrosystem is favoured. The density matrix is studied in a formalism which\nincludes generation of the ingoing state and absorption of the final state.\nThen the dependence of the final state on the conventional scattering amplitude\nfor the microsystem is highly non-linear.\n  In the thermodynamic limit of the macrosystem, the density matrix of the\nensemble (of microsystem plus macrosystem) develops into a final state which\ninvolves a set of macroscopically distinguishable states, each with the\nmicrosystem in one of the basis vector states and the macrosystem in an\nentangled state.\n  For an element of the ensemble, i.e., for a single measurement, the result is\ninstead a random walk, where the microsystem ends up in one of the basis vector\nstates (reduction of the wave packet).\n", "machine_text": "\nThe aim of this article is to study the interaction between a small quantum scattering system (the microsystem) and a large system (the macrosystem). The interaction is assumed to be diagonal in a certain orthonormal basis and involve minimal energy and momentum transfer. An analysis of the transition amplitude for both systems is done using scattering theory, and it is determined that the macrosystem's particle may interact in a random way leading to the wave packet being reduced to one of the basis vector states. In the thermodynamic limit, the ensemble of microsystems and macrosystems develops into a final state with the microsystem in one of the basis vector states and the macrosystem in an entangled state. This final state interaction therefore provides evidence of \"quantum measurement\" as a macroscopic external system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1649}
{"prompt": "Rephrase the abstract of an article with title 'Superconductor-insulator duality for the array of Josephson wires'.\n  We propose novel model system for the studies of superconductor-insulator\ntransitions, which is a regular lattice, whose each link consists of\nJosephson-junction chain of $N \\gg 1$ junctions in sequence. The theory of such\nan array is developed for the case of semiclassical junctions with the\nJosephson energy $E_J$ large compared to the junctions's Coulomb energy $E_C$.\nExact duality transformation is derived, which transforms the Hamiltonian of\nthe proposed model into a standard Hamiltonian of JJ array. The nature of the\nground state is controlled (in the absence of random offset charges) by the\nparameter $q \\approx N^2 \\exp(-\\sqrt{8E_J/E_C})$, with superconductive state\ncorresponding to small $q < q_c $. The values of $q_c$ are calculated for\nmagnetic frustrations $f= 0$ and $f= \\frac12$. Temperature of superconductive\ntransition $T_c(q)$ and $q < q_c$ is estimated for the same values of $f$. In\npresence of strong random offset charges, the T=0 phase diagram is controlled\nby the parameter $\\bar{q} = q/\\sqrt{N}$; we estimated critical value\n$\\bar{q}_c$.\n\n", "human_text": "  We propose novel model system for the studies of superconductor-insulator\ntransitions, which is a regular lattice, whose each link consists of\nJosephson-junction chain of $N \\gg 1$ junctions in sequence. The theory of such\nan array is developed for the case of semiclassical junctions with the\nJosephson energy $E_J$ large compared to the junctions's Coulomb energy $E_C$.\nExact duality transformation is derived, which transforms the Hamiltonian of\nthe proposed model into a standard Hamiltonian of JJ array. The nature of the\nground state is controlled (in the absence of random offset charges) by the\nparameter $q \\approx N^2 \\exp(-\\sqrt{8E_J/E_C})$, with superconductive state\ncorresponding to small $q < q_c $. The values of $q_c$ are calculated for\nmagnetic frustrations $f= 0$ and $f= \\frac12$. Temperature of superconductive\ntransition $T_c(q)$ and $q < q_c$ is estimated for the same values of $f$. In\npresence of strong random offset charges, the T=0 phase diagram is controlled\nby the parameter $\\bar{q} = q/\\sqrt{N}$; we estimated critical value\n$\\bar{q}_c$.\n", "machine_text": "\nWe demonstrate a model of regular lattices whose links are composed of a series of Josephson junctions with large Josephson energy, $E_J$, compared to junction Coulomb energy, $E_C$. Exploring this model's Hamiltonian, we discover a duality transformation that can be applied to arrays of Josephson junctions. The ground state properties are variable according to the parameter $q \\approx N^2 \\exp(-\\sqrt{8E_J/E_C})$, which leads to superconductive states when $q < q_c$. This critical value of $q$ is further determined for magnetic frustrations $f=0$ and $f=\\frac12$. Moreover, the temperature of the superconductive transition, $T_c(q)$ and $q < q_c$, is estimated for similar values of $f$. Additionally, strong random offset charges can affect the zero temperature phase diagram; noting a critical value of $\\bar{q} = q/\\sqrt{N}$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0324}
{"prompt": "Rephrase the abstract of an article with title 'A Global Approach to the Theory of Special Finsler Manifolds'.\n  The aim of the present paper is to provide a global presentation of the\ntheory of special Finsler manifolds. We introduce and investigate globally (or\nintrinsically, free from local coordinates) many of the most important and most\ncommonly used special Finsler manifolds: locally Minkowskian, Berwald,\nLandesberg, general Landesberg, $P$-reducible, $C$-reducible,\nsemi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent,\n$C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of\nthe second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like,\n$R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant\ncurvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global\ndefinitions of these special Finsler manifolds are introduced. Various\nrelationships between the different types of the considered special Finsler\nmanifolds are found. Many local results, known in the literature, are proved\nglobally and several new results are obtained. As a by-product, interesting\nidentities and properties concerning the torsion tensor fields and the\ncurvature tensor fields are deduced. Although our investigation is entirely\nglobal, we provide; for comparison reasons, an appendix presenting a local\ncounterpart of our global approach and the local definitions of the special\nFinsler spaces considered.\n\n", "human_text": "  The aim of the present paper is to provide a global presentation of the\ntheory of special Finsler manifolds. We introduce and investigate globally (or\nintrinsically, free from local coordinates) many of the most important and most\ncommonly used special Finsler manifolds: locally Minkowskian, Berwald,\nLandesberg, general Landesberg, $P$-reducible, $C$-reducible,\nsemi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent,\n$C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of\nthe second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like,\n$R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant\ncurvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global\ndefinitions of these special Finsler manifolds are introduced. Various\nrelationships between the different types of the considered special Finsler\nmanifolds are found. Many local results, known in the literature, are proved\nglobally and several new results are obtained. As a by-product, interesting\nidentities and properties concerning the torsion tensor fields and the\ncurvature tensor fields are deduced. Although our investigation is entirely\nglobal, we provide; for comparison reasons, an appendix presenting a local\ncounterpart of our global approach and the local definitions of the special\nFinsler spaces considered.\n", "machine_text": "This paper provides a comprehensive global perspective of the theory of special Finsler manifolds. Definitions, relationships and results of such manifolds, along with identities and properties of their torsion and curvature tensor fields are studied and examined, in particular, locally Minkowskian, Berwald, Landesberg, general Landesberg, $P$-reducible, $C$-reducible, semi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent, $C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of the second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like, $R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant curvature, of $p$-scalar curvature, and of $s$-$ps$-curvature. Additionally, an appendix is presented providing local information of the special Finsler manifolds studied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0053}
{"prompt": "Rephrase the abstract of an article with title 'Saturation effects in the sub-Doppler spectroscopy of Cesium vapor\n  confined in an Extremely Thin Cell'.\n  Saturation effects affecting absorption and fluorescence spectra of an atomic\nvapor confined in an Extremely Thin Cell (cell thickness $L < 1 \\mu m$) are\ninvestigated experimentally and theoretically. The study is performed on the\n$D_{2}$ line ($\\lambda ~= ~852 nm)$ of $Cs$ and concentrates on the two\nsituations $L = \\lambda /2$ and $L =\\lambda$, the most contrasted ones with\nrespect to the length dependence of the coherent Dicke narrowing. For $L =\n\\lambda /2$, the Dicke-narrowed absorption profile simply broadens and\nsaturates in amplitude when increasing the light intensity, while for $L\n=\\lambda$, sub-Doppler dips of reduced absorption at line-center appear on the\nbroad absorption profile. For a fluorescence detection at $L =\\lambda$,\nsaturation induces narrow dips, but only for hyperfine components undergoing a\npopulation loss through optical pumping. These experimental results are\ninterpreted with the help of the various existing models, and are compared with\nnumerical calculations based upon a two-level modelling that considers both a\nclosed and an open system.\n\n", "human_text": "  Saturation effects affecting absorption and fluorescence spectra of an atomic\nvapor confined in an Extremely Thin Cell (cell thickness $L < 1 \\mu m$) are\ninvestigated experimentally and theoretically. The study is performed on the\n$D_{2}$ line ($\\lambda ~= ~852 nm)$ of $Cs$ and concentrates on the two\nsituations $L = \\lambda /2$ and $L =\\lambda$, the most contrasted ones with\nrespect to the length dependence of the coherent Dicke narrowing. For $L =\n\\lambda /2$, the Dicke-narrowed absorption profile simply broadens and\nsaturates in amplitude when increasing the light intensity, while for $L\n=\\lambda$, sub-Doppler dips of reduced absorption at line-center appear on the\nbroad absorption profile. For a fluorescence detection at $L =\\lambda$,\nsaturation induces narrow dips, but only for hyperfine components undergoing a\npopulation loss through optical pumping. These experimental results are\ninterpreted with the help of the various existing models, and are compared with\nnumerical calculations based upon a two-level modelling that considers both a\nclosed and an open system.\n", "machine_text": "\nThis study looks into the impact of saturation effects on the part of the absorption and fluorescence spectra of atomic vapor confined in an Extremely Thin Cell, measuring fewer than 1 $\\mu$m in thickness. Focus is placed upon the $D_{2}$ line of cesium with a wavelength of 852 nm, predominantly for when the cell is in two situations: $L = \\lambda /2$ and $L = \\lambda$ (the latter having a greater dependence on the effect of Dicke narrowing). With intensities increasing, the Dicke-narrowed absorption profile is observed to broaden and get tamer for $L = \\lambda /2$; however, the profile for $L = \\lambda$ has sub-Doppler dips of lower absorption at the center of the line. Nonetheless, when the light fluoresces at $L = \\lambda$, its saturation leads to dives with a smaller size of the components. Both theoretical models and numerical calculations relying on a two-level system, considering both the open and closed mechanisms, are used to back up the findings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0837}
{"prompt": "Rephrase the abstract of an article with title 'Power spectrum of the maxBCG cluster sample: new evidence for the\n  acoustic features'.\n  We use the direct Fourier method to calculate the redshift-space power\nspectrum of the maxBCG cluster catalog (Koester et al. 2007) -- currently by\nfar the largest existing galaxy cluster sample. The total number of clusters\nused in our analysis is 12,616. After accounting for the radial smearing effect\ncaused by photometric redshift errors and also introducing a simple treatment\nfor the nonlinear effects, we show that currently favored low matter density\n``concordance'' LambdaCDM cosmology provides a very good fit to the estimated\npower. Thanks to the large volume (~ 0.4 h^{-3} Gpc^3), high clustering\namplitude (linear effective bias parameter b_{eff} ~ 3x(0.85/sigma_8)), and\nsufficiently high sampling density (~ 3x10^{-5} h^{3} Mpc^{-3}) the recovered\npower spectrum has high enough signal to noise to allow us to find weak\nevidence (~ 2sigma CL) for the acoustic features. These results are encouraging\nin light of the several proposed large cluster surveys. In case we use the\nphotometric redshift errors as suggested in Koester et al. (2007) we are left\nwith the excess large-scale power which has previously been noticed by several\nother authors.\n\n", "human_text": "  We use the direct Fourier method to calculate the redshift-space power\nspectrum of the maxBCG cluster catalog (Koester et al. 2007) -- currently by\nfar the largest existing galaxy cluster sample. The total number of clusters\nused in our analysis is 12,616. After accounting for the radial smearing effect\ncaused by photometric redshift errors and also introducing a simple treatment\nfor the nonlinear effects, we show that currently favored low matter density\n``concordance'' LambdaCDM cosmology provides a very good fit to the estimated\npower. Thanks to the large volume (~ 0.4 h^{-3} Gpc^3), high clustering\namplitude (linear effective bias parameter b_{eff} ~ 3x(0.85/sigma_8)), and\nsufficiently high sampling density (~ 3x10^{-5} h^{3} Mpc^{-3}) the recovered\npower spectrum has high enough signal to noise to allow us to find weak\nevidence (~ 2sigma CL) for the acoustic features. These results are encouraging\nin light of the several proposed large cluster surveys. In case we use the\nphotometric redshift errors as suggested in Koester et al. (2007) we are left\nwith the excess large-scale power which has previously been noticed by several\nother authors.\n", "machine_text": "\nWe use the Fourier technique in order to determine the redshift-space power spectrum for the maxBCG catalog of galaxy clusters (Koester et al. 2007). This is the largest cluster sample to have ever been analysed. By accounting for the blurring effect of photometric redshift errors and incorporating a treatment for the nonlinear effects, the model of the LambdaCDM cosmology, with its low-matter density, is seen to agree with the estimated power. With its wide volume of 0.4 h^{-3} Gpc^3, the recovered power spectrum has such a large signal-to-noise ratio that feeble evidence (a 2-sigma probability) is found for acoustic features. An excess of power on large scales, pointed out by other researchers, is left when photometric redshift errors are taken into account, as proposed in the work of Koester et al. This research bodes well for forthcoming large cluster surveys.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1843}
{"prompt": "Rephrase the abstract of an article with title 'Towards local electromechanical probing of cellular and biomolecular\n  systems in a liquid environment'.\n  Electromechanical coupling is ubiquitous in biological systems with examples\nranging from simple piezoelectricity in calcified and connective tissues to\nvoltage-gated ion channels, energy storage in mitochondria, and\nelectromechanical activity in cardiac myocytes and outer hair cell stereocilia.\nPiezoresponse force microscopy (PFM) has originally emerged as a technique to\nstudy electromechanical phenomena in ferroelectric materials, and in recent\nyears, has been employed to study a broad range of non-ferroelectric polar\nmaterials, including piezoelectric biomaterials. At the same time, the\ntechnique has been extended from ambient to liquid imaging on model\nferroelectric systems. Here, we present results on local electromechanical\nprobing of several model cellular and biomolecular systems, including insulin\nand lysozyme amyloid fibrils, breast adenocarcinoma cells, and\nbacteriorhodopsin in a liquid environment. The specific features of SPM\noperation in liquid are delineated and bottlenecks on the route towards\nnanometer-resolution electromechanical imaging of biological systems are\nidentified.\n\n", "human_text": "  Electromechanical coupling is ubiquitous in biological systems with examples\nranging from simple piezoelectricity in calcified and connective tissues to\nvoltage-gated ion channels, energy storage in mitochondria, and\nelectromechanical activity in cardiac myocytes and outer hair cell stereocilia.\nPiezoresponse force microscopy (PFM) has originally emerged as a technique to\nstudy electromechanical phenomena in ferroelectric materials, and in recent\nyears, has been employed to study a broad range of non-ferroelectric polar\nmaterials, including piezoelectric biomaterials. At the same time, the\ntechnique has been extended from ambient to liquid imaging on model\nferroelectric systems. Here, we present results on local electromechanical\nprobing of several model cellular and biomolecular systems, including insulin\nand lysozyme amyloid fibrils, breast adenocarcinoma cells, and\nbacteriorhodopsin in a liquid environment. The specific features of SPM\noperation in liquid are delineated and bottlenecks on the route towards\nnanometer-resolution electromechanical imaging of biological systems are\nidentified.\n", "machine_text": "Piezoresponse force microscopy (PFM) has developed from a technique for evaluating electromechanical features in ferroelectric materials to applying these techniques to a diverse range of non-ferroelectric polar materials, combining this with liquid imaging. Here, we discuss the results from local electromechanical probing of various models of cellular and biomolecular systems, including insulin, lysozyme amyloid fibrils, breast adenocarcinoma cells, and bacteriorhodopsin in a liquid environment. SPM features for operation in liquid are discussed, as well as obstacles which must be overcome in order to successfully acquire nanometer-resolution electromagnetic imaging of biological systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3958}
{"prompt": "Rephrase the abstract of an article with title 'New smooth hybrid inflation'.\n  We consider the extension of the supersymmetric Pati-Salam model which solves\nthe b-quark mass problem of supersymmetric grand unified models with exact\nYukawa unification and universal boundary conditions and leads to the so-called\nnew shifted hybrid inflationary scenario. We show that this model can also lead\nto a new version of smooth hybrid inflation based only on renormalizable\ninteractions provided that a particular parameter of its superpotential is\nsomewhat small. The potential possesses valleys of minima with classical\ninclination, which can be used as inflationary paths. The model is consistent\nwith the fitting of the three-year Wilkinson microwave anisotropy probe data by\nthe standard power-law cosmological model with cold dark matter and a\ncosmological constant. In particular, the spectral index turns out to be\nadequately small so that it is compatible with the data. Moreover, the\nPati-Salam gauge group is broken to the standard model gauge group during\ninflation and, thus, no monopoles are formed at the end of inflation.\nSupergravity corrections based on a non-minimal Kaehler potential with a\nconvenient choice of a sign keep the spectral index comfortably within the\nallowed range without generating maxima and minima of the potential on the\ninflationary path. So, unnatural restrictions on the initial conditions for\ninflation can be avoided.\n\n", "human_text": "  We consider the extension of the supersymmetric Pati-Salam model which solves\nthe b-quark mass problem of supersymmetric grand unified models with exact\nYukawa unification and universal boundary conditions and leads to the so-called\nnew shifted hybrid inflationary scenario. We show that this model can also lead\nto a new version of smooth hybrid inflation based only on renormalizable\ninteractions provided that a particular parameter of its superpotential is\nsomewhat small. The potential possesses valleys of minima with classical\ninclination, which can be used as inflationary paths. The model is consistent\nwith the fitting of the three-year Wilkinson microwave anisotropy probe data by\nthe standard power-law cosmological model with cold dark matter and a\ncosmological constant. In particular, the spectral index turns out to be\nadequately small so that it is compatible with the data. Moreover, the\nPati-Salam gauge group is broken to the standard model gauge group during\ninflation and, thus, no monopoles are formed at the end of inflation.\nSupergravity corrections based on a non-minimal Kaehler potential with a\nconvenient choice of a sign keep the spectral index comfortably within the\nallowed range without generating maxima and minima of the potential on the\ninflationary path. So, unnatural restrictions on the initial conditions for\ninflation can be avoided.\n", "machine_text": "\nThis article presents an extension of the supersymmetric Pati-Salam model which can lead to a new shifted hybrid inflationary scenario, as well as a version of smooth hybrid inflation with only renormalizable interactions. These potentials possess valleys of minima with the capability to be utilized as inflationary paths and are compliant with the three-year Wilkinson microwave anisotropy probe data. Additionally, the breaking of the Pati-Salam gauge group down to the standard model during inflation ensures the lack of any monopoles at the end of inflation. Through a non-minimal Kaehler potential with a suitable sign supergravity corrections can be added to the inflationary path without creating maxima or minima, allowing for natural initial conditions for inflation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3786}
{"prompt": "Rephrase the abstract of an article with title 'Entangling Independent Photons by Time Measurement'.\n  A quantum system composed of two or more subsystems can be in an entangled\nstate, i.e. a state in which the properties of the global system are well\ndefined but the properties of each subsystem are not. Entanglement is at the\nheart of quantum physics, both for its conceptual foundations and for\napplications in information processing and quantum communication. Remarkably,\nentanglement can be \"swapped\": if one prepares two independent entangled pairs\nA1-A2 and B1-B2, a joint measurement on A1 and B1 (called a \"Bell-State\nMeasurement\", BSM) has the effect of projecting A2 and B2 onto an entangled\nstate, although these two particles have never interacted or shared any common\npast[1,2]. Experiments using twin photons produced by spontaneous parametric\ndown-conversion (SPDC) have already demonstrated entanglement swapping[3-6],\nbut here we present its first realization using continuous wave (CW) sources,\nas originally proposed[2]. The challenge was to achieve sufficiently sharp\nsynchronization of the photons in the BSM. Using narrow-band filters, the\ncoherence time of the photons that undergo the BSM is significantly increased,\nexceeding the temporal resolution of the detectors. Hence pulsed sources can be\nreplaced by CW sources, which do not require any synchronization[6,7], allowing\nfor the first time the use of completely autonomous sources. Our experiment\nexploits recent progress in the time precision of photon detectors, in the\nefficiency of photon pair production by SPDC with waveguides in nonlinear\ncrystals[8], and in the stability of narrow-band filters. This approach is\nindependent of the form of entanglement; we employed time-bin entangled\nphotons[9] at telecom wavelengths. Our setup is robust against thermal or\nmechanical fluctuations in optical fibres thanks to cm-long coherence lengths.\n\n", "human_text": "  A quantum system composed of two or more subsystems can be in an entangled\nstate, i.e. a state in which the properties of the global system are well\ndefined but the properties of each subsystem are not. Entanglement is at the\nheart of quantum physics, both for its conceptual foundations and for\napplications in information processing and quantum communication. Remarkably,\nentanglement can be \"swapped\": if one prepares two independent entangled pairs\nA1-A2 and B1-B2, a joint measurement on A1 and B1 (called a \"Bell-State\nMeasurement\", BSM) has the effect of projecting A2 and B2 onto an entangled\nstate, although these two particles have never interacted or shared any common\npast[1,2]. Experiments using twin photons produced by spontaneous parametric\ndown-conversion (SPDC) have already demonstrated entanglement swapping[3-6],\nbut here we present its first realization using continuous wave (CW) sources,\nas originally proposed[2]. The challenge was to achieve sufficiently sharp\nsynchronization of the photons in the BSM. Using narrow-band filters, the\ncoherence time of the photons that undergo the BSM is significantly increased,\nexceeding the temporal resolution of the detectors. Hence pulsed sources can be\nreplaced by CW sources, which do not require any synchronization[6,7], allowing\nfor the first time the use of completely autonomous sources. Our experiment\nexploits recent progress in the time precision of photon detectors, in the\nefficiency of photon pair production by SPDC with waveguides in nonlinear\ncrystals[8], and in the stability of narrow-band filters. This approach is\nindependent of the form of entanglement; we employed time-bin entangled\nphotons[9] at telecom wavelengths. Our setup is robust against thermal or\nmechanical fluctuations in optical fibres thanks to cm-long coherence lengths.\n", "machine_text": "\nIn this article, we demonstrate for the first time the entanglement of two independent photons through time measurement. This method removes the need for synchronization and can be easily implemented with continuous wave (CW) sources. Our approach combines recent advancements in achieving high-precision timing with photon detectors, paired-photon production with nonlinear waveguides crystals, and long-coherence narrow-band filters. Furthermore, our approach is special as it is independent of the specific form of entanglement demonstrated; in this case, time-bin entangled photons at telecommunications wavelengths were used. Furthermore, out system has strong robustness against thermal or mechanical fluctuations due to its cm-long coherence lengths.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0758}
{"prompt": "Rephrase the abstract of an article with title 'Testing and selection of cosmological models with $(1+z)^6$ corrections'.\n  In the paper we check whether the contribution of $(-)(1+z)^6$ type in the\nFriedmann equation can be tested. We consider some astronomical tests to\nconstrain the density parameters in such models. We describe different\ninterpretations of such an additional term: geometric effects of Loop Quantum\nCosmology, effects of braneworld cosmological models, non-standard cosmological\nmodels in metric-affine gravity, and models with spinning fluid. Kinematical\n(or geometrical) tests based on null geodesics are insufficient to separate\nindividual matter components when they behave like perfect fluid and scale in\nthe same way. Still, it is possible to measure their overall effect. We use\nrecent measurements of the coordinate distances from the Fanaroff-Riley type\nIIb (FRIIb) radio galaxy (RG) data, supernovae type Ia (SNIa) data, baryon\noscillation peak and cosmic microwave background radiation (CMBR) observations\nto obtain stronger bounds for the contribution of the type considered. We\ndemonstrate that, while $\\rho^2$ corrections are very small, they can be tested\nby astronomical observations -- at least in principle. Bayesian criteria of\nmodel selection (the Bayesian factor, AIC, and BIC) are used to check if\nadditional parameters are detectable in the present epoch. As it turns out, the\n$\\Lambda$CDM model is favoured over the bouncing model driven by loop quantum\neffects. Or, in other words, the bounds obtained from cosmography are very\nweak, and from the point of view of the present data this model is\nindistinguishable from the $\\Lambda$CDM one.\n\n", "human_text": "  In the paper we check whether the contribution of $(-)(1+z)^6$ type in the\nFriedmann equation can be tested. We consider some astronomical tests to\nconstrain the density parameters in such models. We describe different\ninterpretations of such an additional term: geometric effects of Loop Quantum\nCosmology, effects of braneworld cosmological models, non-standard cosmological\nmodels in metric-affine gravity, and models with spinning fluid. Kinematical\n(or geometrical) tests based on null geodesics are insufficient to separate\nindividual matter components when they behave like perfect fluid and scale in\nthe same way. Still, it is possible to measure their overall effect. We use\nrecent measurements of the coordinate distances from the Fanaroff-Riley type\nIIb (FRIIb) radio galaxy (RG) data, supernovae type Ia (SNIa) data, baryon\noscillation peak and cosmic microwave background radiation (CMBR) observations\nto obtain stronger bounds for the contribution of the type considered. We\ndemonstrate that, while $\\rho^2$ corrections are very small, they can be tested\nby astronomical observations -- at least in principle. Bayesian criteria of\nmodel selection (the Bayesian factor, AIC, and BIC) are used to check if\nadditional parameters are detectable in the present epoch. As it turns out, the\n$\\Lambda$CDM model is favoured over the bouncing model driven by loop quantum\neffects. Or, in other words, the bounds obtained from cosmography are very\nweak, and from the point of view of the present data this model is\nindistinguishable from the $\\Lambda$CDM one.\n", "machine_text": "\nIn this paper, we investigate the possibility of distinguishing the influence of a $(1+z)^6$ modification to the Friedmann equation through cosmological observations. Various interpretations of this extra term, including geometric changes associated with Loop Quantum Cosmology, braneworld models, metric-affine gravity and spinning fluid effects are considered. We use current measurements such as those of the coordinate distances from the Fanaroff-Riley type IIb (FRIIb) radio galaxy (RG) data, supernovae type Ia (SNIa) data, baryon oscillation peak and the cosmic microwave background radiation (CMBR) to assess the contribution of the extra $(1+z)^6$ term to the standard $\\Lambda$CDM model. We employ Bayesian model selection criteria such as the Bayesian factor, AIC, and BIC to identify if the additional parameters are detectable in current observations. Our results indicate that even though the $\\rho^2$ corrections are small, astronomical observations can detect them in principle. Nonetheless, our data does not support a bounce model associated with loop quantum effects, nor does it suggest that it differs from the $\\Lambda$CDM model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0283}
{"prompt": "Rephrase the abstract of an article with title 'Effective conservation of energy and momentum algorithm using switching\n  potentials suitable for molecular dynamics simulation of thermodynamical\n  systems'.\n  During a crossover via a switching mechanism from one 2-body potential to\nanother as might be applied in modeling (chemical) reactions in the vicinity of\nbond formation, energy violations would occur due to finite step size which\ndetermines the trajectory of the particles relative to the potential\ninteractions of the unbonded state by numerical (e.g. Verlet) integration. This\nproblem is overcome by an algorithm which preserves the coordinates of the\nsystem for each move, but corrects for energy discrepancies by ensuring both\nenergy and momentum conservation in the dynamics. The algorithm is tested for a\nhysteresis loop reaction model with an without the implementation of the\nalgorithm. The tests involve checking the rate of energy flow out of the MD\nsimulation box; in the equilibrium state, no net rate of flows within\nexperimental error should be observed. The temperature and pressure of the box\nshould also be invariant within the range of fluctuation of these quantities.\nIt is demonstrated that the algorithm satisfies these criteria.\n\n", "human_text": "  During a crossover via a switching mechanism from one 2-body potential to\nanother as might be applied in modeling (chemical) reactions in the vicinity of\nbond formation, energy violations would occur due to finite step size which\ndetermines the trajectory of the particles relative to the potential\ninteractions of the unbonded state by numerical (e.g. Verlet) integration. This\nproblem is overcome by an algorithm which preserves the coordinates of the\nsystem for each move, but corrects for energy discrepancies by ensuring both\nenergy and momentum conservation in the dynamics. The algorithm is tested for a\nhysteresis loop reaction model with an without the implementation of the\nalgorithm. The tests involve checking the rate of energy flow out of the MD\nsimulation box; in the equilibrium state, no net rate of flows within\nexperimental error should be observed. The temperature and pressure of the box\nshould also be invariant within the range of fluctuation of these quantities.\nIt is demonstrated that the algorithm satisfies these criteria.\n", "machine_text": "\nThis paper presents an algorithm which prevents energy violations caused by the finite step size of a trajectory of particles relative to unbonded state potential interactions while undergoing crossover via a switching mechanism. The algorithm effectively conserves both energy and momentum in the dynamics, and is tested by examining energy flow rate and temperature/pressure invariance in a hysteresis loop reaction model. The results show that the algorithm satisfies the criteria of energy and momentum conservation as desired for molecular dynamics simulation of thermodynamic systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0556}
{"prompt": "Rephrase the abstract of an article with title 'Aharonov-Bohm effect and broken valley-degeneracy in graphene rings'.\n  We analyze theoretically the electronic properties of Aharonov-Bohm rings\nmade of graphene. We show that the combined effect of the ring confinement and\napplied magnetic flux offers a controllable way to lift the orbital degeneracy\noriginating from the two valleys, even in the absence of intervalley\nscattering. The phenomenon has observable consequences on the persistent\ncurrent circulating around the closed graphene ring, as well as on the ring\nconductance. We explicitly confirm this prediction analytically for a circular\nring with a smooth boundary modelled by a space-dependent mass term in the\nDirac equation. This model describes rings with zero or weak intervalley\nscattering so that the valley isospin is a good quantum number. The tunable\nbreaking of the valley degeneracy by the flux allows for the controlled\nmanipulation of valley isospins. We compare our analytical model to another\ntype of ring with strong intervalley scattering. For the latter case, we study\na ring of hexagonal form with lattice-terminated zigzag edges numerically. We\nfind for the hexagonal ring that the orbital degeneracy can still be controlled\nvia the flux, similar to the ring with the mass confinement.\n\n", "human_text": "  We analyze theoretically the electronic properties of Aharonov-Bohm rings\nmade of graphene. We show that the combined effect of the ring confinement and\napplied magnetic flux offers a controllable way to lift the orbital degeneracy\noriginating from the two valleys, even in the absence of intervalley\nscattering. The phenomenon has observable consequences on the persistent\ncurrent circulating around the closed graphene ring, as well as on the ring\nconductance. We explicitly confirm this prediction analytically for a circular\nring with a smooth boundary modelled by a space-dependent mass term in the\nDirac equation. This model describes rings with zero or weak intervalley\nscattering so that the valley isospin is a good quantum number. The tunable\nbreaking of the valley degeneracy by the flux allows for the controlled\nmanipulation of valley isospins. We compare our analytical model to another\ntype of ring with strong intervalley scattering. For the latter case, we study\na ring of hexagonal form with lattice-terminated zigzag edges numerically. We\nfind for the hexagonal ring that the orbital degeneracy can still be controlled\nvia the flux, similar to the ring with the mass confinement.\n", "machine_text": "\nWe present a theoretical study of the Aharonov-Bohm rings made of graphene. These rings display an interesting effect due to the externally applied magnetic field - the orbital degeneracy originating from the two valleys can be broken, even in the absence of intervalley scattering. We explore this phenomenon and its effects on the persistent current of the ring, as well as on the conductance. Analytically, we confirm this prediction with a model that considers a circular ring with a smooth boundary and a space-dependent mass term. Numerically, we consider a ring with a hexagonal form and lattice-terminated zigzag edges. We find that this type of ring displays a similar behaviour, with the orbital degeneracy being controllable via the flux.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2103}
{"prompt": "Rephrase the abstract of an article with title 'Non-zero trilinear parameter in the mSUGRA model - dark matter and\n  collider signals at Tevatron and LHC'.\n  Phenomenologically viable and interesting regions of parameter space in the\nminimal super-gravity (mSUGRA) model with small $m_0$ and small $m_{1/2}$\nconsistent with the WMAP data on dark matter relic density and the bound on the\nmass of the lightest Higgs scalar $ m_h>$ 114 GeV from LEP2 open up if the\nrather adhoc assumption $A_0$=0, where $A_0$ is the common trilinear soft\nbreaking parameter, employed in most of the existing analyses is relaxed. Since\nthis region corresponds to relatively light squarks and gluinos which are\nlikely to be probed extensively in the very early stages of the LHC\nexperiments, the consequences of moderate or large negative values of $A_0$ are\nexamined in detail. We find that in this region several processes including\nlightest supersymmetric particle (LSP) pair annihilation, LSP - lighter tau\nslepton (${\\tilde \\tau}_1$) coannihilation and LSP - lighter top squark\n(${\\tilde t}_1$) coannihilation contribute to the observed dark matter relic\ndensity. %\\sout{The possibility that a relic density producing ${\\tilde t}_1$\ncan be %observed at the current experiments at the Tevatron is wide open.} The\npossibility that a ${\\tilde t}_1$ that can participate in coannihilation with\nthe lightest neutralino to satisfy the WMAP bound on relic density and at the\nsame time be observed at the current experiments at the Tevatron is wide open.\nAt the LHC a large number of squark - gluino events lead to a very distinctive\nsemi-inclusive signature $\\tau^\\pm$+X$_\\tau$ (anything without a tau lepton)\nwith a characteristic size much larger than $e^\\pm$+X$_e$ or $\\mu^\\pm$+X$_\\mu$\nevents.\n\n", "human_text": "  Phenomenologically viable and interesting regions of parameter space in the\nminimal super-gravity (mSUGRA) model with small $m_0$ and small $m_{1/2}$\nconsistent with the WMAP data on dark matter relic density and the bound on the\nmass of the lightest Higgs scalar $ m_h>$ 114 GeV from LEP2 open up if the\nrather adhoc assumption $A_0$=0, where $A_0$ is the common trilinear soft\nbreaking parameter, employed in most of the existing analyses is relaxed. Since\nthis region corresponds to relatively light squarks and gluinos which are\nlikely to be probed extensively in the very early stages of the LHC\nexperiments, the consequences of moderate or large negative values of $A_0$ are\nexamined in detail. We find that in this region several processes including\nlightest supersymmetric particle (LSP) pair annihilation, LSP - lighter tau\nslepton (${\\tilde \\tau}_1$) coannihilation and LSP - lighter top squark\n(${\\tilde t}_1$) coannihilation contribute to the observed dark matter relic\ndensity. %\\sout{The possibility that a relic density producing ${\\tilde t}_1$\ncan be %observed at the current experiments at the Tevatron is wide open.} The\npossibility that a ${\\tilde t}_1$ that can participate in coannihilation with\nthe lightest neutralino to satisfy the WMAP bound on relic density and at the\nsame time be observed at the current experiments at the Tevatron is wide open.\nAt the LHC a large number of squark - gluino events lead to a very distinctive\nsemi-inclusive signature $\\tau^\\pm$+X$_\\tau$ (anything without a tau lepton)\nwith a characteristic size much larger than $e^\\pm$+X$_e$ or $\\mu^\\pm$+X$_\\mu$\nevents.\n", "machine_text": "\nThe assumption of a non-zero trilinear parameter (A$_0$) in the minimal supergravity model\n(mSUGRA) is explored in context to understanding dark matter (DM) relic density and its\nsignals at collider experiments. It is found that parameter space regions consistent\nwith WMAP data on DM relic density and LEP2 bound on the lightest Higgs scalar can be\nexamined with this assumption. Multiple processes such as annihilation, coannihilation\nof lightest supersymmetric particle (LSP) and ${\\tilde \\tau}_1$ light tau slepton, ${\\tilde\nt}_1$ light top squark etc. are found to contribute to the relic density. The possibility\nof ${\\tilde t}_1$ observation at Tevatron is wide open. In addition, the LHC experiments\nexpect a significantly large number of squark-gluino events with a distinctively\nlarger $\\tau^\\pm$+X$_\\tau$ semi-inclusive signature than no-lepton events.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0921}
{"prompt": "Rephrase the abstract of an article with title 'QED calculation of the 2p1/2-2s and 2p3/2-2s transition energies and the\n  ground-state hyperfine splitting in lithiumlike scandium'.\n  We present the most accurate up-to-date theoretical values of the\n{2p_{1/2}}-{2s} and {2p_{3/2}}-{2s} transition energies and the ground-state\nhyperfine splitting in ${\\rm Sc}^{18+}$. All two- and three-electron\ncontributions to the energy values up to the two-photon level are treated in\nthe framework of bound-state QED without $\\aZ$-expansion. The interelectronic\ninteraction beyond the two-photon level is taken into account by means of the\nlarge-scale configuration-interaction Dirac-Fock-Sturm (CI-DFS) method. The\nrelativistic recoil correction is calculated with many-electron wave functions\nin order to take into account the electron-correlation effect. The accuracy of\nthe transition energy values is improved by a factor of five compared to the\nprevious calculations. The CI-DFS calculation of interelectronic-interaction\neffects and the evaluation of the QED correction in an effective screening\npotential provide significant improvement for the $2s$ hyperfine splitting. The\nresults obtained are in a good agreement with recently published experimental\ndata.\n\n", "human_text": "  We present the most accurate up-to-date theoretical values of the\n{2p_{1/2}}-{2s} and {2p_{3/2}}-{2s} transition energies and the ground-state\nhyperfine splitting in ${\\rm Sc}^{18+}$. All two- and three-electron\ncontributions to the energy values up to the two-photon level are treated in\nthe framework of bound-state QED without $\\aZ$-expansion. The interelectronic\ninteraction beyond the two-photon level is taken into account by means of the\nlarge-scale configuration-interaction Dirac-Fock-Sturm (CI-DFS) method. The\nrelativistic recoil correction is calculated with many-electron wave functions\nin order to take into account the electron-correlation effect. The accuracy of\nthe transition energy values is improved by a factor of five compared to the\nprevious calculations. The CI-DFS calculation of interelectronic-interaction\neffects and the evaluation of the QED correction in an effective screening\npotential provide significant improvement for the $2s$ hyperfine splitting. The\nresults obtained are in a good agreement with recently published experimental\ndata.\n", "machine_text": "This paper presents an improved calculation of the {2p_{1/2}}-{2s}, {2p_{3/2}}-{2s} transition energies, and ground-state hyperfine splitting in ${\\rm Sc}^{18+}$, which takes into account two- and three-electron contributions up to two-photon levels in a bound-state Quantum Electrodynamics (QED) model. Interelectronic interactions beyond two-photon level are handled using a large-scale Configuration Interaction (CI)-Dirac Fock-Sturm method and the relativistic recoil correction is calculated with many-electron wave functions to incorporate the effect of electron-correlation. In comparison to previous calculations, the accuracy of the transition energies has increased by five-fold. The results of our calculations are compared to the recent experimental data, with close agreement.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2822}
{"prompt": "Rephrase the abstract of an article with title 'Measuring the spin polarization and Zeeman energy of a spin-polarized\n  electron gas: Comparison between Raman scattering and photoluminescence'.\n  We compare resonant electronic Raman scattering and photoluminescence\nmeasurements for the characterization of a spin-polarized two-dimensional\nelectron gas embedded in $\\text{Cd}_{1-x}\\text{Mn}_x\\text{Te}$ single quantum\nwells. From Raman scattering by single-particle excitations in a zero magnetic\nfield, we measure the Fermi velocity and then obtain the Fermi energy (as well\nas the electron density), which is comparable to that extracted from\nphotoluminescence for moderate electron densities, assuming a bare band-edge\nmass. At large electron densities, the Fermi energies derived from Raman\nscattering and photoluminescence differ. For an applied in-plane magnetic field\nand zero wave vector transferred to the electron gas, Raman scattering spectra\nshow peaks at both the Zeeman energy $Z$, resulting from collective excitations\nof the spin-polarized electron gas, and the one electron spin-flip energy\n$Z^*$. Magneto-photoluminescence spectra show conduction band splitting that\nare equivalent to $Z$, suggesting that collective effects are present in the\nphotoluminescence spectra. Assuming (as before) an uncorrected mass, the degree\nof spin polarization $\\zeta$ determined from the magneto-photoluminescence\nlineshape is found to differ from that derived from the magnetic field\ndependent Raman scattering measurements for large electron densities. We\nattribute the discrepancy in measuring $\\zeta$ and the Fermi energy to the\nrenormalized mass resulting from many-body electron-electron interactions.\n\n", "human_text": "  We compare resonant electronic Raman scattering and photoluminescence\nmeasurements for the characterization of a spin-polarized two-dimensional\nelectron gas embedded in $\\text{Cd}_{1-x}\\text{Mn}_x\\text{Te}$ single quantum\nwells. From Raman scattering by single-particle excitations in a zero magnetic\nfield, we measure the Fermi velocity and then obtain the Fermi energy (as well\nas the electron density), which is comparable to that extracted from\nphotoluminescence for moderate electron densities, assuming a bare band-edge\nmass. At large electron densities, the Fermi energies derived from Raman\nscattering and photoluminescence differ. For an applied in-plane magnetic field\nand zero wave vector transferred to the electron gas, Raman scattering spectra\nshow peaks at both the Zeeman energy $Z$, resulting from collective excitations\nof the spin-polarized electron gas, and the one electron spin-flip energy\n$Z^*$. Magneto-photoluminescence spectra show conduction band splitting that\nare equivalent to $Z$, suggesting that collective effects are present in the\nphotoluminescence spectra. Assuming (as before) an uncorrected mass, the degree\nof spin polarization $\\zeta$ determined from the magneto-photoluminescence\nlineshape is found to differ from that derived from the magnetic field\ndependent Raman scattering measurements for large electron densities. We\nattribute the discrepancy in measuring $\\zeta$ and the Fermi energy to the\nrenormalized mass resulting from many-body electron-electron interactions.\n", "machine_text": "\nIn this article, we investigate the differences between electronic Raman scattering and photoluminescence for the characterization of a spin-polarized two-dimensional electron gas embedded in $\\text{Cd}_{1-x}\\text{Mn}_x\\text{Te}$ single quantum wells. From Raman scattering in a zero magnetic field, we measure the Fermi velocity and then calculate the Fermi energy and density. We compare these figures to photoluminescence results at moderate electron densities. However, when an in-plane magnetic field is applied, the difference in the Fermi energy becomes more pronounced. We also observe the Zeeman energy $Z$ and one electron spin-flip energy $Z^*$ in the Raman scattering spectra. The magneto-photoluminescence spectra shows conduction band splitting that are equivalent to $Z$, which suggests collective effects are present. We attribute the discrepancy in measuring the degree of spin polarization $\\zeta$ and the Fermi energy to the renormalized mass resulting from electron-electron interactions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1255}
{"prompt": "Rephrase the abstract of an article with title 'Rapid Mixing of Gibbs Sampling on Graphs that are Sparse on Average'.\n  In this work we show that for every $d < \\infty$ and the Ising model defined\non $G(n,d/n)$, there exists a $\\beta_d > 0$, such that for all $\\beta <\n\\beta_d$ with probability going to 1 as $n \\to \\infty$, the mixing time of the\ndynamics on $G(n,d/n)$ is polynomial in $n$. Our results are the first\npolynomial time mixing results proven for a natural model on $G(n,d/n)$ for $d\n> 1$ where the parameters of the model do not depend on $n$. They also provide\na rare example where one can prove a polynomial time mixing of Gibbs sampler in\na situation where the actual mixing time is slower than $n \\polylog(n)$. Our\nproof exploits in novel ways the local treelike structure of Erd\\H{o}s-R\\'enyi\nrandom graphs, comparison and block dynamics arguments and a recent result of\nWeitz.\n  Our results extend to much more general families of graphs which are sparse\nin some average sense and to much more general interactions. In particular,\nthey apply to any graph for which every vertex $v$ of the graph has a\nneighborhood $N(v)$ of radius $O(\\log n)$ in which the induced sub-graph is a\ntree union at most $O(\\log n)$ edges and where for each simple path in $N(v)$\nthe sum of the vertex degrees along the path is $O(\\log n)$. Moreover, our\nresult apply also in the case of arbitrary external fields and provide the\nfirst FPRAS for sampling the Ising distribution in this case. We finally\npresent a non Markov Chain algorithm for sampling the distribution which is\neffective for a wider range of parameters. In particular, for $G(n,d/n)$ it\napplies for all external fields and $\\beta < \\beta_d$, where $d \\tanh(\\beta_d)\n= 1$ is the critical point for decay of correlation for the Ising model on\n$G(n,d/n)$.\n\n", "human_text": "  In this work we show that for every $d < \\infty$ and the Ising model defined\non $G(n,d/n)$, there exists a $\\beta_d > 0$, such that for all $\\beta <\n\\beta_d$ with probability going to 1 as $n \\to \\infty$, the mixing time of the\ndynamics on $G(n,d/n)$ is polynomial in $n$. Our results are the first\npolynomial time mixing results proven for a natural model on $G(n,d/n)$ for $d\n> 1$ where the parameters of the model do not depend on $n$. They also provide\na rare example where one can prove a polynomial time mixing of Gibbs sampler in\na situation where the actual mixing time is slower than $n \\polylog(n)$. Our\nproof exploits in novel ways the local treelike structure of Erd\\H{o}s-R\\'enyi\nrandom graphs, comparison and block dynamics arguments and a recent result of\nWeitz.\n  Our results extend to much more general families of graphs which are sparse\nin some average sense and to much more general interactions. In particular,\nthey apply to any graph for which every vertex $v$ of the graph has a\nneighborhood $N(v)$ of radius $O(\\log n)$ in which the induced sub-graph is a\ntree union at most $O(\\log n)$ edges and where for each simple path in $N(v)$\nthe sum of the vertex degrees along the path is $O(\\log n)$. Moreover, our\nresult apply also in the case of arbitrary external fields and provide the\nfirst FPRAS for sampling the Ising distribution in this case. We finally\npresent a non Markov Chain algorithm for sampling the distribution which is\neffective for a wider range of parameters. In particular, for $G(n,d/n)$ it\napplies for all external fields and $\\beta < \\beta_d$, where $d \\tanh(\\beta_d)\n= 1$ is the critical point for decay of correlation for the Ising model on\n$G(n,d/n)$.\n", "machine_text": "This study discusses the efficiency of Gibbs sampling on graphs that obtaining sparse structure on average. We prove that for a given positive answer $d$ and Ising model defined on $G(n,d/n)$, there is a parameter $\\beta_d$ such that, as $n \\rightarrow \\infty$, a polynomial time of mixing is achieved. Our method uses the local tree-like structure of $G(n,d/n)$. We show that our results extend to a wider range of general graph frameworks, external fields, and interactions. We also feature a non-Markov Chain algorithm for sampling the Ising model distribution and applies for all external fields and $\\beta < \\beta_d$, with a critical point at $d \\tanh(\\beta_d) = 1$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3603}
{"prompt": "Rephrase the abstract of an article with title 'Harmonic sections in sphere bundles, normal neighborhoods of reduction\n  loci, and instanton moduli spaces on definite 4-manifolds'.\n  We prove an existence theorem for gauge invariant $L^2$-normal neighborhoods\nof the reduction loci in the space ${\\cal A}_a(E)$ of oriented connections on a\nfixed Hermitian 2-bundle $E$. We use this to obtain results on the topology of\nthe moduli space ${\\cal B}_a(E)$ of (non-necessarily irreducible) oriented\nconnections, and to study the Donaldson $\\mu$-classes globally around the\nreduction loci. In this part of the article we use essentially the concept of\nharmonic section in a sphere bundle with respect to an Euclidean connection.\n  Second, we concentrate on moduli spaces of instantons on definite 4-manifolds\nwith arbitrary first Betti number. We prove strong generic regularity results\nwhich imply (for bundles with \"odd\" first Chern class) the existence of a\nconnected, dense open set of \"good\" metrics for which all the reductions in the\nUhlenbeck compactification of the moduli space are simultaneously regular.\nThese results can be used to define new Donaldson type invariants for definite\n4-manifolds. The idea behind this construction is to notice that, for a good\nmetric $g$, the geometry of the instanton moduli spaces around the reduction\nloci is always the same, independently of the choice of $g$. The connectedness\nof the space of good metrics is important, in order to prove that no\nwall-crossing phenomena (jumps of invariants) occur. Moreover, we notice that,\nfor low instanton numbers, the corresponding moduli spaces are a priori compact\nand contain no reductions at all so, in these cases, the existence of\nwell-defined Donaldson type invariants is obvious. The natural question is to\ndecide whether these new Donaldson type invariants yield essentially new\ndifferential topological information on the base manifold have, or have a\npurely topological nature.\n\n", "human_text": "  We prove an existence theorem for gauge invariant $L^2$-normal neighborhoods\nof the reduction loci in the space ${\\cal A}_a(E)$ of oriented connections on a\nfixed Hermitian 2-bundle $E$. We use this to obtain results on the topology of\nthe moduli space ${\\cal B}_a(E)$ of (non-necessarily irreducible) oriented\nconnections, and to study the Donaldson $\\mu$-classes globally around the\nreduction loci. In this part of the article we use essentially the concept of\nharmonic section in a sphere bundle with respect to an Euclidean connection.\n  Second, we concentrate on moduli spaces of instantons on definite 4-manifolds\nwith arbitrary first Betti number. We prove strong generic regularity results\nwhich imply (for bundles with \"odd\" first Chern class) the existence of a\nconnected, dense open set of \"good\" metrics for which all the reductions in the\nUhlenbeck compactification of the moduli space are simultaneously regular.\nThese results can be used to define new Donaldson type invariants for definite\n4-manifolds. The idea behind this construction is to notice that, for a good\nmetric $g$, the geometry of the instanton moduli spaces around the reduction\nloci is always the same, independently of the choice of $g$. The connectedness\nof the space of good metrics is important, in order to prove that no\nwall-crossing phenomena (jumps of invariants) occur. Moreover, we notice that,\nfor low instanton numbers, the corresponding moduli spaces are a priori compact\nand contain no reductions at all so, in these cases, the existence of\nwell-defined Donaldson type invariants is obvious. The natural question is to\ndecide whether these new Donaldson type invariants yield essentially new\ndifferential topological information on the base manifold have, or have a\npurely topological nature.\n", "machine_text": "\nThis article explores the concept of harmonic sections in sphere bundles with respect to an Euclidean connection, to prove an existence theorem for gauge invariant $L^2$-normal neighborhoods of the reduction loci in the space ${\\cal A}_a(E)$ of oriented connections on a fixed Hermitian 2-bundle $E$. Additionally, these results are used to obtain results on the topology of ${\\cal B}_a(E)$, the moduli space of (non-necessarily irreducible) oriented connections, and to study Donaldson $\\mu$-classes globally around these reductions. We also provide strong generic regularity results for definite 4-manifolds with arbitrary first Betti number, which explain the existence of a connected, dense open set of \"good\" metrics that allow all reductions in the Uhlenbeck compactification of the moduli space to be simultaneously regular. This in turn allows establishing new Donaldson type invariants, confirming that connectedness of the space of good metrics is important, as it demonstrates that no wall-crossing phenomena take place. Last, the compactness of the moduli spaces at low instanton numbers is explored, showing these moduli spaces contain no reductions and that Donaldson type invariants can be naturally defined. The article finally considers if these new Donaldson type invariants yield new differential topological information on the base manifold.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2625}
{"prompt": "Rephrase the abstract of an article with title 'Hydrodynamical simulations of the jet in the symbiotic star MWC 560 III.\n  Application to X-ray jets in symbiotic stars'.\n  In papers I and II in this series, we presented hydrodynamical simulations of\njet models with parameters representative of the symbiotic system MWC 560.\nThese were simulations of a pulsed, initially underdense jet in a high density\nambient medium. Since the pulsed emission of the jet creates internal shocks\nand since the jet velocity is very high, the jet bow shock and the internal\nshocks are heated to high temperatures and should therefore emit X-ray\nradiation. In this paper, we investigate in detail the X-ray properties of the\njets in our models. We have focused our study on the total X-ray luminosity and\nits temporal variability, the resulting spectra and the spatial distribution of\nthe emission. Temperature and density maps from our hydrodynamical simulations\nwith radiative cooling presented in the second paper are used together with\nemissivities calculated with the atomic database ATOMDB. The jets in our models\nshow extended and variable X-ray emission which can be characterized as a sum\nof hot and warm components with temperatures that are consistent with\nobservations of CH Cyg and R Aqr. The X-ray spectra of our model jets show\nemission line features which correspond to observed features in the spectra of\nCH Cyg. The innermost parts of our pulsed jets show iron line emission in the\n6.4 - 6.7 keV range which may explain such emission from the central source in\nR Aqr. We conclude that MWC 560 should be detectable with Chandra or\nXMM-Newton, and such X-ray observations will provide crucial for understanding\njets in symbiotic stars.\n\n", "human_text": "  In papers I and II in this series, we presented hydrodynamical simulations of\njet models with parameters representative of the symbiotic system MWC 560.\nThese were simulations of a pulsed, initially underdense jet in a high density\nambient medium. Since the pulsed emission of the jet creates internal shocks\nand since the jet velocity is very high, the jet bow shock and the internal\nshocks are heated to high temperatures and should therefore emit X-ray\nradiation. In this paper, we investigate in detail the X-ray properties of the\njets in our models. We have focused our study on the total X-ray luminosity and\nits temporal variability, the resulting spectra and the spatial distribution of\nthe emission. Temperature and density maps from our hydrodynamical simulations\nwith radiative cooling presented in the second paper are used together with\nemissivities calculated with the atomic database ATOMDB. The jets in our models\nshow extended and variable X-ray emission which can be characterized as a sum\nof hot and warm components with temperatures that are consistent with\nobservations of CH Cyg and R Aqr. The X-ray spectra of our model jets show\nemission line features which correspond to observed features in the spectra of\nCH Cyg. The innermost parts of our pulsed jets show iron line emission in the\n6.4 - 6.7 keV range which may explain such emission from the central source in\nR Aqr. We conclude that MWC 560 should be detectable with Chandra or\nXMM-Newton, and such X-ray observations will provide crucial for understanding\njets in symbiotic stars.\n", "machine_text": "\nThrough the hydrodynamical simulations of jet models representative of MWC 560 presented in papers I and II of this series, we have examined the X-ray properties of these jets. In this paper, we assess the total X-ray luminosity and its temporal variability, the spectra, and the spatial distribution of the emission within the models frameworks. Taking into account the radiative cooling of the gas as outlined in the second paper of our series, we investigate the temperature and density maps, and make use of the atomic database ATOMDB to calculate X-ray emissivities. Our results indicate that the model jets produce extended and varying X-ray emission featuring hot and warm components consistent with what is observed from CH Cyg and R Aqr. The simulated X-ray spectra contain similar emission line features as those seen in the spectra of CH Cyg. Inner parts of the pulsed jets show iron line emission matching the 6.4 - 6.7 range, which likely causes the central source in R Aqr. The findings of our research suggest that MWC 560 should be detectable via Chandra or XMM-Newton, and X-ray observations of this system can yield information critical to understanding jets in symbiotic stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.224}
{"prompt": "Rephrase the abstract of an article with title 'Search for Radiative Decays of Upsilon(1S) into eta and eta''.\n  We report on a search for the radiative decay of Upsilon(1S) to the\npseudoscalar mesons eta and etaprime in 21.2 +/- 0.2 times 10^6 Upsilon(1S)\ndecays collected with the CLEO III detector at the Cornell Electron Storage\nRing (CESR). The eta meson was reconstructed in the three modes eta to\ngamma-gamma, eta to pi+pi-pi0 and eta to 3pi0. The etaprime meson was\nreconstructed in the mode etaprime to pi+ pi- eta with eta decaying through any\nof the above three modes, and also etaprime to gamma rho, where rho decays to\npi^+ pi^-.\n  Five out of the seven sub-modes are found to be virtually background-free. In\nfour of them we find no signal candidates and in one Upsilon(1S) to\ngamma-etaprime, etaprime to pi+ pi- eta, eta to pi+pi-pi0 there are two good\nsignal candidates, which is insufficient evidence to claim a signal. The other\ntwo sub-modes eta to gamma-gamma and etaprime to gamma rho are background\nlimited, and show no excess of events in their signal regions. We combine the\nresults from different channels and obtain upper limits at the 90% C.L. which\nare B(Upsilon(1S) to gamma eta) < 1.0 times 10^-6 and B(Upsilon(1S) to gamma\netaprime) < 1.9 times 10^-6. Our limits are an order of magnitude tighter than\nthe previous ones and below the predictions made by some theoretical models.\n\n", "human_text": "  We report on a search for the radiative decay of Upsilon(1S) to the\npseudoscalar mesons eta and etaprime in 21.2 +/- 0.2 times 10^6 Upsilon(1S)\ndecays collected with the CLEO III detector at the Cornell Electron Storage\nRing (CESR). The eta meson was reconstructed in the three modes eta to\ngamma-gamma, eta to pi+pi-pi0 and eta to 3pi0. The etaprime meson was\nreconstructed in the mode etaprime to pi+ pi- eta with eta decaying through any\nof the above three modes, and also etaprime to gamma rho, where rho decays to\npi^+ pi^-.\n  Five out of the seven sub-modes are found to be virtually background-free. In\nfour of them we find no signal candidates and in one Upsilon(1S) to\ngamma-etaprime, etaprime to pi+ pi- eta, eta to pi+pi-pi0 there are two good\nsignal candidates, which is insufficient evidence to claim a signal. The other\ntwo sub-modes eta to gamma-gamma and etaprime to gamma rho are background\nlimited, and show no excess of events in their signal regions. We combine the\nresults from different channels and obtain upper limits at the 90% C.L. which\nare B(Upsilon(1S) to gamma eta) < 1.0 times 10^-6 and B(Upsilon(1S) to gamma\netaprime) < 1.9 times 10^-6. Our limits are an order of magnitude tighter than\nthe previous ones and below the predictions made by some theoretical models.\n", "machine_text": "\nWe survey the radiative decay of the Upsilon(1S) particle into the pseudoscalar mesons eta and etaprime, having observed data from 21.2 +/- 0.2 * 10^6 Upsilon(1S) decays detected by the CLEO III detector at the Cornell Electron Storage Ring. We observe five out of the seven sub-modes to be nearly free of background, and two of these modes include two good signal candidates, albeit insufficient to consider a signal confirmed. The remaining two sub-modes, however, show no noticeable excess of events in their respective regions. The results are combined to form 90% C.L. upper limits for B(Upsilon(1S) to gamma eta) < 1.0 times 10^-6 and B(Upsilon(1S) to gamma etaprime) < 1.9 times 10^-6, exemplifying an order of magnitude improvement compared to the previous bounds, and being below the predictions in some theoretical models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3063}
{"prompt": "Rephrase the abstract of an article with title 'Nova Geminorum 1912 and the Origin of the Idea of Gravitational Lensing'.\n  Einstein's early calculations of gravitational lensing, contained in a\nscratch notebook and dated to the spring of 1912, are reexamined. A hitherto\nunknown letter by Einstein suggests that he entertained the idea of explaining\nthe phenomenon of new stars by gravitational lensing in the fall of 1915 much\nmore seriously than was previously assumed. A reexamination of the relevant\ncalculations by Einstein shows that, indeed, at least some of them most likely\ndate from early October 1915. But in support of earlier historical\ninterpretation of Einstein's notes, it is argued that the appearance of Nova\nGeminorum 1912 (DN Gem) in March 1912 may, in fact, provide a relevant context\nand motivation for Einstein's lensing calculations on the occasion of his first\nmeeting with Erwin Freundlich during a visit in Berlin in April 1912. We also\ncomment on the significance of Einstein's consideration of gravitational\nlensing in the fall of 1915 for the reconstruction of Einstein's final steps in\nhis path towards general relativity.\n\n", "human_text": "  Einstein's early calculations of gravitational lensing, contained in a\nscratch notebook and dated to the spring of 1912, are reexamined. A hitherto\nunknown letter by Einstein suggests that he entertained the idea of explaining\nthe phenomenon of new stars by gravitational lensing in the fall of 1915 much\nmore seriously than was previously assumed. A reexamination of the relevant\ncalculations by Einstein shows that, indeed, at least some of them most likely\ndate from early October 1915. But in support of earlier historical\ninterpretation of Einstein's notes, it is argued that the appearance of Nova\nGeminorum 1912 (DN Gem) in March 1912 may, in fact, provide a relevant context\nand motivation for Einstein's lensing calculations on the occasion of his first\nmeeting with Erwin Freundlich during a visit in Berlin in April 1912. We also\ncomment on the significance of Einstein's consideration of gravitational\nlensing in the fall of 1915 for the reconstruction of Einstein's final steps in\nhis path towards general relativity.\n", "machine_text": "This paper examines the origin of the concept of gravitational lensing as proposed by Einstein. Through a historic review of Einstein's notebooks in 1912 and a letter from 1915, it is suggested that the idea of the phenomenon of new stars being the result of gravitational lensing was taken more seriously by Einstein in the fall of 1915 than was previously thought. Calculations by Einstein indicate that around the time of his first meeting with Erwin Freundlich in April 1912, Einstein began considering gravitational lensing, likely inspired by the appearance of Nova Geminorum 1912 (DN Gem) in March of that year. The implications of Einstein's investigation of gravitational lensing in 1915 for his development of the theory of general relativity is also addressed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0963}
{"prompt": "Rephrase the abstract of an article with title 'Intricate Knots in Proteins: Function and Evolution'.\n  A number of recently discovered protein structures incorporate a rather\nunexpected structural feature: a knot in the polypeptide backbone. These knots\nare extremely rare, but their occurrence is likely connected to protein\nfunction in as yet unexplored fashion. Our analysis of the complete Protein\nData Bank reveals several new knots which, along with previously discovered\nones, can shed light on such connections. In particular, we identify the most\ncomplex knot discovered to date in human ubiquitin hydrolase, and suggest that\nits entangled topology protects it against unfolding and degradation by the\nproteasome. Knots in proteins are typically preserved across species and\nsometimes even across kingdoms. However, we also identify a knot which only\nappears in some transcarbamylases while being absent in homologous proteins of\nsimilar structure. The emergence of the knot is accompanied by a shift in the\nenzymatic function of the protein. We suggest that the simple insertion of a\nshort DNA fragment into the gene may suffice to turn an unknotted into a\nknotted structure in this protein.\n\n", "human_text": "  A number of recently discovered protein structures incorporate a rather\nunexpected structural feature: a knot in the polypeptide backbone. These knots\nare extremely rare, but their occurrence is likely connected to protein\nfunction in as yet unexplored fashion. Our analysis of the complete Protein\nData Bank reveals several new knots which, along with previously discovered\nones, can shed light on such connections. In particular, we identify the most\ncomplex knot discovered to date in human ubiquitin hydrolase, and suggest that\nits entangled topology protects it against unfolding and degradation by the\nproteasome. Knots in proteins are typically preserved across species and\nsometimes even across kingdoms. However, we also identify a knot which only\nappears in some transcarbamylases while being absent in homologous proteins of\nsimilar structure. The emergence of the knot is accompanied by a shift in the\nenzymatic function of the protein. We suggest that the simple insertion of a\nshort DNA fragment into the gene may suffice to turn an unknotted into a\nknotted structure in this protein.\n", "machine_text": "\nBy analyzing the entire Protein Data Bank, we unveil several intricate knots found within proteins. These unique geometries play a crucial role in the functionality of many proteins and have allowed for the preservation of certain characteristics across species. Amongst them is the most intricate knot discovered to date in a human enzyme, ubiquitin hydrolase, which serves as a protective mechanism against degradation. Additionally, we expose a unique knot found only in some transcarbamylases leading to a shift in the enzymatic function of the protein. This suggests that the simple insertion of a small amount of DNA could be enough to create this transition. Altogether, our research brings forth revolutionary insights regarding protein knot structures and their impacts on evolution and functionality.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0191}
{"prompt": "Rephrase the abstract of an article with title 'Is there Evidence for a Hubble bubble? The Nature of Type Ia Supernova\n  Colors and Dust in External Galaxies'.\n  We examine recent evidence from the luminosity-redshift relation of Type Ia\nSupernovae (SNe Ia) for the $\\sim 3 \\sigma$ detection of a ``Hubble bubble'' --\na departure of the local value of the Hubble constant from its globally\naveraged value \\citep{Jha:07}. By comparing the MLCS2k2 fits used in that study\nto the results from other light-curve fitters applied to the same data, we\ndemonstrate that this is related to the interpretation of SN color excesses\n(after correction for a light-curve shape-color relation) and the presence of a\ncolor gradient across the local sample. If the slope of the linear relation\n($\\beta$) between SN color excess and luminosity is fit empirically, then the\nbubble disappears. If, on the other hand, the color excess arises purely from\nMilky Way-like dust, then SN data clearly favors a Hubble bubble. We\ndemonstrate that SN data give $\\beta \\simeq 2$, instead of the $\\beta \\simeq 4$\none would expect from purely Milky-Way-like dust. This suggests that either SN\nintrinsic colors are more complicated than can be described with a single\nlight-curve shape parameter, or that dust around SN is unusual. Disentangling\nthese possibilities is both a challenge and an opportunity for large-survey SN\nIa cosmology.\n\n", "human_text": "  We examine recent evidence from the luminosity-redshift relation of Type Ia\nSupernovae (SNe Ia) for the $\\sim 3 \\sigma$ detection of a ``Hubble bubble'' --\na departure of the local value of the Hubble constant from its globally\naveraged value \\citep{Jha:07}. By comparing the MLCS2k2 fits used in that study\nto the results from other light-curve fitters applied to the same data, we\ndemonstrate that this is related to the interpretation of SN color excesses\n(after correction for a light-curve shape-color relation) and the presence of a\ncolor gradient across the local sample. If the slope of the linear relation\n($\\beta$) between SN color excess and luminosity is fit empirically, then the\nbubble disappears. If, on the other hand, the color excess arises purely from\nMilky Way-like dust, then SN data clearly favors a Hubble bubble. We\ndemonstrate that SN data give $\\beta \\simeq 2$, instead of the $\\beta \\simeq 4$\none would expect from purely Milky-Way-like dust. This suggests that either SN\nintrinsic colors are more complicated than can be described with a single\nlight-curve shape parameter, or that dust around SN is unusual. Disentangling\nthese possibilities is both a challenge and an opportunity for large-survey SN\nIa cosmology.\n", "machine_text": "\nWe investigate the evidence indicating a possible 'Hubble bubble': a separation between the locally measured Hubble constant and its average value \\citep{Jha:07}. After contrasting the MLCS2k2 light-curve fitting of the data with various other light-curve fitters, we identify a correlation between the Type Ia supernova's colour surplus corrected for a shape-colour relation, and the colour gradient across the local sample. If the colour insurgence is empirically fit, the bubble ceases to exist. However, if it results from a dust like the Milky Way, then the bubble persists. Our research produced a $\\beta$ of about 2, indicating the dust which is diffused around the supernova remnant may have something unique about it. This reveals both a challenge and a chance for future SN Ia cosmological surveys.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0367}
{"prompt": "Rephrase the abstract of an article with title 'Finite temperature corrections and embedded strings in noncommutative\n  geometry and the standard model with neutrino mixing'.\n  The recent extension of the standard model to include massive neutrinos in\nthe framework of noncommutative geometry and the spectral action principle\ninvolves new scalar fields and their interactions with the usual complex scalar\ndoublet. After ensuring that they bring no unphysical consequences, we address\nthe question of how these fields affect the physics predicted in Weinberg-Salam\ntheory, particularly in the context of the Electroweak phase transition.\nApplying the Dolan-Jackiw procedure, we calculate the finite temperature\ncorrections, and find that the phase transition is first order. The new scalar\ninteractions significantly improve the stability of the Electroweak Z string,\nthrough the ``bag'' phenomenon described by Watkins and Vachaspati. (Recently\ncosmic strings have climbed back into interest due to new evidence). Sourced by\nstatic embedded strings, an internal space analogy of Cartan's torsion is\ndrawn, and a possible Higgs-force-like `gravitational' effect of this\nnon-propagating torsion on the fermion masses is described. We also check that\nthe field generating the Majorana mass for the $\\nu_R$ is non-zero in the\nphysical vacuum.\n\n", "human_text": "  The recent extension of the standard model to include massive neutrinos in\nthe framework of noncommutative geometry and the spectral action principle\ninvolves new scalar fields and their interactions with the usual complex scalar\ndoublet. After ensuring that they bring no unphysical consequences, we address\nthe question of how these fields affect the physics predicted in Weinberg-Salam\ntheory, particularly in the context of the Electroweak phase transition.\nApplying the Dolan-Jackiw procedure, we calculate the finite temperature\ncorrections, and find that the phase transition is first order. The new scalar\ninteractions significantly improve the stability of the Electroweak Z string,\nthrough the ``bag'' phenomenon described by Watkins and Vachaspati. (Recently\ncosmic strings have climbed back into interest due to new evidence). Sourced by\nstatic embedded strings, an internal space analogy of Cartan's torsion is\ndrawn, and a possible Higgs-force-like `gravitational' effect of this\nnon-propagating torsion on the fermion masses is described. We also check that\nthe field generating the Majorana mass for the $\\nu_R$ is non-zero in the\nphysical vacuum.\n", "machine_text": "\nThis article investigates how the addition of new scalar fields and interactions to the Standard Model impacts the predicted physics of the Weinberg-Salam theory, particularly the Electroweak phase transition. To this end, utilizing the Dolan-Jackiw method, finite temperature corrections are calculated and the phase transition found to be of first order. Additionally, the interaction of these new scalar fields strengthens the stability of the Z string of the Electroweak phase transition through the ``bag'' phenomenon first described by Watkins and Vachaspati. Furthermore, a 'gravitational' effect of non-propagating torsion on the mass of the fermions is proposed, as well as a check to make sure that the field generating the Majorana mass for the $\\nu_R$ is non-zero in the physical vacuum. All of this research could hold relevance with regards to the recent interest of study in cosmic strings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0613}
{"prompt": "Rephrase the abstract of an article with title 'The origin of the molecular emission around the southern hemisphere Re 4\n  IRS - HH 188 region'.\n  We present SEST observations of the molecular environment ahead of the\nsouthern Herbig-Haro object 188 (HH188), associated with the low-mass protostar\nRe4 IRS. We have also used the SuperCosmos Halpha survey to search for Halpha\nemission associated with the Re4 IRS - HH188 region. The aim of the present\nwork is to study the properties of the molecular gas and to better characterize\nthis southern star forming region. We mapped the HCO+ 3-2 and H13CO+ 1-0\nemission around the YSO and took spectra of the CH3OH 2(0)-1(0)A+ and\n2(-1)-1(-1)E and SO 6(5)-5(4) towards the central source. Column densities are\nderived and different scenarios are considered to explain the origin of the\nmolecular emission. HCO+ arises from a relatively compact region around the\nYSO; however, its peak emission is displaced to the south following the outflow\ndirection. Our chemical analysis indicates that a plausible scenario is that\nmost of the emission arises from the cold, illuminated dense gas ahead of the\nHH188 object. We have also found that HH188, a high excitation object, seems to\nbe part of a parsec scale and highly collimated HH system. Re4 IRS is probably\na binary protostellar system, in the late Class 0 or Class I phase. One of the\nprotostars, invisible in the near-IR, seems to power the HH188 system.\n\n", "human_text": "  We present SEST observations of the molecular environment ahead of the\nsouthern Herbig-Haro object 188 (HH188), associated with the low-mass protostar\nRe4 IRS. We have also used the SuperCosmos Halpha survey to search for Halpha\nemission associated with the Re4 IRS - HH188 region. The aim of the present\nwork is to study the properties of the molecular gas and to better characterize\nthis southern star forming region. We mapped the HCO+ 3-2 and H13CO+ 1-0\nemission around the YSO and took spectra of the CH3OH 2(0)-1(0)A+ and\n2(-1)-1(-1)E and SO 6(5)-5(4) towards the central source. Column densities are\nderived and different scenarios are considered to explain the origin of the\nmolecular emission. HCO+ arises from a relatively compact region around the\nYSO; however, its peak emission is displaced to the south following the outflow\ndirection. Our chemical analysis indicates that a plausible scenario is that\nmost of the emission arises from the cold, illuminated dense gas ahead of the\nHH188 object. We have also found that HH188, a high excitation object, seems to\nbe part of a parsec scale and highly collimated HH system. Re4 IRS is probably\na binary protostellar system, in the late Class 0 or Class I phase. One of the\nprotostars, invisible in the near-IR, seems to power the HH188 system.\n", "machine_text": "\nIn this work, we analyse the properties of the molecular gas, such as HCO+ 3-2\nand H13CO+ 1-0, around Re4 IRS and the southern Herbig-Haro object 188 (HH188)\nusing SEST observations and the SuperCosmos Halpha survey. Our results reveal\nthat most of the molecular emission arises from the cold, illuminated dense gas\nin front of the star forming region. We have also found that the YSO is part of\na parsec scale and highly collimated HH system and that the protostellar system\nis in the lateClass 0 or Class I phase. We also derive the column densities and\nconsider different scenarios to explain the origin of the molecular emission,\nwhere the peak emission is observed to be shifted towards the outflow direction.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1427}
{"prompt": "Rephrase the abstract of an article with title 'A case for variational geomagnetic data assimilation: insights from a\n  one-dimensional, nonlinear, and sparsely observed MHD system'.\n  Secular variations of the geomagnetic field have been measured with a\ncontinuously improving accuracy during the last few hundred years, culminating\nnowadays with satellite data. It is however well known that the dynamics of the\nmagnetic field is linked to that of the velocity field in the core and any\nattempt to model secular variations will involve a coupled dynamical system for\nmagnetic field and core velocity. Unfortunately, there is no direct observation\nof the velocity. Independently of the exact nature of the above-mentioned\ncoupled system -- some version being currently under construction -- the\nquestion is debated in this paper whether good knowledge of the magnetic field\ncan be translated into good knowledge of core dynamics. Furthermore, what will\nbe the impact of the most recent and precise geomagnetic data on our knowledge\nof the geomagnetic field of the past and future? These questions are cast into\nthe language of variational data assimilation, while the dynamical system\nconsidered in this paper consists in a set of two oversimplified\none-dimensional equations for magnetic and velocity fields. This toy model\nretains important features inherited from the induction and Navier-Stokes\nequations: non-linear magnetic and momentum terms are present and its linear\nresponse to small disturbances contains Alfv\\'en waves. It is concluded that\nvariational data assimilation is indeed appropriate in principle, even though\nthe velocity field remains hidden at all times; it allows us to recover the\nentire evolution of both fields from partial and irregularly distributed\ninformation on the magnetic field. This work constitutes a first step on the\nway toward the reassimilation of historical geomagnetic data and geomagnetic\nforecast.\n\n", "human_text": "  Secular variations of the geomagnetic field have been measured with a\ncontinuously improving accuracy during the last few hundred years, culminating\nnowadays with satellite data. It is however well known that the dynamics of the\nmagnetic field is linked to that of the velocity field in the core and any\nattempt to model secular variations will involve a coupled dynamical system for\nmagnetic field and core velocity. Unfortunately, there is no direct observation\nof the velocity. Independently of the exact nature of the above-mentioned\ncoupled system -- some version being currently under construction -- the\nquestion is debated in this paper whether good knowledge of the magnetic field\ncan be translated into good knowledge of core dynamics. Furthermore, what will\nbe the impact of the most recent and precise geomagnetic data on our knowledge\nof the geomagnetic field of the past and future? These questions are cast into\nthe language of variational data assimilation, while the dynamical system\nconsidered in this paper consists in a set of two oversimplified\none-dimensional equations for magnetic and velocity fields. This toy model\nretains important features inherited from the induction and Navier-Stokes\nequations: non-linear magnetic and momentum terms are present and its linear\nresponse to small disturbances contains Alfv\\'en waves. It is concluded that\nvariational data assimilation is indeed appropriate in principle, even though\nthe velocity field remains hidden at all times; it allows us to recover the\nentire evolution of both fields from partial and irregularly distributed\ninformation on the magnetic field. This work constitutes a first step on the\nway toward the reassimilation of historical geomagnetic data and geomagnetic\nforecast.\n", "machine_text": "\nThe purpose of this paper is to explore whether obtaining precise geomagnetic data can be used to learn about the concealed dynamics of the core. With the help of a one-dimensional, nonlinear, and unevenly monitored model of magnetohydrodynamic equilibriums, the authors investigate whether Variational Data Assimilation (VDA) is an appropriate approach for uncovering the evolution of both the core's velocity and magnetism. Their results show that even without direct observations of the velocity, VDA can correctly model the entire course of both fields. Therefore, this work offers a stepping stone to understanding the previous, present, and future of the geomagnetic field through the reintegration of historic data and making geomagnetic predictions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1777}
{"prompt": "Rephrase the abstract of an article with title 'Interpreting and predicting the yield of transit surveys: Giant planets\n  in the OGLE fields'.\n  Transiting extrasolar planets are now discovered jointly by photometric\nsurveys and by radial velocimetry. We want to determine whether the different\ndata sets are compatible between themselves and with models of the evolution of\nextrasolar planets. We simulate directly a population of stars corresponding to\nthe OGLE transit survey and assign them planetary companions based on radial\nvelocimetry discoveries. We use a model of the evolution and structure of giant\nplanets assuming a variable fraction of heavy elements. The output list of\ndetectable planets of the simulations is compared to the real detections. We\nconfirm that the radial velocimetry and photometric survey data sets are\ncompatible within the statistical errors, assuming that planets with periods\nbetween 1 and 2 days are approximately 5 times less frequent than planets with\nperiods between 2 and 5 days. We show that evolution models fitting present\nobservational constraints predict a lack of small giant planets with large\nmasses. We also identify distinct populations of planets: those with short\nperiods (P < 10d) are only found in orbit around metal-rich stars with [Fe/H] >\n-0.07. We further confirm the relative absence of low-mass giant planets at\nsmall orbital distances.\n\n", "human_text": "  Transiting extrasolar planets are now discovered jointly by photometric\nsurveys and by radial velocimetry. We want to determine whether the different\ndata sets are compatible between themselves and with models of the evolution of\nextrasolar planets. We simulate directly a population of stars corresponding to\nthe OGLE transit survey and assign them planetary companions based on radial\nvelocimetry discoveries. We use a model of the evolution and structure of giant\nplanets assuming a variable fraction of heavy elements. The output list of\ndetectable planets of the simulations is compared to the real detections. We\nconfirm that the radial velocimetry and photometric survey data sets are\ncompatible within the statistical errors, assuming that planets with periods\nbetween 1 and 2 days are approximately 5 times less frequent than planets with\nperiods between 2 and 5 days. We show that evolution models fitting present\nobservational constraints predict a lack of small giant planets with large\nmasses. We also identify distinct populations of planets: those with short\nperiods (P < 10d) are only found in orbit around metal-rich stars with [Fe/H] >\n-0.07. We further confirm the relative absence of low-mass giant planets at\nsmall orbital distances.\n", "machine_text": "\nIn this study, we investigate the compatibility and consistency between photometric  surveys and radial velocimetry data sets in terms of exoplanet population simulation.The OGLE field is used to simulate a star population and assign them extrasolar companions. Models of planet evolution and structure with varying fractions of heavy elements are utilized. We assess the compatibility of the output list of detectable planets from the simulations with the real detections, and determine whether planets with periods between 1 and 2 days are fewer than those with orbits between 2 and 5 days. Additionally, trends of relative absence of giant planets with low mass and small orbital distances are also established. Additionally, it is inferred that metal-rich stars with [Fe/H] >-0.07 are likely to have short period planets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1919}
{"prompt": "Rephrase the abstract of an article with title 'Effective gravity from a quantum gauge theory in Euclidean space-time'.\n  We consider a $SO(d)$ gauge theory in an Euclidean $d$-dimensional\nspace-time, which is known to be renormalizable to all orders in perturbation\ntheory for $2\\le{d}\\le4$. Then, with the help of a space-time representation of\nthe gauge group, the gauge theory is mapped into a curved space-time with\nlinear connection. Further, in that mapping the gauge field plays the role of\nthe linear connection of the curved space-time and an effective metric tensor\narises naturally from the mapping. The obtained action, being quadratic in the\nRiemann-Christoffel tensor, at a first sight, spoils a gravity interpretation\nof the model. Thus, we provide a sketch of a mechanism that breaks the $SO(d)$\ncolor invariance and generates the Einstein-Hilbert term, as well as a\ncosmological constant term, allowing an interpretation of the model as a\nmodified gravity in the Palatini formalism. In that sense, gravity can be\nvisualized as an effective classical theory, originated from a well defined\nquantum gauge theory. We also show that, in the four dimensional case, two\npossibilities for particular solutions of the field equations are the de Sitter\nand Anti de Sitter space-times.\n\n", "human_text": "  We consider a $SO(d)$ gauge theory in an Euclidean $d$-dimensional\nspace-time, which is known to be renormalizable to all orders in perturbation\ntheory for $2\\le{d}\\le4$. Then, with the help of a space-time representation of\nthe gauge group, the gauge theory is mapped into a curved space-time with\nlinear connection. Further, in that mapping the gauge field plays the role of\nthe linear connection of the curved space-time and an effective metric tensor\narises naturally from the mapping. The obtained action, being quadratic in the\nRiemann-Christoffel tensor, at a first sight, spoils a gravity interpretation\nof the model. Thus, we provide a sketch of a mechanism that breaks the $SO(d)$\ncolor invariance and generates the Einstein-Hilbert term, as well as a\ncosmological constant term, allowing an interpretation of the model as a\nmodified gravity in the Palatini formalism. In that sense, gravity can be\nvisualized as an effective classical theory, originated from a well defined\nquantum gauge theory. We also show that, in the four dimensional case, two\npossibilities for particular solutions of the field equations are the de Sitter\nand Anti de Sitter space-times.\n", "machine_text": "By analyzing a $SO(d)$ gauge theory in a Euclidean $d$-dimensional space-time, we provide a mechanism that breaks the $SO(d)$ color invariance and generates an effective metric tensor - allowing for an interpretation of the model as a modified gravity. The action of the model is quadratic in the Riemann-Christoffel tensor and two particular solutions for the field equations that arise in the four dimensional case are the de Sitter and Anti de Sitter space-times. Thus, we come up with a framework that enables effective gravity from a quantum gauge theory in Euclidean space-time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.22}
{"prompt": "Rephrase the abstract of an article with title 'Refined asymptotics around solitons for gKdV equations'.\n  We consider the generalized Korteweg-de Vries equation $$ \\partial_t u +\n\\partial_x (\\partial_x^2 u + f(u))=0, \\quad (t,x)\\in [0,T)\\times \\mathbb{R}$$\nwith general $C^2$ nonlinearity $f$. Under an explicit condition on $f$ and\n$c>0$, there exists a solution in the energy space $H^1$ of the type\n$u(t,x)=Q_c(x-x_0-ct)$, called soliton. Stability theory for $Q_c$ is\nwell-known.\n  In previous works, we have proved that for $f(u)=u^p$, $p=2,3,4$, the family\nof solitons is asymptotically stable in some local sense in $H^1$, i.e. if\n$u(t)$ is close to $Q_{c}$ (for all $t\\geq 0$), then $u(t,.+\\rho(t))$ locally\nconverges in the energy space to some $Q_{c_+}$ as $t\\to +\\infty$, for some\n$c^+\\sim c$.\n  Then, the asymptotic stability result could be extended to the case of\ngeneral assumptions on $f$ and $Q_c$.\n  The objective of this paper is twofold.\n  The main objective is to prove that in the case $f(u)=u^p$, $p=2,3,4$,\n$\\rho(t)-c_+ t$ has limit as $t\\to +\\infty$ under the additional assumption\n$x_+ u\\in L^2$.\n  The second objective of this paper is to provide large time stability and\nasymptotic stability results for two soliton solutions for the case of general\nnonlinearity $f(u)$, when the ratio of the speeds of the solitons is small. The\nmotivation is to accompany forthcoming works devoted to the collision of two\nsolitons in the nonintegrable case. The arguments are refinements of previous\nworks specialized to the case $u(t)\\sim Q_{c_1}+Q_{c_2}$, for $0< c_2 \\ll c_1$.\n\n", "human_text": "  We consider the generalized Korteweg-de Vries equation $$ \\partial_t u +\n\\partial_x (\\partial_x^2 u + f(u))=0, \\quad (t,x)\\in [0,T)\\times \\mathbb{R}$$\nwith general $C^2$ nonlinearity $f$. Under an explicit condition on $f$ and\n$c>0$, there exists a solution in the energy space $H^1$ of the type\n$u(t,x)=Q_c(x-x_0-ct)$, called soliton. Stability theory for $Q_c$ is\nwell-known.\n  In previous works, we have proved that for $f(u)=u^p$, $p=2,3,4$, the family\nof solitons is asymptotically stable in some local sense in $H^1$, i.e. if\n$u(t)$ is close to $Q_{c}$ (for all $t\\geq 0$), then $u(t,.+\\rho(t))$ locally\nconverges in the energy space to some $Q_{c_+}$ as $t\\to +\\infty$, for some\n$c^+\\sim c$.\n  Then, the asymptotic stability result could be extended to the case of\ngeneral assumptions on $f$ and $Q_c$.\n  The objective of this paper is twofold.\n  The main objective is to prove that in the case $f(u)=u^p$, $p=2,3,4$,\n$\\rho(t)-c_+ t$ has limit as $t\\to +\\infty$ under the additional assumption\n$x_+ u\\in L^2$.\n  The second objective of this paper is to provide large time stability and\nasymptotic stability results for two soliton solutions for the case of general\nnonlinearity $f(u)$, when the ratio of the speeds of the solitons is small. The\nmotivation is to accompany forthcoming works devoted to the collision of two\nsolitons in the nonintegrable case. The arguments are refinements of previous\nworks specialized to the case $u(t)\\sim Q_{c_1}+Q_{c_2}$, for $0< c_2 \\ll c_1$.\n", "machine_text": "This article investigates the asymptotic stability of solitons for gKdV equations of the type $\\partial_t u + \\partial_x (\\partial_x^2 u + f(u))=0$ with $f$ a general $C^2$ nonlinearity. Through an explicit condition on $f$ and $c>0$, a solution of the form $u(t,x)=Q_c(x-x_0-ct)$ is constructed; stability theory of this discovery is covered. The article then seeks to extend the stability result to the specific case of $f(u)=u^p$ for $p=2,3,4$ and also in general nonlinearity $f(u)$, when the speed ratio of two solitons is small. We strive to show that for the specialized case, the difference between the two measured speeds approaches a limit as time increases, given the additional requirement of $x_+ u\\in L^2$. Further, this paper aims to provide long-term asymptotic stability for two soliton solutions for general nonlinearity $f(u)$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1178}
{"prompt": "Rephrase the abstract of an article with title 'How to tell a gravastar from a black hole'.\n  Gravastars have been recently proposed as potential alternatives to explain\nthe astrophysical phenomenology traditionally associated to black holes,\nraising the question of whether the two objects can be distinguished at all.\nLeaving aside the debate about the processes that would lead to the formation\nof a gravastar and the astronomical evidence in their support, we here address\ntwo basic questions: Is a gravastar stable against generic perturbations? If\nstable, can an observer distinguish it from a black hole of the same mass? To\nanswer these questions we construct a general class of gravastars and determine\nthe conditions they must satisfy in order to exist as equilibrium solutions of\nthe Einstein equations. For such models we perform a systematic stability\nanalysis against axial-perturbations, computing the real and imaginary parts of\nthe eigenfrequencies. Overall, we find that gravastars are stable to axial\nperturbations, but also that their quasi-normal modes differ from those of a\nblack hole of the same mass and thus can be used to discern, beyond dispute, a\ngravastar from a black hole.\n\n", "human_text": "  Gravastars have been recently proposed as potential alternatives to explain\nthe astrophysical phenomenology traditionally associated to black holes,\nraising the question of whether the two objects can be distinguished at all.\nLeaving aside the debate about the processes that would lead to the formation\nof a gravastar and the astronomical evidence in their support, we here address\ntwo basic questions: Is a gravastar stable against generic perturbations? If\nstable, can an observer distinguish it from a black hole of the same mass? To\nanswer these questions we construct a general class of gravastars and determine\nthe conditions they must satisfy in order to exist as equilibrium solutions of\nthe Einstein equations. For such models we perform a systematic stability\nanalysis against axial-perturbations, computing the real and imaginary parts of\nthe eigenfrequencies. Overall, we find that gravastars are stable to axial\nperturbations, but also that their quasi-normal modes differ from those of a\nblack hole of the same mass and thus can be used to discern, beyond dispute, a\ngravastar from a black hole.\n", "machine_text": "\nCan a gravastar be distinguished from a black hole of the same mass? We explore the answer to this question by constructing a general class of gravastars and systematically analyzing the stability of these objects against axial perturbations. Comparing the quasi-normal modes of both objects reveals a unique signature of a gravastar, thus enabling observers to conclusively distinguish the two objects of same mass. We additionally identify the conditions a given gravastar must satisfy in order to exist as an equilibrium solution of the Einstein equations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1513}
{"prompt": "Rephrase the abstract of an article with title 'How robust are the constraints on cosmology and galaxy evolution from\n  the lens-redshift test?'.\n  The redshift distribution of galaxy lenses in known gravitational lens\nsystems provides a powerful test that can potentially discriminate amongst\ncosmological models. However, applications of this elegant test have been\ncurtailed by two factors: our ignorance of how galaxies evolve with redshift,\nand the absence of methods to deal with the effect of incomplete information in\nlensing systems. In this paper, we investigate both issues in detail. We\nexplore how to extract the properties of evolving galaxies, assuming that the\ncosmology is well determined by other techniques. We propose a new nested Monte\nCarlo method to quantify the effects of incomplete data. We apply the\nlens-redshift test to an improved sample of seventy lens systems derived from\nrecent observations, primarily from the SDSS, SLACS and the CLASS surveys. We\nfind that the limiting factor in applying the lens-redshift test derives from\npoor statistics, including incomplete information samples, and biased sampling.\nMany lenses that uniformly sample the underlying true image separation\ndistribution will be needed to use this test as a complementary method to\nmeasure the value of the cosmological constant or the properties of evolving\ngalaxies. Planned future surveys by missions like the SNAP satellite or LSST\nare likely to usher in a new era for strong lensing studies that utilize this\ntest. With expected catalogues of thousands of new strong lenses, the\nlens-redshift test could offer a powerful tool to probe cosmology as well as\ngalaxy evolution.\n\n", "human_text": "  The redshift distribution of galaxy lenses in known gravitational lens\nsystems provides a powerful test that can potentially discriminate amongst\ncosmological models. However, applications of this elegant test have been\ncurtailed by two factors: our ignorance of how galaxies evolve with redshift,\nand the absence of methods to deal with the effect of incomplete information in\nlensing systems. In this paper, we investigate both issues in detail. We\nexplore how to extract the properties of evolving galaxies, assuming that the\ncosmology is well determined by other techniques. We propose a new nested Monte\nCarlo method to quantify the effects of incomplete data. We apply the\nlens-redshift test to an improved sample of seventy lens systems derived from\nrecent observations, primarily from the SDSS, SLACS and the CLASS surveys. We\nfind that the limiting factor in applying the lens-redshift test derives from\npoor statistics, including incomplete information samples, and biased sampling.\nMany lenses that uniformly sample the underlying true image separation\ndistribution will be needed to use this test as a complementary method to\nmeasure the value of the cosmological constant or the properties of evolving\ngalaxies. Planned future surveys by missions like the SNAP satellite or LSST\nare likely to usher in a new era for strong lensing studies that utilize this\ntest. With expected catalogues of thousands of new strong lenses, the\nlens-redshift test could offer a powerful tool to probe cosmology as well as\ngalaxy evolution.\n", "machine_text": "\nThis study examines the limitations of using the redshift distribution of galaxy lenses in gravitational lens systems as a tool to learn more about cosmology and galaxy evolution. We evaluate ways to discern the properties of evolving galaxies, taking into account realistic cosmological models. Additionally, a new nested Monte Carlo method is proposed to address any missing data that could arise from incomplete information. Applying the lens-redshift test to an improved collection of 70 lens systems, mostly from the SDSS, SLACS, and the CLASS surveys, suggests that limitations stem from a lack of statistics, including incomplete data samples and biased sampling. Acquiring more lenses to uniformly sample the true image separation distribution is a key part of using this test for measuring cosmological constants and evolving galaxies. Anticipated future surveys from satellites like SNAP and LSST are likely to provide enormous amounts of strong lenses, making the lens-redshift test a more viable way to explore cosmology and galaxy evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3042}
{"prompt": "Rephrase the abstract of an article with title 'FIRST-based survey of Compact Steep Spectrum sources, V.\n  Milliarcsecond-scale morphology of CSS objects'.\n  Multifrequency VLBA observations of the final group of ten objects in a\nsample of FIRST-based compact steep spectrum (CSS) sources are presented. The\nsample was selected to investigate whether objects of this kind could be relics\nof radio-loud AGNs switched off at very early stages of their evolution or\npossibly to indicate intermittent activity. Initial observations were made\nusing MERLIN at 5 GHz. The sources have now been observed with the VLBA at 1.7,\n5 and 8.4 GHz in a snapshot mode with phase-referencing. The resulting maps are\npresented along with unpublished 8.4-GHz VLA images of five sources. Some of\nthe sources discussed here show a complex radio morphology and therefore a\ncomplicated past that, in some cases, might indicate intermittent activity. One\nof the sources studied - 1045+352 - is known as a powerful radio and\ninfrared-luminous broad absorption line (BAL) quasar. It is a young CSS object\nwhose asymmetric two-sided morphology on a scale of several hundred parsecs,\nextending in two different directions, may suggest intermittent activity. The\nyoung age and compact structure of 1045+352 is consistent with the evolution\nscenario of BAL quasars. It has also been confirmed that the submillimetre flux\nof 1045+352 can be seriously contaminated by synchrotron emission.\n\n", "human_text": "  Multifrequency VLBA observations of the final group of ten objects in a\nsample of FIRST-based compact steep spectrum (CSS) sources are presented. The\nsample was selected to investigate whether objects of this kind could be relics\nof radio-loud AGNs switched off at very early stages of their evolution or\npossibly to indicate intermittent activity. Initial observations were made\nusing MERLIN at 5 GHz. The sources have now been observed with the VLBA at 1.7,\n5 and 8.4 GHz in a snapshot mode with phase-referencing. The resulting maps are\npresented along with unpublished 8.4-GHz VLA images of five sources. Some of\nthe sources discussed here show a complex radio morphology and therefore a\ncomplicated past that, in some cases, might indicate intermittent activity. One\nof the sources studied - 1045+352 - is known as a powerful radio and\ninfrared-luminous broad absorption line (BAL) quasar. It is a young CSS object\nwhose asymmetric two-sided morphology on a scale of several hundred parsecs,\nextending in two different directions, may suggest intermittent activity. The\nyoung age and compact structure of 1045+352 is consistent with the evolution\nscenario of BAL quasars. It has also been confirmed that the submillimetre flux\nof 1045+352 can be seriously contaminated by synchrotron emission.\n", "machine_text": "\nThis study investigated a sample of ten FIRST-based compact steep spectrum (CSS) sources, making use of multifrequency Very Long Baseline Array (VLBA) observations at 1.7, 5 and 8.4 GHz as well as unpublished 8.4GHz Very Large Array (VLA) images of five sources. The purpose was to examine their morphological characteristics on milliarcsecond scales in order to evaluate whether they could be relics of early-stage radio-loud AGNs or indicators of intermittent activity. The resulting maps suggest a complex radio past in some cases, possibly due to intense activity that outputs into multiple directions. The prominent example of this is 1045+352, a young CSS object whose powerful synchrotron emission is also seen in the infrared in the form of a broad absorption line (BAL) quasar. Its asymmetric two-sided morphology may suggest episodes of intermittent activity, which are consistent with the evolutionary hardening of BAL quasars. It has also been confirmed that the submillimetre flux of 1045+352 is largely composed of synchrotron emission.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0351}
{"prompt": "Rephrase the abstract of an article with title 'Mechanical Proof of the Second Law of Thermodynamics Based on Volume\n  Entropy'.\n  In a previous work (M. Campisi. Stud. Hist. Phil. M. P. 36 (2005) 275-290) we\nhave addressed the mechanical foundations of equilibrium thermodynamics on the\nbasis of the Generalized Helmholtz Theorem. It was found that the volume\nentropy provides a good mechanical analogue of thermodynamic entropy because it\nsatisfies the heat theorem and it is an adiabatic invariant. This property\nexplains the ``equal'' sign in Clausius principle ($S_f \\geq S_i$) in a purely\nmechanical way and suggests that the volume entropy might explain the ``larger\nthan'' sign (i.e. the Law of Entropy Increase) if non adiabatic transformations\nwere considered. Based on the principles of microscopic (quantum or classical)\nmechanics here we prove that, provided the initial equilibrium satisfy the\nnatural condition of decreasing ordering of probabilities, the expectation\nvalue of the volume entropy cannot decrease for arbitrary transformations\nperformed by some external sources of work on a insulated system. This can be\nregarded as a rigorous quantum mechanical proof of the Second Law. We discuss\nhow this result relates to the Minimal Work Principle and improves over\nprevious attempts. The natural evolution of entropy is towards larger values\nbecause the natural state of matter is at positive temperature. Actually the\nLaw of Entropy Decrease holds in artificially prepared negative temperature\nsystems.\n\n", "human_text": "  In a previous work (M. Campisi. Stud. Hist. Phil. M. P. 36 (2005) 275-290) we\nhave addressed the mechanical foundations of equilibrium thermodynamics on the\nbasis of the Generalized Helmholtz Theorem. It was found that the volume\nentropy provides a good mechanical analogue of thermodynamic entropy because it\nsatisfies the heat theorem and it is an adiabatic invariant. This property\nexplains the ``equal'' sign in Clausius principle ($S_f \\geq S_i$) in a purely\nmechanical way and suggests that the volume entropy might explain the ``larger\nthan'' sign (i.e. the Law of Entropy Increase) if non adiabatic transformations\nwere considered. Based on the principles of microscopic (quantum or classical)\nmechanics here we prove that, provided the initial equilibrium satisfy the\nnatural condition of decreasing ordering of probabilities, the expectation\nvalue of the volume entropy cannot decrease for arbitrary transformations\nperformed by some external sources of work on a insulated system. This can be\nregarded as a rigorous quantum mechanical proof of the Second Law. We discuss\nhow this result relates to the Minimal Work Principle and improves over\nprevious attempts. The natural evolution of entropy is towards larger values\nbecause the natural state of matter is at positive temperature. Actually the\nLaw of Entropy Decrease holds in artificially prepared negative temperature\nsystems.\n", "machine_text": "The present work offers a mechanical proof of the Second Law of Thermodynamics by providing an analysis of the volume entropy. This study looks at the Generalized Helmholtz Theorem and explores how the volume entropy satisfies the heat theorem, and can be considered an adiabatic invariant, which explains the 'equal' sign of the Clausius Principle. We derive from this the 'larger than' sign when considering non-adiabatic transformations. We then go on to show that, provided the natural ordering of probabilities is decreasing, the expected value of volume entropy cannot decrease for any type of external source of work on an insulated system. As such, this is a rigorous quantum mechanical proof of the Second Law, which also relates to the Minimal Work Principle. Lastly, we tackle the Natural Law of Entropy Increase and the possible decrease of entropy in artificially prepared negative temperature systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2567}
{"prompt": "Rephrase the abstract of an article with title 'Selective control of the apoptosis signaling network in heterogeneous\n  cell populations'.\n  Selective control in a population is the ability to control a member of the\npopulation while leaving the other members relatively unaffected. The concept\nof selective control is developed using cell death or apoptosis in\nheterogeneous cell populations as an example. Apoptosis signaling in\nheterogeneous cells is described by an ensemble of gene networks with identical\ntopology but different link strengths. Selective control depends on the\nstatistics of signaling in the ensemble of networks and we analyse the effects\nof superposition, non-linearity and feedback on these statistics. Parallel\npathways promote normal statistics while series pathways promote skew\ndistributions which in the most extreme cases become log-normal. We also show\nthat feedback and non-linearity can produce bimodal signaling statistics, as\ncan discreteness and non-linearity. Two methods for optimizing selective\ncontrol are presented. The first is an exhaustive search method and the second\nis a linear programming based approach. Though control of a single gene in the\nsignaling network yields little selectivity, control of a few genes typically\nyields higher levels of selectivity. The statistics of gene combinations\nsusceptible to selective control is studied and is used to identify general\ncontrol strategies. We found that selectivity is promoted by acting on the\nleast sensitive nodes in the case of weak populations, while selective control\nof robust populations is optimized through perturbations of more sensitive\nnodes. High throughput experiments with heterogeneous cell lines could be\ndesigned in an analogous manner, with the further possibility of incorporating\nthe selectivity optimization process into a closed-loop control system.\n\n", "human_text": "  Selective control in a population is the ability to control a member of the\npopulation while leaving the other members relatively unaffected. The concept\nof selective control is developed using cell death or apoptosis in\nheterogeneous cell populations as an example. Apoptosis signaling in\nheterogeneous cells is described by an ensemble of gene networks with identical\ntopology but different link strengths. Selective control depends on the\nstatistics of signaling in the ensemble of networks and we analyse the effects\nof superposition, non-linearity and feedback on these statistics. Parallel\npathways promote normal statistics while series pathways promote skew\ndistributions which in the most extreme cases become log-normal. We also show\nthat feedback and non-linearity can produce bimodal signaling statistics, as\ncan discreteness and non-linearity. Two methods for optimizing selective\ncontrol are presented. The first is an exhaustive search method and the second\nis a linear programming based approach. Though control of a single gene in the\nsignaling network yields little selectivity, control of a few genes typically\nyields higher levels of selectivity. The statistics of gene combinations\nsusceptible to selective control is studied and is used to identify general\ncontrol strategies. We found that selectivity is promoted by acting on the\nleast sensitive nodes in the case of weak populations, while selective control\nof robust populations is optimized through perturbations of more sensitive\nnodes. High throughput experiments with heterogeneous cell lines could be\ndesigned in an analogous manner, with the further possibility of incorporating\nthe selectivity optimization process into a closed-loop control system.\n", "machine_text": "\nThis article examines the concept of selective control in a heterogeneous cell population by considering cell death, or apoptosis, as an example. An analysis is conducted on the impact that superposition, non-linearity, and feedback have on statistics involved in the signaling of apoptosis in these populations. Using both exhaustive search and linear programming methods, two approaches are presented for optimizing selective control. By manipulating a few genes within the apoptosis network significant levels of selectivity can be achieved. We additionally investigate the statistics of gene combinations in order to develop general control strategies, and determine that weak populations receive the best results when controlling the least sensitive nodes, while strong populations benefit from targeting the more sensitive nodes. Suggestions are made for applying the finding of this research in experiments and for the development of closed-loop control systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4634}
{"prompt": "Rephrase the abstract of an article with title 'Analyzing Design Process and Experiments on the AnITA Generic Tutoring\n  System'.\n  In the field of tutoring systems, investigations have shown that there are\nmany tutoring systems specific to a specific domain that, because of their\nstatic architecture, cannot be adapted to other domains. As consequence, often\nneither methods nor knowledge can be reused. In addition, the knowledge\nengineer must have programming skills in order to enhance and evaluate the\nsystem. One particular challenge is to tackle these problems with the\ndevelopment of a generic tutoring system. AnITA, as a stand-alone application,\nhas been developed and implemented particularly for this purpose. However, in\nthe testing phase, we discovered that this architecture did not fully match the\nuser's intuitive understanding of the use of a learning tool. Therefore, AnITA\nhas been redesigned to exclusively work as a client/server application and\nrenamed to AnITA2. This paper discusses the evolvements made on the AnITA\ntutoring system, the goal of which is to use generic principles for system\nre-use in any domain. Two experiments were conducted, and the results are\npresented in this paper.\n\n", "human_text": "  In the field of tutoring systems, investigations have shown that there are\nmany tutoring systems specific to a specific domain that, because of their\nstatic architecture, cannot be adapted to other domains. As consequence, often\nneither methods nor knowledge can be reused. In addition, the knowledge\nengineer must have programming skills in order to enhance and evaluate the\nsystem. One particular challenge is to tackle these problems with the\ndevelopment of a generic tutoring system. AnITA, as a stand-alone application,\nhas been developed and implemented particularly for this purpose. However, in\nthe testing phase, we discovered that this architecture did not fully match the\nuser's intuitive understanding of the use of a learning tool. Therefore, AnITA\nhas been redesigned to exclusively work as a client/server application and\nrenamed to AnITA2. This paper discusses the evolvements made on the AnITA\ntutoring system, the goal of which is to use generic principles for system\nre-use in any domain. Two experiments were conducted, and the results are\npresented in this paper.\n", "machine_text": "\nThis paper presents an analysis of the design process and experiments conducted on the AnITA Generic Tutoring System, a stand-alone application intended to provide a generic platform for re-use of tutoring systems in any domain. After the initial testing phase revealed issues in user understanding, the system was redesigned to become a client/server application called AnITA2. The paper details the morphing of AnITA to AnITA2, describes the two experiments conducted on the new system, and shares the results of those experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1402}
{"prompt": "Rephrase the abstract of an article with title 'Epitaxial thin films of multiferroic Bi2FeCrO6 with B-site cationic\n  order'.\n  Epitaxial thin films of Bi2FeCrO6 have been synthesized by pulsed laser\ndeposition on SrRuO3 on (100)- and (111)-oriented SrTiO3 substrates. Detailed\nX-ray diffraction and cross-section transmission electron microscopy analysis\nrevealed a double perovskite crystal structure of the Bi2FeCrO6 epitaxial films\nvery similar to that of BiFeO3 along with a particularly noteworthy Fe3+/Cr3+\ncation ordering along the [111] direction. The films contain no detectable\nmagnetic iron oxide impurities and have the correct cationic average\nstoichiometry throughout their thickness. They however exhibit a slight\nmodulation in the Fe and Cr compositions forming complementary stripe patterns,\nsuggesting minor local excess or depletion of Fe and Cr. The epitaxial BFCO\nfilms exhibit good ferroelectric and piezoelectric properties, in addition to\nmagnetic properties at room temperature, as well as an unexpected\ncrystallographic orientation dependence of their room temperature magnetic\nproperties. Our results qualitatively confirm the predictions made using the\nab-initio calculations: the double-perovskite structure of Bi2FeCrO6 films\nexhibit a Fe3+/Cr3+ cation ordering and good multiferroic properties, along\nwith the unpredicted existence of magnetic ordering at room temperature.\n\n", "human_text": "  Epitaxial thin films of Bi2FeCrO6 have been synthesized by pulsed laser\ndeposition on SrRuO3 on (100)- and (111)-oriented SrTiO3 substrates. Detailed\nX-ray diffraction and cross-section transmission electron microscopy analysis\nrevealed a double perovskite crystal structure of the Bi2FeCrO6 epitaxial films\nvery similar to that of BiFeO3 along with a particularly noteworthy Fe3+/Cr3+\ncation ordering along the [111] direction. The films contain no detectable\nmagnetic iron oxide impurities and have the correct cationic average\nstoichiometry throughout their thickness. They however exhibit a slight\nmodulation in the Fe and Cr compositions forming complementary stripe patterns,\nsuggesting minor local excess or depletion of Fe and Cr. The epitaxial BFCO\nfilms exhibit good ferroelectric and piezoelectric properties, in addition to\nmagnetic properties at room temperature, as well as an unexpected\ncrystallographic orientation dependence of their room temperature magnetic\nproperties. Our results qualitatively confirm the predictions made using the\nab-initio calculations: the double-perovskite structure of Bi2FeCrO6 films\nexhibit a Fe3+/Cr3+ cation ordering and good multiferroic properties, along\nwith the unpredicted existence of magnetic ordering at room temperature.\n", "machine_text": "\nEpitaxial thin films of Bi2FeCrO6, a material with a double-perovskite crystal\nstructure resembling that of BiFeO3, have been prepared via pulsed laser\ndeposition on (100)- and (111)-oriented SrTiO3 substrates. X-ray diffraction\nand cross-section transmission electron microscopy revealed a particular\nFe3+/Cr3+ ordering in the Bi2FeCrO6 films along the [111] direction. The\ncompositions of Fe and Cr were also found to show variation throughout the\nfilm, forming complementary stripe patterns. The resulting films were free from\nmagnetic iron oxide impurities and contained the correct cationic average\nstochiometry. Additionally, these multiferroic films have been shown to have\ngood ferroelectric and piezoelectric properties, in addition to room\ntemperature magnetic properties, which exhibit an unexpected orientation\ndependence. This is in agreement with ab-initio modelling, which confirms the\nFe3+/Cr3+ ordering and multifunctional properties of the BFCO films.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.439}
{"prompt": "Rephrase the abstract of an article with title 'Nonstationary random acoustic and electromagnetic fields as wave\n  diffusion processes'.\n  We investigate the effects of relatively rapid variations of the boundaries\nof an overmoded cavity on the stochastic properties of its interior acoustic or\nelectromagnetic field. For quasi-static variations, this field can be\nrepresented as an ideal incoherent and statistically homogeneous isotropic\nrandom scalar or vector field, respectively. A physical model is constructed\nshowing that the field dynamics can be characterized as a generalized diffusion\nprocess. The Langevin--It\\^{o} and Fokker--Planck equations are derived and\ntheir associated statistics and distributions for the complex analytic field,\nits magnitude and energy density are computed. The energy diffusion parameter\nis found to be proportional to the square of the ratio of the standard\ndeviation of the source field to the characteristic time constant of the\ndynamic process, but is independent of the initial energy density, to first\norder. The energy drift vanishes in the asymptotic limit. The time-energy\nprobability distribution is in general not separable, as a result of\nnonstationarity. A general solution of the Fokker--Planck equation is obtained\nin integral form, together with explicit closed-form solutions for several\nasymptotic cases. The findings extend known results on statistics and\ndistributions of quasi-stationary ideal random fields (pure diffusions), which\nare retrieved as special cases.\n\n", "human_text": "  We investigate the effects of relatively rapid variations of the boundaries\nof an overmoded cavity on the stochastic properties of its interior acoustic or\nelectromagnetic field. For quasi-static variations, this field can be\nrepresented as an ideal incoherent and statistically homogeneous isotropic\nrandom scalar or vector field, respectively. A physical model is constructed\nshowing that the field dynamics can be characterized as a generalized diffusion\nprocess. The Langevin--It\\^{o} and Fokker--Planck equations are derived and\ntheir associated statistics and distributions for the complex analytic field,\nits magnitude and energy density are computed. The energy diffusion parameter\nis found to be proportional to the square of the ratio of the standard\ndeviation of the source field to the characteristic time constant of the\ndynamic process, but is independent of the initial energy density, to first\norder. The energy drift vanishes in the asymptotic limit. The time-energy\nprobability distribution is in general not separable, as a result of\nnonstationarity. A general solution of the Fokker--Planck equation is obtained\nin integral form, together with explicit closed-form solutions for several\nasymptotic cases. The findings extend known results on statistics and\ndistributions of quasi-stationary ideal random fields (pure diffusions), which\nare retrieved as special cases.\n", "machine_text": "\nWe examine how variations in the boundaries of an overmoded cavity can impact the randomness of its interior acoustic or electromagnetic field. This field can be viewed as an ideal incoherent, statistically homogeneous, and isotropic random scalar or vector field, respectively. We construct a physical model which indicates that the field dynamics can be recognized as an advanced diffusion process. We work out the Langevin-It\\^{o} and Fokker-Planck equations, in order to determine the contentions and distributions of the complex analytic field, its magnitude, and energy density. We discover the energy diffusion factor to be relative to the square of the ratio of the standard deviation of the source field to the deciding time continual of the dynamic procedure, yet independent of the beginning energy density, as first order. The energy drift vanishes asymptotically. The time-energy probability distribution is generally separate, due to nonstationarity. We provide a broad solution of the Fokker-Planck equation in an integral type, as well as explicit closed form solutions for certain asymptotic cases. Our discoveries stretch out beyond those of known results on statistics and distributions of quasi-stationary ideal random fields (ordinary diffusions), which are admired as extraordinary cases.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0525}
{"prompt": "Rephrase the abstract of an article with title 'Neel order in square and triangular lattice Heisenberg models'.\n  Using examples of the square- and triangular-lattice Heisenberg models we\ndemonstrate that the density matrix renormalization group method (DMRG) can be\neffectively used to study magnetic ordering in two-dimensional lattice spin\nmodels. We show that local quantities in DMRG calculations, such as the on-site\nmagnetization M, should be extrapolated with the truncation error, not with its\nsquare root, as previously assumed. We also introduce convenient sequences of\nclusters, using cylindrical boundary conditions and pinning magnetic fields,\nwhich provide for rapidly converging finite-size scaling. This scaling behavior\non our clusters is clarified using finite-size analysis of the effective\nsigma-model and finite-size spin-wave theory. The resulting greatly improved\nextrapolations allow us to determine the thermodynamic limit of M for the\nsquare lattice with an error comparable to quantum Monte Carlo. For the\ntriangular lattice, we verify the existence of three-sublattice magnetic order,\nand estimate the order parameter to be M = 0.205(15).\n\n", "human_text": "  Using examples of the square- and triangular-lattice Heisenberg models we\ndemonstrate that the density matrix renormalization group method (DMRG) can be\neffectively used to study magnetic ordering in two-dimensional lattice spin\nmodels. We show that local quantities in DMRG calculations, such as the on-site\nmagnetization M, should be extrapolated with the truncation error, not with its\nsquare root, as previously assumed. We also introduce convenient sequences of\nclusters, using cylindrical boundary conditions and pinning magnetic fields,\nwhich provide for rapidly converging finite-size scaling. This scaling behavior\non our clusters is clarified using finite-size analysis of the effective\nsigma-model and finite-size spin-wave theory. The resulting greatly improved\nextrapolations allow us to determine the thermodynamic limit of M for the\nsquare lattice with an error comparable to quantum Monte Carlo. For the\ntriangular lattice, we verify the existence of three-sublattice magnetic order,\nand estimate the order parameter to be M = 0.205(15).\n", "machine_text": "\nWe examine the two-dimensional lattice spin models of the square and triangular lattice Heisenberg models, using the density matrix renormalization group (DMRG) method, and find that it can be utilized to effectively measure the magnetization ordering. We discover that it is essential to extrapolate local values obtained from the DMRG calculations using the truncation error and not the square root, as had been previously assumed. To improve finite-size scaling of the clusters, we introduce cyclic boundary conditions and fixed magnetization fields. The finite-size analysis of the effective sigma-model and spin-wave theory provide further insights about the scaling behavior. These extrapolations so obtained enable us to attain the value of the order parameter for the square lattice with a precision similar to those obtained from quantum Monte Carlo. For the triangular lattice, the order parameter of M = 0.205(15) reveals that the three-sublattice magnetic order exists.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2746}
{"prompt": "Rephrase the abstract of an article with title 'The potential of mass rearing of Monoksa dorsiplana (Pteromalidae) a\n  native gregarious ectoparasitoid of Pseudopachymeria spinipes (Bruchidae)in\n  South America'.\n  In Chile and Uruguay,the gregarious Pteromalidae (Monoksa dorsiplana) has\nbeen discovered emerging from seeds of the persistent pods of Acacia caven\nattacked by the univoltin bruchid Pseudopachymeria spinipes. We investigated\nthe potential for mass rearing of this gregarious ectoparasitoid on an\nalternative bruchid host, Callosobruchus maculatus, to use it against the\nbruchidae of native and cultured species of Leguminosea seeds in South America.\nThe mass rearing of M.dorsiplana was carried out in a population cage where the\ndensity of egg-laying females per infested seed was increased from 1:1 on the\nfirst day to 5:1 on the last (fifth) day. Under these experimental conditions\negg-clutch size per host increased, and at the same time the mortality of eggs\nlaid also increased. The density of egg-laying females influenced the sex ratio\nwhich tended towards a balance of sons and daughters,in contrast to the sex\nratio of a single egg-laying female per host (1 son to 7 daughters). The mean\nweight of adults emerging from a parasitized host was negatively correlated\nwith the egg-clutch size, i.e., as egg-clutch size increased, adult weight\ndecreased. All these results show that mass rearing of the gregarious\nectoparasitoid M.dorsiplana was possible under laboratory conditions on an\nalternative bruchid host C.maculatus. As M.dorsiplana is a natural enemy of\nlarval and pupal stages of bruchidae, the next step was to investigate whether\nthe biological control of bruchid C.maculatus was possible in an experimental\nstructure of stored beans.\n\n", "human_text": "  In Chile and Uruguay,the gregarious Pteromalidae (Monoksa dorsiplana) has\nbeen discovered emerging from seeds of the persistent pods of Acacia caven\nattacked by the univoltin bruchid Pseudopachymeria spinipes. We investigated\nthe potential for mass rearing of this gregarious ectoparasitoid on an\nalternative bruchid host, Callosobruchus maculatus, to use it against the\nbruchidae of native and cultured species of Leguminosea seeds in South America.\nThe mass rearing of M.dorsiplana was carried out in a population cage where the\ndensity of egg-laying females per infested seed was increased from 1:1 on the\nfirst day to 5:1 on the last (fifth) day. Under these experimental conditions\negg-clutch size per host increased, and at the same time the mortality of eggs\nlaid also increased. The density of egg-laying females influenced the sex ratio\nwhich tended towards a balance of sons and daughters,in contrast to the sex\nratio of a single egg-laying female per host (1 son to 7 daughters). The mean\nweight of adults emerging from a parasitized host was negatively correlated\nwith the egg-clutch size, i.e., as egg-clutch size increased, adult weight\ndecreased. All these results show that mass rearing of the gregarious\nectoparasitoid M.dorsiplana was possible under laboratory conditions on an\nalternative bruchid host C.maculatus. As M.dorsiplana is a natural enemy of\nlarval and pupal stages of bruchidae, the next step was to investigate whether\nthe biological control of bruchid C.maculatus was possible in an experimental\nstructure of stored beans.\n", "machine_text": "\nAn investigation has been conducted to examine the possibility of mass rearing the native gregarious ectoparasitoid Monoksa dorsiplana, which emerges from Pseudopachymeria spinipes (Bruchidae) seeds in South America, on a different host, Callosobruchus maculatus, for use as a biological control against Leguminosae species. Studies show that when density of egg-laying females increased from 1:1 to 5:1, egg-clutch size per host rose and mortality of eggs laid also raised. Additionally, the ratio of males and females tended to balance, differing from single egg-laying female per host cases. Correlation studies between adult weight of parasites and clutch size display a negative trend, indicating that weight of adults decreased as egg-clutch size increased. To further research applicability of M. dorsiplana to bruchid C. maculatus control in stored beans, the effect of its mass rearing in laboratory circumstances must be studied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.271}
{"prompt": "Rephrase the abstract of an article with title 'Considering the Case for Biodiversity Cycles: Reexamining the Evidence\n  for Periodicity in the Fossil Record'.\n  Medvedev and Melott (2007) have suggested that periodicity in fossil\nbiodiversity may be induced by cosmic rays which vary as the Solar System\noscillates normal to the galactic disk. We re-examine the evidence for a 62\nmillion year (Myr) periodicity in biodiversity throughout the Phanerozoic\nhistory of animal life reported by Rohde & Mueller (2005), as well as related\nquestions of periodicity in origination and extinction. We find that the signal\nis robust against variations in methods of analysis, and is based on\nfluctuations in the Paleozoic and a substantial part of the Mesozoic.\nExamination of origination and extinction is somewhat ambiguous, with results\ndepending upon procedure. Origination and extinction intensity as defined by RM\nmay be affected by an artifact at 27 Myr in the duration of stratigraphic\nintervals. Nevertheless, when a procedure free of this artifact is implemented,\nthe 27 Myr periodicity appears in origination, suggesting that the artifact may\nultimately be based on a signal in the data. A 62 Myr feature appears in\nextinction, when this same procedure is used. We conclude that evidence for a\nperiodicity at 62 Myr is robust, and evidence for periodicity at approximately\n27 Myr is also present, albeit more ambiguous.\n\n", "human_text": "  Medvedev and Melott (2007) have suggested that periodicity in fossil\nbiodiversity may be induced by cosmic rays which vary as the Solar System\noscillates normal to the galactic disk. We re-examine the evidence for a 62\nmillion year (Myr) periodicity in biodiversity throughout the Phanerozoic\nhistory of animal life reported by Rohde & Mueller (2005), as well as related\nquestions of periodicity in origination and extinction. We find that the signal\nis robust against variations in methods of analysis, and is based on\nfluctuations in the Paleozoic and a substantial part of the Mesozoic.\nExamination of origination and extinction is somewhat ambiguous, with results\ndepending upon procedure. Origination and extinction intensity as defined by RM\nmay be affected by an artifact at 27 Myr in the duration of stratigraphic\nintervals. Nevertheless, when a procedure free of this artifact is implemented,\nthe 27 Myr periodicity appears in origination, suggesting that the artifact may\nultimately be based on a signal in the data. A 62 Myr feature appears in\nextinction, when this same procedure is used. We conclude that evidence for a\nperiodicity at 62 Myr is robust, and evidence for periodicity at approximately\n27 Myr is also present, albeit more ambiguous.\n", "machine_text": "This paper reviews the evidence for periodicity in fossil biodiversity over the course of the Phanerozoic era, as suggested by Rohde & Mueller (2005). We investigate the strength of the signal found by Rohde & Mueller (2005) and evaluate the occurrence of periodicity in origination and extinction of animal species. Our analysis discovers fluctuations in biodiversity in the Paleozoic and early Mesozoic eras and indicates that there may be a 62 million year periodicity as suggested by Rohde and Mueller (2005). Additionally, our findings suggest artifacts at a 27 million year period in origination and extinction, potentially lending evidence to a periodicity in these processes as well. This review highlights the importance of considering the impact of cosmic rays on the fossil record and emphasizes the potential of a more thorough evaluation of biodiversity cycles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2896}
{"prompt": "Rephrase the abstract of an article with title 'Hydrodynamical simulation of detonations in superbursts. I. The\n  hydrodynamical algorithm and some preliminary one-dimensional results'.\n  Aims. This work presents a new hydrodynamical algorithm to study\nastrophysical detonations. A prime motivation of this development is the\ndescription of a carbon detonation in conditions relevant to superbursts, which\nare thought to result from the propagation of a detonation front around the\nsurface of a neutron star in the carbon layer underlying the atmosphere.\nMethods. The algorithm we have developed is a finite-volume method inspired by\nthe original MUSCL scheme of van Leer (1979). The algorithm is of second-order\nin the smooth part of the flow and avoids dimensional splitting. It is applied\nto some test cases, and the time-dependent results are compared to the\ncorresponding steady state solution. Results. Our algorithm proves to be robust\nto test cases, and is considered to be reliably applicable to astrophysical\ndetonations. The preliminary one-dimensional calculations we have performed\ndemonstrate that the carbon detonation at the surface of a neutron star is a\nmultiscale phenomenon. The length scale of liberation of energy is $10^6$ times\nsmaller than the total reaction length. We show that a multi-resolution\napproach can be used to solve all the reaction lengths. This result will be\nvery useful in future multi-dimensional simulations. We present also\nthermodynamical and composition profiles after the passage of a detonation in a\npure carbon or mixed carbon-iron layer, in thermodynamical conditions relevant\nto superbursts in pure helium accretor systems.\n\n", "human_text": "  Aims. This work presents a new hydrodynamical algorithm to study\nastrophysical detonations. A prime motivation of this development is the\ndescription of a carbon detonation in conditions relevant to superbursts, which\nare thought to result from the propagation of a detonation front around the\nsurface of a neutron star in the carbon layer underlying the atmosphere.\nMethods. The algorithm we have developed is a finite-volume method inspired by\nthe original MUSCL scheme of van Leer (1979). The algorithm is of second-order\nin the smooth part of the flow and avoids dimensional splitting. It is applied\nto some test cases, and the time-dependent results are compared to the\ncorresponding steady state solution. Results. Our algorithm proves to be robust\nto test cases, and is considered to be reliably applicable to astrophysical\ndetonations. The preliminary one-dimensional calculations we have performed\ndemonstrate that the carbon detonation at the surface of a neutron star is a\nmultiscale phenomenon. The length scale of liberation of energy is $10^6$ times\nsmaller than the total reaction length. We show that a multi-resolution\napproach can be used to solve all the reaction lengths. This result will be\nvery useful in future multi-dimensional simulations. We present also\nthermodynamical and composition profiles after the passage of a detonation in a\npure carbon or mixed carbon-iron layer, in thermodynamical conditions relevant\nto superbursts in pure helium accretor systems.\n", "machine_text": "\nThis article presents a hydrodynamical algorithm as a tool to study astrophysical detonations, with a specific aim of simulating the carbon detonation that occurs in a superburst event. The algorithm is based on the MUSCL scheme of van Leer and is second-order accurate. Tests performed using the algorithm demonstrate it to be reliable. Preliminary one-dimensional studies show that the carbon detonation process is a multi-scale phenomenon, with the liberation of energy occurring on a length scale $10^6$ times smaller than the total reaction length. It is suggested that a multi-resolution approach can be used to tackle all the reaction lengths. Thermodynamic and composition profiles for different layers of carbon, iron and helium relevant to superbursts are also provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2674}
{"prompt": "Rephrase the abstract of an article with title 'Imbalanced Superfluid Phase of a Trapped Fermi Gas in the BCS-BEC\n  Crossover Regime'.\n  We theoretically investigate the ground state of trapped neutral fermions\nwith population imbalance in the BCS-BEC crossover regime. On the basis of the\nsingle-channel Hamiltonian, we perform full numerical calculations of the\nBogoliubov-de Gennes equation coupled with the regularized gap and number\nequations. The zero-temperature phase diagram in the crossover regime is\npresented, where the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) pairing state\ngoverns the weak-coupling BCS region of a resonance. It is found that the FFLO\noscillation vanishes in the BEC side, in which the system under population\nimbalance turns into a phase separation (PS) between locally binding superfluid\nand fully polarized spin domains. We also demonstrate numerical calculations\nwith a large particle number O(10^5), comparable to that observed in recent\nexperiments. The resulting density profile on a resonance yields the PS, which\nis in good agreement with the recent experiments, while the FFLO modulation\nexists in the pairing field. It is also proposed that the most favorable\nlocation for the detection of the FFLO oscillation is in the vicinity of the\ncritical population imbalance in the weak coupling BCS regime, where the\noscillation periodicity becomes much larger than the interparticle spacing.\nFinally, we analyze the radio-frequency (RF) spectroscopy in the imbalanced\nsystem. The clear difference in the RF spectroscopy between BCS and BEC sides\nreveals the structure of the pairing field and local ``magnetization''.\n\n", "human_text": "  We theoretically investigate the ground state of trapped neutral fermions\nwith population imbalance in the BCS-BEC crossover regime. On the basis of the\nsingle-channel Hamiltonian, we perform full numerical calculations of the\nBogoliubov-de Gennes equation coupled with the regularized gap and number\nequations. The zero-temperature phase diagram in the crossover regime is\npresented, where the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) pairing state\ngoverns the weak-coupling BCS region of a resonance. It is found that the FFLO\noscillation vanishes in the BEC side, in which the system under population\nimbalance turns into a phase separation (PS) between locally binding superfluid\nand fully polarized spin domains. We also demonstrate numerical calculations\nwith a large particle number O(10^5), comparable to that observed in recent\nexperiments. The resulting density profile on a resonance yields the PS, which\nis in good agreement with the recent experiments, while the FFLO modulation\nexists in the pairing field. It is also proposed that the most favorable\nlocation for the detection of the FFLO oscillation is in the vicinity of the\ncritical population imbalance in the weak coupling BCS regime, where the\noscillation periodicity becomes much larger than the interparticle spacing.\nFinally, we analyze the radio-frequency (RF) spectroscopy in the imbalanced\nsystem. The clear difference in the RF spectroscopy between BCS and BEC sides\nreveals the structure of the pairing field and local ``magnetization''.\n", "machine_text": "\nIn this article, we explore the impact of population imbalance on the superfluid phase of a trapped fermion gas in the BCS-BEC crossover regime. We use full numerical calculations of the Bogoliubov-de Gennes equation combined with the regularized gap and number equations. We present a zero-temperature phase diagram including the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) pairing state that dominates the weak-coupling BCS region of a resonance, but vanishes in the BEC side as the system further becomes phase separated between locally binding superfluid areas and fully polarised spin domains. We also bring forth numerical calculations with a particle number similar to the one observed in recent experiments. This yields the phase separation in the density profile on the resonance, matching recent experiments. Furthermore, we hint at the existance of FFLO modulation that is at its strongest near the population imbalance critical in the weak coupling BCS regime, resulting in higher amplitude and a periodicity larger than the interparticle spacing. We also examine the difference in RF spectroscopy (radio-frequency) between BCS and BEC sides, thus revealing the structure of the pairing field and local magnetization.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3361}
{"prompt": "Rephrase the abstract of an article with title 'Many-to-One Throughput Capacity of IEEE 802.11 Multi-hop Wireless\n  Networks'.\n  This paper investigates the many-to-one throughput capacity (and by symmetry,\none-to-many throughput capacity) of IEEE 802.11 multi-hop networks. It has\ngenerally been assumed in prior studies that the many-to-one throughput\ncapacity is upper-bounded by the link capacity L. Throughput capacity L is not\nachievable under 802.11. This paper introduces the notion of \"canonical\nnetworks\", which is a class of regularly-structured networks whose capacities\ncan be analyzed more easily than unstructured networks. We show that the\nthroughput capacity of canonical networks under 802.11 has an analytical upper\nbound of 3L/4 when the source nodes are two or more hops away from the sink;\nand simulated throughputs of 0.690L (0.740L) when the source nodes are many\nhops away. We conjecture that 3L/4 is also the upper bound for general\nnetworks. When all links have equal length, 2L/3 can be shown to be the upper\nbound for general networks. Our simulations show that 802.11 networks with\nrandom topologies operated with AODV routing can only achieve throughputs far\nbelow the upper bounds. Fortunately, by properly selecting routes near the\ngateway (or by properly positioning the relay nodes leading to the gateway) to\nfashion after the structure of canonical networks, the throughput can be\nimproved significantly by more than 150%. Indeed, in a dense network, it is\nworthwhile to deactivate some of the relay nodes near the sink judiciously.\n\n", "human_text": "  This paper investigates the many-to-one throughput capacity (and by symmetry,\none-to-many throughput capacity) of IEEE 802.11 multi-hop networks. It has\ngenerally been assumed in prior studies that the many-to-one throughput\ncapacity is upper-bounded by the link capacity L. Throughput capacity L is not\nachievable under 802.11. This paper introduces the notion of \"canonical\nnetworks\", which is a class of regularly-structured networks whose capacities\ncan be analyzed more easily than unstructured networks. We show that the\nthroughput capacity of canonical networks under 802.11 has an analytical upper\nbound of 3L/4 when the source nodes are two or more hops away from the sink;\nand simulated throughputs of 0.690L (0.740L) when the source nodes are many\nhops away. We conjecture that 3L/4 is also the upper bound for general\nnetworks. When all links have equal length, 2L/3 can be shown to be the upper\nbound for general networks. Our simulations show that 802.11 networks with\nrandom topologies operated with AODV routing can only achieve throughputs far\nbelow the upper bounds. Fortunately, by properly selecting routes near the\ngateway (or by properly positioning the relay nodes leading to the gateway) to\nfashion after the structure of canonical networks, the throughput can be\nimproved significantly by more than 150%. Indeed, in a dense network, it is\nworthwhile to deactivate some of the relay nodes near the sink judiciously.\n", "machine_text": "This paper looks into the capacity of IEEE 802.11 multi-hop wireless networks with respect to the many-to-one throughput. Historically, it has been surmised that the throughput capacity would not exceed the individual link capacity. By introducing the concept of \"canonical networks\" which are more systematically organized than non-structured models, the paper shows that, in such networks, the upper limit of the throughput capacity when the sources are two or more hops away can be as high as 3L/4. Experiments also indicated a peak throughput of 0.690L (0.740L) when the sources are distant hops away from the sink. Further research suggests that the upper bound for arbitrary structures may still be capped at 3L/4. Moreover, when all the links are of identical length, the highest achievable throughput is 2L/3. In random topologies with AODV routing, the throughputs fall significantly below the upper bounds. To address this issue, proper selection of routes and reorganization of relay nodes near the gateway can be beneficial, resulting in an increase in throughput by more than 150%.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0528}
{"prompt": "Rephrase the abstract of an article with title 'On the dimension of subspaces with bounded Schmidt rank'.\n  We consider the question of how large a subspace of a given bipartite quantum\nsystem can be when the subspace contains only highly entangled states. This is\nmotivated in part by results of Hayden et al., which show that in large d x\nd--dimensional systems there exist random subspaces of dimension almost d^2,\nall of whose states have entropy of entanglement at least log d - O(1). It is\nalso related to results due to Parthasarathy on the dimension of completely\nentangled subspaces, which have connections with the construction of\nunextendible product bases. Here we take as entanglement measure the Schmidt\nrank, and determine, for every pair of local dimensions dA and dB, and every r,\nthe largest dimension of a subspace consisting only of entangled states of\nSchmidt rank r or larger. This exact answer is a significant improvement on the\nbest bounds that can be obtained using random subspace techniques. We also\ndetermine the converse: the largest dimension of a subspace with an upper bound\non the Schmidt rank. Finally, we discuss the question of subspaces containing\nonly states with Schmidt equal to r.\n\n", "human_text": "  We consider the question of how large a subspace of a given bipartite quantum\nsystem can be when the subspace contains only highly entangled states. This is\nmotivated in part by results of Hayden et al., which show that in large d x\nd--dimensional systems there exist random subspaces of dimension almost d^2,\nall of whose states have entropy of entanglement at least log d - O(1). It is\nalso related to results due to Parthasarathy on the dimension of completely\nentangled subspaces, which have connections with the construction of\nunextendible product bases. Here we take as entanglement measure the Schmidt\nrank, and determine, for every pair of local dimensions dA and dB, and every r,\nthe largest dimension of a subspace consisting only of entangled states of\nSchmidt rank r or larger. This exact answer is a significant improvement on the\nbest bounds that can be obtained using random subspace techniques. We also\ndetermine the converse: the largest dimension of a subspace with an upper bound\non the Schmidt rank. Finally, we discuss the question of subspaces containing\nonly states with Schmidt equal to r.\n", "machine_text": "This article presents an investigation of the dimensions of subspaces that possess states with bounded Schmidt rank. We study the largest dimension of a subspace made up of states with Schmidt rank at least equal to r, and with local dimensions dA and dB, and the maximum value of the dimension of a subspace with all states having a Schmidt rank that no greater than r. This is a progress in understanding the Hayden et al. results, which show that high dimensional subspaces of certain bi-partite systems are highly entangled, and also reflects the Parthasarathy results that concern completely entangled subspaces and their relationships to the development of unextendible product bases. We extend the improved random subspace techniques to reach this better understanding.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0705}
{"prompt": "Rephrase the abstract of an article with title 'Interval Conjectures for level Hilbert functions'.\n  We conjecture that the set of all Hilbert functions of (artinian) level\nalgebras enjoys a very natural form of regularity, which we call the {\\em\nInterval Conjecture} (IC): If, for some positive integer $\\alpha $,\n$(1,h_1,...,h_i,...,h_e)$ and $(1,h_1,...,h_i+\\alpha ,...,h_e)$ are both level\n$h$-vectors, then $(1,h_1,...,h_i+\\beta ,...,h_e)$ is also level for each\ninteger $\\beta =0,1,..., \\alpha .$ In the Gorenstein case, i.e. when $h_e=1$,\nwe also supply the {\\em Gorenstein Interval Conjecture} (GIC), which naturally\ngeneralizes the IC, and basically states that the same property simultaneously\nholds for any two symmetric entries, say $h_i$ and $h_{e-i}$, of a Gorenstein\n$h$-vector.\n  These conjectures are inspired by the research performed in this area over\nthe last few years. A series of recent results seems to indicate that it will\nbe nearly impossible to characterize explicitly the sets of all Gorenstein or\nof all level Hilbert functions. Therefore, our conjectures would at least\nprovide the existence of a very strong - and natural - form of order in the\nstructure of such important and complicated sets.\n  We are still far from proving the conjectures at this point. However, we will\nalready solve a few interesting cases, especially when it comes to the IC, in\nthis paper. Among them, that of Gorenstein $h$-vectors of socle degree 4, that\nof level $h$-vectors of socle degree 2, and that of non-unimodal level\n$h$-vectors of socle degree 3 and any given codimension.\n\n", "human_text": "  We conjecture that the set of all Hilbert functions of (artinian) level\nalgebras enjoys a very natural form of regularity, which we call the {\\em\nInterval Conjecture} (IC): If, for some positive integer $\\alpha $,\n$(1,h_1,...,h_i,...,h_e)$ and $(1,h_1,...,h_i+\\alpha ,...,h_e)$ are both level\n$h$-vectors, then $(1,h_1,...,h_i+\\beta ,...,h_e)$ is also level for each\ninteger $\\beta =0,1,..., \\alpha .$ In the Gorenstein case, i.e. when $h_e=1$,\nwe also supply the {\\em Gorenstein Interval Conjecture} (GIC), which naturally\ngeneralizes the IC, and basically states that the same property simultaneously\nholds for any two symmetric entries, say $h_i$ and $h_{e-i}$, of a Gorenstein\n$h$-vector.\n  These conjectures are inspired by the research performed in this area over\nthe last few years. A series of recent results seems to indicate that it will\nbe nearly impossible to characterize explicitly the sets of all Gorenstein or\nof all level Hilbert functions. Therefore, our conjectures would at least\nprovide the existence of a very strong - and natural - form of order in the\nstructure of such important and complicated sets.\n  We are still far from proving the conjectures at this point. However, we will\nalready solve a few interesting cases, especially when it comes to the IC, in\nthis paper. Among them, that of Gorenstein $h$-vectors of socle degree 4, that\nof level $h$-vectors of socle degree 2, and that of non-unimodal level\n$h$-vectors of socle degree 3 and any given codimension.\n", "machine_text": "\nThis paper presents the Interval Conjecture (IC) and the Gorenstein Interval Conjecture (GIC) regarding level Hilbert functions. The IC states that, for any given positive integer $\\alpha$, if the $h$-vectors $(1,h_1,...,h_i,...,h_e)$ and $(1,h_1,...,h_i+\\alpha ,...,h_e)$ are both level, then $(1,h_1,...,h_i+\\beta ,...,h_e)$ is also level for all $\\beta =0,1,..., \\alpha$. The GIC is a generalization of IC for symmetric entries of a Gorenstein $h$-vector. Despite a lack of proof, several interesting cases of the conjecture, such as those related to Gorenstein $h$-vectors of degree 4, level $h$-vectors of degree 2, and non-unimodal level $h$-vectors of degree 3, are solved here. This paper further suggests that it would be difficult to explicitly characterize the sets of all Gorenstein or level Hilbert functions, but these conjectures provide the opportunity to discover a strong order in such an intricate and complicated structure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0806}
{"prompt": "Rephrase the abstract of an article with title 'The Kinematics of the Ultra-Faint Milky Way Satellites: Solving the\n  Missing Satellite Problem'.\n  We present Keck/DEIMOS spectroscopy of stars in 8 of the newly discovered\nultra-faint dwarf galaxies around the Milky Way. We measure the velocity\ndispersions of Canes Venatici I and II, Ursa Major I and II, Coma Berenices,\nHercules, Leo IV and Leo T from the velocities of 18 - 214 stars in each galaxy\nand find dispersions ranging from 3.3 to 7.6 km/s. The 6 galaxies with absolute\nmagnitudes M_V < -4 are highly dark matter-dominated, with mass-to-light ratios\napproaching 1000. The measured velocity dispersions are inversely correlated\nwith their luminosities, indicating that a minimum mass for luminous galactic\nsystems may not yet have been reached. We also measure the metallicities of the\nobserved stars and find that the 6 brightest of the ultra-faint dwarfs extend\nthe luminosity-metallicity relationship followed by brighter dwarfs by 2 orders\nof magnitude in luminosity; several of these objects have mean metallicities as\nlow as [Fe/H] = -2.3 and therefore represent some of the most metal-poor known\nstellar systems. We detect metallicity spreads of up to 0.5 dex in several\nobjects, suggesting multiple star formation epochs. Having established the\nmasses of the ultra-faint dwarfs, we re-examine the missing satellite problem.\nAfter correcting for the sky coverage of the SDSS, we find that the ultra-faint\ndwarfs substantially alleviate the discrepancy between the predicted and\nobserved numbers of satellites around the Milky Way, but there are still a\nfactor of ~4 too few dwarf galaxies over a significant range of masses. We show\nthat if galaxy formation in low-mass dark matter halos is strongly suppressed\nafter reionization, the simulated circular velocity function of CDM subhalos\ncan be brought into approximate agreement with the observed circular velocity\nfunction of Milky Way satellite galaxies. [slightly abridged]\n\n", "human_text": "  We present Keck/DEIMOS spectroscopy of stars in 8 of the newly discovered\nultra-faint dwarf galaxies around the Milky Way. We measure the velocity\ndispersions of Canes Venatici I and II, Ursa Major I and II, Coma Berenices,\nHercules, Leo IV and Leo T from the velocities of 18 - 214 stars in each galaxy\nand find dispersions ranging from 3.3 to 7.6 km/s. The 6 galaxies with absolute\nmagnitudes M_V < -4 are highly dark matter-dominated, with mass-to-light ratios\napproaching 1000. The measured velocity dispersions are inversely correlated\nwith their luminosities, indicating that a minimum mass for luminous galactic\nsystems may not yet have been reached. We also measure the metallicities of the\nobserved stars and find that the 6 brightest of the ultra-faint dwarfs extend\nthe luminosity-metallicity relationship followed by brighter dwarfs by 2 orders\nof magnitude in luminosity; several of these objects have mean metallicities as\nlow as [Fe/H] = -2.3 and therefore represent some of the most metal-poor known\nstellar systems. We detect metallicity spreads of up to 0.5 dex in several\nobjects, suggesting multiple star formation epochs. Having established the\nmasses of the ultra-faint dwarfs, we re-examine the missing satellite problem.\nAfter correcting for the sky coverage of the SDSS, we find that the ultra-faint\ndwarfs substantially alleviate the discrepancy between the predicted and\nobserved numbers of satellites around the Milky Way, but there are still a\nfactor of ~4 too few dwarf galaxies over a significant range of masses. We show\nthat if galaxy formation in low-mass dark matter halos is strongly suppressed\nafter reionization, the simulated circular velocity function of CDM subhalos\ncan be brought into approximate agreement with the observed circular velocity\nfunction of Milky Way satellite galaxies. [slightly abridged]\n", "machine_text": "\nThis paper investigates the kinematics of 8 newly discovered ultra-faint dwarf galaxies near the Milky Way, using Keck/DEIMOS spectroscopy to measure velocity dispersions ranging from 3.3 to 7.6 km/s. These galaxies have a mass-to-light ratio which is highly dark matter-dominated and an inverse relationship between their luminosity and the velocity dispersions. Additionally, we measure the metallicity of the observed stars and confirm the luminosity-metallicity relationship found in the brighter dwarf galaxies by two orders of magnitude, with some having mean metallicities as low as [Fe/H] = -2.3. Using this information, we discuss how the ultra-faint dwarfs may contribute to decline in missing satellite problem, which describes the discrepancy between the expected number of satellites and the observed amount. After accounting for the sky coverage of the SDSS survey, this study suggests that if galaxy formation in low-mass dark matter halos is strongly suppressed after reionization, the simulated circular velocity function of CDM subhalos can be brought into approximate agreement with the observed velocities of Milky Way satellite galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0516}
{"prompt": "Rephrase the abstract of an article with title 'The Chemical Compositions of the Type II Cepheids -- The BL Her and W\n  Vir Variables'.\n  Abundance analyses from high-resolution optical spectra are presented for 19\nType II Cepheids in the Galactic field. The sample includes both short-period\n(BL Her) and long-period (W Vir) stars. This is the first extensive abundance\nanalysis of these variables. The C, N, and O abundances with similar spreads\nfor the BL Her and W Vir show evidence for an atmosphere contaminated with\n$3\\alpha$-process and CN-cycling products. A notable anomaly of the BL Her\nstars is an overabundance of Na by a factor of about five relative to their\npresumed initial abundances. This overabundance is not seen in the W Vir stars.\nThe abundance anomalies running from mild to extreme in W Vir stars but not\nseen in the BL Her stars are attributed to dust-gas separation that provides an\natmosphere deficient in elements of high condensation temperature, notably Al,\nCa, Sc, Ti, and $s$-process elements. Such anomalies have previously been seen\namong RV Tau stars which represent a long-period extension of the variability\nenjoyed by the Type II Cepheids. Comments are offered on how the contrasting\nabundance anomalies of BL Her and W Vir stars may be explained in terms of the\nstars' evolution from the blue horizontal branch.\n\n", "human_text": "  Abundance analyses from high-resolution optical spectra are presented for 19\nType II Cepheids in the Galactic field. The sample includes both short-period\n(BL Her) and long-period (W Vir) stars. This is the first extensive abundance\nanalysis of these variables. The C, N, and O abundances with similar spreads\nfor the BL Her and W Vir show evidence for an atmosphere contaminated with\n$3\\alpha$-process and CN-cycling products. A notable anomaly of the BL Her\nstars is an overabundance of Na by a factor of about five relative to their\npresumed initial abundances. This overabundance is not seen in the W Vir stars.\nThe abundance anomalies running from mild to extreme in W Vir stars but not\nseen in the BL Her stars are attributed to dust-gas separation that provides an\natmosphere deficient in elements of high condensation temperature, notably Al,\nCa, Sc, Ti, and $s$-process elements. Such anomalies have previously been seen\namong RV Tau stars which represent a long-period extension of the variability\nenjoyed by the Type II Cepheids. Comments are offered on how the contrasting\nabundance anomalies of BL Her and W Vir stars may be explained in terms of the\nstars' evolution from the blue horizontal branch.\n", "machine_text": "This study investigated the chemical compositions of 19 Type II Cepheids in the Galactic field, which consisted of both short and long-period variables. This is the first extensive chemical abundance analysis of these stars, discovering the presence of contamination of their atmospheres with products of $\\mathrm{3\\alpha}$-process and CN-cycling. The BL Her stars were identified to have Na overabundances that were not seen in the W Vir stars. The W Vir stars, however, exhibited a range of abundance anomalies not seen in the BL Her stars, which were attributed to dust-gas separation leading to atmospheres containing lower than expected amounts of elements of high condensation temperature. Possible explanations of the contrasting abundance anomalies of the two types of Type II Cepheids were presented in the context of their evolution from the blue horizontal branch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2029}
{"prompt": "Rephrase the abstract of an article with title 'Aspects of stochastic resonance in reaction-diffusion systems: The\n  nonequilibrium-potential approach'.\n  We analyze several aspects of the phenomenon of stochastic resonance in\nreaction-diffusion systems, exploiting the nonequilibrium potential's\nframework. The generalization of this formalism (sketched in the appendix) to\nextended systems is first carried out in the context of a simplified scalar\nmodel, for which stationary patterns can be found analytically. We first show\nhow system-size stochastic resonance arises naturally in this framework, and\nthen how the phenomenon of array-enhanced stochastic resonance can be further\nenhanced by letting the diffusion coefficient depend on the field. A yet less\ntrivial generalization is exemplified by a stylized version of the\nFitzHugh-Nagumo system, a paradigm of the activator-inhibitor class. After\ndiscussing for this system the second aspect enumerated above, we derive from\nit -through an adiabatic-like elimination of the inhibitor field- an effective\nscalar model that includes a nonlocal contribution. Studying the role played by\nthe range of the nonlocal kernel and its effect on stochastic resonance, we\nfind an optimal range that maximizes the system's response.\n\n", "human_text": "  We analyze several aspects of the phenomenon of stochastic resonance in\nreaction-diffusion systems, exploiting the nonequilibrium potential's\nframework. The generalization of this formalism (sketched in the appendix) to\nextended systems is first carried out in the context of a simplified scalar\nmodel, for which stationary patterns can be found analytically. We first show\nhow system-size stochastic resonance arises naturally in this framework, and\nthen how the phenomenon of array-enhanced stochastic resonance can be further\nenhanced by letting the diffusion coefficient depend on the field. A yet less\ntrivial generalization is exemplified by a stylized version of the\nFitzHugh-Nagumo system, a paradigm of the activator-inhibitor class. After\ndiscussing for this system the second aspect enumerated above, we derive from\nit -through an adiabatic-like elimination of the inhibitor field- an effective\nscalar model that includes a nonlocal contribution. Studying the role played by\nthe range of the nonlocal kernel and its effect on stochastic resonance, we\nfind an optimal range that maximizes the system's response.\n", "machine_text": "\nExploring the various elements of stochastic resonance in reaction-diffusion systems, we apply the nonequilibrium potential approach. We start by examining a simple scalar model which enables us to analytically obtain stationary patterns. Our findings indicate that system-sized resonance can be derived from this method and that array-enhanced resonance is heightened when the diffusion coefficient is dependent on the field. Further studying a stylized version of the FitzHugh-Nagumo system, we acquire a meaningful scalar model including a nonlocal contribution. We analyze the influence of the range of the nonlocal kernel on stochastic resonance which displays an optimum range for maximizing the system's response.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1148}
{"prompt": "Rephrase the abstract of an article with title 'Phase transition in the two-component symmetric exclusion process with\n  open boundaries'.\n  We consider single-file diffusion in an open system with two species $A,B$ of\nparticles. At the boundaries we assume different reservoir densities which\ndrive the system into a non-equilibrium steady state. As a model we use an\none-dimensional two-component simple symmetric exclusion process with two\ndifferent hopping rates $D_A,D_B$ and open boundaries. For investigating the\ndynamics in the hydrodynamic limit we derive a system of coupled non-linear\ndiffusion equations for the coarse-grained particle densities. The relaxation\nof the initial density profile is analyzed by numerical integration. Exact\nanalytical expressions are obtained for the self-diffusion coefficients, which\nturns out to be length-dependent, and for the stationary solution. In the\nsteady state we find a discontinuous boundary-induced phase transition as the\ntotal exterior density gradient between the system boundaries is varied. At one\nboundary a boundary layer develops inside which the current flows against the\nlocal density gradient. Generically the width of the boundary layer and the\nbulk density profiles do not depend on the two hopping rates. At the phase\ntransition line, however, the individual density profiles depend strongly on\nthe ratio $D_A/D_B$. Dynamic Monte Carlo simulation confirm our theoretical\npredictions.\n\n", "human_text": "  We consider single-file diffusion in an open system with two species $A,B$ of\nparticles. At the boundaries we assume different reservoir densities which\ndrive the system into a non-equilibrium steady state. As a model we use an\none-dimensional two-component simple symmetric exclusion process with two\ndifferent hopping rates $D_A,D_B$ and open boundaries. For investigating the\ndynamics in the hydrodynamic limit we derive a system of coupled non-linear\ndiffusion equations for the coarse-grained particle densities. The relaxation\nof the initial density profile is analyzed by numerical integration. Exact\nanalytical expressions are obtained for the self-diffusion coefficients, which\nturns out to be length-dependent, and for the stationary solution. In the\nsteady state we find a discontinuous boundary-induced phase transition as the\ntotal exterior density gradient between the system boundaries is varied. At one\nboundary a boundary layer develops inside which the current flows against the\nlocal density gradient. Generically the width of the boundary layer and the\nbulk density profiles do not depend on the two hopping rates. At the phase\ntransition line, however, the individual density profiles depend strongly on\nthe ratio $D_A/D_B$. Dynamic Monte Carlo simulation confirm our theoretical\npredictions.\n", "machine_text": "\nIn this paper, we examine a two-component simple symmetric exclusion process with open boundaries whose dynamics are considered in the hydrodynamic limit. We derive a system of non-linear diffusion equations for the coarse-grained particle densities, then apply numerical integration to analyze the relaxation of the initial density profile. Further, exact analytical expressions are derived for the self-diffusion coefficients and the stationary solution, from which a boundary-induced phase transition is discovered at a point when the total exterior density gradient between the boundaries is varied. Monte Carlo simulations verify the theoretical results, demonstrating a dependence on the ratio of the two hopping rates, $D_A/D_B$ at the phase transition line.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0596}
{"prompt": "Rephrase the abstract of an article with title 'New Superstring Isometries and Hidden Dimensions'.\n  We explore the hierarchy of hidden space-time symmetries of noncritical\nstrings in RNS formalism, realized nonlinearly. Under these symmetry\ntransformations the variation of the matter part of the RNS action is cancelled\nby that of the ghost part. These symmetries, referred to as the\n$\\alpha$-symmetries, are induced by special space-time generators, violating\nthe equivalence of ghost pictures. We classify the $\\alpha$-symmetry generators\nin terms of superconformal ghost cohomologies $H_{n}\\sim{H_{-n-2}}(n\\geq{0})$\nand associate these generators with a chain of hidden space-time dimensions,\nwith each ghost cohomology $H_{n}\\sim{H_{-n-2}}$ ``contributing'' an extra\ndimension. Namely, we show that each ghost cohomology $H_{n}\\sim{H_{-n-2}}$ of\nnon-critical superstring theory in $d$-dimensions contains $d+n+1$\n$\\alpha$-symmetry generators and the generators from\n$H_{k}\\sim{H_{-k-2}},1\\leq{k}\\leq{n}$, combined together, extend the space-time\nisometry group from the naive $SO(d,2)$ to $SO(d+n,2)$. In the simplest case of\n$n=1$ the $\\alpha$-generators are identified with the extra symmetries of the\n$2T$-physics formalism, also known to originate from a hidden space-time\ndimension.\n\n", "human_text": "  We explore the hierarchy of hidden space-time symmetries of noncritical\nstrings in RNS formalism, realized nonlinearly. Under these symmetry\ntransformations the variation of the matter part of the RNS action is cancelled\nby that of the ghost part. These symmetries, referred to as the\n$\\alpha$-symmetries, are induced by special space-time generators, violating\nthe equivalence of ghost pictures. We classify the $\\alpha$-symmetry generators\nin terms of superconformal ghost cohomologies $H_{n}\\sim{H_{-n-2}}(n\\geq{0})$\nand associate these generators with a chain of hidden space-time dimensions,\nwith each ghost cohomology $H_{n}\\sim{H_{-n-2}}$ ``contributing'' an extra\ndimension. Namely, we show that each ghost cohomology $H_{n}\\sim{H_{-n-2}}$ of\nnon-critical superstring theory in $d$-dimensions contains $d+n+1$\n$\\alpha$-symmetry generators and the generators from\n$H_{k}\\sim{H_{-k-2}},1\\leq{k}\\leq{n}$, combined together, extend the space-time\nisometry group from the naive $SO(d,2)$ to $SO(d+n,2)$. In the simplest case of\n$n=1$ the $\\alpha$-generators are identified with the extra symmetries of the\n$2T$-physics formalism, also known to originate from a hidden space-time\ndimension.\n", "machine_text": "In this article, we investigate the hierarchy of superstring isometries and hidden dimensions. Such transformations, which we refer to as $\\alpha$-symmetries, are induced by the presence of special space-time generators, allowing for the cancellation of variations in the matter and ghost parts of RNS formalism. We classify the $\\alpha$-symmetry generators according to the ghost cohomology, and associate each one with an associated hidden space-time dimension. Specifically, when considering a non-critical superstring with $d$-dimensions, we show that each ghost cohomology $H_{n}\\sim{H_{-n-2}}$ contains $d+n+1$ corresponding $\\alpha$-symmetry generators. Furthermore, by combining the generators from $H_{k}\\sim{H_{-k-2}},1\\leq{k}\\leq{n}$, the isometry group of the space-time is extended from the original $SO(d,2)$ to $SO(d+n,2)$. We also examine the case of $n=1$, a situation in which the $\\alpha$-symmetries were previously understood to come from a hidden dimension.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0275}
{"prompt": "Rephrase the abstract of an article with title 'Privacy - an Issue for eLearning? A Trend Analysis Reflecting the\n  Attitude of European eLearning Users'.\n  Availing services provided via the Internet became a widely accepted means in\norganising one's life. Beside others, eLearning goes with this trend as well.\nBut, while employing Internet service makes life more convenient, at the same\ntime, it raises risks with respect to the protection of the users' privacy.\nThis paper analyses the attitudes of eLearning users towards their privacy by,\ninitially, pointing out terminology and legal issues connected with privacy.\nFurther, the concept and implementation as well as a result analysis of a\nconducted study is presented, which explores the problem area from different\nperspectives. The paper will show that eLearning users indeed care for the\nprotection of their personal information when using eLearning services.\nHowever, their attitudes and behaviour slightly differ. In conclusion, we\nprovide first approaches of assisting possibilities for users how to resolve\nthe difference of requirements and their actual activities with respect to\nprivacy protection.\n\n", "human_text": "  Availing services provided via the Internet became a widely accepted means in\norganising one's life. Beside others, eLearning goes with this trend as well.\nBut, while employing Internet service makes life more convenient, at the same\ntime, it raises risks with respect to the protection of the users' privacy.\nThis paper analyses the attitudes of eLearning users towards their privacy by,\ninitially, pointing out terminology and legal issues connected with privacy.\nFurther, the concept and implementation as well as a result analysis of a\nconducted study is presented, which explores the problem area from different\nperspectives. The paper will show that eLearning users indeed care for the\nprotection of their personal information when using eLearning services.\nHowever, their attitudes and behaviour slightly differ. In conclusion, we\nprovide first approaches of assisting possibilities for users how to resolve\nthe difference of requirements and their actual activities with respect to\nprivacy protection.\n", "machine_text": "This paper explores how European eLearning users perceive their privacy when accessing eLearning services. First, various terms and legal aspects relevant to this issue are presented. Then, a survey is conducted to gain further insight on the matter. The result of the survey will be evaluated in order to determine the attitude of eLearning users towards their privacy when utilizing these services. It will be revealed that, although there is considerable concern for protection of personal information, users are more likely to accommodate existing requirements than to take additional steps for their privacy protection. Lastly, the paper proposes approaches to help users reconcile their concerns with their actual actions in regards to privacy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0612}
{"prompt": "Rephrase the abstract of an article with title 'Vortical and Wave Modes in 3D Rotating Stratified Flows: Random Large\n  Scale Forcing'.\n  Utilizing an eigenfunction decomposition, we study the growth and spectra of\nenergy in the vortical and wave modes of a 3D rotating stratified fluid as a\nfunction of $\\epsilon = f/N$. Working in regimes characterized by moderate\nBurger numbers, i.e. $Bu = 1/\\epsilon^2 < 1$ or $Bu \\ge 1$, our results\nindicate profound change in the character of vortical and wave mode\ninteractions with respect to $Bu = 1$. As with the reference state of\n$\\epsilon=1$, for $\\epsilon < 1$ the wave mode energy saturates quite quickly\nand the ensuing forward cascade continues to act as an efficient means of\ndissipating ageostrophic energy. Further, these saturated spectra steepen as\n$\\epsilon$ decreases: we see a shift from $k^{-1}$ to $k^{-5/3}$ scaling for\n$k_f < k < k_d$ (where $k_f$ and $k_d$ are the forcing and dissipation scales,\nrespectively). On the other hand, when $\\epsilon > 1$ the wave mode energy\nnever saturates and comes to dominate the total energy in the system. In fact,\nin a sense the wave modes behave in an asymmetric manner about $\\epsilon = 1$.\nWith regard to the vortical modes, for $\\epsilon \\le 1$, the signatures of 3D\nquasigeostrophy are clearly evident. Specifically, we see a $k^{-3}$ scaling\nfor $k_f < k < k_d$ and, in accord with an inverse transfer of energy, the\nvortical mode energy never saturates but rather increases for all $k < k_f$. In\ncontrast, for $\\epsilon > 1$ and increasing, the vortical modes contain a\nprogressively smaller fraction of the total energy indicating that the 3D\nquasigeostrophic subsystem plays an energetically smaller role in the overall\ndynamics.\n\n", "human_text": "  Utilizing an eigenfunction decomposition, we study the growth and spectra of\nenergy in the vortical and wave modes of a 3D rotating stratified fluid as a\nfunction of $\\epsilon = f/N$. Working in regimes characterized by moderate\nBurger numbers, i.e. $Bu = 1/\\epsilon^2 < 1$ or $Bu \\ge 1$, our results\nindicate profound change in the character of vortical and wave mode\ninteractions with respect to $Bu = 1$. As with the reference state of\n$\\epsilon=1$, for $\\epsilon < 1$ the wave mode energy saturates quite quickly\nand the ensuing forward cascade continues to act as an efficient means of\ndissipating ageostrophic energy. Further, these saturated spectra steepen as\n$\\epsilon$ decreases: we see a shift from $k^{-1}$ to $k^{-5/3}$ scaling for\n$k_f < k < k_d$ (where $k_f$ and $k_d$ are the forcing and dissipation scales,\nrespectively). On the other hand, when $\\epsilon > 1$ the wave mode energy\nnever saturates and comes to dominate the total energy in the system. In fact,\nin a sense the wave modes behave in an asymmetric manner about $\\epsilon = 1$.\nWith regard to the vortical modes, for $\\epsilon \\le 1$, the signatures of 3D\nquasigeostrophy are clearly evident. Specifically, we see a $k^{-3}$ scaling\nfor $k_f < k < k_d$ and, in accord with an inverse transfer of energy, the\nvortical mode energy never saturates but rather increases for all $k < k_f$. In\ncontrast, for $\\epsilon > 1$ and increasing, the vortical modes contain a\nprogressively smaller fraction of the total energy indicating that the 3D\nquasigeostrophic subsystem plays an energetically smaller role in the overall\ndynamics.\n", "machine_text": "\nWe explore how energy is distributed in the vortical and wave modes of a 3D rotating stratified fluid given different values of Burger numbers characterized by $\\epsilon = f/N = Bu^{-1/2}$. Our investigation reveals a transformation of the interactions between the wave and vortical modes relative to the reference state of $Bu = 1$ depending on whether $\\epsilon < 1$ or $\\epsilon > 1$. When $\\epsilon < 1$, the wave mode energy saturates quickly and follows a steepening of $k^{-1}$ to $k^{-5/3}$ scaling for wave modes between the forcing and dissipation scales, $k_f$ and $k_d$, respectively. On the other hand, if $\\epsilon > 1$, wave mode energy dominates and never saturates. Our results suggest that 3D quasigeostrophy is evident when $\\epsilon \\le 1$; the vortical mode energy follows a $k^{-3}$ scaling and amplifies with wave modes up to the forcing scale. For $\\epsilon > 1$, the vortical mode composes a smaller portion of the total energy and the 3D quasigeostrophic subsystem plays a diminished role in the overall dynamics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2452}
{"prompt": "Rephrase the abstract of an article with title 'A study of the $p d \\to p d \\eta$ reaction'.\n  A study of the $p d \\to p d \\eta$ reaction in the energy range where the\nrecent data from Uppsala are available, is done in the two-step model of $\\eta$\nproduction including the final state interaction. The $\\eta -d$ final state\ninteraction is incorporated through the solution of the Lippmann Schwinger\nequation using an elastic scattering matrix element, $T_{\\eta d \\to \\eta d}$,\nwhich is required to be half off-shell. It is written in a factorized form,\nwith an off-shell form factor multiplying an on-shell part given by an\neffective range expansion up to the fourth power in momentum. The parameters of\nthis expansion have been taken from an existing recent relativistic Faddeev\nequation solution for the $\\eta NN$ system corresponding to different $\\eta-N$\nscattering amplitudes. Calculations have also been done using few body\nequations within a finite rank approximation (FRA) to generate $T_{\\eta d \\to\n\\eta d}$. The $p-d$ final state interaction is included in the spirit of the\nWatson-Migdal prescription by multiplying the matrix element by the inverse of\nthe Jost function. The $\\eta-d$ interaction is found to be dominant in the\nregion of small invariant $\\eta -d$ mass, $M_{\\eta d}$. The $p-d$ interaction\nenhances the cross section in the whole region of $M_{\\eta d}$, but is larger\nfor large $M_{\\eta d}$. We find nearly isotropic angular distributions of the\nproton and the deuteron in the final state. All the above observations are in\nagreement with data. The production mechanism for the entire range of the\nexisting data on the $p d \\to p d \\eta$ reaction seems to be dominated by the\ntwo-step model of $\\eta$ production.\n\n", "human_text": "  A study of the $p d \\to p d \\eta$ reaction in the energy range where the\nrecent data from Uppsala are available, is done in the two-step model of $\\eta$\nproduction including the final state interaction. The $\\eta -d$ final state\ninteraction is incorporated through the solution of the Lippmann Schwinger\nequation using an elastic scattering matrix element, $T_{\\eta d \\to \\eta d}$,\nwhich is required to be half off-shell. It is written in a factorized form,\nwith an off-shell form factor multiplying an on-shell part given by an\neffective range expansion up to the fourth power in momentum. The parameters of\nthis expansion have been taken from an existing recent relativistic Faddeev\nequation solution for the $\\eta NN$ system corresponding to different $\\eta-N$\nscattering amplitudes. Calculations have also been done using few body\nequations within a finite rank approximation (FRA) to generate $T_{\\eta d \\to\n\\eta d}$. The $p-d$ final state interaction is included in the spirit of the\nWatson-Migdal prescription by multiplying the matrix element by the inverse of\nthe Jost function. The $\\eta-d$ interaction is found to be dominant in the\nregion of small invariant $\\eta -d$ mass, $M_{\\eta d}$. The $p-d$ interaction\nenhances the cross section in the whole region of $M_{\\eta d}$, but is larger\nfor large $M_{\\eta d}$. We find nearly isotropic angular distributions of the\nproton and the deuteron in the final state. All the above observations are in\nagreement with data. The production mechanism for the entire range of the\nexisting data on the $p d \\to p d \\eta$ reaction seems to be dominated by the\ntwo-step model of $\\eta$ production.\n", "machine_text": "This article examines the $p d \\to p d \\eta$ reaction in the energy range where new data from Uppsala is available. To incorporate the $\\eta -d$ final state interaction, we solve the Lippmann Schwinger equation using an elastic scattering matrix element of half-offshell form factor given by an effective range expansion up to the fourth power in momentum. The parameters for the expansion were taken from a Faddeev equation solution for the $\\eta NN$ system which was based on different $\\eta-N$ scattering amplitudes. We also  generated $T_{\\eta d \\to \\eta d}$ from few-body equations employing the FRA. The $p-d$ final state interaction is included by multiplying the matrix element with the inverse of the Jost function according to the Watson-Migdal prescription. From the findings we deduce that the $\\eta-d$ interaction is dominant in the region of small invariant $\\eta -d$ mass, $M_{\\eta d}$, while the $p-d$ interaction affects the cross section in all areas of $M_{\\eta d}$. Examination of the angular distributions of protons and deuterons in the final state show that they are nearly isotropic. These results are in agreement with experimental data, indicating that the two-step model is the dominant mechanism of $\\eta$ production.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.153}
{"prompt": "Rephrase the abstract of an article with title 'The Merger in Abell 576: A Line of Sight Bullet Cluster?'.\n  Using a combination of Chandra and XMM observations, we confirmed the\npresence of a significant velocity gradient along the NE/E-W/SW direction in\nthe intracluster gas of the cluster Abell 576. The results are consistent with\na previous ASCA SIS analysis of this cluster. The error weighted average over\nACIS-S3, EPIC MOS 1 & 2 spectrometers for the maximum velocity difference is\n>3.3E03 km/s at the 90% confidence level, similar to the velocity limits\nestimated indirectly for the \"bullet\" cluster (1E0657-56). The probability that\nthe velocity gradient is generated by standard random gain fluctuations with\nChandra and XMM is <0.1%. The regions of maximum velocity gradient are in CCD\nzones that have the lowest temporal gain variations. It is unlikely that the\nvelocity gradient is due to Hubble distance differences between projected\nclusters (probability<~0.01%). We mapped the distribution of elemental\nabundance ratios across the cluster and detected a strong chemical\ndiscontinuity using the abundance ratio of silicon to iron, equivalent to a\nvariation from 100% SN Ia iron mass fraction in the West-Northwest regions to\n32% in the Eastern region. The \"center\" of the cluster is located at the\nchemical discontinuity boundary, which is inconsistent with the radially\nsymmetric chemical gradient found in some regular clusters, but consistent with\na cluster merging scenario. We predict that the velocity gradient as measured\nwill produce a variation of the CMB temperature towards the East of the core of\nthe cluster that will be detectable by current and near-future bolometers. The\nmeasured velocity gradient opens for the possibility that this cluster is\npassing through a near line-of-sight merger stage where the cores have recently\ncrossed.\n\n", "human_text": "  Using a combination of Chandra and XMM observations, we confirmed the\npresence of a significant velocity gradient along the NE/E-W/SW direction in\nthe intracluster gas of the cluster Abell 576. The results are consistent with\na previous ASCA SIS analysis of this cluster. The error weighted average over\nACIS-S3, EPIC MOS 1 & 2 spectrometers for the maximum velocity difference is\n>3.3E03 km/s at the 90% confidence level, similar to the velocity limits\nestimated indirectly for the \"bullet\" cluster (1E0657-56). The probability that\nthe velocity gradient is generated by standard random gain fluctuations with\nChandra and XMM is <0.1%. The regions of maximum velocity gradient are in CCD\nzones that have the lowest temporal gain variations. It is unlikely that the\nvelocity gradient is due to Hubble distance differences between projected\nclusters (probability<~0.01%). We mapped the distribution of elemental\nabundance ratios across the cluster and detected a strong chemical\ndiscontinuity using the abundance ratio of silicon to iron, equivalent to a\nvariation from 100% SN Ia iron mass fraction in the West-Northwest regions to\n32% in the Eastern region. The \"center\" of the cluster is located at the\nchemical discontinuity boundary, which is inconsistent with the radially\nsymmetric chemical gradient found in some regular clusters, but consistent with\na cluster merging scenario. We predict that the velocity gradient as measured\nwill produce a variation of the CMB temperature towards the East of the core of\nthe cluster that will be detectable by current and near-future bolometers. The\nmeasured velocity gradient opens for the possibility that this cluster is\npassing through a near line-of-sight merger stage where the cores have recently\ncrossed.\n", "machine_text": "\nUsing Chandra and XMM observations, we confirmed the presence of a large-scale velocity disparity across Abell 576 in the NE/E-W/SW direction, agreeing with previous ASCA SIS measurements. At 90% confidence level, the maximum velocity difference exceeded 3.3E03 km/s, similar to limits found in the bullet cluster (1E0657-56). It is unlikely the velocity gradient is caused by random fluctuations in both Chandra and XMM data, or Hubble distance discrepancies between the two merging clusters. We mapped the abundance of chemical elements and determined a strong chemical difference between the West-Northwest and East regions, going from 100% SN Ia iron mass fraction to 32%. The cluster center was located at this chemical boundary, potentially owing to a cluster straight merger. This velocity gradient may also result in changes in CMB temperature that could be identified by current and upcoming bolometers. All of this evidence suggests Abell 576 could be entering a line-of-sight merger.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1073}
{"prompt": "Rephrase the abstract of an article with title 'The inefficiency of the first-order Fermi process in UHECR production at\n  relativistic shocks'.\n  The question of the origin of ultra-high-energy cosmic rays at relativistic\nshock waves is discussed in the light of results of recent Monte Carlo studies\nof the first-order Fermi particle acceleration (Niemiec & Ostrowski 2006,\nNiemiec et al. 2006). The models of the turbulent magnetic field near the shock\nconsidered in these simulations include realistic features of the perturbed\nmagnetic field structures at the shock, which allow us to study all the field\nand particle motion characteristics that are important for cosmic-ray\nacceleration. Our results show that turbulent conditions near the shock, that\nare consistent with the shock jump conditions, lead to substantial\nmodifications of the acceleration process with respect to the simplified\nmodels, that produce wide-range power-law energy distributions, often with the\n\"universal\" spectral index. Relativistic shocks are essentially always\nsuperluminal, and thus they preferentially generate steep particle spectra with\ncutoffs well below the maximum scattering energy, often not exceeding the\nenergy of the compressed background plasma ions. Thus, cosmic-ray acceleration\nto very high energies at relativistic shock waves is inefficient, and such\nshocks are not expected to be the sources of ultra-high-energy particles.\n\n", "human_text": "  The question of the origin of ultra-high-energy cosmic rays at relativistic\nshock waves is discussed in the light of results of recent Monte Carlo studies\nof the first-order Fermi particle acceleration (Niemiec & Ostrowski 2006,\nNiemiec et al. 2006). The models of the turbulent magnetic field near the shock\nconsidered in these simulations include realistic features of the perturbed\nmagnetic field structures at the shock, which allow us to study all the field\nand particle motion characteristics that are important for cosmic-ray\nacceleration. Our results show that turbulent conditions near the shock, that\nare consistent with the shock jump conditions, lead to substantial\nmodifications of the acceleration process with respect to the simplified\nmodels, that produce wide-range power-law energy distributions, often with the\n\"universal\" spectral index. Relativistic shocks are essentially always\nsuperluminal, and thus they preferentially generate steep particle spectra with\ncutoffs well below the maximum scattering energy, often not exceeding the\nenergy of the compressed background plasma ions. Thus, cosmic-ray acceleration\nto very high energies at relativistic shock waves is inefficient, and such\nshocks are not expected to be the sources of ultra-high-energy particles.\n", "machine_text": "Recent Monte Carlo simulations of the first-order Fermi particle acceleration process at relativistic shocks have provided new insights into the origin of ultra-high-energy cosmic rays (UHECRs). While a simplified model of particle acceleration appears to generate power-law distributions with \"universal\" spectral indices across a wide range of energies, a more realistic consideration of the turbulent magnetic fields and field structures at the shock suggests that UHECR production at relativistic shock waves is quite inefficient. Consequently, while relativistic shocks are efficient at producing particles of lower energy, they are not expected to be the primary sources of UHECRs due to the steep, cut-off spectra generated by superluminal shocks.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4453}
{"prompt": "Rephrase the abstract of an article with title 'Discovery of extreme asymmetry in the debris disk surrounding HD 15115'.\n  We report the first scattered light detection of a dusty debris disk\nsurrounding the F2V star HD 15115 using the Hubble Space Telescope in the\noptical, and Keck adaptive optics in the near-infrared. The most remarkable\nproperty of the HD 15115 disk relative to other debris disks is its extreme\nlength asymmetry. The east side of the disk is detected to ~315 AU radius,\nwhereas the west side of the disk has radius >550 AU. We find a blue optical to\nnear-infrared scattered light color relative to the star that indicates grain\nscattering properties similar to the AU Mic debris disk. The existence of a\nlarge debris disk surrounding HD 15115 adds further evidence for membership in\nthe Beta Pic moving group, which was previously argued based on kinematics\nalone. Here we hypothesize that the extreme disk asymmetry is due to dynamical\nperturbations from HIP 12545, an M star 0.5 degrees (0.38 pc) east of HD 15115\nthat shares a common proper motion vector, heliocentric distance, galactic\nspace velocity, and age.\n\n", "human_text": "  We report the first scattered light detection of a dusty debris disk\nsurrounding the F2V star HD 15115 using the Hubble Space Telescope in the\noptical, and Keck adaptive optics in the near-infrared. The most remarkable\nproperty of the HD 15115 disk relative to other debris disks is its extreme\nlength asymmetry. The east side of the disk is detected to ~315 AU radius,\nwhereas the west side of the disk has radius >550 AU. We find a blue optical to\nnear-infrared scattered light color relative to the star that indicates grain\nscattering properties similar to the AU Mic debris disk. The existence of a\nlarge debris disk surrounding HD 15115 adds further evidence for membership in\nthe Beta Pic moving group, which was previously argued based on kinematics\nalone. Here we hypothesize that the extreme disk asymmetry is due to dynamical\nperturbations from HIP 12545, an M star 0.5 degrees (0.38 pc) east of HD 15115\nthat shares a common proper motion vector, heliocentric distance, galactic\nspace velocity, and age.\n", "machine_text": "We have detected a dusty debris disk surrounding the F2V star HD 15115 using the Hubble Space Telescope in the optical and Keck adaptive optics in the near-infrared. This disk is especially notable for its intense length asymmetry, with the east side detected at approximately 315 AU of radius and the west side detected at a radius of over 550 AU. We found that the optical to near-infrared color of the scattered light is similar to AU Mic's debris disk. Linkages to the Beta Pic moving group were previously believed through kinematic arguments, now bolstered by the existence of the large debris disk. We conjecture that the extreme asymmetry could be due to dynamical perturbations from the nearby M star, HIP 12545, which shares a common proper motion vector, heliocentric distance, galactic space velocity, and age.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0645}
{"prompt": "Rephrase the abstract of an article with title 'Inter-network regions of the Sun at millimetre wavelengths'.\n  The continuum intensity at wavelengths around 1 mm provides an excellent way\nto probe the solar chromosphere. Future high-resolution millimetre arrays, such\nas the Atacama Large Millimeter Array (ALMA), will thus produce valuable input\nfor the ongoing controversy on the thermal structure and the dynamics of this\nlayer. Synthetic brightness temperature maps are calculated on basis of\nthree-dimensional radiation (magneto-)hydrodynamic (MHD) simulations. While the\nmillimetre continuum at 0.3mm originates mainly from the upper photosphere, the\nlonger wavelengths considered here map the low and middle chromosphere. The\neffective formation height increases generally with wavelength and also from\ndisk-centre towards the solar limb. The average intensity contribution\nfunctions are usually rather broad and in some cases they are even\ndouble-peaked as there are contributions from hot shock waves and cool\npost-shock regions in the model chromosphere. Taking into account the\ndeviations from ionisation equilibrium for hydrogen gives a less strong\nvariation of the electron density and with it of the optical depth. The result\nis a narrower formation height range. The average brightness temperature\nincreases with wavelength and towards the limb. The relative contrast depends\non wavelength in the same way as the average intensity but decreases towards\nthe limb. The dependence of the brightness temperature distribution on\nwavelength and disk-position can be explained with the differences in formation\nheight and the variation of temperature fluctuations with height in the model\natmospheres.\n\n", "human_text": "  The continuum intensity at wavelengths around 1 mm provides an excellent way\nto probe the solar chromosphere. Future high-resolution millimetre arrays, such\nas the Atacama Large Millimeter Array (ALMA), will thus produce valuable input\nfor the ongoing controversy on the thermal structure and the dynamics of this\nlayer. Synthetic brightness temperature maps are calculated on basis of\nthree-dimensional radiation (magneto-)hydrodynamic (MHD) simulations. While the\nmillimetre continuum at 0.3mm originates mainly from the upper photosphere, the\nlonger wavelengths considered here map the low and middle chromosphere. The\neffective formation height increases generally with wavelength and also from\ndisk-centre towards the solar limb. The average intensity contribution\nfunctions are usually rather broad and in some cases they are even\ndouble-peaked as there are contributions from hot shock waves and cool\npost-shock regions in the model chromosphere. Taking into account the\ndeviations from ionisation equilibrium for hydrogen gives a less strong\nvariation of the electron density and with it of the optical depth. The result\nis a narrower formation height range. The average brightness temperature\nincreases with wavelength and towards the limb. The relative contrast depends\non wavelength in the same way as the average intensity but decreases towards\nthe limb. The dependence of the brightness temperature distribution on\nwavelength and disk-position can be explained with the differences in formation\nheight and the variation of temperature fluctuations with height in the model\natmospheres.\n", "machine_text": " By analyzing millimetre wavelengths around 1 mm, the solar chromosphere can be evaluated. Future high-resolution millimetre arrays, such as the Atacama Large Millimeter Array (ALMA), can help further improve the understanding of the thermal structure and dynamics of this layer. The data produced by these arrays is used to calculate synthetic brightness temperature maps on the basis of three-dimensional radiation (magneto-)hydrodynamic (MHD) simulations. Different wavelengths go through different parts of the photosphere and chromosphere, with longer wavelengths mapping the low and middle chromosphere. Variations in the electron density and optical depth caused by deviations from ionisation equilibrium have an effect on the range of the formation height and the average brightness temperature. Comparing the brightness temperature distributions across different wavelengths and disk positions provides valuable insight into the temperature fluctuations in these atmospheric layers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2304}
{"prompt": "Rephrase the abstract of an article with title 'Statistical Evidence for Three classes of Gamma-ray Bursts'.\n  Two different multivariate clustering techniques, the K-means partitioning\nmethod and the Dirichlet process of mixture modeling, have been applied to the\nBATSE Gamma-ray burst (GRB) catalog, to obtain the optimum number of coherent\ngroups. In the standard paradigm, GRB are classified in only two groups, the\nlong and short bursts. However, for both the clustering techniques, the optimal\nnumber of classes was found to be three, a result which is consistent with\nprevious statistical analysis. In this classification, the long bursts are\nfurther divided into two groups which are primarily differentiated by their\ntotal fluence and duration and hence are named low and high fluence GRB.\nAnalysis of GRB with known red-shifts and spectral parameters suggests that low\nfluence GRB have nearly constant isotropic energy output of 10^{52} ergs while\nfor the high fluence ones, the energy output ranges from 10^{52} to 10^{54}\nergs. It is speculated that the three kinds of GRBs reflect three different\norigins: mergers of neutron star systems, mergers between white dwarfs and\nneutron stars, and collapse of massive stars.\n\n", "human_text": "  Two different multivariate clustering techniques, the K-means partitioning\nmethod and the Dirichlet process of mixture modeling, have been applied to the\nBATSE Gamma-ray burst (GRB) catalog, to obtain the optimum number of coherent\ngroups. In the standard paradigm, GRB are classified in only two groups, the\nlong and short bursts. However, for both the clustering techniques, the optimal\nnumber of classes was found to be three, a result which is consistent with\nprevious statistical analysis. In this classification, the long bursts are\nfurther divided into two groups which are primarily differentiated by their\ntotal fluence and duration and hence are named low and high fluence GRB.\nAnalysis of GRB with known red-shifts and spectral parameters suggests that low\nfluence GRB have nearly constant isotropic energy output of 10^{52} ergs while\nfor the high fluence ones, the energy output ranges from 10^{52} to 10^{54}\nergs. It is speculated that the three kinds of GRBs reflect three different\norigins: mergers of neutron star systems, mergers between white dwarfs and\nneutron stars, and collapse of massive stars.\n", "machine_text": "\nBased on the application of two distinct multi-clustering techniques to the BATSE Gamma-ray burst (GRB) catalogue, evidence for three classes of GRBs has been found. This classification splits the long bursts into two categories based on their total fluence and duration, referred to here as low and high fluence GRBs. Statistical analysis of GRBs with known redshifts and spectral parameters indicates that low fluence GRBs have an approximately constant energy output of 10^{52} ergs, with the energy output of the high fluence GRBs varying from 10^{52} to 10^{54} ergs. It is assumed that this three-fold division of GRBs reflects different origination events, such as the merger of neutron star systems, a merger between a white dwarf and a neutron star and the collapse of massive stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.402}
{"prompt": "Rephrase the abstract of an article with title 'Reparametrization Invariance, the controversial extraction of $\\alpha$\n  from $B\\to\\pi\\pi$ and New Physics'.\n  The extraction of the weak phase $\\alpha$ from $B\\to\\pi\\pi$ decays has been\ncontroversial from a statistical point of view, as the frequentist vs. bayesian\nconfrontation shows. We analyse several relevant questions which have not\ndeserved full attention and pervade the extraction of $\\alpha$.\nReparametrization Invariance proves appropriate to understand those issues. We\nshow that some Standard Model inspired parametrizations can be senseless or\ninadequate if they go beyond the minimal Gronau and London assumptions: the\nsingle weak phase $\\alpha$ just in the $\\Delta I=3/2$ amplitudes, the isospin\nrelations and experimental data. Beside those analyses, we extract $\\alpha$\nthrough the use of several adequate parametrizations, showing that there is no\nrelevant discrepancy between frequentist and bayesian results. The most\nrelevant information, in terms of $\\alpha$, is the exclusion of values around\n$\\alpha\\sim \\pi/4$; this result is valid in the presence of arbitrary New\nPhysics contributions to the $\\Delta I=1/2$ piece.\n\n", "human_text": "  The extraction of the weak phase $\\alpha$ from $B\\to\\pi\\pi$ decays has been\ncontroversial from a statistical point of view, as the frequentist vs. bayesian\nconfrontation shows. We analyse several relevant questions which have not\ndeserved full attention and pervade the extraction of $\\alpha$.\nReparametrization Invariance proves appropriate to understand those issues. We\nshow that some Standard Model inspired parametrizations can be senseless or\ninadequate if they go beyond the minimal Gronau and London assumptions: the\nsingle weak phase $\\alpha$ just in the $\\Delta I=3/2$ amplitudes, the isospin\nrelations and experimental data. Beside those analyses, we extract $\\alpha$\nthrough the use of several adequate parametrizations, showing that there is no\nrelevant discrepancy between frequentist and bayesian results. The most\nrelevant information, in terms of $\\alpha$, is the exclusion of values around\n$\\alpha\\sim \\pi/4$; this result is valid in the presence of arbitrary New\nPhysics contributions to the $\\Delta I=1/2$ piece.\n", "machine_text": "The extraction of the weak phase $\\alpha$ from $B\\to\\pi\\pi$ decays has been the subject of debate from a statistical standpoint with the frequentist-bayesian confrontation. This article examines several questions that have been disregarded but that are important for understanding the extraction of $\\alpha$. Reparametrization Invariance (RI) is used to ascertain that certain Standard Model inspired parametrizations can be inaccurate or inadequate if they move beyond the minimal Gronau-London assumptions. These assumptions include the single weak phase $\\alpha$, just in the $\\Delta I=3/2$ amplitudes, the isospin relations and experiment data. After assessing these issues, the author uses several applicable parametrizations to extract $\\alpha$, finding no noteworthy discrepancy between the frequentist and bayesian outcomes. Most significantly, RI shows that values of $\\alpha \\sim \\pi/4$ are ruled out, even if New Physics might be contributing to the $\\Delta I=1/2$ component.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0174}
{"prompt": "Rephrase the abstract of an article with title 'Dynamic condensation of water at crack tips in fused silica glass'.\n  Water molecules play a fundamental role in the physics of slow crack\npropagation in glasses. It is commonly understood that, during\nstress-corrosion, water molecules that move in the crack cavity effectively\nreduce the bond strength at the strained crack tip and, thus, support crack\npropagation. Yet the details of the environmental condition at the crack tip in\nmoist air are not well determined. In a previous work, we reported direct\nevidence of the presence of a 100 nm long liquid condensate at the crack tip in\nfused silica glass during very slow crack propagation (10^-9 to 10^-10 m/s).\nThese observations are based on in-situ AFM phase imaging techniques applied on\nDCDC glass specimens in controlled atmosphere. Here, we discuss the physical\norigin of the AFM phase contrast between the liquid condensate and the glass\nsurface in relation to tip-sample adhesion induced by capillary bridges. We\nthen report new experimental data on the water condensation length increase\nwith relative humidity in the atmosphere. The measured condensation lengths\nwere much larger than what predicted using the Kelvin equation and expected\ngeometry of the crack tip.\n\n", "human_text": "  Water molecules play a fundamental role in the physics of slow crack\npropagation in glasses. It is commonly understood that, during\nstress-corrosion, water molecules that move in the crack cavity effectively\nreduce the bond strength at the strained crack tip and, thus, support crack\npropagation. Yet the details of the environmental condition at the crack tip in\nmoist air are not well determined. In a previous work, we reported direct\nevidence of the presence of a 100 nm long liquid condensate at the crack tip in\nfused silica glass during very slow crack propagation (10^-9 to 10^-10 m/s).\nThese observations are based on in-situ AFM phase imaging techniques applied on\nDCDC glass specimens in controlled atmosphere. Here, we discuss the physical\norigin of the AFM phase contrast between the liquid condensate and the glass\nsurface in relation to tip-sample adhesion induced by capillary bridges. We\nthen report new experimental data on the water condensation length increase\nwith relative humidity in the atmosphere. The measured condensation lengths\nwere much larger than what predicted using the Kelvin equation and expected\ngeometry of the crack tip.\n", "machine_text": "\nBy studying the physical characteristics of the crack tip in moist air, the presence of a dynamic 100 nm liquid condensate has been identified in fused silica glass surfaces during slow crack propagation. Taking this further, in-situ Atomic Force Microscopy (AFM) was employed to estimate the sticking forces between the condensate and the glass surface due to the formation of capillary bridges. Additionally, our experiments revealed an increase in condensation length with relative humidity, an effect that was not predicted by the Kelvin equation and believed crack tip geometry.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2531}
{"prompt": "Rephrase the abstract of an article with title 'Galaxy Colours in the AKARI Deep SEP Survey'.\n  We investigate the segregation of the extragalactic population via colour\ncriteria to produce an efficient and inexpensive methodology to select specific\nsource populations as a function of far-infrared flux. Combining galaxy\nevolution scenarios and a detailed spectral library of galaxies, we produce\nsimulated catalogues incorporating segregation of the extragalactic population\ninto component types (Normal, star-forming, AGN) via color cuts. As a practical\napplication we apply our criteria to the deepest survey to be undertaken in the\nfar-infrared with the AKARI (formerly ASTRO-F) satellite. Using the\nfar-infrared wavebands of the Far-Infrared Surveyor (FIS, one of the\nfocal-plane instruments on AKARI) we successfully segregate the normal,\nstarburst and ULIRG populations. We also show that with additional MIR imaging\nfrom AKARI's Infrared Camera (IRC), significant contamination and/or degeneracy\ncan be further decreased and show a particular example of the separation of\ncool normal galaxies and cold ULIRG sources. We conclude that our criteria\nprovide an efficient means of selecting source populations (including rare\nluminous objects) and produce colour-segregated source counts without the\nrequirement of time intensive ground-based follow up to differentiate between\nthe general galaxy population.\n\n", "human_text": "  We investigate the segregation of the extragalactic population via colour\ncriteria to produce an efficient and inexpensive methodology to select specific\nsource populations as a function of far-infrared flux. Combining galaxy\nevolution scenarios and a detailed spectral library of galaxies, we produce\nsimulated catalogues incorporating segregation of the extragalactic population\ninto component types (Normal, star-forming, AGN) via color cuts. As a practical\napplication we apply our criteria to the deepest survey to be undertaken in the\nfar-infrared with the AKARI (formerly ASTRO-F) satellite. Using the\nfar-infrared wavebands of the Far-Infrared Surveyor (FIS, one of the\nfocal-plane instruments on AKARI) we successfully segregate the normal,\nstarburst and ULIRG populations. We also show that with additional MIR imaging\nfrom AKARI's Infrared Camera (IRC), significant contamination and/or degeneracy\ncan be further decreased and show a particular example of the separation of\ncool normal galaxies and cold ULIRG sources. We conclude that our criteria\nprovide an efficient means of selecting source populations (including rare\nluminous objects) and produce colour-segregated source counts without the\nrequirement of time intensive ground-based follow up to differentiate between\nthe general galaxy population.\n", "machine_text": "\nIn our study, we have developed an economical and effective method of separating the extragalactic population into component groups (Normal, Star-forming, AGN) based on color criteria. We have applied a color cut on the data generated in the greatest far-infrared survey ever conducted using AKARI (formerly ASTRO-F). By using the Far-Infrared Surveyor (FIS) from the AKARI satellite and MIR images from its Infrared Camera (IRC), we have been able to sort out certain galaxies like normal galaxies, starburst, and ULIRG. Our approach helps to quickly identify various source populations, including rare luminous objects, without having to invest too much time in ground-follow ups. These results provide a means of identifying specific source populations and generating colour-stratified source counts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.186}
{"prompt": "Rephrase the abstract of an article with title 'Electron Doping of Cuprates via Interfaces with Manganites'.\n  The electron doping of undoped high-$T_c$ cuprates via the transfer of charge\nfrom manganites (or other oxides) using heterostructure geometries is here\ntheoretically discussed. This possibility is mainly addressed via a detailed\nanalysis of photoemission and diffusion voltage experiments, which locate the\nFermi level of manganites above the bottom of the upper Hubbard band of some\ncuprate parent compounds. A diagram with the relative location of Fermi levels\nand gaps for several oxides is presented. The procedure discussed here is\ngeneric, allowing for the qualitative prediction of the charge flow direction\nat several oxide interfaces. The addition of electrons to antiferromagnetic Cu\noxides may lead to a superconducting state at the interface with minimal\nquenched disorder. Model calculations using static and dynamical mean-field\ntheory, supplemented by a Poisson equation formalism to address charge\nredistribution at the interface, support this view. The magnetic state of the\nmanganites could be antiferromagnetic or ferromagnetic. The former is better to\ninduce superconductivity than the latter, since the spin-polarized charge\ntransfer will be detrimental to singlet superconductivity. It is concluded that\nin spite of the robust Hubbard gaps, the electron doping of undoped cuprates at\ninterfaces appears possible, and its realization may open an exciting area of\nresearch in oxide heterostructures.\n\n", "human_text": "  The electron doping of undoped high-$T_c$ cuprates via the transfer of charge\nfrom manganites (or other oxides) using heterostructure geometries is here\ntheoretically discussed. This possibility is mainly addressed via a detailed\nanalysis of photoemission and diffusion voltage experiments, which locate the\nFermi level of manganites above the bottom of the upper Hubbard band of some\ncuprate parent compounds. A diagram with the relative location of Fermi levels\nand gaps for several oxides is presented. The procedure discussed here is\ngeneric, allowing for the qualitative prediction of the charge flow direction\nat several oxide interfaces. The addition of electrons to antiferromagnetic Cu\noxides may lead to a superconducting state at the interface with minimal\nquenched disorder. Model calculations using static and dynamical mean-field\ntheory, supplemented by a Poisson equation formalism to address charge\nredistribution at the interface, support this view. The magnetic state of the\nmanganites could be antiferromagnetic or ferromagnetic. The former is better to\ninduce superconductivity than the latter, since the spin-polarized charge\ntransfer will be detrimental to singlet superconductivity. It is concluded that\nin spite of the robust Hubbard gaps, the electron doping of undoped cuprates at\ninterfaces appears possible, and its realization may open an exciting area of\nresearch in oxide heterostructures.\n", "machine_text": "\nThis paper examines the possibility of doping high-$T_c$ cuprates with free electrons which are sourced from transfer of charge at the interface with manganites (or other oxides) through heterostructure geometries. By analyzing photoemission and diffusion voltage experiments, it can be seen that the Fermi level of manganites is positioned higher than the bottom of the upper Hubbard band of cuprate parent compounds. Our research results in a diagram with the relative location of Fermi levels and gaps for a variety of oxides, as well as in a generic indication of the direction of charge flow at the interfaces between them. Model calculations using static and dynamical mean-field theory and supplemented by a Poisson equation to address the redistribution of charge at the interface, suggest that this transfer of electrons to an antiferromagnetic Cu oxide can result in a superconducting state, provided that minimal quenched disorder is present. Furthermore, this process appears to be more successful when the magnetic state of the manganites is antiferromagnetic instead of ferromagnetic, since spin-polarized charge transfer has a negative effect on singlet superconductivity. Therefore, the electron doping of undoped cuprates at interfaces can be made possible, and this opens up a new area of research in oxide heterostructures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0498}
{"prompt": "Rephrase the abstract of an article with title 'Scanning magnetoresistance microscopy of atom chips'.\n  Surface based geometries of microfabricated wires or patterned magnetic films\ncan be used to magnetically trap and manipulate ultracold neutral atoms or\nBose-Einstein condensates. We investigate the magnetic properties of such atom\nchips using a scanning magnetoresistive (MR) microscope with high spatial\nresolution and high field sensitivity. We show that MR sensors are ideally\nsuited to observe small variations of the magnetic field caused by\nimperfections in the wires or magnetic materials which ultimately lead to\nfragmentation of ultracold atom clouds. Measurements are also provided for the\nmagnetic field produced by a thin current-carrying wire with small geometric\nmodulations along the edge. Comparisons of our measurements with a full numeric\ncalculation of the current flow in the wire and the subsequent magnetic field\nshow excellent agreement. Our results highlight the use of scanning MR\nmicroscopy as a convenient and powerful technique for precisely characterizing\nthe magnetic fields produced near the surface of atom chips.\n\n", "human_text": "  Surface based geometries of microfabricated wires or patterned magnetic films\ncan be used to magnetically trap and manipulate ultracold neutral atoms or\nBose-Einstein condensates. We investigate the magnetic properties of such atom\nchips using a scanning magnetoresistive (MR) microscope with high spatial\nresolution and high field sensitivity. We show that MR sensors are ideally\nsuited to observe small variations of the magnetic field caused by\nimperfections in the wires or magnetic materials which ultimately lead to\nfragmentation of ultracold atom clouds. Measurements are also provided for the\nmagnetic field produced by a thin current-carrying wire with small geometric\nmodulations along the edge. Comparisons of our measurements with a full numeric\ncalculation of the current flow in the wire and the subsequent magnetic field\nshow excellent agreement. Our results highlight the use of scanning MR\nmicroscopy as a convenient and powerful technique for precisely characterizing\nthe magnetic fields produced near the surface of atom chips.\n", "machine_text": "\nUsing a scanning magnetoresistive (MR) microscope with large spatial resolution and sensitive to magnetic fields, we have studied small variations of the magnetic field produced by imperfections in microfabricated wires and patterned magnetic films that are utilized to manipulate cold neutral atoms or Bose-Einstein condensates. Our research demonstrates that MR sensors are ideally suited for detecting minor changes in the magnetic field, which may result in the disruption of the ultracold atoms. Additionally, we verified the accuracy of our measurements against simulated magnetic fields stemming from thin, current-carrying wires with slight modifications to the edge. We found that our results closely matched the prediction of the calculations. Our study indicates that scanning MR microscopy is an efficient and reliable technique to precisely evaluate the magnetic fields near atom chips.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3137}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic ray confinement in fossil cluster bubbles'.\n  Most cool core clusters of galaxies possess active galactic nuclei (AGN) in\ntheir centers. These AGN inflate buoyant bubbles containing non-thermal radio\nemitting particles. If such bubbles efficiently confine cosmic rays (CR) then\nthis could explain ``radio ghosts'' seen far from cluster centers. We simulate\nthe diffusion of cosmic rays from buoyant bubbles inflated by AGN. Our\nsimulations include the effects of the anisotropic particle diffusion\nintroduced by magnetic fields. Our models are consistent with the X-ray\nmorphology of AGN bubbles, with disruption being suppressed by the magnetic\ndraping effect. We conclude that for such magnetic field topologies, a\nsubstantial fraction of cosmic rays can be confined inside the bubbles on\nbuoyant rise timescales even when the parallel diffusivity coefficient is very\nlarge. For isotropic diffusion at a comparable level, cosmic rays would leak\nout of the bubbles too rapidly to be consistent with radio observations. Thus,\nthe long confinement times associated with the magnetic suppression of CR\ndiffusion can explain the presence of radio ghosts. We show that the partial\nescape of cosmic rays is mostly confined to the wake of the rising bubbles, and\nspeculate that this effect could: (1) account for the excitation of the\nH$\\alpha$ filaments trailing behind the bubbles in the Perseus cluster, (2)\ninject entropy into the metal enriched material being lifted by the bubbles\nand, thus, help to displace it permanently from the cluster center and (3)\nproduce observable $\\gamma$-rays via the interaction of the diffusing cosmic\nrays with the thermal intracluster medium (ICM).\n\n", "human_text": "  Most cool core clusters of galaxies possess active galactic nuclei (AGN) in\ntheir centers. These AGN inflate buoyant bubbles containing non-thermal radio\nemitting particles. If such bubbles efficiently confine cosmic rays (CR) then\nthis could explain ``radio ghosts'' seen far from cluster centers. We simulate\nthe diffusion of cosmic rays from buoyant bubbles inflated by AGN. Our\nsimulations include the effects of the anisotropic particle diffusion\nintroduced by magnetic fields. Our models are consistent with the X-ray\nmorphology of AGN bubbles, with disruption being suppressed by the magnetic\ndraping effect. We conclude that for such magnetic field topologies, a\nsubstantial fraction of cosmic rays can be confined inside the bubbles on\nbuoyant rise timescales even when the parallel diffusivity coefficient is very\nlarge. For isotropic diffusion at a comparable level, cosmic rays would leak\nout of the bubbles too rapidly to be consistent with radio observations. Thus,\nthe long confinement times associated with the magnetic suppression of CR\ndiffusion can explain the presence of radio ghosts. We show that the partial\nescape of cosmic rays is mostly confined to the wake of the rising bubbles, and\nspeculate that this effect could: (1) account for the excitation of the\nH$\\alpha$ filaments trailing behind the bubbles in the Perseus cluster, (2)\ninject entropy into the metal enriched material being lifted by the bubbles\nand, thus, help to displace it permanently from the cluster center and (3)\nproduce observable $\\gamma$-rays via the interaction of the diffusing cosmic\nrays with the thermal intracluster medium (ICM).\n", "machine_text": "\nThe current study assesses the confinement of cosmic rays (CR) in fossil cluster bubbles inflated by active galactic nuclei (AGN). We simulate the diffusion of CR particles within the bubble and find that for realistic magnetic field topologies, a substantial fraction of CRs can be confined and sustain the presence of radio ghosts. We also speculate that such confinement of CR could account for the presence of H$\\alpha$ filaments trailing behind the bubbles, permanently displace metal enriched material from the cluster center and provide an observable $\\gamma$-ray output from the interaction of the diffusing cosmic rays and the thermal intracluster medium (ICM).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3235}
{"prompt": "Rephrase the abstract of an article with title 'An Optical Source Catalog of the North Ecliptic Pole Region'.\n  We present a five (u*,g',r',i',z') band optical photometry catalog of the\nsources in the North Ecliptic Pole (NEP) region based on deep observations made\nwith MegaCam at CFHT. The source catalog covers about 2 square degree area\ncentered at the NEP and reaches depths of about 26 mag for u*, g', r' bands,\nabout 25 mag for i' band, and about 24 mag for z' band (4 sigma detection over\nan 1 arcsec aperture). The total number of cataloged sources brighter than r'=\n23 mag is about 56,000 including both point sources and extended sources. From\nthe investigation of photometric properties using the color-magnitude diagrams\nand color-color diagrams, we have found that the colors of extended sources are\nmostly (u*-r') < 3.0 and (g'-z') > 0.5. This can be used to separate the\nextended sources from the point sources reliably, even for the faint source\ndomain where typical morphological classification schemes hardly work\nefficiently. We have derived an empirical color-redshift relation of the red\nsequence galaxies using the Sloan Digital Sky Survey data. By applying this\nrelation to our photometry catalog and searching for any spatial overdensities,\nwe have found two galaxy clusters and one nearby galaxy group.\n\n", "human_text": "  We present a five (u*,g',r',i',z') band optical photometry catalog of the\nsources in the North Ecliptic Pole (NEP) region based on deep observations made\nwith MegaCam at CFHT. The source catalog covers about 2 square degree area\ncentered at the NEP and reaches depths of about 26 mag for u*, g', r' bands,\nabout 25 mag for i' band, and about 24 mag for z' band (4 sigma detection over\nan 1 arcsec aperture). The total number of cataloged sources brighter than r'=\n23 mag is about 56,000 including both point sources and extended sources. From\nthe investigation of photometric properties using the color-magnitude diagrams\nand color-color diagrams, we have found that the colors of extended sources are\nmostly (u*-r') < 3.0 and (g'-z') > 0.5. This can be used to separate the\nextended sources from the point sources reliably, even for the faint source\ndomain where typical morphological classification schemes hardly work\nefficiently. We have derived an empirical color-redshift relation of the red\nsequence galaxies using the Sloan Digital Sky Survey data. By applying this\nrelation to our photometry catalog and searching for any spatial overdensities,\nwe have found two galaxy clusters and one nearby galaxy group.\n", "machine_text": "\nThis research provides a five-band optical photometry catalog for the North Ecliptic Pole region consisting of approximately 56,000 sources brighter than r\u2019 = 23 mag. These sources include both point and extended sources and were observed extensively using MegaCam at CFHT. Results from the analysis of the catalog's photometric properties, including color-magnitude and color-color diagrams, indicate that the majority of extended sources possess colors of (u*-r')< 3.0 and (g'-z')> 0.5. Additionally, a comparison of these sources to the Sloan Digital Sky Survey data allowed for the identification of two probable clusters and one group. Ultimately, this catalog may aid in separating extended sources from point sources, even when the sources are faint and traditional morphological classification schemes are ineffective.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1182}
{"prompt": "Rephrase the abstract of an article with title 'On generalized entropy measures and pathways'.\n  Product probability property, known in the literature as statistical\nindependence, is examined first. Then generalized entropies are introduced, all\nof which give generalizations to Shannon entropy. It is shown that the nature\nof the recursivity postulate automatically determines the logarithmic\nfunctional form for Shannon entropy. Due to the logarithmic nature, Shannon\nentropy naturally gives rise to additivity, when applied to situations having\nproduct probability property. It is argued that the natural process is\nnon-additivity, important, for example, in statistical mechanics, even in\nproduct probability property situations and additivity can hold due to the\ninvolvement of a recursivity postulate leading to a logarithmic function.\nGeneralizations, including Mathai's generalized entropy are introduced and some\nof the properties are examined. Situations are examined where Mathai's entropy\nleads to pathway models, exponential and power law behavior and related\ndifferential equations. Connection of Mathai's entropy to Kerridge's measure of\n\"inaccuracy\" is also explored.\n\n", "human_text": "  Product probability property, known in the literature as statistical\nindependence, is examined first. Then generalized entropies are introduced, all\nof which give generalizations to Shannon entropy. It is shown that the nature\nof the recursivity postulate automatically determines the logarithmic\nfunctional form for Shannon entropy. Due to the logarithmic nature, Shannon\nentropy naturally gives rise to additivity, when applied to situations having\nproduct probability property. It is argued that the natural process is\nnon-additivity, important, for example, in statistical mechanics, even in\nproduct probability property situations and additivity can hold due to the\ninvolvement of a recursivity postulate leading to a logarithmic function.\nGeneralizations, including Mathai's generalized entropy are introduced and some\nof the properties are examined. Situations are examined where Mathai's entropy\nleads to pathway models, exponential and power law behavior and related\ndifferential equations. Connection of Mathai's entropy to Kerridge's measure of\n\"inaccuracy\" is also explored.\n", "machine_text": "\nThis paper explores the concept of generalised entropies, beyond Shannon entropy, and aims to examine the implications of the recursivity postulate for these different forms of entropy. It looks at how the accumulative, logarithmic updates to Shannon entropy due to the postulate enable it to generate an additivity in situations of product probability. Other forms of generalised entropies, such as Mathai's entropy, are examined in relation to the impact on statistical mechanics and the development of pathways, exponential and power law behaviours and associated differential equations. Additionally, the paper explores the connections between Mathai's entropy and Kerridge's measure of inaccuracy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0326}
{"prompt": "Rephrase the abstract of an article with title 'Implications for the Constrained MSSM from a new prediction for b to s\n  gamma'.\n  We re-examine the properties of the Constrained MSSM in light of updated\nconstraints, paying particular attention to the impact of the recent\nsubstantial shift in the Standard Model prediction for BR(B to X_s gamma). With\nthe help of a Markov Chain Monte Carlo scanning technique, we vary all relevant\nparameters simultaneously and derive Bayesian posterior probability maps. We\nfind that the case of \\mu>0 remains favored, and that for \\mu<0 it is\nconsiderably more difficult to find a good global fit to current constraints.\nIn both cases we find a strong preference for a focus point region. This leads\nto improved prospects for detecting neutralino dark matter in direct searches,\nwhile superpartner searches at the LHC become more problematic, especially when\n\\mu<0. In contrast, prospects for exploring the whole mass range of the\nlightest Higgs boson at the Tevatron and the LHC remain very good, which\nshould, along with dark matter searches, allow one to gain access to the\notherwise experimentally challenging focus point region. An alternative measure\nof the mean quality-of-fit which we also employ implies that present data are\nnot yet constraining enough to draw more definite conclusions. We also comment\non the dependence of our results on the choice of priors and on some other\nassumptions.\n\n", "human_text": "  We re-examine the properties of the Constrained MSSM in light of updated\nconstraints, paying particular attention to the impact of the recent\nsubstantial shift in the Standard Model prediction for BR(B to X_s gamma). With\nthe help of a Markov Chain Monte Carlo scanning technique, we vary all relevant\nparameters simultaneously and derive Bayesian posterior probability maps. We\nfind that the case of \\mu>0 remains favored, and that for \\mu<0 it is\nconsiderably more difficult to find a good global fit to current constraints.\nIn both cases we find a strong preference for a focus point region. This leads\nto improved prospects for detecting neutralino dark matter in direct searches,\nwhile superpartner searches at the LHC become more problematic, especially when\n\\mu<0. In contrast, prospects for exploring the whole mass range of the\nlightest Higgs boson at the Tevatron and the LHC remain very good, which\nshould, along with dark matter searches, allow one to gain access to the\notherwise experimentally challenging focus point region. An alternative measure\nof the mean quality-of-fit which we also employ implies that present data are\nnot yet constraining enough to draw more definite conclusions. We also comment\non the dependence of our results on the choice of priors and on some other\nassumptions.\n", "machine_text": "\nA reevaluation of the Constrained MSSM has been performed in light of newly revised constraints, with special focus on the consequences of a large variation in the Standard Model estimation of BR(B to X_s gamma). Through a Markov Chain Monte Carlo scanning system to sample different parameters in the MSSM, we studied the posterior probability maps to check the preferred case of $\\mu> 0$ and develop an understanding of the challenges for $\\mu<0$.The focus point region shows strong preference in both cases, which consequently has a definite impact on the prospects for observing neutralino dark matter and superpartner searches. Tevatron and LHC searches related to the lightest Higgs boson are unaffected, and provide opportunities to gain access to the focus point region otherwise hard to probe. An alternative global fit measure demonstrates that current data are not definitive enough for definite conclusions. Aspects like alternative priors and other assumptions are also discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2012}
{"prompt": "Rephrase the abstract of an article with title 'Surface gap solitons at a nonlinearity interface'.\n  We demonstrate existence of waves localized at the interface of two nonlinear\nperiodic media with different coefficients of the cubic nonlinearity via the\none-dimensional Gross--Pitaevsky equation. We call these waves the surface gap\nsolitons (SGS). In the case of smooth symmetric periodic potentials, we study\nanalytically bifurcations of SGS's from standard gap solitons and determine\nnumerically the maximal jump of the nonlinearity coefficient allowing for the\nSGS existence. We show that the maximal jump vanishes near the thresholds of\nbifurcations of gap solitons. In the case of continuous potentials with a jump\nin the first derivative at the interface, we develop a homotopy method of\ncontinuation of SGS families from the solution obtained via gluing of parts of\nthe standard gap solitons and study existence of SGS's in the photonic band\ngaps. We explain the termination of the SGS families in the interior points of\nthe band gaps from the bifurcation of linear bound states in the continuous\nnon-smooth potentials.\n\n", "human_text": "  We demonstrate existence of waves localized at the interface of two nonlinear\nperiodic media with different coefficients of the cubic nonlinearity via the\none-dimensional Gross--Pitaevsky equation. We call these waves the surface gap\nsolitons (SGS). In the case of smooth symmetric periodic potentials, we study\nanalytically bifurcations of SGS's from standard gap solitons and determine\nnumerically the maximal jump of the nonlinearity coefficient allowing for the\nSGS existence. We show that the maximal jump vanishes near the thresholds of\nbifurcations of gap solitons. In the case of continuous potentials with a jump\nin the first derivative at the interface, we develop a homotopy method of\ncontinuation of SGS families from the solution obtained via gluing of parts of\nthe standard gap solitons and study existence of SGS's in the photonic band\ngaps. We explain the termination of the SGS families in the interior points of\nthe band gaps from the bifurcation of linear bound states in the continuous\nnon-smooth potentials.\n", "machine_text": "This article examines the presence of waves localized in the interface of two different cubic nonlinear periodic media. We have given them the name 'surface gap solitons' (SGS). Using formal analysis, we investigate the emergence of these SGS's via bifurcation of standard gap solitons. Moreover, to find the largest coefficient jump which allows for the SGS existence, numerical solutions are established. We note that the largest jump is witnessed near transition points of gap solitons. We create a homotopy method of continuation of SGS families, together with the analysis of SGS in the photonic band gaps by employing a continuous potential with a differential jump at the interface. In the end, we explain why SGS's are limited to the interior points of band gap by bifurcations of linear bound states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1742}
{"prompt": "Rephrase the abstract of an article with title 'On global solution to the Klein-Gordon-Hartree equation below energy\n  space'.\n  In this paper, we consider the Cauchy problem for Klein-Gordon equation with\na cubic convolution nonlinearity in $\\R^3$. By making use of Bourgain's method\nin conjunction with a precise Strichartz estimate of S.Klainerman and D.Tataru,\nwe establish the $H^s (s<1)$ global well-posedness of the Cauchy problem for\nthe cubic convolution defocusing Klein-Gordon-Hartree equation. Before arriving\nat the previously discussed conclusion, we obtain global solution for this\nnon-scaling equation with small initial data in $H^{s_0}\\times H^{s_0-1}$ where\n$s_0=\\frac\\gamma 6$ but not $\\frac\\gamma2-1$, for this equation that we\nconsider is a subconformal equation in some sense. In doing so a number of\nnonlinear prior estimates are already established by using Bony's\ndecomposition, flexibility of Klein-Gordon admissible pairs which are slightly\ndifferent from that of wave equation and a commutator estimate. We establish\nthis commutator estimate by exploiting cancellation property and utilizing\nCoifman and Meyer multilinear multiplier theorem. As far as we know, it seems\nthat this is the first result on low regularity for this Klein-Gordon-Hartree\nequation.\n\n", "human_text": "  In this paper, we consider the Cauchy problem for Klein-Gordon equation with\na cubic convolution nonlinearity in $\\R^3$. By making use of Bourgain's method\nin conjunction with a precise Strichartz estimate of S.Klainerman and D.Tataru,\nwe establish the $H^s (s<1)$ global well-posedness of the Cauchy problem for\nthe cubic convolution defocusing Klein-Gordon-Hartree equation. Before arriving\nat the previously discussed conclusion, we obtain global solution for this\nnon-scaling equation with small initial data in $H^{s_0}\\times H^{s_0-1}$ where\n$s_0=\\frac\\gamma 6$ but not $\\frac\\gamma2-1$, for this equation that we\nconsider is a subconformal equation in some sense. In doing so a number of\nnonlinear prior estimates are already established by using Bony's\ndecomposition, flexibility of Klein-Gordon admissible pairs which are slightly\ndifferent from that of wave equation and a commutator estimate. We establish\nthis commutator estimate by exploiting cancellation property and utilizing\nCoifman and Meyer multilinear multiplier theorem. As far as we know, it seems\nthat this is the first result on low regularity for this Klein-Gordon-Hartree\nequation.\n", "machine_text": "This paper investigates the Cauchy problem for the Klein-Gordon equation featuring cubic convolution nonlinearity in $\\R^3$. By using a combination of Bourgain's method and a Strichartz estimate from Klainerman and Tataru, we show the global, $H^s (s<1)$ well-posedness of the Cauchy problem for the cubic convolution-based Klein-Gordon-Hartree equation. Additionally, we provide a novel global solution for this non-scaling equation with small initial data in $H^{s_0}\\times H^{s_0-1}$ where $s_0=\\frac\\gamma 6$ but not $\\frac\\gamma2-1$. To arrive at the aforementioned conclusion, we utilize Bony's decomposition, flexibility of Klein-Gordon admissible pairs which diverges from the wave equation, and a specific commutator estimate arising from the cancellation property together with the Coifman and Meyer multilinear multiplier theorem. This appears to be the first result linking low regularity to this Klein-Gordon-Hartree equation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1866}
{"prompt": "Rephrase the abstract of an article with title 'Efficient Multidimensional Data Redistribution for Resizable Parallel\n  Computations'.\n  Traditional parallel schedulers running on cluster supercomputers support\nonly static scheduling, where the number of processors allocated to an\napplication remains fixed throughout the execution of the job. This results in\nunder-utilization of idle system resources thereby decreasing overall system\nthroughput. In our research, we have developed a prototype framework called\nReSHAPE, which supports dynamic resizing of parallel MPI applications executing\non distributed memory platforms. The resizing library in ReSHAPE includes\nsupport for releasing and acquiring processors and efficiently redistributing\napplication state to a new set of processors. In this paper, we derive an\nalgorithm for redistributing two-dimensional block-cyclic arrays from $P$ to\n$Q$ processors, organized as 2-D processor grids. The algorithm ensures a\ncontention-free communication schedule for data redistribution if $P_r \\leq\nQ_r$ and $P_c \\leq Q_c$. In other cases, the algorithm implements circular row\nand column shifts on the communication schedule to minimize node contention.\n\n", "human_text": "  Traditional parallel schedulers running on cluster supercomputers support\nonly static scheduling, where the number of processors allocated to an\napplication remains fixed throughout the execution of the job. This results in\nunder-utilization of idle system resources thereby decreasing overall system\nthroughput. In our research, we have developed a prototype framework called\nReSHAPE, which supports dynamic resizing of parallel MPI applications executing\non distributed memory platforms. The resizing library in ReSHAPE includes\nsupport for releasing and acquiring processors and efficiently redistributing\napplication state to a new set of processors. In this paper, we derive an\nalgorithm for redistributing two-dimensional block-cyclic arrays from $P$ to\n$Q$ processors, organized as 2-D processor grids. The algorithm ensures a\ncontention-free communication schedule for data redistribution if $P_r \\leq\nQ_r$ and $P_c \\leq Q_c$. In other cases, the algorithm implements circular row\nand column shifts on the communication schedule to minimize node contention.\n", "machine_text": "\nThis study outlines a prototype framework, ReSHAPE, which facilitates dynamic resizing of parallel MPI applications in distributed memory platforms. The included library provides an efficient means of redistributing a two-dimensional block-cyclic array of data from $P$ to $Q$ processors arranged in a 2-D processor grid with a contention-free communication schedule when $P_r \\leq Q_r$ and $P_c \\leq Q_c$. Otherwise, circular row and column shifts are performed on the communication schedule to minimize node collisions. Our proposal seeks to improve system throughput by fully utilizing idle system resources for parallel computations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2146}
{"prompt": "Rephrase the abstract of an article with title 'Relaxation of a dewetting contact line Part 1: A full-scale hydrodynamic\n  calculation'.\n  The relaxation of a dewetting contact line is investigated theoretically in\nthe so-called \"Landau-Levich\" geometry in which a vertical solid plate is\nwithdrawn from a bath of partially wetting liquid. The study is performed in\nthe framework of lubrication theory, in which the hydrodynamics is resolved at\nall length scales (from molecular to macroscopic). We investigate the\nbifurcation diagram for unperturbed contact lines, which turns out to be more\ncomplex than expected from simplified 'quasi-static' theories based upon an\napparent contact angle. Linear stability analysis reveals that below the\ncritical capillary number of entrainment, Ca_c, the contact line is linearly\nstable at all wavenumbers. Away from the critical point the dispersion relation\nhas an asymptotic behaviour sigma~|q| and compares well to a quasi-static\napproach. Approaching Ca_c, however, a different mechanism takes over and the\ndispersion evolves from |q| to the more common q^2. These findings imply that\ncontact lines can not be treated as universal objects governed by some\neffective law for the macroscopic contact angle, but viscous effects have to be\ntreated explicitly.\n\n", "human_text": "  The relaxation of a dewetting contact line is investigated theoretically in\nthe so-called \"Landau-Levich\" geometry in which a vertical solid plate is\nwithdrawn from a bath of partially wetting liquid. The study is performed in\nthe framework of lubrication theory, in which the hydrodynamics is resolved at\nall length scales (from molecular to macroscopic). We investigate the\nbifurcation diagram for unperturbed contact lines, which turns out to be more\ncomplex than expected from simplified 'quasi-static' theories based upon an\napparent contact angle. Linear stability analysis reveals that below the\ncritical capillary number of entrainment, Ca_c, the contact line is linearly\nstable at all wavenumbers. Away from the critical point the dispersion relation\nhas an asymptotic behaviour sigma~|q| and compares well to a quasi-static\napproach. Approaching Ca_c, however, a different mechanism takes over and the\ndispersion evolves from |q| to the more common q^2. These findings imply that\ncontact lines can not be treated as universal objects governed by some\neffective law for the macroscopic contact angle, but viscous effects have to be\ntreated explicitly.\n", "machine_text": "\nThis paper examines the relaxation of a dewetting contact line in what is referred to as the 'Landau-Levich' geometry. Here, a vertical plate is being withdrawn from a liquid bath that partially wets the plate. The hydrodynamics at all scales (from molecular to macroscopic) are resolved through the analysis of a lubrication theory. The bifurcation diagram for unperturbed contact lines is more complex than expected from simplified theories involving an apparent contact angle. A linear stability analysis demonstrates that below the critical capillary number, the contact line is stable at all wavenumbers, and compared favorably to the quasi-static approach. However, as the critical number is approached, another mechanism takes over and the dispersion changes from |q| to q^2. These results indicate that contact lines should not be assumed to obey a single effective law for the macroscopic contact angle, but instead require explicit consideration of viscous effects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3576}
{"prompt": "Rephrase the abstract of an article with title 'Redefining the Missing Satellites Problem'.\n  Numerical simulations of Milky-Way size Cold Dark Matter (CDM) halos predict\na steeply rising mass function of small dark matter subhalos and a substructure\ncount that greatly outnumbers the observed satellites of the Milky Way. Several\nproposed explanations exist, but detailed comparison between theory and\nobservation in terms of the maximum circular velocity (Vmax) of the subhalos is\nhampered by the fact that Vmax for satellite halos is poorly constrained. We\npresent comprehensive mass models for the well-known Milky Way dwarf\nsatellites, and derive likelihood functions to show that their masses within\n0.6 kpc (M_0.6) are strongly constrained by the present data. We show that the\nM_0.6 mass function of luminous satellite halos is flat between ~ 10^7 and 10^8\nM_\\odot. We use the ``Via Lactea'' N-body simulation to show that the M_0.6\nmass function of CDM subhalos is steeply rising over this range. We rule out\nthe hypothesis that the 11 well-known satellites of the Milky Way are hosted by\nthe 11 most massive subhalos. We show that models where the brightest\nsatellites correspond to the earliest forming subhalos or the most massive\naccreted objects both reproduce the observed mass function. A similar analysis\nwith the newly-discovered dwarf satellites will further test these scenarios\nand provide powerful constraints on the CDM small-scale power spectrum and warm\ndark matter models.\n\n", "human_text": "  Numerical simulations of Milky-Way size Cold Dark Matter (CDM) halos predict\na steeply rising mass function of small dark matter subhalos and a substructure\ncount that greatly outnumbers the observed satellites of the Milky Way. Several\nproposed explanations exist, but detailed comparison between theory and\nobservation in terms of the maximum circular velocity (Vmax) of the subhalos is\nhampered by the fact that Vmax for satellite halos is poorly constrained. We\npresent comprehensive mass models for the well-known Milky Way dwarf\nsatellites, and derive likelihood functions to show that their masses within\n0.6 kpc (M_0.6) are strongly constrained by the present data. We show that the\nM_0.6 mass function of luminous satellite halos is flat between ~ 10^7 and 10^8\nM_\\odot. We use the ``Via Lactea'' N-body simulation to show that the M_0.6\nmass function of CDM subhalos is steeply rising over this range. We rule out\nthe hypothesis that the 11 well-known satellites of the Milky Way are hosted by\nthe 11 most massive subhalos. We show that models where the brightest\nsatellites correspond to the earliest forming subhalos or the most massive\naccreted objects both reproduce the observed mass function. A similar analysis\nwith the newly-discovered dwarf satellites will further test these scenarios\nand provide powerful constraints on the CDM small-scale power spectrum and warm\ndark matter models.\n", "machine_text": "In this article, we investigate the disparity between the number of observed satellites in the Milky Way and its predicted CDM mass function. We explore the maximum circular velocities (Vmax) of the Milky Way's luminous satellites and construct mass models in order to derive the likelihoods of their masses within 0.6 kpc (M_0.6). We then compare the flat M_0.6 mass function of luminous satellites to the steeply rising CDM subhalos mass function. After ruling out the hypothesis that the 11 well-known satellites are hosted by the 11 most massive subhalos, we show that models which account for the earliest-forming or most massive accreted objects better fit the observed mass function. We conclude that further analysis of newly-discovered dwarf satellites may provide additional powerful constraints on the CDM small-scale power spectrum and warm dark matter models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1817}
{"prompt": "Rephrase the abstract of an article with title '8.4GHz VLBI observations of SN2004et in NGC6946'.\n  We report on 8.4GHz Very Long Baseline Interferometry (VLBI) observations of\nthe type II-P supernova SN2004et in the spiral galaxy NGC 6946, made on 20\nFebruary 2005 (151 days after explosion). The Very Large Array (VLA) flux\ndensity was 1.23$\\pm$0.07 mJy, corresponding to an isotropic luminosity at\n8.4GHz of (4.45$\\pm$0.3)$\\times10^{25}$ erg s$^{-1}$ Hz$^{-1}$ and a brightness\ntemperature of (1.3$\\pm$0.3)$\\times10^{8}$ K. We also provide an improved\nsource position, accurate to about 0.5 mas in each coordinate. The VLBI image\nshows a clear asymmetry. From model fitting of the size of the radio emission,\nwe estimate a minimum expansion velocity of 15,700$\\pm$2,000 km s$^{-1}$. This\nvelocity is more than twice the expected mean expansion velocity estimated from\na synchrotron self-absorbed emission model, thus suggesting that synchrotron\nself-absorption is not relevant for this supernova. With the benefit of an\noptical spectrum obtained 12 days after explosion, we favor an emission model\nwhich consists of two hot spots on an underlying expanding shell of width\ncomparable to that of SN 1993J.\n\n", "human_text": "  We report on 8.4GHz Very Long Baseline Interferometry (VLBI) observations of\nthe type II-P supernova SN2004et in the spiral galaxy NGC 6946, made on 20\nFebruary 2005 (151 days after explosion). The Very Large Array (VLA) flux\ndensity was 1.23$\\pm$0.07 mJy, corresponding to an isotropic luminosity at\n8.4GHz of (4.45$\\pm$0.3)$\\times10^{25}$ erg s$^{-1}$ Hz$^{-1}$ and a brightness\ntemperature of (1.3$\\pm$0.3)$\\times10^{8}$ K. We also provide an improved\nsource position, accurate to about 0.5 mas in each coordinate. The VLBI image\nshows a clear asymmetry. From model fitting of the size of the radio emission,\nwe estimate a minimum expansion velocity of 15,700$\\pm$2,000 km s$^{-1}$. This\nvelocity is more than twice the expected mean expansion velocity estimated from\na synchrotron self-absorbed emission model, thus suggesting that synchrotron\nself-absorption is not relevant for this supernova. With the benefit of an\noptical spectrum obtained 12 days after explosion, we favor an emission model\nwhich consists of two hot spots on an underlying expanding shell of width\ncomparable to that of SN 1993J.\n", "machine_text": "\nThrough 8.4GHz very long baseline interferometry (VLBI) observation of type II-P supernova SN2004et in NGC 6946, we were able to measure an isotropic luminosity at 8.4GHz of (4.45$\\pm$0.3)$\\times10^{25}$ erg s$^{-1}$ Hz$^{-1}$, and a brightness temperature of (1.3$\\pm$0.3)$\\times10^{8}$ K. Model fitting of the size of the radio emission gave an estimated minimum expansion velocity of 15,700$\\pm$2,000 km s$^{-1}$. This is more than twice the estimated mean expansion velocity from a synchrotron self-absorbed emission model, indicating that such a model is not applicable for this supernova. From an optical spectrum twelve days after explosion, we propose an emission model made up of two hot spots on an expanding shell of comparable width to SN 1993J.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3853}
{"prompt": "Rephrase the abstract of an article with title 'Polymer Quantum Mechanics and its Continuum Limit'.\n  A rather non-standard quantum representation of the canonical commutation\nrelations of quantum mechanics systems, known as the polymer representation has\ngained some attention in recent years, due to its possible relation with Planck\nscale physics. In particular, this approach has been followed in a symmetric\nsector of loop quantum gravity known as loop quantum cosmology. Here we explore\ndifferent aspects of the relation between the ordinary Schroedinger theory and\nthe polymer description. The paper has two parts. In the first one, we derive\nthe polymer quantum mechanics starting from the ordinary Schroedinger theory\nand show that the polymer description arises as an appropriate limit. In the\nsecond part we consider the continuum limit of this theory, namely, the reverse\nprocess in which one starts from the discrete theory and tries to recover back\nthe ordinary Schroedinger quantum mechanics. We consider several examples of\ninterest, including the harmonic oscillator, the free particle and a simple\ncosmological model.\n\n", "human_text": "  A rather non-standard quantum representation of the canonical commutation\nrelations of quantum mechanics systems, known as the polymer representation has\ngained some attention in recent years, due to its possible relation with Planck\nscale physics. In particular, this approach has been followed in a symmetric\nsector of loop quantum gravity known as loop quantum cosmology. Here we explore\ndifferent aspects of the relation between the ordinary Schroedinger theory and\nthe polymer description. The paper has two parts. In the first one, we derive\nthe polymer quantum mechanics starting from the ordinary Schroedinger theory\nand show that the polymer description arises as an appropriate limit. In the\nsecond part we consider the continuum limit of this theory, namely, the reverse\nprocess in which one starts from the discrete theory and tries to recover back\nthe ordinary Schroedinger quantum mechanics. We consider several examples of\ninterest, including the harmonic oscillator, the free particle and a simple\ncosmological model.\n", "machine_text": "\nThis paper studies the connection between ordinary Schroedinger quantum mechanics and a non-standard representation known as polymer quantum mechanics, which has become the focus of interest in recent years due to its potential links to Planck scale physics. We first proceed in deducing polymer quantum mechanics from ordinary quantum mechanics by taking a particular limit, followed by a further consideration of the continuum limit, in which the process of going from the discrete to the Schroedinger description is explored. Resources are put into examining various relevant examples, such as the harmonic oscillator, a free particle and a simple cosmological model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0007}
{"prompt": "Rephrase the abstract of an article with title 'SW Sextantis stars: the dominant population of CVs with orbital periods\n  between 3-4 hours'.\n  [Abridged] We present time-series optical photometry of five new CVs\nidentified by the Hamburg Quasar Survey. The eclipses observed in HS 0129+2933,\nHS 0220+0603, and HS 0455+8315 provided very accurate orbital periods of\n3.35129827(65), 3.58098501(34), and 3.56937674(26) h, respectively. HS\n0805+3822 shows grazing eclipses and has a likely orbital period of 3.2169(2)\nh. Time-resolved optical spectroscopy of the new CVs (with the exception of HS\n0805+3822) is also presented. Radial velocity studies provided an orbital\nperiod of 3.55 h for HS 1813+6122, which allowed us to identify the observed\nphotometric signal at 3.39 h as a negative superhump wave. The spectroscopic\nbehaviour clearly identifies these new CVs as new SW Sextantis stars. These new\nadditions increase the number of known SW Sex stars to 35. Almost 40 per cent\nof the total SW Sex population do not show eclipses, invalidating the\nrequirement of eclipses as a defining characteristic of the class and the\nmodels based on a high orbital inclination geometry alone. On the other hand,\nthe predominance of orbital periods in the narrow 3-4.5 h range is becoming\nmore pronounced. In fact, almost half the CVs which populate the 3-4.5 h period\ninterval are definite members of the class. These statistics are confirmed by\nour results from the Hamburg Quasar Survey CVs. Remarkably, 54 per cent of the\nHamburg nova-like variables have been identified as SW Sex stars with orbital\nperiods in the 3-4.5 h range. The observation of this pile-up of systems close\nto the upper boundary of the period gap is difficult to reconcile with the\nstandard theory of CV evolution, as the SW Sex stars are believed to have the\nhighest mass transfer rates among CVs. Finally, we review the full range of\ncommon properties that the SW Sex stars exhibit.\n\n", "human_text": "  [Abridged] We present time-series optical photometry of five new CVs\nidentified by the Hamburg Quasar Survey. The eclipses observed in HS 0129+2933,\nHS 0220+0603, and HS 0455+8315 provided very accurate orbital periods of\n3.35129827(65), 3.58098501(34), and 3.56937674(26) h, respectively. HS\n0805+3822 shows grazing eclipses and has a likely orbital period of 3.2169(2)\nh. Time-resolved optical spectroscopy of the new CVs (with the exception of HS\n0805+3822) is also presented. Radial velocity studies provided an orbital\nperiod of 3.55 h for HS 1813+6122, which allowed us to identify the observed\nphotometric signal at 3.39 h as a negative superhump wave. The spectroscopic\nbehaviour clearly identifies these new CVs as new SW Sextantis stars. These new\nadditions increase the number of known SW Sex stars to 35. Almost 40 per cent\nof the total SW Sex population do not show eclipses, invalidating the\nrequirement of eclipses as a defining characteristic of the class and the\nmodels based on a high orbital inclination geometry alone. On the other hand,\nthe predominance of orbital periods in the narrow 3-4.5 h range is becoming\nmore pronounced. In fact, almost half the CVs which populate the 3-4.5 h period\ninterval are definite members of the class. These statistics are confirmed by\nour results from the Hamburg Quasar Survey CVs. Remarkably, 54 per cent of the\nHamburg nova-like variables have been identified as SW Sex stars with orbital\nperiods in the 3-4.5 h range. The observation of this pile-up of systems close\nto the upper boundary of the period gap is difficult to reconcile with the\nstandard theory of CV evolution, as the SW Sex stars are believed to have the\nhighest mass transfer rates among CVs. Finally, we review the full range of\ncommon properties that the SW Sex stars exhibit.\n", "machine_text": "\nThis paper discusses the results of a Hamburg Quasar Survey which identified five CVs. Photometric measurements of the eclipses allowed for the determination of very precise orbital periods of 3.35129827(65), 3.58098501(34), 3.56937674(26) h, and a likely period of 3.2169(2) h. Time-resolved optical spectroscopy also was conducted, which resulted in the identification of the CVs as SW Sextantis stars. The percentage of known SW Sex stars with orbital periods in the 3-4.5 h range is emphasized, and statistics are provided to back up this claim. An exploration of the common properties of SW Sex stars is included, as well as a discussion on why the pile-up of systems close to the upper boundary of this period gap is hard to explain in terms of the standard theory of CV evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1129}
{"prompt": "Rephrase the abstract of an article with title 'The Black Hole Mass - Spheroid Luminosity relation'.\n  The differing M_bh-Luminosity relations presented in McLure & Dunlop, Marconi\n& Hunt and Erwin et al. have been investigated. A number of issues have been\nidentified and addressed in each of these studies, including but not limited\nto: the removal of a dependency on the Hubble constant; a correction for dust\nattenuation in the bulges of disc galaxies; the identification of lenticular\ngalaxies previously treated as elliptical galaxies; and application of the same\n(Y|X) regression analysis. These adjustments result in relations which now\npredict similar black hole masses. The optimal K-band relation is\nlog(M_bh/M_sun) = -0.37(+/-0.04)[M_K +24] + 8.29(+/-0.08), with a total (not\nintrinsic) scatter in log M_bh equal to 0.33 dex. This level of scatter is\nsimilar to the value of 0.34 dex from the M_bh-sigma relation of Tremaine et\nal. and compares favourably with the value of 0.31 dex from the M_bh-n relation\nof Graham & Driver. Using different photometric data, consistent relations in\nthe B- and R-band are also provided, although we do note that the small (N=13)\nR-band sample used by Erwin et al. is found here to have a slope of\n-0.30(+/-0.06) and a total scatter of 0.31 dex. Performing a symmetrical\nregression on the larger K-band sample gives a slope of -0.40, implying M_bh ~\nL^{1.00}. Implications for galaxy-black hole coevolution, in terms of dry\nmergers, are briefly discussed, as are predictions for intermediate mass black\nholes. Finally, as previously noted by Tundo et al., a potential bias in the\ngalaxy sample used to define the M_bh-L relations is shown and a corrective\nformula provided.\n\n", "human_text": "  The differing M_bh-Luminosity relations presented in McLure & Dunlop, Marconi\n& Hunt and Erwin et al. have been investigated. A number of issues have been\nidentified and addressed in each of these studies, including but not limited\nto: the removal of a dependency on the Hubble constant; a correction for dust\nattenuation in the bulges of disc galaxies; the identification of lenticular\ngalaxies previously treated as elliptical galaxies; and application of the same\n(Y|X) regression analysis. These adjustments result in relations which now\npredict similar black hole masses. The optimal K-band relation is\nlog(M_bh/M_sun) = -0.37(+/-0.04)[M_K +24] + 8.29(+/-0.08), with a total (not\nintrinsic) scatter in log M_bh equal to 0.33 dex. This level of scatter is\nsimilar to the value of 0.34 dex from the M_bh-sigma relation of Tremaine et\nal. and compares favourably with the value of 0.31 dex from the M_bh-n relation\nof Graham & Driver. Using different photometric data, consistent relations in\nthe B- and R-band are also provided, although we do note that the small (N=13)\nR-band sample used by Erwin et al. is found here to have a slope of\n-0.30(+/-0.06) and a total scatter of 0.31 dex. Performing a symmetrical\nregression on the larger K-band sample gives a slope of -0.40, implying M_bh ~\nL^{1.00}. Implications for galaxy-black hole coevolution, in terms of dry\nmergers, are briefly discussed, as are predictions for intermediate mass black\nholes. Finally, as previously noted by Tundo et al., a potential bias in the\ngalaxy sample used to define the M_bh-L relations is shown and a corrective\nformula provided.\n", "machine_text": "In this study, the Black Hole Mass-Spheroid Luminosity relation is investigated by evaluating the differences in the M_bh-Luminosity relations proposed by McLure & Dunlop, Marconi & Hunt and Erwin et al. Variance in these equations due to factors such as dust attenuation, the inclusion of lenticular galaxies and the same (Y|X) regressional analysis are appraised. Adjustments made, ultimately produce a relation that yields consistent black hole masses. Analysis of K, B and R-bands yields corresponding M_bh-L relations. Discussion of the implications for dry mergers, intermediate mass black holes and a potential sample selection bias follow. An expression for correction is provided in order to rectify the bias.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0618}
{"prompt": "Rephrase the abstract of an article with title 'Relativistic Fluctuation Theorems: Theory and explicit examples'.\n  To reveal how nonequilibrium physics and relativity theory intertwine, this\narticles studies relativistic Brownian motion under cosmic expansion. Two\nfluctuation theorems for the entropy ds, which is locally produced in this\nextreme nonequilibrium situation, are presented and proven. The first,\n<exp(-ds)>=1, is a generalization of the second law of thermodynamics, that\nremains valid at relativistic particle energies and under high cosmic expansion\nrates. From this relation follows, that the probability to observe a local\nreduction of entropy is exponentially small even if the universe was to\nrecollapse. For the special case of the Einstein-de Sitter universe an\nadditional relation, <exp(-ds-dh)>=1, is derived which holds simultaneously\nwith the first relation and where dh is proportional to the Hubble constant.\nFurthermore, the fluctuation theorems are shown to provide a physical criterion\nto resolve the known discretization dilemma arising in special-relativistic\nBrownian motion. Explicit examples and a general method for the computation of\nnon-Gaussian entropy fluctuations are provided.\n\n", "human_text": "  To reveal how nonequilibrium physics and relativity theory intertwine, this\narticles studies relativistic Brownian motion under cosmic expansion. Two\nfluctuation theorems for the entropy ds, which is locally produced in this\nextreme nonequilibrium situation, are presented and proven. The first,\n<exp(-ds)>=1, is a generalization of the second law of thermodynamics, that\nremains valid at relativistic particle energies and under high cosmic expansion\nrates. From this relation follows, that the probability to observe a local\nreduction of entropy is exponentially small even if the universe was to\nrecollapse. For the special case of the Einstein-de Sitter universe an\nadditional relation, <exp(-ds-dh)>=1, is derived which holds simultaneously\nwith the first relation and where dh is proportional to the Hubble constant.\nFurthermore, the fluctuation theorems are shown to provide a physical criterion\nto resolve the known discretization dilemma arising in special-relativistic\nBrownian motion. Explicit examples and a general method for the computation of\nnon-Gaussian entropy fluctuations are provided.\n", "machine_text": "\nIn this article, two relativistic fluctuation theorems pertaining to entropy ds which is locally produced as a consequence of nonequilibrium physics and relativity theory are examined. The first theorem, <exp(-ds)>=1, is a generalization of the second law of thermodynamics with the capability to remain valid in the presence of relativistic particle energies and high cosmic expansion rates. Additionally, the special case of the Einstein-de Sitter universe offers an additional relation known as <exp(-ds-dh)>=1, where dh is proportional to the Hubble constant, which simultaneously holds with the first theorem. Furthermore, the fluctuation theorems risk providing an answer to a discretization dilemma arising from special-relativistic Brownian motion. Examples of these theorems as well as a method for computing non-Gaussian entropy fluctuations are also provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3115}
{"prompt": "Rephrase the abstract of an article with title 'Koszul duality in deformation quantization, I'.\n  Let $\\alpha$ be a polynomial Poisson bivector on a finite-dimensional vector\nspace $V$ over $\\mathbb{C}$. Then Kontsevich [K97] gives a formula for a\nquantization $f\\star g$ of the algebra $S(V)^*$. We give a construction of an\nalgebra with the PBW property defined from $\\alpha$ by generators and\nrelations. Namely, we define an algebra as the quotient of the free tensor\nalgebra $T(V^*)$ by relations $x_i\\otimes x_j-x_j\\otimes x_i=R_{ij}(\\hbar)$\nwhere $R_{ij}(\\hbar)\\in T(V^*)\\otimes\\hbar \\mathbb{C}[[\\hbar]]$, $R_{ij}=\\hbar\n\\Sym(\\alpha_{ij})+\\mathcal{O}(\\hbar^2)$, with one relation for each pair of\n$i,j=1...\\dim V$. We prove that the constructed algebra obeys the PBW property,\nand this is a generalization of the Poincar\\'{e}-Birkhoff-Witt theorem. In the\ncase of a linear Poisson structure we get the PBW theorem itself, and for a\nquadratic Poisson structure we get an object closely related to a quantum\n$R$-matrix on $V$. At the same time we get a free resolution of the deformed\nalgebra (for an arbitrary $\\alpha$).\n  The construction of this PBW algebra is rather simple, as well as the proof\nof the PBW property. The major efforts should be undertaken to prove the\nconjecture that in this way we get an algebra isomorphic to the Kontsevich\nstar-algebra.\n\n", "human_text": "  Let $\\alpha$ be a polynomial Poisson bivector on a finite-dimensional vector\nspace $V$ over $\\mathbb{C}$. Then Kontsevich [K97] gives a formula for a\nquantization $f\\star g$ of the algebra $S(V)^*$. We give a construction of an\nalgebra with the PBW property defined from $\\alpha$ by generators and\nrelations. Namely, we define an algebra as the quotient of the free tensor\nalgebra $T(V^*)$ by relations $x_i\\otimes x_j-x_j\\otimes x_i=R_{ij}(\\hbar)$\nwhere $R_{ij}(\\hbar)\\in T(V^*)\\otimes\\hbar \\mathbb{C}[[\\hbar]]$, $R_{ij}=\\hbar\n\\Sym(\\alpha_{ij})+\\mathcal{O}(\\hbar^2)$, with one relation for each pair of\n$i,j=1...\\dim V$. We prove that the constructed algebra obeys the PBW property,\nand this is a generalization of the Poincar\\'{e}-Birkhoff-Witt theorem. In the\ncase of a linear Poisson structure we get the PBW theorem itself, and for a\nquadratic Poisson structure we get an object closely related to a quantum\n$R$-matrix on $V$. At the same time we get a free resolution of the deformed\nalgebra (for an arbitrary $\\alpha$).\n  The construction of this PBW algebra is rather simple, as well as the proof\nof the PBW property. The major efforts should be undertaken to prove the\nconjecture that in this way we get an algebra isomorphic to the Kontsevich\nstar-algebra.\n", "machine_text": "\nIn this article, we consider a polynomial Poisson bivector $\\alpha$ on a finite-dimensional vector space $V$ over $\\mathbb{C}$. We present a construction of an algebra with the PBW (Poincar\\'{e}-Bihkoff-Witt) property from $\\alpha$ that is defined by generators and relations. Namely, we show how to construct a quotient of the free tensor algebra $T(V^*)$ given by relations $x_i\\otimes x_j-x_j\\otimes x_i=R_{ij}(\\hbar)$, where $R_{ij}(\\hbar)\\in T(V^*) \\otimes \\hbar \\mathbb{C}[[\\hbar]]$ and $R_{ij} = \\hbar \\Sym(\\alpha_{ij})+ \\mathcal{O} (\\hbar^2)$. Here, there is one relation for each pair $i,j=1...\\dim V$. Additionally, we prove that this defined algebra obeys the PBW property, which is an extension of the Poincar\\'{e}-Birkhoff-Witt theorem. Further, the case of a linear Poisson structure gives the PBW theorem itself, and a quadratic Poisson structure gives an object closely related to a quantum $R$-matrix on $V$. In the same light, we obtain a free resolution of the deformed algebra (for an arbitrary $\\alpha$). \nWhile the construction of the PBW algebra is simple and the proof of the PBW property is straightforward, more effort is needed to prove the conjecture that in this way we can obtain an isomorphic algebra to the Kontsevich star-algebra.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2381}
{"prompt": "Rephrase the abstract of an article with title 'Symmetries in Differential Geometry: A Computational Approach to\n  Prolongations'.\n  The aim of this work is to develop a systematic manner to close\noverdetermined systems arising from conformal Killing tensors (CKT). The\nresearch performs this action for 1-tensor and 2-tensors. This research makes\nit possible to develop a new general method for any rank of CKT. This method\ncan also be applied to other types of Killing equations, as well as to\noverdetermined systems constrained by some other conditions.\n  The major methodological apparatus of the research is a decomposition of the\nsection bundles where the covariant derivatives of the CKT land via generalized\ngradients. This decomposition generates a tree in which each row represents a\nhigher derivative. After using the conformal Killing equation, just a few\ncomponents (branches) survive, which means that most of them can be expressed\nin terms of lower order terms. This results in a finite number of independent\njets. Thus, any higher covariant derivative can be written in terms of these\njets.\n  The findings of this work are significant methodologically and, more\nspecifically, in the potential for the discovery of symmetries. First, this\nwork has uncovered a new method that could be used to close overdetermined\nsystems arising from conformal Killing tensors (CKT). Second, through an\napplication of this method, this research finds higher symmetry operators of\nfirst and second degree, which are known by other means, for the Laplace\noperator. The findings also reveal the first order symmetry operators for the\nYamabe case. Moreover, the research leads to conjectures about the second order\nsymmetries of the Yamabe operator.\n\n", "human_text": "  The aim of this work is to develop a systematic manner to close\noverdetermined systems arising from conformal Killing tensors (CKT). The\nresearch performs this action for 1-tensor and 2-tensors. This research makes\nit possible to develop a new general method for any rank of CKT. This method\ncan also be applied to other types of Killing equations, as well as to\noverdetermined systems constrained by some other conditions.\n  The major methodological apparatus of the research is a decomposition of the\nsection bundles where the covariant derivatives of the CKT land via generalized\ngradients. This decomposition generates a tree in which each row represents a\nhigher derivative. After using the conformal Killing equation, just a few\ncomponents (branches) survive, which means that most of them can be expressed\nin terms of lower order terms. This results in a finite number of independent\njets. Thus, any higher covariant derivative can be written in terms of these\njets.\n  The findings of this work are significant methodologically and, more\nspecifically, in the potential for the discovery of symmetries. First, this\nwork has uncovered a new method that could be used to close overdetermined\nsystems arising from conformal Killing tensors (CKT). Second, through an\napplication of this method, this research finds higher symmetry operators of\nfirst and second degree, which are known by other means, for the Laplace\noperator. The findings also reveal the first order symmetry operators for the\nYamabe case. Moreover, the research leads to conjectures about the second order\nsymmetries of the Yamabe operator.\n", "machine_text": "This article explores a computational approach to uncovering symmetries in differential geometry arising from conformal Killing tensors (CKT). Specifically, the aim of this research is to develop a systematic approach to reduce the number of components required to solve overdetermined systems of differential equations within the CKT framework. Through a decomposition of the section bundles, a structure is developed which generates a tree in which each row represents a higher derivative. With the use of the conformal Killing equation, a finite number of independent jets is found which express any first or second order covariant derivatives. The outcome of the proposed method is a heightened discovery of symmetry operators at first and second degree, as well as revealing the first order symmetry operators of the Yamabe case. Additionally, the discovery of these processes has led to further conjectures about the second order symmetry operators of the Yamabe operator.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0764}
{"prompt": "Rephrase the abstract of an article with title 'On the stratified dust distribution of the GG Tau circumbinary ring'.\n  Our objective is to study the vertical dust distribution in the circumbinary\nring of the binary system GG Tau and to search for evidence of stratification,\none of the first steps expected to occur during planet formation.\n  We present a simultaneous analysis of four scattered light images spanning a\nrange of wavelength from 800 nm to 3800 nm and compare them with (i) a\nparametric prescription for the vertical dust stratification, and (ii) with the\nresults of SPH bi-fluid hydrodynamic calculations.\n  The parametric prescription and hydrodynamical calculations of stratification\nboth reproduce the observed brightness profiles well. These models also provide\na correct match for the observed star/ring integrated flux ratio. Another\nsolution with a well-mixed, but ``exotic'', dust size distribution also matches\nthe brightness profile ratios but fails to match the star/ring flux ratio.\nThese results give support to the presence of vertical stratification of the\ndust in the ring of GG Tau and further predict the presence of a radial\nstratification also.\n\n", "human_text": "  Our objective is to study the vertical dust distribution in the circumbinary\nring of the binary system GG Tau and to search for evidence of stratification,\none of the first steps expected to occur during planet formation.\n  We present a simultaneous analysis of four scattered light images spanning a\nrange of wavelength from 800 nm to 3800 nm and compare them with (i) a\nparametric prescription for the vertical dust stratification, and (ii) with the\nresults of SPH bi-fluid hydrodynamic calculations.\n  The parametric prescription and hydrodynamical calculations of stratification\nboth reproduce the observed brightness profiles well. These models also provide\na correct match for the observed star/ring integrated flux ratio. Another\nsolution with a well-mixed, but ``exotic'', dust size distribution also matches\nthe brightness profile ratios but fails to match the star/ring flux ratio.\nThese results give support to the presence of vertical stratification of the\ndust in the ring of GG Tau and further predict the presence of a radial\nstratification also.\n", "machine_text": "\nWe seek to explore the stratified makeup of the GG Tau circumbinary ring through scrutiny of four different scattered light images from the 800 to 3800 nm range. This process allows us to compare two models of stratification--a parametric prescription and bi-fluid hydrostatic calculations--in order to discern any evidence it may present. The two models seem to replicate the data accurately, with the parametric prescription matching the brightness profile and the hydrostatic calculations correctly accounting for star/ring integrated flux. An alternate solution of a well-mixed, yet \"irregular\" dust size distribution fits the brightness profile but not the star/ring flux ratio. This research provides evidence of dust stratification in the GG Tau ring and suggests that a radial stratification is likely present as well.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2747}
{"prompt": "Rephrase the abstract of an article with title 'Recursive calculation of effective resistances in distance-regular\n  networks based on Bose-Mesner algebra and Christoffel-Darboux identity'.\n  Recently in \\cite{jss1}, the authors have given a method for calculation of\nthe effective resistance (resistance distance) on distance-regular networks,\nwhere the calculation was based on stratification introduced in \\cite{js} and\nStieltjes transform of the spectral distribution (Stieltjes function)\nassociated with the network. Also, in Ref. \\cite{jss1} it has been shown that\nthe resistance distances between a node $\\alpha$ and all nodes $\\beta$\nbelonging to the same stratum with respect to the $\\alpha$\n($R_{\\alpha\\beta^{(i)}}$, $\\beta$ belonging to the $i$-th stratum with respect\nto the $\\alpha$) are the same. In this work, an algorithm for recursive\ncalculation of the resistance distances in an arbitrary distance-regular\nresistor network is provided, where the derivation of the algorithm is based on\nthe Bose-Mesner algebra, stratification of the network, spectral techniques and\nChristoffel-Darboux identity. It is shown that the effective resistance on a\ndistance-regular network is an strictly increasing function of the shortest\npath distance defined on the network. In the other words, the two-point\nresistance $R_{\\alpha\\beta^{(m+1)}}$ is strictly larger than\n$R_{\\alpha\\beta^{(m)}}$. The link between the resistance distance and random\nwalks on distance-regular networks is discussed, where the average commute time\n(CT) and its square root (called Euclidean commute time (ECT)) as a distance\nare related to the effective resistance. Finally, for some important examples\nof finite distance- regular networks, the resistance distances are calculated.\n  {\\bf Keywords: resistance distance, association scheme, stratification,\ndistance-regular networks, Christoffel-Darboux identity}\n  {\\bf PACs Index: 01.55.+b, 02.10.Yn}\n\n", "human_text": "  Recently in \\cite{jss1}, the authors have given a method for calculation of\nthe effective resistance (resistance distance) on distance-regular networks,\nwhere the calculation was based on stratification introduced in \\cite{js} and\nStieltjes transform of the spectral distribution (Stieltjes function)\nassociated with the network. Also, in Ref. \\cite{jss1} it has been shown that\nthe resistance distances between a node $\\alpha$ and all nodes $\\beta$\nbelonging to the same stratum with respect to the $\\alpha$\n($R_{\\alpha\\beta^{(i)}}$, $\\beta$ belonging to the $i$-th stratum with respect\nto the $\\alpha$) are the same. In this work, an algorithm for recursive\ncalculation of the resistance distances in an arbitrary distance-regular\nresistor network is provided, where the derivation of the algorithm is based on\nthe Bose-Mesner algebra, stratification of the network, spectral techniques and\nChristoffel-Darboux identity. It is shown that the effective resistance on a\ndistance-regular network is an strictly increasing function of the shortest\npath distance defined on the network. In the other words, the two-point\nresistance $R_{\\alpha\\beta^{(m+1)}}$ is strictly larger than\n$R_{\\alpha\\beta^{(m)}}$. The link between the resistance distance and random\nwalks on distance-regular networks is discussed, where the average commute time\n(CT) and its square root (called Euclidean commute time (ECT)) as a distance\nare related to the effective resistance. Finally, for some important examples\nof finite distance- regular networks, the resistance distances are calculated.\n  {\\bf Keywords: resistance distance, association scheme, stratification,\ndistance-regular networks, Christoffel-Darboux identity}\n  {\\bf PACs Index: 01.55.+b, 02.10.Yn}\n", "machine_text": "\nThis article presents an algorithm for the recursive calculation of effective resistances in distance-regular networks, which takes into account the Bose-Mesner algebra, stratification of the network, spectral techniques and the Christoffel-Darboux identity. It is argued that the resistance distance between two nodes on the network is an strictly increasing function of the shortest path distance. Furthermore, a connection between the resistance distance and random walks is explored, linking the average commute time and its square root to the effective resistance. Results of the algorithm are also given for several important examples of finite distance-regular networks.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.248}
{"prompt": "Rephrase the abstract of an article with title 'Supersymmetric Q Solitons of Arbitrary Genus'.\n  We construct \"Flying Saucer\" solitons in supersymmetric N=2 gauge theory\nwhich is known to support BPS domain walls with a U(1) gauge field localized on\nits worldvolume. We demonstrate that this model supports exotic particle-like\nsolitons whose topology is largely arbitrary: closed orientable surfaces in\nthree-dimensional space which can have arbitrary genus. In particular, we focus\non Q tori. Q tori and similar solitons of higher genera are obtained by folding\nthe domain wall into an appropriate surface. Nontrivial cycles on the domain\nwall worldvolume (handles) are stabilized by crossed electric and magnetic\nfields inside the folded domain wall. Three distinct frameworks are used to\nprove the existence of these Flying Saucer solitons and study their properties:\nthe worldvolume description (including the Dirac-Born-Infeld action), the bulk\ntheory description in the sigma-model limit, and the bulk theory description in\nthe thin-edge approximation. In the sigma-model framework the Q torus is shown\nto be related to the Hopf Skyrmion studied previously.\n\n", "human_text": "  We construct \"Flying Saucer\" solitons in supersymmetric N=2 gauge theory\nwhich is known to support BPS domain walls with a U(1) gauge field localized on\nits worldvolume. We demonstrate that this model supports exotic particle-like\nsolitons whose topology is largely arbitrary: closed orientable surfaces in\nthree-dimensional space which can have arbitrary genus. In particular, we focus\non Q tori. Q tori and similar solitons of higher genera are obtained by folding\nthe domain wall into an appropriate surface. Nontrivial cycles on the domain\nwall worldvolume (handles) are stabilized by crossed electric and magnetic\nfields inside the folded domain wall. Three distinct frameworks are used to\nprove the existence of these Flying Saucer solitons and study their properties:\nthe worldvolume description (including the Dirac-Born-Infeld action), the bulk\ntheory description in the sigma-model limit, and the bulk theory description in\nthe thin-edge approximation. In the sigma-model framework the Q torus is shown\nto be related to the Hopf Skyrmion studied previously.\n", "machine_text": "\n\nWe investigate supersymmetric N=2 gauge theory which features BPS domain walls with an included U(1) gauge field localized on its worldvolume. We explore the dynamic properties of some new particle-like solitons, whose topologies can have any arbitrary genus. We particularly consider the Q tori solitons, which we refer to as \u2018Flying Saucer' solitons. These are generated by folding the domain wall into an appropriate surface and stabilized through crossed electric and magnetic fields. To analyze the character of these Q tori, we construct three distinct frameworks: a worldvolume description, a bulk theory description in the sigma-model limit, and a bulk theory description furnished in the thin-edge approximation. Through investigation of these, we uncover a link between the Q torus and Hopf Skyrmion previously studied.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0379}
{"prompt": "Rephrase the abstract of an article with title 'Black Hole Evaporation in an Expanding Universe'.\n  We calculate the quantum radiation power of black holes which are asymptotic\nto the Einstein-de Sitter universe at spatial and null infinities. We consider\ntwo limiting mass accretion scenarios, no accretion and significant accretion.\nWe find that the radiation power strongly depends on not only the asymptotic\ncondition but also the mass accretion scenario. For the no accretion case, we\nconsider the Einstein-Straus solution, where a black hole of constant mass\nresides in the dust Friedmann universe. We find negative cosmological\ncorrection besides the expected redshift factor. This is given in terms of the\ncubic root of ratio in size of the black hole to the cosmological horizon, so\nthat it is currently of order $10^{-5} (M/10^{6}M_{\\odot})^{1/3} (t/14\n{Gyr})^{-1/3}$ but could have been significant at the formation epoch of\nprimordial black holes. Due to the cosmological effects, this black hole has\nnot settled down to an equilibrium state. This cosmological correction may be\ninterpreted in an analogy with the radiation from a moving mirror in a flat\nspacetime. For the significant accretion case, we consider the Sultana-Dyer\nsolution, where a black hole tends to increase its mass in proportion to the\ncosmological scale factor. In this model, we find that the radiation power is\napparently the same as the Hawking radiation from the Schwarzschild black hole\nof which mass is that of the growing mass at each moment. Hence, the energy\nloss rate decreases and tends to vanish as time proceeds. Consequently, the\nenergy loss due to evaporation is insignificant compared to huge mass accretion\nonto the black hole. Based on this model, we propose a definition of\nquasi-equilibrium temperature for general conformal stationary black holes.\n\n", "human_text": "  We calculate the quantum radiation power of black holes which are asymptotic\nto the Einstein-de Sitter universe at spatial and null infinities. We consider\ntwo limiting mass accretion scenarios, no accretion and significant accretion.\nWe find that the radiation power strongly depends on not only the asymptotic\ncondition but also the mass accretion scenario. For the no accretion case, we\nconsider the Einstein-Straus solution, where a black hole of constant mass\nresides in the dust Friedmann universe. We find negative cosmological\ncorrection besides the expected redshift factor. This is given in terms of the\ncubic root of ratio in size of the black hole to the cosmological horizon, so\nthat it is currently of order $10^{-5} (M/10^{6}M_{\\odot})^{1/3} (t/14\n{Gyr})^{-1/3}$ but could have been significant at the formation epoch of\nprimordial black holes. Due to the cosmological effects, this black hole has\nnot settled down to an equilibrium state. This cosmological correction may be\ninterpreted in an analogy with the radiation from a moving mirror in a flat\nspacetime. For the significant accretion case, we consider the Sultana-Dyer\nsolution, where a black hole tends to increase its mass in proportion to the\ncosmological scale factor. In this model, we find that the radiation power is\napparently the same as the Hawking radiation from the Schwarzschild black hole\nof which mass is that of the growing mass at each moment. Hence, the energy\nloss rate decreases and tends to vanish as time proceeds. Consequently, the\nenergy loss due to evaporation is insignificant compared to huge mass accretion\nonto the black hole. Based on this model, we propose a definition of\nquasi-equilibrium temperature for general conformal stationary black holes.\n", "machine_text": "\nWe evaluate the emission of quantum radiation from black holes which are asymptotically close to an Einstein-de Sitter universe. We compare two different scenarios: no accretion, and significant accretion. The radiation power is highly dependent on the asymptotic condition and this mass accretion status. In the no accretion case, we analyze the Einstein-Straus solution where the black hole has a fixed mass within a Friedmann universe of dust. A cosmological correction shows that at present, it's a tiny amount ($10^{-5} (M/10^{6}M_{\\odot})^{1/3} (t/14 {Gyr})^{-1/3}$) but could have been influential when the primordial black holes formed. This implies that the black hole has not reached equilibrium yet, and this effect may be linked to radiation released from a flat spacetime by a moving mirror. For significant accretion, we look at the Sultana-Dyer solution, which states that the black hole grows in size in proportion to the cosmological scale factor. We find that the radiation power is comparable to Hawking radiation from a Schwarzschild black hole of the same, growing mass. This means that the energy loss due to evaporation is minuscule when compared to the mass accumulated by the black hole. As a result this research suggests a new definition of the quasi-equilibrium temperature of general conformal stationary black holes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4012}
{"prompt": "Rephrase the abstract of an article with title 'Softening of the stiffness of bottlebrush polymers by mutual interaction'.\n  We study bottlebrush macromolecules in a good solvent by small-angle neutron\nscattering (SANS), static light scattering (SLS), and dynamic light scattering\n(DLS). These polymers consist of a linear backbone to which long side chains\nare chemically grafted. The backbone contains about 1600 monomer units (weight\naverage) and every second monomer unit carries side-chains with ca. 60 monomer\nunits. The SLS- and SANS data extrapolated to infinite dilution lead to the\nform factor of the polymer that can be described in terms of a worm-like chain\nwith a contour length of 380 nm and a persistence length of 17.5 nm. An\nanalysis of the DLS data confirm these model parameters. The scattering\nintensities taken at finite concentration can be modeled using the polymer\nreference interaction site model. It reveals a softening of the bottlebrush\npolymers caused by their mutual interaction. We demonstrate that the\npersistence decreases from 17.5 nm down to 5 nm upon increasing the\nconcentration from dilute solution to the highest concentration 40.59 g/l under\nconsideration. The observed softening of the chains is comparable to the\ntheoretically predicted decrease of the electrostatic persistence length of\nlinear polyelectrolyte chains at finite concentrations.\n\n", "human_text": "  We study bottlebrush macromolecules in a good solvent by small-angle neutron\nscattering (SANS), static light scattering (SLS), and dynamic light scattering\n(DLS). These polymers consist of a linear backbone to which long side chains\nare chemically grafted. The backbone contains about 1600 monomer units (weight\naverage) and every second monomer unit carries side-chains with ca. 60 monomer\nunits. The SLS- and SANS data extrapolated to infinite dilution lead to the\nform factor of the polymer that can be described in terms of a worm-like chain\nwith a contour length of 380 nm and a persistence length of 17.5 nm. An\nanalysis of the DLS data confirm these model parameters. The scattering\nintensities taken at finite concentration can be modeled using the polymer\nreference interaction site model. It reveals a softening of the bottlebrush\npolymers caused by their mutual interaction. We demonstrate that the\npersistence decreases from 17.5 nm down to 5 nm upon increasing the\nconcentration from dilute solution to the highest concentration 40.59 g/l under\nconsideration. The observed softening of the chains is comparable to the\ntheoretically predicted decrease of the electrostatic persistence length of\nlinear polyelectrolyte chains at finite concentrations.\n", "machine_text": "\nUsing various analytical methods (SANS, SLS & DLS), we investigate the effect of mutual interaction on the stiffness of bottlebrush macromolecules in a good solvent. The macromolecules monitored consist of a linear backbone with long side chains chemically attached, containing 1600 average monomer units (each second one having 60 monomer units). According to the theoretical model derived from the SLS & SANS extrapolated data, the contour length of the polymer is 380 nm and the persistence length is 17.5 nm. Examining the DLS data confirms these model parameters. The polymer reference interaction site model applied to the scattering intensities at finite concentrations unveils a softening of the bottlebrush polymers caused by their mutual interaction. This phenomenon of softening results in a decrease of persistence from 17.5 nm to 5 nm as the concentration increases from dilute solution to 40.59 g/l. The decrease in persistence length is similar to the electrostatic decay of linear polyelectrolyte chains attributed to finite concentrations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3329}
{"prompt": "Rephrase the abstract of an article with title 'Deriving temperature, mass and age of evolved stars from high-resolution\n  spectra. Application to field stars and the open cluster IC 4651'.\n  We test our capability of deriving stellar physical parameters of giant stars\nby analysing a sample of field stars and the well studied open cluster IC 4651\nwith different spectroscopic methods. The use of a technique based on\nline-depth ratios (LDRs) allows us to determine with high precision the\neffective temperature of the stars and to compare the results with those\nobtained with a classical LTE abundance analysis. (i) For the field stars we\nfind that the temperatures derived by means of the LDR method are in excellent\nagreement with those found by the spectral synthesis. This result is extremely\nencouraging because it shows that spectra can be used to firmly derive\npopulation characteristics (e.g., mass and age) of the observed stars. (ii) For\nthe IC 4651 stars we use the determined effective temperature to derive the\nfollowing results. a) The reddening E(B-V) of the cluster is 0.12+/-0.02,\nlargely independent of the color-temperature calibration used. b) The age of\nthe cluster is 1.2+/-0.2 Gyr. c) The typical mass of the analysed giant stars\nis 2.0+/-0.2M_sun. Moreover, we find a systematic difference of about 0.2 dex\nin log g between spectroscopic and evolutionary values. We conclude that, in\nspite of known limitations, a classical spectroscopic analysis of giant stars\nmay indeed result in very reliable stellar parameters. We caution that the\nquality of the agreement, on the other hand, depends on the details of the\nadopted spectroscopic analysis.\n\n", "human_text": "  We test our capability of deriving stellar physical parameters of giant stars\nby analysing a sample of field stars and the well studied open cluster IC 4651\nwith different spectroscopic methods. The use of a technique based on\nline-depth ratios (LDRs) allows us to determine with high precision the\neffective temperature of the stars and to compare the results with those\nobtained with a classical LTE abundance analysis. (i) For the field stars we\nfind that the temperatures derived by means of the LDR method are in excellent\nagreement with those found by the spectral synthesis. This result is extremely\nencouraging because it shows that spectra can be used to firmly derive\npopulation characteristics (e.g., mass and age) of the observed stars. (ii) For\nthe IC 4651 stars we use the determined effective temperature to derive the\nfollowing results. a) The reddening E(B-V) of the cluster is 0.12+/-0.02,\nlargely independent of the color-temperature calibration used. b) The age of\nthe cluster is 1.2+/-0.2 Gyr. c) The typical mass of the analysed giant stars\nis 2.0+/-0.2M_sun. Moreover, we find a systematic difference of about 0.2 dex\nin log g between spectroscopic and evolutionary values. We conclude that, in\nspite of known limitations, a classical spectroscopic analysis of giant stars\nmay indeed result in very reliable stellar parameters. We caution that the\nquality of the agreement, on the other hand, depends on the details of the\nadopted spectroscopic analysis.\n", "machine_text": "\nWe analyse a sample of stars from both field stars and the well-studied open cluster IC 4651 with diverse spectroscopic methods to identify their physical parameters. We use a line-depth ratio (LDR) based technique to precisely calculate the effective temperatures, which we compare to those obtained through a classical LTE abundance approach. (i) For the field stars, the LDR-determined temperatures are found to be strongly in accordance with the temperatures assessed by a spectral synthesis; proving that spectra actually provide us with population characteristics such as mass and age. (ii) For IC 4651, we derive a reddening value of E(B-V) = 0.12 \u00b1 0.02, independent from the employed colour-temperature calibration, an age of 1.2 \u00b1 0.2 Gyr, and further a mean mass of 2.0 \u00b1 0.2 M_sun for the examined giants. Additionally, we detect a systemic difference of around 0.2 dex for the log g between the derived spectroscopic and evolutionary values. Ultimately, we determine that, despite the limitations, spectroscopic treatments of giant stars essentially lead to dependable stellar parameters\u2014while the magnitude of consistency essentially hinges on the details of the adopted spectroscopic approach.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3192}
{"prompt": "Rephrase the abstract of an article with title 'Nonlinear Evolution of Baryon Acoustic Oscillations'.\n  We study the nonlinear evolution of the baryon acoustic oscillations (BAO) in\nthe dark matter power spectrum and correlation function using renormalized\nperturbation theory (RPT). In a previous paper we showed that RPT successfully\npredicts the damping of acoustic oscillations; here we extend our calculation\nto the enhancement of power due to mode-coupling. We show that mode-coupling\ngenerates additional oscillations that are out of phase with those in the\nlinear spectrum, leading to shifts in the scales of oscillation nodes defined\nwith respect to a smooth spectrum. When Fourier transformed, these out of phase\noscillations induce percent-level shifts in the acoustic peak of the two-point\ncorrelation function. We present predictions for these shifts as a function of\nredshift; these should be considered as a robust lower limit to the more\nrealistic case that includes in addition redshift distortions and galaxy bias.\nWe show that these nonlinear effects occur at very large scales, leading to a\nbreakdown of linear theory at scales much larger than commonly thought. We\ndiscuss why virialized halo profiles are not responsible for these effects,\nwhich can be understood from basic physics of gravitational instability. Our\nresults are in excellent agreement with numerical simulations, and can be used\nas a starting point for modeling BAO in future observations. To meet this end,\nwe suggest a simple physically motivated model to correct for the shifts caused\nby mode-coupling.\n\n", "human_text": "  We study the nonlinear evolution of the baryon acoustic oscillations (BAO) in\nthe dark matter power spectrum and correlation function using renormalized\nperturbation theory (RPT). In a previous paper we showed that RPT successfully\npredicts the damping of acoustic oscillations; here we extend our calculation\nto the enhancement of power due to mode-coupling. We show that mode-coupling\ngenerates additional oscillations that are out of phase with those in the\nlinear spectrum, leading to shifts in the scales of oscillation nodes defined\nwith respect to a smooth spectrum. When Fourier transformed, these out of phase\noscillations induce percent-level shifts in the acoustic peak of the two-point\ncorrelation function. We present predictions for these shifts as a function of\nredshift; these should be considered as a robust lower limit to the more\nrealistic case that includes in addition redshift distortions and galaxy bias.\nWe show that these nonlinear effects occur at very large scales, leading to a\nbreakdown of linear theory at scales much larger than commonly thought. We\ndiscuss why virialized halo profiles are not responsible for these effects,\nwhich can be understood from basic physics of gravitational instability. Our\nresults are in excellent agreement with numerical simulations, and can be used\nas a starting point for modeling BAO in future observations. To meet this end,\nwe suggest a simple physically motivated model to correct for the shifts caused\nby mode-coupling.\n", "machine_text": "\nWe explore the nonlinear evolution of baryon acoustic oscillations (BAO) in\nthe dark matter power spectrum and correlation function using renormalized\nperturbation theory (RPT). In our prior study, we showed that RPT effectively\ndescribes the damping of acoustic oscillations. We extend this investigation in\norder to quantify the increase in power which is brought about by\nmode-coupling. We find that the mode-coupling produces additional, out of\nphase oscillations, leading to changes of node positions, when compared to a\nsmooth spectrum. Upon Fourier transforming, these oscillations contribute to\nthe correlation function and induce percent-level shifts in the peak amplitude\nof the two-point correlation. Our prediction of these shifts is provided as a\nfunction of redshift. This effect should be taken into account while\nenvisaging more realistic models, which also factor in redshift distortion and\ngalaxy bias into their consideration. Our analysis suggests that the\nbreakdown of linear theory happens at scales much larger than was previously\nthought. We demonstrate that the virialized halo profile does not have an\ninfluence on these effects, which can rather be attributed to the fundamentals\nof gravitational instability. Our findings are in good agreement with the\nresults of numerical simulations, and have the potential to aid in the creation\nof model for BAO within future observational endeavors. For this aspect, we\nprovide a physically motivated mechanism which can be used to make\ncorrections for the shifts brought about by mode-coupling.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2783}
{"prompt": "Rephrase the abstract of an article with title 'Search for gravitational waves from binary inspirals in S3 and S4 LIGO\n  data'.\n  We report on a search for gravitational waves from the coalescence of compact\nbinaries during the third and fourth LIGO science runs. The search focused on\ngravitational waves generated during the inspiral phase of the binary\nevolution. In our analysis, we considered three categories of compact binary\nsystems, ordered by mass: (i) primordial black hole binaries with masses in the\nrange 0.35 M(sun) < m1, m2 < 1.0 M(sun), (ii) binary neutron stars with masses\nin the range 1.0 M(sun) < m1, m2 < 3.0 M(sun), and (iii) binary black holes\nwith masses in the range 3.0 M(sun)< m1, m2 < m_(max) with the additional\nconstraint m1+ m2 < m_(max), where m_(max) was set to 40.0 M(sun) and 80.0\nM(sun) in the third and fourth science runs, respectively. Although the\ndetectors could probe to distances as far as tens of Mpc, no gravitational-wave\nsignals were identified in the 1364 hours of data we analyzed. Assuming a\nbinary population with a Gaussian distribution around 0.75-0.75 M(sun), 1.4-1.4\nM(sun), and 5.0-5.0 M(sun), we derived 90%-confidence upper limit rates of 4.9\nyr^(-1) L10^(-1) for primordial black hole binaries, 1.2 yr^(-1) L10^(-1) for\nbinary neutron stars, and 0.5 yr^(-1) L10^(-1) for stellar mass binary black\nholes, where L10 is 10^(10) times the blue light luminosity of the Sun.\n\n", "human_text": "  We report on a search for gravitational waves from the coalescence of compact\nbinaries during the third and fourth LIGO science runs. The search focused on\ngravitational waves generated during the inspiral phase of the binary\nevolution. In our analysis, we considered three categories of compact binary\nsystems, ordered by mass: (i) primordial black hole binaries with masses in the\nrange 0.35 M(sun) < m1, m2 < 1.0 M(sun), (ii) binary neutron stars with masses\nin the range 1.0 M(sun) < m1, m2 < 3.0 M(sun), and (iii) binary black holes\nwith masses in the range 3.0 M(sun)< m1, m2 < m_(max) with the additional\nconstraint m1+ m2 < m_(max), where m_(max) was set to 40.0 M(sun) and 80.0\nM(sun) in the third and fourth science runs, respectively. Although the\ndetectors could probe to distances as far as tens of Mpc, no gravitational-wave\nsignals were identified in the 1364 hours of data we analyzed. Assuming a\nbinary population with a Gaussian distribution around 0.75-0.75 M(sun), 1.4-1.4\nM(sun), and 5.0-5.0 M(sun), we derived 90%-confidence upper limit rates of 4.9\nyr^(-1) L10^(-1) for primordial black hole binaries, 1.2 yr^(-1) L10^(-1) for\nbinary neutron stars, and 0.5 yr^(-1) L10^(-1) for stellar mass binary black\nholes, where L10 is 10^(10) times the blue light luminosity of the Sun.\n", "machine_text": "\nIn this article, we examine the prospect of detecting gravitational waves from binary systems merging in the third and fourth runs of LIGO science. We conducted an analysis which targets the inspiral phase of the binary. The classification of the binary systems was determined by their mass - primordial black hole binaries with 0.35 to 1.0 M(sun), binary neutron stars (1.0 to 3.0 M(sun)), and binary black holes (3.0 to 40.0 M(sun) for the third run, and 3.0 to 80.0 M(sun) for the fourth). After surveying 1364 hours of data, we found no gravitational waves signals. Through supposing a binary population with a Gaussian distribution around 0.75-0.75 M(sun), 1.4-1.4 M(sun) and 5.0-5.0 M(sun), we were able to place 90%-confidence upper limit rates of 4.9 per year per 10^(10) solar blue light luminosity for primordial black hole binaries, 1.2 per year per 10^(10) solar blue light luminosity for binary neutron stars and 0.5 per year per 10^(10) solar blue light luminosity for binary black holes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3368}
{"prompt": "Rephrase the abstract of an article with title 'The structure of hypersonic shock waves using Navier-Stokes equations\n  modified to include mass diffusion'.\n  Howard Brenner has recently proposed modifications to the Navier-Stokes\nequations that relate to a diffusion of fluid volume that would be significant\nfor flows with high density gradients. In a previous paper (Greenshields &\nReese, 2007), we found these modifications gave good predictions of the viscous\nstructure of shock waves in argon in the range Mach 1.0-12.0 (while\nconventional Navier-Stokes equations are known to fail above about Mach 2).\nHowever, some areas of concern with this model were a somewhat arbitrary choice\nof modelling coefficient, and potentially unphysical and unstable solutions. In\nthis paper, we therefore present slightly different modifications to include\nmolecule mass diffusion fully in the Navier-Stokes equations. These\nmodifications are shown to be stable and produce physical solutions to the\nshock problem of a quality broadly similar to those from the family of extended\nhydrodynamic models that includes the Burnett equations. The modifications\nprimarily add a diffusion term to the mass conservation equation, so are at\nleast as simple to solve as the Navier-Stokes equations; there are none of the\nnumerical implementation problems of conventional extended hydrodynamics\nmodels, particularly in respect of boundary conditions. We recommend further\ninvestigation and testing on a number of different benchmark non-equilibrium\nflow cases.\n\n", "human_text": "  Howard Brenner has recently proposed modifications to the Navier-Stokes\nequations that relate to a diffusion of fluid volume that would be significant\nfor flows with high density gradients. In a previous paper (Greenshields &\nReese, 2007), we found these modifications gave good predictions of the viscous\nstructure of shock waves in argon in the range Mach 1.0-12.0 (while\nconventional Navier-Stokes equations are known to fail above about Mach 2).\nHowever, some areas of concern with this model were a somewhat arbitrary choice\nof modelling coefficient, and potentially unphysical and unstable solutions. In\nthis paper, we therefore present slightly different modifications to include\nmolecule mass diffusion fully in the Navier-Stokes equations. These\nmodifications are shown to be stable and produce physical solutions to the\nshock problem of a quality broadly similar to those from the family of extended\nhydrodynamic models that includes the Burnett equations. The modifications\nprimarily add a diffusion term to the mass conservation equation, so are at\nleast as simple to solve as the Navier-Stokes equations; there are none of the\nnumerical implementation problems of conventional extended hydrodynamics\nmodels, particularly in respect of boundary conditions. We recommend further\ninvestigation and testing on a number of different benchmark non-equilibrium\nflow cases.\n", "machine_text": "\nThis article presents a modification of the Navier-Stokes equations in order to incorporate mass diffusion in the flow at hypersonic velocities. Results from this modified model are compared with those of the model used by Greenshields & Reese (2007), which included a somewhat arbitrary choice of coefficients, as well as potential instabilities. The new model's modifications add a diffusion term to the mass conservation equation, meaning efficient and stable results are now possible with boundary conditions that are simpler to satisfy than traditional extended hydrodynamics models. The quality of the altered model's predictions for shock waves in argon in the Mach 1.0-12.0 range are similar to those of the extended hydrodynamics models that include the Burnett equations. In light of these results and the simplicity of implementation, further research of the model is recommended.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0141}
{"prompt": "Rephrase the abstract of an article with title 'Can We Detect the Anisotropic Shapes of Quasar HII Regions During\n  Reionization Through The Small-Scale Redshifted 21cm Power Spectrum?'.\n  Light travel time delays distort the apparent shapes of HII regions\nsurrounding bright quasars during early stages of cosmic reionization.\nIndividual HII regions may remain undetectable in forthcoming redshifted 21 cm\nexperiments. However, the systematic deformation along the line of sight may be\ndetectable statistically, either by stacking tomographic 21cm images of quasars\nidentified, for example, by JWST, or as small-scale anisotropy in the\nthree-dimensional 21cm power spectrum. Here we consider the detectability of\nthis effect. The anisotropy is largest when HII regions are large and expand\nrapidly, and we find that if bright quasars contributed to the early stages of\nreionization, then they can produce significant anisotropy, on scales\ncomparable to the typical sizes of HII regions of the bright quasars (approx.\n30 Mpc and below). The effect therefore cannot be ignored when analyzing future\n21cm power spectra on small scales. If 10 percent of the volume of the IGM at\nredshift z=10 is ionized by quasars with typical ionizing luminosity of S= 5 x\n10^{56} photons/second, the distortions can enhance by more than 10 percent the\n21cm power spectrum in the radial (redshift) direction, relative to the\ntransverse directions. The level of this anisotropy exceeds that due to\nredshift-space distortion, and has the opposite sign. We show that on-going\nexperiments such as MWA should be able to detect this effect. A detection would\nreveal the presence of bright quasars, and shed light on the ionizing yield and\nage of the ionizing sources, and the distribution and small-scale clumping of\nneutral intergalactic gas in their vicinity.\n\n", "human_text": "  Light travel time delays distort the apparent shapes of HII regions\nsurrounding bright quasars during early stages of cosmic reionization.\nIndividual HII regions may remain undetectable in forthcoming redshifted 21 cm\nexperiments. However, the systematic deformation along the line of sight may be\ndetectable statistically, either by stacking tomographic 21cm images of quasars\nidentified, for example, by JWST, or as small-scale anisotropy in the\nthree-dimensional 21cm power spectrum. Here we consider the detectability of\nthis effect. The anisotropy is largest when HII regions are large and expand\nrapidly, and we find that if bright quasars contributed to the early stages of\nreionization, then they can produce significant anisotropy, on scales\ncomparable to the typical sizes of HII regions of the bright quasars (approx.\n30 Mpc and below). The effect therefore cannot be ignored when analyzing future\n21cm power spectra on small scales. If 10 percent of the volume of the IGM at\nredshift z=10 is ionized by quasars with typical ionizing luminosity of S= 5 x\n10^{56} photons/second, the distortions can enhance by more than 10 percent the\n21cm power spectrum in the radial (redshift) direction, relative to the\ntransverse directions. The level of this anisotropy exceeds that due to\nredshift-space distortion, and has the opposite sign. We show that on-going\nexperiments such as MWA should be able to detect this effect. A detection would\nreveal the presence of bright quasars, and shed light on the ionizing yield and\nage of the ionizing sources, and the distribution and small-scale clumping of\nneutral intergalactic gas in their vicinity.\n", "machine_text": "\nWe investigate whether the shape of HII regions around bright quasars during reionization is detectable in the small-scale redshifted 21 cm power spectrum. Our results suggest that if a significant portion of the IGM at redshift z=10 is ionized by quasars with typical ionizing luminosity, the effect of the anisotropic shapes can lead to an enhancement of more than 10 percent in the 21 cm power spectrum in the radial direction compared to the transverse direction. This level of anisotropy surpasses that of the redshift-space distortion, yet the opposite sign. With on-going experiments such as the MWA, this anisotropy should be detectable and will give insight into the ionizing yield and age of the ionizing sources, and the intergalactic neutral gas in the vicinity of the quasars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0981}
{"prompt": "Rephrase the abstract of an article with title 'Strong peak points and denseness of strong peak functions'.\n  Let $C_b(K)$ be the set of all bounded continuous (real or complex) functions\non a complete metric space $K$ and $A$ a closed subspace of $C_b(K)$. Using the\nvariational method, it is shown that the set of all strong peak functions in\n$A$ is dense if and only if the set of all strong peak points is a norming\nsubset of $A$. As a corollary we show that if $X$ is a locally uniformly\nconvex, complex Banach space, then the set of all strong peak functions in\n$\\mathcal{A}(B_X)$ is a dense $G_\\delta$ subset. Moreover if $X$ is separable,\nsmooth and locally uniformly convex, then the set of all norm and numerical\nstrong peak functions in $\\mathcal{A}_u(B_X:X)$ is a dense $G_\\delta$ subset.\nIn case that a set of uniformly strongly exposed points of a (real or complex)\nBanach space $X$ is a norming subset of $\\mathcal{P}({}^n X)$ for some $n\\ge\n1$, then the set of all strongly norm attaining elements in $\\mathcal{P}({}^n\nX)$ is dense, in particular, the set of all points at which the norm of\n$\\mathcal{P}({}^n X)$ is Fr\\'echet differentiable is a dense $G_\\delta$ subset.\n\n", "human_text": "  Let $C_b(K)$ be the set of all bounded continuous (real or complex) functions\non a complete metric space $K$ and $A$ a closed subspace of $C_b(K)$. Using the\nvariational method, it is shown that the set of all strong peak functions in\n$A$ is dense if and only if the set of all strong peak points is a norming\nsubset of $A$. As a corollary we show that if $X$ is a locally uniformly\nconvex, complex Banach space, then the set of all strong peak functions in\n$\\mathcal{A}(B_X)$ is a dense $G_\\delta$ subset. Moreover if $X$ is separable,\nsmooth and locally uniformly convex, then the set of all norm and numerical\nstrong peak functions in $\\mathcal{A}_u(B_X:X)$ is a dense $G_\\delta$ subset.\nIn case that a set of uniformly strongly exposed points of a (real or complex)\nBanach space $X$ is a norming subset of $\\mathcal{P}({}^n X)$ for some $n\\ge\n1$, then the set of all strongly norm attaining elements in $\\mathcal{P}({}^n\nX)$ is dense, in particular, the set of all points at which the norm of\n$\\mathcal{P}({}^n X)$ is Fr\\'echet differentiable is a dense $G_\\delta$ subset.\n", "machine_text": "\nThis article seeks to study the density of strong peak functions and peak points using the variational method. As a result, it is found that if a closed subspace $A$ in a complete metric space $K$ possesses a set of strong peak points, then this set is a norming subset of $A$. Furthermore, for a complex locally uniformly convex Banach space $X$, the set of all strong peak functions in $\\mathcal{A}(B_X)$ is a dense $G_\\delta$ subset. Additionally, for a complex separable, smooth, and locally uniformly convex Banach space $X$, the set of all strong norm-attaining and numerical peak functions in $\\mathcal{A}_u(B_X:X)$ is a dense $G_\\delta$ subset. Finally, should a set of uniformly strongly exposed points in a (complex or real) Banach space $X$ be a norming subset of $\\mathcal{P}({}^nX)$ for some $n\\ge 1$, then the set of all strongly-norm attaining elements in $\\mathcal{P}({}^nX)$ is dense, and the set of points at which the norm of $\\mathcal{P}({}^nX)$ is Fr\u00e9chet differentiable is a dense $G_\\delta$ subset.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.265}
{"prompt": "Rephrase the abstract of an article with title 'Observations of Microwave Continuum Emission from Air Shower Plasmas'.\n  We investigate a possible new technique for microwave measurements of\nultra-high energy cosmic ray (UHECR) extensive air showers which relies on\ndetection of expected continuum radiation in the microwave range, caused by\nfree-electron collisions with neutrals in the tenuous plasma left after the\npassage of the shower. We performed an initial experiment at the AWA (Argonne\nWakefield Accelerator) laboratory in 2003 and measured broadband microwave\nemission from air ionized via high energy electrons and photons. A follow-up\nexperiment at SLAC (Stanford Linear Accelerator Center) in summer of 2004\nconfirmed the major features of the previous AWA observations with better\nprecision and made additional measurements relevant to the calorimetric\ncapabilities of the method. Prompted by these results we built a prototype\ndetector using satellite television technology, and have made measurements\nindicating possible detection of cosmic ray extensive air showers. The method,\nif confirmed by experiments now in progress, could provide a high-duty cycle\ncomplement to current nitrogen fluorescence observations of UHECR, which are\nlimited to dark, clear nights. By contrast, decimeter microwave observations\ncan be made both night and day, in clear or cloudy weather, or even in the\npresence of moderate precipitation.\n\n", "human_text": "  We investigate a possible new technique for microwave measurements of\nultra-high energy cosmic ray (UHECR) extensive air showers which relies on\ndetection of expected continuum radiation in the microwave range, caused by\nfree-electron collisions with neutrals in the tenuous plasma left after the\npassage of the shower. We performed an initial experiment at the AWA (Argonne\nWakefield Accelerator) laboratory in 2003 and measured broadband microwave\nemission from air ionized via high energy electrons and photons. A follow-up\nexperiment at SLAC (Stanford Linear Accelerator Center) in summer of 2004\nconfirmed the major features of the previous AWA observations with better\nprecision and made additional measurements relevant to the calorimetric\ncapabilities of the method. Prompted by these results we built a prototype\ndetector using satellite television technology, and have made measurements\nindicating possible detection of cosmic ray extensive air showers. The method,\nif confirmed by experiments now in progress, could provide a high-duty cycle\ncomplement to current nitrogen fluorescence observations of UHECR, which are\nlimited to dark, clear nights. By contrast, decimeter microwave observations\ncan be made both night and day, in clear or cloudy weather, or even in the\npresence of moderate precipitation.\n", "machine_text": "We have conducted two experiments to measure microwave radiation from energetic particle shower plasmas. In 2003, at the Argonne Wakefield Accelerator lab, our measurements indicated the possibility of microwave emission from air ionized by high energy electrons and photons. A follow-up experiment at SLAC (Stanford Linear Accelerator Center) in summer 2004 provided additional support for these observations. To further assess the potential of this method to detect UHECR air showers, we have built a prototype detector, and have made measurements indicating a potential detection of cosmic rays. Compared to nitrogen fluorescence technology, this method would provide all-weather, 24-hour duty cycle access to UHECR measurements, with moderate precipitation being possible. Further experiments are currently underway to confirm these promising initial results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2589}
{"prompt": "Rephrase the abstract of an article with title 'Halo-model signatures from 380,000 SDSS Luminous Red Galaxies with\n  photometric redshifts'.\n  We analyze the small-scale clustering in \"MegaZ-LRG\", a large\nphotometric-redshift catalogue of Luminous Red Galaxies extracted from the\nimaging dataset of the Sloan Digital Sky Survey. MegaZ-LRG, presented in a\ncompanion paper, spans the redshift range 0.4 < z < 0.7 with an r.m.s. redshift\nerror dz ~ 0.03(1+z), covering 5,914 deg^2 to map out a total cosmic volume 2.5\nh^-3 Gpc^3. In this study we use 380,000 photometric redshifts to measure\nsignificant deviations from the canonical power-law fit to the angular\ncorrelation function in a series of narrow redshift slices, in which we\nconstruct volume-limited samples. These deviations are direct signatures of the\nmanner in which these galaxies populate the underlying network of dark matter\nhaloes. We cleanly delineate the separate contributions of the \"1-halo\" and\n\"2-halo\" clustering terms and fit our measurements by parameterizing the halo\noccupation distribution N(M) of the galaxies. Our results are successfully fit\nby a \"central\" galaxy contribution with a \"soft\" transition from zero to one\ngalaxies, combined with a power-law \"satellite\" galaxy component, the slope of\nwhich is a strong function of galaxy luminosity. The large majority of galaxies\nare classified as central objects of their host dark matter haloes rather than\nsatellites in more massive systems. The effective halo mass of MegaZ-LRG\ngalaxies lies in the range log_10 (M_eff / h^-1 M_sol) = 13.61 - 13.8\n(increasing with redshift, assuming large-scale normalization sigma_8 = 0.8)\nfor corresponding number densities in the range n_g = 5.03 - 0.56 x 10^-4 h^3\nMpc^-3. Our results confirm the usefulness of the halo model for gaining\nphysical insight into the patterns of galaxy clustering.\n\n", "human_text": "  We analyze the small-scale clustering in \"MegaZ-LRG\", a large\nphotometric-redshift catalogue of Luminous Red Galaxies extracted from the\nimaging dataset of the Sloan Digital Sky Survey. MegaZ-LRG, presented in a\ncompanion paper, spans the redshift range 0.4 < z < 0.7 with an r.m.s. redshift\nerror dz ~ 0.03(1+z), covering 5,914 deg^2 to map out a total cosmic volume 2.5\nh^-3 Gpc^3. In this study we use 380,000 photometric redshifts to measure\nsignificant deviations from the canonical power-law fit to the angular\ncorrelation function in a series of narrow redshift slices, in which we\nconstruct volume-limited samples. These deviations are direct signatures of the\nmanner in which these galaxies populate the underlying network of dark matter\nhaloes. We cleanly delineate the separate contributions of the \"1-halo\" and\n\"2-halo\" clustering terms and fit our measurements by parameterizing the halo\noccupation distribution N(M) of the galaxies. Our results are successfully fit\nby a \"central\" galaxy contribution with a \"soft\" transition from zero to one\ngalaxies, combined with a power-law \"satellite\" galaxy component, the slope of\nwhich is a strong function of galaxy luminosity. The large majority of galaxies\nare classified as central objects of their host dark matter haloes rather than\nsatellites in more massive systems. The effective halo mass of MegaZ-LRG\ngalaxies lies in the range log_10 (M_eff / h^-1 M_sol) = 13.61 - 13.8\n(increasing with redshift, assuming large-scale normalization sigma_8 = 0.8)\nfor corresponding number densities in the range n_g = 5.03 - 0.56 x 10^-4 h^3\nMpc^-3. Our results confirm the usefulness of the halo model for gaining\nphysical insight into the patterns of galaxy clustering.\n", "machine_text": "\nIn this work, we analyze the small-scale clustering of a photometric-redshift catalog of Luminous Red Galaxies known as \"MegaZ-LRG\", which spans redshifts from 0.4 to 0.7 and covers a cosmic volume of 2.5 h^-3 Gpc^3. By examining 380,000 photometric redshifts, we detect significant deviations from the canonical power-law fit to the angular correlation function within a series of narrow redshift slices. These deviations are attributed to the manner in which these galaxies inhabit dark matter haloes, leading to distinct \"1-halo\" and \"2-halo\" clustering terms. Our results are modeled by the halo occupation distribution and show that the majority of galaxies are primary citizens of their host dark matter haloes rather than satellites in more massive systems. The effective halo masses of MegaZ-LRG galaxies range from log_10 (M_eff / h^-1 M_sol) = 13.61 - 13.8 with corresponding number densities in the range of n_g = 5.03 - 0.56 x 10^-4 h^3 Mpc^-3. This analysis confirms the applicability of the halo model in deciphering physical information from the observed galaxy clustering.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3377}
{"prompt": "Rephrase the abstract of an article with title 'GRB 061121: Broadband spectral evolution through the prompt and\n  afterglow phases of a bright burst'.\n  Swift triggered on a precursor to the main burst of GRB 061121 (z=1.314),\nallowing observations to be made from the optical to gamma-ray bands. Many\nother telescopes, including Konus-Wind, XMM-Newton, ROTSE and the Faulkes\nTelescope North, also observed the burst. The gamma-ray, X-ray and UV/optical\nemission all showed a peak ~75s after the trigger, although the optical and\nX-ray afterglow components also appear early on - before, or during, the main\npeak. Spectral evolution was seen throughout the burst, with the prompt\nemission showing a clear positive correlation between brightness and hardness.\nThe Spectral Energy Distribution (SED) of the prompt emission, stretching from\n1eV up to 1MeV, is very flat, with a peak in the flux density at ~1keV. The\noptical-to-X-ray spectra at this time are better fitted by a broken, rather\nthan single, power-law, similar to previous results for X-ray flares. The SED\nshows spectral hardening as the afterglow evolves with time. This behaviour\nmight be a symptom of self-Comptonisation, although circumstellar densities\nsimilar to those found in the cores of molecular clouds would be required. The\nafterglow also decays too slowly to be accounted for by the standard models.\nAlthough the precursor and main emission show different spectral lags, both are\nconsistent with the lag-luminosity correlation for long bursts. GRB 061121 is\nthe instantaneously brightest long burst yet detected by Swift. Using a\ncombination of Swift and Konus-Wind data, we estimate an isotropic energy of\n2.8x10^53 erg over 1keV - 10MeV in the GRB rest frame. A probable jet break is\ndetected at ~2x10^5s, leading to an estimate of ~10^51 erg for the\nbeaming-corrected gamma-ray energy.\n\n", "human_text": "  Swift triggered on a precursor to the main burst of GRB 061121 (z=1.314),\nallowing observations to be made from the optical to gamma-ray bands. Many\nother telescopes, including Konus-Wind, XMM-Newton, ROTSE and the Faulkes\nTelescope North, also observed the burst. The gamma-ray, X-ray and UV/optical\nemission all showed a peak ~75s after the trigger, although the optical and\nX-ray afterglow components also appear early on - before, or during, the main\npeak. Spectral evolution was seen throughout the burst, with the prompt\nemission showing a clear positive correlation between brightness and hardness.\nThe Spectral Energy Distribution (SED) of the prompt emission, stretching from\n1eV up to 1MeV, is very flat, with a peak in the flux density at ~1keV. The\noptical-to-X-ray spectra at this time are better fitted by a broken, rather\nthan single, power-law, similar to previous results for X-ray flares. The SED\nshows spectral hardening as the afterglow evolves with time. This behaviour\nmight be a symptom of self-Comptonisation, although circumstellar densities\nsimilar to those found in the cores of molecular clouds would be required. The\nafterglow also decays too slowly to be accounted for by the standard models.\nAlthough the precursor and main emission show different spectral lags, both are\nconsistent with the lag-luminosity correlation for long bursts. GRB 061121 is\nthe instantaneously brightest long burst yet detected by Swift. Using a\ncombination of Swift and Konus-Wind data, we estimate an isotropic energy of\n2.8x10^53 erg over 1keV - 10MeV in the GRB rest frame. A probable jet break is\ndetected at ~2x10^5s, leading to an estimate of ~10^51 erg for the\nbeaming-corrected gamma-ray energy.\n", "machine_text": "\nSwift and Konus-Wind observations of GRB 061121 (z=1.314), one of the brightest long bursts ever detected, found evidence for an emitted energy of 2.8x10^53 erg over the energy range between 1keV - 10MeV observed in the GRB's rest frame. Additionally, an X-ray flare comparable to previous results was detected, suggesting spectral evolution throughout the burst, which was characterized by a flat SED and a positive correlation between brightness and hardness. The optical-to-X-ray spectra could also be modelled best by a broken, rather than single, power-law. Later on a jet break was seen at ~2x10^5s and lead to an estimated beaming-corrected gamma-ray energy of ~10^51 erg. Observations of the prompt and afterglow phases of GRB 061121 enabled the detection of different spectral lags respectively, and both lags were found to be consistent with the lag-luminosity correlation for long bursts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1609}
{"prompt": "Rephrase the abstract of an article with title 'Maximum solutions of normalized Ricci flows on 4-manifolds'.\n  We consider maximum solution $g(t)$, $t\\in [0, +\\infty)$, to the normalized\nRicci flow. Among other things, we prove that, if $(M, \\omega) $ is a smooth\ncompact symplectic 4-manifold such that $b_2^+(M)>1$ and let\n$g(t),t\\in[0,\\infty)$, be a solution to (1.3) on $M$ whose Ricci curvature\nsatisfies that $|\\text{Ric}(g(t))|\\leq 3$ and additionally $\\chi(M)=3 \\tau\n(M)>0$, then there exists an $m\\in \\mathbb{N}$, and a sequence of points\n$\\{x_{j,k}\\in M\\}$, $j=1, ..., m$, satisfying that, by passing to a\nsubsequence, $$(M, g(t_{k}+t), x_{1,k},..., x_{m,k})\n\\stackrel{d_{GH}}\\longrightarrow (\\coprod_{j=1}^m N_j, g_{\\infty},\nx_{1,\\infty}, ...,, x_{m,\\infty}),$$ $t\\in [0, \\infty)$, in the $m$-pointed\nGromov-Hausdorff sense for any sequence $t_{k}\\longrightarrow \\infty$, where\n$(N_{j}, g_{\\infty})$, $j=1,..., m$, are complete complex hyperbolic orbifolds\nof complex dimension 2 with at most finitely many isolated orbifold points.\nMoreover, the convergence is $C^{\\infty}$ in the non-singular part of\n$\\coprod_1^m N_{j}$ and\n$\\text{Vol}_{g_{0}}(M)=\\sum_{j=1}^{m}\\text{Vol}_{g_{\\infty}}(N_{j})$, where\n$\\chi(M)$ (resp. $\\tau(M)$) is the Euler characteristic (resp. signature) of\n$M$.\n\n", "human_text": "  We consider maximum solution $g(t)$, $t\\in [0, +\\infty)$, to the normalized\nRicci flow. Among other things, we prove that, if $(M, \\omega) $ is a smooth\ncompact symplectic 4-manifold such that $b_2^+(M)>1$ and let\n$g(t),t\\in[0,\\infty)$, be a solution to (1.3) on $M$ whose Ricci curvature\nsatisfies that $|\\text{Ric}(g(t))|\\leq 3$ and additionally $\\chi(M)=3 \\tau\n(M)>0$, then there exists an $m\\in \\mathbb{N}$, and a sequence of points\n$\\{x_{j,k}\\in M\\}$, $j=1, ..., m$, satisfying that, by passing to a\nsubsequence, $$(M, g(t_{k}+t), x_{1,k},..., x_{m,k})\n\\stackrel{d_{GH}}\\longrightarrow (\\coprod_{j=1}^m N_j, g_{\\infty},\nx_{1,\\infty}, ...,, x_{m,\\infty}),$$ $t\\in [0, \\infty)$, in the $m$-pointed\nGromov-Hausdorff sense for any sequence $t_{k}\\longrightarrow \\infty$, where\n$(N_{j}, g_{\\infty})$, $j=1,..., m$, are complete complex hyperbolic orbifolds\nof complex dimension 2 with at most finitely many isolated orbifold points.\nMoreover, the convergence is $C^{\\infty}$ in the non-singular part of\n$\\coprod_1^m N_{j}$ and\n$\\text{Vol}_{g_{0}}(M)=\\sum_{j=1}^{m}\\text{Vol}_{g_{\\infty}}(N_{j})$, where\n$\\chi(M)$ (resp. $\\tau(M)$) is the Euler characteristic (resp. signature) of\n$M$.\n", "machine_text": "\nIn this article, we analyze the maximum solutions of the normalized Ricci flows on compact symplectic 4-manifolds, $(M, \\omega)$, such that $b_2^+(M) > 1$. We prove that, if  $|\\text{Ric}(g(t))| \\leq 3$ and $\\chi(M) = 3 \\tau (M) > 0$, then there exists an $m\\in \\mathbb{N}$ and a sequence of points $\\{x_{j,k}\\in M\\}$, $j=1, ..., m$, that, under a subsequence, converges to $(\\coprod_{j=1}^m N_j, g_{\\infty}, x_{1,\\infty}, ...,, x_{m,\\infty})$ in the $m$-pointed Gromov-Hausdorff sense for any $t_{k}\\longrightarrow \\infty$. The limit is a complete complex hyperbolic orbifold of complex dimension 2 with at most finitely many isolated orbifold points. We show that the convergence is $C^{\\infty}$ in the non-singular part of $\\coprod_1^m N_{j}$ and that the total volume of the manifold is equal to the sum of the volumes of the convergence solutions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0714}
{"prompt": "Rephrase the abstract of an article with title 'The role of GRB 031203 in clarifying the astrophysical GRB scenario'.\n  The luminosity and the spectral distribution of the afterglow of GRB 031203\nhave been presented within our theoretical framework, which envisages the GRB\nstructure as composed by a proper-GRB, emitted at the transparency of an\nelectron-positron plasma with suitable baryon loading, and an afterglow\ncomprising the \"prompt emission\" as due to external shocks. In addition to the\nGRB emission, there appears to be a prolonged soft X-Ray emission lasting for\n10^6-10^7 seconds followed by an exponential decay. This additional source has\nbeen called by us URCA-3. It is urgent to establish if this component is\nrelated to the GRB or to the Supernova (SN). In this second case, there are two\npossibilities: either the interaction of the SN ejecta with the interstellar\nmedium or, possibly, the cooling of a young neutron star formed in the SN\n2003lw process. The analogies and the differences between this triptych GRB\n031203 / SN 2003lw / URCA-3 and the corresponding ones GRB 980425 / SN 1998bw /\nURCA-1 and GRB 030329 / SN 2003dh / URCA-2, as well as GRB 060218 / SN 2006aj\nare discussed.\n\n", "human_text": "  The luminosity and the spectral distribution of the afterglow of GRB 031203\nhave been presented within our theoretical framework, which envisages the GRB\nstructure as composed by a proper-GRB, emitted at the transparency of an\nelectron-positron plasma with suitable baryon loading, and an afterglow\ncomprising the \"prompt emission\" as due to external shocks. In addition to the\nGRB emission, there appears to be a prolonged soft X-Ray emission lasting for\n10^6-10^7 seconds followed by an exponential decay. This additional source has\nbeen called by us URCA-3. It is urgent to establish if this component is\nrelated to the GRB or to the Supernova (SN). In this second case, there are two\npossibilities: either the interaction of the SN ejecta with the interstellar\nmedium or, possibly, the cooling of a young neutron star formed in the SN\n2003lw process. The analogies and the differences between this triptych GRB\n031203 / SN 2003lw / URCA-3 and the corresponding ones GRB 980425 / SN 1998bw /\nURCA-1 and GRB 030329 / SN 2003dh / URCA-2, as well as GRB 060218 / SN 2006aj\nare discussed.\n", "machine_text": "\nWe analyze the GRB 031203 afterglow using a theoretical framework that interprets the GRB structure as a combination of a proper GRB, released when an electron-positron plasma reaches its critical point, and an \"immediate emission\" due to external shocks. In addition to this, the GRB 031203 is noted to generate a prolonged soft X-Ray emission lasting up to 10^7 seconds, and looks to decay exponentially. Named by us URCA-3, researchers are attempting to ascertain whether this additional energy source is linked to the GRB or to the accompanying supernova (SN) 2003lw. If the latter is found to be true, then the energy source could either be from the SN ejecta's interaction with the interstellar medium or from the cooling of an emergent neutron star, formed in the SN 2003lw event. Comparisons and contrasts between the GRB 031203/ SN 2003lw/ URCA-3 triptych and other analogous GRB/ SN/URCA associations have been discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2456}
{"prompt": "Rephrase the abstract of an article with title 'Multiple Routes for Glutamate Receptor Trafficking: Surface Diffusion\n  and Membrane Traffic Cooperate to Bring Receptors to Synapses'.\n  Trafficking of glutamate receptors into and out of synapses is critically\ninvolved in the plasticity of excitatory synaptic transmission. Endocytosis and\nexocytosis of receptors have initially been thought to account alone for this\ntrafficking. However, membrane proteins also traffic through surface lateral\ndiffusion in the plasma membrane. We describe developments in\nelectrophysiological and optical approaches that have allowed for the real time\nmeasurement of glutamate receptor surface trafficking in live neurons. These\ninclude (i) specific imaging of surface receptors using a pH sensitive\nfluorescent protein, (ii) design of a photoactivable drug to inactivate locally\nsurface receptors and monitor electrophysiologically their recovery, and\n(iii)application of single molecule fluorescence microscopy to directly track\nthe movement of individual surface receptors with nanometer resolution inside\nand outside synapses. Altogether, these approaches have demonstrated that\nglutamate receptors diffuse at high rates in the neuronal membrane and suggest\na key role for surface diffusion in the regulation of receptor numbers at\nsynapses.\n\n", "human_text": "  Trafficking of glutamate receptors into and out of synapses is critically\ninvolved in the plasticity of excitatory synaptic transmission. Endocytosis and\nexocytosis of receptors have initially been thought to account alone for this\ntrafficking. However, membrane proteins also traffic through surface lateral\ndiffusion in the plasma membrane. We describe developments in\nelectrophysiological and optical approaches that have allowed for the real time\nmeasurement of glutamate receptor surface trafficking in live neurons. These\ninclude (i) specific imaging of surface receptors using a pH sensitive\nfluorescent protein, (ii) design of a photoactivable drug to inactivate locally\nsurface receptors and monitor electrophysiologically their recovery, and\n(iii)application of single molecule fluorescence microscopy to directly track\nthe movement of individual surface receptors with nanometer resolution inside\nand outside synapses. Altogether, these approaches have demonstrated that\nglutamate receptors diffuse at high rates in the neuronal membrane and suggest\na key role for surface diffusion in the regulation of receptor numbers at\nsynapses.\n", "machine_text": "\nThe proper regulation of excitatory synaptic transmission relies heavily on the trafficking of glutamate receptors in and out of synapses. Reproduction by endocytosis and exocytosis of these receptors had earlier been thought to be the only mechanism of such trafficking. However, a more multifaceted approach has been realized through various motion-tracking techniques that demonstrated the diffusion of glutamate receptors on the neuronal plasma membrane. The use of pH-sensitive fluorescent proteins and photoactivatable drugs, as well as single molecule fluorescent microscopy have enabled the live observation of receptor surface trafficking within and outside of synapses. Examination of these findings concluded that these receptors traverse the neuronal membrane at an impressive speed and play a major role in controlling the amount of receptors at the synapses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3854}
{"prompt": "Rephrase the abstract of an article with title 'Evolution of complex modular biological networks'.\n  Biological networks have evolved to be highly functional within uncertain\nenvironments while remaining extremely adaptable. One of the main contributors\nto the robustness and evolvability of biological networks is believed to be\ntheir modularity of function, with modules defined as sets of genes that are\nstrongly interconnected but whose function is separable from those of other\nmodules. Here, we investigate the in silico evolution of modularity and\nrobustness in complex artificial metabolic networks that encode an increasing\namount of information about their environment while acquiring ubiquitous\nfeatures of biological, social, and engineering networks, such as scale-free\nedge distribution, small-world property, and fault-tolerance. These networks\nevolve in environments that differ in their predictability, and allow us to\nstudy modularity from topological, information-theoretic, and gene-epistatic\npoints of view using new tools that do not depend on any preconceived notion of\nmodularity. We find that for our evolved complex networks as well as for the\nyeast protein-protein interaction network, synthetic lethal pairs consist\nmostly of redundant genes that lie close to each other and therefore within\nmodules, while knockdown suppressor pairs are farther apart and often straddle\nmodules, suggesting that knockdown rescue is mediated by alternative pathways\nor modules. The combination of network modularity tools together with genetic\ninteraction data constitutes a powerful approach to study and dissect the role\nof modularity in the evolution and function of biological networks.\n\n", "human_text": "  Biological networks have evolved to be highly functional within uncertain\nenvironments while remaining extremely adaptable. One of the main contributors\nto the robustness and evolvability of biological networks is believed to be\ntheir modularity of function, with modules defined as sets of genes that are\nstrongly interconnected but whose function is separable from those of other\nmodules. Here, we investigate the in silico evolution of modularity and\nrobustness in complex artificial metabolic networks that encode an increasing\namount of information about their environment while acquiring ubiquitous\nfeatures of biological, social, and engineering networks, such as scale-free\nedge distribution, small-world property, and fault-tolerance. These networks\nevolve in environments that differ in their predictability, and allow us to\nstudy modularity from topological, information-theoretic, and gene-epistatic\npoints of view using new tools that do not depend on any preconceived notion of\nmodularity. We find that for our evolved complex networks as well as for the\nyeast protein-protein interaction network, synthetic lethal pairs consist\nmostly of redundant genes that lie close to each other and therefore within\nmodules, while knockdown suppressor pairs are farther apart and often straddle\nmodules, suggesting that knockdown rescue is mediated by alternative pathways\nor modules. The combination of network modularity tools together with genetic\ninteraction data constitutes a powerful approach to study and dissect the role\nof modularity in the evolution and function of biological networks.\n", "machine_text": "\nThis article investigates the evolution of modularity and robustness in complex, artificial metabolic networks. Such networks encode an increasing amount of information about the environment while obtaining ubiquitous features of biological and engineering networks, such as scale-free edge distribution, small world property, and fault-tolerance. Using new, modularity-based tools, the study examines the effect of environmental unpredictability on the development of modularity in these networks, alongside the modularity observed in the yeast protein-protein interaction network. Researchers found that for evolved networks, synthetic lethal pairs consisted of redundant genes that were close together, while knockdown suppressor pairs were often found at a distance and spanned between modules. This article therefore supports the use of network modularity tools and genetic interaction data to study the role of modularity in the evolution and function of biological networks.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4674}
{"prompt": "Rephrase the abstract of an article with title 'The born again (VLTP) scenario revisited: The mass of the remnants and\n  implications for V4334 Sgr'.\n  We present 1-D numerical simulations of the very late thermal pulse\n  (VLTP) scenario for a wide range of remnant masses. We show that by taking\ninto account the different possible remnant masses, the observed evolution of\nV4334 Sgr (a.k.a. Sakurai's Object) can be reproduced within the standard\n1D-MLT stellar evolutionary models without the inclusion of any $ad-hoc$\nreduced mixing efficiency. Our simulations hint at a consistent picture with\npresent observations of V4334 Sgr. From energetics, and within the standard MLT\napproach, we show that low mass remnants \\hbox{($M\\lesssim0.6$\\msun)} are\nexpected to behave markedly different than higher mass remnants\n\\hbox{($M\\gtrsim0.6$\\msun)} in the sense that the latter are not expected to\nexpand significantly as a result of the violent H-burning that takes place\nduring the VLTP. We also assess the discrepancy in the born again times\nobtained by different authors by comparing the energy that can be liberated by\nH-burning during the VLTP event.\n\n", "human_text": "  We present 1-D numerical simulations of the very late thermal pulse\n  (VLTP) scenario for a wide range of remnant masses. We show that by taking\ninto account the different possible remnant masses, the observed evolution of\nV4334 Sgr (a.k.a. Sakurai's Object) can be reproduced within the standard\n1D-MLT stellar evolutionary models without the inclusion of any $ad-hoc$\nreduced mixing efficiency. Our simulations hint at a consistent picture with\npresent observations of V4334 Sgr. From energetics, and within the standard MLT\napproach, we show that low mass remnants \\hbox{($M\\lesssim0.6$\\msun)} are\nexpected to behave markedly different than higher mass remnants\n\\hbox{($M\\gtrsim0.6$\\msun)} in the sense that the latter are not expected to\nexpand significantly as a result of the violent H-burning that takes place\nduring the VLTP. We also assess the discrepancy in the born again times\nobtained by different authors by comparing the energy that can be liberated by\nH-burning during the VLTP event.\n", "machine_text": "\nWe revisit the born again (VLTP) scenario, analyzing the range of remnant\nmasses and its implications for V4334 Sgr. Our numerical simulations demonstrate\nthat the standard 1D-MLT models of stellar evolution can account for\nV4334 Sgr\u00b4s observed behaviour without added ad-hoc reduced mixing efficiency.\nWe find that lower mass remnants \\hbox{($M\\lesssim0.6$\\msun)} show distinct\nresponse patterns compared to higher mass \\hbox{($M\\gtrsim0.6$\\msun)}\nremnant, the latter being unlikely to expand significantly due to its violent\nH-burning during VLTP. We further compare the energy released by\nH-burning during VLTP, to investigate discrepancies in the born again times by\nvarious authors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0714}
{"prompt": "Rephrase the abstract of an article with title 'Interaction between a fast rotating sunspot and ephemeral regions as the\n  origin of the major solar event on 2006 December 13'.\n  The major solar event on 2006 December 13 is characterized by the\napproximately simultaneous occurrence of a heap of hot ejecta, a great\ntwo-ribbon flare and an extended Earth-directed coronal mass ejection. We\nexamine the magnetic field and sunspot evolution in active region NOAA AR\n10930, the source region of the event, while it transited the solar disk centre\nfrom Dec. 10 to Dec. 13. We find that the obvious changes in the active region\nassociated with the event are the development of magnetic shear, the appearance\nof ephemeral regions and fast rotation of a smaller sunspot. Around the area of\nthe magnetic neutral line of the active region, interaction between the fast\nrotating sunspot and the ephemeral regions triggers continual brightening and\nfinally the major flare. It is indicative that only after the sunspot rotates\nup to 200$^{\\circ}$ does the major event take place. The sunspot rotates at\nleast 240$^{\\circ}$ about its centre, the largest sunspot rotation angle which\nhas been reported.\n\n", "human_text": "  The major solar event on 2006 December 13 is characterized by the\napproximately simultaneous occurrence of a heap of hot ejecta, a great\ntwo-ribbon flare and an extended Earth-directed coronal mass ejection. We\nexamine the magnetic field and sunspot evolution in active region NOAA AR\n10930, the source region of the event, while it transited the solar disk centre\nfrom Dec. 10 to Dec. 13. We find that the obvious changes in the active region\nassociated with the event are the development of magnetic shear, the appearance\nof ephemeral regions and fast rotation of a smaller sunspot. Around the area of\nthe magnetic neutral line of the active region, interaction between the fast\nrotating sunspot and the ephemeral regions triggers continual brightening and\nfinally the major flare. It is indicative that only after the sunspot rotates\nup to 200$^{\\circ}$ does the major event take place. The sunspot rotates at\nleast 240$^{\\circ}$ about its centre, the largest sunspot rotation angle which\nhas been reported.\n", "machine_text": "\nThe major solar event of 2006 December 13, characterized by a series of\nhot ejecta, a sizeable two-ribbon flare, and a wide Earth-directed coronal\nmass ejection, is linked to the evolution of the magnetic field and sunspot\nin the source region of active region NOAA AR 10930 as it passed the center of\nthe solar disk from December 10 to 13. Interaction between a rapidly spinning\nsunspot and ephemeral regions in the vicinity of the active region's magnetic\nneutral line set off a series of brightenings that led ultimately to the large\nflare event. We propose that this sunspot must have rotated at least a 200$^{\\circ}$\nbefore the flare could take place, the greatest sunspot roataion angle reported\nto date.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0607}
{"prompt": "Rephrase the abstract of an article with title 'Temporal Runtime Verification using Monadic Difference Logic'.\n  In this paper we present an algorithm for performing runtime verification of\na bounded temporal logic over timed runs. The algorithm consists of three\nelements. First, the bounded temporal formula to be verified is translated into\na monadic first-order logic over difference inequalities, which we call monadic\ndifference logic. Second, at each step of the timed run, the monadic difference\nformula is modified by computing a quotient with the state and time of that\nstep. Third, the resulting formula is checked for being a tautology or being\nunsatisfiable by a decision procedure for monadic difference logic.\n  We further provide a simple decision procedure for monadic difference logic\nbased on the data structure Difference Decision Diagrams. The algorithm is\ncomplete in a very strong sense on a subclass of temporal formulae\ncharacterized as homogeneously monadic and it is approximate on other formulae.\nThe approximation comes from the fact that not all unsatisfiable or\ntautological formulae are recognised at the earliest possible time of the\nruntime verification.\n  Contrary to existing approaches, the presented algorithms do not work by\nsyntactic rewriting but employ efficient decision structures which make them\napplicable in real applications within for instance business software.\n\n", "human_text": "  In this paper we present an algorithm for performing runtime verification of\na bounded temporal logic over timed runs. The algorithm consists of three\nelements. First, the bounded temporal formula to be verified is translated into\na monadic first-order logic over difference inequalities, which we call monadic\ndifference logic. Second, at each step of the timed run, the monadic difference\nformula is modified by computing a quotient with the state and time of that\nstep. Third, the resulting formula is checked for being a tautology or being\nunsatisfiable by a decision procedure for monadic difference logic.\n  We further provide a simple decision procedure for monadic difference logic\nbased on the data structure Difference Decision Diagrams. The algorithm is\ncomplete in a very strong sense on a subclass of temporal formulae\ncharacterized as homogeneously monadic and it is approximate on other formulae.\nThe approximation comes from the fact that not all unsatisfiable or\ntautological formulae are recognised at the earliest possible time of the\nruntime verification.\n  Contrary to existing approaches, the presented algorithms do not work by\nsyntactic rewriting but employ efficient decision structures which make them\napplicable in real applications within for instance business software.\n", "machine_text": "\nThis work introduces a technique for carrying out temporal runtime verification using monadic difference logic. This algorithm involves three steps. First, a bounded temporal logic formula is converted into a first-order monadic logic, given by a set of difference inequalities. Second, the formula is amended each time the timed run advances, through computing the corresponding state and time current values. Finally, the ensuing formulae are determined to be either tautological or unsatisfiable by means of a specialized monadic difference decision procedure. To assist in this process, an algorithm has been devised based on Difference Decision Diagrams. This approach is complete when facing homogeneously monadic formulae and approximate in other cases, meaning that not all tautologies and unsatisfiable formulae are captured in the earliest point of runtime verification. Moreover, the proposed solution surpasses existing rewritings and makes use of efficient decision structures working towards practical applications such as business software.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4604}
{"prompt": "Rephrase the abstract of an article with title 'Calcium and synaptic dynamics underlying reverberatory activity in\n  neuronal networks'.\n  Persistent activity is postulated to drive neural network plasticity and\nlearning. To investigate its underlying cellular mechanisms, we developed a\nbiophysically tractable model that explains the emergence, sustenance, and\neventual termination of short-term persistent activity. Using the model, we\nreproduced the features of reverberating activity that were observed in small\n(50-100 cells) networks of cultured hippocampal neurons, such as the appearance\nof polysynaptic current clusters, the typical inter-cluster intervals, the\ntypical duration of reverberation, and the response to changes in\nextra-cellular ionic composition. The model relies on action\npotential-triggered residual presynaptic calcium, which we suggest plays an\nimportant role in sustaining reverberations. We show that reverberatory\nactivity is maintained by enhanced asynchronous transmitter release from\npre-synaptic terminals, which in itself depends on the dynamics of residual\npresynaptic calcium. Hence, asynchronous release, rather than being a \"synaptic\nnoise\", can play an important role in network dynamics. Additionally, we found\nthat a fast timescale synaptic depression is responsible for oscillatory\nnetwork activation during reverberations, whereas the onset of a slow timescale\ndepression leads to the termination of reverberation. The simplicity of our\nmodel enabled a number of predictions that were confirmed by additional\nanalyses of experimental manipulations.\n\n", "human_text": "  Persistent activity is postulated to drive neural network plasticity and\nlearning. To investigate its underlying cellular mechanisms, we developed a\nbiophysically tractable model that explains the emergence, sustenance, and\neventual termination of short-term persistent activity. Using the model, we\nreproduced the features of reverberating activity that were observed in small\n(50-100 cells) networks of cultured hippocampal neurons, such as the appearance\nof polysynaptic current clusters, the typical inter-cluster intervals, the\ntypical duration of reverberation, and the response to changes in\nextra-cellular ionic composition. The model relies on action\npotential-triggered residual presynaptic calcium, which we suggest plays an\nimportant role in sustaining reverberations. We show that reverberatory\nactivity is maintained by enhanced asynchronous transmitter release from\npre-synaptic terminals, which in itself depends on the dynamics of residual\npresynaptic calcium. Hence, asynchronous release, rather than being a \"synaptic\nnoise\", can play an important role in network dynamics. Additionally, we found\nthat a fast timescale synaptic depression is responsible for oscillatory\nnetwork activation during reverberations, whereas the onset of a slow timescale\ndepression leads to the termination of reverberation. The simplicity of our\nmodel enabled a number of predictions that were confirmed by additional\nanalyses of experimental manipulations.\n", "machine_text": "\nThis research gives an explanation for the emergence, sustained maintenance, and eventual cessation of short-term persistent activity in neural networks by using a biophysically tractable model. Specifically, we studied the features of reverberatory activity observed in small networks of cultured hippocampal neurons, such as the presence of polysynaptic current clusters, the amount of time in between clusters and the average length of the reverberations when faced with changes in the extra-cellular composition. We suggest that persistent reverberatory activity is supported by asynchronous neurotransmitter release triggered by action-potential dependent residual presynaptic calcium. Additionally, we found that rapid synaptic depression is the reason for oscillatory network activation during reverberation and slow time-scale depression is the cause of their termination. Our model allowed us to make multiple testable predictions that were successfully verified by further experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1611}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical Diophantine Approximation'.\n  Let $\\mu$ be a Gibbs measure of the doubling map $T$ of the circle. For a\n$\\mu$-generic point $x$ and a given sequence $\\{r_n\\} \\subset \\R^+$, consider\nthe intervals $(T^nx - r_n \\pmod 1, T^nx + r_n \\pmod 1)$. In analogy to the\nclassical Dvoretzky covering of the circle we study the covering properties of\nthis sequence of intervals. This study is closely related to the local entropy\nfunction of the Gibbs measure and to hitting times for moving targets. A mass\ntransference principle is obtained for Gibbs measures which are multifractal.\nSuch a principle was shown by Beresnevich and Velani \\cite{BV} only for\nmonofractal measures. In the symbolic language we completely describe the\ncombinatorial structure of a typical relatively short sequence, in particular\nwe can describe the occurrence of ''atypical'' relatively long words. Our\nresults have a direct and deep number-theoretical interpretation via\ninhomogeneous diadic diophantine approximation by numbers belonging to a given\n(diadic) diophantine class.\n\n", "human_text": "  Let $\\mu$ be a Gibbs measure of the doubling map $T$ of the circle. For a\n$\\mu$-generic point $x$ and a given sequence $\\{r_n\\} \\subset \\R^+$, consider\nthe intervals $(T^nx - r_n \\pmod 1, T^nx + r_n \\pmod 1)$. In analogy to the\nclassical Dvoretzky covering of the circle we study the covering properties of\nthis sequence of intervals. This study is closely related to the local entropy\nfunction of the Gibbs measure and to hitting times for moving targets. A mass\ntransference principle is obtained for Gibbs measures which are multifractal.\nSuch a principle was shown by Beresnevich and Velani \\cite{BV} only for\nmonofractal measures. In the symbolic language we completely describe the\ncombinatorial structure of a typical relatively short sequence, in particular\nwe can describe the occurrence of ''atypical'' relatively long words. Our\nresults have a direct and deep number-theoretical interpretation via\ninhomogeneous diadic diophantine approximation by numbers belonging to a given\n(diadic) diophantine class.\n", "machine_text": "\nWe analyze the covering properties of a sequence of intervals set by a given sequence of values $\\{r_n\\} \\subset \\R^+$ around a $\\mu$-generic point $x$ in the doubling map $T$ of the circle, and its relationship to the local entropy function of the Gibbs measure $\\mu$ and the hitting times of moving targets. Different to the work of Beresnevich and Velani \\cite{BV}, we establish a mass transference principle for multifractal measures. Using symbolic language, we give a detailed description of the combinatorial structure of a typical, relatively short sequence, including the occurrence of atypical, longer words. These results are further connected to the theoretical field of inhomogeneous diadic diophantine approximation of numbers falling into a certain diophantine class.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4203}
{"prompt": "Rephrase the abstract of an article with title 'Interaction of Supernova Ejecta with Nearby Protoplanetary Disks'.\n  The early Solar System contained short-lived radionuclides such as 60Fe (t1/2\n= 1.5 Myr) whose most likely source was a nearby supernova. Previous models of\nSolar System formation considered a supernova shock that triggered the collapse\nof the Sun's nascent molecular cloud. We advocate an alternative hypothesis,\nthat the Solar System's protoplanetary disk had already formed when a very\nclose (< 1 pc) supernova injected radioactive material directly into the disk.\nWe conduct the first numerical simulations designed to answer two questions\nrelated to this hypothesis: will the disk be destroyed by such a close\nsupernova; and will any of the ejecta be mixed into the disk? Our simulations\ndemonstrate that the disk does not absorb enough momentum from the shock to\nescape the protostar to which it is bound. Only low amounts (< 1%) of mass loss\noccur, due to stripping by Kelvin-Helmholtz instabilities across the top of the\ndisk, which also mix into the disk about 1% of the intercepted ejecta. These\nlow efficiencies of destruction and injectation are due to the fact that the\nhigh disk pressures prevent the ejecta from penetrating far into the disk\nbefore stalling. Injection of gas-phase ejecta is too inefficient to be\nconsistent with the abundances of radionuclides inferred from meteorites. On\nthe other hand, the radionuclides found in meteorites would have condensed into\ndust grains in the supernova ejecta, and we argue that such grains will be\ninjected directly into the disk with nearly 100% efficiency. The meteoritic\nabundances of the short-lived radionuclides such as 60Fe therefore are\nconsistent with injection of grains condensed from the ejecta of a nearby (< 1\npc) supernova, into an already-formed protoplanetary disk.\n\n", "human_text": "  The early Solar System contained short-lived radionuclides such as 60Fe (t1/2\n= 1.5 Myr) whose most likely source was a nearby supernova. Previous models of\nSolar System formation considered a supernova shock that triggered the collapse\nof the Sun's nascent molecular cloud. We advocate an alternative hypothesis,\nthat the Solar System's protoplanetary disk had already formed when a very\nclose (< 1 pc) supernova injected radioactive material directly into the disk.\nWe conduct the first numerical simulations designed to answer two questions\nrelated to this hypothesis: will the disk be destroyed by such a close\nsupernova; and will any of the ejecta be mixed into the disk? Our simulations\ndemonstrate that the disk does not absorb enough momentum from the shock to\nescape the protostar to which it is bound. Only low amounts (< 1%) of mass loss\noccur, due to stripping by Kelvin-Helmholtz instabilities across the top of the\ndisk, which also mix into the disk about 1% of the intercepted ejecta. These\nlow efficiencies of destruction and injectation are due to the fact that the\nhigh disk pressures prevent the ejecta from penetrating far into the disk\nbefore stalling. Injection of gas-phase ejecta is too inefficient to be\nconsistent with the abundances of radionuclides inferred from meteorites. On\nthe other hand, the radionuclides found in meteorites would have condensed into\ndust grains in the supernova ejecta, and we argue that such grains will be\ninjected directly into the disk with nearly 100% efficiency. The meteoritic\nabundances of the short-lived radionuclides such as 60Fe therefore are\nconsistent with injection of grains condensed from the ejecta of a nearby (< 1\npc) supernova, into an already-formed protoplanetary disk.\n", "machine_text": "\nThe injection of galactic short-lived radionuclides, such as 60Fe found in meteorites, is thought to have been sourced from a nearby supernova. In this study, we consider an alternative hypothesis to the initial model of supernova shock triggering the Solar System's protoplanetary collapse, wherein the supernova would directly inject the radioactive material into a pre-existing disk. Through numerical simulations we examine the potential for the disk to be disrupted, and the amount of original gas or dust-phase ejecta that could be mixed in. Results indicate the disk's high pressure can contain the shock wave, resulting in low (<1%) levels of mass loss due to Kelvin-Helmholtz instabilities, carrying with it around 1% of injected jet material. This is too inefficient for gas-ejection to account for meteoritic radionuclide abundances, however, the more effectively injected dust-phase materials are more likely to reach the disk and seem to explain the short-lived isotope data. Thus the meteoritic abundances of 60Fe, indicate that condensed dust grains can be injected into a protoplanetary disk as a result of a very close (<1pc) supernova.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1652}
{"prompt": "Rephrase the abstract of an article with title 'Realization of an Economical Polymer Optical Fiber Demultiplexer'.\n  Polymer Optical Fiber (POF) can be and are being used in various fields of\napplications. Two of the main fields are the automotive and the home\nentertainment sector. The POF can be applied in several different optical\ncommunication systems as automotive multi-media busses or in-house Ethernet\nsystems.\n  The requirements of bandwidth are increasing very fast in these sectors and\ntherefore solutions that satisfy these demands are of high actuality. One\nsolution is to use the wavelength division multiplexing (WDM) technique. Here,\nseveral different wavelengths can carry information over one POF fiber. All\nwavelengths that are transmitted over the fiber, must be separated at the\nreceiver to regain and redirect the information channels. These separators are\nso-called Demultiplexers.\n  There are several systems available on the market, which are all afflicted\nwith certain disadvantages. But all these solutions have one main disadvantage,\nthey are all too expensive for most of the applications mentioned above. So the\ngoal of this study is to develop an economical Demultiplexer for WDM\ntransmission over POF.\n  The main idea is to separate the chromatic light in its monochromatic\ncomponents with the help of a prism with low reciprocal dispersive power. The\nprism and the other assemblies, which are needed to adjust the optical path,\nshould be manufactured in injection molding technique. This manufacturing\ntechnique is a very simple and economical way to produce a mass production\napplicable Demultiplexer for POF.\n\n", "human_text": "  Polymer Optical Fiber (POF) can be and are being used in various fields of\napplications. Two of the main fields are the automotive and the home\nentertainment sector. The POF can be applied in several different optical\ncommunication systems as automotive multi-media busses or in-house Ethernet\nsystems.\n  The requirements of bandwidth are increasing very fast in these sectors and\ntherefore solutions that satisfy these demands are of high actuality. One\nsolution is to use the wavelength division multiplexing (WDM) technique. Here,\nseveral different wavelengths can carry information over one POF fiber. All\nwavelengths that are transmitted over the fiber, must be separated at the\nreceiver to regain and redirect the information channels. These separators are\nso-called Demultiplexers.\n  There are several systems available on the market, which are all afflicted\nwith certain disadvantages. But all these solutions have one main disadvantage,\nthey are all too expensive for most of the applications mentioned above. So the\ngoal of this study is to develop an economical Demultiplexer for WDM\ntransmission over POF.\n  The main idea is to separate the chromatic light in its monochromatic\ncomponents with the help of a prism with low reciprocal dispersive power. The\nprism and the other assemblies, which are needed to adjust the optical path,\nshould be manufactured in injection molding technique. This manufacturing\ntechnique is a very simple and economical way to produce a mass production\napplicable Demultiplexer for POF.\n", "machine_text": "\nThe goal of this study is to create an economically viable Polymer Optical Fiber (POF) Demultiplexer for Wavelength Division Multiplexing (WDM) systems to fulfil the increasing bandwidth demands of the automotive and home entertainment sectors. The concept relies on separating chromatic light into its monochromatic components with the help of a prism with low reciprocal dispersion power. To make the Demultiplexer cost-effective, components such as the prism and others necessary for path adjustment must be produced using injection molding. This technique offers an efficient and economical approach for producing POF Demultiplexers in large numbers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3964}
{"prompt": "Rephrase the abstract of an article with title 'A New Template Family For The Detection Of Gravitational Waves From\n  Comparable Mass Black Hole Binaries'.\n  In order to improve the phasing of the comparable-mass waveform as we\napproach the last stable orbit for a system, various re-summation methods have\nbeen used to improve the standard post-Newtonian waveforms. In this work we\npresent a new family of templates for the detection of gravitational waves from\nthe inspiral of two comparable-mass black hole binaries. These new adiabatic\ntemplates are based on re-expressing the derivative of the binding energy and\nthe gravitational wave flux functions in terms of shifted Chebyshev\npolynomials. The Chebyshev polynomials are a useful tool in numerical methods\nas they display the fastest convergence of any of the orthogonal polynomials.\nIn this case they are also particularly useful as they eliminate one of the\nfeatures that plagues the post-Newtonian expansion. The Chebyshev binding\nenergy now has information at all post-Newtonian orders, compared to the\npost-Newtonian templates which only have information at full integer orders. In\nthis work, we compare both the post-Newtonian and Chebyshev templates against a\nfiducially exact waveform. This waveform is constructed from a hybrid method of\nusing the test-mass results combined with the mass dependent parts of the\npost-Newtonian expansions for the binding energy and flux functions. Our\nresults show that the Chebyshev templates achieve extremely high fitting\nfactors at all PN orders and provide excellent parameter extraction. We also\nshow that this new template family has a faster Cauchy convergence, gives a\nbetter prediction of the position of the Last Stable Orbit and in general\nrecovers higher Signal-to-Noise ratios than the post-Newtonian templates.\n\n", "human_text": "  In order to improve the phasing of the comparable-mass waveform as we\napproach the last stable orbit for a system, various re-summation methods have\nbeen used to improve the standard post-Newtonian waveforms. In this work we\npresent a new family of templates for the detection of gravitational waves from\nthe inspiral of two comparable-mass black hole binaries. These new adiabatic\ntemplates are based on re-expressing the derivative of the binding energy and\nthe gravitational wave flux functions in terms of shifted Chebyshev\npolynomials. The Chebyshev polynomials are a useful tool in numerical methods\nas they display the fastest convergence of any of the orthogonal polynomials.\nIn this case they are also particularly useful as they eliminate one of the\nfeatures that plagues the post-Newtonian expansion. The Chebyshev binding\nenergy now has information at all post-Newtonian orders, compared to the\npost-Newtonian templates which only have information at full integer orders. In\nthis work, we compare both the post-Newtonian and Chebyshev templates against a\nfiducially exact waveform. This waveform is constructed from a hybrid method of\nusing the test-mass results combined with the mass dependent parts of the\npost-Newtonian expansions for the binding energy and flux functions. Our\nresults show that the Chebyshev templates achieve extremely high fitting\nfactors at all PN orders and provide excellent parameter extraction. We also\nshow that this new template family has a faster Cauchy convergence, gives a\nbetter prediction of the position of the Last Stable Orbit and in general\nrecovers higher Signal-to-Noise ratios than the post-Newtonian templates.\n", "machine_text": "This paper presents a new template family for identifying gravitational waves produced by comparable-mass black hole binaries. The templates, based upon re-expressing the derivative of the binding energy and gravitational wave flux functions using shifted Chebyshev polynomials, offer improvements in both the speed and accuracy of detecting the inspiral of two comparable-mass black hole binaries. As shifted Chebyshev polynomials have the fastest convergence of any orthogonal polynomial, they are better suited for signal detection than the traditional post-Newtonian expansions. The new templates are compared to a fiducially exact waveform, one constructed via a hybrid approach combining test-mass results with mass-dependent parts of post-Newtonian expansions for the binding energy and flux functions. The results show that these new Chebyshev templates offer significant improvements with respect to Signal-to-Noise ratios, fitting factors, the position of the Last Stable Orbit, and more.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0114}
{"prompt": "Rephrase the abstract of an article with title 'Non-commutative Donaldson-Thomas theory and the conifold'.\n  Given a quiver algebra A with relations defined by a superpotential, this\npaper defines a set of invariants of A counting framed cyclic A-modules,\nanalogous to rank-1 Donaldson-Thomas invariants of Calabi-Yau threefolds. For\nthe special case when A is the non-commutative crepant resolution of the\nthreefold ordinary double point, it is proved using torus localization that the\ninvariants count certain pyramid-shaped partition-like configurations, or\nequivalently infinite dimer configurations in the square dimer model with a\nfixed boundary condition. The resulting partition function admits an infinite\nproduct expansion, which factorizes into the rank-1 Donaldson-Thomas partition\nfunctions of the commutative crepant resolution of the singularity and its\nflop. The different partition functions are speculatively interpreted as\ncounting stable objects in the derived category of A-modules under different\nstability conditions; their relationship should then be an instance of wall\ncrossing in the space of stability conditions on this triangulated category.\n\n", "human_text": "  Given a quiver algebra A with relations defined by a superpotential, this\npaper defines a set of invariants of A counting framed cyclic A-modules,\nanalogous to rank-1 Donaldson-Thomas invariants of Calabi-Yau threefolds. For\nthe special case when A is the non-commutative crepant resolution of the\nthreefold ordinary double point, it is proved using torus localization that the\ninvariants count certain pyramid-shaped partition-like configurations, or\nequivalently infinite dimer configurations in the square dimer model with a\nfixed boundary condition. The resulting partition function admits an infinite\nproduct expansion, which factorizes into the rank-1 Donaldson-Thomas partition\nfunctions of the commutative crepant resolution of the singularity and its\nflop. The different partition functions are speculatively interpreted as\ncounting stable objects in the derived category of A-modules under different\nstability conditions; their relationship should then be an instance of wall\ncrossing in the space of stability conditions on this triangulated category.\n", "machine_text": "This paper considers the non-commutative Donaldson-Thomas invariants for the conifold. Using the theory of torus localization, it is demonstrated that the invariants count a specific set of pyramid-shaped partition-like configurations that can also be thought of as infinite dimer configurations in the square dimer model with a fixed boundary condition. Furthermore, this partition function is found to be equivalent to an infinite product expansion that factorizes into rank-1 Donaldson-Thomas partition functions of both the commutative crepant resolution of the singularity and its flop. Finally, through speculation, these partition functions are related to the stability of A-modules in the derived category and, thus, provide an instance of wall-crossing within it.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3419}
{"prompt": "Rephrase the abstract of an article with title 'X-ray Timing Observations of PSR J1930+1852 in the Crab-like SNR\n  G54.1+0.3'.\n  We present new X-ray timing and spectral observations of PSR J1930+1852, the\nyoung energetic pulsar at the center of the non-thermal supernova remnant\nG54.1+0.3. Using data obtained with the Rossi X-ray Timing Explorer and Chandra\nX-ray observatories we have derived an updated timing ephemeris of the 136 ms\npulsar spanning 6 years. During this interval, however, the period evolution\nshows significant variability from the best fit constant spin-down rate of\n$\\dot P = 7.5112(6) \\times 10^{-13}$ s s$^{-1}$, suggesting strong timing noise\nand/or glitch activity. The X-ray emission is highly pulsed ($71\\pm5%$\nmodulation) and is characterized by an asymmetric, broad profile ($\\sim 70%$\nduty cycle) which is nearly twice the radio width. The spectrum of the pulsed\nemission is well fitted with an absorbed power law of photon index $\\Gamma =\n1.2\\pm0.2$; this is marginally harder than that of the unpulsed component. The\ntotal 2-10 keV flux of the pulsar is $1.7 \\times 10^{-12}$ erg cm$^{-2}$\ns$^{-1}$. These results confirm PSR J1930+1852 as a typical Crab-like pulsar.\n\n", "human_text": "  We present new X-ray timing and spectral observations of PSR J1930+1852, the\nyoung energetic pulsar at the center of the non-thermal supernova remnant\nG54.1+0.3. Using data obtained with the Rossi X-ray Timing Explorer and Chandra\nX-ray observatories we have derived an updated timing ephemeris of the 136 ms\npulsar spanning 6 years. During this interval, however, the period evolution\nshows significant variability from the best fit constant spin-down rate of\n$\\dot P = 7.5112(6) \\times 10^{-13}$ s s$^{-1}$, suggesting strong timing noise\nand/or glitch activity. The X-ray emission is highly pulsed ($71\\pm5%$\nmodulation) and is characterized by an asymmetric, broad profile ($\\sim 70%$\nduty cycle) which is nearly twice the radio width. The spectrum of the pulsed\nemission is well fitted with an absorbed power law of photon index $\\Gamma =\n1.2\\pm0.2$; this is marginally harder than that of the unpulsed component. The\ntotal 2-10 keV flux of the pulsar is $1.7 \\times 10^{-12}$ erg cm$^{-2}$\ns$^{-1}$. These results confirm PSR J1930+1852 as a typical Crab-like pulsar.\n", "machine_text": "\nWe present a new analysis of timing and X-ray spectral data from PSR J1930+1852, the energetic young pulsar located at the centre of the non-thermal supernova remnant G54.1+0.3. Using data from the Rossi X-ray Timing Explorer and Chandra X-ray observatories, we tracked the period of the 136 ms pulsar over a 6-year span. We observed strong timing noise and/or glitch activity, deviating from the expected spin-down rate of $\\dot P = 7.5112(6) \\times 10^{-13}$ s s$^{-1}$. The X-ray emission showed a high degree of pulsation, modulated by 71%, with an asymmetrical pulse shape. The high energy flux sits at $1.7 \\times 10^{-12}$ erg cm$^{-2}$ s$^{-1}$ and has a photon index of 1.2\u00b10.2, making it harder than the unpulsed component. These observations reaffirm PSR J1930+1852 as a representative of the \u2018Crab-like pulsar\u2019 class.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0973}
{"prompt": "Rephrase the abstract of an article with title 'Simulation of Heme using DFT+U: a step toward accurate spin-state\n  energetics'.\n  We investigate the DFT+U approach as a viable solution to describe the\nlow-lying states of ligated and unligated iron heme complexes. Besides their\ncentral role in organometallic chemistry, these compounds represent a\nparadigmatic case where LDA, GGA, and common hybrid functionals fail to\nreproduce the experimental magnetic splittings. In particular, the imidazole\npentacoordinated heme is incorrectly described as a triplet by all usual DFT\nflavors. In this study we show that a U parameter close to 4 eV leads to spin\ntransitions and molecular geometries in quantitative agreement with\nexperiments, and that DFT+U represents an appealing tool in the description of\niron porphyrin complexes, at a much reduced cost compared to correlated\nquantum-chemistry methods. The possibility of obtaining the U parameter from\nfirst-principles is explored through a self-consistent linear-response\nformulation. We find that this approach, which proved to be successful in other\niron systems, produces in this case some overestimation with respect to the\noptimal values of U.\n\n", "human_text": "  We investigate the DFT+U approach as a viable solution to describe the\nlow-lying states of ligated and unligated iron heme complexes. Besides their\ncentral role in organometallic chemistry, these compounds represent a\nparadigmatic case where LDA, GGA, and common hybrid functionals fail to\nreproduce the experimental magnetic splittings. In particular, the imidazole\npentacoordinated heme is incorrectly described as a triplet by all usual DFT\nflavors. In this study we show that a U parameter close to 4 eV leads to spin\ntransitions and molecular geometries in quantitative agreement with\nexperiments, and that DFT+U represents an appealing tool in the description of\niron porphyrin complexes, at a much reduced cost compared to correlated\nquantum-chemistry methods. The possibility of obtaining the U parameter from\nfirst-principles is explored through a self-consistent linear-response\nformulation. We find that this approach, which proved to be successful in other\niron systems, produces in this case some overestimation with respect to the\noptimal values of U.\n", "machine_text": "The aim of this work is to assess the accuracy of the DFT+U approach in the modelling of heme systems, which are commonly used in organometallic chemistry but have so far been insufficiently described by LDA, GGA, and other hybrid functionals. In particular, our findings demonstrate that a U parameter of around 4 eV enables the accurate prediction of spin states and molecular geometries in accordance with experimental evidence. We also demonstrate that the DFT+U approach outperforms more time and computationally expensive quantum-chemistry methods at a lower cost. Finally, we study the possibility of deriving the U parameter from first principles by means of self-consistent linear response theory, and show that while this approach can yield promising results, some overestimation of U value is present.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2743}
{"prompt": "Rephrase the abstract of an article with title 'Distributed implementation of standard oracle operators'.\n  The standard oracle operator corresponding to a function f is a unitary\noperator that computes this function coherently, i.e. it maintains\nsuperpositions. This operator acts on a bipartite system, where the subsystems\nare the input and output registers. In distributed quantum computation, these\nsubsystems may be spatially separated, in which case we will be interested in\nits classical and entangling capacities. For an arbitrary function f, we show\nthat the unidirectional classical and entangling capacities of this operator\nare log_{2}(n_{f}) bits/ebits, where n_{f} is the number of different values\nthis function can take. An optimal procedure for bidirectional classical\ncommunication with a standard oracle operator corresponding to a permutation on\nZ_{M} is given. The bidirectional classical capacity of such an operator is\nfound to be 2log_{2}(M) bits. The proofs of these capacities are facilitated by\nan optimal distributed protocol for the implementation of an arbitrary standard\noracle operator.\n\n", "human_text": "  The standard oracle operator corresponding to a function f is a unitary\noperator that computes this function coherently, i.e. it maintains\nsuperpositions. This operator acts on a bipartite system, where the subsystems\nare the input and output registers. In distributed quantum computation, these\nsubsystems may be spatially separated, in which case we will be interested in\nits classical and entangling capacities. For an arbitrary function f, we show\nthat the unidirectional classical and entangling capacities of this operator\nare log_{2}(n_{f}) bits/ebits, where n_{f} is the number of different values\nthis function can take. An optimal procedure for bidirectional classical\ncommunication with a standard oracle operator corresponding to a permutation on\nZ_{M} is given. The bidirectional classical capacity of such an operator is\nfound to be 2log_{2}(M) bits. The proofs of these capacities are facilitated by\nan optimal distributed protocol for the implementation of an arbitrary standard\noracle operator.\n", "machine_text": "\nIn this article, we examine the distributed implementation of standard oracle operators and their associated unidirectional and bidirectional classical and entangling capacities. The standard oracle operator is a unitary operator that coputes a function coherently while maintaining superpositions on a bipartite system - the input and output registers. We present an optimal protocol for bidirectional classical communication with a permutation function, and derive the corresponding capacities of 2log_{2}(M) bits. We also establish the unidirectional classical and entangling capacities as log_{2}(n_{f}) bits/ ebbits for an arbitrary function f, with n_{f} denoting the number of different values this function can take. The described protocol and associated results facilitate the distributed implementation of the oracle operator.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2249}
{"prompt": "Rephrase the abstract of an article with title 'MgB2 single crystals substituted with Li and with Li-C: Structural and\n  superconducting properties'.\n  The effect of Li substitution for Mg and of Li-C co-substitution on the\nsuperconducting properties and crystal structure of MgB2 single crystals has\nbeen investigated. It has been found that hole doping with Li decreases the\nsuperconducting transition temperature Tc, but at a slower rate than electron\ndoping with C or Al. Tc of MgB2 crystals with simultaneously substituted Li for\nMg and C for B decreases more than in the case where C is substituted alone.\nThis means that holes introduced by Li cannot counterbalance the effect of\ndecrease of Tc caused by introduction of electrons coming from C. The possible\nreason of it can be that holes coming from Li occupy the pi band while\nelectrons coming from C fill the sigma band. The temperature dependences of the\nupper critical field Hc2 for Al and Li substituted crystals with the same Tc\nshow a similar dHc2/dT slope at Tc and a similar Hc2(T) behavior, despite of\nmuch different substitution level. This indicates that the mechanism\ncontrolling Hc2 and Tc is similar in both hole and electron doped crystals.\nElectrical transport measurements show an increase of resistivity both in Li\nsubstituted crystals and in Li and C co-substituted crystals. This indicates\nenhanced scattering due to defects introduced by substitutions including\ndistortion of the lattice. The observed behavior can be explained as a result\nof two effects, influencing both Tc and Hc2. The first one is doping related to\nthe changes in the carrier concentration, which may lead to the decrease or to\nthe increase of Tc. The second one is related to the introduction of new\nscattering centers leading to the modification of the interband and/or\nintraband scattering and therefore, to changes in the superconducting gaps and\nto the reduction of Tc.\n\n", "human_text": "  The effect of Li substitution for Mg and of Li-C co-substitution on the\nsuperconducting properties and crystal structure of MgB2 single crystals has\nbeen investigated. It has been found that hole doping with Li decreases the\nsuperconducting transition temperature Tc, but at a slower rate than electron\ndoping with C or Al. Tc of MgB2 crystals with simultaneously substituted Li for\nMg and C for B decreases more than in the case where C is substituted alone.\nThis means that holes introduced by Li cannot counterbalance the effect of\ndecrease of Tc caused by introduction of electrons coming from C. The possible\nreason of it can be that holes coming from Li occupy the pi band while\nelectrons coming from C fill the sigma band. The temperature dependences of the\nupper critical field Hc2 for Al and Li substituted crystals with the same Tc\nshow a similar dHc2/dT slope at Tc and a similar Hc2(T) behavior, despite of\nmuch different substitution level. This indicates that the mechanism\ncontrolling Hc2 and Tc is similar in both hole and electron doped crystals.\nElectrical transport measurements show an increase of resistivity both in Li\nsubstituted crystals and in Li and C co-substituted crystals. This indicates\nenhanced scattering due to defects introduced by substitutions including\ndistortion of the lattice. The observed behavior can be explained as a result\nof two effects, influencing both Tc and Hc2. The first one is doping related to\nthe changes in the carrier concentration, which may lead to the decrease or to\nthe increase of Tc. The second one is related to the introduction of new\nscattering centers leading to the modification of the interband and/or\nintraband scattering and therefore, to changes in the superconducting gaps and\nto the reduction of Tc.\n", "machine_text": "\nThis research examines the changes in the superconducting characteristics, as well as the crystal structure, of MgB2 single crystals which have been substituted with Li, and co-substituted with Li-C. It has been determined that the introduction of holes into the lattice through Li substitution decreases the critical transition temperature Tc of the crystal, albeit at a slower rate than in the case of electron doping with elements such as Al or C. Additionally, when both Li and C are involved together, the Tc of the MgB2 crystal decreases even more severely. Examination of the temperature dependences of the upper critical field Hc2 for crystals of equivalent Tc with differing substitution levels has revealed that the Hc2 behaviour is similar in both hole and electron doped crystals. It is thought that this may be due to holes from Li occupying the pi band, while electrons from C filling the sigma band. Transport measurements have demonstrated a subsequent increase in resistivity in both Li-substituted and Li-C co-substituted crystals, which could be attributed to the formation of defects arising from the lattice distortions caused by substitution. It appears that both the introduction of carriers and newly created scattering mechanisms play a role in seeing changes in both Tc and Hc2.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3526}
{"prompt": "Rephrase the abstract of an article with title 'New flaring of an ultraluminous X-ray source in NGC 1365'.\n  We have studied a highly variable ultraluminous X-ray source (ULX) in the\nFornax galaxy NGC 1365, with a series of 12 Chandra and XMM-Newton observations\nbetween 2002 and 2006. In 2006 April, the source peaked at a luminosity ~ 3 x\n10^{40} erg/s in the 0.3-10 keV band (similar to the maximum luminosity found\nby ASCA in 1995), and declined on an e-folding timescale ~ 3 days. The X-ray\nspectrum is always dominated by a broad power-law-like component. When the\nsource is seen at X-ray luminosities ~ 10^{40} erg/s, an additional soft\nthermal component (which we interpret as emission from the accretion disk)\ncontributes ~ 1/4 of the X-ray flux; when the luminosity is higher, ~ 3 x\n10^{40} erg/s, the thermal component is not detected and must contribute < 10%\nof the flux. At the beginning of the decline, ionized absorption is detected\naround 0.5-2 keV; it is a possible signature of a massive outflow. The\npower-law is always hard, with a photon index Gamma ~ 1.7 (and even flatter at\ntimes), as is generally the case with bright ULXs. We speculate that this\nsource and perhaps most other bright ULXs are in a high/hard state: as the\naccretion rate increases well above the Eddington limit, more and more power is\nextracted from the inner region of the inflow through non-radiative channels,\nand is used to power a Comptonizing corona, jet or wind. The observed thermal\ncomponent comes from the standard outer disk; the transition radius between\nouter standard disk and Comptonizing inner region moves further out and to\nlower disk temperatures as the accretion rate increases. This produces the\nobserved appearance of a large, cool disk. Based on X-ray luminosity and\nspectral arguments, we suggest that this accreting black hole has a likely mass\n~ 50-150 Msun (even without accounting for possible beaming).\n\n", "human_text": "  We have studied a highly variable ultraluminous X-ray source (ULX) in the\nFornax galaxy NGC 1365, with a series of 12 Chandra and XMM-Newton observations\nbetween 2002 and 2006. In 2006 April, the source peaked at a luminosity ~ 3 x\n10^{40} erg/s in the 0.3-10 keV band (similar to the maximum luminosity found\nby ASCA in 1995), and declined on an e-folding timescale ~ 3 days. The X-ray\nspectrum is always dominated by a broad power-law-like component. When the\nsource is seen at X-ray luminosities ~ 10^{40} erg/s, an additional soft\nthermal component (which we interpret as emission from the accretion disk)\ncontributes ~ 1/4 of the X-ray flux; when the luminosity is higher, ~ 3 x\n10^{40} erg/s, the thermal component is not detected and must contribute < 10%\nof the flux. At the beginning of the decline, ionized absorption is detected\naround 0.5-2 keV; it is a possible signature of a massive outflow. The\npower-law is always hard, with a photon index Gamma ~ 1.7 (and even flatter at\ntimes), as is generally the case with bright ULXs. We speculate that this\nsource and perhaps most other bright ULXs are in a high/hard state: as the\naccretion rate increases well above the Eddington limit, more and more power is\nextracted from the inner region of the inflow through non-radiative channels,\nand is used to power a Comptonizing corona, jet or wind. The observed thermal\ncomponent comes from the standard outer disk; the transition radius between\nouter standard disk and Comptonizing inner region moves further out and to\nlower disk temperatures as the accretion rate increases. This produces the\nobserved appearance of a large, cool disk. Based on X-ray luminosity and\nspectral arguments, we suggest that this accreting black hole has a likely mass\n~ 50-150 Msun (even without accounting for possible beaming).\n", "machine_text": "We report a significant flare in an ultraluminous X-ray source located inside NGC 1365, a galaxy in the Fornax cluster. Utilizing 12 Chandra and XMM-Newton observations taken from 2002 - 2006, we found that the source brightness peaked at ~3 x 10^40 erg/s and then quickly declined on an e-folding timescale of approximately 3 days. X-ray spectroscopy revealed a dominant broad power-law-like component as well as an additional soft thermal component when the luminosity was at or near ~10^40 erg/s. This thermal component is theorized to be emitted from the accretion disk. Ionized absorption was also observed at the beginning of the decline in brightness. These results, combined with a photon index of Gamma ~1.7 and lack of thermal emission when luminosity is above 3 X 10^40 erg/s suggest that this source is in a \u2018high/hard\u2019 state. Our analysis of the data implies the accreting black hole has a mass of 50 - 150 Msun, even without considering beaming effects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3977}
{"prompt": "Rephrase the abstract of an article with title 'A Novel String Derived Z' With Stable Proton, Light-Neutrinos and\n  R-parity violation'.\n  The Standard Model indicates the realization of grand unified structures in\nnature, and can only be viewed as an effective theory below a higher energy\ncutoff. While the renormalizable Standard Model forbids proton decay mediating\noperators due to accidental global symmetries, many extensions of the Standard\nModel introduce such dimension four, five and six operators. Furthermore,\nquantum gravity effects are expected to induce proton instability, indicating\nthat the higher energy cutoff scale must be above 10^{16}GeV. Quasi-realistic\nheterotic string models provide the arena to explore how perturbative quantum\ngravity affects the particle physics phenomenology. An appealing explanation\nfor the proton longevity is provided by the existence of an Abelian gauge\nsymmetry that suppresses the proton decay mediating operators. Additionally,\nsuch a low-scale U(1) symmetry should: allow the suppression of the left-handed\nneutrino masses by a seesaw mechanism; allow fermion Yukawa couplings to the\nelectroweak Higgs doublets; be anomaly free; be family universal. These\nrequirements render the existence of such U(1) symmetries in quasi-realistic\nheterotic string models highly non-trivial. We demonstrate the existence of a\nU(1) symmetry that satisfies all of the above requirements in a class of\nleft-right symmetric heterotic string models in the free fermionic formulation.\nThe existence of the extra Z' in the energy range accessible to future\nexperiments is motivated by the requirement of adequate suppression of proton\ndecay mediation. We further show that while the extra U(1) forbids dimension\nfour baryon number violating operators it allows dimension four lepton number\nviolating operators and R-parity violation.\n\n", "human_text": "  The Standard Model indicates the realization of grand unified structures in\nnature, and can only be viewed as an effective theory below a higher energy\ncutoff. While the renormalizable Standard Model forbids proton decay mediating\noperators due to accidental global symmetries, many extensions of the Standard\nModel introduce such dimension four, five and six operators. Furthermore,\nquantum gravity effects are expected to induce proton instability, indicating\nthat the higher energy cutoff scale must be above 10^{16}GeV. Quasi-realistic\nheterotic string models provide the arena to explore how perturbative quantum\ngravity affects the particle physics phenomenology. An appealing explanation\nfor the proton longevity is provided by the existence of an Abelian gauge\nsymmetry that suppresses the proton decay mediating operators. Additionally,\nsuch a low-scale U(1) symmetry should: allow the suppression of the left-handed\nneutrino masses by a seesaw mechanism; allow fermion Yukawa couplings to the\nelectroweak Higgs doublets; be anomaly free; be family universal. These\nrequirements render the existence of such U(1) symmetries in quasi-realistic\nheterotic string models highly non-trivial. We demonstrate the existence of a\nU(1) symmetry that satisfies all of the above requirements in a class of\nleft-right symmetric heterotic string models in the free fermionic formulation.\nThe existence of the extra Z' in the energy range accessible to future\nexperiments is motivated by the requirement of adequate suppression of proton\ndecay mediation. We further show that while the extra U(1) forbids dimension\nfour baryon number violating operators it allows dimension four lepton number\nviolating operators and R-parity violation.\n", "machine_text": "\nThis paper investigates how perturbative quantum gravity affects the particle \nphysics phenomenology of quasi-realistic heterotic string models. We identify an \nappealing explanation for the longevity of the proton that lies in the existence \nof an Abelian gauge symmetry. This U(1) symmetry should suppress the proton decay \nmediating operators, permit fermion Yukawa couplings to the electroweak Higgs \ndoublets, and allow the suppression of left-handed neutrino masses by a seesaw \nmechanism. Following stringent requirements, we successfully demonstrate the \nexistence of a suitable U(1) symmetry in this class of models. We find that this \nZ' is predicted to exist potentially in the energy range accessible to future \nexperiments, and is also capable of inducing both lepton number and R-parity \nviolation, while suppressing baryon number violation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1256}
{"prompt": "Rephrase the abstract of an article with title 'The Transfer Matrix of Superintegrable Chiral Potts Model as the\n  Q-operator of Root-of-unity XXZ Chain with Cyclic Representation of\n  $U_q(sl_2)$'.\n  We demonstrate that the transfer matrix of the inhomogeneous $N$-state chiral\nPotts model with two vertical superintegrable rapidities serves as the\n$Q$-operator of XXZ chain model for a cyclic representation of $U_{\\sf\nq}(sl_2)$ with $N$th root-of-unity ${\\sf q}$ and representation-parameter for\nodd $N$. The symmetry problem of XXZ chain with a general cyclic $U_{\\sf\nq}(sl_2)$-representation is mapped onto the problem of studying $Q$-operator of\nsome special one-parameter family of generalized $\\tau^{(2)}$-models. In\nparticular, the spin-$\\frac{N-1}{2}$ XXZ chain model with ${\\sf q}^N=1$ and the\nhomogeneous $N$-state chiral Potts model at a specific superintegrable point\nare unified as one physical theory. By Baxter's method developed for producing\n$Q_{72}$-operator of the root-of-unity eight-vertex model, we construct the\n$Q_R, Q_L$- and $Q$-operators of a superintegrable $\\tau^{(2)}$-model, then\nidentify them with transfer matrices of the $N$-state chiral Potts model for a\npositive integer $N$. We thus obtain a new method of producing the\nsuperintegrable $N$-state chiral Potts transfer matrix from the\n$\\tau^{(2)}$-model by constructing its $Q$-operator.\n\n", "human_text": "  We demonstrate that the transfer matrix of the inhomogeneous $N$-state chiral\nPotts model with two vertical superintegrable rapidities serves as the\n$Q$-operator of XXZ chain model for a cyclic representation of $U_{\\sf\nq}(sl_2)$ with $N$th root-of-unity ${\\sf q}$ and representation-parameter for\nodd $N$. The symmetry problem of XXZ chain with a general cyclic $U_{\\sf\nq}(sl_2)$-representation is mapped onto the problem of studying $Q$-operator of\nsome special one-parameter family of generalized $\\tau^{(2)}$-models. In\nparticular, the spin-$\\frac{N-1}{2}$ XXZ chain model with ${\\sf q}^N=1$ and the\nhomogeneous $N$-state chiral Potts model at a specific superintegrable point\nare unified as one physical theory. By Baxter's method developed for producing\n$Q_{72}$-operator of the root-of-unity eight-vertex model, we construct the\n$Q_R, Q_L$- and $Q$-operators of a superintegrable $\\tau^{(2)}$-model, then\nidentify them with transfer matrices of the $N$-state chiral Potts model for a\npositive integer $N$. We thus obtain a new method of producing the\nsuperintegrable $N$-state chiral Potts transfer matrix from the\n$\\tau^{(2)}$-model by constructing its $Q$-operator.\n", "machine_text": "We analyze the $Q$-operator of XXZ chain for cyclic representation\nof $U_{\\sf q}(sl_2)$, which then yields the transfer matrix of a\nsuperintegrable inhomogeneous $N$-state chiral Potts model for odd\n$N$ at two vertical rapidities. This allows us to unify the\nspin-$\\frac{N-1}{2}$ XXZ chain model with ${\\sf q}^N=1$ and the\nhomogeneous $N$-state chiral Potts model at a specific\nsuperintegrable point as one physical theory.  We demonstrate a\nnovel method by which the superintegrable transfer matrix of the\n$N$-state chiral Potts model can be constructed with Baxter's\ntechnique applied to the root-of-unity eight-vertex model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2856}
{"prompt": "Rephrase the abstract of an article with title 'Hamiltonian formalism in Friedmann cosmology and its quantization'.\n  We propose a Hamiltonian formalism for a generalized\nFriedmann-Roberson-Walker cosmology model in the presence of both a variable\nequation of state (EOS) parameter $w(a)$ and a variable cosmological constant\n$\\Lambda(a)$, where $a$ is the scale factor. This Hamiltonian system containing\n1 degree of freedom and without constraint, gives Friedmann equations as the\nequation of motion, which describes a mechanical system with a variable mass\nobject moving in a potential field. After an appropriate transformation of the\nscale factor, this system can be further simplified to an object with constant\nmass moving in an effective potential field. In this framework, the $\\Lambda$\ncold dark matter model as the current standard model of cosmology corresponds\nto a harmonic oscillator. We further generalize this formalism to take into\naccount the bulk viscosity and other cases. The Hamiltonian can be quantized\nstraightforwardly, but this is different from the approach of the\nWheeler-DeWitt equation in quantum cosmology.\n\n", "human_text": "  We propose a Hamiltonian formalism for a generalized\nFriedmann-Roberson-Walker cosmology model in the presence of both a variable\nequation of state (EOS) parameter $w(a)$ and a variable cosmological constant\n$\\Lambda(a)$, where $a$ is the scale factor. This Hamiltonian system containing\n1 degree of freedom and without constraint, gives Friedmann equations as the\nequation of motion, which describes a mechanical system with a variable mass\nobject moving in a potential field. After an appropriate transformation of the\nscale factor, this system can be further simplified to an object with constant\nmass moving in an effective potential field. In this framework, the $\\Lambda$\ncold dark matter model as the current standard model of cosmology corresponds\nto a harmonic oscillator. We further generalize this formalism to take into\naccount the bulk viscosity and other cases. The Hamiltonian can be quantized\nstraightforwardly, but this is different from the approach of the\nWheeler-DeWitt equation in quantum cosmology.\n", "machine_text": "\nThis article investigates a Hamiltonian formalism in Friedmann cosmology, introducing a variable equation of state and varying cosmological constant. Presenting a system with a single degree of freedom and no constraints, equivalent to a mechanical system with a changing mass particle in a potential field, the Friedmann equations are recovered as the equation of motion. We explore simplifying the system through a transformation of the scale factor, leading to a particle of fixed mass in an effective potential field. The $\\Lambda$ cold dark matter model equates to an harmonic oscillator in this context, and the formalism is extended to incorporate elements of bulk viscosity. Finally, utilising a straightforward approach, the Hamiltonian is observed to be quantized, displaying a contrast from the approach of the Wheeler-DeWitt equation in quantum cosmology.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0672}
{"prompt": "Rephrase the abstract of an article with title 'Free Energy of Activation for the Comorosan Effect'.\n  Initial reaction rate data for lactic dehydrogenase / pyruvate, lactic\ndehydrogenase / lactate and malic dehydrogenase / malate enzyme reactions were\nanalyzed to obtain activation free energy changes of -329, -195 and -221\ncal/mole, respectively, for rate increases associated with time-specific\nirradiation of the crystalline substrates prior to dissolution and\nincorporation in the reaction solutions. These energies, presumably, correspond\nto conformational or vibrational changes in the reactants or the activated\ncomplex. For the lactic dehydrogenase / pyruvate reaction, it is estimated that\non the order of 10% of the irradiation energy (546 nm, 400 footcandles for 5\nseconds) would be required to produce the observed reaction rate increase if a\npresumed photoproduct is consumed stoichiometrically with the pyruvate\nsubstrate. These findings are consistent with the proposition that the observed\nreaction rate enhancement involves photoproducts derived from oscillatory\natmospheric gas reactions at the crystalline enzyme substrate surfaces rather\nthan photo-excitations of the substrate molecules, per se.\n\n", "human_text": "  Initial reaction rate data for lactic dehydrogenase / pyruvate, lactic\ndehydrogenase / lactate and malic dehydrogenase / malate enzyme reactions were\nanalyzed to obtain activation free energy changes of -329, -195 and -221\ncal/mole, respectively, for rate increases associated with time-specific\nirradiation of the crystalline substrates prior to dissolution and\nincorporation in the reaction solutions. These energies, presumably, correspond\nto conformational or vibrational changes in the reactants or the activated\ncomplex. For the lactic dehydrogenase / pyruvate reaction, it is estimated that\non the order of 10% of the irradiation energy (546 nm, 400 footcandles for 5\nseconds) would be required to produce the observed reaction rate increase if a\npresumed photoproduct is consumed stoichiometrically with the pyruvate\nsubstrate. These findings are consistent with the proposition that the observed\nreaction rate enhancement involves photoproducts derived from oscillatory\natmospheric gas reactions at the crystalline enzyme substrate surfaces rather\nthan photo-excitations of the substrate molecules, per se.\n", "machine_text": "\nAn analysis of data from three enzyme-catalyzed reactions (lactic dehydrogenase / pyruvate, lactic dehydrogenase / lactate and malic dehydrogenase / malate) showed an activation free energy change in the range of -329 to -221 cal/mole associated with time-specific irradiation of the crystalline substrates prior to dissolution and incorporation into the reaction mixture. The energy presumably represents changes in the conformation or vibration of the reactants of the activated complex. Assuming that 10% of the irradiation energy was consumed during the pyruvate reaction, the results suggest that the observed rate increase is due to photoproducts derived from gas oscillations on the crystalline enzyme substrate surface, and not necessarily due to photo-excitation of the substrate molecules.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1504}
{"prompt": "Rephrase the abstract of an article with title 'Conservation-Law-Induced Quantum Limits for Physical Realizations of the\n  Quantum NOT Gate'.\n  In recent investigations, it has been found that conservation laws generally\nlead to precision limits on quantum computing. Lower bounds of the error\nprobability have been obtained for various logic operations from the\ncommutation relation between the noise operator and the conserved quantity or\nfrom the recently developed universal uncertainty principle for the\nnoise-disturbance trade-off in general measurements. However, the problem of\nobtaining the precision limit to realizing the quantum NOT gate has eluded a\nsolution from these approaches. Here, we develop a new method for this problem\nbased on analyzing the trace distance between the output state from the\nrealization under consideration and the one from the ideal gate. Using the\nmathematical apparatus of orthogonal polynomials, we obtain a general lower\nbound on the error probability for the realization of the quantum NOT gate in\nterms of the number of qubits in the control system under the conservation of\nthe total angular momentum of the computational qubit plus the the control\nsystem along the direction used to encode the computational basis. The lower\nbound turns out to be more stringent than one might expect from previous\nresults. The new method is expected to lead to more accurate estimates for\nphysical realizations of various types of quantum computations under\nconservation laws, and to contribute to related problems such as the accuracy\nof programmable quantum processors.\n\n", "human_text": "  In recent investigations, it has been found that conservation laws generally\nlead to precision limits on quantum computing. Lower bounds of the error\nprobability have been obtained for various logic operations from the\ncommutation relation between the noise operator and the conserved quantity or\nfrom the recently developed universal uncertainty principle for the\nnoise-disturbance trade-off in general measurements. However, the problem of\nobtaining the precision limit to realizing the quantum NOT gate has eluded a\nsolution from these approaches. Here, we develop a new method for this problem\nbased on analyzing the trace distance between the output state from the\nrealization under consideration and the one from the ideal gate. Using the\nmathematical apparatus of orthogonal polynomials, we obtain a general lower\nbound on the error probability for the realization of the quantum NOT gate in\nterms of the number of qubits in the control system under the conservation of\nthe total angular momentum of the computational qubit plus the the control\nsystem along the direction used to encode the computational basis. The lower\nbound turns out to be more stringent than one might expect from previous\nresults. The new method is expected to lead to more accurate estimates for\nphysical realizations of various types of quantum computations under\nconservation laws, and to contribute to related problems such as the accuracy\nof programmable quantum processors.\n", "machine_text": "\nAnalyses of conservation laws have previously been conducted to examine their impact on the accuracy of quantum computing operations. Such studies have yielded lower limits of error probabilities for a variety of logic operations. Nevertheless, the challenge of determining the exact lower bound for the implementation of a quantum NOT gate has yet to be resolved through such approaches. This paper introduces a new framework for addressing this issue. We analyze the trace distance between the output state resulting from the actual gate and that intended to be produced by the ideal quantum NOT gate. By employing orthogonal polynomials, we compute a general lower bound on the error probability related to realizations of the quantum NOT gate using control systems containing a certain number of qubits, in which the total angular momentum of the computation qubit plus the control will remain conserved along the dirction used to encode the own system. This lower bound proves to be more demanding than one expected from the previous results. Our new approach should assist with obtaining higher accuracies in other physical implementations of quantum computing operations where conservation laws are imposed, as well as help to answer questions such as the degree of accuracy achievable in programmable quantum processors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.188}
{"prompt": "Rephrase the abstract of an article with title 'Characterization of separability and entanglement in $(2\\times{D})$- and\n  $(3\\times{D})$-dimensional systems by single-qubit and single-qutrit unitary\n  transformations'.\n  We investigate the geometric characterization of pure state bipartite\nentanglement of $(2\\times{D})$- and $(3\\times{D})$-dimensional composite\nquantum systems. To this aim, we analyze the relationship between states and\ntheir images under the action of particular classes of local unitary\noperations. We find that invariance of states under the action of single-qubit\nand single-qutrit transformations is a necessary and sufficient condition for\nseparability. We demonstrate that in the $(2\\times{D})$-dimensional case the\nvon Neumann entropy of entanglement is a monotonic function of the minimum\nsquared Euclidean distance between states and their images over the set of\nsingle qubit unitary transformations. Moreover, both in the $(2\\times{D})$- and\nin the $(3\\times{D})$-dimensional cases the minimum squared Euclidean distance\nexactly coincides with the linear entropy (and thus as well with the tangle\nmeasure of entanglement in the $(2\\times{D})$-dimensional case). These results\nprovide a geometric characterization of entanglement measures originally\nestablished in informational frameworks. Consequences and applications of the\nformalism to quantum critical phenomena in spin systems are discussed.\n\n", "human_text": "  We investigate the geometric characterization of pure state bipartite\nentanglement of $(2\\times{D})$- and $(3\\times{D})$-dimensional composite\nquantum systems. To this aim, we analyze the relationship between states and\ntheir images under the action of particular classes of local unitary\noperations. We find that invariance of states under the action of single-qubit\nand single-qutrit transformations is a necessary and sufficient condition for\nseparability. We demonstrate that in the $(2\\times{D})$-dimensional case the\nvon Neumann entropy of entanglement is a monotonic function of the minimum\nsquared Euclidean distance between states and their images over the set of\nsingle qubit unitary transformations. Moreover, both in the $(2\\times{D})$- and\nin the $(3\\times{D})$-dimensional cases the minimum squared Euclidean distance\nexactly coincides with the linear entropy (and thus as well with the tangle\nmeasure of entanglement in the $(2\\times{D})$-dimensional case). These results\nprovide a geometric characterization of entanglement measures originally\nestablished in informational frameworks. Consequences and applications of the\nformalism to quantum critical phenomena in spin systems are discussed.\n", "machine_text": "\nWe analyze the geometric properties of bipartite pure state entanglement of $(2\\times{D})$- and $(3\\times{D})$-dimensional quantum systems when acted upon by single-qubit and single-qutrit local unitary transformations. Our research reveals that the invariance of states under the said transformations is a necessary and sufficient condition for separability. Furthermore, the computation of the von Neumann entropy of entanglement for the $(2\\times{D})$-dimensional case is a monotonic function of the squared Euclidean distance between states and their images. In both cases, both linear entropy and tangle measure (for $(2\\times{D})$-dimensional case) are found to be exact representations of the squared Euclidean distance. We discuss the implications of this formalism and its applications to quantum critical phenomena in spin systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1561}
{"prompt": "Rephrase the abstract of an article with title 'Secure sharing of random bits over the Internet'.\n  Although one-time pad encrypted files can be sent through Internet channels,\nthe need for renewing shared secret keys have made this method unpractical.\nThis work presents a scheme to turn practical the fast sharing of random keys\nover arbitrary Internet channels. Starting with a shared secret key sequence of\nlength K_0 the users end up with a secure new sequence K >> K_0. Using these\nsequences for posteriori message encryption the legitimate users have absolute\nsecurity control without the need for third parties. Additionally, the security\nlevel does not depend on the unproven difficulty of factoring numbers in\nprimes. In the proposed scheme a fast optical random source generates random\nbits and noise for key renewals. The transmitted signals are recorded signals\nthat carries both the random binary signals to be exchanged and physical noise\nthat cannot be eliminated by the attacker. These signals allow amplification\nover the Internet network without degrading security. The proposed system is\nalso secure against a-posteriori known-plaintext attack on the key.\nInformation-theoretic analysis is presented and bounds for secure operation are\nquantitatively determined.\n\n", "human_text": "  Although one-time pad encrypted files can be sent through Internet channels,\nthe need for renewing shared secret keys have made this method unpractical.\nThis work presents a scheme to turn practical the fast sharing of random keys\nover arbitrary Internet channels. Starting with a shared secret key sequence of\nlength K_0 the users end up with a secure new sequence K >> K_0. Using these\nsequences for posteriori message encryption the legitimate users have absolute\nsecurity control without the need for third parties. Additionally, the security\nlevel does not depend on the unproven difficulty of factoring numbers in\nprimes. In the proposed scheme a fast optical random source generates random\nbits and noise for key renewals. The transmitted signals are recorded signals\nthat carries both the random binary signals to be exchanged and physical noise\nthat cannot be eliminated by the attacker. These signals allow amplification\nover the Internet network without degrading security. The proposed system is\nalso secure against a-posteriori known-plaintext attack on the key.\nInformation-theoretic analysis is presented and bounds for secure operation are\nquantitatively determined.\n", "machine_text": "\nThis article offers a novel approach to securely share random bits over the Internet without needing to use third parties as well as factoring numbers into primes. The scheme starts with a shared sequence of length K_0 and then, with the use of a fast optical random source, generates needed random bits and noise for creating a sequence K >> K_0. This is done in order to enable thorough encryption for each message transmitted - users have absolute control of the security. The transmission of the random signals and physical noise are in the form of recorded signals which are immune from any deduction or addition from an outside attacker. This process is further examined and has also been proven to be secure against known-plaintext attack. The information-theoretic analysis provides quantitative bounds for secure operation of the system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2243}
{"prompt": "Rephrase the abstract of an article with title 'Theory of anomalous diffusive reaction rates on realistic self-affine\n  fractals'.\n  In this letter, a theoretical method for the analysis of diffusive\nflux/current to limited scale self-affine random fractals is presented and\ncompared with experimentally measured electrochemical current for such\nroughness. The theory explains the several experimental findings of the\ntemporal scale invariance as well as deviation from this of current transients\nin terms of three dominant fractal parameters for the limited-length scales of\nroughness. This theoretical method is based on limited scale power-law\ncharacterization of the interfacial roughness spectrum and the solution of\ndiffusion equation under the diffusion-limited boundary conditions on rough\ninterfaces. More broadly, these calculations challenges the earlier belief that\nthe anomalous behavior is solely dependent on fractal dimension of roughness\nand highlight the potential to apply this equation for the scale invariant\nroughness determination. Finally, the validity of theoretical result is tested\nwith extensive experimental data.\n\n", "human_text": "  In this letter, a theoretical method for the analysis of diffusive\nflux/current to limited scale self-affine random fractals is presented and\ncompared with experimentally measured electrochemical current for such\nroughness. The theory explains the several experimental findings of the\ntemporal scale invariance as well as deviation from this of current transients\nin terms of three dominant fractal parameters for the limited-length scales of\nroughness. This theoretical method is based on limited scale power-law\ncharacterization of the interfacial roughness spectrum and the solution of\ndiffusion equation under the diffusion-limited boundary conditions on rough\ninterfaces. More broadly, these calculations challenges the earlier belief that\nthe anomalous behavior is solely dependent on fractal dimension of roughness\nand highlight the potential to apply this equation for the scale invariant\nroughness determination. Finally, the validity of theoretical result is tested\nwith extensive experimental data.\n", "machine_text": "\nThis article presents a theoretical approach to understanding the fluctuation and current of diffusive reaction rates facilitated by realistic self-affine fractals. By using a theoretical method which takes into account the limited length-scales of these fractals,  this paper explores how three key fractal parameters play a role in determining the temporal scale-invariance and deviations from it, within current fluctuations. This new theoretical formula was then validated with experimentation, and found to challenge the earlier notion that anomalous behaviour is strictly dependent on fractal dimension.Overall,  this paper attests to the potential of this theoretical method to be applied to the scale-invariant roughness determination. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2813}
{"prompt": "Rephrase the abstract of an article with title 'Z^0 \\to 2\\gamma and the Twisted Coproduct of the Poincar\\'{e} Group'.\n  Yang's theorem forbids the process $Z^0 \\to 2\\gamma$ in any Poincar\\'{e}\ninvariant theory if photons are bosons and their two-particle states transform\nunder the Poincar\\'{e} group in the standard way (under the standard coproduct\nof the Poincar\\'{e} group). This is an important result as it does not depend\non the assumptions of quantum field theory. Recent work on noncommutative\ngeometry requires deforming the above coproduct by the Drinfel'd twist. We\nprove that $Z^0 \\to 2\\gamma$ is forbidden for the twisted coproduct as well.\nThis result is also independent of the assumptions of quantum field theory. As\nan illustration of the use of our general formulae, we further show that $Z^0\n\\to \\nu + \\nu$ is forbidden for the standard or twisted coproduct of the\nPoincar\\'{e} group if the neutrino is massless, even if lepton number is not\nconserved. This is a special case of our general result that a massive particle\nof spin $j$ cannot decay into two identical massless particles of the same\nhelicity if $j$ is odd, regardless of the coproduct used.\n\n", "human_text": "  Yang's theorem forbids the process $Z^0 \\to 2\\gamma$ in any Poincar\\'{e}\ninvariant theory if photons are bosons and their two-particle states transform\nunder the Poincar\\'{e} group in the standard way (under the standard coproduct\nof the Poincar\\'{e} group). This is an important result as it does not depend\non the assumptions of quantum field theory. Recent work on noncommutative\ngeometry requires deforming the above coproduct by the Drinfel'd twist. We\nprove that $Z^0 \\to 2\\gamma$ is forbidden for the twisted coproduct as well.\nThis result is also independent of the assumptions of quantum field theory. As\nan illustration of the use of our general formulae, we further show that $Z^0\n\\to \\nu + \\nu$ is forbidden for the standard or twisted coproduct of the\nPoincar\\'{e} group if the neutrino is massless, even if lepton number is not\nconserved. This is a special case of our general result that a massive particle\nof spin $j$ cannot decay into two identical massless particles of the same\nhelicity if $j$ is odd, regardless of the coproduct used.\n", "machine_text": "\nYang's theorem indicates that $Z^0 \\to 2\\gamma$ is not permitted in any Poincar\\'{e}\ninvariant theory when considering bosonic photons with two-particle states transforming\naccording to the standard coproduct of the Poincar\\'{e} group. Nonetheless, a novel \nDrinfel'd twist of the coproduct has been proposed in noncommutative geometry. Using \ngeneral formulae, this paper demonstrates that this process is forbidden in either \nthe standard or the twisted coproduct of the Poincar\\'{e} group; this result is\nindependent of the conventions in quantum field theory. As an example, $Z^0 \\to \\nu + \\nu$\nis found to be prohibited under the same conditions, even if lepton number is not conserved.\nMoreover, more generally, any massive particle with odd spin that decays into two identical \nmassless particles of the same helicity is also disallowed irrespective of the coproduct.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0921}
{"prompt": "Rephrase the abstract of an article with title 'Structural parameters for globular clusters in M31 and generalizations\n  for the fundamental plane'.\n  The structures of globular clusters (GCs) reflect their dynamical states and\npast histories. High-resolution imaging allows the exploration of morphologies\nof clusters in other galaxies. Surface brightness profiles from new Hubble\nSpace Telescope observations of 34 globular clusters in M31 are presented,\ntogether with fits of several different structural models to each cluster. M31\nclusters appear to be adequately fit by standard King models, and do not\nobviously require alternate descriptions with relatively stronger halos, such\nas are needed to fit many GCs in other nearby galaxies. The derived structural\nparameters are combined with corrected versions of those measured in an earlier\nsurvey to construct a comprehensive catalog of structural and dynamical\nparameters for M31 GCs with a sample size similar to that for the Milky Way.\nClusters in M31, the Milky Way, Magellanic Clouds, Fornax dwarf spheroidal and\nNGC 5128 define a very tight fundamental plane with identical slopes. The\ncombined evidence for these widely different galaxies strongly reinforces the\nview that old globular clusters have near-universal structural properties\nregardless of host environment.\n\n", "human_text": "  The structures of globular clusters (GCs) reflect their dynamical states and\npast histories. High-resolution imaging allows the exploration of morphologies\nof clusters in other galaxies. Surface brightness profiles from new Hubble\nSpace Telescope observations of 34 globular clusters in M31 are presented,\ntogether with fits of several different structural models to each cluster. M31\nclusters appear to be adequately fit by standard King models, and do not\nobviously require alternate descriptions with relatively stronger halos, such\nas are needed to fit many GCs in other nearby galaxies. The derived structural\nparameters are combined with corrected versions of those measured in an earlier\nsurvey to construct a comprehensive catalog of structural and dynamical\nparameters for M31 GCs with a sample size similar to that for the Milky Way.\nClusters in M31, the Milky Way, Magellanic Clouds, Fornax dwarf spheroidal and\nNGC 5128 define a very tight fundamental plane with identical slopes. The\ncombined evidence for these widely different galaxies strongly reinforces the\nview that old globular clusters have near-universal structural properties\nregardless of host environment.\n", "machine_text": "\nAnalysis of high-res imaging from the Hubble Space Telescope of 34 globular clusters (GCs) in M31 offer insight into their shapes,Past dynamical states and\ntheir evolution. King models  fit the M31 clusters well and no stronger halo models were necessary as compared to those in other galaxies. A catalog of structural and dynamical parameters regarding M31 GCs has been compiled, comparable to that of the Milky Way. Ultimately, the data from these various galaxies has shown an almost perfect match in their fundamental planes. This is an indication that old GCs have nearly identical properties regardless of where they are found.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2057}
{"prompt": "Rephrase the abstract of an article with title 'Exploded Fibrations'.\n  Initiated by Gromov, the study of holomorphic curves in symplectic manifolds\nhas been a powerfull tool in symplectic topology, however the moduli space of\nholomorphic curves is often very difficult to find. A common technique is to\nstudy the limiting behavior of holomorphic curves in a degenerating family of\ncomplex structures which corresponds to a kind of adiabatic limit. The category\nof exploded fibrations is an extension of the smooth category in which some of\nthese degenerations can be described as smooth families.\n  The first part of this paper is devoted to defining exploded fibrations and a\nslightly more specialized category of exploded torus fibrations. Later sections\ncontain the transverse interesction theory for exploded fibrations and some\nexamples of holomorphic curves in exploded torus fibrations, including a brief\ndiscussion of the relationship between tropical geometry and exploded torus\nfibrations. In the final section, the perturbation theory of holomorphic curves\nin exploded torus fibrations is sketched.\n\n", "human_text": "  Initiated by Gromov, the study of holomorphic curves in symplectic manifolds\nhas been a powerfull tool in symplectic topology, however the moduli space of\nholomorphic curves is often very difficult to find. A common technique is to\nstudy the limiting behavior of holomorphic curves in a degenerating family of\ncomplex structures which corresponds to a kind of adiabatic limit. The category\nof exploded fibrations is an extension of the smooth category in which some of\nthese degenerations can be described as smooth families.\n  The first part of this paper is devoted to defining exploded fibrations and a\nslightly more specialized category of exploded torus fibrations. Later sections\ncontain the transverse interesction theory for exploded fibrations and some\nexamples of holomorphic curves in exploded torus fibrations, including a brief\ndiscussion of the relationship between tropical geometry and exploded torus\nfibrations. In the final section, the perturbation theory of holomorphic curves\nin exploded torus fibrations is sketched.\n", "machine_text": "\nSince its introduction by Gromov, the analysis of holomorphic curves in symplectic \nmanifolds has been an important element of symplectic topology; however the moduli space of\nthese curves is often difficult to find. Exploded fibrations are an extension of \nthe smooth category which allows one to study certain degenerations of the curves in \nsmooth families. This paper describes the category of exploded fibrations and exploded\ntorus fibrations, provides transverse intersection theory for this category, and \npresents examples of holomorphic curves within exploded torus fibrations. Also included\nis an overview of the relationship between tropical geometry and exploded torus fibrations\nand a brief sketch of the perturbation theory of holomorphic curves in this setting.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2408}
{"prompt": "Rephrase the abstract of an article with title 'The Intrinsically X-ray Weak Quasar PHL 1811. II. Optical and UV Spectra\n  and Analysis'.\n  This is the second of two papers reporting observations and analysis of the\nunusually bright (m_b=14.4), luminous (M_B=-25.5), nearby (z=0.192) narrow-line\nquasar PHL 1811. The first paper reported that PHL 1811 is intrinsically X-ray\nweak, and presented a spectral energy distribution (SED). Here we present HST\nSTIS optical and UV spectra, and ground-based optical spectra. The optical and\nUV line emission is very unusual. There is no evidence for forbidden or\nsemiforbidden lines. The near-UV spectrum is dominated by very strong FeII and\nFeIII, and unusual low-ionization lines such as NaID and CaII H&K are observed.\nHigh-ionization lines are very weak; CIV has an equivalent width of 6.6A, a\nfactor of ~5 smaller than measured from quasar composite spectra. An unusual\nfeature near 1200A can be deblended in terms of Ly\\alpha, NV, SiII, and CIII*\nusing the blueshifted CIV profile as a template. Photoionization modeling shows\nthat the unusual line emission can be explained qualitatively by the unusually\nsoft SED. Principally, a low gas temperature results in inefficient emission of\ncollisionally excited lines, including the semiforbidden lines generally used\nas density diagnostics. The emission resembles that of high-density gas; in\nboth cases this is a consequence of inefficient cooling. PHL 1811 is very\nunusual, but we note that quasar surveys are generally biased against finding\nsimilar objects.\n\n", "human_text": "  This is the second of two papers reporting observations and analysis of the\nunusually bright (m_b=14.4), luminous (M_B=-25.5), nearby (z=0.192) narrow-line\nquasar PHL 1811. The first paper reported that PHL 1811 is intrinsically X-ray\nweak, and presented a spectral energy distribution (SED). Here we present HST\nSTIS optical and UV spectra, and ground-based optical spectra. The optical and\nUV line emission is very unusual. There is no evidence for forbidden or\nsemiforbidden lines. The near-UV spectrum is dominated by very strong FeII and\nFeIII, and unusual low-ionization lines such as NaID and CaII H&K are observed.\nHigh-ionization lines are very weak; CIV has an equivalent width of 6.6A, a\nfactor of ~5 smaller than measured from quasar composite spectra. An unusual\nfeature near 1200A can be deblended in terms of Ly\\alpha, NV, SiII, and CIII*\nusing the blueshifted CIV profile as a template. Photoionization modeling shows\nthat the unusual line emission can be explained qualitatively by the unusually\nsoft SED. Principally, a low gas temperature results in inefficient emission of\ncollisionally excited lines, including the semiforbidden lines generally used\nas density diagnostics. The emission resembles that of high-density gas; in\nboth cases this is a consequence of inefficient cooling. PHL 1811 is very\nunusual, but we note that quasar surveys are generally biased against finding\nsimilar objects.\n", "machine_text": "\nThis paper reports on the second of two concerning the intense, luminous quasar PHL 1811 situated closeby at a redshift of 0.192. The first of the reports stated that PHL 1811 is intrinsically weak to X-rays. Here, HST STIS optical and ultra-violet spectra and ground-based optical spectra are presented. The optical and ultraviolet line emission is extraordinary, with no signs of forbidden or semi-forbidden lines. The near-ultraviolet spectrum is largely composed of strong FeII and FeIII element lines and unusual low-ionization elements such as NaID and CaII H&K. High-ionization lines are barely visible, with CIV having an equivalent width of merely 6.6A, around a fifth of the one recorded by quasar composite spectra. An unexpected feature near 1200A is described with the help of Ly\u03b1, NV, SiII and CIII* using the shifted CIV profile as a template. Utilizing photoionization modeling, one can infer that the rare, peculiar line emission is primarily caused by the soft SED, significantly lowering the gas temperature which leads to less competent emission of collisionally-thrilled lines. This effect is similar to when faced with high-density gas, where cooling can be inefficient. PHL 1811 is uncommon but not impossible to come by since most quasar surveys overlook such objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.094}
{"prompt": "Rephrase the abstract of an article with title 'Formation and Collisional Evolution of Kuiper Belt Objects'.\n  This chapter summarizes analytic theory and numerical calculations for the\nformation and collisional evolution of KBOs at 20--150 AU. We describe the main\npredictions of a baseline self-stirring model and show how dynamical\nperturbations from a stellar flyby or stirring by a giant planet modify the\nevolution. Although robust comparisons between observations and theory require\nbetter KBO statistics and more comprehensive calculations, the data are broadly\nconsistent with KBO formation in a massive disk followed by substantial\ncollisional grinding and dynamical ejection. However, there are important\nproblems reconciling the results of coagulation and dynamical calculations.\nContrasting our current understanding of the evolution of KBOs and asteroids\nsuggests that additional observational constraints, such as the identification\nof more dynamical families of KBOs (like the 2003 EL61 family), would provide\nadditional information on the relative roles of collisional grinding and\ndynamical ejection in the Kuiper Belt. The uncertainties also motivate\ncalculations that combine collisional and dynamical evolution, a `unified'\ncalculation that should give us a better picture of KBO formation and\nevolution.\n\n", "human_text": "  This chapter summarizes analytic theory and numerical calculations for the\nformation and collisional evolution of KBOs at 20--150 AU. We describe the main\npredictions of a baseline self-stirring model and show how dynamical\nperturbations from a stellar flyby or stirring by a giant planet modify the\nevolution. Although robust comparisons between observations and theory require\nbetter KBO statistics and more comprehensive calculations, the data are broadly\nconsistent with KBO formation in a massive disk followed by substantial\ncollisional grinding and dynamical ejection. However, there are important\nproblems reconciling the results of coagulation and dynamical calculations.\nContrasting our current understanding of the evolution of KBOs and asteroids\nsuggests that additional observational constraints, such as the identification\nof more dynamical families of KBOs (like the 2003 EL61 family), would provide\nadditional information on the relative roles of collisional grinding and\ndynamical ejection in the Kuiper Belt. The uncertainties also motivate\ncalculations that combine collisional and dynamical evolution, a `unified'\ncalculation that should give us a better picture of KBO formation and\nevolution.\n", "machine_text": "This paper reviews the analytical models and numerical approaches used to understand the formation and ensuing collisional changes of Kuiper Belt Objects (KBOs) located in the range of 20 to 150 astronomical units (AU). It provides an assessment of the fundamental self-stirring model and how deviation occur through flyby or giant planet stirring. Though genuine comparison between the outcome of these studies and data from observations require more comprehensive analysis, the evidence supports KBO creation from a massive disk and following development accounts for significant collisional erosion and dynamical rejection. Nevertheless, a compatibility between the results of combining colliding and dynamical analysis is challenging to realize. This refers to distinctions between the present comprehension of KBO and asteroid development and advocates for more distinct families of KBO, like 2003 EL61 family, to acquire extra understanding into the contribution of collisional abrasion and dynamical rejection in the Kuiper Belt. This research sparks the absolute need for the development of a consolidated calculation, combining both the collisional and dynamical evolution in order to gain a better insight regarding KBO formation and evolution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0259}
{"prompt": "Rephrase the abstract of an article with title 'Spectroscopy of Ultracold, Trapped Cesium Feshbach Molecules'.\n  We explore the rich internal structure of Cs_2 Feshbach molecules. Pure\nultracold molecular samples are prepared in a CO_2-laser trap, and a multitude\nof weakly bound states is populated by elaborate magnetic-field ramping\ntechniques. Our methods use different Feshbach resonances as input ports and\nvarious internal level crossings for controlled state transfer. We populate\nhigher partial-wave states of up to eight units of rotational angular momentum\n(l-wave states). We investigate the molecular structure by measurements of the\nmagnetic moments for various states. Avoided level crossings between different\nmolecular states are characterized through the changes in magnetic moment and\nby a Landau-Zener tunneling method. Based on microwave spectroscopy, we present\na precise measurement of the magnetic-field dependent binding energy of the\nweakly bound s-wave state that is responsible for the large background\nscattering length of Cs. This state is of particular interest because of its\nquantum-halo character.\n\n", "human_text": "  We explore the rich internal structure of Cs_2 Feshbach molecules. Pure\nultracold molecular samples are prepared in a CO_2-laser trap, and a multitude\nof weakly bound states is populated by elaborate magnetic-field ramping\ntechniques. Our methods use different Feshbach resonances as input ports and\nvarious internal level crossings for controlled state transfer. We populate\nhigher partial-wave states of up to eight units of rotational angular momentum\n(l-wave states). We investigate the molecular structure by measurements of the\nmagnetic moments for various states. Avoided level crossings between different\nmolecular states are characterized through the changes in magnetic moment and\nby a Landau-Zener tunneling method. Based on microwave spectroscopy, we present\na precise measurement of the magnetic-field dependent binding energy of the\nweakly bound s-wave state that is responsible for the large background\nscattering length of Cs. This state is of particular interest because of its\nquantum-halo character.\n", "machine_text": "\nWe examine the intricate structure of Cesium Feshbach molecules with an elaborate magnetic-field ramping technique in a CO_2-laser trap. We successfully populate molecular states with up to eight units of rotational angular momentum, uncovering avoided level crossings through the change of magnetic moments and a Landau-Zener tunneling method. Utilizing microwave spectroscopy, we precisely measure the magnetic-field dependent binding energy of the complex s-wave state that produces the large background scattering length of Cs and it's quantum-halo character. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1041}
{"prompt": "Rephrase the abstract of an article with title 'Evidence for nonlinear diffusive shock acceleration of cosmic-rays in\n  the 2006 outburst of the recurrent nova RS Ophiuchi'.\n  Spectroscopic observations of the 2006 outburst of the recurrent nova RS\nOphiuchi at both infrared (IR) and X-ray wavelengths have shown that the blast\nwave has decelerated at a higher rate than predicted by the standard\ntest-particle adiabatic shock-wave model. Here we show that the observed\nevolution of the nova remnant can be explained by the diffusive shock\nacceleration of particles at the blast wave and the subsequent escape of the\nhighest energy ions from the shock region. Nonlinear particle acceleration can\nalso account for the difference of shock velocities deduced from the IR and\nX-ray data. The maximum energy that accelerated electrons and protons can have\nachieved in few days after outburst is found to be as high as a few TeV. Using\nthe semi-analytic model of nonlinear diffusive shock acceleration developed by\nBerezhko & Ellison, we show that the postshock temperature of the shocked gas\nmeasured with RXTE/PCA and Swift/XRT imply a relatively moderate acceleration\nefficiency.\n\n", "human_text": "  Spectroscopic observations of the 2006 outburst of the recurrent nova RS\nOphiuchi at both infrared (IR) and X-ray wavelengths have shown that the blast\nwave has decelerated at a higher rate than predicted by the standard\ntest-particle adiabatic shock-wave model. Here we show that the observed\nevolution of the nova remnant can be explained by the diffusive shock\nacceleration of particles at the blast wave and the subsequent escape of the\nhighest energy ions from the shock region. Nonlinear particle acceleration can\nalso account for the difference of shock velocities deduced from the IR and\nX-ray data. The maximum energy that accelerated electrons and protons can have\nachieved in few days after outburst is found to be as high as a few TeV. Using\nthe semi-analytic model of nonlinear diffusive shock acceleration developed by\nBerezhko & Ellison, we show that the postshock temperature of the shocked gas\nmeasured with RXTE/PCA and Swift/XRT imply a relatively moderate acceleration\nefficiency.\n", "machine_text": "\nThis paper investigates the deceleration of the blast wave at the 2006 outburst of the RS Ophiuchi recurrent nova, which has been observed spectroscopically at both infrared and X-ray wavelengths. Results reveal that the observed evolution of the remnant can be explained by the diffusive shock acceleration of particles from the blast wave, accompanied by the escape of the most energetic ions from the area. The nonlinear acceleration process is seen to explain the disparity between shock velocities inferred from the IR and X-ray data. The semi-analytic model of nonlinear diffusive shock acceleration developed by Berezhko & Ellison was used to compute the maximum energy that accelerated electrons and protons could reach shortly after the outburst, which is found to be as high as a few TeV. Examination of postshock temperatures with RXTE/PCA and Swift/XRT indicates a moderate acceleration efficiency.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4422}
{"prompt": "Rephrase the abstract of an article with title 'A data-analysis driven comparison of analytic and numerical coalescing\n  binary waveforms: nonspinning case'.\n  We compare waveforms obtained by numerically evolving nonspinning binary\nblack holes to post-Newtonian (PN) template families currently used in the\nsearch for gravitational waves by ground-based detectors. We find that the\ntime-domain 3.5PN template family, which includes the inspiral phase, has\nfitting factors (FFs) >= 0.96 for binary systems with total mass M = 10 ~ 20\nMsun. The time-domain 3.5PN effective-one-body template family, which includes\nthe inspiral, merger and ring-down phases, gives satisfactory signal-matching\nperformance with FFs >= 0.96 for binary systems with total mass M = 10 ~ 120\nMsun. If we introduce a cutoff frequency properly adjusted to the final\nblack-hole ring-down frequency, we find that the frequency-domain\nstationary-phase-approximated template family at 3.5PN order has FFs >= 0.96\nfor binary systems with total mass M = 10 ~ 20 Msun. However, to obtain high\nmatching performances for larger binary masses, we need to either extend this\nfamily to unphysical regions of the parameter space or introduce a 4PN order\ncoefficient in the frequency-domain GW phase. Finally, we find that the\nphenomenological Buonanno-Chen-Vallisneri family has FFs >= 0.97 with total\nmass M=10 ~ 120Msun. The main analyses use the noise spectral-density of LIGO,\nbut several tests are extended to VIRGO and advanced LIGO noise-spectral\ndensities.\n\n", "human_text": "  We compare waveforms obtained by numerically evolving nonspinning binary\nblack holes to post-Newtonian (PN) template families currently used in the\nsearch for gravitational waves by ground-based detectors. We find that the\ntime-domain 3.5PN template family, which includes the inspiral phase, has\nfitting factors (FFs) >= 0.96 for binary systems with total mass M = 10 ~ 20\nMsun. The time-domain 3.5PN effective-one-body template family, which includes\nthe inspiral, merger and ring-down phases, gives satisfactory signal-matching\nperformance with FFs >= 0.96 for binary systems with total mass M = 10 ~ 120\nMsun. If we introduce a cutoff frequency properly adjusted to the final\nblack-hole ring-down frequency, we find that the frequency-domain\nstationary-phase-approximated template family at 3.5PN order has FFs >= 0.96\nfor binary systems with total mass M = 10 ~ 20 Msun. However, to obtain high\nmatching performances for larger binary masses, we need to either extend this\nfamily to unphysical regions of the parameter space or introduce a 4PN order\ncoefficient in the frequency-domain GW phase. Finally, we find that the\nphenomenological Buonanno-Chen-Vallisneri family has FFs >= 0.97 with total\nmass M=10 ~ 120Msun. The main analyses use the noise spectral-density of LIGO,\nbut several tests are extended to VIRGO and advanced LIGO noise-spectral\ndensities.\n", "machine_text": "\nWe study and compare waveforms of nonspinning black hole binaries produced through numerical and analytical means. We measure the performance of the templates used in detecting gravitational waves by ground-based instruments by inspecting their fitting factors (FFs). Our research finds that the 3.5 PN order template spanning the inspiral phase yields FFs of 0.96 or higher for binary systems with a total mass of 10 to 20 solar masses. The 3.5 PN effective-one-body template catering to the merger and ring-down phase produces satisfactory matching performance, with fitting factors of 0.96 or higher, for binaries with a total mass of 10 to 120 solar masses. If a cutoff frequency is adjusted correspondingly to the final black hole ring-down frequency, the 3.5 PN order stationary-phase-approximated frequency-domain template secures matching performance of 0.96 or higher for binary systems with a total mass of 10 to 20 solar masses. However, larger masses necessitate either an extended template into the unphysical parts of the parameter space or a 4PN order coefficient. The Buonanno-Chen-Vallisneri template, which is phenomenological in nature, yields matching performance of 0.97 or higher with binary masses ranging from 10 to 120 solar masses. We assess the performance of our templates with the LIGO, VIRGO and advanced LIGO noise spectral densities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1964}
{"prompt": "Rephrase the abstract of an article with title 'Bifurcations and chaos in semiconductor superlattices with a tilted\n  magnetic field'.\n  We study the effects of dissipation on electron transport in a semiconductor\nsuperlattice with an applied bias voltage and a magnetic field that is tilted\nrelative to the superlattice axis.In previous work, we showed that although the\napplied fields are stationary,they act like a THz plane wave, which strongly\ncouples the Bloch and cyclotron motion of electrons within the lowest miniband.\nAs a consequence,the electrons exhibit a unique type of Hamiltonian chaos,\nwhich creates an intricate mesh of conduction channels (a stochastic web) in\nphase space, leading to a large resonant increase in the current flow at\ncritical values of the applied voltage. This phase-space patterning provides a\nsensitive mechanism for controlling electrical resistance. In this paper, we\ninvestigate the effects of dissipation on the electron dynamics by modifying\nthe semiclassical equations of motion to include a linear damping term. We\ndemonstrate that even in the presence of dissipation,deterministic chaos plays\nan important role in the electron transport process. We identify mechanisms for\nthe onset of chaos and explore the associated sequence of bifurcations in the\nelectron trajectories. When the Bloch and cyclotron frequencies are\ncommensurate, complex multistability phenomena occur in the system. In\nparticular, for fixed values of the control parameters several distinct stable\nregimes can coexist, each corresponding to different initial conditions. We\nshow that this multistability has clear, experimentally-observable, signatures\nin the electron transport characteristics.\n\n", "human_text": "  We study the effects of dissipation on electron transport in a semiconductor\nsuperlattice with an applied bias voltage and a magnetic field that is tilted\nrelative to the superlattice axis.In previous work, we showed that although the\napplied fields are stationary,they act like a THz plane wave, which strongly\ncouples the Bloch and cyclotron motion of electrons within the lowest miniband.\nAs a consequence,the electrons exhibit a unique type of Hamiltonian chaos,\nwhich creates an intricate mesh of conduction channels (a stochastic web) in\nphase space, leading to a large resonant increase in the current flow at\ncritical values of the applied voltage. This phase-space patterning provides a\nsensitive mechanism for controlling electrical resistance. In this paper, we\ninvestigate the effects of dissipation on the electron dynamics by modifying\nthe semiclassical equations of motion to include a linear damping term. We\ndemonstrate that even in the presence of dissipation,deterministic chaos plays\nan important role in the electron transport process. We identify mechanisms for\nthe onset of chaos and explore the associated sequence of bifurcations in the\nelectron trajectories. When the Bloch and cyclotron frequencies are\ncommensurate, complex multistability phenomena occur in the system. In\nparticular, for fixed values of the control parameters several distinct stable\nregimes can coexist, each corresponding to different initial conditions. We\nshow that this multistability has clear, experimentally-observable, signatures\nin the electron transport characteristics.\n", "machine_text": "\n\nThis paper investigates how dissipative effects influence the Hamiltonian chaos seen in electron transport through semiconductor superlattices exposed to a tilted magnetic field. This type of chaos results in a 'stochastic web' of conduction channels, leading to a resonant increase in current flow. We modify the semiclassical equations of motion to include a linear damping term, and show that it only further enhances the electron dynamics. We also identify mechanisms that initiate chaos, and analyze the associated bifurcations in electron trajectories as a result of commensurate Bloch and cyclotron frequencies. Our findings demonstrate multistability in the system, with distinct, experimentally-observable, signatures in the transport characteristics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2004}
{"prompt": "Rephrase the abstract of an article with title 'Thermodynamics and the virial expansion for trapped fluids in arbitrary\n  external potentials'.\n  We present the full thermodynamics of a fluid confined by an arbitrary\nexternal potential based on the virial expansion of the grand potential. The\nfluid may be classical or quantum and it is assumed that interatomic\ninteractions are pairwise additive. We indicate how the appropriate\n\"generalized\" volume and pressure variables, that replace the usual volume and\nhydrostatic pressure, emerge for a given confining potential in the\nthermodynamic limit. A discussion of the physical meaning and of the\nmeasurement of these variables is presented. We emphasize that this treatment\nyields the correct equation of state of the fluid and we give its virial\nexpansion. We propose an experiment to measure the heat capacity, so that with\nthis quantity and the equation of state, the complete thermodynamics of the\nsystem may be extracted. As a corollary, we find that the so-called {\\it local\ndensity approximation} for these systems follows in the thermodynamic limit,\nalthough we also point out that it cannot be used indiscriminately for all\nlocal variables. Along the text we discuss the relevance of these findings in\nthe description of the currently confined ultracold gases.\n\n", "human_text": "  We present the full thermodynamics of a fluid confined by an arbitrary\nexternal potential based on the virial expansion of the grand potential. The\nfluid may be classical or quantum and it is assumed that interatomic\ninteractions are pairwise additive. We indicate how the appropriate\n\"generalized\" volume and pressure variables, that replace the usual volume and\nhydrostatic pressure, emerge for a given confining potential in the\nthermodynamic limit. A discussion of the physical meaning and of the\nmeasurement of these variables is presented. We emphasize that this treatment\nyields the correct equation of state of the fluid and we give its virial\nexpansion. We propose an experiment to measure the heat capacity, so that with\nthis quantity and the equation of state, the complete thermodynamics of the\nsystem may be extracted. As a corollary, we find that the so-called {\\it local\ndensity approximation} for these systems follows in the thermodynamic limit,\nalthough we also point out that it cannot be used indiscriminately for all\nlocal variables. Along the text we discuss the relevance of these findings in\nthe description of the currently confined ultracold gases.\n", "machine_text": "\nWe overview the thermodynamic properties of a fluid trapped in a potential of arbitrary strength. This fluid may be classical or quantum, and we assume that interatomic interactions are purely pairwise. This treatment yields the equation of state, while a corresponding virial expansion is also taken into account. We briefly discuss the measurement of the pressure and volume variables that emerge in the thermodynamic limit and present procedures by which the heat capacity may be evaluated. This would then allow one to obtain the complete thermodynamics of the system. We use this to demonstrate that the local density approximation holds in the thermodynamic limit, however, we note its limited use for local variables. As we complete our analysis we point to the current research involving ultracold gases as possible examples of this theory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1322}
{"prompt": "Rephrase the abstract of an article with title 'The dust distribution in edge-on galaxies. Radiative transfer fits of V\n  and K'-band images'.\n  Aims: I have analyzed a sample of seven nearby edge-on galaxies observed in\nthe V and K'-band, in order to infer the properties of the dust distribution.\n  Methods: A radiative transfer model, including scattering, have been used to\ndecompose each image into a stellar disk, a bulge, and a dust disk. The\nparameters describing the distributions have been obtained through standard X^2\nminimization techniques.\n  Results: The dust disks fitted to the V-band images are consistent with\nprevious work in literature: the radial scalelength of dust is larger than that\nfor stars (h_d/h_s ~ 1.5); the dust disk has a smaller vertical scalelength\nthan the stellar (z_d/z_s ~ 1/3); the dust disk is almost transparent when seen\nface-on (central, face-on, optical depth tau_0 =0.5-1.5). Faster radiative\ntransfer models which neglect scattering can produce equivalent fits, with\nchanges in the derived parameters within the accuracy of full fits including\nscattering. In the K'-band, no trace is found of a second, massive, dust disk\nwhich has been invoked to explain observations of dust emission in the\nsubmillimeter. I discuss the model degeneracies and the effect of complex\nstructures on the fitted distributions. In particular, most bulges in the\nsample show a box/peanuts morphology with large residuals; two\nlower-inclination galaxies show a dust ring distribution, which could be the\ncause for the large fitted dust scalelengths.\n\n", "human_text": "  Aims: I have analyzed a sample of seven nearby edge-on galaxies observed in\nthe V and K'-band, in order to infer the properties of the dust distribution.\n  Methods: A radiative transfer model, including scattering, have been used to\ndecompose each image into a stellar disk, a bulge, and a dust disk. The\nparameters describing the distributions have been obtained through standard X^2\nminimization techniques.\n  Results: The dust disks fitted to the V-band images are consistent with\nprevious work in literature: the radial scalelength of dust is larger than that\nfor stars (h_d/h_s ~ 1.5); the dust disk has a smaller vertical scalelength\nthan the stellar (z_d/z_s ~ 1/3); the dust disk is almost transparent when seen\nface-on (central, face-on, optical depth tau_0 =0.5-1.5). Faster radiative\ntransfer models which neglect scattering can produce equivalent fits, with\nchanges in the derived parameters within the accuracy of full fits including\nscattering. In the K'-band, no trace is found of a second, massive, dust disk\nwhich has been invoked to explain observations of dust emission in the\nsubmillimeter. I discuss the model degeneracies and the effect of complex\nstructures on the fitted distributions. In particular, most bulges in the\nsample show a box/peanuts morphology with large residuals; two\nlower-inclination galaxies show a dust ring distribution, which could be the\ncause for the large fitted dust scalelengths.\n", "machine_text": "This article evaluates the dust distribution in seven nearby edge-on galaxies using both V and K'-band observations. I employed a radiative transfer model to decompose the images into stellar disks, bulges, and dust disks. Standard X^2 minimization techniques were utilized to acquire parameters which describe the distributions. Upon examining the face-on optical depth of the dust disks, I found that they were nearly transparent. In contrast, a second massive dust disk which has been implicated in past investigations of submillimeter emissions was not observed in the K'-band. To conclude, I consider the effects of complex structures and the influence of the model degeneracies on fitting the dust distributions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1471}
{"prompt": "Rephrase the abstract of an article with title 'Random Access Broadcast: Stability and Throughput Analysis'.\n  A wireless network in which packets are broadcast to a group of receivers\nthrough use of a random access protocol is considered in this work. The\nrelation to previous work on networks of interacting queues is discussed and\nsubsequently, the stability and throughput regions of the system are analyzed\nand presented. A simple network of two source nodes and two destination nodes\nis considered first. The broadcast service process is analyzed assuming a\nchannel that allows for packet capture and multipacket reception. In this small\nnetwork, the stability and throughput regions are observed to coincide. The\nsame problem for a network with N sources and M destinations is considered\nnext. The channel model is simplified in that multipacket reception is no\nlonger permitted. Bounds on the stability region are developed using the\nconcept of stability rank and the throughput region of the system is compared\nto the bounds. Our results show that as the number of destination nodes\nincreases, the stability and throughput regions diminish. Additionally, a\nprevious conjecture that the stability and throughput regions coincide for a\nnetwork of arbitrarily many sources is supported for a broadcast scenario by\nthe results presented in this work.\n\n", "human_text": "  A wireless network in which packets are broadcast to a group of receivers\nthrough use of a random access protocol is considered in this work. The\nrelation to previous work on networks of interacting queues is discussed and\nsubsequently, the stability and throughput regions of the system are analyzed\nand presented. A simple network of two source nodes and two destination nodes\nis considered first. The broadcast service process is analyzed assuming a\nchannel that allows for packet capture and multipacket reception. In this small\nnetwork, the stability and throughput regions are observed to coincide. The\nsame problem for a network with N sources and M destinations is considered\nnext. The channel model is simplified in that multipacket reception is no\nlonger permitted. Bounds on the stability region are developed using the\nconcept of stability rank and the throughput region of the system is compared\nto the bounds. Our results show that as the number of destination nodes\nincreases, the stability and throughput regions diminish. Additionally, a\nprevious conjecture that the stability and throughput regions coincide for a\nnetwork of arbitrarily many sources is supported for a broadcast scenario by\nthe results presented in this work.\n", "machine_text": "This article explores the properties of a wireless network that employs a\nrandom access protocol to broadcast packets to a group of receivers. Through\nstudy of a network consisting of two source nodes and two destination nodes,\nas well as a network consisting of N source nodes and M destination nodes, \nwe analyze the stability and throughput regions of the system. We observe\nthat the stability and throughput regions coincide in the small network, \nand that the stability region steadily shrinks with respect to the number \nof destination nodes. Our results suggest that the stability and throughput \nregions of an arbitrarily large network coincide when broadcasting is \ninvolved.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2778}
{"prompt": "Rephrase the abstract of an article with title 'The initial conditions of star formation in the Ophiuchus main cloud:\n  Kinematics of the protocluster condensations'.\n  The earliest phases of clustered star formation and the origin of the stellar\ninitial mass function (IMF) are currently much debated. In order to constrain\nthe origin of the IMF, we investigated the internal and relative motions of\nstarless condensations and protostars previously detected by us in the dust\ncontinuum at 1.2mm in the L1688 protocluster of the Ophiuchus molecular cloud\ncomplex. The starless condensations have a mass spectrum resembling the IMF and\nare therefore likely representative of the initial stages of star formation in\nthe protocluster. We carried out detailed molecular line observations,\nincluding some N2H+(1-0) mapping, of the Ophiuchus protocluster condensations\nusing the IRAM 30m telescope. We measured subsonic or at most transonic levels\nof internal turbulence within the condensations, implying virial masses which\ngenerally agree within a factor of ~ 2 with the masses derived from the 1.2mm\ndust continuum. This supports the notion that most of the L1688 starless\ncondensations are gravitationally bound and prestellar in nature. We measured a\nglobal one-dimensional velocity dispersion of less than 0.4 km/s between\ncondensations. This small relative velocity dispersion implies that, in\ngeneral, the condensations do not have time to interact with one another before\nevolving into pre-main sequence objects. Our observations support the view that\nthe IMF is partly determined by cloud fragmentation at the prestellar stage.\nCompetitive accretion is unlikely to be the dominant mechanism at the\nprotostellar stage in the Ophiuchus protocluster, but it may possibly govern\nthe growth of starless, self-gravitating condensations initially produced by\ngravoturbulent fragmentation toward an IMF, Salpeter-like mass spectrum.\n\n", "human_text": "  The earliest phases of clustered star formation and the origin of the stellar\ninitial mass function (IMF) are currently much debated. In order to constrain\nthe origin of the IMF, we investigated the internal and relative motions of\nstarless condensations and protostars previously detected by us in the dust\ncontinuum at 1.2mm in the L1688 protocluster of the Ophiuchus molecular cloud\ncomplex. The starless condensations have a mass spectrum resembling the IMF and\nare therefore likely representative of the initial stages of star formation in\nthe protocluster. We carried out detailed molecular line observations,\nincluding some N2H+(1-0) mapping, of the Ophiuchus protocluster condensations\nusing the IRAM 30m telescope. We measured subsonic or at most transonic levels\nof internal turbulence within the condensations, implying virial masses which\ngenerally agree within a factor of ~ 2 with the masses derived from the 1.2mm\ndust continuum. This supports the notion that most of the L1688 starless\ncondensations are gravitationally bound and prestellar in nature. We measured a\nglobal one-dimensional velocity dispersion of less than 0.4 km/s between\ncondensations. This small relative velocity dispersion implies that, in\ngeneral, the condensations do not have time to interact with one another before\nevolving into pre-main sequence objects. Our observations support the view that\nthe IMF is partly determined by cloud fragmentation at the prestellar stage.\nCompetitive accretion is unlikely to be the dominant mechanism at the\nprotostellar stage in the Ophiuchus protocluster, but it may possibly govern\nthe growth of starless, self-gravitating condensations initially produced by\ngravoturbulent fragmentation toward an IMF, Salpeter-like mass spectrum.\n", "machine_text": "\nThis study aims to shed light on the origin of the stellar initial mass function by analyzing the movements of starless condensations and protostars previously detected in the L1688 protocluster of the Ophiuchus molecular cloud complex. IRAM 30m telescope observations were used to measure velocity variations both within the condensations and between them, finding subsonic or at most transonic levels of internal turbulence, viral masses similar to those derived from the 1.2mm dust continuum, and a global one-dimensional velocity dispersion of less than 0.4 km/s. Such small relative velocity dispersion implies limited time for condensations to interact with one another prior to developing into pre-main sequence objects. Our findings support the idea that the IMF is partly shaped by cloud fragmentation at the prestellar stage, without computative accretion playing a major role in the protostellar stage of the Ophiuchus protocluster, though it may be a factor in the evolution of self-gravitating condensations toward a Salpeter-like mass spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1535}
{"prompt": "Rephrase the abstract of an article with title 'Combination of OFDM and CDMA for high data rate UWB'.\n  For Wireless Personal Area Network (WPAN) systems, resource allocation\nbetween several users within a piconet and the coexistence of several piconets\nare very important points to take into consideration for the optimization of\nhigh data rate Ultra Wide Band (UWB) systems. To improve the performance of the\nMulti-Band OFDM (Orthogonal Frequency Division Multiplex) solution proposed by\nthe Multi-Band OFDM Alliance (MBOA), the addition of a spreading component in\nthe frequency domain is a good solution since it makes resource allocation\neasier and also offers better robustness against channel frequency selectivity\nand narrowband interference. The Spread Spectrum - Multi-Carrier - Multiple\nAccess (SS-MC-MA) system proposed in this article offers not only the\nadvantages of Multi-Carrier - Coded Division Multiple Access (MC-CDMA) brought\nby frequency spreading, but also a more effective dynamic resource allocation\nin a multi-user and multi-piconet context. These improvements are obtained\nwithout increasing the complexity of the radio-frequency part compared to the\nclassical MBOA solution.\n\n", "human_text": "  For Wireless Personal Area Network (WPAN) systems, resource allocation\nbetween several users within a piconet and the coexistence of several piconets\nare very important points to take into consideration for the optimization of\nhigh data rate Ultra Wide Band (UWB) systems. To improve the performance of the\nMulti-Band OFDM (Orthogonal Frequency Division Multiplex) solution proposed by\nthe Multi-Band OFDM Alliance (MBOA), the addition of a spreading component in\nthe frequency domain is a good solution since it makes resource allocation\neasier and also offers better robustness against channel frequency selectivity\nand narrowband interference. The Spread Spectrum - Multi-Carrier - Multiple\nAccess (SS-MC-MA) system proposed in this article offers not only the\nadvantages of Multi-Carrier - Coded Division Multiple Access (MC-CDMA) brought\nby frequency spreading, but also a more effective dynamic resource allocation\nin a multi-user and multi-piconet context. These improvements are obtained\nwithout increasing the complexity of the radio-frequency part compared to the\nclassical MBOA solution.\n", "machine_text": "A major focus of this article is to present a novel technique, combination of Orthogonal Frequency Division Multiplexing (OFDM) and Code Division Multiple Access (CDMA) to achieve higher data rate for Wireless Personal Area Network (WPAN). As the Multi-Band OFDM Alliance (MBOA) solution is already existing, this new system named Spread Spectrum - Multi-Carrier - Multiple Access (SS-MC-MA) offers advantages of Multi-Carrier - Coded Division Multiple Access (MC-CDMA), along with more effective dynamic resource allocation in both multi-user and multi-protonet context. Additionally, this technique does not incur any complexity increase in the radio-frequency part as compared to classical MBOA solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.043}
{"prompt": "Rephrase the abstract of an article with title 'Convolutions on compact groups and Fourier algebras of coset spaces'.\n  In this note we study two related questions. (1) For a compact group G, what\nare the ranges of the convolution maps on A(GXG) given for u,v in A(G) by $u X\nv |-> u*v' ($v'(s)=v(s^{-1})$) and $u X v |-> u*v$? (2) For a locally compact\ngroup G and a compact subgroup K, what are the amenability properties of the\nFourier algebra of the coset space A(G/K)? The algebra A(G/K) was defined and\nstudied by the first named author.\n  In answering the first question, we obtain for compact groups which do not\nadmit an abelian subgroup of finite index, some new subalgebras of A(G). Using\nthose algebras we can find many instances in which A(G/K) fails the most\nrudimentary amenability property: operator weak amenability. However, using\ndifferent techniques, we show that if the connected component of the identity\nof G is abelian, then A(G/K) always satisfies the stronger property that it is\nhyper-Tauberian, which is a concept developed by the second named author. We\nalso establish a criterion which characterises operator amenability of A(G/K)\nfor a class of groups which includes the maximally almost periodic groups.\n\n", "human_text": "  In this note we study two related questions. (1) For a compact group G, what\nare the ranges of the convolution maps on A(GXG) given for u,v in A(G) by $u X\nv |-> u*v' ($v'(s)=v(s^{-1})$) and $u X v |-> u*v$? (2) For a locally compact\ngroup G and a compact subgroup K, what are the amenability properties of the\nFourier algebra of the coset space A(G/K)? The algebra A(G/K) was defined and\nstudied by the first named author.\n  In answering the first question, we obtain for compact groups which do not\nadmit an abelian subgroup of finite index, some new subalgebras of A(G). Using\nthose algebras we can find many instances in which A(G/K) fails the most\nrudimentary amenability property: operator weak amenability. However, using\ndifferent techniques, we show that if the connected component of the identity\nof G is abelian, then A(G/K) always satisfies the stronger property that it is\nhyper-Tauberian, which is a concept developed by the second named author. We\nalso establish a criterion which characterises operator amenability of A(G/K)\nfor a class of groups which includes the maximally almost periodic groups.\n", "machine_text": "\nIn this paper, we explore two concepts: convolutions on compact groups and Fourier algebras of coset spaces. Specifically, we consider the range of the convolution maps on A(GXG), and the amenability properties of the Fourier algebra of the coset space A(G/K). Firstly, our work has enabled us to uncover new subalgebras of A(G), present in compact groups without an abelian subgroup of finite index. Our results here provide insight into situations where A(G/K) lacks basic amenability properties like operator weak amenability. Furthermore, we find that if the connected component of the identity in G is abelian, then A(G/K) is hyper-Tauberian, while a criterion is proposed to ascertain operator amenability of A(G/K) for a selection of groups that includes the maximally almost periodic groups.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4277}
{"prompt": "Rephrase the abstract of an article with title 'Adjointability of densely defined closed operators and the\n  Magajna-Schweizer Theorem'.\n  In this notes unbounded regular operators on Hilbert $C^*$-modules over\narbitrary $C^*$-algebras are discussed. A densely defined operator $t$\npossesses an adjoint operator if the graph of $t$ is an orthogonal summand.\nMoreover, for a densely defined operator $t$ the graph of $t$ is orthogonally\ncomplemented and the range of $P_FP_{G(t)^\\bot}$ is dense in its biorthogonal\ncomplement if and only if $t$ is regular. For a given $C^*$-algebra $\\mathcal\nA$ any densely defined $\\mathcal A$-linear closed operator $t$ between Hilbert\n$C^*$-modules is regular, if and only if any densely defined $\\mathcal\nA$-linear closed operator $t$ between Hilbert $C^*$-modules admits a densely\ndefined adjoint operator, if and only if $\\mathcal A$ is a $C^*$-algebra of\ncompact operators. Some further characterizations of closed and regular modular\noperators are obtained.\n  Changes 1: Improved results, corrected misprints, added references. Accepted\nby J. Operator Theory, August 2007 / Changes 2: Filled gap in the proof of Thm.\n3.1, changes in the formulations of Cor. 3.2 and Thm. 3.4, updated references\nand address of the second author.\n\n", "human_text": "  In this notes unbounded regular operators on Hilbert $C^*$-modules over\narbitrary $C^*$-algebras are discussed. A densely defined operator $t$\npossesses an adjoint operator if the graph of $t$ is an orthogonal summand.\nMoreover, for a densely defined operator $t$ the graph of $t$ is orthogonally\ncomplemented and the range of $P_FP_{G(t)^\\bot}$ is dense in its biorthogonal\ncomplement if and only if $t$ is regular. For a given $C^*$-algebra $\\mathcal\nA$ any densely defined $\\mathcal A$-linear closed operator $t$ between Hilbert\n$C^*$-modules is regular, if and only if any densely defined $\\mathcal\nA$-linear closed operator $t$ between Hilbert $C^*$-modules admits a densely\ndefined adjoint operator, if and only if $\\mathcal A$ is a $C^*$-algebra of\ncompact operators. Some further characterizations of closed and regular modular\noperators are obtained.\n  Changes 1: Improved results, corrected misprints, added references. Accepted\nby J. Operator Theory, August 2007 / Changes 2: Filled gap in the proof of Thm.\n3.1, changes in the formulations of Cor. 3.2 and Thm. 3.4, updated references\nand address of the second author.\n", "machine_text": "The present article focuses on unbounded regular operators acting on Hilbert $C^*$-modules over arbitrary $C^*$-algebras. The Magajna-Schweizer Theorem is used to demonstrate that a densely defined operator $t$ has an adjoint operator if the graph of $t$ is an orthogonal summand. The range of $P_FP_{G(t)^\\bot}$ is dense in its biorthogonal complement if and only if $t$ is regular. Additionally, this study shows that a densely defined $\\mathcal A$-linear closed operator $t$ between Hilbert $C^*$-modules is regular if and only if $\\mathcal A$ is a $C^*$-algebra of compact operators. A number of further characterizations of closed and regular modular operators were also obtained. The initial article has been modified with the addition of corrected misprints, improved results, and updated references.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2576}
{"prompt": "Rephrase the abstract of an article with title 'Critical edge behavior in unitary random matrix ensembles and the thirty\n  fourth Painleve transcendent'.\n  We describe a new universality class for unitary invariant random matrix\nensembles. It arises in the double scaling limit of ensembles of random $n\n\\times n$ Hermitian matrices $Z_{n,N}^{-1} |\\det M|^{2\\alpha} e^{-N \\Tr V(M)}\ndM$ with $\\alpha > -1/2$, where the factor $|\\det M|^{2\\alpha}$ induces\ncritical eigenvalue behavior near the origin. Under the assumption that the\nlimiting mean eigenvalue density associated with $V$ is regular, and that the\norigin is a right endpoint of its support, we compute the limiting eigenvalue\ncorrelation kernel in the double scaling limit as $n, N \\to \\infty$ such that\n$n^{2/3}(n/N-1) = O(1)$. We use the Deift-Zhou steepest descent method for the\nRiemann-Hilbert problem for polynomials on the line orthogonal with respect to\nthe weight $|x|^{2\\alpha} e^{-NV(x)}$. Our main attention is on the\nconstruction of a local parametrix near the origin by means of the\n$\\psi$-functions associated with a distinguished solution of the Painleve XXXIV\nequation. This solution is related to a particular solution of the Painleve II\nequation, which however is different from the usual Hastings-McLeod solution.\n\n", "human_text": "  We describe a new universality class for unitary invariant random matrix\nensembles. It arises in the double scaling limit of ensembles of random $n\n\\times n$ Hermitian matrices $Z_{n,N}^{-1} |\\det M|^{2\\alpha} e^{-N \\Tr V(M)}\ndM$ with $\\alpha > -1/2$, where the factor $|\\det M|^{2\\alpha}$ induces\ncritical eigenvalue behavior near the origin. Under the assumption that the\nlimiting mean eigenvalue density associated with $V$ is regular, and that the\norigin is a right endpoint of its support, we compute the limiting eigenvalue\ncorrelation kernel in the double scaling limit as $n, N \\to \\infty$ such that\n$n^{2/3}(n/N-1) = O(1)$. We use the Deift-Zhou steepest descent method for the\nRiemann-Hilbert problem for polynomials on the line orthogonal with respect to\nthe weight $|x|^{2\\alpha} e^{-NV(x)}$. Our main attention is on the\nconstruction of a local parametrix near the origin by means of the\n$\\psi$-functions associated with a distinguished solution of the Painleve XXXIV\nequation. This solution is related to a particular solution of the Painleve II\nequation, which however is different from the usual Hastings-McLeod solution.\n", "machine_text": "This article explores a new universality class that emerges in unitary invariant random matrix ensembles. We examine the double scaling limit of random Hermitian matrices weighted with a $|\\det M|^{2\\alpha} e^{-N \\Tr V(M)}$ factor, where $\\alpha$ is more than -1/2. This results in critical eigenvalue behavior near the origin, provided that the mean eigenvalue density associated with the potential $V$ is regular at the origin and that it is the right endpoint of its support. Our analysis consequently computes the limiting eigenvalue correlation kernel through the Deift-Zhou steepest descent method. We further explore the existence of a parametrix near the origin, by employing a solution of the Painleve XXXIV equation. This is related to a particular solution of the Painleve II equation, which is different from the usual Hastings-McLeod solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1972}
{"prompt": "Rephrase the abstract of an article with title 'A large acceptance scintillator detector with wavelength shifting fibre\n  read-out for search of eta-nucleus bound states'.\n  A large acceptance scintillator detector with wavelength shifting optical\nfibre readout has been designed and built to detect the decay particles of\n$\\eta$-nucleus bound system (the so-called $\\eta$-mesic nuclei), namely,\nprotons and pions. The detector, named as ENSTAR detector, consists of 122\npieces of plastic scintillator of various shapes and sizes, which are arranged\nin a cylindrical geometry to provide particle identification, energy loss and\ncoarse position information for these particles. A solid angle coverage of\n$\\sim$95% of total 4$\\pi$ is obtained in the present design of the detector.\nMonte Carlo phase space calculations performed to simulate the formation and\ndecay of $\\eta$-mesic nuclei suggest that its decay particles, the protons and\npions are emitted with an opening angle of 150$^\\circ \\pm 20^\\circ$, and with\nenergies in the range of 25 to 300 MeV and 225 to 450 MeV respectively. The\ndetailed GEANT simulations show that $\\sim$ 80 % of the decay particles\n(protons and pions) can be detected within ENSTAR. Several test measurements\nusing alpha source, cosmic-ray muons etc. have been carried out to study the\nresponse of ENSTAR scintillator pieces. The in-beam tests of fully assembled\ndetector with proton beam of momentum 870 MeV/c from the Cooler synchrotron\nCOSY have been performed. The test results show that the scintillator fiber\ndesign chosen for the detector has performed satisfactorily well. The present\narticle describes the detector design, simulation studies, construction details\nand test results.\n\n", "human_text": "  A large acceptance scintillator detector with wavelength shifting optical\nfibre readout has been designed and built to detect the decay particles of\n$\\eta$-nucleus bound system (the so-called $\\eta$-mesic nuclei), namely,\nprotons and pions. The detector, named as ENSTAR detector, consists of 122\npieces of plastic scintillator of various shapes and sizes, which are arranged\nin a cylindrical geometry to provide particle identification, energy loss and\ncoarse position information for these particles. A solid angle coverage of\n$\\sim$95% of total 4$\\pi$ is obtained in the present design of the detector.\nMonte Carlo phase space calculations performed to simulate the formation and\ndecay of $\\eta$-mesic nuclei suggest that its decay particles, the protons and\npions are emitted with an opening angle of 150$^\\circ \\pm 20^\\circ$, and with\nenergies in the range of 25 to 300 MeV and 225 to 450 MeV respectively. The\ndetailed GEANT simulations show that $\\sim$ 80 % of the decay particles\n(protons and pions) can be detected within ENSTAR. Several test measurements\nusing alpha source, cosmic-ray muons etc. have been carried out to study the\nresponse of ENSTAR scintillator pieces. The in-beam tests of fully assembled\ndetector with proton beam of momentum 870 MeV/c from the Cooler synchrotron\nCOSY have been performed. The test results show that the scintillator fiber\ndesign chosen for the detector has performed satisfactorily well. The present\narticle describes the detector design, simulation studies, construction details\nand test results.\n", "machine_text": "\n\nThis paper introduces ENSTAR, a large acceptance scintillator detector, which has been developed to detect the decay particles resulting from the formation and decay of $\\eta$-mesic nuclei, namely protons and pions. ENSTAR consists of 122 plastic scintillator pieces of various shapes and sizes arranged in a cylindrical geometry, resulting in an almost complete coverage ($\\sim$95%) of the full 4$\\pi$ solid angle. Based on simulation predictions, it is suggested that the decay particles emitted from the $\\eta$-mesic nuclei will have energies of 25 to 300 MeV for protons and 225 to 450 MeV for pions, with an angular opening of 150$^\\circ \\pm 20^\\circ$. Simulations show that the detector will detect approximately 80% of these particles, and multiple test measurements have been carried out to study the detector's response. In-beam tests with a proton beam of 870 MeV/c from COSY have also been conducted, which demonstrate that the scintillator fibre design performs adequately. This work provides an overview of ENSTAR's design, simulations, construction and test results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2386}
{"prompt": "Rephrase the abstract of an article with title 'Demographics of Transition Objects'.\n  The unusual properties of transition objects (young stars with an optically\nthin inner disc surrounded by an optically thick outer disc) suggest that\nsignificant disc evolution has occured in these systems. We explore the nature\nof these systems by examining their demographics, specifically their stellar\naccretion rates (Mdot) and disc masses (Mdisc) compared to those of accreting T\nTauri stars of comparable age. We find that transition objects in Taurus occupy\na restricted region of the Mdot vs. Mdisc plane. Compared to non-transition\nsingle stars in Taurus, they have stellar accretion rates that are typically\n~10 times lower at the same disc mass and median disc masses ~4 times larger.\nThese properties are anticipated by several proposed planet formation theories\nand suggest that the formation of Jovian mass planets may play a significant\nrole in explaining the origin of at least some transition objects. Considering\ntransition objects as a distinct demographic group among accreting T Tauri\nstars leads to a tighter relationship between disc masses and stellar accretion\nrates, with a slope between the two quantities that is close to the value of\nunity expected in simple theories of disc accretion.\n\n", "human_text": "  The unusual properties of transition objects (young stars with an optically\nthin inner disc surrounded by an optically thick outer disc) suggest that\nsignificant disc evolution has occured in these systems. We explore the nature\nof these systems by examining their demographics, specifically their stellar\naccretion rates (Mdot) and disc masses (Mdisc) compared to those of accreting T\nTauri stars of comparable age. We find that transition objects in Taurus occupy\na restricted region of the Mdot vs. Mdisc plane. Compared to non-transition\nsingle stars in Taurus, they have stellar accretion rates that are typically\n~10 times lower at the same disc mass and median disc masses ~4 times larger.\nThese properties are anticipated by several proposed planet formation theories\nand suggest that the formation of Jovian mass planets may play a significant\nrole in explaining the origin of at least some transition objects. Considering\ntransition objects as a distinct demographic group among accreting T Tauri\nstars leads to a tighter relationship between disc masses and stellar accretion\nrates, with a slope between the two quantities that is close to the value of\nunity expected in simple theories of disc accretion.\n", "machine_text": "\nThis article investigates the characteristics of transition objects (objects consisting of both an optically thin inner disc surrounded by an optically thick outer disc) and their associated disc masses (Mdisc) and stellar accretion rates (Mdot). We examine the demographic differences between accreting T Tauri stars with the same age, compared to the transition objects. We observe that transition objects possess a significantly lower Mdot at the same Mdisc, with a median Mdisc being 4 times greater than those of non-transition single stars in Taurus. These demographics may support theories of planet formation and disc accretion. An analysis of the Mdot-Mdisc plane suggests that transition objects form a distinct demographic group, which, when separated out, leads to a close relationship between Mdisc and Mdot with a slope close to the value of one anticipated in simple disc accretion theories.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1681}
{"prompt": "Rephrase the abstract of an article with title 'A Cosmological Framework for the Co-Evolution of Quasars, Supermassive\n  Black Holes, and Elliptical Galaxies: II. Formation of Red Ellipticals'.\n  (Abridged) We develop and test a model for the cosmological role of mergers\nin the formation and quenching of red, early-type galaxies. Making the ansatz\nthat star formation is quenched after a gas-rich, spheroid-forming major\nmerger, we demonstrate that this naturally predicts the turnover in the\nefficiency of star formation at ~L_star, as well as the observed mass\nfunctions/density of red galaxies as a function of redshift, the formation\ntimes of spheroids as a function of mass, and the fraction of quenched galaxies\nas a function of galaxy and halo mass, environment, and redshift. Comparing to\na variety of semi-analytic models in which quenching is primarily driven by\nhalo mass considerations or secular/disk instabilities, we demonstrate that our\nmodel and different broad classes of models make unique and robust qualitative\npredictions for a number of observables, including the red fraction as a\nfunction of galaxy and halo mass, the density of passive galaxies and evolution\nof the color-morphology-density relations at high z, and the fraction of\ndisky/boxy spheroids as a function of mass. In each case, the observations\nfavor a model in which galaxies quench after a major merger builds a massive\nspheroid, and disfavor quenching via secular or pure halo processes. We discuss\na variety of physical possibilities for this quenching, and propose a mixed\nscenario in which traditional quenching in hot, massive halos is supplemented\nby the feedback associated with star formation and quasar activity in a major\nmerger, which temporarily suppress cooling and establish the conditions of a\ndynamically hot halo in the central regions of the host, even in low mass\nhalos.\n\n", "human_text": "  (Abridged) We develop and test a model for the cosmological role of mergers\nin the formation and quenching of red, early-type galaxies. Making the ansatz\nthat star formation is quenched after a gas-rich, spheroid-forming major\nmerger, we demonstrate that this naturally predicts the turnover in the\nefficiency of star formation at ~L_star, as well as the observed mass\nfunctions/density of red galaxies as a function of redshift, the formation\ntimes of spheroids as a function of mass, and the fraction of quenched galaxies\nas a function of galaxy and halo mass, environment, and redshift. Comparing to\na variety of semi-analytic models in which quenching is primarily driven by\nhalo mass considerations or secular/disk instabilities, we demonstrate that our\nmodel and different broad classes of models make unique and robust qualitative\npredictions for a number of observables, including the red fraction as a\nfunction of galaxy and halo mass, the density of passive galaxies and evolution\nof the color-morphology-density relations at high z, and the fraction of\ndisky/boxy spheroids as a function of mass. In each case, the observations\nfavor a model in which galaxies quench after a major merger builds a massive\nspheroid, and disfavor quenching via secular or pure halo processes. We discuss\na variety of physical possibilities for this quenching, and propose a mixed\nscenario in which traditional quenching in hot, massive halos is supplemented\nby the feedback associated with star formation and quasar activity in a major\nmerger, which temporarily suppress cooling and establish the conditions of a\ndynamically hot halo in the central regions of the host, even in low mass\nhalos.\n", "machine_text": "We explore a new framework of cosmological understanding, wherein the development and quenching of red early-type galaxies is greatly influenced by major mergers. By assuming path cessation of star formation is prompted by these mergers, we are able to accurately predict characteristics like the efficiency of star formation at ~L_star, and also the mass function and density of red galaxies as a function of redshift, and growth rates of spheroids as a function of mass. Through comparison of these results with various semi-analytic models in which quenching is mainly due to halo mass or other secular or disk instabilities, we deduce which models provide the best fit for a range of observable outcomes like red fraction contingent upon halo and galaxy mass, and evolutions of color morphology to density at high z's. We postulate that quenching happens via a two-fold process of transitioning to hot and massive halos, combined with the feedback of quasar activity in a major merger.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1246}
{"prompt": "Rephrase the abstract of an article with title 'Study of Direct Photon plus Jet production in CMS Experiment at\n  \\sqrt{s}=14 TeV'.\n  We present simulation results of $\\gamma$ + Jet analysis using CMS (Compact\nMuon Solenoid) Object-Oriented software at the Large Hadron Collider (LHC)\ncenter of mass energy $\\sqrt{s}$=14 TeV. The study of direct photon production\nhelps in validating the perturbative Quantum Chromodynamics (pQCD) and\nproviding information on the gluon distribution in the nucleons. Direct photon\nprocesses also constitute a major background to several other Standard Model\n(SM) processes and signals of new physics. Thus these processes need to be\nunderstood precisely in the new energy regime. In this work, we have done a\ndetailed study of the GEANT4 simulated $\\gamma$ + jet events generated with\nPythia, and the related background processes. Isolation cuts have been\noptimized for direct photon which improves the signal over background ratio by\n$\\sim25%$ as compared to previous studies done in CMS. The inclusion of a large\n$\\Delta\\phi$ cut between the photon and the leading jet at $40^0$ in the\nanalysis leads to a further increase of $\\sim15%$ in S/B, thus giving an\noverall gain of $\\sim42%$ in S/B ratio.\n\n", "human_text": "  We present simulation results of $\\gamma$ + Jet analysis using CMS (Compact\nMuon Solenoid) Object-Oriented software at the Large Hadron Collider (LHC)\ncenter of mass energy $\\sqrt{s}$=14 TeV. The study of direct photon production\nhelps in validating the perturbative Quantum Chromodynamics (pQCD) and\nproviding information on the gluon distribution in the nucleons. Direct photon\nprocesses also constitute a major background to several other Standard Model\n(SM) processes and signals of new physics. Thus these processes need to be\nunderstood precisely in the new energy regime. In this work, we have done a\ndetailed study of the GEANT4 simulated $\\gamma$ + jet events generated with\nPythia, and the related background processes. Isolation cuts have been\noptimized for direct photon which improves the signal over background ratio by\n$\\sim25%$ as compared to previous studies done in CMS. The inclusion of a large\n$\\Delta\\phi$ cut between the photon and the leading jet at $40^0$ in the\nanalysis leads to a further increase of $\\sim15%$ in S/B, thus giving an\noverall gain of $\\sim42%$ in S/B ratio.\n", "machine_text": "\nIn this study, we conduct an analysis with the aim of better\nunderstanding the direct photon production process in the context of the CMS\nExperiment at the Large Hadron Collider (LHC). Our simulation utilizes\nGEANT4, Pythia and CMS Object-Oriented software to generate $\\gamma$ + jet\nevents at center of mass energy $\\sqrt{s}$=14 TeV. Such a study strengthens the verification of perturbative Quantum Chromodynamics (pQCD) and highlights significant effects of the gluon distribution in nucleons. Additionally, this research can aid in formulating a more profound knowledge of the direct photon background, a component of the Standard Model (SM), and its potential as a marker for new physics. To this end, we have adjusted the isolation cuts to improve the signal/background ratio by $\\sim25%$ compared to CMS publications, and incorporated a large $\\Delta\\phi$ cut of $40^0$ between the photon and leading jet which further contributes to an overall gain of $\\sim42%$ in S/B.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.274}
{"prompt": "Rephrase the abstract of an article with title 'Energy Density-Flux Correlations in an Unusual Quantum State and in the\n  Vacuum'.\n  In this paper we consider the question of the degree to which negative and\npositive energy are intertwined. We examine in more detail a previously studied\nquantum state of the massless minimally coupled scalar field, which we call a\n``Helfer state''. This is a state in which the energy density can be made\narbitrarily negative over an arbitrarily large region of space, but only at one\ninstant in time. In the Helfer state, the negative energy density is\naccompanied by rapidly time-varying energy fluxes. It is the latter feature\nwhich allows the quantum inequalities, bounds which restrict the magnitude and\nduration of negative energy, to hold for this class of states. An observer who\ninitially passes through the negative energy region will quickly encounter\nfluxes of positive energy which subsequently enter the region. We examine in\ndetail the correlation between the energy density and flux in the Helfer state\nin terms of their expectation values. We then study the correlation function\nbetween energy density and flux in the Minkowski vacuum state, for a massless\nminimally coupled scalar field in both two and four dimensions. In this latter\nanalysis we examine correlation functions rather than expectation values.\nRemarkably, we see qualitatively similar behavior to that in the Helfer state.\nMore specifically, an initial negative energy vacuum fluctuation in some region\nof space is correlated with a subsequent flux fluctuation of positive energy\ninto the region. We speculate that the mechanism which ensures that the quantum\ninequalities hold in the Helfer state, as well as in other quantum states\nassociated with negative energy, is, at least in some sense, already\n``encoded'' in the fluctuations of the vacuum.\n\n", "human_text": "  In this paper we consider the question of the degree to which negative and\npositive energy are intertwined. We examine in more detail a previously studied\nquantum state of the massless minimally coupled scalar field, which we call a\n``Helfer state''. This is a state in which the energy density can be made\narbitrarily negative over an arbitrarily large region of space, but only at one\ninstant in time. In the Helfer state, the negative energy density is\naccompanied by rapidly time-varying energy fluxes. It is the latter feature\nwhich allows the quantum inequalities, bounds which restrict the magnitude and\nduration of negative energy, to hold for this class of states. An observer who\ninitially passes through the negative energy region will quickly encounter\nfluxes of positive energy which subsequently enter the region. We examine in\ndetail the correlation between the energy density and flux in the Helfer state\nin terms of their expectation values. We then study the correlation function\nbetween energy density and flux in the Minkowski vacuum state, for a massless\nminimally coupled scalar field in both two and four dimensions. In this latter\nanalysis we examine correlation functions rather than expectation values.\nRemarkably, we see qualitatively similar behavior to that in the Helfer state.\nMore specifically, an initial negative energy vacuum fluctuation in some region\nof space is correlated with a subsequent flux fluctuation of positive energy\ninto the region. We speculate that the mechanism which ensures that the quantum\ninequalities hold in the Helfer state, as well as in other quantum states\nassociated with negative energy, is, at least in some sense, already\n``encoded'' in the fluctuations of the vacuum.\n", "machine_text": "\nThis paper investigates the relationship between negative and positive energy in a particular quantum state, called the Helfer state, in which a significant amount of negative energy can exist for a limited amount of time. The temporal flux associated with this state allows the quantum inequalities to hold, which limits the magnitude and duration of its negative energy. We then compare these correlations to those of the massless, minimally coupled scalar field in Minkowski vacuum states in two- and four-dimensions. Remarkably, both scenarios show similar behavior; when negative energy is localized in some region, it is accompanied by a positive energy flux into the region. We postulate that this mechanism which keeps the quantum inequalities intact under negative energy is, in some sense, embedded in the fluctuations of the vacuum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.197}
{"prompt": "Rephrase the abstract of an article with title 'An Extrasolar Planet Census with a Space-based Microlensing Survey'.\n  A space-based gravitational microlensing exoplanet survey will provide a\nstatistical census of exoplanets with masses down to 0.1 Earth-masses and\norbital separations ranging from 0.5AU to infinity. This includes analogs to\nall the Solar System's planets except for Mercury, as well as most types of\nplanets predicted by planet formation theories. Such a survey will provide\nresults on the frequency of planets around all types of stars except those with\nshort lifetimes. Close-in planets with separations < 0.5 AU are invisible to a\nspace-based microlensing survey, but these can be found by Kepler. Other\nmethods, including ground-based microlensing, cannot approach the comprehensive\nstatistics on the mass and semi-major axis distribution of extrasolar planets\nthat a space-based microlensing survey will provide. The terrestrial planet\nsensitivity of a ground-based microlensing survey is limited to the vicinity of\nthe Einstein radius at 2-3 AU, and space-based imaging is needed to identify\nand determine the mass of the planetary host stars for the vast majority of\nplanets discovered by microlensing. Thus, a space-based microlensing survey is\nlikely to be the only way to gain a comprehensive understanding of the nature\nof planetary systems, which is needed to understand planet formation and\nhabitability. The proposed Microlensing Planet Finder (MPF) mission is an\nexample of a space-based microlensing survey that can accomplish these\nobjectives with proven technology and a cost that fits comfortably under the\nNASA Discovery Program cost cap.\n\n", "human_text": "  A space-based gravitational microlensing exoplanet survey will provide a\nstatistical census of exoplanets with masses down to 0.1 Earth-masses and\norbital separations ranging from 0.5AU to infinity. This includes analogs to\nall the Solar System's planets except for Mercury, as well as most types of\nplanets predicted by planet formation theories. Such a survey will provide\nresults on the frequency of planets around all types of stars except those with\nshort lifetimes. Close-in planets with separations < 0.5 AU are invisible to a\nspace-based microlensing survey, but these can be found by Kepler. Other\nmethods, including ground-based microlensing, cannot approach the comprehensive\nstatistics on the mass and semi-major axis distribution of extrasolar planets\nthat a space-based microlensing survey will provide. The terrestrial planet\nsensitivity of a ground-based microlensing survey is limited to the vicinity of\nthe Einstein radius at 2-3 AU, and space-based imaging is needed to identify\nand determine the mass of the planetary host stars for the vast majority of\nplanets discovered by microlensing. Thus, a space-based microlensing survey is\nlikely to be the only way to gain a comprehensive understanding of the nature\nof planetary systems, which is needed to understand planet formation and\nhabitability. The proposed Microlensing Planet Finder (MPF) mission is an\nexample of a space-based microlensing survey that can accomplish these\nobjectives with proven technology and a cost that fits comfortably under the\nNASA Discovery Program cost cap.\n", "machine_text": "\nA space-based gravitational microlensing survey could provide a statistical census of exoplanets from 0.1 Earth-masses in size and orbital separations from 0.5AU to infinity. This would include analogs to all Solar System planets except for Mercury, as well as the predicted planets from planet formation theories. This type of survey is capable of providing detailed estimates of the frequency of planets around all types of stars, including those with short lifetimes. Planets with orbital separations smaller then 0.5 AU would be invisible due to the limitations of a space-based microlensing survey, but these can be found by other methods such as the Kepler mission. Ground-based microlensing is limited to near the Einstein radius of 2-3AU, while space-based imaging is needed to identify and determine the mass of the host stars of most planets discovered by microlensing. Therefore a space-based microlensing survey is likely to be the only way to get a thorough understanding of planetary systems, which is critical in order to deduce planet formation and habitability. The proposed Microlensing Planet Finder mission is an example of a viable and cost-comfortable space-based microlensing survey.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0454}
{"prompt": "Rephrase the abstract of an article with title 'An integral field spectroscopic survey for high redshift damped\n  Lyman-alpha galaxies'.\n  We search for galaxy counterparts to damped Lyman-alpha absorbers (DLAs) at\nz>2 towards nine quasars, which have 14 DLAs and 8 sub-DLAs in their spectra.\nWe use integral field spectroscopy to search for Ly-alpha emission line objects\nat the redshifts of the absorption systems. Besides recovering two previously\nconfirmed objects, we find six statistically significant candidate Ly-alpha\nemission line objects. The candidates are identified as having wavelengths\nclose to the DLA line where the background quasar emission is absorbed. In\ncomparison with the six currently known Ly-alpha emitting DLA galaxies the\ncandidates have similar line fluxes and line widths, while velocity offsets\nbetween the emission lines and systemic DLA redshifts are larger. The impact\nparameters are larger than 10 kpc, and lower column density systems are found\nat larger impact parameters. Assuming that a single gas cloud extends from the\nQSO line of sight to the location of the candidate emission line, we find that\nthe average candidate DLA galaxy is surrounded by neutral gas with an\nexponential scale length of ~5 kpc.\n\n", "human_text": "  We search for galaxy counterparts to damped Lyman-alpha absorbers (DLAs) at\nz>2 towards nine quasars, which have 14 DLAs and 8 sub-DLAs in their spectra.\nWe use integral field spectroscopy to search for Ly-alpha emission line objects\nat the redshifts of the absorption systems. Besides recovering two previously\nconfirmed objects, we find six statistically significant candidate Ly-alpha\nemission line objects. The candidates are identified as having wavelengths\nclose to the DLA line where the background quasar emission is absorbed. In\ncomparison with the six currently known Ly-alpha emitting DLA galaxies the\ncandidates have similar line fluxes and line widths, while velocity offsets\nbetween the emission lines and systemic DLA redshifts are larger. The impact\nparameters are larger than 10 kpc, and lower column density systems are found\nat larger impact parameters. Assuming that a single gas cloud extends from the\nQSO line of sight to the location of the candidate emission line, we find that\nthe average candidate DLA galaxy is surrounded by neutral gas with an\nexponential scale length of ~5 kpc.\n", "machine_text": "\nWe conducted an integral field spectroscopic survey for high redshift damped Lyman-alpha galaxies, focusing on nine quasars with 14 DLAs and 8 sub-DLAs present in their spectra. Our survey was able to confirm two of the systems, and identified six new candidate Ly-alpha emitting DLA galaxies. The new candidates showed similar line fluxes and widths as the 6 already confirmed Ly-alpha emitting galaxies, although spectrum shifts between in emission lines and DLAs redshifts were larger. The new candidates had impact parameters generous than 10kpc, and lower column density systems seemed to be located at larger distances. The average candidate DLA galaxy is probably enshrouded by an extended, exponentially scaled neutral gas cloud with a radius of ~5kpc.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0654}
{"prompt": "Rephrase the abstract of an article with title 'Detailed kinetic study of the ring opening of cycloalkanes by CBS-QB3\n  calculations'.\n  This work reports a theoretical study of the gas phase unimolecular\ndecomposition of cyclobutane, cyclopentane and cyclohexane by means of quantum\nchemical calculations. A biradical mechanism has been envisaged for each\ncycloalkane, and the main routes for the decomposition of the biradicals formed\nhave been investigated at the CBS-QB3 level of theory. Thermochemical data\n(\\delta H^0_f, S^0, C^0_p) for all the involved species have been obtained by\nmeans of isodesmic reactions. The contribution of hindered rotors has also been\nincluded. Activation barriers of each reaction have been analyzed to assess the\n1 energetically most favorable pathways for the decomposition of biradicals.\nRate constants have been derived for all elementary reactions using transition\nstate theory at 1 atm and temperatures ranging from 600 to 2000 K. Global rate\nconstant for the decomposition of the cyclic alkanes in molecular products have\nbeen calculated. Comparison between calculated and experimental results allowed\nto validate the theoretical approach. An important result is that the\nrotational barriers between the conformers, which are usually neglected, are of\nimportance in decomposition rate of the largest biradicals. Ring strain\nenergies (RSE) in transition states for ring opening have been estimated and\nshow that the main part of RSE contained in the cyclic reactants is removed\nupon the activation process.\n\n", "human_text": "  This work reports a theoretical study of the gas phase unimolecular\ndecomposition of cyclobutane, cyclopentane and cyclohexane by means of quantum\nchemical calculations. A biradical mechanism has been envisaged for each\ncycloalkane, and the main routes for the decomposition of the biradicals formed\nhave been investigated at the CBS-QB3 level of theory. Thermochemical data\n(\\delta H^0_f, S^0, C^0_p) for all the involved species have been obtained by\nmeans of isodesmic reactions. The contribution of hindered rotors has also been\nincluded. Activation barriers of each reaction have been analyzed to assess the\n1 energetically most favorable pathways for the decomposition of biradicals.\nRate constants have been derived for all elementary reactions using transition\nstate theory at 1 atm and temperatures ranging from 600 to 2000 K. Global rate\nconstant for the decomposition of the cyclic alkanes in molecular products have\nbeen calculated. Comparison between calculated and experimental results allowed\nto validate the theoretical approach. An important result is that the\nrotational barriers between the conformers, which are usually neglected, are of\nimportance in decomposition rate of the largest biradicals. Ring strain\nenergies (RSE) in transition states for ring opening have been estimated and\nshow that the main part of RSE contained in the cyclic reactants is removed\nupon the activation process.\n", "machine_text": "This article proposes a study of ring opening reactions of cyclobutane, cyclopentane, and cyclohexane using quantum chemical calculations. A biradical decomposition model is defined for each alkane and evaluated at the CBS-QB3 level of theory. The energy output of the reaction (\\delta H^0_f, S^0, C^0_p) is obtained through isodesmic reactions of the molecules, and hindered rotors are taken into account. In addition, activation energies are computed to discover the most favorable pathways of the biradical decomposition, and rate constants are determined at temperatures ranging from 600-2000 K and a pressure of 1 atm. Comparison of the predicted results to experimental observations is used to validate the theoretical approach. The importance of rotational barriers between conformers is evident, and ring strain energies are postulated to calculate the energy removed during the activation process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.07}
{"prompt": "Rephrase the abstract of an article with title 'Insulating state and the importance of the spin-orbit coupling in\n  Ca$_3$CoRhO$_6$'.\n  We have carried out a comparative theoretical study of the electronic\nstructure of the novel one-dimensional Ca$_3$CoRhO$_6$ and Ca$_3$FeRhO$_6$\nsystems. The insulating antiferromagnetic state for the Ca$_3$FeRhO$_6$ can be\nwell explained by band structure calculations with the closed shell high-spin\n$d^5$ (Fe$^{3+}$) and low-spin $t_{2g}^{6}$ (Rh$^{3+}$) configurations. We\nfound for the Ca$_3$CoRhO$_6$ that the Co has a strong tendency to be $d^7$\n(Co$^{2+}$) rather than $d^6$ (Co$^{3+}$), and that there is an orbital\ndegeneracy in the local Co electronic structure. We argue that it is the\nspin-orbit coupling which will lift this degeneracy thereby enabling local spin\ndensity approximation + Hubbard U (LSDA+U) band structure calculations to\ngenerate the band gap. We predict that the orbital contribution to the magnetic\nmoment in Ca$_3$CoRhO$_6$ is substantial, i.e. significantly larger than 1\n$\\mu_B$ per formula unit. Moreover, we propose a model for the contrasting\nintra-chain magnetism in both materials.\n\n", "human_text": "  We have carried out a comparative theoretical study of the electronic\nstructure of the novel one-dimensional Ca$_3$CoRhO$_6$ and Ca$_3$FeRhO$_6$\nsystems. The insulating antiferromagnetic state for the Ca$_3$FeRhO$_6$ can be\nwell explained by band structure calculations with the closed shell high-spin\n$d^5$ (Fe$^{3+}$) and low-spin $t_{2g}^{6}$ (Rh$^{3+}$) configurations. We\nfound for the Ca$_3$CoRhO$_6$ that the Co has a strong tendency to be $d^7$\n(Co$^{2+}$) rather than $d^6$ (Co$^{3+}$), and that there is an orbital\ndegeneracy in the local Co electronic structure. We argue that it is the\nspin-orbit coupling which will lift this degeneracy thereby enabling local spin\ndensity approximation + Hubbard U (LSDA+U) band structure calculations to\ngenerate the band gap. We predict that the orbital contribution to the magnetic\nmoment in Ca$_3$CoRhO$_6$ is substantial, i.e. significantly larger than 1\n$\\mu_B$ per formula unit. Moreover, we propose a model for the contrasting\nintra-chain magnetism in both materials.\n", "machine_text": "\nThis theoretical study of the novel one-dimensional Ca$_3$CoRhO$_6$ and Ca$_3$FeRhO$_6$ systems was conducted for the purpose of understanding the importance of spin-orbit coupling in their insulating antiferromagnetic states. Calculations with the closed shell high-spin $d^5$ (Fe$^{3+}$) and low-spin $t_{2g}^{6}$ (Rh$^{3+}$) configurations produced results in line with the expected behavior of Ca$_3$FeRhO$_6$ and a strong tendency for Co to be $d^7$ (Co$^{2+}$) in Ca$_3$CoRhO$_6$. Spin-orbit coupling was shown to lift the orbital degeneracy enabling local spin density approximation + Hubbard U (LSDA+U) simulations to generate a band gap. It was found that the orbital contribution to the magnetism of Ca$_3$CoRhO$_6$ was substantial and a model for the differing intra-chain magnetisms was proposed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4538}
{"prompt": "Rephrase the abstract of an article with title 'The Search for Muon Neutrinos from Northern Hemisphere Gamma-Ray Bursts\n  with AMANDA'.\n  We present the results of the analysis of neutrino observations by the\nAntarctic Muon and Neutrino Detector Array (AMANDA) correlated with photon\nobservations of more than 400 gamma-ray bursts (GRBs) in the Northern\nHemisphere from 1997 to 2003. During this time period, AMANDA's effective\ncollection area for muon neutrinos was larger than that of any other existing\ndetector. Based on our observations of zero neutrinos during and immediately\nprior to the GRBs in the dataset, we set the most stringent upper limit on muon\nneutrino emission correlated with gamma-ray bursts. Assuming a Waxman-Bahcall\nspectrum and incorporating all systematic uncertainties, our flux upper limit\nhas a normalization at 1 PeV of\n  E^2{\\Phi}_{\\nu} {\\leq} 6.0 \\times 10^{-9} GeV cm^{-2} s^{-1} sr^{-1}, with\n90% of the events expected within the energy range of ~10 TeV to ~3 PeV. The\nimpact of this limit on several theoretical models of GRBs is discussed, as\nwell as the future potential for detection of GRBs by next generation neutrino\ntelescopes. Finally, we briefly describe several modifications to this analysis\nin order to apply it to other types of transient point sources.\n\n", "human_text": "  We present the results of the analysis of neutrino observations by the\nAntarctic Muon and Neutrino Detector Array (AMANDA) correlated with photon\nobservations of more than 400 gamma-ray bursts (GRBs) in the Northern\nHemisphere from 1997 to 2003. During this time period, AMANDA's effective\ncollection area for muon neutrinos was larger than that of any other existing\ndetector. Based on our observations of zero neutrinos during and immediately\nprior to the GRBs in the dataset, we set the most stringent upper limit on muon\nneutrino emission correlated with gamma-ray bursts. Assuming a Waxman-Bahcall\nspectrum and incorporating all systematic uncertainties, our flux upper limit\nhas a normalization at 1 PeV of\n  E^2{\\Phi}_{\\nu} {\\leq} 6.0 \\times 10^{-9} GeV cm^{-2} s^{-1} sr^{-1}, with\n90% of the events expected within the energy range of ~10 TeV to ~3 PeV. The\nimpact of this limit on several theoretical models of GRBs is discussed, as\nwell as the future potential for detection of GRBs by next generation neutrino\ntelescopes. Finally, we briefly describe several modifications to this analysis\nin order to apply it to other types of transient point sources.\n", "machine_text": "\nThis paper details the AMANDA (Antarctic Muon and Neutrino Detector Array) observations from 1997 to 2003 of photon observations from more than 400 Gamma-Ray Bursts (GRBs) in the Northern Hemisphere. This data set has enabled us to set the most robust upper limit to date for muon neutrino emission from GRBs. Taking into account the Waxman-Bahcall spectrum, our flux upper limit comes in at 6.0 x 10^-9 GeV cm^-2 s^-1 sr^-1 at 1 PeV, with 90% of neutrinos situated between 10 TeV and 3 PeV. We discuss the implications of this limit on several existing theoretical models and the anticipatory detection of GRBs by upcoming neutrino telescopes. Additionally, modifications to this analysis are considered for application in other transient point source studies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1186}
{"prompt": "Rephrase the abstract of an article with title 'On Pure Spinor Superfield Formalism'.\n  We show that a certain superfield formalism can be used to find an off-shell\nsupersymmetric description for some supersymmetric field theories where\nconventional superfield formalism does not work. This \"new\" formalism contains\neven auxiliary variables in addition to conventional odd super-coordinates. The\nidea of this construction is similar to the pure spinor formalism developed by\nN.Berkovits. It is demonstrated that using this formalism it is possible to\nprove that the certain Chern-Simons-like (Witten's OSFT-like) theory can be\nconsidered as an off-shell version for some on-shell supersymmetric field\ntheories. We use the simplest non-trivial model found in [2] to illustrate the\npower of this pure spinor superfield formalism. Then we redo all the\ncalculations for the case of 10-dimensional Super-Yang-Mills theory. The\nconstruction of off-shell description for this theory is more subtle in\ncomparison with the model of [2] and requires additional Z_2 projection. We\ndiscover experimentally (through a direct explicit calculation) a non-trivial\nZ_2 duality at the level of Feynman diagrams. The nature of this duality\nrequires a better investigation.\n\n", "human_text": "  We show that a certain superfield formalism can be used to find an off-shell\nsupersymmetric description for some supersymmetric field theories where\nconventional superfield formalism does not work. This \"new\" formalism contains\neven auxiliary variables in addition to conventional odd super-coordinates. The\nidea of this construction is similar to the pure spinor formalism developed by\nN.Berkovits. It is demonstrated that using this formalism it is possible to\nprove that the certain Chern-Simons-like (Witten's OSFT-like) theory can be\nconsidered as an off-shell version for some on-shell supersymmetric field\ntheories. We use the simplest non-trivial model found in [2] to illustrate the\npower of this pure spinor superfield formalism. Then we redo all the\ncalculations for the case of 10-dimensional Super-Yang-Mills theory. The\nconstruction of off-shell description for this theory is more subtle in\ncomparison with the model of [2] and requires additional Z_2 projection. We\ndiscover experimentally (through a direct explicit calculation) a non-trivial\nZ_2 duality at the level of Feynman diagrams. The nature of this duality\nrequires a better investigation.\n", "machine_text": "\nIn this paper, we present an off-shell supersymmetric description for some supersymmetric field-theories where traditional superfield formalism is not effective. This new formalism involves introducing auxiliary variables in addition to the conventional odd super-coordinates, which is similar to the pure spinor formalism developed by N. Berkovits. We show that this formalism can be used to analyse a Chern-Simons-like (Wittens OSFT-like) theory and prove that it is an off-shell version of some on-shell supersymmetric field theories. We utilize the simplest non-trivial model found in [2] to exemplify the potential of this pure spinor superfield formalism, followed by repeating all the calculations for the 10-dimensional Super-Yang-Mills theory. In this latter case, deriving an off-shell description is more difficult and an additional Z_2 projection is also required. We discover a non-trivial Z_2 duality in the Feynman diagrams, but the nature of this duality needs further studying.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2191}
{"prompt": "Rephrase the abstract of an article with title 'The Dynamical Discrete Web'.\n  The dynamical discrete web (DDW), introduced in recent work of Howitt and\nWarren, is a system of coalescing simple symmetric one-dimensional random walks\nwhich evolve in an extra continuous dynamical parameter s. The evolution is by\nindependent updating of the underlying Bernoulli variables indexed by discrete\nspace-time that define the discrete web at any fixed s. In this paper, we study\nthe existence of exceptional (random) values of s where the paths of the web do\nnot behave like usual random walks and the Hausdorff dimension of the set of\nsuch exceptional s. Our results are motivated by those about exceptional times\nfor dynamical percolation in high dimension by H\\\"aggstrom, Peres and Steif,\nand in dimension two by Schramm and Steif. The exceptional behavior of the\nwalks in DDW is rather different from the situation for dynamical random walks\nof Benjamini, H\\\"aggstrom, Peres and Steif. In particular, we prove that there\nare exceptional values of s for which the walk from the origin S^s(n) has\nlimsup S^s(n)/\\sqrt n \\leq K with a nontrivial dependence of the Hausdorff\ndimension on K. We also discuss how these and other results extend to the\ndynamical Brownian web, a natural scaling limit of DDW. The scaling limit is\nthe focus of a paper in preparation; it was studied by Howitt and Warren and is\nrelated to the Brownian net of Sun and Swart.\n\n", "human_text": "  The dynamical discrete web (DDW), introduced in recent work of Howitt and\nWarren, is a system of coalescing simple symmetric one-dimensional random walks\nwhich evolve in an extra continuous dynamical parameter s. The evolution is by\nindependent updating of the underlying Bernoulli variables indexed by discrete\nspace-time that define the discrete web at any fixed s. In this paper, we study\nthe existence of exceptional (random) values of s where the paths of the web do\nnot behave like usual random walks and the Hausdorff dimension of the set of\nsuch exceptional s. Our results are motivated by those about exceptional times\nfor dynamical percolation in high dimension by H\\\"aggstrom, Peres and Steif,\nand in dimension two by Schramm and Steif. The exceptional behavior of the\nwalks in DDW is rather different from the situation for dynamical random walks\nof Benjamini, H\\\"aggstrom, Peres and Steif. In particular, we prove that there\nare exceptional values of s for which the walk from the origin S^s(n) has\nlimsup S^s(n)/\\sqrt n \\leq K with a nontrivial dependence of the Hausdorff\ndimension on K. We also discuss how these and other results extend to the\ndynamical Brownian web, a natural scaling limit of DDW. The scaling limit is\nthe focus of a paper in preparation; it was studied by Howitt and Warren and is\nrelated to the Brownian net of Sun and Swart.\n", "machine_text": "\nThis paper studies the unique behavior of the Dynamical Discrete Web (DDW) system introduced by Howitt and Warren. DDW is composed of coalesced one-dimensional random walks that evolve through an extra continuous parameter s. We examine the exceptional (random) values of s which can cause the walkers to behave differently than normal random walks. This behavior is connected to the Hausdorff dimension of the corresponding set of s and is motivated by related observations made by Haggstrom, Peres, Steif and Schramm, who studied dynamical percolation in higher dimensions. This behavior differs notably from Benjamini, Haggstrom, Peres, and Steif\u2019s study of dynamical random walks. We prove that there is a limit for the limsup of S^s(n) \\sqrt n which is governed by a nontrivial relationship. Additionally, we touch on the topic of how our findings extend to the dynamical Brownian web, its scaling version, and the Brownian net of Sun and Swart, all of which are subjects of a paper currently being prepared.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2706}
{"prompt": "Rephrase the abstract of an article with title 'Quantification of discreteness effects in cosmological N-body\n  simulations: II. Evolution up to shell crossing'.\n  We apply a recently developed perturbative formalism which describes the\nevolution under their self-gravity of particles displaced from a perfect\nlattice to quantify precisely, up to shell crossing, the effects of\ndiscreteness in dissipationless cosmological N-body simulations. We give simple\nexpressions, explicitly dependent on the particle density, for the evolution of\npower in each mode as a function of red-shift. For typical starting red-shifts\nthe effect of finite particle number is to {\\it slow down} slightly the growth\nof power compared to that in the fluid limit (e.g. by about ten percent at half\nthe Nyquist frequency), and to induce also dispersion in the growth as a\nfunction of direction at a comparable level. In the limit that the initial\nred-shift tends to infinity, at fixed particle density, the evolution in fact\ndiverges from that in the fluid limit (described by the Zeldovich\napproximation). Contrary to widely held belief, this means that a simulation\nstarted at a red-shift much higher than the red-shift of shell crossing\nactually gives a worse, rather than a better, result. We also study how these\neffects are modified when there is a small-scale regularization of the\ngravitational force. We show that such a smoothing may reduce the anisotropy of\nthe discreteness effects, but it then {\\it increases} their average effect.\nThis behaviour illustrates the fact that the discreteness effects described\nhere are distinct from those usually considered in this context, due to\ntwo-body collisions. Indeed the characteristic time for divergence from the\ncollisionless limit is proportional to $N^{2/3}$, rather than $N/ \\log N$ in\nthe latter case.\n\n", "human_text": "  We apply a recently developed perturbative formalism which describes the\nevolution under their self-gravity of particles displaced from a perfect\nlattice to quantify precisely, up to shell crossing, the effects of\ndiscreteness in dissipationless cosmological N-body simulations. We give simple\nexpressions, explicitly dependent on the particle density, for the evolution of\npower in each mode as a function of red-shift. For typical starting red-shifts\nthe effect of finite particle number is to {\\it slow down} slightly the growth\nof power compared to that in the fluid limit (e.g. by about ten percent at half\nthe Nyquist frequency), and to induce also dispersion in the growth as a\nfunction of direction at a comparable level. In the limit that the initial\nred-shift tends to infinity, at fixed particle density, the evolution in fact\ndiverges from that in the fluid limit (described by the Zeldovich\napproximation). Contrary to widely held belief, this means that a simulation\nstarted at a red-shift much higher than the red-shift of shell crossing\nactually gives a worse, rather than a better, result. We also study how these\neffects are modified when there is a small-scale regularization of the\ngravitational force. We show that such a smoothing may reduce the anisotropy of\nthe discreteness effects, but it then {\\it increases} their average effect.\nThis behaviour illustrates the fact that the discreteness effects described\nhere are distinct from those usually considered in this context, due to\ntwo-body collisions. Indeed the characteristic time for divergence from the\ncollisionless limit is proportional to $N^{2/3}$, rather than $N/ \\log N$ in\nthe latter case.\n", "machine_text": "\nWe studied the properties of cosmological simulations which consist of particles causally displaced from an ideal lattice, subject to their own gravitational fields. We present a new set of perturbative equations which, up to shell crossing, quantify the effects of discreteness on the N-body simulations. Our approximation predicts that initial red-shifts of finite particle densities will reduce the growth of power in comparison to the fluid limit, generally by about 10% of the Nyquist frequency, and slightly modify its dispersion as it evolves. While contrary to the general intuition, our analysis shows that a higher initial red-shift actually produces a worse result than a lower one. We also analysed how the discreteness effects are altered when the errors due to two-body collisions are lowered. While smoothing the force was found to decrease the anisotropy, it is shown to enhances the average discreteness effect, due to a time relationship $N^{2/3}$ between the collisionless and collisional regimes, in contrast with the relationship $N / \\log N$ predicted in the former case.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3697}
{"prompt": "Rephrase the abstract of an article with title 'Kinematics of Spiral Arm Streaming in M51'.\n  We use CO and H alpha velocity fields to study the gas kinematics in the\nspiral arms and interarms of M51 (NGC 5194), and fit the 2D velocity field to\nestimate the radial and tangential velocity components as a function of spiral\nphase (arm distance). We find large radial and tangential streaming velocities,\nwhich are qualitatively consistent with the predictions of density wave theory\nand support the existence of shocks. The streaming motions are complex, varying\nsignificantly across the galaxy as well as along and between arms. Aberrations\nin the velocity field indicate that the disk is not coplanar, perhaps as far in\nas 20\\arcsec\\ (800 pc) from the center. Velocity profile fits from CO and H\nalpha are typically similar, suggesting that most of the H alpha emission\noriginates from regions of recent star formation. We also explore vortensity\nand mass conservation conditions. Vortensity conservation, which does not\nrequire a steady state, is empirically verified. The velocity and density\nprofiles show large and varying mass fluxes, which are inconsistent with a\nsteady flow for a single dominant global spiral mode. We thus conclude that the\nspiral arms cannot be in a quasi-steady state in any rotating frame, and/or\nthat out of plane motions may be significant.\n\n", "human_text": "  We use CO and H alpha velocity fields to study the gas kinematics in the\nspiral arms and interarms of M51 (NGC 5194), and fit the 2D velocity field to\nestimate the radial and tangential velocity components as a function of spiral\nphase (arm distance). We find large radial and tangential streaming velocities,\nwhich are qualitatively consistent with the predictions of density wave theory\nand support the existence of shocks. The streaming motions are complex, varying\nsignificantly across the galaxy as well as along and between arms. Aberrations\nin the velocity field indicate that the disk is not coplanar, perhaps as far in\nas 20\\arcsec\\ (800 pc) from the center. Velocity profile fits from CO and H\nalpha are typically similar, suggesting that most of the H alpha emission\noriginates from regions of recent star formation. We also explore vortensity\nand mass conservation conditions. Vortensity conservation, which does not\nrequire a steady state, is empirically verified. The velocity and density\nprofiles show large and varying mass fluxes, which are inconsistent with a\nsteady flow for a single dominant global spiral mode. We thus conclude that the\nspiral arms cannot be in a quasi-steady state in any rotating frame, and/or\nthat out of plane motions may be significant.\n", "machine_text": "\nThe kinematics of the spiral arm streaming in M51 (NGC 5194) are investigated through velocity fields of CO and H alpha. Fitting a 2D velocity field extrapolates the radial and tangential velocity components over different spiral phases, revealing large radial and tangential streaming velocities in accordance with density wave theory and indicating the existence of shocks. The streaming motions indicate complexity across the galaxy, in both between and along arms. Aberrations in the velocity field suggest that the disk is not coplanar at least as close in as 800 pc to the center. The profiles of the H alpha and CO emission are similar, suggesting that the H alpha originates from regions of newly formed stars. The vortensity looses and mass flows are also examined, uncovering varying mass fluxes, which cannot be reconciled with a single global spiral mode. Thus, it is concluded that the spiral arms cannot be in a steady state or that out of plane motions may be particularly relevant.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.324}
{"prompt": "Rephrase the abstract of an article with title 'Magnetic and axial-vector transitions of the baryon antidecuplet'.\n  We report the recent results of the magnetic transitions and axial-vector\ntransitions of the baryon antidecuplet within the framework of the chiral\nquark-soliton model. The dynamical model parameters are fixed by experimental\ndata for the magnetic moments of the baryon octet, for the hyperon semileptonic\ndecay constants, and for the singlet axial-vector constant. The transition\nmagnetic moments $\\mu_{\\Lambda\\Sigma}$ and $\\mu_{N\\Delta}$ are well reproduced\nand other octet-decuplet and octet-antidecuplet transitions are predicted. In\nparticular, the present calculation of $\\mu_{\\Sigma\\Sigma^*}$ is found to be\nbelow the upper bound $0.82\\mu_N$ that the SELEX collaboration measured very\nrecently. The results explains consistently the recent findings of a new $N^*$\nresonance from the GRAAL and Tohoku LNS group. We also obtain the transition\naxial-vector constants for the $\\Theta^+\\to KN$ from which the decay width of\nthe $\\Theta^{+}$ pentaquark baryon is determined as a function of the\npion-nucleon sigma term $\\Sigma_{\\pi N}$. We investigate the dependence of the\ndecay width of the $\\Theta^{+}$ on the $g_{A}^{(0)}$, with the $g_{A}^{(0)}$\nvaried within the range of the experimental uncertainty. We show that a small\ndecay width of the $\\Theta^{+}\\to KN$, i.e. $\\Gamma_{\\Theta KN} \\leq 1$ MeV, is\ncompatible with the values of all known semileptonic decays with the generally\naccepted value of $g_{A}^{(0)} \\approx 0.3$ for the proton.\n\n", "human_text": "  We report the recent results of the magnetic transitions and axial-vector\ntransitions of the baryon antidecuplet within the framework of the chiral\nquark-soliton model. The dynamical model parameters are fixed by experimental\ndata for the magnetic moments of the baryon octet, for the hyperon semileptonic\ndecay constants, and for the singlet axial-vector constant. The transition\nmagnetic moments $\\mu_{\\Lambda\\Sigma}$ and $\\mu_{N\\Delta}$ are well reproduced\nand other octet-decuplet and octet-antidecuplet transitions are predicted. In\nparticular, the present calculation of $\\mu_{\\Sigma\\Sigma^*}$ is found to be\nbelow the upper bound $0.82\\mu_N$ that the SELEX collaboration measured very\nrecently. The results explains consistently the recent findings of a new $N^*$\nresonance from the GRAAL and Tohoku LNS group. We also obtain the transition\naxial-vector constants for the $\\Theta^+\\to KN$ from which the decay width of\nthe $\\Theta^{+}$ pentaquark baryon is determined as a function of the\npion-nucleon sigma term $\\Sigma_{\\pi N}$. We investigate the dependence of the\ndecay width of the $\\Theta^{+}$ on the $g_{A}^{(0)}$, with the $g_{A}^{(0)}$\nvaried within the range of the experimental uncertainty. We show that a small\ndecay width of the $\\Theta^{+}\\to KN$, i.e. $\\Gamma_{\\Theta KN} \\leq 1$ MeV, is\ncompatible with the values of all known semileptonic decays with the generally\naccepted value of $g_{A}^{(0)} \\approx 0.3$ for the proton.\n", "machine_text": "\nThis article presents findings from a study of the magnetic and axial-vector transitions of the baryon antidecuplet using the chiral quark-soliton model. The calculated parameters were obtained from the experimental data for the baryon octet's magnetic moments, hyperon semileptonic decay constants, and singlet axial-vector constant. Results indicate that transition magnetic moments $\\mu_{\\Lambda\\Sigma}$ and $\\mu_{N\\Delta}$ are accurately reproduced and other octet-decuplet and octet-antidecuplet transitions are predicted. Additionally, the calculated $\\mu_{\\Sigma\\Sigma^*}$ falls below the limit imposed by the SELEX collaboration. The precise results explain new observations by the GRAAL and Tohoku LNS group. Furthermore, the transition axial-vector constants for the $\\Theta^+\\to KN$ and its associated decay width as a function of the pion-nucleon sigma term $\\Sigma_{\\pi N}$ are determined. The study also investigates how varying the $g_{A}^{(0)}$ affects the decay width, concluding that a small decay width is possible with generally accepted $g_{A}^{(0)}$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1777}
{"prompt": "Rephrase the abstract of an article with title 'Quantum Hall ferromagnetism in graphene: a SU(4) bosonization approach'.\n  We study the quantum Hall effect in graphene at filling factors \\nu = 0 and\n\\nu = \\pm, concentrating on the quantum Hall ferromagnetic regime, within a\nnon-perturbative bosonization formalism. We start by developing a bosonization\nscheme for electrons with two discrete degrees of freedom (spin-1/2 and\npseudospin-1/2) restricted to the lowest Landau level. Three distinct phases\nare considered, namely the so-called spin-pseudospin, spin, and pseudospin\nphases. The first corresponds to a quarter-filled (\\nu =-1) while the others to\na half-filled (\\nu = 0) lowest Landau level. In each case, we show that the\nelementary neutral excitations can be treated approximately as a set of\nn-independent kinds of boson excitations. The boson representation of the\nprojected electron density, the spin, pseudospin, and mixed spin-pseudospin\ndensity operators are derived. We then apply the developed formalism to the\neffective continuous model, which includes SU(4) symmetry breaking terms,\nrecently proposed by Alicea and Fisher. For each quantum Hall state, an\neffective interacting boson model is derived and the dispersion relations of\nthe elementary excitations are analytically calculated. We propose that the\ncharged excitations (quantum Hall skyrmions) can be described as a coherent\nstate of bosons. We calculate the semiclassical limit of the boson model\nderived from the SU(4) invariant part of the original fermionic Hamiltonian and\nshow that it agrees with the results of Arovas and co-workers for SU(N) quantum\nHall skyrmions. We briefly discuss the influence of the SU(4) symmetry breaking\nterms in the skyrmion energy.\n\n", "human_text": "  We study the quantum Hall effect in graphene at filling factors \\nu = 0 and\n\\nu = \\pm, concentrating on the quantum Hall ferromagnetic regime, within a\nnon-perturbative bosonization formalism. We start by developing a bosonization\nscheme for electrons with two discrete degrees of freedom (spin-1/2 and\npseudospin-1/2) restricted to the lowest Landau level. Three distinct phases\nare considered, namely the so-called spin-pseudospin, spin, and pseudospin\nphases. The first corresponds to a quarter-filled (\\nu =-1) while the others to\na half-filled (\\nu = 0) lowest Landau level. In each case, we show that the\nelementary neutral excitations can be treated approximately as a set of\nn-independent kinds of boson excitations. The boson representation of the\nprojected electron density, the spin, pseudospin, and mixed spin-pseudospin\ndensity operators are derived. We then apply the developed formalism to the\neffective continuous model, which includes SU(4) symmetry breaking terms,\nrecently proposed by Alicea and Fisher. For each quantum Hall state, an\neffective interacting boson model is derived and the dispersion relations of\nthe elementary excitations are analytically calculated. We propose that the\ncharged excitations (quantum Hall skyrmions) can be described as a coherent\nstate of bosons. We calculate the semiclassical limit of the boson model\nderived from the SU(4) invariant part of the original fermionic Hamiltonian and\nshow that it agrees with the results of Arovas and co-workers for SU(N) quantum\nHall skyrmions. We briefly discuss the influence of the SU(4) symmetry breaking\nterms in the skyrmion energy.\n", "machine_text": "\nWe present a SU(4) bosonization approach to explore the quantum Hall ferromagnetic regime in graphene, characterized by filling factors \\nu = 0 and \\nu = \\pm. Our approach is based on a non-perturbative formalism for electrons with spin-1/2 and pseudospin-1/2 degrees of freedom, with attendant three phases of spin-pseudospin, spin, or pseudospin. We then derive the boson representation of the projected electron density, spin, pseudospin, and spin-pseudospin density operators. Applying the formalism to an effective continuous model, the dispersion relations of elementary neutral excitations are calculated. We further propose that the charged excitations (e.g. quantum Hall skyrmions) can be described by a coherent state of bosons and illustrate the semiclassical limit of the derived boson model in accordance with the findings of Arovas and co-workers. To conclude, the influence of SU(4) symmetry breaking terms in skyrmion energy is addressed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3671}
{"prompt": "Rephrase the abstract of an article with title 'Light Heavy MSSM Higgs Bosons at Large tan_beta'.\n  The region of MSSM Higgs parameter space currently excluded by the CDF\nCollaboration, based on an analysis of ~1 fb^-1 of integrated luminosity, is\nless than the expected sensitivity. We analyze the potential implications of\nthe persistence of this discrepancy within the MSSM, assuming that the soft\nsupersymmetry-breaking contributions to scalar masses are universal, apart from\nthose to the Higgs masses (the NUHM model). We find that a light heavy MSSM\nHiggs signal in the unexcluded part of the sensitive region could indeed be\naccommodated in this simple model, even after taking into account other\nconstraints from cold dark matter, electroweak precision observables and B\nphysics observables. In this case the NUHM suggests that supersymmetric\nsignatures should also be detectable in the near future in some other\nmeasurements such as BR(B_s -> mu+ mu-), BR(b -> s gamma) and (g-2)_mu, and M_h\nwould have to be very close to the LEP exclusion limit. In addition, the dark\nmatter candidate associated with this model should be on the verge of detection\nin direct detection experiments.\n\n", "human_text": "  The region of MSSM Higgs parameter space currently excluded by the CDF\nCollaboration, based on an analysis of ~1 fb^-1 of integrated luminosity, is\nless than the expected sensitivity. We analyze the potential implications of\nthe persistence of this discrepancy within the MSSM, assuming that the soft\nsupersymmetry-breaking contributions to scalar masses are universal, apart from\nthose to the Higgs masses (the NUHM model). We find that a light heavy MSSM\nHiggs signal in the unexcluded part of the sensitive region could indeed be\naccommodated in this simple model, even after taking into account other\nconstraints from cold dark matter, electroweak precision observables and B\nphysics observables. In this case the NUHM suggests that supersymmetric\nsignatures should also be detectable in the near future in some other\nmeasurements such as BR(B_s -> mu+ mu-), BR(b -> s gamma) and (g-2)_mu, and M_h\nwould have to be very close to the LEP exclusion limit. In addition, the dark\nmatter candidate associated with this model should be on the verge of detection\nin direct detection experiments.\n", "machine_text": "\nThis paper examines the potential implications of a discrepancy between the MSSM Higgs parameter space currently excluded by the CDF Collaboration and its expected sensitivity, as seen with ~1 fb^-1 of integrated luminosity. Specifically, we analyze the possibility that a light heavy MSSM Higgs signal could be observed in the unexcluded part of the sensitive region within the NUHM model, which approximates scalar mass contributions as universal, apart from those to Higgs masses. Other constraints such as dark matter, electroweak precision observables, B physics observables and M_h must be taken into account, and the analysis suggests that supersymmetric signatures should likely be detected in the near future in these areas. Furthermore, the dark matter candidate associated with the model should be close to being found in direct detection experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0977}
{"prompt": "Rephrase the abstract of an article with title 'The Haunted Halos of Andromeda and Triangulum: A panorama of galaxy\n  formation in action'.\n  We present a deep photometric survey of M31, conducted with the CFHT and INT,\ncovering the inner 50 kpc of the galaxy, the Southern quadrant out to 150 kpc,\nand extending to M33. This is the first systematic panoramic study of this very\noutermost region of galaxies. We detect several streams and other large-scale\nstructures, and two new dwarf galaxies: And XV and XVI. The discovery of\nsubstructure on the minor axis, together with the fact that the light profile\nbetween 0.5 < R < 1.3 follows the exponential ``extended disk'', is\nparticularly important in shedding light on the mixed and sometimes conflicting\nresults reported in previous studies. Underlying the substructures lies a\nfaint, metal-poor, smooth and extremely extended halo, reaching out to at least\n150 kpc. The smooth halo component in M31 has a profile that can be fit with a\nHernquist model of immense scale radius ~55 kpc, almost a factor of 4 larger\nthan theoretical predictions. Alternatively a power-law with exponent -1.91 +/-\n0.11 can be fit to the profile. The total luminosity of this structure is\nsimilar to that of the halo of the Milky Way. This vast, smooth, underlying\nhalo is reminiscent of a classical monolithic model and completely unexpected\nfrom modern galaxy formation models. M33 is also found to have an extended\nmetal-poor halo component, which can be fit with a Hernquist model also of\nscale radius ~55 kpc. These extended slowly-decreasing halos will provide a\nchallenge and strong constraints for further modeling. [Abridged]\n\n", "human_text": "  We present a deep photometric survey of M31, conducted with the CFHT and INT,\ncovering the inner 50 kpc of the galaxy, the Southern quadrant out to 150 kpc,\nand extending to M33. This is the first systematic panoramic study of this very\noutermost region of galaxies. We detect several streams and other large-scale\nstructures, and two new dwarf galaxies: And XV and XVI. The discovery of\nsubstructure on the minor axis, together with the fact that the light profile\nbetween 0.5 < R < 1.3 follows the exponential ``extended disk'', is\nparticularly important in shedding light on the mixed and sometimes conflicting\nresults reported in previous studies. Underlying the substructures lies a\nfaint, metal-poor, smooth and extremely extended halo, reaching out to at least\n150 kpc. The smooth halo component in M31 has a profile that can be fit with a\nHernquist model of immense scale radius ~55 kpc, almost a factor of 4 larger\nthan theoretical predictions. Alternatively a power-law with exponent -1.91 +/-\n0.11 can be fit to the profile. The total luminosity of this structure is\nsimilar to that of the halo of the Milky Way. This vast, smooth, underlying\nhalo is reminiscent of a classical monolithic model and completely unexpected\nfrom modern galaxy formation models. M33 is also found to have an extended\nmetal-poor halo component, which can be fit with a Hernquist model also of\nscale radius ~55 kpc. These extended slowly-decreasing halos will provide a\nchallenge and strong constraints for further modeling. [Abridged]\n", "machine_text": "\nThis paper discusses a systematic panoramic survey of M31, including its Southern quadrant out to 150 kpc, and M33. We detect substructure, two new dwarf galaxies, and a faint metal-poor halo. This halo, which can be fit with either a Hernquist model or a power-law, is surprisingly large in scale and extends to 150 kpc, similar to the halo of the Milky Way. Its presence appears to conflict with modern galaxy formation models, making it a puzzle that they must solve. M33 is found to have a comparable extended metal-poor halo structure, thus providing a challenge and constraint for further modeling.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1318}
{"prompt": "Rephrase the abstract of an article with title 'Thermal effects on nuclear symmetry energy with a momentum-dependent\n  effective interaction'.\n  The knowledge of the nuclear symmetry energy of hot neutron-rich matter is\nimportant for understanding the dynamical evolution of massive stars and the\nsupernova explosion mechanisms. In particular, the electron capture rate on\nnuclei and/or free protons in presupernova explosions is especially sensitive\nto the symmetry energy at finite temperature. In view of the above, in the\npresent work we calculate the symmetry energy as a function of the temperature\nfor various values of the baryon density, by applying a momentum-dependent\neffective interaction. In addition to a previous work, the thermal effects are\nstudied separately both in the kinetic part and the interaction part of the\nsymmetry energy. We focus also on the calculations of the mean field potential,\nemployed extensively in heavy ion reaction research, both for nuclear and pure\nneutron matter. The proton fraction and the electron chemical potential, which\nare crucial quantities for representing the thermal evolution of supernova and\nneutron stars, are calculated for various values of the temperature. Finally,\nwe construct a temperature dependent equation of state of $\\beta$-stable\nnuclear matter, the basic ingredient for the evaluation of the neutron star\nproperties.\n\n", "human_text": "  The knowledge of the nuclear symmetry energy of hot neutron-rich matter is\nimportant for understanding the dynamical evolution of massive stars and the\nsupernova explosion mechanisms. In particular, the electron capture rate on\nnuclei and/or free protons in presupernova explosions is especially sensitive\nto the symmetry energy at finite temperature. In view of the above, in the\npresent work we calculate the symmetry energy as a function of the temperature\nfor various values of the baryon density, by applying a momentum-dependent\neffective interaction. In addition to a previous work, the thermal effects are\nstudied separately both in the kinetic part and the interaction part of the\nsymmetry energy. We focus also on the calculations of the mean field potential,\nemployed extensively in heavy ion reaction research, both for nuclear and pure\nneutron matter. The proton fraction and the electron chemical potential, which\nare crucial quantities for representing the thermal evolution of supernova and\nneutron stars, are calculated for various values of the temperature. Finally,\nwe construct a temperature dependent equation of state of $\\beta$-stable\nnuclear matter, the basic ingredient for the evaluation of the neutron star\nproperties.\n", "machine_text": "This study investigates the thermal effects on nuclear symmetry energy for different baryon density values using a momentum-dependent effective interaction. The symmetry energy, mean field potential, proton fraction and electron chemical potential are estimated at various temperatures. Additionally, an equation of state of $\\beta$-stable nuclear matter is constructed, providing essential information for the evaluation of neutron star properties. The results of this work provide valuable insight into the dynamical evolution of massive stars, presupernova explosions and neutron stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0698}
{"prompt": "Rephrase the abstract of an article with title 'The distance and neutral environment of the massive stellar cluster\n  Westerlund 1'.\n  The goal of this study is to determine a distance to Westerlund 1 independent\nof the characteristics of the stellar population and to study its neutral\nenvironment, using observations of atomic hydrogen. The HI observations are\ntaken from the Southern Galactic Plane Survey to study HI absorption in the\ndirection of the HII region created by the members of Westerlund 1 and to\ninvestigate its environment as observed in the HI line emission. A Galactic\nrotation curve was derived using the recently revised values for the Galactic\ncentre distance of $R_\\odot = 7.6$ kpc, and the velocity of the Sun around the\nGalactic centre of $\\Theta_\\odot = 214$ km s$^{-1}$. The newly determined\nrotation model leads us to derive a distance of $3.9\\pm 0.7$ kpc to Westerlund\n1, consistent with a location in the Scutum-Crux Arm. Included in this estimate\nis a very careful investigation of possible sources of error for the Galactic\nrotation curve. We also report on small expanding HI features around the\ncluster with a maximum dynamic age of 600,000 years and a larger bubble which\nhas a minimum dynamic age of 2.5 million years. Additionally we re-calculated\nthe kinematic distances to nearby HII regions and supernova remnants based on\nour new Galaxic rotation curve. We propose that in the early stages of the\ndevelopment of Wd 1 a large interstellar bubble of diameter about 50 pc was\ncreated by the cluster members. This bubble has a dynamic age similar to the\nage of the cluster. Small expanding bubbles, with dynamical ages $\\sim 0.6$ Myr\nare found around Wd 1, which we suggest consist of recombined material lost by\ncluster members through their winds.\n\n", "human_text": "  The goal of this study is to determine a distance to Westerlund 1 independent\nof the characteristics of the stellar population and to study its neutral\nenvironment, using observations of atomic hydrogen. The HI observations are\ntaken from the Southern Galactic Plane Survey to study HI absorption in the\ndirection of the HII region created by the members of Westerlund 1 and to\ninvestigate its environment as observed in the HI line emission. A Galactic\nrotation curve was derived using the recently revised values for the Galactic\ncentre distance of $R_\\odot = 7.6$ kpc, and the velocity of the Sun around the\nGalactic centre of $\\Theta_\\odot = 214$ km s$^{-1}$. The newly determined\nrotation model leads us to derive a distance of $3.9\\pm 0.7$ kpc to Westerlund\n1, consistent with a location in the Scutum-Crux Arm. Included in this estimate\nis a very careful investigation of possible sources of error for the Galactic\nrotation curve. We also report on small expanding HI features around the\ncluster with a maximum dynamic age of 600,000 years and a larger bubble which\nhas a minimum dynamic age of 2.5 million years. Additionally we re-calculated\nthe kinematic distances to nearby HII regions and supernova remnants based on\nour new Galaxic rotation curve. We propose that in the early stages of the\ndevelopment of Wd 1 a large interstellar bubble of diameter about 50 pc was\ncreated by the cluster members. This bubble has a dynamic age similar to the\nage of the cluster. Small expanding bubbles, with dynamical ages $\\sim 0.6$ Myr\nare found around Wd 1, which we suggest consist of recombined material lost by\ncluster members through their winds.\n", "machine_text": "\nThis paper reports the findings of a study focused on assessing the distance and neutral environment of the stellar cluster Westerlund 1. Through utilising Southern Galactic Plane Survey data for atomic hydrogen, the authors were able to explore HI absorption from the HII region connected to the cluster, as well as investigate its environment as seen in HI line emission. Using an updated Galactic rotation curve \u2013 with revised values for the distance from the Galactic centre and the velocity of the Sun around this centre \u2013 the research team derive a distance of 3.9 \u00b1 0.7 kpc to Westerlund 1, placing the cluster in the Scutum-Crux Arm. Additionally, a multitude of other elements are evaluated, including potential sources of error in the Galactic rotation curve, small expanding HI features with a maximum dynamic age of 600,000 years around the cluster, as well as a larger bubble with a minimum dynamic age of 2.5 million years. Finally, a re-evaluation of kinematic distances to nearby HII regions and supernova remnants based on the new Galactic rotation curve is presented. The authors offer the suggestion that the collective effects of stellar winds in the early stages of Westerlund 1's formation created a 50 pc bubble with a dynamic age comparable to the cluster's.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3073}
{"prompt": "Rephrase the abstract of an article with title 'Efficient Simulations of Early Structure Formation and Reionization'.\n  We present a method to construct semi-numerical ``simulations'', which can\nefficiently generate realizations of halo distributions and ionization maps at\nhigh redshifts. Our procedure combines an excursion-set approach with\nfirst-order Lagrangian perturbation theory and operates directly on the linear\ndensity and velocity fields. As such, the achievable dynamic range with our\nalgorithm surpasses the current practical limit of N-body codes by orders of\nmagnitude. This is particularly significant in studies of reionization, where\nthe dynamic range is the principal limiting factor. We test our halo-finding\nand HII bubble-finding algorithms independently against N-body simulations with\nradiative transfer and obtain excellent agreement. We compute the size\ndistributions of ionized and neutral regions in our maps. We find even larger\nionized bubbles than do purely analytic models at the same volume-weighted mean\nhydrogen neutral fraction. We also generate maps and power spectra of 21-cm\nbrightness temperature fluctuations, which for the first time include\ncorrections due to gas bulk velocities. We find that velocities widen the tails\nof the temperature distributions and increase small-scale power, though these\neffects quickly diminish as reionization progresses. We also include some\npreliminary results from a simulation run with the largest dynamic range to\ndate: a 250 Mpc box that resolves halos with masses M >~ 2.2 x10^8 M_sun. We\nshow that accurately modeling the late stages of reionization requires such\nlarge scales. The speed and dynamic range provided by our semi-numerical\napproach will be extremely useful in the modeling of early structure formation\nand reionization.\n\n", "human_text": "  We present a method to construct semi-numerical ``simulations'', which can\nefficiently generate realizations of halo distributions and ionization maps at\nhigh redshifts. Our procedure combines an excursion-set approach with\nfirst-order Lagrangian perturbation theory and operates directly on the linear\ndensity and velocity fields. As such, the achievable dynamic range with our\nalgorithm surpasses the current practical limit of N-body codes by orders of\nmagnitude. This is particularly significant in studies of reionization, where\nthe dynamic range is the principal limiting factor. We test our halo-finding\nand HII bubble-finding algorithms independently against N-body simulations with\nradiative transfer and obtain excellent agreement. We compute the size\ndistributions of ionized and neutral regions in our maps. We find even larger\nionized bubbles than do purely analytic models at the same volume-weighted mean\nhydrogen neutral fraction. We also generate maps and power spectra of 21-cm\nbrightness temperature fluctuations, which for the first time include\ncorrections due to gas bulk velocities. We find that velocities widen the tails\nof the temperature distributions and increase small-scale power, though these\neffects quickly diminish as reionization progresses. We also include some\npreliminary results from a simulation run with the largest dynamic range to\ndate: a 250 Mpc box that resolves halos with masses M >~ 2.2 x10^8 M_sun. We\nshow that accurately modeling the late stages of reionization requires such\nlarge scales. The speed and dynamic range provided by our semi-numerical\napproach will be extremely useful in the modeling of early structure formation\nand reionization.\n", "machine_text": "\nWe present a novel semi-numerical procedure to generate realistic representations of high redshift halo and ionization distributions, combining an excursion-set approach and first-order Lagrangian perturbation theory applied directly to linear density and velocity fields. This method will dramatically outpace the current practical limit of N-body codes in terms of dynamic range, allowing a greater accuracy in reionization studies due to better resolution. We compare the resulting halo and HII bubble distributions from our approach with those from N-body simulations and radiative transfer and find extremely good agreement. We also asses the size distributions of ionized and neutral regions, as well as power spectra of 21-cm brightness temperature fluctuations, and find them to be in line with previous predictions. We also include results based on a simulation of our semi-numerical approach run on absolutely the largest dynamic range to date, that of a 250 Mpc box with the capacity to resolve halos with a mass M >~ 2.2 x10^8 M_sun. This clearly highlights the importance of such a large scale to accurately model the late stages of reionization. Our semi-numerical approach offers increased speed and dynamic range which will be invaluable in the modeling of early structure formation and reionization.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0946}
{"prompt": "Rephrase the abstract of an article with title 'Systematic uncertainties of hadron parameters obtained with QCD sum\n  rules'.\n  We study the uncertainties of the determination of the ground-state\nparameters from Shifman-Vainshtein-Zakharov (SVZ) sum rules, making use of the\nharmonic-oscillator potential model as an example. In this case, one knows the\nexact solution for the polarization operator $\\Pi(\\mu)$, which allows one to\nobtain both the OPE to any order and the spectrum of states. We start with the\nOPE for $\\Pi(\\mu)$ and analyze the extraction of the square of the ground-state\nwave function, $R\\propto|\\Psi_0(\\vec r=0)|^2$, from an SVZ sum rule, setting\nthe mass of the ground state $E_0$ equal to its known value and treating the\neffective continuum threshold as a fit parameter. We show that in a limited\n``fiducial'' range of the Borel parameter there exists a solution for the\neffective threshold which precisely reproduces the exact $\\Pi(\\mu)$ for any\nvalue of $R$ within the range $0.7 \\le R/R_0 \\le 1.15$ ($R_0$ is the known\nexact value). Thus, the value of $R$ extracted from the sum rule is determined\nto a great extent by the contribution of the hadron continuum. Our main finding\nis that in the cases where the hadron continuum is not known and is modeled by\nan effective continuum threshold, the systematic uncertainties of the sum-rule\nprocedure cannot be controlled.\n\n", "human_text": "  We study the uncertainties of the determination of the ground-state\nparameters from Shifman-Vainshtein-Zakharov (SVZ) sum rules, making use of the\nharmonic-oscillator potential model as an example. In this case, one knows the\nexact solution for the polarization operator $\\Pi(\\mu)$, which allows one to\nobtain both the OPE to any order and the spectrum of states. We start with the\nOPE for $\\Pi(\\mu)$ and analyze the extraction of the square of the ground-state\nwave function, $R\\propto|\\Psi_0(\\vec r=0)|^2$, from an SVZ sum rule, setting\nthe mass of the ground state $E_0$ equal to its known value and treating the\neffective continuum threshold as a fit parameter. We show that in a limited\n``fiducial'' range of the Borel parameter there exists a solution for the\neffective threshold which precisely reproduces the exact $\\Pi(\\mu)$ for any\nvalue of $R$ within the range $0.7 \\le R/R_0 \\le 1.15$ ($R_0$ is the known\nexact value). Thus, the value of $R$ extracted from the sum rule is determined\nto a great extent by the contribution of the hadron continuum. Our main finding\nis that in the cases where the hadron continuum is not known and is modeled by\nan effective continuum threshold, the systematic uncertainties of the sum-rule\nprocedure cannot be controlled.\n", "machine_text": "\nThis research sets out to explore the systematic uncertainties encountered in the use of Shifman-Vainshtein-Zakharov (SVZ) sum rules to identify the parameters of hadron ground-states. We put this idea to the test by utilising the harmonic-oscillator potential model in a bid to uncover the influence of hadron continuum on the extraction of the square of the ground-state wave function, $R\\propto|\\Psi_0(\\vec r=0)|^2$ from an SVZ sum rule. Results indicate that the hadron continuum exhibits a major part in establishing the output of the sum rule and the exact value of $R$, though when the exact continuum is not known, it is difficult to control the systematic uncertainties of the procedure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.047}
{"prompt": "Rephrase the abstract of an article with title 'The Infrared Ca II triplet as metallicity indicator'.\n  From observations of almost 500 RGB stars in 29 Galactic open and globular\nclusters, we have investigated the behaviour of the infrared Ca II triplet\n(8498, 8542 and 8662 \\AA) in the age range 13$\\leq$Age/Gyr$\\leq$0.25 and the\nmetallicity range $-2.2\\leq$ [Fe/H] $\\leq$+0.47. These are the widest ranges of\nages and metallicities in which the behaviour of the Ca II triplet lines has\nbeen investigated in a homogeneous way. We report the first empirical study of\nthe variation of the CaII triplet lines strength, for given metallicities, with\nrespect to luminosity. We find that the sequence defined by each cluster in the\nLuminosity-$\\Sigma$Ca plane is not exactly linear. However, when only stars in\na small magnitude interval are observed, the sequences can be considered as\nlinear. We have studied the the Ca II triplet lines on three metallicities\nscales. While a linear correlation between the reduced equivalent width ($W'_V$\nor $W'_I$) versus metallicity is found in the \\citet{cg97} and \\citet{ki03}\nscales, a second order term needs to be added when the \\citet{zw84} scale is\nadopted. We investigate the role of age from the wide range of ages covered by\nour sample. We find that age has a weak influence on the final relationship.\nFinally, the relationship derived here is used to estimate the metallicities of\nthree poorly studied open clusters: Berkeley 39, Trumpler 5 and Collinder 110.\nFor the latter, the metallicity derived here is the first spectroscopic\nestimate available.\n\n", "human_text": "  From observations of almost 500 RGB stars in 29 Galactic open and globular\nclusters, we have investigated the behaviour of the infrared Ca II triplet\n(8498, 8542 and 8662 \\AA) in the age range 13$\\leq$Age/Gyr$\\leq$0.25 and the\nmetallicity range $-2.2\\leq$ [Fe/H] $\\leq$+0.47. These are the widest ranges of\nages and metallicities in which the behaviour of the Ca II triplet lines has\nbeen investigated in a homogeneous way. We report the first empirical study of\nthe variation of the CaII triplet lines strength, for given metallicities, with\nrespect to luminosity. We find that the sequence defined by each cluster in the\nLuminosity-$\\Sigma$Ca plane is not exactly linear. However, when only stars in\na small magnitude interval are observed, the sequences can be considered as\nlinear. We have studied the the Ca II triplet lines on three metallicities\nscales. While a linear correlation between the reduced equivalent width ($W'_V$\nor $W'_I$) versus metallicity is found in the \\citet{cg97} and \\citet{ki03}\nscales, a second order term needs to be added when the \\citet{zw84} scale is\nadopted. We investigate the role of age from the wide range of ages covered by\nour sample. We find that age has a weak influence on the final relationship.\nFinally, the relationship derived here is used to estimate the metallicities of\nthree poorly studied open clusters: Berkeley 39, Trumpler 5 and Collinder 110.\nFor the latter, the metallicity derived here is the first spectroscopic\nestimate available.\n", "machine_text": " By examining nearly 500 red giant stars in 29 galactic open clusters and globular clusters, this empirical study seeks to analyze the changes in strength of the infrared Ca II triplet (8498, 8542 and 8662 \\AA) corresponding with the given metallicity and luminosity. The age and metallicity range of these samples are the widest for which the Ca II triplet has been examined homogeneously. The results suggest a correlation between reduced equivalent width and metallicity, with a second order term if the \\citet{zw84} scale is utilized. It was additionally found that age had only a minor role to play in the relationship. The findings are applied to estimate the metallicities of Berkeley 39, Trumpler 5, and Collinder 110 clusters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3335}
{"prompt": "Rephrase the abstract of an article with title 'New Close Binary Systems from the SDSS-I (Data Release Five) and the\n  Search for Magnetic White Dwarfs in Cataclysmic Variable Progenitor Systems'.\n  We present the latest catalog of more than 1200 spectroscopically-selected\nclose binary systems observed with the Sloan Digital Sky Survey through Data\nRelease Five. We use the catalog to search for magnetic white dwarfs in\ncataclysmic variable progenitor systems. Given that approximately 25% of\ncataclysmic variables contain a magnetic white dwarf, and that our large sample\nof close binary systems should contain many progenitors of cataclysmic\nvariables, it is quite surprising that we find only two potential magnetic\nwhite dwarfs in this sample. The candidate magnetic white dwarfs, if confirmed,\nwould possess relatively low magnetic field strengths (B_WD < 10 MG) that are\nsimilar to those of intermediate-Polars but are much less than the average\nfield strength of the current Polar population. Additional observations of\nthese systems are required to definitively cast the white dwarfs as magnetic.\nEven if these two systems prove to be the first evidence of detached magnetic\nwhite dwarf + M dwarf binaries, there is still a large disparity between the\nproperties of the presently known cataclysmic variable population and the\npresumed close binary progenitors.\n\n", "human_text": "  We present the latest catalog of more than 1200 spectroscopically-selected\nclose binary systems observed with the Sloan Digital Sky Survey through Data\nRelease Five. We use the catalog to search for magnetic white dwarfs in\ncataclysmic variable progenitor systems. Given that approximately 25% of\ncataclysmic variables contain a magnetic white dwarf, and that our large sample\nof close binary systems should contain many progenitors of cataclysmic\nvariables, it is quite surprising that we find only two potential magnetic\nwhite dwarfs in this sample. The candidate magnetic white dwarfs, if confirmed,\nwould possess relatively low magnetic field strengths (B_WD < 10 MG) that are\nsimilar to those of intermediate-Polars but are much less than the average\nfield strength of the current Polar population. Additional observations of\nthese systems are required to definitively cast the white dwarfs as magnetic.\nEven if these two systems prove to be the first evidence of detached magnetic\nwhite dwarf + M dwarf binaries, there is still a large disparity between the\nproperties of the presently known cataclysmic variable population and the\npresumed close binary progenitors.\n", "machine_text": "\nThis paper investigates over 1200 close binary systems observed with the SDSS-I Data Release Five and seeks to find any magnetic white dwarf\nin these systems as they could be potential progenitors of Cataclysmic Variables. Surprisingly, only two of these binary systems are believed to contain magnetic white dwarfs with a magnetic field strength lower than 10 MG. To\nconfirm this result, further observations are needed. Finding these two candidate systems is encouraging given that the expected proportion of Cataclysmic Variables containing magnetic white dwarfs is approximately 25%.\nHowever, even if these were the first known detached magnetic white dwarf + M dwarf binaries, that would still not explain the discrepancy between the known Cataclysmic Variable population and the likely close binary progenitors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0789}
{"prompt": "Rephrase the abstract of an article with title 'Folding model study of the isobaric analog excitation: isovector density\n  dependence, Lane potential and nuclear symmetry energy'.\n  A consistent folding model analysis of the ($\\Delta S=0, \\Delta T=1$) charge\nexchange \\pn reaction measured with $^{48}$Ca, $^{90}$Zr, $^{120}$Sn and\n$^{208}$Pb targets at the proton energies of 35 and 45 MeV is done within a\ntwo-channel coupling formalism. The nuclear ground state densities given by the\nHartree-Fock-Bogoljubov formalism and the density dependent CDM3Y6 interaction\nwere used as inputs for the folding calculation of the nucleon optical\npotential and \\pn form factor. To have an accurate isospin dependence of the\ninteraction, a complex isovector density dependence of the CDM3Y6 interaction\nhas been carefully calibrated against the microscopic Brueckner-Hatree-Fock\ncalculation by Jeukenne, Lejeune and Mahaux before being used as folding input.\nSince the isovector coupling was used to explicitly link the isovector part of\nthe nucleon optical potential to the cross section of \\pn reaction exciting the\n0$^+$ isobaric analog states in $^{48}$Sc, $^{90}$Nb, $^{120}$Sb and\n$^{208}$Bi, the newly parameterized isovector density dependence could be well\ntested in the folding model analysis of the \\pn reaction. The isospin- and\ndensity dependent CDM3Y6 interaction was further used in the Hartree-Fock\ncalculation of asymmetric nuclear matter, and a realistic estimation of the\nnuclear symmetry energy has been made.\n\n", "human_text": "  A consistent folding model analysis of the ($\\Delta S=0, \\Delta T=1$) charge\nexchange \\pn reaction measured with $^{48}$Ca, $^{90}$Zr, $^{120}$Sn and\n$^{208}$Pb targets at the proton energies of 35 and 45 MeV is done within a\ntwo-channel coupling formalism. The nuclear ground state densities given by the\nHartree-Fock-Bogoljubov formalism and the density dependent CDM3Y6 interaction\nwere used as inputs for the folding calculation of the nucleon optical\npotential and \\pn form factor. To have an accurate isospin dependence of the\ninteraction, a complex isovector density dependence of the CDM3Y6 interaction\nhas been carefully calibrated against the microscopic Brueckner-Hatree-Fock\ncalculation by Jeukenne, Lejeune and Mahaux before being used as folding input.\nSince the isovector coupling was used to explicitly link the isovector part of\nthe nucleon optical potential to the cross section of \\pn reaction exciting the\n0$^+$ isobaric analog states in $^{48}$Sc, $^{90}$Nb, $^{120}$Sb and\n$^{208}$Bi, the newly parameterized isovector density dependence could be well\ntested in the folding model analysis of the \\pn reaction. The isospin- and\ndensity dependent CDM3Y6 interaction was further used in the Hartree-Fock\ncalculation of asymmetric nuclear matter, and a realistic estimation of the\nnuclear symmetry energy has been made.\n", "machine_text": "\nThis article presents an analysis of a two-channel coupling formalism for the charge-exchange reaction with isobaric analog excitation in four different target nuclei ($^{48}$Ca, $^{90}$Zr, $^{120}$Sn and $^{208}$Pb) at the proton energies of 35 and 45 MeV. This research utilizes the Hartree-Fock-Bogoljubov nuclear ground state densities, as well as the density-dependent CDM3Y6 interaction, for the folding calculation of the nucleon optical potential and \\pn form factor. The complex isovector density dependence of the CDM3Y6 used for the analysis had been previously calibrated against the Brueckner-Hatree-Fock microscopic calculation. As such, this study serves to test the accuracy of the isovector coupling via examining the 0$^+$ isobaric analog states in $^{48}$Sc, $^{90}$Nb, $^{120}$Sb and $^{208}$Bi in the folding model analysis of the \\pn reaction. Furthermore, the isospin- and density-dependent CDM3Y6 interaction was utilized for the Hartree-Fock calculation of symmetric and asymmetric nuclear matter allowing for a realistic estimation of the nuclear symmetry energy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1282}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic Acceleration Data and Bulk-Brane Energy Exchange'.\n  We consider a braneworld model with bulk-brane energy exchange. This allows\nfor crossing of the w=-1 phantom divide line without introducing phantom energy\nwith quantum instabilities. We use the latest SnIa data included in the Gold06\ndataset to provide an estimate of the preferred parameter values of this\nbraneworld model. We use three fitting approaches which provide best fit\nparameter values and hint towards a bulk energy component that behaves like\nrelativistic matter which is propagating in the bulk and is moving at a speed v\nalong the fifth dimension, while the bulk-brane energy exchange component\ncorresponds to negative pressure and signifies energy flowing from the bulk\ninto the brane. We find that the best fit effective equation of state parameter\n$w_{eff}$ marginally crosses the phantom divide line w=-1. Thus, we have\ndemonstrated both the ability of this class of braneworld models to provide\ncrossing of the phantom divide and also that cosmological data hint towards\nnatural values for the model parameters.\n\n", "human_text": "  We consider a braneworld model with bulk-brane energy exchange. This allows\nfor crossing of the w=-1 phantom divide line without introducing phantom energy\nwith quantum instabilities. We use the latest SnIa data included in the Gold06\ndataset to provide an estimate of the preferred parameter values of this\nbraneworld model. We use three fitting approaches which provide best fit\nparameter values and hint towards a bulk energy component that behaves like\nrelativistic matter which is propagating in the bulk and is moving at a speed v\nalong the fifth dimension, while the bulk-brane energy exchange component\ncorresponds to negative pressure and signifies energy flowing from the bulk\ninto the brane. We find that the best fit effective equation of state parameter\n$w_{eff}$ marginally crosses the phantom divide line w=-1. Thus, we have\ndemonstrated both the ability of this class of braneworld models to provide\ncrossing of the phantom divide and also that cosmological data hint towards\nnatural values for the model parameters.\n", "machine_text": "This paper examines a cosmological brane-bulk model of exchange of energy between the two realms. We investigate the possibility of the model to offer a crossing of the phantom divide without introducing phantom energy, which has underlying quantum instabilities. Our research uses the seminal Gold06 SnIa dataset to provide an estimate of the preferred parameter values. We provide 3 different fitting approaches that propose the best fit parameters, and suggest that a bulk energy component is responsible for the energy flow to the brane, exhibiting a behaviour akin to relativistic matter that propagates in the bulk at a velocity v. The bulk-brane exchange component, meanwhile, indicates energy is transferred from the bulk to the brane, signifying negative pressure. Our findings illustrate the ability of such braneworld models to afford a natural crossing of the phantom divide line, while pointing to the relevant parameter values in agreement with current cosmic acceleration data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3181}
{"prompt": "Rephrase the abstract of an article with title 'Relic abundance of dark matter in universal extra dimension models with\n  right-handed neutrinos'.\n  Relic abundance of dark matter is investigated in the framework of universal\nextra dimension models with right-handed neutrinos. These models are free from\nthe serious Kaluza-Klein (KK) graviton problem that the original universal\nextra dimension model has. The first KK particle of the right-handed neutrino\nis a candidate for dark matter in this framework, and its relic abundance is\ndetermined by three processes, (1) the decay of the KK photon into the first KK\nright-handed neutrino in the late universe, (2) production of the first KK\nright-handed neutrino from the thermal bath in the early universe, and (3) the\ndecay of higher KK right-handed neutrinos into the first KK right-handed\nneutrino in the late universe. When ordinary neutrino masses are large enough\nsuch as the degenerate mass spectrum case, the last process contribute to the\nabundance significantly, even if the reheating temperature is low. The scale of\nthe extra dimension consistent with cosmological observations can be 500 GeV in\nthe minimal setup of universal extra dimension models with right-handed\nneutrinos.\n\n", "human_text": "  Relic abundance of dark matter is investigated in the framework of universal\nextra dimension models with right-handed neutrinos. These models are free from\nthe serious Kaluza-Klein (KK) graviton problem that the original universal\nextra dimension model has. The first KK particle of the right-handed neutrino\nis a candidate for dark matter in this framework, and its relic abundance is\ndetermined by three processes, (1) the decay of the KK photon into the first KK\nright-handed neutrino in the late universe, (2) production of the first KK\nright-handed neutrino from the thermal bath in the early universe, and (3) the\ndecay of higher KK right-handed neutrinos into the first KK right-handed\nneutrino in the late universe. When ordinary neutrino masses are large enough\nsuch as the degenerate mass spectrum case, the last process contribute to the\nabundance significantly, even if the reheating temperature is low. The scale of\nthe extra dimension consistent with cosmological observations can be 500 GeV in\nthe minimal setup of universal extra dimension models with right-handed\nneutrinos.\n", "machine_text": "The abundance of dark matter is explored in the context of Universal Extra\nDimension (UED) models which include right-handed neutrinos. As this new setup\ndoesn't suffer from Kaluza-Klein (KK) graviton problems, the first KK particle\nof the right-handed neutrino is a possible dark matter candidate. Its relic\nabundance can be determined by three mechanisms: (1) Decay of the KK photon\ninto the first KK right-handed neutrino late in the universe; (2) Production\nof the first KK right-handed neutrino from the thermal bath early in the\nuniverse; and (3) Decay of higher KK right-handed neutrinos into the first\nKK right-handed neutrino again late in the universe. This last process can\ncontribute significantly to the amount of dark matter, regardless of the\nreheating temperature of the universe, when the ordinary neutrino mass is high\nenough, as seen in cases of degenerate neutrino mass spectra. The scale of the\nextra dimension which is consistent with observational cosmology can then be\nestimated to be 500 GeV for the minimal configuration of the UED models with\nright-handed neutrinos.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0934}
{"prompt": "Rephrase the abstract of an article with title 'A Derivation of Einstein Gravity without the Axiom of Choice: Topology\n  Hidden in GR'.\n  A derivation of the equations of motion of general relativity is presented\nthat does not invoke the Axiom of Choice, but requires the explicit\nconstruction of a choice function q for continuous three-space regions. The\nmotivation for this (seemingly academic) endeavour is to take the background\nindependence intrinsic to Einstein gravity one step further, and to assure that\nboth the equations of motion and the way in which those equations of motion are\nderived are as self-consistent as possible. That is, solutions to the equations\nof motion of general relativity endow a three-space region with a physical and\ndistinguishing geometry in four-dimensional space-time. However, in order to\nderive these equations of motion one should first be able to choose a\nthree-space region without having any prior knowledge of its physically\nappropriate geometry. The expression of this choice process requires a\nthree-dimensional topological manifold Q, to which all considered three-space\nregions belong, and that generates an equation of motion whose solutions are q.\nThese solutions relate the effects of curvature to the source term through the\ntopology of Q and constitute Einstein gravity. Q is given by 2T^3+3S^1xS^2, and\nis embedded in four dimensions. This points toward a hidden topological content\nfor general relativity, best phrased as: Q and q provide a structure for how to\nchoose a three-space region irrespective of what geometric properties it has,\nwhile at the same time Q and q determine that only GR can endow a three-space\nwith those geometric properties. In this sense, avoiding the Axiom of Choice\nallows one to gain physical insight into GR. Possible links with holography are\npointed out.\n\n", "human_text": "  A derivation of the equations of motion of general relativity is presented\nthat does not invoke the Axiom of Choice, but requires the explicit\nconstruction of a choice function q for continuous three-space regions. The\nmotivation for this (seemingly academic) endeavour is to take the background\nindependence intrinsic to Einstein gravity one step further, and to assure that\nboth the equations of motion and the way in which those equations of motion are\nderived are as self-consistent as possible. That is, solutions to the equations\nof motion of general relativity endow a three-space region with a physical and\ndistinguishing geometry in four-dimensional space-time. However, in order to\nderive these equations of motion one should first be able to choose a\nthree-space region without having any prior knowledge of its physically\nappropriate geometry. The expression of this choice process requires a\nthree-dimensional topological manifold Q, to which all considered three-space\nregions belong, and that generates an equation of motion whose solutions are q.\nThese solutions relate the effects of curvature to the source term through the\ntopology of Q and constitute Einstein gravity. Q is given by 2T^3+3S^1xS^2, and\nis embedded in four dimensions. This points toward a hidden topological content\nfor general relativity, best phrased as: Q and q provide a structure for how to\nchoose a three-space region irrespective of what geometric properties it has,\nwhile at the same time Q and q determine that only GR can endow a three-space\nwith those geometric properties. In this sense, avoiding the Axiom of Choice\nallows one to gain physical insight into GR. Possible links with holography are\npointed out.\n", "machine_text": "\nThis paper examines the implications of avoiding the Axiom of Choice for deriving the equations of motion for Einstein gravity. A topological manifold Q is provided, which contains all considered three-space regions and produces an equation of motion whose solutions are related to curvature and the source term through the topology of Q. This implies that GR is determined by this topological structure and is self-consistent in the sense that solutions to the equation of motion give a three-space region its physical, distinguishing geometry in four-dimensional spacetime. In addition, Q and q provide a structure for how to choose a three-space region without regard to any prior knowledge of its geometry. This presents us with the possibility of gaining further physical insight into GR, as well as exploring possible connections between this and holography.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3902}
{"prompt": "Rephrase the abstract of an article with title 'Bulk viscosity in a cold CFL superfluid'.\n  We compute one of the bulk viscosity coefficients of cold CFL quark matter in\nthe temperature regime where the contribution of mesons, quarks and gluons to\ntransport phenomena is Boltzmann suppressed. In that regime dissipation occurs\ndue to collisions of superfluid phonons, the Goldstone modes associated to the\nspontaneous breaking of baryon symmetry. We first review the hydrodynamics of\nrelativistic superfluids, and remind that there are at least three bulk\nviscosity coefficients in these systems. We then compute the bulk viscosity\ncoefficient associated to the normal fluid component of the superfluid. In our\nanalysis we use Son's effective field theory for the superfluid phonon, amended\nto include scale breaking effects proportional to the square of the strange\nquark mass m_s. We compute the bulk viscosity at leading order in the scale\nbreaking parameter, and find that it is dominated by collinear splitting and\njoining processes. The resulting transport coefficient is zeta=0.011 m_s^4/T,\ngrowing at low temperature T until the phonon fluid description stops making\nsense. Our results are relevant to study the rotational properties of a compact\nstar formed by CFL quark matter.\n\n", "human_text": "  We compute one of the bulk viscosity coefficients of cold CFL quark matter in\nthe temperature regime where the contribution of mesons, quarks and gluons to\ntransport phenomena is Boltzmann suppressed. In that regime dissipation occurs\ndue to collisions of superfluid phonons, the Goldstone modes associated to the\nspontaneous breaking of baryon symmetry. We first review the hydrodynamics of\nrelativistic superfluids, and remind that there are at least three bulk\nviscosity coefficients in these systems. We then compute the bulk viscosity\ncoefficient associated to the normal fluid component of the superfluid. In our\nanalysis we use Son's effective field theory for the superfluid phonon, amended\nto include scale breaking effects proportional to the square of the strange\nquark mass m_s. We compute the bulk viscosity at leading order in the scale\nbreaking parameter, and find that it is dominated by collinear splitting and\njoining processes. The resulting transport coefficient is zeta=0.011 m_s^4/T,\ngrowing at low temperature T until the phonon fluid description stops making\nsense. Our results are relevant to study the rotational properties of a compact\nstar formed by CFL quark matter.\n", "machine_text": "\nIn this article, we investigate one of the bulk viscosity coefficients of a cold CFL quark matter in the temperature regime where the contributions of mesons, quarks, and gluons to transport phenomena are Boltzmann suppressed. In this temperature regime, dissipation is the result of the collision between superfluid phonons, which are the Goldstone modes associated with the spontaneous breaking of baryon symmetry. This paper provides a review of the hydrodynamics of relativistic superfluids and explains that there are at least three bulk viscosity coefficients in these systems. We then analyze the bulk viscosity coefficient from the normal fluid component of the superfluid by utilizing Son's effective field theory. This theory is amended to account for scaling effects that are proportional to the square of the strange quark mass, m_s. We find that the bulk viscosity coefficient is 0.011 m_s^4/T and it increases at lower temperatures until the phonon fluid description stops working. This study is applicable for understanding the rotational properties of a dense star that is formed from CFL quark matter.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3909}
{"prompt": "Rephrase the abstract of an article with title 'Prewavelet Solution to Poisson Equations'.\n  Finite element method is one of powerful numerical methods to solve PDE.\nUsually, if a finite element solution to a Poisson equation based on a\ntriangulation of the underlying domain is not accurate enough, one will discard\nthe solution and then refine the triangulation uniformly and compute a new\nfinite element solution over the refined triangulation. It is wasteful to\ndiscard the original finite element solution. We propose a prewavelet method to\nsave the original solution by adding a prewavelet subsolution to obtain the\nrefined level finite element solution. To increase the accuracy of numerical\nsolution to Poisson equations, we can keep adding prewavelet subsolutions.\n  Our prewavelets are orthogonal in the $H^1$ norm and they are compactly\nsupported except for one globally supported basis function in a rectangular\ndomain. We have implemented these prewavelet basis functions in MATLAB and used\nthem for numerical solution of Poisson equation with Dirichlet boundary\nconditions. Numerical simulation demonstrates that our prewavelet solution is\nmuch more efficient than the standard finite element method.\n\n", "human_text": "  Finite element method is one of powerful numerical methods to solve PDE.\nUsually, if a finite element solution to a Poisson equation based on a\ntriangulation of the underlying domain is not accurate enough, one will discard\nthe solution and then refine the triangulation uniformly and compute a new\nfinite element solution over the refined triangulation. It is wasteful to\ndiscard the original finite element solution. We propose a prewavelet method to\nsave the original solution by adding a prewavelet subsolution to obtain the\nrefined level finite element solution. To increase the accuracy of numerical\nsolution to Poisson equations, we can keep adding prewavelet subsolutions.\n  Our prewavelets are orthogonal in the $H^1$ norm and they are compactly\nsupported except for one globally supported basis function in a rectangular\ndomain. We have implemented these prewavelet basis functions in MATLAB and used\nthem for numerical solution of Poisson equation with Dirichlet boundary\nconditions. Numerical simulation demonstrates that our prewavelet solution is\nmuch more efficient than the standard finite element method.\n", "machine_text": "The present paper introduces a prewavelet solution for the numerical solution of Poisson equations, with the aim of improving accuracy. This method employs orthogonal prewavelets which are compactly supported with the exception of one globally supported basis function in a rectangular domain. The prewavelet method was implemented in MATLAB and used to obtain solutions to Poisson equation with Dirichlet boundary conditions, leading to improved efficiency when compared to the standard finite element method. Results from numerical simulation studies confirm the effectiveness of the proposed prewavelet solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2094}
{"prompt": "Rephrase the abstract of an article with title 'Optimizing Scrip Systems: Efficiency, Crashes, Hoarders, and Altruists'.\n  We discuss the design of efficient scrip systems and develop tools for\nempirically analyzing them. For those interested in the empirical study of\nscrip systems, we demonstrate how characteristics of agents in a system can be\ninferred from the equilibrium distribution of money. From the perspective of a\nsystem designer, we examine the effect of the money supply on social welfare\nand show that social welfare is maximized by increasing the money supply up to\nthe point that the system experiences a ``monetary crash,'' where money is\nsufficiently devalued that no agent is willing to perform a service. We also\nexamine the implications of the presence of altruists and hoarders on the\nperformance of the system. While a small number of altruists may improve social\nwelfare, too many can also cause the system to experience a monetary crash,\nwhich may be bad for social welfare. Hoarders generally decrease social welfare\nbut, surprisingly, they also promote system stability by helping prevent\nmonetary crashes. In addition, we provide new technical tools for analyzing and\ncomputing equilibria by showing that our model exhibits strategic\ncomplementarities, which implies that there exist equilibria in pure strategies\nthat can be computed efficiently.\n\n", "human_text": "  We discuss the design of efficient scrip systems and develop tools for\nempirically analyzing them. For those interested in the empirical study of\nscrip systems, we demonstrate how characteristics of agents in a system can be\ninferred from the equilibrium distribution of money. From the perspective of a\nsystem designer, we examine the effect of the money supply on social welfare\nand show that social welfare is maximized by increasing the money supply up to\nthe point that the system experiences a ``monetary crash,'' where money is\nsufficiently devalued that no agent is willing to perform a service. We also\nexamine the implications of the presence of altruists and hoarders on the\nperformance of the system. While a small number of altruists may improve social\nwelfare, too many can also cause the system to experience a monetary crash,\nwhich may be bad for social welfare. Hoarders generally decrease social welfare\nbut, surprisingly, they also promote system stability by helping prevent\nmonetary crashes. In addition, we provide new technical tools for analyzing and\ncomputing equilibria by showing that our model exhibits strategic\ncomplementarities, which implies that there exist equilibria in pure strategies\nthat can be computed efficiently.\n", "machine_text": "\nBy using various tools to analyze the dynamics of scrip systems, this paper contributes insights regarding the optimization of such systems. We show that increasing the money supply until it causes a monetary crash yields the highest possible social welfare. We also investigate the effects of altruism and hoarding on the effectiveness of the system, and reveal that too much altruism can lead to a crash, but that hoarders surprisingly stabilise the system and help avoid one. Furthermore, we describe how strategic complementarities in the system can be used to efficiently compute equilibria which would be hard or impossible to compute otherwise.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.411}
{"prompt": "Rephrase the abstract of an article with title 'The Magnetar Nature and the Outburst Mechanism of a Transient Anomalous\n  X-ray Pulsar'.\n  Anomalous X-ray Pulsars (AXPs) belong to a class of neutron stars believed to\nharbor the strongest magnetic fields in the universe, as indicated by their\nenergetic bursts and their rapid spindowns. However, an unambiguous measurement\nof their surface field strengths has not been made to date. It is also not\nknown whether AXP outbursts result from changes in the neutron star magnetic\nfield or crust properties. Here we report a spectroscopic measurement of the\nsurface magnetic field strength of an AXP, XTE J1810$-$197, and solidify its\nmagnetar nature. The field strength obtained from detailed spectral analysis\nand modeling, B = (2.72$\\pm$0.03)$\\times10^{14}$ G, is remarkably close to the\nvalue inferred from the rate of spindown of this source and remains nearly\nconstant during numerous observations spanning over an order of magnitude in\nsource flux. The surface temperature, on the other hand, declines steadily and\ndramatically following the 2003 outburst of this source. Our findings\ndemonstrate that heating occurs in the upper neutron star crust during an\noutburst and sheds light on the transient behaviour of AXPs.\n\n", "human_text": "  Anomalous X-ray Pulsars (AXPs) belong to a class of neutron stars believed to\nharbor the strongest magnetic fields in the universe, as indicated by their\nenergetic bursts and their rapid spindowns. However, an unambiguous measurement\nof their surface field strengths has not been made to date. It is also not\nknown whether AXP outbursts result from changes in the neutron star magnetic\nfield or crust properties. Here we report a spectroscopic measurement of the\nsurface magnetic field strength of an AXP, XTE J1810$-$197, and solidify its\nmagnetar nature. The field strength obtained from detailed spectral analysis\nand modeling, B = (2.72$\\pm$0.03)$\\times10^{14}$ G, is remarkably close to the\nvalue inferred from the rate of spindown of this source and remains nearly\nconstant during numerous observations spanning over an order of magnitude in\nsource flux. The surface temperature, on the other hand, declines steadily and\ndramatically following the 2003 outburst of this source. Our findings\ndemonstrate that heating occurs in the upper neutron star crust during an\noutburst and sheds light on the transient behaviour of AXPs.\n", "machine_text": "\nThe unique properties of Anomalous X-ray Pulsars (AXPs) have led to the belief that they sustain some of the strongest magnetic fields in the cosmos. To date, an accurate reading of the surface field intensities has been elusive. Similarly, it has not been clear whether these objects experience outbursts due to their fields or the properties of the neutron star's crust. In this article, a precise surface magnetic field strength is measured for AXP XTE J1810$-$197, confirming its magnetar nature. Analysis and modeling of the source yielded a value of B = (2.72$\\pm$0.03)$\\times10^{14}$ G, remarkably close to that predicted by the rate of spindown from numerous observations over varying flux intensities. Notably, the surface temperature of this AXP steadily decreased after a 2003 outburst. Our findings provide evidence of energy footprints from the AXP's magnet and illustrate the transient behavior of this class of neutron stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3713}
{"prompt": "Rephrase the abstract of an article with title 'Dalitz plot analysis of the D+ to K-pi+pi+ decay in the FOCUS experiment'.\n  Using data collected by the high energy photoproduction experiment FOCUS at\nFermilab we performed a Dalitz plot analysis of the Cabibbo favored decay D+ to\nK-pi+ pi+. This study uses 53653 Dalitz-plot events with a signal fraction of ~\n97%, and represents the highest statistics, most complete Dalitz plot analysis\nfor this channel. Results are presented and discussed using two different\nformalisms. The first is a simple sum of Breit--Wigner functions with freely\nfitted masses and widths. It is the model traditionally adopted and serves as\ncomparison with the already published analyses. The second uses a K-matrix\napproach for the dominant S-wave, in which the parameters are fixed by first\nfitting Kpi scattering data and continued to threshold by Chiral Perturbation\nTheory. We show that the Dalitz plot distribution for this decay is consistent\nwith the assumption of two body dominance of the final state interactions and\nthe description of these interactions is in agreement with other data on the\nKpi final state.\n\n", "human_text": "  Using data collected by the high energy photoproduction experiment FOCUS at\nFermilab we performed a Dalitz plot analysis of the Cabibbo favored decay D+ to\nK-pi+ pi+. This study uses 53653 Dalitz-plot events with a signal fraction of ~\n97%, and represents the highest statistics, most complete Dalitz plot analysis\nfor this channel. Results are presented and discussed using two different\nformalisms. The first is a simple sum of Breit--Wigner functions with freely\nfitted masses and widths. It is the model traditionally adopted and serves as\ncomparison with the already published analyses. The second uses a K-matrix\napproach for the dominant S-wave, in which the parameters are fixed by first\nfitting Kpi scattering data and continued to threshold by Chiral Perturbation\nTheory. We show that the Dalitz plot distribution for this decay is consistent\nwith the assumption of two body dominance of the final state interactions and\nthe description of these interactions is in agreement with other data on the\nKpi final state.\n", "machine_text": "\nUsing the data collected by the FOCUS high energy photoproduction experiment at Fermilab, we have conducted a Dalitz plot analysis of the Cabibbo favored decay D+ to K-pi+ pi+. This analysis counts 53653 Dalitz-plot events with a ~97% signal fraction, and is the most complete and highest statistics Dalitz plot analysis conducted thus far for this channel. The results are described using two different formalisms; the first utilizes Breit--Wigner functions for each component and freely fitted mass and widths, which is the method customarily utilized, and serves as a benchmark for comparisons with other published analyses. The second is formulated with a K-matrix approach for the dominant S-wave component, where parameters are determined first by fitting Kpi scattering data and then traced to threshold using Chiral Perturbation Theory. Our results are in agreement with the hypothesis that the final state interactions are dominated by two body processes, and are consistent with the description of these interactions based on other Kpi data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2248}
{"prompt": "Rephrase the abstract of an article with title 'Magnetic Evolution and Temperature Variation in a Coronal Hole'.\n  We have explored the magnetic flux evolution and temperature variation in a\ncoronal-hole region, using Big Bear Solar Observatory (BBSO) deep magnetograms\nand {\\it SOHO}/EIT images observed from 2005 October 10 to 14. For comparison,\nwe also investigated a neighboring quiet region of the Sun. The coronal hole\nevolved from its mature stage to its disappearance during the observing period.\nWe have obtained the following results: (1) When the coronal hole was well\ndeveloped on October 10, about 60 % of the magnetic flux was positive. The EUV\nbrightness was 420 counts pixel$^{-1}$, and the coronal temperature, estimated\nfrom the line ratio of the EIT 195 {\\AA} and 171 {\\AA} images, was 1.07 MK. (2)\nOn October 14, when the coronal hole had almost disappeared, 51 % of the\nmagnetic flux was positive, the EUV radiance was 530 counts pixel$^{-1}$, and\nthe temperature was 1.10 MK. (3) In the neighboring quiet region, the fraction\nof positive flux varied between 0.49 and 0.47. The EUV brightness displayed an\nirregular variation, with a mean value of 870 counts pixel$^{-1}$. The\ntemperature was almost constant at 1.11 MK during the five-day observation. Our\nresults demonstrate that in a coronal hole less imbalance of the magnetic flux\nin opposite polarities leads to stronger EUV brightness and higher coronal\ntemperatures.\n\n", "human_text": "  We have explored the magnetic flux evolution and temperature variation in a\ncoronal-hole region, using Big Bear Solar Observatory (BBSO) deep magnetograms\nand {\\it SOHO}/EIT images observed from 2005 October 10 to 14. For comparison,\nwe also investigated a neighboring quiet region of the Sun. The coronal hole\nevolved from its mature stage to its disappearance during the observing period.\nWe have obtained the following results: (1) When the coronal hole was well\ndeveloped on October 10, about 60 % of the magnetic flux was positive. The EUV\nbrightness was 420 counts pixel$^{-1}$, and the coronal temperature, estimated\nfrom the line ratio of the EIT 195 {\\AA} and 171 {\\AA} images, was 1.07 MK. (2)\nOn October 14, when the coronal hole had almost disappeared, 51 % of the\nmagnetic flux was positive, the EUV radiance was 530 counts pixel$^{-1}$, and\nthe temperature was 1.10 MK. (3) In the neighboring quiet region, the fraction\nof positive flux varied between 0.49 and 0.47. The EUV brightness displayed an\nirregular variation, with a mean value of 870 counts pixel$^{-1}$. The\ntemperature was almost constant at 1.11 MK during the five-day observation. Our\nresults demonstrate that in a coronal hole less imbalance of the magnetic flux\nin opposite polarities leads to stronger EUV brightness and higher coronal\ntemperatures.\n", "machine_text": "\nWe explored the magnetic flux and temperature changes in a particular coronal hole between the period of October 10th to 14th in 2005 by using the Big Bear Solar Observatory deep magnetogram and the SOHO/EIT images. We compare the results to the findings in the neighboring quiet region of the sun over the same period. We found that when the coronal hole was strong on October 10th, the positive flux comprised of around 60%, while the EUV brightness was 420 counts pixel$^{-1}$ and the coronal temperature was 1.07 MK. On October 14th, when the coronal hole had nearly faded away, 51% of the positive flux remained, with EUV brightness and temperature rising to 530 counts pixel$^{-1}$ and 1.10 MK respectively. Meanwhile, in the quiet region the fraction of positive flux shifted between 0.49 and 0.47, with EUV brightness meanly at 870 counts pixel$^{-1}$ and temperature almost stable at 1.11 MK. From the results, it appears that a lower imbalance between the flux of opposite polarities within a coronal hole leads to stronger EUV brightness and higher coronal temperature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0598}
{"prompt": "Rephrase the abstract of an article with title 'The Cut-off Covering Spectrum'.\n  We introduce the $R$ cut-off covering spectrum and the cut-off covering\nspectrum of a complete length space or Riemannian manifold. The spectra measure\nthe sizes of localized holes in the space and are defined using covering spaces\ncalled $\\delta$ covers and $R$ cut-off $\\delta$ covers. They are investigated\nusing $\\delta$ homotopies which are homotopies via grids whose squares are\nmapped into balls of radius $\\delta$.\n  On locally compact spaces, we prove that these new spectra are subsets of the\nclosure of the length spectrum. We prove the $R$ cut-off covering spectrum is\nalmost continuous with respect to the pointed Gromov-Hausdorff convergence of\nspaces and that the cut-off covering spectrum is also relatively well behaved.\nThis is not true of the covering spectrum defined in our earlier work which was\nshown to be well behaved on compact spaces. We close by analyzing these spectra\non Riemannian manifolds with lower bounds on their sectional and Ricci\ncurvature and their limit spaces.\n\n", "human_text": "  We introduce the $R$ cut-off covering spectrum and the cut-off covering\nspectrum of a complete length space or Riemannian manifold. The spectra measure\nthe sizes of localized holes in the space and are defined using covering spaces\ncalled $\\delta$ covers and $R$ cut-off $\\delta$ covers. They are investigated\nusing $\\delta$ homotopies which are homotopies via grids whose squares are\nmapped into balls of radius $\\delta$.\n  On locally compact spaces, we prove that these new spectra are subsets of the\nclosure of the length spectrum. We prove the $R$ cut-off covering spectrum is\nalmost continuous with respect to the pointed Gromov-Hausdorff convergence of\nspaces and that the cut-off covering spectrum is also relatively well behaved.\nThis is not true of the covering spectrum defined in our earlier work which was\nshown to be well behaved on compact spaces. We close by analyzing these spectra\non Riemannian manifolds with lower bounds on their sectional and Ricci\ncurvature and their limit spaces.\n", "machine_text": "\nThis work studies the $R$ cut-off covering spectrum and the cut-off covering spectrum of complete length spaces and Riemannian manifolds. These spectra measure the sizes of localized holes in the space and are defined by utilizing $\\delta$ covers, $R$ cut-off $\\delta$ covers, and $\\delta$ homotopies where the squares of the homotopies are mapped into a ball of radius $\\delta$. Taking local compactness into consideration, we show that these new spectra are subsets of the closure of the length spectrum. The results also demonstrate that the pointed Gromov-Hausdorff convergence of spaces reveals the $R$ cut-off covering spectrum to be almost continuous, with the cut-off covering spectrum showing to possess a relatively well behaved property in contrast to the covering spectrum established in our earlier work. To end with, the spectra are analyzed on Riemannian manifolds with lower bounds on their sectional and Ricci curvature, and their corresponding limit spaces.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3822}
{"prompt": "Rephrase the abstract of an article with title 'What it takes to measure a fundamental difference between dark matter\n  and baryons: the halo velocity anisotropy'.\n  Numerous ongoing experiments aim at detecting WIMP dark matter particles from\nthe galactic halo directly through WIMP-nucleon interactions. Once such a\ndetection is established a confirmation of the galactic origin of the signal is\nneeded. This requires a direction-sensitive detector. We show that such a\ndetector can measure the velocity anisotropy beta of the galactic halo.\nCosmological N-body simulations predict the dark matter anisotropy to be\nnonzero, beta~0.2. Baryonic matter has beta=0 and therefore a detection of a\nnonzero beta would be strong proof of the fundamental difference between dark\nand baryonic matter. We estimate the sensitivity for various detector\nconfigurations using Monte Carlo methods and we show that the strongest signal\nis found in the relatively few high recoil energy events. Measuring beta to the\nprecision of ~0.03 will require detecting more than 10^4 WIMP events with\nnuclear recoil energies greater than 100 keV for a WIMP mass of 100 GeV and a\n32S target. This number corresponds to ~10^6 events at all energies. We discuss\nvariations with respect to input parameters and we show that our method is\nrobust to the presence of backgrounds and discuss the possible improved\nsensitivity for an energy-sensitive detector.\n\n", "human_text": "  Numerous ongoing experiments aim at detecting WIMP dark matter particles from\nthe galactic halo directly through WIMP-nucleon interactions. Once such a\ndetection is established a confirmation of the galactic origin of the signal is\nneeded. This requires a direction-sensitive detector. We show that such a\ndetector can measure the velocity anisotropy beta of the galactic halo.\nCosmological N-body simulations predict the dark matter anisotropy to be\nnonzero, beta~0.2. Baryonic matter has beta=0 and therefore a detection of a\nnonzero beta would be strong proof of the fundamental difference between dark\nand baryonic matter. We estimate the sensitivity for various detector\nconfigurations using Monte Carlo methods and we show that the strongest signal\nis found in the relatively few high recoil energy events. Measuring beta to the\nprecision of ~0.03 will require detecting more than 10^4 WIMP events with\nnuclear recoil energies greater than 100 keV for a WIMP mass of 100 GeV and a\n32S target. This number corresponds to ~10^6 events at all energies. We discuss\nvariations with respect to input parameters and we show that our method is\nrobust to the presence of backgrounds and discuss the possible improved\nsensitivity for an energy-sensitive detector.\n", "machine_text": "\nResearchers are eager to confirm direct WIMP dark matter particle detections from the galactic halo as scientific proof of their existence, and a step towards this is the use of a direction-sensitive detector. This experiment can measure the velocity anisotropy of the halo, denoted as 'beta', which, according to cosmological N-body simulations, is nonzero for dark matter, but zero for baryonic matter. Through Monte Carlo analysis, it has been concluded that detecting more than 10^4 WIMP events with nuclear recoil energies of 100 keV or more in a 32S target, leading to a precision of around 0.03, can increase the chances of improving the sensitivity greatly. Backgrounds and other potential factors have been considered during the study, and the findings have shown that a direction-sensitive detector is a resilient way of distinguishing between dark matter and baryonic matter.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2909}
{"prompt": "Rephrase the abstract of an article with title 'Generalized Twistor Transform And Dualities, With A New Description of\n  Particles With Spin, Beyond Free and Massless'.\n  A generalized twistor transform for spinning particles in 3+1 dimensions is\nconstructed that beautifully unifies many types of spinning systems by mapping\nthem to the same twistor, thus predicting an infinite set of duality relations\namong spinning systems with different Hamiltonians. Usual 1T-physics is not\nequipped to explain the duality relationships and unification between these\nsystems. We use 2T-physics in 4+2 dimensions to uncover new properties of\ntwistors, and expect that our approach will prove to be useful for practical\napplications as well as for a deeper understanding of fundamental physics.\nUnexpected structures for a new description of spinning particles emerge. A\nunifying symmetry SU(2,3) that includes conformal symmetry SU(2,2)=SO(4,2) in\nthe massless case, turns out to be a fundamental property underlying the\ndualities of a large set of spinning systems, including those that occur in\nhigh spin theories. This may lead to new forms of string theory backgrounds as\nwell as to new methods for studying various corners of M theory. In this paper\nwe present the main concepts, and in a companion paper we give other details.\n\n", "human_text": "  A generalized twistor transform for spinning particles in 3+1 dimensions is\nconstructed that beautifully unifies many types of spinning systems by mapping\nthem to the same twistor, thus predicting an infinite set of duality relations\namong spinning systems with different Hamiltonians. Usual 1T-physics is not\nequipped to explain the duality relationships and unification between these\nsystems. We use 2T-physics in 4+2 dimensions to uncover new properties of\ntwistors, and expect that our approach will prove to be useful for practical\napplications as well as for a deeper understanding of fundamental physics.\nUnexpected structures for a new description of spinning particles emerge. A\nunifying symmetry SU(2,3) that includes conformal symmetry SU(2,2)=SO(4,2) in\nthe massless case, turns out to be a fundamental property underlying the\ndualities of a large set of spinning systems, including those that occur in\nhigh spin theories. This may lead to new forms of string theory backgrounds as\nwell as to new methods for studying various corners of M theory. In this paper\nwe present the main concepts, and in a companion paper we give other details.\n", "machine_text": "\nThis paper outlines a generalized twistor transform for spinning particles in 3+1 dimensions that can describe and predict infinite duality relationships among spinning systems with different Hamiltonians beyond the known free and massless cases. Using 2T-physics in 4+2 dimensions new properties of twistors are uncovered to construct a unified description of spinning particles. The fundamental underlying symmetry of SU(2,3), which includes conformal symmetry SU(2,2)=SO(4,2) in the massless case, is presented and may have potential implications in new forms of string theory background, as well as pave a new path to studying several aspects of M theory. Further details are provided in the companion paper.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0296}
{"prompt": "Rephrase the abstract of an article with title 'Multiple Parton Scattering in Nuclei: Quark-quark Scattering'.\n  Modifications to quark and antiquark fragmentation functions due to\nquark-quark (antiquark) double scattering in nuclear medium are studied\nsystematically up to order \\cal{O}(\\alpha_{s}^2)$ in deeply inelastic\nscattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$,\ntwist-four contributions from quark-quark (antiquark) rescattering also exhibit\nthe Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon\nbremsstrahlung induced by multiple parton scattering. Compared to quark-gluon\nscattering, the modification, which is dominated by $t$-channel quark-quark\n(antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the\nratio of quark and gluon distributions in the medium. Such a modification is\nnot negligible for realistic kinematics and finite medium size. The\nmodifications to quark (antiquark) fragmentation functions from quark-antiquark\nannihilation processes are shown to be determined by the antiquark (quark)\ndistribution density in the medium. The asymmetry in quark and antiquark\ndistributions in nuclei will lead to different modifications of quark and\nantiquark fragmentation functions inside a nucleus, which qualitatively\nexplains the experimentally observed flavor dependence of the leading hadron\nsuppression in semi-inclusive DIS off nuclear targets. The quark-antiquark\nannihilation processes also mix quark and gluon fragmentation functions in the\nlarge fractional momentum region, leading to a flavor dependence of jet\nquenching in heavy-ion collisions.\n\n", "human_text": "  Modifications to quark and antiquark fragmentation functions due to\nquark-quark (antiquark) double scattering in nuclear medium are studied\nsystematically up to order \\cal{O}(\\alpha_{s}^2)$ in deeply inelastic\nscattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$,\ntwist-four contributions from quark-quark (antiquark) rescattering also exhibit\nthe Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon\nbremsstrahlung induced by multiple parton scattering. Compared to quark-gluon\nscattering, the modification, which is dominated by $t$-channel quark-quark\n(antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the\nratio of quark and gluon distributions in the medium. Such a modification is\nnot negligible for realistic kinematics and finite medium size. The\nmodifications to quark (antiquark) fragmentation functions from quark-antiquark\nannihilation processes are shown to be determined by the antiquark (quark)\ndistribution density in the medium. The asymmetry in quark and antiquark\ndistributions in nuclei will lead to different modifications of quark and\nantiquark fragmentation functions inside a nucleus, which qualitatively\nexplains the experimentally observed flavor dependence of the leading hadron\nsuppression in semi-inclusive DIS off nuclear targets. The quark-antiquark\nannihilation processes also mix quark and gluon fragmentation functions in the\nlarge fractional momentum region, leading to a flavor dependence of jet\nquenching in heavy-ion collisions.\n", "machine_text": "This paper studies how quark-quark and antiquark-antiquark double scattering in an nuclear medium affect quark and antiquark fragmentation functions, a process commonly referred to as multiple parton scattering. Results show that this modification is orders of magnitude smaller than those from quark-gluon scattering due to the factor of $C_F/C_A=4/9$. This modification is not insignificant for realistic kinematics and is seen to be dependent on the quark or antiquark distributions in the medium. It is further seen to cause an asymmetry between quark and antiquark fragmentation functions, leading to a flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. Additionally, quark-antiquark annihilation results in a mixing of quark and gluon fragmentation functions in the large fractional momentum region of heavy-ion collisions, causing a flavor dependence of jet quenching.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0106}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological Shock Waves in the Large Scale Structure of the Universe:\n  Non-gravitational Effects'.\n  Cosmological shock waves result from supersonic flow motions induced by\nhierarchical clustering of nonlinear structures in the universe. These shocks\ngovern the nature of cosmic plasma through thermalization of gas and\nacceleration of nonthermal, cosmic-ray (CR) particles. We study the statistics\nand energetics of shocks formed in cosmological simulations of a concordance\n$\\Lambda$CDM universe, with a special emphasis on the effects of\nnon-gravitational processes such as radiative cooling, photoionization/heating,\nand galactic superwind feedbacks. Adopting an improved model for gas\nthermalization and CR acceleration efficiencies based on nonlinear diffusive\nshock acceleration calculations, we then estimate the gas thermal energy and\nthe CR energy dissipated at shocks through the history of the universe. Since\nshocks can serve as sites for generation of vorticity, we also examine the\nvorticity that should have been generated mostly at curved shocks in\ncosmological simulations. We find that the dynamics and energetics of shocks\nare governed primarily by the gravity of matter, so other non-gravitational\nprocesses do not affect significantly the global energy dissipation and\nvorticity generation at cosmological shocks. Our results reinforce scenarios in\nwhich the intracluster medium and warm-hot intergalactic medium contain\nenergetically significant populations of nonthermal particles and turbulent\nflow motions.\n\n", "human_text": "  Cosmological shock waves result from supersonic flow motions induced by\nhierarchical clustering of nonlinear structures in the universe. These shocks\ngovern the nature of cosmic plasma through thermalization of gas and\nacceleration of nonthermal, cosmic-ray (CR) particles. We study the statistics\nand energetics of shocks formed in cosmological simulations of a concordance\n$\\Lambda$CDM universe, with a special emphasis on the effects of\nnon-gravitational processes such as radiative cooling, photoionization/heating,\nand galactic superwind feedbacks. Adopting an improved model for gas\nthermalization and CR acceleration efficiencies based on nonlinear diffusive\nshock acceleration calculations, we then estimate the gas thermal energy and\nthe CR energy dissipated at shocks through the history of the universe. Since\nshocks can serve as sites for generation of vorticity, we also examine the\nvorticity that should have been generated mostly at curved shocks in\ncosmological simulations. We find that the dynamics and energetics of shocks\nare governed primarily by the gravity of matter, so other non-gravitational\nprocesses do not affect significantly the global energy dissipation and\nvorticity generation at cosmological shocks. Our results reinforce scenarios in\nwhich the intracluster medium and warm-hot intergalactic medium contain\nenergetically significant populations of nonthermal particles and turbulent\nflow motions.\n", "machine_text": "\nWe investigate the impact of non-gravitational phenomena on cosmological shock waves produced by supersonic structures in a $\\Lambda$CDM concordance universe. Our model takes into account cooling and photoionization of gases, as well as superwind feedbacks, to calculate thermalisation and cosmic-ray acceleration efficiencies. We then evaluate the gas thermal energy dissipation and cosmic-ray energy dissipated at these shocks over the evolution of the universe. We also analyse the vorticity created at curved shocks in cosmological simulations, and find that gravitational forces are the primary influence on the energetics and dynamics of these shocks, and non-gravitational forces make a minor difference. This suggests that intracluster and intergalactic media may contain non-thermal particles, turbulence and vorticity generated mostly from shock waves.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1521}
{"prompt": "Rephrase the abstract of an article with title 'Selection Against Demographic Stochasticity in Age-Structured\n  Populations'.\n  It has been shown that differences in fecundity variance can influence the\nprobability of invasion of a genotype in a population, i.e. a genotype with\nlower variance in offspring number can be favored in finite populations even if\nit has a somewhat lower mean fitness than a competitor. In this paper,\nGillespie's results are extended to population genetic systems with explicit\nage structure, where the demographic variance (variance in growth rate)\ncalculated in the work of Engen and colleagues is used as a generalization of\n\"variance in offspring number\" to predict the interaction between deterministic\nand random forces driving change in allele frequency. By calculating the\nvariance from the life history parameters, it is shown that selection against\nvariance in the growth rate will favor a genotypes with lower stochasticity in\nage specific survival and fertility rates. A diffusion approximation for\nselection and drift in a population with two genotypes with different life\nhistory matrices (and therefore, different growth rates and demographic\nvariances) is derived and shown to be consistent with individual based\nsimulations. It is also argued that for finite populations, perturbation\nanalyses of both the growth rate and demographic variances may be necessary to\ndetermine the sensitivity of \"fitness\" (broadly defined) to changes in the life\nhistory parameters.\n\n", "human_text": "  It has been shown that differences in fecundity variance can influence the\nprobability of invasion of a genotype in a population, i.e. a genotype with\nlower variance in offspring number can be favored in finite populations even if\nit has a somewhat lower mean fitness than a competitor. In this paper,\nGillespie's results are extended to population genetic systems with explicit\nage structure, where the demographic variance (variance in growth rate)\ncalculated in the work of Engen and colleagues is used as a generalization of\n\"variance in offspring number\" to predict the interaction between deterministic\nand random forces driving change in allele frequency. By calculating the\nvariance from the life history parameters, it is shown that selection against\nvariance in the growth rate will favor a genotypes with lower stochasticity in\nage specific survival and fertility rates. A diffusion approximation for\nselection and drift in a population with two genotypes with different life\nhistory matrices (and therefore, different growth rates and demographic\nvariances) is derived and shown to be consistent with individual based\nsimulations. It is also argued that for finite populations, perturbation\nanalyses of both the growth rate and demographic variances may be necessary to\ndetermine the sensitivity of \"fitness\" (broadly defined) to changes in the life\nhistory parameters.\n", "machine_text": "\nThis paper evaluates how differences in demographic variance, or variance in population growth rate, influence the likelihood of a given genotype to succeed in a population. Utilizing the research of Engen and other related studies, it proposes a generalization regarding the interactions between determinable and random forces that shape the prevalence of certain alleles. By examining variance in life history parameters, evidence is presented that demonstrates the increased preference for genotypes that display less stochasticity in age-specific survival and fertility. Moreover, diffusion approximations and individual based simulations are utilized to measure the influence of different life history parameters on an organism's overall fitness. Ultimately, perturbation analyses of the growth rate and demographic variance may be crucial for pinpointing the impact of life history parameters on fitness in finite populations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2607}
{"prompt": "Rephrase the abstract of an article with title 'What happened to the Cosmological QCD Phase Transition?'.\n  The scenario that some first-order phase transitions may have taken place in\nthe early Universe offers us one of the most intriguing and fascinating\nquestions in cosmology. Indeed, the role played by the latent \"heat\" or energy\nreleased in the phase transition is highly nontrivial and may lead to some\nsurprising, important results. In this paper, we take the wisdom that the\ncosmological QCD phase transition, which happened at a time between 10^(-5) sec\nand 10^(-4) sec or at the temperature of about 150 MeV and accounts for\nconfinement of quarks and gluons to within hadrons, would be of first order. To\nget the essence out of the scenario, it is sufficient to approximate the true\nQCD vacuum as one of degenerate theta-vacua and when necessary we try to model\nit effectively via a complex scalar field with spontaneous symmetry breaking.\nWe examine how and when \"pasted\" or \"patched\" domain walls are formed, how long\nsuch walls evolve in the long run, and we believe that the significant portion\nof dark matter could be accounted for in terms of such domain-wall structure\nand its remnants. Of course, the cosmological QCD phase transition happened in\nthe way such that the false vacua associated with baryons and many other\ncolor-singlet objects did not disappear (that is, using the bag-model language,\nthere are bags of radius 1.0 fermi for the baryons) - but the amount of the\nenergy remained in the false vacua is negligible. The latent energy released\ndue to the conversion of the false vacua to the true vacua, in the form of\n\"pasted\" or \"patched\" domain walls in the short run and their numerous evolved\nobjects, should make the concept of the \"radiation-dominated\" epoch, or of the\n\"matter-dominated\" epoch to be re-examined.\n\n", "human_text": "  The scenario that some first-order phase transitions may have taken place in\nthe early Universe offers us one of the most intriguing and fascinating\nquestions in cosmology. Indeed, the role played by the latent \"heat\" or energy\nreleased in the phase transition is highly nontrivial and may lead to some\nsurprising, important results. In this paper, we take the wisdom that the\ncosmological QCD phase transition, which happened at a time between 10^(-5) sec\nand 10^(-4) sec or at the temperature of about 150 MeV and accounts for\nconfinement of quarks and gluons to within hadrons, would be of first order. To\nget the essence out of the scenario, it is sufficient to approximate the true\nQCD vacuum as one of degenerate theta-vacua and when necessary we try to model\nit effectively via a complex scalar field with spontaneous symmetry breaking.\nWe examine how and when \"pasted\" or \"patched\" domain walls are formed, how long\nsuch walls evolve in the long run, and we believe that the significant portion\nof dark matter could be accounted for in terms of such domain-wall structure\nand its remnants. Of course, the cosmological QCD phase transition happened in\nthe way such that the false vacua associated with baryons and many other\ncolor-singlet objects did not disappear (that is, using the bag-model language,\nthere are bags of radius 1.0 fermi for the baryons) - but the amount of the\nenergy remained in the false vacua is negligible. The latent energy released\ndue to the conversion of the false vacua to the true vacua, in the form of\n\"pasted\" or \"patched\" domain walls in the short run and their numerous evolved\nobjects, should make the concept of the \"radiation-dominated\" epoch, or of the\n\"matter-dominated\" epoch to be re-examined.\n", "machine_text": "\nThis paper investigates the implications of the cosmological QCD phase transition that occurred between 10^(-5) seconds and 10^(-4) seconds, at a temperature of approximately 150 MeV, and led to the confinement of quarks and gluons within hadrons. The authors approximate the true QCD vacuum with degenerate theta-vacua and model its effects with a complex scalar field with spontaneous symmetry breaking. They examine the formation of \u201cpasted\u201d or \u201cpatched\u201d domain walls and the evolution of such walls in the long run. It is suggested that a significant portion of dark matter could be attributed to remnants of the domain walls. Additionally, the paper raises the question of whether false vacua associated with color-singlet objects could alter the evaluation of the \u201cradiation-dominated\u201d epoch or the \u201cmatter-dominated\u201d epoch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4149}
{"prompt": "Rephrase the abstract of an article with title 'Ageing memory and glassiness of a driven vortex system'.\n  Many systems in nature, glasses, interfaces and fractures being some\nexamples, cannot equilibrate with their environment, which gives rise to novel\nand surprising behaviour such as memory effects, ageing and nonlinear dynamics.\nUnlike their equilibrated counterparts, the dynamics of out-of- equilibrium\nsystems is generally too complex to be captured by simple macroscopic laws.\nHere we investigate a system that straddles the boundary between glass and\ncrystal: a Bragg glass formed by vortices in a superconductor. We find that the\nresponse to an applied force evolves according to a stretched exponential, with\nthe exponent reflecting the deviation from equilibrium. After the force is\nremoved, the system ages with time and its subsequent response time scales\nlinearly with its age (simple ageing), meaning that older systems are slower\nthan younger ones. We show that simple ageing can occur naturally in the\npresence of sufficient quenched disorder. Moreover, the hierarchical\ndistribution of timescales, arising when chunks of loose vortices cannot move\nbefore trapped ones become dislodged, leads to a stretched-exponential\nresponse.\n\n", "human_text": "  Many systems in nature, glasses, interfaces and fractures being some\nexamples, cannot equilibrate with their environment, which gives rise to novel\nand surprising behaviour such as memory effects, ageing and nonlinear dynamics.\nUnlike their equilibrated counterparts, the dynamics of out-of- equilibrium\nsystems is generally too complex to be captured by simple macroscopic laws.\nHere we investigate a system that straddles the boundary between glass and\ncrystal: a Bragg glass formed by vortices in a superconductor. We find that the\nresponse to an applied force evolves according to a stretched exponential, with\nthe exponent reflecting the deviation from equilibrium. After the force is\nremoved, the system ages with time and its subsequent response time scales\nlinearly with its age (simple ageing), meaning that older systems are slower\nthan younger ones. We show that simple ageing can occur naturally in the\npresence of sufficient quenched disorder. Moreover, the hierarchical\ndistribution of timescales, arising when chunks of loose vortices cannot move\nbefore trapped ones become dislodged, leads to a stretched-exponential\nresponse.\n", "machine_text": "\nThe non-equilibrium dynamics of many natural systems, such as glasses, interfaces, and fractures, often exhibit unique behaviour resulting from memory effects, ageing, and complex nonlinear dynamics. In this article, we focus on a curious system that lies between a glass and a crystal: a Bragg glass of vortices in a superconductor. We discover that when a force is applied to the system, the response obeys a stretched exponential law with an exponent that indicates the deviation from equilibrium. We also observe that, when the force is removed, the system ages with time and its response is subject to simple ageing, meaning that older systems respond more slowly than younger ones. We show that simple ageing is likely to occur when there is enough quenched disorder present. Furthermore, we demonstrate that the hierarchical arrangement of timescales caused by loose vortices unable to move before the trapped ones, leads to the stretched exponential response.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0779}
{"prompt": "Rephrase the abstract of an article with title 'How to find neutral leptons of the nuMSM?'.\n  An extension of the Standard Model by three singlet fermions with masses\nsmaller than the electroweak scale allows to explain simultaneously neutrino\noscillations, dark matter and baryon asymmetry of the Universe. We discuss the\nproperties of neutral leptons in this model and the ways they can be searched\nfor in particle physics experiments. We establish, in particular, a lower and\nan upper bound on the strength of interaction of neutral leptons coming from\ncosmological considerations and from the data on neutrino oscillations. We\nanalyse the production of neutral leptons in the decays of different mesons and\nin $pp$ collisions. We study in detail decays of neutral leptons and establish\na lower bound on their mass coming from existing experimental data and Big Bang\nNucleosynthesis. We argue that the search for a specific missing energy signal\nin kaon decays would allow to strengthen considerably the bounds on neutral\nfermion couplings and to find or definitely exclude them below the kaon\nthreshold. To enter into cosmologically interesting parameter range for masses\nabove kaon mass the dedicated searches similar to CERN PS191 experiment would\nbe needed with the use of intensive proton beams. We argue that the use of\nCNGS, NuMI, T2K or NuTeV beams could allow to search for singlet leptons below\ncharm in a large portion of the parameter space of the nuMSM. The search of\nsinglet fermions in the mass interval 2-5 GeV would require a considerable\nincrease of the intensity of proton accelerators or the detailed analysis of\nkinematics of more than 10^{10} B-meson decays.\n\n", "human_text": "  An extension of the Standard Model by three singlet fermions with masses\nsmaller than the electroweak scale allows to explain simultaneously neutrino\noscillations, dark matter and baryon asymmetry of the Universe. We discuss the\nproperties of neutral leptons in this model and the ways they can be searched\nfor in particle physics experiments. We establish, in particular, a lower and\nan upper bound on the strength of interaction of neutral leptons coming from\ncosmological considerations and from the data on neutrino oscillations. We\nanalyse the production of neutral leptons in the decays of different mesons and\nin $pp$ collisions. We study in detail decays of neutral leptons and establish\na lower bound on their mass coming from existing experimental data and Big Bang\nNucleosynthesis. We argue that the search for a specific missing energy signal\nin kaon decays would allow to strengthen considerably the bounds on neutral\nfermion couplings and to find or definitely exclude them below the kaon\nthreshold. To enter into cosmologically interesting parameter range for masses\nabove kaon mass the dedicated searches similar to CERN PS191 experiment would\nbe needed with the use of intensive proton beams. We argue that the use of\nCNGS, NuMI, T2K or NuTeV beams could allow to search for singlet leptons below\ncharm in a large portion of the parameter space of the nuMSM. The search of\nsinglet fermions in the mass interval 2-5 GeV would require a considerable\nincrease of the intensity of proton accelerators or the detailed analysis of\nkinematics of more than 10^{10} B-meson decays.\n", "machine_text": "This article explores the characteristics and potential methods for discovering neutral leptons in the extended Standard Model (nuMSM). We investigate the lower and upper bounds of interaction strength of neutral leptons based on cosmological evidence, as well as data on neutrino oscillations. We study the production of neutral leptons in decays of mesons and $pp$ collisions, and assess the lower bound of the mass of these leptons from Big Bang Nucleosynthesis and current experimental data. Additionally, we suggest a missing energy signal in kaon decays to help improve the strength of neutral lepton couplings in finding or rejecting them below the kaon threshold. To investigate the cosmologically important mass range above the kaon, dedicated searches with intensive proton beams need to be deployed, such as those conducted at CERN PS191. Proton beams from CNGS, NuMI, T2K, or NuTeV could be used to search for singlet leptons below the charm mass in the wide parameter space of the nuMSM. For a mass range of 2-5 GeV, a higher intensity of proton accelerators or a comprehensive analysis of more than 10 billion B-meson decays may be necessary.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1729}
{"prompt": "Rephrase the abstract of an article with title 'Mixed Hyperbolic - Second-Order Parabolic Formulations of General\n  Relativity'.\n  Two new formulations of general relativity are introduced. The first one is a\nparabolization of the Arnowitt, Deser, Misner (ADM) formulation and is derived\nby addition of combinations of the constraints and their derivatives to the\nright-hand-side of the ADM evolution equations. The desirable property of this\nmodification is that it turns the surface of constraints into a local attractor\nbecause the constraint propagation equations become second-order parabolic\nindependently of the gauge conditions employed. This system may be classified\nas mixed hyperbolic - second-order parabolic. The second formulation is a\nparabolization of the Kidder, Scheel, Teukolsky formulation and is a manifestly\nmixed strongly hyperbolic - second-order parabolic set of equations, bearing\nthus resemblance to the compressible Navier-Stokes equations. As a first test,\na stability analysis of flat space is carried out and it is shown that the\nfirst modification exponentially damps and smoothes all constraint violating\nmodes. These systems provide a new basis for constructing schemes for long-term\nand stable numerical integration of the Einstein field equations.\n\n", "human_text": "  Two new formulations of general relativity are introduced. The first one is a\nparabolization of the Arnowitt, Deser, Misner (ADM) formulation and is derived\nby addition of combinations of the constraints and their derivatives to the\nright-hand-side of the ADM evolution equations. The desirable property of this\nmodification is that it turns the surface of constraints into a local attractor\nbecause the constraint propagation equations become second-order parabolic\nindependently of the gauge conditions employed. This system may be classified\nas mixed hyperbolic - second-order parabolic. The second formulation is a\nparabolization of the Kidder, Scheel, Teukolsky formulation and is a manifestly\nmixed strongly hyperbolic - second-order parabolic set of equations, bearing\nthus resemblance to the compressible Navier-Stokes equations. As a first test,\na stability analysis of flat space is carried out and it is shown that the\nfirst modification exponentially damps and smoothes all constraint violating\nmodes. These systems provide a new basis for constructing schemes for long-term\nand stable numerical integration of the Einstein field equations.\n", "machine_text": "This paper introduces two formulations of general relativity derived from the Arnowitt, Deser, Misner (ADM) and Kidder, Scheel, Teukolsky representations. These systems have the desirable property of turning the constraint surface into a local attractor in the ADM frame while their Kidder, Scheel, Teukolsky incarnation resembles the compressible Navier-Stokes equations. By performing a stability analysis of flat space, it was determined that the first modification exponentially damps and eliminates all constraint-violating modes. These systems allow for long-term and stable numerical integration of the Einstein equations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2861}
{"prompt": "Rephrase the abstract of an article with title 'Consistency between renormalization group running of chiral operator and\n  counting rule -- Case of chiral pion production operator --'.\n  In nuclear chiral perturbation theory (ChPT), an operator is defined in a\nspace with a cutoff which may be varied within a certain range. The operator\nruns as a result of the variation of the cutoff [renormalization group (RG)\nrunning]. In order for ChPT to be useful, the operator should run in a way\nconsistent with the counting rule; that is, the running of chiral counter terms\nhave to be of natural size. We vary the cutoff using the Wilsonian\nrenormalization group (WRG) equation, and examine this consistency. As an\nexample, we study the s-wave pion production operator for NN\\to d pi, derived\nin ChPT. We demonstrate that the WRG running does not generate any\nchiral-symmetry-violating (CSV) interaction, provided that we start with an\noperator which does not contain a CSV term. We analytically show how the\ncounter terms are generated in the WRG running in case of the infinitesimal\ncutoff reduction. Based on the analytic result, we argue a range of the cutoff\nvariation for which the running of the counter terms is of natural size. Then,\nwe numerically confirm this.\n\n", "human_text": "  In nuclear chiral perturbation theory (ChPT), an operator is defined in a\nspace with a cutoff which may be varied within a certain range. The operator\nruns as a result of the variation of the cutoff [renormalization group (RG)\nrunning]. In order for ChPT to be useful, the operator should run in a way\nconsistent with the counting rule; that is, the running of chiral counter terms\nhave to be of natural size. We vary the cutoff using the Wilsonian\nrenormalization group (WRG) equation, and examine this consistency. As an\nexample, we study the s-wave pion production operator for NN\\to d pi, derived\nin ChPT. We demonstrate that the WRG running does not generate any\nchiral-symmetry-violating (CSV) interaction, provided that we start with an\noperator which does not contain a CSV term. We analytically show how the\ncounter terms are generated in the WRG running in case of the infinitesimal\ncutoff reduction. Based on the analytic result, we argue a range of the cutoff\nvariation for which the running of the counter terms is of natural size. Then,\nwe numerically confirm this.\n", "machine_text": "\nThis article evaluates the consistency between the renormalization group (RG) running of the chiral operator and the counting rule in nuclear chiral perturbation theory (ChPT). Using the Wilsonian RG (WRG) equation, we examine the running of an example s-wave pion production operator for NN\\to d pi. We demonstrate that as long as the initial operator has no chiral-symmetry-violating interaction, the WRG running will not generate any. In addition, an analytic expression of the counter terms generated due to the infinitesimal cutoff reduction is provided. Further, we discuss the range of the cutoff variation for which the running of the counter terms is of natural size. Finally, our findings are verified with numerical results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3757}
{"prompt": "Rephrase the abstract of an article with title 'Determination of intrinsic switching field distributions in\n  perpendicular recording media: numerical study of the $\\Delta H(M, \\Delta M)$\n  method'.\n  We present a numerical study of the $\\Delta H(M,\\Delta M)$ method and its\nability to accurately determine intrinsic switching field distributions in\ninteracting granular magnetic materials such as perpendicular recording media.\nIn particular, we study how this methodology fails for large ferromagnetic\ninter-granular interactions, at which point the associated strongly correlated\nmagnetization reversal cannot be properly represented by the mean-field\napproximation, upon which the $\\Delta H(M,\\Delta M)$ method is based. In this\nstudy, we use a 2-dimensional array of symmetric hysterons that have an\nintrinsic switching field distribution of standard deviation $\\sigma$ and\nferromagnetic nearest-neighbor interactions $J$. We find the $\\Delta H(M,\\Delta\nM)$ method to be very accurate for small $J/\\sigma$ values, while substantial\nerrors develop once the effective exchange field becomes comparable with\n$\\sigma$, corroborating earlier results from micromagnetic simulations. We\nfurthermore demonstrate that this failure is correlated with deviations from\ndata set redundancy, which is a key property of the mean-field approximation.\nThus, the $\\Delta H(M,\\Delta M)$ method fails in a well defined and\nquantifiable manner that can be easily assessed from the data sets alone.\n\n", "human_text": "  We present a numerical study of the $\\Delta H(M,\\Delta M)$ method and its\nability to accurately determine intrinsic switching field distributions in\ninteracting granular magnetic materials such as perpendicular recording media.\nIn particular, we study how this methodology fails for large ferromagnetic\ninter-granular interactions, at which point the associated strongly correlated\nmagnetization reversal cannot be properly represented by the mean-field\napproximation, upon which the $\\Delta H(M,\\Delta M)$ method is based. In this\nstudy, we use a 2-dimensional array of symmetric hysterons that have an\nintrinsic switching field distribution of standard deviation $\\sigma$ and\nferromagnetic nearest-neighbor interactions $J$. We find the $\\Delta H(M,\\Delta\nM)$ method to be very accurate for small $J/\\sigma$ values, while substantial\nerrors develop once the effective exchange field becomes comparable with\n$\\sigma$, corroborating earlier results from micromagnetic simulations. We\nfurthermore demonstrate that this failure is correlated with deviations from\ndata set redundancy, which is a key property of the mean-field approximation.\nThus, the $\\Delta H(M,\\Delta M)$ method fails in a well defined and\nquantifiable manner that can be easily assessed from the data sets alone.\n", "machine_text": "We present a numerical study of the $\\Delta H(M, \\Delta M)$ method for calculating intrinsic switching field distributions of interacting granular magnetic materials such as perpendicular recording media. We employ a 2-dimensional array of symmetric hysterons with intrinsic switching field dispersions of standard deviation $\\sigma$ and ferromagnetic nearest-neighbor interactions $J$. We investigate the accuracy of this methodology for various values of both $\\sigma$ and $J$. Our findings demonstrate that the $\\Delta H(M,\\Delta M)$ method is effective for low $J/\\sigma$ ratios, while errors develop when the exchange field reaches values comparable to $\\sigma$. This is demonstrated to be linked to non-compliance with data set redundancy, which is a fundamental requirement of the mean-field approximation adopted by the $\\Delta H(M, \\Delta M)$method. We thus conclude that this failure of the $\\Delta H(M,\\Delta M)$ method can be assessed from the data sets themselves through this analysis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1118}
{"prompt": "Rephrase the abstract of an article with title 'Very Massive Stars in High-Redshift Galaxies'.\n  A significant fraction of Lyman Alpha (Lya) emitting galaxies (LAEs) at z>\n5.7 have rest-frame equivalent widths (EW) greater than ~100 Angstrom. However\nonly a small fraction of the Lya flux produced by a galaxy is transmitted\nthrough the IGM, which implies intrinsic Lya EWs that are in excess of the\nmaximum allowed for a population-II stellar population having a Salpeter mass\nfunction. In this paper we study characteristics of the sources powering Lya\nemission in high redshift galaxies. We propose a simple model for Lya emitters\nin which galaxies undergo a burst of very massive star formation that results\nin a large intrinsic EW, followed by a phase of population-II star formation\nwith a lower EW. We confront this model with a range of high redshift\nobservations and find that the model is able to simultaneously describe the\nfollowing eight properties of the high redshift galaxy population with\nplausible values for parameters like the efficiency and duration of star\nformation: i-iv) the UV and Lya luminosity functions of LAEs at z=5.7 and 6.5,\nv-vi) the mean and variance of the EW distribution of Lya selected galaxies at\nz=5.7, vii) the EW distribution of i-drop galaxies at z~6, and viii) the\nobserved correlation of stellar age with EW. Our modeling suggests that the\nobserved anomalously large intrinsic equivalent widths require a burst of very\nmassive star formation lasting no more than a few to ten percent of the\ngalaxies star forming lifetime. This very massive star formation may indicate\nthe presence of population-III star formation in a few per cent of i-drop\ngalaxies, and in about half of the Lya selected galaxies.\n\n", "human_text": "  A significant fraction of Lyman Alpha (Lya) emitting galaxies (LAEs) at z>\n5.7 have rest-frame equivalent widths (EW) greater than ~100 Angstrom. However\nonly a small fraction of the Lya flux produced by a galaxy is transmitted\nthrough the IGM, which implies intrinsic Lya EWs that are in excess of the\nmaximum allowed for a population-II stellar population having a Salpeter mass\nfunction. In this paper we study characteristics of the sources powering Lya\nemission in high redshift galaxies. We propose a simple model for Lya emitters\nin which galaxies undergo a burst of very massive star formation that results\nin a large intrinsic EW, followed by a phase of population-II star formation\nwith a lower EW. We confront this model with a range of high redshift\nobservations and find that the model is able to simultaneously describe the\nfollowing eight properties of the high redshift galaxy population with\nplausible values for parameters like the efficiency and duration of star\nformation: i-iv) the UV and Lya luminosity functions of LAEs at z=5.7 and 6.5,\nv-vi) the mean and variance of the EW distribution of Lya selected galaxies at\nz=5.7, vii) the EW distribution of i-drop galaxies at z~6, and viii) the\nobserved correlation of stellar age with EW. Our modeling suggests that the\nobserved anomalously large intrinsic equivalent widths require a burst of very\nmassive star formation lasting no more than a few to ten percent of the\ngalaxies star forming lifetime. This very massive star formation may indicate\nthe presence of population-III star formation in a few per cent of i-drop\ngalaxies, and in about half of the Lya selected galaxies.\n", "machine_text": "This article studies the properties of very massive stars in high redshift galaxies. To explore this area, a model involving a brief episode of very massive star formation was developed. This model was used to evaluate the observed UV and Lya luminosity functions, mean and variance of the equivalent width distribution of Lya selected galaxies, EW distribution of i-drop galaxies, and the correlation of stellar age and EW. The analysis revealed that the anomalously large intrinsic EWs were related to a burst of very massive star formation lasting at most a fraction of the galaxies' total star-forming lifetimes. These findings suggest that population-III star formation may be present in a few percent of i-drop galaxies and around half of the Lya selected galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1671}
{"prompt": "Rephrase the abstract of an article with title 'Stable oscillations of a predator-prey probabilistic cellular automaton:\n  a mean-field approach'.\n  We analyze a probabilistic cellular automaton describing the dynamics of\ncoexistence of a predator-prey system. The individuals of each species are\nlocalized over the sites of a lattice and the local stochastic updating rules\nare inspired on the processes of the Lotka-Volterra model. Two levels of\nmean-field approximations are set up. The simple approximation is equivalent to\nan extended patch model, a simple metapopulation model with patches colonized\nby prey, patches colonized by predators and empty patches. This approximation\nis capable of describing the limited available space for species occupancy. The\npair approximation is moreover able to describe two types of coexistence of\nprey and predators: one where population densities are constant in time and\nanother displaying self-sustained time-oscillations of the population\ndensities. The oscillations are associated with limit cycles and arise through\na Hopf bifurcation. They are stable against changes in the initial conditions\nand, in this sense, they differ from the Lotka-Volterra cycles which depend on\ninitial conditions. In this respect, the present model is biologically more\nrealistic than the Lotka-Volterra model.\n\n", "human_text": "  We analyze a probabilistic cellular automaton describing the dynamics of\ncoexistence of a predator-prey system. The individuals of each species are\nlocalized over the sites of a lattice and the local stochastic updating rules\nare inspired on the processes of the Lotka-Volterra model. Two levels of\nmean-field approximations are set up. The simple approximation is equivalent to\nan extended patch model, a simple metapopulation model with patches colonized\nby prey, patches colonized by predators and empty patches. This approximation\nis capable of describing the limited available space for species occupancy. The\npair approximation is moreover able to describe two types of coexistence of\nprey and predators: one where population densities are constant in time and\nanother displaying self-sustained time-oscillations of the population\ndensities. The oscillations are associated with limit cycles and arise through\na Hopf bifurcation. They are stable against changes in the initial conditions\nand, in this sense, they differ from the Lotka-Volterra cycles which depend on\ninitial conditions. In this respect, the present model is biologically more\nrealistic than the Lotka-Volterra model.\n", "machine_text": "\nThis paper examines a probabilistic cellular automaton that simulates the mutual survivability of predator and prey species. The individuals of each species are distributed over spots in a lattice while local stochastic update methods draw on the processes of the Lotka-Volterra model. A mean-field approach is employed at two levels, where the basic approximation is akin to an extended patch model describing the limited space available to species. The pairing approximation further allows for a stable, self-sustaining oscillation of population densities, by way of a Hopf bifurcation. Such oscillations are distinct from Lotka-Volterra cycles insofar as they are resistant to changes of initial conditions, making this model more biologically realistic than the Lotka-Volterra model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0512}
{"prompt": "Rephrase the abstract of an article with title 'Second-Order Type Isomorphisms Through Game Semantics'.\n  The characterization of second-order type isomorphisms is a purely\nsyntactical problem that we propose to study under the enlightenment of game\nsemantics. We study this question in the case of second-order\n&#955;$\\mu$-calculus, which can be seen as an extension of system F to\nclassical logic, and for which we de&#64257;ne a categorical framework: control\nhyperdoctrines. Our game model of &#955;$\\mu$-calculus is based on polymorphic\narenas (closely related to Hughes' hyperforests) which evolve during the play\n(following the ideas of Murawski-Ong). We show that type isomorphisms coincide\nwith the \"equality\" on arenas associated with types. Finally we deduce the\nequational characterization of type isomorphisms from this equality. We also\nrecover from the same model Roberto Di Cosmo's characterization of type\nisomorphisms for system F. This approach leads to a geometrical comprehension\non the question of second order type isomorphisms, which can be easily extended\nto some other polymorphic calculi including additional programming features.\n\n", "human_text": "  The characterization of second-order type isomorphisms is a purely\nsyntactical problem that we propose to study under the enlightenment of game\nsemantics. We study this question in the case of second-order\n&#955;$\\mu$-calculus, which can be seen as an extension of system F to\nclassical logic, and for which we de&#64257;ne a categorical framework: control\nhyperdoctrines. Our game model of &#955;$\\mu$-calculus is based on polymorphic\narenas (closely related to Hughes' hyperforests) which evolve during the play\n(following the ideas of Murawski-Ong). We show that type isomorphisms coincide\nwith the \"equality\" on arenas associated with types. Finally we deduce the\nequational characterization of type isomorphisms from this equality. We also\nrecover from the same model Roberto Di Cosmo's characterization of type\nisomorphisms for system F. This approach leads to a geometrical comprehension\non the question of second order type isomorphisms, which can be easily extended\nto some other polymorphic calculi including additional programming features.\n", "machine_text": "\nWe explore the questions of second-order type isomorphisms by examining their characterization through game semantics. We focus our analysis on the &#955;$\\mu$-calculus, an extension of system F that incorporates classical logic, by developing a categorical framework known as control hyperdoctrines. Our game model of &#955;$\\mu$-calculus, which consists of polymorphic arenas and Hughes' hyperforests, allows us to demonstrate that type isomorphisms are equivalent to the \"equality\" associated with types. From this equality, we deduce the equational characterization of type isomorphisms. We also observe that Roberto Di Cosmo's characterization of type isomorphisms for system F is retrieved from the same model. This methodology allows for a geometrical comprehension of second-order type isomorphism, which may be easily extended to various other polymorphic calculi featuring additional programming characteristics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4226}
{"prompt": "Rephrase the abstract of an article with title 'Phase diagram of the dilute magnet LiHo_xY_{1-x}F_4'.\n  We study the effective long-range Ising dipole model with a local exchange\ninteraction appropriate for the dilute magnetic compound LiHo_{x}Y_{1-x}F_4.\nOur calculations yield a value of 0.12 K for the nearest neighbor exchange\ninteraction. Using a Monte Carlo method we calculate the phase boundary T_c(x)\nbetween the ferromagnetic and paramagnetic phases. We demonstrate that the\nexperimentally observed linear decrease in T_c with dilution is not the simple\nmean-field result, but a combination of the effects of fluctuations, the\nexchange interaction and the hyperfine coupling. Furthermore, we find a\ncritical dilution x_c=0.21(2), below which there is no ordering. In agreement\nwith recent Monte Carlo simulations on a similar model, we find no evidence of\nthe experimentally observed freezing of the glassy state in our calculation. We\napply the theory of Stephen and Aharony to LiHo_{x}Y_{1-x}F_4 and find that the\ntheory does predict a finite-temperature freezing of the spin glass. Reasons\nfor the discrepancies are discussed.\n\n", "human_text": "  We study the effective long-range Ising dipole model with a local exchange\ninteraction appropriate for the dilute magnetic compound LiHo_{x}Y_{1-x}F_4.\nOur calculations yield a value of 0.12 K for the nearest neighbor exchange\ninteraction. Using a Monte Carlo method we calculate the phase boundary T_c(x)\nbetween the ferromagnetic and paramagnetic phases. We demonstrate that the\nexperimentally observed linear decrease in T_c with dilution is not the simple\nmean-field result, but a combination of the effects of fluctuations, the\nexchange interaction and the hyperfine coupling. Furthermore, we find a\ncritical dilution x_c=0.21(2), below which there is no ordering. In agreement\nwith recent Monte Carlo simulations on a similar model, we find no evidence of\nthe experimentally observed freezing of the glassy state in our calculation. We\napply the theory of Stephen and Aharony to LiHo_{x}Y_{1-x}F_4 and find that the\ntheory does predict a finite-temperature freezing of the spin glass. Reasons\nfor the discrepancies are discussed.\n", "machine_text": "\nThis study examines the Ising dipole model as it relates to the dilute magnetic material LiHo_{x}Y_{1-x}F_4. Our calculations provide a value of 0.12 K for the nearest neighbor exchange interaction. Using Monte Carlo calculations, we are able to compute the boundary T_c(x) at which the ferromagnetic and paramagnetic phases occur. We further demonstrate that the linear decrease in T_c with increasing dilution is not as straightforward as originally thought, as fluctuations and the exchange interactions play a role in the behavior. We identify a critical dilution x_c=0.21(2) above which there appears to be no ordering. We fail to reproduce the experimentally-observed freezing of the spin glass in our simulations. We relate our results to the findings of Stephen and Aharony and plot their theory of finite-temperature freezing. Discrepancies between our work and experiments are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3656}
{"prompt": "Rephrase the abstract of an article with title 'The Millennium Galaxy Catalogue: The local supermassive black hole mass\n  function in early- and late-type galaxies'.\n  We provide a new estimate of the local supermassive black hole mass function\nusing (i) the empirical relation between supermassive black hole mass and the\nSersic index of the host spheroidal stellar system and (ii) the measured\n(spheroid) Sersic indices drawn from 10k galaxies in the Millennium Galaxy\nCatalogue. The observational simplicity of our approach, and the direct\nmeasurements of the black hole predictor quantity, i.e. the Sersic index, for\nboth elliptical galaxies and the bulges of disc galaxies makes it\nstraightforward to estimate accurate black hole masses in early- and late-type\ngalaxies alike. We have parameterised the supermassive black hole mass function\nwith a Schechter function and find, at the low-mass end, a logarithmic slope\n(1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxy\nsample. Considering spheroidal stellar systems brighter than M_B = -18 mag, and\nintegrating down to black hole masses of 10^6 M_sun, we find that the local\nmass density of supermassive black holes in early-type galaxies rho_{bh,\nearly-type} = (3.5+/-1.2) x 10^5 h^3_{70} M_sun Mpc^{-3}, and in late-type\ngalaxies rho_{bh, late-type} = (1.0+/-0.5) x 10^5 h^3_{70} M_sun Mpc^{-3}. The\nuncertainties are derived from Monte Carlo simulations which include\nuncertainties in the M_bh-n relation, the catalogue of Sersic indices, the\ngalaxy weights and Malmquist bias. The combined, cosmological, supermassive\nblack hole mass density is thus Omega_{bh, total} = (3.2+/-1.2) x 10^{-6} h_70.\nThat is, using a new and independent method, we conclude that (0.007+/-0.003)\nh^3_{70} per cent of the universe's baryons are presently locked up in\nsupermassive black holes at the centres of galaxies.\n\n", "human_text": "  We provide a new estimate of the local supermassive black hole mass function\nusing (i) the empirical relation between supermassive black hole mass and the\nSersic index of the host spheroidal stellar system and (ii) the measured\n(spheroid) Sersic indices drawn from 10k galaxies in the Millennium Galaxy\nCatalogue. The observational simplicity of our approach, and the direct\nmeasurements of the black hole predictor quantity, i.e. the Sersic index, for\nboth elliptical galaxies and the bulges of disc galaxies makes it\nstraightforward to estimate accurate black hole masses in early- and late-type\ngalaxies alike. We have parameterised the supermassive black hole mass function\nwith a Schechter function and find, at the low-mass end, a logarithmic slope\n(1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxy\nsample. Considering spheroidal stellar systems brighter than M_B = -18 mag, and\nintegrating down to black hole masses of 10^6 M_sun, we find that the local\nmass density of supermassive black holes in early-type galaxies rho_{bh,\nearly-type} = (3.5+/-1.2) x 10^5 h^3_{70} M_sun Mpc^{-3}, and in late-type\ngalaxies rho_{bh, late-type} = (1.0+/-0.5) x 10^5 h^3_{70} M_sun Mpc^{-3}. The\nuncertainties are derived from Monte Carlo simulations which include\nuncertainties in the M_bh-n relation, the catalogue of Sersic indices, the\ngalaxy weights and Malmquist bias. The combined, cosmological, supermassive\nblack hole mass density is thus Omega_{bh, total} = (3.2+/-1.2) x 10^{-6} h_70.\nThat is, using a new and independent method, we conclude that (0.007+/-0.003)\nh^3_{70} per cent of the universe's baryons are presently locked up in\nsupermassive black holes at the centres of galaxies.\n", "machine_text": "Based on the data from the Millennium Galaxy Catalogue, this study provides an in-depth evaluation of the local supermassive black hole mass function in both early- and late-type galaxies. We use a Schechter function to parameterise the black hole mass function, with a low-mass end logarithmic slope (1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxies. Integrating the estimates from 10,000 galaxies (brighter than M_B = -18 mag) down to black hole masses of 10^6 M_sun, we estimate a local mass density of supermassive black holes as 3.5+/-1.2 x 10^5 h^3_{70} M_sun Mpc^{-3} in early-type galaxies, and 1.0+/-0.5 x 10^5 h^3_{70} M_sun Mpc^{-3} in late-type galaxies. The cosmological supermassive black hole mass density is thus computed to be 3.2+/-1.2 x 10^{-6} h_70, indicating that around 0.007+/-0.003 h^3_{70} per cent of the universe's baryons are locked into these objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0316}
{"prompt": "Rephrase the abstract of an article with title 'The neighborhood of the Standard Model: mixing angles and quark-lepton\n  complementarity for three generations of non-degenerate coupled fermions'.\n  We investigate the potential (small) deviations from the unitarity of the\nmixing matrix that are expected to occur, because of mass splittings, in the\nQuantum Field Theory of non-degenerate coupled systems. We extend our previous\nanalysis concerning mixing angles, which led to a precise determination of the\nCabibbo angle, to the case of three generations of fermions. We show that the\nsame condition for neutral currents of mass eigenstates, i.e. that universality\nof diagonal currents is violated with the same strength as the absence of\nnon-diagonal ones, is satisfied: on one hand, by the three CKM mixing angles\nwith a precision higher than the experimental uncertainty; on the other hand,\nby a neutrino-like mixing pattern in which theta_{23} is maximal, and tan (2\ntheta_{12})=2. This last pattern turns out to satisfy exactly the \"quark-lepton\ncomplementarity condition\" theta_c + theta_{12}= pi/4. Moreover, among all\nsolutions, two values for the third neutrino mixing angle arise which satisfy\nthe bound sin^2(theta_{13}) < 0.1: theta_{13} = +/- 5.7 10^{-3} and theta_{13}\n= +/- 0.2717. The so-called \"Neighborhood of the Standard Model\" is thus\nconfirmed to exhibit special patterns which presumably originate in physics\n\"Beyond the Standard Model\".\n\n", "human_text": "  We investigate the potential (small) deviations from the unitarity of the\nmixing matrix that are expected to occur, because of mass splittings, in the\nQuantum Field Theory of non-degenerate coupled systems. We extend our previous\nanalysis concerning mixing angles, which led to a precise determination of the\nCabibbo angle, to the case of three generations of fermions. We show that the\nsame condition for neutral currents of mass eigenstates, i.e. that universality\nof diagonal currents is violated with the same strength as the absence of\nnon-diagonal ones, is satisfied: on one hand, by the three CKM mixing angles\nwith a precision higher than the experimental uncertainty; on the other hand,\nby a neutrino-like mixing pattern in which theta_{23} is maximal, and tan (2\ntheta_{12})=2. This last pattern turns out to satisfy exactly the \"quark-lepton\ncomplementarity condition\" theta_c + theta_{12}= pi/4. Moreover, among all\nsolutions, two values for the third neutrino mixing angle arise which satisfy\nthe bound sin^2(theta_{13}) < 0.1: theta_{13} = +/- 5.7 10^{-3} and theta_{13}\n= +/- 0.2717. The so-called \"Neighborhood of the Standard Model\" is thus\nconfirmed to exhibit special patterns which presumably originate in physics\n\"Beyond the Standard Model\".\n", "machine_text": "\nWe analyze the possible deviations from the unitarity of the Quantum Field Theory of coupled, non-degenerate fermions which occur when the elements of the mixing matrix take account of the fermion mass splittings. We demonstrate that the three CKM mixing angles, together with a neutrino-like mixing pattern in which theta_{23 } is maximal and tan(2 theta_{12}) = 2, can be employed to verify that neutrally charged mass eigenstates are universally diagonal with the same amount of violation as the non-diagonal ones. Furthermore, two solutions for the third neutrino mixing angle meet the imposed limit sin^2(theta_{13}) < 0.1: theta_{13} = +/- 5.7 10^-3, and theta 13 = +/- 0.2717. These results demonstrate that the vicinity of the Standard Model includes certain patterns which might be indicative of physics beyond the Standard Model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1237}
{"prompt": "Rephrase the abstract of an article with title 'A deeper X-ray study of the core of the Perseus galaxy cluster: the\n  power of sound waves and the distribution of metals and cosmic rays'.\n  We make a further study of the very deep Chandra observation of the X-ray\nbrightest galaxy cluster, A426 in Perseus. We examine the radial distribution\nof energy flux inferred by the quasi-concentric ripples in surface brightness,\nassuming they are due to sound waves, and show that it is a significant\nfraction of the energy lost by radiative cooling within the inner 75-100 kpc,\nwhere the cooling time is 4-5 Gyr, respectively. The wave flux decreases\noutward with radius, consistent with energy being dissipated. Some newly\ndiscovered large ripples beyond 100 kpc, and a possible intact bubble at 170\nkpc radius, may indicate a larger level of activity by the nucleus a few 100\nMyr ago. The distribution of metals in the intracluster gas peaks at a radius\nof about 40 kpc and is significantly clumpy on scales of 5 kpc. The temperature\ndistribution of the soft X-ray filaments and the hard X-ray emission component\nfound within the inner 50 kpc are analysed in detail. The pressure due to the\nnonthermal electrons, responsible for a spectral component interpreted as\ninverse Compton emission, is high within 40 kpc of the centre and boosts the\npower in sound waves there; it drops steeply beyond 40 kpc. We find no thermal\nemission from the radio bubbles; in order for any thermal gas to have a filling\nfactor within the bubbles exceeding 50 per cent, the temperature of that gas\nhas to exceed 50 keV.\n\n", "human_text": "  We make a further study of the very deep Chandra observation of the X-ray\nbrightest galaxy cluster, A426 in Perseus. We examine the radial distribution\nof energy flux inferred by the quasi-concentric ripples in surface brightness,\nassuming they are due to sound waves, and show that it is a significant\nfraction of the energy lost by radiative cooling within the inner 75-100 kpc,\nwhere the cooling time is 4-5 Gyr, respectively. The wave flux decreases\noutward with radius, consistent with energy being dissipated. Some newly\ndiscovered large ripples beyond 100 kpc, and a possible intact bubble at 170\nkpc radius, may indicate a larger level of activity by the nucleus a few 100\nMyr ago. The distribution of metals in the intracluster gas peaks at a radius\nof about 40 kpc and is significantly clumpy on scales of 5 kpc. The temperature\ndistribution of the soft X-ray filaments and the hard X-ray emission component\nfound within the inner 50 kpc are analysed in detail. The pressure due to the\nnonthermal electrons, responsible for a spectral component interpreted as\ninverse Compton emission, is high within 40 kpc of the centre and boosts the\npower in sound waves there; it drops steeply beyond 40 kpc. We find no thermal\nemission from the radio bubbles; in order for any thermal gas to have a filling\nfactor within the bubbles exceeding 50 per cent, the temperature of that gas\nhas to exceed 50 keV.\n", "machine_text": "\nWe take a closer look at the X-ray emission of the brightest galaxy cluster in Perseus, A426, using Chandra data. This reveals ripples with quasi-concentric circles, likely caused by sound waves, that equate to an energy flux within 75-100 kpc of the core, with a correspondingly long cooling time of 4-5 Gyr. Further outward, these ripple patterns indicate energy loss, as well as some newly found large ripples, and a possible buble, that indicate activity within the past hundred million years. We examine the the radial distribution of metals, noticing that it peaks at about 40 kpc and is clumpy on  5 kpc scales. We moreover analyze the soft and hard X-ray filaments within a 50 kpc radius and find that the pressure caused by electrons, responsible for the inverse Compton emission, is amplified nearer to the core and falls off quickly after 40 kpc. Lastly, no thermal gas is discovered in the radio bubble and to prove otherwise, the gas temperature would have to exceed 50 keV.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2712}
{"prompt": "Rephrase the abstract of an article with title 'On the X-Ray emission of Gamma Ray Bursts'.\n  Recent data gathered and triggered by the SWIFT satellite have greatly\nimproved our knowledge of long-duration gamma ray bursts (GRBs) and X-ray\nflashes (XRFs). This is particularly the case for the X-ray data at all times.\nWe show that the entire X-ray observations are in excellent agreement with the\npredictions of the `cannonball' model of GRBs and XRFs, which are based on\nsimple physics and were published long before the launch of SWIFT. Two\nmechanisms underlie these predictions: inverse Compton scattering and\nsynchrotron radiation, generally dominant at early and late times,\nrespectively. The former mechanism provides a unified description of the\ngamma-ray peaks, X-ray flares and even the optical `humps' seen in some\nfavourable cases; i.e. their very different durations, fluxes and peak-times\nare related precisely as predicted. The observed smooth or bumpy fast decay of\nthe X-ray light curve is correctly described case-by-case, in minute detail.\nThe `canonical' X-ray plateau, as well as the subsequent gradual steepening of\nthe afterglow to an asymptotic power-law decay, are as foretold. So are the\nchromatic and achromatic properties of the light-curves.\n\n", "human_text": "  Recent data gathered and triggered by the SWIFT satellite have greatly\nimproved our knowledge of long-duration gamma ray bursts (GRBs) and X-ray\nflashes (XRFs). This is particularly the case for the X-ray data at all times.\nWe show that the entire X-ray observations are in excellent agreement with the\npredictions of the `cannonball' model of GRBs and XRFs, which are based on\nsimple physics and were published long before the launch of SWIFT. Two\nmechanisms underlie these predictions: inverse Compton scattering and\nsynchrotron radiation, generally dominant at early and late times,\nrespectively. The former mechanism provides a unified description of the\ngamma-ray peaks, X-ray flares and even the optical `humps' seen in some\nfavourable cases; i.e. their very different durations, fluxes and peak-times\nare related precisely as predicted. The observed smooth or bumpy fast decay of\nthe X-ray light curve is correctly described case-by-case, in minute detail.\nThe `canonical' X-ray plateau, as well as the subsequent gradual steepening of\nthe afterglow to an asymptotic power-law decay, are as foretold. So are the\nchromatic and achromatic properties of the light-curves.\n", "machine_text": "\nRecent data collected by SWIFT and subsequent analysis has greatly increased our knowledge of X-ray emission from long-duration gamma ray bursts (GRBs) and X-ray flashes (XRFs). This article explains how the cannonball model of GRBs and XRFs previously proposed, based on the physics of inverse Compton scattering and synchrotron radiation, applied well to re-analyzed X-ray observations. The predictions of the model - such as the duration, flux and peak-times of gamma-ray peaks, X-ray flares and optical humps - have been accurately realized. Also discussed is the ability of the model to correctly describe the smooth or bumpy fast decays of the X-ray light curve, the canonical X-ray plateau, and the gradual steepening of the afterglow which ultimately reaches a power-law decay, both chromatically and achromatically.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.088}
{"prompt": "Rephrase the abstract of an article with title 'Recovering galaxy star formation and metallicity histories from spectra\n  using VESPA'.\n  We introduce VErsatile SPectral Analysis (VESPA): a new method which aims to\nrecover robust star formation and metallicity histories from galactic spectra.\nVESPA uses the full spectral range to construct a galaxy history from synthetic\nmodels. We investigate the use of an adaptative parametrization grid to recover\nreliable star formation histories on a galaxy-by-galaxy basis. Our goal is\nrobustness as opposed to high resolution histories, and the method is designed\nto return high time resolution only where the data demand it. In this paper we\ndetail the method and we present our findings when we apply VESPA to synthetic\nand real Sloan Digital Sky Survey (SDSS) spectroscopic data. We show that the\nnumber of parameters that can be recovered from a spectrum depends strongly on\nthe signal-to-noise, wavelength coverage and presence or absence of a young\npopulation. For a typical SDSS sample of galaxies, we can normally recover\nbetween 2 to 5 stellar populations. We find very good agreement between VESPA\nand our previous analysis of the SDSS sample with MOPED.\n\n", "human_text": "  We introduce VErsatile SPectral Analysis (VESPA): a new method which aims to\nrecover robust star formation and metallicity histories from galactic spectra.\nVESPA uses the full spectral range to construct a galaxy history from synthetic\nmodels. We investigate the use of an adaptative parametrization grid to recover\nreliable star formation histories on a galaxy-by-galaxy basis. Our goal is\nrobustness as opposed to high resolution histories, and the method is designed\nto return high time resolution only where the data demand it. In this paper we\ndetail the method and we present our findings when we apply VESPA to synthetic\nand real Sloan Digital Sky Survey (SDSS) spectroscopic data. We show that the\nnumber of parameters that can be recovered from a spectrum depends strongly on\nthe signal-to-noise, wavelength coverage and presence or absence of a young\npopulation. For a typical SDSS sample of galaxies, we can normally recover\nbetween 2 to 5 stellar populations. We find very good agreement between VESPA\nand our previous analysis of the SDSS sample with MOPED.\n", "machine_text": "\nThis paper introduces VErsatile SPectral Analysis (VESPA): an algorithm designed to \naccurately model star formation and metallicity histories of galaxies using only \nspectroscopic data. Adaptive parametrization grids are employed to more reliably\nproduce individual star formation histories. As opposed to high-resolution histories, \nVESPA is mainly focused on providing robust histories in all conditions. We\ndescribe and evaluate the method with synthetic and real Sloan Digital Sky Survey \n(SDSS) spectra. Results indicate that the number of stellar populations recovered \nalters depending on the noise, wavelength coverage, and age of the galaxy. For a \ntypical SDSS sample, typically between 2 and 5 stellar populations can effectively \nbe recovered. Comparisons to previous analyses with MOPED reveal strong agreement \nbetween VESPA predictions and existing results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0941}
{"prompt": "Rephrase the abstract of an article with title 'Strings on AdS_2 and the High-Energy Limit of Noncritical M-Theory'.\n  Noncritical M-theory in 2+1 dimensions has been defined as a double-scaling\nlimit of a nonrelativistic Fermi liquid on a flat two-dimensional plane. Here\nwe study this noncritical M-theory in the limit of high energies, analogous to\nthe \\alpha'\\to\\infty limit of string theory. In the related case of\ntwo-dimensional Type 0A strings, it has been argued that the conformal\n\\alpha'\\to\\infty limit leads to AdS_2 with a propagating fermion whose mass is\nset by the value of the RR flux. Here we provide evidence that in the\nhigh-energy limit, the natural ground state of noncritical M-theory similarly\ndescribes the AdS_2\\times S^1 spacetime, with a massless propagating fermion.\nWe argue that the spacetime effective theory in this background is captured by\na topological higher-spin extension of conformal Chern-Simons gravity in 2+1\ndimensions, consistently coupled to a massless Dirac field. Intriguingly, the\ntwo-dimensional plane populated by the original nonrelativistic fermions is\nessentially the twistor space associated with the symmetry group of the\nAdS_2\\times S^1 spacetime; thus, at least in the high-energy limit, noncritical\nM-theory can be nonperturbatively described as a \"Fermi liquid on twistor\nspace.\"\n\n", "human_text": "  Noncritical M-theory in 2+1 dimensions has been defined as a double-scaling\nlimit of a nonrelativistic Fermi liquid on a flat two-dimensional plane. Here\nwe study this noncritical M-theory in the limit of high energies, analogous to\nthe \\alpha'\\to\\infty limit of string theory. In the related case of\ntwo-dimensional Type 0A strings, it has been argued that the conformal\n\\alpha'\\to\\infty limit leads to AdS_2 with a propagating fermion whose mass is\nset by the value of the RR flux. Here we provide evidence that in the\nhigh-energy limit, the natural ground state of noncritical M-theory similarly\ndescribes the AdS_2\\times S^1 spacetime, with a massless propagating fermion.\nWe argue that the spacetime effective theory in this background is captured by\na topological higher-spin extension of conformal Chern-Simons gravity in 2+1\ndimensions, consistently coupled to a massless Dirac field. Intriguingly, the\ntwo-dimensional plane populated by the original nonrelativistic fermions is\nessentially the twistor space associated with the symmetry group of the\nAdS_2\\times S^1 spacetime; thus, at least in the high-energy limit, noncritical\nM-theory can be nonperturbatively described as a \"Fermi liquid on twistor\nspace.\"\n", "machine_text": "\nWe investigate the high-energy limit of noncritical M-theory in 2+1 dimensions, which is a double-scaling limit of a nonrelativistic Fermi liquid on a flat two-dimensional plane. Our analysis is analogous to the \\alpha'\\to\\infty limit of string theory, in which case two-dimensional Type 0A strings were asserted to give rise to AdS_2 with a propagating fermion whose mass is set by the RR flux. Here, we provide evidence that the natural ground state of noncritical M-theory for high energies describes AdS_2\\times S^1, with a massless fermion. A topological extension of conformal Chern-Simons gravity in 2+1 dimensions, coupled to a massless Dirac field, is found to capture the spacetime effective theory in this background. Interestingly, the starting two-dimensional plane is the twistor space associated with the symmetry group of AdS_2\\times S^1, proving that at high energies, noncritical M-theory can be described as a \"Fermi liquid on twistor space\".", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.223}
{"prompt": "Rephrase the abstract of an article with title 'Acceleration and Substructure Constraints in a Quasar Outflow'.\n  We present observations of probable line-of-sight acceleration of a broad\nabsorption trough of C IV in the quasar SDSS J024221.87+004912.6. We also\ndiscuss how the velocity overlap of two other outflowing systems in the same\nobject constrains the properties of the outflows. The Si IV doublet in each\nsystem has one unblended transition and one transition which overlaps with\nabsorption from the other system. The residual flux in the overlapping trough\nis well fit by the product of the residual fluxes in the unblended troughs. For\nthese optically thick systems to yield such a result, at least one of them must\nconsist of individual subunits rather than being a single structure with\nvelocity-dependent coverage of the source. If these subunits are identical,\nopaque, spherical clouds, we estimate the cloud radius to be r = 3.9 10^15 cm.\nIf they are identical, opaque, linear filaments, we estimate their width to be\nw = 6.5 10^14 cm. These subunits are observed to cover the Mg II broad emission\nline region of the quasar, at which distance from the black hole the above\nfilament width is equal to the predicted scale height of the outer atmosphere\nof a thin accretion disk. Insofar as that scale height is a natural size scale\nfor structures originating in an accretion disk, these observations are\nevidence that the accretion disk can be a source of quasar absorption systems.\nBased on data from ESO program 075.B-0190(A).\n\n", "human_text": "  We present observations of probable line-of-sight acceleration of a broad\nabsorption trough of C IV in the quasar SDSS J024221.87+004912.6. We also\ndiscuss how the velocity overlap of two other outflowing systems in the same\nobject constrains the properties of the outflows. The Si IV doublet in each\nsystem has one unblended transition and one transition which overlaps with\nabsorption from the other system. The residual flux in the overlapping trough\nis well fit by the product of the residual fluxes in the unblended troughs. For\nthese optically thick systems to yield such a result, at least one of them must\nconsist of individual subunits rather than being a single structure with\nvelocity-dependent coverage of the source. If these subunits are identical,\nopaque, spherical clouds, we estimate the cloud radius to be r = 3.9 10^15 cm.\nIf they are identical, opaque, linear filaments, we estimate their width to be\nw = 6.5 10^14 cm. These subunits are observed to cover the Mg II broad emission\nline region of the quasar, at which distance from the black hole the above\nfilament width is equal to the predicted scale height of the outer atmosphere\nof a thin accretion disk. Insofar as that scale height is a natural size scale\nfor structures originating in an accretion disk, these observations are\nevidence that the accretion disk can be a source of quasar absorption systems.\nBased on data from ESO program 075.B-0190(A).\n", "machine_text": "\nWe investigate the possible line-of-sight acceleration of a C IV broad absorption trough in a quasar, SDSS J024221.87+004912.6. Combining two other outflowing systems constrains the properties of the outflows. Observations of the residual flux in an overlapping trough provide evidence for structures in both systems consisting of individual subunits, either opaque, spherical clouds with radius r = 3.9 10^15 cm or opaque, linear filaments with width w = 6.5 10^14 cm, which cover the Mg II broad emission line region of the quasar. This suggests that the accretion disk can be a source of quasar absorption systems, as the latter's width is equal to the scale height of the thin accretion disk at the same distance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3772}
{"prompt": "Rephrase the abstract of an article with title 'Multi-wavelength observations of Southern Hot Molecular Cores traced by\n  methanol masers - I. Ammonia and 24 GHz Continuum Data'.\n  We present observations of the (1,1), (2,2), (4,4) and (5,5) inversion\ntransitions of para-ammonia (NH3) and 24 GHz continuum, taken with the\nAustralia Telescope Compact Array toward 21 southern Galactic hot molecular\ncores traced by 6.7 GHz methanol maser emission. We detect NH3(1,1) emission\ntoward all 21 regions and 24 GHz continuum emission toward 12 of the regions,\nincluding 6 with no reported 8 GHz continuum counterparts. In total, we find\nthe 21 regions contain 41 NH3(1,1) cores. We extract characteristic spectra for\nevery core at each of the NH3 transitions and present both integrated intensity\nmaps and channel maps for each region. The NH3(4,4)+(5,5) emission is always\nunresolved and found at the maser position indicating that the methanol masers\nare found at the warmest part of the core. We observe large asymmetries in the\nNH3(1,1) hyperfine line profiles and conclude this is due to a number of dense,\nsmall clumps within the beam. We derive properties of the ionised gas and find\nthe 24 GHz continuum sources not detected at 8 GHz are always coincident with\nboth NH3 and methanol masers in contrast to those detected at 8 + 24 GHz which\nare generally offset from the methanol masers. We investigate the possibility\nthat the former may be hyper-compact HII regions. Finally, we separate the\ncores into five groups, based on their association with NH3, methanol maser and\ncontinuum emission. From the different physical properties of the cores in the\ngroups, we discuss the possibility that these groups may represent cores at\ndifferent evolutionary stages of the massive star formation process.\n\n", "human_text": "  We present observations of the (1,1), (2,2), (4,4) and (5,5) inversion\ntransitions of para-ammonia (NH3) and 24 GHz continuum, taken with the\nAustralia Telescope Compact Array toward 21 southern Galactic hot molecular\ncores traced by 6.7 GHz methanol maser emission. We detect NH3(1,1) emission\ntoward all 21 regions and 24 GHz continuum emission toward 12 of the regions,\nincluding 6 with no reported 8 GHz continuum counterparts. In total, we find\nthe 21 regions contain 41 NH3(1,1) cores. We extract characteristic spectra for\nevery core at each of the NH3 transitions and present both integrated intensity\nmaps and channel maps for each region. The NH3(4,4)+(5,5) emission is always\nunresolved and found at the maser position indicating that the methanol masers\nare found at the warmest part of the core. We observe large asymmetries in the\nNH3(1,1) hyperfine line profiles and conclude this is due to a number of dense,\nsmall clumps within the beam. We derive properties of the ionised gas and find\nthe 24 GHz continuum sources not detected at 8 GHz are always coincident with\nboth NH3 and methanol masers in contrast to those detected at 8 + 24 GHz which\nare generally offset from the methanol masers. We investigate the possibility\nthat the former may be hyper-compact HII regions. Finally, we separate the\ncores into five groups, based on their association with NH3, methanol maser and\ncontinuum emission. From the different physical properties of the cores in the\ngroups, we discuss the possibility that these groups may represent cores at\ndifferent evolutionary stages of the massive star formation process.\n", "machine_text": "\nWe used the Australia Telescope Compact Array to observe 21 southern Galactic hot molecular cores with 6.7 GHz methanol maser emission in (1,1), (2,2), (4,4) and (5,5) inversion transitions of para-ammonia (NH3) and 24 GHz continuum. We discovered 41 NH3 (1,1) cores, 12 of which had associated 24 GHz continuum emission. Our findings suggest that there are asymmetries in the NH3(1,1) line profile due to numerous dense, small clumps. By comparing the physical properties of the cores across five groups, we propose that they represent evolutionary stages in the massive star formation process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2096}
{"prompt": "Rephrase the abstract of an article with title 'A Massive Yang-Mills Theory based on the Nonlinearly Realized Gauge\n  Group'.\n  We propose a subtraction scheme for a massive Yang-Mills theory realized via\na nonlinear representation of the gauge group (here SU(2)). It is based on the\nsubtraction of the poles in D-4 of the amplitudes, in dimensional\nregularization, after a suitable normalization has been performed. Perturbation\ntheory is in the number of loops and the procedure is stable under iterative\nsubtraction of the poles. The unphysical Goldstone bosons, the Faddeev-Popov\nghosts and the unphysical mode of the gauge field are expected to cancel out in\nthe unitarity equation. The spontaneous symmetry breaking parameter is not a\nphysical variable. We use the tools already tested in the nonlinear sigma\nmodel: hierarchy in the number of Goldstone boson legs and weak power-counting\nproperty (finite number of independent divergent amplitudes at each order). It\nis intriguing that the model is naturally based on the symmetry SU(2)_L local\ntimes SU(2)_R global. By construction the physical amplitudes depend on the\nmass and on the self-coupling constant of the gauge particle and moreover on\nthe scale parameter of the radiative corrections. The Feynman rules are in the\nLandau gauge.\n\n", "human_text": "  We propose a subtraction scheme for a massive Yang-Mills theory realized via\na nonlinear representation of the gauge group (here SU(2)). It is based on the\nsubtraction of the poles in D-4 of the amplitudes, in dimensional\nregularization, after a suitable normalization has been performed. Perturbation\ntheory is in the number of loops and the procedure is stable under iterative\nsubtraction of the poles. The unphysical Goldstone bosons, the Faddeev-Popov\nghosts and the unphysical mode of the gauge field are expected to cancel out in\nthe unitarity equation. The spontaneous symmetry breaking parameter is not a\nphysical variable. We use the tools already tested in the nonlinear sigma\nmodel: hierarchy in the number of Goldstone boson legs and weak power-counting\nproperty (finite number of independent divergent amplitudes at each order). It\nis intriguing that the model is naturally based on the symmetry SU(2)_L local\ntimes SU(2)_R global. By construction the physical amplitudes depend on the\nmass and on the self-coupling constant of the gauge particle and moreover on\nthe scale parameter of the radiative corrections. The Feynman rules are in the\nLandau gauge.\n", "machine_text": "\nThis paper offers a subtraction scheme for a Yang-Mills theory realized utilizing a nonlinear representation of the SU(2) gauge group. We apply dimensional regularization for the manipulation of the associated poles in D-4. The unphysical Goldstone bosons, the Faddeev-Popov ghosts, and the unphysical mode of the gauge field are anticipated to be eliminated through the unitarity equation. The spontaneous symmetry breaking parameter is not a physical variable. We employ the tools already verified through the nonlinear sigma model: the hierarchy involving the number of Goldstone boson legs and a weak power-counting property (finite number of independent divergent amplitudes at every order). The inherent symmetry of the model proves to be SU(2)_L local times SU(2)_R global. The physical amplitudes are dependent on the mass, the self-coupling constant of the gauge particle, and the scale parameter of the radiative corrections. The implementation of the calculation is done in the Landau gauge.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2339}
{"prompt": "Rephrase the abstract of an article with title 'Long time existence of smooth solutions for the rapidly rotating\n  shallow-water and Euler equations'.\n  We study the stabilizing effect of rotational forcing in the nonlinear\nsetting of two-dimensional shallow-water and more general models of\ncompressible Euler equations. In [H. Liu and E. Tadmor, Phys. D 188 (2004), no.\n3-4, 262-276] we have shown that the pressureless version of these equations\nadmit global smooth solution for a large set of sub-critical initial\nconfigurations. In the present work we prove that when rotational force\ndominates the pressure, it \\emph{prolongs} the life-span of smooth solutions\nfor t < ln(1/d); here d << 1 is the ratio of the pressure gradient measured by\nthe inverse squared Froude number, relative to the dominant rotational forces\nmeasured by the inverse Rossby number. Our study reveals a ``nearby''\nperiodic-in-time approximate solution in the small d-regime, upon which hinges\nthe long time existence of the exact smooth solution. These results are in\nagreement with the close-to periodic dynamics observed in the ``near inertial\noscillation'' (NIO) regime which follows oceanic storms. Indeed, our results\nindicate the existence of smooth, ``approximate periodic'' solution for a time\nperiod of \\emph{days}, which is the relevant time period found in NIO\nobesrvations.\n\n", "human_text": "  We study the stabilizing effect of rotational forcing in the nonlinear\nsetting of two-dimensional shallow-water and more general models of\ncompressible Euler equations. In [H. Liu and E. Tadmor, Phys. D 188 (2004), no.\n3-4, 262-276] we have shown that the pressureless version of these equations\nadmit global smooth solution for a large set of sub-critical initial\nconfigurations. In the present work we prove that when rotational force\ndominates the pressure, it \\emph{prolongs} the life-span of smooth solutions\nfor t < ln(1/d); here d << 1 is the ratio of the pressure gradient measured by\nthe inverse squared Froude number, relative to the dominant rotational forces\nmeasured by the inverse Rossby number. Our study reveals a ``nearby''\nperiodic-in-time approximate solution in the small d-regime, upon which hinges\nthe long time existence of the exact smooth solution. These results are in\nagreement with the close-to periodic dynamics observed in the ``near inertial\noscillation'' (NIO) regime which follows oceanic storms. Indeed, our results\nindicate the existence of smooth, ``approximate periodic'' solution for a time\nperiod of \\emph{days}, which is the relevant time period found in NIO\nobesrvations.\n", "machine_text": "\nIn this article, we look at the effect of rotational forcing on global smooth solutions of the two-dimensional shallow-water and compressible Euler equations that lack pressure. A prior investigation done by H. Liu and E. Tadmor in 2004 found that these equations admit long-term consistent solutions for a variety of sub-critical initial conditions. We now prove that when rotational forces surpass pressure, this leads to an extension of the duration of continuous, smooth solutions. This holds true when the ratio of the pressure gradient to the dominant rotational forces, measured by the inverse squared Froude number and inverse Rossby number respectively, is much smaller than one. Further analysis of the analysis reveals an approximate periodic solution within this small d-regime, which allows the exact smooth solutions to endure for a time period in excess of a day. This aligns with the close-to periodic dynamics seen in the aftermath of oceanic storms, called near inertial oscillations (NIOS).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0758}
{"prompt": "Rephrase the abstract of an article with title 'Variation of the Amati Relation with the Cosmological Redshift: a\n  Selection Effect or an Evolution Effect?'.\n  Because of the limit in the number of gamma-ray bursts (GRBs) with available\nredshifts and spectra, all current investigations on the correlation among GRB\nvariables use burst samples with redshifts that span a very large range. The\nevolution and selection effects have thus been ignored, which might have\nimportant influence on the results. In this Letter, we divide the 48\nlong-duration GRBs in Amati (2006, 2007) into four groups with redshift from\nlow to high, each group contains 12 GRBs. Then we fit each group with the Amati\nrelation $\\log E_\\iso = a + b \\log E_\\p$, and check if the parameters $a$ and\n$b$ evolve with the GRB redshift. We find that $a$ and $b$ vary with the mean\nredshift of the GRBs in each group systematically and significantly.\nMonte-Carlo simulations show that there is only $\\sim 4$ percent of chance that\nthe variation is caused by the selection effect arising from the fluence limit.\nHence, our results may indicate that GRBs evolve strongly with the cosmological\nredshift.\n\n", "human_text": "  Because of the limit in the number of gamma-ray bursts (GRBs) with available\nredshifts and spectra, all current investigations on the correlation among GRB\nvariables use burst samples with redshifts that span a very large range. The\nevolution and selection effects have thus been ignored, which might have\nimportant influence on the results. In this Letter, we divide the 48\nlong-duration GRBs in Amati (2006, 2007) into four groups with redshift from\nlow to high, each group contains 12 GRBs. Then we fit each group with the Amati\nrelation $\\log E_\\iso = a + b \\log E_\\p$, and check if the parameters $a$ and\n$b$ evolve with the GRB redshift. We find that $a$ and $b$ vary with the mean\nredshift of the GRBs in each group systematically and significantly.\nMonte-Carlo simulations show that there is only $\\sim 4$ percent of chance that\nthe variation is caused by the selection effect arising from the fluence limit.\nHence, our results may indicate that GRBs evolve strongly with the cosmological\nredshift.\n", "machine_text": "This paper focuses on exploring the variation in the Amati relation\u2014the correlation between the energy of a gamma-ray burst (GRB) and its peak energy\u2014with the cosmological redshift. This investigates the evolution and selection effects of 48 long-duration GRBs from Amati (2006, 2007) divided into four groups with redshifts of increasing value, with each group containing 12 GRBs. Following a fitting to the data, it was found that the parameters $a$ and $b$ of the Amati relation varied systematically with the mean redshift of the bursts. Monte-Carlo simulations demonstrated that this variation was unlikely to be to due selection bias from flux limits, adding weight to the idea that GRBs evolve strongly with increasing redshift.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3128}
{"prompt": "Rephrase the abstract of an article with title 'Diffuse Gamma-Rays Produced in Cosmic-Ray Interactions and the TeV-band\n  Spectrum of RX J1713.7-3946'.\n  We employ the Monte Carlo particle collision code DPMJET3.04 to determine the\nmultiplicity spectra of various secondary particles (in addition to $\\pi^0$'s)\nwith $\\gamma$'s as the final decay state, that are produced in cosmic-ray\n($p$'s and $\\alpha$'s) interactions with the interstellar medium. We derive an\neasy-to-use $\\gamma$-ray production matrix for cosmic rays with energies up to\nabout 10 PeV. This $\\gamma$-ray production matrix is applied to the GeV excess\nin diffuse Galactic $\\gamma$-rays observed by EGRET, and we conclude the\nnon-$\\pi^0$ decay components are insufficient to explain the GeV excess,\nalthough they have contributed a different spectrum from the $\\pi^0$-decay\ncomponent. We also test the hypothesis that the TeV-band $\\gamma$-ray emission\nof the shell-type SNR RX J1713.7-3946 observed with HESS is caused by hadronic\ncosmic rays which are accelerated by a cosmic-ray modified shock. By the\n$\\chi^2$ statistics, we find a continuously softening spectrum is strongly\npreferred, in contrast to expectations. A hardening spectrum has about 1%\nprobability to explain the HESS data, but then only if a hard cutoff at 50-100\nTeV is imposed on the particle spectrum.\n\n", "human_text": "  We employ the Monte Carlo particle collision code DPMJET3.04 to determine the\nmultiplicity spectra of various secondary particles (in addition to $\\pi^0$'s)\nwith $\\gamma$'s as the final decay state, that are produced in cosmic-ray\n($p$'s and $\\alpha$'s) interactions with the interstellar medium. We derive an\neasy-to-use $\\gamma$-ray production matrix for cosmic rays with energies up to\nabout 10 PeV. This $\\gamma$-ray production matrix is applied to the GeV excess\nin diffuse Galactic $\\gamma$-rays observed by EGRET, and we conclude the\nnon-$\\pi^0$ decay components are insufficient to explain the GeV excess,\nalthough they have contributed a different spectrum from the $\\pi^0$-decay\ncomponent. We also test the hypothesis that the TeV-band $\\gamma$-ray emission\nof the shell-type SNR RX J1713.7-3946 observed with HESS is caused by hadronic\ncosmic rays which are accelerated by a cosmic-ray modified shock. By the\n$\\chi^2$ statistics, we find a continuously softening spectrum is strongly\npreferred, in contrast to expectations. A hardening spectrum has about 1%\nprobability to explain the HESS data, but then only if a hard cutoff at 50-100\nTeV is imposed on the particle spectrum.\n", "machine_text": "\nThis paper investigates the spectra of the secondary particles (other than $\\pi^0$'s) and $\\gamma$-rays produced in cosmic-ray ($p$'s and $\\alpha$'s) interactions with the interstellar medium. We use the Monte Carlo particle collision code DPMJET3.04 to derive an easy-to-use $\\gamma$-ray production matrix for cosmic rays with energies up to 10 PeV and apply it to the GeV excess in diffuse Galactic $\\gamma$-rays discovered by EGRET. Our conclusion is that the non-$\\pi^0$ decay components are not enough to explain the GeV excess, but do contribute a different spectrum to the $\\pi^0$-decay component. We also use the $\\chi^2$ statistics to evaluate the hypothesis that the TeV-band $\\gamma$-ray emission of the shell-type SNR RX J1713.7-3946 detected with HESS is caused by hadronic cosmic rays accelerated by a cosmic-ray modified shock. We find that a continuously softening spectrum is favoured, as opposed to an expected hardening. However, with a hard cutoff at 50-100 TeV, the hardening spectrum has about a 1% probability of explaining the HESS data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0506}
{"prompt": "Rephrase the abstract of an article with title 'A large scale extinction map of the Galactic Anticenter from 2MASS'.\n  We present a 127deg x 63deg extinction map of the Anticenter of the Galaxy,\nbased on <J-H> and <H-K> colour excess maps from 2MASS. This 8001 square degree\nmap with a resolution of 4 arcminutes is provided as online material. The\ncolour excess ratio <J-H> / <H-K> is used to determine the power law index of\nthe reddening law (\\beta) for individual regions contained in the area (e.g.\nOrion, Perseus, Taurus, Auriga, Monoceros, Camelopardalis, Cassiopeia). On\naverage we find a dominant value of \\beta=1.8+-0.2 for the individual clouds,\nin agreement with the canonical value for the interstellar medium. We also show\nthat there is an internal scatter of \\beta values in these regions, and that in\nsome areas more than one dominant \\beta value is present. This indicates large\nscale variations in the dust properties. The analysis of the A_V values within\nindividual regions shows a change in the slope of the column density\ndistribution with distance. This can either be attributed to a change in the\ngoverning physical processes in molecular clouds on spatial scales of about 1pc\nor an A_V dilution with distance in our map.\n\n", "human_text": "  We present a 127deg x 63deg extinction map of the Anticenter of the Galaxy,\nbased on <J-H> and <H-K> colour excess maps from 2MASS. This 8001 square degree\nmap with a resolution of 4 arcminutes is provided as online material. The\ncolour excess ratio <J-H> / <H-K> is used to determine the power law index of\nthe reddening law (\\beta) for individual regions contained in the area (e.g.\nOrion, Perseus, Taurus, Auriga, Monoceros, Camelopardalis, Cassiopeia). On\naverage we find a dominant value of \\beta=1.8+-0.2 for the individual clouds,\nin agreement with the canonical value for the interstellar medium. We also show\nthat there is an internal scatter of \\beta values in these regions, and that in\nsome areas more than one dominant \\beta value is present. This indicates large\nscale variations in the dust properties. The analysis of the A_V values within\nindividual regions shows a change in the slope of the column density\ndistribution with distance. This can either be attributed to a change in the\ngoverning physical processes in molecular clouds on spatial scales of about 1pc\nor an A_V dilution with distance in our map.\n", "machine_text": "We have constructed an extensive 8001 square degree extinction map of the Anticenter region of the Galaxy from 2MASS. This map is provided with a resolution of 4 arcminutes, and uses the <J-H> and <H-K> colour excess maps to determine the power law index of the reddening law (\\beta) for individual regions such as Orion, Perseus, Taurus, Auriga, Monoceros, Camelopardalis, and Cassiopeia. On average, we find the dominant value of \\beta to be 1.8+-0.2, in agreement with the interstellar medium. It was also observed that there is an internal scatter in \\beta values in these regions and that some areas have more than one dominant \\beta value present, which reveals considerable variation in the dust properties. Analysis of the visual extinction (A_V) values within individual regions further demonstrates a change in the slope of the column density distribution with distance, indicating a shift in the governing physical processes in the molecular clouds. Additionally, the map hints at a possible A_V dilution with distance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2993}
{"prompt": "Rephrase the abstract of an article with title 'Analytic steady-state space use patterns and rapid computations in\n  mechanistic home range analysis'.\n  Mechanistic home range models are important tools in modeling animal dynamics\nin spatially-complex environments. We introduce a class of stochastic models\nfor animal movement in a habitat of varying preference. Such models interpolate\nbetween spatially-implicit resource selection analysis (RSA) and\nadvection-diffusion models, possessing these two models as limiting cases. We\nfind a closed-form solution for the steady-state (equilibrium) probability\ndistribution u* using a factorization of the redistribution operator into\nsymmetric and diagonal parts. How space use is controlled by the preference\nfunction w then depends on the characteristic width of the redistribution\nkernel: when w changes rapidly compared to this width, u* ~ w, whereas on\nglobal scales large compared to this width, u* ~ w^2. We analyse the behavior\nat discontinuities in w which occur at habitat type boundaries. We simulate the\ndynamics of space use given two-dimensional prey-availability data and explore\nthe effect of the redistribution kernel width. Our factorization allows such\nnumerical simulations to be done extremely fast; we expect this to aid the\ncomputationally-intensive task of model parameter fitting and inverse modeling.\n\n", "human_text": "  Mechanistic home range models are important tools in modeling animal dynamics\nin spatially-complex environments. We introduce a class of stochastic models\nfor animal movement in a habitat of varying preference. Such models interpolate\nbetween spatially-implicit resource selection analysis (RSA) and\nadvection-diffusion models, possessing these two models as limiting cases. We\nfind a closed-form solution for the steady-state (equilibrium) probability\ndistribution u* using a factorization of the redistribution operator into\nsymmetric and diagonal parts. How space use is controlled by the preference\nfunction w then depends on the characteristic width of the redistribution\nkernel: when w changes rapidly compared to this width, u* ~ w, whereas on\nglobal scales large compared to this width, u* ~ w^2. We analyse the behavior\nat discontinuities in w which occur at habitat type boundaries. We simulate the\ndynamics of space use given two-dimensional prey-availability data and explore\nthe effect of the redistribution kernel width. Our factorization allows such\nnumerical simulations to be done extremely fast; we expect this to aid the\ncomputationally-intensive task of model parameter fitting and inverse modeling.\n", "machine_text": "This article explores the application of a stochastic model in the context of animal movement in an environment with varying preference. Our method involves the determination of a closed-form solution for the steady-state probability distribution using the factorization of the redistribution operator. We then determine how space use is affected by the preference function w, particularly in relation to the characteristic width of the redistribution kernel. Data simulations show insight into the effects of kernel width and we explore the behavior at discontinuities in w as well. This solution offers a rapid computation for model parameter fitting and inverse modeling that can be beneficial in home range analysis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3473}
{"prompt": "Rephrase the abstract of an article with title 'Luminosity function of binary X-ray sources calculated using the\n  Scenario Machine'.\n  Using the ``Scenario Machine'' we have carried out a population synthesis of\nX-ray binaries for the purpose of modelling of X-ray luminosity functions\n(XLFs) in different types of galaxies: star burst, spiral, and elliptical. This\ncomputer code allows to calculate, by using Monte Carlo simulations, the\nevolution of a large ensemble of binary systems, with proper accounting for the\nspin evolution of magnetized neutron stars.\n  We show that the XLF has no universal type. It depends on the star formation\nrate in the galaxy. Also it is of importance to take into account the evolution\nof binary systems and life times of X-ray stages in theoretical models of such\nfunctions. We have calculated cumulative and differential XLFs for the galaxy\nwith the constant star formation rate. Also we have calculated cumulative\nluminosity functions for different intervals of time after the star formation\nburst in the galaxy and curves depicting the evolution of the X-ray luminosity\nafter the star formation burst in the galaxy.\n\n", "human_text": "  Using the ``Scenario Machine'' we have carried out a population synthesis of\nX-ray binaries for the purpose of modelling of X-ray luminosity functions\n(XLFs) in different types of galaxies: star burst, spiral, and elliptical. This\ncomputer code allows to calculate, by using Monte Carlo simulations, the\nevolution of a large ensemble of binary systems, with proper accounting for the\nspin evolution of magnetized neutron stars.\n  We show that the XLF has no universal type. It depends on the star formation\nrate in the galaxy. Also it is of importance to take into account the evolution\nof binary systems and life times of X-ray stages in theoretical models of such\nfunctions. We have calculated cumulative and differential XLFs for the galaxy\nwith the constant star formation rate. Also we have calculated cumulative\nluminosity functions for different intervals of time after the star formation\nburst in the galaxy and curves depicting the evolution of the X-ray luminosity\nafter the star formation burst in the galaxy.\n", "machine_text": "\nThis research employs the ``Scenario Machine'' to analyze X-ray binaries and the X-ray luminosity functions (XLFs),in different types of galaxies. Monte Carlo simulations were used to simulate the evolution and spin of neutron stars, along with other binary systems. We found that the XLF for each galaxy depend on its star formation rate, as well as other evolutionary parameters of binary systems. We calculated the cumulative and differential XLFs for a constant star formation rate galaxy and other curves which depicted the evolution of the X-ray luminosity. This research revealed the effectiveness of the Scenario Machine in analyzing XLFs and helped to understand their dependence on the star formation rate and other important parameters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.286}
{"prompt": "Rephrase the abstract of an article with title 'Complexity Considerations, cSAT Lower Bound'.\n  This article discusses completeness of Boolean Algebra as First Order Theory\nin Goedel's meaning. If Theory is complete then any possible transformation is\nequivalent to some transformation using axioms, predicates etc. defined for\nthis theory. If formula is to be proved (or disproved) then it has to be\nreduced to axioms. If every transformation is deducible then also optimal\ntransformation is deducible. If every transformation is exponential then\noptimal one is too, what allows to define lower bound for discussed problem to\nbe exponential (outside P). Then we show algorithm for NDTM solving the same\nproblem in O(n^c) (so problem is in NP), what proves that P \\neq NP.\n  Article proves also that result of relativisation of P=NP question and oracle\nshown by Baker-Gill-Solovay distinguish between deterministic and\nnon-deterministic calculation models. If there exists oracle A for which\nP^A=NP^A then A consists of infinite number of algorithms, DTMs, axioms and\npredicates, or like NDTM infinite number of simultaneous states.\n\n", "human_text": "  This article discusses completeness of Boolean Algebra as First Order Theory\nin Goedel's meaning. If Theory is complete then any possible transformation is\nequivalent to some transformation using axioms, predicates etc. defined for\nthis theory. If formula is to be proved (or disproved) then it has to be\nreduced to axioms. If every transformation is deducible then also optimal\ntransformation is deducible. If every transformation is exponential then\noptimal one is too, what allows to define lower bound for discussed problem to\nbe exponential (outside P). Then we show algorithm for NDTM solving the same\nproblem in O(n^c) (so problem is in NP), what proves that P \\neq NP.\n  Article proves also that result of relativisation of P=NP question and oracle\nshown by Baker-Gill-Solovay distinguish between deterministic and\nnon-deterministic calculation models. If there exists oracle A for which\nP^A=NP^A then A consists of infinite number of algorithms, DTMs, axioms and\npredicates, or like NDTM infinite number of simultaneous states.\n", "machine_text": "This article focuses on the complexity considerations of cSAT, and provides a lower bound for the problem being exponential (outside of P). It presents an algorithm for solving the problem using an NDTM in O(n^c), thus proving that P does not equal NP. Furthermore, this article confirms the relativized P=NP question, as well as the oracle constructed by Baker-Gill-Solovay which distinguishes between deterministic and non-deterministic calculation models. It is demonstrated that if the P=NP question is to hold in an oracle A, then this oracle must consist of either an infinite number of algorithms, DTMs, axioms and predicates, or an infinite number of simultaneous states in an NDTM.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0514}
{"prompt": "Rephrase the abstract of an article with title 'A Systematic Scan for 7-colourings of the Grid'.\n  We study the mixing time of a systematic scan Markov chain for sampling from\nthe uniform distribution on proper 7-colourings of a finite rectangular\nsub-grid of the infinite square lattice, the grid. A systematic scan Markov\nchain cycles through finite-size subsets of vertices in a deterministic order\nand updates the colours assigned to the vertices of each subset. The systematic\nscan Markov chain that we present cycles through subsets consisting of 2x2\nsub-grids and updates the colours assigned to the vertices using a procedure\nknown as heat-bath. We give a computer-assisted proof that this systematic scan\nMarkov chain mixes in O(log n) scans, where n is the size of the rectangular\nsub-grid. We make use of a heuristic to compute required couplings of\ncolourings of 2x2 sub-grids. This is the first time the mixing time of a\nsystematic scan Markov chain on the grid has been shown to mix for less than 8\ncolours. We also give partial results that underline the challenges of proving\nrapid mixing of a systematic scan Markov chain for sampling 6-colourings of the\ngrid by considering 2x3 and 3x3 sub-grids.\n\n", "human_text": "  We study the mixing time of a systematic scan Markov chain for sampling from\nthe uniform distribution on proper 7-colourings of a finite rectangular\nsub-grid of the infinite square lattice, the grid. A systematic scan Markov\nchain cycles through finite-size subsets of vertices in a deterministic order\nand updates the colours assigned to the vertices of each subset. The systematic\nscan Markov chain that we present cycles through subsets consisting of 2x2\nsub-grids and updates the colours assigned to the vertices using a procedure\nknown as heat-bath. We give a computer-assisted proof that this systematic scan\nMarkov chain mixes in O(log n) scans, where n is the size of the rectangular\nsub-grid. We make use of a heuristic to compute required couplings of\ncolourings of 2x2 sub-grids. This is the first time the mixing time of a\nsystematic scan Markov chain on the grid has been shown to mix for less than 8\ncolours. We also give partial results that underline the challenges of proving\nrapid mixing of a systematic scan Markov chain for sampling 6-colourings of the\ngrid by considering 2x3 and 3x3 sub-grids.\n", "machine_text": "\nThis paper examines the mixing time of a systematic scan Markov chain for sampling from the uniform distribution of 7 colours on a finite rectangular sub-grid of the infinite square lattice, the grid. The systematic scan Markov chain cycles through 2x2 sub-grids to update the colour assignments to the vertices of the sub-grids using a technique known as heat-bath. We use computer-assisted proof to show that the chain mixes in O(log n) scans, where n is the size of the rectangular sub-grid. This is the first time rapid mixing of a systematic scan Markov chain has been demonstrated for less than 8 colours on the grid. In addition, our partial results help to highlight the challenges of proving rapid mixing of the chain for 6-colourings of the grid in the case of 2x3 and 3x3 sub-grids.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1625}
{"prompt": "Rephrase the abstract of an article with title 'The Wide Field Spectrograph (WiFeS)'.\n  This paper describes the Wide Field Spectrograph (WiFeS) under construction\nat the Research School of Astronomy and Astrophysics (RSAA) of the Australian\nNational University (ANU) for the ANU 2.3m telescope at the Siding Spring\nObservatory. WiFeS is a powerful integral field, double-beam, concentric,\nimage-slicing spectrograph designed to deliver excellent thoughput, wavelength\nstability, spectrophotometric performance and superb image quality along with\nwide spectral coverage throughout the 320-950 nm wavelength region. It provides\na 25x38 arcsec. field with 0.5 arcsec. sampling along each of twenty five 38X1\narcsec slitlets. The output format is optimized to match the 4096x4096 pixel\nCCD detectors in each of two cameras individually optimized for the blue and\nthe red ends of the spectrum, respectively. A process of \"interleaved\nnod-and-shuffle\" will be applied to permit quantum noise-limited sky\nsubtraction. Using VPH gratings, spectral resolutions of 3000 and 7000 are\nprovided. The full spectral range is covered in a single exposure at R=3000,\nand in two exposures in the R=7000 mode. The use of transmissive coated optics,\nVPH gratings and optimized mirror coatings ensures a throughput (including\ntelescope atmosphere and detector) > 30% over a wide spectral range. The\nconcentric image-slicer design ensures an excellent and uniform image quality\nacross the full field. To maximize scientific return, the whole instrument is\nconfigured for remote observing, pipeline data reduction, and the accumulation\nof calibration image libraries.\n\n", "human_text": "  This paper describes the Wide Field Spectrograph (WiFeS) under construction\nat the Research School of Astronomy and Astrophysics (RSAA) of the Australian\nNational University (ANU) for the ANU 2.3m telescope at the Siding Spring\nObservatory. WiFeS is a powerful integral field, double-beam, concentric,\nimage-slicing spectrograph designed to deliver excellent thoughput, wavelength\nstability, spectrophotometric performance and superb image quality along with\nwide spectral coverage throughout the 320-950 nm wavelength region. It provides\na 25x38 arcsec. field with 0.5 arcsec. sampling along each of twenty five 38X1\narcsec slitlets. The output format is optimized to match the 4096x4096 pixel\nCCD detectors in each of two cameras individually optimized for the blue and\nthe red ends of the spectrum, respectively. A process of \"interleaved\nnod-and-shuffle\" will be applied to permit quantum noise-limited sky\nsubtraction. Using VPH gratings, spectral resolutions of 3000 and 7000 are\nprovided. The full spectral range is covered in a single exposure at R=3000,\nand in two exposures in the R=7000 mode. The use of transmissive coated optics,\nVPH gratings and optimized mirror coatings ensures a throughput (including\ntelescope atmosphere and detector) > 30% over a wide spectral range. The\nconcentric image-slicer design ensures an excellent and uniform image quality\nacross the full field. To maximize scientific return, the whole instrument is\nconfigured for remote observing, pipeline data reduction, and the accumulation\nof calibration image libraries.\n", "machine_text": "\nThe Wide Field Spectrograph (WiFeS) is an integral field, double-beam, concentric, image-slicing spectrograph that is currently being built as part of the Australian National University's (ANU) 2.3m telescope located at the Siding Spring Observatory. It is designed to provide high throughput, wavelength accuracy, and spectrophotometric performance, in addition to a wide spectral coverage in the 320-950 nm range, along with excellent image quality. It features a 25x38 arcsec field with 0.5 arcsec sampling in twenty-five 38x1 arcsec slitlets. The two cameras are both CCD-based and optimized for their respective blue or red ends of the spectrum. To maximize sky subtraction, the \u201cinterleaved nod-and-shuffle\u201d process will be utilised. Along with Volume Phase Holographic (VPH) gratings offering resolutions of 3000 and 7000, 30% throughput (including atmosphere and detector) is also attained. The use of transmissive coated optics and optimised mirror coatings further enhances WiFeS's performance. In order to enrich the scientific output, all aspects of the instrument have been placed in a remote observing configuration, with pipeline data reduction and collated calibration image libraries available for use.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0287}
{"prompt": "Rephrase the abstract of an article with title 'Super Low Traction under EHD and Mixed Lubrication Regimes'.\n  After the pioneered experimental works on superlubricity by Martin et al. on\nMoS2 [1], Hirano et al. on tungsten and silicon [2] and the further\nconfirmation by Dienwiebel et al. on graphite [3], many groups around the word\ninvestigated the occurrence of near frictionless sliding contacts. This large\nmobilization of tribologists, material sciences specialists and physicists has\nlead to emerging solutions involving new materials and coatings, the most\npromising being carbon based like graphite, diamond, carbon composites or\ndiamond-like-carbons. Some of them are currently used in practical\napplications. The situation is different especially in EHL: the highest\nfriction coefficients are close to 10% when traction fluids are involved, i.e.\nfluids that have especially designed to transmit the highest friction, and they\nvary within 3-6% for the rest of lubricants. The range of variation is\nconsequently very narrow and these typical values are really low compared to\nthose obtained in dry contacts: as a consequence the gain expected from a super\nlow traction regime in lubrication will be probably more limited, especially in\nthe case of experiments conducted at the meso or macro scales. This weak\nperspective could be one explanation on the relatively low number of articles\nin recent literature dealing with lubricated superlubricity in the above\nconditions.\n\n", "human_text": "  After the pioneered experimental works on superlubricity by Martin et al. on\nMoS2 [1], Hirano et al. on tungsten and silicon [2] and the further\nconfirmation by Dienwiebel et al. on graphite [3], many groups around the word\ninvestigated the occurrence of near frictionless sliding contacts. This large\nmobilization of tribologists, material sciences specialists and physicists has\nlead to emerging solutions involving new materials and coatings, the most\npromising being carbon based like graphite, diamond, carbon composites or\ndiamond-like-carbons. Some of them are currently used in practical\napplications. The situation is different especially in EHL: the highest\nfriction coefficients are close to 10% when traction fluids are involved, i.e.\nfluids that have especially designed to transmit the highest friction, and they\nvary within 3-6% for the rest of lubricants. The range of variation is\nconsequently very narrow and these typical values are really low compared to\nthose obtained in dry contacts: as a consequence the gain expected from a super\nlow traction regime in lubrication will be probably more limited, especially in\nthe case of experiments conducted at the meso or macro scales. This weak\nperspective could be one explanation on the relatively low number of articles\nin recent literature dealing with lubricated superlubricity in the above\nconditions.\n", "machine_text": "This article presents an overview of the current research in superlubricity under mixed lubrication and EHD regimes. It summarizes the pioneering works of scientist such as Martin, Hirano, and Dienwiebel and further confirms their results. It also highlights the development of carbon-based coatings and materials being used in industrial applications. The article goes on to explain that while friction coefficients between 3-10% have been achieved in lubricant-based regimes, the gains from superlubricity in the meso- and macro-scales are expected to be somewhat limited. It wraps up with an analysis of fewer articles on lubricated superlubricity in recent literature, and offers a possible explanation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1799}
{"prompt": "Rephrase the abstract of an article with title 'Rigidity-dependent cosmic ray energy spectra in the knee region obtained\n  with the GAMMA experiment'.\n  On the basis of the extensive air shower (EAS) data obtained by the GAMMA\nexperiment, the energy spectra and elemental composition of the primary cosmic\nrays are derived in the 1-100 PeV energy range. The reconstruction of the\nprimary energy spectra is carried out using an EAS inverse approach in the\nframework of the SIBYLL2.1 and QGSJET01 interaction models and the hypothesis\nof power-law primary energy spectra with rigidity-dependent knees. The energy\nspectra of primary H, He, O-like and Fe-like nuclei obtained with the SIBYLL\ninteraction model agree with corresponding extrapolations of the balloon and\nsatellite data to ~1 PeV energies. The energy spectra obtained from the QGSJET\nmodel show a predominantly proton composition in the knee region. The\nrigidity-dependent knee feature of the primary energy spectra for each\ninteraction model is displayed at the following rigidities: ~2.5+/-0.2 PV\n(SIBYLL) and ~3.1-4.2 PV (QGSJET). All the results presented are derived taking\ninto account the detector response, the reconstruction uncertainties of the EAS\nparameters, and fluctuations in the EAS development.\n\n", "human_text": "  On the basis of the extensive air shower (EAS) data obtained by the GAMMA\nexperiment, the energy spectra and elemental composition of the primary cosmic\nrays are derived in the 1-100 PeV energy range. The reconstruction of the\nprimary energy spectra is carried out using an EAS inverse approach in the\nframework of the SIBYLL2.1 and QGSJET01 interaction models and the hypothesis\nof power-law primary energy spectra with rigidity-dependent knees. The energy\nspectra of primary H, He, O-like and Fe-like nuclei obtained with the SIBYLL\ninteraction model agree with corresponding extrapolations of the balloon and\nsatellite data to ~1 PeV energies. The energy spectra obtained from the QGSJET\nmodel show a predominantly proton composition in the knee region. The\nrigidity-dependent knee feature of the primary energy spectra for each\ninteraction model is displayed at the following rigidities: ~2.5+/-0.2 PV\n(SIBYLL) and ~3.1-4.2 PV (QGSJET). All the results presented are derived taking\ninto account the detector response, the reconstruction uncertainties of the EAS\nparameters, and fluctuations in the EAS development.\n", "machine_text": "\nUsing data collected by the GAMMA experiment, an exhaustive air shower (EAS)\ninverse approach was undertaken to explore the energy spectra and component\nstructure of cosmic ray primaries within a rigidity range of 1-100 PeV. Both\nthe SIBYLL2.1 and QGSJET01 interaction models were employed in this study and\npower-law primary energy spectra with rigidity-dependent knees were assumed.\nThe results show agreements between extrapolations of balloon and satellite\nmeasurements and the energies obtained from the SIBYLL model for H, He, O-lik\nand Fe-like nuclei. Within the QGSJET model, a mostly proton composition was\nobserved in the knee region. Analysis of the primary energy spectra found a\nrigidity-dependent knee feature in the models, occurring at 2.5\u00b10.2 PV (SIBYLL)\nand 3.1-4.2 PV (QGSJET). The precision of the results was ensured by\nconsideration of the detector response, EAS parameters, and fluctuations in\nEAS development.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.32}
{"prompt": "Rephrase the abstract of an article with title 'The importance of the merging activity for the kinetic polarization of\n  the Sunyaev-Zel'dovich signal from galaxy clusters'.\n  The polarization sensitivity of the upcoming millimetric observatories will\nopen new possibilities for studying the properties of galaxy clusters and for\nusing them as powerful cosmological probes. For this reason it is necessary to\ninvestigate in detail the characteristics of the polarization signals produced\nby their highly ionized intra-cluster medium (ICM). This work is focussed on\nthe polarization effect induced by the ICM bulk motions, the so-called kpSZ\nsignal, which has an amplitude proportional to the optical depth and to the\nsquare of the tangential velocity. In particular we study how this polarization\nsignal is affected by the internal dynamics of galaxy clusters and what is its\ndependence on the physical modelling adopted to describe the baryonic\ncomponent. This is done by producing realistic kpSZ maps starting from the\noutputs of two different sets of high-resolution hydrodynamical N-body\nsimulations. The first set (17 objects) follows only non-radiative\nhydrodynamics, while for each of 9 objects of the second set we implement four\ndifferent kinds of physical processes. Our results shows that the kpSZ signal\nturns out to be a very sensitive probe of the dynamical status of galaxy\nclusters. We find that major merger events can amplify the signal up to one\norder of magnitude with respect to relaxed clusters, reaching amplitude up to\nabout 100 nuK. This result implies that the internal ICM dynamics must be taken\ninto account when evaluating this signal because simplicistic models, based on\nspherical rigid bodies, may provide wrong estimates. Finally we find that the\ndependence on the physical modelling of the baryonic component is relevant only\nin the very inner regions of clusters.\n\n", "human_text": "  The polarization sensitivity of the upcoming millimetric observatories will\nopen new possibilities for studying the properties of galaxy clusters and for\nusing them as powerful cosmological probes. For this reason it is necessary to\ninvestigate in detail the characteristics of the polarization signals produced\nby their highly ionized intra-cluster medium (ICM). This work is focussed on\nthe polarization effect induced by the ICM bulk motions, the so-called kpSZ\nsignal, which has an amplitude proportional to the optical depth and to the\nsquare of the tangential velocity. In particular we study how this polarization\nsignal is affected by the internal dynamics of galaxy clusters and what is its\ndependence on the physical modelling adopted to describe the baryonic\ncomponent. This is done by producing realistic kpSZ maps starting from the\noutputs of two different sets of high-resolution hydrodynamical N-body\nsimulations. The first set (17 objects) follows only non-radiative\nhydrodynamics, while for each of 9 objects of the second set we implement four\ndifferent kinds of physical processes. Our results shows that the kpSZ signal\nturns out to be a very sensitive probe of the dynamical status of galaxy\nclusters. We find that major merger events can amplify the signal up to one\norder of magnitude with respect to relaxed clusters, reaching amplitude up to\nabout 100 nuK. This result implies that the internal ICM dynamics must be taken\ninto account when evaluating this signal because simplicistic models, based on\nspherical rigid bodies, may provide wrong estimates. Finally we find that the\ndependence on the physical modelling of the baryonic component is relevant only\nin the very inner regions of clusters.\n", "machine_text": "\nThe potential for millimetric observatories to explore the polarization signals generated by highly ionized intra-cluster media (ICM) necessitates a closer examination of the characteristics of such signals. In particular, this work studies the impact of bulk ICM motions, called the kpSZ signal, on the polarization effect, which has an amplitude that is proportional to the optical depths and squared tangential velocity. To analyze this, two sets of high-resolution hydrodynamical N-body simulations were used to generate realistic kpSZ maps. The first set included 17 objects with non-radiative hydrodynamics while the second set included 9 objects with four differently-implemented physical processes. The results highlighted that the kpSZ signal is highly sensitive to the dynamics of galaxy clusters, and major mergers can amplify the signal an order of magnitude amounting up to 100 nuK. It was found that simplicistic models with spherical rigid bodies do not necessarily provide accurate estimates and the dependence on the physics of the baryonic component was only observed within the inner regions of clusters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.083}
{"prompt": "Rephrase the abstract of an article with title 'Separability Criterion for multipartite quantum states based on the\n  Bloch representation of density matrices'.\n  We give a new separability criterion, a necessary condition for separability\nof $N$-partite quantum states. The criterion is based on the Bloch\nrepresentation of a $N$-partite quantum state and makes use of multilinear\nalgebra, in particular, the matrization of tensors. Our criterion applies to\n{\\it arbitrary} $N$-partite quantum states in\n$\\mathcal{H}=\\mathcal{H}^{d_1}\\otimes \\mathcal{H}^{d_2} \\otimes ... \\otimes\n\\mathcal{H}^{d_N}.$ The criterion can test whether a $N$-partite state is\nentangled and can be applied to different partitions of the $N$-partite system.\nWe provide examples that show the ability of this criterion to detect\nentanglement. We show that this criterion can detect bound entangled states. We\nprove a sufficiency condition for separability of a 3-partite state,\nstraightforwardly generalizable to the case $N > 3,$ under certain condition.\nWe also give a necessary and sufficient condition for separability of a class\nof $N$-qubit states which includes $N$-qubit PPT states.\n\n", "human_text": "  We give a new separability criterion, a necessary condition for separability\nof $N$-partite quantum states. The criterion is based on the Bloch\nrepresentation of a $N$-partite quantum state and makes use of multilinear\nalgebra, in particular, the matrization of tensors. Our criterion applies to\n{\\it arbitrary} $N$-partite quantum states in\n$\\mathcal{H}=\\mathcal{H}^{d_1}\\otimes \\mathcal{H}^{d_2} \\otimes ... \\otimes\n\\mathcal{H}^{d_N}.$ The criterion can test whether a $N$-partite state is\nentangled and can be applied to different partitions of the $N$-partite system.\nWe provide examples that show the ability of this criterion to detect\nentanglement. We show that this criterion can detect bound entangled states. We\nprove a sufficiency condition for separability of a 3-partite state,\nstraightforwardly generalizable to the case $N > 3,$ under certain condition.\nWe also give a necessary and sufficient condition for separability of a class\nof $N$-qubit states which includes $N$-qubit PPT states.\n", "machine_text": "\nThis paper presents a new separability criterion, which is necessary for separability of $N$-partite quantum states. The criterion is based on the Bloch representation of the density matrix of the $N$-partite system. Utilizing multilinear algebra and tensor matrization, the criterion can test states with {\\it any} dimensions $\\mathcal{H}=\\mathcal{H}^{d_1}\\otimes \\mathcal{H}^{d_2} \\otimes ... \\otimes\n\\mathcal{H}^{d_N}$. We provide demonstrative examples of the practicality of the criterion in detecting entanglement of different partitions, including bound entangled states. Furthermore, we offer a sufficiency condition for separability of a 3-partite system that is extensible to any $N>3$ under necessary conditions. We additionally display a necessary and sufficient condition for separability of a class of $N$-qubit states, containing PPT states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3942}
{"prompt": "Rephrase the abstract of an article with title 'An X-ray Imaging Study of the Stellar Population in RCW49'.\n  We present the results of a high-resolution X-ray imaging study of the\nstellar population in the Galactic massive star-forming region RCW49 and its\ncentral OB association Westerlund 2. We obtained a 40 ks X-ray image of a\n17'x17' field using the Chandra X-ray Observatory and deep NIR images using the\nInfrared Survey Facility in a concentric 8'3x8'3 region. We detected 468 X-ray\nsources and identified optical, NIR, and Spitzer Space Telescope MIR\ncounterparts for 379 of them. The unprecedented spatial resolution and\nsensitivity of the X-ray image, enhanced by optical and infrared imaging data,\nyielded the following results: (1) The central OB association Westerlund 2 is\nresolved for the first time in the X-ray band. X-ray emission is detected from\nall spectroscopically-identified early-type stars in this region. (2) Most\n(86%) X-ray sources with optical or infrared identifications are cluster\nmembers in comparison with a control field in the Galactic Plane. (3) A loose\nconstraint (2--5 kpc) for the distance to RCW49 is derived from the mean X-ray\nluminosity of T Tauri stars. (4) The cluster X-ray population consists of\nlow-mass pre--main-sequence and early-type stars as obtained from X-ray and NIR\nphotometry. About 30 new OB star candidates are identified. (5) We estimate a\ncluster radius of 6'--7' based on the X-ray surface number density profiles.\n(6) A large fraction (90%) of cluster members are identified individually using\ncomplimentary X-ray and MIR excess emission. (7) The brightest five X-ray\nsources, two Wolf-Rayet stars and three O stars, have hard thermal spectra.\n\n", "human_text": "  We present the results of a high-resolution X-ray imaging study of the\nstellar population in the Galactic massive star-forming region RCW49 and its\ncentral OB association Westerlund 2. We obtained a 40 ks X-ray image of a\n17'x17' field using the Chandra X-ray Observatory and deep NIR images using the\nInfrared Survey Facility in a concentric 8'3x8'3 region. We detected 468 X-ray\nsources and identified optical, NIR, and Spitzer Space Telescope MIR\ncounterparts for 379 of them. The unprecedented spatial resolution and\nsensitivity of the X-ray image, enhanced by optical and infrared imaging data,\nyielded the following results: (1) The central OB association Westerlund 2 is\nresolved for the first time in the X-ray band. X-ray emission is detected from\nall spectroscopically-identified early-type stars in this region. (2) Most\n(86%) X-ray sources with optical or infrared identifications are cluster\nmembers in comparison with a control field in the Galactic Plane. (3) A loose\nconstraint (2--5 kpc) for the distance to RCW49 is derived from the mean X-ray\nluminosity of T Tauri stars. (4) The cluster X-ray population consists of\nlow-mass pre--main-sequence and early-type stars as obtained from X-ray and NIR\nphotometry. About 30 new OB star candidates are identified. (5) We estimate a\ncluster radius of 6'--7' based on the X-ray surface number density profiles.\n(6) A large fraction (90%) of cluster members are identified individually using\ncomplimentary X-ray and MIR excess emission. (7) The brightest five X-ray\nsources, two Wolf-Rayet stars and three O stars, have hard thermal spectra.\n", "machine_text": "\nThis high-resolution X-ray imaging study of the stellar population in the Galactic massive star-forming region RCW49 and its central OB association Westerlund 2, obtained with the Chandra X-ray Observatory and the Infrared Survey Facility, has yielded a number of insights about the region. We were successful in resolving Westerlund 2 for the first time in X-ray and found over eighty percent of the X-ray sources with optical or infrared identifications to be cluster members. We further estimated a 2-5 kpc distance for RCW49 from the mean X-ray luminosities of T Tauri stars, identified 30 new OB star candidates, estimated a 6-7' cluster radius based on the X-ray surface number density profiles, and found 90% of the cluster members to be individually identified using X-ray and MIR excess emission. The five brightest X-ray sources, two Wolf-Rayet stars and three O stars, showed hard thermal spectra.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0702}
{"prompt": "Rephrase the abstract of an article with title 'Testing String Theory with CMB'.\n  Future detection/non-detection of tensor modes from inflation in CMB\nobservations presents a unique way to test certain features of string theory.\nCurrent limit on the ratio of tensor to scalar perturbations, r=T/S, is r <\n0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all\nknown string theory inflation models predict tensor modes well below the level\nof detection. Therefore a possible experimental discovery of tensor modes may\npresent a challenge to string cosmology.\n  The strongest bound on r in string inflation follows from the observation\nthat in most of the models based on the KKLT construction, the value of the\nHubble constant H during inflation must be smaller than the gravitino mass. For\nthe gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an\nextremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r\n> 10^{-3} would imply that the gravitinos in this class of models are\nsuperheavy, m_{3/2} > 10^{13} GeV. This would have important implications for\nparticle phenomenology based on string theory.\n\n", "human_text": "  Future detection/non-detection of tensor modes from inflation in CMB\nobservations presents a unique way to test certain features of string theory.\nCurrent limit on the ratio of tensor to scalar perturbations, r=T/S, is r <\n0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all\nknown string theory inflation models predict tensor modes well below the level\nof detection. Therefore a possible experimental discovery of tensor modes may\npresent a challenge to string cosmology.\n  The strongest bound on r in string inflation follows from the observation\nthat in most of the models based on the KKLT construction, the value of the\nHubble constant H during inflation must be smaller than the gravitino mass. For\nthe gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an\nextremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r\n> 10^{-3} would imply that the gravitinos in this class of models are\nsuperheavy, m_{3/2} > 10^{13} GeV. This would have important implications for\nparticle phenomenology based on string theory.\n", "machine_text": "By examining CMB data, the validity of string theory can be tested. The current upper limit on the ratio of tensor to scalar perturbations, r=T/S, is r < 0.3. Future detection of tensor modes may occur in the range of r > 10^{-2} - 10^{-3}. In traditional string theory inflation models, this would present a challenge as it predicts that these tensor values will remain far below the level of detection. In relation, the KKLT construction limits the Hubble constant H during inflation to a value smaller than the gravitino mass, resulting in an upper bound of r < 10^{-24}. If this is seen, then it would suggest the gravitinos in this model would be superheavy, m_{3/2} > 10^{13} GeV, providing significant implications for particle phenomenology associated with string theory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0647}
{"prompt": "Rephrase the abstract of an article with title 'The Magnetic Sensitivity of the Ba II D1 and D2 Lines of the Fraunhofer\n  Spectrum'.\n  The physical interpretation of the spectral line polarization produced by the\njoint action of the Hanle and Zeeman effects offers a unique opportunity to\nobtain empirical information about hidden aspects of solar and stellar\nmagnetism. To this end, it is important to achieve a complete understanding of\nthe sensitivity of the emergent spectral line polarization to the presence of a\nmagnetic field. Here we present a detailed theoretical investigation on the\nrole of resonance scattering and magnetic fields on the polarization signals of\nthe Ba II D1 and D2 lines of the Fraunhofer spectrum, respectively at 4934 \\AA\\\nand 4554 \\AA. We adopt a three-level model of Ba II, and we take into account\nthe hyperfine structure that is shown by the $^{135}$Ba and $^{137}$Ba\nisotopes. Despite of their relatively small abundance (18%), the contribution\ncoming from these two isotopes is indeed fundamental for the interpretation of\nthe polarization signals observed in these lines. We consider an optically thin\nslab model, through which we can investigate in a rigorous way the essential\nphysical mechanisms involved (resonance polarization, Zeeman, Paschen-Back and\nHanle effects), avoiding complications due to radiative transfer effects. We\nassume the slab to be illuminated from below by the photospheric solar\ncontinuum radiation field, and we investigate the radiation scattered at 90\ndegrees, both in the absence and in the presence of magnetic fields,\ndeterministic and microturbulent. We show in particular the existence of a\ndifferential magnetic sensitivity of the three-peak Q/I profile that is\nobserved in the D2 line in quiet regions close to the solar limb, which is of\ngreat interest for magnetic field diagnostics.\n\n", "human_text": "  The physical interpretation of the spectral line polarization produced by the\njoint action of the Hanle and Zeeman effects offers a unique opportunity to\nobtain empirical information about hidden aspects of solar and stellar\nmagnetism. To this end, it is important to achieve a complete understanding of\nthe sensitivity of the emergent spectral line polarization to the presence of a\nmagnetic field. Here we present a detailed theoretical investigation on the\nrole of resonance scattering and magnetic fields on the polarization signals of\nthe Ba II D1 and D2 lines of the Fraunhofer spectrum, respectively at 4934 \\AA\\\nand 4554 \\AA. We adopt a three-level model of Ba II, and we take into account\nthe hyperfine structure that is shown by the $^{135}$Ba and $^{137}$Ba\nisotopes. Despite of their relatively small abundance (18%), the contribution\ncoming from these two isotopes is indeed fundamental for the interpretation of\nthe polarization signals observed in these lines. We consider an optically thin\nslab model, through which we can investigate in a rigorous way the essential\nphysical mechanisms involved (resonance polarization, Zeeman, Paschen-Back and\nHanle effects), avoiding complications due to radiative transfer effects. We\nassume the slab to be illuminated from below by the photospheric solar\ncontinuum radiation field, and we investigate the radiation scattered at 90\ndegrees, both in the absence and in the presence of magnetic fields,\ndeterministic and microturbulent. We show in particular the existence of a\ndifferential magnetic sensitivity of the three-peak Q/I profile that is\nobserved in the D2 line in quiet regions close to the solar limb, which is of\ngreat interest for magnetic field diagnostics.\n", "machine_text": "\nThis paper presents a theoretical study of the impact of resonance scattering and magnetic fields on the degree and pattern of polarization in the Ba II D1 and D2 lines of the Fraunhofer spectrum -- at 4934 \\AA\\ and 4554 \\AA\\, respectively. A three-level atomic model of Ba II is used, and we take into account the hyperfine structure brought on by the $^{135}$Ba and $^{137}$Ba isotopes -- though their abundance is comparatively small (18%). Our approach utilizes an optically thin slab model, which permits us to investigate the impact of the major physical mechanisms (e.g. resonance polarization, Zeeman, Paschen-Back, and Hanle effects) in an orderly manner. We use the solar photospheric continuum radiation field to illuminate the slab from below, and study the scattered light at 90 degrees for both zero and arbitrary magnetic field strengths. Interestingly, our results point toward a differentially magnetically sensitive three-peak Q/I profile that is found in the D2 line within the solar limb. This detail has relevance for magnetic field diagnostics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3979}
{"prompt": "Rephrase the abstract of an article with title 'Geometrically frustrated magnetic behavior of Sr3NiRhO6 and Sr3NiPtO6'.\n  The results of ac and dc magnetic susceptibility isothermal magnetization and\nheat-capacity measurements as a function of temperature (T) are reported for\nSr3NiRhO6 and Sr3NiPtO6 containing magnetic chains arranged in a triangular\nfashion in the basal plane and crystallizing in K4CdCl6-derived rhombohedral\nstructure. The results establish that both the compounds are magnetically\nfrustrated, however in different ways. In the case of the Rh compound, the\nsusceptibility data reveal that there are two magnetic transitions, one in the\nrange 10 -15 K and the other appearing as a smooth crossover near 45 K, with a\nlarge frequency dependence of ac susceptibility in the range 10 to 40 K; in\naddition, the features in C(T) are smeared out at these temperatures. The\nmagnetic properties are comparable to those of previously known few compounds\nwith partially disordered antiferromagnetic structure. On the other hand, for\nSr3NiPtO6, there is no evidence for long-range magnetic ordering down to 1.8 K\ndespite large value of paramagnetic Curie temperature.\n\n", "human_text": "  The results of ac and dc magnetic susceptibility isothermal magnetization and\nheat-capacity measurements as a function of temperature (T) are reported for\nSr3NiRhO6 and Sr3NiPtO6 containing magnetic chains arranged in a triangular\nfashion in the basal plane and crystallizing in K4CdCl6-derived rhombohedral\nstructure. The results establish that both the compounds are magnetically\nfrustrated, however in different ways. In the case of the Rh compound, the\nsusceptibility data reveal that there are two magnetic transitions, one in the\nrange 10 -15 K and the other appearing as a smooth crossover near 45 K, with a\nlarge frequency dependence of ac susceptibility in the range 10 to 40 K; in\naddition, the features in C(T) are smeared out at these temperatures. The\nmagnetic properties are comparable to those of previously known few compounds\nwith partially disordered antiferromagnetic structure. On the other hand, for\nSr3NiPtO6, there is no evidence for long-range magnetic ordering down to 1.8 K\ndespite large value of paramagnetic Curie temperature.\n", "machine_text": "\nAn investigation of Sr3NiRhO6 and Sr3NiPtO6 has been conducted to evaluate the geometrically frustrated magnetic behavior. These compounds feature a triangular lattice of magnetic chains in the basal plane, and a K4CdCl6-derived rhombohedral structure. It has been determined that the properties of Sr3NiRhO6 follow what is usually observed in materials with partially disordered antiferromagnetic structure, presenting two magnetic transitions in the range 10\u201015 K and a crossover at 45 K with a large frequency dependence of ac susceptibility within 10\u201040 K. In the case of Sr3NiPtO6, the paramagnetic Curie temperature is quite high, yet there is no evidence of long-range magnetic ordering down to 1.8 K.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1308}
{"prompt": "Rephrase the abstract of an article with title 'Approche variationnelle pour le calcul bay\\'esien dans les probl\\`emes\n  inverses en imagerie'.\n  In a non supervised Bayesian estimation approach for inverse problems in\nimaging systems, one tries to estimate jointly the unknown image pixels $\\fb$\nand the hyperparameters $\\thetab$. This is, in general, done through the joint\nposterior law $p(\\fb,\\thetab|\\gb)$. The expression of this joint law is often\nvery complex and its exploration through sampling and computation of the point\nestimators such as MAP and posterior means need either optimization of non\nconvex criteria or int\\'egration of non Gaussian and multi variate probability\nlaws. In any of these cases, we need to do approximations. We had explored\nbefore the possibilities of Laplace approximation and sampling by MCMC. In this\npaper, we explore the possibility of approximating this joint law by a\nseparable one in $\\fb$ and in $\\thetab$. This gives the possibility of\ndeveloping iterative algorithms with more reasonable computational cost, in\nparticular, if the approximating laws are choosed in the exponential conjugate\nfamilies. The main objective of this paper is to give details of different\nalgorithms we obtain with different choices of these families.\n\n", "human_text": "  In a non supervised Bayesian estimation approach for inverse problems in\nimaging systems, one tries to estimate jointly the unknown image pixels $\\fb$\nand the hyperparameters $\\thetab$. This is, in general, done through the joint\nposterior law $p(\\fb,\\thetab|\\gb)$. The expression of this joint law is often\nvery complex and its exploration through sampling and computation of the point\nestimators such as MAP and posterior means need either optimization of non\nconvex criteria or int\\'egration of non Gaussian and multi variate probability\nlaws. In any of these cases, we need to do approximations. We had explored\nbefore the possibilities of Laplace approximation and sampling by MCMC. In this\npaper, we explore the possibility of approximating this joint law by a\nseparable one in $\\fb$ and in $\\thetab$. This gives the possibility of\ndeveloping iterative algorithms with more reasonable computational cost, in\nparticular, if the approximating laws are choosed in the exponential conjugate\nfamilies. The main objective of this paper is to give details of different\nalgorithms we obtain with different choices of these families.\n", "machine_text": "\nThis paper explores the idea of approximating the joint posterior law $p(\\fb,\\thetab|\\gb)$ that is commonly used in unsupervised Bayesian estimation for inverse problems in imaging systems. In doing so, the goal is to obtain a simpler expression of the form of a separable law for both $\\fb$ and $\\thetab$, thereby, allowing for the development of iterative algorithms with lesser computational cost. Specifically, such approximations involve the use of exponential conjugate families and this paper provides details of the different algorithms that were obtained from different choices of these families. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1914}
{"prompt": "Rephrase the abstract of an article with title 'A Planetary System Around HD 155358: The Lowest Metallicity Planet Host\n  Star'.\n  We report the detection of two planetary mass companions to the solar-type\nstar HD 155358. The two planets have orbital periods of 195.0 and 530.3 days,\nwith eccentricities of 0.11 and 0.18. The minimum masses for these planets are\n0.89 and 0.50 Jupiter masses respectively. The orbits are close enough to each\nother, and the planets are sufficiently massive, that the planets are\ngravitationally interacting with each other, with their eccentricities and\narguments of periastron varying with periods of 2300--2700 years. While large\nuncertainties remain in the orbital eccentricities, our orbital integration\ncalculations indicate that our derived orbits would be dynamically stable for\nat least 10^8 years. With a metallicity [Fe/H] of -0.68, HD 155358 is tied with\nthe K1III giant planet host star HD 47536 for the lowest metallicity of any\nplanet host star yet found. Thus, a star with only 21% of the heavy-element\ncontent of our Sun was still able to form a system of at least two Jovian-mass\nplanets and have their orbits evolve to semi-major axes of 0.6-1.2 AU.\n\n", "human_text": "  We report the detection of two planetary mass companions to the solar-type\nstar HD 155358. The two planets have orbital periods of 195.0 and 530.3 days,\nwith eccentricities of 0.11 and 0.18. The minimum masses for these planets are\n0.89 and 0.50 Jupiter masses respectively. The orbits are close enough to each\nother, and the planets are sufficiently massive, that the planets are\ngravitationally interacting with each other, with their eccentricities and\narguments of periastron varying with periods of 2300--2700 years. While large\nuncertainties remain in the orbital eccentricities, our orbital integration\ncalculations indicate that our derived orbits would be dynamically stable for\nat least 10^8 years. With a metallicity [Fe/H] of -0.68, HD 155358 is tied with\nthe K1III giant planet host star HD 47536 for the lowest metallicity of any\nplanet host star yet found. Thus, a star with only 21% of the heavy-element\ncontent of our Sun was still able to form a system of at least two Jovian-mass\nplanets and have their orbits evolve to semi-major axes of 0.6-1.2 AU.\n", "machine_text": "\nWe present the discovery of two Jovian-mass planets orbiting a solar-like star: HD 155358. The planets, found with orbital periods of 195.0 and 530.3 days and eccentricities of 0.11 and 0.18 respectively, interact to influence each other's eccentricities and periastron passages in orbits lasting at least 10^8 years. This host star is remarkable for its record-low metallicity of -0.68, only 21% of the heavy-element content of our Sun. Despite the lack of heavy element content, the system still facilitated formation of at least two planets with semi-major axes at 0.6-1.2 AU.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3228}
{"prompt": "Rephrase the abstract of an article with title 'EF Cha: Warm Dust Orbiting a Nearby 10 Myr Old Star'.\n  Most Vega-like stars have far-infrared excess (60micron or longward in IRAS,\nISO, or Spitzer MIPS bands) and contain cold dust (<~150K) analogous to the\nSun's Kuiper-Belt region. However, dust in a region more akin to our asteroid\nbelt and thus relevant to the terrestrial planet building process is warm and\nproduces excess emission in mid-infrared wavelengths. By cross-correlating\nHipparcos dwarfs with the MSX catalog, we found that EF Cha, a member of the\nrecently identified, ~10 Myr old, ``Cha-Near'' Moving Group, possesses\nprominent mid-infrared excess. N-band spectroscopy reveals a strong emission\nfeature characterized by a mixture of small, warm, amorphous and possibly\ncrystalline silicate grains. Survival time of warm dust grains around this A9\nstar is <~ 1E5 yrs, much less than the age of the star. Thus, grains in this\nextra-solar terrestrial planetary zone must be of \"second generation\" and not a\nremnant of primodial dust and are suggestive of substantial planet formation\nactivity. Such second generation warm excess occurs around ~ 13% of the\nearly-type stars in nearby young stellar associations.\n\n", "human_text": "  Most Vega-like stars have far-infrared excess (60micron or longward in IRAS,\nISO, or Spitzer MIPS bands) and contain cold dust (<~150K) analogous to the\nSun's Kuiper-Belt region. However, dust in a region more akin to our asteroid\nbelt and thus relevant to the terrestrial planet building process is warm and\nproduces excess emission in mid-infrared wavelengths. By cross-correlating\nHipparcos dwarfs with the MSX catalog, we found that EF Cha, a member of the\nrecently identified, ~10 Myr old, ``Cha-Near'' Moving Group, possesses\nprominent mid-infrared excess. N-band spectroscopy reveals a strong emission\nfeature characterized by a mixture of small, warm, amorphous and possibly\ncrystalline silicate grains. Survival time of warm dust grains around this A9\nstar is <~ 1E5 yrs, much less than the age of the star. Thus, grains in this\nextra-solar terrestrial planetary zone must be of \"second generation\" and not a\nremnant of primodial dust and are suggestive of substantial planet formation\nactivity. Such second generation warm excess occurs around ~ 13% of the\nearly-type stars in nearby young stellar associations.\n", "machine_text": "\nA recent survey has identified that EF Cha, a particular star within the Cha-Near Moving Group, is approximately 10 million years old and is situated close to us. By utilizing the Hipparcos dwarfs and MSX catalog, a prominent mid-infrared surplus was found with a copious emission feature generated by small warm amorphous and possibly crystalline silicate particles. This is suggestive of the presence of active planet formation occurring in an area that resembles the asteroid belt in our own Solar System. As the dust grains do not last longer than 100,000 years, it is clear that the warm surplus must be composed of second generation grains and not by primeval dust. Moreover, it has been found that this is the case for around 13% of the early type stars located in nearby young stellar associations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1265}
{"prompt": "Rephrase the abstract of an article with title 'High angular resolution imaging of the circumstellar material around\n  intermediate mass (IM) stars'.\n  In this Paper we present high angular resolution imaging of 3\nintermediate-mass (IM) stars using the Plateau de Bure Interferometer (PdBI).\nIn particular we present the chemical study we have carried out towards the IM\nhot core NGC 7129--FIRS 2. This is the first chemical study in an IM hot core\nand provides important hints to understand the dependence of the hot core\nchemistry on the stellar luminosity. We also present our high angular\nresolution (0.3\") images of the borderline Class 0-Class I object IC1396 N.\nThese images trace the warm region of this IM protostar with unprecedent detail\n(0.3\"\\sim200 AU at the distance of IC1396 N) and provide the first detection of\na cluster of IM hot cores. Finally, we present our interferometric continuum\nand spectroscopic images of the disk around the Herbig Be star R Mon. We have\ndetermined the kinematics and physical structure of the disk associated with\nthis B0 star. The low spectral index derived from the dust emission as well as\nthe flat geometry of the disk suggest a more rapid evolution of the disks\nassociated with massive stars. In the Discussion, we dare to propose a possible\nevolutionary sequence for the warm circumstellar material around IM stars.\n\n", "human_text": "  In this Paper we present high angular resolution imaging of 3\nintermediate-mass (IM) stars using the Plateau de Bure Interferometer (PdBI).\nIn particular we present the chemical study we have carried out towards the IM\nhot core NGC 7129--FIRS 2. This is the first chemical study in an IM hot core\nand provides important hints to understand the dependence of the hot core\nchemistry on the stellar luminosity. We also present our high angular\nresolution (0.3\") images of the borderline Class 0-Class I object IC1396 N.\nThese images trace the warm region of this IM protostar with unprecedent detail\n(0.3\"\\sim200 AU at the distance of IC1396 N) and provide the first detection of\na cluster of IM hot cores. Finally, we present our interferometric continuum\nand spectroscopic images of the disk around the Herbig Be star R Mon. We have\ndetermined the kinematics and physical structure of the disk associated with\nthis B0 star. The low spectral index derived from the dust emission as well as\nthe flat geometry of the disk suggest a more rapid evolution of the disks\nassociated with massive stars. In the Discussion, we dare to propose a possible\nevolutionary sequence for the warm circumstellar material around IM stars.\n", "machine_text": "\nUsing the Plateau de Bure Interferometer (PdBI), this paper provides detailed high angular resolution imaging of the warm circumstellar material around three intermediate-mass (IM) stars. We present our findings of an in-depth chemical study conducted at the IM hot core NGC 7129-FIRS 2, which is the first to be studied in this area and offers new insights into the connection between stellar luminosity and hot core chemistry. Subsequently, we demonstrate our 0.3\" (200 AU) resolution imaging of the IM protostar IC1396 N, showing a newly detected cluster of IM hot cores and tracing the warm region in unprecedented detail. Finally, with dust emission and flat geometry inferring rapid evolution, we present our interferometric continuum and spectroscopic images of the disk around the Herbig Be star R Mon. Concluding the paper, a possible evolutionary sequence is proposed for the warm circumstellar material around IM stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3725}
{"prompt": "Rephrase the abstract of an article with title 'Ly-alpha Emission-Line Galaxies at z = 3.1 in the Extended Chandra Deep\n  Field South'.\n  We describe the results of an extremely deep, 0.28 deg^2 survey for z = 3.1\nLy-alpha emission-line galaxies in the Extended Chandra Deep Field South. By\nusing a narrow-band 5000 Anstrom filter and complementary broadband photometry\nfrom the MUSYC survey, we identify a statistically complete sample of 162\ngalaxies with monochromatic fluxes brighter than 1.5 x 10^-17 ergs cm^-2 s^-1\nand observers frame equivalent widths greater than 80 Angstroms. We show that\nthe equivalent width distribution of these objects follows an exponential with\na rest-frame scale length of w_0 = 76 +/- 10 Angstroms. In addition, we show\nthat in the emission line, the luminosity function of Ly-alpha galaxies has a\nfaint-end power-law slope of alpha = -1.49 +/- 0.4, a bright-end cutoff of log\nL^* = 42.64 +/- 0.2, and a space density above our detection thresholds of 1.46\n+/- 0.12 x 10^-3 h70^3 galaxies Mpc^-3. Finally, by comparing the emission-line\nand continuum properties of the LAEs, we show that the star-formation rates\nderived from Ly-alpha are ~3 times lower than those inferred from the\nrest-frame UV continuum. We use this offset to deduce the existence of a small\namount of internal extinction within the host galaxies. This extinction,\ncoupled with the lack of extremely-high equivalent width emitters, argues that\nthese galaxies are not primordial Pop III objects, though they are young and\nrelatively chemically unevolved.\n\n", "human_text": "  We describe the results of an extremely deep, 0.28 deg^2 survey for z = 3.1\nLy-alpha emission-line galaxies in the Extended Chandra Deep Field South. By\nusing a narrow-band 5000 Anstrom filter and complementary broadband photometry\nfrom the MUSYC survey, we identify a statistically complete sample of 162\ngalaxies with monochromatic fluxes brighter than 1.5 x 10^-17 ergs cm^-2 s^-1\nand observers frame equivalent widths greater than 80 Angstroms. We show that\nthe equivalent width distribution of these objects follows an exponential with\na rest-frame scale length of w_0 = 76 +/- 10 Angstroms. In addition, we show\nthat in the emission line, the luminosity function of Ly-alpha galaxies has a\nfaint-end power-law slope of alpha = -1.49 +/- 0.4, a bright-end cutoff of log\nL^* = 42.64 +/- 0.2, and a space density above our detection thresholds of 1.46\n+/- 0.12 x 10^-3 h70^3 galaxies Mpc^-3. Finally, by comparing the emission-line\nand continuum properties of the LAEs, we show that the star-formation rates\nderived from Ly-alpha are ~3 times lower than those inferred from the\nrest-frame UV continuum. We use this offset to deduce the existence of a small\namount of internal extinction within the host galaxies. This extinction,\ncoupled with the lack of extremely-high equivalent width emitters, argues that\nthese galaxies are not primordial Pop III objects, though they are young and\nrelatively chemically unevolved.\n", "machine_text": "\nThis work presents the results of a deep survey of 162 Ly-alpha emission-line galaxies at a redshift of 3.1 in the Extended Chandra Deep Field South. The galaxies were identified by utilizing a narrow-band 5000 Anstrom filter and complementary broadband photometric data from the MUSYC survey with a monochromatic flux brighter than 1.5 x 10^-17 ergs cm^-2 s^-1 and an observers frame equivalent width exceeding 80 Angstroms. The equivalent width distribution follows an exponential with a rest-frame scale length of 76 Angstroms and a faint-end power-law slope of -1.49 observed at a space density of 1.46 x 10^-3 h70^3 galaxies Mpc^-3. In addition, the star-formation rates derived from Ly-alpha are ~3 times lower than that calculated from the rest-frame UV continuum, leading us to deduce the presence of internal extinction within the galaxies. This, combined with the lack of extremely-high equivalent width emitters, suggests these galaxies are young, relatively chemically unevolved, and likely not primordial Pop III objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3917}
{"prompt": "Rephrase the abstract of an article with title 'Effective anisotropies and energy barriers of magnetic nanoparticles\n  with Neel surface anisotropy'.\n  Magnetic nanoparticles with Neel surface anisotropy, different internal\nstructures, surface arrangements and elongation are modelled as many-spin\nsystems. The results suggest that the energy of many-spin nanoparticles cut\nfrom cubic lattices can be represented by an effective one-spin potential\ncontaining uniaxial and cubic anisotropies. It is shown that the values and\nsigns of the corresponding constants depend strongly on the particle's surface\narrangement, internal structure and elongation. Particles cut from a simple\ncubic lattice have the opposite sign of the effective cubic term, as compared\nto particles cut from the face-centered cubic lattice. Furthermore, other\nremarkable phenomena are observed in nanoparticles with relatively strong\nsurface effects: (i) In elongated particles surface effects can change the sign\nof the uniaxial anisotropy. (ii) In symmetric particles (spherical and\ntruncated octahedral) with cubic core anisotropy surface effects can change its\nsign. We also show that the competition between the core and surface\nanisotropies leads to a new energy that contributes to both the 2nd- and\n4th-order effective anisotropies.\n\n", "human_text": "  Magnetic nanoparticles with Neel surface anisotropy, different internal\nstructures, surface arrangements and elongation are modelled as many-spin\nsystems. The results suggest that the energy of many-spin nanoparticles cut\nfrom cubic lattices can be represented by an effective one-spin potential\ncontaining uniaxial and cubic anisotropies. It is shown that the values and\nsigns of the corresponding constants depend strongly on the particle's surface\narrangement, internal structure and elongation. Particles cut from a simple\ncubic lattice have the opposite sign of the effective cubic term, as compared\nto particles cut from the face-centered cubic lattice. Furthermore, other\nremarkable phenomena are observed in nanoparticles with relatively strong\nsurface effects: (i) In elongated particles surface effects can change the sign\nof the uniaxial anisotropy. (ii) In symmetric particles (spherical and\ntruncated octahedral) with cubic core anisotropy surface effects can change its\nsign. We also show that the competition between the core and surface\nanisotropies leads to a new energy that contributes to both the 2nd- and\n4th-order effective anisotropies.\n", "machine_text": "\nThe structure, size, and arrangement of magnetic nanoparticles with Neel surface anisotropy were investigated by modelling them as many-spin systems. It was revealed that the energy of particles cut from cubic lattices can be represented by effective one-spin potentials containing uniaxial and cubic anisotropies. Results show that the values and signs of these constants are highly dependent on the arrangement and structure of the nanoparticle, as well as its elongation. It was additionally discovered that strong surface effects can induce changes in the signs of uniaxial and core anisotropies in symmetric and elongated particles, respectively. Additionally, the competition between core and surface anisotropies was found to lead to a new energy that contributes to effective 2nd and 4th-order anisotropies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1689}
{"prompt": "Rephrase the abstract of an article with title 'Scattering amplitudes in strongly coupled N=4 SYM from semiclassical\n  strings in AdS'.\n  Very recently in arXiv:0705.0303 Alday and Maldacena gave a string theory\nprescription for computing (all) planar amplitudes in N=4 supersymmetric gauge\ntheory at strong coupling using the AdS/CFT correspondence. These amplitudes\nare determined by a classical string solution and contain a universal\nexponential factor involving the action of the classical string. On the gauge\ntheory side, expressions for perturbative amplitudes at strong coupling were\npreviously proposed only for specific helicities of external particles -- the\nmaximally helicity violating or MHV amplitudes. These follow from the\nexponential ansatz of Bern, Dixon and Smirnov for MHV amplitudes in N=4 SYM. In\nthis paper we examine the amplitudes dependence on helicities and\nparticle-types of external states. We consider the prefactor of string\namplitudes and give arguments suggesting that the prefactor at strong coupling\nshould be the same as the Yang-Mills tree-level amplitude for the same process.\nThis implies that scattering amplitudes in N=4 SYM simplify dramatically in the\nstrong coupling limit. It follows from our proposal that in this limit all (MHV\nand non-MHV) n-point amplitudes are given by the (known) tree-level Yang-Mills\nresult times the helicity-independent (and particle-type-independent) universal\nexponential.\n\n", "human_text": "  Very recently in arXiv:0705.0303 Alday and Maldacena gave a string theory\nprescription for computing (all) planar amplitudes in N=4 supersymmetric gauge\ntheory at strong coupling using the AdS/CFT correspondence. These amplitudes\nare determined by a classical string solution and contain a universal\nexponential factor involving the action of the classical string. On the gauge\ntheory side, expressions for perturbative amplitudes at strong coupling were\npreviously proposed only for specific helicities of external particles -- the\nmaximally helicity violating or MHV amplitudes. These follow from the\nexponential ansatz of Bern, Dixon and Smirnov for MHV amplitudes in N=4 SYM. In\nthis paper we examine the amplitudes dependence on helicities and\nparticle-types of external states. We consider the prefactor of string\namplitudes and give arguments suggesting that the prefactor at strong coupling\nshould be the same as the Yang-Mills tree-level amplitude for the same process.\nThis implies that scattering amplitudes in N=4 SYM simplify dramatically in the\nstrong coupling limit. It follows from our proposal that in this limit all (MHV\nand non-MHV) n-point amplitudes are given by the (known) tree-level Yang-Mills\nresult times the helicity-independent (and particle-type-independent) universal\nexponential.\n", "machine_text": "\nRecently, Alday and Maldacena applied the AdS/CFT correspondence to derive an equation for computing all planar amplitudes from string theory in N=4 supersymmetric gauge theory at strong coupling. This expression had a universal exponential factor that contained the action of the classical string. Previous calculations had only been made with specific external particle helicities -- the maximal helicity violating or MHV amplitudes. This article studies the impact of changes in external particle helicities and types on the amplitudes. We propose that the strong coupling limit of these amplitudes should be the same as their Yang-Mills tree-level counterparts with the added multiplier of the universal exponential. Our conclusion is that, in the strong coupling limit, all MHV and non-MHV scattering amplitudes will be identical to the known tree-level amplitudes multiplied by a helicity-independent, particle-type-independent, universal exponential.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2113}
{"prompt": "Rephrase the abstract of an article with title 'Galactic Wind Signatures around High Redshift Galaxies'.\n  We carry out cosmological chemodynamical simulations with different strengths\nof supernova (SN) feedback and study how galactic winds from star-forming\ngalaxies affect the features of hydrogen (HI) and metal (CIV and OVI)\nabsorption systems in the intergalactic medium at high redshift. We find that\nthe outflows tend to escape to low density regions, and hardly affect the dense\nfilaments visible in HI absorption. As a result, the strength of HI absorption\nnear galaxies is not reduced by galactic winds, but even slightly increases. We\nalso find that a lack of HI absorption for lines of sight (LOS) close to\ngalaxies, as found by Adelberger et al., can be created by hot gas around the\ngalaxies induced by accretion shock heating. In contrast to HI, metal\nabsorption systems are sensitive to the presence of winds. The models without\nfeedback can produce the strong CIV and OVI absorption lines in LOS within 50\nkpc from galaxies, while strong SN feedback is capable of creating strong CIV\nand OVI lines out to about twice that distance. We also analyze the mean\ntransmissivity of HI, CIV, and OVI within 1 h$^{-1}$ Mpc from star-forming\ngalaxies. The probability distribution of the transmissivity of HI is\nindependent of the strength of SN feedback, but strong feedback produces LOS\nwith lower transmissivity of metal lines. Additionally, strong feedback can\nproduce strong OVI lines even in cases where HI absorption is weak. We conclude\nthat OVI is probably the best tracer for galactic winds at high redshift.\n\n", "human_text": "  We carry out cosmological chemodynamical simulations with different strengths\nof supernova (SN) feedback and study how galactic winds from star-forming\ngalaxies affect the features of hydrogen (HI) and metal (CIV and OVI)\nabsorption systems in the intergalactic medium at high redshift. We find that\nthe outflows tend to escape to low density regions, and hardly affect the dense\nfilaments visible in HI absorption. As a result, the strength of HI absorption\nnear galaxies is not reduced by galactic winds, but even slightly increases. We\nalso find that a lack of HI absorption for lines of sight (LOS) close to\ngalaxies, as found by Adelberger et al., can be created by hot gas around the\ngalaxies induced by accretion shock heating. In contrast to HI, metal\nabsorption systems are sensitive to the presence of winds. The models without\nfeedback can produce the strong CIV and OVI absorption lines in LOS within 50\nkpc from galaxies, while strong SN feedback is capable of creating strong CIV\nand OVI lines out to about twice that distance. We also analyze the mean\ntransmissivity of HI, CIV, and OVI within 1 h$^{-1}$ Mpc from star-forming\ngalaxies. The probability distribution of the transmissivity of HI is\nindependent of the strength of SN feedback, but strong feedback produces LOS\nwith lower transmissivity of metal lines. Additionally, strong feedback can\nproduce strong OVI lines even in cases where HI absorption is weak. We conclude\nthat OVI is probably the best tracer for galactic winds at high redshift.\n", "machine_text": "\nThrough the use of cosmological chemodynamical simulations, we investigate the effects of galactic winds from star-forming galaxies on the features of hydrogen (HI) and metal (CIV and OVI) absorption systems in the intergalactic medium at high redshift. We find that the outflows travel to low density regions, while hardly affecting the denser filaments shown in HI absorption. Our models show that HI absorption is not lessened by winds, but can actually be slightly increased. We also notice that a lack of HI absorption near galaxies, observed by Adelberger et al., can be caused by hot gas created by accretion shock heating. On the other hand, metal absorption lines are strongly affected by the presence of winds \u2014 in particular, models without winds can create strong CIV and OVI lines within 50 kpc from galaxies, while strong winds can produce these lines out to about 100 kpc. Additionally, we examine the transmissivity of HI, CIV, and OVI within 1 h$^{-1}$ Mpc from star-forming galaxies, with our results demonstrating that the probability distribution of HI transmissivity is unaffected by different strengths of supernova (SN) feedback. However, strong SN feedback leads to weaker metal line transmissivity. Furthermore, strong feedback creates strong OVI lines even in cases where HI absorption is weak. Our findings imply that OVI is most likely the top indicator of galactic winds at high redshift.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0652}
{"prompt": "Rephrase the abstract of an article with title 'NBODY meets stellar population - The HYDE-PARC Project'.\n  N-body simulations give us a rough idea of how the shape of a simulated\nobject appears in three-dimensional space. From an observational point of view\nthis may give us a misleading picture. The faint stars may be the most common\nstars in the system but the morphological information obtained by observations\nof an object may be dominated by the color properties of the bright stars. Due\nto dynamical effects, such as energy equipartition, different masses of stars\nmay populate different regions in the object. Since stars are evolving in mass\nthe stellar evolution may also influence the dynamics of the system. Hence, if\none is interested in simulating what the morphology will look like through a\ntelescope, one needs to simulate in addition evolving stars and weight them by\ntheir luminosity. Therefore we need to combine simulations of the dynamical\nevolution and a stellar population synthesis at the same time. For the\ndynamical evolution part we use a parallel version of a direct N-body code,\nNBODY6++. This code also includes stellar evolution. We link the parameters\nfrom this stellar evolution routine to the BaSeL 2.0 stellar library. For\nisolated clusters we found results assimilable to standard stellar population\nsynthesis codes such as the PEGASE code. For clusters in a tidal field we found\nthat the integrated colors become relatively bluer due to energy equipartition\neffects. In the time shortly before dissolution of the cluster the stellar M/L\nratio becomes lower compared to isolated clusters. We compared the results of\nour simulations to integrated spectra of galactic globular clusters. For the\ncluster NGC 1851 we found good agreement between simulation and observation.\nFor extragalactic clusters in M81 and M31 we looked at medium band spectral\nenergy distributions and found for some clusters also a good agreement.\n\n", "human_text": "  N-body simulations give us a rough idea of how the shape of a simulated\nobject appears in three-dimensional space. From an observational point of view\nthis may give us a misleading picture. The faint stars may be the most common\nstars in the system but the morphological information obtained by observations\nof an object may be dominated by the color properties of the bright stars. Due\nto dynamical effects, such as energy equipartition, different masses of stars\nmay populate different regions in the object. Since stars are evolving in mass\nthe stellar evolution may also influence the dynamics of the system. Hence, if\none is interested in simulating what the morphology will look like through a\ntelescope, one needs to simulate in addition evolving stars and weight them by\ntheir luminosity. Therefore we need to combine simulations of the dynamical\nevolution and a stellar population synthesis at the same time. For the\ndynamical evolution part we use a parallel version of a direct N-body code,\nNBODY6++. This code also includes stellar evolution. We link the parameters\nfrom this stellar evolution routine to the BaSeL 2.0 stellar library. For\nisolated clusters we found results assimilable to standard stellar population\nsynthesis codes such as the PEGASE code. For clusters in a tidal field we found\nthat the integrated colors become relatively bluer due to energy equipartition\neffects. In the time shortly before dissolution of the cluster the stellar M/L\nratio becomes lower compared to isolated clusters. We compared the results of\nour simulations to integrated spectra of galactic globular clusters. For the\ncluster NGC 1851 we found good agreement between simulation and observation.\nFor extragalactic clusters in M81 and M31 we looked at medium band spectral\nenergy distributions and found for some clusters also a good agreement.\n", "machine_text": "This paper presents the HYDE-PARC project, which combines N-body simulations and stellar population synthesis in order to investigate the potential influences of dynamical and evolutionary effects on the morphology and properties of stellar clusters. The direct N-body code NBODY6++, including stellar evolution, is used for the dynamical evolution of the cluster, and the BaSeL 2.0 stellar library is used to link the parameters from this stellar evolution routine. Results from simulations of isolated clusters were found to be comparable to those from more traditional stellar population synthesis codes, whereas simulations of clusters in tidal fields showed that their integrated colors became relatively bluer due to energy equipartition impacts. Comparisons between simulations and measurements of galactic globular clusters (like NGC 1851) and extragalactic clusters (in M81 and M31) confirm the agreement of the results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3915}
{"prompt": "Rephrase the abstract of an article with title 'Absolute Calibration and Characterization of the Multiband Imaging\n  Photometer for Spitzer. I. The Stellar Calibrator Sample and the 24 micron\n  Calibration'.\n  We present the stellar calibrator sample and the conversion from instrumental\nto physical units for the 24 micron channel of the Multiband Imaging Photometer\nfor Spitzer (MIPS). The primary calibrators are A stars, and the calibration\nfactor based on those stars is 4.54*10^{-2} MJy sr^{-1} (DN/s)^{-1}, with a\nnominal uncertainty of 2%. We discuss the data-reduction procedures required to\nattain this accuracy; without these procdures, the calibration factor obtained\nusing the automated pipeline at the Spitzer Science Center is 1.6% +/- 0.6%\nlower. We extend this work to predict 24 micron flux densities for a sample of\n238 stars which covers a larger range of flux densities and spectral types. We\npresent a total of 348 measurements of 141 stars at 24 micron. This sample\ncovers a factor of ~460 in 24 micron flux density, from 8.6 mJy up to 4.0 Jy.\nWe show that the calibration is linear over that range with respect to target\nflux and background level. The calibration is based on observations made using\n3-second exposures; a preliminary analysis shows that the calibration factor\nmay be 1% and 2% lower for 10- and 30-second exposures, respectively. We also\ndemonstrate that the calibration is very stable: over the course of the\nmission, repeated measurements of our routine calibrator, HD 159330, show a\nroot-mean-square scatter of only 0.4%. Finally, we show that the point spread\nfunction (PSF) is well measured and allows us to calibrate extended sources\naccurately; Infrared Astronomy Satellite (IRAS) and MIPS measurements of a\nsample of nearby galaxies are identical within the uncertainties.\n\n", "human_text": "  We present the stellar calibrator sample and the conversion from instrumental\nto physical units for the 24 micron channel of the Multiband Imaging Photometer\nfor Spitzer (MIPS). The primary calibrators are A stars, and the calibration\nfactor based on those stars is 4.54*10^{-2} MJy sr^{-1} (DN/s)^{-1}, with a\nnominal uncertainty of 2%. We discuss the data-reduction procedures required to\nattain this accuracy; without these procdures, the calibration factor obtained\nusing the automated pipeline at the Spitzer Science Center is 1.6% +/- 0.6%\nlower. We extend this work to predict 24 micron flux densities for a sample of\n238 stars which covers a larger range of flux densities and spectral types. We\npresent a total of 348 measurements of 141 stars at 24 micron. This sample\ncovers a factor of ~460 in 24 micron flux density, from 8.6 mJy up to 4.0 Jy.\nWe show that the calibration is linear over that range with respect to target\nflux and background level. The calibration is based on observations made using\n3-second exposures; a preliminary analysis shows that the calibration factor\nmay be 1% and 2% lower for 10- and 30-second exposures, respectively. We also\ndemonstrate that the calibration is very stable: over the course of the\nmission, repeated measurements of our routine calibrator, HD 159330, show a\nroot-mean-square scatter of only 0.4%. Finally, we show that the point spread\nfunction (PSF) is well measured and allows us to calibrate extended sources\naccurately; Infrared Astronomy Satellite (IRAS) and MIPS measurements of a\nsample of nearby galaxies are identical within the uncertainties.\n", "machine_text": "  We present the calibration factor and conversion from the instrumental units to physical units for the 24 micron channel of the Multiband Imaging Photometer for Spitzer (MIPS). Our primary calibrators are A stars, which resulted in a calibration factor of 4.54*10^{-2} MJy sr^{-1} (DN/s)^{-1}, with a nominal uncertainty of 2%. We present a sample of 348 measurements of 141 stars at 24 micron, which covers a factor of ~460 in 24 micron flux density, from 8.6 mJy up to 4.0 Jy. We discuss data-reduction procedures which must be followed to attain this accuracy, as the automated pipeline at the Spitzer Science Center produces lower results. Furthermore, we show that the calibration is linear with respect to target flux and background level, and is very stable. Lastly, we demonstrate that the point spread function (PSF) iswell measured, allowing us to accurately calibrate extended sources.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2195}
{"prompt": "Rephrase the abstract of an article with title 'Can a charged dust ball be sent through the Reissner--Nordstr\\\"{o}m\n  wormhole?'.\n  In a previous paper we formulated a set of necessary conditions for the\nspherically symmetric weakly charged dust to avoid Big Bang/Big Crunch, shell\ncrossing and permanent central singularities. However, we did not discuss the\nproperties of the energy density, some of which are surprising and seem not to\nhave been known up to now. A singularity of infinite energy density does exist\n-- it is a point singularity situated on the world line of the center of\nsymmetry. The condition that no mass shell collapses to $R = 0$ if it had $R >\n0$ initially thus turns out to be still insufficient for avoiding a\nsingularity. Moreover, at the singularity the energy density $\\epsilon$ is\ndirection-dependent: $\\epsilon \\to - \\infty$ when we approach the singular\npoint along a $t =$ const hypersurface and $\\epsilon \\to + \\infty$ when we\napproach that point along the center of symmetry. The appearance of\nnegative-energy-density regions turns out to be inevitable. We discuss various\naspects of this property of our configuration. We also show that a permanently\npulsating configuration, with the period of pulsation independent of mass, is\npossible only if there exists a permanent central singularity.\n\n", "human_text": "  In a previous paper we formulated a set of necessary conditions for the\nspherically symmetric weakly charged dust to avoid Big Bang/Big Crunch, shell\ncrossing and permanent central singularities. However, we did not discuss the\nproperties of the energy density, some of which are surprising and seem not to\nhave been known up to now. A singularity of infinite energy density does exist\n-- it is a point singularity situated on the world line of the center of\nsymmetry. The condition that no mass shell collapses to $R = 0$ if it had $R >\n0$ initially thus turns out to be still insufficient for avoiding a\nsingularity. Moreover, at the singularity the energy density $\\epsilon$ is\ndirection-dependent: $\\epsilon \\to - \\infty$ when we approach the singular\npoint along a $t =$ const hypersurface and $\\epsilon \\to + \\infty$ when we\napproach that point along the center of symmetry. The appearance of\nnegative-energy-density regions turns out to be inevitable. We discuss various\naspects of this property of our configuration. We also show that a permanently\npulsating configuration, with the period of pulsation independent of mass, is\npossible only if there exists a permanent central singularity.\n", "machine_text": "This research paper aims to investigate the potential sending of a charged dust ball through a Reissner--Nordstr\\\"{o}m wormhole. The article outlines a set of criteria to prevent Big Bang/Big Crunch, shell crossing and permanent central singularities, as well as examining the energy density of the dust ball, which reveals surprising features that were previously unknown. Additionally, it demonstrates how a pulsating configuration, with a permanent central singularity and a period of pulsation independent of mass, is feasible.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4066}
{"prompt": "Rephrase the abstract of an article with title 'Luminous Red Galaxy Population in Clusters at $0.2\\le z\\le 0.6$'.\n  We investigate statistical properties of LRGs in a sample of X-ray selected\ngalaxy clusters at intermediate redshift ($0.2\\le z\\le0.6$). The LRGs are\nselected based on carefully designed color criteria, and the cluster membership\nis assessed via photometric redshifts. As clusters and LRGs are both viewed as\npromising tracer of the underlying dark matter distribution, understanding the\ndistribution of LRGs within clusters is an important issue.\n  Our main findings include:\n  1. The halo occupation distribution of LRGs inside our cluster sample is\n$N(M) = k\\times (M/10^{14})^{a}$ where $a=0.620\\pm 0.105 $ and $k=1.425\\pm0.285\n$ assuming a Poisson distribution for $N(M)$.\n  2. The halo occupation distribution of LRGs ($N(M)$) and the satellite\ndistribution of LRGs ($N-1(M)$) are both consistent with being Poisson. To be\nmore quantitative, we find $Var(N)/<N>= 1.428\\pm 0.351$ and $Var(N-1)/<N-1> =\n1.823 \\pm 0.496$\n  3. The radial profile of LRGs within clusters when fitted with a NFW profile\ngives a concentration of $17.5^{+7.1}_{-4.3}$ ($6.0^{+3.2}_{-1.9}$) including\n(excluding) BLRGs (Brightest LRGs).\n  We also discuss the implications of these observations on the evolution of\nmassive galaxies in clusters.\n\n", "human_text": "  We investigate statistical properties of LRGs in a sample of X-ray selected\ngalaxy clusters at intermediate redshift ($0.2\\le z\\le0.6$). The LRGs are\nselected based on carefully designed color criteria, and the cluster membership\nis assessed via photometric redshifts. As clusters and LRGs are both viewed as\npromising tracer of the underlying dark matter distribution, understanding the\ndistribution of LRGs within clusters is an important issue.\n  Our main findings include:\n  1. The halo occupation distribution of LRGs inside our cluster sample is\n$N(M) = k\\times (M/10^{14})^{a}$ where $a=0.620\\pm 0.105 $ and $k=1.425\\pm0.285\n$ assuming a Poisson distribution for $N(M)$.\n  2. The halo occupation distribution of LRGs ($N(M)$) and the satellite\ndistribution of LRGs ($N-1(M)$) are both consistent with being Poisson. To be\nmore quantitative, we find $Var(N)/<N>= 1.428\\pm 0.351$ and $Var(N-1)/<N-1> =\n1.823 \\pm 0.496$\n  3. The radial profile of LRGs within clusters when fitted with a NFW profile\ngives a concentration of $17.5^{+7.1}_{-4.3}$ ($6.0^{+3.2}_{-1.9}$) including\n(excluding) BLRGs (Brightest LRGs).\n  We also discuss the implications of these observations on the evolution of\nmassive galaxies in clusters.\n", "machine_text": "\nWe use a sample of X-ray selected galaxy clusters at redshift $0.2\\le z\\le 0.6$ to explore and quantify the statistical characteristics of the Luminous Red Galaxy (LRG) population. Our approach involves employing a specific set of criteria for determining LRGs' membership within clusters and measuring their redshifts photometrically. The broad aim of this study is to gain insights into the dark matter distribution and the evolution of massive galaxies in cluster environments.\n\nOur discourse brings to light several notable conclusions. Firstly, the analysis of LRGs' halo occupation distribution reveals a strong connection between the galaxy and the dark matter; this correlation follows the power law formula $N(M) = k\\times (M/10^{14})^{a}$, where $a = 0.620 \\pm 0.105$ and $k = 1.425 \\pm 0.285$. Secondly, Poisson's distribution is an accurately fitting model for both the halo occupation $N(M)$ and satellite occupation $N-1(M)$ of the LRGs. Finally, the NFW profile-based radial profile analysis fetches the LRGs a concentration value of $17.5^{+7.1}_{-4.3}$ including the brightest ones (BLRGs), and $6.0^{+3.2}_{-1.9}$ excluding them.\n\nThis investigation provides a good overview of the LRG population in clusters at $0.2\\le z\\le 0.6$, exploring the relation between galaxies and dark matter distributions as well as resulting implications for the evolution of massive galaxies in clusters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0727}
{"prompt": "Rephrase the abstract of an article with title 'On the Interpretation of the Age Distribution of Star Clusters in the\n  Small Magellanic Cloud'.\n  We re-analyze the age distribution (dN/dt) of star clusters in the Small\nMagellanic Cloud (SMC) using age determinations based on the Magellanic Cloud\nPhotometric Survey. For ages younger than 3x10^9 yr the dN/dt distribution can\nbe approximated by a power-law distribution, dN/dt propto t^-beta, with\n-beta=-0.70+/-0.05 or -beta=-0.84+/-0.04, depending on the model used to derive\nthe ages. Predictions for a cluster population without dissolution limited by a\nV-band detection result in a power-law dN/dt distribution with an index of\n~-0.7. This is because the limiting cluster mass increases with age, due to\nevolutionary fading of clusters, reducing the number of observed clusters at\nold ages. When a mass cut well above the limiting cluster mass is applied, the\ndN/dt distribution is flat up to 1 Gyr. We conclude that cluster dissolution is\nof small importance in shaping the dN/dt distribution and incompleteness causes\ndN/dt to decline. The reason that no (mass independent) infant mortality of\nstar clusters in the first ~10-20 Myr is found is explained by a detection bias\ntowards clusters without nebular emission, i.e. cluster that have survived the\ninfant mortality phase. The reason we find no evidence for tidal (mass\ndependent) cluster dissolution in the first Gyr is explained by the weak tidal\nfield of the SMC. Our results are in sharp contrast to the interpretation of\nChandar et al. (2006), who interpret the declining dN/dt distribution as rapid\ncluster dissolution. This is due to their erroneous assumption that the sample\nis limited by cluster mass, rather than luminosity.\n\n", "human_text": "  We re-analyze the age distribution (dN/dt) of star clusters in the Small\nMagellanic Cloud (SMC) using age determinations based on the Magellanic Cloud\nPhotometric Survey. For ages younger than 3x10^9 yr the dN/dt distribution can\nbe approximated by a power-law distribution, dN/dt propto t^-beta, with\n-beta=-0.70+/-0.05 or -beta=-0.84+/-0.04, depending on the model used to derive\nthe ages. Predictions for a cluster population without dissolution limited by a\nV-band detection result in a power-law dN/dt distribution with an index of\n~-0.7. This is because the limiting cluster mass increases with age, due to\nevolutionary fading of clusters, reducing the number of observed clusters at\nold ages. When a mass cut well above the limiting cluster mass is applied, the\ndN/dt distribution is flat up to 1 Gyr. We conclude that cluster dissolution is\nof small importance in shaping the dN/dt distribution and incompleteness causes\ndN/dt to decline. The reason that no (mass independent) infant mortality of\nstar clusters in the first ~10-20 Myr is found is explained by a detection bias\ntowards clusters without nebular emission, i.e. cluster that have survived the\ninfant mortality phase. The reason we find no evidence for tidal (mass\ndependent) cluster dissolution in the first Gyr is explained by the weak tidal\nfield of the SMC. Our results are in sharp contrast to the interpretation of\nChandar et al. (2006), who interpret the declining dN/dt distribution as rapid\ncluster dissolution. This is due to their erroneous assumption that the sample\nis limited by cluster mass, rather than luminosity.\n", "machine_text": "\nWe investigate the age distribution (dN/dt) of star clusters in the Small\nMagellanic Cloud (SMC) using data from the Magellanic Cloud Photometric\nSurvey. Our results suggest that the age distribution can be represented\nby a power law distribution with an index of about -0.7 for ages younger\nthan 3x10^9 yr. Additionally, we conclude that when a mass cut, much larger\nthan the detection limit, is set, the dN/dt distribution remains flat\nuntil at least 1 Gyr. Our findings dispute Chandar et al.'s (2006) notion\nthat the decline in dN/dt is due to rapid cluster dissolution. In fact,\nwe explain the decline as an incomplete sample caused by the luminosity\ndetection bias. Moreover, we suggest the reason there is no (mass\nindependent) infant mortality of star clusters in the first ~10-20 Myr is\nattributed to a detection bias towards clusters without nebular emission.\nAlso, the reason no evidence of tidal cluster dissolution in the first Gyr\nis found is explained by the weak tidal field of the SMC.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1202}
{"prompt": "Rephrase the abstract of an article with title 'Dynamics of Three Agent Games'.\n  We study the dynamics and resulting score distribution of three-agent games\nwhere after each competition a single agent wins and scores a point. A single\ncompetition is described by a triplet of numbers $p$, $t$ and $q$ denoting the\nprobabilities that the team with the highest, middle or lowest accumulated\nscore wins. We study the full family of solutions in the regime, where the\nnumber of agents and competitions is large, which can be regarded as a\nhydrodynamic limit. Depending on the parameter values $(p,q,t)$, we find six\nqualitatively different asymptotic score distributions and we also provide a\nqualitative understanding of these results. We checked our analytical results\nagainst numerical simulations of the microscopic model and find these to be in\nexcellent agreement. The three agent game can be regarded as a social model\nwhere a player can be favored or disfavored for advancement, based on his/her\naccumulated score. It is also possible to decide the outcome of a three agent\ngame through a mini tournament of two-a gent competitions among the\nparticipating players and it turns out that the resulting possible score\ndistributions are a subset of those obtained for the general three agent-games.\nWe discuss how one can add a steady and democratic decline rate to the model\nand present a simple geometric construction that allows one to write down the\ncorresponding score evolution equations for $n$-agent games.\n\n", "human_text": "  We study the dynamics and resulting score distribution of three-agent games\nwhere after each competition a single agent wins and scores a point. A single\ncompetition is described by a triplet of numbers $p$, $t$ and $q$ denoting the\nprobabilities that the team with the highest, middle or lowest accumulated\nscore wins. We study the full family of solutions in the regime, where the\nnumber of agents and competitions is large, which can be regarded as a\nhydrodynamic limit. Depending on the parameter values $(p,q,t)$, we find six\nqualitatively different asymptotic score distributions and we also provide a\nqualitative understanding of these results. We checked our analytical results\nagainst numerical simulations of the microscopic model and find these to be in\nexcellent agreement. The three agent game can be regarded as a social model\nwhere a player can be favored or disfavored for advancement, based on his/her\naccumulated score. It is also possible to decide the outcome of a three agent\ngame through a mini tournament of two-a gent competitions among the\nparticipating players and it turns out that the resulting possible score\ndistributions are a subset of those obtained for the general three agent-games.\nWe discuss how one can add a steady and democratic decline rate to the model\nand present a simple geometric construction that allows one to write down the\ncorresponding score evolution equations for $n$-agent games.\n", "machine_text": "\nThe present work investigates the dynamics and resulting score distributions of three-agent games, where an individual player wins and scores a point after each competition. A competition is specifically described by three parameters: $p$, $t$ and $q$, which indicate the probabilities of the team with the highest, middle or lowest score winning. We observe six qualitatively different asymptotic score distributions in the large number of agents/competitions regime and provide an expansive qualitative explanation for such results. Numerical simulations of the microscopic model are used to validate the analytical results, giving excellent agreement. This game can be seen as a social model, wherein players can be favoured or disfavoured for advancement based on their accrued scores. It is determined that a mini tournament of two-agent challenges can be used to determine the outcome of the three-agent game and that the possible score distributions generated are a subset of the broader two agent results. Finally, a steady and democratic decline rate is added to the model, with a simple geometric construction capable of writing down the corresponding score evolution equations for $n$-agent games.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1645}
{"prompt": "Rephrase the abstract of an article with title 'HS1857+5144: A hot and young pre-cataclysmic variable'.\n  We report the discovery of a new white dwarf/M dwarf binary, HS1857+5144,\nidentified in the Hamburg Quasar Survey (HQS). Time-resolved optical\nspectroscopy and photometry were carried out to determine the properties of\nthis new cataclysmic variable progenitor pre-CV). The light curves of\nHS1857+5144 display a sinusoidal variation with a period of Porb=383.52 min and\npeak-to-peak amplitudes of 0.7 mag and 1.1 mag in the B-band and R-band,\nrespectively. The large amplitude of the brightness variation results from a\nreflection effect on the heated inner hemisphere of the companion star,\nsuggesting a very high temperature of the white dwarf. Our radial velocity\nstudy confirms the photometric period as the orbital period of the system. A\nmodel atmosphere fit to the spectrum of the white dwarf obtained at minimum\nlight provides limits to its mass and temperature of Mwd=~0.6-1.0 Msun and\nTwd=~70000-100000 K, respectively. The detection of HeII 4686 absorption\nclassifies the primary star of HS1857+5144 as a DAO white dwarf. Combining the\nresults from our spectroscopy and photometry, we estimate the mass of the\ncompanion star and the binary inclination to be Msec=~0.15-0.30 Msun and\ni=~45-55 deg, respectively. We classify HS1857+5144 as one of the youngest\npre-CV known to date. The cooling age of the white dwarf suggests that the\npresent system has just emerged from a common envelope phase ~10^5 yr ago.\nHS1857+5144 will start mass transfer within or below the 2-3h period gap.\n\n", "human_text": "  We report the discovery of a new white dwarf/M dwarf binary, HS1857+5144,\nidentified in the Hamburg Quasar Survey (HQS). Time-resolved optical\nspectroscopy and photometry were carried out to determine the properties of\nthis new cataclysmic variable progenitor pre-CV). The light curves of\nHS1857+5144 display a sinusoidal variation with a period of Porb=383.52 min and\npeak-to-peak amplitudes of 0.7 mag and 1.1 mag in the B-band and R-band,\nrespectively. The large amplitude of the brightness variation results from a\nreflection effect on the heated inner hemisphere of the companion star,\nsuggesting a very high temperature of the white dwarf. Our radial velocity\nstudy confirms the photometric period as the orbital period of the system. A\nmodel atmosphere fit to the spectrum of the white dwarf obtained at minimum\nlight provides limits to its mass and temperature of Mwd=~0.6-1.0 Msun and\nTwd=~70000-100000 K, respectively. The detection of HeII 4686 absorption\nclassifies the primary star of HS1857+5144 as a DAO white dwarf. Combining the\nresults from our spectroscopy and photometry, we estimate the mass of the\ncompanion star and the binary inclination to be Msec=~0.15-0.30 Msun and\ni=~45-55 deg, respectively. We classify HS1857+5144 as one of the youngest\npre-CV known to date. The cooling age of the white dwarf suggests that the\npresent system has just emerged from a common envelope phase ~10^5 yr ago.\nHS1857+5144 will start mass transfer within or below the 2-3h period gap.\n", "machine_text": "\nThe Hamburg Quasar Survey (HQS) recently discovered a hot and young pre-cataclysmic variable, HS1857+5144, an binary system composed of a white dwarf and a M dwarf. To determine its properties, time-resolved optical spectroscopy and photometry were conducted which revealed a sinusoidal variation with a period of 383.52 minutes and peak-to-peak amplitudes of 0.7 mag in the B-band and 1.1 mag in the R-band. These large amplitudes are due to a reflection effect in the heated inner hemisphere of the companion star. The radial velocity study performed on the white dwarf implies that the photometric period can be attributed to the orbital period of the system. By fitting a model atmosphere to its spectrum, the mass and temperature of the white dwarf was estimated to be MwD=~0.6-1.0 Msun and Twd=~70000-100000 K respectively. Additionally, Msec=~0.15-0.30 Msun and i=~45-55 degrees were assessed for the companion star and the binary inclination respectively. This places HS1857+5144 as one of the youngest pre-CV known to date and suggests that the present system emerged from a common envelope phase 10^5 yr ago, ready to start mass transfer within or below the 2-3h period gap.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.178}
{"prompt": "Rephrase the abstract of an article with title 'The Kinetic Sunyaev-Zel'dovich Effect Due to the Electrons of Our Galaxy'.\n  We compute the effect of local electrons on the CMB temperature anisotropies.\nThe number density and distribution of free electrons in our Galaxy has been\naccurately measured from pulsar dispersion measurements. Because of their\ndistribution, the dynamics of our Galaxy and the Galaxy peculiar velocity with\nrespect to the Hubble flow, these free electrons leave a frequency-independent\nimprint on the cosmic microwave background (CMB). In particular, the coherent\nmotion of the free electrons respect to us and to the CMB rest frame produce a\nkinetic Sunyaev-Zeldovich signal. We compute this effect and we note that the\nlarge-scale antisymmetry of the signal gives it an angular power spectrum with\na sawtooth pattern where even multipoles are suppressed with respect to the odd\nones. We find the signal to be small (~ 2 uK) and sub-dominant compared to the\nprimary CMB and other foreground signals. However, since there are no free\nparameters in the modeling of this signal, it can be taken into account if more\nprecise measurements of the primordial signal are required.\n\n", "human_text": "  We compute the effect of local electrons on the CMB temperature anisotropies.\nThe number density and distribution of free electrons in our Galaxy has been\naccurately measured from pulsar dispersion measurements. Because of their\ndistribution, the dynamics of our Galaxy and the Galaxy peculiar velocity with\nrespect to the Hubble flow, these free electrons leave a frequency-independent\nimprint on the cosmic microwave background (CMB). In particular, the coherent\nmotion of the free electrons respect to us and to the CMB rest frame produce a\nkinetic Sunyaev-Zeldovich signal. We compute this effect and we note that the\nlarge-scale antisymmetry of the signal gives it an angular power spectrum with\na sawtooth pattern where even multipoles are suppressed with respect to the odd\nones. We find the signal to be small (~ 2 uK) and sub-dominant compared to the\nprimary CMB and other foreground signals. However, since there are no free\nparameters in the modeling of this signal, it can be taken into account if more\nprecise measurements of the primordial signal are required.\n", "machine_text": "We examine the effect of the electrons in our Milky Way on the variance in CMB temperature. Utilizing the data surrounding the free electrons' distribution, density, and movement in conjunction with the velocity of our Galaxy with regard to the Hubble flow, an effect known as the Kinetic Sunyaev-Zeldovich Effect appears in the cosmic microwave background. This effect does not vary between frequencies, and has an angular power spectrum with low power for even multipoles contrasted with the odd ones. We conclude that even though the atmospheric variance from this effect is minor (~ 2 uK), modeling its behavior could aid in the pursuit of more accurate measurements of the primordial signal.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3245}
{"prompt": "Rephrase the abstract of an article with title 'Gauge symmetry in Kitaev-type spin models and index theorems on odd\n  manifolds'.\n  We construct an exactly soluble spin-$\\frac{1}2$ model on a honeycomb\nlattice, which is a generalization of Kitaev model. The topological phases of\nthe system are analyzed by study of the ground state sector of this model, the\nvortex-free states. Basically, there are two phases, A phase and B phase. The\nbehaviors of both A and B phases may be studied by mapping the ground state\nsector into a general p-wave paired states of spinless fermions with tunable\npairing parameters on a square lattice. In this p-wave paired state theory, the\nA phase is shown to be the strong paired phase, an insulating phase. The B\nphase may be either gapped or gapless determined by the generalized inversion\nsymmetry is broken or not. The gapped B is the weak pairing phase described by\neither the Moore-Read Pfaffian state of the spinless fermions or anti-Pfaffian\nstate of holes depending on the sign of the next nearest neighbor hopping\namplitude. A phase transition between Pfaffian and anti-Pfaffian states are\nfound in the gapped B phase. Furthermore, we show that there is a hidden SU(2)\ngauge symmetry in our model. In the gapped B phase, the ground state has a\nnon-trivial topological number, the spectral first Chern number or the chiral\ncentral charge, which reflects the chiral anomaly of the edge state. We proved\nthat the topological number is identified to the reduced eta-invariant and this\nanomaly may be cancelled by a bulk Wess-Zumino term of SO(3) group through an\nindex theorem in 2+1 dimensions.\n\n", "human_text": "  We construct an exactly soluble spin-$\\frac{1}2$ model on a honeycomb\nlattice, which is a generalization of Kitaev model. The topological phases of\nthe system are analyzed by study of the ground state sector of this model, the\nvortex-free states. Basically, there are two phases, A phase and B phase. The\nbehaviors of both A and B phases may be studied by mapping the ground state\nsector into a general p-wave paired states of spinless fermions with tunable\npairing parameters on a square lattice. In this p-wave paired state theory, the\nA phase is shown to be the strong paired phase, an insulating phase. The B\nphase may be either gapped or gapless determined by the generalized inversion\nsymmetry is broken or not. The gapped B is the weak pairing phase described by\neither the Moore-Read Pfaffian state of the spinless fermions or anti-Pfaffian\nstate of holes depending on the sign of the next nearest neighbor hopping\namplitude. A phase transition between Pfaffian and anti-Pfaffian states are\nfound in the gapped B phase. Furthermore, we show that there is a hidden SU(2)\ngauge symmetry in our model. In the gapped B phase, the ground state has a\nnon-trivial topological number, the spectral first Chern number or the chiral\ncentral charge, which reflects the chiral anomaly of the edge state. We proved\nthat the topological number is identified to the reduced eta-invariant and this\nanomaly may be cancelled by a bulk Wess-Zumino term of SO(3) group through an\nindex theorem in 2+1 dimensions.\n", "machine_text": "\nIn this work, we explore the gauge symmetry of a spin-$\\frac{1}2$ model on a honeycomb lattice, which is based on Kitaev model. The topological phases of the system are studied by looking into its ground state sector, the vortex-free states. It is found there are two fundamental phases, labeled as A and B, whose nature can be revealed by mapping onto a p-wave paired states of spinless fermions with adjustable pairing parameters in a square lattice. The A phase is seen to be the strong pairing phase, an insulating stage, and the B phase can be gapped or gapless based on the broken or preserved generalized inversion symmetry. The gapped B phase is further shown to be the weak pairing phase, either described by Moore-Read Pfaffian state of spinless fermions or anti-Pfaffian state of holes depending on the sign of the next nearest neighbor hopping amplitude. In addition, we discover the hidden SU(2) gauge symmetry in the model. The gapped B phase has a special topological number, the spectral first Chern number or the chiral central charge, which indicates the chiral anomaly of the edge state. This anomaly is identified as the reduced Eta-invariant and can be eliminated by a Wess-Zumino term of SO(3) group through an index theorem in 2+1 dimensions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3829}
{"prompt": "Rephrase the abstract of an article with title 'Plasma Modes Along the Open Field Lines of a Neutron Star'.\n  We consider electrostatic plasma modes along the open field lines of a\nrotating neutron star. Goldreich-Julian charge density in general relativity is\nanalyzed for the neutron star with zero inclination. It is found that the\ncharge density is maximum at the polar cap and it remains almost same in\ncertain extended region of the pole. For a steady state Goldreich-Julian charge\ndensity we found the usual plasma oscillation along the field lines; plasma\nfrequency resembles to the gravitational redshift close to the Schwarzschild\nradius. We study the nonlinear plasma mode along the field lines. From the\nsystem of equations under general relativity, a second order differential\nequation is derived. The equation contains a term which describes the growing\nplasma modes near Schwarzschild radius in a black hole environment. The term\nvanishes with the distance far away from the gravitating object. For initially\nzero potential and field on the surface of a neutron star, Goldreich-Julian\ncharge density is found to create the plasma mode, which is enhanced and\npropagates almost without damping along the open field lines. We briefly\noutline our plan to extend the work for studying soliton propagation along the\nopen field lines of strongly gravitating objects.\n\n", "human_text": "  We consider electrostatic plasma modes along the open field lines of a\nrotating neutron star. Goldreich-Julian charge density in general relativity is\nanalyzed for the neutron star with zero inclination. It is found that the\ncharge density is maximum at the polar cap and it remains almost same in\ncertain extended region of the pole. For a steady state Goldreich-Julian charge\ndensity we found the usual plasma oscillation along the field lines; plasma\nfrequency resembles to the gravitational redshift close to the Schwarzschild\nradius. We study the nonlinear plasma mode along the field lines. From the\nsystem of equations under general relativity, a second order differential\nequation is derived. The equation contains a term which describes the growing\nplasma modes near Schwarzschild radius in a black hole environment. The term\nvanishes with the distance far away from the gravitating object. For initially\nzero potential and field on the surface of a neutron star, Goldreich-Julian\ncharge density is found to create the plasma mode, which is enhanced and\npropagates almost without damping along the open field lines. We briefly\noutline our plan to extend the work for studying soliton propagation along the\nopen field lines of strongly gravitating objects.\n", "machine_text": "\nThis article studies the electrostatic plasma modes along the open field lines of a rotating neutron star. We explore the Goldreich-Julian charge density under general relativity, finding it is greatest at the polar cap with a more constant level in the subsequent extended region. We then look at the steady state Goldreich-Julian charge density to discover plasma oscillations along the field lines, with plasma frequency closely resembling the gravitational redshift near to the Schwarzschild radius. To investigate further, we derive a second order differential equation from the nonlinear plasma mode along the field lines, which contains a defining term depicting growing plasma modes around the black hole environment. Simultaneously, we find that the Goldreich-Julian charge density produces a propagating plasma mode on the neutron star surface, which is considerably enhanced, but remains almost unimpeded over long distances. Finally, we discuss how to further develop the work by looking at soliton propagation along the open field lines of strongly gravitating objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.438}
{"prompt": "Rephrase the abstract of an article with title 'The spin-flip phenomenon in supermassive black hole binary mergers'.\n  Massive merging black holes will be the primary sources of powerful\ngravitational waves at low frequency, and will permit to test general\nrelativity with candidate galaxies close to a binary black hole merger. In this\npaper we identify the typical mass ratio of the two black holes but then show\nthat the distance when gravitational radiation becomes the dominant dissipative\neffect (over dynamical friction) does not depend on the mass ratio. However the\ndynamical evolution in the gravitational wave emission regime does. For the\ntypical range of mass ratios the final stage of the merger is preceded by a\nrapid precession and a subsequent spin-flip of the main black hole. This\nalready occurs in the inspiral phase, therefore can be described analytically\nby post-Newtonian techniques. We then identify the radio galaxies with a\nsuper-disk as those in which the rapidly precessing jet produces effectively a\npowerful wind, entraining the environmental gas to produce the appearance of a\nthick disk. These specific galaxies are thus candidates for a merger of two\nblack holes to happen in the astronomically near future.\n\n", "human_text": "  Massive merging black holes will be the primary sources of powerful\ngravitational waves at low frequency, and will permit to test general\nrelativity with candidate galaxies close to a binary black hole merger. In this\npaper we identify the typical mass ratio of the two black holes but then show\nthat the distance when gravitational radiation becomes the dominant dissipative\neffect (over dynamical friction) does not depend on the mass ratio. However the\ndynamical evolution in the gravitational wave emission regime does. For the\ntypical range of mass ratios the final stage of the merger is preceded by a\nrapid precession and a subsequent spin-flip of the main black hole. This\nalready occurs in the inspiral phase, therefore can be described analytically\nby post-Newtonian techniques. We then identify the radio galaxies with a\nsuper-disk as those in which the rapidly precessing jet produces effectively a\npowerful wind, entraining the environmental gas to produce the appearance of a\nthick disk. These specific galaxies are thus candidates for a merger of two\nblack holes to happen in the astronomically near future.\n", "machine_text": "\nIn this paper, we explore the spin-flip phenomenon in binary black hole mergers of supermassive amounts. We identify the typical mass ratio of the two black holes, and demonstrate that the distance when gravitational radiation becomes the dominant dissipation factor is unaffected by the mass ratio. However, the dynamical evolution of the merger that ensues is influenced by the mass ratio. For the typical mass ratios encountered in the mergers, we discover a rapid precession and spin-flip of the main black hole prior to the final stage of the merger. We articulate how this phenomenon is also capable of being treated analytically with post-Newtonian techniques during the inspiral stage. Furthermore, we locate evidence that suggests radio galaxies with a super-disk appear as a result of a powerful wind generated by the rapidly precessing jet, which entrain environmental gas to produce a thick disk look. These galaxies are then possible candidates to experience binary black hole mergers close to our epoch.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1968}
{"prompt": "Rephrase the abstract of an article with title 'Critical phenomena in complex networks'.\n  The combination of the compactness of networks, featuring small diameters,\nand their complex architectures results in a variety of critical effects\ndramatically different from those in cooperative systems on lattices. In the\nlast few years, researchers have made important steps toward understanding the\nqualitatively new critical phenomena in complex networks. We review the\nresults, concepts, and methods of this rapidly developing field. Here we mostly\nconsider two closely related classes of these critical phenomena, namely\nstructural phase transitions in the network architectures and transitions in\ncooperative models on networks as substrates. We also discuss systems where a\nnetwork and interacting agents on it influence each other. We overview a wide\nrange of critical phenomena in equilibrium and growing networks including the\nbirth of the giant connected component, percolation, k-core percolation,\nphenomena near epidemic thresholds, condensation transitions, critical\nphenomena in spin models placed on networks, synchronization, and\nself-organized criticality effects in interacting systems on networks. We also\ndiscuss strong finite size effects in these systems and highlight open problems\nand perspectives.\n\n", "human_text": "  The combination of the compactness of networks, featuring small diameters,\nand their complex architectures results in a variety of critical effects\ndramatically different from those in cooperative systems on lattices. In the\nlast few years, researchers have made important steps toward understanding the\nqualitatively new critical phenomena in complex networks. We review the\nresults, concepts, and methods of this rapidly developing field. Here we mostly\nconsider two closely related classes of these critical phenomena, namely\nstructural phase transitions in the network architectures and transitions in\ncooperative models on networks as substrates. We also discuss systems where a\nnetwork and interacting agents on it influence each other. We overview a wide\nrange of critical phenomena in equilibrium and growing networks including the\nbirth of the giant connected component, percolation, k-core percolation,\nphenomena near epidemic thresholds, condensation transitions, critical\nphenomena in spin models placed on networks, synchronization, and\nself-organized criticality effects in interacting systems on networks. We also\ndiscuss strong finite size effects in these systems and highlight open problems\nand perspectives.\n", "machine_text": "\nThis paper aims to provide an overview of the unique range of critical phenomena that can emerge from complex network architectures, such as small diameters, as well as cooperative models on networks. Particular attention is placed upon topics such as structural phase transitions, percolation, k-core percolation, phenomena near epidemic thresholds, and condensation transitions. In addition, the paper offers analysis regarding spin models placed on networks, as well as self-organized criticality phenomena among interacting systems on networks. This overview also marks the significant progress made in the past few years in gaining insight into these new critical phenomena, while also discussing strong finite-size effects in these systems, as well as potential open questions and future prospects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.001}
{"prompt": "Rephrase the abstract of an article with title 'The Mass Function of Active Black Holes in the Local Universe'.\n  We present the first measurement of the black hole (BH) mass function for\nbroad-line active galaxies in the local Universe. Using the ~9000 broad-line\nactive galaxies from the Fourth Data Release of the Sloan Digital Sky Survey,\nwe construct a broad-line luminosity function that agrees very well with the\nlocal soft X-ray luminosity function. Using standard virial relations, we then\nconvert observed broad-line luminosities and widths into BH masses. A mass\nfunction constructed in this way has the unique capability to probe the mass\nregion <10^6 M_sun, which, while insignificant in terms of total BH mass\ndensity, nevertheless may place important constraints on the mass distribution\nof seed BHs in the early Universe. The characteristic local active BH has a\nmass of ~10^7 M_sun radiating at 10% of the Eddington rate. The active fraction\nis a strong function of BH mass; at both higher and lower masses the active\nmass function falls more steeply than one would infer from the distribution of\nbulge luminosity. The deficit of local massive radiating BHs is a well-known\nphenomenon, while we present the first robust measurement of a decline in the\nspace density of active BHs at low mass.\n\n", "human_text": "  We present the first measurement of the black hole (BH) mass function for\nbroad-line active galaxies in the local Universe. Using the ~9000 broad-line\nactive galaxies from the Fourth Data Release of the Sloan Digital Sky Survey,\nwe construct a broad-line luminosity function that agrees very well with the\nlocal soft X-ray luminosity function. Using standard virial relations, we then\nconvert observed broad-line luminosities and widths into BH masses. A mass\nfunction constructed in this way has the unique capability to probe the mass\nregion <10^6 M_sun, which, while insignificant in terms of total BH mass\ndensity, nevertheless may place important constraints on the mass distribution\nof seed BHs in the early Universe. The characteristic local active BH has a\nmass of ~10^7 M_sun radiating at 10% of the Eddington rate. The active fraction\nis a strong function of BH mass; at both higher and lower masses the active\nmass function falls more steeply than one would infer from the distribution of\nbulge luminosity. The deficit of local massive radiating BHs is a well-known\nphenomenon, while we present the first robust measurement of a decline in the\nspace density of active BHs at low mass.\n", "machine_text": "\nWe measure the mass function of active black holes in the local Universe using data from the Fourth Data Release of the Sloan Digital Sky Survey. Our results show that the characteristic local active black hole has a mass of around 10^7 M_sun and is radiating at 10% of the Eddington rate. We find that the active fraction strongly depends on black hole mass, dropping more steeply than expected when the mass is both lower and higher than the characteristic mass. This deficit of massive radiating black holes is not a new observation, however this is the first measurement of a decline in the space density of active black holes at low mass. Our findings provide novel insights into the distribution of seed black holes in the early Universe.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.002}
{"prompt": "Rephrase the abstract of an article with title 'Contractions, deformations and curvature'.\n  The role of curvature in relation with Lie algebra contractions of the\npseudo-ortogonal algebras so(p,q) is fully described by considering some\nassociated symmetrical homogeneous spaces of constant curvature within a\nCayley-Klein framework. We show that a given Lie algebra contraction can be\ninterpreted geometrically as the zero-curvature limit of some underlying\nhomogeneous space with constant curvature. In particular, we study in detail\nthe contraction process for the three classical Riemannian spaces (spherical,\nEuclidean, hyperbolic), three non-relativistic (Newtonian) spacetimes and three\nrelativistic ((anti-)de Sitter and Minkowskian) spacetimes. Next, from a\ndifferent perspective, we make use of quantum deformations of Lie algebras in\norder to construct a family of spaces of non-constant curvature that can be\ninterpreted as deformations of the above nine spaces. In this framework, the\nquantum deformation parameter is identified as the parameter that controls the\ncurvature of such \"quantum\" spaces.\n\n", "human_text": "  The role of curvature in relation with Lie algebra contractions of the\npseudo-ortogonal algebras so(p,q) is fully described by considering some\nassociated symmetrical homogeneous spaces of constant curvature within a\nCayley-Klein framework. We show that a given Lie algebra contraction can be\ninterpreted geometrically as the zero-curvature limit of some underlying\nhomogeneous space with constant curvature. In particular, we study in detail\nthe contraction process for the three classical Riemannian spaces (spherical,\nEuclidean, hyperbolic), three non-relativistic (Newtonian) spacetimes and three\nrelativistic ((anti-)de Sitter and Minkowskian) spacetimes. Next, from a\ndifferent perspective, we make use of quantum deformations of Lie algebras in\norder to construct a family of spaces of non-constant curvature that can be\ninterpreted as deformations of the above nine spaces. In this framework, the\nquantum deformation parameter is identified as the parameter that controls the\ncurvature of such \"quantum\" spaces.\n", "machine_text": "This article assesses the role of curvature in relation to the contraction of Lie algebra pseudo-orthogonal so(p,q), analysing the zero-curvature limit of constant curvature homogenous spaces. By using quantum deformations of Lie algebras, a family of spaces of non-constant curvature is constructed. This research discerns the effects of the parameter of quantum deformation on the curvature of these \"quantum\" spaces, when compared to their classical counterparts (e.g. spherical, Euclidean and hyperbolic Riemannian spaces). ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2208}
{"prompt": "Rephrase the abstract of an article with title 'Shear-rate dependent transport coefficients for inelastic Maxwell models'.\n  The Boltzmann equation for d-dimensional inelastic Maxwell models is\nconsidered to analyze transport properties in spatially inhomogeneous states\nclose to the simple shear flow. A normal solution is obtained via a\nChapman--Enskog--like expansion around a local shear flow distribution f^{(0)}\nthat retains all the hydrodynamic orders in the shear rate. The constitutive\nequations for the heat and momentum fluxes are obtained to first order in the\ndeviations of the hydrodynamic field gradients from their values in the\nreference state and the corresponding generalized transport coefficients are\n{\\em exactly} determined in terms of the coefficient of restitution \\alpha and\nthe shear rate a. Since f^{(0)} applies for arbitrary values of the shear rate\nand is not restricted to weak dissipation, the transport coefficients turn out\nto be nonlinear functions of both parameters a and \\alpha. A comparison with\nprevious results obtained for inelastic hard spheres from a kinetic model of\nthe Boltzmann equation is also carried out.\n\n", "human_text": "  The Boltzmann equation for d-dimensional inelastic Maxwell models is\nconsidered to analyze transport properties in spatially inhomogeneous states\nclose to the simple shear flow. A normal solution is obtained via a\nChapman--Enskog--like expansion around a local shear flow distribution f^{(0)}\nthat retains all the hydrodynamic orders in the shear rate. The constitutive\nequations for the heat and momentum fluxes are obtained to first order in the\ndeviations of the hydrodynamic field gradients from their values in the\nreference state and the corresponding generalized transport coefficients are\n{\\em exactly} determined in terms of the coefficient of restitution \\alpha and\nthe shear rate a. Since f^{(0)} applies for arbitrary values of the shear rate\nand is not restricted to weak dissipation, the transport coefficients turn out\nto be nonlinear functions of both parameters a and \\alpha. A comparison with\nprevious results obtained for inelastic hard spheres from a kinetic model of\nthe Boltzmann equation is also carried out.\n", "machine_text": "This paper investigates transport properties in spatially inhomogeneous states close to the simple shear flow of d-dimensional inelastic Maxwell models. A Chapman-Enskog-like expansion is employed to obtain the local shear flow distribution, f^(0). The constitutive equations for the heat and momentum fluxes and their respective generalised transport coefficients are determined, with their exact functions of the coefficient of restitution and the shear rate. This result holds for any combination of a and \u03b1, providing a comparison with results obtained for inelastic hard spheres from a prior kinetic model of the Boltzmann equation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0092}
{"prompt": "Rephrase the abstract of an article with title 'The Trade-off between Processing Gains of an Impulse Radio UWB System in\n  the Presence of Timing Jitter'.\n  In time hopping impulse radio, $N_f$ pulses of duration $T_c$ are transmitted\nfor each information symbol. This gives rise to two types of processing gain:\n(i) pulse combining gain, which is a factor $N_f$, and (ii) pulse spreading\ngain, which is $N_c=T_f/T_c$, where $T_f$ is the mean interval between two\nsubsequent pulses. This paper investigates the trade-off between these two\ntypes of processing gain in the presence of timing jitter. First, an additive\nwhite Gaussian noise (AWGN) channel is considered and approximate closed form\nexpressions for bit error probability are derived for impulse radio systems\nwith and without pulse-based polarity randomization. Both symbol-synchronous\nand chip-synchronous scenarios are considered. The effects of multiple-access\ninterference and timing jitter on the selection of optimal system parameters\nare explained through theoretical analysis. Finally, a multipath scenario is\nconsidered and the trade-off between processing gains of a synchronous impulse\nradio system with pulse-based polarity randomization is analyzed. The effects\nof the timing jitter, multiple-access interference and inter-frame interference\nare investigated. Simulation studies support the theoretical results.\n\n", "human_text": "  In time hopping impulse radio, $N_f$ pulses of duration $T_c$ are transmitted\nfor each information symbol. This gives rise to two types of processing gain:\n(i) pulse combining gain, which is a factor $N_f$, and (ii) pulse spreading\ngain, which is $N_c=T_f/T_c$, where $T_f$ is the mean interval between two\nsubsequent pulses. This paper investigates the trade-off between these two\ntypes of processing gain in the presence of timing jitter. First, an additive\nwhite Gaussian noise (AWGN) channel is considered and approximate closed form\nexpressions for bit error probability are derived for impulse radio systems\nwith and without pulse-based polarity randomization. Both symbol-synchronous\nand chip-synchronous scenarios are considered. The effects of multiple-access\ninterference and timing jitter on the selection of optimal system parameters\nare explained through theoretical analysis. Finally, a multipath scenario is\nconsidered and the trade-off between processing gains of a synchronous impulse\nradio system with pulse-based polarity randomization is analyzed. The effects\nof the timing jitter, multiple-access interference and inter-frame interference\nare investigated. Simulation studies support the theoretical results.\n", "machine_text": "In this paper, we explore the give-and-take between the two benefits of time hopping impulse radio, pulse combining gain and pulse spreading gain, in presence of timing jitter. We analyze the impact of Additive White Gaussian Noise (AWGN) channel on bit error probability for systems with and without pulse-based randomization, using both symbol- synchronous and chip-synchronous scenarios. In addition, the effects of multiple access interference and timing jitter on the selection of optimal system parameters are researched and clarified through theoretical observations. Finally, a multipath scenario is investigated, to assess the trade-off between processing gains of a synchronous impulse radio system with pulse-based polarity randomization. The effects of timing jitter, multiple-access interference and inter-frame interference are also consider and proved by simulation studies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3408}
{"prompt": "Rephrase the abstract of an article with title 'Evolutionary Neural Gas (ENG): A Model of Self Organizing Network from\n  Input Categorization'.\n  Despite their claimed biological plausibility, most self organizing networks\nhave strict topological constraints and consequently they cannot take into\naccount a wide range of external stimuli. Furthermore their evolution is\nconditioned by deterministic laws which often are not correlated with the\nstructural parameters and the global status of the network, as it should happen\nin a real biological system. In nature the environmental inputs are noise\naffected and fuzzy. Which thing sets the problem to investigate the possibility\nof emergent behaviour in a not strictly constrained net and subjected to\ndifferent inputs. It is here presented a new model of Evolutionary Neural Gas\n(ENG) with any topological constraints, trained by probabilistic laws depending\non the local distortion errors and the network dimension. The network is\nconsidered as a population of nodes that coexist in an ecosystem sharing local\nand global resources. Those particular features allow the network to quickly\nadapt to the environment, according to its dimensions. The ENG model analysis\nshows that the net evolves as a scale-free graph, and justifies in a deeply\nphysical sense- the term gas here used.\n\n", "human_text": "  Despite their claimed biological plausibility, most self organizing networks\nhave strict topological constraints and consequently they cannot take into\naccount a wide range of external stimuli. Furthermore their evolution is\nconditioned by deterministic laws which often are not correlated with the\nstructural parameters and the global status of the network, as it should happen\nin a real biological system. In nature the environmental inputs are noise\naffected and fuzzy. Which thing sets the problem to investigate the possibility\nof emergent behaviour in a not strictly constrained net and subjected to\ndifferent inputs. It is here presented a new model of Evolutionary Neural Gas\n(ENG) with any topological constraints, trained by probabilistic laws depending\non the local distortion errors and the network dimension. The network is\nconsidered as a population of nodes that coexist in an ecosystem sharing local\nand global resources. Those particular features allow the network to quickly\nadapt to the environment, according to its dimensions. The ENG model analysis\nshows that the net evolves as a scale-free graph, and justifies in a deeply\nphysical sense- the term gas here used.\n", "machine_text": "\nIn this article, we explore the potential of Evolutionary Neural Gas (ENG) as a model of self organizing network that is able to take into account a wide range of external inputs. This model is different than traditional self organizing networks in the sense that there are no topological constraints, and the evolution is dictated by probabilistic laws that depend on the local distortion errors and the network dimension. This creates an ecosystem of randomly connected nodes that can quickly adapt to environmental inputs. An analysis of ENG reveals that the network evolves as a scale-free graph, a feature that gives it the justification of the term 'gas' as used here.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0598}
{"prompt": "Rephrase the abstract of an article with title 'Functional renormalization for quantum phase transitions with\n  non-relativistic bosons'.\n  Functional renormalization yields a simple unified description of bosons at\nzero temperature, in arbitrary space dimension $d$ and for $M$ complex fields.\nWe concentrate on nonrelativistic bosons and an action with a linear time\nderivative. The ordered phase can be associated with a nonzero density of\n(quasi) particles $n$. The behavior of observables and correlation functions in\nthe ordered phase depends crucially on the momentum $k_{ph}$, which is\ncharacteristic for a given experiment. For the dilute regime $k_{ph}\\gtrsim\nn^{1/d}$ the quantum phase transition is simple, with the same ``mean field''\ncritical exponents for all $d$ and $M$. On the other hand, the dense regime\n$k_{ph}\\ll n^{1/d}$ reveals a rather rich spectrum of features, depending on\n$d$ and $M$. In this regime one observes for $d\\leq 3$ a crossover to a\nrelativistic action with second time derivatives. This admits order for $d>1$,\nwhereas $d=1$ shows a behavior similar to the low temperature phase of the\nclassical two-dimensional $O(2M)$-models.\n\n", "human_text": "  Functional renormalization yields a simple unified description of bosons at\nzero temperature, in arbitrary space dimension $d$ and for $M$ complex fields.\nWe concentrate on nonrelativistic bosons and an action with a linear time\nderivative. The ordered phase can be associated with a nonzero density of\n(quasi) particles $n$. The behavior of observables and correlation functions in\nthe ordered phase depends crucially on the momentum $k_{ph}$, which is\ncharacteristic for a given experiment. For the dilute regime $k_{ph}\\gtrsim\nn^{1/d}$ the quantum phase transition is simple, with the same ``mean field''\ncritical exponents for all $d$ and $M$. On the other hand, the dense regime\n$k_{ph}\\ll n^{1/d}$ reveals a rather rich spectrum of features, depending on\n$d$ and $M$. In this regime one observes for $d\\leq 3$ a crossover to a\nrelativistic action with second time derivatives. This admits order for $d>1$,\nwhereas $d=1$ shows a behavior similar to the low temperature phase of the\nclassical two-dimensional $O(2M)$-models.\n", "machine_text": "\nThrough the use of functional renormalization, this paper investigates how bosons behave at zero\ntemperature in space dimensions, $d$, and for $M$ complex fields with a linear time derivative action. \nFor the dilute regime, characterized by $k_{ph}\\gtrsim n^{1/d}$, the quantum phase transition is found to simplify, \nwith the same ``mean field'' critical exponents for all $d$ and $M$. In contrast, the dense regime with \n$k_{ph}\\ll n^{1/d}$ is shown to exhibit a variety of features depending on both $d$ and $M$. \nFor $d\\leq 3$, when a relativistic action with second time derivatives is adopted, one \nfinds that for $d>1$ order is restored, with $d=1$ displaying a behavior akin to the low temperature phase \nof classical two-dimensional $O(2M)$-models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1661}
{"prompt": "Rephrase the abstract of an article with title 'Transient X-ray Emission from Normal Galactic Nuclei'.\n  X-ray transients appeared in optically non-active galactic nuclei have been\nobserved in recent years. The most popular model explaining this kind of\nphenomena is the conventional tidal disruption model. In this model, when a\nstar moves within the tidal radius of a black hole, part of the star materials\nwill fall into the black hole through an accretion disk, which gives rise to\nthe luminous flare. We propose that the X-ray emission may not necessarily come\nfrom radiation of the accretion disk alone. Instead, it may be related to a\njet. As the jet travels in the interstellar medium, a shock is produced and\nsynchrotron radiation is expected. We compared the model light curve and the\nsynchrotron radiation spectrum with the observed data, and find that our model\nexplains the observed light curve and late-time spectrum well. Our model\npredicts that these transient active galactic nuclei could be sources of the\nfuture gamma-ray satellites, e.g. GLAST and the emission region will be\nexpanding with time.\n\n", "human_text": "  X-ray transients appeared in optically non-active galactic nuclei have been\nobserved in recent years. The most popular model explaining this kind of\nphenomena is the conventional tidal disruption model. In this model, when a\nstar moves within the tidal radius of a black hole, part of the star materials\nwill fall into the black hole through an accretion disk, which gives rise to\nthe luminous flare. We propose that the X-ray emission may not necessarily come\nfrom radiation of the accretion disk alone. Instead, it may be related to a\njet. As the jet travels in the interstellar medium, a shock is produced and\nsynchrotron radiation is expected. We compared the model light curve and the\nsynchrotron radiation spectrum with the observed data, and find that our model\nexplains the observed light curve and late-time spectrum well. Our model\npredicts that these transient active galactic nuclei could be sources of the\nfuture gamma-ray satellites, e.g. GLAST and the emission region will be\nexpanding with time.\n", "machine_text": "Recently identified X-ray transients associated with optically non-active galactic nuclei have been studied in relation to the conventional tidal disruption model. This suggests the X-ray emission is generated by accretion disk radiation, yet the model does not fully explain the observed light curves and late-time spectra. Therefore, we consider the hypothesis that the X-ray emission from these transient active galactic nuclei is also related to a shock-produced jet. After comparing the model light curves and synchrotron radiation spectra with the observed data, we have found evidence to support our hypothesis. Our model predicts that these transient galactic nuclei may soon be detectable by gamma-ray satellites such as GLAST and that the emission region will, over time, expand.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.348}
{"prompt": "Rephrase the abstract of an article with title 'Galaxy Evolution and Environment'.\n  The properties of galaxies are strongly correlated with their environment,\nwith red galaxies dominating galaxy clusters and blue galaxies dominating the\ngeneral field. However, not all field galaxies are young: studies of the\ncolors, line strengths, and M/L ratios of massive early-type galaxies at\n0<z<1.3 show that the most massive galaxies do not seem to care about their\nsurroundings, and have very similar ages irrespective of their environment.\nThere is good evidence that the growth of these galaxies does continue longer\nin the field than in clusters, via (nearly) dissipationless mergers of already\nold galaxies. These results are consistent with predictions of recent galaxy\nformation models, which incorporate AGN feedback to suppress star formation in\nthe most massive halos. Systematic studies of the relation of galaxies with\ntheir environment beyond z=1 are difficult, and still somewhat contradictory.\nIntriguingly both the DEEP2 and VVDS surveys find that the color-density\nrelation disappears at z~1.3, unfortunately just at the point where both\nsurveys become highly incomplete. On the other hand, clustering studies at\nz~2.5 have shown that red galaxies cluster more strongly than blue galaxies,\nimplying that the color-density relation was already in place at that redshift.\n\n", "human_text": "  The properties of galaxies are strongly correlated with their environment,\nwith red galaxies dominating galaxy clusters and blue galaxies dominating the\ngeneral field. However, not all field galaxies are young: studies of the\ncolors, line strengths, and M/L ratios of massive early-type galaxies at\n0<z<1.3 show that the most massive galaxies do not seem to care about their\nsurroundings, and have very similar ages irrespective of their environment.\nThere is good evidence that the growth of these galaxies does continue longer\nin the field than in clusters, via (nearly) dissipationless mergers of already\nold galaxies. These results are consistent with predictions of recent galaxy\nformation models, which incorporate AGN feedback to suppress star formation in\nthe most massive halos. Systematic studies of the relation of galaxies with\ntheir environment beyond z=1 are difficult, and still somewhat contradictory.\nIntriguingly both the DEEP2 and VVDS surveys find that the color-density\nrelation disappears at z~1.3, unfortunately just at the point where both\nsurveys become highly incomplete. On the other hand, clustering studies at\nz~2.5 have shown that red galaxies cluster more strongly than blue galaxies,\nimplying that the color-density relation was already in place at that redshift.\n", "machine_text": "\nA recent investigation of galaxies between 0-1.3 redshift has revealed a significant correlation between the properties of galaxies and their environment, with red galaxies found to be common in clusters while blue galaxies populate the general field. Though, not all field galaxies are young according to the study, with the most massive galaxies found to have similar ages regardless of their background. This supports the theory of galaxy formation which incorporates AGN feedback to impede star formation in massive halos. There is still some, albeit nuanced, discrepancy in findings of surveys at redshifts beyond 1.3. Interestingly, the DEEP2 and VVDS surveys discovered that the connection between color and density of galaxies was no longer present at z=1.3, the point which their respective studies began to lack complete data. At the same time, clustering studies conducted at z~2.5 concluded that red galaxies were more heavily clustered than blue galaxies, a result which suggests the color-density relation was existing since at least that redshift.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.176}
{"prompt": "Rephrase the abstract of an article with title 'Converting genetic network oscillations into somite spatial pattern'.\n  In most vertebrate species, the body axis is generated by the formation of\nrepeated transient structures called somites. This spatial periodicity in\nsomitogenesis has been related to the temporally sustained oscillations in\ncertain mRNAs and their associated gene products in the cells forming the\npresomatic mesoderm. The mechanism underlying these oscillations have been\nidentified as due to the delays involved in the synthesis of mRNA and\ntranslation into protein molecules [J. Lewis, Current Biol. {\\bf 13}, 1398\n(2003)]. In addition, in the zebrafish embryo intercellular Notch signalling\ncouples these oscillators and a longitudinal positional information signal in\nthe form of an Fgf8 gradient exists that could be used to transform these\ncoupled temporal oscillations into the observed spatial periodicity of somites.\nHere we consider a simple model based on this known biology and study its\nconsequences for somitogenesis. Comparison is made with the known properties of\nsomite formation in the zebrafish embryo . We also study the effects of\nlocalized Fgf8 perturbations on somite patterning.\n\n", "human_text": "  In most vertebrate species, the body axis is generated by the formation of\nrepeated transient structures called somites. This spatial periodicity in\nsomitogenesis has been related to the temporally sustained oscillations in\ncertain mRNAs and their associated gene products in the cells forming the\npresomatic mesoderm. The mechanism underlying these oscillations have been\nidentified as due to the delays involved in the synthesis of mRNA and\ntranslation into protein molecules [J. Lewis, Current Biol. {\\bf 13}, 1398\n(2003)]. In addition, in the zebrafish embryo intercellular Notch signalling\ncouples these oscillators and a longitudinal positional information signal in\nthe form of an Fgf8 gradient exists that could be used to transform these\ncoupled temporal oscillations into the observed spatial periodicity of somites.\nHere we consider a simple model based on this known biology and study its\nconsequences for somitogenesis. Comparison is made with the known properties of\nsomite formation in the zebrafish embryo . We also study the effects of\nlocalized Fgf8 perturbations on somite patterning.\n", "machine_text": "\nThrough genetic network oscillations and the presence of a longitudinal positional information signal, the zebrafish embryo is able to generate the body axis by the formation of repeated somites. By investigating a model based on known biology, the mechanism of somitogenesis can be elucidated. The model was then compared to the actual structure of somites seen in the zebrafish embryo and further validated by studying the effects of localized Fgf8 perturbations. This paper highlights how molecular oscillations and signaling gradients can be used to convert into the spatial pattern of somites.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3071}
{"prompt": "Rephrase the abstract of an article with title 'The evolution of interstellar clouds in a streaming hot plasma including\n  heat conduction'.\n  To examine the evolution of giant molecular clouds in the stream of a hot\nplasma we performed two-dimensional hydrodynamical simulations that take full\naccount of self-gravity, heating and cooling effects and heat conduction by\nelectrons. We use the thermal conductivity of a fully ionized hydrogen plasma\nproposed by Spitzer and a saturated heat flux according to Cowie & McKee in\nregions where the mean free path of the electrons is large compared to the\ntemperature scaleheight. Significant structural and evolutionary differences\noccur between simulations with and without heat conduction. Dense clouds in\npure dynamical models experience dynamical destruction by Kelvin-Helmholtz (KH)\ninstability. In static models heat conduction leads to evaporation of such\nclouds. Heat conduction acting on clouds in a gas stream smooths out steep\ntemperature and density gradients at the edge of the cloud because the\nconduction timescale is shorter than the cooling timescale. This diminishes the\nvelocity gradient between the streaming plasma and the cloud, so that the\ntimescale for the onset of KH instabilities increases, and the surface of the\ncloud becomes less susceptible to KH instabilities. The stabilisation effect of\nheat conduction against KH instability is more pronounced for smaller and less\nmassive clouds. As in the static case more realistic cloud conditions allow\nheat conduction to transfer hot material onto the cloud's surface and to mix\nthe accreted gas deeper into the cloud.\n\n", "human_text": "  To examine the evolution of giant molecular clouds in the stream of a hot\nplasma we performed two-dimensional hydrodynamical simulations that take full\naccount of self-gravity, heating and cooling effects and heat conduction by\nelectrons. We use the thermal conductivity of a fully ionized hydrogen plasma\nproposed by Spitzer and a saturated heat flux according to Cowie & McKee in\nregions where the mean free path of the electrons is large compared to the\ntemperature scaleheight. Significant structural and evolutionary differences\noccur between simulations with and without heat conduction. Dense clouds in\npure dynamical models experience dynamical destruction by Kelvin-Helmholtz (KH)\ninstability. In static models heat conduction leads to evaporation of such\nclouds. Heat conduction acting on clouds in a gas stream smooths out steep\ntemperature and density gradients at the edge of the cloud because the\nconduction timescale is shorter than the cooling timescale. This diminishes the\nvelocity gradient between the streaming plasma and the cloud, so that the\ntimescale for the onset of KH instabilities increases, and the surface of the\ncloud becomes less susceptible to KH instabilities. The stabilisation effect of\nheat conduction against KH instability is more pronounced for smaller and less\nmassive clouds. As in the static case more realistic cloud conditions allow\nheat conduction to transfer hot material onto the cloud's surface and to mix\nthe accreted gas deeper into the cloud.\n", "machine_text": "\nThis study employed two-dimensional hydrodynamical simulations in order to investigate the impact of heat conduction on the evolution of interstellar clouds within a hot plasma stream. Self-gravity, cooling and heating effects were also taken into consideration. The results of the simulations showed considerable differences depending on the presence or absence of heat conduction from the plasma stream. In simulations without thermal conduction, Kelvin-Helmholtz (KH) instabilities were the chief cause of a cloud's rapid destruction. When heat conduction was allowed, the temperature and density gradients around the edge of the cloud were significantly weakened. This lengthened the timescale for KH instabilities to arise and led to a decline in the cloud's vulnerability to KH instabilities. The effect was more pronounced for smaller and less massive clouds. Furthermore, hot material was transferred from the plasma onto the cloud's surface and mixed deeper into the cloud.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3592}
{"prompt": "Rephrase the abstract of an article with title 'Spatial separation of small and large grains in the transitional disk\n  around the young star IRS 48'.\n  We present spatially resolved mid-infrared images of the disk surrounding the\nyoung star IRS 48 in the Ophiuchus cloud complex. The disk exhibits a ring-like\nstructure at 18.7 micron, and is dominated by very strong emission from\npolycyclic aromatic hydrocarbons at shorter wavelengths. This allows a detailed\nstudy of the relative distributions of small and large dust grains.\n  Images of IRS 48 in 5 mid-infrared bands from 8.6 to 18.7 micron as well as a\nlow resolution N-band spectrum are obtained with VLT-VISIR. Optical\nspectroscopy is used to determine the spectral type of the central star and to\nmeasure the strength of the Halpha line.\n  The 18.7 micron ring peaks at a diameter of 110 AU, with a gap of ~ 60 AU.\nThe shape of the ring is consistent with an inclination of i = 48 +- 8 degrees.\nIn contrast, the 7.5-13 micron PAH emission bands are centered on the source\nand appear to fill the gap within the ring. The measured PAH line strengths are\n10-100x stronger than those typically measured for young M0 stars and can only\nbe explained with a high PAH abundance and/or strong excess optical/UV\nemission. The morphology of the images, combined with the absence of a silicate\nemission feature, imply that the inner disk has been cleared of micron-sized\ndust but with a significant population of PAHs remaining. We argue that the gap\ncan be due to grain growth and settling or to clearing by an unseen planetary\nor low-mass companion. IRS 48 may represent a short-lived transitional phase\nfrom a classical to a weak-line T Tauri star.\n\n", "human_text": "  We present spatially resolved mid-infrared images of the disk surrounding the\nyoung star IRS 48 in the Ophiuchus cloud complex. The disk exhibits a ring-like\nstructure at 18.7 micron, and is dominated by very strong emission from\npolycyclic aromatic hydrocarbons at shorter wavelengths. This allows a detailed\nstudy of the relative distributions of small and large dust grains.\n  Images of IRS 48 in 5 mid-infrared bands from 8.6 to 18.7 micron as well as a\nlow resolution N-band spectrum are obtained with VLT-VISIR. Optical\nspectroscopy is used to determine the spectral type of the central star and to\nmeasure the strength of the Halpha line.\n  The 18.7 micron ring peaks at a diameter of 110 AU, with a gap of ~ 60 AU.\nThe shape of the ring is consistent with an inclination of i = 48 +- 8 degrees.\nIn contrast, the 7.5-13 micron PAH emission bands are centered on the source\nand appear to fill the gap within the ring. The measured PAH line strengths are\n10-100x stronger than those typically measured for young M0 stars and can only\nbe explained with a high PAH abundance and/or strong excess optical/UV\nemission. The morphology of the images, combined with the absence of a silicate\nemission feature, imply that the inner disk has been cleared of micron-sized\ndust but with a significant population of PAHs remaining. We argue that the gap\ncan be due to grain growth and settling or to clearing by an unseen planetary\nor low-mass companion. IRS 48 may represent a short-lived transitional phase\nfrom a classical to a weak-line T Tauri star.\n", "machine_text": "\nWe analyze the disk around the young star IRS 48 situated in the Ophiuchus cloud complex, making use of mid-infrared imagery from VISIR and taking into account the spectral type and Halpha line strength of the central star. Our findings reveal a ring-like structure 18.7 microns in diameter with a gap of approximately 60 AU, suggesting that the inner disk is depleted of small dust yet a PAH population persists. We infer that this may represent an intermediate stage from a classical to a weak-line T Tauri star, and the gap might be the result of grain growth and settling or planetary or low-mass companion clearance.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2969}
{"prompt": "Rephrase the abstract of an article with title 'Timing and Lensing of the Colliding Bullet Clusters: barely enough time\n  and gravity to accelerate the bullet'.\n  We present semi-analytical constraint on the amount of dark matter in the\nmerging bullet galaxy cluster using the classical Local Group timing arguments.\nWe consider particle orbits in potential models which fit the lensing data.\n{\\it Marginally consistent} CDM models in Newtonian gravity are found with a\ntotal mass M_{CDM} = 1 x 10^{15}Msun of Cold DM: the bullet subhalo can move\nwith V_{DM}=3000km/s, and the \"bullet\" X-ray gas can move with\nV_{gas}=4200km/s. These are nearly the {\\it maximum speeds} that are\naccelerable by the gravity of two truncated CDM halos in a Hubble time even\nwithout the ram pressure. Consistency breaks down if one adopts higher end of\nthe error bars for the bullet gas speed (5000-5400km/s), and the bullet gas\nwould not be bound by the sub-cluster halo for the Hubble time. Models with\nV_{DM}~ 4500km/s ~ V_{gas} would invoke unrealistic large amount M_{CDM}=7x\n10^{15}Msun of CDM for a cluster containing only ~ 10^{14}Msun of gas. Our\nresults are generalisable beyond General Relativity, e.g., a speed of\n$4500\\kms$ is easily obtained in the relativistic MONDian lensing model of\nAngus et al. (2007). However, MONDian model with little hot dark matter\n$M_{HDM} \\le 0.6\\times 10^{15}\\msun$ and CDM model with a small halo mass $\\le\n1\\times 10^{15}\\msun$ are barely consistent with lensing and velocity data.\n\n", "human_text": "  We present semi-analytical constraint on the amount of dark matter in the\nmerging bullet galaxy cluster using the classical Local Group timing arguments.\nWe consider particle orbits in potential models which fit the lensing data.\n{\\it Marginally consistent} CDM models in Newtonian gravity are found with a\ntotal mass M_{CDM} = 1 x 10^{15}Msun of Cold DM: the bullet subhalo can move\nwith V_{DM}=3000km/s, and the \"bullet\" X-ray gas can move with\nV_{gas}=4200km/s. These are nearly the {\\it maximum speeds} that are\naccelerable by the gravity of two truncated CDM halos in a Hubble time even\nwithout the ram pressure. Consistency breaks down if one adopts higher end of\nthe error bars for the bullet gas speed (5000-5400km/s), and the bullet gas\nwould not be bound by the sub-cluster halo for the Hubble time. Models with\nV_{DM}~ 4500km/s ~ V_{gas} would invoke unrealistic large amount M_{CDM}=7x\n10^{15}Msun of CDM for a cluster containing only ~ 10^{14}Msun of gas. Our\nresults are generalisable beyond General Relativity, e.g., a speed of\n$4500\\kms$ is easily obtained in the relativistic MONDian lensing model of\nAngus et al. (2007). However, MONDian model with little hot dark matter\n$M_{HDM} \\le 0.6\\times 10^{15}\\msun$ and CDM model with a small halo mass $\\le\n1\\times 10^{15}\\msun$ are barely consistent with lensing and velocity data.\n", "machine_text": "\nIn this article, we explore the implications of timing and lensing observations of the colliding Bullet Clusters to estimate the amount of dark matter in the merged galaxy. Utilizing particle orbits and potential models that fit the lensing data, we find {\\it barely adequate} models of Cold Dark Matter (CDM) with Newtonian gravity in which the bullet subhalo possesses a total mass of around $1\\times 10^{15}\\msun$ and moves at a speed of $3000\\kms$, while the 'bullet' X-ray gas can move at a rate of $4200\\kms$. These velocities represent near the high end of what is hope to be manageable by the gravity of two truncated CDM halos in a Hubble period, even without taking into account the influence of ram pressure. If the upper extremes of bullet gas speed ($5000-5400\\kms$) are accepted, the consistency breaks down, and the gas would not remain bound to the sub-cluster halo for the entire Hubble time. Models with V_{DM} = 4500\\kms ~ V_{gas} would necessitate an excessive amount of CDM for a cluster holding $~10^{14}\\msun$ of gas. Our conclusions are applicable beyond General Relativity, for example, a velocity of $4500\\kms$ is easily achieved in the relativistic MONDian lensing model of Angus et al. (2007). Moreover, MONDian models with a marginal quantity of Hot Dark Matter ($M_{HDM} \u2264 0.6\\times 10^{15}\\msun$) and CDM models with reduced halo mass ($ \u2264 1\\times 10^{15}\\msun$) are just barely consistent with both lensing and velocity data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0094}
{"prompt": "Rephrase the abstract of an article with title 'Marcus-Lushnikov processes, Smoluchowski's and Flory's models'.\n  The Marcus-Lushnikov process is a finite stochastic particle system in which\neach particle is entirely characterized by its mass. Each pair of particles\nwith masses $x$ and $y$ merges into a single particle at a given rate $K(x,y)$.\nWe consider a {\\it strongly gelling} kernel behaving as $K(x,y)=x^\\alpha y + x\ny^\\alpha$ for some $\\alpha\\in (0,1]$. In such a case, it is well-known that\n{\\it gelation} occurs, that is, giant particles emerge. Then two possible\nmodels for hydrodynamic limits of the Marcus-Lushnikov process arise: the\nSmoluchowski equation, in which the giant particles are inert, and the Flory\nequation, in which the giant particles interact with finite ones. We show that,\nwhen using a suitable cut-off coagulation kernel in the Marcus-Lushnikov\nprocess and letting the number of particles increase to infinity, the possible\nlimits solve either the Smoluchowski equation or the Flory equation. We also\nstudy the asymptotic behaviour of the largest particle in the Marcus-Lushnikov\nprocess without cut-off and show that there is only one giant particle. This\nsingle giant particle represents, asymptotically, the lost mass of the solution\nto the Flory equation.\n\n", "human_text": "  The Marcus-Lushnikov process is a finite stochastic particle system in which\neach particle is entirely characterized by its mass. Each pair of particles\nwith masses $x$ and $y$ merges into a single particle at a given rate $K(x,y)$.\nWe consider a {\\it strongly gelling} kernel behaving as $K(x,y)=x^\\alpha y + x\ny^\\alpha$ for some $\\alpha\\in (0,1]$. In such a case, it is well-known that\n{\\it gelation} occurs, that is, giant particles emerge. Then two possible\nmodels for hydrodynamic limits of the Marcus-Lushnikov process arise: the\nSmoluchowski equation, in which the giant particles are inert, and the Flory\nequation, in which the giant particles interact with finite ones. We show that,\nwhen using a suitable cut-off coagulation kernel in the Marcus-Lushnikov\nprocess and letting the number of particles increase to infinity, the possible\nlimits solve either the Smoluchowski equation or the Flory equation. We also\nstudy the asymptotic behaviour of the largest particle in the Marcus-Lushnikov\nprocess without cut-off and show that there is only one giant particle. This\nsingle giant particle represents, asymptotically, the lost mass of the solution\nto the Flory equation.\n", "machine_text": "\nThis paper considers the Marcus-Lushnikov process, a stochastic particle system in which each particle is characterized by mass. We investigate the implications of a strongly gelling kernel, $K(x,y)=x^\\alpha y + x y^\\alpha$, where gelation occurs, resulting in the emergence of giant particles. Two possible hydrodynamic limits then arise: the Smoluchowski equation, in which the large particles are static, and the Flory equation, wherein the huge particles are reactive. Using a specific cut-off in the Marcus-Lushnikov process, we show that the possible limits solve either the Smoluchowski or the Flory equation. Further, we also explore the asymptotic behaviour of the largest particle in the Marcus-Lushnikov process sans cut-off, displaying that there is only one giant particle which asymptotically represents the lost mass of the Flory equation solution.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2057}
{"prompt": "Rephrase the abstract of an article with title 'Galaxy evolution in the infra-red: comparison of a hierarchical galaxy\n  formation model with SPITZER data'.\n  We present predictions for the evolution of the galaxy luminosity function,\nnumber counts and redshift distributions in the IR based on the Lambda-CDM\ncosmological model. We use the combined GALFORM semi-analytical galaxy\nformation model and GRASIL spectrophotometric code to compute galaxy SEDs\nincluding the reprocessing of radiation by dust. The model, which is the same\nas that in Baugh et al (2005), assumes two different IMFs: a normal solar\nneighbourhood IMF for quiescent star formation in disks, and a very top-heavy\nIMF in starbursts triggered by galaxy mergers. We have shown previously that\nthe top-heavy IMF seems to be necessary to explain the number counts of faint\nsub-mm galaxies. We compare the model with observational data from the SPITZER\nSpace Telescope, with the model parameters fixed at values chosen before\nSPITZER data became available. We find that the model matches the observed\nevolution in the IR remarkably well over the whole range of wavelengths probed\nby SPITZER. In particular, the SPITZER data show that there is strong evolution\nin the mid-IR galaxy luminosity function over the redshift range z ~ 0-2, and\nthis is reproduced by our model without requiring any adjustment of parameters.\nOn the other hand, a model with a normal IMF in starbursts predicts far too\nlittle evolution in the mid-IR luminosity function, and is therefore excluded.\n\n", "human_text": "  We present predictions for the evolution of the galaxy luminosity function,\nnumber counts and redshift distributions in the IR based on the Lambda-CDM\ncosmological model. We use the combined GALFORM semi-analytical galaxy\nformation model and GRASIL spectrophotometric code to compute galaxy SEDs\nincluding the reprocessing of radiation by dust. The model, which is the same\nas that in Baugh et al (2005), assumes two different IMFs: a normal solar\nneighbourhood IMF for quiescent star formation in disks, and a very top-heavy\nIMF in starbursts triggered by galaxy mergers. We have shown previously that\nthe top-heavy IMF seems to be necessary to explain the number counts of faint\nsub-mm galaxies. We compare the model with observational data from the SPITZER\nSpace Telescope, with the model parameters fixed at values chosen before\nSPITZER data became available. We find that the model matches the observed\nevolution in the IR remarkably well over the whole range of wavelengths probed\nby SPITZER. In particular, the SPITZER data show that there is strong evolution\nin the mid-IR galaxy luminosity function over the redshift range z ~ 0-2, and\nthis is reproduced by our model without requiring any adjustment of parameters.\nOn the other hand, a model with a normal IMF in starbursts predicts far too\nlittle evolution in the mid-IR luminosity function, and is therefore excluded.\n", "machine_text": "\nIn this paper, we investigate the evolution of IR galaxy features using the Lambda-CDM cosmological model and semi-analytical galaxy formation theory. Specifically, we analyze the luminosity function, number counts and redshift distributions based on the GALFORM, GRASIL and SPITZER Space Telescope data. The model, already established by Baugh et al (2005), assumes two distinct initial mass functions (IMF): one is standard for constant star formation in the disks, the other is extremely top-heavy for starbursts launched by galaxy mergers. Previous studies have demonstrated that the high-mass IMF is necessary to explain the number of faint sub-mm galaxies. When tested against SPITZER data with fixed parameter values, the model adequately reproduces the IR evolution over the full range of SPITZER wavelengths. Evidently, the mid-IR luminosity function shows strong evolution from z=0 to z=2 and our results without adjusting any model parameters accurately track the changes. On the contrary, the 'normal IMF' version for starbursts proves to be underperforming in capturing the mid-IR luminosity evolution and is hence ruled out.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1562}
{"prompt": "Rephrase the abstract of an article with title 'Origin of the 60K plateau in YBa_2Cu_3O_6+x'.\n  A model for charge transfer mechanism in YBa2Cu3O6+x high-Tc cuprate based on\ncritical chain length concept is proposed to account for 60K and 90K plateaus\nin Tc(x) dependence. It has been shown, when the statistics of CuO chain\nformation was described in terms of two dimensional asymmetric next-to-nearest\nneighbor Ising (ASYNNNI) model, that at any constant temperature below the top\nof OII phase there exists a uniquely defined value of critical chain length\nlcr(T) that yields a constant doping p(x)=const over the regime of OII phase\n(related to 60K plateau of Tc(x)), while 90K plateau coincides with the\nmonotonously increasing p(x) over optimal doping level p=0.16 in the regime of\nOI phase. Short length chains (l<lcr(T)), together with the first lcr(T)-2\nholes in longer chains (l>lcr(T)), are taken as not capable of attracting\nelectrons from CuO2 planes.. It is shown that only a part (41%) of the\nremaining l-lcr(T)+1 holes in the long chains can capture electrons. The\nresults obtained indicate that the ASYNNNI model and two-plateaus-like behavior\nof Tc(x) in YBa2Cu3O6+x are closely connected.\n\n", "human_text": "  A model for charge transfer mechanism in YBa2Cu3O6+x high-Tc cuprate based on\ncritical chain length concept is proposed to account for 60K and 90K plateaus\nin Tc(x) dependence. It has been shown, when the statistics of CuO chain\nformation was described in terms of two dimensional asymmetric next-to-nearest\nneighbor Ising (ASYNNNI) model, that at any constant temperature below the top\nof OII phase there exists a uniquely defined value of critical chain length\nlcr(T) that yields a constant doping p(x)=const over the regime of OII phase\n(related to 60K plateau of Tc(x)), while 90K plateau coincides with the\nmonotonously increasing p(x) over optimal doping level p=0.16 in the regime of\nOI phase. Short length chains (l<lcr(T)), together with the first lcr(T)-2\nholes in longer chains (l>lcr(T)), are taken as not capable of attracting\nelectrons from CuO2 planes.. It is shown that only a part (41%) of the\nremaining l-lcr(T)+1 holes in the long chains can capture electrons. The\nresults obtained indicate that the ASYNNNI model and two-plateaus-like behavior\nof Tc(x) in YBa2Cu3O6+x are closely connected.\n", "machine_text": "This paper proposes a model for understanding the origin of the two plateaus in the temperature-doping dependence of high-Tc cuprate YBa2Cu3O6+x. The model is based on the concept of critical chain length and described in terms of two-dimensional asymmetric next-to-nearest-neighbor Ising model. It has been found that for any temperature below the top of the OII phase, there exists a uniquely defined critical chain length lcr(T), which yields a constant doping p(x)=const (corresponding to the 60K plateau of Tc(x)) in the regime of OII phase, and following a monotonously increasing p(x) over optimal doping level p=0.16 in the regime of OI phase (90K plateau). A part of the holes in the long chains can capture electrons, leading to two plateaus-like behavior of Tc(x) in YBa2Cu3O6+x.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1887}
{"prompt": "Rephrase the abstract of an article with title 'Fourier resolved spectroscopy of 4U 1728-34: New Insights into Spectral\n  and Temporal Properties of Low-Mass X-ray Binaries'.\n  Using archival RXTE data we derive the 2-16 keV Fourier-resolved spectra of\nthe Atoll source 4U 1728-34 in a sequence of its timing states as its low QPO\nfrequency spans the range between 6 and 94 Hz. The increase in the QPO\nfrequency accompanies a spectral transition of the source from its island to\nits banana states. The banana-states' Fourier-resolved spectra are well fitted\nby a single blackbody component with $kT \\sim 2-3$ keV depending on the source\nposition in the color -- color diagram and the Fourier frequency, thus\nindicating that this spectral component is responsible for the source\nvariability on these timescales. This result is in approximate agreement with\nsimilar behavior exhibited by the Z sources, suggesting that, as in that case,\nthe boundary layer -- the likely source of the thermal component -- is\nsupported by radiation pressure. Furthermore, it is found that the iron line at\n$\\sim$6.6 keV, clearly present in the averaged spectra, not apparent within the\nlimitations of our measurements in the frequency-resolved spectra irrespective\nof the frequency range. This would indicate that this spectral component\nexhibits little variability on time scales comprising the interval\n$10^{-2}-10^2$ seconds. In the island state the single blackbody model proved\ninadequate, particularly notable in our lowest frequency band ($0.008-0.8$ Hz).\nAn absorbed powerlaw or an additive blackbody plus hard powerlaw model was\nrequired to obtain a satisfactory fit. Statistics do not allow unambiguous\ndiscrimination between these possible scenarios.\n\n", "human_text": "  Using archival RXTE data we derive the 2-16 keV Fourier-resolved spectra of\nthe Atoll source 4U 1728-34 in a sequence of its timing states as its low QPO\nfrequency spans the range between 6 and 94 Hz. The increase in the QPO\nfrequency accompanies a spectral transition of the source from its island to\nits banana states. The banana-states' Fourier-resolved spectra are well fitted\nby a single blackbody component with $kT \\sim 2-3$ keV depending on the source\nposition in the color -- color diagram and the Fourier frequency, thus\nindicating that this spectral component is responsible for the source\nvariability on these timescales. This result is in approximate agreement with\nsimilar behavior exhibited by the Z sources, suggesting that, as in that case,\nthe boundary layer -- the likely source of the thermal component -- is\nsupported by radiation pressure. Furthermore, it is found that the iron line at\n$\\sim$6.6 keV, clearly present in the averaged spectra, not apparent within the\nlimitations of our measurements in the frequency-resolved spectra irrespective\nof the frequency range. This would indicate that this spectral component\nexhibits little variability on time scales comprising the interval\n$10^{-2}-10^2$ seconds. In the island state the single blackbody model proved\ninadequate, particularly notable in our lowest frequency band ($0.008-0.8$ Hz).\nAn absorbed powerlaw or an additive blackbody plus hard powerlaw model was\nrequired to obtain a satisfactory fit. Statistics do not allow unambiguous\ndiscrimination between these possible scenarios.\n", "machine_text": "\nBy analyzing RXTE data, we investigate the spectral and temporal properties of the low-mass X-ray binary 4U 1728-34 as its low- QPO frequency ranges from 6 to 94 Hz. As the QPO frequency increases, the source transitions from its island to its banana state. Our Fourier-resolved spectroscopy reveals that the banana states' spectra are well fitted by a single black body component with $kT \\sim 2-3$ keV. This suggests that this component originates from the boundary layer, and is in agreement with similar behavior seen in the Z sources. The iron line at $\\sim$6.6 keV, visible in the averaged spectrum, disappears in the frequency-resolved spectra, suggesting that it has little variability on timescales of $10^{-2}-10^2$s. In the island state, no single model seems to adequately fit the spectra, though an absorbed powerlaw model or an additive blackbody plus hard powerlaw model may suffice.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1552}
{"prompt": "Rephrase the abstract of an article with title 'MiniBooNE Results and Neutrino Schemes with 2 sterile Neutrinos:\n  Possible Mass Orderings and Observables related to Neutrino Masses'.\n  The MiniBooNE and LSND experiments are compatible with each other when two\nsterile neutrinos are added to the three active ones. In this case there are\neight possible mass orderings. In two of them both sterile neutrinos are\nheavier than the three active ones. In the next two scenarios both sterile\nneutrinos are lighter than the three active ones. The remaining four scenarios\nhave one sterile neutrino heavier and another lighter than the three active\nones. We analyze all scenarios with respect to their predictions for\nmass-related observables. These are the sum of neutrino masses as constrained\nby cosmological observations, the kinematic mass parameter as measurable in the\nKATRIN experiment, and the effective mass governing neutrinoless double beta\ndecay. It is investigated how these non-oscillation probes can distinguish\nbetween the eight scenarios. Six of the eight possible mass orderings predict\npositive signals in the KATRIN and future neutrinoless double beta decay\nexperiments. We also remark on scenarios with three sterile neutrinos. In\naddition we make some comments on the possibility of using decays of high\nenergy astrophysical neutrinos to discriminate between the mass orderings in\npresence of two sterile neutrinos.\n\n", "human_text": "  The MiniBooNE and LSND experiments are compatible with each other when two\nsterile neutrinos are added to the three active ones. In this case there are\neight possible mass orderings. In two of them both sterile neutrinos are\nheavier than the three active ones. In the next two scenarios both sterile\nneutrinos are lighter than the three active ones. The remaining four scenarios\nhave one sterile neutrino heavier and another lighter than the three active\nones. We analyze all scenarios with respect to their predictions for\nmass-related observables. These are the sum of neutrino masses as constrained\nby cosmological observations, the kinematic mass parameter as measurable in the\nKATRIN experiment, and the effective mass governing neutrinoless double beta\ndecay. It is investigated how these non-oscillation probes can distinguish\nbetween the eight scenarios. Six of the eight possible mass orderings predict\npositive signals in the KATRIN and future neutrinoless double beta decay\nexperiments. We also remark on scenarios with three sterile neutrinos. In\naddition we make some comments on the possibility of using decays of high\nenergy astrophysical neutrinos to discriminate between the mass orderings in\npresence of two sterile neutrinos.\n", "machine_text": "\nThe MiniBooNE and LSND experiments have been found to potentially be compatible if two sterile neutrinos are incorporated into the existing three active ones. Eight mass ordering scenarios are found to be present, two of which consider the steriles being heavier than the active neutrinos and the other two suggest the opposite. The remaining four include one heavier and one lighter, respectively. Results from cosmological studies and the KATRIN and future neutrinoless double beta decay experiments provide non-oscillation observables potentially capable of discriminating between the eight cases. It has been proposed that high-energy astrophysical neutrinos could decouple the mass orderings in a two-sterile neutrino configuration. All this is discussed, and our paper also considers three-sterile neutrino scenarios.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1462}
{"prompt": "Rephrase the abstract of an article with title 'Conjectures on exact solution of three - dimensional (3D) simple\n  orthorhombic Ising lattices'.\n  We report the conjectures on the three-dimensional (3D) Ising model on simple\northorhombic lattices, together with the details of calculations for a putative\nexact solution. Two conjectures, an additional rotation in the fourth curled-up\ndimension and the weight factors on the eigenvectors, are proposed to serve as\na boundary condition to deal with the topologic problem of the 3D Ising model.\nThe partition function of the 3D simple orthorhombic Ising model is evaluated\nby spinor analysis, by employing these conjectures. Based on the validity of\nthe conjectures, the critical temperature of the simple orthorhombic Ising\nlattices could be determined by the relation of KK* = KK' + KK'' + K'K'' or\nsinh 2K sinh 2(K' + K'' + K'K''/K) = 1. For a simple cubic Ising lattice, the\ncritical point is putatively determined to locate exactly at the golden ratio\nxc = exp(-2Kc) = (sq(5) - 1)/2, as derived from K* = 3K or sinh 2K sinh 6K = 1.\nIf the conjectures would be true, the specific heat of the simple orthorhombic\nIsing system would show a logarithmic singularity at the critical point of the\nphase transition. The spontaneous magnetization and the spin correlation\nfunctions of the simple orthorhombic Ising ferromagnet are derived explicitly.\nThe putative critical exponents derived explicitly for the simple orthorhombic\nIsing lattices are alpha = 0, beta = 3/8, gamma = 5/4, delta = 13/3, eta = 1/8\nand nu = 2/3, showing the universality behavior and satisfying the scaling\nlaws. The cooperative phenomena near the critical point are studied and the\nresults obtained based on the conjectures are compared with those of the\napproximation methods and the experimental findings. The 3D to 2D crossover\nphenomenon differs with the 2D to 1D crossover phenomenon and there is a\ngradual crossover of the exponents from the 3D values to the 2D ones.\n\n", "human_text": "  We report the conjectures on the three-dimensional (3D) Ising model on simple\northorhombic lattices, together with the details of calculations for a putative\nexact solution. Two conjectures, an additional rotation in the fourth curled-up\ndimension and the weight factors on the eigenvectors, are proposed to serve as\na boundary condition to deal with the topologic problem of the 3D Ising model.\nThe partition function of the 3D simple orthorhombic Ising model is evaluated\nby spinor analysis, by employing these conjectures. Based on the validity of\nthe conjectures, the critical temperature of the simple orthorhombic Ising\nlattices could be determined by the relation of KK* = KK' + KK'' + K'K'' or\nsinh 2K sinh 2(K' + K'' + K'K''/K) = 1. For a simple cubic Ising lattice, the\ncritical point is putatively determined to locate exactly at the golden ratio\nxc = exp(-2Kc) = (sq(5) - 1)/2, as derived from K* = 3K or sinh 2K sinh 6K = 1.\nIf the conjectures would be true, the specific heat of the simple orthorhombic\nIsing system would show a logarithmic singularity at the critical point of the\nphase transition. The spontaneous magnetization and the spin correlation\nfunctions of the simple orthorhombic Ising ferromagnet are derived explicitly.\nThe putative critical exponents derived explicitly for the simple orthorhombic\nIsing lattices are alpha = 0, beta = 3/8, gamma = 5/4, delta = 13/3, eta = 1/8\nand nu = 2/3, showing the universality behavior and satisfying the scaling\nlaws. The cooperative phenomena near the critical point are studied and the\nresults obtained based on the conjectures are compared with those of the\napproximation methods and the experimental findings. The 3D to 2D crossover\nphenomenon differs with the 2D to 1D crossover phenomenon and there is a\ngradual crossover of the exponents from the 3D values to the 2D ones.\n", "machine_text": "\nIn this article, we speculate on a potential exact solution to the three-dimensional (3D) Ising model on simple orthorhombic lattices. To this end, we propose two conjectures: introducing an additional rotation in the fourth curled-up dimension, as well as defining the appropriate weight factors on the eigenvectors, which act as boundaries to address the topological problem of the 3D Ising model. Utilizing Spinor analysis, the partition function is evaluated using these conjectures. The critical temperature of the simple orthorhombic Ising lattices is then determined according to the relation of KK* = KK'+KK''+K'K'' or sinh2Ksinh2(K'+K''+K'K''/K)=1. Furthermore, the logarithmic singularity at the transition point, plus the explicit expressions for the spontaneous magnetization and spin correlation functions are derived. Moreover, the critical exponents of the simple orthorhombic Ising lattices, alpha = 0, beta = 3/8, gamma = 5/4, delta = 13/3, eta = 1/8 and nu = 2/3, show the universal behavior and satisfy the scaling laws. Finally, the 3D to 2D crossover differs from the 2D to 1D crossover and a gradual transition of exponents from 3D to 2D is observed. The results of this article are compared with those of other approximate methods and experimental evidence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1045}
{"prompt": "Rephrase the abstract of an article with title 'A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA\n  Networks with Delay QoS Constraints'.\n  A game-theoretic framework is used to study the effect of constellation size\non the energy efficiency of wireless networks for M-QAM modulation. A\nnon-cooperative game is proposed in which each user seeks to choose its\ntransmit power (and possibly transmit symbol rate) as well as the constellation\nsize in order to maximize its own utility while satisfying its delay\nquality-of-service (QoS) constraint. The utility function used here measures\nthe number of reliable bits transmitted per joule of energy consumed, and is\nparticularly suitable for energy-constrained networks. The best-response\nstrategies and Nash equilibrium solution for the proposed game are derived. It\nis shown that in order to maximize its utility (in bits per joule), a user must\nchoose the lowest constellation size that can accommodate the user's delay\nconstraint. This strategy is different from one that would maximize spectral\nefficiency. Using this framework, the tradeoffs among energy efficiency, delay,\nthroughput and constellation size are also studied and quantified. In addition,\nthe effect of trellis-coded modulation on energy efficiency is discussed.\n\n", "human_text": "  A game-theoretic framework is used to study the effect of constellation size\non the energy efficiency of wireless networks for M-QAM modulation. A\nnon-cooperative game is proposed in which each user seeks to choose its\ntransmit power (and possibly transmit symbol rate) as well as the constellation\nsize in order to maximize its own utility while satisfying its delay\nquality-of-service (QoS) constraint. The utility function used here measures\nthe number of reliable bits transmitted per joule of energy consumed, and is\nparticularly suitable for energy-constrained networks. The best-response\nstrategies and Nash equilibrium solution for the proposed game are derived. It\nis shown that in order to maximize its utility (in bits per joule), a user must\nchoose the lowest constellation size that can accommodate the user's delay\nconstraint. This strategy is different from one that would maximize spectral\nefficiency. Using this framework, the tradeoffs among energy efficiency, delay,\nthroughput and constellation size are also studied and quantified. In addition,\nthe effect of trellis-coded modulation on energy efficiency is discussed.\n", "machine_text": "\nIn this article, a game-theoretic method is used to analyze how variations in constellation size impact the energy efficiency of code-division multiple access (CDMA) networks that have a set Quality-of-Service (QoS) delay limit. A non-cooperative game is proposed where users attempt to maximize their individual utility, which is measured by the amount of reliable data transmitted for a given amount of energy consumption, while satisfying the designated delay QoS. The article illustrates the best-response strategies, Nash equilibria, and the trade-offs between energy efficiency, delay, throughput, and constellation size. It is established that to achieve the utmost utility (in bits per joule), a user is to choose the smallest constellation size that meets their delay requirements, as opposed to maximizing spectral efficiency. The influence of trellis-coded modulation on energy efficiency is then explored.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1788}
{"prompt": "Rephrase the abstract of an article with title 'Hierarchy of N=8 Mechanics Models'.\n  Using the N=4 superspace approach in one dimension (time), we construct\ngeneral N=8 supersymmetric mechanics actions for the multiplets (b,8,8-b)\nclassified in hep-th/0406015, with the main focus on the previously unexplored\ncases of (8,8,0), (7,8,1) and (6,8,2), as well as on (5,8,3) for completeness.\nN=8 supersymmetry of the action amounts to a harmonicity condition for the\nLagrangian with respect to its superfield arguments. We derive the generic\noff-shell component action for the ``root'' multiplet (8,8,0), prove that the\nactions for all other multiplets follow from it through automorphic dualities\nand argue that this hierarchical structure is universal. The bosonic target\ngeometry in all cases is conformally flat, with a unique scalar potential\n(except for the root multiplet). We show that the N=4 superfield constraints\nrespect the full R-symmetry and find the explicit realization of its quotient\nover the manifest R-symmetry on superfields and component fields. Several\nR-symmetric N=4 superfield Lagrangians with N=8 supersymmetry are either newly\nfound or reproduced by a simple universal method.\n\n", "human_text": "  Using the N=4 superspace approach in one dimension (time), we construct\ngeneral N=8 supersymmetric mechanics actions for the multiplets (b,8,8-b)\nclassified in hep-th/0406015, with the main focus on the previously unexplored\ncases of (8,8,0), (7,8,1) and (6,8,2), as well as on (5,8,3) for completeness.\nN=8 supersymmetry of the action amounts to a harmonicity condition for the\nLagrangian with respect to its superfield arguments. We derive the generic\noff-shell component action for the ``root'' multiplet (8,8,0), prove that the\nactions for all other multiplets follow from it through automorphic dualities\nand argue that this hierarchical structure is universal. The bosonic target\ngeometry in all cases is conformally flat, with a unique scalar potential\n(except for the root multiplet). We show that the N=4 superfield constraints\nrespect the full R-symmetry and find the explicit realization of its quotient\nover the manifest R-symmetry on superfields and component fields. Several\nR-symmetric N=4 superfield Lagrangians with N=8 supersymmetry are either newly\nfound or reproduced by a simple universal method.\n", "machine_text": " The superspace approach in one dimension is applied to construct N=8 supersymmetric mechanics models for multiplets (b,8,8-b) classified in hep-th/0406015, focusing on the previously unexplored cases of (8,8,0), (7,8,1) and (6,8,2), plus (5,8,3). The N=8 supersymmetry of the action is verified through a harmonicity condition of the Lagrangian to its superfield arguments. It is revealed that the bosonic target geometry is conformally flat, with a unique scalar potential apart from the 'root' multiplet. The N=4 superfield constraints demonstrate respect towards the full R-symmetry, with its quotient over the manifest R-symmetry found in terms of superfields and component fields. Several R-symmetric N=4 superfield Lagrangians with N=8 supersymmetry are uncovered, with a universal method that uncovers or reproduces them.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3064}
{"prompt": "Rephrase the abstract of an article with title 'Expressing Combinatorial Optimization Problems by Systems of Polynomial\n  Equations and the Nullstellensatz'.\n  Systems of polynomial equations over the complex or real numbers can be used\nto model combinatorial problems. In this way, a combinatorial problem is\nfeasible (e.g. a graph is 3-colorable, hamiltonian, etc.) if and only if a\nrelated system of polynomial equations has a solution. In the first part of\nthis paper, we construct new polynomial encodings for the problems of finding\nin a graph its longest cycle, the largest planar subgraph, the edge-chromatic\nnumber, or the largest k-colorable subgraph.\n  For an infeasible polynomial system, the (complex) Hilbert Nullstellensatz\ngives a certificate that the associated combinatorial problem is infeasible.\nThus, unless P = NP, there must exist an infinite sequence of infeasible\ninstances of each hard combinatorial problem for which the minimum degree of a\nHilbert Nullstellensatz certificate of the associated polynomial system grows.\n  We show that the minimum-degree of a Nullstellensatz certificate for the\nnon-existence of a stable set of size greater than the stability number of the\ngraph is the stability number of the graph. Moreover, such a certificate\ncontains at least one term per stable set of G. In contrast, for non-3-\ncolorability, we found only graphs with Nullstellensatz certificates of degree\nfour.\n\n", "human_text": "  Systems of polynomial equations over the complex or real numbers can be used\nto model combinatorial problems. In this way, a combinatorial problem is\nfeasible (e.g. a graph is 3-colorable, hamiltonian, etc.) if and only if a\nrelated system of polynomial equations has a solution. In the first part of\nthis paper, we construct new polynomial encodings for the problems of finding\nin a graph its longest cycle, the largest planar subgraph, the edge-chromatic\nnumber, or the largest k-colorable subgraph.\n  For an infeasible polynomial system, the (complex) Hilbert Nullstellensatz\ngives a certificate that the associated combinatorial problem is infeasible.\nThus, unless P = NP, there must exist an infinite sequence of infeasible\ninstances of each hard combinatorial problem for which the minimum degree of a\nHilbert Nullstellensatz certificate of the associated polynomial system grows.\n  We show that the minimum-degree of a Nullstellensatz certificate for the\nnon-existence of a stable set of size greater than the stability number of the\ngraph is the stability number of the graph. Moreover, such a certificate\ncontains at least one term per stable set of G. In contrast, for non-3-\ncolorability, we found only graphs with Nullstellensatz certificates of degree\nfour.\n", "machine_text": "\nThis article explores how systems of polynomial equations can be used to model and express a variety of combinatorial optimization problems. An important result of this paper is the construction of polynomial encodings for the problems of finding the longest cycle, the largest planar subgraph, the edge-chromatic number, and the largest k-colorable subgraph of a given graph. In addition, we demonstrate that the Hilbert Nullstellensatz can provide certificates of infeasibility for each problem, which implies that the minimum degree of the related certificate for \"hard\" problems must increase along an infinite sequence of problems. We present evidence of this by showing that the minimum degree of the Nullstellensatz certificate for the non-existence of a stable set with size greater than the graph's stability number is the stability number of the graph and that the certificate contains at least one term per stable set. In contrast, the certificate for the non-3-colorability of a graph was only of degree four.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0578}
{"prompt": "Rephrase the abstract of an article with title '4U 0115+63 from RXTE and INTEGRAL Data: Pulse Profile and Cyclotron Line\n  Energy'.\n  We analyze the observations of the transient X-ray pulsar 4U 0115+63 with the\nRXTE and INTEGRAL observatories in a wide X-ray (3-100 keV) energy band during\nits intense outbursts in 1999 and 2004. The energy of the fundamental harmonic\nof the cyclotron resonance absorption line near the maximum of the X-ray flux\nfrom the source (luminosity range 5x10^{37} - 2x10^{38} erg/s) is ~11 keV. When\nthe pulsar luminosity falls below ~5x10^{37} erg/s, the energy of the\nfundamental harmonic is displaced sharply toward the high energies, up to ~16\nkeV. Under the assumption of a dipole magnetic field configuration, this change\nin cyclotron harmonic energy corresponds to a decrease in the height of the\nemitting region by ~2 km, while other spectral parameters, in particular, the\ncutoff energy, remain essentially constant. At a luminosity ~7x10^{37} erg/s,\nfour almost equidistant cyclotron line harmonics are clearly seen in the\nspectrum. This suggests that either the region where the emission originates is\ncompact or the emergent spectrum from different (in height) segments of the\naccretion column is uniform. We have found significant pulse profile variations\nwith energy, luminosity, and time. In particular, we show that the profile\nvariations from pulse to pulse are not reduced to a simple modulation of the\naccretion rate specified by external conditions.\n\n", "human_text": "  We analyze the observations of the transient X-ray pulsar 4U 0115+63 with the\nRXTE and INTEGRAL observatories in a wide X-ray (3-100 keV) energy band during\nits intense outbursts in 1999 and 2004. The energy of the fundamental harmonic\nof the cyclotron resonance absorption line near the maximum of the X-ray flux\nfrom the source (luminosity range 5x10^{37} - 2x10^{38} erg/s) is ~11 keV. When\nthe pulsar luminosity falls below ~5x10^{37} erg/s, the energy of the\nfundamental harmonic is displaced sharply toward the high energies, up to ~16\nkeV. Under the assumption of a dipole magnetic field configuration, this change\nin cyclotron harmonic energy corresponds to a decrease in the height of the\nemitting region by ~2 km, while other spectral parameters, in particular, the\ncutoff energy, remain essentially constant. At a luminosity ~7x10^{37} erg/s,\nfour almost equidistant cyclotron line harmonics are clearly seen in the\nspectrum. This suggests that either the region where the emission originates is\ncompact or the emergent spectrum from different (in height) segments of the\naccretion column is uniform. We have found significant pulse profile variations\nwith energy, luminosity, and time. In particular, we show that the profile\nvariations from pulse to pulse are not reduced to a simple modulation of the\naccretion rate specified by external conditions.\n", "machine_text": "\nThe transient X-ray pulsar 4U 0115+63 underwent efficient outbursts in 1999 and\n2004, which were observed using RXTE and INTEGRAL on a wide energy range (3-100\nkeV). The authors determined that the energy of the lowest resonance absorption\nline in the spectrum near the cycle's peak (luminosity ranging from 5x10^{37} -\n2x10^{38} erg/s) is ~11 keV. They further report that when the luminosity of\nthe pulsar falls to below 5x10^{37} erg/s, the resonance line energy significantly\nincreases up to ~16 keV and the height of the confined emission region reduces\nby ~2 km with no change in other spectral parameters. In addition, when the\nluminosity is at ~7x10^{37} erg/s, four approximately equal resonance line\nharmonics become visible, implying a compact emission spot or uniform radiation\nfrom several accretion columns. The study also provides evidence of considerable\nvariations in the pulse profile depending on energy, luminosity change and\ntime of the outburst. Thus, it is clear that the modulation of the accretion\nrate is not the sole reason for the observed pulse profile variability.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2874}
{"prompt": "Rephrase the abstract of an article with title 'Analytic result for the one-loop massless triangle Feynman diagram'.\n  Different mathematical methods have been applied to obtain the analytic\nresult for the massless triangle Feynman diagram yielding a sum of four\nlinearly independent hypergeometric functions $F_4$. In this paper I work out\nthe diagram and show that that result, though mathematically sound, is not\nphysically correct, because it misses a fundamental physical constraint imposed\nby the conservation of momentum, which should reduce by one the total number of\nlinearly independent (l.i.) functions $F_4$ in the overall solution. Taking\ninto account that the momenta flowing along the three legs of the diagram are\nconstrained by momentum conservation, the number of overall l.i. functions that\nenter the most general solution must reduce accordingly.\n  To determine the exact structure and content of the analytic solution for the\nthree-point function, I use the analogy that exists between Feynman diagrams\nand electric circuit networks, in which the electric current flowing in the\nnetwork plays the role of the momentum flowing in the lines of a Feynman\ndiagram. This analogy is employed to define exactly which three out of the four\nhypergeometric functions are relevant to the analytic solution for the Feynman\ndiagram. The analogy is built based on the equivalence between electric\nresistance circuit networks of type \"Y\" and \"Delta\" in which flows a conserved\ncurrent. The equivalence is established via the theorem of minimum energy\ndissipation within circuits having these structures.\n\n", "human_text": "  Different mathematical methods have been applied to obtain the analytic\nresult for the massless triangle Feynman diagram yielding a sum of four\nlinearly independent hypergeometric functions $F_4$. In this paper I work out\nthe diagram and show that that result, though mathematically sound, is not\nphysically correct, because it misses a fundamental physical constraint imposed\nby the conservation of momentum, which should reduce by one the total number of\nlinearly independent (l.i.) functions $F_4$ in the overall solution. Taking\ninto account that the momenta flowing along the three legs of the diagram are\nconstrained by momentum conservation, the number of overall l.i. functions that\nenter the most general solution must reduce accordingly.\n  To determine the exact structure and content of the analytic solution for the\nthree-point function, I use the analogy that exists between Feynman diagrams\nand electric circuit networks, in which the electric current flowing in the\nnetwork plays the role of the momentum flowing in the lines of a Feynman\ndiagram. This analogy is employed to define exactly which three out of the four\nhypergeometric functions are relevant to the analytic solution for the Feynman\ndiagram. The analogy is built based on the equivalence between electric\nresistance circuit networks of type \"Y\" and \"Delta\" in which flows a conserved\ncurrent. The equivalence is established via the theorem of minimum energy\ndissipation within circuits having these structures.\n", "machine_text": "\nThis paper outlines the analytic result for the one-loop, massless triangle Feynman diagram. In doing so, the analysis exposes a fundamental physical principle embodied in the conservation of momentum that necessitates a reduction in the total number of linearly independent (l.i.) hypergeometric functions $F_4$ in the diagram's overall solution. To accomplish a total reduction in the number of l.i. functions entering the most general solution, this paper draws on analogies that exist between electric resistance circuit networks and Feynman diagrams, which allows for the identification of which three $F_4$ are relevant to the analytic solution. These analogies are constructed based on the equivalence between the structures of electric circuits of type \"Y\" and \"Delta\" with regards to the dissipated energy in a conserved current. Through this analysis, it is possible to identify which $F_4$ are fundamental to understanding the principle of conservation of momentum in the Feynman diagram.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1082}
{"prompt": "Rephrase the abstract of an article with title 'Statistical Mechanics of Time Independent Non-Dissipative Nonequilibrium\n  States'.\n  We examine the question of whether the formal expressions of equilibrium\nstatistical mechanics can be applied to time independent non-dissipative\nsystems that are not in true thermodynamic equilibrium and are nonergodic. By\nassuming the phase space may be divided into time independent, locally ergodic\ndomains, we argue that within such domains the relative probabilities of\nmicrostates are given by the standard Boltzmann weights. In contrast to\nprevious energy landscape treatments, that have been developed specifically for\nthe glass transition, we do not impose an a priori knowledge of the\ninter-domain population distribution. Assuming that these domains are robust\nwith respect to small changes in thermodynamic state variables we derive a\nvariety of fluctuation formulae for these systems. We verify our theoretical\nresults using molecular dynamics simulations on a model glass forming system.\nNon-equilibrium Transient Fluctuation Relations are derived for the\nfluctuations resulting from a sudden finite change to the system's temperature\nor pressure and these are shown to be consistent with the simulation results.\nThe necessary and sufficient conditions for these relations to be valid are\nthat the domains are internally populated by Boltzmann statistics and that the\ndomains are robust. The Transient Fluctuation Relations thus provide an\nindependent quantitative justification for the assumptions used in our\nstatistical mechanical treatment of these systems.\n\n", "human_text": "  We examine the question of whether the formal expressions of equilibrium\nstatistical mechanics can be applied to time independent non-dissipative\nsystems that are not in true thermodynamic equilibrium and are nonergodic. By\nassuming the phase space may be divided into time independent, locally ergodic\ndomains, we argue that within such domains the relative probabilities of\nmicrostates are given by the standard Boltzmann weights. In contrast to\nprevious energy landscape treatments, that have been developed specifically for\nthe glass transition, we do not impose an a priori knowledge of the\ninter-domain population distribution. Assuming that these domains are robust\nwith respect to small changes in thermodynamic state variables we derive a\nvariety of fluctuation formulae for these systems. We verify our theoretical\nresults using molecular dynamics simulations on a model glass forming system.\nNon-equilibrium Transient Fluctuation Relations are derived for the\nfluctuations resulting from a sudden finite change to the system's temperature\nor pressure and these are shown to be consistent with the simulation results.\nThe necessary and sufficient conditions for these relations to be valid are\nthat the domains are internally populated by Boltzmann statistics and that the\ndomains are robust. The Transient Fluctuation Relations thus provide an\nindependent quantitative justification for the assumptions used in our\nstatistical mechanical treatment of these systems.\n", "machine_text": "\nWe investigate if the principles of equilibrium statistical mechanics can be used to model time independent, non-dissipative systems that are out of thermodynamic equilibrium and nonergodic. We propose that the phase space can be divided into locally ergodic sections and suggest that the relative probabilities of different microstates are determined by Boltzmann probabilities within said sections. Unlike similar approaches commonly applied to transitions in glassy systems, we do not assume any prior knowledge of the domain-domain population distribution. Further, we assume that the domains remain consistent given minor variations in thermodynamic state variables, thus deriving various fluctuation equations and validating them with molecular dynamics simulations. We also derive Transient Fluctuation Relations concerning fluctuations caused by abrupt changes in system pressure or temperature that agree with the simulation results. The Transient Fluctuation Relations reinforce the assumptions used in our statistical mechanics approach as long as the domains are internally Boltzmann populated and remain stable.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0753}
{"prompt": "Rephrase the abstract of an article with title 'Magnetic structure of Sm2IrIn8'.\n  The magnetic structure of the intermetallic antiferromagnet Sm2IrIn8 was\ndetermined using x-ray resonant magnetic scattering (XRMS). Below TN = 14.2,\nSm2IrIn8 has a commensurate antiferromagnetic structure with a propagation\nvector (1/2,0,0). The Sm magnetic moments lie in the ab plane and are rotated\nroughly 18 degrees away from the a axis. The magnetic structure of this\ncompound was obtained by measuring the strong dipolar resonant peak whose\nenhancement was of over two orders of magnitude at the L2 edge. At the L3 edge\nboth quadrupolar and dipolar features were observed in the energy line shape.\nThe magnetic structure and properties of Sm2IrIn8 are found to be consistent\nwith the general trend already seen for the Nd-, Tb- and the Ce-based compounds\nfrom the RmMnIn3m+2n family (R = rare earth; M=Rh or Ir, m = 1, 2; n = 0, 1),\nwhere the crystalline electrical field (CEF) effects determine the direction of\nmagnetic moments and the TN evolution in the series. The measured Neel\ntemperature for Sm2IrIn8 is slightly suppressed when compared to the TN of the\nparent cubic compound SmIn3.\n\n", "human_text": "  The magnetic structure of the intermetallic antiferromagnet Sm2IrIn8 was\ndetermined using x-ray resonant magnetic scattering (XRMS). Below TN = 14.2,\nSm2IrIn8 has a commensurate antiferromagnetic structure with a propagation\nvector (1/2,0,0). The Sm magnetic moments lie in the ab plane and are rotated\nroughly 18 degrees away from the a axis. The magnetic structure of this\ncompound was obtained by measuring the strong dipolar resonant peak whose\nenhancement was of over two orders of magnitude at the L2 edge. At the L3 edge\nboth quadrupolar and dipolar features were observed in the energy line shape.\nThe magnetic structure and properties of Sm2IrIn8 are found to be consistent\nwith the general trend already seen for the Nd-, Tb- and the Ce-based compounds\nfrom the RmMnIn3m+2n family (R = rare earth; M=Rh or Ir, m = 1, 2; n = 0, 1),\nwhere the crystalline electrical field (CEF) effects determine the direction of\nmagnetic moments and the TN evolution in the series. The measured Neel\ntemperature for Sm2IrIn8 is slightly suppressed when compared to the TN of the\nparent cubic compound SmIn3.\n", "machine_text": "\nThe magnetic structure of the intermetallic antiferromagnet Sm2IrIn8 has been studied using x-ray resonant magnetic scattering (XRMS). This technique allowed for the detection of a commensurate antiferromagnetic structure with a propagating vector (1/2,0,0) at temperatures below the Neel temperature (TN) of 14.2 K. It was found that the Sm magnetic moments have a plane of rotation in the ab plane and are displaced roughly 18 degrees from the a axis. Multiple features were noted at the L2 and L3 edges of the XRMS, with a resonant peak at the L2 edge that was amplified around two orders of magnitude. The crystalline electrical field (CEF) effects were determined to be of particular relevance in determining the direction of magnetic moments and TN evolution in the series. The Neel temperature of Sm2IrIn8 is, however, slightly lower than that of the parent cubic compound SmIn3.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.148}
{"prompt": "Rephrase the abstract of an article with title 'Flavour-Dependent Type II Leptogenesis'.\n  We reanalyse leptogenesis via the out-of-equilibrium decay of the lightest\nright-handed neutrino in type II seesaw scenarios, taking into account\nflavour-dependent effects. In the type II seesaw mechanism, in addition to the\ntype I seesaw contribution, an additional direct mass term for the light\nneutrinos is present. We consider type II seesaw scenarios where this\nadditional contribution arises from the vacuum expectation value of a Higgs\ntriplet, and furthermore an effective model-independent approach. We\ninvestigate bounds on the flavour-specific decay asymmetries, on the mass of\nthe lightest right-handed neutrino and on the reheat temperature of the early\nuniverse, and compare them to the corresponding bounds in the type I seesaw\nframework. We show that while flavour-dependent thermal type II leptogenesis\nbecomes more efficient for larger mass scale of the light neutrinos, and the\nbounds become relaxed, the type I seesaw scenario for leptogenesis becomes more\nconstrained. We also argue that in general, flavour-dependent effects cannot be\nignored when dealing with leptogenesis in type II seesaw models.\n\n", "human_text": "  We reanalyse leptogenesis via the out-of-equilibrium decay of the lightest\nright-handed neutrino in type II seesaw scenarios, taking into account\nflavour-dependent effects. In the type II seesaw mechanism, in addition to the\ntype I seesaw contribution, an additional direct mass term for the light\nneutrinos is present. We consider type II seesaw scenarios where this\nadditional contribution arises from the vacuum expectation value of a Higgs\ntriplet, and furthermore an effective model-independent approach. We\ninvestigate bounds on the flavour-specific decay asymmetries, on the mass of\nthe lightest right-handed neutrino and on the reheat temperature of the early\nuniverse, and compare them to the corresponding bounds in the type I seesaw\nframework. We show that while flavour-dependent thermal type II leptogenesis\nbecomes more efficient for larger mass scale of the light neutrinos, and the\nbounds become relaxed, the type I seesaw scenario for leptogenesis becomes more\nconstrained. We also argue that in general, flavour-dependent effects cannot be\nignored when dealing with leptogenesis in type II seesaw models.\n", "machine_text": "\nUsing an effective, model-independent approach, we examine the influence of flavour-dependent aspects on Type II Leptogenesis. This type of leptogenesis includes an additional direct mass term for the light neutrinos, which is usually provided by the vacuum expectation value of a Higgs triplet. We analyze the bound on the flavour-specific decay asymmetry, on the mass of the lightest right-handed neutrino and on the reheat temperature of the early universe in the type II seesaw frameworks. We find that the leptogenesis in type II seesaw models is more efficient when the mass scale of the light neutrinos is large and the bounds are relaxed. In contrast, type I seesaw scenarios become more constricted with flavour-dependent effects taken into account. Finally, we demonstrate that in general, flavour-dependent effects should not be dismissed when considering type II leptogenesis.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1591}
{"prompt": "Rephrase the abstract of an article with title 'Neutral genetic drift can aid functional protein evolution'.\n  BACKGROUND: Many of the mutations accumulated by naturally evolving proteins\nare neutral in the sense that they do not significantly alter a protein's\nability to perform its primary biological function. However, new protein\nfunctions evolve when selection begins to favor other, \"promiscuous\" functions\nthat are incidental to a protein's biological role. If mutations that are\nneutral with respect to a protein's primary biological function cause\nsubstantial changes in promiscuous functions, these mutations could enable\nfuture functional evolution.\n  RESULTS: Here we investigate this possibility experimentally by examining how\ncytochrome P450 enzymes that have evolved neutrally with respect to activity on\na single substrate have changed in their abilities to catalyze reactions on\nfive other substrates. We find that the enzymes have sometimes changed as much\nas four-fold in the promiscuous activities. The changes in promiscuous\nactivities tend to increase with the number of mutations, and can be largely\nrationalized in terms of the chemical structures of the substrates. The\nactivities on chemically similar substrates tend to change in a coordinated\nfashion, potentially providing a route for systematically predicting the change\nin one function based on the measurement of several others.\n  CONCLUSIONS: Our work suggests that initially neutral genetic drift can lead\nto substantial changes in protein functions that are not currently under\nselection, in effect poising the proteins to more readily undergo functional\nevolution should selection \"ask new questions\" in the future.\n\n", "human_text": "  BACKGROUND: Many of the mutations accumulated by naturally evolving proteins\nare neutral in the sense that they do not significantly alter a protein's\nability to perform its primary biological function. However, new protein\nfunctions evolve when selection begins to favor other, \"promiscuous\" functions\nthat are incidental to a protein's biological role. If mutations that are\nneutral with respect to a protein's primary biological function cause\nsubstantial changes in promiscuous functions, these mutations could enable\nfuture functional evolution.\n  RESULTS: Here we investigate this possibility experimentally by examining how\ncytochrome P450 enzymes that have evolved neutrally with respect to activity on\na single substrate have changed in their abilities to catalyze reactions on\nfive other substrates. We find that the enzymes have sometimes changed as much\nas four-fold in the promiscuous activities. The changes in promiscuous\nactivities tend to increase with the number of mutations, and can be largely\nrationalized in terms of the chemical structures of the substrates. The\nactivities on chemically similar substrates tend to change in a coordinated\nfashion, potentially providing a route for systematically predicting the change\nin one function based on the measurement of several others.\n  CONCLUSIONS: Our work suggests that initially neutral genetic drift can lead\nto substantial changes in protein functions that are not currently under\nselection, in effect poising the proteins to more readily undergo functional\nevolution should selection \"ask new questions\" in the future.\n", "machine_text": "\nThis study investigates the ability of a neutral genetic drift to shape the function of proteins beyond their primary biological role. We analyze how cytochrome P450 enzymes evolved neutrally with respect to one substrate react to five others. Our results indicate that these proteins can experience as much as four-fold change in their promiscuous activities over a number of mutations. Further, these activities tend to be associated with the chemical structure of the substrates, with coordinated changes in activities observed when confronted with chemically similar substrates. Our findings suggest that neutral genetic drift can contribute to significantly altered protein functions; the newly obtained changes could be leveraged in the evolution of new functions if required by future selection.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0201}
{"prompt": "Rephrase the abstract of an article with title 'A Comparison between Anomalous 6-cm H$_2$CO Absorption and CO(1-0)\n  Emission in the L1204/S140'.\n  We report observations of the dust cloud L1204 with the Onsala 25-m telescope\nin the 6 cm (1$_{11}-1_{10}$) transition of \\htco. The observed region includes\nthe\n  S140 H${\\alpha}$ arc. This spectral line is seen here in absorption against\nthe cosmic microwave background, indicating the presence of widespread warm\nmolecular gas at intermediate densities. Overall, the distributions of H$_2$CO\nand CO (taken from the literature) are fairly similar, though significant\ndifferences exist at small scales. Most notably, while the CO peak is nearly\ncoincident with the S140 H${\\alpha}$ arc, the maximum H$_2$CO absorption is\nclearly separated from it by a full 10$'$ beam ($\\sim$ 3 pc). We argue that\nthese differences result from differing abundances and excitation requirements.\nThe CO(1-0) line is more optically thick and more biased towards warm gas than\nthe H$_2$CO 6 cm line. On the other hand, formaldehyde is more easily\nphotodissociated and is, therefore, a poorer tracer of the molecular gas\nlocated immediately behind Photon Dominated Regions.\n\n", "human_text": "  We report observations of the dust cloud L1204 with the Onsala 25-m telescope\nin the 6 cm (1$_{11}-1_{10}$) transition of \\htco. The observed region includes\nthe\n  S140 H${\\alpha}$ arc. This spectral line is seen here in absorption against\nthe cosmic microwave background, indicating the presence of widespread warm\nmolecular gas at intermediate densities. Overall, the distributions of H$_2$CO\nand CO (taken from the literature) are fairly similar, though significant\ndifferences exist at small scales. Most notably, while the CO peak is nearly\ncoincident with the S140 H${\\alpha}$ arc, the maximum H$_2$CO absorption is\nclearly separated from it by a full 10$'$ beam ($\\sim$ 3 pc). We argue that\nthese differences result from differing abundances and excitation requirements.\nThe CO(1-0) line is more optically thick and more biased towards warm gas than\nthe H$_2$CO 6 cm line. On the other hand, formaldehyde is more easily\nphotodissociated and is, therefore, a poorer tracer of the molecular gas\nlocated immediately behind Photon Dominated Regions.\n", "machine_text": "\nThis paper presents the results of an observation of the L1204 dust cloud using the Onsala 25-m telescope in the 6 cm (1$_{11}-1_{10}$) transition of \\htco. We detect the spectral line in absorption against the background Cosmic Microwave Radiation, implying that a wide spread of warm molecular gas is present at mid-level densities. A comparison of the H$_2$CO and CO (1-0) emission reveals that, while the overall distributions are alike, there are considerable discrepancies at the granular level. Particularly, the S140 H${\\alpha}$ arc peak is nearly coincident with the CO, however, the H$_2$CO absorption maximum is 10$'$ (approx. 3 pc) away. It is hypothesized that this is due to the fact that \\htco\\ is easily photodissociated and therefore is a weaker marker of the molecular gas just behind Photon Dominated Regions. Consequently, the CO is more saturated and better suited for highlighting warm gas.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0272}
{"prompt": "Rephrase the abstract of an article with title 'Measurement of the top-quark mass using missing $E_T$+jets events with\n  secondary vertex $b$-tagging at CDF II'.\n  We present a measurement of the top-quark mass in $p\\bar p$ collisions at\n\\hbox{$\\sqrt{s}=1.96$} TeV which uses events with an inclusive signature of\nmissing transverse energy and jets. % The event selection is sensitive to\n$t\\bar t\\to W^+bW^-\\bar b\\to l\\nu b q q^\\prime \\bar b$ independent of the\nlepton flavor, and results in a large acceptance for $W\\to\\tau\\nu$ decays. %\nAll-hadronic $t\\bar t$ decays and events with identified electrons or muons are\nvetoed to provide a statistically independent sample with respect to all\nprevious measurements. % The top-quark mass is inferred from the distribution\nof the scalar sum of all jet transverse energies and the missing transverse\nenergy. Using 311 pb$^{-1}$ of integrated luminosity recorded by the Collider\nDetector at Fermilab, we measure a top-quark mass $m_t = 172.3\n^{+10.8}_{-9.6}$(stat.)$\\pm 10.8$(syst.) GeV/$c^2$. While the uncertainty on\n$m_t$ is larger than that of other measurements, the result is statistically\nuncorrelated with those of other methods, and thus can help to reduce the\noverall $m_t$ uncertainty when combined with other existing measurements.\n\n", "human_text": "  We present a measurement of the top-quark mass in $p\\bar p$ collisions at\n\\hbox{$\\sqrt{s}=1.96$} TeV which uses events with an inclusive signature of\nmissing transverse energy and jets. % The event selection is sensitive to\n$t\\bar t\\to W^+bW^-\\bar b\\to l\\nu b q q^\\prime \\bar b$ independent of the\nlepton flavor, and results in a large acceptance for $W\\to\\tau\\nu$ decays. %\nAll-hadronic $t\\bar t$ decays and events with identified electrons or muons are\nvetoed to provide a statistically independent sample with respect to all\nprevious measurements. % The top-quark mass is inferred from the distribution\nof the scalar sum of all jet transverse energies and the missing transverse\nenergy. Using 311 pb$^{-1}$ of integrated luminosity recorded by the Collider\nDetector at Fermilab, we measure a top-quark mass $m_t = 172.3\n^{+10.8}_{-9.6}$(stat.)$\\pm 10.8$(syst.) GeV/$c^2$. While the uncertainty on\n$m_t$ is larger than that of other measurements, the result is statistically\nuncorrelated with those of other methods, and thus can help to reduce the\noverall $m_t$ uncertainty when combined with other existing measurements.\n", "machine_text": "\nIn this paper, we demonstrate a technique to measure the top-quark mass in proton-antiproton collisions with a center-of-mass energy of 1.96 TeV. Our approach utilizes events containing missing transverse energy and high-pT jets, which are created mostly through $t\\bar t\\rightarrow W^+bW^-\\bar b\\rightarrow l\\nu b q q^\\prime\\bar b$ decays. The technique is applicable to events with tau and hadronically decaying $W$-bosons and is independent of electron or muon produced in $W$-decays. We exclude all-hadronic $t\\bar t$ decays  and events with identified electrons or muons making our sample statistically distinct from previous measurements. Our measurements are based on 311 pb$^{-1}$ of integrated luminosity collected with the Collider Detector at Fermilab. The results suggest a top-quark mass of $m_t = 172.3 ^{+10.8}_{-9.6}$(stat.)$\\pm 10.8$(syst.) GeV/$c^2$. This provides a statistically independent estimate of the top-quark mass, thus helping to further reduce the overall uncertainty when combined with other top-quark mass measurements.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1594}
{"prompt": "Rephrase the abstract of an article with title 'A Study in Depth of f0(1370)'.\n  Claims have been made that f0(1370) does not exist. The five primary sets of\ndata requiring its existence are refitted. Major dispersive effects due to the\nopening of the 4pi threshold are included for the first time; the sigma -> 4pi\namplitude plays a strong role. Crystal Barrel data on pbar-p -> 3pizero at rest\nrequire f0(1370) signals of at least 32 and 33 standard deviations in 1S0 and\n3P1 annihilation respectively. Furthermore, they agree within 5 MeV for mass\nand width. Data on pbar-p -> eta-eta-pizero agree and require at least a 19\nstandard deviation contribution. This alone is sufficient to demonstrate the\nexistence of f0(1370). BES II data for J/Psi -> phi-pi-pi contain a visible\nf0(1370) signal > 8 standard devations. In all cases, a resonant phase\nvariation is required. The possibility of a second pole in the sigma amplitude\ndue to the opening of the 4pi channel is excluded. Cern-Munich data for pi-pi\nelastic scattering are fitted well with the inclusion of some mixing between\nsigma, f0(1370) and f0(1500). The pi-pi widths for f2(1565), rho3(1690),\nrho3(1990) and f4(2040) are determined.\n\n", "human_text": "  Claims have been made that f0(1370) does not exist. The five primary sets of\ndata requiring its existence are refitted. Major dispersive effects due to the\nopening of the 4pi threshold are included for the first time; the sigma -> 4pi\namplitude plays a strong role. Crystal Barrel data on pbar-p -> 3pizero at rest\nrequire f0(1370) signals of at least 32 and 33 standard deviations in 1S0 and\n3P1 annihilation respectively. Furthermore, they agree within 5 MeV for mass\nand width. Data on pbar-p -> eta-eta-pizero agree and require at least a 19\nstandard deviation contribution. This alone is sufficient to demonstrate the\nexistence of f0(1370). BES II data for J/Psi -> phi-pi-pi contain a visible\nf0(1370) signal > 8 standard devations. In all cases, a resonant phase\nvariation is required. The possibility of a second pole in the sigma amplitude\ndue to the opening of the 4pi channel is excluded. Cern-Munich data for pi-pi\nelastic scattering are fitted well with the inclusion of some mixing between\nsigma, f0(1370) and f0(1500). The pi-pi widths for f2(1565), rho3(1690),\nrho3(1990) and f4(2040) are determined.\n", "machine_text": "This paper provides an extensive examination of f0(1370), with the primary goal of determining the existence of the particle. By re-fitting five sets of data, major dispersion effects associated with the 4pi threshold are included for the first time. This study finds that Crystal Barrel data and data from BES II both suggest the existence of a f0(1370) particle, with a visible signal greater than 8 standard deviations. Cern-Munich data regarding pi-pi scattering fits well with the inclusion of the particle. This research also determines the pi-pi width of four other particles. The conclusion of this study validates the existence of f0(1370).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1341}
{"prompt": "Rephrase the abstract of an article with title 'Nonlinearity-assisted quantum tunneling in a matter-wave interferometer'.\n  We investigate the {\\em nonlinearity-assisted quantum tunneling} and\nformation of nonlinear collective excitations in a matter-wave interferometer,\nwhich is realised by the adiabatic transformation of a double-well potential\ninto a single-well harmonic trap. In contrast to the linear quantum tunneling\ninduced by the crossing (or avoided crossing) of neighbouring energy levels,\nthe quantum tunneling between different nonlinear eigenstates is assisted by\nthe nonlinear mean-field interaction. When the barrier between the wells\ndecreases, the mean-field interaction aids quantum tunneling between the ground\nand excited nonlinear eigenstates. The resulting {\\em non-adiabatic evolution}\ndepends on the input states. The tunneling process leads to the generation of\ndark solitons, and the number of the generated dark solitons is highly\nsensitive to the matter-wave nonlinearity. The results of the numerical\nsimulations of the matter-wave dynamics are successfully interpreted with a\ncoupled-mode theory for multiple nonlinear eigenstates.\n\n", "human_text": "  We investigate the {\\em nonlinearity-assisted quantum tunneling} and\nformation of nonlinear collective excitations in a matter-wave interferometer,\nwhich is realised by the adiabatic transformation of a double-well potential\ninto a single-well harmonic trap. In contrast to the linear quantum tunneling\ninduced by the crossing (or avoided crossing) of neighbouring energy levels,\nthe quantum tunneling between different nonlinear eigenstates is assisted by\nthe nonlinear mean-field interaction. When the barrier between the wells\ndecreases, the mean-field interaction aids quantum tunneling between the ground\nand excited nonlinear eigenstates. The resulting {\\em non-adiabatic evolution}\ndepends on the input states. The tunneling process leads to the generation of\ndark solitons, and the number of the generated dark solitons is highly\nsensitive to the matter-wave nonlinearity. The results of the numerical\nsimulations of the matter-wave dynamics are successfully interpreted with a\ncoupled-mode theory for multiple nonlinear eigenstates.\n", "machine_text": "\nThis paper explores the effects of nonlinearity on quantum tunneling and formation of collective excitations in a matter-wave interferometer generated by the conversion of a double-well potential into a single-well harmonic trap. Compared to linear quantum tunneling caused by the encounter (or avoidance) of neighbouring energy levels, quantum tunneling between alternate nonlinear eigenstates is supported by the nonlinear mean-field force. When the division between the wells is decreased, the mean-field connection helps quantum tunneling between the ground and excited nonlinear eigenstates. The subsequent {\\em non-adiabatic evolution} depends on pre-defined input states. The tunneling procedure leads to the creation of dark solitons and the amount of dark solitons created is extremely responsive to the nonlinearity of the matter-wave. These theoretical computations are backed up by a coupled-mode theory for multiple nonlinear eigenstates.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2263}
{"prompt": "Rephrase the abstract of an article with title 'Markov properties in presence of measurement noise'.\n  Recently, several powerful tools for the reconstruction of stochastic\ndifferential equations from measured data sets have been proposed [e.g. Siegert\net al., Physics Letters A 243, 275 (1998); Hurn et al., Journal of Time Series\nAnalysis 24, 45 (2003)]. Efficient application of the methods, however,\ngenerally requires Markov properties to be fulfilled. This constraint typically\nseems to be violated on small scales, which frequently is attributed to\nphysical effects. On the other hand, measurement noise such as uncorrelated\nmeasurement and discretization errors has large impacts on the statistics of\nmeasurements on small scales. We demonstrate, that the presence of measurement\nnoise, likewise, spoils Markov properties of an underlying Markov processes.\nThis fact is promising for the further development of techniques for the\nreconstruction of stochastic processes from measured data, since limitations at\nsmall scales might stem from artificial noise sources rather than from\nintrinsic properties of the dynamics of the underlying process. Measurement\nnoise, however, can be controlled much better than the intrinsic dynamics of\nthe underlying process.\n\n", "human_text": "  Recently, several powerful tools for the reconstruction of stochastic\ndifferential equations from measured data sets have been proposed [e.g. Siegert\net al., Physics Letters A 243, 275 (1998); Hurn et al., Journal of Time Series\nAnalysis 24, 45 (2003)]. Efficient application of the methods, however,\ngenerally requires Markov properties to be fulfilled. This constraint typically\nseems to be violated on small scales, which frequently is attributed to\nphysical effects. On the other hand, measurement noise such as uncorrelated\nmeasurement and discretization errors has large impacts on the statistics of\nmeasurements on small scales. We demonstrate, that the presence of measurement\nnoise, likewise, spoils Markov properties of an underlying Markov processes.\nThis fact is promising for the further development of techniques for the\nreconstruction of stochastic processes from measured data, since limitations at\nsmall scales might stem from artificial noise sources rather than from\nintrinsic properties of the dynamics of the underlying process. Measurement\nnoise, however, can be controlled much better than the intrinsic dynamics of\nthe underlying process.\n", "machine_text": "\nRecently, methods for the reconstruction of stochastic differential equations from measured data sets have been developed [e.g. Siegert et al., Physics Letters A 243, 275 (1998); Hurn et al., Journal of Time Series Analysis 24, 45 (2003)]. For their efficient application, Markov properties are generally required, which may be violated on small scales due to physical effects. Through this article, we propose that measurement noise such as uncorrelated measurement and discretization errors may also disrupt Markov properties of an underlying Markov processes. This gives cause for hope that limitations on small scales might not be derived from intrinsic dynamics of the process, but may rather lie in the presence of artificial noise sources. Thus, the measurement noise can be more reliably managed than the dynamics of the underlying process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1222}
{"prompt": "Rephrase the abstract of an article with title '$D_{sJ}$(2317) meson production at RHIC'.\n  Production of $D_{sJ}$(2317) mesons in relativistic heavy ion collisions at\nRHIC is studied. Using the quark coalescence model, we first determine the\ninitial number of $D_{sJ}$(2317) mesons produced during hadronization of\ncreated quark-gluon plasma. The predicted $D_{sJ}$(2317) abundance depends\nsensitively on the quark structure of the $D_{sJ}$(2317) meson. An\norder-of-magnitude larger yield is obtained for a conventional two-quark than\nfor an exotic four-quark $D_{sJ}$(2317) meson. To include the hadronic effect\non the $D_{sJ}$(2317) meson yield, we have evaluated the absorption cross\nsections of the $D_{sJ}$(2317) meson by pion, rho, anti-kaon, and vector\nanti-kaon in a phenomenological hadronic model. Taking into consideration the\nabsorption and production of $D_{sJ}$(2317) mesons during the hadronic stage of\nheavy ion collisions via a kinetic model, we find that the final yield of\n$D_{sJ}$(2317) mesons remains sensitive to its initial number produced from the\nquark-gluon plasma, providing thus the possibility of studying the quark\nstructure of the $D_{sJ}$(2317) meson and its production mechanism in\nrelativistic heavy ion collisions.\n\n", "human_text": "  Production of $D_{sJ}$(2317) mesons in relativistic heavy ion collisions at\nRHIC is studied. Using the quark coalescence model, we first determine the\ninitial number of $D_{sJ}$(2317) mesons produced during hadronization of\ncreated quark-gluon plasma. The predicted $D_{sJ}$(2317) abundance depends\nsensitively on the quark structure of the $D_{sJ}$(2317) meson. An\norder-of-magnitude larger yield is obtained for a conventional two-quark than\nfor an exotic four-quark $D_{sJ}$(2317) meson. To include the hadronic effect\non the $D_{sJ}$(2317) meson yield, we have evaluated the absorption cross\nsections of the $D_{sJ}$(2317) meson by pion, rho, anti-kaon, and vector\nanti-kaon in a phenomenological hadronic model. Taking into consideration the\nabsorption and production of $D_{sJ}$(2317) mesons during the hadronic stage of\nheavy ion collisions via a kinetic model, we find that the final yield of\n$D_{sJ}$(2317) mesons remains sensitive to its initial number produced from the\nquark-gluon plasma, providing thus the possibility of studying the quark\nstructure of the $D_{sJ}$(2317) meson and its production mechanism in\nrelativistic heavy ion collisions.\n", "machine_text": "\nThe effects of hadronic interactions on the yield of $D_{sJ}$(2317) mesons in relativistic heavy ion collisions at RHIC are investigated in this study. Utilizing the quark coalescence model, we calculate the amount of $D_{sJ}$(2317) mesons produced in the quark-gluon plasma phase. The results show that the yield of the $D_{sJ}$(2317) meson is highly sensitive to its quark structure, being significantly higher for a two-quark than for a four-quark state. Taking into account the production and absorption of $D_{sJ}$(2317) mesons during the hadronic stage of collisions using a kinetic model, it is found that the ultimate yield remains dependent on the initial abundance in the quark-gluon plasma, thus offering an opportunity to explore the quark structure and production mechanism of the $D_{sJ}$(2317) meson in relativistic heavy ion collisions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1697}
{"prompt": "Rephrase the abstract of an article with title 'A Census of Baryons in Galaxy Clusters and Groups'.\n  We determine the contribution of stars in galaxies, intracluster stars, and\nthe intracluster medium to the total baryon budget in nearby galaxy clusters\nand groups. We find that the baryon mass fraction (f_b) within r500 is constant\nfor systems with M500 between 6e13 and 1e15 Msun. Although f_b is lower than\nthe WMAP value, the shortfall is on the order of both the observational\nsystematic uncertainties and the depletion of baryons within r500 that is\npredicted by simulations. The data therefore provide no compelling evidence for\nundetected baryonic components, particularly any that vary in importance with\ncluster mass. A unique feature of the current analysis is direct inclusion of\nthe contribution of intracluster light (ICL) in the baryon budget. The increase\nin X-ray gas mass fraction with increasing total mass is entirely accounted for\nby a decrease in the total stellar mass fraction, supporting the argument that\nthe behavior of both the stellar and X-ray gas components is dominated by a\ndecrease in star formation efficiency in more massive environments. Within just\nthe stellar component, the fraction of the total stellar luminosity in the BCG\nand ICL decreases as velocity dispersion increases, suggesting that the BCG+ICL\ncomponent, and in particular the dominant ICL component, grows less efficiently\nin higher mass environments. The degree to which this behavior arises from our\nsample selection, which favored systems with central, giant elliptical\ngalaxies, remains unclear. A more robust result is the identification of low\nmass groups with large BCG+ICL components, demonstrating that the creation of\nintracluster stars does not require a massive cluster environment. Within r500\nand r200, the BCG+ICL contributes on average 40% and 33% of the total stellar\nlight, respectively.\n\n", "human_text": "  We determine the contribution of stars in galaxies, intracluster stars, and\nthe intracluster medium to the total baryon budget in nearby galaxy clusters\nand groups. We find that the baryon mass fraction (f_b) within r500 is constant\nfor systems with M500 between 6e13 and 1e15 Msun. Although f_b is lower than\nthe WMAP value, the shortfall is on the order of both the observational\nsystematic uncertainties and the depletion of baryons within r500 that is\npredicted by simulations. The data therefore provide no compelling evidence for\nundetected baryonic components, particularly any that vary in importance with\ncluster mass. A unique feature of the current analysis is direct inclusion of\nthe contribution of intracluster light (ICL) in the baryon budget. The increase\nin X-ray gas mass fraction with increasing total mass is entirely accounted for\nby a decrease in the total stellar mass fraction, supporting the argument that\nthe behavior of both the stellar and X-ray gas components is dominated by a\ndecrease in star formation efficiency in more massive environments. Within just\nthe stellar component, the fraction of the total stellar luminosity in the BCG\nand ICL decreases as velocity dispersion increases, suggesting that the BCG+ICL\ncomponent, and in particular the dominant ICL component, grows less efficiently\nin higher mass environments. The degree to which this behavior arises from our\nsample selection, which favored systems with central, giant elliptical\ngalaxies, remains unclear. A more robust result is the identification of low\nmass groups with large BCG+ICL components, demonstrating that the creation of\nintracluster stars does not require a massive cluster environment. Within r500\nand r200, the BCG+ICL contributes on average 40% and 33% of the total stellar\nlight, respectively.\n", "machine_text": "\nThis study investigates the role of stars in galaxies, intracluster stars, and the intercluster medium, in order to determine their combined contribution to the total baryon budget for nearby galaxy clusters and groups. Our results show that the baryon mass fraction (f_b) within r500 remains uniform between 6e13 and 1e15 Msun, and is generally lower than the WMAP measure. We do not identify any hidden baryonic components that potentially vary in magnitude with increasing cluster mass. We further observe that the amount of X-ray gas mass rises with an increase in total mass, which can be attributed to a concomitant reduction in star formation efficiency. In addition, the proportion of stellar luminosity contained in the central galaxy and intracluster light gradually reduces in environments with greater velocity dispersion. Notably, there are low mass groups with substantial BCG+ICL components, signifying that the formation of intracluster stars need not be contingent on a massive cluster setting. On average, 40% and 33% of total stellar light is present within r500 and r200, respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1726}
{"prompt": "Rephrase the abstract of an article with title 'Information, information processing and gravity'.\n  I discuss fundamental limits placed on information and information processing\nby gravity. Such limits arise because both information and its processing\nrequire energy, while gravitational collapse (formation of a horizon or black\nhole) restricts the amount of energy allowed in a finite region. Specifically,\nI use a criterion for gravitational collapse called the hoop conjecture. Once\nthe hoop conjecture is assumed a number of results can be obtained directly:\nthe existence of a fundamental uncertainty in spatial distance of order the\nPlanck length, bounds on information (entropy) in a finite region, and a bound\non the rate of information processing in a finite region. In the final section\nI discuss some cosmological issues related to the total amount of information\nin the universe, and note that almost all detailed aspects of the late universe\nare determined by the randomness of quantum outcomes. This paper is based on a\ntalk presented at a 2007 Bellairs Research Institute (McGill University)\nworkshop on black holes and quantum information.\n\n", "human_text": "  I discuss fundamental limits placed on information and information processing\nby gravity. Such limits arise because both information and its processing\nrequire energy, while gravitational collapse (formation of a horizon or black\nhole) restricts the amount of energy allowed in a finite region. Specifically,\nI use a criterion for gravitational collapse called the hoop conjecture. Once\nthe hoop conjecture is assumed a number of results can be obtained directly:\nthe existence of a fundamental uncertainty in spatial distance of order the\nPlanck length, bounds on information (entropy) in a finite region, and a bound\non the rate of information processing in a finite region. In the final section\nI discuss some cosmological issues related to the total amount of information\nin the universe, and note that almost all detailed aspects of the late universe\nare determined by the randomness of quantum outcomes. This paper is based on a\ntalk presented at a 2007 Bellairs Research Institute (McGill University)\nworkshop on black holes and quantum information.\n", "machine_text": "\nThis paper examines the consequences of assuming the hoop conjecture, a criterion for gravity-induced collapse. From the gravitational limitations set, fundamental uncertainties in spatial distance of the Planck length, boundaries on the amount of information held within a limited region, and limits on the rate of information processing within that region result. In conclusion, I consider the implications that quantum randomness has in determining the late universe, and its impact on the overall amount of information existing in the cosmos. This research draws on a lecture which originated at the 2007 Bellairs Research Institute (McGill University) gathering on black holes and quantum information.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1154}
{"prompt": "Rephrase the abstract of an article with title 'The Kinematics and Dynamics of the Globular Clusters and the Planetary\n  Nebulae of NGC 5128'.\n  A new kinematic and dynamic study of the halo of the giant elliptical galaxy,\nNGC 5128, is presented. From a spectroscopically confirmed sample of 340\nglobular clusters and 780 planetary nebulae, the rotation amplitude, rotation\naxis, velocity dispersion, and the total dynamical mass are determined for the\nhalo of NGC 5128. The globular cluster kinematics were searched for both radial\ndependence and metallicity dependence by subdividing the globular cluster\nsample into 158 metal-rich ([Fe/H] > -1.0) and 178 metal-poor ([Fe/H] < -1.0)\nglobular clusters. Our results show the kinematics of the metal-rich and\nmetal-poor subpopulations are quite similar. The kinematics are compared to the\nplanetary nebula population where differences are apparent in the outer regions\nof the halo. The total mass of NGC 5128 is found using the Tracer Mass\nestimator (Evans et al. 2003), to determine the mass supported by internal\nrandom motions, and the spherical component of the Jeans equation to determine\nthe mass supported by rotation. We find a total mass of (1.0+/-0.2) x 10^(12)\nMsun from the planetary nebulae data out to a projected radius of 90 kpc and\n(1.3+/-0.5) x 10^(12) Msun from the globular clusters out to a projected radius\nof 50 kpc. Lastly, we present a new and homogeneous catalog of known globular\nclusters in NGC 5128. This catalog combines all previous definitive cluster\nidentifications from radial velocity studies and HST imaging studies, as well\nas 80 new globular clusters from a study of M.A. Beasley et al. (2007, in\npreparation).\n\n", "human_text": "  A new kinematic and dynamic study of the halo of the giant elliptical galaxy,\nNGC 5128, is presented. From a spectroscopically confirmed sample of 340\nglobular clusters and 780 planetary nebulae, the rotation amplitude, rotation\naxis, velocity dispersion, and the total dynamical mass are determined for the\nhalo of NGC 5128. The globular cluster kinematics were searched for both radial\ndependence and metallicity dependence by subdividing the globular cluster\nsample into 158 metal-rich ([Fe/H] > -1.0) and 178 metal-poor ([Fe/H] < -1.0)\nglobular clusters. Our results show the kinematics of the metal-rich and\nmetal-poor subpopulations are quite similar. The kinematics are compared to the\nplanetary nebula population where differences are apparent in the outer regions\nof the halo. The total mass of NGC 5128 is found using the Tracer Mass\nestimator (Evans et al. 2003), to determine the mass supported by internal\nrandom motions, and the spherical component of the Jeans equation to determine\nthe mass supported by rotation. We find a total mass of (1.0+/-0.2) x 10^(12)\nMsun from the planetary nebulae data out to a projected radius of 90 kpc and\n(1.3+/-0.5) x 10^(12) Msun from the globular clusters out to a projected radius\nof 50 kpc. Lastly, we present a new and homogeneous catalog of known globular\nclusters in NGC 5128. This catalog combines all previous definitive cluster\nidentifications from radial velocity studies and HST imaging studies, as well\nas 80 new globular clusters from a study of M.A. Beasley et al. (2007, in\npreparation).\n", "machine_text": "\nIn this work, kinematics and dynamics of the globular clusters and planetary nebulae of NGC 5128, a giant elliptical galaxy, have been studied using a spectroscopic sample of 340 globular clusters and 780 planetary nebulae. Subdividing the globular cluster sample, the kinematics of metal-rich and metal-poor subpopulations were compared and found to be quite similar. Comparing the kinematics of the two, differences were observed in the outer regions of the halo. The total mass of NGC 5128 was determined from the two populations, resulting in a mass of approximately 1.0 x 10^(12) Msun and 1.3 x 10^(12) Msun from planetary nebulae and globular clusters, respectively. In addition, a new and homogeneous catalog of known globular clusters in NGC 5128, combining all previous definitive cluster identifications from studies, as well as 80 new globular clusters, was presented.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1189}
{"prompt": "Rephrase the abstract of an article with title 'Particle-vibration coupling within covariant density functional theory'.\n  Covariant density functional theory, which has so far been applied only\nwithin the framework of static and time dependent mean field theory is extended\nto include Particle-Vibration Coupling (PVC) in a consistent way. Starting from\na conventional energy functional we calculate the low-lying collective\nvibrations in Relativistic Random Phase Approximation (RRPA) and construct an\nenergy dependent self-energy for the Dyson equation. The resulting\nBethe-Salpeter equation in the particle-hole ($ph$) channel is solved in the\nTime Blocking Approximation (TBA). No additional parameters are used and double\ncounting is avoided by a proper subtraction method. The same energy functional,\ni.e. the same set of coupling constants, generates the Dirac-Hartree\nsingle-particle spectrum, the static part of the residual $ph$-interaction and\nthe particle-phonon coupling vertices. Therefore a fully consistent description\nof nuclear excited states is developed. This method is applied for an\ninvestigation of damping phenomena in the spherical nuclei with closed shells\n$^{208}$Pb and $^{132}$Sn. Since the phonon coupling terms enrich the RRPA\nspectrum with a multitude of $ph\\otimes$phonon components a noticeable\nfragmentation of the giant resonances is found, which is in full agreement with\nexperimental data and with results of the semi-phenomenological\nnon-relativistic approach.\n\n", "human_text": "  Covariant density functional theory, which has so far been applied only\nwithin the framework of static and time dependent mean field theory is extended\nto include Particle-Vibration Coupling (PVC) in a consistent way. Starting from\na conventional energy functional we calculate the low-lying collective\nvibrations in Relativistic Random Phase Approximation (RRPA) and construct an\nenergy dependent self-energy for the Dyson equation. The resulting\nBethe-Salpeter equation in the particle-hole ($ph$) channel is solved in the\nTime Blocking Approximation (TBA). No additional parameters are used and double\ncounting is avoided by a proper subtraction method. The same energy functional,\ni.e. the same set of coupling constants, generates the Dirac-Hartree\nsingle-particle spectrum, the static part of the residual $ph$-interaction and\nthe particle-phonon coupling vertices. Therefore a fully consistent description\nof nuclear excited states is developed. This method is applied for an\ninvestigation of damping phenomena in the spherical nuclei with closed shells\n$^{208}$Pb and $^{132}$Sn. Since the phonon coupling terms enrich the RRPA\nspectrum with a multitude of $ph\\otimes$phonon components a noticeable\nfragmentation of the giant resonances is found, which is in full agreement with\nexperimental data and with results of the semi-phenomenological\nnon-relativistic approach.\n", "machine_text": "\nCovariant density functional theory is extended in this paper to include Particle-Vibration Coupling (PVC), by calculating low-lying collective vibrations in Relativistic Random Phase Approximation (RRPA) and constructing an energy dependent self-energy for the Dyson equation. Bethe-Salpeter equation in the particle-hole ($ph$) channel is solved in the Time Blocking Approximation (TBA), without the need for additional parameters or double counting. This method has been applied for an investigation of damping phenomena in spherical nuclei with closed shells $^{208}$Pb and $^{132}$Sn, which has produced results that are in agreement with experimental data as well as results of the semi-phenomenological non-relativistic approach. This study enhances the capability of covariant density functional theory to give a consistent description of nuclear excite states.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1044}
{"prompt": "Rephrase the abstract of an article with title 'Power control and receiver design for energy efficiency in multipath\n  CDMA channels with bandlimited waveforms'.\n  This paper is focused on the cross-layer design problem of joint multiuser\ndetection and power control for energy-efficiency optimization in a wireless\ndata network through a game-theoretic approach. Building on work of Meshkati,\net al., wherein the tools of game-theory are used in order to achieve\nenergy-efficiency in a simple synchronous code division multiple access system,\nsystem asynchronism, the use of bandlimited chip-pulses, and the multipath\ndistortion induced by the wireless channel are explicitly incorporated into the\nanalysis. Several non-cooperative games are proposed wherein users may vary\ntheir transmit power and their uplink receiver in order to maximize their\nutility, which is defined here as the ratio of data throughput to transmit\npower. In particular, the case in which a linear multiuser detector is adopted\nat the receiver is considered first, and then, the more challenging case in\nwhich non-linear decision feedback multiuser detectors are employed is\nconsidered. The proposed games are shown to admit a unique Nash equilibrium\npoint, while simulation results show the effectiveness of the proposed\nsolutions, as well as that the use of a decision-feedback multiuser receiver\nbrings remarkable performance improvements.\n\n", "human_text": "  This paper is focused on the cross-layer design problem of joint multiuser\ndetection and power control for energy-efficiency optimization in a wireless\ndata network through a game-theoretic approach. Building on work of Meshkati,\net al., wherein the tools of game-theory are used in order to achieve\nenergy-efficiency in a simple synchronous code division multiple access system,\nsystem asynchronism, the use of bandlimited chip-pulses, and the multipath\ndistortion induced by the wireless channel are explicitly incorporated into the\nanalysis. Several non-cooperative games are proposed wherein users may vary\ntheir transmit power and their uplink receiver in order to maximize their\nutility, which is defined here as the ratio of data throughput to transmit\npower. In particular, the case in which a linear multiuser detector is adopted\nat the receiver is considered first, and then, the more challenging case in\nwhich non-linear decision feedback multiuser detectors are employed is\nconsidered. The proposed games are shown to admit a unique Nash equilibrium\npoint, while simulation results show the effectiveness of the proposed\nsolutions, as well as that the use of a decision-feedback multiuser receiver\nbrings remarkable performance improvements.\n", "machine_text": "\nThis article examines the power control and receiver design problem in a wireless data network with the goal of optimizing energy efficiency. The joint multiuser detection and power control approach is carried out via the game-theoretical approach outlined by Meshkati. System asynchronism, the use of band-limited chip pulses, and the multipath distortion from the wireless channel are all accounted for in this analysis. Turing to power control specifically, several non-cooperative games are proposed for users to maximize their efficacy, measured as the ratio of data throughput against transmit power. Beginning with linear multiuser detectors, then transitioning to non-linear decision feedback detectors, the proposed games are shown to yield a singular Nash equilibrium point. Simulation results validate the proposed solutions, while also highlighting the vast improvements achieved with the decision feedback receivers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2383}
{"prompt": "Rephrase the abstract of an article with title 'Stability of isentropic viscous shock profiles in the high-Mach number\n  limit'.\n  By a combination of asymptotic ODE estimates and numerical Evans function\ncalculations, we establish stability of viscous shock solutions of the\nisentropic compressible Navier--Stokes equations with $\\gamma$-law pressure (i)\nin the limit as Mach number $M$ goes to infinity, for any $\\gamma\\ge 1$ (proved\nanalytically), and (ii) for $M\\ge 2,500$, $\\gamma\\in [1,2.5]$ (demonstrated\nnumerically). This builds on and completes earlier studies by\nMatsumura--Nishihara and Barker--Humpherys--Rudd--Zumbrun establishing\nstability for low and intermediate Mach numbers, respectively, indicating\nunconditional stability, independent of shock amplitude, of viscous shock waves\nfor $\\gamma$-law gas dynamics in the range $\\gamma \\in [1,2.5]$. Other\n$\\gamma$-values may be treated similarly, but have not been checked\nnumerically. The main idea is to establish convergence of the Evans function in\nthe high-Mach number limit to that of a pressureless, or ``infinitely\ncompressible'', gas with additional upstream boundary condition determined by a\nboundary-layer analysis. Recall that low-Mach number behavior is\nincompressible.\n\n", "human_text": "  By a combination of asymptotic ODE estimates and numerical Evans function\ncalculations, we establish stability of viscous shock solutions of the\nisentropic compressible Navier--Stokes equations with $\\gamma$-law pressure (i)\nin the limit as Mach number $M$ goes to infinity, for any $\\gamma\\ge 1$ (proved\nanalytically), and (ii) for $M\\ge 2,500$, $\\gamma\\in [1,2.5]$ (demonstrated\nnumerically). This builds on and completes earlier studies by\nMatsumura--Nishihara and Barker--Humpherys--Rudd--Zumbrun establishing\nstability for low and intermediate Mach numbers, respectively, indicating\nunconditional stability, independent of shock amplitude, of viscous shock waves\nfor $\\gamma$-law gas dynamics in the range $\\gamma \\in [1,2.5]$. Other\n$\\gamma$-values may be treated similarly, but have not been checked\nnumerically. The main idea is to establish convergence of the Evans function in\nthe high-Mach number limit to that of a pressureless, or ``infinitely\ncompressible'', gas with additional upstream boundary condition determined by a\nboundary-layer analysis. Recall that low-Mach number behavior is\nincompressible.\n", "machine_text": "\nWe examined the stability of isentropic viscous shock profiles at high Mach numbers by combining numerical Evans function calculations and asymptotic ODE estimates. We determined that, in the range $\\gamma \\in [1,2.5]$ and Mach numbers over $2,500$, viscous shock waves are unconditionally stable, independent of shock amplitude, with $\\gamma$-law gas dynamics. The convergence of the Evans function in the high-Mach number limit was established through a boundary-layer analysis, providing an upstream boundary condition for the pressureless (\"infinitely compressible\") gas. In comparison, low-Mach number behavior is known to be incompressible. Our study concluded and reinforced earlier works of Matsumura-Nishihara and Barker-Humpherys-Rudd-Zumbrun, which examined stability at low and intermediate Mach numbers, respectively. Further investigation of other $\\gamma$-values is possible, but hasnot been done yet.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4244}
{"prompt": "Rephrase the abstract of an article with title 'The standard model on a domain-wall brane?'.\n  We propose a 4+1-dimensional action that is a candidate for realising a\nstandard-model-like effective theory for fields dynamically localised to a\ndomain-wall brane. Our construction is based in part on the conjecture that the\nDvali-Shifman mechanism for dynamically localising gauge bosons works correctly\nin 4+1-d. Assuming this to be so, we require the gauge symmetry to be SU(5)in\nthe bulk, spontaneously breaking to SU(3)xSU(2)xU(1) inside the domain wall,\nthus dynamically localising the standard model gauge bosons provided that the\nSU(5) theory in the bulk exhibits confinement. The wall is created jointly by a\nreal singlet-Higgs field eta configured as a kink, and an SU(5) adjoint-Higgs\nfield chi that takes nonzero values inside the wall. Chiral 3+1-dimensional\nquarks and leptons are confined and split along the bulk direction via their\nYukawa couplings to eta and chi. The Higgs doublet and its colour triplet SU(5)\npartner are similarly localised and split. The splittings suppress\ncoloured-Higgs-induced proton decay and, because of the different localisation\nprofiles, the usual SU(5) mass relation m_e = m_d does not arise. Localised\ngravity is generated via the Randall-Sundrum alternative to compactification.\n\n", "human_text": "  We propose a 4+1-dimensional action that is a candidate for realising a\nstandard-model-like effective theory for fields dynamically localised to a\ndomain-wall brane. Our construction is based in part on the conjecture that the\nDvali-Shifman mechanism for dynamically localising gauge bosons works correctly\nin 4+1-d. Assuming this to be so, we require the gauge symmetry to be SU(5)in\nthe bulk, spontaneously breaking to SU(3)xSU(2)xU(1) inside the domain wall,\nthus dynamically localising the standard model gauge bosons provided that the\nSU(5) theory in the bulk exhibits confinement. The wall is created jointly by a\nreal singlet-Higgs field eta configured as a kink, and an SU(5) adjoint-Higgs\nfield chi that takes nonzero values inside the wall. Chiral 3+1-dimensional\nquarks and leptons are confined and split along the bulk direction via their\nYukawa couplings to eta and chi. The Higgs doublet and its colour triplet SU(5)\npartner are similarly localised and split. The splittings suppress\ncoloured-Higgs-induced proton decay and, because of the different localisation\nprofiles, the usual SU(5) mass relation m_e = m_d does not arise. Localised\ngravity is generated via the Randall-Sundrum alternative to compactification.\n", "machine_text": "This article presents a potential method for generating a standard model like effective\ntheory through a 4+1-dimensional action. Utilizing the Dvali-Shifman mechanism for dynamically \nconfining gauge bosons, we posited that the bulk gauge symmetry should break to \nSU(3)xSU(2)xU(1) within the domain wall. We also established a wall created jointly by a real \nsinglet-Higgs field configured as a kink, and an SU(5) adjoint-Higgs field taking nonzero values \ninside the wall. This wall leads to confinement and splitting of chiral 3+1-dimensional quarks \nand leptons. In addition, a Higgs doublet and its colour triplet SU(5) partner get localised and \nsplit, suppressing coloured-Higgs-induced proton decay. We also propose that localised gravity \ncan be generated through the Randall-Sundrum alternative, as opposed to traditional \ncompactification.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1584}
{"prompt": "Rephrase the abstract of an article with title 'Peculiar Motions in the Region of the Ursa Major Supercluster of\n  Galaxies'.\n  We have investigated the peculiar motions of clusters of galaxies in the Ursa\nMajor (UMa) supercluster and its neighborhood. Based on SDSS (Sloan Digital Sky\nSurvey) data, we have compiled a sample of early-type galaxies and used their\nfundamental plane to determine the cluster distances and peculiar velocities.\nThe samples of early-type galaxies in the central regions (within R_200) of 12\nUMa clusters of galaxies, in three main subsystems of the supercluster -- the\nfilamentary structures connecting the clusters, and in nine clusters from the\nnearest UMa neighborhood have similar parameters. The fairly high overdensity\n(3 by the galaxy number and 15 by the cluster number) suggests that the\nsupercluster as a whole is gravitationally bound, while no significant peculiar\nmotions have been found: the peculiar velocities do not exceed the measurement\nerrors by more than a factor of 1.5-2. The mean random peculiar velocities of\nclusters and the systematic deviations from the overall Hubble expansion in the\nsupercluster are consistent with theoretical estimates. For the possible\napproach of the three UMa subsystems to be confirmed, the measurement accuracy\nmust be increased by a factor of 2-3.\n\n", "human_text": "  We have investigated the peculiar motions of clusters of galaxies in the Ursa\nMajor (UMa) supercluster and its neighborhood. Based on SDSS (Sloan Digital Sky\nSurvey) data, we have compiled a sample of early-type galaxies and used their\nfundamental plane to determine the cluster distances and peculiar velocities.\nThe samples of early-type galaxies in the central regions (within R_200) of 12\nUMa clusters of galaxies, in three main subsystems of the supercluster -- the\nfilamentary structures connecting the clusters, and in nine clusters from the\nnearest UMa neighborhood have similar parameters. The fairly high overdensity\n(3 by the galaxy number and 15 by the cluster number) suggests that the\nsupercluster as a whole is gravitationally bound, while no significant peculiar\nmotions have been found: the peculiar velocities do not exceed the measurement\nerrors by more than a factor of 1.5-2. The mean random peculiar velocities of\nclusters and the systematic deviations from the overall Hubble expansion in the\nsupercluster are consistent with theoretical estimates. For the possible\napproach of the three UMa subsystems to be confirmed, the measurement accuracy\nmust be increased by a factor of 2-3.\n", "machine_text": "\nWe have studied the peculiar motion of clusters of galaxies within the Ursa Major supercluster and its surrounding area through an analysis of Sloan Digital Sky Survey (SDSS) data. A sample of early-type galaxies was compiled and their fundamental plane was used to assess cluster distances and peculiar velocities. The results for the 12 UMa clusters in three distinct subsystems of the supercluster as well as nine clusters from nearby regions were similar. The density of these systems (3 for galaxies and 15 for clusters) indicates that the whole construction is gravitationally bound. Peculiar velocities did not exceed the measurement errors by more than a 2-fold amount. Furthermore, the average random peculiar velocities of the clusters and their congruence with the general Hubble expansion were compatible with the findings of theoretical models. In order to verify the potential convergence of the three UMa subsystems, the precision of the analysis should be improved by a factor 2-3.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3945}
{"prompt": "Rephrase the abstract of an article with title 'A study of structural properties on profiles HMMs'.\n  Motivation: Profile hidden Markov Models (pHMMs) are a popular and very\nuseful tool in the detection of the remote homologue protein families.\nUnfortunately, their performance is not always satisfactory when proteins are\nin the 'twilight zone'. We present HMMER-STRUCT, a model construction algorithm\nand tool that tries to improve pHMM performance by using structural information\nwhile training pHMMs. As a first step, HMMER-STRUCT constructs a set of pHMMs.\nEach pHMM is constructed by weighting each residue in an aligned protein\naccording to a specific structural property of the residue. Properties used\nwere primary, secondary and tertiary structures, accessibility and packing.\nHMMER-STRUCT then prioritizes the results by voting. Results: We used the SCOP\ndatabase to perform our experiments. Throughout, we apply leave-one-family-out\ncross-validation over protein superfamilies. First, we used the MAMMOTH-mult\nstructural aligner to align the training set proteins. Then, we performed two\nsets of experiments. In a first experiment, we compared structure weighted\nmodels against standard pHMMs and against each other. In a second experiment,\nwe compared the voting model against individual pHMMs. We compare method\nperformance through ROC curves and through Precision/Recall curves, and assess\nsignificance through the paired two tailed t-test. Our results show significant\nperformance improvements of all structurally weighted models over default\nHMMER, and a significant improvement in sensitivity of the combined models over\nboth the original model and the structurally weighted models.\n\n", "human_text": "  Motivation: Profile hidden Markov Models (pHMMs) are a popular and very\nuseful tool in the detection of the remote homologue protein families.\nUnfortunately, their performance is not always satisfactory when proteins are\nin the 'twilight zone'. We present HMMER-STRUCT, a model construction algorithm\nand tool that tries to improve pHMM performance by using structural information\nwhile training pHMMs. As a first step, HMMER-STRUCT constructs a set of pHMMs.\nEach pHMM is constructed by weighting each residue in an aligned protein\naccording to a specific structural property of the residue. Properties used\nwere primary, secondary and tertiary structures, accessibility and packing.\nHMMER-STRUCT then prioritizes the results by voting. Results: We used the SCOP\ndatabase to perform our experiments. Throughout, we apply leave-one-family-out\ncross-validation over protein superfamilies. First, we used the MAMMOTH-mult\nstructural aligner to align the training set proteins. Then, we performed two\nsets of experiments. In a first experiment, we compared structure weighted\nmodels against standard pHMMs and against each other. In a second experiment,\nwe compared the voting model against individual pHMMs. We compare method\nperformance through ROC curves and through Precision/Recall curves, and assess\nsignificance through the paired two tailed t-test. Our results show significant\nperformance improvements of all structurally weighted models over default\nHMMER, and a significant improvement in sensitivity of the combined models over\nboth the original model and the structurally weighted models.\n", "machine_text": "\nThis study aims to address the dismal performance of Profile Hidden Markov Models (pHMMs) when detecting proteins in the 'twilight zone'. To this end, we introduce HMMER-STRUCT, an algorithm and tool equipped with the ability to utilize structural information while training pHMMs. In our experiments, we considered properties such as the primary, secondary and tertiary structures, accessibility and packing. Further, we evaluated the performance of the models through the use of a Leave-One-Family-Out cross-validation on a dataset consist of proteins taken from the SCOP database. Our results demonstrate that boosting the performance of the pHMMs using structural features significantly increase accuracy compared to traditional pHMM models and even our individually structure-weighted models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.201}
{"prompt": "Rephrase the abstract of an article with title 'Modeling partitioning of Min proteins between daughter cells after\n  septation in Escherichia coli'.\n  Ongoing sub-cellular oscillation of Min proteins is required to block\nminicelling in E. coli. Experimentally, Min oscillations are seen in newly\ndivided cells and no minicells are produced. In model Min systems many daughter\ncells do not oscillate following septation because of unequal partitioning of\nMin proteins between the daughter cells. Using the 3D model of Huang et al., we\ninvestigate the septation process in detail to determine the cause of the\nasymmetric partitioning of Min proteins between daughter cells. We find that\nthis partitioning problem arises at certain phases of the MinD and MinE\noscillations with respect to septal closure and it persists independently of\nparameter variation. At most 85% of the daughter cells exhibit Min oscillation\nfollowing septation. Enhanced MinD binding at the static polar and dynamic\nseptal regions, consistent with cardiolipin domains, does not substantially\nincrease this fraction of oscillating daughters. We believe that this problem\nwill be shared among all existing Min models and discuss possible biological\nmechanisms that may minimize partitioning errors of Min proteins following\nseptation.\n\n", "human_text": "  Ongoing sub-cellular oscillation of Min proteins is required to block\nminicelling in E. coli. Experimentally, Min oscillations are seen in newly\ndivided cells and no minicells are produced. In model Min systems many daughter\ncells do not oscillate following septation because of unequal partitioning of\nMin proteins between the daughter cells. Using the 3D model of Huang et al., we\ninvestigate the septation process in detail to determine the cause of the\nasymmetric partitioning of Min proteins between daughter cells. We find that\nthis partitioning problem arises at certain phases of the MinD and MinE\noscillations with respect to septal closure and it persists independently of\nparameter variation. At most 85% of the daughter cells exhibit Min oscillation\nfollowing septation. Enhanced MinD binding at the static polar and dynamic\nseptal regions, consistent with cardiolipin domains, does not substantially\nincrease this fraction of oscillating daughters. We believe that this problem\nwill be shared among all existing Min models and discuss possible biological\nmechanisms that may minimize partitioning errors of Min proteins following\nseptation.\n", "machine_text": "This study investigates the partitioning of Min proteins between daughter cells following septation in Escherichia coli by employing the 3D model developed by Huang et al. We examine the MinD and MinE oscillations with respect to septal closure to figure out the source of unequal distribution of Min proteins. Our findings suggest that at least 85% of the daughter cells experience Min oscillations following septation, and that enhanced MinD binding at the polar and dynamic septal regions does not bring about a substantial increase in the fraction of oscillating daughters. We further analyze this problem in the context of other Min models, and suggest possible biological processes which may effectively minimize partitioning errors of Min proteins.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2353}
{"prompt": "Rephrase the abstract of an article with title 'Super-Poissonian Shot Noise as a Measure of Dephasing in Closed Quantum\n  Dots'.\n  Electron-electron interactions play a major role in determining the\nlow-temperature rate of phase loss of electrons in mesoscopic systems. The\nstudy of the dephasing rate is expected to contribute to the understanding of\nthe many-body nature of such systems. Closed quantum dots are of special\ninterest in this respect, due to theoretical predictions suggesting a possible\ntransition temperature below which the dephasing rate vanishes. This prediction\nhas attracted much attention, since closed quantum dots are prime candidates\nfor storage units in quantum computers, and thus their phase coherence\nproperties are of great importance. However, an effective method for measuring\nthe dephasing rate within a closed quantum dot is still lacking. Here we study\ntwo-level systems and show that the Fano factor has a sharp peak as a function\nof the chemical potential, the location of which can be simply related to the\ndephasing rate. We thus suggest to use the properties of the Fano factor peak\nin the super-Poissonian regime as a probe for the dephasing rate.\n\n", "human_text": "  Electron-electron interactions play a major role in determining the\nlow-temperature rate of phase loss of electrons in mesoscopic systems. The\nstudy of the dephasing rate is expected to contribute to the understanding of\nthe many-body nature of such systems. Closed quantum dots are of special\ninterest in this respect, due to theoretical predictions suggesting a possible\ntransition temperature below which the dephasing rate vanishes. This prediction\nhas attracted much attention, since closed quantum dots are prime candidates\nfor storage units in quantum computers, and thus their phase coherence\nproperties are of great importance. However, an effective method for measuring\nthe dephasing rate within a closed quantum dot is still lacking. Here we study\ntwo-level systems and show that the Fano factor has a sharp peak as a function\nof the chemical potential, the location of which can be simply related to the\ndephasing rate. We thus suggest to use the properties of the Fano factor peak\nin the super-Poissonian regime as a probe for the dephasing rate.\n", "machine_text": "\nIn this article, we present a novel method of determining the dephasing rate of closed quantum dots. As electron-electron interactions play a significant part in influencing the low-temperature rate of phase loss of electrons in mesoscopic systems, it is important to be able to measure the dephasing rate of closed quantum dots, as they may serve as storage units in quantum computers. Our method is based on studying two-level systems and measuring the Fano factor peak, which has a direct link to the dephasing rate, in the super-Poissonian regime. Thus, we suggest using this technique for measuring the dephasing rate of closed quantum dots.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2668}
{"prompt": "Rephrase the abstract of an article with title 'Spin Effects in Quantum Chromodynamics and Recurrence Lattices with\n  Multi-Site Exchanges'.\n  In this thesis, we consider some spin effects in QCD and recurrence lattices\nwith multi-site exchanges. Main topic of our manuscript are critical phenomena\nin spin systems defined on the recurrence lattices. Main tool of our approach\nis the method of recursive (hierarchical) lattices. We apply the method of\ndynamical mapping (or recursive lattices) for investigation of magnetic\nproperties of the fluid and solid $^3$He, phase transitions in crystals and\nmacromolecules. First, we analyze the helix-coil phase transition for\npolypeptides and proteins, and describe an quasi unfolding transition (like the\ncold denaturation process) for the degree of helicity (the order parameter for\nmacromolecules). Next we consider the recurrent models of $^3$He defined on the\nsquare, Husimi and hexagon lattices. Using the method of dynamical mapping, the\nmagnetization curves with plateaus, bifurcation point and one period doubling\nare obtained. Then we investigate the model with cubic symmetry defined on the\nBethe lattice and containing both linear and quadratic spin-spin interactions.\nThe magnetization of the system is calculated, and a complex structure of the\nphase transitions between the disordered, partially ordered and completely\nordered states is observed. In the framework of QCD, we consider the azimuthal\nasymmetries in heavy flavor production in the lepton-nucleon deep inelastic\nscattering (DIS). We calculate the azimuthal (or $\\phi$-) dependence of the\nnext-to-leading order heavy-quark-initiated contributions to DIS. It is shown\nthat, contrary to the basic gluon-initiated component, the photon-quark\nscattering mechanism is practically $\\cos2\\phi$-independent. We investigate the\npossibility of measuring both nonperturbative (intrinsic) and perturbative\n(CTEQ, MRST) charm distributions using the $\\cos2\\phi$ asymmetry.\n\n", "human_text": "  In this thesis, we consider some spin effects in QCD and recurrence lattices\nwith multi-site exchanges. Main topic of our manuscript are critical phenomena\nin spin systems defined on the recurrence lattices. Main tool of our approach\nis the method of recursive (hierarchical) lattices. We apply the method of\ndynamical mapping (or recursive lattices) for investigation of magnetic\nproperties of the fluid and solid $^3$He, phase transitions in crystals and\nmacromolecules. First, we analyze the helix-coil phase transition for\npolypeptides and proteins, and describe an quasi unfolding transition (like the\ncold denaturation process) for the degree of helicity (the order parameter for\nmacromolecules). Next we consider the recurrent models of $^3$He defined on the\nsquare, Husimi and hexagon lattices. Using the method of dynamical mapping, the\nmagnetization curves with plateaus, bifurcation point and one period doubling\nare obtained. Then we investigate the model with cubic symmetry defined on the\nBethe lattice and containing both linear and quadratic spin-spin interactions.\nThe magnetization of the system is calculated, and a complex structure of the\nphase transitions between the disordered, partially ordered and completely\nordered states is observed. In the framework of QCD, we consider the azimuthal\nasymmetries in heavy flavor production in the lepton-nucleon deep inelastic\nscattering (DIS). We calculate the azimuthal (or $\\phi$-) dependence of the\nnext-to-leading order heavy-quark-initiated contributions to DIS. It is shown\nthat, contrary to the basic gluon-initiated component, the photon-quark\nscattering mechanism is practically $\\cos2\\phi$-independent. We investigate the\npossibility of measuring both nonperturbative (intrinsic) and perturbative\n(CTEQ, MRST) charm distributions using the $\\cos2\\phi$ asymmetry.\n", "machine_text": "\nThis article examines some spin effects that arise from quantum chromodynamics and recurrent lattices with multiple exchange sites. We explore the critical phenomena that occur in spin systems on recurrence lattices and use the method of recursive lattices to understand the magnetic behaviors of both $^3$He fluids and solids, and phase transitions in crystals and macromolecules. We analyze the helix-coil phase transition of polypeptides and proteins and look into the quasi-unfolding transition (like the cold denaturation process) concerning the helicity order parameter. We then look into the recurrent models of $^3$He defined on the square, Husimi, and hexagon lattices and calculate magnetization curves with plateaus, bifurcation points, and one period doubling. After that, we observe a complex structure of phase transitions between the disordered, partially ordered, and completely ordered states in models featuring cubic symmetry and linear or quadratic spin-spin interactions defined on the Bethe lattice. For quantum chromodynamics, we look at the azimuthal asymmetries in deep inelastic lepton-nucleon scattering and calculate the next-to-leading order in heavy-quark initiated contributions to this scattering. It is determined that the photon-quark scattering mechanism is independent of the $\\cos2\\phi$ asymmetry, unlike the basic gluon-initiated component. Last, we study the possibility of measuring both non-perturbative and perturbative charm distributions with the $\\cos2\\phi$ asymmetry.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1932}
{"prompt": "Rephrase the abstract of an article with title 'Thermodynamics of an Accretion Disk Annulus with Comparable Radiation\n  and Gas Pressure'.\n  We explore the thermodynamic and global structural properties of a local\npatch of an accretion disk whose parameters were chosen so that radiation\npressure and gas pressure would be comparable in magnitude. Heating, radiative\ntransport, and cooling are computed self-consistently with the structure by\nsolving the equations of radiation MHD in the shearing-box approximation. Using\na fully 3-d and energy-conserving code, we compute the structure and energy\nbalance of this disk segment over a span of more than forty cooling times. As\nis also true when gas pressure dominates, the disk's upper atmosphere is\nmagnetically-supported. However, unlike the gas-dominated case, no steady-state\nis reached; instead, the total (i.e., radiation plus gas) energy content\nfluctuates by factors of 3--4 over timescales of several tens of orbits, with\nno secular trend. Because the radiation pressure varies much more than the gas\npressure, the ratio of radiation pressure to gas pressure varies over the\napproximate range 0.5--2. The volume-integrated dissipation rate generally\nincreases with increasing total energy, but the mean trend is somewhat slower\nthan linear, and the instantaneous dissipation rate is often a factor of two\nlarger or smaller than the mean for that total energy level. Locally, the\ndissipation rate per unit volume scales approximately in proportion to the\ncurrent density; the time-average dissipation rate per unit mass is\nproportional to m^{-1/2}, where m is the horizontally-averaged mass column\ndensity to the nearer of the top or bottom surface. As in our earlier study of\na gas-dominated shearing-box, we find that energy transport is completely\ndominated by radiative diffusion, with Poynting flux carrying less than 1% of\nthe energy lost from the box.\n\n", "human_text": "  We explore the thermodynamic and global structural properties of a local\npatch of an accretion disk whose parameters were chosen so that radiation\npressure and gas pressure would be comparable in magnitude. Heating, radiative\ntransport, and cooling are computed self-consistently with the structure by\nsolving the equations of radiation MHD in the shearing-box approximation. Using\na fully 3-d and energy-conserving code, we compute the structure and energy\nbalance of this disk segment over a span of more than forty cooling times. As\nis also true when gas pressure dominates, the disk's upper atmosphere is\nmagnetically-supported. However, unlike the gas-dominated case, no steady-state\nis reached; instead, the total (i.e., radiation plus gas) energy content\nfluctuates by factors of 3--4 over timescales of several tens of orbits, with\nno secular trend. Because the radiation pressure varies much more than the gas\npressure, the ratio of radiation pressure to gas pressure varies over the\napproximate range 0.5--2. The volume-integrated dissipation rate generally\nincreases with increasing total energy, but the mean trend is somewhat slower\nthan linear, and the instantaneous dissipation rate is often a factor of two\nlarger or smaller than the mean for that total energy level. Locally, the\ndissipation rate per unit volume scales approximately in proportion to the\ncurrent density; the time-average dissipation rate per unit mass is\nproportional to m^{-1/2}, where m is the horizontally-averaged mass column\ndensity to the nearer of the top or bottom surface. As in our earlier study of\na gas-dominated shearing-box, we find that energy transport is completely\ndominated by radiative diffusion, with Poynting flux carrying less than 1% of\nthe energy lost from the box.\n", "machine_text": "\nThis article looks at the structure, energy balance, and thermodynamics of a section of an accretion disk in a shearing-box approximation, where both radiation and gas pressure are approximately equal in magnitude. The 3-dimensional, energy-conserving model we employed shows that the entire extent of the disk (from the highest atmospheric layer to the bottom) is magnetically supported, but that a steady-state is not reached. Instead, the total energy content of the segment fluctuates with no secular trend over timescales of several tens of orbits. Furthermore, the dissipation rate and the ratio of radiation to gas pressure differ over a 0.5-2 range, respectively, and the locally-averaged, mass-dependent dissipation rate is proportional to m^{-1/2}. Finally, it is established that the energy transportation out of the system is predominantly through radiative diffusion, with Poynding flux playing a much lesser role.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0305}
{"prompt": "Rephrase the abstract of an article with title 'STBCs from Representation of Extended Clifford Algebras'.\n  A set of sufficient conditions to construct $\\lambda$-real symbol Maximum\nLikelihood (ML) decodable STBCs have recently been provided by Karmakar et al.\nSTBCs satisfying these sufficient conditions were named as Clifford Unitary\nWeight (CUW) codes. In this paper, the maximal rate (as measured in complex\nsymbols per channel use) of CUW codes for $\\lambda=2^a,a\\in\\mathbb{N}$ is\nobtained using tools from representation theory. Two algebraic constructions of\ncodes achieving this maximal rate are also provided. One of the constructions\nis obtained using linear representation of finite groups whereas the other\nconstruction is based on the concept of right module algebra over\nnon-commutative rings. To the knowledge of the authors, this is the first paper\nin which matrices over non-commutative rings is used to construct STBCs. An\nalgebraic explanation is provided for the 'ABBA' construction first proposed by\nTirkkonen et al and the tensor product construction proposed by Karmakar et al.\nFurthermore, it is established that the 4 transmit antenna STBC originally\nproposed by Tirkkonen et al based on the ABBA construction is actually a single\ncomplex symbol ML decodable code if the design variables are permuted and\nsignal sets of appropriate dimensions are chosen.\n\n", "human_text": "  A set of sufficient conditions to construct $\\lambda$-real symbol Maximum\nLikelihood (ML) decodable STBCs have recently been provided by Karmakar et al.\nSTBCs satisfying these sufficient conditions were named as Clifford Unitary\nWeight (CUW) codes. In this paper, the maximal rate (as measured in complex\nsymbols per channel use) of CUW codes for $\\lambda=2^a,a\\in\\mathbb{N}$ is\nobtained using tools from representation theory. Two algebraic constructions of\ncodes achieving this maximal rate are also provided. One of the constructions\nis obtained using linear representation of finite groups whereas the other\nconstruction is based on the concept of right module algebra over\nnon-commutative rings. To the knowledge of the authors, this is the first paper\nin which matrices over non-commutative rings is used to construct STBCs. An\nalgebraic explanation is provided for the 'ABBA' construction first proposed by\nTirkkonen et al and the tensor product construction proposed by Karmakar et al.\nFurthermore, it is established that the 4 transmit antenna STBC originally\nproposed by Tirkkonen et al based on the ABBA construction is actually a single\ncomplex symbol ML decodable code if the design variables are permuted and\nsignal sets of appropriate dimensions are chosen.\n", "machine_text": "\nThis paper investigates the application of Extended Clifford Algebras in the design of Space-Time Block Coding (STBC) systems that are Maximum Likelihood (ML) decodable. To study this problem, the maximal rate of STBCs is obtained with $\\lambda=2^a$ complex symbols per channel used. Algebasic constructions based on linear representations of finite groups and right module algebras of non-commutative rings are presented and an algebraic basis is provided for the 'ABBA' method and tensor product construction, previously proposed by Tirkkonen et al and Karmakar et al respectively. It is established that a four transmit antenna design described by Tirkkonen et al is a single complex symbol ML decodable system if the configuration of design variables and signal sets is modified accordingly.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2507}
{"prompt": "Rephrase the abstract of an article with title 'Resonance and frequency-locking phenomena in spatially extended\n  phytoplankton-zooplankton system with additive noise and periodic forces'.\n  In this paper, we present a spatial version of phytoplankton-zooplankton\nmodel that includes some important factors such as external periodic forces,\nnoise, and diffusion processes. The spatially extended\nphytoplankton-zooplankton system is from the original study by Scheffer [M\nScheffer, Fish and nutrients interplay determines algal biomass: a minimal\nmodel, Oikos \\textbf{62} (1991) 271-282]. Our results show that the spatially\nextended system exhibit a resonant patterns and frequency-locking phenomena.\nThe system also shows that the noise and the external periodic forces play a\nconstructive role in the Scheffer's model: first, the noise can enhance the\noscillation of phytoplankton species' density and format a large clusters in\nthe space when the noise intensity is within certain interval. Second, the\nexternal periodic forces can induce 4:1 and 1:1 frequency-locking and spatially\nhomogeneous oscillation phenomena to appear. Finally, the resonant patterns are\nobserved in the system when the spatial noises and external periodic forces are\nboth turned on. Moreover, we found that the 4:1 frequency-locking transform\ninto 1:1 frequency-locking when the noise intensity increased. In addition to\nelucidating our results outside the domain of Turing instability, we provide\nfurther analysis of Turing linear stability with the help of the numerical\ncalculation by using the Maple software. Significantly, oscillations are\nenhanced in the system when the noise term presents. These results indicate\nthat the oceanic plankton bloom may partly due to interplay between the\nstochastic factors and external forces instead of deterministic factors. These\nresults also may help us to understand the effects arising from undeniable\nsubject to random fluctuations in oceanic plankton bloom.\n\n", "human_text": "  In this paper, we present a spatial version of phytoplankton-zooplankton\nmodel that includes some important factors such as external periodic forces,\nnoise, and diffusion processes. The spatially extended\nphytoplankton-zooplankton system is from the original study by Scheffer [M\nScheffer, Fish and nutrients interplay determines algal biomass: a minimal\nmodel, Oikos \\textbf{62} (1991) 271-282]. Our results show that the spatially\nextended system exhibit a resonant patterns and frequency-locking phenomena.\nThe system also shows that the noise and the external periodic forces play a\nconstructive role in the Scheffer's model: first, the noise can enhance the\noscillation of phytoplankton species' density and format a large clusters in\nthe space when the noise intensity is within certain interval. Second, the\nexternal periodic forces can induce 4:1 and 1:1 frequency-locking and spatially\nhomogeneous oscillation phenomena to appear. Finally, the resonant patterns are\nobserved in the system when the spatial noises and external periodic forces are\nboth turned on. Moreover, we found that the 4:1 frequency-locking transform\ninto 1:1 frequency-locking when the noise intensity increased. In addition to\nelucidating our results outside the domain of Turing instability, we provide\nfurther analysis of Turing linear stability with the help of the numerical\ncalculation by using the Maple software. Significantly, oscillations are\nenhanced in the system when the noise term presents. These results indicate\nthat the oceanic plankton bloom may partly due to interplay between the\nstochastic factors and external forces instead of deterministic factors. These\nresults also may help us to understand the effects arising from undeniable\nsubject to random fluctuations in oceanic plankton bloom.\n", "machine_text": "\nIn this paper, we analyze a spatial version of the classical model of phytoplankton-zooplankton interactions proposed by Scheffer [M Scheffer, Fish and nutrients interplay determines algal biomass: a minimal model, Oikos \\textbf{62} (1991) 271-282]. We extend the model by including external periodic forces, noise, and diffusion processes. Our results show that this spatially extended system presents resonance patterns and frequency-locking phenomena. Moreover, we demonstrate that external periodic forces induce the appearing of 4:1 and 1:1 frequency-locking and spatially homogeneous oscillations while noise is found to enhance the oscillations of the phytoplankton species' density and create large clusters in the space. Furhtermore, the numerical calculation obtained with the help of the Maple software suggests that the 4:1 frequency-locking can transform into 1:1 frequency-locking when the noise intensity increases. Our findings are also out of the scope of Turing instability. Consequently, we can deduce that random fluctuations may play a significant role in regulating oceanic plankton blooms, in contrast to the deterministic factors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3724}
{"prompt": "Rephrase the abstract of an article with title 'The HI content of elliptical and lenticular galaxies with recent star\n  formation'.\n  As a first step toward constraining the efficiency of the star formation\nepisodes that lead to elliptical (E) and lenticular (S0) K+A galaxies, a survey\nfor HI within a sample of E and S0 K+A galaxies and their likely progenitors\n(i.e., actively star forming E and S0 galaxies) has been conducted with the\nNRAO Green Bank Telescope (GBT). The sample was taken from a larger parent\nsample drawn from the Sloan Digital Sky Survey (SDSS). Here, the GBT data and\ninitial results are discussed. Over half (19 out of 30) of all observed\ngalaxies have detectable 21-cm emission. It was found that both the K+A and\nstar forming early-type (SFE) galaxies were on average more gas poor than disk\ngalaxies at the same luminosity while being more gas rich than more typical E\nand S0 galaxies with detected 21-cm emission. The gas richness of K+A galaxies\nappears to be similar to that of SFE galaxies. The star formation rates and\nestimated star formation time scales of the SFE galaxies imply that they are\ncapable of only marginally changing their atomic hydrogen content. Follow-up\nobservations are required to explore these same issues in terms of molecular\ngas, which is more likely to actively participate in the star formation\nprocess. Kinematic data for the HI gas, the warm ionised gas, and the stars\nwithin the galaxies combined with the SDSS $g$ and $i$ band surface brightness\nprofiles imply that the atomic hydrogen is most likely spatially coincident\nwith the star forming regions within ~1 kpc of the galaxies' centres.\n\n", "human_text": "  As a first step toward constraining the efficiency of the star formation\nepisodes that lead to elliptical (E) and lenticular (S0) K+A galaxies, a survey\nfor HI within a sample of E and S0 K+A galaxies and their likely progenitors\n(i.e., actively star forming E and S0 galaxies) has been conducted with the\nNRAO Green Bank Telescope (GBT). The sample was taken from a larger parent\nsample drawn from the Sloan Digital Sky Survey (SDSS). Here, the GBT data and\ninitial results are discussed. Over half (19 out of 30) of all observed\ngalaxies have detectable 21-cm emission. It was found that both the K+A and\nstar forming early-type (SFE) galaxies were on average more gas poor than disk\ngalaxies at the same luminosity while being more gas rich than more typical E\nand S0 galaxies with detected 21-cm emission. The gas richness of K+A galaxies\nappears to be similar to that of SFE galaxies. The star formation rates and\nestimated star formation time scales of the SFE galaxies imply that they are\ncapable of only marginally changing their atomic hydrogen content. Follow-up\nobservations are required to explore these same issues in terms of molecular\ngas, which is more likely to actively participate in the star formation\nprocess. Kinematic data for the HI gas, the warm ionised gas, and the stars\nwithin the galaxies combined with the SDSS $g$ and $i$ band surface brightness\nprofiles imply that the atomic hydrogen is most likely spatially coincident\nwith the star forming regions within ~1 kpc of the galaxies' centres.\n", "machine_text": "\nThis survey of 30 early-type galaxies (E and S0) from the Sloan Digital Sky Survey (SDSS) involved the NRAO Green Bank Telescope (GBT) to investigate the hydrogen content related to recent star formation. 19 galaxies had HI detected in emission. Compared to disk galaxies of similar luminosity, the K+A and star forming early-type galaxies were observed to have lower levels of atomic hydrogen, yet more than typical E and S0 galaxies. Star formation rates and estimated time scales suggest that these galaxies have limited capability to change their hydrogen content. Follow-up observations are necessary to explore these same topics in terms of molecular gas which is more likely to participate in the star formation process. The data obtained from this research suggest that the atomic hydrogen is present within 1 kpc of the galaxy center closest to the star forming regions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3469}
{"prompt": "Rephrase the abstract of an article with title 'Driving Mechanism of Jets and Outflows in Star Formation Process'.\n  The driving mechanism of jets and outflows in star formation process is\nstudied using resistive MHD nested grid simulations. We calculated cloud\nevolution from the molecular cloud core to the stellar core. In the collapsing\ncloud core, we found two distinct flows: Low-velocity flows (sim 5 km/s) with a\nwide opening angle, driven from the adiabatic core, and high-velocity flows\n(sim 30 km/s) with good collimation, driven from the protostar. High-velocity\nflows are enclosed by low-velocity flows after protostar formation. The\ndifference in the degree of collimation between the two flows is caused by the\nstrength of the magnetic field and configuration of the magnetic field lines.\nThe magnetic field around an adiabatic core is strong and has an hourglass\nconfiguration; therefore, flows from the adiabatic core are driven mainly by\nthe magnetocentrifugal mechanism and guided by the hourglass-like field lines.\nIn contrast, the magnetic field around the protostar is weak and has a straight\nconfiguration owing to Ohmic dissipation in the high-density gas region.\nTherefore, flows from the protostar are driven mainly by the magnetic pressure\ngradient force and guided by straight field lines. Differing depth of the\ngravitational potential between the adiabatic core and the protostar cause the\ndifference of the flow speed. Low-velocity flows correspond to the observed\nmolecular outflows, while high-velocity flows correspond to the observed\noptical jets. We suggest that the outflow and the jet are driven by different\ncores, rather than that the outflow being entrained by the jet.\n\n", "human_text": "  The driving mechanism of jets and outflows in star formation process is\nstudied using resistive MHD nested grid simulations. We calculated cloud\nevolution from the molecular cloud core to the stellar core. In the collapsing\ncloud core, we found two distinct flows: Low-velocity flows (sim 5 km/s) with a\nwide opening angle, driven from the adiabatic core, and high-velocity flows\n(sim 30 km/s) with good collimation, driven from the protostar. High-velocity\nflows are enclosed by low-velocity flows after protostar formation. The\ndifference in the degree of collimation between the two flows is caused by the\nstrength of the magnetic field and configuration of the magnetic field lines.\nThe magnetic field around an adiabatic core is strong and has an hourglass\nconfiguration; therefore, flows from the adiabatic core are driven mainly by\nthe magnetocentrifugal mechanism and guided by the hourglass-like field lines.\nIn contrast, the magnetic field around the protostar is weak and has a straight\nconfiguration owing to Ohmic dissipation in the high-density gas region.\nTherefore, flows from the protostar are driven mainly by the magnetic pressure\ngradient force and guided by straight field lines. Differing depth of the\ngravitational potential between the adiabatic core and the protostar cause the\ndifference of the flow speed. Low-velocity flows correspond to the observed\nmolecular outflows, while high-velocity flows correspond to the observed\noptical jets. We suggest that the outflow and the jet are driven by different\ncores, rather than that the outflow being entrained by the jet.\n", "machine_text": "\nThe aim of this study was to explore the mechanism that drives jets and outflows during the star formation process. Utilizing resistive MHD nested grid simulations, the authors calculated the evolution of the molecular cloud to stellar core. It was found that two distinct flows exist in the collapsing cloud core: Low-velocity flows (5 km/s) of wide opening angle, driven by the adiabatic core, and high-velocity flows (30 km/s) of narrow opening angle, driven by the protostar. Magnetic fields around the adiabatic core are strong and shaped like an hourglass; thus, they are able to propel the flow via the magnetocentrifugal mechanism and guide it along hourglass-like field lines. The magnetic forces around the protostar are weaker and the field lines straighter, pointing to magnetic pressure gradient force and straight field lines as the main drivers of the flow. The difference of depths of the gravitational potential between the adiabatic core and the protostar contributes to the distinct velocities of the two flows; the low-velocity flow is thought to manifest itself as observed molecular outflows, while the high-velocity ones can be seen as optical jets. All in all, this study suggests that the outflow and the jet are driven by different regions in the core, and not that the outflow is entrained by the jet.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2073}
{"prompt": "Rephrase the abstract of an article with title 'Testing the Accuracy of Synthetic Stellar Libraries'.\n  In the present work we compare in detail some of the major theoretical\nlibraries with observations, aiming at detecting weaknesses and strengths from\nthe stellar population modelling point of view. We compared model predictions\nand observations for broad- band colours and for high resolution spectral\nfeatures. Concerning the broad-band colours, we measured the stellar colour\ngiven by three recent sets of model atmospheres and flux distributions(Castelli\n& Kurucz 2003; Gustafsson et al. 2003; Brott & Hauschildt 2005), and compared\nthem with a recent UBVRIJHK calibration (Worthey & Lee 2007). We found that the\nmodels can reproduce with reasonable accuracy the stellar colours for a fair\ninterval in effective temperatures and gravities. The exceptions are: 1) the\nU-B colour, where the models are typically redder than the observations, and;\n2) the very cool stars in general (V-K > ~3).Concerning the high resolution\nfeatures, we measured 35 spectral indices defined in the literature on three\nhigh resolution synthetic libraries (Coelho et al. 2005; Martins et al. 2005;\nMunari et al. 2005), and compared them with the observed measurements given by\nthree empirical libraries (Valdes et al.2004; Sanchez-Blazquez et al. 2006;\nPrugniel & Soubiran 2001). We found that the direct comparison between models\nand observations is not a simple task, given the uncertainties in parameter\ndeterminations of empirical libraries. Taking that aside, we found that in\ngeneral the three libraries present similar behaviours and systematic\ndeviations. For stars with Teff < 7000K, the library by Coelho et al. (2005) is\nthe one with best average performance. We detect that lists of atomic and\nmolecular line opacities still need improvement, specially in the blue region\nof thespectrum, and for the cool stars (Teff < ~4500K).\n\n", "human_text": "  In the present work we compare in detail some of the major theoretical\nlibraries with observations, aiming at detecting weaknesses and strengths from\nthe stellar population modelling point of view. We compared model predictions\nand observations for broad- band colours and for high resolution spectral\nfeatures. Concerning the broad-band colours, we measured the stellar colour\ngiven by three recent sets of model atmospheres and flux distributions(Castelli\n& Kurucz 2003; Gustafsson et al. 2003; Brott & Hauschildt 2005), and compared\nthem with a recent UBVRIJHK calibration (Worthey & Lee 2007). We found that the\nmodels can reproduce with reasonable accuracy the stellar colours for a fair\ninterval in effective temperatures and gravities. The exceptions are: 1) the\nU-B colour, where the models are typically redder than the observations, and;\n2) the very cool stars in general (V-K > ~3).Concerning the high resolution\nfeatures, we measured 35 spectral indices defined in the literature on three\nhigh resolution synthetic libraries (Coelho et al. 2005; Martins et al. 2005;\nMunari et al. 2005), and compared them with the observed measurements given by\nthree empirical libraries (Valdes et al.2004; Sanchez-Blazquez et al. 2006;\nPrugniel & Soubiran 2001). We found that the direct comparison between models\nand observations is not a simple task, given the uncertainties in parameter\ndeterminations of empirical libraries. Taking that aside, we found that in\ngeneral the three libraries present similar behaviours and systematic\ndeviations. For stars with Teff < 7000K, the library by Coelho et al. (2005) is\nthe one with best average performance. We detect that lists of atomic and\nmolecular line opacities still need improvement, specially in the blue region\nof thespectrum, and for the cool stars (Teff < ~4500K).\n", "machine_text": "This article examines the accuracy of synthetic stellar libraries by comparison with observation. The models are evaluated based on both broad-band colours and high resolution spectral features. The comparison of the model atmospheres, flux distributions, and UBVRIJHK calibration show that models perform comparatively well, with the exceptions of U-B colour and V-K > ~3 stars. Although the direct comparison between models and observations introduces uncertainties, the three libraries generally exhibit similar behaviour and deviations. An improved list of atomic and molecular line opacities is needed, especially in the blue and for cool stars below 4500K.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1994}
{"prompt": "Rephrase the abstract of an article with title 'New possible properties of atomic nuclei investigated by non linear\n  methods: Fractal and recurrence quantification analysis'.\n  For the first time we apply the methodologies of nonlinear analysis to\ninvestigate atomic matter. We use these methods in the analysis of Atomic\nWeights and of Mass Number of atomic nuclei. Using the AutoCorrelation Function\nand Mutual Information we establish the presence of nonlinear effects in the\nmechanism of increasing mass of atomic nuclei considered as a function of the\natomic number. We find that increasing mass is divergent, possibly chaotic. We\nalso investigate the possible existence of a Power Law for atomic nuclei and,\nusing also the technique of the variogram, we conclude that a fractal regime\ncould superintend to the mechanism of increasing mass for nuclei. Finally,\nusing the Hurst exponent, evidence is obtained that the mechanism of increasing\nmass in atomic nuclei is in the fractional Brownian regime. The most\ninteresting results are obtained by using Recurrence Quantification Analysis\n(RQA). New recurrences, psudoperiodicities, self-resemblance and class of\nself-similarities are identified with values of determinism showing oscillating\nvalues indicating the presence of more or less stability during the process of\nincreasing mass of atomic nuclei. In brief, new regimes of regularities are\nidentified for atomic nuclei that deserve to be studied by future researches.\nIn particular an accurate analysis of binding energy values by nonlinear\nmethods is further required.\n\n", "human_text": "  For the first time we apply the methodologies of nonlinear analysis to\ninvestigate atomic matter. We use these methods in the analysis of Atomic\nWeights and of Mass Number of atomic nuclei. Using the AutoCorrelation Function\nand Mutual Information we establish the presence of nonlinear effects in the\nmechanism of increasing mass of atomic nuclei considered as a function of the\natomic number. We find that increasing mass is divergent, possibly chaotic. We\nalso investigate the possible existence of a Power Law for atomic nuclei and,\nusing also the technique of the variogram, we conclude that a fractal regime\ncould superintend to the mechanism of increasing mass for nuclei. Finally,\nusing the Hurst exponent, evidence is obtained that the mechanism of increasing\nmass in atomic nuclei is in the fractional Brownian regime. The most\ninteresting results are obtained by using Recurrence Quantification Analysis\n(RQA). New recurrences, psudoperiodicities, self-resemblance and class of\nself-similarities are identified with values of determinism showing oscillating\nvalues indicating the presence of more or less stability during the process of\nincreasing mass of atomic nuclei. In brief, new regimes of regularities are\nidentified for atomic nuclei that deserve to be studied by future researches.\nIn particular an accurate analysis of binding energy values by nonlinear\nmethods is further required.\n", "machine_text": "\nFor the first time, we apply nonlinear analysis to the analysis of Atomic Weights and Mass Number of atomic nuclei. Our investigations show the presence of nonlinear influence in the increase of mass in nuclei, potentially revealing chaotic behaviour.  Additionally, the analysis suggests a potential Power Law governing the growth of mass in atomic nuclei. Variogram analysis indicates the activity may be fractal, and the Hurst Exponent suggests the same growing mass behaviour is in the fractional Brownian regime. Recurrence Quantification Analysis (RQA) gives evidence of new recurrences, pseudoperiodicities, self-resemblances and self-similarities, with determinism values displaying varied stability during anatomic nucleus' escalating mass. The results of this analysis point to new regularities in atomic nuclei that need further exploration, particularly in regards to binding energy values using nonlinear methods.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0903}
{"prompt": "Rephrase the abstract of an article with title 'Field dependent quasiparticles in the infinite dimensional Hubbard model'.\n  We present dynamical mean field theory (DMFT) results for the local spectral\ndensities of the one- and two-particle response functions for the infinite\ndimensional Hubbard model in a magnetic field. We look at the different regimes\ncorresponding to half-filling, near half-filling and well away from\nhalf-filling, for intermediate and strong values of the local interaction $U$.\nThe low energy results are analyzed in terms of quasiparticles with field\ndependent parameters. The renormalized parameters are determined by two\ndifferent methods, both based on numerical renormalization group (NRG)\ncalculations, and we find good agreement. Away from half-filling the\nquasiparticle weights, $z_\\sigma(H)$, differ according to the spin type\n$\\sigma=\\uparrow$ or $\\sigma=\\downarrow$. Using the renormalized parameters, we\nshow that DMFT-NRG results for the local longitudinal and transverse dynamic\nspin susceptibilities in an arbitrary field can be understood in terms of\nrepeated scattering of these quasiparticles. We also check Luttinger's theorem\nfor the Hubbard model and find it to be satisfied in all parameter regimes and\nfor all values of the magnetic field.\n\n", "human_text": "  We present dynamical mean field theory (DMFT) results for the local spectral\ndensities of the one- and two-particle response functions for the infinite\ndimensional Hubbard model in a magnetic field. We look at the different regimes\ncorresponding to half-filling, near half-filling and well away from\nhalf-filling, for intermediate and strong values of the local interaction $U$.\nThe low energy results are analyzed in terms of quasiparticles with field\ndependent parameters. The renormalized parameters are determined by two\ndifferent methods, both based on numerical renormalization group (NRG)\ncalculations, and we find good agreement. Away from half-filling the\nquasiparticle weights, $z_\\sigma(H)$, differ according to the spin type\n$\\sigma=\\uparrow$ or $\\sigma=\\downarrow$. Using the renormalized parameters, we\nshow that DMFT-NRG results for the local longitudinal and transverse dynamic\nspin susceptibilities in an arbitrary field can be understood in terms of\nrepeated scattering of these quasiparticles. We also check Luttinger's theorem\nfor the Hubbard model and find it to be satisfied in all parameter regimes and\nfor all values of the magnetic field.\n", "machine_text": "\nIn this paper, we utilize dynamical mean field theory (DMFT) along with numerical renormalization group (NRG) to analyze the local spectral densities of one- and two-particle response functions for the infinite-dimensional Hubbard model in a magnetic field. The regime of half-filling, near half-filling, and away from half-filling, for intermediate and strong $U$ values, is studied. Results suggest the existence of quasiparticles with field dependent parameters, which are quantified via two distinct numerical renormalization methods. After identifying the renormalized parameters, analysis of local longitudinal and transverse dynamic spin susceptibilities for an arbitrary field is successfully explained using the corresponding quasiparticles. Additionally, results show that Luttinger's theorem holds true in all regimes and all values of the magnetic field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3824}
{"prompt": "Rephrase the abstract of an article with title 'Lattice chirality and the decoupling of mirror fermions'.\n  We show, using exact lattice chirality, that partition functions of lattice\ngauge theories with vectorlike fermion representations can be split into\n\"light\" and \"mirror\" parts, such that the \"light\" and \"mirror\" representations\nare chiral. The splitting of the full partition function into \"light\" and\n\"mirror\" is well defined only if the two sectors are separately anomaly free.\nWe show that only then is the generating functional, and hence the spectrum, of\nthe mirror theory a smooth function of the gauge field background. This\nexplains how ideas to use additional non-gauge, high-scale mirror-sector\ndynamics to decouple the mirror fermions without breaking the gauge\nsymmetry--for example, in symmetric phases at strong mirror Yukawa\ncoupling--are forced to respect the anomaly-free condition when combined with\nthe exact lattice chiral symmetry. Our results also explain a paradox posed by\na recent numerical study of the mirror-fermion spectrum in a toy\nwould-be-anomalous two-dimensional theory. In passing, we prove some general\nproperties of the partition functions of arbitrary chiral theories on the\nlattice that should be of interest for further studies in this field.\n\n", "human_text": "  We show, using exact lattice chirality, that partition functions of lattice\ngauge theories with vectorlike fermion representations can be split into\n\"light\" and \"mirror\" parts, such that the \"light\" and \"mirror\" representations\nare chiral. The splitting of the full partition function into \"light\" and\n\"mirror\" is well defined only if the two sectors are separately anomaly free.\nWe show that only then is the generating functional, and hence the spectrum, of\nthe mirror theory a smooth function of the gauge field background. This\nexplains how ideas to use additional non-gauge, high-scale mirror-sector\ndynamics to decouple the mirror fermions without breaking the gauge\nsymmetry--for example, in symmetric phases at strong mirror Yukawa\ncoupling--are forced to respect the anomaly-free condition when combined with\nthe exact lattice chiral symmetry. Our results also explain a paradox posed by\na recent numerical study of the mirror-fermion spectrum in a toy\nwould-be-anomalous two-dimensional theory. In passing, we prove some general\nproperties of the partition functions of arbitrary chiral theories on the\nlattice that should be of interest for further studies in this field.\n", "machine_text": "\nWe investigate how lattice chirality affects the decoupling of mirror fermions. To do so, we demonstrate that the partition functions of lattice gauge theories with vectorlike fermion representations can be divided into 'light' and 'mirror' procedures, such that each representation is chiral. This method only works reliably when the two sectors are anomaly-free. Thus, the use of additional high-scale dynamics to decouple the mirror fermions in a gauge-symmetric phase at a strong mirror-Yukawa coupling is dependent on satisfying the same anomaly-free condition. We also use our findings to explain a recent numerical paradox concerning the mirror-fermion spectrum in a toy 2-dimensional would-be-anomalous theory. Overall, our results unveil new properties concerning the partition functions of chiral theories on a lattice that could be useful for future explorations.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1043}
{"prompt": "Rephrase the abstract of an article with title 'Stokes-vector evolution in a weakly anisotropic inhomogeneous medium'.\n  Equation for evolution of the four-component Stokes vector in weakly\nanisotropic and smoothly inhomogeneous media is derived on the basis of\nquasi-isotropic approximation of the geometrical optics method, which provides\nconsequent asymptotic solution of Maxwell equations. Our equation generalizes\nprevious results, obtained for the normal propagation of electromagnetic waves\nin stratified media. It is valid for curvilinear rays with torsion and is\ncapable to describe normal modes conversion in the inhomogeneous media.\nRemarkably, evolution of the Stokes vector is described by the\nBargmann-Michel-Telegdi equation for relativistic spin precession, whereas the\nequation for the three-component Stokes vector resembles the Landau-Lifshitz\nequation for spin precession in ferromegnetic systems. General theory is\napplied for analysis of polarization evolution in a magnetized plasma. We also\nemphasize fundamental features of the non-Abelian polarization evolution in\nanisotropic inhomogeneous media and illustrate them by simple examples.\n\n", "human_text": "  Equation for evolution of the four-component Stokes vector in weakly\nanisotropic and smoothly inhomogeneous media is derived on the basis of\nquasi-isotropic approximation of the geometrical optics method, which provides\nconsequent asymptotic solution of Maxwell equations. Our equation generalizes\nprevious results, obtained for the normal propagation of electromagnetic waves\nin stratified media. It is valid for curvilinear rays with torsion and is\ncapable to describe normal modes conversion in the inhomogeneous media.\nRemarkably, evolution of the Stokes vector is described by the\nBargmann-Michel-Telegdi equation for relativistic spin precession, whereas the\nequation for the three-component Stokes vector resembles the Landau-Lifshitz\nequation for spin precession in ferromegnetic systems. General theory is\napplied for analysis of polarization evolution in a magnetized plasma. We also\nemphasize fundamental features of the non-Abelian polarization evolution in\nanisotropic inhomogeneous media and illustrate them by simple examples.\n", "machine_text": "\nThis paper is concerned with developing an equation that tracks the transformation of a four-component Stokes vector in a weakly anisotropic and smoothly varying medium. This equation, derived from the quasi-isotropic approximation of the geometric optics method, stands to generalize the results of past studies regarding the normal propagation of electromagnetic waves in stratified media. Its accuracy extends to curvilinear rays with torsion, and it is equipped with the ability to model normal mode conversion in inhomogeneous media. Remarkably, its expression for the Stokes vector can be likened to the Bargmann-Michel-Telegdi equation for the precession of relativistic spin, while the equation for the three-component Stokes vector resembles the Landau-Lifshitz equation used to measure spin precession in ferromagnetic systems. The theory is applied in the context of analyzing polarization evolution in a magnetized plasma, and its basic non-Abelian features, illustrated using some easy-to-grasp examples, are highlighted.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.445}
{"prompt": "Rephrase the abstract of an article with title 'Implications of \"peak oil\" for atmospheric CO2 and climate'.\n  Unconstrained CO2 emission from fossil fuel burning has been the dominant\ncause of observed anthropogenic global warming. The amounts of \"proven\" and\npotential fossil fuel reserves are uncertain and debated. Regardless of the\ntrue values, society has flexibility in the degree to which it chooses to\nexploit these reserves, especially unconventional fossil fuels and those\nlocated in extreme or pristine environments. If conventional oil production\npeaks within the next few decades, it may have a large effect on future\natmospheric CO2 and climate change, depending upon subsequent energy choices.\nAssuming that proven oil and gas reserves do not greatly exceed estimates of\nthe Energy Information Administration, and recent trends are toward lower\nestimates, we show that it is feasible to keep atmospheric CO2 from exceeding\nabout 450 ppm by 2100, provided that emissions from coal, unconventional fossil\nfuels, and land use are constrained. Coal-fired power plants without\nsequestration must be phased out before mid-century to achieve this CO2 limit.\nIt is also important to \"stretch\" conventional oil reserves via energy\nconservation and efficiency, thus averting strong pressures to extract liquid\nfuels from coal or unconventional fossil fuels while clean technologies are\nbeing developed for the era \"beyond fossil fuels\". We argue that a rising price\non carbon emissions is needed to discourage conversion of the vast fossil\nresources into usable reserves, and to keep CO2 beneath the 450 ppm ceiling.\n\n", "human_text": "  Unconstrained CO2 emission from fossil fuel burning has been the dominant\ncause of observed anthropogenic global warming. The amounts of \"proven\" and\npotential fossil fuel reserves are uncertain and debated. Regardless of the\ntrue values, society has flexibility in the degree to which it chooses to\nexploit these reserves, especially unconventional fossil fuels and those\nlocated in extreme or pristine environments. If conventional oil production\npeaks within the next few decades, it may have a large effect on future\natmospheric CO2 and climate change, depending upon subsequent energy choices.\nAssuming that proven oil and gas reserves do not greatly exceed estimates of\nthe Energy Information Administration, and recent trends are toward lower\nestimates, we show that it is feasible to keep atmospheric CO2 from exceeding\nabout 450 ppm by 2100, provided that emissions from coal, unconventional fossil\nfuels, and land use are constrained. Coal-fired power plants without\nsequestration must be phased out before mid-century to achieve this CO2 limit.\nIt is also important to \"stretch\" conventional oil reserves via energy\nconservation and efficiency, thus averting strong pressures to extract liquid\nfuels from coal or unconventional fossil fuels while clean technologies are\nbeing developed for the era \"beyond fossil fuels\". We argue that a rising price\non carbon emissions is needed to discourage conversion of the vast fossil\nresources into usable reserves, and to keep CO2 beneath the 450 ppm ceiling.\n", "machine_text": "\nThe outcomes of our exploitation of fossil fuel reserves is not only uncertain, but highly flexible and dependent on our own choices - particularly those involving unconventional fossil fuels found in extreme or pristine environments, and those of 'peak oil'. In light of estimates from the Energy Information Administration, and recent trends towards lower estimations, there is a possibility to limit atmospheric CO2 emissions to roughly 450 ppm by 2100 by constraining coal, unconventional fossil fuels, and land use. To achieve this, coal-fired power plants must be phased out before mid-century, and there must be a focus on conserving and 'stretching' conventional oil reserves, as well as developing clean technologies for 'beyond fossil fuels'. Ultimately, a rising price on carbon emissions may be the most effective strategy to discourage conversion of fossil losses into usable reserves and keep CO2 beneath the 450 ppm ceiling.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2782}
{"prompt": "Rephrase the abstract of an article with title 'Surveys of the Galactic Center and the Nature of the Galactic Center\n  Lobe'.\n  The Galactic center (GC) is a dense and chaotic region filled with unusual\nsources, such as intense star forming regions, dense star clusters, nonthermal\nradio filaments, and a massive black hole. The proximity of the GC region makes\nit an ideal place to study the unusual processes that tend to manifest\nthemselves in Galactic nuclei. This thesis uses single-dish and interferometric\nradio continuum, radio recombination line, polarized radio continuum, and\nmid-IR observations to study the wide variety of physical processes seen in the\nGC region on physical scales from 0.1 to 100 parsecs. These observations\nprovide one of the most sensitive studies of the radio continuum emission in\nthe central 500 parsecs. I also study the properties of nonthermal radio\nfilaments, which can constrain their origin and the structure of the magnetic\nfield in the GC region.\n  The presence of massive star clusters and a massive black hole suggest that\nstarburst and AGN phenomena can manifest themselves in our Galaxy. This thesis\nexplores this possibility by studying a 150-pc-tall, shell-like structure\ncalled the Galactic center lobe (GCL). Our observations examine the spectral\nindex, dust emission, polarized continuum emission, and ionized gas throughout\nthe GCL. I find strong evidence supporting the idea that the GCL is a true\nthree-dimensional shell located in the GC region with nested layers of ionized,\nmagnetized, and mid-IR--emitting components. I compare the physical conditions\nof the GCL to proposed models for its origin and find best agreement with\nstarburst outflows seen in other galaxies, yet consistent with the currently\nobserved pressure and star formation rate in the central tens of parsecs of our\nGalaxy. (abridged)\n\n", "human_text": "  The Galactic center (GC) is a dense and chaotic region filled with unusual\nsources, such as intense star forming regions, dense star clusters, nonthermal\nradio filaments, and a massive black hole. The proximity of the GC region makes\nit an ideal place to study the unusual processes that tend to manifest\nthemselves in Galactic nuclei. This thesis uses single-dish and interferometric\nradio continuum, radio recombination line, polarized radio continuum, and\nmid-IR observations to study the wide variety of physical processes seen in the\nGC region on physical scales from 0.1 to 100 parsecs. These observations\nprovide one of the most sensitive studies of the radio continuum emission in\nthe central 500 parsecs. I also study the properties of nonthermal radio\nfilaments, which can constrain their origin and the structure of the magnetic\nfield in the GC region.\n  The presence of massive star clusters and a massive black hole suggest that\nstarburst and AGN phenomena can manifest themselves in our Galaxy. This thesis\nexplores this possibility by studying a 150-pc-tall, shell-like structure\ncalled the Galactic center lobe (GCL). Our observations examine the spectral\nindex, dust emission, polarized continuum emission, and ionized gas throughout\nthe GCL. I find strong evidence supporting the idea that the GCL is a true\nthree-dimensional shell located in the GC region with nested layers of ionized,\nmagnetized, and mid-IR--emitting components. I compare the physical conditions\nof the GCL to proposed models for its origin and find best agreement with\nstarburst outflows seen in other galaxies, yet consistent with the currently\nobserved pressure and star formation rate in the central tens of parsecs of our\nGalaxy. (abridged)\n", "machine_text": "\nThis thesis investigates the environment of the Galactic center (GC) in order to better understand the unique processes present in this region. To this effect, an array of observation techniques are employed, such as single-dish and interferometric radio continuum, radio recombination line, polarized radio continuum, and mid-IR observations. These observations span physical scales of 0.1 to 100 parsecs and have resulted in one of the most sensitive studies of the radio continuum emission in the central 500 parsecs. Nonthermal radio filaments are also studied in order to provide insight into their origin and the structure of the magnetic field in the GC region. Moreover, I focus on the Galactic center lobe (GCL), a 150-pc-tall shell-like structure, and analyze the spectral index, dust emission, polarized continuum emission, and ionized gas throughout the GCL. Based on this analyses, strong evidence is found in support of the idea that the GCL is a true three-dimensional shell located in the GC region. Furthermore, an examination of the physical conditions of the GCL reveals that starburst outflows appear to be the most likely explanation for its origin, although other theories cannot be ruled out due to the observed pressure and star formation rate in the central tens of parsecs of our Galaxy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0114}
{"prompt": "Rephrase the abstract of an article with title 'Exclusive photoproduction of $J/\\psi$ in proton-proton and\n  proton-antiproton scattering'.\n  Protons and antiprotons at collider energies are a source of high energy\nWeizs\\\"acker--Williams photons. This may open a possibility to study exclusive\nphotoproduction of heavy vector mesons at energies much larger than possible at\nthe HERA accelerator. Here we present a detailed investigation of the exclusive\n$J/\\psi$ photoproduction in proton-proton (RHIC, LHC) and proton-antiproton\n(Tevatron) collisions. We calculate several differential distributions in $t_1,\nt_2, y, \\phi$, as well as transverse momentum distributions of $J/\\Psi$'s. We\ndiscuss correlations in the azimuthal angle between outgoing protons or proton\nand antiproton as well as in the ($t_1, t_2$) space. Differently from\nelectroproduction experiments, here both colliding beam particles can be a\nsource of photons, and we find large interference terms in azimuthal angle\ndistributions in a broad range of rapidities of the produced meson. We also\ninclude the spin--flip parts in the electromagnetic vertices. We discuss the\neffect of absorptive corrections on various distributions. Interestingly,\nabsorption corrections induce a charge asymmetry in rapidity distributions, and\nare larger for $p p$ reactions than for the $p \\bar p$ case. The reaction\nconsidered here constitutes an important nonreduceable background in recently\nproposed searches for odderon exchange.\n\n", "human_text": "  Protons and antiprotons at collider energies are a source of high energy\nWeizs\\\"acker--Williams photons. This may open a possibility to study exclusive\nphotoproduction of heavy vector mesons at energies much larger than possible at\nthe HERA accelerator. Here we present a detailed investigation of the exclusive\n$J/\\psi$ photoproduction in proton-proton (RHIC, LHC) and proton-antiproton\n(Tevatron) collisions. We calculate several differential distributions in $t_1,\nt_2, y, \\phi$, as well as transverse momentum distributions of $J/\\Psi$'s. We\ndiscuss correlations in the azimuthal angle between outgoing protons or proton\nand antiproton as well as in the ($t_1, t_2$) space. Differently from\nelectroproduction experiments, here both colliding beam particles can be a\nsource of photons, and we find large interference terms in azimuthal angle\ndistributions in a broad range of rapidities of the produced meson. We also\ninclude the spin--flip parts in the electromagnetic vertices. We discuss the\neffect of absorptive corrections on various distributions. Interestingly,\nabsorption corrections induce a charge asymmetry in rapidity distributions, and\nare larger for $p p$ reactions than for the $p \\bar p$ case. The reaction\nconsidered here constitutes an important nonreduceable background in recently\nproposed searches for odderon exchange.\n", "machine_text": "\nThe scattering of protons and antiprotons with high energies at a collider yields Weizs\\\"acker--Williams photons, offering an opportunity to explore exclusive photoproduction of heavy vector mesons in a regime that could not be accessed by the HERA accelerator. In this paper, we investigate exclusively the $J/\\psi$ photoproduction in proton-proton (RHIC, LHC) and proton-antiproton (Tevatron) collisions. Differential distributions in $t_1, t_2, y, \\phi$ as well as transverse momentum distributions of $J/\\Psi$ mesons have been computed and analyzed. What makes this different from electroproduction experiments is that this time both the beam particles can function as a source of photons. Thus, large interference terms emerge in the azimuthal angle distributions for a broad range of rapidities of the produced meson. Effects of absorptive corrections have been also taken into account, causing a charge asymmetry in rapidity distributions which is larger for proton-proton reactions compared to proton-antiproton processes. The findings of our research can be useful in the search for odderon exchange in experimental studies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2887}
{"prompt": "Rephrase the abstract of an article with title 'Double solid twistor spaces: the case of arbitrary signature'.\n  In a recent paper (math.DG/0701278) we constructed a series of new Moishezon\ntwistor spaces which is a kind of variant of the famous LeBrun twistor spaces.\nIn this paper we explicitly give projective models of another series of\nMoishezon twistor spaces on nCP^2 for arbitrary n>2, which can be regarded as a\ngeneralization of the twistor spaces of a 'double solid type' on 3CP^2 studied\nby Kreussler, Kurke, Poon and the author. Similarly to the twistor spaces of\n'double solid type' on 3CP^2, projective models of present twistor spaces have\na natural structure of double covering of a CP^2-bundle over CP^1. We\nexplicitly give a defining polynomial of the branch divisor of the double\ncovering whose restriction to fibers are degree four. If n>3 these are new\ntwistor spaces, to the best of the author's knowledge. We also compute the\ndimension of the moduli space of these twistor spaces. Differently from\nmath.DG/0701278, the present investigation is based on analysis of\npluri-(half-)anticanonical systems of the twistor spaces.\n\n", "human_text": "  In a recent paper (math.DG/0701278) we constructed a series of new Moishezon\ntwistor spaces which is a kind of variant of the famous LeBrun twistor spaces.\nIn this paper we explicitly give projective models of another series of\nMoishezon twistor spaces on nCP^2 for arbitrary n>2, which can be regarded as a\ngeneralization of the twistor spaces of a 'double solid type' on 3CP^2 studied\nby Kreussler, Kurke, Poon and the author. Similarly to the twistor spaces of\n'double solid type' on 3CP^2, projective models of present twistor spaces have\na natural structure of double covering of a CP^2-bundle over CP^1. We\nexplicitly give a defining polynomial of the branch divisor of the double\ncovering whose restriction to fibers are degree four. If n>3 these are new\ntwistor spaces, to the best of the author's knowledge. We also compute the\ndimension of the moduli space of these twistor spaces. Differently from\nmath.DG/0701278, the present investigation is based on analysis of\npluri-(half-)anticanonical systems of the twistor spaces.\n", "machine_text": "This paper introduces a new series of Moishezon twistor spaces on nCP^2, generalizing the twistor spaces of 'double solid type' on 3CP^2. We provide the projective model of the twistor spaces, giving concrete details on the defining polynomial of the branch divisor and the degree of restriction to fibers. If n > 3, these twistor spaces are new to the best of the author's knowledge. We also investigate the moduli space of these twistor spaces, analyzing the pluri-(half-)anticanonical systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.006}
{"prompt": "Rephrase the abstract of an article with title 'XMM-Newton observations of the first unidentified TeV gamma-ray source\n  TeV J2032+4130'.\n  (abridged) The first unidentified very high energy gamma ray source (TeV\nJ2032+4130) in the Cygnus region has been the subject of intensive search for a\ncounterpart source at other wavelengths. A deep ($\\approx 50$ ksec) exposure of\nTeV J2032+4130 with \\textit{XMM-Newton} has been obtained. The contribution of\npoint sources to the observed X-ray emission from TeV J2032+4130 is subtracted\nfrom the data. The point-source subtracted X-ray data are analyzed using blank\nsky exposures and regions adjacent to the position of TeV J2032+4130 in the\nfield of view covered by the XMM-Newton telescopes to search for diffuse X-ray\nemission. An extended X-ray emission region with a full width half maximum\n(FWHM) size of $\\approx 12$ arc min is found. The centroid of the emission is\nco-located with the position of TeV J2032+4130.The energy spectrum of the\nemission coinciding with the position and extension of TeV J2032+4130 can be\nmodeled by a power-law model with a photon index\n$\\Gamma=1.5\\pm0.2_\\mathrm{stat}\\pm0.3_\\mathrm{sys}$ and an energy flux\nintegrated between 2 and 10 keV of $f_{2-10 \\mathrm{keV}} \\approx 7\\cdot\n10^{-13}$ ergs/(cm$^2$ s) which is lower than the very high energy gamma-ray\nflux observed from TeV J2032+4130. We conclude that the faint extended X-ray\nemission discovered in this observation is the X-ray counterpart of TeV\nJ2032+4130. Formally, it can not be excluded that the extended emission is due\nto an unrelated population of faint, hot ($k_BT\\approx 10$ keV) unresolved\npoint-sources which by chance coincides with the position and extension of TeV\nJ2032+4130. We discuss our findings in the frame of both hadronic and leptonic\ngamma-ray production scenarios.\n\n", "human_text": "  (abridged) The first unidentified very high energy gamma ray source (TeV\nJ2032+4130) in the Cygnus region has been the subject of intensive search for a\ncounterpart source at other wavelengths. A deep ($\\approx 50$ ksec) exposure of\nTeV J2032+4130 with \\textit{XMM-Newton} has been obtained. The contribution of\npoint sources to the observed X-ray emission from TeV J2032+4130 is subtracted\nfrom the data. The point-source subtracted X-ray data are analyzed using blank\nsky exposures and regions adjacent to the position of TeV J2032+4130 in the\nfield of view covered by the XMM-Newton telescopes to search for diffuse X-ray\nemission. An extended X-ray emission region with a full width half maximum\n(FWHM) size of $\\approx 12$ arc min is found. The centroid of the emission is\nco-located with the position of TeV J2032+4130.The energy spectrum of the\nemission coinciding with the position and extension of TeV J2032+4130 can be\nmodeled by a power-law model with a photon index\n$\\Gamma=1.5\\pm0.2_\\mathrm{stat}\\pm0.3_\\mathrm{sys}$ and an energy flux\nintegrated between 2 and 10 keV of $f_{2-10 \\mathrm{keV}} \\approx 7\\cdot\n10^{-13}$ ergs/(cm$^2$ s) which is lower than the very high energy gamma-ray\nflux observed from TeV J2032+4130. We conclude that the faint extended X-ray\nemission discovered in this observation is the X-ray counterpart of TeV\nJ2032+4130. Formally, it can not be excluded that the extended emission is due\nto an unrelated population of faint, hot ($k_BT\\approx 10$ keV) unresolved\npoint-sources which by chance coincides with the position and extension of TeV\nJ2032+4130. We discuss our findings in the frame of both hadronic and leptonic\ngamma-ray production scenarios.\n", "machine_text": "\nAn intense XMM-Newton research of the first unidentified, very high energy gamma-ray source (TeV J2032+4130) in the Cygnus region has recently been conducted. Upon examination, the observed X-ray emission from the source had notable point source contributions subtracted. An extensive evaluation of the deminimised emission employing results from blank sky and context-dependent regions of the XMM-Newton's field of view revealed a full width half maximum (FWHM) of approximately 12 arc minutes. Its centroid aligned with TeV J2032+4130's coordinates, and it's energy spectrum portrayed a power-law model with a photon index of 1.5 +/- 0.2_stat +/- 0.3_sys, along with an integrated 2 to 10 keV energy flux at an approximate value of 7*10^-13 ergs/cm^2 s. This energy flux was significantly less than what had been observed in the gamma-ray flux from TeV J2032+4130. It has been assumed the extended X-ray emission presented is the counterpart of TeV J2032+4130, however it is possible it pertains to a related population of weak, hot (kT approximate 10 keV) unrevealed point sources that coincidentally aligns with the source and its extension. We evaluate these possible results in the frame of both hadronic and leptonic gamma-ray generation models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0009}
{"prompt": "Rephrase the abstract of an article with title 'GRMHD/RMHD Simulations and Stability of Magnetized Spine-Sheath\n  Relativistic Jets'.\n  A new general relativistic magnetohydrodynamics (GRMHD) code ``RAISHIN'' used\nto simulate jet generation by rotating and non-rotating black holes with a\ngeometrically thin Keplarian accretion disk finds that the jet develops a\nspine-sheath structure in the rotating black hole case. Spine-sheath structure\nand strong magnetic fields significantly modify the Kelvin-Helmholtz (KH)\nvelocity shear driven instability. The RAISHIN code has been used in its\nrelativistic magnetohydrodynamic (RMHD) configuration to study the effects of\nstrong magnetic fields and weakly relativistic sheath motion, c/2, on the KH\ninstability associated with a relativistic, Lorentz factor equal 2.5, jet\nspine-sheath interaction. In the simulations sound speeds up to c/1.7 and\nAlfven wave speeds up to 0.56 c are considered. Numerical simulation results\nare compared to theoretical predictions from a new normal mode analysis of the\nRMHD equations. Increased stability of a weakly magnetized system resulting\nfrom c/2 sheath speeds and stabilization of a strongly magnetized system\nresulting from c/2 sheath speeds is found.\n\n", "human_text": "  A new general relativistic magnetohydrodynamics (GRMHD) code ``RAISHIN'' used\nto simulate jet generation by rotating and non-rotating black holes with a\ngeometrically thin Keplarian accretion disk finds that the jet develops a\nspine-sheath structure in the rotating black hole case. Spine-sheath structure\nand strong magnetic fields significantly modify the Kelvin-Helmholtz (KH)\nvelocity shear driven instability. The RAISHIN code has been used in its\nrelativistic magnetohydrodynamic (RMHD) configuration to study the effects of\nstrong magnetic fields and weakly relativistic sheath motion, c/2, on the KH\ninstability associated with a relativistic, Lorentz factor equal 2.5, jet\nspine-sheath interaction. In the simulations sound speeds up to c/1.7 and\nAlfven wave speeds up to 0.56 c are considered. Numerical simulation results\nare compared to theoretical predictions from a new normal mode analysis of the\nRMHD equations. Increased stability of a weakly magnetized system resulting\nfrom c/2 sheath speeds and stabilization of a strongly magnetized system\nresulting from c/2 sheath speeds is found.\n", "machine_text": "\nThe RAISHIN code has been employed to examine the stability of relativistic jets with spine-sheath structures, using both general relativistic magnetohydrodynamics (GRMHD) and relativistic magnetohydrodynamic (RMHD) simulations. Results from these simulations show that strong magnetic fields and weakly relativistic sheath motion, c/2, impact the Kelvin-Helmholtz (KH) velocity shear driven instability associated with relativistic Lorentz factor equal 2.5 jet spine-sheath interactions. Different sound and Alfven wave speeds up to c/1.7 and 0.56 c, respectively, have been tested to evaluate the effect of increased stability of weakly magnetized systems as well as the stabilization of strongly magnetized ones. The comparison of numerical results to theoretical predictions formed through a novel normal mode analysis of the RMHD equations suggests that both c/2 sheath speeds result in increased stability of the system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1916}
{"prompt": "Rephrase the abstract of an article with title 'Y a-t-il \\'elimination d'Eupelmus orientalis Crawford par Eupelmus\n  vuilleti Crawford (Hymenoptera : Eupelmidae) des syst\\`emes de stockage du\n  ni\\'eb\\'e (Vigna unguiculata Walp) ?'.\n  Ni\\'eb\\'e is a food leguminous plant cultivated in tropical Africa for its\nseeds rich in proteins. The main problem setted by its production is the\nconservation of harvests. In the fields as in the stocks, the seeds are\ndestroyed by pests (bruchids). These bruchids are always associated with\nseveral entomophagous species of hymenoptera. Four entomophagous species were\nlisted : an egg parasitoid (U lariophaga Stephan), and three solitary larval\nand pupal ectoparasitoids (D. Basalis Rondoni, Pteromalidae; E. vuilleti\nCrawford and E. orientalis Crawford, Eupelmidae). The survey of the populations\nshows that at the beginning of storage, E orientalis is the most abundant\nspecie (72 %) whereas E. vuilleti and D. Basalis respectively represent 12 %\nand 16 % of the hymenoptera. During storage, the E orientalis population\ndecreases gradually and it disappears completely in less than two months after\nthe beginning of storage. E. Vuilleti population becomes gradually more\nimportant than D. basalis population which regress until less than 10 % of the\nemerging parasitoids. E vuilleti adopts ovicide and larvicide behaviour against\nD. Basalis. This behaviour explains its population regression inside granaries.\nIf the aggressive behaviour of this Eupelmidae is a constant, that could also\nexplain the disappearance of E orientalis. However if this species is\nmaintained in stocks, it would be an effective control agent of bruchids\naccording to their parasitic capacities. This study shows that ovicide and\nlarvicide behaviour of E vuilleti is not expressed against E orientalis. When\nthe females have exclusively the hosts already parasitized by E orientalis,\nthey do not lay eggs. The disappearance of E orientalis could not thus be\nexplained by the presence of E. vuilleti.\n\n", "human_text": "  Ni\\'eb\\'e is a food leguminous plant cultivated in tropical Africa for its\nseeds rich in proteins. The main problem setted by its production is the\nconservation of harvests. In the fields as in the stocks, the seeds are\ndestroyed by pests (bruchids). These bruchids are always associated with\nseveral entomophagous species of hymenoptera. Four entomophagous species were\nlisted : an egg parasitoid (U lariophaga Stephan), and three solitary larval\nand pupal ectoparasitoids (D. Basalis Rondoni, Pteromalidae; E. vuilleti\nCrawford and E. orientalis Crawford, Eupelmidae). The survey of the populations\nshows that at the beginning of storage, E orientalis is the most abundant\nspecie (72 %) whereas E. vuilleti and D. Basalis respectively represent 12 %\nand 16 % of the hymenoptera. During storage, the E orientalis population\ndecreases gradually and it disappears completely in less than two months after\nthe beginning of storage. E. Vuilleti population becomes gradually more\nimportant than D. basalis population which regress until less than 10 % of the\nemerging parasitoids. E vuilleti adopts ovicide and larvicide behaviour against\nD. Basalis. This behaviour explains its population regression inside granaries.\nIf the aggressive behaviour of this Eupelmidae is a constant, that could also\nexplain the disappearance of E orientalis. However if this species is\nmaintained in stocks, it would be an effective control agent of bruchids\naccording to their parasitic capacities. This study shows that ovicide and\nlarvicide behaviour of E vuilleti is not expressed against E orientalis. When\nthe females have exclusively the hosts already parasitized by E orientalis,\nthey do not lay eggs. The disappearance of E orientalis could not thus be\nexplained by the presence of E. vuilleti.\n", "machine_text": "\nThis study examines the possible elimination of Eupelmus orientalis Crawford by Eupelmus vuilleti Crawford (Hymenoptera : Eupelmidae) in the storage systems of Ni\\'eb\\'e (Vigna unguiculata Walp). Ni\\'eb\\'e is a food leguminous plant cultivated in tropical Africa for its high protein content. The primary issue regarding production is preservation of harvests, which are typically destroyed by pests (bruchids). Four entomophagous species were observed, one of which--- E. orientalis---was most abundant (72%) at the start of storage, followed by E. vuilleti (12%) and D. Basalis Rondoni, Pteromalidae (16%). Over the course of storage, the population of E. orientalis declined and eventually disappeared within two months. Compared to D. Basalis, the population of E. vuilleti grew and demonstrated ovicide and larvicide behaviours. It is possible that this behaviour is responsible for the decreased presence of E. orientalis. While this species could be a valuable control agent of bruchids, this study showed that E. vuilleti did not engage in ovicide and larvicide behaviour when finding exclusively E. orientalis host already parasitized. Therefore, the disappearance of E. orientalis could not be attributed to the presence of E. vuilleti.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.463}
{"prompt": "Rephrase the abstract of an article with title 'Analysis of a convenient information bound for general quantum channels'.\n  Open questions from Sarovar and Milburn (2006 J.Phys. A: Math. Gen. 39 8487)\nare answered. Sarovar and Milburn derived a convenient upper bound for the\nFisher information of a one-parameter quantum channel. They showed that for\nquasi-classical models their bound is achievable and they gave a necessary and\nsufficient condition for positive operator-valued measures (POVMs) attaining\nthis bound. They asked (i) whether their bound is attainable more generally,\n(ii) whether explicit expressions for optimal POVMs can be derived from the\nattainability condition. We show that the symmetric logarithmic derivative\n(SLD) quantum information is less than or equal to the SM bound, i.e.\\\n$H(\\theta) \\leq C_{\\Upsilon}(\\theta)$ and we find conditions for equality. As\nthe Fisher information is less than or equal to the SLD quantum information,\ni.e. $F_M(\\theta) \\leq H(\\theta)$, we can deduce when equality holds in\n$F_M(\\theta) \\leq C_{\\Upsilon}(\\theta)$. Equality does not hold for all\nchannels. As a consequence, the attainability condition cannot be used to test\nfor optimal POVMs for all channels. These results are extended to\nmulti-parameter channels.\n\n", "human_text": "  Open questions from Sarovar and Milburn (2006 J.Phys. A: Math. Gen. 39 8487)\nare answered. Sarovar and Milburn derived a convenient upper bound for the\nFisher information of a one-parameter quantum channel. They showed that for\nquasi-classical models their bound is achievable and they gave a necessary and\nsufficient condition for positive operator-valued measures (POVMs) attaining\nthis bound. They asked (i) whether their bound is attainable more generally,\n(ii) whether explicit expressions for optimal POVMs can be derived from the\nattainability condition. We show that the symmetric logarithmic derivative\n(SLD) quantum information is less than or equal to the SM bound, i.e.\\\n$H(\\theta) \\leq C_{\\Upsilon}(\\theta)$ and we find conditions for equality. As\nthe Fisher information is less than or equal to the SLD quantum information,\ni.e. $F_M(\\theta) \\leq H(\\theta)$, we can deduce when equality holds in\n$F_M(\\theta) \\leq C_{\\Upsilon}(\\theta)$. Equality does not hold for all\nchannels. As a consequence, the attainability condition cannot be used to test\nfor optimal POVMs for all channels. These results are extended to\nmulti-parameter channels.\n", "machine_text": "This article provides an analysis of the convenient information upper bound proposed by Sarovar and Milburn in 2006 for general quantum channels. It examines how the symmetric logarithmic derivative quantum information is bounded by this upper limit and gives conditions under which they are equal. It further explores how the Fisher information is affected by this upper bound and answers questions raised by Sarovar and Milburn regarding the attainability of this bound and the attainability of optimal POVMs. The results of this article are extended to multi-parameter channels.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0931}
{"prompt": "Rephrase the abstract of an article with title 'Hamiltonian and Brownian systems with long-range interactions: IV.\n  General kinetic equations from the quasilinear theory'.\n  We develop the kinetic theory of Hamiltonian systems with weak long-range\ninteractions. Starting from the Klimontovich equation and using a quasilinear\ntheory, we obtain a general kinetic equation that can be applied to spatially\ninhomogeneous systems and that takes into account memory effects. This equation\nis valid at order 1/N in a proper thermodynamic limit and it coincides with the\nkinetic equation obtained from the BBGKY hierarchy. For N tending to infinity,\nit reduces to the Vlasov equation describing collisionless systems. We describe\nthe process of phase mixing and violent relaxation leading to the formation of\na quasi stationary state (QSS) on the coarse-grained scale. We interprete the\nphysical nature of the QSS in relation to Lynden-Bell's statistical theory and\ndiscuss the problem of incomplete relaxation. In the second part of the paper,\nwe consider the relaxation of a test particle in a thermal bath. We derive a\nFokker-Planck equation by directly calculating the diffusion tensor and the\nfriction force from the Klimontovich equation. We give general expressions of\nthese quantities that are valid for possibly spatially inhomogeneous systems\nwith long correlation time. We show that the diffusion and friction terms have\na very similar structure given by a sort of generalized Kubo formula. We also\nobtain non-markovian kinetic equations that can be relevant when the\nauto-correlation function of the force decreases slowly with time. An interest\nof our approach is to develop a formalism that remains in physical space\n(instead of Fourier space) and that can deal with spatially inhomogeneous\nsystems.\n\n", "human_text": "  We develop the kinetic theory of Hamiltonian systems with weak long-range\ninteractions. Starting from the Klimontovich equation and using a quasilinear\ntheory, we obtain a general kinetic equation that can be applied to spatially\ninhomogeneous systems and that takes into account memory effects. This equation\nis valid at order 1/N in a proper thermodynamic limit and it coincides with the\nkinetic equation obtained from the BBGKY hierarchy. For N tending to infinity,\nit reduces to the Vlasov equation describing collisionless systems. We describe\nthe process of phase mixing and violent relaxation leading to the formation of\na quasi stationary state (QSS) on the coarse-grained scale. We interprete the\nphysical nature of the QSS in relation to Lynden-Bell's statistical theory and\ndiscuss the problem of incomplete relaxation. In the second part of the paper,\nwe consider the relaxation of a test particle in a thermal bath. We derive a\nFokker-Planck equation by directly calculating the diffusion tensor and the\nfriction force from the Klimontovich equation. We give general expressions of\nthese quantities that are valid for possibly spatially inhomogeneous systems\nwith long correlation time. We show that the diffusion and friction terms have\na very similar structure given by a sort of generalized Kubo formula. We also\nobtain non-markovian kinetic equations that can be relevant when the\nauto-correlation function of the force decreases slowly with time. An interest\nof our approach is to develop a formalism that remains in physical space\n(instead of Fourier space) and that can deal with spatially inhomogeneous\nsystems.\n", "machine_text": "\nWe present a study on the kinetic theory of Hamiltonian systems with long-range interactions, where we derive a kinetic equation from a quasilinear theory which allows us to calculate memory effects in inhomogeneous systems. In the thermodynamic limit with N tending toward infinity, this equation reduces to the Vlasov equation which describes collisionless systems. Through this, we analyze the phase mixing and violent relaxation leading to a quasi-stationary state (QSS). We further interpret the physical nature of the QSS in terms of Lynden-Bell's statistical theory, and discuss the incomplete relaxation problem. Additionally, we consider a test particle in a thermal bath, where we calculate the diffusion tensor and friction force, as well as derive a Fokker-Planck equation. Our approach yields a formalism that remains in physical space and is applicable to spatially inhomogeneous systems with long correlation time.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4579}
{"prompt": "Rephrase the abstract of an article with title 'The effect of the relative orientation between the coronal field and new\n  emerging flux: I Global Properties'.\n  The emergence of magnetic flux from the convection zone into the corona is an\nimportant process for the dynamical evolution of the coronal magnetic field. In\nthis paper we extend our previous numerical investigations, by looking at the\nprocess of flux interaction as an initially twisted flux tube emerges into a\nplane parallel, coronal magnetic field. Significant differences are found in\nthe dynamical appearance and evolution of the emergence process depending on\nthe relative orientation between the rising flux system and any preexisting\ncoronal field. When the flux systems are nearly anti-parallel, the experiments\nshow substantial reconnection and demonstrate clear signatures of a high\ntemperature plasma located in the high velocity outflow regions extending from\nthe reconnection region. However, the cases that have a more parallel\norientation of the flux systems show very limited reconnection and none of the\nassociated features. Despite the very different amount of reconnection between\nthe two flux systems, it is found that the emerging flux that is still\nconnected to the original tube, reaches the same height as a function of time.\nAs a compensation for the loss of tube flux, a clear difference is found in the\nextent of the emerging loop in the direction perpendicular to the main axis of\nthe initial flux tube. Increasing amounts of magnetic reconnection decrease the\nvolume, which confines the remaining tube flux.\n\n", "human_text": "  The emergence of magnetic flux from the convection zone into the corona is an\nimportant process for the dynamical evolution of the coronal magnetic field. In\nthis paper we extend our previous numerical investigations, by looking at the\nprocess of flux interaction as an initially twisted flux tube emerges into a\nplane parallel, coronal magnetic field. Significant differences are found in\nthe dynamical appearance and evolution of the emergence process depending on\nthe relative orientation between the rising flux system and any preexisting\ncoronal field. When the flux systems are nearly anti-parallel, the experiments\nshow substantial reconnection and demonstrate clear signatures of a high\ntemperature plasma located in the high velocity outflow regions extending from\nthe reconnection region. However, the cases that have a more parallel\norientation of the flux systems show very limited reconnection and none of the\nassociated features. Despite the very different amount of reconnection between\nthe two flux systems, it is found that the emerging flux that is still\nconnected to the original tube, reaches the same height as a function of time.\nAs a compensation for the loss of tube flux, a clear difference is found in the\nextent of the emerging loop in the direction perpendicular to the main axis of\nthe initial flux tube. Increasing amounts of magnetic reconnection decrease the\nvolume, which confines the remaining tube flux.\n", "machine_text": "\nIn this study, the effects of the interaction between a magnetic flux tube newly emerging from the convection zone and a previously existing coronal field were investigated. Different orientations of the magnetic flux systems yielded varied results in terms of the amount of reconnection, the associated temperature of the plasma and the height and volume of the emerging flux. The greater the amount of reconnection, the smaller the volume of the remaining tube flux, however the height of the flux, regardless of orientation and reconnection, was found to be the same. Results demonstrated substantial reconnection in the cases of anti-parallel orientations, accompanied by a high temperature plasma and fast velocities extending from the reconnection region. In contrast, when the orientation of the flux systems was more parallel, significantly less reconnection was observed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1097}
{"prompt": "Rephrase the abstract of an article with title 'Universal Quantile Estimation with Feedback in the\n  Communication-Constrained Setting'.\n  We consider the following problem of decentralized statistical inference:\ngiven i.i.d. samples from an unknown distribution, estimate an arbitrary\nquantile subject to limits on the number of bits exchanged. We analyze a\nstandard fusion-based architecture, in which each of $m$ sensors transmits a\nsingle bit to the fusion center, which in turn is permitted to send some number\n$k$ bits of feedback. Supposing that each of $\\nodenum$ sensors receives $n$\nobservations, the optimal centralized protocol yields mean-squared error\ndecaying as $\\order(1/[n m])$. We develop and analyze the performance of\nvarious decentralized protocols in comparison to this centralized\ngold-standard. First, we describe a decentralized protocol based on $k =\n\\log(\\nodenum)$ bits of feedback that is strongly consistent, and achieves the\nsame asymptotic MSE as the centralized optimum. Second, we describe and analyze\na decentralized protocol based on only a single bit ($k=1$) of feedback. For\nstep sizes independent of $m$, it achieves an asymptotic MSE of order\n$\\order[1/(n \\sqrt{m})]$, whereas for step sizes decaying as $1/\\sqrt{m}$, it\nachieves the same $\\order(1/[n m])$ decay in MSE as the centralized optimum.\nOur theoretical results are complemented by simulations, illustrating the\ntradeoffs between these different protocols.\n\n", "human_text": "  We consider the following problem of decentralized statistical inference:\ngiven i.i.d. samples from an unknown distribution, estimate an arbitrary\nquantile subject to limits on the number of bits exchanged. We analyze a\nstandard fusion-based architecture, in which each of $m$ sensors transmits a\nsingle bit to the fusion center, which in turn is permitted to send some number\n$k$ bits of feedback. Supposing that each of $\\nodenum$ sensors receives $n$\nobservations, the optimal centralized protocol yields mean-squared error\ndecaying as $\\order(1/[n m])$. We develop and analyze the performance of\nvarious decentralized protocols in comparison to this centralized\ngold-standard. First, we describe a decentralized protocol based on $k =\n\\log(\\nodenum)$ bits of feedback that is strongly consistent, and achieves the\nsame asymptotic MSE as the centralized optimum. Second, we describe and analyze\na decentralized protocol based on only a single bit ($k=1$) of feedback. For\nstep sizes independent of $m$, it achieves an asymptotic MSE of order\n$\\order[1/(n \\sqrt{m})]$, whereas for step sizes decaying as $1/\\sqrt{m}$, it\nachieves the same $\\order(1/[n m])$ decay in MSE as the centralized optimum.\nOur theoretical results are complemented by simulations, illustrating the\ntradeoffs between these different protocols.\n", "machine_text": "This article examines the problem of decentralized statistical inference, in which individual sensors must estimate an arbitrary quantile of an unknown distribution while exchanging a limited number of bits. A centralized approach approach, which yields the best possible mean-squared error decaying as $\\order(1/[n m])$, supposing that each of $\\nodenum$ sensors receive $n$ observations, is analyzed. To compare this performance, two decentralized protocols are developed. The first protocol uses $k = \\log(\\nodenum)$ bits of feedback, and is strongly consistent and attains the same asymptotic mean-squared error as the centralized optimum. The second protocol employs only one bit ($k=1$) of feedback. Depending upon the step size, it may achieve an asymptotic mean-squared error order of $\\order[1/(n \\sqrt{m})]$ or the same $\\order(1/[n m])$ decay in MSE as the optimal centralized protocol. Both theoretical results and simulations are presented to demonstrate the tradeoffs between the protocols.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.072}
{"prompt": "Rephrase the abstract of an article with title 'Near- and Far-Infrared Counterparts of Millimeter Dust Cores in the Vela\n  Molecular Ridge Cloud D'.\n  The aim of this paper is to identify the young protostellar counterparts\nassociated to dust millimeter cores of the Vela Molecular Ridge Cloud D through\nnew IR observations (H_2 narrow-band at 2.12 micron and N broad band at 10.4\nmicron) along with an investigation performed on the existing IR catalogues.\nThe association of mm continuum emission with infrared sources from catalogues\n(IRAS, MSX, 2MASS), JHK data from the literature and new observations, has been\nestablished according to spatial coincidence, infrared colours and spectral\nenergy distributions. Only 7 out of 29 resolved mm cores (and 16 out of the 26\nunresolved ones) do not exhibit signposts of star formation activity. The other\nones are clearly associated with: far-IR sources, H_2 jets or near-IR objects\nshowing a high intrinsic colour excess. The distribution of the spectral\nindices pertaining to the associated sources is peaked at values typical of\nClass I objects, while three objects are signalled as candidates Class 0\nsources. We remark the high detection rate (30%) of H_2 jets driven by sources\nlocated inside the mm-cores. They appear not driven by the most luminous\nobjects in the field, but rather by less luminous objects in young clusters,\ntestifying the co-existence of both low- and intermediate-mass star formation.\nThe presented results reliably describe the young population of VMR-D. However,\nthe statistical evaluation of activity vs inactivity of the investigated cores,\neven in good agreement with results found for other star forming regions, seems\nto reflect the limiting sensitivity of the available facilities rather than any\nproperty intrinsic to the mm-condensations.\n\n", "human_text": "  The aim of this paper is to identify the young protostellar counterparts\nassociated to dust millimeter cores of the Vela Molecular Ridge Cloud D through\nnew IR observations (H_2 narrow-band at 2.12 micron and N broad band at 10.4\nmicron) along with an investigation performed on the existing IR catalogues.\nThe association of mm continuum emission with infrared sources from catalogues\n(IRAS, MSX, 2MASS), JHK data from the literature and new observations, has been\nestablished according to spatial coincidence, infrared colours and spectral\nenergy distributions. Only 7 out of 29 resolved mm cores (and 16 out of the 26\nunresolved ones) do not exhibit signposts of star formation activity. The other\nones are clearly associated with: far-IR sources, H_2 jets or near-IR objects\nshowing a high intrinsic colour excess. The distribution of the spectral\nindices pertaining to the associated sources is peaked at values typical of\nClass I objects, while three objects are signalled as candidates Class 0\nsources. We remark the high detection rate (30%) of H_2 jets driven by sources\nlocated inside the mm-cores. They appear not driven by the most luminous\nobjects in the field, but rather by less luminous objects in young clusters,\ntestifying the co-existence of both low- and intermediate-mass star formation.\nThe presented results reliably describe the young population of VMR-D. However,\nthe statistical evaluation of activity vs inactivity of the investigated cores,\neven in good agreement with results found for other star forming regions, seems\nto reflect the limiting sensitivity of the available facilities rather than any\nproperty intrinsic to the mm-condensations.\n", "machine_text": "This article investigates the association of near- and far-infrared counterparts of millimeter dust cores in the Vela Molecular Ridge Cloud D. Using IR observations (specifically H_2 narrow-band at 2.12 micron and N broad band at 10.4 micron, as well as existing IR catalogues such as IRAS, MSX, and 2MASS), JHK data from the literature, and new observations, the authors calculated the spatial coincidence, infrared colors, and spectral energy distributions to determine the associated sources. Out of 29 resolved dust cores, only 7 showed no signs of star formation activity, while the other ones were associated with far-IR sources, H_2 jets, or near-IR objects that showed a high intrinsic color excess. The spectral indices peaked at values typical of Class I objects, and 3 objects were identified as potential Class 0 sources. The analysis showed a high detection rate (30%) of H_2 jets driven by sources located inside them mm-cores, suggesting the presence of both low- and intermediate-mass star formation. However, it was noted that the rate of activity vs. inactivity of the cores might be biased by the sensitivity of the observed data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1228}
{"prompt": "Rephrase the abstract of an article with title 'Nonlinear Perturbations and Conservation Laws on Curved Backgrounds in\n  GR and Other Metric Theories'.\n  The field-theoretical approach is reviewed. Perturbations in general\nrelativity as well as in an arbitrary $D$-dimensional metric theory are studied\non a background, which is a solution (arbitrary) of the theory. Lagrangian for\nperturbations is defined, and field equations for perturbations are derived\nfrom the variational principle. These equations are exact and equivalent to the\nequations in the standard formulation, but can be approximate also. The\nfield-theoretical description is invariant under gauge (inner) transformations,\nwhich can be presented both in exact and approximate forms. Following the usual\nfield-theoretical prescription, conserved quantities for perturbations are\nconstructed. Conserved currents are expressed through divergences of\nsuperpotentials -- antisymmetric tensor densities. This form allows to relate a\nnecessity to consider local properties of perturbations with a theoretical\nrepresentation of the quasi-local nature of conserved quantities in metric\ntheories. Applications of the formalism in general relativity are discussed.\nGeneralized formulae for an arbitrary metric $D$-dimensional theory are tested\nin the Einstein-Gauss-Bonnet gravity.\n\n", "human_text": "  The field-theoretical approach is reviewed. Perturbations in general\nrelativity as well as in an arbitrary $D$-dimensional metric theory are studied\non a background, which is a solution (arbitrary) of the theory. Lagrangian for\nperturbations is defined, and field equations for perturbations are derived\nfrom the variational principle. These equations are exact and equivalent to the\nequations in the standard formulation, but can be approximate also. The\nfield-theoretical description is invariant under gauge (inner) transformations,\nwhich can be presented both in exact and approximate forms. Following the usual\nfield-theoretical prescription, conserved quantities for perturbations are\nconstructed. Conserved currents are expressed through divergences of\nsuperpotentials -- antisymmetric tensor densities. This form allows to relate a\nnecessity to consider local properties of perturbations with a theoretical\nrepresentation of the quasi-local nature of conserved quantities in metric\ntheories. Applications of the formalism in general relativity are discussed.\nGeneralized formulae for an arbitrary metric $D$-dimensional theory are tested\nin the Einstein-Gauss-Bonnet gravity.\n", "machine_text": "This paper presents a field-theoretic approach to study nonlinear perturbations on background solutions of both generic $D$-dimensional metric theories and general relativity. Perturbations are described by a Lagrangian, obtained from a variational principle, yielding field equations which can be used both in exact and approximate forms. Invariance under gauge transformations is maintained throughout, with particular attention to its exact and approximate representations. Importantly, conserved quantities (expressed as divergences of superpotentials) are constructed, elucidating the theoretical idea of perturbation conservation as a quasi-local nature in metric theories. The formalism is corroborated in general relativity and tested in Einstein-Gauss-Bonnet gravity.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0019}
{"prompt": "Rephrase the abstract of an article with title 'Measuring Dark Energy with Gamma-Ray Bursts and Other Cosmological\n  Probes'.\n  It has been widely shown that the cosmological parameters and dark energy can\nbe constrained by using data from type-Ia supernovae (SNe Ia), the cosmic\nmicrowave background (CMB) anisotropy, the baryon acoustic oscillation (BAO)\npeak from Sloan Digital Sky Survey (SDSS), the X-ray gas mass fraction in\nclusters, and the linear growth rate of perturbations at z=0.15 as obtained\nfrom the 2dF Galaxy Redshift Survey. Recently, gamma-ray bursts (GRBs) have\nalso been argued to be promising standard candles for cosmography. In this\npaper, we present constraints on the cosmological parameters and dark energy by\ncombining a recent GRB sample including 69 events with the other cosmological\nprobes. First, we find that for the LambdaCDM cosmology this combination makes\nthe constraints stringent and the best fit is close to the flat universe.\nSecond, we fit the flat Cardassian expansion model and find that this model is\nconsistent with the LambdaCDM cosmology. Third, we present constraints on\nseveral two-parameter dark energy models and find that these models are also\nconsistent with the LambdaCDM cosmology. Finally, we reconstruct the dark\nenergy equation-of-state parameter w(z) and the deceleration parameter q(z). We\nsee that the acceleration could have started at a redshift from\nz_T=0.40_{-0.08}^{+0.14} to z_T=0.65_{-0.05}^{+0.10}. This difference in the\ntransition redshift is due to different dark energy models that we adopt. The\nmost stringent constraint on w(z) lies in the redshift range z\\sim 0.3-0.6.\n\n", "human_text": "  It has been widely shown that the cosmological parameters and dark energy can\nbe constrained by using data from type-Ia supernovae (SNe Ia), the cosmic\nmicrowave background (CMB) anisotropy, the baryon acoustic oscillation (BAO)\npeak from Sloan Digital Sky Survey (SDSS), the X-ray gas mass fraction in\nclusters, and the linear growth rate of perturbations at z=0.15 as obtained\nfrom the 2dF Galaxy Redshift Survey. Recently, gamma-ray bursts (GRBs) have\nalso been argued to be promising standard candles for cosmography. In this\npaper, we present constraints on the cosmological parameters and dark energy by\ncombining a recent GRB sample including 69 events with the other cosmological\nprobes. First, we find that for the LambdaCDM cosmology this combination makes\nthe constraints stringent and the best fit is close to the flat universe.\nSecond, we fit the flat Cardassian expansion model and find that this model is\nconsistent with the LambdaCDM cosmology. Third, we present constraints on\nseveral two-parameter dark energy models and find that these models are also\nconsistent with the LambdaCDM cosmology. Finally, we reconstruct the dark\nenergy equation-of-state parameter w(z) and the deceleration parameter q(z). We\nsee that the acceleration could have started at a redshift from\nz_T=0.40_{-0.08}^{+0.14} to z_T=0.65_{-0.05}^{+0.10}. This difference in the\ntransition redshift is due to different dark energy models that we adopt. The\nmost stringent constraint on w(z) lies in the redshift range z\\sim 0.3-0.6.\n", "machine_text": "\nThis article investigates the possibility of constraining cosmological parameters and dark energy by looking at a combination of a sample of recent gamma-ray bursts, type-Ia supernovae, cosmic microwave background anisotropy, baryon acoustic oscillation peak, X-ray gas mass fraction, and the linear growth rate of perturbations. After an analysis of the data obtained, consistency with the LambdaCDM cosmology was found in all of the two-parameter dark energy models presented. Additionally, the reconstructions of the dark energy equation-of-state and the deceleration parameter showed that the acceleration of the universe could have started in a redshift between 0.4 and 0.65. The most stringent constraint on w(z) lies in the redshift range z\u223c0.3\u20130.6.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0938}
{"prompt": "Rephrase the abstract of an article with title 'Nonholonomic Ricci Flows: III. Curve Flows and Solitonic Hierarchies'.\n  The geometric constructions are elaborated on (semi) Riemannian manifolds and\nvector bundles provided with nonintegrable distributions defining nonlinear\nconnection structures induced canonically by metric tensors. Such spaces are\ncalled nonholonomic manifolds and described by two equivalent linear\nconnections also induced in unique forms by a metric tensor (the Levi Civita\nand the canonical distinguished connection, d-connection). The lifts of\ngeometric objects on tangent bundles are performed for certain classes of\nd-connections and frame transforms when the Riemann tensor is parametrized by\nconstant matrix coefficients. For such configurations, the flows of\nnon-stretching curves and corresponding bi-Hamilton and solitonic hierarchies\nencode information about Ricci flow evolution, Einstein spaces and exact\nsolutions in gravity and geometric mechanics. The applied methods were\nelaborated formally in Finsler geometry and allows us to develop the formalism\nfor generalized Riemann-Finsler and Lagrange spaces. Nevertheless, all\ngeometric constructions can be equivalently re-defined for the Levi Civita\nconnections and holonomic frames on (semi) Riemannian manifolds.\n\n", "human_text": "  The geometric constructions are elaborated on (semi) Riemannian manifolds and\nvector bundles provided with nonintegrable distributions defining nonlinear\nconnection structures induced canonically by metric tensors. Such spaces are\ncalled nonholonomic manifolds and described by two equivalent linear\nconnections also induced in unique forms by a metric tensor (the Levi Civita\nand the canonical distinguished connection, d-connection). The lifts of\ngeometric objects on tangent bundles are performed for certain classes of\nd-connections and frame transforms when the Riemann tensor is parametrized by\nconstant matrix coefficients. For such configurations, the flows of\nnon-stretching curves and corresponding bi-Hamilton and solitonic hierarchies\nencode information about Ricci flow evolution, Einstein spaces and exact\nsolutions in gravity and geometric mechanics. The applied methods were\nelaborated formally in Finsler geometry and allows us to develop the formalism\nfor generalized Riemann-Finsler and Lagrange spaces. Nevertheless, all\ngeometric constructions can be equivalently re-defined for the Levi Civita\nconnections and holonomic frames on (semi) Riemannian manifolds.\n", "machine_text": "This article explores the properties of nonholonomic Ricci flows, including the flows of curves, Hamiltonian hierarchies and solitonic hierarchies. Connecting these flows to a range of geometrical objects, such as the Levi-Civita connection, the canonical distinguished connection, and the Riemann tensor, this article provides a discussion on how to paramatrize these objects by constant matrix coefficients. Additionally, the article explains how the formalism of Finsler geometry can be used to develop generalized Riemann-Finsler and Lagrange spaces. Although these constructions were initially developed on semi-Riemannian manifolds and vector bundles with nonintegrable distributions, they can be equivalently restated for holonomic frames and Levi-Civita connections on (semi) Riemannian manifolds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2062}
{"prompt": "Rephrase the abstract of an article with title 'Dynamic Screening in a Two-Species Asymmetric Exclusion Process'.\n  The dynamic scaling properties of the one dimensional Burgers equation are\nexpected to change with the inclusion of additional conserved degrees of\nfreedom. We study this by means of 1-D driven lattice gas models that conserve\nboth mass and momentum. The most elementary version of this is the\nArndt-Heinzel-Rittenberg (AHR) process, which is usually presented as a two\nspecies diffusion process, with particles of opposite charge hopping in\nopposite directions and with a variable passing probability.\n  From the hydrodynamics perspective this can be viewed as two coupled Burgers\nequations, with the number of positive and negative momentum quanta\nindividually conserved. We determine the dynamic scaling dimension of the AHR\nprocess from the time evolution of the two-point correlation functions, and\nfind numerically that the dynamic critical exponent is consistent with simple\nKardar-Parisi-Zhang (KPZ) type scaling. We establish that this is the result of\nperfect screening of fluctuations in the stationary state. The two-point\ncorrelations decay exponentially in our simulations and in such a manner that\nin terms of quasi-particles, fluctuations fully screen each other at coarse\ngrained length scales. We prove this screening rigorously using the analytic\nmatrix product structure of the stationary state. The proof suggests the\nexistence of a topological invariant. The process remains in the KPZ\nuniversality class but only in the sense of a factorization, as $({KPZ})^2$.\nThe two Burgers equations decouple at large length scales due to the perfect\nscreening.\n\n", "human_text": "  The dynamic scaling properties of the one dimensional Burgers equation are\nexpected to change with the inclusion of additional conserved degrees of\nfreedom. We study this by means of 1-D driven lattice gas models that conserve\nboth mass and momentum. The most elementary version of this is the\nArndt-Heinzel-Rittenberg (AHR) process, which is usually presented as a two\nspecies diffusion process, with particles of opposite charge hopping in\nopposite directions and with a variable passing probability.\n  From the hydrodynamics perspective this can be viewed as two coupled Burgers\nequations, with the number of positive and negative momentum quanta\nindividually conserved. We determine the dynamic scaling dimension of the AHR\nprocess from the time evolution of the two-point correlation functions, and\nfind numerically that the dynamic critical exponent is consistent with simple\nKardar-Parisi-Zhang (KPZ) type scaling. We establish that this is the result of\nperfect screening of fluctuations in the stationary state. The two-point\ncorrelations decay exponentially in our simulations and in such a manner that\nin terms of quasi-particles, fluctuations fully screen each other at coarse\ngrained length scales. We prove this screening rigorously using the analytic\nmatrix product structure of the stationary state. The proof suggests the\nexistence of a topological invariant. The process remains in the KPZ\nuniversality class but only in the sense of a factorization, as $({KPZ})^2$.\nThe two Burgers equations decouple at large length scales due to the perfect\nscreening.\n", "machine_text": "\nIn this article, we analyze the dynamic scaling properties of a one-dimensional Burgers equation with the addition of conserved degrees of freedom. We achieve this by implementing lattice gas models that maintain number conservation of momentum quanta of both positive and negative charges. Taking the Arndt-Heinzel-Rittenberg (AHR) process as the base model, we discover that it follows a Kardar-Parisi-Zhang (KPZ) type scaling, as seen through its two-part correlation functions in time. We also prove that this scaling is a result of perfect screening of fluctuation in the stationary state, where two-part correlations evidently decrease exponentially on a coarse-grained scale. A proof of this phenomenon is presented with the help of a matrix product structure of the stationary state, which also suggests the presence of a topological invariant. In accordance to the KPZ type scaling, the two Burgers equations decouple from each other upon perfect screening at large length scales.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1377}
{"prompt": "Rephrase the abstract of an article with title 'Accretion vs colliding wind models for the gamma-ray binary LS I +61\n  303: an assessment'.\n  LS I +61 303 is a puzzling Be/X-ray binary with variable gamma-ray emission\nat up TeV energies. The nature of the compact object and the origin of the\nhigh-energy emission are unclear. One family of models invokes particle\nacceleration in shocks from the collision between the B-star wind and a\nrelativistic pulsar wind, while another centers on a relativistic jet powered\nby accretion. Recent high-resolution radio observations showing a putative\n\"cometary tail\" pointing away from the Be star near periastron have been cited\nas support for the pulsar-wind model. We wish here to carry out a quantitative\nassessment of these competing models for this extraordinary source. We apply a\n3D SPH code for dynamical simulations of both the pulsar-wind-interaction and\naccretion-jet models. The former yields a description of the shape of the\nwind-wind interaction surface. The latter provides an estimation of the\naccretion rate. The results allow critical evaluation of how the two distinct\nmodels confront the data in various wavebands under a range of conditions. When\none accounts for the 3D dynamical wind interaction under realistic constraints\nfor the relative strength of the B-star and pulsar winds, the resulting form of\nthe interaction front does not match the putative \"cometary tail\" claimed from\nradio observations. On the other hand, dynamical simulations of the\naccretion-jet model indicate that the orbital phase variation of accretion\npower includes a secondary broad peak well away from periastron, thus providing\na plausible way to explain the observed TeV gamma ray emission toward apastron.\nWe conclude that the colliding-wind model is not clearly established for LS I\n+61 303, while the accretion-jet model can reproduce many key characteristics\nof the observed TeV gamma-ray emission.\n\n", "human_text": "  LS I +61 303 is a puzzling Be/X-ray binary with variable gamma-ray emission\nat up TeV energies. The nature of the compact object and the origin of the\nhigh-energy emission are unclear. One family of models invokes particle\nacceleration in shocks from the collision between the B-star wind and a\nrelativistic pulsar wind, while another centers on a relativistic jet powered\nby accretion. Recent high-resolution radio observations showing a putative\n\"cometary tail\" pointing away from the Be star near periastron have been cited\nas support for the pulsar-wind model. We wish here to carry out a quantitative\nassessment of these competing models for this extraordinary source. We apply a\n3D SPH code for dynamical simulations of both the pulsar-wind-interaction and\naccretion-jet models. The former yields a description of the shape of the\nwind-wind interaction surface. The latter provides an estimation of the\naccretion rate. The results allow critical evaluation of how the two distinct\nmodels confront the data in various wavebands under a range of conditions. When\none accounts for the 3D dynamical wind interaction under realistic constraints\nfor the relative strength of the B-star and pulsar winds, the resulting form of\nthe interaction front does not match the putative \"cometary tail\" claimed from\nradio observations. On the other hand, dynamical simulations of the\naccretion-jet model indicate that the orbital phase variation of accretion\npower includes a secondary broad peak well away from periastron, thus providing\na plausible way to explain the observed TeV gamma ray emission toward apastron.\nWe conclude that the colliding-wind model is not clearly established for LS I\n+61 303, while the accretion-jet model can reproduce many key characteristics\nof the observed TeV gamma-ray emission.\n", "machine_text": "\nThis study assesses two distinct models for the extraordinary gamma-ray binary LS I +61 303: those invoking particle acceleration in a wind collision between the B-star wind and a relativistic pulsar wind, and those centering on a relativistic jet powered by accretion. A 3D SPH code provides dynamical simulations corresponding to both of these models which can be used to evaluate how the models compare with the data from observations of the source in various wavebands. Results indicate that while the wind interaction front predicted by the pulsar-wind model does not match the putative \"cometary tail\" reported in radio observations, the accretion-jet model proposes a plausible explanation for the observed TeV gamma-ray emission towards apastron. Ultimately, the study suggests that the colliding-wind model is not established for LS I +61 303, while the accretion-jet model effectively reproduces the observed gamma-ray emission.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.132}
{"prompt": "Rephrase the abstract of an article with title 'Calibration of the GLAST Burst Monitor detectors'.\n  The GLAST Burst Monitor (GBM) will augment the capabilities of GLAST for the\ndetection of cosmic gamma-ray bursts by extending the energy range (20 MeV to >\n300 GeV) of the Large Area Telescope (LAT) towards lower energies by 2\nBGO-detectors (150 keV to 30 MeV) and 12 NaI(Tl) detectors (10 keV to 1 MeV).\nThe physical detector response of the GBM instrument for GRBs is determined\nwith the help of Monte Carlo simulations, which are supported and verified by\non-ground calibration measurements, performed extensively with the individual\ndetectors at the MPE in 2005. All flight and spare detectors were irradiated\nwith calibrated radioactive sources in the laboratory (from 14 keV to 4.43\nMeV). The energy/channel-relations, the dependences of energy resolution and\neffective areas on the energy and the angular responses were measured. Due to\nthe low number of emission lines of radioactive sources below 100 keV,\ncalibration measurements in the energy range from 10 keV to 60 keV were\nperformed with the X-ray radiometry working group of the\nPhysikalisch-Technische Bundesanstalt (PTB) at the BESSY synchrotron radiation\nfacility, Berlin.\n\n", "human_text": "  The GLAST Burst Monitor (GBM) will augment the capabilities of GLAST for the\ndetection of cosmic gamma-ray bursts by extending the energy range (20 MeV to >\n300 GeV) of the Large Area Telescope (LAT) towards lower energies by 2\nBGO-detectors (150 keV to 30 MeV) and 12 NaI(Tl) detectors (10 keV to 1 MeV).\nThe physical detector response of the GBM instrument for GRBs is determined\nwith the help of Monte Carlo simulations, which are supported and verified by\non-ground calibration measurements, performed extensively with the individual\ndetectors at the MPE in 2005. All flight and spare detectors were irradiated\nwith calibrated radioactive sources in the laboratory (from 14 keV to 4.43\nMeV). The energy/channel-relations, the dependences of energy resolution and\neffective areas on the energy and the angular responses were measured. Due to\nthe low number of emission lines of radioactive sources below 100 keV,\ncalibration measurements in the energy range from 10 keV to 60 keV were\nperformed with the X-ray radiometry working group of the\nPhysikalisch-Technische Bundesanstalt (PTB) at the BESSY synchrotron radiation\nfacility, Berlin.\n", "machine_text": "\nThis article considers the necessary calibration of the detectors for the GLAST Burst Monitor (GBM) instrument in order to maximize its detection effectiveness in detecting cosmic gamma-ray bursts. Monte Carlo simulations are employed to ensure the physical detector response is accurate and are supported by extensive laboratory testing with each individual detector. Radioactive sources were used to get the energy/channel-relations, energy resolution, effective area dependence on energy and angular responses. As certain radioactive sources do not emit enough lines below 100 keV, testing with X-ray radiometry from the Physikalisch-Technische Bundesanstalt (PTB) was performed at the BESSY synchrotron radiation facility in Berlin to cover this range.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2184}
{"prompt": "Rephrase the abstract of an article with title 'Generalized Brjuno functions associated to $\\alpha$-continued fractions'.\n  For \\alpha in the interval [0,1], we consider the one-parameter family of\n\\alpha-continued fraction maps, which include the Gauss map (\\alpha=1) and the\nnearest integer (\\alpha=1/2) and by-excess (\\alpha=0) continued fraction maps.\nTo each of these expansions, and to each choice of a positive function u on the\ninterval I_\\alpha=(0,max(\\alpha,1-\\alpha)) we associate a generalized Brjuno\nfunction B_(\\alpha,u)(x). For \\alpha=1/2 or \\alpha=1, and u(x)=-\\log(x), these\nfunctions were introduced by Yoccoz in his work on the linearization of\nholomorphic maps. Their regularity properties, including BMO regularity and\ntheir extension to the complex plane, have been thoroughly investigated. We\ncompare the functions obtained with different values of \\alpha and we prove\nthat the set of (\\alpha,u)-Brjuno numbers does not depend on the choice of\n\\alpha provided that \\alpha>0. We then consider the case \\alpha=0,\nu(x)=-\\log(x) and we prove that x is a Brjuno number (for \\alpha> 0) if and\nonly if both x and -x are Brjuno numbers for \\alpha=0.\n\n", "human_text": "  For \\alpha in the interval [0,1], we consider the one-parameter family of\n\\alpha-continued fraction maps, which include the Gauss map (\\alpha=1) and the\nnearest integer (\\alpha=1/2) and by-excess (\\alpha=0) continued fraction maps.\nTo each of these expansions, and to each choice of a positive function u on the\ninterval I_\\alpha=(0,max(\\alpha,1-\\alpha)) we associate a generalized Brjuno\nfunction B_(\\alpha,u)(x). For \\alpha=1/2 or \\alpha=1, and u(x)=-\\log(x), these\nfunctions were introduced by Yoccoz in his work on the linearization of\nholomorphic maps. Their regularity properties, including BMO regularity and\ntheir extension to the complex plane, have been thoroughly investigated. We\ncompare the functions obtained with different values of \\alpha and we prove\nthat the set of (\\alpha,u)-Brjuno numbers does not depend on the choice of\n\\alpha provided that \\alpha>0. We then consider the case \\alpha=0,\nu(x)=-\\log(x) and we prove that x is a Brjuno number (for \\alpha> 0) if and\nonly if both x and -x are Brjuno numbers for \\alpha=0.\n", "machine_text": " In this paper, we investigate the family of generalized Brjuno functions associated to \\alpha-continued fractions for \\alpha in the interval [0,1]. This includes the Gauss map (\\alpha=1), the nearest integer (\\alpha=1/2) and the fraction-by-excess (\\alpha=0) continued fraction maps. We associate to each of these expansions a positive function u on the interval I_\\alpha   and construct their corresponding generalized Brjuno functions B_(\u03b1,u)(x). We compare the functions obtained with different values of \\alpha and prove that the set of (\u03b1,u)-Brjuno numbers does not depend on the choice of \\alpha as long as \u03b1>0. We also consider the case when \u2500\u03b1=0, u(x)=-log(x) and prove that x is a Brjuno number (for \\alpha> 0) if and only if x and -x are both Brjuno numbers for \\alpha=0. The regularity properties of these generalized Brjuno functions, including BMO regularity and their extension to the complex plane are also discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.169}
{"prompt": "Rephrase the abstract of an article with title 'Compton Scattering of Fe K alpha Lines in Magnetic Cataclysmic Variables'.\n  Compton scattering of X-rays in the bulk flow of the accretion column in\nmagnetic cataclysmic variables (mCVs) can significantly shift photon energies.\nWe present Monte Carlo simulations based on a nonlinear algorithm demonstrating\nthe effects of Compton scattering on the H-like, He-like and neutral Fe K alpha\nlines produced in the post-shock region of the accretion column. The peak line\nemissivities of the photons in the post-shock flow are taken into consideration\nand frequency shifts due to Doppler effects are also included. We find that\nline profiles are most distorted by Compton scattering effects in strongly\nmagnetized mCVs with a low white dwarf mass and high mass accretion rate and\nwhich are viewed at an oblique angle with respect to the accretion column. The\nresulting line profiles are most sensitive to the inclination angle. We have\nalso explored the effects of modifying the accretion column width and using a\nrealistic emissivity profile. We find that these do not have a significant\noverall effect on the resulting line profiles. A comparison of our simulated\nline spectra with high resolution Chandra/HETGS observations of the mCV GK Per\nindicates that a wing feature redward of the 6.4 keV line may result from\nCompton recoil near the base of the accretion column.\n\n", "human_text": "  Compton scattering of X-rays in the bulk flow of the accretion column in\nmagnetic cataclysmic variables (mCVs) can significantly shift photon energies.\nWe present Monte Carlo simulations based on a nonlinear algorithm demonstrating\nthe effects of Compton scattering on the H-like, He-like and neutral Fe K alpha\nlines produced in the post-shock region of the accretion column. The peak line\nemissivities of the photons in the post-shock flow are taken into consideration\nand frequency shifts due to Doppler effects are also included. We find that\nline profiles are most distorted by Compton scattering effects in strongly\nmagnetized mCVs with a low white dwarf mass and high mass accretion rate and\nwhich are viewed at an oblique angle with respect to the accretion column. The\nresulting line profiles are most sensitive to the inclination angle. We have\nalso explored the effects of modifying the accretion column width and using a\nrealistic emissivity profile. We find that these do not have a significant\noverall effect on the resulting line profiles. A comparison of our simulated\nline spectra with high resolution Chandra/HETGS observations of the mCV GK Per\nindicates that a wing feature redward of the 6.4 keV line may result from\nCompton recoil near the base of the accretion column.\n", "machine_text": "\nBy running a Monte Carlo simulation based on a nonlinear algorithm, we explore the impact of Compton scattering on the H-like, He-like and neutral Fe K alpha lines produced in the post-shock region of the accretion column of magnetic cataclysmic variables (mCVs). The peak line emissivities and frequency shifts due to Doppler effects are taken into account. The results reveal that line profiles are most notably distorted in mCVs that possess a low white dwarf mass, a high mass accretion rate, andare observed at an inclination angle. This distortion is not significantly altered by changes in the column width or the emissivity profile. Our simulations have been compared to Chandra/HETGS observations of GK Per, suggesting that a wing feature redward of the 6.4 keV line likely originates from Compton recoil close to the bottom of the accretion column.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1516}
{"prompt": "Rephrase the abstract of an article with title 'Analytic approach to the thermal Casimir force between metal and\n  dielectric'.\n  The analytic asymptotic expressions for the Casimir free energy, pressure and\nentropy at low temperature in the configuration of one metal and one dielectric\nplate are obtained. For this purpose we develop the perturbation theory in a\nsmall parameter proportional to the product of the separation between the\nplates and the temperature. This is done using both the simplified model of an\nideal metal and of a dielectric with constant dielectric permittivity and for\nthe realistic case of the metal and dielectric with frequency-dependent\ndielectric permittivities. The analytic expressions for all related physical\nquantities at high temperature are also provided. The obtained analytic results\nare compared with numerical computations and good agreement is found. We\ndemonstrate for the first time that the Lifshitz theory, when applied to the\nconfiguration of metal-dielectric, satisfies the requirements of thermodynamics\nif the static dielectric permittivity of a dielectric plate is finite. If it is\ninfinitely large, the Lifshitz formula is shown to violate the Nernst heat\ntheorem. The implications of these results for the thermal quantum field theory\nin Matsubara formulation and for the recent measurements of the Casimir force\nbetween metal and semiconductor surfaces are discussed.\n\n", "human_text": "  The analytic asymptotic expressions for the Casimir free energy, pressure and\nentropy at low temperature in the configuration of one metal and one dielectric\nplate are obtained. For this purpose we develop the perturbation theory in a\nsmall parameter proportional to the product of the separation between the\nplates and the temperature. This is done using both the simplified model of an\nideal metal and of a dielectric with constant dielectric permittivity and for\nthe realistic case of the metal and dielectric with frequency-dependent\ndielectric permittivities. The analytic expressions for all related physical\nquantities at high temperature are also provided. The obtained analytic results\nare compared with numerical computations and good agreement is found. We\ndemonstrate for the first time that the Lifshitz theory, when applied to the\nconfiguration of metal-dielectric, satisfies the requirements of thermodynamics\nif the static dielectric permittivity of a dielectric plate is finite. If it is\ninfinitely large, the Lifshitz formula is shown to violate the Nernst heat\ntheorem. The implications of these results for the thermal quantum field theory\nin Matsubara formulation and for the recent measurements of the Casimir force\nbetween metal and semiconductor surfaces are discussed.\n", "machine_text": "\nWithin this article, a study is conducted to obtain analytic asymptotic expressions of the thermal Casimir free energy, pressure, and entropy at low temperatures in the configuration of one metal and one dielectric plate. To do so, perturbation theory is employed, taking into consideration the product of plate separation and temperature as the small parameter. Numerical computations are compared with the theoretical results and are found to match, revealing that the Lifshitz theory applied to the metal-dielectric set-up satisfies the rules of thermodynamics as long as the static dielectric permittivity is not infinite. It is concluded that Matsubara's formulation of quantum field theory must be adapted if the dielectric permittivity is infinitely large, and corresponding implications for measurements of the Casimir force between metal and semiconductor surfaces are discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3818}
{"prompt": "Rephrase the abstract of an article with title 'A collaborative framework to exchange and share product information\n  within a supply chain context'.\n  The new requirement for \"collaboration\" between multidisciplinary\ncollaborators induces to exchange and share adequate information on the\nproduct, processes throughout the products' lifecycle. Thus, effective capture\nof information, and also its extraction, recording, exchange, sharing, and\nreuse become increasingly critical. These lead companies to adopt new improved\nmethodologies in managing the exchange and sharing of information. The aim of\nthis paper is to describe a collaborative framework system to exchange and\nshare information, which is based on: (i) The Product Process Collaboration\nOrganization model (PPCO) which defines product and process information, and\nthe various collaboration methods for the organizations involved in the supply\nchain. (ii) Viewpoint model describes relationships between each actor and the\ncomprehensive Product/Process model, defining each actor's \"domain of interest\"\nwithin the evolving product definition. (iii) A layer which defines the\ncomprehensive organization and collaboration relationships between the actors\nwithin the supply chain. (iv) Based on the above relationships, the last layer\nproposes a typology of exchanged messages. A communication method, based on\nXML, is developed that supports optimal exchange/sharing of information. To\nillustrate the proposed framework system, an example is presented related to\ncollaborative design of a new piston for an automotive engine. The focus is on\nuser-viewpoint integration to ensure that the adequate information is retrieved\nfrom the PPCO.\n\n", "human_text": "  The new requirement for \"collaboration\" between multidisciplinary\ncollaborators induces to exchange and share adequate information on the\nproduct, processes throughout the products' lifecycle. Thus, effective capture\nof information, and also its extraction, recording, exchange, sharing, and\nreuse become increasingly critical. These lead companies to adopt new improved\nmethodologies in managing the exchange and sharing of information. The aim of\nthis paper is to describe a collaborative framework system to exchange and\nshare information, which is based on: (i) The Product Process Collaboration\nOrganization model (PPCO) which defines product and process information, and\nthe various collaboration methods for the organizations involved in the supply\nchain. (ii) Viewpoint model describes relationships between each actor and the\ncomprehensive Product/Process model, defining each actor's \"domain of interest\"\nwithin the evolving product definition. (iii) A layer which defines the\ncomprehensive organization and collaboration relationships between the actors\nwithin the supply chain. (iv) Based on the above relationships, the last layer\nproposes a typology of exchanged messages. A communication method, based on\nXML, is developed that supports optimal exchange/sharing of information. To\nillustrate the proposed framework system, an example is presented related to\ncollaborative design of a new piston for an automotive engine. The focus is on\nuser-viewpoint integration to ensure that the adequate information is retrieved\nfrom the PPCO.\n", "machine_text": "\nThis paper examines a collaborative framework to facilitate the exchange and sharing of information related to the product and processes in the supply chain context. To achieve this, the Product Process Collaboration Organization (PPCO) model, the Viewpoint model and a communication layer based on XML are proposed. The PPCO model defines product and process information and methods of collaboration for parties in the supply chain. The Viewpoint model outlines the relations between actors and the bigger Product/Process model as well as each actor's domain of interest. Moreover, a typology of exchanged messages is introduced. With an example related to the design of a new piston, this paper showcases the proposed framework's ability to ensure the retrieval of the necessary information from the PPCO layer.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0507}
{"prompt": "Rephrase the abstract of an article with title 'Pseudo-random Puncturing: A Technique to Lower the Error Floor of Turbo\n  Codes'.\n  It has been observed that particular rate-1/2 partially systematic parallel\nconcatenated convolutional codes (PCCCs) can achieve a lower error floor than\nthat of their rate-1/3 parent codes. Nevertheless, good puncturing patterns can\nonly be identified by means of an exhaustive search, whilst convergence towards\nlow bit error probabilities can be problematic when the systematic output of a\nrate-1/2 partially systematic PCCC is heavily punctured. In this paper, we\npresent and study a family of rate-1/2 partially systematic PCCCs, which we\ncall pseudo-randomly punctured codes. We evaluate their bit error rate\nperformance and we show that they always yield a lower error floor than that of\ntheir rate-1/3 parent codes. Furthermore, we compare analytic results to\nsimulations and we demonstrate that their performance converges towards the\nerror floor region, owning to the moderate puncturing of their systematic\noutput. Consequently, we propose pseudo-random puncturing as a means of\nimproving the bandwidth efficiency of a PCCC and simultaneously lowering its\nerror floor.\n\n", "human_text": "  It has been observed that particular rate-1/2 partially systematic parallel\nconcatenated convolutional codes (PCCCs) can achieve a lower error floor than\nthat of their rate-1/3 parent codes. Nevertheless, good puncturing patterns can\nonly be identified by means of an exhaustive search, whilst convergence towards\nlow bit error probabilities can be problematic when the systematic output of a\nrate-1/2 partially systematic PCCC is heavily punctured. In this paper, we\npresent and study a family of rate-1/2 partially systematic PCCCs, which we\ncall pseudo-randomly punctured codes. We evaluate their bit error rate\nperformance and we show that they always yield a lower error floor than that of\ntheir rate-1/3 parent codes. Furthermore, we compare analytic results to\nsimulations and we demonstrate that their performance converges towards the\nerror floor region, owning to the moderate puncturing of their systematic\noutput. Consequently, we propose pseudo-random puncturing as a means of\nimproving the bandwidth efficiency of a PCCC and simultaneously lowering its\nerror floor.\n", "machine_text": "\nIn this work, we put forth and investigate a family of partially systematic parallel concatenated convolutional codes (PCCCs) denoted as pseudo-randomly punctured codes, which have a rate of 1/2. We compare this code family to their rate-1/3 parent codes, in terms of their bit error rate performance. Our findings indicate that the rate-1/2 codes provided better error floor performance, owing to the moderate puncturing of their systematic output. Additionally, we observe that pseudo-random puncturing serves as an effective strategy to simultaneously improve the bandwidth efficiency and reduce the error floor of codes. In conclusion, we propose pseudo-random puncturing as a viable means for ameliorating the performance of PCCCs.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0361}
{"prompt": "Rephrase the abstract of an article with title 'Surface Brightness Profiles for a sample of LMC, SMC and Fornax galaxy\n  Globular Clusters'.\n  We use Hubble Space Telescope archival images to measure central surface\nbrightness profiles of globular clusters around satellite galaxies of the Milky\nWay. We report results for 21 clusters around the LMC, 5 around the SMC, and 4\naround the Fornax dwarf galaxy. The profiles are obtained using a recently\ndeveloped technique based on measuring integrated light, which is tested on an\nextensive simulated dataset. Our results show that for 70% of the sample, the\ncentral photometric points of our profiles are brighter than previous\nmeasurements using star counts with deviations as large as 2 mag/arcsec^2.\nAbout 40% of the objects have central profiles deviating from a flat central\ncore, with central logarithmic slopes continuously distributed between -0.2 and\n-1.2. These results are compared with those found for a sample of Galactic\nclusters using the same method. We confirm the known correlation in which\nyounger clusters tend to have smaller core radii, and we find that they also\nhave brighter central surface brightness values. This seems to indicate that\nglobular clusters might be born relatively concentrated, and that a profile\nwith extended flat cores might not be the ideal choice for initial profiles in\ntheoretical models.\n\n", "human_text": "  We use Hubble Space Telescope archival images to measure central surface\nbrightness profiles of globular clusters around satellite galaxies of the Milky\nWay. We report results for 21 clusters around the LMC, 5 around the SMC, and 4\naround the Fornax dwarf galaxy. The profiles are obtained using a recently\ndeveloped technique based on measuring integrated light, which is tested on an\nextensive simulated dataset. Our results show that for 70% of the sample, the\ncentral photometric points of our profiles are brighter than previous\nmeasurements using star counts with deviations as large as 2 mag/arcsec^2.\nAbout 40% of the objects have central profiles deviating from a flat central\ncore, with central logarithmic slopes continuously distributed between -0.2 and\n-1.2. These results are compared with those found for a sample of Galactic\nclusters using the same method. We confirm the known correlation in which\nyounger clusters tend to have smaller core radii, and we find that they also\nhave brighter central surface brightness values. This seems to indicate that\nglobular clusters might be born relatively concentrated, and that a profile\nwith extended flat cores might not be the ideal choice for initial profiles in\ntheoretical models.\n", "machine_text": "\nUsing archival Hubble Space Telescope images, we examine 21 globular clusters situated around the Large Magellanic Cloud, 5 around the Small Magellanic Cloud, and 4 around the Fornax dwarf galaxy. Our results, acquired by a technically advanced integrated light measuring procedure, demonstrate that two thirds of the sample are brighter than earlier estimates made by star count measurements, with variances as high as two magnitudes per arcsecond squared. Additionally, roughly 40% of the profiles show a deviation from the theoretically defined flat-central-core concept. We found that the central logarithmic slopes for these clusters were distributed between -0.2 and -1.2. Comparing our results with those of a sample of globular clusters in the Milky Way, we discerned a correlation between age and core radius: younger clusters tend to have smaller core radii and higher central surface brightness. Taken together, the results of this study appear to demonstrate that the concentration of globular clusters at birth may be higher than previously assumed, and that the predicted flat-core profile may not be the most suitable initial condition model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3464}
{"prompt": "Rephrase the abstract of an article with title 'Solidity of viscous liquids. V. Long-wavelength dominance of the\n  dynamics'.\n  This paper is the fifth in a series exploring the physical consequences of\nthe solidity of glass-forming liquids. Paper IV proposed a model where the\ndensity field is described by a time-dependent Ginzburg-Landau equation of the\nnonconserved type with rates in $k$ space of the form $\\Gamma_0+Dk^2$. The\nmodel assumes that $D\\gg\\Gamma_0a^2$ where $a$ is the average intermolecular\ndistance; this inequality expresses a long-wavelength dominance of the dynamics\nwhich implies that the Hamiltonian (free energy) to a good approximation may be\ntaken to be ultralocal. In the present paper we argue that this is the simplest\nmodel consistent with the following three experimental facts: 1) Viscous\nliquids approaching the glass transition do not develop long-range order; 2)\nThe glass has lower compressibility than the liquid; 3) The alpha process\ninvolves several decades of relaxation times shorter than the mean relaxation\ntime. The paper proceeds to list six further experimental facts characterizing\nequilibrium viscous liquid dynamics and shows that these are readily understood\nin terms of the model; some are direct consequences, others are quite natural\nwhen viewed in light of the model.\n\n", "human_text": "  This paper is the fifth in a series exploring the physical consequences of\nthe solidity of glass-forming liquids. Paper IV proposed a model where the\ndensity field is described by a time-dependent Ginzburg-Landau equation of the\nnonconserved type with rates in $k$ space of the form $\\Gamma_0+Dk^2$. The\nmodel assumes that $D\\gg\\Gamma_0a^2$ where $a$ is the average intermolecular\ndistance; this inequality expresses a long-wavelength dominance of the dynamics\nwhich implies that the Hamiltonian (free energy) to a good approximation may be\ntaken to be ultralocal. In the present paper we argue that this is the simplest\nmodel consistent with the following three experimental facts: 1) Viscous\nliquids approaching the glass transition do not develop long-range order; 2)\nThe glass has lower compressibility than the liquid; 3) The alpha process\ninvolves several decades of relaxation times shorter than the mean relaxation\ntime. The paper proceeds to list six further experimental facts characterizing\nequilibrium viscous liquid dynamics and shows that these are readily understood\nin terms of the model; some are direct consequences, others are quite natural\nwhen viewed in light of the model.\n", "machine_text": "This article examines the physical implications of the solidity of commonly occurring glass-forming liquids, based on a model involving a time-dependent Ginzburg-Landau equation of the non-conserved type with rates in $k$ space of the form $\\Gamma_0+Dk^2$. The paper aims to demonstrate that this approach, which assumes a dominance of long-wavelength dynamics, can explain several pertinent experimental findings. These include the limitations of viscous liquids to develop structural order, the lower compressibility of glass when compared to its liquid counterpart, and the presence of shorter relaxation timescales within the alpha process. The paper also considers six additional experimental assertions concerning the behaviours of viscous liquids, and verifies that they are logically consistent with the model described.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1329}
{"prompt": "Rephrase the abstract of an article with title 'Depletion effects in smectic phases of hard rod--hard sphere mixtures'.\n  It is known that when hard spheres are added to a pure system of hard rods\nthe stability of the smectic phase may be greatly enhanced, and that this\neffect can be rationalised in terms of depletion forces. In the present paper\nwe first study the effect of orientational order on depletion forces in this\nparticular binary system, comparing our results with those obtained adopting\nthe usual approximation of considering the rods parallel and their orientations\nfrozen. We consider mixtures with rods of different aspect ratios and spheres\nof different diameters, and we treat them within Onsager theory. Our results\nindicate that depletion effects, and consequently smectic stability, decrease\nsignificantly as a result of orientational disorder in the smectic phase when\ncompared with corresponding data based on the frozen--orientation\napproximation. These results are discussed in terms of the $\\tau$ parameter,\nwhich has been proposed as a convenient measure of depletion strength. We\npresent closed expressions for $\\tau$, and show that it is intimately connected\nwith the depletion potential. We then analyse the effect of particle geometry\nby comparing results pertaining to systems of parallel rods of different shapes\n(spherocylinders, cylinders and parallelepipeds). We finally provide results\nbased on the Zwanzig approximation of a Fundamental--Measure\ndensity--functional theory applied to mixtures of parallelepipeds and cubes of\ndifferent sizes. In this case, we show that the $\\tau$ parameter exhibits a\nlinear asymptotic behaviour in the limit of large values of the hard--rod\naspect ratio, in conformity with Onsager theory, as well as in the limit of\nlarge values of the ratio of rod breadth to cube side length, $d$, in contrast\nto Onsager approximation, which predicts $\\tau\\sim d^3$.\n\n", "human_text": "  It is known that when hard spheres are added to a pure system of hard rods\nthe stability of the smectic phase may be greatly enhanced, and that this\neffect can be rationalised in terms of depletion forces. In the present paper\nwe first study the effect of orientational order on depletion forces in this\nparticular binary system, comparing our results with those obtained adopting\nthe usual approximation of considering the rods parallel and their orientations\nfrozen. We consider mixtures with rods of different aspect ratios and spheres\nof different diameters, and we treat them within Onsager theory. Our results\nindicate that depletion effects, and consequently smectic stability, decrease\nsignificantly as a result of orientational disorder in the smectic phase when\ncompared with corresponding data based on the frozen--orientation\napproximation. These results are discussed in terms of the $\\tau$ parameter,\nwhich has been proposed as a convenient measure of depletion strength. We\npresent closed expressions for $\\tau$, and show that it is intimately connected\nwith the depletion potential. We then analyse the effect of particle geometry\nby comparing results pertaining to systems of parallel rods of different shapes\n(spherocylinders, cylinders and parallelepipeds). We finally provide results\nbased on the Zwanzig approximation of a Fundamental--Measure\ndensity--functional theory applied to mixtures of parallelepipeds and cubes of\ndifferent sizes. In this case, we show that the $\\tau$ parameter exhibits a\nlinear asymptotic behaviour in the limit of large values of the hard--rod\naspect ratio, in conformity with Onsager theory, as well as in the limit of\nlarge values of the ratio of rod breadth to cube side length, $d$, in contrast\nto Onsager approximation, which predicts $\\tau\\sim d^3$.\n", "machine_text": "\nThe present study examines the implications of orientational order on depletion forces, and thus its effects on the stability of formation of smectic phases in mixtures of hard rods and hard spheres. An analysis is conducted through Onsager theory, taking into account rods of varying aspect ratios and spheres of varying diameters. It is determined that an orientational disorder causes a decrease in depletion effects and thus stability of the smectic phase as compared to when orientations are constrained to be parallel. To gain insight on particle geometry, systems of parallel rods of different shapes are compared. The Zwanzig approximation of Fundamental-Measure density-functional theory is used to study mixtures of parallelepipeds and cubes. Results show that the $\\tau$ parameter, which reflects depletion strength, follows a linear asymptotic behaviour in the limit of high ratios of both rod breadth to cube side length and rod aspect ratio.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.114}
{"prompt": "Rephrase the abstract of an article with title 'Thermodynamic quantum critical behavior of the Kondo necklace model'.\n  We obtain the phase diagram and thermodynamic behavior of the Kondo necklace\nmodel for arbitrary dimensions $d$ using a representation for the localized and\nconduction electrons in terms of local Kondo singlet and triplet operators. A\ndecoupling scheme on the double time Green's functions yields the dispersion\nrelation for the excitations of the system. We show that in $d\\geq 3$ there is\nan antiferromagnetically ordered state at finite temperatures terminating at a\nquantum critical point (QCP). In 2-d, long range magnetic order occurs only at\nT=0. The line of Neel transitions for $d>2$ varies with the distance to the\nquantum critical point QCP $|g|$ as, $T_N \\propto |g|^{\\psi}$ where the shift\nexponent $\\psi=1/(d-1)$. In the paramagnetic side of the phase diagram, the\nspin gap behaves as $\\Delta\\approx \\sqrt{|g|}$ for $d \\ge 3$ consistent with\nthe value $z=1$ found for the dynamical critical exponent. We also find in this\nregion a power law temperature dependence in the specific heat for\n$k_BT\\gg\\Delta$ and along the non-Fermi liquid trajectory. For $k_BT\n\\ll\\Delta$, in the so-called Kondo spin liquid phase, the thermodynamic\nbehavior is dominated by an exponential temperature dependence.\n\n", "human_text": "  We obtain the phase diagram and thermodynamic behavior of the Kondo necklace\nmodel for arbitrary dimensions $d$ using a representation for the localized and\nconduction electrons in terms of local Kondo singlet and triplet operators. A\ndecoupling scheme on the double time Green's functions yields the dispersion\nrelation for the excitations of the system. We show that in $d\\geq 3$ there is\nan antiferromagnetically ordered state at finite temperatures terminating at a\nquantum critical point (QCP). In 2-d, long range magnetic order occurs only at\nT=0. The line of Neel transitions for $d>2$ varies with the distance to the\nquantum critical point QCP $|g|$ as, $T_N \\propto |g|^{\\psi}$ where the shift\nexponent $\\psi=1/(d-1)$. In the paramagnetic side of the phase diagram, the\nspin gap behaves as $\\Delta\\approx \\sqrt{|g|}$ for $d \\ge 3$ consistent with\nthe value $z=1$ found for the dynamical critical exponent. We also find in this\nregion a power law temperature dependence in the specific heat for\n$k_BT\\gg\\Delta$ and along the non-Fermi liquid trajectory. For $k_BT\n\\ll\\Delta$, in the so-called Kondo spin liquid phase, the thermodynamic\nbehavior is dominated by an exponential temperature dependence.\n", "machine_text": "\nThe thermodynamic behavior of the Kondo necklace model in arbitrary dimensions $d$ is studied using a representation in terms of local Kondo singlet and triplet operators. Our results demonstrate that for $d\\geq 3$ there is an antiferromagnetically ordered state at finite temperatures that terminates at a quantum critical point (QCP). In two dimensions, this long range order only occurs at zero temperature. The Neel transition line varies with the distance to the QCP $|g|$ as $T_N \\propto |g|^{\\psi}$ with the shift exponent $\\psi=1/(d-1)$. As the paramagnetic phase is entered, the spin gap is seen to follow the behavior $\\Delta\\approx \\sqrt{|g|}$ for $d \\ge 3$, matching the dynamical critical exponent $z=1$. For low temperatures (i.e. $k_BT \\ll\\Delta$ in the Kondo spin liquid phase), the thermodynamic behavior is marked by an exponential temperature dependence. On the other hand, in the regime $k_BT\\gg\\Delta$ there is a power law temperature dependence of the specific heat.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1384}
{"prompt": "Rephrase the abstract of an article with title 'Disclinations, dislocations and continuous defects: a reappraisal'.\n  Disclinations, first observed in mesomorphic phases, are relevant to a number\nof ill-ordered condensed matter media, with continuous symmetries or frustrated\norder. They also appear in polycrystals at the edges of grain boundaries. They\nare of limited interest in solid single crystals, where, owing to their large\nelastic stresses, they mostly appear in close pairs of opposite signs. The\nrelaxation mechanisms associated with a disclination in its creation, motion,\nchange of shape, involve an interplay with continuous or quantized dislocations\nand/or continuous disclinations. These are attached to the disclinations or are\nakin to Nye's dislocation densities, well suited here. The notion of 'extended\nVolterra process' takes these relaxation processes into account and covers\ndifferent situations where this interplay takes place. These concepts are\nillustrated by applications in amorphous solids, mesomorphic phases and\nfrustrated media in their curved habit space. The powerful topological theory\nof line defects only considers defects stable against relaxation processes\ncompatible with the structure considered. It can be seen as a simplified case\nof the approach considered here, well suited for media of high plasticity\nor/and complex structures. Topological stability cannot guarantee energetic\nstability and sometimes cannot distinguish finer details of structure of\ndefects.\n\n", "human_text": "  Disclinations, first observed in mesomorphic phases, are relevant to a number\nof ill-ordered condensed matter media, with continuous symmetries or frustrated\norder. They also appear in polycrystals at the edges of grain boundaries. They\nare of limited interest in solid single crystals, where, owing to their large\nelastic stresses, they mostly appear in close pairs of opposite signs. The\nrelaxation mechanisms associated with a disclination in its creation, motion,\nchange of shape, involve an interplay with continuous or quantized dislocations\nand/or continuous disclinations. These are attached to the disclinations or are\nakin to Nye's dislocation densities, well suited here. The notion of 'extended\nVolterra process' takes these relaxation processes into account and covers\ndifferent situations where this interplay takes place. These concepts are\nillustrated by applications in amorphous solids, mesomorphic phases and\nfrustrated media in their curved habit space. The powerful topological theory\nof line defects only considers defects stable against relaxation processes\ncompatible with the structure considered. It can be seen as a simplified case\nof the approach considered here, well suited for media of high plasticity\nor/and complex structures. Topological stability cannot guarantee energetic\nstability and sometimes cannot distinguish finer details of structure of\ndefects.\n", "machine_text": "\nThis paper offers a re-evaluation of disclinations, dislocations and continuous defects in ill-structured condensed matter media with continuous symmetries or frustrated order. In this context, the relaxation mechanisms associated with the creation, motion and change of shape of disclinations relate to dislocations and/or disclinations. The authors provide an example of the extended Volterra process in amorphous solids, mesomorphic phases and media with frustrated order. Moreover, the paper illustrates how this interplay can reveal fine details within the structure of defects that are not always evaluated in topological theory. Yet, topological stability cannot guarantee energetic stability.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3055}
{"prompt": "Rephrase the abstract of an article with title 'Probing the Relation Between X-ray-Derived and Weak-Lensing-Derived\n  Masses for Shear-Selected Galaxy Clusters: I. A781'.\n  We compare X-ray and weak-lensing masses for four galaxy clusters that\ncomprise the top-ranked shear-selected cluster system in the Deep Lens Survey.\nThe weak-lensing observations of this system, which is associated with A781,\nare from the Kitt Peak Mayall 4-m telescope, and the X-ray observations are\nfrom both Chandra and XMM-Newton. For a faithful comparison of masses, we adopt\nthe same matter density profile for each method, which we choose to be an NFW\nprofile. Since neither the X-ray nor weak-lensing data are deep enough to well\nconstrain both the NFW scale radius and central density, we estimate the scale\nradius using a fitting function for the concentration derived from cosmological\nhydrodynamic simulations and an X-ray estimate of the mass assuming\nisothermality. We keep this scale radius in common for both X-ray and\nweak-lensing profiles, and fit for the central density, which scales linearly\nwith mass. We find that for three of these clusters, there is agreement between\nX-ray and weak-lensing NFW central densities, and thus masses. For the other\ncluster, the X-ray central density is higher than that from weak-lensing by 2\nsigma. X-ray images suggest that this cluster may be undergoing a merger with a\nsmaller cluster. This work serves as an additional step towards understanding\nthe possible biases in X-ray and weak-lensing cluster mass estimation methods.\nSuch understanding is vital to efforts to constrain cosmology using X-ray or\nweak-lensing cluster surveys to trace the growth of structure over cosmic time.\n\n", "human_text": "  We compare X-ray and weak-lensing masses for four galaxy clusters that\ncomprise the top-ranked shear-selected cluster system in the Deep Lens Survey.\nThe weak-lensing observations of this system, which is associated with A781,\nare from the Kitt Peak Mayall 4-m telescope, and the X-ray observations are\nfrom both Chandra and XMM-Newton. For a faithful comparison of masses, we adopt\nthe same matter density profile for each method, which we choose to be an NFW\nprofile. Since neither the X-ray nor weak-lensing data are deep enough to well\nconstrain both the NFW scale radius and central density, we estimate the scale\nradius using a fitting function for the concentration derived from cosmological\nhydrodynamic simulations and an X-ray estimate of the mass assuming\nisothermality. We keep this scale radius in common for both X-ray and\nweak-lensing profiles, and fit for the central density, which scales linearly\nwith mass. We find that for three of these clusters, there is agreement between\nX-ray and weak-lensing NFW central densities, and thus masses. For the other\ncluster, the X-ray central density is higher than that from weak-lensing by 2\nsigma. X-ray images suggest that this cluster may be undergoing a merger with a\nsmaller cluster. This work serves as an additional step towards understanding\nthe possible biases in X-ray and weak-lensing cluster mass estimation methods.\nSuch understanding is vital to efforts to constrain cosmology using X-ray or\nweak-lensing cluster surveys to trace the growth of structure over cosmic time.\n", "machine_text": "\nWe investigate the consistency between X-ray-derived and weak-lensing-derived masses for four of the highest ranked shear-selected galaxy clusters affiliated with A781 in the Deep Lens Survey. Specifically, we compare X-ray data from Chandra and XMM-Newton and weak-lensing data from Kitt Peak Mayall 4-m Telescope by adopting a standard NFW profile for mass reconstruction. We fix the scale radius for both X-ray and weak-lensing profiles using a fitting function from cosmological hydrodynamic simulations and an X-ray mass assuming isothermality. Subsequently, we focus on the comparison of the central densities, which scale linearly with mass, for the four clusters. We find that for the majority of the clusters, the X-ray-derived and weak-lensing-derived masses are in agreement, yet a difference of two sigma is detected for one cluster possibly caused by its merger with a smaller cluster. This research can be employed to gain a better understanding of the biases that may arise when estimating mass through X-ray and weak-lensing cluster surveys, as these methods are vital for testing cosmology.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2351}
{"prompt": "Rephrase the abstract of an article with title 'Testing anthropic predictions for Lambda and the CMB temperature'.\n  It has been claimed that the observed magnitude of the vacuum energy density\nis consistent with the distribution predicted in anthropic models, in which an\nensemble of universes is assumed. This calculation is revisited, without making\nthe assumption that the CMB temperature is known, and considering in detail the\npossibility of a recollapsing universe. New accurate approximations for the\ngrowth of perturbations and the mass function of dark haloes are presented.\nStructure forms readily in the recollapsing phase of a model with negative\nLambda, so collapse fraction alone cannot forbid Lambda from being large and\nnegative. A negative Lambda is disfavoured only if we assume that formation of\nobservers can be neglected once the recollapsing universe has heated to T > 8\nK. For the case of positive Lambda, however, the current universe does occupy a\nextremely typical position compared to the predicted distribution on the\nLambda-T plane. Contrasting conclusions can be reached if anthropic arguments\nare applied to the curvature of the universe, and we discuss the falsifiability\nof this mode of anthropic reasoning.\n\n", "human_text": "  It has been claimed that the observed magnitude of the vacuum energy density\nis consistent with the distribution predicted in anthropic models, in which an\nensemble of universes is assumed. This calculation is revisited, without making\nthe assumption that the CMB temperature is known, and considering in detail the\npossibility of a recollapsing universe. New accurate approximations for the\ngrowth of perturbations and the mass function of dark haloes are presented.\nStructure forms readily in the recollapsing phase of a model with negative\nLambda, so collapse fraction alone cannot forbid Lambda from being large and\nnegative. A negative Lambda is disfavoured only if we assume that formation of\nobservers can be neglected once the recollapsing universe has heated to T > 8\nK. For the case of positive Lambda, however, the current universe does occupy a\nextremely typical position compared to the predicted distribution on the\nLambda-T plane. Contrasting conclusions can be reached if anthropic arguments\nare applied to the curvature of the universe, and we discuss the falsifiability\nof this mode of anthropic reasoning.\n", "machine_text": "\nThis article critically examines anthropic models in which an ensemble of universes is assumed, strictly disallowing the assumption that the CMB temperature is known. More accurate approximations of the growth of perturbations and the mass function of dark haloes are put forth as well. It is proposed that a negative Lambda is not necessarily prevented by collapse fraction, while a positive Lambda appears to be in an extremely typical position compared to the envisioned distribution on the Lambda-T plane. The falsifiability of this reasoning is then evaluated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0898}
{"prompt": "Rephrase the abstract of an article with title 'Nurturing Breakthroughs: Lessons from Complexity Theory'.\n  A general theory of innovation and progress in human society is outlined,\nbased on the combat between two opposite forces (conservatism/inertia and\nspeculative herding \"bubble\" behavior). We contend that human affairs are\ncharacterized by ubiquitous ``bubbles'', which involve huge risks which would\nnot otherwise be taken using standard cost/benefit analysis. Bubbles result\nfrom self-reinforcing positive feedbacks. This leads to explore uncharted\nterritories and niches whose rare successes lead to extraordinary discoveries\nand provide the base for the observed accelerating development of technology\nand of the economy. But the returns are very heterogeneous, very risky and may\nnot occur. In other words, bubbles, which are characteristic definitions of\nhuman activity, allow huge risks to get huge returns over large scales. We\noutline some underlying mathematical structure and a few results involving\npositive feedbacks, emergence, heavy-tailed power laws, outliers/kings/black\nswans, the problem of predictability and the illusion of control, as well as\nsome policy implications.\n\n", "human_text": "  A general theory of innovation and progress in human society is outlined,\nbased on the combat between two opposite forces (conservatism/inertia and\nspeculative herding \"bubble\" behavior). We contend that human affairs are\ncharacterized by ubiquitous ``bubbles'', which involve huge risks which would\nnot otherwise be taken using standard cost/benefit analysis. Bubbles result\nfrom self-reinforcing positive feedbacks. This leads to explore uncharted\nterritories and niches whose rare successes lead to extraordinary discoveries\nand provide the base for the observed accelerating development of technology\nand of the economy. But the returns are very heterogeneous, very risky and may\nnot occur. In other words, bubbles, which are characteristic definitions of\nhuman activity, allow huge risks to get huge returns over large scales. We\noutline some underlying mathematical structure and a few results involving\npositive feedbacks, emergence, heavy-tailed power laws, outliers/kings/black\nswans, the problem of predictability and the illusion of control, as well as\nsome policy implications.\n", "machine_text": "\nThis paper examines the implications of complexity theory for human progress and innovation. It argues that our society is characterized by a cycle of bubbles, created by the positive feedback of speculation and herding which can lead to risks that would otherwise not be taken using traditional cost/benefit analysis; however, when these bubbles succeed, they can yield extraordinary results. The underlying mathematical structure of these bubbles is discussed, including the emergence of heavy-tailed power laws, outliers/kings/black swans, predictability/illusory control and more, and relevant policy implications are outlined. Ultimately, this analysis seeks to highlight the vital role that bubbles play in human progress.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1839}
{"prompt": "Rephrase the abstract of an article with title 'In-orbit focal adjustment of the AKARI telescope with IRC images'.\n  AKARI currently in space carries onboard a cryogenically-cooled lightweight\ntelescope with silicon carbide mirrors. The wavefront error of the AKARI\ntelescope obtained in laboratory measurements at 9 K showed that expected\nin-orbit imaging performance was diffraction-limited at a wavelength of 6.2 um.\nThe AKARI telescope has a function of focus adjustment by shifting the\nsecondary mirror in parallel to the optical axis. On the 4th day after the\njettison of the cryostat aperture lid in the orbit, we observed a star with the\nInfraRed Camera (IRC) onboard AKARI. Since the initial star images observed in\nthe near-infrared (IR) bands were significantly blurred, we twice moved the\nsecondary mirror for the focal adjustment based on the results of model\nanalyses as well as data analyses of the near-IR images. In consequence, we\nhave successfully adjusted the focus of the telescope. The in-orbit imaging\nperformance thus obtained for the AKARI telescope is diffraction-limited at a\nwavelength of 7.3 um, slightly degraded from that expected from the laboratory\nmeasurement.\n\n", "human_text": "  AKARI currently in space carries onboard a cryogenically-cooled lightweight\ntelescope with silicon carbide mirrors. The wavefront error of the AKARI\ntelescope obtained in laboratory measurements at 9 K showed that expected\nin-orbit imaging performance was diffraction-limited at a wavelength of 6.2 um.\nThe AKARI telescope has a function of focus adjustment by shifting the\nsecondary mirror in parallel to the optical axis. On the 4th day after the\njettison of the cryostat aperture lid in the orbit, we observed a star with the\nInfraRed Camera (IRC) onboard AKARI. Since the initial star images observed in\nthe near-infrared (IR) bands were significantly blurred, we twice moved the\nsecondary mirror for the focal adjustment based on the results of model\nanalyses as well as data analyses of the near-IR images. In consequence, we\nhave successfully adjusted the focus of the telescope. The in-orbit imaging\nperformance thus obtained for the AKARI telescope is diffraction-limited at a\nwavelength of 7.3 um, slightly degraded from that expected from the laboratory\nmeasurement.\n", "machine_text": "\n\nThis study describes the successful in-orbit focal adjustment of the AKARI telescope, with lightweight Silicon Carbide mirrors cooled to 9 K in the laboratory showing expected diffraction-limited imaging performance at 6.2 um. After the cryostat aperture lid was released in the orbit on the 4th day, images of the star were significantly blurred and had to be adjusted by twice shifting the secondary mirror. Model and data analyses were used to guide the adjustment. The adjusted focus of the AKARI telescope was eventually diffraction-limited at 7.3 um, slightly lower than predicted from laboratory measurements.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.007}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological Coincidence and Dark Mass Problems in Einstein Universe and\n  Friedman Dust Universe with Einstein's Lambda Quantum Cosmology Dark Energy\n  Schroedinger Wave Motion'.\n  In this paper, it is shown that the cosmological model that was introduced in\na sequence of three earlier papers under the title, A Dust Universe Solution to\nthe Dark Energy Problem can be used to analyse and solve the Cosmological\nCoincidence Problem. The generic coincidence problem that appears in the\noriginal Einstein universe model is shown to arise from a misunderstanding\nabout the magnitude of dark energy density and the epoch time governing the\nappearance of the integer relation between dark energy and normal energy\ndensity. The solution to the generic case then clearly points to the source of\nthe time coincidence integer problem in the Friedman dust universe model. It is\nthen possible to eliminate this coincidence by removing a degeneracy between\ndifferent measurement epoch times. In this paper's first appendix, a\nfundamental time dependent relation between dark mass and dark energy is\nderived with suggestions how this relation could explain cosmological voids and\nthe clumping of dark mass to become visible matter. In this paper's second\nappendix, it is shown that that dark energy is a conserved with time substance\nthat is everywhere and for all time permeable to the dark mass and visible mass\nof which the contracting or expanding universe is composed. The last two\nappendices involve detailed studies of cosmology, quantum dark energy related\nissues. There are more detailed abstracts given with all four appendices.\n\n", "human_text": "  In this paper, it is shown that the cosmological model that was introduced in\na sequence of three earlier papers under the title, A Dust Universe Solution to\nthe Dark Energy Problem can be used to analyse and solve the Cosmological\nCoincidence Problem. The generic coincidence problem that appears in the\noriginal Einstein universe model is shown to arise from a misunderstanding\nabout the magnitude of dark energy density and the epoch time governing the\nappearance of the integer relation between dark energy and normal energy\ndensity. The solution to the generic case then clearly points to the source of\nthe time coincidence integer problem in the Friedman dust universe model. It is\nthen possible to eliminate this coincidence by removing a degeneracy between\ndifferent measurement epoch times. In this paper's first appendix, a\nfundamental time dependent relation between dark mass and dark energy is\nderived with suggestions how this relation could explain cosmological voids and\nthe clumping of dark mass to become visible matter. In this paper's second\nappendix, it is shown that that dark energy is a conserved with time substance\nthat is everywhere and for all time permeable to the dark mass and visible mass\nof which the contracting or expanding universe is composed. The last two\nappendices involve detailed studies of cosmology, quantum dark energy related\nissues. There are more detailed abstracts given with all four appendices.\n", "machine_text": "In this article, an analysis of the Cosmological Coincidence Problem is presented and applied to the Einstein Universe and Friedman Dust Universe models. Using the Dust Universe Solution to the Dark Energy Problem, it is demonstrated that the generic coincidence problem within the Einstein universe is due to a misunderstanding of the magnitude of dark energy and the time governing the relation between dark and normal energy density. It is concluded that the degeneracy between different measurement epoch times can be eliminated, providing implications for how dark matter and dark energy interact to form visible matter and how the latter is related to clumping of the former. The appendices then provide further detail on dark energy and quantum dark energy related topics in the context of cosmology.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2872}
{"prompt": "Rephrase the abstract of an article with title 'A relativistic calculation of the deuteron threshold\n  electrodisintegration at backward angles'.\n  The threshold electrodisintegration of the deuteron at backward angles is\nstudied with a relativistic Hamiltonian, including a relativistic\none-pion-exchange potential (OPEP) with off-shell terms as predicted by\npseudovector coupling of pions to nucleons. The bound and scattering states are\nobtained in the center-of-mass frame, and then boosted from it to the Breit\nframe, where the evaluation of the relevant matrix elements of the\nelectromagnetic current operator is carried out. The latter includes, in\naddition to one-body, also two-body terms due to pion exchange, as obtained,\nconsistently with the OPEP, in pseudovector pion-nucleon coupling theory. The\nfull Lorentz structure of these currents is retained. In order to estimate the\nmagnitude of the relativistic effects we perform, for comparison, the\ncalculation with a non-relativistic phase-equivalent Hamiltonian and the\nstandard non-relativistic expressions for the one-body and two-body\npion-exchange currents. Our results for the electrodisintegration cross section\nshow that, in the calculations using one-body currents, relativistic\ncorrections become significant ({\\it i.e.}, larger than 10%) only at high\nmomentum transfer $Q$ ($Q^2 \\simeq 40$fm$^{-2}$ and beyond). However, the\ninclusion of two-body currents makes the relativistic predictions considerably\nsmaller than the corresponding non-relativistic results in the $Q^2$ region\n(18--40) fm$^{-2}$. The calculations based on the relativistic model also\nconfirm the inadequacy, already established in a non-relativistic context, of\nthe present electromagnetic current model to reproduce accurately the\nexperimental data at intermediate values of momentum transfers.\n\n", "human_text": "  The threshold electrodisintegration of the deuteron at backward angles is\nstudied with a relativistic Hamiltonian, including a relativistic\none-pion-exchange potential (OPEP) with off-shell terms as predicted by\npseudovector coupling of pions to nucleons. The bound and scattering states are\nobtained in the center-of-mass frame, and then boosted from it to the Breit\nframe, where the evaluation of the relevant matrix elements of the\nelectromagnetic current operator is carried out. The latter includes, in\naddition to one-body, also two-body terms due to pion exchange, as obtained,\nconsistently with the OPEP, in pseudovector pion-nucleon coupling theory. The\nfull Lorentz structure of these currents is retained. In order to estimate the\nmagnitude of the relativistic effects we perform, for comparison, the\ncalculation with a non-relativistic phase-equivalent Hamiltonian and the\nstandard non-relativistic expressions for the one-body and two-body\npion-exchange currents. Our results for the electrodisintegration cross section\nshow that, in the calculations using one-body currents, relativistic\ncorrections become significant ({\\it i.e.}, larger than 10%) only at high\nmomentum transfer $Q$ ($Q^2 \\simeq 40$fm$^{-2}$ and beyond). However, the\ninclusion of two-body currents makes the relativistic predictions considerably\nsmaller than the corresponding non-relativistic results in the $Q^2$ region\n(18--40) fm$^{-2}$. The calculations based on the relativistic model also\nconfirm the inadequacy, already established in a non-relativistic context, of\nthe present electromagnetic current model to reproduce accurately the\nexperimental data at intermediate values of momentum transfers.\n", "machine_text": "\nThis article examines the threshold electrodisintegration of the deuteron at backwards angles, utilizing a relativistic Hamiltonian that incorporates an off-shell one-pion-exchange potential and pseudovector pion-nucleon coupling theory. Centre-of-mass and Breit frames are used for the bound- and scattering-state evaluations, respectively, and retaining the full lorentz structure of the electromagnetic current operator. To establish the size of relativistic effects, the calculations are performed using both non-relativistic phase-equivalent Hamiltonian and current models. The results illustrate that, when taking into consideration just one body currents, relativistic corrections become considerable for higher momentum transfer $Q$. Conversely, when accounting for two-body currents, predictions are seen to be much smaller than non-relativistic results in the $Q^2$ area 18-40 fm$^{-2}$. Additionally, existing discrepancies between the model and experimental data at intermediate momentum transfer are further substantiated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2514}
{"prompt": "Rephrase the abstract of an article with title 'Minimum Expected Distortion in Gaussian Layered Broadcast Coding with\n  Successive Refinement'.\n  A transmitter without channel state information (CSI) wishes to send a\ndelay-limited Gaussian source over a slowly fading channel. The source is coded\nin superimposed layers, with each layer successively refining the description\nin the previous one. The receiver decodes the layers that are supported by the\nchannel realization and reconstructs the source up to a distortion. In the\nlimit of a continuum of infinite layers, the optimal power distribution that\nminimizes the expected distortion is given by the solution to a set of linear\ndifferential equations in terms of the density of the fading distribution. In\nthe optimal power distribution, as SNR increases, the allocation over the\nhigher layers remains unchanged; rather the extra power is allocated towards\nthe lower layers. On the other hand, as the bandwidth ratio b (channel uses per\nsource symbol) tends to zero, the power distribution that minimizes expected\ndistortion converges to the power distribution that maximizes expected\ncapacity. While expected distortion can be improved by acquiring CSI at the\ntransmitter (CSIT) or by increasing diversity from the realization of\nindependent fading paths, at high SNR the performance benefit from diversity\nexceeds that from CSIT, especially when b is large.\n\n", "human_text": "  A transmitter without channel state information (CSI) wishes to send a\ndelay-limited Gaussian source over a slowly fading channel. The source is coded\nin superimposed layers, with each layer successively refining the description\nin the previous one. The receiver decodes the layers that are supported by the\nchannel realization and reconstructs the source up to a distortion. In the\nlimit of a continuum of infinite layers, the optimal power distribution that\nminimizes the expected distortion is given by the solution to a set of linear\ndifferential equations in terms of the density of the fading distribution. In\nthe optimal power distribution, as SNR increases, the allocation over the\nhigher layers remains unchanged; rather the extra power is allocated towards\nthe lower layers. On the other hand, as the bandwidth ratio b (channel uses per\nsource symbol) tends to zero, the power distribution that minimizes expected\ndistortion converges to the power distribution that maximizes expected\ncapacity. While expected distortion can be improved by acquiring CSI at the\ntransmitter (CSIT) or by increasing diversity from the realization of\nindependent fading paths, at high SNR the performance benefit from diversity\nexceeds that from CSIT, especially when b is large.\n", "machine_text": "\nIn this work, the minimum expected distortion under delay constraints of a Gaussian source transmitted over a slowly fading channel has been investigated. Using layered broadcast coding with successive refinements, the receiver decodes the layers that are supported by the channel and reconstructs the source up to some distortion while the transmitter, who possesses no channel state information (CSI), allocates a variable power over each layer. The optimal power distribution that yields the minimum expected distortion, in the limit of an infinite number of layers, was determined by solving a set of linear differential equations related to the density of the fading distribution. Results showed that as the SNR increases, power is allocated to the lower layers; meanwhile, with diminishing bandwidth ratio (channel uses per source symbol), the optimal power distribution converges to that maximizing the expected capacity. While the expected distortion can be improved by either acquiring CSI or increasing diversity, the performance gains of diversity surpassed those of CSI at high SNR, most notably when the bandwidth ratio was large.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2659}
{"prompt": "Rephrase the abstract of an article with title 'Current status of Japanese detectors'.\n  Current status of TAMA and CLIO detectors in Japan is reported in this\narticle. These two interferometric gravitational-wave detectors are being\ndeveloped for the large cryogenic gravitational wave telescope (LCGT) which is\na future plan for detecting gravitational wave signals at least once per year.\n  TAMA300 is being upgraded to improve the sensitivity in low frequency region\nafter the last observation experiment in 2004. To reduce the seismic noises, we\nare installing new seismic isolation system, which is called TAMA Seismic\nAttenuation System, for the four test masses. We confirmed stable mass locks of\na cavity and improvements of length and angular fluctuations by using two SASs.\nWe are currently optimizing the performance of the third and fourth SASs. We\ncontinue TAMA300 operation and R&D studies for LCGT. Next data taking in the\nsummer of 2007 is planned.\n  CLIO is a 100-m baseline length prototype detector for LCGT to investigate\ninterferometer performance in cryogenic condition. The key features of CLIO are\nthat it locates Kamioka underground site for low seismic noise level, and\nadopts cryogenic Sapphire mirrors for low thermal noise level. The first\noperation of the cryogenic interferometer was successfully demonstrated in\nFebruary of 2006. Current sensitivity at room temperature is close to the\ntarget sensitivity within a factor of 4. Several observation experiments at\nroom temperature have been done. Once the displacement noise reaches at thermal\nnoise level of room temperature, its improvement by cooling test mass mirrors\nshould be demonstrated.\n\n", "human_text": "  Current status of TAMA and CLIO detectors in Japan is reported in this\narticle. These two interferometric gravitational-wave detectors are being\ndeveloped for the large cryogenic gravitational wave telescope (LCGT) which is\na future plan for detecting gravitational wave signals at least once per year.\n  TAMA300 is being upgraded to improve the sensitivity in low frequency region\nafter the last observation experiment in 2004. To reduce the seismic noises, we\nare installing new seismic isolation system, which is called TAMA Seismic\nAttenuation System, for the four test masses. We confirmed stable mass locks of\na cavity and improvements of length and angular fluctuations by using two SASs.\nWe are currently optimizing the performance of the third and fourth SASs. We\ncontinue TAMA300 operation and R&D studies for LCGT. Next data taking in the\nsummer of 2007 is planned.\n  CLIO is a 100-m baseline length prototype detector for LCGT to investigate\ninterferometer performance in cryogenic condition. The key features of CLIO are\nthat it locates Kamioka underground site for low seismic noise level, and\nadopts cryogenic Sapphire mirrors for low thermal noise level. The first\noperation of the cryogenic interferometer was successfully demonstrated in\nFebruary of 2006. Current sensitivity at room temperature is close to the\ntarget sensitivity within a factor of 4. Several observation experiments at\nroom temperature have been done. Once the displacement noise reaches at thermal\nnoise level of room temperature, its improvement by cooling test mass mirrors\nshould be demonstrated.\n", "machine_text": "This article discusses the current status of two interferometric gravitational wave detectors, TAMA300 and CLIO, being developed for the large cryogenic gravitational wave telescope (LCGT) in Japan. TAMA300 is being upgraded to increase sensitivity in the lower frequency region after the last observation experiment in 2004, with the addition of the TAMA Seismic Attenuation System. CLIO is a 100-m prototype aiming to improve the interferometer's performance in cryogenic conditions. The first operation of the cryogenic interferometer was successfully demonstrated in February of 2006 and current sensitivity at room temperature is close to the target sensitivity, with various observation experiments being conducted. Once the displacement noise is similar to the thermal noise level of room temperature, the improvement of cooling test mass mirrors will be demonstrated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2881}
{"prompt": "Rephrase the abstract of an article with title 'Clustering by soft-constraint affinity propagation: Applications to\n  gene-expression data'.\n  Motivation: Similarity-measure based clustering is a crucial problem\nappearing throughout scientific data analysis. Recently, a powerful new\nalgorithm called Affinity Propagation (AP) based on message-passing techniques\nwas proposed by Frey and Dueck \\cite{Frey07}. In AP, each cluster is identified\nby a common exemplar all other data points of the same cluster refer to, and\nexemplars have to refer to themselves. Albeit its proved power, AP in its\npresent form suffers from a number of drawbacks. The hard constraint of having\nexactly one exemplar per cluster restricts AP to classes of regularly shaped\nclusters, and leads to suboptimal performance, {\\it e.g.}, in analyzing gene\nexpression data. Results: This limitation can be overcome by relaxing the AP\nhard constraints. A new parameter controls the importance of the constraints\ncompared to the aim of maximizing the overall similarity, and allows to\ninterpolate between the simple case where each data point selects its closest\nneighbor as an exemplar and the original AP. The resulting soft-constraint\naffinity propagation (SCAP) becomes more informative, accurate and leads to\nmore stable clustering. Even though a new {\\it a priori} free-parameter is\nintroduced, the overall dependence of the algorithm on external tuning is\nreduced, as robustness is increased and an optimal strategy for parameter\nselection emerges more naturally. SCAP is tested on biological benchmark data,\nincluding in particular microarray data related to various cancer types. We\nshow that the algorithm efficiently unveils the hierarchical cluster structure\npresent in the data sets. Further on, it allows to extract sparse gene\nexpression signatures for each cluster.\n\n", "human_text": "  Motivation: Similarity-measure based clustering is a crucial problem\nappearing throughout scientific data analysis. Recently, a powerful new\nalgorithm called Affinity Propagation (AP) based on message-passing techniques\nwas proposed by Frey and Dueck \\cite{Frey07}. In AP, each cluster is identified\nby a common exemplar all other data points of the same cluster refer to, and\nexemplars have to refer to themselves. Albeit its proved power, AP in its\npresent form suffers from a number of drawbacks. The hard constraint of having\nexactly one exemplar per cluster restricts AP to classes of regularly shaped\nclusters, and leads to suboptimal performance, {\\it e.g.}, in analyzing gene\nexpression data. Results: This limitation can be overcome by relaxing the AP\nhard constraints. A new parameter controls the importance of the constraints\ncompared to the aim of maximizing the overall similarity, and allows to\ninterpolate between the simple case where each data point selects its closest\nneighbor as an exemplar and the original AP. The resulting soft-constraint\naffinity propagation (SCAP) becomes more informative, accurate and leads to\nmore stable clustering. Even though a new {\\it a priori} free-parameter is\nintroduced, the overall dependence of the algorithm on external tuning is\nreduced, as robustness is increased and an optimal strategy for parameter\nselection emerges more naturally. SCAP is tested on biological benchmark data,\nincluding in particular microarray data related to various cancer types. We\nshow that the algorithm efficiently unveils the hierarchical cluster structure\npresent in the data sets. Further on, it allows to extract sparse gene\nexpression signatures for each cluster.\n", "machine_text": "\nThe article 'Clustering by soft-constraint affinity propagation: Applications to gene-expression data' aims to develop a new clustering algorithm that overcomes limitations of the existing Affinity Propagation algorithm (AP). This new algorithm, termed Soft-Constraint Affinity Propagation (SCAP), introduces a parameter which modulates the importance of constraints compared to the aim of maximizing overall similarity. This modification enables SCAP to effectively analyze gene expression data as it is more accurate and more stable, decreasing the requirements of external parameter tuning. This new technique is tested on biological benchmark data such as microarray data related to cancer types, showing its efficiency to spotlight hierarchical clusters in the data and the capability to extract sparse gene expression signatures for each cluster.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2646}
{"prompt": "Rephrase the abstract of an article with title 'Modelling long-term trends in lunar exposure to the Earth's plasmasheet'.\n  This paper shows how the exposure of the Moon to the Earth's plasmasheet is\nsubject to decadal variations due to lunar precession. The latter is a key\nproperty of the Moon's apparent orbit around the Earth - the nodes of that\norbit precess around the ecliptic, completing one revolution every 18.6 years.\nThis precession is responsible for a number of astronomical phenomena, e.g. the\nyear to year drift of solar and lunar eclipse periods. It also controls the\necliptic latitude at which the Moon crosses the magnetotail and thus the number\nand duration of lunar encounters with the plasmasheet. This paper presents a\ndetailed model of those encounters and applies it to the period 1960 to 2030.\nThis shows that the total lunar exposure to the plasmasheet will vary from 10\nhours per month at a minimum of the eighteen-year cycle rising to 40 hours per\nmonth at the maximum. These variations could have a profound impact on the\naccumulation of charge due plasmasheet electrons impacting the lunar surface.\nThus we should expect the level of lunar surface charging to vary over the\neighteen-year cycle. The literature contains reports that support this: several\nobservations made during the cycle maximum of 1994-2000 are attributed to\nbombardment and charging of the lunar surface by plasmasheet electrons. Thus we\nconclude that lunar surface charging will vary markedly over an eighteen-year\ncycle driven by lunar precession. It is important to interpret lunar\nenvironment measurements in the context of this cycle and to allow for the\ncycle when designing equipment for deployment on the lunar surface. This is\nparticularly important in respect of developing plans for robotic exploration\non the lunar surface during the next cycle maximum of 2012-19.\n\n", "human_text": "  This paper shows how the exposure of the Moon to the Earth's plasmasheet is\nsubject to decadal variations due to lunar precession. The latter is a key\nproperty of the Moon's apparent orbit around the Earth - the nodes of that\norbit precess around the ecliptic, completing one revolution every 18.6 years.\nThis precession is responsible for a number of astronomical phenomena, e.g. the\nyear to year drift of solar and lunar eclipse periods. It also controls the\necliptic latitude at which the Moon crosses the magnetotail and thus the number\nand duration of lunar encounters with the plasmasheet. This paper presents a\ndetailed model of those encounters and applies it to the period 1960 to 2030.\nThis shows that the total lunar exposure to the plasmasheet will vary from 10\nhours per month at a minimum of the eighteen-year cycle rising to 40 hours per\nmonth at the maximum. These variations could have a profound impact on the\naccumulation of charge due plasmasheet electrons impacting the lunar surface.\nThus we should expect the level of lunar surface charging to vary over the\neighteen-year cycle. The literature contains reports that support this: several\nobservations made during the cycle maximum of 1994-2000 are attributed to\nbombardment and charging of the lunar surface by plasmasheet electrons. Thus we\nconclude that lunar surface charging will vary markedly over an eighteen-year\ncycle driven by lunar precession. It is important to interpret lunar\nenvironment measurements in the context of this cycle and to allow for the\ncycle when designing equipment for deployment on the lunar surface. This is\nparticularly important in respect of developing plans for robotic exploration\non the lunar surface during the next cycle maximum of 2012-19.\n", "machine_text": "\nThis research investigates the impact of lunar precession on the Moon's exposure to Earth's plasmasheet over a period of time. Precession, which is one of the Moon's major orbit properties, causes its nodes to rotate around the ecliptic in a complete revolution every 18.6 years that causes many astronomical events such as drift of solar and lunar eclipses. This study demonstrates how its orbit affects the Moon's encounters with the plasmasheet and estimates that from 1960 to 2030 this amounted to up to 40 hours per month at the apex of the 18-year cycle and 10 hours per month at its minimum. Furthermore, this fluctuation could potentially lead to a significant change in the level of lunar surface charging due to incoming plasmasheet electrons. Evidence for this is found in many measurements taken during the 1994-2000 maxima cycle, where bombardment and charging of the lunar surface is suspected to have occurred. Finally, this research highlights that lunar environment analysis should take into account the precession cycle of the Moon, particularly when designing lunar exploration devices for the upcoming 2012-19 maxima cycle.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0873}
{"prompt": "Rephrase the abstract of an article with title 'Multiwavelength study of massive galaxies at z~2. II. Widespread Compton\n  thick AGN and the concurrent growth of black holes and bulges'.\n  Approximately 20-30% of 1.4<z<2.5 galaxies with K<22 (Vega) detected with\nSpitzer MIPS at 24um show excess mid-IR emission relative to that expected\nbased on the rates of star formation measured from other multiwavelength\ndata.These galaxies also display some near-IR excess in Spitzer IRAC data, with\na spectral energy distribution peaking longward of 1.6um in the rest frame,\nindicating the presence of warm-dust emission usually absent in star forming\ngalaxies. Stacking Chandra data for the mid-IR excess galaxies yields a\nsignificant hard X-ray detection at rest-frame energies >6.2 keV. The stacked\nX-ray spectrum rises steeply at >10 keV, suggesting that these sources host\nCompton-thick Active Galactic Nuclei (AGNs) with column densities N_H~10^{24}\ncm^-2 and an average, unobscured X-ray luminosity L_{2-8 keV}~(1-4)x10^43\nerg/s. Their sky density(~3200 deg^-2) and space density (~2.6x10^-4 Mpc^-3)\nare twice those of X-ray detected AGNs at z~2, and much larger than those of\npreviously-known Compton thick sources at similar redshifts. The mid-IR excess\ngalaxies are part of the long sought-after population of distant heavily\nobscured AGNs predicted by synthesis models of the X-ray background. The\nfraction of mid-IR excess objects increases with galaxy mass, reaching ~50-60%\nfor M~10^11 M_sun, an effect likely connected with downsizing in galaxy\nformation. The ratio of theinferred black hole growth rate from these\nCompton-thick sources to the global star formation rate at z=2 is similar to\nthe mass ratio of black holes to stars inlocal spheroids, implying concurrent\ngrowth of both within the precursors oftoday's massive galaxies.\n\n", "human_text": "  Approximately 20-30% of 1.4<z<2.5 galaxies with K<22 (Vega) detected with\nSpitzer MIPS at 24um show excess mid-IR emission relative to that expected\nbased on the rates of star formation measured from other multiwavelength\ndata.These galaxies also display some near-IR excess in Spitzer IRAC data, with\na spectral energy distribution peaking longward of 1.6um in the rest frame,\nindicating the presence of warm-dust emission usually absent in star forming\ngalaxies. Stacking Chandra data for the mid-IR excess galaxies yields a\nsignificant hard X-ray detection at rest-frame energies >6.2 keV. The stacked\nX-ray spectrum rises steeply at >10 keV, suggesting that these sources host\nCompton-thick Active Galactic Nuclei (AGNs) with column densities N_H~10^{24}\ncm^-2 and an average, unobscured X-ray luminosity L_{2-8 keV}~(1-4)x10^43\nerg/s. Their sky density(~3200 deg^-2) and space density (~2.6x10^-4 Mpc^-3)\nare twice those of X-ray detected AGNs at z~2, and much larger than those of\npreviously-known Compton thick sources at similar redshifts. The mid-IR excess\ngalaxies are part of the long sought-after population of distant heavily\nobscured AGNs predicted by synthesis models of the X-ray background. The\nfraction of mid-IR excess objects increases with galaxy mass, reaching ~50-60%\nfor M~10^11 M_sun, an effect likely connected with downsizing in galaxy\nformation. The ratio of theinferred black hole growth rate from these\nCompton-thick sources to the global star formation rate at z=2 is similar to\nthe mass ratio of black holes to stars inlocal spheroids, implying concurrent\ngrowth of both within the precursors oftoday's massive galaxies.\n", "machine_text": "\nAt redshifts of 1.4<z<2.5 and with K magnitudes of -22 (in the Vega system), approximately 20-30% of galaxies seen by the Spitzer Multiband Imaging Photometer for Spitzer (MIPS) at 24um show more mid-IR emission than is expected from the amount of star formation seen in other multiwavelength data. These same galaxies also have a near-IR infrared excess, with the rest-frame spectral energy distribution peaking longward of 1.6um. When stacking Chandra X-ray data for these galaxies, a significant hard X-ray detection is found at rest-frame energies >6.2 keV. Furthermore, the X-ray spectrum increases steeply at >10 keV, indicating the presence of obscured AGN (Active Galactic Nuclei) with N_H~10^24 cm^-2 and L_{2-8keV}~(1-4)x10^43 erg/s. The large sky and space densities of these mid-IR excess galaxies suggest a previously unknown population of distant, heavily obscured AGN, as was theorized through X-ray background synthesis models. As galaxy mass increases to M~10^11 M_sun, the fraction of the galaxies with mid-IR excess also increases, reaching ~50-60%. This can be attributed to 'downsizing' in galaxy formation. Comparing the inferred black hole growth to the global star formation rate gives a ratio of blackhole to stellar mass similar to that of galaxies in the local universe today, showing concurrent growth of both as massive galaxies form.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2832}
{"prompt": "Rephrase the abstract of an article with title 'The Baryon Fractions and Mass-to-Light Ratios of Early-Type Galaxies'.\n  We jointly model 22 early-type gravitational lens galaxies with stellar\ndynamical measurements using standard CDM halo models. The sample is\ninhomogeneous in both its mass distributions and the evolution of its stellar\npopulations unless the true uncertainties are significantly larger than the\nreported measurement errors. In general, the individual systems cannot\nconstrain halo models, in the sense that the data poorly constrains the stellar\nmass fraction of the halo. The ensemble of systems, however, strongly\nconstrains the average stellar mass represented by the visible galaxies to\n$0.026\\pm0.006$ of the halo mass if we neglect adiabatic compression, rising to\n$0.056\\pm0.011$ of the halo mass if we include adiabatic compression. Both\nestimates are significantly smaller than the global baryon fraction,\ncorresponding to a star formation efficiency for early-type galaxies of\n$10%-30%$. In the adiabatically compressed models, we find an average local\nB-band stellar mass-to-light ratio of $(M/L)_0 =\n(7.2\\pm0.5)(M_{\\sun}/L_{\\sun})$ that evolves by $d\\log(M/L)/dz = -0.72\\pm0.08$\nper unit redshift. Adjusting the isotropy of the stellar orbits has little\neffect on the results. The adiabatically compressed models are strongly favored\nif we impose either local estimates of the mass-to-light ratios of early-type\ngalaxies or the weak lensing measurements for the lens galaxies on 100 kpc\nscales as model constraints.\n\n", "human_text": "  We jointly model 22 early-type gravitational lens galaxies with stellar\ndynamical measurements using standard CDM halo models. The sample is\ninhomogeneous in both its mass distributions and the evolution of its stellar\npopulations unless the true uncertainties are significantly larger than the\nreported measurement errors. In general, the individual systems cannot\nconstrain halo models, in the sense that the data poorly constrains the stellar\nmass fraction of the halo. The ensemble of systems, however, strongly\nconstrains the average stellar mass represented by the visible galaxies to\n$0.026\\pm0.006$ of the halo mass if we neglect adiabatic compression, rising to\n$0.056\\pm0.011$ of the halo mass if we include adiabatic compression. Both\nestimates are significantly smaller than the global baryon fraction,\ncorresponding to a star formation efficiency for early-type galaxies of\n$10%-30%$. In the adiabatically compressed models, we find an average local\nB-band stellar mass-to-light ratio of $(M/L)_0 =\n(7.2\\pm0.5)(M_{\\sun}/L_{\\sun})$ that evolves by $d\\log(M/L)/dz = -0.72\\pm0.08$\nper unit redshift. Adjusting the isotropy of the stellar orbits has little\neffect on the results. The adiabatically compressed models are strongly favored\nif we impose either local estimates of the mass-to-light ratios of early-type\ngalaxies or the weak lensing measurements for the lens galaxies on 100 kpc\nscales as model constraints.\n", "machine_text": "\nWe analyze 22 early-type galaxies where stellar dynamical measurements have been made, and employ standard cold dark matter halo models to approximate the mass distributions. Our results show that the individual galaxies lack a precise way to constrain the halo models; however, the ensemble of systems provide a strong constraint on the average stellar mass. Our estimates yield a star formation efficiency of 10-30%, and a local B-band stellar mass-to-light ratio of 7.2$(M_{\\sun}/L_{\\sun})$ per unit redshift, which can be loosely verified by local estimates and weak lensing measurements. Adjusting the stellar orbits has a minimal effect on our results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3647}
{"prompt": "Rephrase the abstract of an article with title 'Possible X-ray diagnostic for jet/disk dominance in Type 1 AGN'.\n  Using Rossi X-ray Timing Explorer Seyfert 1 and 1.2 data spanning 9 years, we\nstudy correlations between X-ray spectral features. The sample consists of 350\ntime-resolved spectra from 12 Seyfert 1 and 1.2 galaxies. Each spectrum is\nfitted to a model with an intrinsic powerlaw X-ray spectrum produced close to\nthe central black hole that is reprocessed and absorbed by material around the\nblack hole. To test the robustness of our results, we performed Monte Carlo\nsimulations of the spectral sample. We find a complex relationship between the\niron line equivalent width (EW) and the underlying power law index (Gamma). The\ndata reveal a correlation between Gamma and EW which turns over at Gamma <~ 2,\nbut finds a weak anti-correlation for steeper photon indices. We propose that\nthis relationship is driven by dilution of a disk spectrum (which includes the\nnarrow iron line) by a beamed jet component and, hence, could be used as a\ndiagnostic of jet-dominance. In addition, our sample shows a strong correlation\nbetween the reflection fraction (R) and Gamma, but we find that it is likely\nthe result of modeling degeneracies. We also see the X-ray Baldwin effect (an\nanti-correlation between the 2-10 keV X-ray luminosity and EW) for the sample\nas a whole, but not for the individual galaxies and galaxy types.\n\n", "human_text": "  Using Rossi X-ray Timing Explorer Seyfert 1 and 1.2 data spanning 9 years, we\nstudy correlations between X-ray spectral features. The sample consists of 350\ntime-resolved spectra from 12 Seyfert 1 and 1.2 galaxies. Each spectrum is\nfitted to a model with an intrinsic powerlaw X-ray spectrum produced close to\nthe central black hole that is reprocessed and absorbed by material around the\nblack hole. To test the robustness of our results, we performed Monte Carlo\nsimulations of the spectral sample. We find a complex relationship between the\niron line equivalent width (EW) and the underlying power law index (Gamma). The\ndata reveal a correlation between Gamma and EW which turns over at Gamma <~ 2,\nbut finds a weak anti-correlation for steeper photon indices. We propose that\nthis relationship is driven by dilution of a disk spectrum (which includes the\nnarrow iron line) by a beamed jet component and, hence, could be used as a\ndiagnostic of jet-dominance. In addition, our sample shows a strong correlation\nbetween the reflection fraction (R) and Gamma, but we find that it is likely\nthe result of modeling degeneracies. We also see the X-ray Baldwin effect (an\nanti-correlation between the 2-10 keV X-ray luminosity and EW) for the sample\nas a whole, but not for the individual galaxies and galaxy types.\n", "machine_text": "\nWe present a novel approach to determine jet/disk dominance in Type 1 Active Galactic Nuclei (AGN) by exploring the correlation between X-ray spectral features observed through the Rossi X-ray Timing Explorer. Our study, comprising nine years of time-resolved spectra from 350 Seyfert galaxies, finds a possible connection between the iron line equivalent width and the underlying power law index. It appears that the lower the power law index, the higher the iron line equivalent width, suggesting the diminishing of the disk spectrum by a beamed jet component. We additionally observe a strong correlation between the reflection fraction and Gamma, though this may be caused by modeling degeneracies. Finally, we discover the X-ray Baldwin effect, which shows an anti-correlation between 2-10 keV X-ray luminosity and EW for the sample as a whole but not for the individual galaxies or galaxy types. Thus, this study provides a viable method of determining jet/disk dominance in type 1 AGN.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1587}
{"prompt": "Rephrase the abstract of an article with title 'Third-order cosmological perturbations of zero-pressure multi-component\n  fluids: Pure general relativistic nonlinear effects'.\n  Present expansion stage of the universe is believed to be mainly governed by\nthe cosmological constant, collisionless dark matter and baryonic matter. The\nlatter two components are often modeled as zero-pressure fluids. In our\nprevious work we have shown that to the second-order cosmological\nperturbations, the relativistic equations of the zero-pressure, irrotational,\nmulti-component fluids in a spatially near flat background effectively coincide\nwith the Newtonian equations. As the Newtonian equations only have quadratic\norder nonlinearity, it is practically interesting to derive the potential\nthird-order perturbation terms in general relativistic treatment which\ncorrespond to pure general relativistic corrections. Here, we present pure\ngeneral relativistic correction terms appearing in the third-order\nperturbations of the multi-component zero-pressure fluids. We show that, as in\na single component situation, the third-order correction terms are quite small\n(~ 5 x10^{-5} smaller compared with the relativistic/Newtonian second-order\nterms) due to the weak level anisotropy of the cosmic microwave background\nradiation. Still, there do exist pure general relativistic correction terms in\nthird-order perturbations which could potentially become important in future\ndevelopment of precision cosmology. We include the cosmological constant in all\nour analyses.\n\n", "human_text": "  Present expansion stage of the universe is believed to be mainly governed by\nthe cosmological constant, collisionless dark matter and baryonic matter. The\nlatter two components are often modeled as zero-pressure fluids. In our\nprevious work we have shown that to the second-order cosmological\nperturbations, the relativistic equations of the zero-pressure, irrotational,\nmulti-component fluids in a spatially near flat background effectively coincide\nwith the Newtonian equations. As the Newtonian equations only have quadratic\norder nonlinearity, it is practically interesting to derive the potential\nthird-order perturbation terms in general relativistic treatment which\ncorrespond to pure general relativistic corrections. Here, we present pure\ngeneral relativistic correction terms appearing in the third-order\nperturbations of the multi-component zero-pressure fluids. We show that, as in\na single component situation, the third-order correction terms are quite small\n(~ 5 x10^{-5} smaller compared with the relativistic/Newtonian second-order\nterms) due to the weak level anisotropy of the cosmic microwave background\nradiation. Still, there do exist pure general relativistic correction terms in\nthird-order perturbations which could potentially become important in future\ndevelopment of precision cosmology. We include the cosmological constant in all\nour analyses.\n", "machine_text": "\nIn this article, we analyze the effect of pure general relativistic corrections on third-order cosmological perturbations for a system of zero-pressure, irrotational, multi-component fluids in a spatially near flat background. We observe small (~ 5 x10^{-5} smaller compared with the relativistic/Newtonian second-order terms) anisotropies in the cosmic microwave background radiation, indicating the presence of pure general relativistic corrections in the third-order perturbations. In spite of this, we conclude that these corrections are insignificant at its current stage yet could become essential in the future of precision cosmology. The effects of the cosmological constant are taken into account throughout our exploration.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2086}
{"prompt": "Rephrase the abstract of an article with title 'Electro-optically tunable microring resonators in lithium niobate'.\n  Optical microresonators have recently attracted a growing attention in the\nphotonics community. Their applications range from quantum electro-dynamics to\nsensors and filtering devices for optical telecommunication systems, where they\nare likely to become an essential building block. The integration of nonlinear\nand electro-optical properties in the resonators represents a very stimulating\nchallenge, as it would incorporate new and more advanced functionality. Lithium\nniobate is an excellent candidate material, being an established choice for\nelectro-optic and nonlinear optical applications. Here we report on the first\nrealization of optical microring resonators in submicrometric thin films of\nlithium niobate. The high index contrast films are produced by an improved\ncrystal ion slicing and bonding technique using benzocyclobutene. The rings\nhave radius R=100 um and their transmission spectrum has been tuned using the\nelectro-optic effect. These results open new perspectives for the use of\nlithium niobate in chip-scale integrated optical devices and nonlinear optical\nmicrocavities.\n\n", "human_text": "  Optical microresonators have recently attracted a growing attention in the\nphotonics community. Their applications range from quantum electro-dynamics to\nsensors and filtering devices for optical telecommunication systems, where they\nare likely to become an essential building block. The integration of nonlinear\nand electro-optical properties in the resonators represents a very stimulating\nchallenge, as it would incorporate new and more advanced functionality. Lithium\nniobate is an excellent candidate material, being an established choice for\nelectro-optic and nonlinear optical applications. Here we report on the first\nrealization of optical microring resonators in submicrometric thin films of\nlithium niobate. The high index contrast films are produced by an improved\ncrystal ion slicing and bonding technique using benzocyclobutene. The rings\nhave radius R=100 um and their transmission spectrum has been tuned using the\nelectro-optic effect. These results open new perspectives for the use of\nlithium niobate in chip-scale integrated optical devices and nonlinear optical\nmicrocavities.\n", "machine_text": "The emerging development of optical microresonators presents an extensive range of potential applications from quantum electro-dynamics to optical telecommunications. Now, researchers have successfully implemented electro-optically tunable microring resonators on submicrometric thin films of lithium niobate. This implementation was made possible with an improved crystal ion slicing and bonding technique that utilized benzocyclobutene. With a radius of 100 micrometers, the microring resonators can be tuned using the electro-optic effect, suggesting that lithium niobate can be used in chip-scale integrated optical devices and nonlinear optical microcavities. As such, it potentially offers more innovative functionality and a greater degree of control over traditional devices.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2392}
{"prompt": "Rephrase the abstract of an article with title 'Odd-frequency pairing in normal metal/superconductor junctions'.\n  We study the induced odd-frequency pairing states in ballistic normal\nmetal/superconductor (N/S) junctions where a superconductor has even-frequency\nsymmetry in the bulk and a normal metal layer has an arbitrary length. Using\nthe quasiclassical Green's function formalism, we demonstrate that, quite\ngenerally, the pair amplitude in the junction has an admixture of an\nodd-frequency component due to the breakdown of translational invariance near\nthe N/S interface where the pair potential acquires spatial dependence. If a\nsuperconductor has even-parity pair potential (spin-singlet s-wave state), the\nodd-frequency pairing component with odd-parity is induced near the N/S\ninterface, while in the case of odd-parity pair potential (spin-triplet\n$p_{x}$-wave or spin-singlet $d_{xy}$-wave) the odd-frequency component with\neven-parity is generated. We show that in conventional s-wave junctions, the\namplitude of the odd-frequency pairing state is enhanced at energies\ncorresponding to the peaks in the local density of states (LDOS). In $p_x$- and\n$d_{xy}$-wave junctions, the amplitude of the odd-frequency component on the S\nside of the N/S interface is enhanced at zero energy where the midgap Andreev\nresonant state (MARS) appears due to the sign change of the pair potential. The\nodd-frequency component extends into the N region and exceeds the\neven-frequency component at energies corresponding to the LDOS peak positions,\nincluding the MARS.\n\n", "human_text": "  We study the induced odd-frequency pairing states in ballistic normal\nmetal/superconductor (N/S) junctions where a superconductor has even-frequency\nsymmetry in the bulk and a normal metal layer has an arbitrary length. Using\nthe quasiclassical Green's function formalism, we demonstrate that, quite\ngenerally, the pair amplitude in the junction has an admixture of an\nodd-frequency component due to the breakdown of translational invariance near\nthe N/S interface where the pair potential acquires spatial dependence. If a\nsuperconductor has even-parity pair potential (spin-singlet s-wave state), the\nodd-frequency pairing component with odd-parity is induced near the N/S\ninterface, while in the case of odd-parity pair potential (spin-triplet\n$p_{x}$-wave or spin-singlet $d_{xy}$-wave) the odd-frequency component with\neven-parity is generated. We show that in conventional s-wave junctions, the\namplitude of the odd-frequency pairing state is enhanced at energies\ncorresponding to the peaks in the local density of states (LDOS). In $p_x$- and\n$d_{xy}$-wave junctions, the amplitude of the odd-frequency component on the S\nside of the N/S interface is enhanced at zero energy where the midgap Andreev\nresonant state (MARS) appears due to the sign change of the pair potential. The\nodd-frequency component extends into the N region and exceeds the\neven-frequency component at energies corresponding to the LDOS peak positions,\nincluding the MARS.\n", "machine_text": "\nThis article investigates the emergence of odd-frequency pairing states generated within normal metal/superconductor (N/S) junctions. Utilizing the quasiclassical Green's function formalism, we illustrate the ways in which translational invariance breakdown near the N/S interface allows for the generation of odd-frequency pair amplitudes. With an even-parity pairing potential (i.e. traditional spin-singlet s-wave states) in the superconductor, an odd-parity odd-frequency component will be induced at the interface. In the event of an odd-parity potential (including spin-triplet $p_{x}$-wave or spin-singlet $d_{xy}$-wave states), the odd-frequency component created has an even-parity character. Additionally, in conventional s-wave junctions, the amplitude of the odd-frequency pairing state is intensified at energy values corresponding to local density of states peaks. Furthermore, in $p_x$- and $d_{xy}$-wave junctions, the odd-frequency component at the superconductor side of the interface is bolstered at zero-energy, with midgap Andreev resonant state (MARS). Ultimately, this odd-frequency pairing extends across the N region, and surpasses the even-frequency pairing at the LDOS peak-energies, incorporating the MARS.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2506}
{"prompt": "Rephrase the abstract of an article with title 'Near-Infrared Spectra of the Black Hole X-Ray Binary, A0620-00'.\n  We present broadband NIR spectra of A0620-00 obtained with SpeX on the IRTF.\nThe spectrum is characterized by a blue continuum on which are superimposed\nbroad emission lines of HI and HeII and a host of narrower absorption lines of\nneutral metals and molecules. Spectral type standard star spectra scaled to the\ndereddened spectrum of A0620-00 in K exceed the A0620-00 spectrum in J and H\nfor all stars of spectral type K7V or earlier, demonstrating that the donor\nstar, unless later than K7V, cannot be the sole NIR flux source in A0620-00. In\naddition, the atomic absorption lines in the K3V spectrum are too weak with\nrespect to those of A0620-00 even at 100% donor star contribution, restricting\nthe spectral type of the donor star in A0620-00 to later than K3V. Comparison\nof the A0620-00 spectrum to scaled K star spectra indicates that the CO\nabsorption features are significantly weaker in A0620-00 than in field dwarf\nstars. Fits of scaled model spectra of a Roche lobe-filling donor star to the\nspectrum of A0620-00 show that the best match to the CO absorption lines is\nobtained when the C abundance is reduced to [C/H] = -1.5. The donor star\ncontribution in the H waveband is determined to be 82+-2%. Combined with\nprevious published results from Froning & Robinson (2001) and Marsh et al.\n(1994), this gives a precise mass for the black hole in A0620-00 of M_BH =\n9.7+-0.6 M_solar.\n\n", "human_text": "  We present broadband NIR spectra of A0620-00 obtained with SpeX on the IRTF.\nThe spectrum is characterized by a blue continuum on which are superimposed\nbroad emission lines of HI and HeII and a host of narrower absorption lines of\nneutral metals and molecules. Spectral type standard star spectra scaled to the\ndereddened spectrum of A0620-00 in K exceed the A0620-00 spectrum in J and H\nfor all stars of spectral type K7V or earlier, demonstrating that the donor\nstar, unless later than K7V, cannot be the sole NIR flux source in A0620-00. In\naddition, the atomic absorption lines in the K3V spectrum are too weak with\nrespect to those of A0620-00 even at 100% donor star contribution, restricting\nthe spectral type of the donor star in A0620-00 to later than K3V. Comparison\nof the A0620-00 spectrum to scaled K star spectra indicates that the CO\nabsorption features are significantly weaker in A0620-00 than in field dwarf\nstars. Fits of scaled model spectra of a Roche lobe-filling donor star to the\nspectrum of A0620-00 show that the best match to the CO absorption lines is\nobtained when the C abundance is reduced to [C/H] = -1.5. The donor star\ncontribution in the H waveband is determined to be 82+-2%. Combined with\nprevious published results from Froning & Robinson (2001) and Marsh et al.\n(1994), this gives a precise mass for the black hole in A0620-00 of M_BH =\n9.7+-0.6 M_solar.\n", "machine_text": "\nWe have obtained broadband near-infrared (NIR) spectra of A0620-00 using the SpeX instrument on the Infrared Telescope Facility. The spectrum reveals a blue continuum with broad emission lines of hydrogen and helium, and narrower absorption lines of neutral metals and molecules. Comparison with scaled spectral type standard stars shows that the donor star has to be later than K3V, while its contribution to the NIR flux is determined to be 82+-2%. These observations, taken in conjunction with data from Froning & Robinson (2001) and Marsh et al. (1994), allow us to accurately calculate the black hole mass of A0620-00 as 9.7+-0.6 solar masses. Furthermore, signs of lower carbon abundance in A0620-00 compared to field dwarf stars are indicated by the observed CO absorption features.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0267}
{"prompt": "Rephrase the abstract of an article with title 'Network Topology of an Experimental Futures Exchange'.\n  Many systems of different nature exhibit scale free behaviors. Economic\nsystems with power law distribution in the wealth is one of the examples. To\nbetter understand the working behind the complexity, we undertook an empirical\nstudy measuring the interactions between market participants. A Web server was\nsetup to administer the exchange of futures contracts whose liquidation prices\nwere coupled to event outcomes. After free registration, participants started\ntrading to compete for the money prizes upon maturity of the futures contracts\nat the end of the experiment. The evolving `cash' flow network was\nreconstructed from the transactions between players. We show that the network\ntopology is hierarchical, disassortative and scale-free with a power law\nexponent of 1.02+-0.09 in the degree distribution. The small-world property\nemerged early in the experiment while the number of participants was still\nsmall. We also show power law distributions of the net incomes and\ninter-transaction time intervals. Big winners and losers are associated with\nhigh degree, high betweenness centrality, low clustering coefficient and low\ndegree-correlation. We identify communities in the network as groups of the\nlike-minded. The distribution of the community sizes is shown to be power-law\ndistributed with an exponent of 1.19+-0.16.\n\n", "human_text": "  Many systems of different nature exhibit scale free behaviors. Economic\nsystems with power law distribution in the wealth is one of the examples. To\nbetter understand the working behind the complexity, we undertook an empirical\nstudy measuring the interactions between market participants. A Web server was\nsetup to administer the exchange of futures contracts whose liquidation prices\nwere coupled to event outcomes. After free registration, participants started\ntrading to compete for the money prizes upon maturity of the futures contracts\nat the end of the experiment. The evolving `cash' flow network was\nreconstructed from the transactions between players. We show that the network\ntopology is hierarchical, disassortative and scale-free with a power law\nexponent of 1.02+-0.09 in the degree distribution. The small-world property\nemerged early in the experiment while the number of participants was still\nsmall. We also show power law distributions of the net incomes and\ninter-transaction time intervals. Big winners and losers are associated with\nhigh degree, high betweenness centrality, low clustering coefficient and low\ndegree-correlation. We identify communities in the network as groups of the\nlike-minded. The distribution of the community sizes is shown to be power-law\ndistributed with an exponent of 1.19+-0.16.\n", "machine_text": "This article presents the results of an experimental study of the network topology of a Futures Exchange. Using a web server set up to simulate exchanging futures contracts coupled to event outcomes, participants were allowed to register and compete for money prizes upon maturity of the contracts. The interactions between market participants were measured and the cash flow networks was reconstructed from the transactions. The results show that the topology of the network is hierarchical, disassortative, and scale-free, exhibiting a power law exponent of 1.02+-0.09 in the degree distribution. The study also found that the small-world property emerged early in the experiment while the number of participants was still small and there are power law distributions of the net incomes, inter-transaction time intervals, and the distribution of community sizes, which were found to have an exponent of 1.19+-0.16. Furthermore, the study was able to conclusively link the characteristics of high degree, high betweenness centrality, low clustering coefficient, and low degree-correlation with big winners and losers in the exchange.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2551}
{"prompt": "Rephrase the abstract of an article with title 'Natural Priors, CMSSM Fits and LHC Weather Forecasts'.\n  Previous LHC forecasts for the constrained minimal supersymmetric standard\nmodel (CMSSM), based on current astrophysical and laboratory measurements, have\nused priors that are flat in the parameter tan beta, while being constrained to\npostdict the central experimental value of MZ. We construct a different, new\nand more natural prior with a measure in mu and B (the more fundamental MSSM\nparameters from which tan beta and MZ are actually derived). We find that as a\nconsequence this choice leads to a well defined fine-tuning measure in the\nparameter space. We investigate the effect of such on global CMSSM fits to\nindirect constraints, providing posterior probability distributions for Large\nHadron Collider (LHC) sparticle production cross sections. The change in priors\nhas a significant effect, strongly suppressing the pseudoscalar Higgs boson\ndark matter annihilation region, and diminishing the probable values of\nsparticle masses. We also show how to interpret fit information from a Markov\nChain Monte Carlo in a frequentist fashion; namely by using the profile\nlikelihood. Bayesian and frequentist interpretations of CMSSM fits are compared\nand contrasted.\n\n", "human_text": "  Previous LHC forecasts for the constrained minimal supersymmetric standard\nmodel (CMSSM), based on current astrophysical and laboratory measurements, have\nused priors that are flat in the parameter tan beta, while being constrained to\npostdict the central experimental value of MZ. We construct a different, new\nand more natural prior with a measure in mu and B (the more fundamental MSSM\nparameters from which tan beta and MZ are actually derived). We find that as a\nconsequence this choice leads to a well defined fine-tuning measure in the\nparameter space. We investigate the effect of such on global CMSSM fits to\nindirect constraints, providing posterior probability distributions for Large\nHadron Collider (LHC) sparticle production cross sections. The change in priors\nhas a significant effect, strongly suppressing the pseudoscalar Higgs boson\ndark matter annihilation region, and diminishing the probable values of\nsparticle masses. We also show how to interpret fit information from a Markov\nChain Monte Carlo in a frequentist fashion; namely by using the profile\nlikelihood. Bayesian and frequentist interpretations of CMSSM fits are compared\nand contrasted.\n", "machine_text": "This paper examines different priors for the CMSSM parameters used in LHC forecasts and their effect on fitting to indirect constraints. Our new and more natural prior with a measure in mu and B gives rise to a well defined fine-tuning measure in the parameter space. We demonstrate how our choice alters global CMSSM fits to indirect constraints and discuss its implications on Large Hadron Collider (LHC) sparticle production cross sections, such as the pseudoscalar Higgs boson dark matter annihilation region, and on probable values of sparticle masses. We also compare and contrast Bayesian and frequentist interpretations of CMSSM fits and demonstrate how to interpret fit information from a Markov Chain Monte Carlo in a frequentist fashion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0487}
{"prompt": "Rephrase the abstract of an article with title 'Top production at the Tevatron/LHC and nonstandard, strongly interacting\n  spin one particles'.\n  In this note, we consider possible constraints from $t \\bar t$ production on\nthe gauge bosons of theories with an extended strong interaction sector such as\naxigluons or flavour universal colorons. Such constraints are found to be\ncompetitive with those obtained from the dijet data. The current $t \\bar t$\ndata from the Tevatron rule out axigluon masses ($m_A$) up to 900 GeV and 850\nGeV at 2 $\\sigma$ and 4 $\\sigma$ levels respectively. For the case of flavour\nuniversal colorons the data rule out a mass ($m_C$) below 800 GeV (780 GeV) at\nthe $2 (4) \\sigma $ level and also the mass range between 900 GeV to 2.1 TeV at\n2 $\\sigma$ level, for $\\cot \\xi = 1$, where $\\xi$ is the mixing angle. For\n$\\cot \\xi =2$ on the other hand, the excluded range is $m_C \\lsim 950 (920)$\nGeV and $m_C \\gsim 1.02 (1.15 \\lsim m_C \\lsim 1.8)$ TeV at $2 \\sigma$ ($4\n\\sigma $) level. We point out that for higher axigluon/coloron masses, even for\nthe dijet channel, the limits on the coloron mass, for $\\cot \\xi = 1$, may be\ndifferent than those for the axigluon. We also compute the expected\nforward-backward asymmetry for the case of the axigluons which would allow it\nto be discriminated against the SM as also the colorons. We further find that\nat the LHC, the signal should be visible in the $t \\bar t$ invariant mass\nspectrum for a wide range of axigluon and coloron masses that are still\nallowed. We point out how top polarisation may be used to further discriminate\nthe axigluon and coloron case from the SM as well as from each other.\n\n", "human_text": "  In this note, we consider possible constraints from $t \\bar t$ production on\nthe gauge bosons of theories with an extended strong interaction sector such as\naxigluons or flavour universal colorons. Such constraints are found to be\ncompetitive with those obtained from the dijet data. The current $t \\bar t$\ndata from the Tevatron rule out axigluon masses ($m_A$) up to 900 GeV and 850\nGeV at 2 $\\sigma$ and 4 $\\sigma$ levels respectively. For the case of flavour\nuniversal colorons the data rule out a mass ($m_C$) below 800 GeV (780 GeV) at\nthe $2 (4) \\sigma $ level and also the mass range between 900 GeV to 2.1 TeV at\n2 $\\sigma$ level, for $\\cot \\xi = 1$, where $\\xi$ is the mixing angle. For\n$\\cot \\xi =2$ on the other hand, the excluded range is $m_C \\lsim 950 (920)$\nGeV and $m_C \\gsim 1.02 (1.15 \\lsim m_C \\lsim 1.8)$ TeV at $2 \\sigma$ ($4\n\\sigma $) level. We point out that for higher axigluon/coloron masses, even for\nthe dijet channel, the limits on the coloron mass, for $\\cot \\xi = 1$, may be\ndifferent than those for the axigluon. We also compute the expected\nforward-backward asymmetry for the case of the axigluons which would allow it\nto be discriminated against the SM as also the colorons. We further find that\nat the LHC, the signal should be visible in the $t \\bar t$ invariant mass\nspectrum for a wide range of axigluon and coloron masses that are still\nallowed. We point out how top polarisation may be used to further discriminate\nthe axigluon and coloron case from the SM as well as from each other.\n", "machine_text": "In this article, we analyse production of $t \\bar t$ at the Tevatron and the LHC, and its consequences on the presence of strongly interacting spin one particles such as axigluons and flavour universal colorons. We obtain limits on their masses from $t \\bar t$ data, which are found to be comparable to the those from dijet data. We conclude that top polarisation may be used to further discriminate the axigluon and coloron case from the SM as well as from each other. At the LHC, the signal of the presence of these particles should be visible in the $t \\bar t$ invariant mass spectrum for a wide range of axigluon and coloron masses that are still within these limits.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1499}
{"prompt": "Rephrase the abstract of an article with title 'Chandra Observations of Supernova 1987A'.\n  We have been monitoring Supernova (SN) 1987A with {\\it Chandra X-Ray\nObservatory} since 1999. We present a review of previous results from our {\\it\nChandra} observations, and some preliminary results from new {\\it Chandra} data\nobtained in 2006 and 2007. High resolution imaging and spectroscopic studies of\nSN 1987A with {\\it Chandra} reveal that X-ray emission of SN 1987A originates\nfrom the hot gas heated by interaction of the blast wave with the ring-like\ndense circumstellar medium (CSM) that was produced by the massive progenitor's\nequatorial stellar winds before the SN explosion. The blast wave is now\nsweeping through dense CSM all around the inner ring, and thus SN 1987A is\nrapidly brightening in soft X-rays. At the age of 20 yr (as of 2007 January),\nX-ray luminosity of SN 1987A is $L_{\\rm X}$ $\\sim$ 2.4 $\\times$ 10$^{36}$ ergs\ns$^{-1}$ in the 0.5$-$10 keV band. X-ray emission is described by two-component\nplane shock model with electron temperatures of $kT$ $\\sim$ 0.3 and 2 keV. As\nthe shock front interacts with dense CSM all around the inner ring, the X-ray\nremnant is now expanding at a much slower rate of $v$ $\\sim$ 1400 km s$^{-1}$\nthan it was until 2004 ($v$ $\\sim$ 6000 km s$^{-1}$).\n\n", "human_text": "  We have been monitoring Supernova (SN) 1987A with {\\it Chandra X-Ray\nObservatory} since 1999. We present a review of previous results from our {\\it\nChandra} observations, and some preliminary results from new {\\it Chandra} data\nobtained in 2006 and 2007. High resolution imaging and spectroscopic studies of\nSN 1987A with {\\it Chandra} reveal that X-ray emission of SN 1987A originates\nfrom the hot gas heated by interaction of the blast wave with the ring-like\ndense circumstellar medium (CSM) that was produced by the massive progenitor's\nequatorial stellar winds before the SN explosion. The blast wave is now\nsweeping through dense CSM all around the inner ring, and thus SN 1987A is\nrapidly brightening in soft X-rays. At the age of 20 yr (as of 2007 January),\nX-ray luminosity of SN 1987A is $L_{\\rm X}$ $\\sim$ 2.4 $\\times$ 10$^{36}$ ergs\ns$^{-1}$ in the 0.5$-$10 keV band. X-ray emission is described by two-component\nplane shock model with electron temperatures of $kT$ $\\sim$ 0.3 and 2 keV. As\nthe shock front interacts with dense CSM all around the inner ring, the X-ray\nremnant is now expanding at a much slower rate of $v$ $\\sim$ 1400 km s$^{-1}$\nthan it was until 2004 ($v$ $\\sim$ 6000 km s$^{-1}$).\n", "machine_text": "Since 1999, the {\\it Chandra X-Ray Observatory} has been tracking Supernova\n1987A's activity. Our review of previous results from these observations\nconfirms that the X-ray luminosity of SN 1987A originates from the high-energy\nparticles produced as the blast wave from the SN sweeps through the ring-like\ncircumstellar medium. Now, at the age of 20 years, X-ray emissions reach a peak\nluminosity of  $L_{\\rm X}$ $\\sim$ 2.4 $\\times$ 10$^{36}$ ergs s$^{-1}$ in the\n0.5$-$10 keV band with electron temperatures of $kT$ $\\sim$ 0.3 and 2 keV.\nMeanwhile, the X-ray remnant is gradually expanding at a much slower rate of\nabout 1400 km s$^{-1}$ compared to its velocity of 6000 km s$^{-1}$ in 2004.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0209}
{"prompt": "Rephrase the abstract of an article with title 'Introduction to protein folding for physicists'.\n  The prediction of the three-dimensional native structure of proteins from the\nknowledge of their amino acid sequence, known as the protein folding problem,\nis one of the most important yet unsolved issues of modern science. Since the\nconformational behaviour of flexible molecules is nothing more than a complex\nphysical problem, increasingly more physicists are moving into the study of\nprotein systems, bringing with them powerful mathematical and computational\ntools, as well as the sharp intuition and deep images inherent to the physics\ndiscipline. This work attempts to facilitate the first steps of such a\ntransition. In order to achieve this goal, we provide an exhaustive account of\nthe reasons underlying the protein folding problem enormous relevance and\nsummarize the present-day status of the methods aimed to solving it. We also\nprovide an introduction to the particular structure of these biological\nheteropolymers, and we physically define the problem stating the assumptions\nbehind this (commonly implicit) definition. Finally, we review the 'special\nflavor' of statistical mechanics that is typically used to study the\nastronomically large phase spaces of macromolecules. Throughout the whole work,\nmuch material that is found scattered in the literature has been put together\nhere to improve comprehension and to serve as a handy reference.\n\n", "human_text": "  The prediction of the three-dimensional native structure of proteins from the\nknowledge of their amino acid sequence, known as the protein folding problem,\nis one of the most important yet unsolved issues of modern science. Since the\nconformational behaviour of flexible molecules is nothing more than a complex\nphysical problem, increasingly more physicists are moving into the study of\nprotein systems, bringing with them powerful mathematical and computational\ntools, as well as the sharp intuition and deep images inherent to the physics\ndiscipline. This work attempts to facilitate the first steps of such a\ntransition. In order to achieve this goal, we provide an exhaustive account of\nthe reasons underlying the protein folding problem enormous relevance and\nsummarize the present-day status of the methods aimed to solving it. We also\nprovide an introduction to the particular structure of these biological\nheteropolymers, and we physically define the problem stating the assumptions\nbehind this (commonly implicit) definition. Finally, we review the 'special\nflavor' of statistical mechanics that is typically used to study the\nastronomically large phase spaces of macromolecules. Throughout the whole work,\nmuch material that is found scattered in the literature has been put together\nhere to improve comprehension and to serve as a handy reference.\n", "machine_text": "\nThe protein folding problem - determining the three-dimensional native structure of proteins solely from information about their amino acid sequence - is one of the most important yet unsolved problems in modern science. For this reason, physicists have increasingly begun to tackle this complex physical problem using mathematical and computational tools, as well as the expertise and insight of the physics discipline. This work aims to guide those new to this problem and provides an explanation of its importance and current status of research. An introduction to the particular structure of these biological macro-heteropolymers and the assumptions behind the physical definition of the problem are also included. Moreover, a thorough overview of the statistical mechanics most often used to study macromolecules' huge phase spaces is presented in order to facilitate a better understanding. A synthesis of literature on the subject provides for a comprehensive reference.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1845}
{"prompt": "Rephrase the abstract of an article with title 'Lattice QCD study of a five-quark hadronic molecule'.\n  We compute the ground-state energies of a heavy-light K-Lambda like system as\na function of the relative distance r of the hadrons. The heavy quarks, one in\neach hadron, are treated as static. Then, the energies give rise to an\nadiabatic potential Va(r) which we use to study the structure of the five-quark\nsystem. The simulation is based on an anisotropic and asymmetric lattice with\nWilson fermions. Energies are extracted from spectral density functions\nobtained with the maximum entropy method. Our results are meant to give\nqualitative insight: Using the resulting adiabatic potential in a Schroedinger\nequation produces bound state wave functions which indicate that the ground\nstate of the five-quark system resembles a hadronic molecule, whereas the first\nexcited state, having a very small rms radius, is probably better described as\na five-quark cluster, or a pentaquark. We hypothesize that an all light-quark\npentaquark may not exist, but in the heavy-quark sector it might, albeit only\nas an excited state.\n\n", "human_text": "  We compute the ground-state energies of a heavy-light K-Lambda like system as\na function of the relative distance r of the hadrons. The heavy quarks, one in\neach hadron, are treated as static. Then, the energies give rise to an\nadiabatic potential Va(r) which we use to study the structure of the five-quark\nsystem. The simulation is based on an anisotropic and asymmetric lattice with\nWilson fermions. Energies are extracted from spectral density functions\nobtained with the maximum entropy method. Our results are meant to give\nqualitative insight: Using the resulting adiabatic potential in a Schroedinger\nequation produces bound state wave functions which indicate that the ground\nstate of the five-quark system resembles a hadronic molecule, whereas the first\nexcited state, having a very small rms radius, is probably better described as\na five-quark cluster, or a pentaquark. We hypothesize that an all light-quark\npentaquark may not exist, but in the heavy-quark sector it might, albeit only\nas an excited state.\n", "machine_text": "This study investigates the ground-state energies of a five-quark system composed of a heavy-light K-Lambda configuration using lattice QCD. The potential created by the energies of this system, Va(r), is then utilized to probe its structure. The simulation is based on an anisotropic and asymmetric lattice with Wilson fermions. Employing the maximum entropy method, energies are extracted from corresponding spectral density functions. Our results propose the ground state of this 5-quark system resembles a hadronic molecule, while the first excited state is more likely to be a pentaquark cluster. We postulate that light-quark pentaquarks may not be found in nature, but they may exist in an excited form within the heavy-quark sector.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2385}
{"prompt": "Rephrase the abstract of an article with title '(0,2) Gauged Linear Sigma Model on Supermanifold'.\n  We construct (0,2), D=2 gauged linear sigma model on a supermanifold in both\nthe Abelian gauge group and the non-Abelian gauge group. The $\\hat{U}$ operator\nprovides consistency conditions for satisfying the SUSY invariance. Contrary to\nthe Abelian gauge group, it is not essential to introduce the new operator in\norder to check the exact SUSY invariance of the Lagrangian density. However, in\norder to introduce the (0,2) chiral superfields, we need the $\\hat{U}$\noperator, because we can not define the (0,2) chirality conditions of the (0,2)\nchiral superfields without introducing the new operator by using $\\hat{U}$ and\nthe enlarged operator \\hat{U}^{a} was obtained from the conditions that yield\nthe (0,2) supersymmetric invariance of the Lagrangian density of the (0,2) U(N)\ngauged linear sigma model in superfield formalism. We found that the\nconsistency conditions for the Abelian gauge group which assure the (0,2)\nsupersymmetric invariance of Lagrangian density agree with (0,2) chirality\nconditions for superpotential. The supermanifold \\mathcal{M}^{m|n} becomes the\nsuper weighted complex projective space WCP^{m-1|n} in U(1) case, which is\nconsidered as an example of Calabi-Yau supermanifold.\n\n", "human_text": "  We construct (0,2), D=2 gauged linear sigma model on a supermanifold in both\nthe Abelian gauge group and the non-Abelian gauge group. The $\\hat{U}$ operator\nprovides consistency conditions for satisfying the SUSY invariance. Contrary to\nthe Abelian gauge group, it is not essential to introduce the new operator in\norder to check the exact SUSY invariance of the Lagrangian density. However, in\norder to introduce the (0,2) chiral superfields, we need the $\\hat{U}$\noperator, because we can not define the (0,2) chirality conditions of the (0,2)\nchiral superfields without introducing the new operator by using $\\hat{U}$ and\nthe enlarged operator \\hat{U}^{a} was obtained from the conditions that yield\nthe (0,2) supersymmetric invariance of the Lagrangian density of the (0,2) U(N)\ngauged linear sigma model in superfield formalism. We found that the\nconsistency conditions for the Abelian gauge group which assure the (0,2)\nsupersymmetric invariance of Lagrangian density agree with (0,2) chirality\nconditions for superpotential. The supermanifold \\mathcal{M}^{m|n} becomes the\nsuper weighted complex projective space WCP^{m-1|n} in U(1) case, which is\nconsidered as an example of Calabi-Yau supermanifold.\n", "machine_text": "\nWe present a (0,2) gauged linear sigma model on a supermanifold derived using both Abelian and non-Abelian gauge groups. To ensure that the resulting Action satisfies supersymmetry invariance, we require that certain consistency conditions be satisfied. For the Abelian gauge group, these conditions are formulated so as to agree with the (0,2) chirality conditions of the (0,2) chiral superfields. In the non-Abelian gauge group, we introduce the $\\hat{U}$ operator, as well as an enlarged operator $\\hat{U}^{a}$. The supermanifold \\mathcal{M}^{m|n} is demonstrated as an example of a Calabi-Yau supermanifold by mapping onto the super weighted complex projective space WCP^{m-1|n} in the U(1) case.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4021}
{"prompt": "Rephrase the abstract of an article with title 'Nearest-neigbor spacing distributions of the beta-Hermite ensemble of\n  random matrices'.\n  The distributions of the spacing s between nearest-neighbor levels of\nunfolded spectra of random matrices from the beta-Hermite ensemble (beta-HE) is\ninvestigated by Monte Carlo simulations. The random matrices from the beta-HE\nare real-symmetric and tridiagonal where beta, which can take any positive\nvalue, is the reciprocal of the temperature in the classical electrostatic\ninterpretation of eigenvalues. Generalized gamma distributions are shown to be\nexcellent approximations of the nearest-neighbor spacing (NNS) distributions\nfor any beta while being still simple. They account both for the level\nrepulsion when s tends to zero and for the whole shape of the NNS distributions\nin the range of s which is accessible to experiment or to most numerical\nsimulations. The exact NNS distribution of the GOE (beta=1) is in particular\nsignificantly better described by a generalized gamma distribution than it is\nby the Wigner surmise while the best generalized gamma approximation coincides\nessentially with the Wigner surmise for beta larger than ~2. The distributions\nof the minimum NN spacing between eigenvalues of matrices from the beta-HE,\nobtained both from as-calculated eigenvalues and from unfolded eigenvalues are\nBrody distributions.\n\n", "human_text": "  The distributions of the spacing s between nearest-neighbor levels of\nunfolded spectra of random matrices from the beta-Hermite ensemble (beta-HE) is\ninvestigated by Monte Carlo simulations. The random matrices from the beta-HE\nare real-symmetric and tridiagonal where beta, which can take any positive\nvalue, is the reciprocal of the temperature in the classical electrostatic\ninterpretation of eigenvalues. Generalized gamma distributions are shown to be\nexcellent approximations of the nearest-neighbor spacing (NNS) distributions\nfor any beta while being still simple. They account both for the level\nrepulsion when s tends to zero and for the whole shape of the NNS distributions\nin the range of s which is accessible to experiment or to most numerical\nsimulations. The exact NNS distribution of the GOE (beta=1) is in particular\nsignificantly better described by a generalized gamma distribution than it is\nby the Wigner surmise while the best generalized gamma approximation coincides\nessentially with the Wigner surmise for beta larger than ~2. The distributions\nof the minimum NN spacing between eigenvalues of matrices from the beta-HE,\nobtained both from as-calculated eigenvalues and from unfolded eigenvalues are\nBrody distributions.\n", "machine_text": "\nThe distributions of the spacing s between nearest-neighbor levels of unfolded spectra of random matrices from the beta-Hermite ensemble (beta-HE) are analysed via Monte Carlo simulations. These matrices are real-symmetric and tridiagonal and their reciprocal of temperature (beta) can assume any positive value through the classical electrostatic interpretation of eigenvalues. Results show that generalized gamma distributions are excellent fits for the nearest-neighbor spacing (NNS) distributions for any given beta and still remain straightforward. They encompass the level repulsion when s becomes close to zero, as well as the overall shape of NNS distributions in the region easily accessed by experiments or numerical simulations. The exact NNS distribution of the GOE (beta=1) meets with a better description through a generalized gamma distribution than via the Wigner surmise, while the highest generalized gamma approximation coincides essentially with the Wigner surmise when beta is higher than approximately two. Brody distributions were obtained from both as-calculated eigenvalues and unfolded eigenvalues of matrices from the beta-HE in the form of their minimum NN spacing.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3261}
{"prompt": "Rephrase the abstract of an article with title 'Classical and quantum randomness and the financial market'.\n  We analyze complexity of financial (and general economic) processes by\ncomparing classical and quantum-like models for randomness. Our analysis\nimplies that it might be that a quantum-like probabilistic description is more\nnatural for financial market than the classical one. A part of our analysis is\ndevoted to study the possibility of application of the quantum probabilistic\nmodel to agents of financial market. We show that, although the direct quantum\n(physical) reduction (based on using the scales of quantum mechanics) is\nmeaningless, one may apply so called quantum-like models. In our approach\nquantum-like probabilistic behaviour is a consequence of contextualy of\nstatistical data in finances (and economics in general). However, our\nhypothesis on \"quantumness\" of financial data should be tested experimentally\n(as opposed to the conventional description based on the noncontextual\nclassical probabilistic approach). We present a new statistical test based on a\ngeneralization of the well known in quantum physics Bell's inequality.\n\n", "human_text": "  We analyze complexity of financial (and general economic) processes by\ncomparing classical and quantum-like models for randomness. Our analysis\nimplies that it might be that a quantum-like probabilistic description is more\nnatural for financial market than the classical one. A part of our analysis is\ndevoted to study the possibility of application of the quantum probabilistic\nmodel to agents of financial market. We show that, although the direct quantum\n(physical) reduction (based on using the scales of quantum mechanics) is\nmeaningless, one may apply so called quantum-like models. In our approach\nquantum-like probabilistic behaviour is a consequence of contextualy of\nstatistical data in finances (and economics in general). However, our\nhypothesis on \"quantumness\" of financial data should be tested experimentally\n(as opposed to the conventional description based on the noncontextual\nclassical probabilistic approach). We present a new statistical test based on a\ngeneralization of the well known in quantum physics Bell's inequality.\n", "machine_text": "This paper examines the complexity of financial (and general economic) processes by contrasting classical and quantum-like models of randomness. Results indicate that a quantum-like probabilistic model could be more fitting for the financial market than classical models. Efforts to understand how this probabilistic approach applies to agents of the financial market are included in the analysis. It is suggested that the quantum-like probabilistic behavior stems from the context of statistical data in finance (and economics in general), and should be assessed experimentally (contrary to the classical probabilistic method that is non-contextual). Finally, a new statistical test is proposed here, which builds on a generalization of the famous Bell's Inequality from quantum physics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2865}
{"prompt": "Rephrase the abstract of an article with title '\"Illusion of control\" in Minority and Parrondo Games'.\n  Human beings like to believe they are in control of their destiny. This\nubiquitous trait seems to increase motivation and persistence, and is probably\nevolutionarily adaptive. But how good really is our ability to control? How\nsuccessful is our track record in these areas? There is little understanding of\nwhen and under what circumstances we may over-estimate or even lose our ability\nto control and optimize outcomes, especially when they are the result of\naggregations of individual optimization processes. Here, we demonstrate\nanalytically using the theory of Markov Chains and by numerical simulations in\ntwo classes of games, the Minority game and the Parrondo Games, that agents who\noptimize their strategy based on past information actually perform worse than\nnon-optimizing agents. In other words, low-entropy (more informative)\nstrategies under-perform high-entropy (or random) strategies. This provides a\nprecise definition of the \"illusion of control\" in set-ups a priori defined to\nemphasize the importance of optimization.\n\n", "human_text": "  Human beings like to believe they are in control of their destiny. This\nubiquitous trait seems to increase motivation and persistence, and is probably\nevolutionarily adaptive. But how good really is our ability to control? How\nsuccessful is our track record in these areas? There is little understanding of\nwhen and under what circumstances we may over-estimate or even lose our ability\nto control and optimize outcomes, especially when they are the result of\naggregations of individual optimization processes. Here, we demonstrate\nanalytically using the theory of Markov Chains and by numerical simulations in\ntwo classes of games, the Minority game and the Parrondo Games, that agents who\noptimize their strategy based on past information actually perform worse than\nnon-optimizing agents. In other words, low-entropy (more informative)\nstrategies under-perform high-entropy (or random) strategies. This provides a\nprecise definition of the \"illusion of control\" in set-ups a priori defined to\nemphasize the importance of optimization.\n", "machine_text": "\nOur sense of control over our destiny has been found to promote motivation and\npersistence, yet this does not always hold true. Even when such control is based\non past information or optimization processes, it is not always successful. This\nstudy examines this ambiguous dynamic via Markov Chains theory and numerical\nsimulations in two types of games: the Minority game and the Parrondo Games. The\nresults suggest that the attempts to optimize strategies by analyzing prior data\ncan actually result in poorer outcomes than taking no action or taking a random\napproach. This gives an accurate depiction of what is known as an \"illusion of\ncontrol\" in predetermined settings that strive to illustrate the significance of\noptimization.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.112}
{"prompt": "Rephrase the abstract of an article with title 'A p-adic quasi-quadratic point counting algorithm'.\n  In this article we give an algorithm for the computation of the number of\nrational points on the Jacobian variety of a generic ordinary hyperelliptic\ncurve defined over a finite field of cardinality $q$ with time complexity\n$O(n^{2+o(1)})$ and space complexity $O(n^2)$, where $n=\\log(q)$. In the latter\ncomplexity estimate the genus and the characteristic are assumed as fixed. Our\nalgorithm forms a generalization of both, the AGM algorithm of J.-F. Mestre and\nthe canonical lifting method of T. Satoh. We canonically lift a certain\narithmetic invariant of the Jacobian of the hyperelliptic curve in terms of\ntheta constants. The theta null values are computed with respect to a\nsemi-canonical theta structure of level $2^\\nu p$ where $\\nu >0$ is an integer\nand $p=\\mathrm{char}(\\F_q)>2$. The results of this paper suggest a global\npositive answer to the question whether there exists a quasi-quadratic time\nalgorithm for the computation of the number of rational points on a generic\nordinary abelian variety defined over a finite field.\n\n", "human_text": "  In this article we give an algorithm for the computation of the number of\nrational points on the Jacobian variety of a generic ordinary hyperelliptic\ncurve defined over a finite field of cardinality $q$ with time complexity\n$O(n^{2+o(1)})$ and space complexity $O(n^2)$, where $n=\\log(q)$. In the latter\ncomplexity estimate the genus and the characteristic are assumed as fixed. Our\nalgorithm forms a generalization of both, the AGM algorithm of J.-F. Mestre and\nthe canonical lifting method of T. Satoh. We canonically lift a certain\narithmetic invariant of the Jacobian of the hyperelliptic curve in terms of\ntheta constants. The theta null values are computed with respect to a\nsemi-canonical theta structure of level $2^\\nu p$ where $\\nu >0$ is an integer\nand $p=\\mathrm{char}(\\F_q)>2$. The results of this paper suggest a global\npositive answer to the question whether there exists a quasi-quadratic time\nalgorithm for the computation of the number of rational points on a generic\nordinary abelian variety defined over a finite field.\n", "machine_text": "\nThis paper presents an algorithm for finding the number of rational points on the Jacobian variety of a generic ordinary hyperelliptic curve over a finite field of cardinality $q$, with time complexity of $O(n^{2+o(1)})$ and space complexity of $O(n^2)$, where $n = \\log(q)$. Moreover, this complexity estimate assumes the genus and the characteristic remain fixed. Our algorithm can be seen as a generalization of both, J.-F. Mestre's AGM Algorithm and T. Satoh's canonical lifting method. This algorithm depends on lifting an arithmetic invariant of the Jacobian curve in terms of theta constants. The theta null values are worked out with semi-canonical theta structures of level $2^{\\nu}p$ where $\\nu$ is an integer and $p$ is the characteristic of the base field $\\F_q$. The result of this article implies a possible affirmative answer to the question of whether there exists a quasi-quadratic time algorithm for computing the number of rational points on a generic ordinary abelian variety defined over a finite field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0234}
{"prompt": "Rephrase the abstract of an article with title 'Geometric control theory I: mathematical foundations'.\n  A geometric setup for control theory is presented. The argument is developed\nthrough the study of the extremals of action functionals defined on piecewise\ndifferentiable curves, in the presence of differentiable non-holonomic\nconstraints. Special emphasis is put on the tensorial aspects of the theory. To\nstart with, the kinematical foundations, culminating in the so called\nvariational equation, are put on geometrical grounds, via the introduction of\nthe concept of infinitesimal control . On the same basis, the usual\nclassification of the extremals of a variational problem into normal and\nabnormal ones is also rationalized, showing the existence of a purely\nkinematical algorithm assigning to each admissible curve a corresponding\nabnormality index, defined in terms of a suitable linear map. The whole\nmachinery is then applied to constrained variational calculus. The argument\nprovides an interesting revisitation of Pontryagin maximum principle and of the\nErdmann-Weierstrass corner conditions, as well as a proof of the classical\nLagrange multipliers method and a local interpretation of Pontryagin's\nequations as dynamical equations for a free (singular) Hamiltonian system. As a\nfinal, highly non-trivial topic, a sufficient condition for the existence of\nfinite deformations with fixed endpoints is explicitly stated and proved.\n\n", "human_text": "  A geometric setup for control theory is presented. The argument is developed\nthrough the study of the extremals of action functionals defined on piecewise\ndifferentiable curves, in the presence of differentiable non-holonomic\nconstraints. Special emphasis is put on the tensorial aspects of the theory. To\nstart with, the kinematical foundations, culminating in the so called\nvariational equation, are put on geometrical grounds, via the introduction of\nthe concept of infinitesimal control . On the same basis, the usual\nclassification of the extremals of a variational problem into normal and\nabnormal ones is also rationalized, showing the existence of a purely\nkinematical algorithm assigning to each admissible curve a corresponding\nabnormality index, defined in terms of a suitable linear map. The whole\nmachinery is then applied to constrained variational calculus. The argument\nprovides an interesting revisitation of Pontryagin maximum principle and of the\nErdmann-Weierstrass corner conditions, as well as a proof of the classical\nLagrange multipliers method and a local interpretation of Pontryagin's\nequations as dynamical equations for a free (singular) Hamiltonian system. As a\nfinal, highly non-trivial topic, a sufficient condition for the existence of\nfinite deformations with fixed endpoints is explicitly stated and proved.\n", "machine_text": "This article provides an exploration of the mathematical basis for geometric control theory. After introducing the concept of infinitesimal control to develop the underlying kinematical principles, these principles are used to classify extremals of variational problems and create a kinematical algorithm assigning a corresponding abnormality index to each admissible curve. This is then applied to further analysis of constrained variational calculus, re-examining Pontryagin's maximum principle, Erdmann-Weierstrass corner conditions, the Lagrange multiplier method, and developing a free Hamiltonian system for Pontryagin's equations. Finally, a sufficient condition for the existence of finite deformations with fixed endpoints is laid out and proved.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2362}
{"prompt": "Rephrase the abstract of an article with title 'Production of TeV gamma-radiation in the vicinity of the supermassive\n  black hole in the giant radiogalaxy M87'.\n  Although the giant radiogalaxy M 87 harbors many distinct regions of\nbroad-band nonthermal emission, the recently reported fast variability of TeV\ngamma rays from M 87 on a timescale of days strongly constrains the range of\nspeculations concerning the possible sites and scenarios of particle\nacceleration responsible for the observed TeV emission. A natural production\nsite of this radiation is the immediate vicinity of the central supermassive\nmass black hole (BH). Because of the low bolometric luminosity, the nucleus of\nM 87 is effectively transparent for gamma rays up to energy of 10 TeV, which\nmakes this source an ideal laboratory for study of particle acceleration\nprocesses close to the BH event horizon. We critically analyse different\npossible radiation mechanisms in this region, and argue that the observed very\nhigh-energy gamma ray emission can be explained by the inverse Compton emission\nof ultrarelativistic electron-positron pairs produced through the development\nof an electromagnetic cascade in the BH magnetosphere. We demonstrate, through\ndetailed numerical calculations of acceleration and radiation of electrons in\nthe magnetospheric vacuum gap, that this ``pulsar magnetosphere like'' scenario\ncan satisfactorily explain the main properties of TeV gamma-ray emission of M\n87.\n\n", "human_text": "  Although the giant radiogalaxy M 87 harbors many distinct regions of\nbroad-band nonthermal emission, the recently reported fast variability of TeV\ngamma rays from M 87 on a timescale of days strongly constrains the range of\nspeculations concerning the possible sites and scenarios of particle\nacceleration responsible for the observed TeV emission. A natural production\nsite of this radiation is the immediate vicinity of the central supermassive\nmass black hole (BH). Because of the low bolometric luminosity, the nucleus of\nM 87 is effectively transparent for gamma rays up to energy of 10 TeV, which\nmakes this source an ideal laboratory for study of particle acceleration\nprocesses close to the BH event horizon. We critically analyse different\npossible radiation mechanisms in this region, and argue that the observed very\nhigh-energy gamma ray emission can be explained by the inverse Compton emission\nof ultrarelativistic electron-positron pairs produced through the development\nof an electromagnetic cascade in the BH magnetosphere. We demonstrate, through\ndetailed numerical calculations of acceleration and radiation of electrons in\nthe magnetospheric vacuum gap, that this ``pulsar magnetosphere like'' scenario\ncan satisfactorily explain the main properties of TeV gamma-ray emission of M\n87.\n", "machine_text": "The fast-changing TeV gamma-ray emission detected in M 87 has constrained the range of assumptions about the origin of this radiation. This paper proposes the possibility that the TeV radiation is produced by inverse Compton emission of ultra-relativistic electron-positron pairs which develop in an electromagnetic cascade in the magnetosphere of the supermassive black hole. Detailed numerical calculations of particle acceleration and radiation in the magnetospheric vacuum indicate that this \"pulsar-like magnetosphere\" scenario can explain the main characteristics of M 87's TeV gamma-ray emission.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3282}
{"prompt": "Rephrase the abstract of an article with title 'The Differential Rotation of Kappa1 Ceti as Observed by MOST'.\n  We first reported evidence for differential rotation of Kappa1 Ceti in Paper\nI. In this paper we demonstrate that the differential rotation pattern closely\nmatches that for the Sun. This result is based on additional MOST\n(Microvariability & Oscillations of STars) observations in 2004 and 2005, to\ncomplement the 2003 observations discussed in Paper I. Using StarSpotz, a\nprogram developed specifically to analyze MOST photometry, we have solved for\nk, the differential rotation coefficient, and P_{EQ}, the equatorial rotation\nperiod using the light curves from all three years. The spots range in latitude\nfrom 10 to 75 degrees and k = 0.090^{+0.006}_{-0.005} -- less than the solar\nvalue but consistent with the younger age of the star. k is also well\nconstrained by the independent spectroscopic estimate of vsini. We demonstrate\nindependently that the pattern of differential rotation with latitude in fact\nconforms to solar.\n  Details are given of the parallel tempering formalism used in finding the\nmost robust solution which gives P_{EQ} = 8.77^{+0.03}_{-0.04} days -- smaller\nthan that usually adopted, implying an age < 750 My. Our values of P_{EQ} and k\ncan explain the range of rotation periods determined by others by spots or\nactivity at a variety of latitudes. Historically, Ca II activity seems to occur\nconsistently between latitudes 50 and 60 degrees which might indicate a\npermanent magnetic feature. Knowledge of k and P_{EQ} are key to understanding\nthe dynamo mechanism and rotation structure in the convective zone as well\nassessing age for solar-type stars. We recently published values of k and\nP_{EQ} for epsilon Eri based on MOST photometry and expect to analyze MOST\nlight curves for several more spotted, solar-type stars.\n\n", "human_text": "  We first reported evidence for differential rotation of Kappa1 Ceti in Paper\nI. In this paper we demonstrate that the differential rotation pattern closely\nmatches that for the Sun. This result is based on additional MOST\n(Microvariability & Oscillations of STars) observations in 2004 and 2005, to\ncomplement the 2003 observations discussed in Paper I. Using StarSpotz, a\nprogram developed specifically to analyze MOST photometry, we have solved for\nk, the differential rotation coefficient, and P_{EQ}, the equatorial rotation\nperiod using the light curves from all three years. The spots range in latitude\nfrom 10 to 75 degrees and k = 0.090^{+0.006}_{-0.005} -- less than the solar\nvalue but consistent with the younger age of the star. k is also well\nconstrained by the independent spectroscopic estimate of vsini. We demonstrate\nindependently that the pattern of differential rotation with latitude in fact\nconforms to solar.\n  Details are given of the parallel tempering formalism used in finding the\nmost robust solution which gives P_{EQ} = 8.77^{+0.03}_{-0.04} days -- smaller\nthan that usually adopted, implying an age < 750 My. Our values of P_{EQ} and k\ncan explain the range of rotation periods determined by others by spots or\nactivity at a variety of latitudes. Historically, Ca II activity seems to occur\nconsistently between latitudes 50 and 60 degrees which might indicate a\npermanent magnetic feature. Knowledge of k and P_{EQ} are key to understanding\nthe dynamo mechanism and rotation structure in the convective zone as well\nassessing age for solar-type stars. We recently published values of k and\nP_{EQ} for epsilon Eri based on MOST photometry and expect to analyze MOST\nlight curves for several more spotted, solar-type stars.\n", "machine_text": "\nUsing MOST (Microvariability & Oscillations of STars) observations from 2003, 2004, and 2005, this paper presents evidence of a similar differential rotation pattern between Kappa1 Ceti and the Sun. A program called StarSpotz was used to solve for the rate of differential rotation, k, and the equatorial rotation period, P_{EQ}. The analysis revealed a rate of differential rotation (k = 0.090^{+0.006}_{-0.005}) which is less than that of the Sun, but is consistent with the younger age of the star. Furthermore, results from the parallel tempering formalism show an equatorial rotation period of 8.77^{+0.03}_{-0.04} days, smaller than the usually adopted value, implying an age of less than 750 My. These results are then used to explain the range of rotation at a variety of latitudes, as well as to infer a possible permanent magnetic feature at latitudes between 50 and 60 degrees. Using MOST, knowledge of k and P_{EQ} is being gained which can be used to analyze other solar-type stars, helping to build an understanding of dynamo mechanisms and age in solar-type stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2204}
{"prompt": "Rephrase the abstract of an article with title 'The Crossover from Impurity to Valence Band in Diluted Magnetic\n  Semiconductors: The Role of the Coulomb Attraction by Acceptor'.\n  The crossover between an impurity band (IB) and a valence band (VB) regime as\na function of the magnetic impurity concentration in models for diluted\nmagnetic semiconductors (DMS) is studied systematically by taking into\nconsideration the Coulomb attraction between the carriers and the magnetic\nimpurities. The density of states and the ferromagnetic transition temperature\nof a Spin-Fermion model applied to DMS are evaluated using Dynamical Mean-Field\nTheory (DMFT) and Monte Carlo (MC) calculations. It is shown that the addition\nof a square-well-like attractive potential can generate an IB at small enough\nMn doping $x$ for values of the $p-d$ exchange $J$ that are not strong enough\nto generate one by themselves. We observe that the IB merges with the VB when\n$x >= x_c$ where $x_c$ is a function of $J$ and the Coulomb attraction strength\n$V$. Using MC calculations, we demonstrate that the range of the Coulomb\nattraction plays an important role. While the on-site attraction, that has been\nused in previous numerical simulations, effectively renormalizes $J$ for all\nvalues of $x$, an unphysical result, a nearest-neighbor range attraction\nrenormalizes $J$ only at very low dopings, i.e., until the bound holes wave\nfunctions start to overlap. Thus, our results indicate that the Coulomb\nattraction can be neglected to study Mn doped GaSb, GaAs, and GaP in the\nrelevant doping regimes, but it should be included in the case of Mn doped GaN\nthat is expected to be in the IB regime.\n\n", "human_text": "  The crossover between an impurity band (IB) and a valence band (VB) regime as\na function of the magnetic impurity concentration in models for diluted\nmagnetic semiconductors (DMS) is studied systematically by taking into\nconsideration the Coulomb attraction between the carriers and the magnetic\nimpurities. The density of states and the ferromagnetic transition temperature\nof a Spin-Fermion model applied to DMS are evaluated using Dynamical Mean-Field\nTheory (DMFT) and Monte Carlo (MC) calculations. It is shown that the addition\nof a square-well-like attractive potential can generate an IB at small enough\nMn doping $x$ for values of the $p-d$ exchange $J$ that are not strong enough\nto generate one by themselves. We observe that the IB merges with the VB when\n$x >= x_c$ where $x_c$ is a function of $J$ and the Coulomb attraction strength\n$V$. Using MC calculations, we demonstrate that the range of the Coulomb\nattraction plays an important role. While the on-site attraction, that has been\nused in previous numerical simulations, effectively renormalizes $J$ for all\nvalues of $x$, an unphysical result, a nearest-neighbor range attraction\nrenormalizes $J$ only at very low dopings, i.e., until the bound holes wave\nfunctions start to overlap. Thus, our results indicate that the Coulomb\nattraction can be neglected to study Mn doped GaSb, GaAs, and GaP in the\nrelevant doping regimes, but it should be included in the case of Mn doped GaN\nthat is expected to be in the IB regime.\n", "machine_text": "This article evaluates the transition from an impurity band (IB) to a valence band (VB) regime of diluted magnetic semiconductors (DMS) in terms of magnetic impurity concentration, taking into account the Coulomb attraction between carriers and magnetic impurities. We employ Dynamical Mean-Field Theory (DMFT) and Monte Carlo (MC) calculations to analyze the density of states and the ferromagnetic transition temperature. The results suggest a square-well-like potential to initiate an IB at lower magnetic doping levels than that previously thought to be possible. Additionally, the range of the Coulomb attraction is shown to be an important factor in the renormalization of the $p-d$ exchange $J$; it is found that the on-site attraction can effectively renormalize $J$ across all values of $x$, while a nearest-neighbor range attraction can be relied upon at low doping levels only.These findings indicate that the Coulomb attraction should be taken into account when studying Mn-doped GaN, which is expected to be in the IB regime.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0309}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical heterogeneities and the breakdown of the Stokes-Einstein and\n  Stokes-Einstein-Debye relations in simulated water'.\n  We study the Stokes-Einstein (SE) and the Stokes-Einstein-Debye (SED)\nrelations using molecular dynamics simulations of the extended simple point\ncharge model of water. We find that both the SE and SED relations break down at\nlow temperature. To explore the relationship between these breakdowns and\ndynamical heterogeneities (DH), we also calculate the SE and SED relations for\nsubsets of the 7% ``fastest'' and 7% ``slowest'' molecules. We find that the SE\nand SED relations break down in both subsets, and that the breakdowns occur on\nall scales of mobility. Thus these breakdowns appear to be generalized\nphenomena, in contrast with the view where only the most mobile molecules are\nthe origin of the breakdown of the SE and SED relations, embedded in an\ninactive background where these relations hold. At low temperature, the SE and\nSED relations in both subsets of molecules are replaced with ``fractional'' SE\nand SED relations, $D_t\\sim(\\tau/T)^{-\\xi_t}$ and $D_r\\sim(\\tau/T)^{-\\xi_r}$\nwhere $\\xi_t\\approx0.84<1$ and $\\xi_r\\approx0.75<1$. We also find that there is\na decoupling between rotational and translational motion, and that this\ndecoupling occurs in both fastest and slowest subsets of molecules. We also\nfind that when the decoupling increases, upon cooling, the probability of a\nmolecule being classified as both translationally and rotationally fastest also\nincreases. To study the effect of time scale for SE and SED breakdown and\ndecoupling, we introduce a time-dependent version of the SE and SED relations,\nand a time-dependent function that measures the extent of decoupling. Our\nresults suggest that both the decoupling and SE and SED breakdowns are\noriginated at the time scale corresponding to the end of the cage regime, when\ndiffusion starts. This is also the time scale when the DH are more relevant.\n\n", "human_text": "  We study the Stokes-Einstein (SE) and the Stokes-Einstein-Debye (SED)\nrelations using molecular dynamics simulations of the extended simple point\ncharge model of water. We find that both the SE and SED relations break down at\nlow temperature. To explore the relationship between these breakdowns and\ndynamical heterogeneities (DH), we also calculate the SE and SED relations for\nsubsets of the 7% ``fastest'' and 7% ``slowest'' molecules. We find that the SE\nand SED relations break down in both subsets, and that the breakdowns occur on\nall scales of mobility. Thus these breakdowns appear to be generalized\nphenomena, in contrast with the view where only the most mobile molecules are\nthe origin of the breakdown of the SE and SED relations, embedded in an\ninactive background where these relations hold. At low temperature, the SE and\nSED relations in both subsets of molecules are replaced with ``fractional'' SE\nand SED relations, $D_t\\sim(\\tau/T)^{-\\xi_t}$ and $D_r\\sim(\\tau/T)^{-\\xi_r}$\nwhere $\\xi_t\\approx0.84<1$ and $\\xi_r\\approx0.75<1$. We also find that there is\na decoupling between rotational and translational motion, and that this\ndecoupling occurs in both fastest and slowest subsets of molecules. We also\nfind that when the decoupling increases, upon cooling, the probability of a\nmolecule being classified as both translationally and rotationally fastest also\nincreases. To study the effect of time scale for SE and SED breakdown and\ndecoupling, we introduce a time-dependent version of the SE and SED relations,\nand a time-dependent function that measures the extent of decoupling. Our\nresults suggest that both the decoupling and SE and SED breakdowns are\noriginated at the time scale corresponding to the end of the cage regime, when\ndiffusion starts. This is also the time scale when the DH are more relevant.\n", "machine_text": "\nIn this study, we employ molecular dynamics simulations of the extended simple point charge model of water to examine breakdowns in the Stokes-Einstein (SE) and Stokes-Einstein-Debye (SED) relations at low temperature. We discover that both relations break down for both 7% of the ``fastest'' and 7% of the ``slowest'' molecules, a phenomenon which appears to be generalized across all scales of mobility. In this lower temperature range, the SE and SED relations are replaced with the ``fractional'' SE and SED relations; $D_t\\sim(\\tau/T)^{-\\xi_t}$ and $D_r\\sim(\\tau/T)^{-\\xi_r}$ where $\\xi_t\\approx0.84<1$ and $\\xi_r\\approx0.75<1$. Additionally, a decoupling between the rotational and translational motion of the molecules is observed. We also note that the probability of a molecule being identified as both translationally and rotationally fastest increases with the advancement of the decoupling. Through the introduction of a time-dependent version of the SE and SED relations, as well as a time-dependent measure of the extent of decoupling, we find that the decoupling and the SE/SED breakdowns are linked to the dynamical heterogeneities and begin at the time scale in which cages end and diffusion starts.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4475}
{"prompt": "Rephrase the abstract of an article with title 'The nearby QSO host I Zw 1: The stellar disk and adjacent objects'.\n  The relation between tidal interactions, starbursts, and the onset and/or\nfueling of active galactic nuclei (AGN) is a matter of debate. I Zw 1 is\nconsidered as the prototypical narrow-line Seyfert 1 galaxy (NLS1) and as one\nof the closest quasi-stellar objects (QSOs). With a clear spiral host and a\nsmall companion galaxy to the west, I Zw 1 is a possible example of\nminor-merger-related nuclear activity. This study investigates possible signs\nof a relation between merger process, star formation activity, and AGN\nproperties in the case of I Zw 1. The morphology of I Zw 1 and nearby sources\nis investigated via high-resolution NIR images. Color trends in the host galaxy\nof I Zw 1 are discussed by means of optical-to-NIR color composites. Long-slit\nspectra of the QSO nucleus of I Zw 1 and of the two nearby sources to the north\nand the west of the I Zw 1 disk are analyzed. The data support the scenario of\na tidal interaction between I Zw 1 and the small companion galaxy to the west.\nA concentration of blue color in the western part of the I Zw 1 host galaxy\nmight be the manifestation of merger-induced star formation activity. Previous\nfindings that the likely companion has an old evolved stellar population are\nsubstantiated by the new data. An extension to the west of the putative\ncompanion emerges as a separate source. The source to the north of the I Zw 1\ndisk is reconfirmed as a late-type foreground star. Lines in the nuclear K-band\nspectrum of I Zw 1 are discussed in comparison to data prior to this article\nand line fluxes are reported.\n\n", "human_text": "  The relation between tidal interactions, starbursts, and the onset and/or\nfueling of active galactic nuclei (AGN) is a matter of debate. I Zw 1 is\nconsidered as the prototypical narrow-line Seyfert 1 galaxy (NLS1) and as one\nof the closest quasi-stellar objects (QSOs). With a clear spiral host and a\nsmall companion galaxy to the west, I Zw 1 is a possible example of\nminor-merger-related nuclear activity. This study investigates possible signs\nof a relation between merger process, star formation activity, and AGN\nproperties in the case of I Zw 1. The morphology of I Zw 1 and nearby sources\nis investigated via high-resolution NIR images. Color trends in the host galaxy\nof I Zw 1 are discussed by means of optical-to-NIR color composites. Long-slit\nspectra of the QSO nucleus of I Zw 1 and of the two nearby sources to the north\nand the west of the I Zw 1 disk are analyzed. The data support the scenario of\na tidal interaction between I Zw 1 and the small companion galaxy to the west.\nA concentration of blue color in the western part of the I Zw 1 host galaxy\nmight be the manifestation of merger-induced star formation activity. Previous\nfindings that the likely companion has an old evolved stellar population are\nsubstantiated by the new data. An extension to the west of the putative\ncompanion emerges as a separate source. The source to the north of the I Zw 1\ndisk is reconfirmed as a late-type foreground star. Lines in the nuclear K-band\nspectrum of I Zw 1 are discussed in comparison to data prior to this article\nand line fluxes are reported.\n", "machine_text": "This article explores the relationship between tidal influences, star formation and the onset/fueling of active galactic nuclei (AGN) by examining the case of I Zw 1, a quasar with an adjacent spiral hosting galaxy and the small nearby companion to the west. Through high-resolution NIR images and optical to near-infrared color composites, it is revealed that there could very likely be signs of merger-induced star formation activity in the western part of the I Zw 1 host galaxy. Spectroscopic data is used to confirm companion galaxy's old evolved stellar population and also a new separate source to the west. The northern source is reconfirmed as a late-type foreground star. Lastly, lines of the I Zw 1 nucleus K-band spectrum are discussed and line fluxes are provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2383}
{"prompt": "Rephrase the abstract of an article with title 'General Relativistic Flux Modulations from Disk Instabilities in\n  Sagittarius A*'.\n  Near-IR and X-ray flares have been detected from the supermassive black hole\nSgr A* at the center of our Galaxy with a (quasi)-period of ~17-20 minutes,\nsuggesting an emission region only a few Schwarzschild radii above the event\nhorizon. The latest X-ray flare, detected with XMM-Newton, is notable for its\ndetailed lightcurve, yielding not only the highest quality period thus far, but\nalso important structure reflecting the geometry of the emitting region. Recent\nMHD simulations of Sgr A*'s disk have demonstrated the growth of a Rossby wave\ninstability, that enhances the accretion rate for several hours, possibly\naccounting for the observed flares. In this Letter, we carry out ray-tracing\ncalculations in a Schwarzschild metric to determine as accurately as possible\nthe lightcurve produced by general relativistic effects during such a\ndisruption. We find that the Rossby wave induced spiral pattern in the disk is\nan excellent fit to the data, implying a disk inclination angle of ~77 deg.\nNote, however, that if this association is correct, the observed period is not\ndue to the underlying Keplerian motion but, rather, to the pattern speed. The\nfavorable comparison between the observed and simulated lightcurves provides\nimportant additional evidence that the flares are produced in Sgr A*'s inner\ndisk.\n\n", "human_text": "  Near-IR and X-ray flares have been detected from the supermassive black hole\nSgr A* at the center of our Galaxy with a (quasi)-period of ~17-20 minutes,\nsuggesting an emission region only a few Schwarzschild radii above the event\nhorizon. The latest X-ray flare, detected with XMM-Newton, is notable for its\ndetailed lightcurve, yielding not only the highest quality period thus far, but\nalso important structure reflecting the geometry of the emitting region. Recent\nMHD simulations of Sgr A*'s disk have demonstrated the growth of a Rossby wave\ninstability, that enhances the accretion rate for several hours, possibly\naccounting for the observed flares. In this Letter, we carry out ray-tracing\ncalculations in a Schwarzschild metric to determine as accurately as possible\nthe lightcurve produced by general relativistic effects during such a\ndisruption. We find that the Rossby wave induced spiral pattern in the disk is\nan excellent fit to the data, implying a disk inclination angle of ~77 deg.\nNote, however, that if this association is correct, the observed period is not\ndue to the underlying Keplerian motion but, rather, to the pattern speed. The\nfavorable comparison between the observed and simulated lightcurves provides\nimportant additional evidence that the flares are produced in Sgr A*'s inner\ndisk.\n", "machine_text": "\nThis Letter examines the lightcurve of the latest X-ray flare detected from the supermassive black hole Sagittarius A*, which was notable for its distinctive structure. We suggest that this phenomenon is due to a Rossby wave instability in the disk which creates Enhanced accretion, and use ray tracing calculations based on a Schwarzschild metric to determine how general relativistic effects would affect this process. Our simulations of this disk have found a spiral pattern, which when compared to the X-ray data, suggests an inclination angle of 77 deg. This result provides evidence that the flares are generated in Sgr A*'s inner disk, with the observed period likely occurring due to the pattern speed, rather than the Keplerian motion beneath it.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0238}
{"prompt": "Rephrase the abstract of an article with title 'Deep Spectroscopy of Systematically Surveyed Extended Lyman-alpha\n  Sources at z~3-5'.\n  Spatially extended Ly-alpha sources that are faint and/or compact in coninuum\nare candidates for extremely young (~< 10^7 yrs) galaxies at high redshifts. We\npresent medium-resolution (R~2000) spectroscopy of such extended Ly-alpha\nsources found in our previous study at z~3-5, using VLT/VIMOS. The deep\nspectroscopy showed that all 18 objects we observed have large equivalent\nwidths (EWs) exceeding 100 A. For about 30% of our sample (five objects), we\nidentified conspicuous asymmetry on the profiles of the Ly-alpha line. They\nshow broad wing emission components on the red side, and sharp cut-off on the\nblue side of the Ly-alpha line. Such asymmetry is often seen in superwind\ngalaxies known to date, and also consistent with a theoretical prediction of\nsuperwind activity. There are eight objects (8/18 ~ 40%) that have large EWs\nexceeding 200 A, and no clear signature of superwind activities. Such large EWs\ncannot be explained in terms of photo-ionization by a moderately old (>10^7\nyrs) stellar population, even with a top-heavy IMF or an extremely low\nmetallicity. These eight objects clearly show a positive correlation between\nthe Ly-alpha luminosity and the velocity width. This suggests that these eight\nobjects are good candidates for forming-galaxies in a gas-cooling phase.\n\n", "human_text": "  Spatially extended Ly-alpha sources that are faint and/or compact in coninuum\nare candidates for extremely young (~< 10^7 yrs) galaxies at high redshifts. We\npresent medium-resolution (R~2000) spectroscopy of such extended Ly-alpha\nsources found in our previous study at z~3-5, using VLT/VIMOS. The deep\nspectroscopy showed that all 18 objects we observed have large equivalent\nwidths (EWs) exceeding 100 A. For about 30% of our sample (five objects), we\nidentified conspicuous asymmetry on the profiles of the Ly-alpha line. They\nshow broad wing emission components on the red side, and sharp cut-off on the\nblue side of the Ly-alpha line. Such asymmetry is often seen in superwind\ngalaxies known to date, and also consistent with a theoretical prediction of\nsuperwind activity. There are eight objects (8/18 ~ 40%) that have large EWs\nexceeding 200 A, and no clear signature of superwind activities. Such large EWs\ncannot be explained in terms of photo-ionization by a moderately old (>10^7\nyrs) stellar population, even with a top-heavy IMF or an extremely low\nmetallicity. These eight objects clearly show a positive correlation between\nthe Ly-alpha luminosity and the velocity width. This suggests that these eight\nobjects are good candidates for forming-galaxies in a gas-cooling phase.\n", "machine_text": "\nDetailed spectroscopic observations of extended Ly-alpha sources at redshifts z~3-5 were carried out with VLT/VIMOS. Our study reveals that the equivalent widths of Ly-alpha lines for all 18 sources exceed 100\\AA. Out of those, five demonstrate conspicuous asymmetry in the Ly-alpha line shapes, potentially indicating the presence of galactic superwinds. Moreover, a further eight sources display unusually large equivalent widths (larger than 200 \\AA), thus stressing their significance as young galaxies in the midst of a gas-cooling phase. Additionally, we observe a positive correlation between the Ly-alpha luminosity and the velocity width for these 8 objects.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1494}
{"prompt": "Rephrase the abstract of an article with title 'Zero-point radiation and the Big Bang'.\n  This paper develops a cosmological hypothesis based on the following\npropositions:\n  1. Zero-point radiation derives from quantic fluctuations in space, and the\nwavelength of its photons with the greatest energy is inversely proportional to\nthe curvature of space.\n  2. The Universe began as the breaking in of photons of extremely high energy\ncontained in the 3-dimensional surface: $w^2+x^2+y^2+z^2=R^2_i$, whose radius\nhas continued to expand at the speed of ligth since its origin at $t=0$.\n  3. The wavelength of the photons is quantized and the quantum of wavelength\nis invariable.\n  These propositions imply that the value of the total energy of the zero-point\nradiation in the Universe remains constant and the condition $w^2 + x^2 + y^2 +\nz^2 = (R_i + ct)^2 = R_u^2$ determines that every point in our space is subject\nto a tension whose intensity $i$ is proportional to the curvature $1/R_u$. Any\nincrease of $R_u$ implies a decrease in $i$ and consequently an energy flow\nwhich translates into an expansive force. Therefore, the Universe will expand\nindefinitely: no Big Crunch is possible. If the initial radius of the Universe\n$R_i$ has been smaller than the Schwarzschild radius, $R_s$, which corresponds\nto the total mass of the Universe, $M_u$, the generation of matter would have\nlasted for thousands of millions of years. Generation of matter over short\nperiods would have required values for $R_i$ of thousands of millions of light\nyears.\n\n", "human_text": "  This paper develops a cosmological hypothesis based on the following\npropositions:\n  1. Zero-point radiation derives from quantic fluctuations in space, and the\nwavelength of its photons with the greatest energy is inversely proportional to\nthe curvature of space.\n  2. The Universe began as the breaking in of photons of extremely high energy\ncontained in the 3-dimensional surface: $w^2+x^2+y^2+z^2=R^2_i$, whose radius\nhas continued to expand at the speed of ligth since its origin at $t=0$.\n  3. The wavelength of the photons is quantized and the quantum of wavelength\nis invariable.\n  These propositions imply that the value of the total energy of the zero-point\nradiation in the Universe remains constant and the condition $w^2 + x^2 + y^2 +\nz^2 = (R_i + ct)^2 = R_u^2$ determines that every point in our space is subject\nto a tension whose intensity $i$ is proportional to the curvature $1/R_u$. Any\nincrease of $R_u$ implies a decrease in $i$ and consequently an energy flow\nwhich translates into an expansive force. Therefore, the Universe will expand\nindefinitely: no Big Crunch is possible. If the initial radius of the Universe\n$R_i$ has been smaller than the Schwarzschild radius, $R_s$, which corresponds\nto the total mass of the Universe, $M_u$, the generation of matter would have\nlasted for thousands of millions of years. Generation of matter over short\nperiods would have required values for $R_i$ of thousands of millions of light\nyears.\n", "machine_text": "\nThis article explores the hypothesis that the Big Bang began with the release of photons at extremely high energy levels contained in the 3-dimensional space $w^2 + x^2 + y^2 + z^2 = R_i^2$. It argues that the wavelength of the zero-point radiation from quantum fluctuations is inversely proportional to the curvature of the space, and its quantum of wavelength is consistent. As a result, the total energy of this radiation in the Universe remains unchanged, and its expansion is regulated by a tension intensity proportional to the curvature of space. This leads to an everlasting Universe with no Big Crunch, where the initial radius of the Universe $R_i$ must have been lesser than the Schwarzschild radius $R_s$ for the matter generation to take place over extended periods. Should the $R_i$ exceed the $R_s$ mark, the mass of the Universe, $M_u$ would have needed to be much greater for the right period of matter generation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3722}
{"prompt": "Rephrase the abstract of an article with title 'Finite Element Model Updating Using Response Surface Method'.\n  This paper proposes the response surface method for finite element model\nupdating. The response surface method is implemented by approximating the\nfinite element model surface response equation by a multi-layer perceptron. The\nupdated parameters of the finite element model were calculated using genetic\nalgorithm by optimizing the surface response equation. The proposed method was\ncompared to the existing methods that use simulated annealing or genetic\nalgorithm together with a full finite element model for finite element model\nupdating. The proposed method was tested on an unsymmetri-cal H-shaped\nstructure. It was observed that the proposed method gave the updated natural\nfrequen-cies and mode shapes that were of the same order of accuracy as those\ngiven by simulated annealing and genetic algorithm. Furthermore, it was\nobserved that the response surface method achieved these results at a\ncomputational speed that was more than 2.5 times as fast as the genetic\nalgorithm and a full finite element model and 24 times faster than the\nsimulated annealing.\n\n", "human_text": "  This paper proposes the response surface method for finite element model\nupdating. The response surface method is implemented by approximating the\nfinite element model surface response equation by a multi-layer perceptron. The\nupdated parameters of the finite element model were calculated using genetic\nalgorithm by optimizing the surface response equation. The proposed method was\ncompared to the existing methods that use simulated annealing or genetic\nalgorithm together with a full finite element model for finite element model\nupdating. The proposed method was tested on an unsymmetri-cal H-shaped\nstructure. It was observed that the proposed method gave the updated natural\nfrequen-cies and mode shapes that were of the same order of accuracy as those\ngiven by simulated annealing and genetic algorithm. Furthermore, it was\nobserved that the response surface method achieved these results at a\ncomputational speed that was more than 2.5 times as fast as the genetic\nalgorithm and a full finite element model and 24 times faster than the\nsimulated annealing.\n", "machine_text": "\nThis article presents a response surface method for updating finite element models. A multi-layer perceptron is used to approximate the surface response equation of the finite element model. By optimizing this equation with a genetic algorithm, the updated parameters of the model are determined. Comparison of the proposed method to existing methods using simulated annealing or genetic algorithm alongside a full finite element model shows that the response surface method is able to provide similar accuracy in terms of natural frequencies and mode shapes. Moreover, the approach is much faster than either of the two, with a computational speed more than 2.5 times faster than the genetic algorithm and 24 times faster than simulated annealing. The benefits of the proposed method are demonstrated with an unsymmetrical H-shaped structure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1759}
{"prompt": "Rephrase the abstract of an article with title 'Universal spectrum for DNA base CG frequency distribution in Takifugu\n  rubripes (Puffer fish) genome'.\n  The frequency distribution of DNA bases A, C, G, T exhibit fractal\nfluctuations ubiquitous to dynamical systems in nature. The power spectra of\nfractal fluctuations exhibit inverse power law form signifying long-range\ncorrelations between local (small-scale) and global (large-scale)\nperturbations. The author has developed a general systems theory based on\nclassical statistical physics for fractal fluctuations which predicts that the\nprobability distribution of eddy amplitudes and the variance (square of eddy\namplitude)spectrum of fractal fluctuations follow the universal Boltzmann\ninverse power law expressed as a function of the golden mean. The model\npredicted distribution is very close to statistical normal distribution for\nfluctuations within two standard deviations from the mean and exhibits a fat\nlong tail. In this paper it is shown that DNA base CG frequency distribution in\nTakifugu rubripes (Puffer fish) Genome Release 4 exhibit universal inverse\npower law form consistent with model prediction. The observed long-range\ncorrelations in the DNA bases implies that the non-coding 'junk' or 'selfish'\nDNA which appear to be redundant, may also contribute to the efficient\nfunctioning of the protein coding DNA, a result supported by recent studies.\n\n", "human_text": "  The frequency distribution of DNA bases A, C, G, T exhibit fractal\nfluctuations ubiquitous to dynamical systems in nature. The power spectra of\nfractal fluctuations exhibit inverse power law form signifying long-range\ncorrelations between local (small-scale) and global (large-scale)\nperturbations. The author has developed a general systems theory based on\nclassical statistical physics for fractal fluctuations which predicts that the\nprobability distribution of eddy amplitudes and the variance (square of eddy\namplitude)spectrum of fractal fluctuations follow the universal Boltzmann\ninverse power law expressed as a function of the golden mean. The model\npredicted distribution is very close to statistical normal distribution for\nfluctuations within two standard deviations from the mean and exhibits a fat\nlong tail. In this paper it is shown that DNA base CG frequency distribution in\nTakifugu rubripes (Puffer fish) Genome Release 4 exhibit universal inverse\npower law form consistent with model prediction. The observed long-range\ncorrelations in the DNA bases implies that the non-coding 'junk' or 'selfish'\nDNA which appear to be redundant, may also contribute to the efficient\nfunctioning of the protein coding DNA, a result supported by recent studies.\n", "machine_text": "\nIn this paper, the author investigates the frequency distribution of DNA bases A, C, G, and T in Takifugu rubripes (Puffer fish) Genome Release 4. They develop a generalised systems theory based on classical statistical physics in order to predict the probability distribution of eddy amplitudes and the variance spectrum for fractal fluctuations, which follows the universal Boltzmann inverse power law expressed as a function of the golden mean. The findings suggest that the DNA base CG frequency distribution in Takifugu rubripes (Puffer fish) Genome Release 4 exhibit fractal fluctuations in form of an inverse power law, with the model prediction being very close to statistical normal distribution for fluctuations within two standard deviations from the mean and exhibiting a fat long tail. This implies that the non-coding 'junk' or 'selfish' DNA which may seem redundant may, in fact, contribute to the efficient functioning of the protein coding DNA, which is supported by recent studies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2114}
{"prompt": "Rephrase the abstract of an article with title 'Bound State Calculations of the Three-Dimensional Yakubovsky Equations\n  with the inclusion of Three-Body Forces'.\n  The four-body Yakubovsky equations in a Three-Dimensional approach with the\ninclusion of the three-body forces is proposed. The four-body bound state with\ntwo- and three-body interactions is formulated in Three-Dimensional approach\nfor identical particles as function of vector Jacobi momenta, specifically the\nmagnitudes of the momenta and the angles between them. The modified three\ndimensional Yakubovsky integral equations is successfully solved with the\nscalar two-meson exchange three-body force where the Malfliet-Tjon-type\ntwo-body force is implemented. The three-body force effects on the energy\neigenvalue and the four-body wave function, as well as accuracy of our\nnumerical calculations are presented.The four-body Yakubovsky equations in a\nThree-Dimensional approach with the inclusion of the three-body forces is\nproposed. The four-body bound state with two- and three-body interactions is\nformulated in Three-Dimensional approach for identical particles as function of\nvector Jacobi momenta, specifically the magnitudes of the momenta and the\nangles between them. The modified three dimensional Yakubovsky integral\nequations is successfully solved with the scalar two-meson exchange three-body\nforce where the Malfliet-Tjon-type two-body force is implemented. The\nthree-body force effects on the energy eigenvalue and the four-body wave\nfunction, as well as accuracy of our numerical calculations are presented.\n\n", "human_text": "  The four-body Yakubovsky equations in a Three-Dimensional approach with the\ninclusion of the three-body forces is proposed. The four-body bound state with\ntwo- and three-body interactions is formulated in Three-Dimensional approach\nfor identical particles as function of vector Jacobi momenta, specifically the\nmagnitudes of the momenta and the angles between them. The modified three\ndimensional Yakubovsky integral equations is successfully solved with the\nscalar two-meson exchange three-body force where the Malfliet-Tjon-type\ntwo-body force is implemented. The three-body force effects on the energy\neigenvalue and the four-body wave function, as well as accuracy of our\nnumerical calculations are presented.The four-body Yakubovsky equations in a\nThree-Dimensional approach with the inclusion of the three-body forces is\nproposed. The four-body bound state with two- and three-body interactions is\nformulated in Three-Dimensional approach for identical particles as function of\nvector Jacobi momenta, specifically the magnitudes of the momenta and the\nangles between them. The modified three dimensional Yakubovsky integral\nequations is successfully solved with the scalar two-meson exchange three-body\nforce where the Malfliet-Tjon-type two-body force is implemented. The\nthree-body force effects on the energy eigenvalue and the four-body wave\nfunction, as well as accuracy of our numerical calculations are presented.\n", "machine_text": "This paper examines the Three-Dimensional Yakubovsky equations with the addition of three-body forces. This equation is developed in order to create a four-body bound state between identical particles, utilizing the magnitude and angles of vector Jacobi momenta. The energy eigenvalue, wave function, and numerical accuracy of our calculations are all evaluated by the addition of a scalar two-meson exchange three-body force. In addition, the Malfliet-Tjon-type two-body force is implemented.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2056}
{"prompt": "Rephrase the abstract of an article with title 'A New Proof of Pappus's Theorem'.\n  Any stretching of Ringel's non-Pappus pseudoline arrangement when projected\ninto the Euclidean plane, implicitly contains a particular arrangement of nine\ntriangles. This arrangement has a complex constraint involving the sines of its\nangles. These constraints cannot be satisfied by any projection of the initial\narrangement. This is sufficient to prove Pappus's theorem. The derivation of\nthe constraint is via systems of inequalities arising from the polar\ncoordinates of the lines. These systems are linear in r for any given theta,\nand their solubility can be analysed in terms of the signs of determinants. The\nevaluation of the determinants is via a normal form for sums of products of\nsines, giving a powerful system of trigonometric identities. The particular\nresult is generalized to arrangements derived from three edge connected totally\ncyclic directed graphs, conjectured to be sufficient for a complete analysis of\nangle constraining arrangements of lines, and thus a full response to Ringel's\nslope conjecture. These methods are generally applicable to the realizability\nproblem for rank 3 oriented matroids.\n\n", "human_text": "  Any stretching of Ringel's non-Pappus pseudoline arrangement when projected\ninto the Euclidean plane, implicitly contains a particular arrangement of nine\ntriangles. This arrangement has a complex constraint involving the sines of its\nangles. These constraints cannot be satisfied by any projection of the initial\narrangement. This is sufficient to prove Pappus's theorem. The derivation of\nthe constraint is via systems of inequalities arising from the polar\ncoordinates of the lines. These systems are linear in r for any given theta,\nand their solubility can be analysed in terms of the signs of determinants. The\nevaluation of the determinants is via a normal form for sums of products of\nsines, giving a powerful system of trigonometric identities. The particular\nresult is generalized to arrangements derived from three edge connected totally\ncyclic directed graphs, conjectured to be sufficient for a complete analysis of\nangle constraining arrangements of lines, and thus a full response to Ringel's\nslope conjecture. These methods are generally applicable to the realizability\nproblem for rank 3 oriented matroids.\n", "machine_text": "\nBy projecting Ringel's non-Pappus pseudoline arrangement into the Euclidean plane, one can observe that a particular arrangement of nine triangles is implicitly embedded. This arrangement is subject to a complex constraint involving the sines of its angles, which is impossible to be satisfied by any projection of the initial arrangement. These observations, along with the use of systems of inequalities arising from the polar coordinates of the lines and normal forms for sums of products of sines, provide sufficient evidence to prove Pappus's theorem. Furthermore, this result can be generalized to arrangements derived from edge-connected, totally cyclic directed graphs, potentially leading to a full solution to the sliding problem for rank 3 oriented matroids.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3424}
{"prompt": "Rephrase the abstract of an article with title 'Alignment and signed-intensity anomalies in WMAP data'.\n  Significant alignment and signed-intensity anomalies of local features of the\ncosmic microwave background (CMB) are detected on the three-year WMAP data,\nthrough a decomposition of the signal with steerable wavelets on the sphere.\nFirstly, an alignment analysis identifies two mean preferred planes in the sky,\nboth with normal axes close to the CMB dipole axis. The first plane is defined\nby the directions toward which local CMB features are anomalously aligned. A\nmean preferred axis is also identified in this plane, located very close to the\necliptic poles axis. The second plane is defined by the directions anomalously\navoided by local CMB features. This alignment anomaly provides further insight\non recent results (Wiaux et al. 2006). Secondly, a signed-intensity analysis\nidentifies three mean preferred directions in the southern galactic hemisphere\nwith anomalously high or low temperature of local CMB features: a cold spot\nessentially identified with a known cold spot (Vielva et al. 2004), a second\ncold spot lying very close to the southern end of the CMB dipole axis, and a\nhot spot lying close to the southern end of the ecliptic poles axis. In both\nanalyses, the anomalies are observed at wavelet scales corresponding to angular\nsizes around 10 degress on the celestial sphere, with global significance\nlevels around 1%. Further investigation reveals that the alignment and\nsigned-intensity anomalies are only very partially related. Instrumental noise,\nforeground emissions, as well as some form of other systematics, are strongly\nrejected as possible origins of the detections. An explanation might still be\nenvisaged in terms of a global violation of the isotropy of the Universe,\ninducing an intrinsic statistical anisotropy of the CMB.\n\n", "human_text": "  Significant alignment and signed-intensity anomalies of local features of the\ncosmic microwave background (CMB) are detected on the three-year WMAP data,\nthrough a decomposition of the signal with steerable wavelets on the sphere.\nFirstly, an alignment analysis identifies two mean preferred planes in the sky,\nboth with normal axes close to the CMB dipole axis. The first plane is defined\nby the directions toward which local CMB features are anomalously aligned. A\nmean preferred axis is also identified in this plane, located very close to the\necliptic poles axis. The second plane is defined by the directions anomalously\navoided by local CMB features. This alignment anomaly provides further insight\non recent results (Wiaux et al. 2006). Secondly, a signed-intensity analysis\nidentifies three mean preferred directions in the southern galactic hemisphere\nwith anomalously high or low temperature of local CMB features: a cold spot\nessentially identified with a known cold spot (Vielva et al. 2004), a second\ncold spot lying very close to the southern end of the CMB dipole axis, and a\nhot spot lying close to the southern end of the ecliptic poles axis. In both\nanalyses, the anomalies are observed at wavelet scales corresponding to angular\nsizes around 10 degress on the celestial sphere, with global significance\nlevels around 1%. Further investigation reveals that the alignment and\nsigned-intensity anomalies are only very partially related. Instrumental noise,\nforeground emissions, as well as some form of other systematics, are strongly\nrejected as possible origins of the detections. An explanation might still be\nenvisaged in terms of a global violation of the isotropy of the Universe,\ninducing an intrinsic statistical anisotropy of the CMB.\n", "machine_text": "\nIn this article, significant alignment and signed-intensity anomalies of local cosmic microwave background (CMB) features have been detected in the three-year WMAP data using a decomposition of the signal with steerable wavelets on the sphere. Specifically, the alignment analysis revealed two mean preferred planes in the sky, the first with normal axes close to the CMB dipole axis and the second with axes anomalously avoided by local CMB features. The signed-intensity analysis identified three mean preferred directions in the southern galactic hemisphere with anomalously high or low temperature of local CMB features. Both anomalies were observed at wavelet scales corresponding to angular sizes around 10 degrees on the celestial sphere and with global significance levels around 1%, however the alignment and signed-intensity anomalies were only very partially related. Instrumental noise, foreground emissions, and other potential systematics have been strongly rejected as possible origins of the detection. An explanation of the anomalies could lie in a global violation of the isotropy of the Universe, in turn inducing an intrinsic statistical anisotropy of the CMB.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3736}
{"prompt": "Rephrase the abstract of an article with title 'The building up of the disk galaxy M33 and the evolution of the\n  metallicity gradient'.\n  The evolution of radial gradients of metallicity in disk galaxies and its\nrelation with the disk formation are not well understood. Theoretical models of\ngalactic chemical evolution make contrasting predictions about the time\nevolution of metallicity gradients. To test chemical evolution models and trace\nthe star formation and accretion history of low luminosity disk galaxies we\nfocus on the Local Group galaxy M33. We analyze O/H and S/H abundances in\nplanetary nebulae, H{\\sc ii} regions, and young stars, together with known\n[Fe/H] abundances in the old stellar population of M33. With a theoretical\nmodel, we follow the time evolution of gas (diffuse and condensed in clouds),\nstars, and chemical abundances in the disk of M33, assuming that the galaxy is\naccreting gas from an external reservoir. Our model is able to reproduce the\navailable observational constraints on the distribution of gas and stars in M33\nand to predict the time evolution of several chemical abundances. In\nparticular, we find that a model characterized by a continuous infall of gas on\nthe disk, at a rate of $\\dot M_{\\rm inf}\\approx 1$ $M_\\odot$ yr$^{-1}$, almost\nconstant with time, can also account for the relatively high rate of star\nformation and for the shallow chemical gradients. Supported by a large sample\nof high resolution observations for this nearby galaxy, we conclude that the\nmetallicity in the disk of M33 has increased with time at all radii, with a\ncontinuous flattening of the gradient over the last $\\sim 8$ Gyr.\n\n", "human_text": "  The evolution of radial gradients of metallicity in disk galaxies and its\nrelation with the disk formation are not well understood. Theoretical models of\ngalactic chemical evolution make contrasting predictions about the time\nevolution of metallicity gradients. To test chemical evolution models and trace\nthe star formation and accretion history of low luminosity disk galaxies we\nfocus on the Local Group galaxy M33. We analyze O/H and S/H abundances in\nplanetary nebulae, H{\\sc ii} regions, and young stars, together with known\n[Fe/H] abundances in the old stellar population of M33. With a theoretical\nmodel, we follow the time evolution of gas (diffuse and condensed in clouds),\nstars, and chemical abundances in the disk of M33, assuming that the galaxy is\naccreting gas from an external reservoir. Our model is able to reproduce the\navailable observational constraints on the distribution of gas and stars in M33\nand to predict the time evolution of several chemical abundances. In\nparticular, we find that a model characterized by a continuous infall of gas on\nthe disk, at a rate of $\\dot M_{\\rm inf}\\approx 1$ $M_\\odot$ yr$^{-1}$, almost\nconstant with time, can also account for the relatively high rate of star\nformation and for the shallow chemical gradients. Supported by a large sample\nof high resolution observations for this nearby galaxy, we conclude that the\nmetallicity in the disk of M33 has increased with time at all radii, with a\ncontinuous flattening of the gradient over the last $\\sim 8$ Gyr.\n", "machine_text": "\nThis study examines the relationship between the formation of a disk galaxy and the evolution of its metallicity gradient. To do this, we focus on the Local Group galaxy M33, conducting radiative and spectroscopic analyses of planetary nebulae, H{\\sc ii} regions, young stars and the old stellar population. A theoretical model based on the continuous accretion of gas from an external source into the disk of M33 is used to predict the time-evolution and metallicity of various chemical abundances. The model shows that a rate of gas infall close to 1 $M_\\odot$ yr$^{-1}$ over the past 8 billion years is able to simultaneously explain the observed rate of star formation and the shallow observed chemical gradients. This study, bolstered by the large amount of observational data now available, suggests that the metal content in M33's disk has risen with time at all radii, slowly flattening the gradient. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3187}
{"prompt": "Rephrase the abstract of an article with title 'The Sedentary Survey of Extreme High Energy Peaked BL Lacs III. Results\n  from Optical Spectroscopy'.\n  The multi-frequency Sedentary Survey is a flux limited, statistically\nwell-defined sample of highly X-ray dominated BL Lacertae objects (HBLs) which\nincludes 150 sources. In this paper, the third of the series, we report the\nresults of a dedicated optical spectroscopy campaign that, together with\nresults from other independent optical follow up programs, led to the\nspectroscopic identification of all sources in the sample. We carried out a\nsystematic spectroscopic campaign for the observation of all unidentified\nobjects of the sample using the ESO 3.6m, the KPNO 4m, and the TNG optical\ntelescopes. We present new identifications and optical spectra for 76 sources,\n50 of which are new BL Lac objects, 18 are sources previously referred as BL\nLacs but for which no redshift information was available, and 8 are broad\nemission lines AGNs. We find that the multi-frequency selection technique used\nto build the survey is highly efficient (about 90%) in selecting BL Lacs\nobjects. We present positional and spectroscopic information for all confirmed\nBL Lac objects. Our data allowed us to determined 36 redshifts out of the 50\nnew BL Lacs and 5 new redshifts for the previously known objects. The redshift\ndistribution of the complete sample is presented and compared with that of\nother BL Lacs samples. For 26 sources without recognizable absorption features,\nwe calculated lower limits to the redshift using a method based on simulated\noptical spectra with different ratios between jet and galaxy emission. For a\nsubsample of 38 object with high-quality spectra, we find a correlation between\nthe optical spectral slope, the 1.4 GHz radio luminosity, and the Ca H&K break\nvalue, indicating that for powerful/beamed sources the optical light is\ndominated by the non-thermal emission from the jet.\n\n", "human_text": "  The multi-frequency Sedentary Survey is a flux limited, statistically\nwell-defined sample of highly X-ray dominated BL Lacertae objects (HBLs) which\nincludes 150 sources. In this paper, the third of the series, we report the\nresults of a dedicated optical spectroscopy campaign that, together with\nresults from other independent optical follow up programs, led to the\nspectroscopic identification of all sources in the sample. We carried out a\nsystematic spectroscopic campaign for the observation of all unidentified\nobjects of the sample using the ESO 3.6m, the KPNO 4m, and the TNG optical\ntelescopes. We present new identifications and optical spectra for 76 sources,\n50 of which are new BL Lac objects, 18 are sources previously referred as BL\nLacs but for which no redshift information was available, and 8 are broad\nemission lines AGNs. We find that the multi-frequency selection technique used\nto build the survey is highly efficient (about 90%) in selecting BL Lacs\nobjects. We present positional and spectroscopic information for all confirmed\nBL Lac objects. Our data allowed us to determined 36 redshifts out of the 50\nnew BL Lacs and 5 new redshifts for the previously known objects. The redshift\ndistribution of the complete sample is presented and compared with that of\nother BL Lacs samples. For 26 sources without recognizable absorption features,\nwe calculated lower limits to the redshift using a method based on simulated\noptical spectra with different ratios between jet and galaxy emission. For a\nsubsample of 38 object with high-quality spectra, we find a correlation between\nthe optical spectral slope, the 1.4 GHz radio luminosity, and the Ca H&K break\nvalue, indicating that for powerful/beamed sources the optical light is\ndominated by the non-thermal emission from the jet.\n", "machine_text": "This paper presents the results of an observational campaign to identify and spectroscopically characterize the 150-member sample of high-energy X-ray dominated BL Lacertae objects (HBLs) contained in the multi-frequency Sedentary Survey. Using a combination of ESO 3.6m, KPNO 4m, and Telescopio Nazionale Galileo (TNG) optical telescopes, 76 sources were identified and spectra obtained, 50 of which were newly determined to be BL Lac objects, 18 of which were already classified as BL Lacs for which no redshift measurement was available, and 8 being broad emission-line AGNs. A 90% efficiency was calculated for this selection technique. Positional and spectroscopic information for all BL Lacs in the sample are provided, as well as the redshift distributions when compared to other BL Lac samples. Lower limits to the redshift are calculated for 26 sources lacking recognizable absorption features, and a correlation between optical spectral slope, 1.4GHz radio luminosity, and Ca H&K break is found for the 38 sources with high-quality spectra, indicating that in powerful and beamed sources, the optical light is mostly from non-thermal emission from the jet.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1729}
{"prompt": "Rephrase the abstract of an article with title 'Equation of state of isospin-asymmetric nuclear matter in relativistic\n  mean-field models with chiral limits'.\n  Using in-medium hadron properties according to the Brown-Rho scaling due to\nthe chiral symmetry restoration at high densities and considering naturalness\nof the coupling constants, we have newly constructed several relativistic\nmean-field Lagrangians with chiral limits. The model parameters are adjusted\nsuch that the symmetric part of the resulting equation of state at supra-normal\ndensities is consistent with that required by the collective flow data from\nhigh energy heavy-ion reactions, while the resulting density dependence of the\nsymmetry energy at sub-saturation densities agrees with that extracted from the\nrecent isospin diffusion data from intermediate energy heavy-ion reactions. The\nresulting equations of state have the special feature of being soft at\nintermediate densities but stiff at high densities naturally. With these\nconstrained equations of state, it is found that the radius of a 1.4$M_\\odot$\ncanonical neutron star is in the range of 11.9 km$\\leq$R$\\leq$13.1 km, and the\nmaximum neutron star mass is around 2.0$M_\\odot$ close to the recent\nobservations.\n\n", "human_text": "  Using in-medium hadron properties according to the Brown-Rho scaling due to\nthe chiral symmetry restoration at high densities and considering naturalness\nof the coupling constants, we have newly constructed several relativistic\nmean-field Lagrangians with chiral limits. The model parameters are adjusted\nsuch that the symmetric part of the resulting equation of state at supra-normal\ndensities is consistent with that required by the collective flow data from\nhigh energy heavy-ion reactions, while the resulting density dependence of the\nsymmetry energy at sub-saturation densities agrees with that extracted from the\nrecent isospin diffusion data from intermediate energy heavy-ion reactions. The\nresulting equations of state have the special feature of being soft at\nintermediate densities but stiff at high densities naturally. With these\nconstrained equations of state, it is found that the radius of a 1.4$M_\\odot$\ncanonical neutron star is in the range of 11.9 km$\\leq$R$\\leq$13.1 km, and the\nmaximum neutron star mass is around 2.0$M_\\odot$ close to the recent\nobservations.\n", "machine_text": "\nThis paper has developed new relativistic mean-field Lagrangians based on the Brown-Rho scaling due to the chiral symmetry restoration at high densities and adjusted the parameters taking into account naturalness of the coupling constants. The equation of state at supra-normal densities is consistent with collective flow data from high energy heavy-ion reactions, while the density dependence of the symmetry energy at sub-saturation densities matches with the isospin diffusion results from intermediate energy heavy-ion reactions. This newly developed model produces an equation of state which is soft at intermediate densities, but stiff at higher densities and predicts the canonical neutron star radii being in the range of 11.9 km to 13.1 km, and the maximum mass close to 2.0$M_\\odot$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1738}
{"prompt": "Rephrase the abstract of an article with title 'A High-Resolution Survey of Low-Redshift QSO Absorption Lines:\n  Statistics and Physical Conditions of O VI Absorbers'.\n  Using high-resolution UV spectra of 16 low-z QSOs, we study the physical\nconditions and statistics of O VI absorption in the IGM at z < 0.5. We identify\n51 intervening (z_{abs} << z_{QSO}) O VI systems comprised of 77 individual\ncomponents, and we find 14 \"proximate\" systems (z_{abs} ~ z_{QSO}) containing\n34 components. For intervening systems [components] with rest-frame equivalent\nwidth W_{r} > 30 mA, the number of O VI absorbers per unit redshift dN/dz =\n15.6(+2.9/-2.4) [21.0(+3.2/-2.8)], and this decreases to dN/dz = 0.9(+1.0/-0.5)\n[0.3(+0.7/-0.3)] for W_{r} > 300 mA. The number per redshift increases steeply\nas z_{abs} approaches z_{QSO}, and some proximate absorbers have substantially\nlower H I/O VI ratios. The lower proximate ratios could be partially due to\nionization effects but also require higher metallicities. We find that 37% of\nthe intervening O VI absorbers have velocity centroids that are well-aligned\nwith corresponding H I absorption. If the O VI and the H I trace the same gas,\nthe relatively small differences in line widths imply the absorbers are cool\nwith T < 10^{5} K. Most of these well-aligned absorbers have the\ncharacteristics of metal-enriched photoionized gas. However, the O VI in the\napparently simple and cold systems could be associated with a hot phase with T\n~ 10^{5.5} K if the metallicity is high enough to cause the associated broad Ly\nalpha absorption to be too weak to detect. We show that 53% of the intervening\nO VI systems are complex multiphase absorbers that can accommodate both lower\nmetallicity collisionally-ionized gas with T > 10^{5} K and cold photoionzed\ngas.\n\n", "human_text": "  Using high-resolution UV spectra of 16 low-z QSOs, we study the physical\nconditions and statistics of O VI absorption in the IGM at z < 0.5. We identify\n51 intervening (z_{abs} << z_{QSO}) O VI systems comprised of 77 individual\ncomponents, and we find 14 \"proximate\" systems (z_{abs} ~ z_{QSO}) containing\n34 components. For intervening systems [components] with rest-frame equivalent\nwidth W_{r} > 30 mA, the number of O VI absorbers per unit redshift dN/dz =\n15.6(+2.9/-2.4) [21.0(+3.2/-2.8)], and this decreases to dN/dz = 0.9(+1.0/-0.5)\n[0.3(+0.7/-0.3)] for W_{r} > 300 mA. The number per redshift increases steeply\nas z_{abs} approaches z_{QSO}, and some proximate absorbers have substantially\nlower H I/O VI ratios. The lower proximate ratios could be partially due to\nionization effects but also require higher metallicities. We find that 37% of\nthe intervening O VI absorbers have velocity centroids that are well-aligned\nwith corresponding H I absorption. If the O VI and the H I trace the same gas,\nthe relatively small differences in line widths imply the absorbers are cool\nwith T < 10^{5} K. Most of these well-aligned absorbers have the\ncharacteristics of metal-enriched photoionized gas. However, the O VI in the\napparently simple and cold systems could be associated with a hot phase with T\n~ 10^{5.5} K if the metallicity is high enough to cause the associated broad Ly\nalpha absorption to be too weak to detect. We show that 53% of the intervening\nO VI systems are complex multiphase absorbers that can accommodate both lower\nmetallicity collisionally-ionized gas with T > 10^{5} K and cold photoionzed\ngas.\n", "machine_text": "\nIn this work, we survey the physical conditions and statistics of O VI\nabsorbers with high-resolution UV spectra for 16 low-redshift quasars. We\nidentify 51 intervening (z_{abs} << z_{QSO}) systems of O VI with 77\ncomponent lines, and also detect 14 nearby, or 'proximate', systems of\nO VI with 34 components, located at z_{abs} ~ z_{QSO}. Through\nmeasurement of the rest-frame equivalent width of the identified\nlines, we observe that for O VI absorbers with W_{r} > 30 mA, the number\nper unit redshift is 15.6(+2.9/-2.4) [21.0(+3.2/-2.8)] and drops to\n0.9(+1.0/-0.5) [0.3(+0.7/-0.3)] when W_{r} > 300 mA. We also find\nthat when O VI and H I absorbers coexist, the velocity centroids and\nwidths of the two align, suggesting that T < 10^5 K. This likely\nimplies that the absorbers are of metal-enriched photoionized gas. Investigating\nmultiphase absorbers, we surmise that the O VI systems could contain both\nlow-metallicity, collisionally-ionized gas and lower-temperature, photoionized gas. ", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1214}
{"prompt": "Rephrase the abstract of an article with title 'Stability and mode analysis of solar coronal loops using thermodynamic\n  irreversible energy principles'.\n  We study the modes and stability of non - isothermal coronal loop models with\ndifferent intensity values of the equilibrium magnetic field. We use an energy\nprinciple obtained via non - equilibrium thermodynamic arguments. The principle\nis expressed in terms of Hermitian operators and allow to consider together the\ncoupled system of equations: the balance of energy equation and the equation of\nmotion. We determine modes characterized as long - wavelength disturbances that\nare present in inhomogeneous media. This character of the system introduces\nadditional difficulties for the stability analysis because the inhomogeneous\nnature of the medium determines the structure of the disturbance, which is no\nlonger sinusoidal. Moreover, another complication is that we obtain a\ncontinuous spectrum of stable modes in addition to the discrete one. We obtain\na unique unstable mode with a characteristic time that is comparable with the\ncharacteristic life-time observed for loops. The feasibility of wave-based and\nflow-based models is examined.\n\n", "human_text": "  We study the modes and stability of non - isothermal coronal loop models with\ndifferent intensity values of the equilibrium magnetic field. We use an energy\nprinciple obtained via non - equilibrium thermodynamic arguments. The principle\nis expressed in terms of Hermitian operators and allow to consider together the\ncoupled system of equations: the balance of energy equation and the equation of\nmotion. We determine modes characterized as long - wavelength disturbances that\nare present in inhomogeneous media. This character of the system introduces\nadditional difficulties for the stability analysis because the inhomogeneous\nnature of the medium determines the structure of the disturbance, which is no\nlonger sinusoidal. Moreover, another complication is that we obtain a\ncontinuous spectrum of stable modes in addition to the discrete one. We obtain\na unique unstable mode with a characteristic time that is comparable with the\ncharacteristic life-time observed for loops. The feasibility of wave-based and\nflow-based models is examined.\n", "machine_text": "\nWe investigate the stabilty and many forms of the solar corona in an unconstrained setting with varying intensity levels of the magnetic field in equilibrium. We implement an energy-based approach obtained via non-equilibrium thermodynamics which is conveyed as Hermitian operators, to keep tabs on both the motion equation as well as the energy balance. The resultant modes stand out as long wavelength perturbations in heterogeneous milieu. Such a tricky system requires an analytic examination of the stability since there is an entire spectrum of consonant modes along with a solitary unstable mode with a lifetime roughly identical to coronal loops. Finally, to assess the functionalities of wave and flow based models, a comparison is drawn.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1067}
{"prompt": "Rephrase the abstract of an article with title 'Evolutionary Optimisation Methods for Template Based Image Registration'.\n  This paper investigates the use of evolutionary optimisation techniques to\nregister a template with a scene image. An error function is created to measure\nthe correspondence of the template to the image. The problem presented here is\nto optimise the horizontal, vertical and scaling parameters that register the\ntemplate with the scene. The Genetic Algorithm, Simulated Annealing and\nParticle Swarm Optimisations are compared to a Nelder-Mead Simplex optimisation\nwith starting points chosen in a pre-processing stage. The paper investigates\nthe precision and accuracy of each method and shows that all four methods\nperform favourably for image registration. SA is the most precise, GA is the\nmost accurate. PSO is a good mix of both and the Simplex method returns local\nminima the most. A pre-processing stage should be investigated for the\nevolutionary methods in order to improve performance. Discrete versions of the\noptimisation methods should be investigated to further improve computational\nperformance.\n\n", "human_text": "  This paper investigates the use of evolutionary optimisation techniques to\nregister a template with a scene image. An error function is created to measure\nthe correspondence of the template to the image. The problem presented here is\nto optimise the horizontal, vertical and scaling parameters that register the\ntemplate with the scene. The Genetic Algorithm, Simulated Annealing and\nParticle Swarm Optimisations are compared to a Nelder-Mead Simplex optimisation\nwith starting points chosen in a pre-processing stage. The paper investigates\nthe precision and accuracy of each method and shows that all four methods\nperform favourably for image registration. SA is the most precise, GA is the\nmost accurate. PSO is a good mix of both and the Simplex method returns local\nminima the most. A pre-processing stage should be investigated for the\nevolutionary methods in order to improve performance. Discrete versions of the\noptimisation methods should be investigated to further improve computational\nperformance.\n", "machine_text": "\nThis article studies the application of evolutionary optimisation techniques in template-based image registration. An error function is devised to calculate the fit of the template to the image. The task is to optimise the horizontal, vertical and scaling parameters that would position the template in proper alignment with the scene. Four different optimisation methods are compared: Genetic Algorithm, Simulated Annealing, Particle Swarm Optimisation, and Nelder-Mead Simplex. The paper looks at the exactness and the correctness of each method and found that all four work effectively for image registration; with Simulated Annealing scoring the highest for accuracy, Genetic Algorithm being the most accurate, Particle Swarm providing a good blend of the two, and Nelder-Mead Simplex returning the most local minimums. To further enhance performance, it is recommended to consider adding a pre-processing stage to the evolutionary methods, as well as exploring the potential benefits of discrete versions of the said optimisation algorithms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1674}
{"prompt": "Rephrase the abstract of an article with title 'Type D Einstein spacetimes in higher dimensions'.\n  We show that all static spacetimes in higher dimensions are of Weyl types G,\nI_i, D or O. This applies also to stationary spacetimes if additional\nconditions are fulfilled, as for most known black hole/ring solutions. (The\nconclusions change when the Killing generator becomes null, such as at Killing\nhorizons.) Next we demonstrate that the same Weyl types characterize warped\nproduct spacetimes with a one-dimensional Lorentzian (timelike) factor, whereas\nwarped spacetimes with a two-dimensional Lorentzian factor are restricted to\nthe types D or O. By exploring the Bianchi identities, we then analyze the\nsimplest non-trivial case from the above classes - type D vacuum spacetimes,\npossibly with a cosmological constant, dropping, however, the assumptions that\nthe spacetime is static, stationary or warped. It is shown that for ``generic''\ntype D vacuum spacetimes the corresponding principal null directions are\ngeodetic in any dimension (this applies also to type II spacetimes). For n>=5,\nhowever, there may exist particular cases of type D spacetimes which admit\nnon-geodetic multiple principal null directions and we present such examples in\nany n>=7. Further studies are restricted to five dimensions, where the type D\nWeyl tensor is described by a 3x3 matrix \\Phi_{ij}. In the case with\n``twistfree'' (A_{ij}=0) principal null geodesics we show that in a ``generic''\ncase \\Phi_{ij} is symmetric and eigenvectors of \\Phi_{ij} coincide with those\nof the expansion matrix S_{ij}, providing us with three preferred spacelike\ndirections of the spacetime. Similar results are also obtained when relaxing\nthe twistfree condition and assuming instead that \\Phi_{ij} is symmetric. The\nn=5 Myers-Perry black hole and Kerr-NUT-AdS metrics in arbitrary dimension are\nbriefly studied as specific examples of type D vacuum spacetime.\n\n", "human_text": "  We show that all static spacetimes in higher dimensions are of Weyl types G,\nI_i, D or O. This applies also to stationary spacetimes if additional\nconditions are fulfilled, as for most known black hole/ring solutions. (The\nconclusions change when the Killing generator becomes null, such as at Killing\nhorizons.) Next we demonstrate that the same Weyl types characterize warped\nproduct spacetimes with a one-dimensional Lorentzian (timelike) factor, whereas\nwarped spacetimes with a two-dimensional Lorentzian factor are restricted to\nthe types D or O. By exploring the Bianchi identities, we then analyze the\nsimplest non-trivial case from the above classes - type D vacuum spacetimes,\npossibly with a cosmological constant, dropping, however, the assumptions that\nthe spacetime is static, stationary or warped. It is shown that for ``generic''\ntype D vacuum spacetimes the corresponding principal null directions are\ngeodetic in any dimension (this applies also to type II spacetimes). For n>=5,\nhowever, there may exist particular cases of type D spacetimes which admit\nnon-geodetic multiple principal null directions and we present such examples in\nany n>=7. Further studies are restricted to five dimensions, where the type D\nWeyl tensor is described by a 3x3 matrix \\Phi_{ij}. In the case with\n``twistfree'' (A_{ij}=0) principal null geodesics we show that in a ``generic''\ncase \\Phi_{ij} is symmetric and eigenvectors of \\Phi_{ij} coincide with those\nof the expansion matrix S_{ij}, providing us with three preferred spacelike\ndirections of the spacetime. Similar results are also obtained when relaxing\nthe twistfree condition and assuming instead that \\Phi_{ij} is symmetric. The\nn=5 Myers-Perry black hole and Kerr-NUT-AdS metrics in arbitrary dimension are\nbriefly studied as specific examples of type D vacuum spacetime.\n", "machine_text": "In this article, we explore the Weyl type classifications of static, stationary, and warped product spacetimes in higher dimensions in relation to Einstein spacetimes. For a vacuum spacetime, we distinguish between those that can be categorized as type D and those that cannot. We demonstrate that for most of these cases, the principal null directions are geodetic, regardless of the dimension. Furthermore, in the event that the twistfree condition is not met, we provide examples of spacetimes in any dimension n\u22657 that have non-geodetic multiple principal null directions. Finally, the examples of the Myers-Perry black hole and Kerr-NUT-AdS metrics in five dimensions are explored to illustrate the properties of type D vacuum spacetimes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0435}
{"prompt": "Rephrase the abstract of an article with title 'Suzaku Observations of Active Galactic Nuclei Detected in the Swift/BAT\n  Survey: Discovery of \"New Type\" of Buried Supermassive Black Holes'.\n  We present the Suzaku broad band observations of two AGNs detected by the\nSwift/BAT hard X-ray (>15 keV) survey that did not have previous X-ray data,\nSwift J0601.9-8636 and Swift J0138.6-4001. The Suzaku spectra reveals in both\nobjects a heavily absorbed power law component with a column density of NH =~\n10^{23.5-24} cm^{-2} that dominates above 10 keV, and an intense reflection\ncomponent with a solid angle >~ $2\\pi$ from a cold, optically thick medium. We\nfind that these AGNs have an extremely small fraction of scattered light from\nthe nucleus, <~ 0.5% with respect to the intrinsic power law component. This\nindicates that they are buried in a very geometrically-thick torus with a small\nopening angle and/or have unusually small amount of gas responsible for\nscattering. In the former case, the geometry of Swift J0601.9-8636 should be\nnearly face-on as inferred from the small absorption for the reflection\ncomponent. The discovery of two such objects in this small sample implies that\nthere must be a significant number of yet unrecognized, very Compton thick AGNs\nviewed at larger inclination angles in the local universe, which are difficult\nto detect even in the currently most sensitive optical or hard X-ray surveys.\n\n", "human_text": "  We present the Suzaku broad band observations of two AGNs detected by the\nSwift/BAT hard X-ray (>15 keV) survey that did not have previous X-ray data,\nSwift J0601.9-8636 and Swift J0138.6-4001. The Suzaku spectra reveals in both\nobjects a heavily absorbed power law component with a column density of NH =~\n10^{23.5-24} cm^{-2} that dominates above 10 keV, and an intense reflection\ncomponent with a solid angle >~ $2\\pi$ from a cold, optically thick medium. We\nfind that these AGNs have an extremely small fraction of scattered light from\nthe nucleus, <~ 0.5% with respect to the intrinsic power law component. This\nindicates that they are buried in a very geometrically-thick torus with a small\nopening angle and/or have unusually small amount of gas responsible for\nscattering. In the former case, the geometry of Swift J0601.9-8636 should be\nnearly face-on as inferred from the small absorption for the reflection\ncomponent. The discovery of two such objects in this small sample implies that\nthere must be a significant number of yet unrecognized, very Compton thick AGNs\nviewed at larger inclination angles in the local universe, which are difficult\nto detect even in the currently most sensitive optical or hard X-ray surveys.\n", "machine_text": "\n\nThis study, based on Suzaku broad band observations, examined two previously\nunobserved Active Galactic Nuclei (AGNs) detected by the Swift/BAT hard X-ray\nsurvey. It finds both objects contain heavily absorbed power law components,\nreflection components from an optically thick medium, and a tiny fraction of\nscattered light from the nucleus. We conclude that these AGNs are buried in\ngeometrically-thick tori with a narrow opening angle, and postulate there must\nbe more of this \"new type\" of buried supermassive black hole present in the\nlocal universe that have not yet been detected by current optical or hard X-ray\nsurveys.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1168}
{"prompt": "Rephrase the abstract of an article with title 'Characteristics of phonon transmission across epitaxial interfaces: a\n  lattice dynamic study'.\n  Phonon transmission across epitaxial interfaces is studied within the lattice\ndynamic approach. The transmission shows weak dependence on frequency for the\nlattice wave with a fixed angle of incidence. The dependence on azimuth angle\nis found to be related to the symmetry of the boundary interface. The\ntransmission varies smoothly with the change of the incident angle. A critical\nangle of incidence exists when the phonon is incident from the side with large\ngroup velocities to the side with low ones. No significant mode conversion is\nobserved among different acoustic wave branches at the interface, except when\nthe incident angle is near the critical value. Our theoretical result of the\nKapitza conductance $G_{K}$ across the Si-Ge (100) interface at temperature\n$T=200 $K is $4.6\\times10^{8} {\\rm WK}^{-1}{\\rmm}^{-2}$. A scaling law $G_K\n\\propto T^{2.87}$ at low temperature is also reported. Based on the features of\ntransmission obtained within lattice dynamic approach, we propose a simplified\nformula for thermal conductanceacross the epitaxial interface. A reasonable\nconsistency is found between the calculated values and the experimentally\nmeasured ones.\n\n", "human_text": "  Phonon transmission across epitaxial interfaces is studied within the lattice\ndynamic approach. The transmission shows weak dependence on frequency for the\nlattice wave with a fixed angle of incidence. The dependence on azimuth angle\nis found to be related to the symmetry of the boundary interface. The\ntransmission varies smoothly with the change of the incident angle. A critical\nangle of incidence exists when the phonon is incident from the side with large\ngroup velocities to the side with low ones. No significant mode conversion is\nobserved among different acoustic wave branches at the interface, except when\nthe incident angle is near the critical value. Our theoretical result of the\nKapitza conductance $G_{K}$ across the Si-Ge (100) interface at temperature\n$T=200 $K is $4.6\\times10^{8} {\\rm WK}^{-1}{\\rmm}^{-2}$. A scaling law $G_K\n\\propto T^{2.87}$ at low temperature is also reported. Based on the features of\ntransmission obtained within lattice dynamic approach, we propose a simplified\nformula for thermal conductanceacross the epitaxial interface. A reasonable\nconsistency is found between the calculated values and the experimentally\nmeasured ones.\n", "machine_text": " This article investigates the characteristics of phonon transmission through epitaxial interfaces by employing lattice dynamic approach. The results indicate that the transmission characteristic is weakly dependent on frequency and is related to the symmetry of the boundary when the azimuth angle is observed. The transmission also fluctuates smoothly while the incident angle modifies. The analysis suggests the existence of a critical angle of incidence when phonons are coming to the interface between regions with larger and smaller group velocities. Aside from an incident angle near the critical value, scant mode transformations are noticed among different acoustic wave branches at the interface. The theoretical Kapitza conductance across the Si-Ge (100) interface at temperature $T=200$ Kelvin is $4.6\\times 10^{8} {\\rm WK}^{-1}{\\rmm}^{-2}$ and a scaling law $G_K \\propto T^{2.87}$ is suggested for comparatively low temperatures. Additionally, this study presents a simplified formula for thermal conductance across the epitaxial interface that is found to be consistent with experimental results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2954}
{"prompt": "Rephrase the abstract of an article with title 'Distortion in Groups of Circle and Surface Diffeomorphisms'.\n  In these lectures we consider how algebraic properties of discrete subgroups\nof Lie groups restrict the possible actions of those groups on surfaces. The\nresults show a strong parallel between the possible actions of such a group on\nthe circle $S^1$ and the measure preserving actions on surfaces.\n  Our aim is the study of the (non)-existence of actions of lattices in a large\nclass of non-compact Lie groups on surfaces. A definitive analysis of the\nanalogous question for actions on $S^1$ was carried out by \\'E. Ghys. Our\napproach is topological and insofar as possible we try to isolate properties of\na group which provide the tools necessary for our analysis. The two key\nproperties we consider are almost simplicity and the existence of a distortion\nelement. Both will be defined and described in the lectures.\n  Our techniques are almost all from low dimensional dynamics. But we are\ninterested in how algebraic properties of a group -- commutativity, nilpotence,\netc. affect the possible kinds of dynamics which can occur. For most of the\nresults we will consider groups of diffeomorphisms which preserve a Borel\nprobability measure.\n\n", "human_text": "  In these lectures we consider how algebraic properties of discrete subgroups\nof Lie groups restrict the possible actions of those groups on surfaces. The\nresults show a strong parallel between the possible actions of such a group on\nthe circle $S^1$ and the measure preserving actions on surfaces.\n  Our aim is the study of the (non)-existence of actions of lattices in a large\nclass of non-compact Lie groups on surfaces. A definitive analysis of the\nanalogous question for actions on $S^1$ was carried out by \\'E. Ghys. Our\napproach is topological and insofar as possible we try to isolate properties of\na group which provide the tools necessary for our analysis. The two key\nproperties we consider are almost simplicity and the existence of a distortion\nelement. Both will be defined and described in the lectures.\n  Our techniques are almost all from low dimensional dynamics. But we are\ninterested in how algebraic properties of a group -- commutativity, nilpotence,\netc. affect the possible kinds of dynamics which can occur. For most of the\nresults we will consider groups of diffeomorphisms which preserve a Borel\nprobability measure.\n", "machine_text": "\nIn this set of lectures, we investigate how the algebraic characteristics of discrete subgroups of Lie groups affect their possible actions on circles and surfaces. We explore two key properties, namely almost simplicity and the presence of a distortion element, in order to gain insight into the dynamics of non-compact Lie groups on surfaces. Our methods are extensively drawn from low-dimensional dynamics, and we pay particular attention to the influence of features like commutativity and nilpotence. Lastly, our study concentrates mostly on groups of diffeomorphisms that preserve a Borel probability measure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4054}
{"prompt": "Rephrase the abstract of an article with title 'Chiral Properties of Baryon Interpolating Fields'.\n  We study the chiral transformation properties of all possible local\n(non-derivative) interpolating field operators for baryons consisting of three\nquarks with two flavors, assuming good isospin symmetry. We derive and use the\nrelations/identities among the baryon operators with identical quantum numbers\nthat follow from the combined colour, Dirac and isospin Fierz transformations.\nThese relations reduce the number of independent baryon operators with any\ngiven spin and isospin. The Fierz identities also effectively restrict allowed\nbaryon chiral multiplets. It turns out that the chiral multiplets of the\nbaryons are equivalent to their Lorentz representation. For the two independent\nnucleon operators the only permissible chiral multiplet is the fundamental one\n$(\\frac12,0)\\oplus(0,\\frac12)$. For the $\\Delta$, admissible Lorentz\nrepresentations are $(1,\\frac12)\\oplus (\\frac12,1)$ and\n$(\\frac32,0)\\oplus(0,\\frac32)$. In the case of the $(1,\\frac12)\\oplus\n(\\frac12,1)$ chiral multiplet the $I(J)=\\frac32(\\frac32)$ $\\Delta$ field has\none $I(J)=\\frac12(\\frac32)$ chiral partner; otherwise it has none. We also\nconsider the Abelian ($U_A(1)$) chiral transformation properties of fields and\nshow that each baryon comes in two varieties: 1) with Abelian axial charge +3;\nand 2) with Abelian axial charge -1. In case of the nucleon these are the two\nIoffe's fields; in case of the $\\Delta$, the $(1,\\frac12)\\oplus (\\frac12,1)$\nmultiplet has Abelian axial charge -1 and the $(\\frac32,0)\\oplus(0,\\frac32)$\nmultiplet has Abelian axial charge +3.\n\n", "human_text": "  We study the chiral transformation properties of all possible local\n(non-derivative) interpolating field operators for baryons consisting of three\nquarks with two flavors, assuming good isospin symmetry. We derive and use the\nrelations/identities among the baryon operators with identical quantum numbers\nthat follow from the combined colour, Dirac and isospin Fierz transformations.\nThese relations reduce the number of independent baryon operators with any\ngiven spin and isospin. The Fierz identities also effectively restrict allowed\nbaryon chiral multiplets. It turns out that the chiral multiplets of the\nbaryons are equivalent to their Lorentz representation. For the two independent\nnucleon operators the only permissible chiral multiplet is the fundamental one\n$(\\frac12,0)\\oplus(0,\\frac12)$. For the $\\Delta$, admissible Lorentz\nrepresentations are $(1,\\frac12)\\oplus (\\frac12,1)$ and\n$(\\frac32,0)\\oplus(0,\\frac32)$. In the case of the $(1,\\frac12)\\oplus\n(\\frac12,1)$ chiral multiplet the $I(J)=\\frac32(\\frac32)$ $\\Delta$ field has\none $I(J)=\\frac12(\\frac32)$ chiral partner; otherwise it has none. We also\nconsider the Abelian ($U_A(1)$) chiral transformation properties of fields and\nshow that each baryon comes in two varieties: 1) with Abelian axial charge +3;\nand 2) with Abelian axial charge -1. In case of the nucleon these are the two\nIoffe's fields; in case of the $\\Delta$, the $(1,\\frac12)\\oplus (\\frac12,1)$\nmultiplet has Abelian axial charge -1 and the $(\\frac32,0)\\oplus(0,\\frac32)$\nmultiplet has Abelian axial charge +3.\n", "machine_text": "\nIn this article, we explore the chiral transformation properties of baryon operators with two flavors for three quarks. We discuss how the color, Dirac and isospin Fierz transformations can lead to various relations between baryon fields with the same quantum numbers, leading to a reduced number of operators with a specific spin and isospin. The Fierz identities can also be used to limit the chiral multiplets of each baryon, with the chiral multiplet of a nucleon consisting of $(\\frac12,0)\\oplus(0,\\frac12)$ and a $\\Delta$ baryon having both $(1,\\frac12)\\oplus (\\frac12,1)$ and $(\\frac32,0)\\oplus(0,\\frac32)$. An analysis of $U_A \\;(1)$ shows that baryons have either an Abelian axial charge of +3 or -1. We examine this phenomenon, finding dual Abelian axial charges of +3 and -1 for the nucleon's two Ioffe fields and -1 and +3 respectively for the $\\Delta \\;$ $(1,\\frac12)\\oplus (\\frac12,1)$ and $(\\frac32,0)\\oplus(0,\\frac32)$ multiplets.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1896}
{"prompt": "Rephrase the abstract of an article with title 'Sensitivity of solar off-limb line profiles to electron density\n  stratification and the velocity distribution anisotropy'.\n  The effect of the electron density stratification on the intensity profiles\nof the H I Ly-$\\alpha$ line and the O VI and Mg X doublets formed in solar\ncoronal holes is investigated. We employ an analytical 2-D model of the large\nscale coronal magnetic field that provides a good representation of the corona\nat the minimum of solar activity. We use the mass-flux conservation equation to\ndetermine the outflow speed of the solar wind at any location in the solar\ncorona and take into account the integration along the line of sight (LOS). The\nmain assumption we make is that no anisotropy in the kinetic temperature of the\ncoronal species is considered. We find that at distances greater than 1 Rsun\nfrom the solar surface the widths of the emitted lines of O VI and Mg X are\nsensitive to the details of the adopted electron density stratification.\nHowever, Ly-$\\alpha$, which is a pure radiative line, is hardly affected. The\ncalculated total intensities of Ly-$\\alpha$ and the O VI doublet depend to a\nlesser degree on the density stratification and are comparable to the observed\nones for most of the considered density models. The widths of the observed\nprofiles of Ly-$\\alpha$ and Mg X are well reproduced by most of the considered\nelectron density stratifications, while for the O VI doublet only few\nstratifications give satisfying results. The densities deduced from SOHO data\nresult in O VI profiles whose widths and intensity ratio are relatively close\nto the values observed by UVCS although only isotropic velocity distributions\nare employed. These density profiles also reproduce the other considered\nobservables with good accuracy. Thus the need for a strong anisotropy of the\nvelocity distribution (i.e. a temperature anisotropy) is not so clear cut as\nprevious investigations of UVCS data suggested. ...\n\n", "human_text": "  The effect of the electron density stratification on the intensity profiles\nof the H I Ly-$\\alpha$ line and the O VI and Mg X doublets formed in solar\ncoronal holes is investigated. We employ an analytical 2-D model of the large\nscale coronal magnetic field that provides a good representation of the corona\nat the minimum of solar activity. We use the mass-flux conservation equation to\ndetermine the outflow speed of the solar wind at any location in the solar\ncorona and take into account the integration along the line of sight (LOS). The\nmain assumption we make is that no anisotropy in the kinetic temperature of the\ncoronal species is considered. We find that at distances greater than 1 Rsun\nfrom the solar surface the widths of the emitted lines of O VI and Mg X are\nsensitive to the details of the adopted electron density stratification.\nHowever, Ly-$\\alpha$, which is a pure radiative line, is hardly affected. The\ncalculated total intensities of Ly-$\\alpha$ and the O VI doublet depend to a\nlesser degree on the density stratification and are comparable to the observed\nones for most of the considered density models. The widths of the observed\nprofiles of Ly-$\\alpha$ and Mg X are well reproduced by most of the considered\nelectron density stratifications, while for the O VI doublet only few\nstratifications give satisfying results. The densities deduced from SOHO data\nresult in O VI profiles whose widths and intensity ratio are relatively close\nto the values observed by UVCS although only isotropic velocity distributions\nare employed. These density profiles also reproduce the other considered\nobservables with good accuracy. Thus the need for a strong anisotropy of the\nvelocity distribution (i.e. a temperature anisotropy) is not so clear cut as\nprevious investigations of UVCS data suggested. ...\n", "machine_text": "\nThe intensity profiles of the H I Ly-$\\alpha$ line and the O VI and Mg X doublets\nemitted in solar coronal holes are studied in order to determine their sensitivity to electron density stratification. An analytical model for the large-scale coronal magnetic field is utilized to map out the outflow speed of the solar wind at any distance from the solar surface. Based on the assumption of an isotropic kinetic temperature of the coronal species, the effects of the density stratification on the total intensities, widths, and ratio of the observed lines are examined. It is found that the widths of the O VI and Mg X lines are affected by the adopted density profile, while Ly-$\\alpha$ is not. The calculated intensity values for Ly-$\\alpha$ and the O VI doublet are found to be in agreement with the observed measurements for most of the considered density models. Furthermore, the SOHO electron densities can explain the UVCS values for Ly-$\\alpha$ and the O VI doublet with an isotropic velocity distribution, therefore placing into doubt the necessity for strong velocity anisotropy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1127}
{"prompt": "Rephrase the abstract of an article with title 'Relation between exchange-only optimized potential and Kohn-Sham methods\n  with finite basis sets; solution of a paradox'.\n  Arguments showing that exchange-only optimized effective potential (xOEP)\nmethods, with finite basis sets, cannot in general yield the Hartree-Fock (HF)\nground state energy, but a higher one, are given. While the orbital products of\na complete basis are linearly dependent, the HF ground state energy can only be\nobtained via a basis set xOEP scheme in the special case that all products of\noccupied and unoccupied orbitals emerging from the employed orbital basis set\nare linearly independent from each other. In this case, however, exchange\npotentials leading to the HF ground state energy exhibit unphysical\noscillations and do not represent a Kohn-Sham (KS) exchange potential. These\nfindings solve the seemingly paradoxical results of Staroverov, Scuseria and\nDavidson that certain finite basis set xOEP calculations lead to the HF ground\nstate energy despite the fact that within a real space (or complete basis)\nrepresentation the xOEP ground state energy is always higher than the HF\nenergy. Moreover, whether or not the occupied and unoccupied orbital products\nare linearly independent, it is shown that basis set xOEP methods only\nrepresent exact exchange-only (EXX) KS methods, i.e., proper density-functional\nmethods, if the orbital basis set and the auxiliary basis set representing the\nexchange potential are balanced to each other, i.e., if the orbital basis is\ncomprehensive enough for a given auxiliary basis. Otherwise xOEP methods do not\nrepresent EXX KS methods and yield unphysical exchange potentials.\n\n", "human_text": "  Arguments showing that exchange-only optimized effective potential (xOEP)\nmethods, with finite basis sets, cannot in general yield the Hartree-Fock (HF)\nground state energy, but a higher one, are given. While the orbital products of\na complete basis are linearly dependent, the HF ground state energy can only be\nobtained via a basis set xOEP scheme in the special case that all products of\noccupied and unoccupied orbitals emerging from the employed orbital basis set\nare linearly independent from each other. In this case, however, exchange\npotentials leading to the HF ground state energy exhibit unphysical\noscillations and do not represent a Kohn-Sham (KS) exchange potential. These\nfindings solve the seemingly paradoxical results of Staroverov, Scuseria and\nDavidson that certain finite basis set xOEP calculations lead to the HF ground\nstate energy despite the fact that within a real space (or complete basis)\nrepresentation the xOEP ground state energy is always higher than the HF\nenergy. Moreover, whether or not the occupied and unoccupied orbital products\nare linearly independent, it is shown that basis set xOEP methods only\nrepresent exact exchange-only (EXX) KS methods, i.e., proper density-functional\nmethods, if the orbital basis set and the auxiliary basis set representing the\nexchange potential are balanced to each other, i.e., if the orbital basis is\ncomprehensive enough for a given auxiliary basis. Otherwise xOEP methods do not\nrepresent EXX KS methods and yield unphysical exchange potentials.\n", "machine_text": "This paper presents evidence showing that exchange-only optimized effective potential (xOEP) calculatons, while using finite basis sets, are not able to produce Hartree-Fock (HF) ground state energies. This goes against Staroverov, Scuseria and Davidson's assertion that xOEP can lead to exact HF energers under certain circumstances. Solutions to this paradox have been identified too: xOEP only represents exact exchange-only Kohn-Sham methods when the orbital and auxiliary basis sets are balanced. Without this balance, it is not a true KS method, and yields unphysical exchange potentials.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1717}
{"prompt": "Rephrase the abstract of an article with title 'Structural relaxation around substitutional Cr3+ in MgAl2O4'.\n  The structural environment of substitutional Cr3+ ion in MgAl2O4 spinel has\nbeen investigated by Cr K-edge Extended X-ray Absorption Fine Structure (EXAFS)\nand X-ray Absorption Near Edge Structure (XANES) spectroscopies.\nFirst-principles computations of the structural relaxation and of the XANES\nspectrum have been performed, with a good agreement to the experiment. The Cr-O\ndistance is close to that in MgCr2O4, indicating a full relaxation of the first\nneighbors, and the second shell of Al atoms relaxes partially. These\nobservations demonstrate that Vegard's law is not obeyed in the MgAl2O4-MgCr2O4\nsolid solution. Despite some angular site distortion, the local D3d symmetry of\nthe B-site of the spinel structure is retained during the substitution of Cr\nfor Al. Here, we show that the relaxation is accomodated by strain-induced bond\nbuckling, with angular tilts of the Mg-centred tetrahedra around the Cr-centred\noctahedron. By contrast, there is no significant alteration of the angles\nbetween the edge-sharing octahedra, which build chains aligned along the three\nfour-fold axes of the cubic structure.\n\n", "human_text": "  The structural environment of substitutional Cr3+ ion in MgAl2O4 spinel has\nbeen investigated by Cr K-edge Extended X-ray Absorption Fine Structure (EXAFS)\nand X-ray Absorption Near Edge Structure (XANES) spectroscopies.\nFirst-principles computations of the structural relaxation and of the XANES\nspectrum have been performed, with a good agreement to the experiment. The Cr-O\ndistance is close to that in MgCr2O4, indicating a full relaxation of the first\nneighbors, and the second shell of Al atoms relaxes partially. These\nobservations demonstrate that Vegard's law is not obeyed in the MgAl2O4-MgCr2O4\nsolid solution. Despite some angular site distortion, the local D3d symmetry of\nthe B-site of the spinel structure is retained during the substitution of Cr\nfor Al. Here, we show that the relaxation is accomodated by strain-induced bond\nbuckling, with angular tilts of the Mg-centred tetrahedra around the Cr-centred\noctahedron. By contrast, there is no significant alteration of the angles\nbetween the edge-sharing octahedra, which build chains aligned along the three\nfour-fold axes of the cubic structure.\n", "machine_text": "\nIn this article, we explore the structure of the substitutional Cr3+ ion situated in MgAl2O4 spinel. We conducted Cr K-edge Extended X-ray Absorption Fine Structure (EXAFS) and X-ray Absorption Near Edge Structure (XANES) spectroscopies, supplemented by first-principles computations of the structural relaxation and XANES spectrum. Our results revealed that the Cr-O distance is close to that in MgCr2O4 and displays full relaxation from its first neighbors, while the second shell of Al atoms only experience slight relaxation. This deviation from Vegard's law reveals the strain-induced bond buckling from Mg-centered tetrahedra around the Cr-centered octahedron, preserving the angle between the edge-sharing octahedra and the D3d symmetry of the B-site spinel structure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0878}
{"prompt": "Rephrase the abstract of an article with title 'Orbital-Free Density Functional Theory: Kinetic Potentials and Ab-Initio\n  Local Pseudopotentials'.\n  In the density functional (DF) theory of Kohn and Sham, the kinetic energy of\nthe ground state of a system of noninteracting electrons in a general external\nfield is calculated using a set of orbitals. Orbital free methods attempt to\ncalculate this directly from the electron density by approximating the\nuniversal but unknown kinetic energy density functional. However simple local\napproximations are inaccurate and it has proved very difficult to devise\ngenerally accurate nonlocal approximations. We focus instead on the kinetic\npotential, the functional derivative of the kinetic energy DF, which appears in\nthe Euler equation for the electron density. We argue that the kinetic\npotential is more local and more amenable to simple physically motivated\napproximations in many relevant cases, and describe two pathways by which the\nvalue of the kinetic energy can be efficiently calculated. We propose two\nnonlocal orbital free kinetic potentials that reduce to known exact forms for\nboth slowly varying and rapidly varying perturbations and also reproduce exact\nresults for the linear response of the density of the homogeneous system to\nsmall perturbations. A simple and systematic approach for generating accurate\nand weak ab-initio local pseudopotentials which produce a smooth slowly varying\nvalence component of the electron density is proposed for use in orbital free\nDF calculations of molecules and solids. The use of these local\npseudopotentials further minimizes the possible errors from the kinetic\npotentials. Our theory yields results for the total energies and ionization\nenergies of atoms, and for the shell structure in the atomic radial density\nprofiles that are in very good agreement with calculations using the full\nKohn-Sham theory.\n\n", "human_text": "  In the density functional (DF) theory of Kohn and Sham, the kinetic energy of\nthe ground state of a system of noninteracting electrons in a general external\nfield is calculated using a set of orbitals. Orbital free methods attempt to\ncalculate this directly from the electron density by approximating the\nuniversal but unknown kinetic energy density functional. However simple local\napproximations are inaccurate and it has proved very difficult to devise\ngenerally accurate nonlocal approximations. We focus instead on the kinetic\npotential, the functional derivative of the kinetic energy DF, which appears in\nthe Euler equation for the electron density. We argue that the kinetic\npotential is more local and more amenable to simple physically motivated\napproximations in many relevant cases, and describe two pathways by which the\nvalue of the kinetic energy can be efficiently calculated. We propose two\nnonlocal orbital free kinetic potentials that reduce to known exact forms for\nboth slowly varying and rapidly varying perturbations and also reproduce exact\nresults for the linear response of the density of the homogeneous system to\nsmall perturbations. A simple and systematic approach for generating accurate\nand weak ab-initio local pseudopotentials which produce a smooth slowly varying\nvalence component of the electron density is proposed for use in orbital free\nDF calculations of molecules and solids. The use of these local\npseudopotentials further minimizes the possible errors from the kinetic\npotentials. Our theory yields results for the total energies and ionization\nenergies of atoms, and for the shell structure in the atomic radial density\nprofiles that are in very good agreement with calculations using the full\nKohn-Sham theory.\n", "machine_text": " Orbital-free density functional theory (DFT) is a method of computing the energy of the electronic ground state without using orbital wave functions. In this paper, we explore the use of kinetic potentials, which is the functional derivative of the kinetic energy DF, as well as ab-initio local pseudopotentials which reduce errors from the kinetic potentials, as a means to more accurately calculate nonlocal approximations for the kinetic energy. We also propose two nonlocal orbital free kinetic potentials and show that these yield excellent results for total energies, ionization energies, and shell structures in atomic radial density.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1878}
{"prompt": "Rephrase the abstract of an article with title 'Analyticity of layer potentials and $L^{2}$ solvability of boundary\n  value problems for divergence form elliptic equations with complex\n  $L^{\\infty}$ coefficients'.\n  We consider divergence form elliptic operators of the form $L=-\\dv\nA(x)\\nabla$, defined in $R^{n+1} = \\{(x,t)\\in R^n \\times R \\}$, $n \\geq 2$,\nwhere the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly\nelliptic, complex and $t$-independent. We show that for such operators,\nboundedness and invertibility of the corresponding layer potential operators on\n$L^2(\\mathbb{R}^{n})=L^2(\\partial\\mathbb{R}_{+}^{n+1})$, is stable under\ncomplex, $L^{\\infty}$ perturbations of the coefficient matrix. Using a variant\nof the $Tb$ Theorem, we also prove that the layer potentials are bounded and\ninvertible on $L^2(\\mathbb{R}^n)$ whenever $A(x)$ is real and symmetric (and\nthus, by our stability result, also when $A$ is complex, $\\Vert\nA-A^0\\Vert_{\\infty}$ is small enough and $A^0$ is real, symmetric, $L^{\\infty}$\nand elliptic). In particular, we establish solvability of the Dirichlet and\nNeumann (and Regularity) problems, with $L^2$ (resp. $\\dot{L}^2_1)$ data, for\nsmall complex perturbations of a real symmetric matrix. Previously, $L^2$\nsolvability results for complex (or even real but non-symmetric) coefficients\nwere known to hold only for perturbations of constant matrices (and then only\nfor the Dirichlet problem), or in the special case that the coefficients\n$A_{j,n+1}=0=A_{n+1,j}$, $1\\leq j\\leq n$, which corresponds to the Kato square\nroot problem.\n\n", "human_text": "  We consider divergence form elliptic operators of the form $L=-\\dv\nA(x)\\nabla$, defined in $R^{n+1} = \\{(x,t)\\in R^n \\times R \\}$, $n \\geq 2$,\nwhere the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly\nelliptic, complex and $t$-independent. We show that for such operators,\nboundedness and invertibility of the corresponding layer potential operators on\n$L^2(\\mathbb{R}^{n})=L^2(\\partial\\mathbb{R}_{+}^{n+1})$, is stable under\ncomplex, $L^{\\infty}$ perturbations of the coefficient matrix. Using a variant\nof the $Tb$ Theorem, we also prove that the layer potentials are bounded and\ninvertible on $L^2(\\mathbb{R}^n)$ whenever $A(x)$ is real and symmetric (and\nthus, by our stability result, also when $A$ is complex, $\\Vert\nA-A^0\\Vert_{\\infty}$ is small enough and $A^0$ is real, symmetric, $L^{\\infty}$\nand elliptic). In particular, we establish solvability of the Dirichlet and\nNeumann (and Regularity) problems, with $L^2$ (resp. $\\dot{L}^2_1)$ data, for\nsmall complex perturbations of a real symmetric matrix. Previously, $L^2$\nsolvability results for complex (or even real but non-symmetric) coefficients\nwere known to hold only for perturbations of constant matrices (and then only\nfor the Dirichlet problem), or in the special case that the coefficients\n$A_{j,n+1}=0=A_{n+1,j}$, $1\\leq j\\leq n$, which corresponds to the Kato square\nroot problem.\n", "machine_text": "\nWe present a study of the boundedness and invertibility of layer potential operators for divergence-form elliptic equations with complex, $L^{\\infty}$ coefficient matrix $A$. In particular, $R^{n+1}$ is considered, with $n \\geq 2$, and the coefficient matrix $A$ is independently uniform, elliptic and complex. Our results indicate that layer potentials are stable under complex, $L^{\\infty}$ perturbations of the coefficient matrix. Additionally, if the coefficient matrix $A(x)$ is real and symmetric then we show that the layer potentials are bounded and invertible in $L^2(\\mathbb{R}^n)$. Furthermore, through a variant of the $Tb$ theorem, this allows for the solvability of both the Dirichlet and Neumann problems, with $L^2$ and $\\dot{L}^2_1)$ data respectively, for small complex perturbations of real symmetric matrices. These results greatly extend those that were known to hold for only constant matrices, the Kato square root problem or the special case of $A_{j,n+1}=0=A_{n+1,j}$, for $1\\leq j\\leq n$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0836}
{"prompt": "Rephrase the abstract of an article with title 'Angles Between Infinite Dimensional Subspaces with Applications to the\n  Rayleigh-Ritz and Alternating Projectors Methods'.\n  We define angles from-to and between infinite dimensional subspaces of a\nHilbert space, inspired by the work of E. J. Hannan, 1961/1962 for general\ncanonical correlations of stochastic processes. The spectral theory of\nselfadjoint operators is used to investigate the properties of the angles,\ne.g., to establish connections between the angles corresponding to orthogonal\ncomplements. The classical gaps and angles of Dixmier and Friedrichs are\ncharacterized in terms of the angles. We introduce principal invariant\nsubspaces and prove that they are connected by an isometry that appears in the\npolar decomposition of the product of corresponding orthogonal projectors.\nPoint angles are defined by analogy with the point operator spectrum. We bound\nthe Hausdorff distance between the sets of the squared cosines of the angles\ncorresponding to the original subspaces and their perturbations. We show that\nthe squared cosines of the angles from one subspace to another can be\ninterpreted as Ritz values in the Rayleigh-Ritz method, where the former\nsubspace serves as a trial subspace and the orthogonal projector of the latter\nsubspace serves as an operator in the Rayleigh-Ritz method. The Hausdorff\ndistance between the Ritz values, corresponding to different trial subspaces,\nis shown to be bounded by a constant times the gap between the trial subspaces.\nWe prove a similar eigenvalue perturbation bound that involves the gap squared.\nFinally, we consider the classical alternating projectors method and propose\nits ultimate acceleration, using the conjugate gradient approach. The\ncorresponding convergence rate estimate is obtained in terms of the angles. We\nillustrate a possible acceleration for the domain decomposition method with a\nsmall overlap for the 1D diffusion equation.\n\n", "human_text": "  We define angles from-to and between infinite dimensional subspaces of a\nHilbert space, inspired by the work of E. J. Hannan, 1961/1962 for general\ncanonical correlations of stochastic processes. The spectral theory of\nselfadjoint operators is used to investigate the properties of the angles,\ne.g., to establish connections between the angles corresponding to orthogonal\ncomplements. The classical gaps and angles of Dixmier and Friedrichs are\ncharacterized in terms of the angles. We introduce principal invariant\nsubspaces and prove that they are connected by an isometry that appears in the\npolar decomposition of the product of corresponding orthogonal projectors.\nPoint angles are defined by analogy with the point operator spectrum. We bound\nthe Hausdorff distance between the sets of the squared cosines of the angles\ncorresponding to the original subspaces and their perturbations. We show that\nthe squared cosines of the angles from one subspace to another can be\ninterpreted as Ritz values in the Rayleigh-Ritz method, where the former\nsubspace serves as a trial subspace and the orthogonal projector of the latter\nsubspace serves as an operator in the Rayleigh-Ritz method. The Hausdorff\ndistance between the Ritz values, corresponding to different trial subspaces,\nis shown to be bounded by a constant times the gap between the trial subspaces.\nWe prove a similar eigenvalue perturbation bound that involves the gap squared.\nFinally, we consider the classical alternating projectors method and propose\nits ultimate acceleration, using the conjugate gradient approach. The\ncorresponding convergence rate estimate is obtained in terms of the angles. We\nillustrate a possible acceleration for the domain decomposition method with a\nsmall overlap for the 1D diffusion equation.\n", "machine_text": "\nThis article presents a novel approach to the definition of angles in relation to infinite-dimensional subspaces of a Hilbert space. Inspired by work of E. J. Hannan (1961/1962) in the field of canonical correlations of stochastic processes, we utilize spectral theory of selfadjoint operators to unveil the properties of these angles, such as those corresponding to orthogonal complements. We analyze classical gaps and angles of Dixmier and Friedrichs, demonstrating how they are characterized in terms of the angles we introduce. Additionally, we describe how point angles, analogous to point operator spectra, can be defined. In doing so, we develop a method to bound the Hausdorff distance between the sets of the squared cosines of the angles associated with the subspace and its perturbations. We also discuss how the squared cosines of the angles from one subspace to the other can be interpreted as Ritz values in the Rayleigh-Ritz method. Furthermore, analogous results to those just discussed are presented for the alternating-projectors method, including a potential acceleration for domain decomposition based on the conjugate gradient approach as an example.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1023}
{"prompt": "Rephrase the abstract of an article with title 'Rich methane premixed laminar flames doped by light unsaturated\n  hydrocarbons - Part I : allene and propyne'.\n  The structure of three laminar premixed rich flames has been investigated: a\npure methane flame and two methane flames doped by allene and propyne,\nrespectively. The gases of the three flames contain 20.9% (molar) of methane\nand 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure\nmethane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to\na ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have\nbeen stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant,\nwith a gas velocity at the burner of 36 cm/s at 333 K. The concentration\nprofiles of stable species were measured by gas chromatography after sampling\nwith a quartz microprobe. Quantified species included carbon monoxide and\ndioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne,\nallene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene,\n1-butyne, vinylacetylene, and benzene. The temperature was measured using a\nPtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from\n700 K close to the burner up to 1850 K. In order to model these new results,\nsome improvements have been made to a mechanism previously developed in our\nlaboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main\nreaction pathways of consumption of allene and propyne and of formation of C6\naromatic species have been derived from flow rate analyses.\n\n", "human_text": "  The structure of three laminar premixed rich flames has been investigated: a\npure methane flame and two methane flames doped by allene and propyne,\nrespectively. The gases of the three flames contain 20.9% (molar) of methane\nand 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure\nmethane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to\na ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have\nbeen stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant,\nwith a gas velocity at the burner of 36 cm/s at 333 K. The concentration\nprofiles of stable species were measured by gas chromatography after sampling\nwith a quartz microprobe. Quantified species included carbon monoxide and\ndioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne,\nallene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene,\n1-butyne, vinylacetylene, and benzene. The temperature was measured using a\nPtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from\n700 K close to the burner up to 1850 K. In order to model these new results,\nsome improvements have been made to a mechanism previously developed in our\nlaboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main\nreaction pathways of consumption of allene and propyne and of formation of C6\naromatic species have been derived from flow rate analyses.\n", "machine_text": "\nThis study examines the formation and consumption of the rich methane laminar flame structures when doped with the light unsaturated hydrocarbons allene and propyne. The experiments conducted under pressure of 6.7 kPa and a gas temperature range from 333 K up to 1850 K reveal the concentration profiles of several detectable stable species. To enable reliable modelling, a mechanism has been developed in the laboratory in regards to reactions of C3-C4 unsaturated hydrocarbons, with the key reaction pathways of consumption of allene and propyne, as well as production of C6 aromatic species being taken into account. The analysis involves supplied amounts of 20.9% (molar) of methane, 33.4% oxygen and 2.49% C3H4 respectively, with their equivalence ratio standing at 1.25 and 1.55, respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0375}
{"prompt": "Rephrase the abstract of an article with title 'Theory of thermostatted inhomogeneous granular fluids: a self-consistent\n  density functional description'.\n  The authors present a study of the non equilibrium statistical properties of\na one dimensional hard-rod fluid dissipating energy via inelastic collisions\nand subject to the action of a Gaussian heat bath, simulating an external\ndriving mechanism. They show that the description of the fluid based on the\none-particle phase-space reduced distribution function, in principle necessary\nbecause of the presence of velocity dependent collisional dissipation, can be\ncontracted to a simpler description in configurational space. Indeed, by means\nof a multiple-time scale method the authors derive a self-consistent governing\nequation for the particle density distribution function. This equation is\nsimilar to the dynamic density functional equation employed in the study of\ncolloids, but contains additional terms taking into account the inelastic\nnature of the fluid. Such terms cannot be derived from a Liapunov generating\nfunctional and contribute not only to the relaxational properties, but also to\nthe non equilibrium steady state properties. A validation of the theory against\nmolecular dynamics simulations is presented in a series of cases, and good\nagreement is found.\n\n", "human_text": "  The authors present a study of the non equilibrium statistical properties of\na one dimensional hard-rod fluid dissipating energy via inelastic collisions\nand subject to the action of a Gaussian heat bath, simulating an external\ndriving mechanism. They show that the description of the fluid based on the\none-particle phase-space reduced distribution function, in principle necessary\nbecause of the presence of velocity dependent collisional dissipation, can be\ncontracted to a simpler description in configurational space. Indeed, by means\nof a multiple-time scale method the authors derive a self-consistent governing\nequation for the particle density distribution function. This equation is\nsimilar to the dynamic density functional equation employed in the study of\ncolloids, but contains additional terms taking into account the inelastic\nnature of the fluid. Such terms cannot be derived from a Liapunov generating\nfunctional and contribute not only to the relaxational properties, but also to\nthe non equilibrium steady state properties. A validation of the theory against\nmolecular dynamics simulations is presented in a series of cases, and good\nagreement is found.\n", "machine_text": "\nThis paper presents a self-consistent, density functional description of the statistical thermodynamics associated with a one dimensional, energy-dissipating, granular fluid driven by an external Gaussian heat bath. A multiple-time scale method is employed to derive a governing equation for the particle's density distribution function, structured similarly to the dynamic density functional equation used to study colloids, but augmented with additional terms to account for the properties of inelastic collisions that cannot be captured by a Liapunov generating functional. The theory is validated with molecular dynamics simulations and shown to accurately capture the fluid's non-equilibrium steady state properties as well as its relaxational nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1762}
{"prompt": "Rephrase the abstract of an article with title 'High Precision CTE-Measurement of SiC-100 for Cryogenic Space-Telescopes'.\n  We present the results of high precision measurements of the thermal\nexpansion of the sintered SiC, SiC-100, intended for use in cryogenic\nspace-telescopes, in which minimization of thermal deformation of the mirror is\ncritical and precise information of the thermal expansion is needed for the\ntelescope design. The temperature range of the measurements extends from room\ntemperature down to $\\sim$ 10 K. Three samples, #1, #2, and #3 were\nmanufactured from blocks of SiC produced in different lots. The thermal\nexpansion of the samples was measured with a cryogenic dilatometer, consisting\nof a laser interferometer, a cryostat, and a mechanical cooler. The typical\nthermal expansion curve is presented using the 8th order polynomial of the\ntemperature. For the three samples, the coefficients of thermal expansion\n(CTE), $\\bar{\\alpha}_{#1}$, $\\bar{\\alpha}_{#2}$, and $\\bar{\\alpha}_{#3}$ were\nderived for temperatures between 293 K and 10 K. The average and the dispersion\n(1 $\\sigma$ rms) of these three CTEs are 0.816 and 0.002 ($\\times 10^{-6}$/K),\nrespectively. No significant difference was detected in the CTE of the three\nsamples from the different lots. Neither inhomogeneity nor anisotropy of the\nCTE was observed. Based on the obtained CTE dispersion, we performed an\nfinite-element-method (FEM) analysis of the thermal deformation of a 3.5 m\ndiameter cryogenic mirror made of six SiC-100 segments. It was shown that the\npresent CTE measurement has a sufficient accuracy well enough for the design of\nthe 3.5 m cryogenic infrared telescope mission, the Space Infrared telescope\nfor Cosmology and Astrophysics (SPICA).\n\n", "human_text": "  We present the results of high precision measurements of the thermal\nexpansion of the sintered SiC, SiC-100, intended for use in cryogenic\nspace-telescopes, in which minimization of thermal deformation of the mirror is\ncritical and precise information of the thermal expansion is needed for the\ntelescope design. The temperature range of the measurements extends from room\ntemperature down to $\\sim$ 10 K. Three samples, #1, #2, and #3 were\nmanufactured from blocks of SiC produced in different lots. The thermal\nexpansion of the samples was measured with a cryogenic dilatometer, consisting\nof a laser interferometer, a cryostat, and a mechanical cooler. The typical\nthermal expansion curve is presented using the 8th order polynomial of the\ntemperature. For the three samples, the coefficients of thermal expansion\n(CTE), $\\bar{\\alpha}_{#1}$, $\\bar{\\alpha}_{#2}$, and $\\bar{\\alpha}_{#3}$ were\nderived for temperatures between 293 K and 10 K. The average and the dispersion\n(1 $\\sigma$ rms) of these three CTEs are 0.816 and 0.002 ($\\times 10^{-6}$/K),\nrespectively. No significant difference was detected in the CTE of the three\nsamples from the different lots. Neither inhomogeneity nor anisotropy of the\nCTE was observed. Based on the obtained CTE dispersion, we performed an\nfinite-element-method (FEM) analysis of the thermal deformation of a 3.5 m\ndiameter cryogenic mirror made of six SiC-100 segments. It was shown that the\npresent CTE measurement has a sufficient accuracy well enough for the design of\nthe 3.5 m cryogenic infrared telescope mission, the Space Infrared telescope\nfor Cosmology and Astrophysics (SPICA).\n", "machine_text": "\nThis research aimed to measure the coefficient of thermal expansion (CTE) of the sintered silicon carbide (SiC), SiC-100, for use in cryogenic infrared space-telescopes. Three samples, #1, #2, and #3, were taken from blocks of SiC created in different batches and their thermal expansion was measured using a cryogenic dilatometer in a temperature range extending from room temperature to around 10 K. Results revealed an average CTE of 0.816 and a dispersion of 0.002 (expressed as x10^-6/K). No major discrepancies were documented between the CTE of the three samples from separate batches, and no inhomogeneity or anisotropy was observed. To demonstrate the effectiveness of this precise CTE measurement, a finite-element-method (FEM) analysis was completed to analyze the thermal deformation of a 3.5 m diameter cryogenic mirror consisting of six SiC-100 segments, which showed that it has a high enough accuracy for the design of the Space Infrared telescope for Cosmology and Astrophysics (SPICA).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1515}
{"prompt": "Rephrase the abstract of an article with title 'The Sloan Digital Sky Survey Quasar Catalog IV. Fifth Data Release'.\n  We present the fourth edition of the Sloan Digital Sky Survey (SDSS) Quasar\nCatalog. The catalog contains 77,429 objects; this is an increase of over\n30,000 entries since the previous edition. The catalog consists of the objects\nin the SDSS Fifth Data Release that have luminosities larger than M_i = -22.0\n(in a cosmology with H_0 = 70 km/s/Mpc, Omega_M = 0.3, and Omega_Lambda = 0.7)\nhave at least one emission line with FWHM larger than 1000 km/s, or have\ninteresting/complex absorption features, are fainter than i=15.0, and have\nhighly reliable redshifts. The area covered by the catalog is 5740 sq. deg. The\nquasar redshifts range from 0.08 to 5.41, with a median value of 1.48; the\ncatalog includes 891 quasars at redshifts greater than four, of which 36 are at\nredshifts greater than five. Approximately half of the catalog quasars have i <\n19; nearly all have i < 21. For each object the catalog presents positions\naccurate to better than 0.2 arcsec. rms per coordinate, five-band (ugriz)\nCCD-based photometry with typical accuracy of 0.03 mag, and information on the\nmorphology and selection method. The catalog also contains basic radio,\nnear-infrared, and X-ray emission properties of the quasars, when available,\nfrom other large-area surveys. The calibrated digital spectra cover the\nwavelength region 3800--9200A at a spectral resolution of ~2000. The spectra\ncan be retrieved from the public database using the information provided in the\ncatalog. The average SDSS colors of quasars as a function of redshift, derived\nfrom the catalog entries, are presented in tabular form. Approximately 96% of\nthe objects in the catalog were discovered by the SDSS.\n\n", "human_text": "  We present the fourth edition of the Sloan Digital Sky Survey (SDSS) Quasar\nCatalog. The catalog contains 77,429 objects; this is an increase of over\n30,000 entries since the previous edition. The catalog consists of the objects\nin the SDSS Fifth Data Release that have luminosities larger than M_i = -22.0\n(in a cosmology with H_0 = 70 km/s/Mpc, Omega_M = 0.3, and Omega_Lambda = 0.7)\nhave at least one emission line with FWHM larger than 1000 km/s, or have\ninteresting/complex absorption features, are fainter than i=15.0, and have\nhighly reliable redshifts. The area covered by the catalog is 5740 sq. deg. The\nquasar redshifts range from 0.08 to 5.41, with a median value of 1.48; the\ncatalog includes 891 quasars at redshifts greater than four, of which 36 are at\nredshifts greater than five. Approximately half of the catalog quasars have i <\n19; nearly all have i < 21. For each object the catalog presents positions\naccurate to better than 0.2 arcsec. rms per coordinate, five-band (ugriz)\nCCD-based photometry with typical accuracy of 0.03 mag, and information on the\nmorphology and selection method. The catalog also contains basic radio,\nnear-infrared, and X-ray emission properties of the quasars, when available,\nfrom other large-area surveys. The calibrated digital spectra cover the\nwavelength region 3800--9200A at a spectral resolution of ~2000. The spectra\ncan be retrieved from the public database using the information provided in the\ncatalog. The average SDSS colors of quasars as a function of redshift, derived\nfrom the catalog entries, are presented in tabular form. Approximately 96% of\nthe objects in the catalog were discovered by the SDSS.\n", "machine_text": "\nThis work presents the fourth edition of the SDSS Quasar Catalog, which contains 77,429 objects, an increase of over 30,000 entries since the previous edition. This catalog covers an area of 5740 sq. deg. and redshifts range from 0.08 to 5.41 with a median of 1.48, containing 891 quasars at redshifts greater than four, including 36 at redshift five or higher. Quasars with luminosities brighter than M_i=-22.0 and with at least one emission line having FWHM higher than 1000 km/s, are included when fainter than i=15.0. The catalog also provides details on each object's positions, photometric informations on the five-band (ugriz) CCD- based system, morphology, selection process, radio and near-infrared emission properties, when available from other surveys, along with calibrated digital spectra covering 3800- 9200A with a resolution of ~2000. In addition, the tabulated SDSS average quasar colors as a function of redshift are presented. 96% of the quasars are discoveries of the SDSS.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0806}
{"prompt": "Rephrase the abstract of an article with title 'Precision measurement of the Casimir-Lifshitz force in a fluid'.\n  The Casimir force, which results from the confinement of the quantum\nmechanical zero-point fluctuations of the electromagnetic fields, has received\nsignificant attention in recent years for its effect on micro- and nano-scale\nmechanical systems. With few exceptions, experimental observations have been\nlimited to conductive bodies interacting separated by vacuum or air. However,\ninteresting phenomena including repulsive forces are expected to exist in\ncertain circumstances between metals and dielectrics when the intervening\nmedium is not vacuum. In order to better understand the effect of the Casimir\nforce in such situations and to test the robustness of the generalized\nCasimir-Lifshitz theory, we have performed the first precision measurements of\nthe Casimir force between two metals immersed in a fluid. For this situation,\nthe measured force is attractive and is approximately 80% smaller than the\nforce predicted by Casimir for ideal metals in vacuum. We present experimental\nresults and find them to be consistent with Lifshitz's theory.\n\n", "human_text": "  The Casimir force, which results from the confinement of the quantum\nmechanical zero-point fluctuations of the electromagnetic fields, has received\nsignificant attention in recent years for its effect on micro- and nano-scale\nmechanical systems. With few exceptions, experimental observations have been\nlimited to conductive bodies interacting separated by vacuum or air. However,\ninteresting phenomena including repulsive forces are expected to exist in\ncertain circumstances between metals and dielectrics when the intervening\nmedium is not vacuum. In order to better understand the effect of the Casimir\nforce in such situations and to test the robustness of the generalized\nCasimir-Lifshitz theory, we have performed the first precision measurements of\nthe Casimir force between two metals immersed in a fluid. For this situation,\nthe measured force is attractive and is approximately 80% smaller than the\nforce predicted by Casimir for ideal metals in vacuum. We present experimental\nresults and find them to be consistent with Lifshitz's theory.\n", "machine_text": "\nThis study conducted the first precision measurements of the Casimir-Lifshitz force between two metals immersed in a fluid. The forces observed were attractive, about 80% less than that of ideal metals in a vacuum. The obtained results support looking more closely at how repulsive forces between metals and dielectrics in non-vacuum medium can manifest, and examines how well the generalized Casimir-Lifshitz theory holds for these interactions. Experimental results indicating the behavior of the Casimir-Lifshitz forces in this particular situation are reported.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3793}
{"prompt": "Rephrase the abstract of an article with title 'Nonholonomic Ricci Flows and Parametric Deformations of the Solitonic\n  pp--Waves and Schwarzschild Solutions'.\n  We study Ricci flows of some classes of physically valuable solutions in\nEinstein and string gravity. The anholonomic frame method is applied for\ngeneric off-diagonal metric ansatz when the field/ evolution equations are\ntransformed into exactly integrable systems of partial differential equations.\nThe integral varieties of such solutions, in four and five dimensional gravity,\ndepend on arbitrary generation and integration functions of one, two and/ or\nthree variables. Certain classes of nonholonomic frame constraints allow us to\nselect vacuum and/or Einstein metrics, to generalize such solutions for\nnontrivial string (for instance, with antisymmetric torsion fields) and matter\nfield sources. A very important property of this approach (originating from\nFinsler and Lagrange geometry but re-defined for semi-Riemannian spaces) is\nthat new classes of exact solutions can be generated by nonholonomic\ndeformations depending on parameters associated to some generalized Geroch\ntransforms and Ricci flow evolution. In this paper, we apply the method to\nconstruct in explicit form some classes of exact solutions for multi-parameter\nEinstein spaces and their nonholonomic Ricci flows describing evolutions/\ninteractions of solitonic pp-waves and deformations of the Schwarzschild\nmetric. We explore possible physical consequences and speculate on their\nimportance in modern gravity.\n\n", "human_text": "  We study Ricci flows of some classes of physically valuable solutions in\nEinstein and string gravity. The anholonomic frame method is applied for\ngeneric off-diagonal metric ansatz when the field/ evolution equations are\ntransformed into exactly integrable systems of partial differential equations.\nThe integral varieties of such solutions, in four and five dimensional gravity,\ndepend on arbitrary generation and integration functions of one, two and/ or\nthree variables. Certain classes of nonholonomic frame constraints allow us to\nselect vacuum and/or Einstein metrics, to generalize such solutions for\nnontrivial string (for instance, with antisymmetric torsion fields) and matter\nfield sources. A very important property of this approach (originating from\nFinsler and Lagrange geometry but re-defined for semi-Riemannian spaces) is\nthat new classes of exact solutions can be generated by nonholonomic\ndeformations depending on parameters associated to some generalized Geroch\ntransforms and Ricci flow evolution. In this paper, we apply the method to\nconstruct in explicit form some classes of exact solutions for multi-parameter\nEinstein spaces and their nonholonomic Ricci flows describing evolutions/\ninteractions of solitonic pp-waves and deformations of the Schwarzschild\nmetric. We explore possible physical consequences and speculate on their\nimportance in modern gravity.\n", "machine_text": "\nIn this article, we analyze Ricci flows of different classes of solutions from Einstein's and string gravity. The anholonomic frame technique is employed for a generic off-diagonal metric ansatz and the corresponding field equation gets converted into a totally integrable system of partial differential equations. These solutions are dependent on arbitrary generation and integration functions of one, two or three variables. With the incorporation of certain nonholonomic frame restraints, it is possible to devise vacuum, Einstein and even string (with antisymmetric torsion field) metric models. This technique, which takes its roots in Lagrangian and Finsler geometries but is redefined for semi-Riemannian spaces, is useful in developing new classes of exact solutions with the help of nonholonomic parametric deformations based on generalized Geroch transforms and Ricci flow evolutions. With this in mind, we explicitly construct a selection of particular solutions involving multi-parameter Einstein spaces and nontrivial Ricci flows, describing evolutions and interactions of solitonic pp-waves and new variants of the Schwarzschild metric. We analyze the associated physical effects and speculate on their relevance in contemporary gravity studies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0729}
{"prompt": "Rephrase the abstract of an article with title 'Dark matter in the Milky Way, II. the HI gas distribution as a tracer of\n  the gravitational potential'.\n  Context. Gas within a galaxy is forced to establish pressure balance against\ngravitational forces. The shape of an unperturbed gaseous disk can be used to\nconstrain dark matter models. Aims. We derive the 3-D HI volume density\ndistribution for the Milky Way out to a galactocentric radius of 40 kpc and a\nheight of 20 kpc to constrain the Galactic mass distribution. Methods. We used\nthe Leiden/Argentine/Bonn all sky 21-cm line survey. The transformation from\nbrightness temperatures to densities depends on the rotation curve. We explored\nseveral models, reflecting different dark matter distributions. Each of these\nmodels was set up to solve the combined Poisson-Boltzmann equation in a\nself-consistent way and optimized to reproduce the observed flaring. Results.\nBesides a massive extended halo of M ~ 1.8 10^{12} Msun, we find a\nself-gravitating dark matter disk with M=2 to 3 10^{11} Msun, including a dark\nmatter ring at 13 < R < 18.5 kpc with M = 2.2 to 2.8 10^{10} Msun. The\nexistence of the ring was previously postulated from EGRET data and coincides\nwith a giant stellar structure that surrounds the Galaxy. The resulting Milky\nWay rotation curve is flat up to R~27 kpc and slowly decreases outwards. The\n\\hi gas layer is strongly flaring. The HWHM scale height is 60 pc at R = 4 kpc\nand increases to ~2700$ pc at R=40 kpc. Spiral arms cause a noticeable imprint\non the gravitational field, at least out to R = 30 kpc. Conclusions. Our mass\nmodel supports previous proposals that the giant stellar ring structure is due\nto a merging dwarf galaxy. The fact that the majority of the dark matter in the\nMilky Way for $R \\la 40$ kpc can be successfully modeled by a self-gravitating\nisothermal disk raises the question of whether this massive disk may have been\ncaused by similar merger events in the past.\n\n", "human_text": "  Context. Gas within a galaxy is forced to establish pressure balance against\ngravitational forces. The shape of an unperturbed gaseous disk can be used to\nconstrain dark matter models. Aims. We derive the 3-D HI volume density\ndistribution for the Milky Way out to a galactocentric radius of 40 kpc and a\nheight of 20 kpc to constrain the Galactic mass distribution. Methods. We used\nthe Leiden/Argentine/Bonn all sky 21-cm line survey. The transformation from\nbrightness temperatures to densities depends on the rotation curve. We explored\nseveral models, reflecting different dark matter distributions. Each of these\nmodels was set up to solve the combined Poisson-Boltzmann equation in a\nself-consistent way and optimized to reproduce the observed flaring. Results.\nBesides a massive extended halo of M ~ 1.8 10^{12} Msun, we find a\nself-gravitating dark matter disk with M=2 to 3 10^{11} Msun, including a dark\nmatter ring at 13 < R < 18.5 kpc with M = 2.2 to 2.8 10^{10} Msun. The\nexistence of the ring was previously postulated from EGRET data and coincides\nwith a giant stellar structure that surrounds the Galaxy. The resulting Milky\nWay rotation curve is flat up to R~27 kpc and slowly decreases outwards. The\n\\hi gas layer is strongly flaring. The HWHM scale height is 60 pc at R = 4 kpc\nand increases to ~2700$ pc at R=40 kpc. Spiral arms cause a noticeable imprint\non the gravitational field, at least out to R = 30 kpc. Conclusions. Our mass\nmodel supports previous proposals that the giant stellar ring structure is due\nto a merging dwarf galaxy. The fact that the majority of the dark matter in the\nMilky Way for $R \\la 40$ kpc can be successfully modeled by a self-gravitating\nisothermal disk raises the question of whether this massive disk may have been\ncaused by similar merger events in the past.\n", "machine_text": "\nThis article explores how the observed three-dimensional HI volume density distribution of the Milky Way out to a galactocentric distance of 40 kpc and a height of 20 kpc can be used to determine the Galactic mass distribution in order to shed light on dark matter models. By applying the Leiden/Argentine/Bonn all sky 21-cm line survey in combination with different rotation curves, several models of a self-gravitating isothermal gas disk are generated. The resulting model reveals a massive extended halo with a mass of 1.8 x 10^12 Msun and a sizeable self-gravitating dark matter disk with a mass of 2-3 x 10^11 Msun, including a dark matter ring with a mass of 2.2-2.8 x 10^10 Msun which is located between 13 and 18.5 kpc. Additionally, the Milky Way rotation curve remains flat up to 27 kpc and then slowly decreases outward. This model will allow us to further investigate the plausibility of a past mergeral of a dwarf galaxy with the Milky Way, the potential formation of a massive disk due to a similar event, and additional insights into the Dark Matter in the Milky Way.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3925}
{"prompt": "Rephrase the abstract of an article with title 'Comparison of Particle Production in Quark and Gluon Fragmentation at\n  sqrt s ~ 10 GeV'.\n  Using data collected with the CLEO III detector at the Cornell Electron\nStorage Ring, we study the inclusive production of baryons/antibaryons (p, /)\nand mesons (phi and f_2(1270)) in gluon-fragmentation and quark-fragmentation\nprocesses. We first corroborate previous per-event total particle yields in\nUpsilon(1S)->ggg compared with nearby continuum (e+e- -> qqbar) indicating\ngreater (x2) per-event yields of baryons in 3-gluon fragmentation. We find\nsimilar results when we extend that comparison to include the Upsilon(2S) and\nUpsilon(3S) resonances. With higher statistics, we now also probe the momentum\ndependence of these per-event particle yields. Next, we compare particle\nproduction in the photon-tagged process Upsilon(1S)->gggamma with that in e+e-\n-> qqbar events, to allow comparison of two-parton with three-parton\nparticle-specific fragmentation. For each particle, we determine the\n`enhancement' ratio, defined as the ratio of particle yields per gluon\nfragmentation event compared to quark fragmentation event. Thus defined, an\nenhancement of 1.0 implies equal per-event production in both gluon and quark\nfragmentation. In the photon-tagged analysis (U(1S)->gggamma compared to e+e-\n-> qqbar+gamma), we find almost no enhancement for protons (1.2+/-0.1), but a\nsignificant enhancement (1.9+/-0.3) for /\\'s. Overall, per-event baryon\nproduction in radiative two-gluon fragmentation is somewhat smaller than that\nobserved in three-gluon decays of the Upsilon(1S). Our results for baryon\nproduction are inconsistent with the predictions of the JETSET (7.3)\nfragmentation model.\n\n", "human_text": "  Using data collected with the CLEO III detector at the Cornell Electron\nStorage Ring, we study the inclusive production of baryons/antibaryons (p, /)\nand mesons (phi and f_2(1270)) in gluon-fragmentation and quark-fragmentation\nprocesses. We first corroborate previous per-event total particle yields in\nUpsilon(1S)->ggg compared with nearby continuum (e+e- -> qqbar) indicating\ngreater (x2) per-event yields of baryons in 3-gluon fragmentation. We find\nsimilar results when we extend that comparison to include the Upsilon(2S) and\nUpsilon(3S) resonances. With higher statistics, we now also probe the momentum\ndependence of these per-event particle yields. Next, we compare particle\nproduction in the photon-tagged process Upsilon(1S)->gggamma with that in e+e-\n-> qqbar events, to allow comparison of two-parton with three-parton\nparticle-specific fragmentation. For each particle, we determine the\n`enhancement' ratio, defined as the ratio of particle yields per gluon\nfragmentation event compared to quark fragmentation event. Thus defined, an\nenhancement of 1.0 implies equal per-event production in both gluon and quark\nfragmentation. In the photon-tagged analysis (U(1S)->gggamma compared to e+e-\n-> qqbar+gamma), we find almost no enhancement for protons (1.2+/-0.1), but a\nsignificant enhancement (1.9+/-0.3) for /\\'s. Overall, per-event baryon\nproduction in radiative two-gluon fragmentation is somewhat smaller than that\nobserved in three-gluon decays of the Upsilon(1S). Our results for baryon\nproduction are inconsistent with the predictions of the JETSET (7.3)\nfragmentation model.\n", "machine_text": "\nThe CLEO III detector at the Cornell Electron Storage Ring was used to compare particle production in quark- and gluon-fragmentations processes at sqrt s ~ 10 GeV. Per-event total particle yields were compared in Upsilon(1S)->ggg and e+ e- -> qqbar continuum, illustrating greater baryon production in 3-gluon fragmentation. Further, a photon-tagged study of Upsilon(1S)->gggamma and e+ e- -> qqbar+gamma was carried out to investigate two-parton and three-parton fragmentation. Enhancement ratios (defined as the ratio of gluon-to-quark fragmentation yields) determined that baryon production in radiative two-gluon fragmentation was lower than in the Upsilon(1S) three-gluon decays. Furthermore, our results on baryon production disagree with the JETSET (7.3) fragmentation model.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2766}
{"prompt": "Rephrase the abstract of an article with title 'Looking beyond the horizon'.\n  In this short talk we review our results from the paper hep-th/0604075 with\nthe main stress on the issues of causality and acoustic metric in eikonal\napproximation. In addition we correct the formula for the redshift of sound\nsignals from our original work. We show that, if there exists a special kind of\nBorn-Infeld type scalar field, then one can send information from inside a\nblack hole. This information is encoded in perturbations of the field\npropagating in non-trivial scalar field backgrounds, which serve as a \"new\nether\". Although the action of the theory is manifestly Lorentz-invariant the\nnon-trivial solutions break this symmetry spontaneously, allowing, the\nsuperluminal propagation of perturbations with respect to this \"new ether\". We\nfound the stationary solution for background, which describes the accretion of\nthe scalar field onto a black hole. Examining the propagation of small\nperturbations around this solution we show that the signals emitted inside the\nSchwarzschild horizon can reach an observer located outside the black hole.\nThus the accreting field forms a hydrodynamical analog of a black hole whose\nhorizon is inside of the gravitational black hole drawing in the scalar field.\n\n", "human_text": "  In this short talk we review our results from the paper hep-th/0604075 with\nthe main stress on the issues of causality and acoustic metric in eikonal\napproximation. In addition we correct the formula for the redshift of sound\nsignals from our original work. We show that, if there exists a special kind of\nBorn-Infeld type scalar field, then one can send information from inside a\nblack hole. This information is encoded in perturbations of the field\npropagating in non-trivial scalar field backgrounds, which serve as a \"new\nether\". Although the action of the theory is manifestly Lorentz-invariant the\nnon-trivial solutions break this symmetry spontaneously, allowing, the\nsuperluminal propagation of perturbations with respect to this \"new ether\". We\nfound the stationary solution for background, which describes the accretion of\nthe scalar field onto a black hole. Examining the propagation of small\nperturbations around this solution we show that the signals emitted inside the\nSchwarzschild horizon can reach an observer located outside the black hole.\nThus the accreting field forms a hydrodynamical analog of a black hole whose\nhorizon is inside of the gravitational black hole drawing in the scalar field.\n", "machine_text": "This study looks beyond the horizon, exploring the phenomenon of causality, acoustic metrics, and the redshift of sound signals. We show that, by introducing a Born-Infeld type scalar field, it is possible to send information from inside a black hole. This is accomplished by perturbations of the field propagating in a non-trivial scalar field background, which serves as a \"new ether.\" As this theory breaks Lorentz-invariance spontaneously, superluminal speeds of sound signals is possible. In addition, we examine a stationary solution for a background which describes the accretion of a scalar field onto a black hole and the subsequent escape of perturbations through the Schwarzschild horizon. As a result, this can grant observers outside the black hole access to information hitherto unreachable.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3301}
{"prompt": "Rephrase the abstract of an article with title 'Background study for the pn-CCD detector of CERN Axion Solar Telescope'.\n  The CERN Axion Solar Telescope (CAST) experiment searches for axions from the\nSun converted into photons with energies up to around 10 keV via the inverse\nPrimakoff effect in the high magnetic field of a superconducting Large Hadron\nCollider (LHC) prototype magnet. A backside illuminated pn-CCD detector in\nconjunction with an X-ray mirror optics is one of the three detectors used in\nCAST to register the expected photon signal. Since this signal is very rare and\ndifferent background components (environmental gamma radiation, cosmic rays,\nintrinsic radioactive impurities in the set-up, ...) entangle it, a detailed\nstudy of the detector background has been undertaken with the aim to understand\nand further reduce the background level of the detector. The analysis is based\non measured data taken during the Phase I of CAST and on Monte Carlo\nsimulations of different background components. This study will show that the\nobserved background level (at a rate of (8.00+-0.07)10^-5 counts/cm^2/s/keV\nbetween 1 and 7 keV) seems to be dominated by the external gamma background due\nto usual activities at the experimental site, while radioactive impurities in\nthe detector itself and cosmic neutrons could make just smaller contribution.\n\n", "human_text": "  The CERN Axion Solar Telescope (CAST) experiment searches for axions from the\nSun converted into photons with energies up to around 10 keV via the inverse\nPrimakoff effect in the high magnetic field of a superconducting Large Hadron\nCollider (LHC) prototype magnet. A backside illuminated pn-CCD detector in\nconjunction with an X-ray mirror optics is one of the three detectors used in\nCAST to register the expected photon signal. Since this signal is very rare and\ndifferent background components (environmental gamma radiation, cosmic rays,\nintrinsic radioactive impurities in the set-up, ...) entangle it, a detailed\nstudy of the detector background has been undertaken with the aim to understand\nand further reduce the background level of the detector. The analysis is based\non measured data taken during the Phase I of CAST and on Monte Carlo\nsimulations of different background components. This study will show that the\nobserved background level (at a rate of (8.00+-0.07)10^-5 counts/cm^2/s/keV\nbetween 1 and 7 keV) seems to be dominated by the external gamma background due\nto usual activities at the experimental site, while radioactive impurities in\nthe detector itself and cosmic neutrons could make just smaller contribution.\n", "machine_text": "\nThis paper presents a background study of the pn-CCD detector used in the CERN Axion Solar Telescope (CAST) experiment during Phase I. CAST is aimed at detecting axions from the Sun through the inverse Primakoff effect in the high magnetic field of a superconducting Large Hadron Collider (LHC) prototype magnet. Measurements and Monte Carlo simulations were conducted to analyze the level of interference caused by external gamma radiation, cosmic rays, and internal radioactive impurities. Results indicate that the observed background rate of (8.00 +- 0.07) 10^-5 counts/cm^2/s/keV between 1 and 7 keV is mostly driven by gamma radiation from the surrounding environment, while cosmic neutrons and radioactive impurities are comparatively less significant.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2946}
{"prompt": "Rephrase the abstract of an article with title 'Dynamical Coupled-Channel Model of $\\pi N$ Scattering in the W $\\leq$ 2\n  GeV Nucleon Resonance Region'.\n  As a first step to analyze the electromagnetic meson production reactions in\nthe nucleon resonance region, the parameters of the hadronic interactions of a\ndynamical coupled-channel model, developed in {\\it Physics Reports 439, 193\n(2007)}, are determined by fitting the $\\pi N$ scattering data. The channels\nincluded in the calculations are $\\pi N$, $\\eta N$ and $\\pi\\pi N$ which has\n$\\pi\\Delta$, $\\rho N$, and $\\sigma N$ resonant components. The non-resonant\nmeson-baryon interactions of the model are derived from a set of Lagrangians by\nusing a unitary transformation method. One or two bare excited nucleon states\nin each of $S$, $P$, $D$, and $F$ partial waves are included to generate the\nresonant amplitudes in the fits. The parameters of the model are first\ndetermined by fitting as much as possible the empirical $\\pi N$ elastic\nscattering amplitudes of SAID up to 2 GeV. We then refine and confirm the\nresulting parameters by directly comparing the predicted differential cross\nsection and target polarization asymmetry with the original data of the elastic\n$\\pi^{\\pm} p \\to \\pi^{\\pm} p$ and charge-exchange $\\pi^- p \\to \\pi^0 n$\nprocesses. The predicted total cross sections of $\\pi N$ reactions and $\\pi\nN\\to \\eta N$ reactions are also in good agreement with the data. Applications\nof the constructed model in analyzing the electromagnetic meson production data\nas well as the future developments are discussed.\n\n", "human_text": "  As a first step to analyze the electromagnetic meson production reactions in\nthe nucleon resonance region, the parameters of the hadronic interactions of a\ndynamical coupled-channel model, developed in {\\it Physics Reports 439, 193\n(2007)}, are determined by fitting the $\\pi N$ scattering data. The channels\nincluded in the calculations are $\\pi N$, $\\eta N$ and $\\pi\\pi N$ which has\n$\\pi\\Delta$, $\\rho N$, and $\\sigma N$ resonant components. The non-resonant\nmeson-baryon interactions of the model are derived from a set of Lagrangians by\nusing a unitary transformation method. One or two bare excited nucleon states\nin each of $S$, $P$, $D$, and $F$ partial waves are included to generate the\nresonant amplitudes in the fits. The parameters of the model are first\ndetermined by fitting as much as possible the empirical $\\pi N$ elastic\nscattering amplitudes of SAID up to 2 GeV. We then refine and confirm the\nresulting parameters by directly comparing the predicted differential cross\nsection and target polarization asymmetry with the original data of the elastic\n$\\pi^{\\pm} p \\to \\pi^{\\pm} p$ and charge-exchange $\\pi^- p \\to \\pi^0 n$\nprocesses. The predicted total cross sections of $\\pi N$ reactions and $\\pi\nN\\to \\eta N$ reactions are also in good agreement with the data. Applications\nof the constructed model in analyzing the electromagnetic meson production data\nas well as the future developments are discussed.\n", "machine_text": "This paper presents the development of a dynamical coupled-channel model to analyze electromagnetic meson production reactions in the nucleon resonance region, focusing on $\\pi N$ scattering. The channels included in the calculations are $\\pi N$, $\\eta N$ and $\\pi\\pi N$, and a set of hadronic Lagrangians is used to create the non-resonant meson-baryon interactions of the model using a unitary transformation method. The parameters of the model are determined by fitting $\\pi N$ elastic scattering data from SAID up to 2 GeV, and the differential cross section and target polarization asymmetry of the elastic $\\pi^{\\pm} p \\to \\pi^{\\pm} p$ and charge-exchange $\\pi^- p \\to \\pi^0 n$ processes are also compared. The resulting model is then used to predict total cross section of $\\pi N$ reactions and $\\pi N \\to \\eta N$ reactions which are found to produce accurate results. This model is intended to be used in further studies of similar phenomena in the nucleon resonance region.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1615}
{"prompt": "Rephrase the abstract of an article with title 'Self consistency in hadron physics'.\n  In this talk we discuss at hand of two examples the crucial role played by\nself consistency in hadron physics. The first example concerns the quark-mass\ndependence of the baryon octet and decuplet masses. It is shown that within a\nself consistent one-loop approach based on the chiral Lagrangian the\n'mysterious' quark-mass dependence of the $\\Xi$ mass predicted by the MILC\ncollaboration may be recovered in terms of a discontinuous chiral\nextrapolation. This is a consequence of self consistency imposed on the partial\nsummation, i.e. the masses used in the loop functions are identical to those\nobtained from the baryon self energies. In the second example we discuss recent\nstudies on the properties of D mesons in cold nuclear matter as they are\npredicted by coupled-channel dynamics. Here a self consistent many-body\napproach reveals the close interlink of the properties of D meson and\nopen-charm baryon resonances in nuclear matter. The relevance of exotic baryon\nresonances for the spectral distortion of the $D_s^\\pm$ in nuclear matter is\npointed out.\n\n", "human_text": "  In this talk we discuss at hand of two examples the crucial role played by\nself consistency in hadron physics. The first example concerns the quark-mass\ndependence of the baryon octet and decuplet masses. It is shown that within a\nself consistent one-loop approach based on the chiral Lagrangian the\n'mysterious' quark-mass dependence of the $\\Xi$ mass predicted by the MILC\ncollaboration may be recovered in terms of a discontinuous chiral\nextrapolation. This is a consequence of self consistency imposed on the partial\nsummation, i.e. the masses used in the loop functions are identical to those\nobtained from the baryon self energies. In the second example we discuss recent\nstudies on the properties of D mesons in cold nuclear matter as they are\npredicted by coupled-channel dynamics. Here a self consistent many-body\napproach reveals the close interlink of the properties of D meson and\nopen-charm baryon resonances in nuclear matter. The relevance of exotic baryon\nresonances for the spectral distortion of the $D_s^\\pm$ in nuclear matter is\npointed out.\n", "machine_text": "\nIn this article, we explore the significant role which self consistency plays in hadron physics through two examples. The initial example involves the dependence of the octet and decuplet baryon masses on quark mass. With a self consistent loop approach based on a chiral Lagrangian, we are able to account for the 'unforeseen' quark-mass dependence of the \u039e mass as reported by the MILC Collaboration through a discontinuous chiral extrapolation. The resulting outcome implies that self consistency is being applied to the partial summation, with the masses used in the loop functions being identical to those present in the baryon self energies. In the second example, recent studies illustrate the application of this self consistency in analysing the impact of matter on D mesons. With the presence of coupled-channel dynamics, a self consistent many-body approach was able to elucidate the close ties between the properties of D mesons and open-charm baryon resonances in matter. Additionally, we highlighted the significance of exotic baryon resonances in influencing the spectral distortions of the $D_s^\\pm$ in nuclear matter.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2011}
{"prompt": "Rephrase the abstract of an article with title 'A unified shear-thinning treatment of both film thickness and traction\n  in EHD'.\n  A conclusive demonstration has been provided that the nature of the\nshear-thinning, that affects both film thickness and traction in EHL contacts,\nfollows the ordinary power-law rule that has been described by many empirical\nmodels of which Carreau is but one example. This was accomplished by accurate\nmeasurements in viscometers of the shear response of a PAO that possesses a\nvery low critical stress for shear-thinning and accurate measurements\nin-contact of film thickness and traction under conditions which accentuate the\nshear-thinning effect. The in-contact central film thickness and traction were\nentirely predictable from the rheological properties obtained from viscometers\nusing simple calculations. These data should be invaluable to researchers\nendeavoring to accurately simulate Hertz zone behavior since the shear-thinning\nrheology is extensively characterized and accurate in-contact data are\navailable to test. In addition, a new model has been introduced that may be\nuseful for the rheological characterization of mixtures.\n\n", "human_text": "  A conclusive demonstration has been provided that the nature of the\nshear-thinning, that affects both film thickness and traction in EHL contacts,\nfollows the ordinary power-law rule that has been described by many empirical\nmodels of which Carreau is but one example. This was accomplished by accurate\nmeasurements in viscometers of the shear response of a PAO that possesses a\nvery low critical stress for shear-thinning and accurate measurements\nin-contact of film thickness and traction under conditions which accentuate the\nshear-thinning effect. The in-contact central film thickness and traction were\nentirely predictable from the rheological properties obtained from viscometers\nusing simple calculations. These data should be invaluable to researchers\nendeavoring to accurately simulate Hertz zone behavior since the shear-thinning\nrheology is extensively characterized and accurate in-contact data are\navailable to test. In addition, a new model has been introduced that may be\nuseful for the rheological characterization of mixtures.\n", "machine_text": "This article provides an authoritative explanation of the shear-thinning phenomenon affecting the film thickness and traction in EHL contacts, confirming the ordinary power-law rule that has been proposed by many theoretical models such as the Carreau model. Through precise measurements in viscometers and in contact, it was possible to predict the central film thickness and traction from the rheological properties of a PAO with a low critical stress for shear-thinning. These data can be useful for creating an accurate simulation of Hertz zone behavior. Furthermore, a new model has been proposed that can be used to characterize mixtures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1798}
{"prompt": "Rephrase the abstract of an article with title 'High resolution mid-infrared spectroscopy of ultraluminous infrared\n  galaxies'.\n  (Abridged) We present R~600, 10-37um spectra of 53 ULIRGs at z<0.32, taken\nusing the IRS on board Spitzer. All of the spectra show fine structure emission\nlines of Ne, O, S, Si and Ar, as well as molecular Hydrogen lines. Some ULIRGs\nalso show emission lines of Cl, Fe, P, and atomic Hydrogen, and/or absorption\nfeatures from C_2H_2, HCN, and OH. We employ diagnostics based on the\nfine-structure lines, as well as the EWs and luminosities of PAH features and\nthe strength of the 9.7um silicate absorption feature (S_sil), to explore the\npower source behind the infrared emission in ULIRGs. We show that the IR\nemission from the majority of ULIRGs is powered mostly by star formation, with\nonly ~20% of ULIRGs hosting an AGN with a comparable or greater IR luminosity\nthan the starburst. The detection of the 14.32um [NeV] line in just under half\nthe sample however implies that an AGN contributes significantly to the mid-IR\nflux in ~42% of ULIRGs. The emission line ratios, luminosities and PAH EWs are\nconsistent with the starbursts and AGN in ULIRGs being more extincted, and for\nthe starbursts more compact, versions of those in lower luminosity systems. The\nexcitations and electron densities in the NLRs of ULIRGs appear comparable to\nthose of lower luminosity starbursts, though there is evidence that the NLR gas\nin ULIRGs is more dense. We show that the combined luminosity of the 12.81um\n[NeII] and 15.56um [NeIII] lines correlates with both IR luminosity and the\nluminosity of the 6.2 micron and 11.2 micron PAH features in ULIRGs, and use\nthis to derive a calibration between PAH luminosity and star formation rate.\nFinally, we show that ULIRGs with 0.8 < S_sil < 2.4 are likely to be powered\nmainly by star formation, but that ULIRGs with S_sil < 0.8, and possibly those\nwith S_sil > 2.4, contain an IR-luminous AGN.\n\n", "human_text": "  (Abridged) We present R~600, 10-37um spectra of 53 ULIRGs at z<0.32, taken\nusing the IRS on board Spitzer. All of the spectra show fine structure emission\nlines of Ne, O, S, Si and Ar, as well as molecular Hydrogen lines. Some ULIRGs\nalso show emission lines of Cl, Fe, P, and atomic Hydrogen, and/or absorption\nfeatures from C_2H_2, HCN, and OH. We employ diagnostics based on the\nfine-structure lines, as well as the EWs and luminosities of PAH features and\nthe strength of the 9.7um silicate absorption feature (S_sil), to explore the\npower source behind the infrared emission in ULIRGs. We show that the IR\nemission from the majority of ULIRGs is powered mostly by star formation, with\nonly ~20% of ULIRGs hosting an AGN with a comparable or greater IR luminosity\nthan the starburst. The detection of the 14.32um [NeV] line in just under half\nthe sample however implies that an AGN contributes significantly to the mid-IR\nflux in ~42% of ULIRGs. The emission line ratios, luminosities and PAH EWs are\nconsistent with the starbursts and AGN in ULIRGs being more extincted, and for\nthe starbursts more compact, versions of those in lower luminosity systems. The\nexcitations and electron densities in the NLRs of ULIRGs appear comparable to\nthose of lower luminosity starbursts, though there is evidence that the NLR gas\nin ULIRGs is more dense. We show that the combined luminosity of the 12.81um\n[NeII] and 15.56um [NeIII] lines correlates with both IR luminosity and the\nluminosity of the 6.2 micron and 11.2 micron PAH features in ULIRGs, and use\nthis to derive a calibration between PAH luminosity and star formation rate.\nFinally, we show that ULIRGs with 0.8 < S_sil < 2.4 are likely to be powered\nmainly by star formation, but that ULIRGs with S_sil < 0.8, and possibly those\nwith S_sil > 2.4, contain an IR-luminous AGN.\n", "machine_text": "\n\nWe use high-resolution mid-infrared spectroscopy of 53 ULIRGs at z<0.32 observed with the Spitzer IRS instrument to gain insights into the power source behind their infrared emission. Our spectra show a range of fine structure emission lines (e.g. Ne, O, S, Si and Ar) as well as molecular and atomic Hydrogen emission lines. Diagnostics based on the fine-structure lines, the equivalent widths and luminosities of PAH features, and the strength of the 9.7um silicate absorption feature (S_sil) indicate that the majority of ULIRGs are powered mainly by star formation, although detection of the 14.32um [NeV] line in roughly 42% of the sample suggests that an AGN could contribute significantly to the mid-infrared flux in this subset of ULIRGs. We find that the NLRs of ULIRGs are more compact and more extincted than those in lower-luminosity starbursts, but that their excitation and electron densities are comparable. We also establish a correlation between the combined luminosity of the 12.81um [NeII] and 15.56um [NeIII] lines with both IR luminosity and the luminosity of the 6.2 micron and 11.2 micron PAH features in ULIRGs, and use this to derive a calibration between PAH luminosity and star formation rate. Finally, a S_sil ratio in the range of 0.8 to 2.4 is likely to indicate a ULIRG mainly powered by star formation, while S_sil ratios lower than 0.8, and possibly higher than 2.4, indicate the presence of a strong AGN.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0513}
{"prompt": "Rephrase the abstract of an article with title 'A new, very massive modular Liquid Argon Imaging Chamber to detect low\n  energy off-axis neutrinos from the CNGS beam. (Project MODULAr)'.\n  The paper is considering an opportunity for the CERN/GranSasso (CNGS)\nneutrino complex, concurrent time-wise with T2K and NOvA, to search for\ntheta_13 oscillations and CP violation. Compared with large water Cherenkov\n(T2K) and fine grained scintillators (NOvA), the LAr-TPC offers a higher\ndetection efficiency and a lower backgrounds, since virtually all channels may\nbe unambiguously recognized. The present proposal, called MODULAr, describes a\n20 kt fiducial volume LAr-TPC, following very closely the technology developed\nfor the ICARUS-T60o, and is focused on the following activities, for which we\nseek an extended international collaboration:\n  (1) the neutrino beam from the CERN 400 GeV proton beam and an optimised horn\nfocussing, eventually with an increased intensity in the framework of the LHC\naccelerator improvement program;\n  (2) A new experimental area LNGS-B, of at least 50000 m3 at 10 km off-axis\nfrom the main Laboratory, eventually upgradable to larger sizes. A location is\nunder consideration at about 1.2 km equivalent water depth;\n  (3) A new LAr Imaging detector of at least 20 kt fiducial mass. Such an\nincrease in the volume over the current ICARUS T600 needs to be carefully\nconsidered. It is concluded that a very large mass is best realised with a set\nof many identical, independent units, each of 5 kt, \"cloning\" the technology of\nthe T600. Further phases may foresee extensions of MODULAr to meet future\nphysics goals.\n  The experiment might reasonably be operational in about 4/5 years, provided a\nnew hall is excavated in the vicinity of the Gran Sasso Laboratory and adequate\nfunding and participation are made available.\n\n", "human_text": "  The paper is considering an opportunity for the CERN/GranSasso (CNGS)\nneutrino complex, concurrent time-wise with T2K and NOvA, to search for\ntheta_13 oscillations and CP violation. Compared with large water Cherenkov\n(T2K) and fine grained scintillators (NOvA), the LAr-TPC offers a higher\ndetection efficiency and a lower backgrounds, since virtually all channels may\nbe unambiguously recognized. The present proposal, called MODULAr, describes a\n20 kt fiducial volume LAr-TPC, following very closely the technology developed\nfor the ICARUS-T60o, and is focused on the following activities, for which we\nseek an extended international collaboration:\n  (1) the neutrino beam from the CERN 400 GeV proton beam and an optimised horn\nfocussing, eventually with an increased intensity in the framework of the LHC\naccelerator improvement program;\n  (2) A new experimental area LNGS-B, of at least 50000 m3 at 10 km off-axis\nfrom the main Laboratory, eventually upgradable to larger sizes. A location is\nunder consideration at about 1.2 km equivalent water depth;\n  (3) A new LAr Imaging detector of at least 20 kt fiducial mass. Such an\nincrease in the volume over the current ICARUS T600 needs to be carefully\nconsidered. It is concluded that a very large mass is best realised with a set\nof many identical, independent units, each of 5 kt, \"cloning\" the technology of\nthe T600. Further phases may foresee extensions of MODULAr to meet future\nphysics goals.\n  The experiment might reasonably be operational in about 4/5 years, provided a\nnew hall is excavated in the vicinity of the Gran Sasso Laboratory and adequate\nfunding and participation are made available.\n", "machine_text": "\nThis paper presents the possibility for the CERN/GranSasso (CNGS) neutrino complex to search for theta_13 oscillations and CP violation concurrent with T2K and NOvA. A Liquid Argon Imaging Chamber (LAr-TPC) is proposed as the most suitable technology, offering higher detection efficiency and lower backgrounds. MODULAr project proposes a 20 kt fiducial volume detector following the ICARUS-T60o technology, to be placed at least 50000 m3 at 10 km off-axis from the main Laboratory in a location at about 1.2 km equivalent water depth. It will consist of many identical and independent units of 5 kt. There are plans for extensions for future physics goals. Provided a new hall is excavated in the vicinity of the Gran Sasso Laboratory, the experiment might become operational in around 4/5 years with adequate funding and participation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1422}
{"prompt": "Rephrase the abstract of an article with title 'A multiwavelength study of young massive star forming regions: II. The\n  dust environment'.\n  We present observations of 1.2-mm dust continuum emission, made with the\nSwedish ESO Submillimeter Telescope, towards eighteen luminous IRAS point\nsources, all with colors typical of compact HII regions and associated with\nCS(2-1) emission, thought to be representative of young massive star forming\nregions. Emission was detected toward all the IRAS objects. We find that the\n1.2-mm sources associated with them have distinct physical parameters, namely\nsizes of 0.4 pc, dust temperatures of 30 K, masses of 2x10^3 Msun, column\ndensities of 3x10^23 cm^-2, and densities of 4x10^5 cm^-3. We refer to these\ndust structures as massive and dense cores. Most of the 1.2-mm sources show\nsingle-peaked structures, several of which exhibit a bright compact peak\nsurrounded by a weaker extended envelope. The observed radial intensity\nprofiles of sources with this type of morphology are well fitted with power-law\nintensity profiles with power-law indices in the range 1.0-1.7. This result\nindicates that massive and dense cores are centrally condensed, having radial\ndensity profiles with power-law indices in the range 1.5-2.2. We also find that\nthe UC HII regions detected with ATCA towards the IRAS sources investigated\nhere (Paper I) are usually projected at the peak position of the 1.2-mm dust\ncontinuum emission, suggesting that massive stars are formed at the center of\nthe centrally condensed massive and dense cores.\n\n", "human_text": "  We present observations of 1.2-mm dust continuum emission, made with the\nSwedish ESO Submillimeter Telescope, towards eighteen luminous IRAS point\nsources, all with colors typical of compact HII regions and associated with\nCS(2-1) emission, thought to be representative of young massive star forming\nregions. Emission was detected toward all the IRAS objects. We find that the\n1.2-mm sources associated with them have distinct physical parameters, namely\nsizes of 0.4 pc, dust temperatures of 30 K, masses of 2x10^3 Msun, column\ndensities of 3x10^23 cm^-2, and densities of 4x10^5 cm^-3. We refer to these\ndust structures as massive and dense cores. Most of the 1.2-mm sources show\nsingle-peaked structures, several of which exhibit a bright compact peak\nsurrounded by a weaker extended envelope. The observed radial intensity\nprofiles of sources with this type of morphology are well fitted with power-law\nintensity profiles with power-law indices in the range 1.0-1.7. This result\nindicates that massive and dense cores are centrally condensed, having radial\ndensity profiles with power-law indices in the range 1.5-2.2. We also find that\nthe UC HII regions detected with ATCA towards the IRAS sources investigated\nhere (Paper I) are usually projected at the peak position of the 1.2-mm dust\ncontinuum emission, suggesting that massive stars are formed at the center of\nthe centrally condensed massive and dense cores.\n", "machine_text": "\nThis study utilizes the Swedish ESO Submillimeter Telescope to observe 1.2-mm dust emission emanating from eighteen luminous IRAS point sources suspected to be young massive star forming regions associated with CS(2-1) emission. It is found that the associated 1.2-mm sources display unique physical parameters, such as 0.4 pc size, 30 K dust temperature, 2x10^3 Msun mass, 3x10^23 cm^-2 column density and 4x10^5 cm^-3 density. Also, many single-peaked structures were identified, generally comprised of a bright, tightly concentrated peak surrounded by a faint, extended envelope. Power-law intensity profiles fit well with the observed radial intensity profiles, hinting at these sources having centrally condensed, radial density profiles with power-law indices ranging from 1.5-2.2. Lastly, the evidence suggests that massive stars are typically formed at the peaks of these concentrated cores.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2171}
{"prompt": "Rephrase the abstract of an article with title '(Non) Gauge Invariance of Wilsonian Effective Actions in\n  (Supersymmetric) Gauge Theories : A Critical Discussion'.\n  We give a detailed critical discussion of the properties of Wilsonian\neffective actions, defined by integrating out all modes above a given scale\n$\\mu$. In particular, we provide a precise and relatively convenient\nprescription how to implement the infrared cutoff $\\mu$ in any loop integral\nthat is manifestly Lorentz invariant and also preserves global linear\nsymmetries such as e.g. supersymmetry. We discuss the issue of gauge invariance\nof effective actions in general and in particular when using background field\ngauge. Our prescription for the IR cutoff (as any such prescription) breaks the\ngauge symmetry. Using our prescription, we have explicitly computed, at one\nloop, many terms of the Wilsonian effective action for general gauge theories,\ninvolving bosonic and fermionic matter fields of arbitrary masses and in\narbitrary representations, exhibiting the non-gauge invariant (as well as the\ngauge invariant) terms. However, for supersymmetric gauge theories all\nnon-gauge invariant terms cancel within each supermultiplet. This is strong\nevidence that in supersymmetric gauge theories this indeed defines a Lorentz,\nsusy and gauge invariant Wilsonian effective action. As a byproduct, we obtain\nthe explicit one-loop Wilsonian couplings for all higher-derivative terms $F\nD^{2n}F$ in the effective action of arbitrary supersymmetric gauge theories.\n\n", "human_text": "  We give a detailed critical discussion of the properties of Wilsonian\neffective actions, defined by integrating out all modes above a given scale\n$\\mu$. In particular, we provide a precise and relatively convenient\nprescription how to implement the infrared cutoff $\\mu$ in any loop integral\nthat is manifestly Lorentz invariant and also preserves global linear\nsymmetries such as e.g. supersymmetry. We discuss the issue of gauge invariance\nof effective actions in general and in particular when using background field\ngauge. Our prescription for the IR cutoff (as any such prescription) breaks the\ngauge symmetry. Using our prescription, we have explicitly computed, at one\nloop, many terms of the Wilsonian effective action for general gauge theories,\ninvolving bosonic and fermionic matter fields of arbitrary masses and in\narbitrary representations, exhibiting the non-gauge invariant (as well as the\ngauge invariant) terms. However, for supersymmetric gauge theories all\nnon-gauge invariant terms cancel within each supermultiplet. This is strong\nevidence that in supersymmetric gauge theories this indeed defines a Lorentz,\nsusy and gauge invariant Wilsonian effective action. As a byproduct, we obtain\nthe explicit one-loop Wilsonian couplings for all higher-derivative terms $F\nD^{2n}F$ in the effective action of arbitrary supersymmetric gauge theories.\n", "machine_text": "\nThis paper explores the ramifications of Wilsonian effective actions, obtained by integrating out views above a specific scale $\\mu$. We introduce a manifestly Lorentz invariant and global symmetry preserving prescription which uses an infrared cut off at this scale. This opens up a discussion around the gauge invariance of effective actions in general, and particularly when using the background field method. We demonstrate that for Supersymmetric gauge theories, all non-gauge invariant terms cancel within each supermultiplet, providing strong evidence that this prescription outlines a Lorentz, Supersymmetry and gauge invariant action. We provide a one-loop calculation of couplings for higher-derivative terms $F D^{2n}F$ in all Supersymmetric gauge theories as a result.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0362}
{"prompt": "Rephrase the abstract of an article with title 'How to Find More Supernovae with Less Work: Object Classification\n  Techniques for Difference Imaging'.\n  We present the results of applying new object classification techniques to\ndifference images in the context of the Nearby Supernova Factory supernova\nsearch. Most current supernova searches subtract reference images from new\nimages, identify objects in these difference images, and apply simple threshold\ncuts on parameters such as statistical significance, shape, and motion to\nreject objects such as cosmic rays, asteroids, and subtraction artifacts.\nAlthough most static objects subtract cleanly, even a very low false positive\ndetection rate can lead to hundreds of non-supernova candidates which must be\nvetted by human inspection before triggering additional followup. In comparison\nto simple threshold cuts, more sophisticated methods such as Boosted Decision\nTrees, Random Forests, and Support Vector Machines provide dramatically better\nobject discrimination. At the Nearby Supernova Factory, we reduced the number\nof non-supernova candidates by a factor of 10 while increasing our supernova\nidentification efficiency. Methods such as these will be crucial for\nmaintaining a reasonable false positive rate in the automated transient alert\npipelines of upcoming projects such as PanSTARRS and LSST.\n\n", "human_text": "  We present the results of applying new object classification techniques to\ndifference images in the context of the Nearby Supernova Factory supernova\nsearch. Most current supernova searches subtract reference images from new\nimages, identify objects in these difference images, and apply simple threshold\ncuts on parameters such as statistical significance, shape, and motion to\nreject objects such as cosmic rays, asteroids, and subtraction artifacts.\nAlthough most static objects subtract cleanly, even a very low false positive\ndetection rate can lead to hundreds of non-supernova candidates which must be\nvetted by human inspection before triggering additional followup. In comparison\nto simple threshold cuts, more sophisticated methods such as Boosted Decision\nTrees, Random Forests, and Support Vector Machines provide dramatically better\nobject discrimination. At the Nearby Supernova Factory, we reduced the number\nof non-supernova candidates by a factor of 10 while increasing our supernova\nidentification efficiency. Methods such as these will be crucial for\nmaintaining a reasonable false positive rate in the automated transient alert\npipelines of upcoming projects such as PanSTARRS and LSST.\n", "machine_text": "\nThis research examines how newly developed object classification techniques can be used to increase the effectiveness of the Nearby Supernova Factory's supernova search. In contrast to traditional techniques which utilize simple parameter thresholds to filter out objects such as asteroids, cosmic rays, and subtraction artifacts, we applied more effective methods such as Boosted Decision Trees, Random Forests, and Support Vector Machines. This allowed for a reduction in the amount of manual inspection by a factor of 10 while also improving the overall supernova identification rate. We believe that these same methods can be used for efficient alert production and false positive rejection in projects such as PanSTARRS and LSST to help reduce the workload required for supernova detection.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0493}
{"prompt": "Rephrase the abstract of an article with title 'Bayesian reconstruction of the cosmological large-scale structure:\n  methodology, inverse algorithms and numerical optimization'.\n  We address the inverse problem of cosmic large-scale structure reconstruction\nfrom a Bayesian perspective. For a linear data model, a number of known and\nnovel reconstruction schemes, which differ in terms of the underlying signal\nprior, data likelihood, and numerical inverse extra-regularization schemes are\nderived and classified. The Bayesian methodology presented in this paper tries\nto unify and extend the following methods: Wiener-filtering, Tikhonov\nregularization, Ridge regression, Maximum Entropy, and inverse regularization\ntechniques. The inverse techniques considered here are the asymptotic\nregularization, the Jacobi, Steepest Descent, Newton-Raphson,\nLandweber-Fridman, and both linear and non-linear Krylov methods based on\nFletcher-Reeves, Polak-Ribiere, and Hestenes-Stiefel Conjugate Gradients. The\nstructures of the up-to-date highest-performing algorithms are presented, based\non an operator scheme, which permits one to exploit the power of fast Fourier\ntransforms. Using such an implementation of the generalized Wiener-filter in\nthe novel ARGO-software package, the different numerical schemes are\nbenchmarked with 1-, 2-, and 3-dimensional problems including structured white\nand Poissonian noise, data windowing and blurring effects. A novel numerical\nKrylov scheme is shown to be superior in terms of performance and fidelity.\nThese fast inverse methods ultimately will enable the application of sampling\ntechniques to explore complex joint posterior distributions. We outline how the\nspace of the dark-matter density field, the peculiar velocity field, and the\npower spectrum can jointly be investigated by a Gibbs-sampling process. Such a\nmethod can be applied for the redshift distortions correction of the observed\ngalaxies and for time-reversal reconstructions of the initial density field.\n\n", "human_text": "  We address the inverse problem of cosmic large-scale structure reconstruction\nfrom a Bayesian perspective. For a linear data model, a number of known and\nnovel reconstruction schemes, which differ in terms of the underlying signal\nprior, data likelihood, and numerical inverse extra-regularization schemes are\nderived and classified. The Bayesian methodology presented in this paper tries\nto unify and extend the following methods: Wiener-filtering, Tikhonov\nregularization, Ridge regression, Maximum Entropy, and inverse regularization\ntechniques. The inverse techniques considered here are the asymptotic\nregularization, the Jacobi, Steepest Descent, Newton-Raphson,\nLandweber-Fridman, and both linear and non-linear Krylov methods based on\nFletcher-Reeves, Polak-Ribiere, and Hestenes-Stiefel Conjugate Gradients. The\nstructures of the up-to-date highest-performing algorithms are presented, based\non an operator scheme, which permits one to exploit the power of fast Fourier\ntransforms. Using such an implementation of the generalized Wiener-filter in\nthe novel ARGO-software package, the different numerical schemes are\nbenchmarked with 1-, 2-, and 3-dimensional problems including structured white\nand Poissonian noise, data windowing and blurring effects. A novel numerical\nKrylov scheme is shown to be superior in terms of performance and fidelity.\nThese fast inverse methods ultimately will enable the application of sampling\ntechniques to explore complex joint posterior distributions. We outline how the\nspace of the dark-matter density field, the peculiar velocity field, and the\npower spectrum can jointly be investigated by a Gibbs-sampling process. Such a\nmethod can be applied for the redshift distortions correction of the observed\ngalaxies and for time-reversal reconstructions of the initial density field.\n", "machine_text": "\nThis paper describes the use of Bayesian techniques to reconstruct the cosmic large-scale structure from observational data. We discuss how generic linear data models can be represented in terms of signal prior, data likelihood, and numerical inverse extra-regularization schemes. Additionally, the ARGO software package is developed to apply these techniques in an efficient manner using fast Fourier transforms. Benchmarking is done on problem sets of 1, 2, or 3 dimensions with different types of noise, windowing and blurring effects. As a result, a novel numerical Krylov scheme is identified as having superior accuracy with respects to the other candidates. With this we theoretically make the Gibbs sampling process possible to explore complex joint posterior distributions jointly for the dark matter density field, the peculiar velocity field, and the power spectrum. This can be used to assess the redshift distortion of observed galaxies, and even to reconstruct the initial density field in a time-reversal manner.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0429}
{"prompt": "Rephrase the abstract of an article with title 'The formation of S0 galaxies: evidence from globular clusters'.\n  We test the theory that lenticular (S0) galaxies form from spirals whose star\nformation has been shut down. We use the globular cluster specific frequency\nS_N, defined as the number of globular clusters normalised by the galaxy\nluminosity as a diagnostic. NTT/EMMI long-slit spectroscopic observations of 11\nS0 galaxies at z < 0.006 are used to measure the absorption-line indices,\nHdelta, Hgamma, Mgb, Fe5270 and Fe5335 within the central r_e/8. By inverting\nsingle-stellar population models, luminosity-weighted mean ages, metallicities\nand alpha-element abundance ratios are derived. We estimate the amount of\nfading a galaxy has undergone by comparing each galaxy's S_N with its deviation\nfrom the mean spiral S_N. Galaxies with higher S_N have older stellar\npopulations. Moreover, we find that the zero-point and amount of fading is\nconsistent with a scenario where lenticulars are formed by the quenching of\nstar formation in spiral galaxies. Our data also rule out any formation method\nfor S0s which creates a large number of new globular clusters. We confirm that\nprevious results showing a relationship between S_N and color are driven by the\nS_N - Age relation. Five galaxies show detectable Hbeta, [OIII], Halpha or\n[NII] emission lines. However, only in the two youngest galaxies is this\nemission unambiguously from star formation. Our results are consistent with the\ntheory that S0 galaxies are formed when gas in normal spirals is removed,\npossibly as a result of a change in environment. The on-going star formation in\nthe youngest galaxies hints that the timescale of quenching is ~< 1 Gyr. We\nspeculate, therefore, that the truncation of star formation is a rather gentle\nprocess unlikely to involve a rapid burst of star formation.\n\n", "human_text": "  We test the theory that lenticular (S0) galaxies form from spirals whose star\nformation has been shut down. We use the globular cluster specific frequency\nS_N, defined as the number of globular clusters normalised by the galaxy\nluminosity as a diagnostic. NTT/EMMI long-slit spectroscopic observations of 11\nS0 galaxies at z < 0.006 are used to measure the absorption-line indices,\nHdelta, Hgamma, Mgb, Fe5270 and Fe5335 within the central r_e/8. By inverting\nsingle-stellar population models, luminosity-weighted mean ages, metallicities\nand alpha-element abundance ratios are derived. We estimate the amount of\nfading a galaxy has undergone by comparing each galaxy's S_N with its deviation\nfrom the mean spiral S_N. Galaxies with higher S_N have older stellar\npopulations. Moreover, we find that the zero-point and amount of fading is\nconsistent with a scenario where lenticulars are formed by the quenching of\nstar formation in spiral galaxies. Our data also rule out any formation method\nfor S0s which creates a large number of new globular clusters. We confirm that\nprevious results showing a relationship between S_N and color are driven by the\nS_N - Age relation. Five galaxies show detectable Hbeta, [OIII], Halpha or\n[NII] emission lines. However, only in the two youngest galaxies is this\nemission unambiguously from star formation. Our results are consistent with the\ntheory that S0 galaxies are formed when gas in normal spirals is removed,\npossibly as a result of a change in environment. The on-going star formation in\nthe youngest galaxies hints that the timescale of quenching is ~< 1 Gyr. We\nspeculate, therefore, that the truncation of star formation is a rather gentle\nprocess unlikely to involve a rapid burst of star formation.\n", "machine_text": "\nBy examining 11 S0 galaxies at z < 0.006 with NTT/EMMI long-slit spectroscopic observations, we have studied the globular cluster specific frequency S_N as a diagnostic to determine evidence for the formation of S0 galaxies from spirals whose star formation has been halted. Through the use of single-stellar population models, we find that galaxies with higher S_N have older stellar populations, which supports the notion that spirals are fading into lenticular galaxies due to a decrease in their star formation rate. Evidence from the five galaxies which feature detectable emission lines suggests that the process of star formation quenching takes no longer than 1 gigayear. Our findings provide insight into the development of S0 galaxies and show that the truncation of star formation is a relatively gentle process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0623}
{"prompt": "Rephrase the abstract of an article with title 'Shelling-type orderings of regular CW-complexes and acyclic matchings of\n  the Salvetti complex'.\n  Motivated by the work of Salvetti and Settepanella we introduce certain total\norderings of the faces of any shellable regular CW-complex (called\n`shelling-type orderings') that can be used to explicitly construct maximum\nacyclic matchings of the poset of cells of the given complex. Building on an\napplication of this method to the classical zonotope shellings we describe a\nclass of maximum acyclic matchings for the Salvetti complex of a linear\ncomplexified arrangement. To do this, we introduce and study a new\ncombinatorial stratification of the Salvetti complex. For the obtained acyclic\nmatchings we give an explicit description of the critical cells that depends\nonly on the chosen linear extension of the poset of regions. It is always\npossible to choose the linear extension so that the critical cells can be\nexplicitly constructed from the chambers of the arrangement via the bijection\nto no-broken-circuit sets defined by Jewell and Orlik. Our method can be\ngeneralized to arbitraty oriented matroids.\n\n", "human_text": "  Motivated by the work of Salvetti and Settepanella we introduce certain total\norderings of the faces of any shellable regular CW-complex (called\n`shelling-type orderings') that can be used to explicitly construct maximum\nacyclic matchings of the poset of cells of the given complex. Building on an\napplication of this method to the classical zonotope shellings we describe a\nclass of maximum acyclic matchings for the Salvetti complex of a linear\ncomplexified arrangement. To do this, we introduce and study a new\ncombinatorial stratification of the Salvetti complex. For the obtained acyclic\nmatchings we give an explicit description of the critical cells that depends\nonly on the chosen linear extension of the poset of regions. It is always\npossible to choose the linear extension so that the critical cells can be\nexplicitly constructed from the chambers of the arrangement via the bijection\nto no-broken-circuit sets defined by Jewell and Orlik. Our method can be\ngeneralized to arbitraty oriented matroids.\n", "machine_text": "\nInspired by the contributions of Salvetti and Settepanella, we illustrate an ordering technique of the faces in any shellable regular CW-complex (referred to as 'Shelling-type orderings'). The method allows us to  create maximum acyclic matchings of the totality of cells of the specified complex. Utilizing this technique, we  define a set of maximum acyclic matchings of the Salvetti complex of a linear complexified arrangement. To do this, we develop a new type of combinatorial stratification of the Salvetti complex. Through the selection of a linear extension of the poset of regions, we are able to present an explicit description of the critical cells solely based on the chambers of the arrangement and a no-broken-circuit set specified by Jewell and Orlik. Our approach can be extended to any type of oriented matroid.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3107}
{"prompt": "Rephrase the abstract of an article with title 'The unification of Pythagorean theorem for electronic orbitals with\n  Kepler's law for planetary orbits'.\n  In the context of two-dimensional spacetime within a helium atom, both 1s\nelectrons are characterized by wave functions that observe duality equation.\nThey are symmetric, orthogonal and interwoven, forming a dynamic rope structure\nat any moment. Instead of elliptical orbit of planets around the sun,\nelectronic orbitals take the form of matter state transformation cycle. While\nthe kinematic movement of planets is governed by Kepler's first law, electronic\ntransformation obeys Pythagorean theorem, both being equivalent in physical\nprinciple. The atomic spacetime is a continuous medium of electron clouds in\nsynchronized differential and integral processes that are implemented by smooth\ntrigonometry. In order to integrate this new approach with conventional\nphysics, the author translates the pattern of electronic motion in the atomic\nspacetime into spherical volume undulation in Euclidean geometry and calculates\nthe probability density of an electron within the sphere from the classical\nperspective. From the primary wave function of a 1s electron, the author also\ntries to derive the mathematical expression of central force that guides the\nsurrounding bodies along the orbits. The result is exciting and surprising that\nquestions the exactness of the venerable Coulomb's law.\n\n", "human_text": "  In the context of two-dimensional spacetime within a helium atom, both 1s\nelectrons are characterized by wave functions that observe duality equation.\nThey are symmetric, orthogonal and interwoven, forming a dynamic rope structure\nat any moment. Instead of elliptical orbit of planets around the sun,\nelectronic orbitals take the form of matter state transformation cycle. While\nthe kinematic movement of planets is governed by Kepler's first law, electronic\ntransformation obeys Pythagorean theorem, both being equivalent in physical\nprinciple. The atomic spacetime is a continuous medium of electron clouds in\nsynchronized differential and integral processes that are implemented by smooth\ntrigonometry. In order to integrate this new approach with conventional\nphysics, the author translates the pattern of electronic motion in the atomic\nspacetime into spherical volume undulation in Euclidean geometry and calculates\nthe probability density of an electron within the sphere from the classical\nperspective. From the primary wave function of a 1s electron, the author also\ntries to derive the mathematical expression of central force that guides the\nsurrounding bodies along the orbits. The result is exciting and surprising that\nquestions the exactness of the venerable Coulomb's law.\n", "machine_text": "\nThis article explores the potential unification of Pythagorean theorem and Kepler's law in two-dimensional spacetime as applied to an atom's electrons. A duality equation, involving symmetric and interwoven wave functions, describes the movement of electrons which takes the form of a matter state transformation cycle. These principles of motion are stated as equivalents to each other and are brought together with trigonometry in the atomic spacetime. To provide the conventional physics viewpoint, this article attempts to connect electron motion in an atomic spacetime to spherical volume undulation in Euclidean geometry and examines the possible derivation of a central force expression from the primary wave function of an electron. This could potentially challenge the accuracy of the well-known Coulomb's law.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4508}
{"prompt": "Rephrase the abstract of an article with title 'Studies of the temperature and frequency dependent impedance of an\n  electroceramic functional oxide thermistor'.\n  The charge transport mechanism and the macroscopic dielectric constant in\npolycrystalline device materials commonly exhibit several components such as\nelectrode-sample interface, grain boundary and bulk contributions. In order to\ngain precise understanding of the functionality of polycrystalline\nelectroceramic device materials it is essential to deconvolute these\ncontributions. The paradigm of functional thermistor ceramics based on thick\nfilm spinel manganates has been studied by temperature dependent alternating\ncurrent impedance spectroscopy. Three typical relaxation phenomena were\ndetected, which all showed a separated temperature dependence of resistivity\nconsistent with thermally activated charge transport. The dominating grain\nboundary and the interface contributions exhibited distinctively different\ncapacitance allowing clear identification. The composite nature of the\ndielectric properties in polycrystalline functional ceramics was emphasized,\nand impedance spectroscopy was shown to be a powerful tool to account for and\nmodel such behaviour.\n\n", "human_text": "  The charge transport mechanism and the macroscopic dielectric constant in\npolycrystalline device materials commonly exhibit several components such as\nelectrode-sample interface, grain boundary and bulk contributions. In order to\ngain precise understanding of the functionality of polycrystalline\nelectroceramic device materials it is essential to deconvolute these\ncontributions. The paradigm of functional thermistor ceramics based on thick\nfilm spinel manganates has been studied by temperature dependent alternating\ncurrent impedance spectroscopy. Three typical relaxation phenomena were\ndetected, which all showed a separated temperature dependence of resistivity\nconsistent with thermally activated charge transport. The dominating grain\nboundary and the interface contributions exhibited distinctively different\ncapacitance allowing clear identification. The composite nature of the\ndielectric properties in polycrystalline functional ceramics was emphasized,\nand impedance spectroscopy was shown to be a powerful tool to account for and\nmodel such behaviour.\n", "machine_text": "\nIn this study, temperature and frequency dependent impedance of an electroceramic functional oxide thermistor was investigated in order to gain a greater understanding of the charge transport and dielectric properties of polycrystalline device materials. Using alternating current impedance spectroscopy, three distinct relaxation phenomena were identified, all exhibiting a temperature-dependent resistivity. Both grain boundary and interface contributions had different capacitance values, highlighting the composite nature of the dielectric properties in polycrystalline ceramics. The findings illustrate that impedance spectroscopy is a useful method for modelling this behavior.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3378}
{"prompt": "Rephrase the abstract of an article with title 'Phase structure of a surface model on dynamically triangulated spheres\n  with elastic skeletons'.\n  We find three distinct phases; a tubular phase, a planar phase, and the\nspherical phase, in a triangulated fluid surface model. It is also found that\nthese phases are separated by discontinuous transitions. The fluid surface\nmodel is investigated within the framework of the conventional curvature model\nby using the canonical Monte Carlo simulations with dynamical triangulations.\nThe mechanical strength of the surface is given only by skeletons, and no\ntwo-dimensional bending energy is assumed in the Hamiltonian. The skeletons are\ncomposed of elastic linear-chains and rigid junctions and form a\ncompartmentalized structure on the surface, and for this reason the vertices of\ntriangles can diffuse freely only inside the compartments. As a consequence, an\ninhomogeneous structure is introduced in the model; the surface strength inside\nthe compartments is different from the surface strength on the compartments.\nHowever, the rotational symmetry is not influenced by the elastic skeletons;\nthere is no specific direction on the surface. In addition to the three phases\nmentioned above, a collapsed phase is expected to exist in the low bending\nrigidity regime that was not studied here. The inhomogeneous structure and the\nfluidity of vertices are considered to be the origin of such variety of phases.\n\n", "human_text": "  We find three distinct phases; a tubular phase, a planar phase, and the\nspherical phase, in a triangulated fluid surface model. It is also found that\nthese phases are separated by discontinuous transitions. The fluid surface\nmodel is investigated within the framework of the conventional curvature model\nby using the canonical Monte Carlo simulations with dynamical triangulations.\nThe mechanical strength of the surface is given only by skeletons, and no\ntwo-dimensional bending energy is assumed in the Hamiltonian. The skeletons are\ncomposed of elastic linear-chains and rigid junctions and form a\ncompartmentalized structure on the surface, and for this reason the vertices of\ntriangles can diffuse freely only inside the compartments. As a consequence, an\ninhomogeneous structure is introduced in the model; the surface strength inside\nthe compartments is different from the surface strength on the compartments.\nHowever, the rotational symmetry is not influenced by the elastic skeletons;\nthere is no specific direction on the surface. In addition to the three phases\nmentioned above, a collapsed phase is expected to exist in the low bending\nrigidity regime that was not studied here. The inhomogeneous structure and the\nfluidity of vertices are considered to be the origin of such variety of phases.\n", "machine_text": "\nUsing dynamical triangulations, the phase structure of a fluid surface model is determined within the conventional curvature model. The mechanical strength of the surface arises from elastic skeletons of linear-chains and rigid junctions, which form a compartmentalized structure on the surface. By means of Monte Carlo simulations, three distinct phases are observed: a tubular phase, a planar phase and a spherical phase, which are separated by discontinuous transitions. The inclusion of elastic skeletons introduces an inhomogeneous structure to the model, with different surface stregth inside and outside the compartments. Rotational symmetry, however, is preserved. In the low bending rigidity regime, a collapsed phase is likely to exist, but was not surveyed in this investigation. It is hypothesized that the variety of observed phases is due to the inhomogeneous structure and fluidity of vertices.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0493}
{"prompt": "Rephrase the abstract of an article with title 'Faithful Effective-One-Body waveforms of small-mass-ratio coalescing\n  black-hole binaries'.\n  We address the problem of constructing high-accuracy, faithful analytic\nwaveforms describing the gravitational wave signal emitted by inspiralling and\ncoalescing binary black holes. We work within the Effective-One-Body (EOB)\nframework and propose a methodology for improving the current\n(waveform)implementations of this framework based on understanding, element by\nelement, the physics behind each feature of the waveform, and on systematically\ncomparing various EOB-based waveforms with ``exact'' waveforms obtained by\nnumerical relativity approaches. The present paper focuses on small-mass-ratio\nnon-spinning binary systems, which can be conveniently studied by\nRegge-Wheeler-Zerilli-type methods. Our results include: (i) a resummed,\n3PN-accurate description of the inspiral waveform, (ii) a better description of\nradiation reaction during the plunge, (iii) a refined analytic expression for\nthe plunge waveform, (iv) an improved treatment of the matching between the\nplunge and ring-down waveforms. This improved implementation of the EOB\napproach allows us to construct complete analytic waveforms which exhibit a\nremarkable agreement with the ``exact'' ones in modulus, frequency and phase.\nIn particular, the analytic and numerical waveforms stay in phase, during the\nwhole process, within $\\pm 1.1 %$ of a cycle. We expect that the extension of\nour methodology to the comparable-mass case will be able to generate comparably\naccurate analytic waveforms of direct use for the ground-based network of\ninterferometric detectors of gravitational waves.\n\n", "human_text": "  We address the problem of constructing high-accuracy, faithful analytic\nwaveforms describing the gravitational wave signal emitted by inspiralling and\ncoalescing binary black holes. We work within the Effective-One-Body (EOB)\nframework and propose a methodology for improving the current\n(waveform)implementations of this framework based on understanding, element by\nelement, the physics behind each feature of the waveform, and on systematically\ncomparing various EOB-based waveforms with ``exact'' waveforms obtained by\nnumerical relativity approaches. The present paper focuses on small-mass-ratio\nnon-spinning binary systems, which can be conveniently studied by\nRegge-Wheeler-Zerilli-type methods. Our results include: (i) a resummed,\n3PN-accurate description of the inspiral waveform, (ii) a better description of\nradiation reaction during the plunge, (iii) a refined analytic expression for\nthe plunge waveform, (iv) an improved treatment of the matching between the\nplunge and ring-down waveforms. This improved implementation of the EOB\napproach allows us to construct complete analytic waveforms which exhibit a\nremarkable agreement with the ``exact'' ones in modulus, frequency and phase.\nIn particular, the analytic and numerical waveforms stay in phase, during the\nwhole process, within $\\pm 1.1 %$ of a cycle. We expect that the extension of\nour methodology to the comparable-mass case will be able to generate comparably\naccurate analytic waveforms of direct use for the ground-based network of\ninterferometric detectors of gravitational waves.\n", "machine_text": "\nWe present a methodology to construct high-accuracy, effective, and faithful waveforms of the gravitation wave signal emitted by binary black-hole (BBH) mergers. Our focus is on small-mass-ratio non-spinning systems, which can be explored effectively using Regge-Wheeler-Zerilli methods. Our methodology based on the Effective-One-Body (EOB) framework uses a comprehensive approach to understand the physical properties of each component of the waveforms and systematically compares analytic EOB-based waveforms with corresponding exact waveforms from numerical relativity. Our results include an improved, 3PN-accurate description of inspiral waveforms, a refined analytic expression for the plunge waveform, and a better treatment of the matching between the plunge and ring-down waveforms. Our methodology allows us to construct complete analytic waveforms that prove to be in excellent agreement with the exact ones in terms of modulus, frequency, and phase, staying in-phase, on the whole, under $\\pm 1.1 %$ of a cycle. We believe that this procedure can be extended to comparable-mass cases making it useful to ground-based gravitational wave detectors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2519}
{"prompt": "Rephrase the abstract of an article with title 'The influence of horizontal gene transfer on the mean fitness of\n  unicellular populations in static environments'.\n  This paper develops a mathematical model describing the influence that\nconjugation-mediated Horizontal Gene Transfer (HGT) has on the\nmutation-selection balance in an asexually reproducing population of\nunicellular, prokaryotic organisms. It is assumed that mutation-selection\nbalance is reached in the presence of a fixed background concentration of\nantibiotic, to which the population must become resistant in order to survive.\nWe analyze the behavior of the model in the limit of low and high\nantibiotic-induced first-order death rate constants, and find that the highest\nmean fitness is obtained at low rates of bacterial conjugation. As the rate of\nconjugation crosses a threshold, the mean fitness decreases to a minimum, and\nthen rises asymptotically to a limiting value as the rate of conjugation\nbecomes infinitely large. However, this limiting value is smaller than the mean\nfitness obtained in the limit of low conjugation rate. This dependence of the\nmean fitness on the conjugation rate is fairly small for the parameter ranges\nwe have considered, and disappears as the first-order death rate constant due\nto the presence of antibiotic approaches zero. For large values of the\nantibiotic death rate constant, we have obtained an analytical solution for the\nbehavior of the mean fitness that agrees well with the results of simulations.\nThe results of this paper suggest that conjugation-mediated HGT has a slightly\ndeleterious effect on the mean fitness of a population at mutation-selection\nbalance. Therefore, we argue that HGT confers a selective advantage by allowing\nfor faster adaptation to a new or changing environment. The results of this\npaper are consistent with the observation that HGT can be promoted by\nenvironmental stresses on a population.\n\n", "human_text": "  This paper develops a mathematical model describing the influence that\nconjugation-mediated Horizontal Gene Transfer (HGT) has on the\nmutation-selection balance in an asexually reproducing population of\nunicellular, prokaryotic organisms. It is assumed that mutation-selection\nbalance is reached in the presence of a fixed background concentration of\nantibiotic, to which the population must become resistant in order to survive.\nWe analyze the behavior of the model in the limit of low and high\nantibiotic-induced first-order death rate constants, and find that the highest\nmean fitness is obtained at low rates of bacterial conjugation. As the rate of\nconjugation crosses a threshold, the mean fitness decreases to a minimum, and\nthen rises asymptotically to a limiting value as the rate of conjugation\nbecomes infinitely large. However, this limiting value is smaller than the mean\nfitness obtained in the limit of low conjugation rate. This dependence of the\nmean fitness on the conjugation rate is fairly small for the parameter ranges\nwe have considered, and disappears as the first-order death rate constant due\nto the presence of antibiotic approaches zero. For large values of the\nantibiotic death rate constant, we have obtained an analytical solution for the\nbehavior of the mean fitness that agrees well with the results of simulations.\nThe results of this paper suggest that conjugation-mediated HGT has a slightly\ndeleterious effect on the mean fitness of a population at mutation-selection\nbalance. Therefore, we argue that HGT confers a selective advantage by allowing\nfor faster adaptation to a new or changing environment. The results of this\npaper are consistent with the observation that HGT can be promoted by\nenvironmental stresses on a population.\n", "machine_text": "\nThis article investigates how Horizontal Gene Transfer (HGT) via conjugation impacts the mutation-selection equilibrium of a prokaryotic, unicellular organism population in a static environment containing certain levels of antibiotic. Calculations and simulations were undertaken to inspect effects of differing HGT rates and antibiotic first-order death rates. It's found that, generally, a low HGT rate offers optimum mean fitness, and mean fitness drops slightly when the HGT rate increases and crosses a certain threshold before increasing again to an asymptotic but lesser limiting value. Despite this, the effect is negligible for most reasonable parameters and disappears with weaker antibiotic. Ultimately, the paper suggests a small but potentially advantageous selective benefit of HGT that manifests when experiencing environmental pressures. This is reflected in known observations of the promotion of HGT under stressful conditions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3983}
{"prompt": "Rephrase the abstract of an article with title 'Warehousing Web Data'.\n  In a data warehousing process, mastering the data preparation phase allows\nsubstantial gains in terms of time and performance when performing\nmultidimensional analysis or using data mining algorithms. Furthermore, a data\nwarehouse can require external data. The web is a prevalent data source in this\ncontext. In this paper, we propose a modeling process for integrating diverse\nand heterogeneous (so-called multiform) data into a unified format.\nFurthermore, the very schema definition provides first-rate metadata in our\ndata warehousing context. At the conceptual level, a complex object is\nrepresented in UML. Our logical model is an XML schema that can be described\nwith a DTD or the XML-Schema language. Eventually, we have designed a Java\nprototype that transforms our multiform input data into XML documents\nrepresenting our physical model. Then, the XML documents we obtain are mapped\ninto a relational database we view as an ODS (Operational Data Storage), whose\ncontent will have to be re-modeled in a multidimensional way to allow its\nstorage in a star schema-based warehouse and, later, its analysis.\n\n", "human_text": "  In a data warehousing process, mastering the data preparation phase allows\nsubstantial gains in terms of time and performance when performing\nmultidimensional analysis or using data mining algorithms. Furthermore, a data\nwarehouse can require external data. The web is a prevalent data source in this\ncontext. In this paper, we propose a modeling process for integrating diverse\nand heterogeneous (so-called multiform) data into a unified format.\nFurthermore, the very schema definition provides first-rate metadata in our\ndata warehousing context. At the conceptual level, a complex object is\nrepresented in UML. Our logical model is an XML schema that can be described\nwith a DTD or the XML-Schema language. Eventually, we have designed a Java\nprototype that transforms our multiform input data into XML documents\nrepresenting our physical model. Then, the XML documents we obtain are mapped\ninto a relational database we view as an ODS (Operational Data Storage), whose\ncontent will have to be re-modeled in a multidimensional way to allow its\nstorage in a star schema-based warehouse and, later, its analysis.\n", "machine_text": "\nThis paper discusses a model for collating and transforming web data of multiple, heterogeneous formats into a unified structure for use with data warehousing. An abstract conceptualization of a complex object is presented in UML, and the logical model is expressed in XML schema and DTD. A Java implementation of this model is provided and the XML output from this program is then mapped into a relational database and re-modeled in a multidimensional way for storage in a star schema-based warehouse. Through this process, time and performance gains can be realized for analyzing and mining data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1456}
{"prompt": "Rephrase the abstract of an article with title 'A novel spacetime concept for describing electronic motion within a\n  helium atom'.\n  Euclidean space and linear algebra do not characterize dynamic electronic\norbitals satisfactorily for even the motion of both electrons in an inert\nhelium atom cannot be defined in reasonable details. Here the author puts\nforward a novel two-dimensional spacetime model from scratch in the context of\ndefining both electrons in a helium atom. Space and time are treated as two\northogonal, symmetric and complementary quantities under the atomic spacetime.\nElectronic motion observed the rule of differential and integral operations\nthat were implemented by dynamic trigonometric functions. It is demonstrated\nthat the atomic spacetime is not a linear vector space with Newtonian time, and\nwithin which calculus has non-classical definition, and complex wave functions\nhave fresh physical significances. This alternative approach is original,\ninformative and refreshing but still compatible with quantum mechanics in the\nformulation. The description of electronic resonance in helium is also\ncomparable with classical mechanics such as an oscillating pendulum and with\nclassical electromagnetism such as an LC oscillator. The study has effectively\nunified complex function, calculus, and trigonometry in mathematics, and\nprovided a prospect for unifying particle physics with classical physics on the\nnovel spacetime platform.\n\n", "human_text": "  Euclidean space and linear algebra do not characterize dynamic electronic\norbitals satisfactorily for even the motion of both electrons in an inert\nhelium atom cannot be defined in reasonable details. Here the author puts\nforward a novel two-dimensional spacetime model from scratch in the context of\ndefining both electrons in a helium atom. Space and time are treated as two\northogonal, symmetric and complementary quantities under the atomic spacetime.\nElectronic motion observed the rule of differential and integral operations\nthat were implemented by dynamic trigonometric functions. It is demonstrated\nthat the atomic spacetime is not a linear vector space with Newtonian time, and\nwithin which calculus has non-classical definition, and complex wave functions\nhave fresh physical significances. This alternative approach is original,\ninformative and refreshing but still compatible with quantum mechanics in the\nformulation. The description of electronic resonance in helium is also\ncomparable with classical mechanics such as an oscillating pendulum and with\nclassical electromagnetism such as an LC oscillator. The study has effectively\nunified complex function, calculus, and trigonometry in mathematics, and\nprovided a prospect for unifying particle physics with classical physics on the\nnovel spacetime platform.\n", "machine_text": "\nIn this article, an alternative to the Euclidian space-time concept is presented to precisely describe the two electrons within a helium atom. The two-dimensional space-time model is based on two orthogonal and complementary units- space and time. It is shown that calculus and complex wave functions have distinctive physical significances under the new atom spacetime. This novel approach is compatible with quantum mechanics and unifies mathematical theories such as complex functions, calculus and trigonometry. Moreover, the description of helium electron resonance is compared to classical mechanics of an oscillating pendulum and to classical electromagnetism of an LC oscillator. With this novel space-time platform, a prospect to join particle physics with classical physics is provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4331}
{"prompt": "Rephrase the abstract of an article with title 'Observations towards early-type stars in the ESO-POP survey: II --\n  searches for intermediate and high velocity clouds'.\n  We present CaII K and TiII optical spectra of early-type stars taken mainly\nfrom the UVES Paranal Observatory Project, plus HI 21-cm spectra from the\nVila-Elisa and Leiden-Dwingeloo surveys, which are employed to obtain distances\nto intermediate and high velocity clouds. HI emission at a velocity of -117\nkm/s towards the sightline HD 30677 with NHI=1.7x10^19 cm-2 has no\ncorresponding CaII K absorption, which has a signal-to-noise (S/N) ratio of\n610. The star has a spectroscopically determined distance of 2.7-kpc, and hence\nsets this as a firm lower distance limit towards Anti-Centre cloud ACII.\nTowards another sightline (HD 46185), HI at +122 km/s and NHI=1.2x10^19 cm-2 is\nseen. The CaII K spectrum has a S/N = 780, although no absorption is observed\nat the cloud velocity. This similarly places a firm lower distance limit of\n2.9-kpc towards this parcel of gas that may be an intermediate velocity cloud.\nThe lack of intermediate velocity (IV) CaII K absorption towards HD 196426 at a\nS/N = 500 reinforces a lower distance limit of 700-pc towards this part of\nComplex gp, where NHI is 1.1x10^19 cm-2 and velocity is +78 km/s. Additionally,\nno IV CaII K is seen in absorption in the spectrum of HD 19445, which is strong\nin HI with NHI=8x10^19 cm-2 at -42 km/s, placing a firm although uninteresting\nlower distance limit of 39-pc to this part of IV South. Finally, no HV CaII K\nabsorption is seen towards HD 115363 at a S/N = 410, placing a lower distance\nof 3.2-kpc towards the HVC gas at velocity of +224 km/s and NHI=5.2x10^19 cm-2.\nThis gas is in the same region of the sky as complex WE (Wakker 2001), but at\nhigher velocities. The non-detection of CaII K absorption sets a lower distance\nof 3.2-kpc towards the HVC, which is unsurprising if this feature is indeed\nrelated to the Magellanic System.\n\n", "human_text": "  We present CaII K and TiII optical spectra of early-type stars taken mainly\nfrom the UVES Paranal Observatory Project, plus HI 21-cm spectra from the\nVila-Elisa and Leiden-Dwingeloo surveys, which are employed to obtain distances\nto intermediate and high velocity clouds. HI emission at a velocity of -117\nkm/s towards the sightline HD 30677 with NHI=1.7x10^19 cm-2 has no\ncorresponding CaII K absorption, which has a signal-to-noise (S/N) ratio of\n610. The star has a spectroscopically determined distance of 2.7-kpc, and hence\nsets this as a firm lower distance limit towards Anti-Centre cloud ACII.\nTowards another sightline (HD 46185), HI at +122 km/s and NHI=1.2x10^19 cm-2 is\nseen. The CaII K spectrum has a S/N = 780, although no absorption is observed\nat the cloud velocity. This similarly places a firm lower distance limit of\n2.9-kpc towards this parcel of gas that may be an intermediate velocity cloud.\nThe lack of intermediate velocity (IV) CaII K absorption towards HD 196426 at a\nS/N = 500 reinforces a lower distance limit of 700-pc towards this part of\nComplex gp, where NHI is 1.1x10^19 cm-2 and velocity is +78 km/s. Additionally,\nno IV CaII K is seen in absorption in the spectrum of HD 19445, which is strong\nin HI with NHI=8x10^19 cm-2 at -42 km/s, placing a firm although uninteresting\nlower distance limit of 39-pc to this part of IV South. Finally, no HV CaII K\nabsorption is seen towards HD 115363 at a S/N = 410, placing a lower distance\nof 3.2-kpc towards the HVC gas at velocity of +224 km/s and NHI=5.2x10^19 cm-2.\nThis gas is in the same region of the sky as complex WE (Wakker 2001), but at\nhigher velocities. The non-detection of CaII K absorption sets a lower distance\nof 3.2-kpc towards the HVC, which is unsurprising if this feature is indeed\nrelated to the Magellanic System.\n", "machine_text": "\nIn this paper, we present optical spectra from the UVES Paranal Observatory Project of CaII K and TiII spectral lines from early-type stars, as well as HI 21-cm spectra from the Vila-Elisa and Leiden-Dwingeloo surveys. These spectra have been used to infer distances to intermediate and high velocity clouds. We highlight four different sightlines, HD 30677, HD 46185, HD 196426 and HD 19445, by comparing the signal-to-noise (S/N) ratios of the CaII K and HI 21-cm spectra and the velocity of the clouds in each case. This analysis has set firm lower distance limits of 2.7-kpc, 2.9-kpc, 700-pc and 39-pc, respectively. Similarly, a lower distance of 3.2-kpc was determined towards the HVC gas related to the Magellanic System, for the sightline HD 115363. Despite this lack of positive evidence for CaII K absorption, the data provide reliable limits for distances to these clouds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1315}
{"prompt": "Rephrase the abstract of an article with title 'The host galaxies of strong CaII QSO absorption systems at z<0.5'.\n  We present new imaging and spectroscopic observations of the fields of five\nQSOs with very strong intervening CaII absorption systems at redshifts z<0.5\nselected from the Sloan Digital Sky Survey. Recent studies of these very rare\nabsorbers indicate that they may be related to damped Lyman alpha systems\n(DLAs). In all five cases we identify a galaxy at the redshift of the CaII\nsystem with impact parameters up to ~24 kpc. In four out of five cases the\ngalaxies are luminous (L ~L*), metal-rich (Z ~Zsun), massive (velocity\ndispersion, sigma ~100 km/s) spirals. Their star formation rates, deduced from\nHalpha emission, are high, in the range SFR = 0.3 - 30 Msun/yr. In our\nanalysis, we paid particular attention to correcting the observed emission line\nfluxes for stellar absorption and dust extinction. We show that these effects\nare important for a correct SFR estimate; their neglect in previous low-z\nstudies of DLA-selected galaxies has probably led to an underestimate of the\nstar formation activity in at least some DLA hosts. We discuss possible links\nbetween CaII-selected galaxies and DLAs and outline future observations which\nwill help clarify the relationship between these different classes of QSO\nabsorbers.\n\n", "human_text": "  We present new imaging and spectroscopic observations of the fields of five\nQSOs with very strong intervening CaII absorption systems at redshifts z<0.5\nselected from the Sloan Digital Sky Survey. Recent studies of these very rare\nabsorbers indicate that they may be related to damped Lyman alpha systems\n(DLAs). In all five cases we identify a galaxy at the redshift of the CaII\nsystem with impact parameters up to ~24 kpc. In four out of five cases the\ngalaxies are luminous (L ~L*), metal-rich (Z ~Zsun), massive (velocity\ndispersion, sigma ~100 km/s) spirals. Their star formation rates, deduced from\nHalpha emission, are high, in the range SFR = 0.3 - 30 Msun/yr. In our\nanalysis, we paid particular attention to correcting the observed emission line\nfluxes for stellar absorption and dust extinction. We show that these effects\nare important for a correct SFR estimate; their neglect in previous low-z\nstudies of DLA-selected galaxies has probably led to an underestimate of the\nstar formation activity in at least some DLA hosts. We discuss possible links\nbetween CaII-selected galaxies and DLAs and outline future observations which\nwill help clarify the relationship between these different classes of QSO\nabsorbers.\n", "machine_text": "\nWe present findings from detailed observations of five quasars with very strong intervening calcium II absorption systems at redshifts below 0.5 taken from the Sloan Digital Sky Survey. These rare occurrences may be linked to damped Lyman alpha systems. In every case, a galaxy at the same redshift is located within 24 kpc from the observed QSO. Additionally, the four brightest galaxies featured in our observations are luminous, metal-rich spiral galaxies; their star formation rates, stemming from H-alpha emission, are in the range between 0.3 and 30 Msun/yr. Following our analysis, we emphasize the necessity for dust and stellar absorption correction for a more accurate measure of star formation rates in DLA-selected galaxies. We delve further into the potential link between Calcium II-selected galaxies and DLAs and lay out suggestions for future observations in order to make a solid connection between these two types of quasar absorbers.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3462}
{"prompt": "Rephrase the abstract of an article with title 'Laplacian instability of planar streamer ionization fronts - an example\n  of pulled front analysis'.\n  Streamer ionization fronts are pulled fronts propagating into a linearly\nunstable state; the spatial decay of the initial condition of a planar front\nselects dynamically one specific long time attractor out of a continuous\nfamily. A transverse stability analysis has to take these features into\naccount. In this paper we introduce a framework for this transverse stability\nanalysis, involving stable and unstable manifolds in a weighted space. Within\nthis framework, a numerical dynamical systems method for the calculation of the\ndispersion relation as an eigenvalue problem is defined and dispersion curves\nfor different values of the electron diffusion constant and of the electric\nfield ahead of the front are derived. Numerical solutions of the initial value\nproblem confirm the eigenvalue calculations. The numerical work is complemented\nwith analytical expressions for the dispersion relation in the limit of small\nand large wave numbers and with a fit formula for intermediate wave numbers.\nThis empirical fit supports the conjecture that the smallest unstable wave\nlength of the Laplacian instability is proportional to the diffusion length\nthat characterizes the leading edge of the pulled ionization front.\n\n", "human_text": "  Streamer ionization fronts are pulled fronts propagating into a linearly\nunstable state; the spatial decay of the initial condition of a planar front\nselects dynamically one specific long time attractor out of a continuous\nfamily. A transverse stability analysis has to take these features into\naccount. In this paper we introduce a framework for this transverse stability\nanalysis, involving stable and unstable manifolds in a weighted space. Within\nthis framework, a numerical dynamical systems method for the calculation of the\ndispersion relation as an eigenvalue problem is defined and dispersion curves\nfor different values of the electron diffusion constant and of the electric\nfield ahead of the front are derived. Numerical solutions of the initial value\nproblem confirm the eigenvalue calculations. The numerical work is complemented\nwith analytical expressions for the dispersion relation in the limit of small\nand large wave numbers and with a fit formula for intermediate wave numbers.\nThis empirical fit supports the conjecture that the smallest unstable wave\nlength of the Laplacian instability is proportional to the diffusion length\nthat characterizes the leading edge of the pulled ionization front.\n", "machine_text": "This paper analyzes the Laplacian instability of planar streamer ionization fronts, in which the spatial decay of the initial condition of the front dynamically selects one specific long-term attractor from a continuous family. To characterize the transverse stability, a framework involving stable and unstable manifolds in a weighted space is presented. This framework is used in a numerical dynamical systems method to calculate the dispersion relation as an eigenvalue problem and derive the dispersion curves for varying electron diffusion constants and electric fields in front of the front. The initial value problem is confirmed by numerical solutions and the dispersion relation is further supported by analytical expressions in the limit of small and large wave numbers, along with a fit formula for intermediate wave numbers. This empirical fit implies that the smallest unstable wavelength of the Laplacian instability is proportional to the diffusion length of the leading edge of the pulled ionization front.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2088}
{"prompt": "Rephrase the abstract of an article with title 'A general approach to statistical modeling of physical laws:\n  nonparametric regression'.\n  Statistical modeling of experimental physical laws is based on the\nprobability density function of measured variables. It is expressed by\nexperimental data via a kernel estimator. The kernel is determined objectively\nby the scattering of data during calibration of experimental setup. A physical\nlaw, which relates measured variables, is optimally extracted from experimental\ndata by the conditional average estimator. It is derived directly from the\nkernel estimator and corresponds to a general nonparametric regression. The\nproposed method is demonstrated by the modeling of a return map of noisy\nchaotic data. In this example, the nonparametric regression is used to predict\na future value of chaotic time series from the present one. The mean predictor\nerror is used in the definition of predictor quality, while the redundancy is\nexpressed by the mean square distance between data points. Both statistics are\nused in a new definition of predictor cost function. From the minimum of the\npredictor cost function, a proper number of data in the model is estimated.\n\n", "human_text": "  Statistical modeling of experimental physical laws is based on the\nprobability density function of measured variables. It is expressed by\nexperimental data via a kernel estimator. The kernel is determined objectively\nby the scattering of data during calibration of experimental setup. A physical\nlaw, which relates measured variables, is optimally extracted from experimental\ndata by the conditional average estimator. It is derived directly from the\nkernel estimator and corresponds to a general nonparametric regression. The\nproposed method is demonstrated by the modeling of a return map of noisy\nchaotic data. In this example, the nonparametric regression is used to predict\na future value of chaotic time series from the present one. The mean predictor\nerror is used in the definition of predictor quality, while the redundancy is\nexpressed by the mean square distance between data points. Both statistics are\nused in a new definition of predictor cost function. From the minimum of the\npredictor cost function, a proper number of data in the model is estimated.\n", "machine_text": "This article presents a general approach to the statistical modeling of physical laws,  centering around the use of a kernel estimator to express the probability density function of measured variables. Subsequently, the physical law is determined and extracted from experimental data with a conditional average estimator. Using an example of a return map of noisy chaotic data, the nonparametric regression is used to infer a future value of chaotic time series from the present one. A new definition of predictor cost function is formulated using mean predictor error and the mean square distance between data points. The optimal number of data for the model is then estimated from the minimum point of the cost function.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0089}
{"prompt": "Rephrase the abstract of an article with title 'The First Stellar Cluster'.\n  We report results from numerical simulations of star formation in the early\nuniverse that focus on gas at very high densities and very low metallicities.\nWe argue that the gas in the central regions of protogalactic halos will\nfragment as long as it carries sufficient angular momentum. Rotation leads to\nthe build-up of massive disk-like structures which fragment to form protostars.\nAt metallicities Z ~ 10^-5 Zsun, dust cooling becomes effective and leads to a\nsudden drop of temperature at densities above n = 10^12 cm^-3. This induces\nvigorous fragmentation, leading to a very densely-packed cluster of low-mass\nstars. This is the first stellar cluster. The mass function of stars peaks\nbelow 1 Msun, similar to what is found in the solar neighborhood, and\ncomparable to the masses of the very-low metallicity subgiant stars recently\ndiscovered in the halo of our Milky Way. We find that even purely primordial\ngas can fragment at densities 10^14 cm^-3 < n < 10^16 cm^-3, although the\nresulting mass function contains only a few objects (at least a factor of ten\nless than the Z = 10^-5 Zsun mass function), and is biased towards higher\nmasses. A similar result is found for gas with Z = 10^-6 Zsun. Gas with Z <=\n10^-6 Zsun behaves roughly isothermally at these densities (with polytropic\nexponent gamma ~ 1.06) and the massive disk-like structures that form due to\nangular momentum conservation will be marginally unstable. As fragmentation is\nless efficient, we expect stars with Z <= 10^-6 Zsun to be massive, with masses\nin excess of several tens of solar masses, consistent with the results from\nprevious studies.\n\n", "human_text": "  We report results from numerical simulations of star formation in the early\nuniverse that focus on gas at very high densities and very low metallicities.\nWe argue that the gas in the central regions of protogalactic halos will\nfragment as long as it carries sufficient angular momentum. Rotation leads to\nthe build-up of massive disk-like structures which fragment to form protostars.\nAt metallicities Z ~ 10^-5 Zsun, dust cooling becomes effective and leads to a\nsudden drop of temperature at densities above n = 10^12 cm^-3. This induces\nvigorous fragmentation, leading to a very densely-packed cluster of low-mass\nstars. This is the first stellar cluster. The mass function of stars peaks\nbelow 1 Msun, similar to what is found in the solar neighborhood, and\ncomparable to the masses of the very-low metallicity subgiant stars recently\ndiscovered in the halo of our Milky Way. We find that even purely primordial\ngas can fragment at densities 10^14 cm^-3 < n < 10^16 cm^-3, although the\nresulting mass function contains only a few objects (at least a factor of ten\nless than the Z = 10^-5 Zsun mass function), and is biased towards higher\nmasses. A similar result is found for gas with Z = 10^-6 Zsun. Gas with Z <=\n10^-6 Zsun behaves roughly isothermally at these densities (with polytropic\nexponent gamma ~ 1.06) and the massive disk-like structures that form due to\nangular momentum conservation will be marginally unstable. As fragmentation is\nless efficient, we expect stars with Z <= 10^-6 Zsun to be massive, with masses\nin excess of several tens of solar masses, consistent with the results from\nprevious studies.\n", "machine_text": "\nResults from numerical simulations of star formation in the early universe,\nfocusing on gas of low metallicities, have provided evidence that the gas in\nthe central regions of protogalactic halos will undergo fragmentation. This\nfragmentation occurs if the gas carries sufficient angular momentum,\nresulting in a formation of a massive disk-like structure. At a critical\nmetallicity of 10^-5 solar masses, dust cooling becomes effective,\ntriggering a sharp drop in temperature at densities greater than 10^12\ncm^-3 causing vigorous fragmentation and the emergence of the first low-mass\nstellar cluster. Results from this study point towards a mass function of\nstars that is comparable to that of the very-low metallicity subgiant stars\nrecently discovered in the Milky Way galaxy, with the maximum mass falling\nbelow 1 Msun. Experiments conducted below the metallicity of 10^-6 solar\nmasses demonstrate that the gas undergoes partial isothermal collapse with a\npolytropic exponent of gamma ~ 1.06, resulting in few star formations of\nmasses in excess of several tens of solar masses.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0613}
{"prompt": "Rephrase the abstract of an article with title 'A characteristic observable signature of preferred frame effects in\n  relativistic binary pulsars'.\n  In this paper we develop a consistent, phenomenological methodology to\nmeasure preferred-frame effects (PFEs) in binary pulsars that exhibit a high\nrate of periastron advance. We show that in these systems the existence of a\npreferred frame for gravity leads to an observable characteristic `signature'\nin the timing data, which uniquely identifies this effect. We expand the\nstandard Damour-Deruelle timing formula to incorporate this `signature' and\nshow how this new PFE timing model can be used to either measure or constrain\nthe parameters related to a violation of the local Lorentz invariance of\ngravity in the strong internal fields of neutron stars. In particular, we\ndemonstrate that in the presence of PFEs we expect a set of the new timing\nparameters to have a unique relationship that can be measured and tested\nincontrovertibly. This new methodology is applied to the Double Pulsar, which\nturns out to be the ideal test system for this kind of experiments.The\ncurrently available dataset allows us only to study the impact of PFEs on the\norbital precession rate, d omega/dt, providing limits that are, at the moment,\nclearly less stringent than existing limits on PFE strong-field parameters.\nHowever, simulations show that the constraints improve fast in the coming\nyears, allowing us to study all new PFE timing parameters and to check for the\nunique relationship between them. Finally, we show how a combination of several\nsuitable systems in a \"PFE antenna array\", expected to be availabe for instance\nwith the Square-Kilometre-Array (SKA), provides full sensitivity to possible\nviolations of local Lorentz invariance in strong gravitational fields in all\ndirections of the sky. This PFE antenna array may eventually allow us to\ndetermine the direction of a preferred frame should it exist.\n\n", "human_text": "  In this paper we develop a consistent, phenomenological methodology to\nmeasure preferred-frame effects (PFEs) in binary pulsars that exhibit a high\nrate of periastron advance. We show that in these systems the existence of a\npreferred frame for gravity leads to an observable characteristic `signature'\nin the timing data, which uniquely identifies this effect. We expand the\nstandard Damour-Deruelle timing formula to incorporate this `signature' and\nshow how this new PFE timing model can be used to either measure or constrain\nthe parameters related to a violation of the local Lorentz invariance of\ngravity in the strong internal fields of neutron stars. In particular, we\ndemonstrate that in the presence of PFEs we expect a set of the new timing\nparameters to have a unique relationship that can be measured and tested\nincontrovertibly. This new methodology is applied to the Double Pulsar, which\nturns out to be the ideal test system for this kind of experiments.The\ncurrently available dataset allows us only to study the impact of PFEs on the\norbital precession rate, d omega/dt, providing limits that are, at the moment,\nclearly less stringent than existing limits on PFE strong-field parameters.\nHowever, simulations show that the constraints improve fast in the coming\nyears, allowing us to study all new PFE timing parameters and to check for the\nunique relationship between them. Finally, we show how a combination of several\nsuitable systems in a \"PFE antenna array\", expected to be availabe for instance\nwith the Square-Kilometre-Array (SKA), provides full sensitivity to possible\nviolations of local Lorentz invariance in strong gravitational fields in all\ndirections of the sky. This PFE antenna array may eventually allow us to\ndetermine the direction of a preferred frame should it exist.\n", "machine_text": "In this article, we propose a reliable, empirical procedure for analysing the effects of preferred frame effects (PFEs) on binary pulsars with relatively high rates of periastron advance. We demonstrate that this novel PFE timing model generates a recognizable, singular feature in the available data which securely confirms its presence. We further expand this version of the Damour-Deruelle timing equation to include this marked as a determining factor in estimating or constraining the variability of Lorentz invariance of gravity in neutron stars. We then apply this new approach to the Double Pulsar system, demonstrating that our method currently limits the effects of PFEs on this system\u2019s orbital precession rate, d omega/dt, but with the potential to gather more data over the upcoming years to measure all new PFE timing parameters. Lastly, we explore the feasibility of several systems combining as a PFE \u2018antenna array\u2019 with SKA, with the ability to detect any violations of Lorentz invariance of gravity and determine its source should it exist.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2382}
{"prompt": "Rephrase the abstract of an article with title 'Next-to-leading-order corrections to exclusive processes in $k_T$\n  factorization'.\n  We calculate next-to-leading-order (NLO) corrections to exclusive processes\nin $k_T$ factorization theorem, taking $\\pi\\gamma^*\\to\\gamma$ as an example.\nPartons off-shell by $k_T^2$ are considered in both the quark diagrams from\nfull QCD and the effective diagrams for the pion wave function. The gauge\ndependences in the above two sets of diagrams cancel, when deriving the\n$k_T$-dependent hard kernel as their difference. The gauge invariance of the\nhard kernel is then proven to all orders by induction. The light-cone\nsingularities in the $k_T$-dependent pion wave function are regularized by\nrotating the Wilson lines away from the light cone. This regularization\nintroduces a factorization-scheme dependence into the hard kernel, which can be\nminimized in the standard way. Both the large double logarithms $\\ln^2k_T$ and\n$\\ln^2 x$, $x$ being a parton momentum fraction, arise from the loop correction\nto the virtual photon vertex, the former being absorbed into the pion wave\nfunction and organized by the $k_T$ resummation, and the latter absorbed into a\njet function and organized by the threshold resummation. The NLO corrections\nare found to be only few-percent for $\\pi\\gamma^*\\to\\gamma$, if setting the\nfactorization scale to the momentum transfer from the virtual photon.\n\n", "human_text": "  We calculate next-to-leading-order (NLO) corrections to exclusive processes\nin $k_T$ factorization theorem, taking $\\pi\\gamma^*\\to\\gamma$ as an example.\nPartons off-shell by $k_T^2$ are considered in both the quark diagrams from\nfull QCD and the effective diagrams for the pion wave function. The gauge\ndependences in the above two sets of diagrams cancel, when deriving the\n$k_T$-dependent hard kernel as their difference. The gauge invariance of the\nhard kernel is then proven to all orders by induction. The light-cone\nsingularities in the $k_T$-dependent pion wave function are regularized by\nrotating the Wilson lines away from the light cone. This regularization\nintroduces a factorization-scheme dependence into the hard kernel, which can be\nminimized in the standard way. Both the large double logarithms $\\ln^2k_T$ and\n$\\ln^2 x$, $x$ being a parton momentum fraction, arise from the loop correction\nto the virtual photon vertex, the former being absorbed into the pion wave\nfunction and organized by the $k_T$ resummation, and the latter absorbed into a\njet function and organized by the threshold resummation. The NLO corrections\nare found to be only few-percent for $\\pi\\gamma^*\\to\\gamma$, if setting the\nfactorization scale to the momentum transfer from the virtual photon.\n", "machine_text": "In this article, we provide an analysis of NLO corrections to exclusive processes when employing $k_T$ factorization theorem by examining the example of $\\pi\\gamma^*\\to\\gamma$. This exploration consists of incorporating off-shell partons with $k_T^2$ both in the quark diagrams from full QCD and in the effective diagrams for the pion wave function, in order to formulate a $k_T$-dependent hard kernel through the cancellation of gauge dependences. The validity of the hard kernel is subsequently proved to all orders using induction. Besides, the light-cone singularities in the $k_T$-dependent pion wave function are regularized by shifting the Wilson lines from the light cone, which results in factorization-scheme dependent hard kernel that can be minimized. Furthermore, large amounts of double logarithms $\\ln^2k_T$ and $\\ln^2 x$ manifest in the loop correction to the virtual photon vertex, the former of which is managed by $k_T$ resummation and the latter by threshold resummation. Our findings show that the NLO corrections to $\\pi\\gamma^*\\to\\gamma$ are slightly above several percent when the factorization scale is set to the momentum transfer from the virtual photon.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.379}
{"prompt": "Rephrase the abstract of an article with title 'Geometry of curves with exceptional secant planes: linear series along\n  the general curve'.\n  We study linear series on a general curve of genus $g$, whose images are\nexceptional with regard to their secant planes. Working in the framework of an\nextension of Brill-Noether theory to pairs of linear series, we prove that a\ngeneral curve has no linear series with exceptional secant planes, in a very\nprecise sense, whenever the total number of series is finite. Next, we\npartially solve the problem of computing the number of linear series with\nexceptional secant planes in a one-parameter family in terms of tautological\nclasses associated with the family, by evaluating our hypothetical formula\nalong judiciously-chosen test families. As an application, we compute the\nnumber of linear series with exceptional secant planes on a general curve\nequipped with a one-dimensional family of linear series. We pay special\nattention to the extremal case of $d$-secant $(d-2)$-planes to\n$(2d-1)$-dimensional series, which appears in the study of Hilbert schemes of\npoints on surfaces. In that case, our formula may be rewritten in terms of\nhypergeometric series, which allows us both to prove that it is nonzero and to\ndeduce its asymptotics in $d$.\n\n", "human_text": "  We study linear series on a general curve of genus $g$, whose images are\nexceptional with regard to their secant planes. Working in the framework of an\nextension of Brill-Noether theory to pairs of linear series, we prove that a\ngeneral curve has no linear series with exceptional secant planes, in a very\nprecise sense, whenever the total number of series is finite. Next, we\npartially solve the problem of computing the number of linear series with\nexceptional secant planes in a one-parameter family in terms of tautological\nclasses associated with the family, by evaluating our hypothetical formula\nalong judiciously-chosen test families. As an application, we compute the\nnumber of linear series with exceptional secant planes on a general curve\nequipped with a one-dimensional family of linear series. We pay special\nattention to the extremal case of $d$-secant $(d-2)$-planes to\n$(2d-1)$-dimensional series, which appears in the study of Hilbert schemes of\npoints on surfaces. In that case, our formula may be rewritten in terms of\nhypergeometric series, which allows us both to prove that it is nonzero and to\ndeduce its asymptotics in $d$.\n", "machine_text": "\nThis research examines linear series on a general curve of genus $g$, where the images are excluded due to the properties of their secant planes. Utilizing an extension of Brill-Noether theory to pairs of linear series, a general curve has been proven to not possess any linear series with extraordinary secant planes when the total number of such series is finite. Additionally, a one-parameter family of linear series with exceptional secant planes was partially resolved by using tautological classes associated with the family and a hypothetical formula. An application of this study, which relates to the extremal occurrence of $d$-secant $(d-2)$-planes to $(2d-1)$-dimensional series in the investigation of Hilbert schemes of points on surfaces, further explains the nonzero nature and asymptotics in $d$ of the number of linear series with exceptional secant planes on a general curve with a one-dimensional family of linear series by utilizing hypergeometric series.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2049}
{"prompt": "Rephrase the abstract of an article with title 'Lyman Break Galaxies at z~5: Rest-frame UV Spectra II'.\n  We present the results of spectroscopy of Lyman Break Galaxies (LBGs) at z~5\nin the J0053+1234 field with the Faint Object Camera and Spectrograph on the\nSubaru telescope. Among 5 bright candidates with z' < 25.0 mag, 2 objects are\nconfirmed to be at z~5 from their Ly alpha emission and the continuum\ndepression shortward of Ly alpha. The EWs of Ly alpha emission of the 2 LBGs\nare not so strong to be detected as Ly alpha emitters, and one of them shows\nstrong low-ionized interstellar (LIS) metal absorption lines. Two faint objects\nwith z' \\geq 25.0 mag are also confirmed to be at z~5, and their spectra show\nstrong Ly alpha emission in contrast to the bright ones. These results suggest\na deficiency of strong Ly alpha emission in bright LBGs at z~5, which has been\ndiscussed in our previous paper. Combined with our previous spectra of LBGs at\nz~5 obtained around the Hubble Deep Field-North (HDF-N), we made a composite\nspectrum of UV luminous (M_1400 \\leq -21.5 mag) LBGs at z~5. The resultant\nspectrum shows a weak Ly alpha emission and strong LIS absorptions which\nsuggests that the bright LBGs at z~5 have chemically evolved at least to ~0.1\nsolar metallicity. For a part of our sample in the HDF-N region, we obtained\nnear-to-mid infrared data, which constraint stellar masses of these objects.\nWith the stellar mass and the metallicity estimated from LIS absorptions, the\nmetallicities of the LBGs at z~5 tend to be lower than those of the galaxies\nwith the same stellar mass at z \\lesssim 2, although the uncertainty is very\nlarge.\n\n", "human_text": "  We present the results of spectroscopy of Lyman Break Galaxies (LBGs) at z~5\nin the J0053+1234 field with the Faint Object Camera and Spectrograph on the\nSubaru telescope. Among 5 bright candidates with z' < 25.0 mag, 2 objects are\nconfirmed to be at z~5 from their Ly alpha emission and the continuum\ndepression shortward of Ly alpha. The EWs of Ly alpha emission of the 2 LBGs\nare not so strong to be detected as Ly alpha emitters, and one of them shows\nstrong low-ionized interstellar (LIS) metal absorption lines. Two faint objects\nwith z' \\geq 25.0 mag are also confirmed to be at z~5, and their spectra show\nstrong Ly alpha emission in contrast to the bright ones. These results suggest\na deficiency of strong Ly alpha emission in bright LBGs at z~5, which has been\ndiscussed in our previous paper. Combined with our previous spectra of LBGs at\nz~5 obtained around the Hubble Deep Field-North (HDF-N), we made a composite\nspectrum of UV luminous (M_1400 \\leq -21.5 mag) LBGs at z~5. The resultant\nspectrum shows a weak Ly alpha emission and strong LIS absorptions which\nsuggests that the bright LBGs at z~5 have chemically evolved at least to ~0.1\nsolar metallicity. For a part of our sample in the HDF-N region, we obtained\nnear-to-mid infrared data, which constraint stellar masses of these objects.\nWith the stellar mass and the metallicity estimated from LIS absorptions, the\nmetallicities of the LBGs at z~5 tend to be lower than those of the galaxies\nwith the same stellar mass at z \\lesssim 2, although the uncertainty is very\nlarge.\n", "machine_text": "\nUsing the Faint Object Camera and Spectrograph on the Subaru telescope, we have carried out a spectroscopic analysis of LBGs at z~5 in the J0053+1234 field. From the 5 studied candidates, all of which have z' < 25.0 mag, two objects were proven to be at z~5 in correspondence with their Ly alpha emission and the dropped continuum shortward of this feature. Of these two, only one shows noteworthy low-ionised interstellar metal absorptions. Even though the 2 faintest objects, with z' \u2265 25.0 mag, have confirmed to be at z~5, their spectra have strong Ly alpha emission in comparison to the brighter counterparts. In addition to our previously established data on LBGs at z~5 at the Hubble Deep Field - North (HDF-N), we have created a composite spectrum of the UV luminescent, M\u2081\u2084\u2080\u2080 \u2264 -21.5 mag LBGs at z~5 which exhibit weak Ly alpha emission and powerful LIS absorptions, suggesting that these bright sources have reached a hotiosity level of at least 0.1 solar. With the respective IR data on some of our HDF-N sample, we have researched the stellar masses of these bodies. Bearing in mind the metallicity assessed from LIS absorptions, the z~5 LBGs tend to be have lower metallicities than galaxies with equivalent stellar masses at z \\lesssim 2; however, this can be quite uncertain.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1145}
{"prompt": "Rephrase the abstract of an article with title 'Theory of Macroscopic Quantum Tunneling in High-T_c c-Axis Josephson\n  Junctions'.\n  We study macroscopic quantum tunneling (MQT) in c-axis twist Josephson\njunctions made of high-T_c superconductors in order to clarify the influence of\nthe anisotropic order parameter symmetry (OPS) on MQT. The dependence of the\nMQT rate on the twist angle $\\gamma$ about the c-axis is calculated by using\nthe functional integral and the bounce method. Due to the d-wave OPS, the\n$\\gamma$ dependence of standard deviation of the switching current distribution\nand the crossover temperature from thermal activation to MQT are found to be\ngiven by $\\cos2\\gamma$ and $\\sqrt{\\cos2\\gamma}$, respectively. We also show\nthat a dissipative effect resulting from the nodal quasiparticle excitation on\nMQT is negligibly small, which is consistent with recent MQT experiments using\nBi${}_2$Sr${}_2$CaCu${}_2$O${}_{8 + \\delta}$ intrinsic junctions. These results\nindicate that MQT in c-axis twist junctions becomes a useful experimental tool\nfor testing the OPS of high-T_c materials at low temperature, and suggest high\npotential of such junctions for qubit applications.\n\n", "human_text": "  We study macroscopic quantum tunneling (MQT) in c-axis twist Josephson\njunctions made of high-T_c superconductors in order to clarify the influence of\nthe anisotropic order parameter symmetry (OPS) on MQT. The dependence of the\nMQT rate on the twist angle $\\gamma$ about the c-axis is calculated by using\nthe functional integral and the bounce method. Due to the d-wave OPS, the\n$\\gamma$ dependence of standard deviation of the switching current distribution\nand the crossover temperature from thermal activation to MQT are found to be\ngiven by $\\cos2\\gamma$ and $\\sqrt{\\cos2\\gamma}$, respectively. We also show\nthat a dissipative effect resulting from the nodal quasiparticle excitation on\nMQT is negligibly small, which is consistent with recent MQT experiments using\nBi${}_2$Sr${}_2$CaCu${}_2$O${}_{8 + \\delta}$ intrinsic junctions. These results\nindicate that MQT in c-axis twist junctions becomes a useful experimental tool\nfor testing the OPS of high-T_c materials at low temperature, and suggest high\npotential of such junctions for qubit applications.\n", "machine_text": "\nWe examine the influence of anisotropic order parameter symmetry (OPS) on macroscopic quantum tunneling (MQT) in c-axis twist Josephson junctions made up of high-Temperature superconductors. Using the functional integral and bounce technique, we probe the impact of twist angle $\\gamma$ on the rate of MQT. The d-wave nature of OPS brings forth $\\cos2\\gamma$ and $\\sqrt{\\cos2\\gamma}$ dependencies of the crossover temperature from thermal activation to MQT and the standard deviation of switching current distribution, respectively. Additionally, a dissipative effect from nodal quasiparticle excitation is shown to be insignificant, which is consistent with experiments done on Bi${}_2$Sr${}_2$CaCu${}_2$O${}_{8 + \\delta}$ intrinsic junctions. These findings imply that MQT in c-axis twist junctions offers a great potential to test OPS of such substances at low temperatures and can be applied to qubit applications.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1418}
{"prompt": "Rephrase the abstract of an article with title 'J/psi Production in an Equilibrating Partonic System'.\n  Any color singlet or octet ccbar pair is created at short distances and then\nexpands to a full size of J/psi. Such a dynamical evolution process is included\nhere in calculations for the J/psi number distribution as a function of\ntransverse momentum and rapidity in central Au-Au collisions at both RHIC and\nLHC energies. The ccbar pairs are produced in the initial collision and in the\npartonic system during the prethermal and thermal stages through the partonic\nchannels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, and then they\ndissociate in the latter two stages. Dissociation of ccbar in the medium occurs\nvia two reactions: (a) color singlet ccbar plus a gluon turns to color octet\nccbar, (b) color octet ccbar plus a gluon persists as color octet. There are\nmodest yields of ccbar in the prethermal stage at RHIC energy and through the\nreactions ab to ccbar [{2S+1}L_J] at LHC energy for partons with large average\nmomentum in the prethermal stage at both collider energies and in the thermal\nstage at LHC energy. Production from the partonic system competes with the\nsuppression of the initial yield in the deconfined medium. Consequently, a\nbulge within -1.5<y<1.5 has been found for the J/psi number distribution and\nthe ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon\ncollisions. This bulge is caused by the partonic system and is thus an\nindicator of a deconfined partonic medium. Based on this result we suggest the\nrapidity region worth measuring in future experiments at RHIC and LHC to be\n-3<y<3.\n\n", "human_text": "  Any color singlet or octet ccbar pair is created at short distances and then\nexpands to a full size of J/psi. Such a dynamical evolution process is included\nhere in calculations for the J/psi number distribution as a function of\ntransverse momentum and rapidity in central Au-Au collisions at both RHIC and\nLHC energies. The ccbar pairs are produced in the initial collision and in the\npartonic system during the prethermal and thermal stages through the partonic\nchannels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, and then they\ndissociate in the latter two stages. Dissociation of ccbar in the medium occurs\nvia two reactions: (a) color singlet ccbar plus a gluon turns to color octet\nccbar, (b) color octet ccbar plus a gluon persists as color octet. There are\nmodest yields of ccbar in the prethermal stage at RHIC energy and through the\nreactions ab to ccbar [{2S+1}L_J] at LHC energy for partons with large average\nmomentum in the prethermal stage at both collider energies and in the thermal\nstage at LHC energy. Production from the partonic system competes with the\nsuppression of the initial yield in the deconfined medium. Consequently, a\nbulge within -1.5<y<1.5 has been found for the J/psi number distribution and\nthe ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon\ncollisions. This bulge is caused by the partonic system and is thus an\nindicator of a deconfined partonic medium. Based on this result we suggest the\nrapidity region worth measuring in future experiments at RHIC and LHC to be\n-3<y<3.\n", "machine_text": "\n\nThis study looks at the production of J/psi particles in different stages of Au-Au collisions at both RHIC and LHC energies. Specifically, we include the production of any color singlet or octet ccbar pairs at short distances before they expand to a full size of J/psi. Calculations are made to show the J/psi number distribution as a function of transverse momentum and rapidity depending on the partonic channels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x as well as two reactions: (a) color singlet ccbar plus a gluon turns to color octet ccbar and (b) color octet ccbar plus a gluon persists as color octet. The results demonstrate a bulge within -1.5<y<1.5 in the J/psi number distribution and the ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon collisions due to the partonic system, hence indicating the existence of a deconfined partonic medium. To aid further research, it is suggested that future experiments at RHIC and LHC measure in the region of -3<y<3.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0668}
{"prompt": "Rephrase the abstract of an article with title 'Photolytically generated aerosols in the mesosphere and thermosphere of\n  Titan'.\n  Analysis of the Cassini Ultraviolet Imaging Spectrometer (UVIS) stellar and\nsolar occultations at Titan to date include 12 species: N$_{2}$ (nitrogen),\nCH$_{4}$ (methane), C$_{2}$H$_{2}$ (acetylene), C$_{2}$H$_{4}$ (ethylene),\nC$_{2}$H$_{6}$ (ethane), C$_{4}$H$_{2}$ (diacetylene), C$_{6}$H$_{6}$\n(benzene), C$_{6}$N$_{2}$ (dicyanodiacetylene), C$_{2}$N$_{2}$ (cyanogen), HCN\n(hydrogen cyanide), HC$_{3}$N (cyanoacetylene), and aerosols distinguished by a\nstructureless continuum extinction (absorption plus scattering) of photons in\nthe EUV. The introduction of aerosol particles, retaining the same refractive\nindex properties as tholin with radius $\\sim$125 \\AA and using Mie theory,\nprovides a satisfactory fit to the spectra. The derived vertical profile of\naerosol density shows distinct structure, implying a reactive generation\nprocess reaching altitudes more than 1000 km above the surface. A photochemical\nmodel presented here provides a reference basis for examining the chemical and\nphysical processes leading to the distinctive atmospheric opacity at Titan. We\nfind that dicyanodiacetylene is condensable at $\\sim$650 km, where the\natmospheric temperature minimum is located. This species is the simplest\nmolecule identified to be condensable. Observations are needed to confirm the\nexistence and production rates of dicyanodiacetylene.\n\n", "human_text": "  Analysis of the Cassini Ultraviolet Imaging Spectrometer (UVIS) stellar and\nsolar occultations at Titan to date include 12 species: N$_{2}$ (nitrogen),\nCH$_{4}$ (methane), C$_{2}$H$_{2}$ (acetylene), C$_{2}$H$_{4}$ (ethylene),\nC$_{2}$H$_{6}$ (ethane), C$_{4}$H$_{2}$ (diacetylene), C$_{6}$H$_{6}$\n(benzene), C$_{6}$N$_{2}$ (dicyanodiacetylene), C$_{2}$N$_{2}$ (cyanogen), HCN\n(hydrogen cyanide), HC$_{3}$N (cyanoacetylene), and aerosols distinguished by a\nstructureless continuum extinction (absorption plus scattering) of photons in\nthe EUV. The introduction of aerosol particles, retaining the same refractive\nindex properties as tholin with radius $\\sim$125 \\AA and using Mie theory,\nprovides a satisfactory fit to the spectra. The derived vertical profile of\naerosol density shows distinct structure, implying a reactive generation\nprocess reaching altitudes more than 1000 km above the surface. A photochemical\nmodel presented here provides a reference basis for examining the chemical and\nphysical processes leading to the distinctive atmospheric opacity at Titan. We\nfind that dicyanodiacetylene is condensable at $\\sim$650 km, where the\natmospheric temperature minimum is located. This species is the simplest\nmolecule identified to be condensable. Observations are needed to confirm the\nexistence and production rates of dicyanodiacetylene.\n", "machine_text": "\nAnalysis of Cassini UVIS stellar and solar occultations on Titan have revealed the presence of 12 different chemical species in its meso- and thermosphere, including nitrogen, methane, acetylene, ethylene, ethane, diacetylene, benzene, dicyanodiacetylene, cyanoacetylene and hydrogen cyanide. In addition, these measurements have also detected the presence of aerosol particles, with a refractive index equivalent to that of tholin. Through Mie Theory, we were able to establish that these aerosol particles have a radius of $\\sim$125 \\AA, and the derived vertical profile shows unique features which could indicate a reactive generation process going beyond 1000 km above the surface. Our photochemical model was used as a basis to examine the chemistry, physics and opacity of Titan's atmosphere, and we concluded that the simplest molecule condensable in Titan's atmosphere is dicyanodiacetylene and located at 650 km, where the temperature is at its lowest. More observations are required to verify the condensation, production and existence of dicyanodiacetylene.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0145}
{"prompt": "Rephrase the abstract of an article with title 'Mapping the circumstellar SiO maser emission in R Leo'.\n  The study of the innermost circumstellar layers around AGB stars is crucial\nto understand how these envelopes are formed and evolve. The SiO maser emission\noccurs at a few stellar radii from the central star, providing direct\ninformation on the stellar pulsation and on the chemical and physical\nproperties of these regions. Our data also shed light on several aspects of the\nSiO maser pumping theory that are not well understood yet. We aim to determine}\nthe relative spatial distribution of the 43 GHz and 86 GHz SiO maser lines in\nthe oxygen-rich evolved star R Leo. We have imaged with milliarcsecond\nresolution, by means of Very Long Baseline Interferometry, the 43 GHz (28SiO\nv=1, 2 J=1-0 and 29SiO v=0 J=1-0) and 86 GHz (28SiO v=1 J=2-1 and 29SiO v=0\nJ=2-1) masing regions. We confirm previous results obtained in other\noxygen-rich envelopes. In particular, when comparing the 43 GHz emitting\nregions, the 28SiO v=2 transition is produced in an inner layer, closer to the\ncentral star. On the other hand, the 86 GHz line arises in a clearly farther\nshell. We have also mapped for the first time the 29SiO v=0 J=1-0 emission in R\nLeo. The already reported discrepancy between the observed distributions of the\ndifferent maser lines and the theoretical predictions is also found in R Leo.\n\n", "human_text": "  The study of the innermost circumstellar layers around AGB stars is crucial\nto understand how these envelopes are formed and evolve. The SiO maser emission\noccurs at a few stellar radii from the central star, providing direct\ninformation on the stellar pulsation and on the chemical and physical\nproperties of these regions. Our data also shed light on several aspects of the\nSiO maser pumping theory that are not well understood yet. We aim to determine}\nthe relative spatial distribution of the 43 GHz and 86 GHz SiO maser lines in\nthe oxygen-rich evolved star R Leo. We have imaged with milliarcsecond\nresolution, by means of Very Long Baseline Interferometry, the 43 GHz (28SiO\nv=1, 2 J=1-0 and 29SiO v=0 J=1-0) and 86 GHz (28SiO v=1 J=2-1 and 29SiO v=0\nJ=2-1) masing regions. We confirm previous results obtained in other\noxygen-rich envelopes. In particular, when comparing the 43 GHz emitting\nregions, the 28SiO v=2 transition is produced in an inner layer, closer to the\ncentral star. On the other hand, the 86 GHz line arises in a clearly farther\nshell. We have also mapped for the first time the 29SiO v=0 J=1-0 emission in R\nLeo. The already reported discrepancy between the observed distributions of the\ndifferent maser lines and the theoretical predictions is also found in R Leo.\n", "machine_text": "This study investigates the circumstellar SiO maser emissions within the envelope of the oxygen-rich evolved star R Leo. Through Very Long Baseline Interferometry, 43GHz (28SiO v=1, 2 J=1-0, and 29SiO v=0 J=1-0) and 86GHz (28SiO v=1 J=2-1, and 29SiO v=0 J=2-1) maser lines were investigated with milliarcsecond resolution. Results confirmed previously held conclusions on oxygen-rich envelopes, that the 28SiO v=2 transition is produced in an inner layer, closer to the star and the 86GHz line arises in a farther shell. Furthermore, for the first time, the 29SiO v=0 J=1-0 emission was mapped in R Leo. A discrepancy between observed distributions of different maser lines and the theoretical predictions was observed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0682}
{"prompt": "Rephrase the abstract of an article with title 'Pseudogap and charge density waves in two dimensions'.\n  An interaction between electrons and lattice vibrations (phonons) results in\ntwo fundamental quantum phenomena in solids: in three dimensions it can turn a\nmetal into a superconductor whereas in one dimension it can turn a metal into\nan insulator. In two dimensions (2D) both superconductivity and charge-density\nwaves (CDW) are believed to be anomalous. In superconducting cuprates, critical\ntransition temperatures are unusually high and the energy gap may stay unclosed\neven above these temperatures (pseudogap). In CDW-bearing dichalcogenides the\nresistivity below the transition can decrease with temperature even faster than\nin the normal phase and a basic prerequisite for the CDW, the favourable\nnesting conditions (when some sections of the Fermi surface appear shifted by\nthe same vector), seems to be absent. Notwithstanding the existence of\nalternatives to conventional theories, both phenomena in 2D still remain the\nmost fascinating puzzles in condensed matter physics. Using the latest\ndevelopments in high-resolution angle-resolved photoemission spectroscopy\n(ARPES) here we show that the normal-state pseudogap also exists in one of the\nmost studied 2D examples, dichalcogenide 2H-TaSe2, and the formation of CDW is\ndriven by a conventional nesting instability, which is masked by the pseudogap.\nOur findings reconcile and explain a number of unusual, as previously believed,\nexperimental responses as well as disprove many alternative theoretical\napproaches. The magnitude, character and anisotropy of the 2D-CDW pseudogap are\nintriguingly similar to those seen in superconducting cuprates.\n\n", "human_text": "  An interaction between electrons and lattice vibrations (phonons) results in\ntwo fundamental quantum phenomena in solids: in three dimensions it can turn a\nmetal into a superconductor whereas in one dimension it can turn a metal into\nan insulator. In two dimensions (2D) both superconductivity and charge-density\nwaves (CDW) are believed to be anomalous. In superconducting cuprates, critical\ntransition temperatures are unusually high and the energy gap may stay unclosed\neven above these temperatures (pseudogap). In CDW-bearing dichalcogenides the\nresistivity below the transition can decrease with temperature even faster than\nin the normal phase and a basic prerequisite for the CDW, the favourable\nnesting conditions (when some sections of the Fermi surface appear shifted by\nthe same vector), seems to be absent. Notwithstanding the existence of\nalternatives to conventional theories, both phenomena in 2D still remain the\nmost fascinating puzzles in condensed matter physics. Using the latest\ndevelopments in high-resolution angle-resolved photoemission spectroscopy\n(ARPES) here we show that the normal-state pseudogap also exists in one of the\nmost studied 2D examples, dichalcogenide 2H-TaSe2, and the formation of CDW is\ndriven by a conventional nesting instability, which is masked by the pseudogap.\nOur findings reconcile and explain a number of unusual, as previously believed,\nexperimental responses as well as disprove many alternative theoretical\napproaches. The magnitude, character and anisotropy of the 2D-CDW pseudogap are\nintriguingly similar to those seen in superconducting cuprates.\n", "machine_text": "\nIn this article, we discuss two fundamental quantum phenomena that arise from\ninteractions between electrons and lattice vibrations: in three-dimensional systems, a metal can turn into a superconductor and in one-dimensional systems, it can turn an insulator. In two dimensions, the mechanisms that cause these phenomena, leading to charge-density waves (CDWs) and superconductivity, respectively, are less understood than those in higher dimensionalities. We discuss the finding that an anomalous pseudogap \u2013 an energy gap that remains unclosed even above the transition temperature \u2013 exists in a particularly studied two-dimensional compound, dichalcogenide 2H-TaSe2, and that the formation of CDW is driven by a conventional nesting instability, one that is traditionally masked by the pseudogap. These findings shed light onto a number of unusual experimental responses, as well as disproving many alternative theoretical propositions. Furthermore, the magnitude, character and anisotropy of the 2D-CDW pseudogap are strikingly similar to those seen in superconducting cuprates. We use high-resolution angle-resolved photoemission spectroscopy (ARPES) to investigate these two phenomena in 2D systems, as two of the most baffling puzzles in condensed matter physics remain.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1544}
{"prompt": "Rephrase the abstract of an article with title 'Detecting and Characterizing Planetary Systems with Transit Timing'.\n  In the coming decades, research in extrasolar planets aims to advance two\ngoals: 1) detecting and characterizing low-mass planets increasingly similar to\nthe Earth, and 2) improving our understanding of planet formation. We present a\nnew planet detection method that is capable of making large advances towards\nboth of these objectives and describe a modest network of telescopes that is\nable to make the requisite observations. In a system where a known planet\ntransits its host star, a second planet in that system will cause the time\nbetween transits to vary. These transit timing variations can be used to infer\nthe orbital elements and mass of the perturbing planet even if it has a mass\nthat is smaller than the mass of the Earth. This detection technique\ncomplements other techniques because it is most sensitive in mean-motion\nresonances where, due to degeneracies, other techniques have reduced\nsensitivity. Small ground-based observatories have already exceeded the\nphotometric precision necessary to detect sub-Earth mass planets. However, TTV\nplanet searches are currently limited by the relatively small number of\nhigh-precision transit data and insufficient observing time on existing\ntelescopes. These issues will be compounded as the number of known transiting\nplanets suitable for TTV study will increase substantially in the near future.\nA relatively modest investment in a ground-based network of small ($\\sim 0.5\n{\\rm m}$ telescopes could provide the needed coverage and so dramatically\nincrease the effectiveness of transit timing observations.\n\n", "human_text": "  In the coming decades, research in extrasolar planets aims to advance two\ngoals: 1) detecting and characterizing low-mass planets increasingly similar to\nthe Earth, and 2) improving our understanding of planet formation. We present a\nnew planet detection method that is capable of making large advances towards\nboth of these objectives and describe a modest network of telescopes that is\nable to make the requisite observations. In a system where a known planet\ntransits its host star, a second planet in that system will cause the time\nbetween transits to vary. These transit timing variations can be used to infer\nthe orbital elements and mass of the perturbing planet even if it has a mass\nthat is smaller than the mass of the Earth. This detection technique\ncomplements other techniques because it is most sensitive in mean-motion\nresonances where, due to degeneracies, other techniques have reduced\nsensitivity. Small ground-based observatories have already exceeded the\nphotometric precision necessary to detect sub-Earth mass planets. However, TTV\nplanet searches are currently limited by the relatively small number of\nhigh-precision transit data and insufficient observing time on existing\ntelescopes. These issues will be compounded as the number of known transiting\nplanets suitable for TTV study will increase substantially in the near future.\nA relatively modest investment in a ground-based network of small ($\\sim 0.5\n{\\rm m}$ telescopes could provide the needed coverage and so dramatically\nincrease the effectiveness of transit timing observations.\n", "machine_text": "\nThis article presents a method for detecting and characterizing low-mass planetary systems by measuring the transit timing variations (TTVs) between planets. We explore the possibility of using a modest network of telescopes to observe TTVs and identify planets, which can complement other methods of planet detection. We discuss how this technique is especially sensitive to mean-motion resonances, where other detection techniques are not. Furthermore, detectors of sub-Earth mass planets already exist, though current detection mechanisms are limited by the lack of high-precision transit data and a insufficient allocation of observing time. We suggest that a network of telescopes, each 0.5m in size, could be used to increase the efficiency of TTV detection, which could greatly expedite the discoveries of low-mass planetary systems in the future.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0632}
{"prompt": "Rephrase the abstract of an article with title 'A map of the day-night contrast of the extrasolar planet HD 189733b'.\n  \"Hot Jupiter\" extrasolar planets are expected to be tidally locked because\nthey are close (<0.05 astronomical units, where 1 AU is the average Sun-Earth\ndistance) to their parent stars, resulting in permanent daysides and\nnightsides. By observing systems where the planet and star periodically eclipse\neach other, several groups have been able to estimate the temperatures of the\ndaysides of these planets. A key question is whether the atmosphere is able to\ntransport the energy incident upon the dayside to the nightside, which will\ndetermine the temperature at different points on the planet's surface. Here we\nreport observations of HD 189733, the closest of these eclipsing planetary\nsystems, over half an orbital period, from which we can construct a 'map' of\nthe distribution of temperatures. We detected the increase in brightness as the\ndayside of the planet rotated into view. We estimate a minimum brightness\ntemperature of 973 +/- 33 K and a maximum brightness temperature of 1212 +/- 11\nK at a wavelength of 8 microns, indicating that energy from the irradiated\ndayside is efficiently redistributed throughout the atmosphere, in contrast to\na recent claim for another hot Jupiter. Our data indicate that the peak\nhemisphere-integrated brightness occurs 16$\\pm$6 degrees before opposition,\ncorresponding to a hot spot shifted east of the substellar point. The secondary\neclipse (when the planet moves behind the star) occurs 120 +/- 24 s later than\npredicted, which may indicate a slightly eccentric orbit.\n\n", "human_text": "  \"Hot Jupiter\" extrasolar planets are expected to be tidally locked because\nthey are close (<0.05 astronomical units, where 1 AU is the average Sun-Earth\ndistance) to their parent stars, resulting in permanent daysides and\nnightsides. By observing systems where the planet and star periodically eclipse\neach other, several groups have been able to estimate the temperatures of the\ndaysides of these planets. A key question is whether the atmosphere is able to\ntransport the energy incident upon the dayside to the nightside, which will\ndetermine the temperature at different points on the planet's surface. Here we\nreport observations of HD 189733, the closest of these eclipsing planetary\nsystems, over half an orbital period, from which we can construct a 'map' of\nthe distribution of temperatures. We detected the increase in brightness as the\ndayside of the planet rotated into view. We estimate a minimum brightness\ntemperature of 973 +/- 33 K and a maximum brightness temperature of 1212 +/- 11\nK at a wavelength of 8 microns, indicating that energy from the irradiated\ndayside is efficiently redistributed throughout the atmosphere, in contrast to\na recent claim for another hot Jupiter. Our data indicate that the peak\nhemisphere-integrated brightness occurs 16$\\pm$6 degrees before opposition,\ncorresponding to a hot spot shifted east of the substellar point. The secondary\neclipse (when the planet moves behind the star) occurs 120 +/- 24 s later than\npredicted, which may indicate a slightly eccentric orbit.\n", "machine_text": "\nBy observing HD 189733b, the closest known \"Hot Jupiter\" extrasolar planet, we were able to map the day-night temperature contrast across its atmosphere. We found that the minimum brightness temperature was 973 +/- 33 K and the maximum brightness temperature was 1212 +/- 11 K, indicating that energy from the irradiated dayside is efficiently redistributed throughout the planet's atmosphere. Our data suggest that the hot spot is located 16 +/- 6 degrees east of the substellar point, and the secondary eclipse (when the planet moves behind the star) occurred 120 +/- 24 s later than predicted, which may be because of a slightly eccentric orbit.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0993}
{"prompt": "Rephrase the abstract of an article with title 'Settling the Complexity of Computing Two-Player Nash Equilibria'.\n  We settle a long-standing open question in algorithmic game theory. We prove\nthat Bimatrix, the problem of finding a Nash equilibrium in a two-player game,\nis complete for the complexity class PPAD Polynomial Parity Argument, Directed\nversion) introduced by Papadimitriou in 1991.\n  This is the first of a series of results concerning the complexity of Nash\nequilibria. In particular, we prove the following theorems:\n  Bimatrix does not have a fully polynomial-time approximation scheme unless\nevery problem in PPAD is solvable in polynomial time. The smoothed complexity\nof the classic Lemke-Howson algorithm and, in fact, of any algorithm for\nBimatrix is not polynomial unless every problem in PPAD is solvable in\nrandomized polynomial time. Our results demonstrate that, even in the simplest\nform of non-cooperative games, equilibrium computation and approximation are\npolynomial-time equivalent to fixed point computation. Our results also have\ntwo broad complexity implications in mathematical economics and operations\nresearch: Arrow-Debreu market equilibria are PPAD-hard to compute. The P-Matrix\nLinear Complementary Problem is computationally harder than convex programming\nunless every problem in PPAD is solvable in polynomial time.\n\n", "human_text": "  We settle a long-standing open question in algorithmic game theory. We prove\nthat Bimatrix, the problem of finding a Nash equilibrium in a two-player game,\nis complete for the complexity class PPAD Polynomial Parity Argument, Directed\nversion) introduced by Papadimitriou in 1991.\n  This is the first of a series of results concerning the complexity of Nash\nequilibria. In particular, we prove the following theorems:\n  Bimatrix does not have a fully polynomial-time approximation scheme unless\nevery problem in PPAD is solvable in polynomial time. The smoothed complexity\nof the classic Lemke-Howson algorithm and, in fact, of any algorithm for\nBimatrix is not polynomial unless every problem in PPAD is solvable in\nrandomized polynomial time. Our results demonstrate that, even in the simplest\nform of non-cooperative games, equilibrium computation and approximation are\npolynomial-time equivalent to fixed point computation. Our results also have\ntwo broad complexity implications in mathematical economics and operations\nresearch: Arrow-Debreu market equilibria are PPAD-hard to compute. The P-Matrix\nLinear Complementary Problem is computationally harder than convex programming\nunless every problem in PPAD is solvable in polynomial time.\n", "machine_text": "\nWe prove that the classic problem of computing a Nash equilibrium in a two-player game, called 'Bimatrix', is complete for the complexity class PPAD (Polynomial Parity Argument, Directed version). This breakthrough provides the first results concerning the complexity of computing Nash equilibria, and poses profound implications in mathematical economics and operations research. To illustrate, the Arrow-Debreu market equilibria is PPAD-hard to compute, while the P-Matrix Linear Complementary Problem becomes computationally harder than convex programming in PPAD. Additionally, our resolution also implies that Bimatrix has no fully polynomial-time approximation scheme and that the smoothed complexity of any algorithms for computing its Nash Equilibria is not polynomial. All of these culminates in showing that, even in the simplest form of non-cooperative games, equilibrium computation and approximation require levels of complexity equivalent to that of fixed-point computation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1678}
{"prompt": "Rephrase the abstract of an article with title 'Estimation of experimental data redundancy and related statistics'.\n  Redundancy of experimental data is the basic statistic from which the\ncomplexity of a natural phenomenon and the proper number of experiments needed\nfor its exploration can be estimated. The redundancy is expressed by the\nentropy of information pertaining to the probability density function of\nexperimental variables. Since the calculation of entropy is inconvenient due to\nintegration over a range of variables, an approximate expression for redundancy\nis derived that includes only a sum over the set of experimental data about\nthese variables. The approximation makes feasible an efficient estimation of\nthe redundancy of data along with the related experimental information and\ninformation cost function. From the experimental information the complexity of\nthe phenomenon can be simply estimated, while the proper number of experiments\nneeded for its exploration can be determined from the minimum of the cost\nfunction. The performance of the approximate estimation of these statistics is\ndemonstrated on two-dimensional normally distributed random data.\n\n", "human_text": "  Redundancy of experimental data is the basic statistic from which the\ncomplexity of a natural phenomenon and the proper number of experiments needed\nfor its exploration can be estimated. The redundancy is expressed by the\nentropy of information pertaining to the probability density function of\nexperimental variables. Since the calculation of entropy is inconvenient due to\nintegration over a range of variables, an approximate expression for redundancy\nis derived that includes only a sum over the set of experimental data about\nthese variables. The approximation makes feasible an efficient estimation of\nthe redundancy of data along with the related experimental information and\ninformation cost function. From the experimental information the complexity of\nthe phenomenon can be simply estimated, while the proper number of experiments\nneeded for its exploration can be determined from the minimum of the cost\nfunction. The performance of the approximate estimation of these statistics is\ndemonstrated on two-dimensional normally distributed random data.\n", "machine_text": "\nAn analysis of experimental data redundancy and related statistics is presented which provides a method to approximately calculate the entropy, a measure of the complexity of the natural phenomena being explored. The approximate expression of redundancy only involves a sum of the experimental data which makes it more efficient than conventional calculation of entropy. This approach allows for an estimation of the complexity of the phenomenon, as well as a determination of the optimal number of experiments needed for full exploration. The efficacy of the approach is demonstrated on normally distributed two-dimensional random data.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0162}
{"prompt": "Rephrase the abstract of an article with title 'VLBI observations of nineteen GHz-Peaked-Spectrum radio sources at 1.6\n  GHz'.\n  Aims and Methods: We present the results of VLBI observations of nineteen\nGHz-Peaked-Spectrum (GPS) radio sources at 1.6 GHz. Of them, 15 sources are\nselected from the Parkes Half Jansky (PHJ) sample (Snellen 2002), 4 others are\nfrom our previous observation list. We aimed at imaging the structure of GPS\nsources, searching for Compact Symmetric Objects (CSOs) and studying the\nabsorption for the convex radio spectra of GPS sources.\n  Results: We obtained total intensity 1.6 GHz VLBI images of 17 sources for\nthe first time. Of them, 80% show mini-double-lobe radio structure, indicating\nthat they are CSOs or candidates, and their host AGNs could be edge-on to us.\nThis result suggests that there is a high incidence of mini double-lobe sources\n(or CSOs) in the PHJ sample. The sources J0323+0534, J1135-0021, J1352+0232,\nJ2058+0540, J2123-0112 and J2325-0344 with measured redshift, showing\ndouble-lobe structure with sizes of <1 kpc, are classified as CSOs. Three\nsources J1057+0012, J1600-0037 and J1753+2750 are considered as core-jet\nsources according to their morphologies and flux variability.\n\n", "human_text": "  Aims and Methods: We present the results of VLBI observations of nineteen\nGHz-Peaked-Spectrum (GPS) radio sources at 1.6 GHz. Of them, 15 sources are\nselected from the Parkes Half Jansky (PHJ) sample (Snellen 2002), 4 others are\nfrom our previous observation list. We aimed at imaging the structure of GPS\nsources, searching for Compact Symmetric Objects (CSOs) and studying the\nabsorption for the convex radio spectra of GPS sources.\n  Results: We obtained total intensity 1.6 GHz VLBI images of 17 sources for\nthe first time. Of them, 80% show mini-double-lobe radio structure, indicating\nthat they are CSOs or candidates, and their host AGNs could be edge-on to us.\nThis result suggests that there is a high incidence of mini double-lobe sources\n(or CSOs) in the PHJ sample. The sources J0323+0534, J1135-0021, J1352+0232,\nJ2058+0540, J2123-0112 and J2325-0344 with measured redshift, showing\ndouble-lobe structure with sizes of <1 kpc, are classified as CSOs. Three\nsources J1057+0012, J1600-0037 and J1753+2750 are considered as core-jet\nsources according to their morphologies and flux variability.\n", "machine_text": "\nWe conducted VLBI observations of 19 GPS radio sources to gain insights into the structures and components of the AGNs. 15 sources were from the Parkes Half Jansky sample, and 4 from an earlier observational list. At 1.6GHz, 17 sources were observed for the first time, with the majority showing a mini-double-lobe (CSO) structure, hinting that the host AGNs could be oriented towards us edgewise. 6 sources, identified with redshifts, revealed double-lobe structures with sizes of less than 1 kpc, classifying them as CSOs. 3 other sources were found to be core-jet sources based on their flux variability and morphologies. The study thus provides new evidence to suggest that there exists a high incidence of mini-double lobe radiosources in the PHJ sample.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.031}
{"prompt": "Rephrase the abstract of an article with title 'Massive stars and globular cluster formation'.\n  We first present chemodynamical simulations to investigate how stellar winds\nof massive stars influence early dynamical and chemical evolution of forming\nglobular clusters (GCs). In our numerical models, GCs form in\nturbulent,high-density giant molecular clouds (GMCs), which are embedded in a\nmassive dark matter halo at high redshifts. We show how high-density, compact\nstellar systems are formed from GMCs influenced both by physical processes\nassociated with star formation and by tidal fields of their host halos. We also\nshow that chemical pollution of GC-forming GMCs by stellar winds from massive\nstars can result in star-to-star abundance inhomogeneities among light elements\n(e.g., C, N, and O) of stars in GCs. The present model with a canonical initial\nmass function (IMF) also shows a C-N anticorrelation that stars with smaller\n[C/Fe] have larger [N/Fe] in a GC. Although these results imply that\n``self-pollution'' of GC-forming GMCs by stellar winds from massive stars can\ncause abundance inhomogeneities of GCs, the present models with different\nparameters and canonical IMFs can not show N-rich stars with [N/Fe] ~ 0.8\nobserved in some GCs (e.g., NGC 6752). We discuss this apparent failure in the\ncontext of massive star formation preceding low-mass one within GC-forming GMCs\n(``bimodal star formation scenario''). We also show that although almost all\nstars (~97%) show normal He abundances (Y) of ~0.24 some stars later formed in\nGMCs can have Y as high as ~0.3 in some models. The number fraction of He-rich\nstars with Y >0.26 is however found to be small (~10^-3) for most models.\n\n", "human_text": "  We first present chemodynamical simulations to investigate how stellar winds\nof massive stars influence early dynamical and chemical evolution of forming\nglobular clusters (GCs). In our numerical models, GCs form in\nturbulent,high-density giant molecular clouds (GMCs), which are embedded in a\nmassive dark matter halo at high redshifts. We show how high-density, compact\nstellar systems are formed from GMCs influenced both by physical processes\nassociated with star formation and by tidal fields of their host halos. We also\nshow that chemical pollution of GC-forming GMCs by stellar winds from massive\nstars can result in star-to-star abundance inhomogeneities among light elements\n(e.g., C, N, and O) of stars in GCs. The present model with a canonical initial\nmass function (IMF) also shows a C-N anticorrelation that stars with smaller\n[C/Fe] have larger [N/Fe] in a GC. Although these results imply that\n``self-pollution'' of GC-forming GMCs by stellar winds from massive stars can\ncause abundance inhomogeneities of GCs, the present models with different\nparameters and canonical IMFs can not show N-rich stars with [N/Fe] ~ 0.8\nobserved in some GCs (e.g., NGC 6752). We discuss this apparent failure in the\ncontext of massive star formation preceding low-mass one within GC-forming GMCs\n(``bimodal star formation scenario''). We also show that although almost all\nstars (~97%) show normal He abundances (Y) of ~0.24 some stars later formed in\nGMCs can have Y as high as ~0.3 in some models. The number fraction of He-rich\nstars with Y >0.26 is however found to be small (~10^-3) for most models.\n", "machine_text": "\n\nThis work utilizes chemodynamical simulations to explore the effect of massive star winds on the early growth of globular clusters (GCs). It is found that high-density, compact stellar systems emerge from GMCs that are influenced by the physical processes of star formation and by the tidal fields of their host halos. Stellar winds from massive stars that contaminate GC-forming GMCs are responsible for light elements, such as C, N, and O to exhibit star-to-star inhomogeneities in GCs. Our simulations that employed a standard initial mass function (IMF) present a C-N anticorrelation, where stars with smaller [C/Fe] have higher [N/Fe] ratios in the associated clusters. The discrepancy between the numerical models and core GC observations that indicate the presence of N-rich stars (e.g., NGC 6752) with [N/Fe] above 0.8 is pondered in light of the 'bimodal star formation scenario' that suggests that massive star formation occurred before lower-mass star formation in GC-forming GMCs. Additionally, our model includes stars of almost normal He abundances (Y ~ 0.24) with some star population approximating Y ~ 0.3 in certain cases; however, the corresponding number fraction of He-rich stars is identified to be small (\u223c10^-3).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.078}
{"prompt": "Rephrase the abstract of an article with title 'Non-Markovian Stochastic Liouville equation and its Markovian\n  representation. Extensions of the continuous time random walk approach'.\n  Some specific features and extensions of the continuous time random walk\n(CTRW) approach are analyzed in detail within the Markovian representation (MR)\nand CTRW-based non-Markovian stochastic Liouville equation (SLE). In the MR\nCTRW processes are represented by multidimensional Markovian ones. In this\nrepresentation the probability distribution function (PDF) W(t) of fluctuation\nrenewals is associated with that of reoccurrences in a certain jump state of\nsome Markovian controlling process. Within the MR the non-Markovian SLE, which\ndescribes the effect of CTRW-like noise on relaxation of dynamic and stochastic\nsystems, is generalized to take into account the influence of relaxing systems\non statistical properties of noise. The generalized non-Markovian SLE is\napplied to study two modifications of the CTRW approach. One of them considers\nthe cascaded CTRWs in which the controlling process is actually CTRW-like one\ncontrolled by another CTRW process, controlled in turn by the third one, etc.\nWithin the MR simple expression for the PDF W(t) of total controlling process\nis obtained in terms of Markovian variants of controlling PDFs in the cascade.\nThe expression is shown to be especially simple and instructive in the case of\nanomalous processes determined by long time tailed W(t). The cascaded CTRWs can\nmodel the effect of complexity of a system on relaxation kinetics (in glasses,\nfractals, branching media, ultrametric structures, etc.). Another\nCTRW-modification describes the kinetics of processes governed by fluctuating\nW(t). Within the MR the problem is analyzed in a general form without\nrestrictive assumptions on correlations of PDFs of consecutive renewals. The\nanalysis shows that W(t) can strongly affect the kinetics of the process.\nPossible manifestations of this effect are discussed.\n\n", "human_text": "  Some specific features and extensions of the continuous time random walk\n(CTRW) approach are analyzed in detail within the Markovian representation (MR)\nand CTRW-based non-Markovian stochastic Liouville equation (SLE). In the MR\nCTRW processes are represented by multidimensional Markovian ones. In this\nrepresentation the probability distribution function (PDF) W(t) of fluctuation\nrenewals is associated with that of reoccurrences in a certain jump state of\nsome Markovian controlling process. Within the MR the non-Markovian SLE, which\ndescribes the effect of CTRW-like noise on relaxation of dynamic and stochastic\nsystems, is generalized to take into account the influence of relaxing systems\non statistical properties of noise. The generalized non-Markovian SLE is\napplied to study two modifications of the CTRW approach. One of them considers\nthe cascaded CTRWs in which the controlling process is actually CTRW-like one\ncontrolled by another CTRW process, controlled in turn by the third one, etc.\nWithin the MR simple expression for the PDF W(t) of total controlling process\nis obtained in terms of Markovian variants of controlling PDFs in the cascade.\nThe expression is shown to be especially simple and instructive in the case of\nanomalous processes determined by long time tailed W(t). The cascaded CTRWs can\nmodel the effect of complexity of a system on relaxation kinetics (in glasses,\nfractals, branching media, ultrametric structures, etc.). Another\nCTRW-modification describes the kinetics of processes governed by fluctuating\nW(t). Within the MR the problem is analyzed in a general form without\nrestrictive assumptions on correlations of PDFs of consecutive renewals. The\nanalysis shows that W(t) can strongly affect the kinetics of the process.\nPossible manifestations of this effect are discussed.\n", "machine_text": "\nThis article examines the use of the continuous time random walk (CTRW) approach and its extensions in the Markovian representation (MR) and the non-Markovian stochastic Liouville equation (SLE). This representation allows the probability distribution function (PDF) of fluctuation renewals to be linked with the reoccurrences of a certain jump state in the controlling process of a Markovian system. The article also explores the effect of CTRW-like noise on the relaxation of dynamic and stochastic systems, as well as modifications of the CTRW approach. These include the cascade of CTRWs and processes governed by fluctuating PDFs. It is shown that the W(t) of the controlling process can significantly affect the kinetics of the system, with the possible results of this effect being discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2358}
{"prompt": "Rephrase the abstract of an article with title 'The Evolution of Dark Matter Halo Properties in Clusters, Filaments,\n  Sheets and Voids'.\n  We use a series of N-body simulations of the LCDM cosmology to investigate\nthe redshift evolution since z=1 of the properties and alignment with the\nlarge-scale structure of haloes in clusters, filaments, sheets and voids. We\nfind that: (i) Once a rescaling of the halo mass with M*, the mass scale\ncollapsing at redshift z, is performed, there is no further significant\nredshift dependence in the halo properties; (ii) The environment influences\nhalo shape and formation time at all investigated redshifts for haloes with\nmasses M<M*; and (iii) There is a significant alignment of both spin and shape\nof haloes with filaments and sheets. In detail, at all redshifts up to z=1: a)\nHaloes with M<M* tend to be more oblate when located in clusters than in the\nother environments; this trend is reversed at higher masses: above about M*,\nhalos in clusters are typically more prolate than similar massive haloes in\nsheets, filaments and voids. b) Haloes with M>M* in filaments spin more rapidly\nthan similar mass haloes in clusters; haloes in voids have the lowest median\nspin parameters; c) Haloes with M<M* tend to be younger in voids and older in\nclusters; d) In sheets, halo spin vectors tend to lie within the sheet plane\nindependent of mass; in filaments, instead, haloes with M<M* tend to spin\nparallel to the filament and haloes with M>M* perpendicular to it. For masses\nM>M*, the major axis of haloes in filaments and sheets is strongly aligned with\nthe filament or the sheet. Such halo-LSS alignments may be of importance in\nweak lensing analyses of cosmic shear. A question that is opened by our study\nis why, in the 0 < z < 1 redshift regime that we have investigated, the mass\nscale M* sets roughly the threshold below which the LSS-environment either\nbegins to affect, or reverses, the properties of dark matter haloes.\n\n", "human_text": "  We use a series of N-body simulations of the LCDM cosmology to investigate\nthe redshift evolution since z=1 of the properties and alignment with the\nlarge-scale structure of haloes in clusters, filaments, sheets and voids. We\nfind that: (i) Once a rescaling of the halo mass with M*, the mass scale\ncollapsing at redshift z, is performed, there is no further significant\nredshift dependence in the halo properties; (ii) The environment influences\nhalo shape and formation time at all investigated redshifts for haloes with\nmasses M<M*; and (iii) There is a significant alignment of both spin and shape\nof haloes with filaments and sheets. In detail, at all redshifts up to z=1: a)\nHaloes with M<M* tend to be more oblate when located in clusters than in the\nother environments; this trend is reversed at higher masses: above about M*,\nhalos in clusters are typically more prolate than similar massive haloes in\nsheets, filaments and voids. b) Haloes with M>M* in filaments spin more rapidly\nthan similar mass haloes in clusters; haloes in voids have the lowest median\nspin parameters; c) Haloes with M<M* tend to be younger in voids and older in\nclusters; d) In sheets, halo spin vectors tend to lie within the sheet plane\nindependent of mass; in filaments, instead, haloes with M<M* tend to spin\nparallel to the filament and haloes with M>M* perpendicular to it. For masses\nM>M*, the major axis of haloes in filaments and sheets is strongly aligned with\nthe filament or the sheet. Such halo-LSS alignments may be of importance in\nweak lensing analyses of cosmic shear. A question that is opened by our study\nis why, in the 0 < z < 1 redshift regime that we have investigated, the mass\nscale M* sets roughly the threshold below which the LSS-environment either\nbegins to affect, or reverses, the properties of dark matter haloes.\n", "machine_text": "\nBy using N-body simulations in the context of LCDM cosmology, this study explores the varying properties and alignment of dark matter haloes with the large-scale structure in clusters, filaments, sheets and voids since redshift z=1. Results indicate that after normalizing the halo mass with M*, the mass scale collapsing at z, there is no further noticeable evolution. Additionally, a dependence on environment is manifest for haloes with masses below M* at all redshifts. The most evident observation is a substantial alignment of halo spin and shape with the filaments and sheets. In particular, haloes in clusters were identified as more oblate below M* while above the same scale they are usually more prolate. Furthermore, those in filaments have a higher spin rate in comparison with masses of similar size in clusters, voids contain the lowest spin parameters and halo formation times were discovered to be altered in correlated to their locations. Finally, the evidence from this work suggests that the threshold of M* likely marks the starting point of the LSS environment in influencing or even reversing the attributes of DM haloes over the measured redshift range of 0 < z < 1.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2595}
{"prompt": "Rephrase the abstract of an article with title 'Atmospheric Dynamics of Short-period Extra Solar Gas Giant Planets I:\n  Dependence of Night-Side Temperature on Opacity'.\n  More than two dozen short-period Jupiter-mass gas giant planets have been\ndiscovered around nearby solar-type stars in recent years, several of which\nundergo transits, making them ideal for the detection and characterization of\ntheir atmospheres. Here we adopt a three-dimensional radiative hydrodynamical\nnumerical scheme to simulate atmospheric circulation on close-in gas giant\nplanets. In contrast to the conventional GCM and shallow water algorithms, this\nmethod does not assume quasi hydrostatic equilibrium and it approximates\nradiation transfer from optically thin to thick regions with flux-limited\ndiffusion. In the first paper of this series, we consider\nsynchronously-spinning gas giants. We show that a full three-dimensional\ntreatment, coupled with rotationally modified flows and an accurate treatment\nof radiation, yields a clear temperature transition at the terminator. Based on\na series of numerical simulations with varying opacities, we show that the\nnight-side temperature is a strong indicator of the opacity of the planetary\natmosphere. Planetary atmospheres that maintain large, interstellar opacities\nwill exhibit large day-night temperature differences, while planets with\nreduced atmospheric opacities due to extensive grain growth and sedimentation\nwill exhibit much more uniform temperatures throughout their photosphere's. In\naddition to numerical results, we present a four-zone analytic approximation to\nexplain this dependence.\n\n", "human_text": "  More than two dozen short-period Jupiter-mass gas giant planets have been\ndiscovered around nearby solar-type stars in recent years, several of which\nundergo transits, making them ideal for the detection and characterization of\ntheir atmospheres. Here we adopt a three-dimensional radiative hydrodynamical\nnumerical scheme to simulate atmospheric circulation on close-in gas giant\nplanets. In contrast to the conventional GCM and shallow water algorithms, this\nmethod does not assume quasi hydrostatic equilibrium and it approximates\nradiation transfer from optically thin to thick regions with flux-limited\ndiffusion. In the first paper of this series, we consider\nsynchronously-spinning gas giants. We show that a full three-dimensional\ntreatment, coupled with rotationally modified flows and an accurate treatment\nof radiation, yields a clear temperature transition at the terminator. Based on\na series of numerical simulations with varying opacities, we show that the\nnight-side temperature is a strong indicator of the opacity of the planetary\natmosphere. Planetary atmospheres that maintain large, interstellar opacities\nwill exhibit large day-night temperature differences, while planets with\nreduced atmospheric opacities due to extensive grain growth and sedimentation\nwill exhibit much more uniform temperatures throughout their photosphere's. In\naddition to numerical results, we present a four-zone analytic approximation to\nexplain this dependence.\n", "machine_text": "\nIn this paper, we study the dependence of night-side temperature on opacity on short-period extra solar gas giant planets, through a three-dimensional radiative hydrodynamical numerical scheme that considers rotationally modified flows and accurately treats radiation transfer between optically thin and thick regions. Employing a suite of numerical simulations, we demonstrate that night-side temperature is a strong indicator of opacity; higher opacities cause greater day-night temperature differences, while opacities diminished by grain growth and sedimentation lead to more even temperatures across the planet's photosphere. Additionally, we propose a four-zone model to explain this observed relationship. This work marks the first in a series of studies that aim to characterize the atmospheric dynamics of extra solar gas giants.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3269}
{"prompt": "Rephrase the abstract of an article with title 'Determination of Low-Energy Parameters of Neutron--Proton Scattering on\n  the Basis of Modern Experimental Data from Partial-Wave Analyses'.\n  The triplet and singlet low-energy parameters in the effective-range\nexpansion for neutron--proton scattering are determined by using the latest\nexperimental data on respective phase shifts from the SAID nucleon--nucleon\ndatabase. The results differ markedly from the analogous parameters obtained on\nthe basis of the phase shifts of the Nijmegen group and contradict the\nparameter values that are presently used as experimental ones. The values found\nwith the aid of the phase shifts from the SAID nucleon--nucleon database for\nthe total cross section for the scattering of zero-energy neutrons by protons,\n$\\sigma_{0}=20.426 $b, and the neutron--proton coherent scattering length,\n$f=-3.755 $fm, agree perfectly with the experimental cross-section values\nobtained by Houk, $\\sigma_{0}=20.436\\pm 0.023 $b, and experimental\nscattering-length values obtained by Houk and Wilson, $f=-3.756\\pm 0.009 $fm,\nbut they contradict cross-section values of $\\sigma_{0}=20.491\\pm 0.014 $b\naccording to Dilg and coherent-scattering-length values of $f=-3.7409\\pm 0.0011\n$fm according to Koester and Nistler.\n\n", "human_text": "  The triplet and singlet low-energy parameters in the effective-range\nexpansion for neutron--proton scattering are determined by using the latest\nexperimental data on respective phase shifts from the SAID nucleon--nucleon\ndatabase. The results differ markedly from the analogous parameters obtained on\nthe basis of the phase shifts of the Nijmegen group and contradict the\nparameter values that are presently used as experimental ones. The values found\nwith the aid of the phase shifts from the SAID nucleon--nucleon database for\nthe total cross section for the scattering of zero-energy neutrons by protons,\n$\\sigma_{0}=20.426 $b, and the neutron--proton coherent scattering length,\n$f=-3.755 $fm, agree perfectly with the experimental cross-section values\nobtained by Houk, $\\sigma_{0}=20.436\\pm 0.023 $b, and experimental\nscattering-length values obtained by Houk and Wilson, $f=-3.756\\pm 0.009 $fm,\nbut they contradict cross-section values of $\\sigma_{0}=20.491\\pm 0.014 $b\naccording to Dilg and coherent-scattering-length values of $f=-3.7409\\pm 0.0011\n$fm according to Koester and Nistler.\n", "machine_text": "\nThis article is focused on the assessment and evaluation of low-energy parameters for neutron--proton scattering with the aid of precise and modern experimental data from partial-wave analyses. Notable differences arise between the obtained results and existing parameters that are currently used as experimental values. Comparing the resultant total cross section from scattering of zero-energy neutrons by protons, ($\\sigma_{0}=20.426 $b) and the neutron-proton coherent scattering length ($f=-3.755$ fm) with those obtained by Houk ($\\sigma_{0}=20.436\\pm 0.023 $b) and Houk and Wilson (f=-3.756\\pm 0.009 $fm), respectively, the results agree perfectly. Contrarily, they are inconsistent with those of Dilg ($\\sigma_{0}=20.491\\pm 0.014 $b) and Koester and Nistler (f=-3.7409\\pm 0.0011 $fm).", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1024}
{"prompt": "Rephrase the abstract of an article with title 'What Makes a System Complex? an Approach to Self-Organization and\n  Emergence'.\n  The fast changing reality in technical and natural domains perceived by\nalways more accurate observations has drawn attention on new and very broad\nclass of systems with specific behaviour represented under the common wording\ncomplexity. From elementary system graph representation with components as\nnodes and interactions as vertices, systems are shown to belong to only three\nstates : simple, complicated, and complex, the main properties of which are\ndiscussed. The first two states have been studied at length over past\ncenturies, and last one finds its origin in the elementary fact that when\nsystem performance is pushed up, there exists a threshold above which\ninteraction between components overtake outside interaction. Then system\nself-organizes and filters corresponding outer action, making it more robust to\nouter effect, with emergence of new behaviour not predictable from only\ncomponents study. Examples in Physics and Biology are given. Three main classes\nof complexity behaviour are distinguished corresponding to different grades of\ndifficulty to handle their dynamics. The interest of using complex state\nproperties in man-made systems is stressed. Important issues concentrating on\nthe difficult balance between relative system isolation when becoming complex\nand required delegation of corresponding new capability from (outside) operator\nare discussed. This implies giving the system some intelligence in an adequate\nframe between new augmented system state and supervising operator, with\nconsequences on canonical system triplet {effector-sensor-controller} to be\nreorganized in this new setting. Moreover, entering complexity state opens the\npossibility for function to feedback onto structure, ie to mimic at technical\nlevel the invention of Nature over Her very long history.\n\n", "human_text": "  The fast changing reality in technical and natural domains perceived by\nalways more accurate observations has drawn attention on new and very broad\nclass of systems with specific behaviour represented under the common wording\ncomplexity. From elementary system graph representation with components as\nnodes and interactions as vertices, systems are shown to belong to only three\nstates : simple, complicated, and complex, the main properties of which are\ndiscussed. The first two states have been studied at length over past\ncenturies, and last one finds its origin in the elementary fact that when\nsystem performance is pushed up, there exists a threshold above which\ninteraction between components overtake outside interaction. Then system\nself-organizes and filters corresponding outer action, making it more robust to\nouter effect, with emergence of new behaviour not predictable from only\ncomponents study. Examples in Physics and Biology are given. Three main classes\nof complexity behaviour are distinguished corresponding to different grades of\ndifficulty to handle their dynamics. The interest of using complex state\nproperties in man-made systems is stressed. Important issues concentrating on\nthe difficult balance between relative system isolation when becoming complex\nand required delegation of corresponding new capability from (outside) operator\nare discussed. This implies giving the system some intelligence in an adequate\nframe between new augmented system state and supervising operator, with\nconsequences on canonical system triplet {effector-sensor-controller} to be\nreorganized in this new setting. Moreover, entering complexity state opens the\npossibility for function to feedback onto structure, ie to mimic at technical\nlevel the invention of Nature over Her very long history.\n", "machine_text": "This paper provides an exploration into the notion of system complexity, examining three states of complexity - simple, complicated, and complex - as well as their associated properties. Examples of complex systems in Physics and Biology are discussed, as well as the potential applications of this phenomenon in man-made systems. Consideration is given to the difficult balance between relative system isolation and the required delegation of new capabilities from outside, leading to the reorganization of the classical system triplet {effector-sensor-controller}. It is emphasized that entering the complexity state opens the possibility of allowing function to feedback onto structure, to better replicate the biotic inventions of Nature.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.044}
{"prompt": "Rephrase the abstract of an article with title 'Beyond the semi-classical description of black hole evaporation'.\n  In the semi-classical treatment, i.e. in a classical black hole geometry,\nHawking quanta emerge from trans-Planckian configurations because of scale\ninvariance. There is indeed no scale to stop the blue-shifting effect\nencountered in the backward propagation towards the event horizon. On the\ncontrary, when taking into account the gravitational interactions neglected in\nthe semi-classical treatment, a UV scale stopping the blue-shift could be\ndynamically engendered. To show that this is the case, we use a\nnon-perturbative treatment based on the large-N limit, where $N$ is the number\nof matter fields. In this limit, the semi-classical treatment is the leading\ncontribution. Non-linear gravitational effects appear in the next orders and in\nthe first of these, the effects are governed by the two-point correlation\nfunction of the energy-momentum tensor evaluated in the vacuum. Taking this\ncorrelator into account, backward propagated modes are dissipated at a distance\nfrom the horizon $\\propto G\\kappa$ when measured in a freely falling frame.\n($G$ is Newton's constant and $\\kappa$ the surface gravity.) This result can be\nalso obtained by considering light propagation in a stochastic ensemble of\nmetrics whose fluctuations are determined by the above correlator.\n\n", "human_text": "  In the semi-classical treatment, i.e. in a classical black hole geometry,\nHawking quanta emerge from trans-Planckian configurations because of scale\ninvariance. There is indeed no scale to stop the blue-shifting effect\nencountered in the backward propagation towards the event horizon. On the\ncontrary, when taking into account the gravitational interactions neglected in\nthe semi-classical treatment, a UV scale stopping the blue-shift could be\ndynamically engendered. To show that this is the case, we use a\nnon-perturbative treatment based on the large-N limit, where $N$ is the number\nof matter fields. In this limit, the semi-classical treatment is the leading\ncontribution. Non-linear gravitational effects appear in the next orders and in\nthe first of these, the effects are governed by the two-point correlation\nfunction of the energy-momentum tensor evaluated in the vacuum. Taking this\ncorrelator into account, backward propagated modes are dissipated at a distance\nfrom the horizon $\\propto G\\kappa$ when measured in a freely falling frame.\n($G$ is Newton's constant and $\\kappa$ the surface gravity.) This result can be\nalso obtained by considering light propagation in a stochastic ensemble of\nmetrics whose fluctuations are determined by the above correlator.\n", "machine_text": "This article explores beyond the semi-classical description of black hole evaporation by considering the effects of gravitational interactions which were previously neglected. To examine these effects, a non-perturbative treatment based on the large-N limit is used, in which the effects of non-linear gravitational interactions appear in higher orders and are governed by the two-point correlation function of the energy-momentum tensor. It is found that the previously unavoidable blue-shifting is stopped at a distance from the horizon $\\propto G\\kappa$ when measured in a freely falling frame. This result is also obtained by considering light propagation in a stochastic ensemble of metrics whose fluctuations are determined by this correlation function.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2563}
{"prompt": "Rephrase the abstract of an article with title 'Probing polarization states of primordial gravitational waves with CMB\n  anisotropies'.\n  We discuss the polarization signature of primordial gravitational waves\nimprinted in cosmic microwave background (CMB) anisotropies. The high-energy\nphysics motivated by superstring theory or M-theory generically yield parity\nviolating terms, which may produce a circularly polarized gravitational wave\nbackground (GWB) during inflation. In contrast to the standard prediction of\ninflation with un-polarized GWB, circularly polarized GWB generates\nnon-vanishing TB and EB-mode power spectra of CMB anisotropies. We evaluate the\nTB and EB-mode power spectra taking into account the secondary effects and\ninvestigate the dependence of cosmological parameters. We then discuss current\nconstraints on the circularly polarized GWB from large angular scales (l < 16)\nof the three year WMAP data. Prospects for future CMB experiments are also\ninvestigated based on a Monte Carlo analysis of parameter estimation, showing\nthat the circular polarization degree, varepsilon, which is the asymmetry of\nthe tensor power spectra between right- and left-handed modes normalized by the\ntotal amplitude, can be measured down to |varepsilon| 0.35(r/0.05)^{-0.6}.\n\n", "human_text": "  We discuss the polarization signature of primordial gravitational waves\nimprinted in cosmic microwave background (CMB) anisotropies. The high-energy\nphysics motivated by superstring theory or M-theory generically yield parity\nviolating terms, which may produce a circularly polarized gravitational wave\nbackground (GWB) during inflation. In contrast to the standard prediction of\ninflation with un-polarized GWB, circularly polarized GWB generates\nnon-vanishing TB and EB-mode power spectra of CMB anisotropies. We evaluate the\nTB and EB-mode power spectra taking into account the secondary effects and\ninvestigate the dependence of cosmological parameters. We then discuss current\nconstraints on the circularly polarized GWB from large angular scales (l < 16)\nof the three year WMAP data. Prospects for future CMB experiments are also\ninvestigated based on a Monte Carlo analysis of parameter estimation, showing\nthat the circular polarization degree, varepsilon, which is the asymmetry of\nthe tensor power spectra between right- and left-handed modes normalized by the\ntotal amplitude, can be measured down to |varepsilon| 0.35(r/0.05)^{-0.6}.\n", "machine_text": "\nIn this article, we look into the polarization properties of primordial\ngravitational waves (GWB) embedded in cosmic microwave background (CMB) anisotropies. Unlike\nthe usual assumption that gravitation waves are unpolarized, theories of high-energy\nphysics, like those motivated by superstring and M-theory, predict that these waves\ncould contain a circularly-polarized component. Accordingly, this would have an effect\non the TB and EB-mode power spectra of CMB anisotropies. We evaluate these secondary\neffects and analyze the data collected from the three year WMAP mission to determine\nthe validity of this theory. To further expand on our understanding of this circularly\npolarized gravitation wave background, we look into how\nits degree of polarization, expressed by the asymmetry of the tensor power spectra \nnormalized by the total amplitude, can be measured by future CMB experiments down to\n|varepsilon| 0.35(r/0.05)^{-0.6}, when r stands for tensor-to-scalar ratio.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3701}
{"prompt": "Rephrase the abstract of an article with title 'Bayesian analysis of the low-resolution polarized 3-year WMAP sky maps'.\n  We apply a previously developed Gibbs sampling framework to the foreground\ncorrected 3-yr WMAP polarization data and compute the power spectrum and\nresidual foreground template amplitude posterior distributions. We first\nanalyze the co-added Q- and V-band data, and compare our results to the\nlikelihood code published by the WMAP team. We find good agreement, and thus\nverify the numerics and data processing steps of both approaches. However, we\nalso analyze the Q- and V-bands separately, allowing for non-zero EB\ncross-correlations and including two individual foreground template amplitudes\ntracing synchrotron and dust emission. In these analyses, we find tentative\nevidence of systematics: The foreground tracers correlate with each of the Q-\nand V-band sky maps individually, although not with the co-added QV map; there\nis a noticeable negative EB cross-correlation at l <~ 16 in the V-band map; and\nfinally, when relaxing the constraints on EB and BB, noticeable differences are\nobserved between the marginalized band powers in the Q- and V-bands. Further\nstudies of these features are imperative, given the importance of the low-l EE\nspectrum on the optical depth of reionization tau and the spectral index of\nscalar perturbations n_s.\n\n", "human_text": "  We apply a previously developed Gibbs sampling framework to the foreground\ncorrected 3-yr WMAP polarization data and compute the power spectrum and\nresidual foreground template amplitude posterior distributions. We first\nanalyze the co-added Q- and V-band data, and compare our results to the\nlikelihood code published by the WMAP team. We find good agreement, and thus\nverify the numerics and data processing steps of both approaches. However, we\nalso analyze the Q- and V-bands separately, allowing for non-zero EB\ncross-correlations and including two individual foreground template amplitudes\ntracing synchrotron and dust emission. In these analyses, we find tentative\nevidence of systematics: The foreground tracers correlate with each of the Q-\nand V-band sky maps individually, although not with the co-added QV map; there\nis a noticeable negative EB cross-correlation at l <~ 16 in the V-band map; and\nfinally, when relaxing the constraints on EB and BB, noticeable differences are\nobserved between the marginalized band powers in the Q- and V-bands. Further\nstudies of these features are imperative, given the importance of the low-l EE\nspectrum on the optical depth of reionization tau and the spectral index of\nscalar perturbations n_s.\n", "machine_text": "\nWe analyze the 3-year WMAP polarization data that has been corrected for foregrounds, using a Gibbs sampling method. The results of this analysis are compared to those found by the WMAP team and found to be aligned. However, further analysis is done to separate the Q- and V-bands, accounting for non-zero EB cross correlations and adding in the amplitudes of synchrotron and dust emission. Deviations are found in these, signifying systematics that should be taken into account. These are especially important due to the low-l EE spectrum influencing parameters such as tau and n_s.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3643}
{"prompt": "Rephrase the abstract of an article with title 'Jet-disturbed molecular gas near the Seyfert 2 nucleus in M51'.\n  Previous molecular gas observations at arcsecond-scale resolution of the\nSeyfert 2 galaxy M51 suggest the presence of a dense circumnuclear rotating\ndisk, which may be the reservoir for fueling the active nucleus and obscures it\nfrom direct view in the optical. However, our recent interferometric CO(3-2)\nobservations show a hint of a velocity gradient perpendicular to the rotating\ndisk, which suggests a more complex structure than previously thought. To image\nthe putative circumnuclear molecular gas disk at sub-arcsecond resolution to\nbetter understand both the spatial distribution and kinematics of the molecular\ngas. We carried out CO(2-1) and CO(1-0) line observations of the nuclear region\nof M51 with the new A configuration of the IRAM Plateau de Bure Interferometer,\nyielding a spatial resolution lower than 15 pc. The high resolution images show\nno clear evidence of a disk, aligned nearly east-west and perpendicular to the\nradio jet axis, as suggested by previous observations, but show two separate\nfeatures located on the eastern and western sides of the nucleus. The western\nfeature shows an elongated structure along the jet and a good velocity\ncorrespondence with optical emission lines associated with the jet, suggesting\nthat this feature is a jet-entrained gas. The eastern feature is elongated\nnearly east-west ending around the nucleus. A velocity gradient appears in the\nsame direction with increasingly blueshifted velocities near the nucleus. This\nvelocity gradient is in the opposite sense of that previously inferred for the\nputative circumnuclear disk. Possible explanations for the observed molecular\ngas distribution and kinematics are that a rotating gas disk disturbed by the\njet, gas streaming toward the nucleus, or a ring with another smaller counter-\nor Keplarian-rotating gas disk inside.\n\n", "human_text": "  Previous molecular gas observations at arcsecond-scale resolution of the\nSeyfert 2 galaxy M51 suggest the presence of a dense circumnuclear rotating\ndisk, which may be the reservoir for fueling the active nucleus and obscures it\nfrom direct view in the optical. However, our recent interferometric CO(3-2)\nobservations show a hint of a velocity gradient perpendicular to the rotating\ndisk, which suggests a more complex structure than previously thought. To image\nthe putative circumnuclear molecular gas disk at sub-arcsecond resolution to\nbetter understand both the spatial distribution and kinematics of the molecular\ngas. We carried out CO(2-1) and CO(1-0) line observations of the nuclear region\nof M51 with the new A configuration of the IRAM Plateau de Bure Interferometer,\nyielding a spatial resolution lower than 15 pc. The high resolution images show\nno clear evidence of a disk, aligned nearly east-west and perpendicular to the\nradio jet axis, as suggested by previous observations, but show two separate\nfeatures located on the eastern and western sides of the nucleus. The western\nfeature shows an elongated structure along the jet and a good velocity\ncorrespondence with optical emission lines associated with the jet, suggesting\nthat this feature is a jet-entrained gas. The eastern feature is elongated\nnearly east-west ending around the nucleus. A velocity gradient appears in the\nsame direction with increasingly blueshifted velocities near the nucleus. This\nvelocity gradient is in the opposite sense of that previously inferred for the\nputative circumnuclear disk. Possible explanations for the observed molecular\ngas distribution and kinematics are that a rotating gas disk disturbed by the\njet, gas streaming toward the nucleus, or a ring with another smaller counter-\nor Keplarian-rotating gas disk inside.\n", "machine_text": "\nIn our recent IRAM Plateau de Bure Interferometer observations of M51, the Seyfert 2 galaxy, we found two distinct molecular gas features on either side of the nucleus. These features are not associated with the previously believed rotating disk, but instead were found to exhibit velocity gradients, suggesting that the molecular gas near the active nucleus is being disturbed by a powerful jet. Our observations suggest that the molecular gas could be a result of either a rotating gas disk that the jet is interacting with, gas flowing into the nucleus, or a combination of the two. The high resolution images at sub-arcsecond scales provide insight into a more complex structure of the nuclear region of M51 that was not previously understood.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0947}
{"prompt": "Rephrase the abstract of an article with title 'The richest superclusters. I. Morphology'.\n  We study the morphology of the richest superclusters from the catalogues of\nsuperclusters of galaxies in the 2dF Galaxy Redshift Survey and compare the\nmorphology of real superclusters with model superclusters in the Millennium\nSimulation. We use Minkowski functionals and shapefinders to quantify the\nmorphology of superclusters: their sizes, shapes, and clumpiness. We generate\nempirical models of simple geometry to understand which morphologies correspond\nto the supercluster shapefinders. We show that rich superclusters have\nelongated, filamentary shapes with high-density clumps in their core regions.\nThe clumpiness of superclusters is determined using the fourth Minkowski\nfunctional $V_3$. In the $K_1$-$K_2$ shapefinder plane the morphology of\nsuperclusters is described by a curve which is characteristic to\nmulti-branching filaments. We also find that the differences between the fourth\nMinkowski functional $V_3$ for the bright and faint galaxies in observed\nsuperclusters are larger than in simulated superclusters.\n\n", "human_text": "  We study the morphology of the richest superclusters from the catalogues of\nsuperclusters of galaxies in the 2dF Galaxy Redshift Survey and compare the\nmorphology of real superclusters with model superclusters in the Millennium\nSimulation. We use Minkowski functionals and shapefinders to quantify the\nmorphology of superclusters: their sizes, shapes, and clumpiness. We generate\nempirical models of simple geometry to understand which morphologies correspond\nto the supercluster shapefinders. We show that rich superclusters have\nelongated, filamentary shapes with high-density clumps in their core regions.\nThe clumpiness of superclusters is determined using the fourth Minkowski\nfunctional $V_3$. In the $K_1$-$K_2$ shapefinder plane the morphology of\nsuperclusters is described by a curve which is characteristic to\nmulti-branching filaments. We also find that the differences between the fourth\nMinkowski functional $V_3$ for the bright and faint galaxies in observed\nsuperclusters are larger than in simulated superclusters.\n", "machine_text": "\nIn this study, we use Minkowski functionals and shapefinders to conduct a detailed analysis of the morphology of the richest superclusters from the 2dF Galaxy Redshift Survey and from the Millennium Simulation. We compare the observed and modeled superclusters to ascertain their sizes, shapes, and clumpiness. We find that rich superclusters are often elongated filaments with high-density clumps at their core. The fourth Minkowski functional $V_3$ is used to quantify the clumpiness of superclusters, with the morphology of superclusters described by a distinctive curve in the $K_1$-$K_2$ shapefinder plane. Moreover, our results indicate that the difference between the fourth Minkowski functional $V_3$ for faint and bright galaxies in observed superclusters is more pronounced than in the simulated superclusters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1122}
{"prompt": "Rephrase the abstract of an article with title 'The Origin of the Arches Stellar Cluster Mass Function'.\n  We investigate the time evolution of the mass distribution of pre-stellar\ncores (PSCs) and their transition to the initial stellar mass function (IMF) in\nthe central parts of a molecular cloud (MC) under the assumption that the\ncoalescence of cores is important. Our aim is to explain the observed shallow\nIMF in dense stellar clusters such as the Arches cluster. The initial\ndistributions of PSCs at various distances from the MC center are those of\ngravitationally unstable cores resulting from the gravo-turbulent fragmentation\nof the MC. As time evolves, there is a competition between the PSCs rates of\ncoalescence and collapse. Whenever the local rate of collapse is larger than\nthe rate of coalescence in a given mass bin, cores are collapsed into stars.\nWith appropriate parameters, we find that the coalescence-collapse model\nreproduces very well all the observed characteristics of the Arches stellar\ncluster IMF; Namely, the slopes at high and low mass ends and the peculiar bump\nobserved at ~5-6 M_sol. Our results suggest that today's IMF of the Arches\ncluster is very similar to the primordial one and is prior to the dynamical\neffects of mass segregation becoming important\n\n", "human_text": "  We investigate the time evolution of the mass distribution of pre-stellar\ncores (PSCs) and their transition to the initial stellar mass function (IMF) in\nthe central parts of a molecular cloud (MC) under the assumption that the\ncoalescence of cores is important. Our aim is to explain the observed shallow\nIMF in dense stellar clusters such as the Arches cluster. The initial\ndistributions of PSCs at various distances from the MC center are those of\ngravitationally unstable cores resulting from the gravo-turbulent fragmentation\nof the MC. As time evolves, there is a competition between the PSCs rates of\ncoalescence and collapse. Whenever the local rate of collapse is larger than\nthe rate of coalescence in a given mass bin, cores are collapsed into stars.\nWith appropriate parameters, we find that the coalescence-collapse model\nreproduces very well all the observed characteristics of the Arches stellar\ncluster IMF; Namely, the slopes at high and low mass ends and the peculiar bump\nobserved at ~5-6 M_sol. Our results suggest that today's IMF of the Arches\ncluster is very similar to the primordial one and is prior to the dynamical\neffects of mass segregation becoming important\n", "machine_text": "\nThis paper examines the origin of the Arches stellar cluster mass function, from the time evolution of pre-stellar cores in the center of a molecular cloud. We consider the coalescence of cores to be of importance in this process. For different distances from the cloud center, gravo-turbulent fragmention produces a number of gravitationally unstable cores. Evolutionary effects such as coalescence and collapse are examined regarding whether collapse rates for certain bins are higher than the rate of coalescence. The resulting model is able to accurately display the specific characteristics of the stellar cluster mass function, such as the slopes at high and low ends, and the bump at the ~5-6M_sol mark. Consequently, our research suggests that the current IMF of Arches is similar to its original, while the consequential effects of mass segregation remain absent.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.095}
{"prompt": "Rephrase the abstract of an article with title 'Superradiance and stimulated scattering in SNR 1987A'.\n  The rings observed around supernova remnant 1987A are emitted by a plasma\nmainly made of ionized and neutral hydrogen atoms. With a density of 10 power\n10 atoms per cubic metre, and at least a dimension of plasma of 0.01\nlight-year, the column density is 10 power 24 atoms per square metre, much more\nthan needed for an optically thick gas at Lyman frequencies (Case B). While, at\n10000 K, the bulky gas would absorb Lyman lines fully, at 50000K it emits\nsuperradiant lines. As superradiance de-excites the atoms strongly, nearly all\navailable energy is emitted in a few competing modes: Superradiance appears\nonly for beams which cross the largest column densities; for an observation\nfrom Earth, these beams generate three elliptical hollow cylinders whose bases\nare the observed rings; admitting that the Earth is not in a privileged\ndirection, these cylinders envelope ellipsoidal shells observed, for the\nexternal rings, by photon echoes. For the equatorial ring, the brightness of\nthe superradiant beams is multiplied by a quasi-resonant induced scattering of\nthe rays emitted by the star. The de-excitation of atoms by emitted beams cools\nthe gas strongly, so that ionization decreases fast, the process self\naccelerates. The energy of the high radiance rays from the star is strongly\nscattered to the ring while the low radiance of the glow which surrounds the\nstar is rather amplified. The fast absorption of the radial beams produces the\nradial decrease of radiance of the ring while a competition of modes produces\nthe pearls.\n\n", "human_text": "  The rings observed around supernova remnant 1987A are emitted by a plasma\nmainly made of ionized and neutral hydrogen atoms. With a density of 10 power\n10 atoms per cubic metre, and at least a dimension of plasma of 0.01\nlight-year, the column density is 10 power 24 atoms per square metre, much more\nthan needed for an optically thick gas at Lyman frequencies (Case B). While, at\n10000 K, the bulky gas would absorb Lyman lines fully, at 50000K it emits\nsuperradiant lines. As superradiance de-excites the atoms strongly, nearly all\navailable energy is emitted in a few competing modes: Superradiance appears\nonly for beams which cross the largest column densities; for an observation\nfrom Earth, these beams generate three elliptical hollow cylinders whose bases\nare the observed rings; admitting that the Earth is not in a privileged\ndirection, these cylinders envelope ellipsoidal shells observed, for the\nexternal rings, by photon echoes. For the equatorial ring, the brightness of\nthe superradiant beams is multiplied by a quasi-resonant induced scattering of\nthe rays emitted by the star. The de-excitation of atoms by emitted beams cools\nthe gas strongly, so that ionization decreases fast, the process self\naccelerates. The energy of the high radiance rays from the star is strongly\nscattered to the ring while the low radiance of the glow which surrounds the\nstar is rather amplified. The fast absorption of the radial beams produces the\nradial decrease of radiance of the ring while a competition of modes produces\nthe pearls.\n", "machine_text": "\nThe analysis of supernova remnant 1987A has revealed that the rings around it are emitted by a plasma mainly composed of ionized and neutral hydrogen atoms with a density of 10^10 atoms per cubic metre and, at least, a dimension of plasma of 0.01 light-years. This high column density is greater than what is needed for an optically thick gas at Lyman frequencies (Case B). When heated to a temperature of 50,000 K, the gas begins to emit superradiant lines. This de-excitation process results in almost all of the available energy being emitted in a handful of competing modes. This can only be seen when the beams cross the highest column densities, and when viewed from Earth, three elliptical hollow cylinders appear, which form the visible rings. The brightness of the superradiant beams is also amplified by a quasi-resonant induced scattering of the rays emitted by the star in the equatorial ring. Because of this de-excitation process, the gas is quickly cooled and ionization decreases rapidly, resulting in the radial decrease of radiance of the ring and the formation of pearls when competing modes occur.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.039}
{"prompt": "Rephrase the abstract of an article with title 'Power Allocation for Discrete-Input Delay-Limited Fading Channels'.\n  We consider power allocation algorithms for fixed-rate transmission over\nNakagami-m non-ergodic block-fading channels with perfect transmitter and\nreceiver channel state information and discrete input signal constellations,\nunder both short- and long-term power constraints. Optimal power allocation\nschemes are shown to be direct applications of previous results in the\nliterature. We show that the SNR exponent of the optimal short-term scheme is\ngiven by m times the Singleton bound. We also illustrate the significant gains\navailable by employing long-term power constraints. In particular, we analyze\nthe optimal long-term solution, showing that zero outage can be achieved\nprovided that the corresponding short-term SNR exponent with the same system\nparameters is strictly greater than one. Conversely, if the short-term SNR\nexponent is smaller than one, we show that zero outage cannot be achieved. In\nthis case, we derive the corresponding long-term SNR exponent as a function of\nthe Singleton bound. Due to the nature of the expressions involved, the\ncomplexity of optimal schemes may be prohibitive for system implementation. We\ntherefore propose simple sub-optimal power allocation schemes whose outage\nprobability performance is very close to the minimum outage probability\nobtained by optimal schemes. We also show the applicability of these techniques\nto practical systems employing orthogonal frequency division multiplexing.\n\n", "human_text": "  We consider power allocation algorithms for fixed-rate transmission over\nNakagami-m non-ergodic block-fading channels with perfect transmitter and\nreceiver channel state information and discrete input signal constellations,\nunder both short- and long-term power constraints. Optimal power allocation\nschemes are shown to be direct applications of previous results in the\nliterature. We show that the SNR exponent of the optimal short-term scheme is\ngiven by m times the Singleton bound. We also illustrate the significant gains\navailable by employing long-term power constraints. In particular, we analyze\nthe optimal long-term solution, showing that zero outage can be achieved\nprovided that the corresponding short-term SNR exponent with the same system\nparameters is strictly greater than one. Conversely, if the short-term SNR\nexponent is smaller than one, we show that zero outage cannot be achieved. In\nthis case, we derive the corresponding long-term SNR exponent as a function of\nthe Singleton bound. Due to the nature of the expressions involved, the\ncomplexity of optimal schemes may be prohibitive for system implementation. We\ntherefore propose simple sub-optimal power allocation schemes whose outage\nprobability performance is very close to the minimum outage probability\nobtained by optimal schemes. We also show the applicability of these techniques\nto practical systems employing orthogonal frequency division multiplexing.\n", "machine_text": "\nIn this article, we analyze power allocation algorithms for fixed-rate transmission over Nakagami-m non-ergodic block-fading channels with perfect transmitter and receiver channel state information and discrete input signal constellations. We determine the optimal short-term scheme with an SNR exponent of m times the Singleton bound and present significant gains available from long-term power constraints, including the capability to achieve zero outage when an SNR exponent greater than one is achieved by the corresponding short-term method. In cases where the SNR exponent is lesser than one, we compute the corresponding long-term SNR exponent and show that, unfortunately, zero outage cannot be accomplished. We further discuss simple, sub-optimal power allocation schemes that are viable with regards to complexity in the case of system implementation and indicate the effectiveness of these techniques with the use of orthogonal frequency division multiplexing.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2033}
{"prompt": "Rephrase the abstract of an article with title 'Quasars Lensed by Globular Clusters of Spiral and Elliptical Galaxies'.\n  Based on the SDSS catalog, we have found new close quasar-galaxy pairs.\nQuasars projected onto the halos of nearer galaxies are encountered among the\nmultitude of quasars observed at various distances from us. Among them there\nare quasars that are close to the galaxies not only in angular separation, but\nalso in redshift. Such quasar-galaxy pairs are called close pairs. We developed\nfurther the hypothesis that such pairs appear, because the fluxer on the\nnucleus of the more distant galaxy passes through halo globular clusters of the\nnearer galaxy,resulting in magnification and splitting of the image of the\nsource that we interpret as a quasar. To corroborate this hypothesis, we\nanalyzed the distribution of quasars in the plane of the halos of these\ngalaxies. The quasars from close pairs were found to follow the density profile\nof globular clusters in the halos of elliptical and spiral galaxies with slopes\nof -1.5 and -2.4 for elliptical and spiral galaxies, respectively. This\nsuggests that quasars do not appear near galaxies by chance and that quasars\nare associated with galaxies via halo globular clusters.\n\n", "human_text": "  Based on the SDSS catalog, we have found new close quasar-galaxy pairs.\nQuasars projected onto the halos of nearer galaxies are encountered among the\nmultitude of quasars observed at various distances from us. Among them there\nare quasars that are close to the galaxies not only in angular separation, but\nalso in redshift. Such quasar-galaxy pairs are called close pairs. We developed\nfurther the hypothesis that such pairs appear, because the fluxer on the\nnucleus of the more distant galaxy passes through halo globular clusters of the\nnearer galaxy,resulting in magnification and splitting of the image of the\nsource that we interpret as a quasar. To corroborate this hypothesis, we\nanalyzed the distribution of quasars in the plane of the halos of these\ngalaxies. The quasars from close pairs were found to follow the density profile\nof globular clusters in the halos of elliptical and spiral galaxies with slopes\nof -1.5 and -2.4 for elliptical and spiral galaxies, respectively. This\nsuggests that quasars do not appear near galaxies by chance and that quasars\nare associated with galaxies via halo globular clusters.\n", "machine_text": "\nWe have studied the distribution of quasars in close proximity to galaxies from the Sloan Digital Sky Survey data. Our analysis supports the hypothesis that these types of quasars, known as 'close pairs', are gravitationally lensed by globular clusters in the halos of elliptical and spiral galaxies. We find that quasars which form close pairs tend to follow the rich density profiles of globular clusters in these types of galaxies, with slopes of -1.5 and -2.4 respectively. This implies a mutual relationship between quasars and galaxies, in which the lensing effects of globular clusters are likely key to their proximity.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0446}
{"prompt": "Rephrase the abstract of an article with title 'A Model of Late Long-Term Potentiation Simulates Aspects of Memory\n  Maintenance'.\n  Late long-term potentiation (L-LTP) appears essential for the formation of\nlong-term memory, with memories at least partly encoded by patterns of\nstrengthened synapses. How memories are preserved for months or years, despite\nmolecular turnover, is not well understood. Ongoing recurrent neuronal\nactivity, during memory recall or during sleep, has been hypothesized to\npreferentially potentiate strong synapses, preserving memories. This hypothesis\nhas not been evaluated in the context of a mathematical model representing\nbiochemical pathways important for L-LTP. I incorporated ongoing activity into\ntwo such models: a reduced model that represents some of the essential\nbiochemical processes, and a more detailed published model. The reduced model\nrepresents synaptic tagging and gene induction intuitively, and the detailed\nmodel adds activation of essential kinases by Ca. Ongoing activity was modeled\nas continual brief elevations of [Ca]. In each model, two stable states of\nsynaptic weight resulted. Positive feedback between synaptic weight and the\namplitude of ongoing Ca transients underlies this bistability. A tetanic or\ntheta-burst stimulus switches a model synapse from a low weight to a high\nweight stabilized by ongoing activity. Bistability was robust to parameter\nvariations. Simulations illustrated that prolonged decreased activity reset\nsynapses to low weights, suggesting a plausible forgetting mechanism. However,\nepisodic activity with shorter inactive intervals maintained strong synapses.\nBoth models support experimental predictions. Tests of these predictions are\nexpected to further understanding of how neuronal activity is coupled to\nmaintenance of synaptic strength.\n\n", "human_text": "  Late long-term potentiation (L-LTP) appears essential for the formation of\nlong-term memory, with memories at least partly encoded by patterns of\nstrengthened synapses. How memories are preserved for months or years, despite\nmolecular turnover, is not well understood. Ongoing recurrent neuronal\nactivity, during memory recall or during sleep, has been hypothesized to\npreferentially potentiate strong synapses, preserving memories. This hypothesis\nhas not been evaluated in the context of a mathematical model representing\nbiochemical pathways important for L-LTP. I incorporated ongoing activity into\ntwo such models: a reduced model that represents some of the essential\nbiochemical processes, and a more detailed published model. The reduced model\nrepresents synaptic tagging and gene induction intuitively, and the detailed\nmodel adds activation of essential kinases by Ca. Ongoing activity was modeled\nas continual brief elevations of [Ca]. In each model, two stable states of\nsynaptic weight resulted. Positive feedback between synaptic weight and the\namplitude of ongoing Ca transients underlies this bistability. A tetanic or\ntheta-burst stimulus switches a model synapse from a low weight to a high\nweight stabilized by ongoing activity. Bistability was robust to parameter\nvariations. Simulations illustrated that prolonged decreased activity reset\nsynapses to low weights, suggesting a plausible forgetting mechanism. However,\nepisodic activity with shorter inactive intervals maintained strong synapses.\nBoth models support experimental predictions. Tests of these predictions are\nexpected to further understanding of how neuronal activity is coupled to\nmaintenance of synaptic strength.\n", "machine_text": "This article discusses a mathematical model of biochemical pathways integral to late long-term potentiation (L-LTP) which helps explain memory formation and maintenance. It investigates how recurrent neuronal activity, experienced during memory recall or sleeping, can preferentially strengthen synapses and preserve memories for months or years. Two models are discussed, representing synaptic tagging, gene induction, and kinase activation by calcium that is modeled as continual brief elevations in concentration. The results demonstrate a positive feedback between synaptic weight and activity amplitudes, promoting two stable states of synaptic weight. A tetanic or theta-burst stimulus can switch a model synapse from a low weight to a high weight which is maintained by ongoing activity. Furthermore, decreased activity can reset synapses to the low weight state. Thus, this model offers a plausible explanation of forgetting and provides predictive tests of the coupling of neuronal activity to synaptic strength.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3724}
{"prompt": "Rephrase the abstract of an article with title 'Scale-dependent Galaxy Bias'.\n  We present a simple heuristic model to demonstrate how feedback related to\nthe galaxy formation process can result in a scale-dependent bias of mass\nversus light, even on very large scales. The model invokes the idea that\ngalaxies form initially in locations determined by the local density field, but\nthe subsequent formation of galaxies is also influenced by the presence of\nnearby galaxies that have already formed. The form of bias that results\npossesses some features that are usually described in terms of stochastic\neffects, but our model is entirely deterministic once the density field is\nspecified. Features in the large-scale galaxy power spectrum (such as wiggles\nthat might in an extreme case mimic the effect of baryons on the primordial\ntransfer function) could, at least in principle, arise from spatial modulations\nof the galaxy formation process that arise naturally in our model. We also show\nhow this fully deterministic model gives rise to apparently stochasticity in\nthe galaxy distribution.\n\n", "human_text": "  We present a simple heuristic model to demonstrate how feedback related to\nthe galaxy formation process can result in a scale-dependent bias of mass\nversus light, even on very large scales. The model invokes the idea that\ngalaxies form initially in locations determined by the local density field, but\nthe subsequent formation of galaxies is also influenced by the presence of\nnearby galaxies that have already formed. The form of bias that results\npossesses some features that are usually described in terms of stochastic\neffects, but our model is entirely deterministic once the density field is\nspecified. Features in the large-scale galaxy power spectrum (such as wiggles\nthat might in an extreme case mimic the effect of baryons on the primordial\ntransfer function) could, at least in principle, arise from spatial modulations\nof the galaxy formation process that arise naturally in our model. We also show\nhow this fully deterministic model gives rise to apparently stochasticity in\nthe galaxy distribution.\n", "machine_text": "\nWe propose a heuristic model to demonstrate how feedback related to galaxy formation could manifest in a scale-dependent bias between mass and light on even large scales. The formation of galaxies is impacted both by the local density field and existing galaxies, resulting in a structured, rather than stochastic, bias. Features in the large-scale galaxy power spectrum, such as baryons influencing the primordial transfer function, can also be produced within this deterministic model. Another consequence is a stochastic appearance in the galaxy distribution, potentially providing new insights into the structure of our universe.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0412}
{"prompt": "Rephrase the abstract of an article with title 'Mid-Infrared Fine Structure Line Ratios in Active Galactic Nuclei\n  Observed with Spitzer IRS: Evidence for Extinction by the Torus'.\n  We present the first systematic investigation of the [NeV] (14um/24um) and\n[SIII] (18um/33um) infrared line flux ratios, traditionally used to estimate\nthe density of the ionized gas, in a sample of 41 Type 1 and Type 2 active\ngalactic nuclei (AGNs) observed with the Infrared Spectrograph on board\nSpitzer. The majority of galaxies with both [NeV] lines detected have observed\n[NeV] line flux ratios consistent with or below the theoretical low density\nlimit, based on calculations using currently available collision strengths and\nignoring absorption and stimulated emission. We find that Type 2 AGNs have\nlower line flux ratios than Type 1 AGNs and that all of the galaxies with line\nflux ratios below the low density limit are Type 2 AGNs. We argue that\ndifferential infrared extinction to the [NeV] emitting region due to dust in\nthe obscuring torus is responsible for the ratios below the low density limit\nand we suggest that the ratio may be a tracer of the inclination angle of the\ntorus to our line of sight. Because the temperature of the gas, the amount of\nextinction, and the effect of absorption and stimulated emission on the line\nratios are all unknown, we are not able to determine the electron densities\nassociated with the [NeV] line flux ratios for the objects in our sample. We\nalso find that the [SIII] emission from the galaxies in our sample is extended\nand originates primarily in star forming regions. Since the emission from\nlow-ionization species is extended, any analysis using line flux ratios from\nsuch species obtained from slits of different sizes is invalid for most nearby\ngalaxies.\n\n", "human_text": "  We present the first systematic investigation of the [NeV] (14um/24um) and\n[SIII] (18um/33um) infrared line flux ratios, traditionally used to estimate\nthe density of the ionized gas, in a sample of 41 Type 1 and Type 2 active\ngalactic nuclei (AGNs) observed with the Infrared Spectrograph on board\nSpitzer. The majority of galaxies with both [NeV] lines detected have observed\n[NeV] line flux ratios consistent with or below the theoretical low density\nlimit, based on calculations using currently available collision strengths and\nignoring absorption and stimulated emission. We find that Type 2 AGNs have\nlower line flux ratios than Type 1 AGNs and that all of the galaxies with line\nflux ratios below the low density limit are Type 2 AGNs. We argue that\ndifferential infrared extinction to the [NeV] emitting region due to dust in\nthe obscuring torus is responsible for the ratios below the low density limit\nand we suggest that the ratio may be a tracer of the inclination angle of the\ntorus to our line of sight. Because the temperature of the gas, the amount of\nextinction, and the effect of absorption and stimulated emission on the line\nratios are all unknown, we are not able to determine the electron densities\nassociated with the [NeV] line flux ratios for the objects in our sample. We\nalso find that the [SIII] emission from the galaxies in our sample is extended\nand originates primarily in star forming regions. Since the emission from\nlow-ionization species is extended, any analysis using line flux ratios from\nsuch species obtained from slits of different sizes is invalid for most nearby\ngalaxies.\n", "machine_text": "\nBased on the Infrared Spectrograph (IRS) observations of 41 Type 1 and Type 2 active galactic nuclei (AGNs), this research constitutes a systematic study of the [NeV] (14um/24um) and [SIII] (18um/33um) infrared line flux ratios that are typically applied to estimate the density of the ionized gas. The results indicate that the [NeV] line flux ratios observed in the majority of galaxies with both these lines detected are compatible with the theoretical low density limit, assuming current collision strengths and omitting absorption and stimulated emission. A distinction is made between the measurements of Type 1 and Type 2 AGNs, with the latter having lower ratios than the former. We postulate that the lower ratios in Type 2 AGNs can be attributed to different infrared extinction due to dust found in the torus. Additionally, analysis of the extended [SIII] emission was implemented, which originated mainly from star forming regions, demonstrating that any application of line flux ratios resulting from slits of varying sizes is invalid for most nearby galaxies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0547}
{"prompt": "Rephrase the abstract of an article with title 'Strings as sigma models and in the tensionless limit'.\n  This thesis considers two different aspects of string theory, the tensionless\nlimit of the string and supersymmetric sigma models. The tensionless limit is\nused to find a IIB supergravity background generated by a tensionless string.\nQuantization of the tensionless string in a pp-wave background is performed and\nthe tensionless limit is found to commute with quantization. Further, the sigma\nmodel with N=(2,2) extended world-sheet supersymmetry is considered and the\nrequirement on the target space to have a bi-Hermitean geometry is reviewed. It\nis shown that the equivalence between bi-Hermitean geometry and generalized\nKahler follows, in this context, from the equivalence between the Lagrangian-\nand Hamiltonian formulation of the model. Moreover, the explicit T-duality\ntransformation in the Hamiltonian formulation of the sigma model is constructed\nand shown to be a symplectomorphism. Under certain assumptions, the amount of\nextended supersymmetry present in the sigma model is shown to be preserved\nunder T-duality. Further, by requiring N=(2,2) extended supersymmetry in a\nfirst order formulation of the sigma model an intriguing geometrical structure\narises and in a special case generalized complex geometry is found to be\ncontained in the new framework.\n\n", "human_text": "  This thesis considers two different aspects of string theory, the tensionless\nlimit of the string and supersymmetric sigma models. The tensionless limit is\nused to find a IIB supergravity background generated by a tensionless string.\nQuantization of the tensionless string in a pp-wave background is performed and\nthe tensionless limit is found to commute with quantization. Further, the sigma\nmodel with N=(2,2) extended world-sheet supersymmetry is considered and the\nrequirement on the target space to have a bi-Hermitean geometry is reviewed. It\nis shown that the equivalence between bi-Hermitean geometry and generalized\nKahler follows, in this context, from the equivalence between the Lagrangian-\nand Hamiltonian formulation of the model. Moreover, the explicit T-duality\ntransformation in the Hamiltonian formulation of the sigma model is constructed\nand shown to be a symplectomorphism. Under certain assumptions, the amount of\nextended supersymmetry present in the sigma model is shown to be preserved\nunder T-duality. Further, by requiring N=(2,2) extended supersymmetry in a\nfirst order formulation of the sigma model an intriguing geometrical structure\narises and in a special case generalized complex geometry is found to be\ncontained in the new framework.\n", "machine_text": "\nThis paper investigates two different aspects of string theory - the tensionless limit of a string and the supersymmetric sigma model. It is established that the tensionless limit is consistent with quantization in a pp-wave background. It is further demonstrated that a bi-Hermitian target space provides an equivalent generalised K\u00e4hler structure in the sigma model.Moreover, T-duality is shown to be a symplectomorphism in the Hamiltonian formulation of the sigma model, and in special cases, the N=(2,2) extended supersymmetry is preserved. Lastly, a first-order formulation of the sigma model reveals a geometrical framework containing generalized complex geometry.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2346}
{"prompt": "Rephrase the abstract of an article with title 'Universality of Mixed Action Extrapolation Formulae'.\n  Mixed action theories with chirally symmetric valence fermions exhibit very\ndesirable features both at the level of the lattice calculations as well as in\nthe construction and implementation of the low energy mixed action effective\nfield theory. In this work we show that when such a mixed action effective\nfield theory is projected onto the valence sector, both the Lagrangian and the\nextrapolation formulae become universal in form through next to leading order,\nfor all variants of discretization methods used for the sea fermions. Our\nconclusion relies on the chiral nature of the valence quarks. The result\nimplies that for all sea quark methods which are in the same universality class\nas QCD, the numerical values of the physical coefficients in the various mixed\naction chiral Lagrangians will be the same up to lattice spacing dependent\ncorrections. This allows us to construct a prescription to determine the mixed\naction extrapolation formulae for a large class of hadronic correlation\nfunctions computed in partially quenched chiral perturbation theory at the\none-loop level. For specific examples, we apply this prescription to the\nnucleon twist--2 matrix elements and the nucleon--nucleon system. In addition,\nwe determine the mixed action extrapolation formula for the neutron EDM as this\nprovides a nice example of a theta-dependent observable; these observables are\nexceptions to our prescription.\n\n", "human_text": "  Mixed action theories with chirally symmetric valence fermions exhibit very\ndesirable features both at the level of the lattice calculations as well as in\nthe construction and implementation of the low energy mixed action effective\nfield theory. In this work we show that when such a mixed action effective\nfield theory is projected onto the valence sector, both the Lagrangian and the\nextrapolation formulae become universal in form through next to leading order,\nfor all variants of discretization methods used for the sea fermions. Our\nconclusion relies on the chiral nature of the valence quarks. The result\nimplies that for all sea quark methods which are in the same universality class\nas QCD, the numerical values of the physical coefficients in the various mixed\naction chiral Lagrangians will be the same up to lattice spacing dependent\ncorrections. This allows us to construct a prescription to determine the mixed\naction extrapolation formulae for a large class of hadronic correlation\nfunctions computed in partially quenched chiral perturbation theory at the\none-loop level. For specific examples, we apply this prescription to the\nnucleon twist--2 matrix elements and the nucleon--nucleon system. In addition,\nwe determine the mixed action extrapolation formula for the neutron EDM as this\nprovides a nice example of a theta-dependent observable; these observables are\nexceptions to our prescription.\n", "machine_text": " \nIn this article, we demonstrate that the form of the extrapolation formulae used in mixed action theories with chirally symmetric valence fermions is universal up to the next-to-leading order. Our conclusion relies on the fact that the valence quarks are chirally-symmetric. We then construct a prescription to determine the extrapolation formulae for a range of hadronic correlation functions which are computed through partially quenched chiral perturbation theory at the one-loop level. We apply this prescription to the nucleon twist--2 matrix elements and the neutron EDM, both of which are theta-dependent observables. Our results indicate that the numerical values of the physical coefficients within these mixed action chiral Lagrangians will have the same values across all sea quark methods in the same universal classification as QCD, with slight corrections related to the lattice spacing.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0035}
{"prompt": "Rephrase the abstract of an article with title 'VLBI observations of seven BL Lac objects from RGB sample'.\n  We present EVN observations of seven BL Lac objects selected from the RGB\nsample. To investigate the intrinsic radiation property of BL Lac objects, we\nestimated the Doppler factor with the VLA or MERLIN core and the total 408 MHz\nluminosity for a sample of 170 BL Lac objects. The intrinsic (comoving)\nsynchrotron peak frequency was then calculated by using the estimated Doppler\nfactor. Assuming a Lorentz factor of 5, the viewing angle of jets was\nconstrained. The high-resolution VLBI images of seven sources all show a\ncore-jet structure. We estimated the proper motions of three sources with the\nVLBI archive data, and find that the apparent speed increases with the distance\nof components to the core for all of them. In our BL Lacs sample, the Doppler\nfactor of LBLs is systematically larger than that of IBLs and HBLs. We find a\nsignificant anti-correlation between the total 408 MHz luminosity and the\nintrinsic synchrotron peak frequency. However, the scatter is much larger than\nfor the blazar sequence. Moreover, we find a significant positive correlation\nbetween the viewing angle and the intrinsic synchrotron peak frequency. The BL\nLac objects show a continuous distribution on the viewing angle. While LBLs\nhave a smaller viewing angle than that of IBLs and HBLs, IBLs are comparable to\nHBLs. We conclude that the intrinsic synchrotron peak frequency is not only\nrelated to the intrinsic radio power (though with a large scatter), but also to\nthe viewing angle for the present sample.\n\n", "human_text": "  We present EVN observations of seven BL Lac objects selected from the RGB\nsample. To investigate the intrinsic radiation property of BL Lac objects, we\nestimated the Doppler factor with the VLA or MERLIN core and the total 408 MHz\nluminosity for a sample of 170 BL Lac objects. The intrinsic (comoving)\nsynchrotron peak frequency was then calculated by using the estimated Doppler\nfactor. Assuming a Lorentz factor of 5, the viewing angle of jets was\nconstrained. The high-resolution VLBI images of seven sources all show a\ncore-jet structure. We estimated the proper motions of three sources with the\nVLBI archive data, and find that the apparent speed increases with the distance\nof components to the core for all of them. In our BL Lacs sample, the Doppler\nfactor of LBLs is systematically larger than that of IBLs and HBLs. We find a\nsignificant anti-correlation between the total 408 MHz luminosity and the\nintrinsic synchrotron peak frequency. However, the scatter is much larger than\nfor the blazar sequence. Moreover, we find a significant positive correlation\nbetween the viewing angle and the intrinsic synchrotron peak frequency. The BL\nLac objects show a continuous distribution on the viewing angle. While LBLs\nhave a smaller viewing angle than that of IBLs and HBLs, IBLs are comparable to\nHBLs. We conclude that the intrinsic synchrotron peak frequency is not only\nrelated to the intrinsic radio power (though with a large scatter), but also to\nthe viewing angle for the present sample.\n", "machine_text": "\nWe present Very Long Baseline Interferometry (VLBI) results of BL Lac objects taken from the RGB sample. By using the Doppler factor of the Very Long Array (VLA) or Multi-Element Radio Linked Interferometer (MERLIN) core and total 408MHz luminosity, we calculated the intrinsic (comoving) synchrotron peak frequency of 170 BL Lac sources. We based our assumptions on a Lorentz factor of 5 and estimated the viewing angles of the jets accordingly. The VLBI images of the seven sources were supportive of the core-jet structure. Through the use of archive data, we determined the proper motions for three sources and observed an increase in speed when the components moved away from the core. Our sample confirms the Doppler factor of LBLs to be larger than IBLs and HBLs. We found an anti-correlation between the 408MHz luminosity and intrinsic synchrotron peak frequency, although the accompanying scatter was high. Additionally, a positive correlation was observed between the viewing angle and intrinsic synchrotron peak frequency, which suggests that these two values are linked in our sample. Finally, the BL Lacs show a consistent range of viewing angles, with LBLs having a lower value than IBLs and HBLs, while IBLs and HBLs have comparable angles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0191}
{"prompt": "Rephrase the abstract of an article with title 'Grand minima and maxima of solar activity: New observational constraints'.\n  Using a reconstruction of sunspot numbers stretching over multiple millennia,\nwe analyze the statistics of the occurrence of grand minima and maxima and set\nnew observational constraints on long-term solar and stellar dynamo models.\n  We present an updated reconstruction of sunspot number over multiple\nmillennia, from $^{14}$C data by means of a physics-based model, using an\nupdated model of the evolution of the solar open magnetic flux. A list of grand\nminima and maxima of solar activity is presented for the Holocene (since 9500\nBC) and the statistics of both the length of individual events as well as the\nwaiting time between them are analyzed.\n  The occurrence of grand minima/maxima is driven not by long-term cyclic\nvariability, but by a stochastic/chaotic process. The waiting time distribution\nof the occurrence of grand minima/maxima deviates from an exponential\ndistribution, implying that these events tend to cluster together with long\nevent-free periods between the clusters. Two different types of grand minima\nare observed: short (30--90 years) minima of Maunder type and long ($>$110\nyears) minima of Sp\\\"orer type, implying that a deterministic behaviour of the\ndynamo during a grand minimum defines its length. The duration of grand maxima\nfollows an exponential distribution, suggesting that the duration of a grand\nmaximum is determined by a random process.\n  These results set new observational constraints upon the long-term behaviour\nof the solar dynamo.\n\n", "human_text": "  Using a reconstruction of sunspot numbers stretching over multiple millennia,\nwe analyze the statistics of the occurrence of grand minima and maxima and set\nnew observational constraints on long-term solar and stellar dynamo models.\n  We present an updated reconstruction of sunspot number over multiple\nmillennia, from $^{14}$C data by means of a physics-based model, using an\nupdated model of the evolution of the solar open magnetic flux. A list of grand\nminima and maxima of solar activity is presented for the Holocene (since 9500\nBC) and the statistics of both the length of individual events as well as the\nwaiting time between them are analyzed.\n  The occurrence of grand minima/maxima is driven not by long-term cyclic\nvariability, but by a stochastic/chaotic process. The waiting time distribution\nof the occurrence of grand minima/maxima deviates from an exponential\ndistribution, implying that these events tend to cluster together with long\nevent-free periods between the clusters. Two different types of grand minima\nare observed: short (30--90 years) minima of Maunder type and long ($>$110\nyears) minima of Sp\\\"orer type, implying that a deterministic behaviour of the\ndynamo during a grand minimum defines its length. The duration of grand maxima\nfollows an exponential distribution, suggesting that the duration of a grand\nmaximum is determined by a random process.\n  These results set new observational constraints upon the long-term behaviour\nof the solar dynamo.\n", "machine_text": "\nUsing a new model to reconstruct the sunspot numbers over the last few millennia, we analyse the timescale and occurrence of grand minima and maxima events. This data reveals that the events follow a non-exponential distribution, implying the association of these events with a stochastic/chaotic process. We observe that grand minima are indicative of two different types: short (30-90 year) Maunder-type and longer ($>$110) Sp\\\"orer-type events, hinting at a deterministic behavior of the dynamo that may influence their length. Grand maxima follow an exponential distribution, which suggests they are determined by random processes. This new researched provides new observational evidence to further our understanding and inform long-term solar dynamo models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0385}
{"prompt": "Rephrase the abstract of an article with title 'On the foundations of thermodynamics'.\n  On the basis of new, concise foundations, this paper establishes the four\nlaws of thermodynamics, the Maxwell relations, and the stability requirements\nfor response functions, in a form applicable to global (homogeneous), local\n(hydrodynamic) and microlocal (kinetic) equilibrium.\n  The present, self-contained treatment needs very little formal machinery and\nstays very close to the formulas as they are applied by the practicing\nphysicist, chemist, or engineer. From a few basic assumptions, the full\nstructure of phenomenological thermodynamics and of classical and quantum\nstatistical mechanics is recovered.\n  Care has been taken to keep the foundations free of subjective aspects (which\ntraditionally creep in through information or probability). One might describe\nthe paper as a uniform treatment of the nondynamical part of classical and\nquantum statistical mechanics ``without statistics'' (i.e., suitable for the\ndefinite descriptions of single objects) and ``without mechanics'' (i.e.,\nindependent of microscopic assumptions). When enriched by the traditional\nexamples and applications, this paper may serve as the basis for a course on\nthermal physics.\n\n", "human_text": "  On the basis of new, concise foundations, this paper establishes the four\nlaws of thermodynamics, the Maxwell relations, and the stability requirements\nfor response functions, in a form applicable to global (homogeneous), local\n(hydrodynamic) and microlocal (kinetic) equilibrium.\n  The present, self-contained treatment needs very little formal machinery and\nstays very close to the formulas as they are applied by the practicing\nphysicist, chemist, or engineer. From a few basic assumptions, the full\nstructure of phenomenological thermodynamics and of classical and quantum\nstatistical mechanics is recovered.\n  Care has been taken to keep the foundations free of subjective aspects (which\ntraditionally creep in through information or probability). One might describe\nthe paper as a uniform treatment of the nondynamical part of classical and\nquantum statistical mechanics ``without statistics'' (i.e., suitable for the\ndefinite descriptions of single objects) and ``without mechanics'' (i.e.,\nindependent of microscopic assumptions). When enriched by the traditional\nexamples and applications, this paper may serve as the basis for a course on\nthermal physics.\n", "machine_text": "This research offers new, concise foundations for establishing the four laws of thermodynamics, the Maxwell relationships, and the stability requirements of response functions, all in an applicable form to global, local and microlocal equilibrium. This work uses very little in the way of formality, remaining closely tied to the formulae used by professionals in the physics, chemistry, and engineering fields. Through a small set of assumptions, the full structure of phenomena-based thermodynamics and classical and quantum statistical mechanics is revealed. This paper is clear of the subjective elements that often manifest in information or probablitiy by concentrating solely on the static parts of classical and quantum statistical mechanics, which accommodate single object descriptions. When completed with traditional cases and applications, this work can be used as the base of a thermal physics course.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.379}
{"prompt": "Rephrase the abstract of an article with title 'Single Top Results from CDF'.\n  The CDF Collaboration has analyzed 955/pb of CDF II data to search for\nelectroweak single top quark production at the Tevatron. We employ three\ndifferent analysis techniques to search for a single top signal: multivariate\nlikelihood functions; neural networks; the matrix element analysis technique.\nThe sensitivities to a single top signal at the rate predicted by the Standard\nModel are 2.1 - 2.6 sigma. The first two analyses observe a deficit of single\ntop-like events and set upper limits on the production cross section. The\nmatrix element analysis observes a 2.3 sigma single top excess and measures a\ncombined t-channel and s-channel cross section of 2.7 +1.5-1.3 pb. Using the\nsame dataset, we have searched for non-Standard Model production of single top\nquarks through a heavy W' boson resonance. No evidence for a signal is\nobserved. We exclude at the 95 % C.L. W' boson production with masses of 760\nGeV/c^2 (790 GeV/c^2) in case the right handed neutrino is smaller (larger)\nthan the mass of the W' boson.\n\n", "human_text": "  The CDF Collaboration has analyzed 955/pb of CDF II data to search for\nelectroweak single top quark production at the Tevatron. We employ three\ndifferent analysis techniques to search for a single top signal: multivariate\nlikelihood functions; neural networks; the matrix element analysis technique.\nThe sensitivities to a single top signal at the rate predicted by the Standard\nModel are 2.1 - 2.6 sigma. The first two analyses observe a deficit of single\ntop-like events and set upper limits on the production cross section. The\nmatrix element analysis observes a 2.3 sigma single top excess and measures a\ncombined t-channel and s-channel cross section of 2.7 +1.5-1.3 pb. Using the\nsame dataset, we have searched for non-Standard Model production of single top\nquarks through a heavy W' boson resonance. No evidence for a signal is\nobserved. We exclude at the 95 % C.L. W' boson production with masses of 760\nGeV/c^2 (790 GeV/c^2) in case the right handed neutrino is smaller (larger)\nthan the mass of the W' boson.\n", "machine_text": "The CDF Collaboration has conducted an analysis of 955/pb of data from CDF II to investigate the production of electroweak single top quark production at the Tevatron. Three different analysis techniques, including likelihood functions, neural networks, and the matrix element analysis, have been employed to detect a single top signal in line with the Standard Model. The results of the two preliminary analyses indicate that there is a deficit of single-top-like events and set upper limits on the production cross section. The matrix element analysis suggests a 2.3 sigma single top excess with a cross section  measurement of 2.7 \u00b11.5-1.3 pb. Additionally, the search for non-Standard Model production of single top quarks through a heavy W' boson resonance yielded no evidence for a signal. This data analysis has allowed for the exclusion of W' bosons at the 95 % C.L. with masses of 760 or 790 GeV/c^2, based on whether the right handed neutrino is smaller or larger than the mass of the W' boson respectively.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0282}
{"prompt": "Rephrase the abstract of an article with title 'Refuting the Pseudo Attack on the REESSE1+ Cryptosystem'.\n  We illustrate through example 1 and 2 that the condition at theorem 1 in [8]\ndissatisfies necessity, and the converse proposition of fact 1.1 in [8] does\nnot hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for\nf(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a\nlogic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4\nto be invalid. Demonstrate through ex.4 and 5 that each or the combination of\nqu+1 > qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) +\nf(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4\nand alg.2 based on table 1 are disordered and wrong logically. Further,\nmanifest through a repeated experiment and ex.5 that the data at table 2 is\nfalsified, and the example in [8] is woven elaborately. We explain why Cx = Ax\n* W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To\nthe signature fraud, we point out that [8] misunderstands the existence of T^-1\nand Q^-1 % (M-1), and forging of Q can be easily avoided through moving H.\nTherefore, the conclusion of [8] that REESSE1+ is not secure at all (which\nconnotes that [8] can extract a related private key from any public key in\nREESSE1+) is fully incorrect, and as long as the parameter Omega is fitly\nselected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure.\n\n", "human_text": "  We illustrate through example 1 and 2 that the condition at theorem 1 in [8]\ndissatisfies necessity, and the converse proposition of fact 1.1 in [8] does\nnot hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for\nf(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a\nlogic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4\nto be invalid. Demonstrate through ex.4 and 5 that each or the combination of\nqu+1 > qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) +\nf(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4\nand alg.2 based on table 1 are disordered and wrong logically. Further,\nmanifest through a repeated experiment and ex.5 that the data at table 2 is\nfalsified, and the example in [8] is woven elaborately. We explain why Cx = Ax\n* W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To\nthe signature fraud, we point out that [8] misunderstands the existence of T^-1\nand Q^-1 % (M-1), and forging of Q can be easily avoided through moving H.\nTherefore, the conclusion of [8] that REESSE1+ is not secure at all (which\nconnotes that [8] can extract a related private key from any public key in\nREESSE1+) is fully incorrect, and as long as the parameter Omega is fitly\nselected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure.\n", "machine_text": "In this paper, we refute a pseudo attack on the REESSE1+ cryptosystem. We provide examples, analyze the logic of deductions, and conduct experiments to prove that none of the claims made in the attack are sufficient. We also explain why the signature of REESSE1+ v2.1 is modified and point out that the original attack misunderstands certain properties. Finally, we conclude that in so far as the parameter Omega is properly chosen, the REESSE1+ cryptosystem with Cx = Ax * W^f(x) (% M) is secure.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0492}
{"prompt": "Rephrase the abstract of an article with title 'The Norma Cluster (ACO 3627): I. A Dynamical Analysis of the Most\n  Massive Cluster in the Great Attractor'.\n  A detailed dynamical analysis of the nearby rich Norma cluster (ACO 3627) is\npresented. From radial velocities of 296 cluster members, we find a mean\nvelocity of 4871 +/- 54 km/s and a velocity dispersion of 925 km/s. The mean\nvelocity of the E/S0 population (4979 +/- 85 km/s) is offset with respect to\nthat of the S/Irr population (4812 +/- 70 km/s) by `Delta' v = 164 km/s in the\ncluster rest frame. This offset increases towards the core of the cluster. The\nE/S0 population is free of any detectable substructure and appears relaxed. Its\nshape is clearly elongated with a position angle that is aligned along the\ndominant large-scale structures in this region, the so-called Norma wall. The\ncentral cD galaxy has a very large peculiar velocity of 561 km/s which is most\nprobably related to an ongoing merger at the core of the cluster. The\nspiral/irregular galaxies reveal a large amount of substructure; two\ndynamically distinct subgroups within the overall spiral-population have been\nidentified, located along the Norma wall elongation. The dynamical mass of the\nNorma cluster within its Abell radius is 1 - 1.1 x 10^15 h^-1_73 M_Sun. One of\nthe cluster members, the spiral galaxy WKK 6176 which recently was observed to\nhave a 70 kpc X-ray tail, reveals numerous striking low-brightness filaments\npointing away from the cluster centre suggesting strong interaction with the\nintracluster medium.\n\n", "human_text": "  A detailed dynamical analysis of the nearby rich Norma cluster (ACO 3627) is\npresented. From radial velocities of 296 cluster members, we find a mean\nvelocity of 4871 +/- 54 km/s and a velocity dispersion of 925 km/s. The mean\nvelocity of the E/S0 population (4979 +/- 85 km/s) is offset with respect to\nthat of the S/Irr population (4812 +/- 70 km/s) by `Delta' v = 164 km/s in the\ncluster rest frame. This offset increases towards the core of the cluster. The\nE/S0 population is free of any detectable substructure and appears relaxed. Its\nshape is clearly elongated with a position angle that is aligned along the\ndominant large-scale structures in this region, the so-called Norma wall. The\ncentral cD galaxy has a very large peculiar velocity of 561 km/s which is most\nprobably related to an ongoing merger at the core of the cluster. The\nspiral/irregular galaxies reveal a large amount of substructure; two\ndynamically distinct subgroups within the overall spiral-population have been\nidentified, located along the Norma wall elongation. The dynamical mass of the\nNorma cluster within its Abell radius is 1 - 1.1 x 10^15 h^-1_73 M_Sun. One of\nthe cluster members, the spiral galaxy WKK 6176 which recently was observed to\nhave a 70 kpc X-ray tail, reveals numerous striking low-brightness filaments\npointing away from the cluster centre suggesting strong interaction with the\nintracluster medium.\n", "machine_text": "\nAn examination of ACO 3627, commonly known as the Norma cluster, has been completed to better understand the most massive cluster in the Great Attractor. The radial velocities of numerous cluster members were collected and a mean velocity of 4871 +/- 54 km/s and velocity dispersion of 925 km/s were determined. It was found that the E/S0 population was offset from the S/Irr population in the cluster by 'Delta' v = 164 km/s and the offset increased towards the core. Additionally, two dynamically distinct subgroups were identified in the spiral-population located along the Norma wall. The mass of the cluster within its Abell radius is estimated to be between 1 - 1.1 x 10^15 h^-1_73 M_Sun and a spiral galaxy, WKK 6176, with a 70 kpc X-ray tail exhibits strong interaction with the intracluster medium evidenced by multiple low-brightness filaments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2227}
{"prompt": "Rephrase the abstract of an article with title 'Adiabatic pumping through a quantum dot in the Kondo regime: Exact\n  results at the Toulouse limit'.\n  Transport properties of ultrasmall quantum dots with a single unpaired\nelectron are commonly modeled by the nonequilibrium Kondo model, describing the\nexchange interaction of a spin-1/2 local moment with two leads of\nnoninteracting electrons. Remarkably, the model possesses an exact solution\nwhen tuned to a special manifold in its parameter space known as the Toulouse\nlimit. We use the Toulouse limit to exactly calculate the adiabatically pumped\nspin current in the Kondo regime. In the absence of both potential scattering\nand a voltage bias, the instantaneous charge current is strictly zero for a\ngeneric Kondo model. However, a nonzero spin current can be pumped through the\nsystem in the presence of a finite magnetic field, provided the spin couples\nasymmetrically to the two leads. Tunneling through a Kondo impurity thus offers\na natural mechanism for generating a pure spin current. We show, in particular,\nthat one can devise pumping cycles along which the average spin pumped per\ncycle is closely equal to $\\hbar$. By analogy with Brouwer's formula for\nnoninteracting systems with two driven parameters, the pumped spin current is\nexpressed as a geometrical property of a scattering matrix. However, the\nrelevant %Alex: I replaced topological with geometrical in the sentence above\nscattering matrix that enters the formulation pertains to the Majorana fermions\nthat appear at the Toulouse limit rather than the physical electrons that carry\nthe current. These results are obtained by combining the nonequilibrium Keldysh\nGreen function technique with a systematic gradient expansion, explicitly\nexposing the small parameter controlling the adiabatic limit.\n\n", "human_text": "  Transport properties of ultrasmall quantum dots with a single unpaired\nelectron are commonly modeled by the nonequilibrium Kondo model, describing the\nexchange interaction of a spin-1/2 local moment with two leads of\nnoninteracting electrons. Remarkably, the model possesses an exact solution\nwhen tuned to a special manifold in its parameter space known as the Toulouse\nlimit. We use the Toulouse limit to exactly calculate the adiabatically pumped\nspin current in the Kondo regime. In the absence of both potential scattering\nand a voltage bias, the instantaneous charge current is strictly zero for a\ngeneric Kondo model. However, a nonzero spin current can be pumped through the\nsystem in the presence of a finite magnetic field, provided the spin couples\nasymmetrically to the two leads. Tunneling through a Kondo impurity thus offers\na natural mechanism for generating a pure spin current. We show, in particular,\nthat one can devise pumping cycles along which the average spin pumped per\ncycle is closely equal to $\\hbar$. By analogy with Brouwer's formula for\nnoninteracting systems with two driven parameters, the pumped spin current is\nexpressed as a geometrical property of a scattering matrix. However, the\nrelevant %Alex: I replaced topological with geometrical in the sentence above\nscattering matrix that enters the formulation pertains to the Majorana fermions\nthat appear at the Toulouse limit rather than the physical electrons that carry\nthe current. These results are obtained by combining the nonequilibrium Keldysh\nGreen function technique with a systematic gradient expansion, explicitly\nexposing the small parameter controlling the adiabatic limit.\n", "machine_text": "In this article, we investigate the transport properties of a system with a single unpaired electron, modeled by a nonequilibrium Kondo model. Taking advantage of the special parameter space of the Toulouse limit, we exactly calculate the adiabatically pumped spin current through the Kondo regime. We show that this provides a natural mechanism of generating a pure spin current. By examining the relevant scattering matrix of Majorana fermions in the Toulouse limit, we express this spin current as a geometrical property of the system. Combining the Keldysh Green function technique with a gradient expansion, we uncover the small parameter that determines the adiabatic limit.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3014}
{"prompt": "Rephrase the abstract of an article with title 'Detecting atmospheric neutrino oscillations in the ATLAS detector at\n  CERN'.\n  We discuss the possibility to study oscillations of atmospheric neutrinos in\nthe ATLAS experiment at CERN. Due to the large total detector mass, a\nsignificant number of events is expected, and during the shutdown phases of the\nLHC, reconstruction of these events will be possible with very good energy and\nangular resolutions, and with charge identification. We argue that 500 live\ndays of neutrino running could be achieved, and that a total of ~160 contained\n\\nu_\\mu events and ~360 upward going muons could be collected during this time.\nDespite the low statistics, the excellent detector resolution will allow for an\nunambiguous confirmation of atmospheric neutrino oscillations and for\nmeasurements of the leading oscillation parameters. Though our detailed\nsimulations show that the sensitivity of ATLAS is worse than that of dedicated\nneutrino experiments, we demonstrate that more sophisticated detectors, e.g. at\nthe ILC, could be highly competitive with upcoming superbeam experiments, and\nmight even give indications for the mass hierarchy and for the value of\ntheta-13.\n\n", "human_text": "  We discuss the possibility to study oscillations of atmospheric neutrinos in\nthe ATLAS experiment at CERN. Due to the large total detector mass, a\nsignificant number of events is expected, and during the shutdown phases of the\nLHC, reconstruction of these events will be possible with very good energy and\nangular resolutions, and with charge identification. We argue that 500 live\ndays of neutrino running could be achieved, and that a total of ~160 contained\n\\nu_\\mu events and ~360 upward going muons could be collected during this time.\nDespite the low statistics, the excellent detector resolution will allow for an\nunambiguous confirmation of atmospheric neutrino oscillations and for\nmeasurements of the leading oscillation parameters. Though our detailed\nsimulations show that the sensitivity of ATLAS is worse than that of dedicated\nneutrino experiments, we demonstrate that more sophisticated detectors, e.g. at\nthe ILC, could be highly competitive with upcoming superbeam experiments, and\nmight even give indications for the mass hierarchy and for the value of\ntheta-13.\n", "machine_text": "This paper puts forward the potential of the ATLAS detector at CERN to detect\natmospheric neutrino oscillations. With a total of 500 days running detecting\nevents, 160 \\nu_\\mu events, and 360 upward going muons, there could potentially\nbe an unambiguous confirmation of neutrino oscillations and a measurement of the\nleading oscillation parameters. Our simulations were done to check the\nsensitivity of ATLAS compared to other neutrino experiments and suggest that\nthe ILC may be as useful, or even more so, than box beam projects for\nestablishing the mass hierarchy, and for measuring the value of theta-13.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2595}
{"prompt": "Rephrase the abstract of an article with title 'Towards the Distribution of the Size of a Largest Planar Matching and\n  Largest Planar Subgraph in Random Bipartite Graphs'.\n  We address the following question: When a randomly chosen regular bipartite\nmulti--graph is drawn in the plane in the ``standard way'', what is the\ndistribution of its maximum size planar matching (set of non--crossing disjoint\nedges) and maximum size planar subgraph (set of non--crossing edges which may\nshare endpoints)? The problem is a generalization of the Longest Increasing\nSequence (LIS) problem (also called Ulam's problem). We present combinatorial\nidentities which relate the number of r-regular bipartite multi--graphs with\nmaximum planar matching (maximum planar subgraph) of at most d edges to a\nsigned sum of restricted lattice walks in Z^d, and to the number of pairs of\nstandard Young tableaux of the same shape and with a ``descend--type''\nproperty. Our results are obtained via generalizations of two combinatorial\nproofs through which Gessel's identity can be obtained (an identity that is\ncrucial in the derivation of a bivariate generating function associated to the\ndistribution of LISs, and key to the analytic attack on Ulam's problem).\n  We also initiate the study of pattern avoidance in bipartite multigraphs and\nderive a generalized Gessel identity for the number of bipartite 2-regular\nmultigraphs avoiding a specific (monotone) pattern.\n\n", "human_text": "  We address the following question: When a randomly chosen regular bipartite\nmulti--graph is drawn in the plane in the ``standard way'', what is the\ndistribution of its maximum size planar matching (set of non--crossing disjoint\nedges) and maximum size planar subgraph (set of non--crossing edges which may\nshare endpoints)? The problem is a generalization of the Longest Increasing\nSequence (LIS) problem (also called Ulam's problem). We present combinatorial\nidentities which relate the number of r-regular bipartite multi--graphs with\nmaximum planar matching (maximum planar subgraph) of at most d edges to a\nsigned sum of restricted lattice walks in Z^d, and to the number of pairs of\nstandard Young tableaux of the same shape and with a ``descend--type''\nproperty. Our results are obtained via generalizations of two combinatorial\nproofs through which Gessel's identity can be obtained (an identity that is\ncrucial in the derivation of a bivariate generating function associated to the\ndistribution of LISs, and key to the analytic attack on Ulam's problem).\n  We also initiate the study of pattern avoidance in bipartite multigraphs and\nderive a generalized Gessel identity for the number of bipartite 2-regular\nmultigraphs avoiding a specific (monotone) pattern.\n", "machine_text": "\nThis paper looks into the probability of the maximum size of a planar matching and maximum size planar subgraph occuring when a random regular bipartite multigraph is placed in the plane in a standard way. This addresses an important generalisation of Longest Increasing Sequence (LIS)/ Ulam's problem. We present equations that connect the number of regular bipartite multigraphs with the maximum size planar matching and planar subgraph of at most d edges in terms of restricted lattice walks in Z^d and the number of pairs of standard Young tableaux with the same shape and a descending pattern. Additionally, we explore pattern avoidance in bipartite multigraphs, leading to a generalised Gessel identity for the number of bipipartite 2-regular multigraphs which disregard a monotone pattern.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2223}
{"prompt": "Rephrase the abstract of an article with title 'Helical, Angular and Radial Ordering in Narrow Capillaries'.\n  To enlighten the nature of the order-disorder and order-order transitions in\nblock copolymer melts confined in narrow capillaries we analyze peculiarities\nof the conventional Landau weak crystallization theory of systems confined to\ncylindrical geometry. This phenomenological approach provides a quantitative\nclassification of the cylindrical ordered morphologies by expansion of the\norder parameter spatial distribution into the eigenfunctions of the Laplace\noperator. The symmetry of the resulting ordered morphologies is shown to\nstrongly depend both on the boundary conditions (wall preference) and the ratio\nof the cylinder radius and the wave length of the critical order parameter\nfluctuations, which determine the bulk ordering of the system under\nconsideration. In particular, occurrence of the helical morphologies is a\nrather general consequence of the imposed cylindrical symmetry for narrow\nenough capillaries. We discuss also the ODT and OOT involving some other\nsimplest morphologies. The presented results are relevant also to other\nordering systems as charge-density waves appearing under addition of an ionic\nsolute to a solvent in its critical region, weakly charged polyelectrolyte\nsolutions in poor solvent, microemulsions etc.\n\n", "human_text": "  To enlighten the nature of the order-disorder and order-order transitions in\nblock copolymer melts confined in narrow capillaries we analyze peculiarities\nof the conventional Landau weak crystallization theory of systems confined to\ncylindrical geometry. This phenomenological approach provides a quantitative\nclassification of the cylindrical ordered morphologies by expansion of the\norder parameter spatial distribution into the eigenfunctions of the Laplace\noperator. The symmetry of the resulting ordered morphologies is shown to\nstrongly depend both on the boundary conditions (wall preference) and the ratio\nof the cylinder radius and the wave length of the critical order parameter\nfluctuations, which determine the bulk ordering of the system under\nconsideration. In particular, occurrence of the helical morphologies is a\nrather general consequence of the imposed cylindrical symmetry for narrow\nenough capillaries. We discuss also the ODT and OOT involving some other\nsimplest morphologies. The presented results are relevant also to other\nordering systems as charge-density waves appearing under addition of an ionic\nsolute to a solvent in its critical region, weakly charged polyelectrolyte\nsolutions in poor solvent, microemulsions etc.\n", "machine_text": "\nWe investigate the various ordering transitions in block copolymer melts held in narrow capillaries. To determine the variety of ordered morphologies, we employ a phenomenological Landau weak crystallization theory of cylindrical geometry, based on the theory of order parameters and the eigenfunctions of the Laplace operator. Our results show the impact of boundary conditions and specific cylinder radius-wave length ratio on the symmetry of the resulting morphologies, and the emergence of helical structures. Furthermore, our research explores the order-disorder transitions (ODT) and the order-order transitions (OOT) involving some of the simplest morphologies. Additionally, these findings also relate to ordering systems such as charge-density waves in a critical region, microemulsions and weakly charged polyelectrolytes in a poor solvent.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3755}
{"prompt": "Rephrase the abstract of an article with title 'Non-Abelian hydrodynamics and the flow of spin in spin-orbit coupled\n  substances'.\n  Motivated by heavy ion collision experiments, we study the hydrodynamic\nproperties of non-Abelian systems. These issues arise in condensed matter\nphysics in the context of transport of spins in the presence of spin orbit\ncoupling: the Pauli Hamiltonian governing the leading relativistic corrections\nin condensed matter systems can be rewritten in a language of SU(2) covariant\nderivatives, where the role of the non-Abelian gauge fields is taken by the\nphysical electromagnetic fields. Taking a similar perspective as Jackiw and\ncoworkers, we show that non-abelian hydrodynamical currents can be factored in\na non-coherent 'classical' part, and a coherent part requiring macroscopic\nnon-abelian quantum entanglement. Non-abelian flow being thus a much richer\naffair than familiar hydrodynamics, permits us to classify the various spin\ntransport phenomena in in condensed matter physics in a unifying framework.In\nsemiconductor spintronics, the absence of hydrodynamics is well known, but in\nour formulation it is directly associated with the fact that non-abelian\ncurrents are only covariantly conserved.We analyze the quantum mechanical\nsingle particle currents of relevance to mesoscopic transport with as highlight\nthe Aharonov-Casher effect, where we demonstrate that the non-abelian transport\nstructure renders it much more fragile than its abelian counterpart, the\nAharonov-Bohm effect. We subsequently focus on spin flows protected by order\nparameters, of which the spin-spiral magnets and the spin superfluids are\nimportant examples. The surprising bonus is that the presence of an order\nparameter, being single-valued, restores hydrodynamics. We demonstrate a new\neffect: the trapping of electrical line charge, being the 'fixed frame'\nnon-Abelian analogue of the familiar magnetic flux trapping by superconductors.\n\n", "human_text": "  Motivated by heavy ion collision experiments, we study the hydrodynamic\nproperties of non-Abelian systems. These issues arise in condensed matter\nphysics in the context of transport of spins in the presence of spin orbit\ncoupling: the Pauli Hamiltonian governing the leading relativistic corrections\nin condensed matter systems can be rewritten in a language of SU(2) covariant\nderivatives, where the role of the non-Abelian gauge fields is taken by the\nphysical electromagnetic fields. Taking a similar perspective as Jackiw and\ncoworkers, we show that non-abelian hydrodynamical currents can be factored in\na non-coherent 'classical' part, and a coherent part requiring macroscopic\nnon-abelian quantum entanglement. Non-abelian flow being thus a much richer\naffair than familiar hydrodynamics, permits us to classify the various spin\ntransport phenomena in in condensed matter physics in a unifying framework.In\nsemiconductor spintronics, the absence of hydrodynamics is well known, but in\nour formulation it is directly associated with the fact that non-abelian\ncurrents are only covariantly conserved.We analyze the quantum mechanical\nsingle particle currents of relevance to mesoscopic transport with as highlight\nthe Aharonov-Casher effect, where we demonstrate that the non-abelian transport\nstructure renders it much more fragile than its abelian counterpart, the\nAharonov-Bohm effect. We subsequently focus on spin flows protected by order\nparameters, of which the spin-spiral magnets and the spin superfluids are\nimportant examples. The surprising bonus is that the presence of an order\nparameter, being single-valued, restores hydrodynamics. We demonstrate a new\neffect: the trapping of electrical line charge, being the 'fixed frame'\nnon-Abelian analogue of the familiar magnetic flux trapping by superconductors.\n", "machine_text": "We analyze the hydrodynamic flow of spins in a class of condensed matter systems where spin-orbit coupling is present. In this context, we are able to apply a language similar to that of Jackiw et al for a non-Abelian non-coherent 'classical' and macroscopic non-Abelian quantum entanglement. We give examples of spin transport phenomena in semiconductor spintronics, where we show that the the non-Abelian structure renders Aharonov-Casher effect more fragile than the Aharonov-Bohm effect. Additionally, we make the observation that when an order parameter is single-valued, hydrodynamics is restored. This restoration of hydrodynamics allows us to further explore the notion of line charge trapping in fixed frames, analogous to magnetic flux trapping in superconductors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2953}
{"prompt": "Rephrase the abstract of an article with title 'Cosmological Casimir effect with maximum planckian momentum and\n  accelerating universe'.\n  We develop here a mechanism that, without making use of a cosmological\nconstant, reproduces an accelerating universe. This is done by taking into\naccount Casimir vacuum energy density, assuming that the underlying theory\nallows a maximum momentum, that turns out to be the leading contribution term\nto Einstein equations in a large expanding FRW universe. As stated in numerous\nquantum gravity studies, we postulate that maximum momentum is related to the\nexistence of the Planck length as a fundamental length. This insight, together\nwith the assumption of a Planck scale correction to the energy/momentum\ndispersion-relation on a FRW background, is used here to calculate Casimir\nvacuum energy. We show that, under these hypothesis, an accelerated universe\nexpansion is obtained. As last step we analyze the compatibility of the\nresulting model with experimental data, writing down the equation of state for\nCasimir energy and pressure and observing that this equation of state belongs\nto a class of models that naturally fits cosmological observations. We\nemphasize that our result relies, once a fundamental length is introduced in\nCasimir effect, just on general arguments thus it is independent on an explicit\nform of the energy-momentum dispersion relation.\n\n", "human_text": "  We develop here a mechanism that, without making use of a cosmological\nconstant, reproduces an accelerating universe. This is done by taking into\naccount Casimir vacuum energy density, assuming that the underlying theory\nallows a maximum momentum, that turns out to be the leading contribution term\nto Einstein equations in a large expanding FRW universe. As stated in numerous\nquantum gravity studies, we postulate that maximum momentum is related to the\nexistence of the Planck length as a fundamental length. This insight, together\nwith the assumption of a Planck scale correction to the energy/momentum\ndispersion-relation on a FRW background, is used here to calculate Casimir\nvacuum energy. We show that, under these hypothesis, an accelerated universe\nexpansion is obtained. As last step we analyze the compatibility of the\nresulting model with experimental data, writing down the equation of state for\nCasimir energy and pressure and observing that this equation of state belongs\nto a class of models that naturally fits cosmological observations. We\nemphasize that our result relies, once a fundamental length is introduced in\nCasimir effect, just on general arguments thus it is independent on an explicit\nform of the energy-momentum dispersion relation.\n", "machine_text": "\nIn this article, we propose a novel way to create an accelerating universe without adopting a cosmological constant. We posit that this is accomplished by taking into account Casimir vacuum energy density and a maximum momentum, consistent with quantum gravity studies, that is proportional to the Planck length. Our hypothesis further include a Planck scale correction to the energy/momentum dispersion-relation of a FRW background. We demonstrate that these assumptions equate to a vacuum energy density which yield an accelerated universe. Simulation reveals that our model explains most observations contained in current cosmological data. We emphasize that our conclusion relies solely on general aspects of the energy-momentum dispersion-relation, and is independent of any implicit forms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3152}
{"prompt": "Rephrase the abstract of an article with title 'Dynamic Effects Increasing Network Vulnerability to Cascading Failures'.\n  We study cascading failures in networks using a dynamical flow model based on\nsimple conservation and distribution laws to investigate the impact of\ntransient dynamics caused by the rebalancing of loads after an initial network\nfailure (triggering event). It is found that considering the flow dynamics may\nimply reduced network robustness compared to previous static overload failure\nmodels. This is due to the transient oscillations or overshooting in the loads,\nwhen the flow dynamics adjusts to the new (remaining) network structure. We\nobtain {\\em upper} and {\\em lower} limits to network robustness, and it is\nshown that {\\it two} time scales $\\tau$ and $\\tau_0$, defined by the network\ndynamics, are important to consider prior to accurately addressing network\nrobustness or vulnerability. The robustness of networks showing cascading\nfailures is generally determined by a complex interplay between the network\ntopology and flow dynamics, where the ratio $\\chi=\\tau/\\tau_0$ determines the\nrelative role of the two of them.\n\n", "human_text": "  We study cascading failures in networks using a dynamical flow model based on\nsimple conservation and distribution laws to investigate the impact of\ntransient dynamics caused by the rebalancing of loads after an initial network\nfailure (triggering event). It is found that considering the flow dynamics may\nimply reduced network robustness compared to previous static overload failure\nmodels. This is due to the transient oscillations or overshooting in the loads,\nwhen the flow dynamics adjusts to the new (remaining) network structure. We\nobtain {\\em upper} and {\\em lower} limits to network robustness, and it is\nshown that {\\it two} time scales $\\tau$ and $\\tau_0$, defined by the network\ndynamics, are important to consider prior to accurately addressing network\nrobustness or vulnerability. The robustness of networks showing cascading\nfailures is generally determined by a complex interplay between the network\ntopology and flow dynamics, where the ratio $\\chi=\\tau/\\tau_0$ determines the\nrelative role of the two of them.\n", "machine_text": "This work investigates how dynamics increases the vulnerability of networks to cascading failures. Using a conservation and distribution model based on flow, it is established that the dynamic factor has a negative impact on the robustness of the network relative to static overload models. By providing upper and lower network robustness thresholds, an interplay between the network topology, flow dynamics, and the ratio $\\chi$ of time scales $\\tau$ and $\\tau_0$ is recognized as determining the full extent of vulnerabilities to cascading failures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1952}
{"prompt": "Rephrase the abstract of an article with title 'Broad-band Spectral Evolution of Scorpius X-1 along its Color-Color\n  Diagram'.\n  We analyze a large collection of RXTE archive data from April 1997 to August\n2003 of the bright X-ray source Scorpius X-1 in order to study the broadband\nspectral evolution of the source for different values of the inferred mass\naccretion rate by studying energy spectra from selected regions in the Z-track\nof its Color-Color Diagram. A two-component model, consisting of a soft thermal\ncomponent interpreted as thermal emission from an accretion disk and a thermal\nComptonization component, is unable to fit the whole 3--200 keV energy spectrum\nat low accretion rates. Strong residuals in the highest energy band of the\nspectrum require the addition of a third component that can be fitted with a\npower-law component, that could represent a second thermal Comptonization from\na much hotter plasma, or a hybrid thermal/non-thermal Comptonization. We\ndiscuss the physical implications derived from the results of our analysis,\nwith a particular emphasis on the hardest part of the X-ray emission and its\npossible origins.\n\n", "human_text": "  We analyze a large collection of RXTE archive data from April 1997 to August\n2003 of the bright X-ray source Scorpius X-1 in order to study the broadband\nspectral evolution of the source for different values of the inferred mass\naccretion rate by studying energy spectra from selected regions in the Z-track\nof its Color-Color Diagram. A two-component model, consisting of a soft thermal\ncomponent interpreted as thermal emission from an accretion disk and a thermal\nComptonization component, is unable to fit the whole 3--200 keV energy spectrum\nat low accretion rates. Strong residuals in the highest energy band of the\nspectrum require the addition of a third component that can be fitted with a\npower-law component, that could represent a second thermal Comptonization from\na much hotter plasma, or a hybrid thermal/non-thermal Comptonization. We\ndiscuss the physical implications derived from the results of our analysis,\nwith a particular emphasis on the hardest part of the X-ray emission and its\npossible origins.\n", "machine_text": "\nThis study looks into the broadband spectral evolution of Scorpius X-1 by utilizing RXTE archived data from April 1997 to August 2003. We utilize its Color-Color Diagram to make inferences of the mass accretion rate. Through an energy spectra acquired from regions of its Color-Color Diagram, we were able to develop a two-component model made up of a soft thermal component interpreted as thermal emission coming from an accretion disk, and a thermal Comptonization component. Additionally, new evidence suggests the need for an extra third component, which can be shown as a power-law component to represent a second thermal Comptonization from a much hotter plasma, or a hybrid thermal/non-thermal Comptonization. Our analyses and its implications are discussed, with a critical focus on the hardest X-ray emission and the possible causes for it.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4172}
{"prompt": "Rephrase the abstract of an article with title 'Optical implementation and entanglement distribution in Gaussian valence\n  bond states'.\n  We study Gaussian valence bond states of continuous variable systems,\nobtained as the outputs of projection operations from an ancillary space of M\ninfinitely entangled bonds connecting neighboring sites, applied at each of $N$\nsites of an harmonic chain. The entanglement distribution in Gaussian valence\nbond states can be controlled by varying the input amount of entanglement\nengineered in a (2M+1)-mode Gaussian state known as the building block, which\nis isomorphic to the projector applied at a given site. We show how this\nmechanism can be interpreted in terms of multiple entanglement swapping from\nthe chain of ancillary bonds, through the building blocks. We provide optical\nschemes to produce bisymmetric three-mode Gaussian building blocks (which\ncorrespond to a single bond, M=1), and study the entanglement structure in the\noutput Gaussian valence bond states. The usefulness of such states for quantum\ncommunication protocols with continuous variables, like telecloning and\nteleportation networks, is finally discussed.\n\n", "human_text": "  We study Gaussian valence bond states of continuous variable systems,\nobtained as the outputs of projection operations from an ancillary space of M\ninfinitely entangled bonds connecting neighboring sites, applied at each of $N$\nsites of an harmonic chain. The entanglement distribution in Gaussian valence\nbond states can be controlled by varying the input amount of entanglement\nengineered in a (2M+1)-mode Gaussian state known as the building block, which\nis isomorphic to the projector applied at a given site. We show how this\nmechanism can be interpreted in terms of multiple entanglement swapping from\nthe chain of ancillary bonds, through the building blocks. We provide optical\nschemes to produce bisymmetric three-mode Gaussian building blocks (which\ncorrespond to a single bond, M=1), and study the entanglement structure in the\noutput Gaussian valence bond states. The usefulness of such states for quantum\ncommunication protocols with continuous variables, like telecloning and\nteleportation networks, is finally discussed.\n", "machine_text": "This paper examines Gaussian valence bond states generated from a projection of an auxiliary space containing M joined pairs of links attached at each of N sites within a harmonic chain. By manipulating the input level of entanglement of a (2M+1)-mode Gaussian component known as the building block, we investigate the transmission of entangled bonds throughout the system. To illustrate, we illustrate an optical method of creating symmetrical three-mode Gaussian building blocks (which signify a single bond, M=1) and review the entanglement structure in the output Gaussian valence bond states. Lastly, we comment on how these states can be employed for continuous variable quantum communication protocols such as telecloning and teleportation networks.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.158}
{"prompt": "Rephrase the abstract of an article with title 'X-ray Flares in Orion Low Mass Stars'.\n  Context. X-ray flares are common phenomena in pre-main sequence stars. Their\nanalysis gives insights into the physics at work in young stellar coronae. The\nOrion Nebula Cluster offers a unique opportunity to study large samples of\nyoung low mass stars. This work is part of the Chandra Orion Ultradeep project\n(COUP), an ~10 day long X-ray observation of the Orion Nebula Cluster (ONC).\nAims. Our main goal is to statistically characterize the flare-like variability\nof 165 low mass (0.1-0.3 M_sun) ONC members in order to test and constrain the\nphysical scenario in which flares explain all the observed emission. Methods.\nWe adopt a maximum likelihood piece-wise representation of the observed X-ray\nlight curves and detect flares by taking into account both the amplitude and\ntime derivative of the count-rate. We then derive the frequency and energy\ndistribution of the flares. Results. The high energy tail of the energy\ndistribution of flares is well described by a power-law with index 2.2. We test\nthe hypothesis that light curves are built entirely by overlapping flares with\na single power law energy distribution. We constrain the parameters of this\nsimple model for every single light curve. The analysis of synthetic light\ncurves obtained from the model indicates a good agreement with the observed\ndata. Comparing low mass stars with stars in the mass interval (0.9-1.2M_sun),\nwe establish that, at ~1 Myr, low mass and solar mass stars of similar X-ray\nluminosity have very similar flare frequencies. Conclusions. Our observational\nresults are consistent with the following model/scenario: the light curves are\nentirely built by over- lapping flares with a power-law intensity distribution;\nthe intense flares are individually detected, while the weak ones merge and\nform a pseudo-quiescent level, which we indicate as the characteristic level.\n\n", "human_text": "  Context. X-ray flares are common phenomena in pre-main sequence stars. Their\nanalysis gives insights into the physics at work in young stellar coronae. The\nOrion Nebula Cluster offers a unique opportunity to study large samples of\nyoung low mass stars. This work is part of the Chandra Orion Ultradeep project\n(COUP), an ~10 day long X-ray observation of the Orion Nebula Cluster (ONC).\nAims. Our main goal is to statistically characterize the flare-like variability\nof 165 low mass (0.1-0.3 M_sun) ONC members in order to test and constrain the\nphysical scenario in which flares explain all the observed emission. Methods.\nWe adopt a maximum likelihood piece-wise representation of the observed X-ray\nlight curves and detect flares by taking into account both the amplitude and\ntime derivative of the count-rate. We then derive the frequency and energy\ndistribution of the flares. Results. The high energy tail of the energy\ndistribution of flares is well described by a power-law with index 2.2. We test\nthe hypothesis that light curves are built entirely by overlapping flares with\na single power law energy distribution. We constrain the parameters of this\nsimple model for every single light curve. The analysis of synthetic light\ncurves obtained from the model indicates a good agreement with the observed\ndata. Comparing low mass stars with stars in the mass interval (0.9-1.2M_sun),\nwe establish that, at ~1 Myr, low mass and solar mass stars of similar X-ray\nluminosity have very similar flare frequencies. Conclusions. Our observational\nresults are consistent with the following model/scenario: the light curves are\nentirely built by over- lapping flares with a power-law intensity distribution;\nthe intense flares are individually detected, while the weak ones merge and\nform a pseudo-quiescent level, which we indicate as the characteristic level.\n", "machine_text": "This work analyzes X-ray flares in 165 low-mass pre-main sequence stars in the Orion Nebula Cluster using theorights and methods of the Chandra Orion Ultradeep project. Maximum likelihood piece-wise representation of the observed X-ray light curves allows us to detect flares by considering both their amplitude and time derivative. We derive the frequency and energy distribution of the flares and find the high energy tail follows a power-law with index 2.2. Synthetic light curves made from the model match the observed data, suggesting the light curves are built from a population of overlapping flares with a single power law energy distribution. Comparing low and solar mass stars, we find at ~1 Myr, similar X-ray luminosities have similar flare frequencies. This supports a model in which the observed light curves are derived from overlapping flares with a power-law intensity distribution and a characteristic level from weak flares merged together.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.15}
{"prompt": "Rephrase the abstract of an article with title 'Late-time emission of type Ia supernovae: optical and near-infrared\n  observations of SN 2001el'.\n  We present optical and near-infrared light curves of SN 2001el from 310 to\n445 days past maximum light, obtained with the Very Large Telescope. The\nlate-time optical (UBVRI) light curves decay in a nearly linear fashion with\ndecay time scales of 1.43\\pm0.14, 1.43\\pm0.06, 1.48\\pm0.06, 1.45\\pm0.07, and\n1.03\\pm0.07 magnitudes (per hundred days) in the U, B, V, R and I bands,\nrespectively. In contrast, in the near-infrared (JHKs) bands the time evolution\nof the flux appears to be nearly constant at these epochs. We measure decline\nrates (per hundred days) of 0.19\\pm0.10 and 0.17\\pm0.11 magnitudes in the J and\nH bands, respectively. We construct a UVOIR light curve, and find that the\nlate-time luminosity has a decay time scale nearly consistent with complete\ndepostion of positron kinetic energy. The late-time light curves of the normal\ntype Ia SN 2001el demonstrate the increased importance of the near-infrared\ncontribution. This was previously observed in the peculiar SN 2000cx, and the\nresults for SN 2001el thus ensure that the conclusions previously based on a\nsingle peculiar event are applicable to normal type Ia supernovae. The measured\nlate-time UVOIR decline rate suggests that a majority of the positrons are\ntrapped within the ejecta. This results does not favor the predictions of a\nweak and/or radially combed magnetic field configuration.\n\n", "human_text": "  We present optical and near-infrared light curves of SN 2001el from 310 to\n445 days past maximum light, obtained with the Very Large Telescope. The\nlate-time optical (UBVRI) light curves decay in a nearly linear fashion with\ndecay time scales of 1.43\\pm0.14, 1.43\\pm0.06, 1.48\\pm0.06, 1.45\\pm0.07, and\n1.03\\pm0.07 magnitudes (per hundred days) in the U, B, V, R and I bands,\nrespectively. In contrast, in the near-infrared (JHKs) bands the time evolution\nof the flux appears to be nearly constant at these epochs. We measure decline\nrates (per hundred days) of 0.19\\pm0.10 and 0.17\\pm0.11 magnitudes in the J and\nH bands, respectively. We construct a UVOIR light curve, and find that the\nlate-time luminosity has a decay time scale nearly consistent with complete\ndepostion of positron kinetic energy. The late-time light curves of the normal\ntype Ia SN 2001el demonstrate the increased importance of the near-infrared\ncontribution. This was previously observed in the peculiar SN 2000cx, and the\nresults for SN 2001el thus ensure that the conclusions previously based on a\nsingle peculiar event are applicable to normal type Ia supernovae. The measured\nlate-time UVOIR decline rate suggests that a majority of the positrons are\ntrapped within the ejecta. This results does not favor the predictions of a\nweak and/or radially combed magnetic field configuration.\n", "machine_text": "\nWe explore the late-time optical and near-infrared light curves of SN 2001el and their contribution from 310 to 445 days post the peak brightness. The UBVRI bands are found to have an even, linear decay with time constants of 1.43\\pm0.14, 1.43\\pm0.06, 1.48\\pm0.06, 1.45\\pm0.07, and 1.03\\pm0.07 magnitudes (each hundred days), respectively. Meanwhile, the JHKs bands display a more nearly-constant rate in the same period, with 0.19\\pm0.10 and 0.17\\pm0.11 magnitudes (each hundred days) in J and H, respectively. Compiling the ultraviolet, optical, infrared (UVOIR) luminosity has a decay time that closely coincides with the kinetic energy of positrons. It is seen, therefore, that a significant amount of energy resides in the near-infrared components of the light curve, which was previously observed in the peculiar SN 2000cx and not restricted to it. The UVOIR output is a sign of the positrons being trapped within the ejecta, conflicting with predictions of a weak and/or radially oriented magnetic field configuration.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2381}
{"prompt": "Rephrase the abstract of an article with title 'The Habitat Segregation between Lyman Break Galaxies and Lyman alpha\n  Emitters around a QSO at z~5'.\n  We carried out a target survey for Lyman break galaxies (LBGs) and Lyman\nalpha emitters (LAEs) around QSO SDSS J0211-0009 at z=4.87. The deep and wide\nbroadband and narrowband imaging simultaneously revealed the perspective\nstructure of these two high-z populations. The LBGs without Ly-alpha emission\nform a filamentary structure including the QSO, while the LAEs are distributed\naround the QSO but avoid it within a distance of ~4.5Mpc. On the other hand, we\nserendipitously discovered a protocluster with a significant concentration of\nLBGs and LAEs where no strongly UV ionizing source such as a QSO or radio\ngalaxy is known to exist. In this cluster field, two populations are spatially\ncross-correlated with each other. The relative spatial distribution of LAEs to\nLBGs is in stark contrast between the QSO and the cluster fields. We also found\na weak trend showing that the number counts based on Ly-alpha and UV continuum\nfluxes of LAEs in the QSO field are slightly lower than in the cluster field,\nwhereas the number counts of LBGs are almost consistent with each other. The\nLAEs avoid the nearby region around the QSO where the local UV background\nradiation could be ~100 times stronger than the average for the epoch. The\nclustering segregation between LBGs and LAEs seen in the QSO field could be due\nto either enhanced early galaxy formation in an overdense environment having\ncaused all the LAEs to evolve into LBGs, or local photoionization due to the\nstrong UV radiation from the QSO effectively causing a deficit in low-mass\ngalaxies like LAEs.\n\n", "human_text": "  We carried out a target survey for Lyman break galaxies (LBGs) and Lyman\nalpha emitters (LAEs) around QSO SDSS J0211-0009 at z=4.87. The deep and wide\nbroadband and narrowband imaging simultaneously revealed the perspective\nstructure of these two high-z populations. The LBGs without Ly-alpha emission\nform a filamentary structure including the QSO, while the LAEs are distributed\naround the QSO but avoid it within a distance of ~4.5Mpc. On the other hand, we\nserendipitously discovered a protocluster with a significant concentration of\nLBGs and LAEs where no strongly UV ionizing source such as a QSO or radio\ngalaxy is known to exist. In this cluster field, two populations are spatially\ncross-correlated with each other. The relative spatial distribution of LAEs to\nLBGs is in stark contrast between the QSO and the cluster fields. We also found\na weak trend showing that the number counts based on Ly-alpha and UV continuum\nfluxes of LAEs in the QSO field are slightly lower than in the cluster field,\nwhereas the number counts of LBGs are almost consistent with each other. The\nLAEs avoid the nearby region around the QSO where the local UV background\nradiation could be ~100 times stronger than the average for the epoch. The\nclustering segregation between LBGs and LAEs seen in the QSO field could be due\nto either enhanced early galaxy formation in an overdense environment having\ncaused all the LAEs to evolve into LBGs, or local photoionization due to the\nstrong UV radiation from the QSO effectively causing a deficit in low-mass\ngalaxies like LAEs.\n", "machine_text": "\nWe conducted an observational survey of LBGs and LAEs surrounding QSO SDSS J0211-0009 located at z=4.87. The combination of broad- and narrow-band imaging methods uncovered a singular structural difference between the two populations of high-z objects: the LBGs void of Ly-alpha emission lived in a filament-like structure centered on the QSO, while the LAEs resided away from the QSO, within a distance of ~4.5Mpc. Additionally, we discovered a large concentration of LBGs and LAEs in a clustering context after chance encounter, with no obvious strong UV ionizing sources in the region -- such as a QSO or a radio galaxy -- known to exist. Furthermore, we noted that LAEs and LBGs had significantly different spatial distributions in the QSO field, as opposed to the observation of majority correlation in the protocluster field. A slight fall in the number count of LAEs in the QSO field in comparison to the protocluster field was seen under both Ly-alpha and UV continuum flux parameters, which suggests that deadly amounts of UV radiation from the QSO is particularly affecting the low-mass galaxies and resulting in the growth of LBGs. Consequently, the segregation between Lyman break galaxies and Lyman Alpha Emitters can be accounted to either accelerated early galaxy formation in an overdense environment, or local photoionization by the QSO.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2238}
{"prompt": "Rephrase the abstract of an article with title 'Mesoscopic fluctuations of the supercurrent in diffusive Josephson\n  junctions'.\n  We study mesoscopic fluctuations and weak localization correction to the\nsupercurrent in Josephson junctions with coherent diffusive electron dynamics\nin the normal part. Two kinds of junctions are considered: a chaotic dot\ncoupled to superconductors by tunnel barriers and a diffusive junction with\ntransparent normal--superconducting interfaces. The amplitude of current\nfluctuations and the weak localization correction to the average current are\ncalculated as functions of the ratio between the superconducting gap and the\nelectron dwell energy, temperature, and superconducting phase difference across\nthe junction. Technically, fluctuations on top of the spatially inhomogeneous\nproximity effect in the normal region are described by the replicated version\nof the \\sigma-model. For the case of diffusive junctions with transparent\ninterfaces, the magnitude of mesoscopic fluctuations of the critical current\nappears to be nearly 3 times larger than the prediction of the previous theory\nwhich did not take the proximity effect into account.\n\n", "human_text": "  We study mesoscopic fluctuations and weak localization correction to the\nsupercurrent in Josephson junctions with coherent diffusive electron dynamics\nin the normal part. Two kinds of junctions are considered: a chaotic dot\ncoupled to superconductors by tunnel barriers and a diffusive junction with\ntransparent normal--superconducting interfaces. The amplitude of current\nfluctuations and the weak localization correction to the average current are\ncalculated as functions of the ratio between the superconducting gap and the\nelectron dwell energy, temperature, and superconducting phase difference across\nthe junction. Technically, fluctuations on top of the spatially inhomogeneous\nproximity effect in the normal region are described by the replicated version\nof the \\sigma-model. For the case of diffusive junctions with transparent\ninterfaces, the magnitude of mesoscopic fluctuations of the critical current\nappears to be nearly 3 times larger than the prediction of the previous theory\nwhich did not take the proximity effect into account.\n", "machine_text": "\nThe present research investigates the mesoscopic fluctuations and weak localization corrections on the supercurrent in Josephson junctions involving diffusive electron motion in their normal parts. Two distinct types of junction - a chaotic dot with tunnel barriers between it and the superconductors, and a diffusive junction with transparent interfaces - are studied. The current fluctuations, along with the weak localization corrections in relation to the average current, are established as a function of certain parameters including the ratio between the superconducting gap and the electron dwell energy, the temperature and the phase difference across the junction. To consider the inhomogeneous proximity effect of the normal region, the replicated version of the \\sigma-model is applied. In the case of a diffusive junction with transparent interfaces, the mesoscopic fluctuations of the critical current appear to be is nearly 3 times higher than the previous estimates when taking the proximity effect into account.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3436}
{"prompt": "Rephrase the abstract of an article with title 'The beta function of gauge theories at two loops in differential\n  renormalization'.\n  This PhD thesis is devoted to show that differential renormalization is a\nsimple and useful renormalization method that we can use when dealing with\ngauge theories. In this work, it is shown how the one-loop results of\nConstraint Differential Renormalization can be fruitfully applied when\nrenormalizing two-loop amplitudes. As an example of this procedure, the\ntwo-loop beta functions of various relevant gauge theories are obtained (QED,\nSuperQED, Yang-Mills and N=1 SuperYM) without making use of the Ward\nidentities, which are mandatory in the standard differential renormalization\nprocedure. Also, we study how to deal with expressions that have IR and UV\ndivergences, showing that both are renormalized with independent scales. This\nresult allow us to give new insight on the origin of the higher order\ncorrections to the beta function of the N=1 SuperYM theory, as in this case we\nhave both divergences due to the form of the gauge propagator. This is an\nadvantage over usual dimensional regularization methods, where both divergences\nbecome mixed.\n\n", "human_text": "  This PhD thesis is devoted to show that differential renormalization is a\nsimple and useful renormalization method that we can use when dealing with\ngauge theories. In this work, it is shown how the one-loop results of\nConstraint Differential Renormalization can be fruitfully applied when\nrenormalizing two-loop amplitudes. As an example of this procedure, the\ntwo-loop beta functions of various relevant gauge theories are obtained (QED,\nSuperQED, Yang-Mills and N=1 SuperYM) without making use of the Ward\nidentities, which are mandatory in the standard differential renormalization\nprocedure. Also, we study how to deal with expressions that have IR and UV\ndivergences, showing that both are renormalized with independent scales. This\nresult allow us to give new insight on the origin of the higher order\ncorrections to the beta function of the N=1 SuperYM theory, as in this case we\nhave both divergences due to the form of the gauge propagator. This is an\nadvantage over usual dimensional regularization methods, where both divergences\nbecome mixed.\n", "machine_text": "\nIn this thesis, differential renormalization is proposed as a straightforward\nrenormalization approach for analyzing perturbative gauge theories. The\nutility of the one-loop findings of the Constrained Differential\nRenormalization is then highlighted for treating two-loop amplitudes and\nworks. Particular attention is paid to the two-loop beta functions of\ndifferent pertinent gauge theories like QED, SuperQED, Yang-Mills, and N=1\nSuperYM. This is accomplished without relying on the Ward identities usually\nobligatory while using the typical differential renormalization\nprocedure. The study also discloses how to treat expressions comprising\nboth ultraviolet and infrared divergences and is successful in\ndemonstrating that these diversities are regulated through independent\nscales. This outcome bestows new ideas concerning the source of higher-order\ncorrections to the beta function of the N=1 SuperYM theory since, in this\ncase, divergences owing to the shape of the gauge propagator are both\nvisible. In contrast, usual dimensional regularization methods blur both\ndivergences into one.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1793}
{"prompt": "Rephrase the abstract of an article with title 'Position-Velocity Diagrams for the Maser Emission coming from a\n  Keplerian Ring'.\n  We have studied the maser emission from a thin, planar, gaseous ring in\nKeplerian rotation around a central mass observed edge-on. The absorption\ncoefficient within the ring is assumed to follow a power law dependence with\nthe distance from the central mass as, k=k0r^{-q}. We have calculated\nposition-velocity diagrams for the most intense maser features, for different\nvalues of the exponent q. We have found that, depending on the value of q,\nthese diagrams can be qualitatively different. The most intense maser emission\nat a given velocity can either come mainly from regions close to the inner or\nouter edges of the amplifying ring or from the line perpendicular to the line\nof sight and passing through the central mass (as is commonly assumed).\nParticularly, when q>1 the position-velocity diagram is qualitatively similar\nto the one observed for the water maser emission in the nucleus of the galaxy\nNGC 4258. In the context of this simple model, we conclude that in this object\nthe absorption coefficient depends on the radius of the amplifying ring as a\ndecreasing function, in order to have significant emission coming from the\ninner edge of the ring.\n\n", "human_text": "  We have studied the maser emission from a thin, planar, gaseous ring in\nKeplerian rotation around a central mass observed edge-on. The absorption\ncoefficient within the ring is assumed to follow a power law dependence with\nthe distance from the central mass as, k=k0r^{-q}. We have calculated\nposition-velocity diagrams for the most intense maser features, for different\nvalues of the exponent q. We have found that, depending on the value of q,\nthese diagrams can be qualitatively different. The most intense maser emission\nat a given velocity can either come mainly from regions close to the inner or\nouter edges of the amplifying ring or from the line perpendicular to the line\nof sight and passing through the central mass (as is commonly assumed).\nParticularly, when q>1 the position-velocity diagram is qualitatively similar\nto the one observed for the water maser emission in the nucleus of the galaxy\nNGC 4258. In the context of this simple model, we conclude that in this object\nthe absorption coefficient depends on the radius of the amplifying ring as a\ndecreasing function, in order to have significant emission coming from the\ninner edge of the ring.\n", "machine_text": "\nWe have studied the effects of maser emission originating from a thin, flat gaseous ring orbiting around a central mass, configured edge-on. The power law relation k=k0r^{-q}, which describes the absorption coefficient as a function of distance from the central mass, was used to calculate the Position-Velocity (PV) diagrams for various values of the exponent q. Our results unearthed significant differences in the PV diagrams depending on the value of q. In particular, the most intense maser features may originate from either the inner or outer rings of the amplifying object, or from the region nearest to the central mass, contrary to the commonly assumed scenario.  Our calculations indicate that, in the case of NGC 4258, a decreasing absorption coefficient with increasing radius of the amplifying ring is needed in order to generate strong maser emission at the ring's inner edge.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0819}
{"prompt": "Rephrase the abstract of an article with title 'Spectral Efficiency of Spectrum Pooling Systems'.\n  In this contribution, we investigate the idea of using cognitive radio to\nreuse locally unused spectrum to increase the total system capacity. We\nconsider a multiband/wideband system in which the primary and cognitive users\nwish to communicate to different receivers, subject to mutual interference and\nassume that each user knows only his channel and the unused spectrum through\nadequate sensing. The basic idea under the proposed scheme is based on the\nnotion of spectrum pooling. The idea is quite simple: a cognitive radio will\nlisten to the channel and, if sensed idle, will transmit during the voids. It\nturns out that, although its simplicity, the proposed scheme showed very\ninteresting features with respect to the spectral efficiency and the maximum\nnumber of possible pairwise cognitive communications. We impose the constraint\nthat users successively transmit over available bands through selfish water\nfilling. For the first time, our study has quantified the asymptotic (with\nrespect to the band) achievable gain of using spectrum pooling in terms of\nspectral efficiency compared to classical radio systems. We then derive the\ntotal spectral efficiency as well as the maximum number of possible pairwise\ncommunications of such a spectrum pooling system.\n\n", "human_text": "  In this contribution, we investigate the idea of using cognitive radio to\nreuse locally unused spectrum to increase the total system capacity. We\nconsider a multiband/wideband system in which the primary and cognitive users\nwish to communicate to different receivers, subject to mutual interference and\nassume that each user knows only his channel and the unused spectrum through\nadequate sensing. The basic idea under the proposed scheme is based on the\nnotion of spectrum pooling. The idea is quite simple: a cognitive radio will\nlisten to the channel and, if sensed idle, will transmit during the voids. It\nturns out that, although its simplicity, the proposed scheme showed very\ninteresting features with respect to the spectral efficiency and the maximum\nnumber of possible pairwise cognitive communications. We impose the constraint\nthat users successively transmit over available bands through selfish water\nfilling. For the first time, our study has quantified the asymptotic (with\nrespect to the band) achievable gain of using spectrum pooling in terms of\nspectral efficiency compared to classical radio systems. We then derive the\ntotal spectral efficiency as well as the maximum number of possible pairwise\ncommunications of such a spectrum pooling system.\n", "machine_text": "\nThis article examines the concept of using spectrum pooling to achieve improved spectral efficiency in multiband/wideband systems via the utilization of cognitive radio. We assume that primary and cognitive users are attempting to reach different receivers, while being aware of interference and their channel condition. The goal of this study is to assess the peak performance of a spectrum pooling system due to its simplicity. We impose the constraint that users transmit over available bands through selfish water filling algorithms. Our research has determined the asymptotic gain in spectral efficiency achieved through this technique, and also will quantify the total spectral efficiency as well as the number of potential pairwise cognitive communications that can be established.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3025}
{"prompt": "Rephrase the abstract of an article with title 'Spatial and kinematic alignments between central and satellite halos'.\n  Based on a cosmological N-body simulation we analyze spatial and kinematic\nalignments of satellite halos within six times the virial radius of group size\nhost halos (Rvir). We measure three different types of spatial alignment: halo\nalignment between the orientation of the group central substructure (GCS) and\nthe distribution of its satellites, radial alignment between the orientation of\na satellite and the direction towards its GCS, and direct alignment between the\norientation of the GCS and that of its satellites. In analogy we use the\ndirections of satellite velocities and probe three further types of alignment:\nthe radial velocity alignment between the satellite velocity and connecting\nline between satellite and GCS, the halo velocity alignment between the\norientation of the GCS and satellite velocities and the auto velocity alignment\nbetween the satellites orientations and their velocities. We find that\nsatellites are preferentially located along the major axis of the GCS within at\nleast 6 Rvir (the range probed here). Furthermore, satellites preferentially\npoint towards the GCS. The most pronounced signal is detected on small scales\nbut a detectable signal extends out to 6 Rvir. The direct alignment signal is\nweaker, however a systematic trend is visible at distances < 2 Rvir. All\nvelocity alignments are highly significant on small scales. Our results suggest\nthat the halo alignment reflects the filamentary large scale structure which\nextends far beyond the virial radii of the groups. In contrast, the main\ncontribution to the radial alignment arises from the adjustment of the\nsatellite orientations in the group tidal field. The projected data reveal good\nagreement with recent results derived from large galaxy surveys. (abridged)\n\n", "human_text": "  Based on a cosmological N-body simulation we analyze spatial and kinematic\nalignments of satellite halos within six times the virial radius of group size\nhost halos (Rvir). We measure three different types of spatial alignment: halo\nalignment between the orientation of the group central substructure (GCS) and\nthe distribution of its satellites, radial alignment between the orientation of\na satellite and the direction towards its GCS, and direct alignment between the\norientation of the GCS and that of its satellites. In analogy we use the\ndirections of satellite velocities and probe three further types of alignment:\nthe radial velocity alignment between the satellite velocity and connecting\nline between satellite and GCS, the halo velocity alignment between the\norientation of the GCS and satellite velocities and the auto velocity alignment\nbetween the satellites orientations and their velocities. We find that\nsatellites are preferentially located along the major axis of the GCS within at\nleast 6 Rvir (the range probed here). Furthermore, satellites preferentially\npoint towards the GCS. The most pronounced signal is detected on small scales\nbut a detectable signal extends out to 6 Rvir. The direct alignment signal is\nweaker, however a systematic trend is visible at distances < 2 Rvir. All\nvelocity alignments are highly significant on small scales. Our results suggest\nthat the halo alignment reflects the filamentary large scale structure which\nextends far beyond the virial radii of the groups. In contrast, the main\ncontribution to the radial alignment arises from the adjustment of the\nsatellite orientations in the group tidal field. The projected data reveal good\nagreement with recent results derived from large galaxy surveys. (abridged)\n", "machine_text": "\nUsing a cosmological N-body simulation, this study examines how satellites of group-sized halos are spatially and kinematically aligned relative to the orientation of the central substructure of their host groups (GCS, six times the virial radius, or Rvir). Three different types of spatial alignment were assessed: (1) the orientation of the GCS relative to its satellites, (2) the orientation of the satellite relative to its GCS, and (3) the direct alignment between the orientation of the GCS and its satellites. For each, three types of velocity alignment were also measured: (1) the velocity of the satellite relative to the connecting line between the satellite and the GCS, (2) the orientation of the GCS relative to the satellite velocities, and (3) the auto-orientation of satellite velocities relative to their orientations. Results showed that satellite halos tended to be distributed along the GCS's major axis up to 6 Rvir. Furthermore, the satellites preferentially pointed in the direction of the GCS, with the greatest signal concentration on small scales detectable up to 6 Rvir. All velocity alignments were found to be particularly marked in short-scale ranges. These results establish contradicting evidence - the halo alignments seeming to reflect extend beyond the virial radius, while the main radial alignments were deemed to derive from the satellites adjusting to the group tidal field. Findings were found to be consistent with those from larger galaxy surveys.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0262}
{"prompt": "Rephrase the abstract of an article with title 'Multimodal nested sampling: an efficient and robust alternative to MCMC\n  methods for astronomical data analysis'.\n  In performing a Bayesian analysis of astronomical data, two difficult\nproblems often emerge. First, in estimating the parameters of some model for\nthe data, the resulting posterior distribution may be multimodal or exhibit\npronounced (curving) degeneracies, which can cause problems for traditional\nMCMC sampling methods. Second, in selecting between a set of competing models,\ncalculation of the Bayesian evidence for each model is computationally\nexpensive. The nested sampling method introduced by Skilling (2004), has\ngreatly reduced the computational expense of calculating evidences and also\nproduces posterior inferences as a by-product. This method has been applied\nsuccessfully in cosmological applications by Mukherjee et al. (2006), but their\nimplementation was efficient only for unimodal distributions without pronounced\ndegeneracies. Shaw et al. (2007), recently introduced a clustered nested\nsampling method which is significantly more efficient in sampling from\nmultimodal posteriors and also determines the expectation and variance of the\nfinal evidence from a single run of the algorithm, hence providing a further\nincrease in efficiency. In this paper, we build on the work of Shaw et al. and\npresent three new methods for sampling and evidence evaluation from\ndistributions that may contain multiple modes and significant degeneracies; we\nalso present an even more efficient technique for estimating the uncertainty on\nthe evaluated evidence. These methods lead to a further substantial improvement\nin sampling efficiency and robustness, and are applied to toy problems to\ndemonstrate the accuracy and economy of the evidence calculation and parameter\nestimation. Finally, we discuss the use of these methods in performing Bayesian\nobject detection in astronomical datasets.\n\n", "human_text": "  In performing a Bayesian analysis of astronomical data, two difficult\nproblems often emerge. First, in estimating the parameters of some model for\nthe data, the resulting posterior distribution may be multimodal or exhibit\npronounced (curving) degeneracies, which can cause problems for traditional\nMCMC sampling methods. Second, in selecting between a set of competing models,\ncalculation of the Bayesian evidence for each model is computationally\nexpensive. The nested sampling method introduced by Skilling (2004), has\ngreatly reduced the computational expense of calculating evidences and also\nproduces posterior inferences as a by-product. This method has been applied\nsuccessfully in cosmological applications by Mukherjee et al. (2006), but their\nimplementation was efficient only for unimodal distributions without pronounced\ndegeneracies. Shaw et al. (2007), recently introduced a clustered nested\nsampling method which is significantly more efficient in sampling from\nmultimodal posteriors and also determines the expectation and variance of the\nfinal evidence from a single run of the algorithm, hence providing a further\nincrease in efficiency. In this paper, we build on the work of Shaw et al. and\npresent three new methods for sampling and evidence evaluation from\ndistributions that may contain multiple modes and significant degeneracies; we\nalso present an even more efficient technique for estimating the uncertainty on\nthe evaluated evidence. These methods lead to a further substantial improvement\nin sampling efficiency and robustness, and are applied to toy problems to\ndemonstrate the accuracy and economy of the evidence calculation and parameter\nestimation. Finally, we discuss the use of these methods in performing Bayesian\nobject detection in astronomical datasets.\n", "machine_text": "\nThe estimation of parameters and selection between a set of models for an astronomical data can be challenging tasks due to the presence of multimodal posterior distributions and degeneracies. These difficulties can be counteracted with the usage of the nested sampling method proposed by Skilling (2004), which has shown effectiveness in cosmological applications and reduces computational expense. Shaw et al. (2007) introduced a clustered nested sampling method which is more efficient in sampling from multimodal distribution and calculating evidence. This paper provides further development of their method through three additional approaches to sampling and evidence evaluation for distributions containing many modes or degeneracies. These methods considerably reduce the computational burden in accuracy estimation and parameter estimation and are validated with toy problems. Finally, the application of these methods to Bayesian object detection in astronomical datasets is discussed.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3704}
{"prompt": "Rephrase the abstract of an article with title 'The richest superclusters. II. Galaxy populations'.\n  We study the morphology of galaxy populations of the richest superclusters\nfrom the catalogue of superclusters of galaxies in the 2dF Galaxy Redshift\nSurvey using the luminosity density distribution and Minkowski functional V3.\nWe compare the properties of grouped and isolated galaxies in regions of\ndifferent density in superclusters. We find that in high-density cores of rich\nsuperclusters there is an excess of early type, passive galaxies, among\ngalaxies in groups and clusters, as well as among those which do not belong to\ngroups, while in lower density outer regions there are more blue, star-forming\ngalaxies both in groups and among those galaxies which do not belong to groups.\nThis also shows that the galaxy content of groups depends on the environment\nwhere the groups reside in. The density distributions and the behaviour of the\nMinkowski functional V3 for different superclusters show that substructures in\nsuperclusters as traced by different populations of galaxies are very\ndifferent. Our results show that both local (group/cluster) and global\n(supercluster) environments are important in forming galaxy morphologies and\nstar formation activity. The presence of a high density core with X-ray\nclusters and a relatively small fraction of star-forming galaxies in the\nsupercluster SCL126 may be an indication that this supercluster has started its\nevolution earlier than the supercluster SCL9.\n\n", "human_text": "  We study the morphology of galaxy populations of the richest superclusters\nfrom the catalogue of superclusters of galaxies in the 2dF Galaxy Redshift\nSurvey using the luminosity density distribution and Minkowski functional V3.\nWe compare the properties of grouped and isolated galaxies in regions of\ndifferent density in superclusters. We find that in high-density cores of rich\nsuperclusters there is an excess of early type, passive galaxies, among\ngalaxies in groups and clusters, as well as among those which do not belong to\ngroups, while in lower density outer regions there are more blue, star-forming\ngalaxies both in groups and among those galaxies which do not belong to groups.\nThis also shows that the galaxy content of groups depends on the environment\nwhere the groups reside in. The density distributions and the behaviour of the\nMinkowski functional V3 for different superclusters show that substructures in\nsuperclusters as traced by different populations of galaxies are very\ndifferent. Our results show that both local (group/cluster) and global\n(supercluster) environments are important in forming galaxy morphologies and\nstar formation activity. The presence of a high density core with X-ray\nclusters and a relatively small fraction of star-forming galaxies in the\nsupercluster SCL126 may be an indication that this supercluster has started its\nevolution earlier than the supercluster SCL9.\n", "machine_text": "\nIn this study, we explore the galaxy makeup of the most abundant superclusters in the 2dF Galaxy Redshift Survey using luminosity density distributions and the Minkowski functional V3. We compare the properties of grouped and separate galaxies in regions of varying density in superclusters. Results indicate that in major cores of rich superclusters there is an excess of early type, inactive galaxies among both group members and non-members, whereas in areas of lesser density in the outer reaches, there are more star-forming blue galaxies in groups and non-grouped galaxies. This reveals that the content of groups is dependent upon the milieu in which they reside. The arrangement of the luminosity density and the behavior of the Minkowski functional V3 for different superclusters reveal considerable variance between supercluster substructures. It is concluded from this research that not only local (group/cluster) but also overall (supercluster) conditions play vital roles in forming galaxy morphology as well as star formation activity. SCL126, with its numerous X-ray clusters in the high-density core and a limited proportion of star-forming galaxies, could be evidence of an earlier start to its development compared to SCL9.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1126}
{"prompt": "Rephrase the abstract of an article with title 'Lifetime Improvement in Wireless Sensor Networks via Collaborative\n  Beamforming and Cooperative Transmission'.\n  Collaborative beamforming (CB) and cooperative transmission (CT) have\nrecently emerged as communication techniques that can make effective use of\ncollaborative/cooperative nodes to create a virtual\nmultiple-input/multiple-output (MIMO) system. Extending the lifetime of\nnetworks composed of battery-operated nodes is a key issue in the design and\noperation of wireless sensor networks. This paper considers the effects on\nnetwork lifetime of allowing closely located nodes to use CB/CT to reduce the\nload or even to avoid packet-forwarding requests to nodes that have critical\nbattery life. First, the effectiveness of CB/CT in improving the signal\nstrength at a faraway destination using energy in nearby nodes is studied.\nThen, the performance improvement obtained by this technique is analyzed for a\nspecial 2D disk case. Further, for general networks in which\ninformation-generation rates are fixed, a new routing problem is formulated as\na linear programming problem, while for other general networks, the cost for\nrouting is dynamically adjusted according to the amount of energy remaining and\nthe effectiveness of CB/CT. From the analysis and the simulation results, it is\nseen that the proposed method can reduce the payloads of energy-depleting nodes\nby about 90% in the special case network considered and improve the lifetimes\nof general networks by about 10%, compared with existing techniques.\n\n", "human_text": "  Collaborative beamforming (CB) and cooperative transmission (CT) have\nrecently emerged as communication techniques that can make effective use of\ncollaborative/cooperative nodes to create a virtual\nmultiple-input/multiple-output (MIMO) system. Extending the lifetime of\nnetworks composed of battery-operated nodes is a key issue in the design and\noperation of wireless sensor networks. This paper considers the effects on\nnetwork lifetime of allowing closely located nodes to use CB/CT to reduce the\nload or even to avoid packet-forwarding requests to nodes that have critical\nbattery life. First, the effectiveness of CB/CT in improving the signal\nstrength at a faraway destination using energy in nearby nodes is studied.\nThen, the performance improvement obtained by this technique is analyzed for a\nspecial 2D disk case. Further, for general networks in which\ninformation-generation rates are fixed, a new routing problem is formulated as\na linear programming problem, while for other general networks, the cost for\nrouting is dynamically adjusted according to the amount of energy remaining and\nthe effectiveness of CB/CT. From the analysis and the simulation results, it is\nseen that the proposed method can reduce the payloads of energy-depleting nodes\nby about 90% in the special case network considered and improve the lifetimes\nof general networks by about 10%, compared with existing techniques.\n", "machine_text": "The current study examines how Collaborative Beamforming (CB) and Cooperative Transmission (CT) can be used to improve the longevity of networks composed of battery-driven nodes. This paper looks at the positive influence that allowing nearby nodes to employ CB/CT to decrease the burden or avoid transmitting requests to nodes with scarce battery life can have. Initially, the authors analyze the effect of CB/CT on the signal strength at a far off destination using energy from local nodes. Subsequently, the improvements gained when applying this technique to a 2D disk case are measured. Additionally, formulating a new routing issue as a linear programming problem is considered for networks in which data generating rates remain constant. Lastly, for more general networks, the cost for routing is adaptively adjusted dependent on the remaining energy, along with the capacity of CB/CT. Outcomes of the research, together with simulation results, demonstrate that the proposed technique can lessen the energy demands of close to depleted nodes by approximately 90% in the specialized case network, while also improving the lifetimes of general networks by approximately 10% compared to other existing techniques.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3391}
{"prompt": "Rephrase the abstract of an article with title 'Stringy E-functions of hypersurfaces and of Brieskorn singularities'.\n  We show that for a hypersurface Batyrev's stringy E-function can be seen as a\nresidue of the Hodge zeta function, a specialization of the motivic zeta\nfunction of Denef and Loeser. This is a nice application of inversion of\nadjunction. If an affine hypersurface is given by a polynomial that is\nnon-degenerate with respect to its Newton polyhedron, then the motivic zeta\nfunction and thus the stringy E-function can be computed from this Newton\npolyhedron (by work of Artal, Cassou-Nogues, Luengo and Melle based on an\nalgorithm of Denef and Hoornaert). We use this procedure to obtain an easy way\nto compute the contribution of a Brieskorn singularity to the stringy\nE-function. As a corollary, we prove that stringy Hodge numbers of varieties\nwith a certain class of strictly canonical Brieskorn singularities are\nnonnegative. We conclude by computing an interesting 6-dimensional example. It\nshows that a result, implying nonnegativity of stringy Hodge numbers in lower\ndimensional cases, obtained in our previous paper, is not true in higher\ndimension.\n\n", "human_text": "  We show that for a hypersurface Batyrev's stringy E-function can be seen as a\nresidue of the Hodge zeta function, a specialization of the motivic zeta\nfunction of Denef and Loeser. This is a nice application of inversion of\nadjunction. If an affine hypersurface is given by a polynomial that is\nnon-degenerate with respect to its Newton polyhedron, then the motivic zeta\nfunction and thus the stringy E-function can be computed from this Newton\npolyhedron (by work of Artal, Cassou-Nogues, Luengo and Melle based on an\nalgorithm of Denef and Hoornaert). We use this procedure to obtain an easy way\nto compute the contribution of a Brieskorn singularity to the stringy\nE-function. As a corollary, we prove that stringy Hodge numbers of varieties\nwith a certain class of strictly canonical Brieskorn singularities are\nnonnegative. We conclude by computing an interesting 6-dimensional example. It\nshows that a result, implying nonnegativity of stringy Hodge numbers in lower\ndimensional cases, obtained in our previous paper, is not true in higher\ndimension.\n", "machine_text": "\nIn this paper we use a method applied by Denef and Loeser to analyze the stringy E-function of a hypersurface via the Hodge zeta function. We employ the inversion of adjunction technique and an algorithm of Denef and Hoornaert, utilized by Artal, Cassou-Nogues, Luengo and Melle, to calculate the motivic zeta function and stringy E-function from a given non-degenerate Newton polyhedron. This approach allows us to determine stringy E-function contributions from Brieskorn singularities. It serves to deduce that the stringy Hodge numbers of varieties with particular types of strictly canonical Brieskorn singularities are all non-negative. Moreover, by computing a six-dimensional example, we show that a result from a prior paper, implying non-negativity of stringy Hodge numbers in lower dimensions, is not true in higher dimensions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0798}
{"prompt": "Rephrase the abstract of an article with title 'Mapping the Youngest Galaxies to Redshift One'.\n  We describe results of a narrow band search for ultra-strong emission line\ngalaxies (USELs) with EW(H beta) > 30 A. 542 candidate galaxies are found in a\nhalf square degree survey using two ~100 Angstrom 8150 A and 9140 A filters\nwith Subaru/SuprimeCam. Followup spectroscopy for randomly selected objects in\nthe sample with KeckII/DEIMOS shows they consist of [OIII] 5007, [OII] 3727,\nand H alpha selected strong-emission line galaxies at intermediate redshifts (z\n< 1), and Ly alpha emitting galaxies at high-redshift (z >> 5). We determine\nthe H beta luminosity functions and the star formation density of the USELs,\nwhich is 5-10% of the value found from ultraviolet continuum objects at z=0-1,\nsuggesting they correspond to a major epoch in galaxy formation at these\nredshifts. Many USELs show the temperature-sensitive [OIII] 4363 auroral lines\nand about a dozen have oxygen abundances characteristic of eXtremely Metal Poor\nGalaxies (XMPGs). These XMPGs are the most distant known today. Our high yield\nrate of XMPGs suggests this is a powerful method for finding such populations.\nThe lowest metallicity measured in our sample is 12+log(O/H) = 7.06\n(6.78-7.44), close to the minimum metallicity found in local galaxies. The\nluminosities, metallicities and star formation rates of USELs are consistent\nwith the strong emitters being start-up intermediate mass galaxies and suggest\nthat galaxies are still forming in relatively chemically pristine sites at z <\n1.\n\n", "human_text": "  We describe results of a narrow band search for ultra-strong emission line\ngalaxies (USELs) with EW(H beta) > 30 A. 542 candidate galaxies are found in a\nhalf square degree survey using two ~100 Angstrom 8150 A and 9140 A filters\nwith Subaru/SuprimeCam. Followup spectroscopy for randomly selected objects in\nthe sample with KeckII/DEIMOS shows they consist of [OIII] 5007, [OII] 3727,\nand H alpha selected strong-emission line galaxies at intermediate redshifts (z\n< 1), and Ly alpha emitting galaxies at high-redshift (z >> 5). We determine\nthe H beta luminosity functions and the star formation density of the USELs,\nwhich is 5-10% of the value found from ultraviolet continuum objects at z=0-1,\nsuggesting they correspond to a major epoch in galaxy formation at these\nredshifts. Many USELs show the temperature-sensitive [OIII] 4363 auroral lines\nand about a dozen have oxygen abundances characteristic of eXtremely Metal Poor\nGalaxies (XMPGs). These XMPGs are the most distant known today. Our high yield\nrate of XMPGs suggests this is a powerful method for finding such populations.\nThe lowest metallicity measured in our sample is 12+log(O/H) = 7.06\n(6.78-7.44), close to the minimum metallicity found in local galaxies. The\nluminosities, metallicities and star formation rates of USELs are consistent\nwith the strong emitters being start-up intermediate mass galaxies and suggest\nthat galaxies are still forming in relatively chemically pristine sites at z <\n1.\n", "machine_text": "\nThis study utilized two narrow band filters, Subaru/SuprimeCam 8150A and 9140A, to survey a half square degree of space and search for ultra-strong emission line galaxies (USELs). After spectral verification with KeckII/DEIMOS, 542 USELs consisting of strong-emission line galaxies of intermediate redshifts (z < 1) and Lyman Alpha emitting galaxies of high redshitfs (z >> 5) were identified. The H beta luminosity functions and star formation density of these USELs were then determined and were found to be 5-10% of the value found from UV continuum objects at similar redshifts, signifying a major epoch of galaxy formation at these redshifts. Many of the USELs showed temperature-sensitive [OIII] 4363 auroral lines and a dozen of these were found to have oxygen abundances characteristic of the most distant XMPGs known today. These XMPGs were found to have low metallicities, close to the minimum found in local galaxies, and their luminosities, metallicities and star formation rates are consistent with them being start-up intermediate mass galaxies, suggesting that galaxies are still being formed in relatively unexplored and chemically pristine sites at z < 1.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0643}
{"prompt": "Rephrase the abstract of an article with title 'A Note on the Inapproximability of Correlation Clustering'.\n  We consider inapproximability of the correlation clustering problem defined\nas follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\"\n(similar) or \"-\" (dissimilar), correlation clustering seeks to partition the\nvertices into clusters so that the number of pairs correctly (resp.\nincorrectly) classified with respect to the labels is maximized (resp.\nminimized). The two complementary problems are called MaxAgree and MinDisagree,\nrespectively, and have been studied on complete graphs, where every edge is\nlabeled, and general graphs, where some edge might not have been labeled.\nNatural edge-weighted versions of both problems have been studied as well. Let\nS-MaxAgree denote the weighted problem where all weights are taken from set S,\nwe show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\delta})$\nessentially belongs to the same hardness class in the following sense: if there\nis a polynomial time algorithm that approximates S-MaxAgree within a factor of\n$\\lambda = O(\\log{|V|})$ with high probability, then for any choice of S',\nS'-MaxAgree can be approximated in polynomial time within a factor of $(\\lambda\n+ \\epsilon)$, where $\\epsilon > 0$ can be arbitrarily small, with high\nprobability. A similar statement also holds for $S-MinDisagree. This result\nimplies it is hard (assuming $NP \\neq RP$) to approximate unweighted MaxAgree\nwithin a factor of $80/79-\\epsilon$, improving upon a previous known factor of\n$116/115-\\epsilon$ by Charikar et. al. \\cite{Chari05}.\n\n", "human_text": "  We consider inapproximability of the correlation clustering problem defined\nas follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\"\n(similar) or \"-\" (dissimilar), correlation clustering seeks to partition the\nvertices into clusters so that the number of pairs correctly (resp.\nincorrectly) classified with respect to the labels is maximized (resp.\nminimized). The two complementary problems are called MaxAgree and MinDisagree,\nrespectively, and have been studied on complete graphs, where every edge is\nlabeled, and general graphs, where some edge might not have been labeled.\nNatural edge-weighted versions of both problems have been studied as well. Let\nS-MaxAgree denote the weighted problem where all weights are taken from set S,\nwe show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\delta})$\nessentially belongs to the same hardness class in the following sense: if there\nis a polynomial time algorithm that approximates S-MaxAgree within a factor of\n$\\lambda = O(\\log{|V|})$ with high probability, then for any choice of S',\nS'-MaxAgree can be approximated in polynomial time within a factor of $(\\lambda\n+ \\epsilon)$, where $\\epsilon > 0$ can be arbitrarily small, with high\nprobability. A similar statement also holds for $S-MinDisagree. This result\nimplies it is hard (assuming $NP \\neq RP$) to approximate unweighted MaxAgree\nwithin a factor of $80/79-\\epsilon$, improving upon a previous known factor of\n$116/115-\\epsilon$ by Charikar et. al. \\cite{Chari05}.\n", "machine_text": "\nIn this report, we examine the difficulty of approximating the correlation clustering problem in polynomial time. This problem involves partitioning a graph $G = (V,E)$, where each edge is labeled either \"+\"(similar) or \"-\"(dissimilar), into clusters in order to maximize the number of pairs correctly/incorrectly classified with respect to their labels. The challenges arise when we consider weighted versions of the problem, and their difficulty increases with the weights bounded by $O(|V|^{1/2-\\delta})$. Our result shows that if there exists a polynomial time algorithm that can approximate the weighted task within a factor of $\\lambda = O(\\log{|V|})$, then for any choice of S', S'-MaxAgree/MinDisagree can be approximated within a factor of $(\\lambda + \\epsilon)$ with high probability, where $\\epsilon > 0$ can be arbitrarily small. This result improves upon Charikar et. al.'s previous known factor of $116/115-\\epsilon$ for the unweighted version of MaxAgree.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2092}
{"prompt": "Rephrase the abstract of an article with title 'UV Caps and Modulus Stabilization for 6D Gauged Chiral Supergravity'.\n  We describe an explicit UV regularization of the brane singularities for all\n4D flat configurations of 6D gauged chiral supergravity compactified on axially\nsymmetric internal spaces (for which the general solutions are known). All such\nsolutions have two or fewer co-dimension two singularities, which we resolve in\nterms of microscopic co-dimension one cylindrical 4-branes, whose interiors are\ncapped using the most general possible 4D flat solution of the 6D field\nequations. By so doing we show that such a cap is always possible for any given\nbulk geometry, and obtain an explicit relationship between the properties of\nthe capped 4-branes and the various parameters which describe the bulk\nsolution. We show how these branes generically stabilize the size of the extra\ndimensions by breaking the scale invariance which relates classical solutions\nto 6D supergravity, and we compute the scalar potential for this modulus in the\n4D effective theory. The lifting of this marginal direction provides a natural\nrealization of the Goldberger-Wise stabilization mechanism in six dimensions.\n\n", "human_text": "  We describe an explicit UV regularization of the brane singularities for all\n4D flat configurations of 6D gauged chiral supergravity compactified on axially\nsymmetric internal spaces (for which the general solutions are known). All such\nsolutions have two or fewer co-dimension two singularities, which we resolve in\nterms of microscopic co-dimension one cylindrical 4-branes, whose interiors are\ncapped using the most general possible 4D flat solution of the 6D field\nequations. By so doing we show that such a cap is always possible for any given\nbulk geometry, and obtain an explicit relationship between the properties of\nthe capped 4-branes and the various parameters which describe the bulk\nsolution. We show how these branes generically stabilize the size of the extra\ndimensions by breaking the scale invariance which relates classical solutions\nto 6D supergravity, and we compute the scalar potential for this modulus in the\n4D effective theory. The lifting of this marginal direction provides a natural\nrealization of the Goldberger-Wise stabilization mechanism in six dimensions.\n", "machine_text": "\nWe present a novel way to regularize the singularities derived from co-dimension two 4-branes in 6D gauged chiral supergravity compactified on axially symmetric internal spaces. This method involves capping the interiors of the branes with a 4D flat solution of the 6D field equations, a process which is always possible for any given bulk geometry. By breaking the scale invariance which connects the classical solutions to 6D supergravity, we show that these brane caps generically stabilize the size of the extra dimensions and calculate the resulting scalar potential in the 4D effective theory. This has the consequence of naturally implementing the Goldberger-Wise stabilization mechanism in six dimensions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3212}
{"prompt": "Rephrase the abstract of an article with title 'An absorption origin for the soft excess in Seyfert 1 AGN'.\n  (abridged) The soft excess seen in the X-ray spectra of many high mass\naccretion rate AGN can be well modelled by reflection from a partially ionised\naccretion disc. However, the derived parameters are often extreme, both in\nterms of the underlying spacetime and the reflection geometry, and these models\nrequire that the disc is far from hydrostatic equilibrium. An alternative model\nuses similarly partially ionised, velocity smeared material but seen in\nabsorption, though again the derived velocities are extreme, requiring magnetic\ndriving (in the jet?) rather than a simple line driven disc wind. We find that\nwhile both models give comparably good fits to XMM--Newton data, we favour the\nabsorption model as, unlike reflection, all the derived spectral indices are\nsoft. This is as expected by analogy with the correspondingly high mass\naccretion rate stellar mass black holes. Furthermore, these X-ray spectra are\nconsistent with a one--to--one mapping between AGN type and spectral state,\nwith NLS1's having softer spectra corresponding to the very high state, while\nthe broad line AGN have Gamma~2 as expected for the high/soft state. We also\nuse the simultaneous OM data to derive the ratio of disc to total accretion\npower which is another tracer of spectral state in X-ray binaries. This does\nnot always show that the disc in NLS1's contributes less than 80 per cent of\nthe total power, as expected for a very high state. We suggest that this is an\nartifact of the standard disc models used to determine the disc luminosity in\nour fits. The disc seen in the very high state of black hole binaries is often\nobserved to be distorted from the standard shape, and a similar effect in\nNLS1's could recover the correspondance between black hole binary spectral\nstate and AGN type.\n\n", "human_text": "  (abridged) The soft excess seen in the X-ray spectra of many high mass\naccretion rate AGN can be well modelled by reflection from a partially ionised\naccretion disc. However, the derived parameters are often extreme, both in\nterms of the underlying spacetime and the reflection geometry, and these models\nrequire that the disc is far from hydrostatic equilibrium. An alternative model\nuses similarly partially ionised, velocity smeared material but seen in\nabsorption, though again the derived velocities are extreme, requiring magnetic\ndriving (in the jet?) rather than a simple line driven disc wind. We find that\nwhile both models give comparably good fits to XMM--Newton data, we favour the\nabsorption model as, unlike reflection, all the derived spectral indices are\nsoft. This is as expected by analogy with the correspondingly high mass\naccretion rate stellar mass black holes. Furthermore, these X-ray spectra are\nconsistent with a one--to--one mapping between AGN type and spectral state,\nwith NLS1's having softer spectra corresponding to the very high state, while\nthe broad line AGN have Gamma~2 as expected for the high/soft state. We also\nuse the simultaneous OM data to derive the ratio of disc to total accretion\npower which is another tracer of spectral state in X-ray binaries. This does\nnot always show that the disc in NLS1's contributes less than 80 per cent of\nthe total power, as expected for a very high state. We suggest that this is an\nartifact of the standard disc models used to determine the disc luminosity in\nour fits. The disc seen in the very high state of black hole binaries is often\nobserved to be distorted from the standard shape, and a similar effect in\nNLS1's could recover the correspondance between black hole binary spectral\nstate and AGN type.\n", "machine_text": "\nThe X-ray spectra of many high-mass accretion rate active galactic nuclei (AGN) show a 'soft excess' that can be successfully modelled by assuming that the AGN is reflecting off a partially ionised accretion disc. This requires extremely exotic parameters concerning the underlying spacetime and the reflection geometry, and demands that the source of the reflection is far from hydrostatic equilibrium. An alternative explanation of the soft excess considers absorption from similarly partially ionised, velocity-smeared material, predominantly in the jet. Both of these models produce comparably good fits to XMM-Newton observation data, however the absorption model is preferred due to all the derived spectral indices resulting in a soft excess, which is as expected for AGN operating at a high mass accretion rate. The OM data from the simultaneous observations are used to suggest that the disk of an AGN in the very high state, like in stellar mass black holes, yields up to 80 per cent of the total accretion power. We suggest that the discrepancy between what is expected for the very high state in AGN and what is observed is due to distortions from the traditional shape of the accretion disk, echoing what is seen in stellar mass black holes.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.297}
{"prompt": "Rephrase the abstract of an article with title 'A Complete Catalog of Swift GRB Spectra and Durations: Demise of a\n  Physical Origin for Pre-Swift High-Energy Correlations'.\n  We calculate durations and spectral paramaters for 218 Swift bursts detected\nby the BAT instrument between and including GRBs 041220 and 070509, including\n77 events with measured redshifts. Incorporating prior knowledge into the\nspectral fits, we are able to measure the characteristic $\\nu F_{\\nu}$ spectral\npeak energy $E_{\\rm pk,obs}$ and the isotropic equivalent energy $E_{\\rm iso}$\n(1--$10^4$ keV) for all events. This complete and rather extensive catalog,\nanalyzed with a unified methodology, allows us to address the persistence and\norigin of high-energy correlations suggested in pre-Swift observations. We find\nthat the $E_{\\rm pk,obs}$-$E_{\\rm iso}$ correlation is present in the Swift\nsample; however, the best-fit powerlaw relation is inconsistent with the\nbest-fit pre-Swift relation at >5 sigma significance. Moreover, it has a factor\n>~ 2 larger intrinsic scatter, after accounting for large errors on $E_{\\rm\npk,obs}$. A large fraction of the Swift events are hard and subluminous\nrelative to (and inconsistent with) the pre-Swift relation, in agreement with\nindications from BATSE GRBs without redshift. Moreover, we determine an\nexperimental threshold for the BAT detector and show how the $E_{\\rm\npk,obs}$--$E_{\\rm iso}$ correlation arises artificially due to partial\ncorrelation with the threshold. We show that pre-Swift correlations found by\nAmati et al.(2002), Yonetoku et al. (2004), Firmani et al.(2006) (and\nindependently by others) are likely unrelated to the physical properties of\nGRBs and are likely useless for tests of cosmology. Also, an explanation of\nthese correlations in terms of a detector threshold provides a natural and\nquantitative explanation for why short-duration GRBs and events at low redshift\ntend to be outliers to the correlations.\n\n", "human_text": "  We calculate durations and spectral paramaters for 218 Swift bursts detected\nby the BAT instrument between and including GRBs 041220 and 070509, including\n77 events with measured redshifts. Incorporating prior knowledge into the\nspectral fits, we are able to measure the characteristic $\\nu F_{\\nu}$ spectral\npeak energy $E_{\\rm pk,obs}$ and the isotropic equivalent energy $E_{\\rm iso}$\n(1--$10^4$ keV) for all events. This complete and rather extensive catalog,\nanalyzed with a unified methodology, allows us to address the persistence and\norigin of high-energy correlations suggested in pre-Swift observations. We find\nthat the $E_{\\rm pk,obs}$-$E_{\\rm iso}$ correlation is present in the Swift\nsample; however, the best-fit powerlaw relation is inconsistent with the\nbest-fit pre-Swift relation at >5 sigma significance. Moreover, it has a factor\n>~ 2 larger intrinsic scatter, after accounting for large errors on $E_{\\rm\npk,obs}$. A large fraction of the Swift events are hard and subluminous\nrelative to (and inconsistent with) the pre-Swift relation, in agreement with\nindications from BATSE GRBs without redshift. Moreover, we determine an\nexperimental threshold for the BAT detector and show how the $E_{\\rm\npk,obs}$--$E_{\\rm iso}$ correlation arises artificially due to partial\ncorrelation with the threshold. We show that pre-Swift correlations found by\nAmati et al.(2002), Yonetoku et al. (2004), Firmani et al.(2006) (and\nindependently by others) are likely unrelated to the physical properties of\nGRBs and are likely useless for tests of cosmology. Also, an explanation of\nthese correlations in terms of a detector threshold provides a natural and\nquantitative explanation for why short-duration GRBs and events at low redshift\ntend to be outliers to the correlations.\n", "machine_text": "\nWe use a unified methodology to calculate the characteristic spectral peak energy $E_{\\rm pk,obs}$ and the isotropic equivalent energy $E_{\\rm iso}$ of 218 Swift bursts detected by the BAT instrument between GRBs 041220 and 070509, including 77 events with measured redshifts. This comprehensive catalog helps to address the existence and origin of the high-energy correlations previously observed in pre-Swift observations. Our findings are that the $E_{\\rm pk,obs}$-$E_{\\rm iso}$ correlation does continue to be present in the Swift sample; however, the powerlaw relation is markedly different from the pre-Swift relation. Furthermore, the Swift sample consists of a large number of hard, subluminous GRBs, which agrees with indications from BATSE GRBs without redshifts. An explanation in terms of a detector threshold appears to explain why short-duration GRBs and low-redshift events are outliers to the correlations. Based on this, we are able to conclude that the high-energy correlations previously uncovered by Amati et al.(2002), Yonetoku et al. (2004), Firmani et al.(2006) are unlikely related to the physical properties of GRBs and, therefore, likely useless for testing cosmologies.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1275}
{"prompt": "Rephrase the abstract of an article with title 'An Adaptive Strategy for the Classification of G-Protein Coupled\n  Receptors'.\n  One of the major problems in computational biology is the inability of\nexisting classification models to incorporate expanding and new domain\nknowledge. This problem of static classification models is addressed in this\npaper by the introduction of incremental learning for problems in\nbioinformatics. Many machine learning tools have been applied to this problem\nusing static machine learning structures such as neural networks or support\nvector machines that are unable to accommodate new information into their\nexisting models. We utilize the fuzzy ARTMAP as an alternate machine learning\nsystem that has the ability of incrementally learning new data as it becomes\navailable. The fuzzy ARTMAP is found to be comparable to many of the widespread\nmachine learning systems. The use of an evolutionary strategy in the selection\nand combination of individual classifiers into an ensemble system, coupled with\nthe incremental learning ability of the fuzzy ARTMAP is proven to be suitable\nas a pattern classifier. The algorithm presented is tested using data from the\nG-Coupled Protein Receptors Database and shows good accuracy of 83%. The system\npresented is also generally applicable, and can be used in problems in genomics\nand proteomics.\n\n", "human_text": "  One of the major problems in computational biology is the inability of\nexisting classification models to incorporate expanding and new domain\nknowledge. This problem of static classification models is addressed in this\npaper by the introduction of incremental learning for problems in\nbioinformatics. Many machine learning tools have been applied to this problem\nusing static machine learning structures such as neural networks or support\nvector machines that are unable to accommodate new information into their\nexisting models. We utilize the fuzzy ARTMAP as an alternate machine learning\nsystem that has the ability of incrementally learning new data as it becomes\navailable. The fuzzy ARTMAP is found to be comparable to many of the widespread\nmachine learning systems. The use of an evolutionary strategy in the selection\nand combination of individual classifiers into an ensemble system, coupled with\nthe incremental learning ability of the fuzzy ARTMAP is proven to be suitable\nas a pattern classifier. The algorithm presented is tested using data from the\nG-Coupled Protein Receptors Database and shows good accuracy of 83%. The system\npresented is also generally applicable, and can be used in problems in genomics\nand proteomics.\n", "machine_text": "\nThis paper proposes an adaptive strategy to tackle the challenge of updating classification models with new information. Instead of using traditional machine learning tools such as neural networks and support vector machines, we propose the use of the incremental learning capability of fuzzy ARTMAP as an alternative. This algorithm is then combined with an evolutionary strategy of selection and combination of individual classifiers into a unified ensemble system. The proposed system has been tested using data from the G-Protein Coupled Receptor Database and demonstrated a high accuracy of 83%. Additionally, it is generally applicable and can be used in various problems related to genomics and proteomics.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3453}
{"prompt": "Rephrase the abstract of an article with title 'R-matrices in Rime'.\n  We replace the ice Ansatz on matrix solutions of the Yang-Baxter equation by\na weaker condition which we call \"rime\". Rime solutions include the standard\nDrinfeld-Jimbo R-matrix. Solutions of the Yang--Baxter equation within the rime\nAnsatz which are maximally different from the standard one we call \"strict\nrime\". A strict rime non-unitary solution is parameterized by a projective\nvector. We show that this solution transforms to the Cremmer-Gervais R-matrix\nby a change of basis with a matrix containing symmetric functions in the\ncomponents of the parameterizing vector. A strict unitary solution (the rime\nAnsatz is well adapted for taking a unitary limit) is shown to be equivalent to\na quantization of a classical \"boundary\" r-matrix of Gerstenhaber and\nGiaquinto. We analyze the structure of the elementary rime blocks and find, as\na by-product, that all non-standard R-matrices of GL(1|1)-type can be uniformly\ndescribed in a rime form.\n  We discuss then connections of the classical rime solutions with the Bezout\noperators. The Bezout operators satisfy the (non-)homogeneous associative\nclassical Yang--Baxter equation which is related to the Rota-Baxter operators.\n  We classify the rime Poisson brackets: they form a 3-dimensional pencil. A\nnormal form of each individual member of the pencil depends on the discriminant\nof a certain quadratic polynomial. We also classify orderable quadratic rime\nassociative algebras.\n  For the standard Drinfeld-Jimbo solution, there is a choice of the\nmultiparameters, for which it can be non-trivially rimed. However, not every\nBelavin-Drinfeld triple admits a choice of the multiparameters for which it can\nbe rimed. We give a minimal example.\n\n", "human_text": "  We replace the ice Ansatz on matrix solutions of the Yang-Baxter equation by\na weaker condition which we call \"rime\". Rime solutions include the standard\nDrinfeld-Jimbo R-matrix. Solutions of the Yang--Baxter equation within the rime\nAnsatz which are maximally different from the standard one we call \"strict\nrime\". A strict rime non-unitary solution is parameterized by a projective\nvector. We show that this solution transforms to the Cremmer-Gervais R-matrix\nby a change of basis with a matrix containing symmetric functions in the\ncomponents of the parameterizing vector. A strict unitary solution (the rime\nAnsatz is well adapted for taking a unitary limit) is shown to be equivalent to\na quantization of a classical \"boundary\" r-matrix of Gerstenhaber and\nGiaquinto. We analyze the structure of the elementary rime blocks and find, as\na by-product, that all non-standard R-matrices of GL(1|1)-type can be uniformly\ndescribed in a rime form.\n  We discuss then connections of the classical rime solutions with the Bezout\noperators. The Bezout operators satisfy the (non-)homogeneous associative\nclassical Yang--Baxter equation which is related to the Rota-Baxter operators.\n  We classify the rime Poisson brackets: they form a 3-dimensional pencil. A\nnormal form of each individual member of the pencil depends on the discriminant\nof a certain quadratic polynomial. We also classify orderable quadratic rime\nassociative algebras.\n  For the standard Drinfeld-Jimbo solution, there is a choice of the\nmultiparameters, for which it can be non-trivially rimed. However, not every\nBelavin-Drinfeld triple admits a choice of the multiparameters for which it can\nbe rimed. We give a minimal example.\n", "machine_text": "\nIn this article we examine the weak condition of rime instead of the standard Ansatz when studying matrix solutions of the Yang-Baxter equation. We identify the different types of solutions under rime, including the Drinfeld-Jimbo R-matrix, Cremmer-Gervais R-matrix, and R-matrices associated with GL(1|1)-type. We link these rime solutions to the Bezout operators and look into the structure of the elementary rime blocks. Additionally, we classify the various possible rime Poisson brackets and associative algebras of orderable quadratic rime, and consider the case of the Drinfeld-Jimbo solution that can be rimed when chosen multiparameters are selected.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1947}
{"prompt": "Rephrase the abstract of an article with title 'Focusing of high-energy particles in the electrostatic field of a\n  homogeneously charged sphere and the effective momentum approximation'.\n  The impact of the strongly attractive electromagnetic field of heavy nuclei\non electrons in quasi-elastic (e,e') scattering is often accounted for by the\neffective momentum approximation. This method is a plane wave Born\napproximation which takes the twofold effect of the attractive nucleus on\ninitial and final state electrons into account, namely the modification of the\nelectron momentum in the vicinity of the nucleus, and the focusing of electrons\ntowards the nuclear region leading to an enhancement of the corresponding wave\nfunction amplitudes. The focusing effect due to the attractive Coulomb field of\na homogeneously charged sphere on a classical ensemble of charged particles\nincident on the field is calculated in the highly relativistic limit and\ncompared to results obtained from exact solutions of the Dirac equation. The\nresult is relevant for the theoretical foundation of the effective momentum\napproximation and describes the high energy behavior of the amplitude of\ncontinuum Dirac waves in the potential of a homogeneously charged sphere. Our\nfindings indicate that the effective momentum approximation is a useful\napproximation for the calculation of Coulomb corrections in (e,e') scattering\noff heavy nuclei for sufficiently high electron energies and momentum transfer.\n\n", "human_text": "  The impact of the strongly attractive electromagnetic field of heavy nuclei\non electrons in quasi-elastic (e,e') scattering is often accounted for by the\neffective momentum approximation. This method is a plane wave Born\napproximation which takes the twofold effect of the attractive nucleus on\ninitial and final state electrons into account, namely the modification of the\nelectron momentum in the vicinity of the nucleus, and the focusing of electrons\ntowards the nuclear region leading to an enhancement of the corresponding wave\nfunction amplitudes. The focusing effect due to the attractive Coulomb field of\na homogeneously charged sphere on a classical ensemble of charged particles\nincident on the field is calculated in the highly relativistic limit and\ncompared to results obtained from exact solutions of the Dirac equation. The\nresult is relevant for the theoretical foundation of the effective momentum\napproximation and describes the high energy behavior of the amplitude of\ncontinuum Dirac waves in the potential of a homogeneously charged sphere. Our\nfindings indicate that the effective momentum approximation is a useful\napproximation for the calculation of Coulomb corrections in (e,e') scattering\noff heavy nuclei for sufficiently high electron energies and momentum transfer.\n", "machine_text": "\nThe effective momentum approximation has been developed to take into account the effect of a strongly attractive electromagnetic field of heavy nuclei on electrons in quasi-elastic (e,e') scattering. This method is based on a plane wave Born approximation and considers the negative effects of an attractive nucleus on both the initial and final state electrons by modifying the electron momentum near the nucleus and amplifying the corresponding wave functions. Here, we analyze the focusing behavior of an ensemble of high-energy particles in the electrostatic field of a homogeneously charged sphere using exact solutions of the Dirac equation as well as a highly relativistic limit. Our results indicate that the effective momentum approximation is a valid tool for Coulomb corrections in (e,e') scattering off heavy nuclei at high electron energies and momentum transfer.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1119}
{"prompt": "Rephrase the abstract of an article with title 'The Magnetic Field of the Solar Corona from Pulsar Observations'.\n  We present a novel experiment with the capacity to independently measure both\nthe electron density and the magnetic field of the solar corona. We achieve\nthis through measurement of the excess Faraday rotation due to propagation of\nthe polarised emission from a number of pulsars through the magnetic field of\nthe solar corona. This method yields independent measures of the integrated\nelectron density, via dispersion of the pulsed signal and the magnetic field,\nvia the amount of Faraday rotation. In principle this allows the determination\nof the integrated magnetic field through the solar corona along many lines of\nsight without any assumptions regarding the electron density distribution. We\npresent a detection of an increase in the rotation measure of the pulsar\nJ1801$-$2304 of approximately 160 \\rad at an elongation of 0.95$^\\circ$ from\nthe centre of the solar disk. This corresponds to a lower limit of the magnetic\nfield strength along this line of sight of $> 393\\mu\\mathrm{G}$. The lack of\nprecision in the integrated electron density measurement restricts this result\nto a limit, but application of coronal plasma models can further constrain this\nto approximately 20mG, along a path passing 2.5 solar radii from the solar\nlimb. Which is consistent with predictions obtained using extensions to the\nSource Surface models published by Wilcox Solar Observatory\n\n", "human_text": "  We present a novel experiment with the capacity to independently measure both\nthe electron density and the magnetic field of the solar corona. We achieve\nthis through measurement of the excess Faraday rotation due to propagation of\nthe polarised emission from a number of pulsars through the magnetic field of\nthe solar corona. This method yields independent measures of the integrated\nelectron density, via dispersion of the pulsed signal and the magnetic field,\nvia the amount of Faraday rotation. In principle this allows the determination\nof the integrated magnetic field through the solar corona along many lines of\nsight without any assumptions regarding the electron density distribution. We\npresent a detection of an increase in the rotation measure of the pulsar\nJ1801$-$2304 of approximately 160 \\rad at an elongation of 0.95$^\\circ$ from\nthe centre of the solar disk. This corresponds to a lower limit of the magnetic\nfield strength along this line of sight of $> 393\\mu\\mathrm{G}$. The lack of\nprecision in the integrated electron density measurement restricts this result\nto a limit, but application of coronal plasma models can further constrain this\nto approximately 20mG, along a path passing 2.5 solar radii from the solar\nlimb. Which is consistent with predictions obtained using extensions to the\nSource Surface models published by Wilcox Solar Observatory\n", "machine_text": "\nThis paper explores a new research approach of using pulsar observations to independently measure both the electron density and the magnetic field of the solar corona. Our method, which measures the Faraday rotation from the polarized emission from a number of pulsars, allows us to obtain integrated measurements of the electron density and the magnetic field. Consequently, these measurements enable us to determine the integrated magnetic field through the solar corona, without any need for an assumed electron density distribution. Results indicate that the Faraday rotation of the pulsar J1801$-$2304 increased by roughly 160 \\rad at an elongation of 0.95$^\\circ$ from the sun\u2019s centre, suggesting a minimum magnetic field strength of 393$\\mu$G along this line of sight. Although the precision of electron density measurement is not satisfactory, applying coronal plasma models can restrict the value to a range around 20mG along a path between 2.5 solar radii and the solar limb, which is in concordance with the Source Surface models published by Wilcox Solar Observatory.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1869}
{"prompt": "Rephrase the abstract of an article with title 'Cosmogenic neutrinos as a probe of the transition from Galactic to\n  extragalactic cosmic rays'.\n  There are two promising scenarios that explain the ankle, which is a dip in\nthe spectrum of cosmic rays at $\\sim 10^{19}$ eV. A scenario interprets the\nankle as the transition from Galactic to extragalactic cosmic rays ({\\it\nankle-transition scenario}), while the other is that the dip caused by pair\nproduction on the cosmic microwave background radiation ({\\it proton-dip\nscenario}). In this paper, we consider whether cosmogenic neutrinos can be a\nclue to judge which scenario is favored. We calculated the fluxes of cosmogenic\nneutrinos following these scenarios with plausible physical parameter sets, and\nfound several important features as follows. First of all, the neutrino flux at\n$\\sim 10^{20}$ eV becomes much higher in the ankle-transition scenario as long\nas the maximum energy of the cosmic rays at sources is sufficiently high. On\nthe other hand, the neutrino spectrum has a characteristic peak at $\\sim\n10^{16}$ eV in the proton-dip scenario on the condition that extragalactic\nprotons significantly contribute to the observed cosmic rays down to $10^{17}$\neV. Thus, we conclude cosmogenic neutrinos should give us a clue to judge which\nscenario is favored, unless these features are masked by the neutrino\nbackground coming from possible, powerful neutrino sources such as AGNs and\nGRBs. We also found an interesting feature that the neutrino flux at $\\sim\n10^{18}$ eV depends only on the cosmological evolution of the cosmic ray\nsources. That means cosmogenic neutrinos with the energy bring us information\non the cosmological evolution of the sources of ultra-high energy cosmic rays.\nFinally, we compare the fluxes of cosmogenic neutrinos with the expected\nsensitivity curves of several neutrino detectors, and conclude the detection of\ncosmogenic neutrinos in the near future is promising.\n\n", "human_text": "  There are two promising scenarios that explain the ankle, which is a dip in\nthe spectrum of cosmic rays at $\\sim 10^{19}$ eV. A scenario interprets the\nankle as the transition from Galactic to extragalactic cosmic rays ({\\it\nankle-transition scenario}), while the other is that the dip caused by pair\nproduction on the cosmic microwave background radiation ({\\it proton-dip\nscenario}). In this paper, we consider whether cosmogenic neutrinos can be a\nclue to judge which scenario is favored. We calculated the fluxes of cosmogenic\nneutrinos following these scenarios with plausible physical parameter sets, and\nfound several important features as follows. First of all, the neutrino flux at\n$\\sim 10^{20}$ eV becomes much higher in the ankle-transition scenario as long\nas the maximum energy of the cosmic rays at sources is sufficiently high. On\nthe other hand, the neutrino spectrum has a characteristic peak at $\\sim\n10^{16}$ eV in the proton-dip scenario on the condition that extragalactic\nprotons significantly contribute to the observed cosmic rays down to $10^{17}$\neV. Thus, we conclude cosmogenic neutrinos should give us a clue to judge which\nscenario is favored, unless these features are masked by the neutrino\nbackground coming from possible, powerful neutrino sources such as AGNs and\nGRBs. We also found an interesting feature that the neutrino flux at $\\sim\n10^{18}$ eV depends only on the cosmological evolution of the cosmic ray\nsources. That means cosmogenic neutrinos with the energy bring us information\non the cosmological evolution of the sources of ultra-high energy cosmic rays.\nFinally, we compare the fluxes of cosmogenic neutrinos with the expected\nsensitivity curves of several neutrino detectors, and conclude the detection of\ncosmogenic neutrinos in the near future is promising.\n", "machine_text": "\nThis paper explores whether cosmogenic neutrinos can shed light on the distinction between two theories that explain the ankle, which is a break in the the spectrum of cosmic rays at around 10$^{19}$ eV: one {\\it ankle-transition scenario}, which interprets the ankle as the transition from Galactic to extragalactic cosmic rays, and the other is the {\\it proton-dip scenario}, where the dip is the result of pair production on the cosmic microwave background radiation. Furthermore, we consider the practicality of the near-future detection of cosmogenic neutrinos with several detectors. Using plausible physical parameter sets to calculate the fluxes of cosmogenic neutrinos following both scenarios, we found important features which could be utilised to determine which of the two theories is favored. For example, the neutrino flux at $\\sim 10^{20}$ eV increases significantly in the ankle-transition scenario as long as the maximum energy of cosmic rays at the source is adequate, while a characteristic peak at $\\sim 10^{16}$ eV is expected in the proton-dip scenario if extragalactic protons contribute significantly to the observed cosmic rays down to $10^{17}$ eV. Hence, we conclude that cosmogenic neutrinos can provide a clue to judge which of the two most likely scenarios is favored; unless of course, these features are masked by the potential presence of background neutrinos from other sources such as AGN and GRB's. Additionally, we found an interesting feature that the flux of cosmogenic neutrinos at $\\sim 10^{18}$ eV is exclusively determined by the cosmological evolution of cosmic ray sources; this means cosmogenic neutrinos with this energy could potentially give information on the cosmological evolution of the sources of ultra-high energy cosmic rays. Finally, comparing the fluxes of cosmogenic neutrinos with the expected sensitivity curves for multiple neutrino detectors, we determine that detection of cosmogenic neutrinos in the near future is attainable.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0979}
{"prompt": "Rephrase the abstract of an article with title 'Wang-Landau molecular dynamics technique to search for low-energy\n  conformational space of proteins'.\n  Multicanonical molecular dynamics (MD) is a powerful technique for sampling\nconformations on rugged potential surfaces such as protein. However, it is\nnotoriously difficult to estimate the multicanonical temperature effectively.\nWang and Landau developed a convenient method for estimating the density of\nstates based on a multicanonical Monte Carlo method. In their method, the\ndensity of states is calculated autonomously during a simulation. In this paper\nwe develop a set of techniques to effectively apply the Wang-Landau method to\nMD simulations. In the multicanonical MD, the estimation of the derivative of\nthe density of states is critical. In order to estimate it accurately, we\ndevise two original improvements. First, the correction for the density of\nstates is made smooth by using the Gaussian distribution obtained by a short\ncanonical simulation. Second, an approximation is applied to the derivative,\nwhich is based on the Gaussian distribution and the multiple weighted histogram\ntechnique. A test of this method was performed with small polypeptides,\nMet-enkephalin and Trp-cage, and it is demonstrated that Wang-Landau MD is\nconsistent with replica exchange MD but can sample much larger conformational\nspace.\n\n", "human_text": "  Multicanonical molecular dynamics (MD) is a powerful technique for sampling\nconformations on rugged potential surfaces such as protein. However, it is\nnotoriously difficult to estimate the multicanonical temperature effectively.\nWang and Landau developed a convenient method for estimating the density of\nstates based on a multicanonical Monte Carlo method. In their method, the\ndensity of states is calculated autonomously during a simulation. In this paper\nwe develop a set of techniques to effectively apply the Wang-Landau method to\nMD simulations. In the multicanonical MD, the estimation of the derivative of\nthe density of states is critical. In order to estimate it accurately, we\ndevise two original improvements. First, the correction for the density of\nstates is made smooth by using the Gaussian distribution obtained by a short\ncanonical simulation. Second, an approximation is applied to the derivative,\nwhich is based on the Gaussian distribution and the multiple weighted histogram\ntechnique. A test of this method was performed with small polypeptides,\nMet-enkephalin and Trp-cage, and it is demonstrated that Wang-Landau MD is\nconsistent with replica exchange MD but can sample much larger conformational\nspace.\n", "machine_text": "\nThis paper introduces a novel method for navigating the low-energy conformational space of proteins through the use of the Wang-Landau molecular dynamics (MD) technique. It is argued that the effectiveness of multicanonical MD can be improved by introducing a procedure to accurately calculate the density of states. Two original improvements, namely the use of a Gaussian distribution generated with a short canonical simulation and the application of an approximated derivative based on that same distribution and the multiple-weighted histogram, are proposed in order to make the estimation process more efficient and reliable. Two polypeptides, Met-enkephalin and Trp-cage, are chosen as models and tested for their response to the Wang-Landau MD. The results suggest that this method of searching for low-energy conformations is comparable to that of replica exchange MD but can explore a much wider range of conformational variation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3365}
{"prompt": "Rephrase the abstract of an article with title 'The Use of ITIL for Process Optimisation in the IT Service Centre of\n  Harz University, exemplified in the Release Management Process'.\n  This paper details the use of the IT Infrastructure Library Framework (ITIL)\nfor optimising process workflows in the IT Service Centre of Harz University in\nWernigerode, Germany, exemplified by the Release Management Process. It is\ndescribed, how, during the course of a special ITIL project, the As-Is-Status\nof the various original processes was documented as part of the process life\ncycle and then transformed in the To-Be-Status, according to the ITIL Best\nPractice Framework. It is also shown, how the ITIL framework fits into the\nfour-layered-process model, that could be derived from interviews with the\nuniversities IT support staff, and how the various modified processes\ninterconnect with each other to form a value chain. The paper highlights the\nfinal results of the project and gives an outlook on the future use of ITIL as\na business modelling tool in the IT Service Centre of Harz University. It is\ncurrently being considered, whether the process model developed during the\nproject could be used as a reference model for other university IT centres.\n\n", "human_text": "  This paper details the use of the IT Infrastructure Library Framework (ITIL)\nfor optimising process workflows in the IT Service Centre of Harz University in\nWernigerode, Germany, exemplified by the Release Management Process. It is\ndescribed, how, during the course of a special ITIL project, the As-Is-Status\nof the various original processes was documented as part of the process life\ncycle and then transformed in the To-Be-Status, according to the ITIL Best\nPractice Framework. It is also shown, how the ITIL framework fits into the\nfour-layered-process model, that could be derived from interviews with the\nuniversities IT support staff, and how the various modified processes\ninterconnect with each other to form a value chain. The paper highlights the\nfinal results of the project and gives an outlook on the future use of ITIL as\na business modelling tool in the IT Service Centre of Harz University. It is\ncurrently being considered, whether the process model developed during the\nproject could be used as a reference model for other university IT centres.\n", "machine_text": "\nThis article examines the implementation of the IT Infrastructure Library (ITIL) and its effectiveness for streamlining the processes of the IT Service Centre of Harz University (Wernigerode, Germany). The Release Management Process illustrates ITIL's usefulness as a tool for optimisation. A four-layered structure was derived from interviewing IT support staff and launching an ITIL project to map the current state of the process and transition to the optimal state of ITIL Best Practices. The changes, including the interactions and value chain between the modified processes, are detailed. Additionally, the paper presents the final outcomes of the project, along with potential future use of ITIL at the Harz University IT Service Centre and other universities.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2351}
{"prompt": "Rephrase the abstract of an article with title 'Influence of Orbital Behaviour and Chaos on the Shape of Dark Matter\n  Halos'.\n  It has been shown that the dissipative gas infall during galaxy formation has\nthe capability to modify the shape of dark matter halos. In this paper we\nperform the first detailed analysis of particle orbits in a cosmological dark\nmatter halos to understand {\\it how} and {\\it why} baryons alter its shape. We\nperform a series of numerical experiments where we grow a baryonic core inside\na live dark matter halo extracted from a cosmological simulation. We follow the\norbits of more than 300 particles with more that 50000 timesteps. Our results\nclearly show that the dissipational component is responsible for repeatedly\ndeflecting orbits which visit often the center of the system. Moreover the\ngravitational potential time dependence associated with the growth of the\nbaryonic mass, shifts the frequencies of the orbits, making them extremely\nchaotic. This randomization makes the orbits explore a large phase space. When\nthis effect takes place for a significant number of orbits it will be\nmanifested in the density distribution as an approach to a rounder\nconfiguration. As a consequence, the influence of the central mass on the shape\nof the phase space decreases with increasing distance from the center. We\ndiscuss the importance of future analysis of controlled experiments (i.e. using\nanalytic potentials instead of live DM halos) to better decipher the dynamics\nof this phenomenon.\n\n", "human_text": "  It has been shown that the dissipative gas infall during galaxy formation has\nthe capability to modify the shape of dark matter halos. In this paper we\nperform the first detailed analysis of particle orbits in a cosmological dark\nmatter halos to understand {\\it how} and {\\it why} baryons alter its shape. We\nperform a series of numerical experiments where we grow a baryonic core inside\na live dark matter halo extracted from a cosmological simulation. We follow the\norbits of more than 300 particles with more that 50000 timesteps. Our results\nclearly show that the dissipational component is responsible for repeatedly\ndeflecting orbits which visit often the center of the system. Moreover the\ngravitational potential time dependence associated with the growth of the\nbaryonic mass, shifts the frequencies of the orbits, making them extremely\nchaotic. This randomization makes the orbits explore a large phase space. When\nthis effect takes place for a significant number of orbits it will be\nmanifested in the density distribution as an approach to a rounder\nconfiguration. As a consequence, the influence of the central mass on the shape\nof the phase space decreases with increasing distance from the center. We\ndiscuss the importance of future analysis of controlled experiments (i.e. using\nanalytic potentials instead of live DM halos) to better decipher the dynamics\nof this phenomenon.\n", "machine_text": "\nA comprehensive analysis of particle orbits in cosmic dark matter halos has been conducted in order to extrapolate how and why baryons transform the shape of these structures. Numerical experiments which incorporated a baryonic core inside a live dark matter halo extracted from an observational sample have consistently revealed that the dissipative component is responsible for influencing nearby orbits numerous times through visits to the centre. The gravitational potential changes caused by increases in the baryonic mass can be shown to cause the frequencies of orbits to become more random, leading to a large exploration of the system's phase space that evidences itself in a more round overall configuration. This influence of the central mass on the shape of the phase space is thus seen to become weakened with increasing distance from the center. Future experiments which use analytic potentials rather than live DM halos will be necessary to further decode the dynamics of this significant phenomenon.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3078}
{"prompt": "Rephrase the abstract of an article with title 'The symmetric heavy-light ansatz'.\n  The symmetric heavy-light ansatz is a method for finding the ground state of\nany dilute unpolarized system of attractive two-component fermions.\nOperationally it can be viewed as a generalization of the Kohn-Sham equations\nin density functional theory applied to N-body density correlations. While the\noriginal Hamiltonian has an exact Z_2 symmetry, the heavy-light ansatz breaks\nthis symmetry by skewing the mass ratio of the two components. In the limit\nwhere one component is infinitely heavy, the many-body problem can be solved in\nterms of single-particle orbitals. The original Z_2 symmetry is recovered by\nenforcing Z_2 symmetry as a constraint on N-body density correlations for the\ntwo components. For the 1D, 2D, and 3D attractive Hubbard models the method is\nin very good agreement with exact Lanczos calculations for few-body systems at\narbitrary coupling. For the 3D attractive Hubbard model there is very good\nagreement with lattice Monte Carlo results for many-body systems in the limit\nof infinite scattering length.\n\n", "human_text": "  The symmetric heavy-light ansatz is a method for finding the ground state of\nany dilute unpolarized system of attractive two-component fermions.\nOperationally it can be viewed as a generalization of the Kohn-Sham equations\nin density functional theory applied to N-body density correlations. While the\noriginal Hamiltonian has an exact Z_2 symmetry, the heavy-light ansatz breaks\nthis symmetry by skewing the mass ratio of the two components. In the limit\nwhere one component is infinitely heavy, the many-body problem can be solved in\nterms of single-particle orbitals. The original Z_2 symmetry is recovered by\nenforcing Z_2 symmetry as a constraint on N-body density correlations for the\ntwo components. For the 1D, 2D, and 3D attractive Hubbard models the method is\nin very good agreement with exact Lanczos calculations for few-body systems at\narbitrary coupling. For the 3D attractive Hubbard model there is very good\nagreement with lattice Monte Carlo results for many-body systems in the limit\nof infinite scattering length.\n", "machine_text": "The symmetric heavy-light ansatz provides a method for finding the ground state of a diluted, unpolarized system of two-component fermions. Based on the Kohn-Sham equations in density functional theory, the approach skews the mass ratio between the different components, resulting in an effective single-particle solution. In order to retain the original Z_2 symmetry, a constraint is imposed onto the N-body density correlations of the two components. This method has been applied to the 1D, 2D and 3D attractive Hubbard models, and its results were found to agree well with exact Lanczos calculations for few-body systems and Monte Carlo simulations for many-body systems.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3439}
{"prompt": "Rephrase the abstract of an article with title 'Massive CP$^1$ theory from a microscopic model for doped\n  antiferromagnets'.\n  A path-integral for the t-J model in two dimensions is constructed based on\nDirac quantization, with an action found originally by Wiegmann (Phys. Rev.\nLett. {\\bf 60}, 821 (1988); Nucl. Phys. B323, 311 (1989)). Concentrating on the\nlow doping limit, we assume short range antiferromagnetic order of the spin\ndegrees of freedom. Going over to a local spin quantization axis of the dopant\nfermions, that follows the spin degree of freedom, staggered CP$^1$ fields\nresult and the constraint against double occupancy can be resolved. The\nstaggered CP$^1$ fields are split into slow and fast modes, such that after a\ngradient expansion, and after integrating out the fast modes and the dopant\nfermions, a CP$^1$ field-theory with a massive gauge field is obtained that\ndescribes generically incommensurate coplanar magnetic structures, as discussed\npreviously in the context of frustrated quantum antiferromagnets. Hence, the\npossibility of deconfined spinons is opened by doping a colinear\nantiferromagnet.\n\n", "human_text": "  A path-integral for the t-J model in two dimensions is constructed based on\nDirac quantization, with an action found originally by Wiegmann (Phys. Rev.\nLett. {\\bf 60}, 821 (1988); Nucl. Phys. B323, 311 (1989)). Concentrating on the\nlow doping limit, we assume short range antiferromagnetic order of the spin\ndegrees of freedom. Going over to a local spin quantization axis of the dopant\nfermions, that follows the spin degree of freedom, staggered CP$^1$ fields\nresult and the constraint against double occupancy can be resolved. The\nstaggered CP$^1$ fields are split into slow and fast modes, such that after a\ngradient expansion, and after integrating out the fast modes and the dopant\nfermions, a CP$^1$ field-theory with a massive gauge field is obtained that\ndescribes generically incommensurate coplanar magnetic structures, as discussed\npreviously in the context of frustrated quantum antiferromagnets. Hence, the\npossibility of deconfined spinons is opened by doping a colinear\nantiferromagnet.\n", "machine_text": "An article titled 'Massive CP$^1$ Theory from a Microscopic Model for Doped Antiferromagnets' presents a detailed study of a two-dimensional t-J model with Dirac quantization, conducted to understand the effects of doping a colinear antiferromagnet. In the low doping limit, short-range antiferromagnetic order of spin degrees of freedom is assumed. A local spin quantization axis of the dopant fermions then gives rise to the staggered CP$^1$ fields, thereby resolving the double occupancy constraint. By subsequent splitting of slow and fast modes and integration of the fast modes and dopant fermions, a CP$^1$ field-theory including a massive gauge field is obtained. As a result, incommensurate coplanar magnetic structures are seen and the possibility of deconfined spinons is opened.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1918}
{"prompt": "Rephrase the abstract of an article with title 'Luminous Red Galaxy Clustering at z~0.7 - First Results using AAOmega'.\n  We report on the AAT-AAOmega LRG Pilot observing run to establish the\nfeasibility of a large spectroscopic survey using the new AAOmega instrument.\nWe have selected Luminous Red Galaxies (LRGs) using single epoch SDSS\nriz-photometry to i<20.5 and z<20.2. We have observed in 3 fields including the\nCOSMOS field and the COMBO-17 S11 field, obtaining a sample of ~600 redshift\nz>=0.5 LRGs. Exposure times varied from 1 - 4 hours to determine the minimum\nexposure for AAOmega to make an essentially complete LRG redshift survey in\naverage conditions. We show that LRG redshifts to i<20.5 can measured in\napproximately 1.5hr exposures and present comparisons with 2SLAQ and COMBO-17\n(photo-)redshifts. Crucially, the riz selection coupled with the 3-4 times\nimproved AAOmega throughput is shown to extend the LRG mean redshift from\nz=0.55 for 2SLAQ to z=0.681+/- 0.005 for riz-selected LRGs. This extended range\nis vital for maximising the S/N for the detection of the baryon acoustic\noscillations (BAOs). Furthermore, we show that the amplitude of LRG clustering\nis s_0 = 9.9+/-0.7 h^-1 Mpc, as high as that seen in the 2SLAQ LRG Survey.\nConsistent results for the real-space amplitude are found from projected and\nsemi-projected correlation functions. This high clustering amplitude is\nconsistent with a long-lived population whose bias evolves as predicted by a\nsimple ``high-peaks'' model. We conclude that a redshift survey of 360 000 LRGs\nover 3000deg^2, with an effective volume some 4 times bigger than previously\nused to detect BAO with LRGs, is possible with AAOmega in 170 nights.\n\n", "human_text": "  We report on the AAT-AAOmega LRG Pilot observing run to establish the\nfeasibility of a large spectroscopic survey using the new AAOmega instrument.\nWe have selected Luminous Red Galaxies (LRGs) using single epoch SDSS\nriz-photometry to i<20.5 and z<20.2. We have observed in 3 fields including the\nCOSMOS field and the COMBO-17 S11 field, obtaining a sample of ~600 redshift\nz>=0.5 LRGs. Exposure times varied from 1 - 4 hours to determine the minimum\nexposure for AAOmega to make an essentially complete LRG redshift survey in\naverage conditions. We show that LRG redshifts to i<20.5 can measured in\napproximately 1.5hr exposures and present comparisons with 2SLAQ and COMBO-17\n(photo-)redshifts. Crucially, the riz selection coupled with the 3-4 times\nimproved AAOmega throughput is shown to extend the LRG mean redshift from\nz=0.55 for 2SLAQ to z=0.681+/- 0.005 for riz-selected LRGs. This extended range\nis vital for maximising the S/N for the detection of the baryon acoustic\noscillations (BAOs). Furthermore, we show that the amplitude of LRG clustering\nis s_0 = 9.9+/-0.7 h^-1 Mpc, as high as that seen in the 2SLAQ LRG Survey.\nConsistent results for the real-space amplitude are found from projected and\nsemi-projected correlation functions. This high clustering amplitude is\nconsistent with a long-lived population whose bias evolves as predicted by a\nsimple ``high-peaks'' model. We conclude that a redshift survey of 360 000 LRGs\nover 3000deg^2, with an effective volume some 4 times bigger than previously\nused to detect BAO with LRGs, is possible with AAOmega in 170 nights.\n", "machine_text": "\nWe present the the first results of the AAT-AAOmega LRG Pilot observing run to assess the viability of a massive spectroscopic survey with AAOmega. We analyze up to 600 Luminous Red Galaxies (LRGs) to z>=0.5 in three fields, including COSMOS and COMBO-17 S11. We investigate how exposure times ranging from 1 - 4 hours impact the potential of AAOmega for an essentially complete redshift survey in relatively mild conditions. We ascertain that 1.5 hours of exposure are viable for LRG redshifts up to i<20.5 and further show that the riz selection and 3-4 times heightened AAOmega throughput can drive the mean redshift from z=0.55 (2SLAQ) to z=0.681+/- 0.005 for the riz-selected LRGs. The expanded range is significant in amplifying the signal-to-noise ratio for the detection of baryon acoustic oscillations (BAOs). Moreover, we discover that the LRG clustering strength matches the figures as seen in the 2SLAQ LRG Survey, obtained from both projected and semi-projected correlation functions. We believe that with AAOmega, a survey of 360,000 LRGs over 3,000 deg^2 with an efficient volume four times bigger than before can be feasible in 170 nights.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3739}
{"prompt": "Rephrase the abstract of an article with title 'Inflection point as a manifestation of tricritical point on the dynamic\n  phase boundary in Ising meanfield dynamics'.\n  We studied the dynamical phase transition in kinetic Ising ferromagnet driven\nby oscillating magnetic field in meanfield approximation. The meanfield\ndifferential equation was solved by sixth order Runge-Kutta-Felberg method. We\ncalculated the transition temperature as a function of amplitude and frequency\nof the oscillating field. This was plotted against field amplitude taking\nfrequency as a parameter. As frequency increases the phase boundary is observed\nto become inflated. The phase boundary shows an inflection point which\nseparates the nature of the transition. On the dynamic phase boundary a\ntricritical point (TCP) was found, which separates the nature\n(continuous/discontinuous) of the dynamic transition across the phase boundary.\nThe inflection point is identified as the TCP and hence a simpler method of\ndetermining the position of TCP was found. TCP was observed to shift towards\nhigh field for higher frequency. As frequency decreases the dynamic phase\nboundary is observe to shrink. In the zero frequency limit this boundary shows\na tendency to merge to the temperature variation of the coercive field.\n\n", "human_text": "  We studied the dynamical phase transition in kinetic Ising ferromagnet driven\nby oscillating magnetic field in meanfield approximation. The meanfield\ndifferential equation was solved by sixth order Runge-Kutta-Felberg method. We\ncalculated the transition temperature as a function of amplitude and frequency\nof the oscillating field. This was plotted against field amplitude taking\nfrequency as a parameter. As frequency increases the phase boundary is observed\nto become inflated. The phase boundary shows an inflection point which\nseparates the nature of the transition. On the dynamic phase boundary a\ntricritical point (TCP) was found, which separates the nature\n(continuous/discontinuous) of the dynamic transition across the phase boundary.\nThe inflection point is identified as the TCP and hence a simpler method of\ndetermining the position of TCP was found. TCP was observed to shift towards\nhigh field for higher frequency. As frequency decreases the dynamic phase\nboundary is observe to shrink. In the zero frequency limit this boundary shows\na tendency to merge to the temperature variation of the coercive field.\n", "machine_text": "\nIn this analysis, we employed the meanfield approximation to study a kinetic Ising ferromagnet responded to an oscillating magnetic field. Estimate of the transition temperature as a function of the amplitude and frequency was computed with the help of the sixth order Runge-Kutta-Felberg method. Plotting the data, the phase boundary was observed to expand as frequency intensifies, containing an inflection point that divides the type of transition. Upon further inspection, this inflection point was identfied as the tricritical point (TCP). We demonstrate that this inflection point can be used to reliably approximate the position of TCP. As the frequency decreases, the dynamic phase boundary was reduced and in the zero-frequency limit, it was seen that this boundary gravitated towards the temperature of the coercive field.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.457}
{"prompt": "Rephrase the abstract of an article with title 'Vortex in axion condensate as a dark matter halo'.\n  We study the possibility of the vortices formation in axion condensate on the\ngalactic scale. Such vortices can occur as a result of global rotation of the\nearly universe. We study analytical models of vortices and calculate exemplary\ngalaxy rotation curves. Depending on the setup it is possible to obtain a\nvariety of shapes which give a good qualitative agreement with observational\nresults. However, as we show, the extremely low velocity dispersions of the\naxions velocity are required to form the single vortex on the galactic scales.\nWe find that the required velocity dispersion is of the order of $\\sigma\n\\approx 10^{-12} \\frac{m}{s}$. This is much smaller that predicted within the\npresent understanding of the axion physics. The vortices in axion condensate\ncan be however formed on the much smaller scales and give seeds to the galaxy\nformation and to their angular momenta. On the other hand, the vortices can be\nformed on the galactic scales, but only if the mass of the axion-like particles\nis of the order of $10^{-30}$eV. In this case, the particle de Broglie\nwavelength is comparable with the galactic diameter. This condition must be\nfulfilled in order to keep the coherence of the quantum condensate on the\ngalactic scales.\n\n", "human_text": "  We study the possibility of the vortices formation in axion condensate on the\ngalactic scale. Such vortices can occur as a result of global rotation of the\nearly universe. We study analytical models of vortices and calculate exemplary\ngalaxy rotation curves. Depending on the setup it is possible to obtain a\nvariety of shapes which give a good qualitative agreement with observational\nresults. However, as we show, the extremely low velocity dispersions of the\naxions velocity are required to form the single vortex on the galactic scales.\nWe find that the required velocity dispersion is of the order of $\\sigma\n\\approx 10^{-12} \\frac{m}{s}$. This is much smaller that predicted within the\npresent understanding of the axion physics. The vortices in axion condensate\ncan be however formed on the much smaller scales and give seeds to the galaxy\nformation and to their angular momenta. On the other hand, the vortices can be\nformed on the galactic scales, but only if the mass of the axion-like particles\nis of the order of $10^{-30}$eV. In this case, the particle de Broglie\nwavelength is comparable with the galactic diameter. This condition must be\nfulfilled in order to keep the coherence of the quantum condensate on the\ngalactic scales.\n", "machine_text": "\nWe explore the potential for the generation of vortices in axion condensates on galactic scales and analyse the associated rotation curves of model galaxies. We find that when suitable configurations are assumed, the curves resemble observational results fairly closely. In order for a single vortex to form on galactic scales, the velocity dispersion of the axions must be incredibly low, on the order of $\\sigma\\approx 10^{-12} \\frac{m}{s}$, which is far lower than the current theories of axion physics suggest. Alternatively, if the axion-like particle has a mass of $10^{-30}$eV, its de Broglie wavelength may be comparable to the galactic diameter, allowing its condensate to remain coherent on the galactic scale. This result could provide the impetus for galaxy formation and impart angular momentum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3017}
{"prompt": "Rephrase the abstract of an article with title 'Correlation between Infrared Colors and Intensity Ratios of SiO Maser\n  Lines'.\n  We present the results of SiO millimeter-line observations of a sample of\nknown SiO maser sources covering a wide dust-temperature range. A cold part of\nthe sample was selected from the SiO maser sources found in our recent SiO\nmaser survey of cold dusty objects. The aim of the present research is to\ninvestigate the causes of the correlation between infrared colors and SiO maser\nintensity ratios among different transition lines. In particular, the\ncorrelation between infrared colors and SiO maser intensity ratio among the\nJ=1-0 v=1, 2, and 3 lines are mainly concerned in this paper. We observed in\ntotal 75 SiO maser sources with the Nobeyama 45m telescope quasi-simultaneously\nin the SiO J=1-0 v=0, 1, 2, 3, 4 and J=2-1 v=1, 2 lines. We also observed the\nsample in the 29SiO J=1-0 v=0 and J=2-1 v=0, and 30SiO J=1-0 v=0 lines, and the\nH2O 6(1,6)-5(2,3) line. As reported in previous papers, we confirmed that the\nintensity ratios of the SiO J=1-0 v=2 to v=1 lines clearly correlate with\ninfrared colors. In addition, we found possible correlation between infrared\ncolors and the intensity ratios of the SiO J=1-0 v=3 to v=1&2 lines. Two\noverlap lines of H2O (i.e., 11(6,6) nu_2=1 -> 12(7,5) nu_2=0 and 5(0,5) nu_2=2\n-> 6(3,4) nu_2=1) might explain these correlation if these overlap lines become\nstronger with increase of infrared colors, although the phenomena also might be\nexplained by more fundamental ways if we take into account the variation of\nopacity from object to object.\n\n", "human_text": "  We present the results of SiO millimeter-line observations of a sample of\nknown SiO maser sources covering a wide dust-temperature range. A cold part of\nthe sample was selected from the SiO maser sources found in our recent SiO\nmaser survey of cold dusty objects. The aim of the present research is to\ninvestigate the causes of the correlation between infrared colors and SiO maser\nintensity ratios among different transition lines. In particular, the\ncorrelation between infrared colors and SiO maser intensity ratio among the\nJ=1-0 v=1, 2, and 3 lines are mainly concerned in this paper. We observed in\ntotal 75 SiO maser sources with the Nobeyama 45m telescope quasi-simultaneously\nin the SiO J=1-0 v=0, 1, 2, 3, 4 and J=2-1 v=1, 2 lines. We also observed the\nsample in the 29SiO J=1-0 v=0 and J=2-1 v=0, and 30SiO J=1-0 v=0 lines, and the\nH2O 6(1,6)-5(2,3) line. As reported in previous papers, we confirmed that the\nintensity ratios of the SiO J=1-0 v=2 to v=1 lines clearly correlate with\ninfrared colors. In addition, we found possible correlation between infrared\ncolors and the intensity ratios of the SiO J=1-0 v=3 to v=1&2 lines. Two\noverlap lines of H2O (i.e., 11(6,6) nu_2=1 -> 12(7,5) nu_2=0 and 5(0,5) nu_2=2\n-> 6(3,4) nu_2=1) might explain these correlation if these overlap lines become\nstronger with increase of infrared colors, although the phenomena also might be\nexplained by more fundamental ways if we take into account the variation of\nopacity from object to object.\n", "machine_text": "\nThe purpose of this study is to look into the potential relationship between infrared color and line intensity ratios in various transitions of SiO masers. We compiled a sample of 75 SiO maser sources to examine the correlation between infrared colors and intensity ratios between the J=1-0 v=1, 2, and 3 lines. By utilizing the Nobeyama 45m telescope, we observed the sample in the SiO J=1-0 v=0, 1, 2, 3, 4 and J=2-1 v=1, 2 lines, as well as the 29SiO J=1-0 v=0 and J=2-1 v=0, and 30SiO J=1-0 v=0 lines, and the H2O 6(1,6)-5(2,3) line. We discovered that the intensity ratios of the SiO J=1-0 v=2 to v=1 lines have a clear correlation with infrared colors. In addition, it was found that there may be a correlation between infrared colors and the intensity ratios of the SiO J=1-0 v=3 to v=1&2 lines. It is plausible that two H2O overlap lines, 11(6,6) nu_2=1 -> 12(7,5) nu_2=0 and 5(0,5) nu_2=2 -> 6(3,4) nu_2=1, could be contributing to this correlation, though further investigations involving the effects of opacity on the variability of the results must be considered.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0945}
{"prompt": "Rephrase the abstract of an article with title 'SN 2006bp: Probing the Shock Breakout of a Type II-P Supernova'.\n  HET optical spectroscopy and unfiltered ROTSE-III photometry spanning the\nfirst 11 months since explosion of the Type II-P SN 2006bp are presented. Flux\nlimits from the days before discovery combined with the initial rapid\nbrightening suggest the supernova was first detected just hours after shock\nbreakout. Optical spectra obtained about 2 days after breakout exhibit narrow\nemission lines corresponding to HeII 4200, HeII 4686, and CIV 5805 in the rest\nframe, and these features persist in a second observation obtained 5 hours\nlater; however, these emission lines are not detected the following night nor\nin subsequent observations. We suggest that these lines emanate from material\nclose to the explosion site, possibly in the outer layers of the progenitor\nthat have been ionized by the high energy photons released at shock breakout. A\nP-Cygni profile is observed around 4450 A in the +2 and +3 day spectra.\nPrevious studies have attributed this feature to high velocity H-beta, but we\ndiscuss the possibility that this profile is instead due to HeII 4687. Further\nHET observations (14 nights in total) covering the spectral evolution across\nthe photometric plateau up to 73 days after breakout and during the nebular\nphase around day +340 are presented, and expansion velocities are derived for\nkey features. The measured decay slope for the unfiltered light curve is 0.0073\n+/- 0.0004 mag/day between days +121 and +335, which is significantly slower\nthan the decay of rate 56Co. We combine our HET measurements with published\nX-ray, UV, and optical data to obtain a quasi-bolometric light curve through\nday +60. We see a slow cooling over the first 25 days, but no sign of an early\nsharp peak; any such feature from the shock breakout must have lasted less than\n~1 day.[ABRIDGED]\n\n", "human_text": "  HET optical spectroscopy and unfiltered ROTSE-III photometry spanning the\nfirst 11 months since explosion of the Type II-P SN 2006bp are presented. Flux\nlimits from the days before discovery combined with the initial rapid\nbrightening suggest the supernova was first detected just hours after shock\nbreakout. Optical spectra obtained about 2 days after breakout exhibit narrow\nemission lines corresponding to HeII 4200, HeII 4686, and CIV 5805 in the rest\nframe, and these features persist in a second observation obtained 5 hours\nlater; however, these emission lines are not detected the following night nor\nin subsequent observations. We suggest that these lines emanate from material\nclose to the explosion site, possibly in the outer layers of the progenitor\nthat have been ionized by the high energy photons released at shock breakout. A\nP-Cygni profile is observed around 4450 A in the +2 and +3 day spectra.\nPrevious studies have attributed this feature to high velocity H-beta, but we\ndiscuss the possibility that this profile is instead due to HeII 4687. Further\nHET observations (14 nights in total) covering the spectral evolution across\nthe photometric plateau up to 73 days after breakout and during the nebular\nphase around day +340 are presented, and expansion velocities are derived for\nkey features. The measured decay slope for the unfiltered light curve is 0.0073\n+/- 0.0004 mag/day between days +121 and +335, which is significantly slower\nthan the decay of rate 56Co. We combine our HET measurements with published\nX-ray, UV, and optical data to obtain a quasi-bolometric light curve through\nday +60. We see a slow cooling over the first 25 days, but no sign of an early\nsharp peak; any such feature from the shock breakout must have lasted less than\n~1 day.[ABRIDGED]\n", "machine_text": "\nWe probe the shock breakout of a Type II-P supernova named SN 2006bp. We present HET optical spectroscopy and unfiltered ROTSE-III photometry for the first 11 months following the explosion. It suggested that the supernova was first detected a few hours after the shock breakout occurred. Two-day-old spectra exhibited features stemming from HeII 4200, HeII 4686, and CIV 5805 in the rest frame. These were absent in subsequent spectra taken later. We speculate that they are a product of the high energy photons released at the shock breakout, originating from the outer layers of the progenitor. Additionally, a P-Cygni profile around 4450 A was observed in two spectra following the explosion. We discuss its possible origins, as well as measure the expansion velocity of key features. A slow cooling was detected in the quasi-bolometric light curve up until 25 days following the explosion; however, there is no evidence for an early peak.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3478}
{"prompt": "Rephrase the abstract of an article with title 'XO-2b: Transiting Hot Jupiter in a Metal-rich Common Proper Motion\n  Binary'.\n  We report on a V=11.2 early K dwarf, XO-2 (GSC 03413-00005), that hosts a\nRp=0.98+0.03/-0.01 Rjup, Mp=0.57+/-0.06 Mjup transiting extrasolar planet,\nXO-2b, with an orbital period of 2.615857+/-0.000005 days. XO-2 has high\nmetallicity, [Fe/H]=0.45+/-0.02, high proper motion, mu_tot=157 mas/yr, and has\na common proper motion stellar companion with 31\" separation. The two stars are\nnearly identical twins, with very similar spectra and apparent magnitudes. Due\nto the high metallicity, these early K dwarf stars have a mass and radius close\nto solar, Ms=0.98+/-0.02 Msolar and Rs=0.97+0.02/-0.01 Rsolar. The high proper\nmotion of XO-2 results from an eccentric orbit (Galactic pericenter, Rper<4\nkpc) well confined to the Galactic disk (Zmax~100 pc). In addition, the phase\nspace position of XO-2 is near the Hercules dynamical stream, which points to\nan origin of XO-2 in the metal-rich, inner Thin Disk and subsequent dynamical\nscattering into the solar neighborhood. We describe an efficient Markov Chain\nMonte Carlo algorithm for calculating the Bayesian posterior probability of the\nsystem parameters from a transit light curve.\n\n", "human_text": "  We report on a V=11.2 early K dwarf, XO-2 (GSC 03413-00005), that hosts a\nRp=0.98+0.03/-0.01 Rjup, Mp=0.57+/-0.06 Mjup transiting extrasolar planet,\nXO-2b, with an orbital period of 2.615857+/-0.000005 days. XO-2 has high\nmetallicity, [Fe/H]=0.45+/-0.02, high proper motion, mu_tot=157 mas/yr, and has\na common proper motion stellar companion with 31\" separation. The two stars are\nnearly identical twins, with very similar spectra and apparent magnitudes. Due\nto the high metallicity, these early K dwarf stars have a mass and radius close\nto solar, Ms=0.98+/-0.02 Msolar and Rs=0.97+0.02/-0.01 Rsolar. The high proper\nmotion of XO-2 results from an eccentric orbit (Galactic pericenter, Rper<4\nkpc) well confined to the Galactic disk (Zmax~100 pc). In addition, the phase\nspace position of XO-2 is near the Hercules dynamical stream, which points to\nan origin of XO-2 in the metal-rich, inner Thin Disk and subsequent dynamical\nscattering into the solar neighborhood. We describe an efficient Markov Chain\nMonte Carlo algorithm for calculating the Bayesian posterior probability of the\nsystem parameters from a transit light curve.\n", "machine_text": "\nWe examine an early K-type dwarf star, XO-2 (GSC 03413-00005), that is found to host an extrasolar planet, XO-2b, possessing a mass of 0.57+/-0.06 Mjup and a radius of 0.98+0.03/-0.01 Rjup, with an orbital period of 2.615857+/-0.000005 days. This star has a high metal content (with [Fe/H]=0.45+/-0.02), two components in common proper motion with a separation of 31\u201d, and a high total proper motion of 157 mas/yr. These components are almost identical in terms of spectrum, magnitude and stellar mass/radius (Ms=0.98+/-0.02 Msolar; Rs=0.97+0.02/-0.01 Rsolar), and may have been thrown towards the Galactic Disk as a result of their eccentric orbit (Rper<4 kpc). Furthermore, XO-2 is regionally located to a Hercules dynamical stream, potentially tracing back its origin to the metal-rich, inner rim of the Thin Disk. We introduce a new Markov Chain Monte Carlo method in order to assess, via a transit light curve, the posterior probability of the parameters of this system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0003}
{"prompt": "Rephrase the abstract of an article with title 'PSR J1453+1902 and the radio luminosities of solitary versus binary\n  millisecond pulsars'.\n  We present 3 yr of timing observations for PSR J1453+1902, a 5.79-ms pulsar\ndiscovered during a 430-MHz drift-scan survey with the Arecibo telescope. Our\nobservations show that PSR J1453+1902 is solitary and has a proper motion of\n8(2) mas/yr. At the nominal distance of 1.2 kpc estimated from the pulsar's\ndispersion measure, this corresponds to a transverse speed of 46(11) km/s,\ntypical of the millisecond pulsar population. We analyse the current sample of\n55 millisecond pulsars in the Galactic disk and revisit the question of whether\nthe luminosities of isolated millisecond pulsars are different from their\nbinary counterparts. We demonstrate that the apparent differences in the\nluminosity distributions seen in samples selected from 430-MHz surveys can be\nexplained by small-number statistics and observational selection biases. An\nexamination of the sample from 1400-MHz surveys shows no differences in the\ndistributions. The simplest conclusion from the current data is that the spin,\nkinematic, spatial and luminosity distributions of isolated and binary\nmillisecond pulsars are consistent with a single homogeneous population.\n\n", "human_text": "  We present 3 yr of timing observations for PSR J1453+1902, a 5.79-ms pulsar\ndiscovered during a 430-MHz drift-scan survey with the Arecibo telescope. Our\nobservations show that PSR J1453+1902 is solitary and has a proper motion of\n8(2) mas/yr. At the nominal distance of 1.2 kpc estimated from the pulsar's\ndispersion measure, this corresponds to a transverse speed of 46(11) km/s,\ntypical of the millisecond pulsar population. We analyse the current sample of\n55 millisecond pulsars in the Galactic disk and revisit the question of whether\nthe luminosities of isolated millisecond pulsars are different from their\nbinary counterparts. We demonstrate that the apparent differences in the\nluminosity distributions seen in samples selected from 430-MHz surveys can be\nexplained by small-number statistics and observational selection biases. An\nexamination of the sample from 1400-MHz surveys shows no differences in the\ndistributions. The simplest conclusion from the current data is that the spin,\nkinematic, spatial and luminosity distributions of isolated and binary\nmillisecond pulsars are consistent with a single homogeneous population.\n", "machine_text": "\nWe investigate the radio luminosities of solitary versus binary millisecond pulsars through observations of PSR J1453+1902, a 5.79-ms pulsar from a 430-MHz drift-scan survey with the Arecibo telescope. The observations confirm this object is isolated, with a proper motion of 8(2) mas/yr and a nominal distance of 1.2 kpc. Evaluating a current sample of 55 pulsars in the Galactic disk, we examine whether the luminosities of isolated millisecond pulsars differ from their companions. By examining survey samples from 430-MHz and 1400-MHz, we see no distinction in the luminosity distributions, implying a single homogeneous population. Therefore, our results suggest that the spin, kinematic, spatial and luminosity distributions of isolated and binary millisecond pulsars are drawn from the same source.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0685}
{"prompt": "Rephrase the abstract of an article with title 'Dynamic fibrils in H-alpha and C IV'.\n  Aim: To study the interaction of the solar chromosphere with the transition\nregion, in particular active-region jets in the transition region and their\nrelation to chromospheric fibrils. Methods: We carefully align image sequences\ntaken simultaneously in C IV with the Transition Region and Coronal Explorer\nand in H-alpha with the Swedish 1-m Solar Telescope. We examine the temporal\nevolution of \"dynamic fibrils\", i.e., individual short-lived active-region\nchromospheric jet-like features in H-alpha. Results: All dynamic fibrils appear\nas absorption features in H-alpha that progress from the blue to the red wing\nthrough the line, and often show recurrent behavior. Some of them, but not all,\nappear also as bright features in C IV which develop at or just beyond the apex\nof the H-alpha darkening. They tend to best resemble the H-alpha fibril at +700\nmA half a minute earlier. Conclusions: Dynamic chromospheric fibrils observed\nin H-alpha regularly correspond to transition-region jets observed in the\nultraviolet. This correspondence suggests that some plasma associated with\ndynamic fibrils is heated to transition-region temperatures.\n\n", "human_text": "  Aim: To study the interaction of the solar chromosphere with the transition\nregion, in particular active-region jets in the transition region and their\nrelation to chromospheric fibrils. Methods: We carefully align image sequences\ntaken simultaneously in C IV with the Transition Region and Coronal Explorer\nand in H-alpha with the Swedish 1-m Solar Telescope. We examine the temporal\nevolution of \"dynamic fibrils\", i.e., individual short-lived active-region\nchromospheric jet-like features in H-alpha. Results: All dynamic fibrils appear\nas absorption features in H-alpha that progress from the blue to the red wing\nthrough the line, and often show recurrent behavior. Some of them, but not all,\nappear also as bright features in C IV which develop at or just beyond the apex\nof the H-alpha darkening. They tend to best resemble the H-alpha fibril at +700\nmA half a minute earlier. Conclusions: Dynamic chromospheric fibrils observed\nin H-alpha regularly correspond to transition-region jets observed in the\nultraviolet. This correspondence suggests that some plasma associated with\ndynamic fibrils is heated to transition-region temperatures.\n", "machine_text": "\nThe purpose of this study was to understand the connection between the solar chromosphere and the transition region by examining the activity of certain jets in the transition region. In order to study this, images that were taken simulataenously in Hydrogen-alpha (H-alpha) and C IV (ultraviolet) were carefully aligned. It was found that the so-called \"dynamic fibrils\" (jet-like features in the chromosphere) were seen as an absorption in the H-alpha line, which then transitioned from blue to red in the line. Moreover, some but not all of these dynamic fibrils also appeared as bright features in the C IV images appearing at or beyond the peak of the dimming of the H-alpha line. The results suggest that some of the plasma connected to dynamic fibrils was heated to transition-region temperatures.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.2011}
{"prompt": "Rephrase the abstract of an article with title 'Probing dark energy with steerable wavelets through correlation of WMAP\n  and NVSS local morphological measures'.\n  Using local morphological measures on the sphere defined through a steerable\nwavelet analysis, we examine the three-year WMAP and the NVSS data for\ncorrelation induced by the integrated Sachs-Wolfe (ISW) effect. The steerable\nwavelet constructed from the second derivative of a Gaussian allows one to\ndefine three local morphological measures, namely the signed-intensity,\norientation and elongation of local features. Detections of correlation between\nthe WMAP and NVSS data are made with each of these morphological measures. The\nmost significant detection is obtained in the correlation of the\nsigned-intensity of local features at a significance of 99.9%. By inspecting\nsigned-intensity sky maps, it is possible for the first time to see the\ncorrelation between the WMAP and NVSS data by eye. Foreground contamination and\ninstrumental systematics in the WMAP data are ruled out as the source of all\nsignificant detections of correlation. Our results provide new insight on the\nISW effect by probing the morphological nature of the correlation induced\nbetween the cosmic microwave background and large scale structure of the\nUniverse. Given the current constraints on the flatness of the Universe, our\ndetection of the ISW effect again provides direct and independent evidence for\ndark energy. Moreover, this new morphological analysis may be used in future to\nhelp us to better understand the nature of dark energy.\n\n", "human_text": "  Using local morphological measures on the sphere defined through a steerable\nwavelet analysis, we examine the three-year WMAP and the NVSS data for\ncorrelation induced by the integrated Sachs-Wolfe (ISW) effect. The steerable\nwavelet constructed from the second derivative of a Gaussian allows one to\ndefine three local morphological measures, namely the signed-intensity,\norientation and elongation of local features. Detections of correlation between\nthe WMAP and NVSS data are made with each of these morphological measures. The\nmost significant detection is obtained in the correlation of the\nsigned-intensity of local features at a significance of 99.9%. By inspecting\nsigned-intensity sky maps, it is possible for the first time to see the\ncorrelation between the WMAP and NVSS data by eye. Foreground contamination and\ninstrumental systematics in the WMAP data are ruled out as the source of all\nsignificant detections of correlation. Our results provide new insight on the\nISW effect by probing the morphological nature of the correlation induced\nbetween the cosmic microwave background and large scale structure of the\nUniverse. Given the current constraints on the flatness of the Universe, our\ndetection of the ISW effect again provides direct and independent evidence for\ndark energy. Moreover, this new morphological analysis may be used in future to\nhelp us to better understand the nature of dark energy.\n", "machine_text": "\nBy means of a steerable wavelet that involves the second derivative of a Gaussian, we can now visually inspect, for the first time, the correlation between cosmic microwave background (CWM) and large scale structure of the Universe on a local level. This approach reveals the integrated Sachs-Wolfe (ISW) effect that is consistent with dark energy through the use of three morphological measures -the signed-intensity, orientation and elongation- made from WMAP and NVSS data. The correlations are significant at 99.9% and instrumental systematics and foreground contamination are ruled out as their origin. Therefore, this new morphological analysis delivers independent evidence for dark energy as well as a better way to explore its nature in the future.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0626}
{"prompt": "Rephrase the abstract of an article with title 'The largest eigenvalues of finite rank deformation of large Wigner\n  matrices: convergence and nonuniversality of the fluctuations'.\n  In this paper, we investigate the asymptotic spectrum of complex or real\nDeformed Wigner matrices $(M_N)_N$ defined by $M_N=W_N/\\sqrt{N}+A_N$ where\n$W_N$ is an $N\\times N$ Hermitian (resp., symmetric) Wigner matrix whose\nentries have a symmetric law satisfying a Poincar\\'{e} inequality. The matrix\n$A_N$ is Hermitian (resp., symmetric) and deterministic with all but finitely\nmany eigenvalues equal to zero. We first show that, as soon as the first\nlargest or last smallest eigenvalues of $A_N$ are sufficiently far from zero,\nthe corresponding eigenvalues of $M_N$ almost surely exit the limiting\nsemicircle compact support as the size $N$ becomes large. The corresponding\nlimits are universal in the sense that they only involve the variance of the\nentries of $W_N$. On the other hand, when $A_N$ is diagonal with a sole simple\nnonnull eigenvalue large enough, we prove that the fluctuations of the largest\neigenvalue are not universal and vary with the particular distribution of the\nentries of $W_N$.\n\n", "human_text": "  In this paper, we investigate the asymptotic spectrum of complex or real\nDeformed Wigner matrices $(M_N)_N$ defined by $M_N=W_N/\\sqrt{N}+A_N$ where\n$W_N$ is an $N\\times N$ Hermitian (resp., symmetric) Wigner matrix whose\nentries have a symmetric law satisfying a Poincar\\'{e} inequality. The matrix\n$A_N$ is Hermitian (resp., symmetric) and deterministic with all but finitely\nmany eigenvalues equal to zero. We first show that, as soon as the first\nlargest or last smallest eigenvalues of $A_N$ are sufficiently far from zero,\nthe corresponding eigenvalues of $M_N$ almost surely exit the limiting\nsemicircle compact support as the size $N$ becomes large. The corresponding\nlimits are universal in the sense that they only involve the variance of the\nentries of $W_N$. On the other hand, when $A_N$ is diagonal with a sole simple\nnonnull eigenvalue large enough, we prove that the fluctuations of the largest\neigenvalue are not universal and vary with the particular distribution of the\nentries of $W_N$.\n", "machine_text": "This article examines the asymptotic characteristics of large Deformed Wigner matrices $M_N=W_N/\\sqrt{N}+A_N$. $W_N$ is a Hermitian (respectively, symmetric) matrix with entries that follow a symmetric law, while $A_N$ is deterministic Hermitian (respectively, symmetric) with almost all eigenvalues equal to zero. We determine that as soon as the first largest or last smallest eigenvalues of $A_N$ are sufficiently large, the corresponding eigenvalues of $M_N$ almost surely escape the limiting semicircle support as $N$ increases. Furthermore, these limits are universal in the sense that the variance of the entries of $W_N$ is the only factor involved. Conversely, when $A_N$ is diagonal with a single large non-zero eigenvalue, we prove that the fluctuations of the largest eigenvalue are not universal, and are determined by the particular distribution of the entries of $W_N$.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0136}
{"prompt": "Rephrase the abstract of an article with title 'Energy dependence of jet transport parameter and parton saturation in\n  quark-gluon plasma'.\n  We study the evolution and saturation of the gluon distribution function in\nthe quark-gluon plasma as probed by a propagating parton and its effect on the\ncomputation of jet quenching or transport parameter $\\hat{q}$. For thermal\npartons, the saturation scale $Q^2_s$ is found to be proportional to the Debye\nscreening mass $\\mu_D^2$. For hard probes, evolution at small $x=Q^2_s/6ET$\nleads to jet energy dependence of $\\hat{q}$. We study this dependence for both\na conformal gauge theory in weak and strong coupling limit and for (pure gluon)\nQCD. The energy dependence can be used to extract the shear viscosity $\\eta$ of\nthe medium since $\\eta$ can be related to the transport parameter for thermal\npartons in a transport description. We also derive upper bounds on the\ntransport parameter for both energetic and thermal partons. The later leads to\na lower bound on shear viscosity-to-entropy density ratio which is consistent\nwith the conjectured lower bound $\\eta/s\\geq 1/4\\pi$. We also discuss the\nimplications on the study of jet quenching at the BNL Relativistic Heavy Ion\nCollider and the CERN Large Hadron Collider and the bulk properties of the\ndense matter.\n\n", "human_text": "  We study the evolution and saturation of the gluon distribution function in\nthe quark-gluon plasma as probed by a propagating parton and its effect on the\ncomputation of jet quenching or transport parameter $\\hat{q}$. For thermal\npartons, the saturation scale $Q^2_s$ is found to be proportional to the Debye\nscreening mass $\\mu_D^2$. For hard probes, evolution at small $x=Q^2_s/6ET$\nleads to jet energy dependence of $\\hat{q}$. We study this dependence for both\na conformal gauge theory in weak and strong coupling limit and for (pure gluon)\nQCD. The energy dependence can be used to extract the shear viscosity $\\eta$ of\nthe medium since $\\eta$ can be related to the transport parameter for thermal\npartons in a transport description. We also derive upper bounds on the\ntransport parameter for both energetic and thermal partons. The later leads to\na lower bound on shear viscosity-to-entropy density ratio which is consistent\nwith the conjectured lower bound $\\eta/s\\geq 1/4\\pi$. We also discuss the\nimplications on the study of jet quenching at the BNL Relativistic Heavy Ion\nCollider and the CERN Large Hadron Collider and the bulk properties of the\ndense matter.\n", "machine_text": "\nThis article examines the impact of a moving parton and the saturation of gluon distribution in the quark-gluon plasma on jet quenching or transport parameter $\\hat{q}$. We analyze the dependence of $\\hat{q}$ on jet energy when related to the Debye screening mass $\\mu_D^2$ and find results for both a conformal gauge theory and for QCD. We investigate the extraction of shear viscosity $\\eta$ from transport parameters of thermal partons as well as derive limits on said parameters. This leads to a lower bound on the ratio of shear viscosity-to-entropy density that is in agreement with the proposed value of $\\eta/s\\geq 1/4\\pi$. Additionally, we comment on the implications these findings have for studying jet quenching at two major particle colliders.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1352}
{"prompt": "Rephrase the abstract of an article with title 'Cosmic string formation by flux trapping'.\n  We study the formation of cosmic strings by confining a stochastic magnetic\nfield into flux tubes in a numerical simulation. We use overdamped evolution in\na potential that is minimized when the flux through each face in the simulation\nlattice is a multiple of the fundamental flux quantum. When the typical number\nof flux quanta through a correlation-length-sized region is initially about 1,\nwe find a string network similar to that generated by the Kibble-Zurek\nmechanism. With larger initial flux, the loop distribution and the Brownian\nshape of the infinite strings remain unchanged, but the fraction of length in\ninfinite strings is increased. A 2D slice of the network exhibits bundles of\nstrings pointing in the same direction, as in earlier 2D simulations. We find,\nhowever, that strings belonging to the same bundle do not stay together in 3D\nfor much longer than the correlation length. As the initial flux per\ncorrelation length is decreased, there is a point at which infinite strings\ndisappear, as in the Hagedorn transition.\n\n", "human_text": "  We study the formation of cosmic strings by confining a stochastic magnetic\nfield into flux tubes in a numerical simulation. We use overdamped evolution in\na potential that is minimized when the flux through each face in the simulation\nlattice is a multiple of the fundamental flux quantum. When the typical number\nof flux quanta through a correlation-length-sized region is initially about 1,\nwe find a string network similar to that generated by the Kibble-Zurek\nmechanism. With larger initial flux, the loop distribution and the Brownian\nshape of the infinite strings remain unchanged, but the fraction of length in\ninfinite strings is increased. A 2D slice of the network exhibits bundles of\nstrings pointing in the same direction, as in earlier 2D simulations. We find,\nhowever, that strings belonging to the same bundle do not stay together in 3D\nfor much longer than the correlation length. As the initial flux per\ncorrelation length is decreased, there is a point at which infinite strings\ndisappear, as in the Hagedorn transition.\n", "machine_text": "\nWe explore the formation of cosmic strings by trapping a stochastic magnetic field inside flux tubes in a numerical simulation. To achieve this, the potential is minimized when the flow of flux through every surface of the simulation lattice is a multiple of the fundamental flux quantum. When commencing with the typical number of flux quanta in a correlation-length-sized region of approximately 1, a formed string network had seen similarity to that of the Kibble-Zurek Mechanism. When the initial flux rate per correlation length is amplified, the loop distribution and the Brownian shape of the continuous strings persists, although the length portion of the infinite strings is raised. Also, viewing a two dimensional slice of the network, strings are seen arranged in bundles facing in the same direction as in past 2D simulations. Our finding \u2013 which differs from before \u2013 is that when viewed in 3D, strings tied in the same bundle do not stay connected following the correlation length. When lowering the rate of the initial flux per correlation length, the dissipation of the infinite strings occur, a situation reminiscent of the Hagedorn transition.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1577}
{"prompt": "Rephrase the abstract of an article with title 'Critical Casimir Effect in superfluid wetting films'.\n  Recent experimental data for the complete wetting behavior of pure 4He and of\n3He-4He mixtures exposed to solid substrates show that there is a change of the\ncorresponding film thicknesses L upon approaching thermodynamically the\nlambda-transition and the tricritical end point, respectively, which can be\nattributed to critical Casimir forces f_C. We calculate the scaling functions\nvartheta of f_C within models representing the corresponding universality\nclasses. For the mixtures our analysis provides an understanding of the rich\nbehavior of vartheta deduced from the experimental data and predicts the\ncrossover behavior between the tricritical point and the lambda-transition of\npure 4He which are connected by a line of critical points. The formation of a\n'soft-mode' phase within the wetting films gives rise to a pronounced maximum\nof f_C below the tricritical point as observed experimentally. Near the\ntricritical point we find logarithmic corrections ~L^(-3)(ln L)^(1/2) for the\nleading behavior of vartheta dominating the contributions from the background\ndispersion forces.\n\n", "human_text": "  Recent experimental data for the complete wetting behavior of pure 4He and of\n3He-4He mixtures exposed to solid substrates show that there is a change of the\ncorresponding film thicknesses L upon approaching thermodynamically the\nlambda-transition and the tricritical end point, respectively, which can be\nattributed to critical Casimir forces f_C. We calculate the scaling functions\nvartheta of f_C within models representing the corresponding universality\nclasses. For the mixtures our analysis provides an understanding of the rich\nbehavior of vartheta deduced from the experimental data and predicts the\ncrossover behavior between the tricritical point and the lambda-transition of\npure 4He which are connected by a line of critical points. The formation of a\n'soft-mode' phase within the wetting films gives rise to a pronounced maximum\nof f_C below the tricritical point as observed experimentally. Near the\ntricritical point we find logarithmic corrections ~L^(-3)(ln L)^(1/2) for the\nleading behavior of vartheta dominating the contributions from the background\ndispersion forces.\n", "machine_text": "\nA recent investigation of pure 4He and mixtures of 3He-4He exposed to solid substrates reveals a shift in the corresponding film thickness upon nearing the lambda-transition and tricritical endpoint, respectively. The resulting phenomenon, which is caused by the critical Casimir force f_C, is analyzed in terms of models that represent universality classes. Results from the data suggest the emergence of a 'soft-mode' phase, which promotes a pronounced maximum in f_C near the tricritical point. Simulations also suggest that logarithmic corrections of  ~L^(-3)(ln L)^(1/2) govern the behavior of the force when in close proximity to the tricritical point, overriding the predominant contributions from the background dispersion forces.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1064}
{"prompt": "Rephrase the abstract of an article with title 'Sampling using a `bank' of clues'.\n  An easy-to-implement form of the Metropolis Algorithm is described which,\nunlike most standard techniques, is well suited to sampling from multi-modal\ndistributions on spaces with moderate numbers of dimensions (order ten) in\nenvironments typical of investigations into current constraints on\nBeyond-the-Standard-Model physics. The sampling technique makes use of\npre-existing information (which can safely be of low or uncertain quality)\nrelating to the distribution from which it is desired to sample. This\ninformation should come in the form of a ``bank'' or ``cache'' of space points\nof which at least some may be expected to be near regions of interest in the\ndesired distribution. In practical circumstances such ``banks of clues'' are\neasy to assemble from earlier work, aborted runs, discarded burn-in samples\nfrom failed sampling attempts, or from prior scouting investigations. The\ntechnique equilibrates between disconnected parts of the distribution without\nuser input. The algorithm is not lead astray by ``bad'' clues, but there is no\nfree lunch: performance gains will only be seen where clues are helpful.\n\n", "human_text": "  An easy-to-implement form of the Metropolis Algorithm is described which,\nunlike most standard techniques, is well suited to sampling from multi-modal\ndistributions on spaces with moderate numbers of dimensions (order ten) in\nenvironments typical of investigations into current constraints on\nBeyond-the-Standard-Model physics. The sampling technique makes use of\npre-existing information (which can safely be of low or uncertain quality)\nrelating to the distribution from which it is desired to sample. This\ninformation should come in the form of a ``bank'' or ``cache'' of space points\nof which at least some may be expected to be near regions of interest in the\ndesired distribution. In practical circumstances such ``banks of clues'' are\neasy to assemble from earlier work, aborted runs, discarded burn-in samples\nfrom failed sampling attempts, or from prior scouting investigations. The\ntechnique equilibrates between disconnected parts of the distribution without\nuser input. The algorithm is not lead astray by ``bad'' clues, but there is no\nfree lunch: performance gains will only be seen where clues are helpful.\n", "machine_text": "This paper presents a Metropolis Algorithm-based sampling method that is suitable for exploring moderate-dimensional spaces from multi-modal distributions. The technique requires an existing 'bank' or 'cache' of points that are presumed to be close to the regions of interest in the distribution being sampled. These points can be gathered through past studies, failed sampling efforts, or other methods. The algorithm is shown to be efficient even with weakened clues, though optimal performance will only be achieved when clues are helpful.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0486}
{"prompt": "Rephrase the abstract of an article with title 'The Maximal Amount of Gravitational Waves in the Curvaton Scenario'.\n  The curvaton scenario for the generation of the cosmological curvature\nperturbation on large scales represents an alternative to the standard\nslow-roll scenario of inflation in which the observed density perturbations are\ndue to fluctuations of the inflaton field itself. Its basic assumption is that\nthe initial curvature perturbation due to the inflaton field is negligible.\nThis is attained by lowering the energy scale of inflation, thereby highly\nsuppressing the amount of gravitational waves produced during inflation. We\ncompute the power-spectrum of the gravitational waves generated at second order\nin perturbation theory by the curvaton (isocurvature) perturbations between the\nend of inflation and the curvaton decay. An interesting property of this\ncontribution to the tensor perturbations is that it is directly proportional to\nthe amount of non-Gaussianity predicted within the curvaton scenario. We show\nthat the spectrum of gravitational waves may be in the range of future\ngravitational wave detectors.\n\n", "human_text": "  The curvaton scenario for the generation of the cosmological curvature\nperturbation on large scales represents an alternative to the standard\nslow-roll scenario of inflation in which the observed density perturbations are\ndue to fluctuations of the inflaton field itself. Its basic assumption is that\nthe initial curvature perturbation due to the inflaton field is negligible.\nThis is attained by lowering the energy scale of inflation, thereby highly\nsuppressing the amount of gravitational waves produced during inflation. We\ncompute the power-spectrum of the gravitational waves generated at second order\nin perturbation theory by the curvaton (isocurvature) perturbations between the\nend of inflation and the curvaton decay. An interesting property of this\ncontribution to the tensor perturbations is that it is directly proportional to\nthe amount of non-Gaussianity predicted within the curvaton scenario. We show\nthat the spectrum of gravitational waves may be in the range of future\ngravitational wave detectors.\n", "machine_text": "\n\nThe curvaton scenario has been proposed in order to attain a cosmological\ncurvature perturbation on large scales which acts as an alternative to the standard\nslow-roll scenario of inflation. This is realized by greatly reducing the\ninflation energy scale and thereby suppressing the amplitude of gravitational\nwaves produced during inflation. Through second-order perturbation theory, this\nprocess of the curvaton perturbations could result in generated tensor\nperturbations. Our findings suggest that the outcome of this mechanism can be\ndetected by future gravitational wave detectors, while also being highly\ncorrelated with the amount of non-Gaussianity predicted in the curvaton scenario.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.424}
{"prompt": "Rephrase the abstract of an article with title 'Decoherence of many-spin systems in NMR: From molecular characterization\n  to an environmentally induced quantum dynamical phase transition'.\n  The control of open quantum systems has a fundamental relevance for fields\nranging from quantum information processing to nanotechnology. Typically, the\nsystem whose coherent dynamics one wants to manipulate, interacts with an\nenvironment that smoothly degrades its quantum dynamics. Thus, a precise\nunderstanding of the inner mechanisms of this process, called \"decoherence\", is\ncritical to develop strategies to control the quantum dynamics. In this thesis\nwe solved the generalized Liouville-von Neumann quantum master equation to\nobtain the dynamics of many-spin systems interacting with a spin bath. We also\nsolve the spin dynamics within the Keldysh formalism. Both methods lead to\nidentical solutions and together gave us the possibility to obtain numerous\nphysical predictions that contrast well with Nuclear Magnetic Resonance\nexperiments. We applied these tools for molecular characterizations,\ndevelopment of new numerical methodologies and the control of quantum dynamics\nin experimental implementations. But, more important, these results contributed\nto fundamental physical interpretations of how quantum dynamics behaves in open\nsystems. In particular, we found a manifestation of an environmentally induced\nquantum dynamical phase transition.\n\n", "human_text": "  The control of open quantum systems has a fundamental relevance for fields\nranging from quantum information processing to nanotechnology. Typically, the\nsystem whose coherent dynamics one wants to manipulate, interacts with an\nenvironment that smoothly degrades its quantum dynamics. Thus, a precise\nunderstanding of the inner mechanisms of this process, called \"decoherence\", is\ncritical to develop strategies to control the quantum dynamics. In this thesis\nwe solved the generalized Liouville-von Neumann quantum master equation to\nobtain the dynamics of many-spin systems interacting with a spin bath. We also\nsolve the spin dynamics within the Keldysh formalism. Both methods lead to\nidentical solutions and together gave us the possibility to obtain numerous\nphysical predictions that contrast well with Nuclear Magnetic Resonance\nexperiments. We applied these tools for molecular characterizations,\ndevelopment of new numerical methodologies and the control of quantum dynamics\nin experimental implementations. But, more important, these results contributed\nto fundamental physical interpretations of how quantum dynamics behaves in open\nsystems. In particular, we found a manifestation of an environmentally induced\nquantum dynamical phase transition.\n", "machine_text": "This thesis explores the decoherence of many-spin systems in Nuclear Magnetic Resonance, in order to better understand how quantum dynamics behaves in open systems. We derived the Generalized Liouville-von Neumann quantum master equation to study the dynamics of many-spin systems and their interaction with a spin bath. Our results confirm several physical interpretations and contrast well with NMR experiments. We utilized our findings for molecular characterization, numerical method development, and the control of quantum dynamics in experiments. Most notably, we discovered an environmentally induced quantum dynamical phase transition.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.235}
{"prompt": "Rephrase the abstract of an article with title 'Physisorption of Nucleobases on Graphene'.\n  We report the results of our first-principles investigation on the\ninteraction of the nucleobases adenine (A), cytosine (C), guanine (G), thymine\n(T), and uracil (U) with graphene, carried out within the density functional\ntheory framework, with additional calculations utilizing Hartree--Fock plus\nsecond-order Moeller-Plesset perturbation theory. The calculated binding energy\nof the nucleobases shows the following hierarchy: G > T ~ C ~ A > U, with the\nequilibrium configuration being very similar for all five of them. Our results\nclearly demonstrate that the nucleobases exhibit significantly different\ninteraction strengths when physisorbed on graphene. The stabilizing factor in\nthe interaction between the base molecule and graphene sheet is dominated by\nthe molecular polarizability that allows a weakly attractive dispersion force\nto be induced between them. The present study represents a significant step\ntowards a first-principles understanding of how the base sequence of DNA can\naffect its interaction with carbon nanotubes, as observed experimentally.\n\n", "human_text": "  We report the results of our first-principles investigation on the\ninteraction of the nucleobases adenine (A), cytosine (C), guanine (G), thymine\n(T), and uracil (U) with graphene, carried out within the density functional\ntheory framework, with additional calculations utilizing Hartree--Fock plus\nsecond-order Moeller-Plesset perturbation theory. The calculated binding energy\nof the nucleobases shows the following hierarchy: G > T ~ C ~ A > U, with the\nequilibrium configuration being very similar for all five of them. Our results\nclearly demonstrate that the nucleobases exhibit significantly different\ninteraction strengths when physisorbed on graphene. The stabilizing factor in\nthe interaction between the base molecule and graphene sheet is dominated by\nthe molecular polarizability that allows a weakly attractive dispersion force\nto be induced between them. The present study represents a significant step\ntowards a first-principles understanding of how the base sequence of DNA can\naffect its interaction with carbon nanotubes, as observed experimentally.\n", "machine_text": "We analyze the ability of different nucleobases to interact with graphene in a study that uses density functional theory and Hartree-Fock plus second order Moeller-Plesset perturbation theory. Our results demonstrate that the nucleobases, adenine (A), cytosine (C), guanine (G), thymine (T), and uracil (U), inherently differ in how strongly they interact with graphene due to its polarizability. This type of interaction is weak but crucial in understanding the behavior of DNA when it interacts with carbon nanotubes, as has been seen experimentally.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1316}
{"prompt": "Rephrase the abstract of an article with title 'The Dark Side of a Patchwork Universe'.\n  While observational cosmology has recently progressed fast, it revealed a\nserious dilemma called dark energy: an unknown source of exotic energy with\nnegative pressure driving a current accelerating phase of the universe. All\nattempts so far to find a convincing theoretical explanation have failed, so\nthat one of the last hopes is the yet to be developed quantum theory of\ngravity. In this article, loop quantum gravity is considered as a candidate,\nwith an emphasis on properties which might play a role for the dark energy\nproblem. Its basic feature is the discrete structure of space, often associated\nwith quantum theories of gravity on general grounds. This gives rise to\nwell-defined matter Hamiltonian operators and thus sheds light on conceptual\nquestions related to the cosmological constant problem. It also implies typical\nquantum geometry effects which, from a more phenomenological point of view, may\nresult in dark energy. In particular the latter scenario allows several\nnon-trivial tests which can be made more precise by detailed observations in\ncombination with a quantitative study of numerical quantum gravity. If the\nspeculative possibility of a loop quantum gravitational origin of dark energy\nturns out to be realized, a program as outlined here will help to hammer out\nour ideas for a quantum theory of gravity, and at the same time allow\npredictions for the distant future of our universe.\n\n", "human_text": "  While observational cosmology has recently progressed fast, it revealed a\nserious dilemma called dark energy: an unknown source of exotic energy with\nnegative pressure driving a current accelerating phase of the universe. All\nattempts so far to find a convincing theoretical explanation have failed, so\nthat one of the last hopes is the yet to be developed quantum theory of\ngravity. In this article, loop quantum gravity is considered as a candidate,\nwith an emphasis on properties which might play a role for the dark energy\nproblem. Its basic feature is the discrete structure of space, often associated\nwith quantum theories of gravity on general grounds. This gives rise to\nwell-defined matter Hamiltonian operators and thus sheds light on conceptual\nquestions related to the cosmological constant problem. It also implies typical\nquantum geometry effects which, from a more phenomenological point of view, may\nresult in dark energy. In particular the latter scenario allows several\nnon-trivial tests which can be made more precise by detailed observations in\ncombination with a quantitative study of numerical quantum gravity. If the\nspeculative possibility of a loop quantum gravitational origin of dark energy\nturns out to be realized, a program as outlined here will help to hammer out\nour ideas for a quantum theory of gravity, and at the same time allow\npredictions for the distant future of our universe.\n", "machine_text": "This article examines the possibility of loop quantum gravity as a potential explanation for the mysterious dark energy driving the expansion of the universe. The core feature of loop quantum gravity is the discrete structure of space, which opens the door to define matter Hamiltonians and address questions regarding the cosmological constant problem. From a more phenomenological perspective, quantum geometry effects may be the origin of dark energy. Tests of this scenario and a quantitative study of quantum gravity can provide predictions for the future of our universe.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4398}
{"prompt": "Rephrase the abstract of an article with title 'How to clean a dirty floor: Probabilistic potential theory and the\n  Dobrushin uniqueness theorem'.\n  Motivated by the Dobrushin uniqueness theorem in statistical mechanics, we\nconsider the following situation: Let \\alpha be a nonnegative matrix over a\nfinite or countably infinite index set X, and define the \"cleaning operators\"\n\\beta_h = I_{1-h} + I_h \\alpha for h: X \\to [0,1] (here I_f denotes the\ndiagonal matrix with entries f). We ask: For which \"cleaning sequences\" h_1,\nh_2, ... do we have c \\beta_{h_1} ... \\beta_{h_n} \\to 0 for a suitable class of\n\"dirt vectors\" c? We show, under a modest condition on \\alpha, that this occurs\nwhenever \\sum_i h_i = \\infty everywhere on X. More generally, we analyze the\ncleaning of subsets \\Lambda \\subseteq X and the final distribution of dirt on\nthe complement of \\Lambda. We show that when supp(h_i) \\subseteq \\Lambda with\n\\sum_i h_i = \\infty everywhere on \\Lambda, the operators \\beta_{h_1} ...\n\\beta_{h_n} converge as n \\to \\infty to the \"balayage operator\" \\Pi_\\Lambda =\n\\sum_{k=0}^\\infty (I_\\Lambda \\alpha)^k I_{\\Lambda^c). These results are\nobtained in two ways: by a fairly simple matrix formalism, and by a more\npowerful tree formalism that corresponds to working with formal power series in\nwhich the matrix elements of \\alpha are treated as noncommuting indeterminates.\n\n", "human_text": "  Motivated by the Dobrushin uniqueness theorem in statistical mechanics, we\nconsider the following situation: Let \\alpha be a nonnegative matrix over a\nfinite or countably infinite index set X, and define the \"cleaning operators\"\n\\beta_h = I_{1-h} + I_h \\alpha for h: X \\to [0,1] (here I_f denotes the\ndiagonal matrix with entries f). We ask: For which \"cleaning sequences\" h_1,\nh_2, ... do we have c \\beta_{h_1} ... \\beta_{h_n} \\to 0 for a suitable class of\n\"dirt vectors\" c? We show, under a modest condition on \\alpha, that this occurs\nwhenever \\sum_i h_i = \\infty everywhere on X. More generally, we analyze the\ncleaning of subsets \\Lambda \\subseteq X and the final distribution of dirt on\nthe complement of \\Lambda. We show that when supp(h_i) \\subseteq \\Lambda with\n\\sum_i h_i = \\infty everywhere on \\Lambda, the operators \\beta_{h_1} ...\n\\beta_{h_n} converge as n \\to \\infty to the \"balayage operator\" \\Pi_\\Lambda =\n\\sum_{k=0}^\\infty (I_\\Lambda \\alpha)^k I_{\\Lambda^c). These results are\nobtained in two ways: by a fairly simple matrix formalism, and by a more\npowerful tree formalism that corresponds to working with formal power series in\nwhich the matrix elements of \\alpha are treated as noncommuting indeterminates.\n", "machine_text": "\nThis paper examines the application of the unique Dobrushin theorem in statistical mechanics to the question of cleaning a dirty floor. We present a theorem under mild assumptions on the floor's properties, which states that when a cleaning sequence is applied such that the sum of each sequence is equal to infinity everywhere on the floor, it will eventually converge to a balayage operator $\\Pi_\\Lambda$. We provide two approaches to prove this result: a simple matrix formalism, and a tree formalism, applying formal power series to the coefficients of the floor's matrix. Our study allows us to analyse the cleaning of subsets of the floor, as well as the final distribution of dirt on its complimentary set.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3156}
{"prompt": "Rephrase the abstract of an article with title 'Off-center HII regions in power-law density distributions'.\n  The expansion of ionization fronts in uniform and spherically symmetric\npower-law density distributions is a well-studied topic. However, in many\nsituations, such as a star formed at the edge of a molecular cloud core, an\noffset power-law density distribution would be more appropriate. In this paper\na few of the main issues of the formation and expansion of HII regions in such\nmedia are outlined and results are presented for the particular cases where the\nunderlying power laws are 1/r^2 and 1/r^3. A simple criterion is developed for\ndetermining whether the initial photoionized region will be unbounded, which\ndepends on the power-law exponent and the ratio of the equivalent Stroemgren\nradius produced by the star in a uniform medium to the stellar offset distance.\nIn the expansion stage, the ionized volumes will eventually become unbounded\nunless pressure balance with the external medium is reached before the\nionization front velocity becomes supersonic with respect to the ionized gas.\n\n", "human_text": "  The expansion of ionization fronts in uniform and spherically symmetric\npower-law density distributions is a well-studied topic. However, in many\nsituations, such as a star formed at the edge of a molecular cloud core, an\noffset power-law density distribution would be more appropriate. In this paper\na few of the main issues of the formation and expansion of HII regions in such\nmedia are outlined and results are presented for the particular cases where the\nunderlying power laws are 1/r^2 and 1/r^3. A simple criterion is developed for\ndetermining whether the initial photoionized region will be unbounded, which\ndepends on the power-law exponent and the ratio of the equivalent Stroemgren\nradius produced by the star in a uniform medium to the stellar offset distance.\nIn the expansion stage, the ionized volumes will eventually become unbounded\nunless pressure balance with the external medium is reached before the\nionization front velocity becomes supersonic with respect to the ionized gas.\n", "machine_text": "This article discusses how offset HII regions can form and expand in media with power-law density distributions. It presents results for power-law exponents of 1/r^2 and 1/r^3 and develops a criterion to determine whether the action of a stellar source will be able to produce an unbounded ionized volume. Further, the paper examines the conditions under which the HII region will remain bounded or expand, depending on the external pressure of the medium.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0711}
{"prompt": "Rephrase the abstract of an article with title 'Coupling between magnetic ordering and structural instabilities in\n  perovskite biferroics: A first-principles study'.\n  We use first-principles density functional theory-based calculations to\ninvestigate structural instabilities in the high symmetry cubic perovskite\nstructure of rare-earth (R $=$ La, Y, Lu) and Bi-based biferroic chromites,\nfocusing on $\\Gamma$ and $R$ point phonons of states with para-, ferro-, and\nantiferromagnetic ordering. We find that (a) the structure with G-type\nantiferromagnetic ordering is most stable, (b) the most dominant structural\ninstabilities in these oxides are the ones associated with rotations of oxygen\noctahedra, and (c) structural instabilities involving changes in Cr-O-Cr bond\nangle depend sensitively on the changes in magnetic ordering. The dependence of\nstructural instabilities on magnetic ordering can be understood in terms of how\nsuper-exchange interactions depend on the Cr-O-Cr bond angles and Cr-O bond\nlengths. We demonstrate how adequate buckling of Cr-O-Cr chains can favour\nferromagnetism. Born effective charges (BEC) calculated using the Berry phase\nexpression are found to be anomalously large for the A-cations, indicating\ntheir chemical relevance to ferroelectric distortions.\n\n", "human_text": "  We use first-principles density functional theory-based calculations to\ninvestigate structural instabilities in the high symmetry cubic perovskite\nstructure of rare-earth (R $=$ La, Y, Lu) and Bi-based biferroic chromites,\nfocusing on $\\Gamma$ and $R$ point phonons of states with para-, ferro-, and\nantiferromagnetic ordering. We find that (a) the structure with G-type\nantiferromagnetic ordering is most stable, (b) the most dominant structural\ninstabilities in these oxides are the ones associated with rotations of oxygen\noctahedra, and (c) structural instabilities involving changes in Cr-O-Cr bond\nangle depend sensitively on the changes in magnetic ordering. The dependence of\nstructural instabilities on magnetic ordering can be understood in terms of how\nsuper-exchange interactions depend on the Cr-O-Cr bond angles and Cr-O bond\nlengths. We demonstrate how adequate buckling of Cr-O-Cr chains can favour\nferromagnetism. Born effective charges (BEC) calculated using the Berry phase\nexpression are found to be anomalously large for the A-cations, indicating\ntheir chemical relevance to ferroelectric distortions.\n", "machine_text": "In this study, we use first-principles density functional theory-based calculations to explore the relationship between\nmagnetic ordering and structural instabilities of high-symmetry cubic perovskite biferroics with rare-earth (R = La, Y, Lu) and\nBi-ions. We examine the phonons of the different para-, ferro-, and antiferromagnetic states at the $\\Gamma$ and\n$R$ points, and find that the structure with G-type antiferromagnetic ordering is the most stable. We also detect\nsignificant instabilities associated with rotations of oxygen octahedra, and that Cr-O-Cr bond angle destabilization\ndepends sensitively on the magnetic ordering. Analysis of our results reveals how super-exchange interactions are\ninfluenced by Cr-O-Cr bond angles and Cr-O bond lengths. Furthermore, large Born effective charges (BEC) for A-cations\nare related to ferroelectric distortions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1251}
{"prompt": "Rephrase the abstract of an article with title 'Dark matter halo abundances, clustering and assembly histories at high\n  redshift'.\n  We use a suite of high-resolution N-body simulations to study the properties,\nabundance and clustering of high mass halos at high redshift, including their\nmass assembly histories and mergers. We find that the analytic form which best\nfits the abundance of halos depends sensitively on the assumed definition of\nhalo mass, with common definitions of halo mass differing by a factor of two\nfor these low concentration, massive halos. A significant number of massive\nhalos are undergoing rapid mass accretion, with major merger activity being\ncommon. We compare the mergers and mass accretion histories to the extended\nPress-Schechter formalism.\n  We consider how major merger induced star formation or black hole accretion\nmay change the distribution of photon production from collapsed halos, and\nhence reionization, using some simplified examples. In all of these, the photon\ndistribution for a halo of a given mass acquires a large scatter. If rare, high\nmass halos contribute significantly to the photon production rates, the scatter\nin photon production rate can translate into additional scatter in the sizes of\nionized bubbles.\n\n", "human_text": "  We use a suite of high-resolution N-body simulations to study the properties,\nabundance and clustering of high mass halos at high redshift, including their\nmass assembly histories and mergers. We find that the analytic form which best\nfits the abundance of halos depends sensitively on the assumed definition of\nhalo mass, with common definitions of halo mass differing by a factor of two\nfor these low concentration, massive halos. A significant number of massive\nhalos are undergoing rapid mass accretion, with major merger activity being\ncommon. We compare the mergers and mass accretion histories to the extended\nPress-Schechter formalism.\n  We consider how major merger induced star formation or black hole accretion\nmay change the distribution of photon production from collapsed halos, and\nhence reionization, using some simplified examples. In all of these, the photon\ndistribution for a halo of a given mass acquires a large scatter. If rare, high\nmass halos contribute significantly to the photon production rates, the scatter\nin photon production rate can translate into additional scatter in the sizes of\nionized bubbles.\n", "machine_text": "\nUsing a series of high resolution N-body simulations, we explore the clustering, abundance, and mass assembly history of dark matter halos at high redshift. We discover that the accuracy of the analytical shape that fits the halo abundance is highly dependent on the definition of halo mass, and these low concentration, massive halos can vary by up to a factor of two in mass. Merger activity and mass accretion are seen to be frequent among these massive halos, which we compare to the Press-Schechter formalism. Then, we analyze how the increased levels of star formation and black hole accretion from large mergers can influence the distribution of ionizing photons during reionization, introducing a large scatter in photon production from halos of a given mass. This can therefore result in greater variability in sizes of ionized bubbles.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0208}
{"prompt": "Rephrase the abstract of an article with title 'Phase behavior of a fluid with competing attractive and repulsive\n  interactions'.\n  Fluids in which the interparticle potential has a hard core, is attractive at\nmoderate separations, and repulsive at greater separations are known to exhibit\nnovel phase behavior, including stable inhomogeneous phases. Here we report a\njoint simulation and theoretical study of such a fluid, focusing on the\nrelationship between the liquid-vapor transition line and any new phases. The\nphase diagram is studied as a function of the amplitude of the attraction for a\ncertain fixed amplitude of the long ranged repulsion. We find that the effect\nof the repulsion is to substitute the liquid-vapor critical point and a portion\nof the associated liquid-vapor transition line, by two first order transitions.\nOne of these transitions separates the vapor from a fluid of spherical\nliquidlike clusters; the other separates the liquid from a fluid of spherical\nvoids. At low temperature, the two transition lines intersect one another and a\nvapor-liquid transition line at a triple point. While most integral equation\ntheories are unable to describe the new phase transitions, the Percus Yevick\napproximation does succeed in capturing the vapor-cluster transition, as well\nas aspects of the structure of the cluster fluid, in reasonable agreement with\nthe simulation results.\n\n", "human_text": "  Fluids in which the interparticle potential has a hard core, is attractive at\nmoderate separations, and repulsive at greater separations are known to exhibit\nnovel phase behavior, including stable inhomogeneous phases. Here we report a\njoint simulation and theoretical study of such a fluid, focusing on the\nrelationship between the liquid-vapor transition line and any new phases. The\nphase diagram is studied as a function of the amplitude of the attraction for a\ncertain fixed amplitude of the long ranged repulsion. We find that the effect\nof the repulsion is to substitute the liquid-vapor critical point and a portion\nof the associated liquid-vapor transition line, by two first order transitions.\nOne of these transitions separates the vapor from a fluid of spherical\nliquidlike clusters; the other separates the liquid from a fluid of spherical\nvoids. At low temperature, the two transition lines intersect one another and a\nvapor-liquid transition line at a triple point. While most integral equation\ntheories are unable to describe the new phase transitions, the Percus Yevick\napproximation does succeed in capturing the vapor-cluster transition, as well\nas aspects of the structure of the cluster fluid, in reasonable agreement with\nthe simulation results.\n", "machine_text": "\nIn this work, we investigate the phase behavior of a fluid with attractive and repulsive interparticle interactions, by assessing the effects of attraction and repulsion on the liquid-vapor transition. Our simulations and theoretical analysis reveal that the repulsion can supplant the liquid-vapor critical point, as well as parts of the associated transition line, by two first order transitions. Consequently, a vapor-liquid transition line can appear at a triple point. Our integral equation studies indicate that the Percus-Yevick approximation is capable of capturing the vapor-cluster transition, as well as describing the cluster fluid to a good degree of accuracy in comparison to simulation results.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0618}
{"prompt": "Rephrase the abstract of an article with title 'Very High Energy $\\gamma$-ray and Near Infrared observations of\n  1ES2344+514 during 2004-05'.\n  We have observed the BL Lac object 1ES2344+514 (z = 0.044) in Very High\nEnergy (VHE) gamma-ray and near-infrared wavelength bands with TACTIC and MIRO\ntelescopes respectively. The observations were made from 18th October to 9th\nDecember 2004 and 27th October 2005 to 1st January 2006. Detailed analysis of\nthe TACTIC data indicates absence of a statistically significant gamma-ray\nsignal both in overall data and on a nightly basis from the source direction.\nWe estimate an upper limit of I($\\geq$1.5 TeV)$\\leq 3.84 \\times 10^{-12}$\nphotons cm$^{-2}$ s$^{-1}$ at a 3$\\sigma$ confidence level on the integrated\n$\\gamma$-ray flux. In addition, we have also compared TACTIC TeV light curves\nwith those of the RXTE ASM (2-12keV) for the contemporary period and find that\nthere are no statistically significant increases in the signal strengths from\nthe source in both these energy regions. During 2004 IR observations,\n1ES2344+514 shows low level (~0.06 magnitude) day-to-day variation in both, J &\nH bands. However, during 2005 observation epoch, the source brightens up by\nabout 0.41 magnitude from its October 2005 level J magnitude= 12.64 to J =\n12.23 on December 6, 2005. It then fades by about 0.2 magnitude during 6 to 10\nDecember, 2005. The variation is seen in both, J & H, bands simultaneously. The\nlight travel time arguments suggest that the emission region size is of the\norder of $10^{17}$ cms.\n\n", "human_text": "  We have observed the BL Lac object 1ES2344+514 (z = 0.044) in Very High\nEnergy (VHE) gamma-ray and near-infrared wavelength bands with TACTIC and MIRO\ntelescopes respectively. The observations were made from 18th October to 9th\nDecember 2004 and 27th October 2005 to 1st January 2006. Detailed analysis of\nthe TACTIC data indicates absence of a statistically significant gamma-ray\nsignal both in overall data and on a nightly basis from the source direction.\nWe estimate an upper limit of I($\\geq$1.5 TeV)$\\leq 3.84 \\times 10^{-12}$\nphotons cm$^{-2}$ s$^{-1}$ at a 3$\\sigma$ confidence level on the integrated\n$\\gamma$-ray flux. In addition, we have also compared TACTIC TeV light curves\nwith those of the RXTE ASM (2-12keV) for the contemporary period and find that\nthere are no statistically significant increases in the signal strengths from\nthe source in both these energy regions. During 2004 IR observations,\n1ES2344+514 shows low level (~0.06 magnitude) day-to-day variation in both, J &\nH bands. However, during 2005 observation epoch, the source brightens up by\nabout 0.41 magnitude from its October 2005 level J magnitude= 12.64 to J =\n12.23 on December 6, 2005. It then fades by about 0.2 magnitude during 6 to 10\nDecember, 2005. The variation is seen in both, J & H, bands simultaneously. The\nlight travel time arguments suggest that the emission region size is of the\norder of $10^{17}$ cms.\n", "machine_text": "\nWe have examined 1ES2344+514 (z = 0.044) in VHE gamma-rays and the near-infrared wavelength bands via TACTIC and MIRO telescopes. Our analysis from 18th October to 9th December 2004 and 27th October 2005-1st January 2006 provided no statistically significant $\\gamma$-ray signals. We estimated an upper limit of I($\\geq$1.5 TeV)$\\leq 3.84 \\times 10^{-12}$photons cm$^{-2}$ s$^{-1}$. Comparisons between TACTIC TeV light curves and RXTE ASM (2-12 keV) data found no remarkable increases. In 2004, there was minimal (~0.06 magnitude) day-to-day variation in both, J & H bands. Conversely, 1ES2344+514 grew brighter (J= 12.23 from October 2005 J magnitude = 12.64) from 27th October to 6th December 2005, then faded in the next few days. These variations were seen in both the J & H bands. The estimated emission region size is ~$10^{17}$ cms.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3533}
{"prompt": "Rephrase the abstract of an article with title 'Complementarity in the Bohr-Einstein Photon Box'.\n  The photon box thought experiment can be considered a forerunner of the\nEPR-experiment: by performing suitable measurements on the box it is possible\nto ``prepare'' the photon, long after it has escaped, in either of two\ncomplementary states. Consistency requires that the corresponding box\nmeasurements be complementary as well. At first sight it seems, however, that\nthese measurements can be jointly performed with arbitrary precision: they\npertain to different systems (the center of mass of the box and an internal\nclock, respectively). But this is deceptive. As we show by explicit\ncalculation, although the relevant quantities are simultaneously measurable,\nthey develop non-vanishing commutators when calculated back to the time of\nescape of the photon. This justifies Bohr's qualitative arguments in a precise\nway; and it illustrates how the details of the dynamics conspire to guarantee\nthe requirements of complementarity. In addition, our calculations exhibit a\n``fine structure'' in the distribution of the uncertainties over the\ncomplementary quantities: depending on \\textit{when} the box measurement is\nperformed, the resulting quantum description of the photon differs. This brings\nus close to the argumentation of the later EPR thought experiment.\n\n", "human_text": "  The photon box thought experiment can be considered a forerunner of the\nEPR-experiment: by performing suitable measurements on the box it is possible\nto ``prepare'' the photon, long after it has escaped, in either of two\ncomplementary states. Consistency requires that the corresponding box\nmeasurements be complementary as well. At first sight it seems, however, that\nthese measurements can be jointly performed with arbitrary precision: they\npertain to different systems (the center of mass of the box and an internal\nclock, respectively). But this is deceptive. As we show by explicit\ncalculation, although the relevant quantities are simultaneously measurable,\nthey develop non-vanishing commutators when calculated back to the time of\nescape of the photon. This justifies Bohr's qualitative arguments in a precise\nway; and it illustrates how the details of the dynamics conspire to guarantee\nthe requirements of complementarity. In addition, our calculations exhibit a\n``fine structure'' in the distribution of the uncertainties over the\ncomplementary quantities: depending on \\textit{when} the box measurement is\nperformed, the resulting quantum description of the photon differs. This brings\nus close to the argumentation of the later EPR thought experiment.\n", "machine_text": "\nThis paper examines the Bohr-Einstein photon box thought experiment, which can be seen as a precursor of the EPR experiment, and explores the concept of complementarity. It is proposed that by making pertinent measurements on the box, the photon can be prepared, long after it has escaped, in either of two states. In order for consistency to be maintained, it is also necessary for the measurements on the box to be complementary. Initially, it appears that these measurements can be carried out precisely at the same time, as they refer to different systems (the center of mass of the box and an internal clock). However, when this is explored in detail, it is revealed that these measurements are linked in such a way that the commutators become non-zero when applied to the time of the photon's escape, affirming Bohr's predictions. Moreover, our calculations uncover a 'fine structure', based on \\textit{when} the measurements are done, which ultimately alters the quantum description of the photon. This analysis provides insight into how the dynamics cooperate to preserve complementarity and reflects how the later EPR thought experiment was argued.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2762}
{"prompt": "Rephrase the abstract of an article with title 'Many concepts and two logics of algorithmic reduction'.\n  Within the program of finding axiomatizations for various parts of\ncomputability logic, it was proved earlier that the logic of interactive Turing\nreduction is exactly the implicative fragment of Heyting's intuitionistic\ncalculus. That sort of reduction permits unlimited reusage of the computational\nresource represented by the antecedent. An at least equally basic and natural\nsort of algorithmic reduction, however, is the one that does not allow such\nreusage. The present article shows that turning the logic of the first sort of\nreduction into the logic of the second sort of reduction takes nothing more\nthan just deleting the contraction rule from its Gentzen-style axiomatization.\nThe first (Turing) sort of interactive reduction is also shown to come in three\nnatural versions. While those three versions are very different from each\nother, their logical behaviors (in isolation) turn out to be indistinguishable,\nwith that common behavior being precisely captured by implicative\nintuitionistic logic. Among the other contributions of the present article is\nan informal introduction of a series of new -- finite and bounded -- versions\nof recurrence operations and the associated reduction operations. An online\nsource on computability logic can be found at\nhttp://www.cis.upenn.edu/~giorgi/cl.html\n\n", "human_text": "  Within the program of finding axiomatizations for various parts of\ncomputability logic, it was proved earlier that the logic of interactive Turing\nreduction is exactly the implicative fragment of Heyting's intuitionistic\ncalculus. That sort of reduction permits unlimited reusage of the computational\nresource represented by the antecedent. An at least equally basic and natural\nsort of algorithmic reduction, however, is the one that does not allow such\nreusage. The present article shows that turning the logic of the first sort of\nreduction into the logic of the second sort of reduction takes nothing more\nthan just deleting the contraction rule from its Gentzen-style axiomatization.\nThe first (Turing) sort of interactive reduction is also shown to come in three\nnatural versions. While those three versions are very different from each\nother, their logical behaviors (in isolation) turn out to be indistinguishable,\nwith that common behavior being precisely captured by implicative\nintuitionistic logic. Among the other contributions of the present article is\nan informal introduction of a series of new -- finite and bounded -- versions\nof recurrence operations and the associated reduction operations. An online\nsource on computability logic can be found at\nhttp://www.cis.upenn.edu/~giorgi/cl.html\n", "machine_text": "\nThis article examines two forms of algorithmic reduction, illustrated in the interactive Turing reduction and the associated Gentzen-style axiomatization. The article reveals that the second form of reduction, which is not allowed to reuse the antecedent, can be derived by deleting the contraction rule from the first form of reduction. Additionally, three versions of Turing interactive reduction are presented, which demonstrate distinct behaviours but are logically indistinguishable. Furthermore, a series of new finite and bounded versions of recurrence and reduction operations are presented informally. Finally, an online source for computability logic is provided.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0103}
{"prompt": "Rephrase the abstract of an article with title 'Squark and Gaugino Hadroproduction and Decays in Non-Minimal Flavour\n  Violating Supersymmetry'.\n  We present an extensive analysis of squark and gaugino hadroproduction and\ndecays in non-minimal flavour violating supersymmetry. We employ the so-called\nsuper-CKM basis to define the possible misalignment of quark and squark\nrotations, and we use generalized (possibly complex) charges to define the\nmutual couplings of (s)quarks and gauge bosons/gauginos. The cross sections for\nall squark-(anti-)squark/gaugino pair and squark-gaugino associated production\nprocesses as well as their decay widths are then given in compact analytic\nform. For four different constrained supersymmetry breaking models with\nnon-minimal flavour violation in the second/third generation squark sector\nonly, we establish the parameter space regions allowed/favoured by low-energy,\nelectroweak precision, and cosmological constraints and display the chirality\nand flavour decomposition of all up- and down-type squark mass eigenstates.\nFinally, we compute numerically the dependence of a representative sample of\nproduction cross sections at the LHC on the off-diagonal mass matrix elements\nin the experimentally allowed/favoured ranges.\n\n", "human_text": "  We present an extensive analysis of squark and gaugino hadroproduction and\ndecays in non-minimal flavour violating supersymmetry. We employ the so-called\nsuper-CKM basis to define the possible misalignment of quark and squark\nrotations, and we use generalized (possibly complex) charges to define the\nmutual couplings of (s)quarks and gauge bosons/gauginos. The cross sections for\nall squark-(anti-)squark/gaugino pair and squark-gaugino associated production\nprocesses as well as their decay widths are then given in compact analytic\nform. For four different constrained supersymmetry breaking models with\nnon-minimal flavour violation in the second/third generation squark sector\nonly, we establish the parameter space regions allowed/favoured by low-energy,\nelectroweak precision, and cosmological constraints and display the chirality\nand flavour decomposition of all up- and down-type squark mass eigenstates.\nFinally, we compute numerically the dependence of a representative sample of\nproduction cross sections at the LHC on the off-diagonal mass matrix elements\nin the experimentally allowed/favoured ranges.\n", "machine_text": "\nThis article examines the hadroproduction and decays of the squark and gaugino particles in supersymmetry theories where there is non-minimal flavour violation. To quantify the misalignment of quark and squark rotations, the authors use the super-CKM basis. Furthermore, this work looks at generalized (possibly complex) charges to determine the interactions between (s)quarks, gauge bosons and gauginos. The cross sections for a variety of squark-(anti-)squark/gaugino pair and squark-gaugino associated production processes have been given in analytical form. Additionally, four different constrained forms of supersymmetry breaking models with non-minimal flavour violation have been used to set up the parameter space, and this space is in agreement with low-energy, electroweak precision and cosmological constraints. The chirality and flavour decomposition of all up- and down-type squark mass eigenstates is presented. Lastly, numerical examples have been included to depict the production cross sections at the LHC, based on the experimentally allowed/favoured ranges of off-diagonal mass matrix elements.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1826}
{"prompt": "Rephrase the abstract of an article with title 'Can we ever distinguish between quintessence and a cosmological\n  constant?'.\n  Many ambitious experiments have been proposed to constrain dark energy and\ndetect its evolution. At present, observational constraints are consistent with\na cosmological constant and there is no firm evidence for any evolution in the\ndark energy equation of state w. In this paper, we pose the following question:\nsuppose that future dark energy surveys constrain w at low redshift to be\nconsistent with -1 to a percent level accuracy, what are the implications for\nmodels of dynamical dark energy? We investigate this problem in a\nmodel-independent way by following quintessence field trajectories in `energy'\nphase-space. Attractor dynamics in this phase-space leads to two classes of\nacceptable models: 1) models with flat potentials, i.e. an effective\ncosmological constant, and 2) models with potentials that suddenly flatten with\na characteristic kink. The prospect of further constraining the second class of\nmodels from distance measurements and fluctuation growth rates at low redshift\n(z<3) seems poor. However, in some models of this second class, the dark energy\nmakes a significant contribution to the total energy density at high redshift.\nSuch models can be further constrained from observation of the cosmic microwave\nbackground anisotropies and from primordial nucleosynthesis. It is possible,\ntherefore, to construct models in which the dark energy at high redshift causes\nobservable effects, even if future dark energy surveys constrain w at low\nredshift to be consistent with -1 to high precision.\n\n", "human_text": "  Many ambitious experiments have been proposed to constrain dark energy and\ndetect its evolution. At present, observational constraints are consistent with\na cosmological constant and there is no firm evidence for any evolution in the\ndark energy equation of state w. In this paper, we pose the following question:\nsuppose that future dark energy surveys constrain w at low redshift to be\nconsistent with -1 to a percent level accuracy, what are the implications for\nmodels of dynamical dark energy? We investigate this problem in a\nmodel-independent way by following quintessence field trajectories in `energy'\nphase-space. Attractor dynamics in this phase-space leads to two classes of\nacceptable models: 1) models with flat potentials, i.e. an effective\ncosmological constant, and 2) models with potentials that suddenly flatten with\na characteristic kink. The prospect of further constraining the second class of\nmodels from distance measurements and fluctuation growth rates at low redshift\n(z<3) seems poor. However, in some models of this second class, the dark energy\nmakes a significant contribution to the total energy density at high redshift.\nSuch models can be further constrained from observation of the cosmic microwave\nbackground anisotropies and from primordial nucleosynthesis. It is possible,\ntherefore, to construct models in which the dark energy at high redshift causes\nobservable effects, even if future dark energy surveys constrain w at low\nredshift to be consistent with -1 to high precision.\n", "machine_text": "\nIn this paper, we consider the potential of distinguishing between a cosmological constant and a dynamically evolving quintessence field if future dark energy surveys constrain the equation of state to be consistent with -1 to a percent level accuracy. We first analyze the model-independent trajectories available in 'energy' phase-space, and find that two classes of acceptable models result from the attractor dynamics: those representing an effective cosmological constant, and those with potentials that abruptly flatten with a distinct kink. Although the former models cannot be further probed using distance measurements or the growth of fluctuations at low redshift (z<3), models of the latter type exist in which the dark energy exhibits an observable impact at high redshift. These can be examined further by examining cosmic microwave background anisotropies and primordial nucleosynthesis. Therefore, we conclude that it is feasible to identify models in which dark energy has measurable effects even when w is constrained to be close to -1.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1955}
{"prompt": "Rephrase the abstract of an article with title 'Testing outer boundary treatments for the Einstein equations'.\n  Various methods of treating outer boundaries in numerical relativity are\ncompared using a simple test problem: a Schwarzschild black hole with an\noutgoing gravitational wave perturbation. Numerical solutions computed using\ndifferent boundary treatments are compared to a `reference' numerical solution\nobtained by placing the outer boundary at a very large radius. For each\nboundary treatment, the full solutions including constraint violations and\nextracted gravitational waves are compared to those of the reference solution,\nthereby assessing the reflections caused by the artificial boundary. These\ntests use a first-order generalized harmonic formulation of the Einstein\nequations. Constraint-preserving boundary conditions for this system are\nreviewed, and an improved boundary condition on the gauge degrees of freedom is\npresented. Alternate boundary conditions evaluated here include freezing the\nincoming characteristic fields, Sommerfeld boundary conditions, and the\nconstraint-preserving boundary conditions of Kreiss and Winicour. Rather\ndifferent approaches to boundary treatments, such as sponge layers and spatial\ncompactification, are also tested. Overall the best treatment found here\ncombines boundary conditions that preserve the constraints, freeze the\nNewman-Penrose scalar Psi_0, and control gauge reflections.\n\n", "human_text": "  Various methods of treating outer boundaries in numerical relativity are\ncompared using a simple test problem: a Schwarzschild black hole with an\noutgoing gravitational wave perturbation. Numerical solutions computed using\ndifferent boundary treatments are compared to a `reference' numerical solution\nobtained by placing the outer boundary at a very large radius. For each\nboundary treatment, the full solutions including constraint violations and\nextracted gravitational waves are compared to those of the reference solution,\nthereby assessing the reflections caused by the artificial boundary. These\ntests use a first-order generalized harmonic formulation of the Einstein\nequations. Constraint-preserving boundary conditions for this system are\nreviewed, and an improved boundary condition on the gauge degrees of freedom is\npresented. Alternate boundary conditions evaluated here include freezing the\nincoming characteristic fields, Sommerfeld boundary conditions, and the\nconstraint-preserving boundary conditions of Kreiss and Winicour. Rather\ndifferent approaches to boundary treatments, such as sponge layers and spatial\ncompactification, are also tested. Overall the best treatment found here\ncombines boundary conditions that preserve the constraints, freeze the\nNewman-Penrose scalar Psi_0, and control gauge reflections.\n", "machine_text": "\nThis article examines the various approaches to treating outer boundaries in numerical relativity, testing them with a simple configuration of a Schwarzschild black hole with an outgoing gravitational wave perturbation. The numerical solutions of all different boundary treatments are compared to a 'reference' numerical solution generated at a huge radius, measuring the reflections caused by the artificial boundary. An improved boundary condition for the gauge degrees of freedom is introduced, along with other possibilities, such as freezing incoming characteristic fields, Sommerfeld boundary conditions, and the constraint-preserving boundary conditions of Kreiss and Winicour. Sponge layers and spatial compactification are also tested. In conclusion, the best treatment found involves the combined use of constraints preservation, the freezing of the Newman-Penrose scalar Psi_0, and control of gauge reflections.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0782}
{"prompt": "Rephrase the abstract of an article with title 'A deeper search for the progenitor of the Type Ic Supernova 2002ap'.\n  (Abridged) We present a search for the progenitor star of the Type Ic\nSupernova 2002ap in deep, high quality pre-explosion observations taken with\nthe Canada-France-Hawaii Telescope (CFHT). Aligning high-resolution Hubble\nSpace Telescope (HST) observations of the supernova itself with the archival\nCFHT images allowed us to pinpoint the location of the progenitor site on the\nground based observations. We find that a source visible in the B and R band\npre-explosion images close to the position of the SN is (1) not coincident with\nthe SN position within the uncertainties of our relative astrometry, and (2) is\nstill visible ~ 4.7 yrs post-explosion in late-time observations taken with the\nWilliam Herschel Telescope. We therefore conclude that it is not the progenitor\nof SN 2002ap. Comparing our luminosity limits with stellar models of single\nstars at appropriate metallicity (Z=0.008) we conclude that any single star\nprogenitor must have experienced at least twice the standard mass loss rates\nduring pre-Wolf-Rayet evolution, been initially > 30-40M(Sun) and exploded as a\nWolf-Rayet star of final mass 10-12M(Sun). Alternatively an initially less\nmassive progenitor may have evolved in an interacting binary system. We\nconstrain any possible binary companion to a main sequence star of < 20M(Sun),\na neutron star or a black hole. By combining the pre-explosion limits with the\nejecta mass estimates and constraints from X-ray and radio observations we\nconclude that any binary interaction most likely occurred as Case B mass\ntransfer, either with or without a subsequent common envelope evolution phase.\n\n", "human_text": "  (Abridged) We present a search for the progenitor star of the Type Ic\nSupernova 2002ap in deep, high quality pre-explosion observations taken with\nthe Canada-France-Hawaii Telescope (CFHT). Aligning high-resolution Hubble\nSpace Telescope (HST) observations of the supernova itself with the archival\nCFHT images allowed us to pinpoint the location of the progenitor site on the\nground based observations. We find that a source visible in the B and R band\npre-explosion images close to the position of the SN is (1) not coincident with\nthe SN position within the uncertainties of our relative astrometry, and (2) is\nstill visible ~ 4.7 yrs post-explosion in late-time observations taken with the\nWilliam Herschel Telescope. We therefore conclude that it is not the progenitor\nof SN 2002ap. Comparing our luminosity limits with stellar models of single\nstars at appropriate metallicity (Z=0.008) we conclude that any single star\nprogenitor must have experienced at least twice the standard mass loss rates\nduring pre-Wolf-Rayet evolution, been initially > 30-40M(Sun) and exploded as a\nWolf-Rayet star of final mass 10-12M(Sun). Alternatively an initially less\nmassive progenitor may have evolved in an interacting binary system. We\nconstrain any possible binary companion to a main sequence star of < 20M(Sun),\na neutron star or a black hole. By combining the pre-explosion limits with the\nejecta mass estimates and constraints from X-ray and radio observations we\nconclude that any binary interaction most likely occurred as Case B mass\ntransfer, either with or without a subsequent common envelope evolution phase.\n", "machine_text": "We have conducted a deep search for the progenitor of the Type Ic Supernova 2002ap by employing pre-explosion observations from the Canada-France-Hawaii Telescope. Aligning high-resolution Hubble Space Telescope observations of the supernova with the archival CFHT images enabled us to identify the location of the progenitor site on the ground-based observations. We were able to conclude that an observed source close to the SN position was not the progenitor, due to its visibility post-explosion, with late-time observations taken with the William Herschel Telescope. Comparisons to stellar models indicate that any single star progenitor could have experienced at least twice the standard mass loss rate during pre-Wolf-Rayet evolution, been initially more massive than 30-40 solar masses, and exploded as a Wolf-Rayet star with a final mass of 10-12 solar masses. Also possible is a scenario of an initially less massive progenitor, but in an interacting binary system. We have deduced that any possible binary companion would be a main-sequence star of less than 20 solar masses, a neutron star, or a black hole. By combining limits from pre-explosion obvervations, ejecta mass estimates and constraints from X-ray and radio observations, we have concluded that any binary interaction most likely happened during a Case B mass transfer, with or without a subsequent common envelope evolution phase.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.05}
{"prompt": "Rephrase the abstract of an article with title 'Non-adiabatic Effects in the Dissociation of Oxygen Molecules at the\n  Al(111) Surface'.\n  The measured low initial sticking probability of oxygen molecules at the\nAl(111) surface that had puzzled the field for many years was recently\nexplained in a non-adiabatic picture invoking spin-selection rules [J. Behler\net al., Phys. Rev. Lett. 94, 036104 (2005)]. These selection rules tend to\nconserve the initial spin-triplet character of the free O2 molecule during the\nmolecule's approach to the surface. A new locally-constrained\ndensity-functional theory approach gave access to the corresponding\npotential-energy surface (PES) seen by such an impinging spin-triplet molecule\nand indicated barriers to dissociation which reduce the sticking probability.\nHere, we further substantiate this non-adiabatic picture by providing a\ndetailed account of the employed approach. Building on the previous work, we\nfocus in particular on inaccuracies in present-day exchange-correlation\nfunctionals. Our analysis shows that small quantitative differences in the\nspin-triplet constrained PES obtained with different gradient-corrected\nfunctionals have a noticeable effect on the lowest kinetic energy part of the\nresulting sticking curve.\n\n", "human_text": "  The measured low initial sticking probability of oxygen molecules at the\nAl(111) surface that had puzzled the field for many years was recently\nexplained in a non-adiabatic picture invoking spin-selection rules [J. Behler\net al., Phys. Rev. Lett. 94, 036104 (2005)]. These selection rules tend to\nconserve the initial spin-triplet character of the free O2 molecule during the\nmolecule's approach to the surface. A new locally-constrained\ndensity-functional theory approach gave access to the corresponding\npotential-energy surface (PES) seen by such an impinging spin-triplet molecule\nand indicated barriers to dissociation which reduce the sticking probability.\nHere, we further substantiate this non-adiabatic picture by providing a\ndetailed account of the employed approach. Building on the previous work, we\nfocus in particular on inaccuracies in present-day exchange-correlation\nfunctionals. Our analysis shows that small quantitative differences in the\nspin-triplet constrained PES obtained with different gradient-corrected\nfunctionals have a noticeable effect on the lowest kinetic energy part of the\nresulting sticking curve.\n", "machine_text": "\nThe researchers of a recent study managed to explain the perplexing behavior of oxygen molecules when they first make contact with the Al(111) surface. By invoking spin-selection rules, these researchers uncovered a non-adiabatic picture of the molecules sticking to the surface. Density-functional theory was used to analyze the potential-energy surface which showed possible barriers to molecule dissociation. This article further explains the details of the utilized approach and addresses any inaccuracies of exchange-correlation functionals. It is concluded from the analysis that slight modifications of the spin-triplet constrained potential-energy surface can have an impact on the lowest kinetic energy portion of the sticking rate.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2202}
{"prompt": "Rephrase the abstract of an article with title 'Difermion condensates in vacuum in 2-4D four-fermion interaction models'.\n  Theoretical analysis of interplay between the condensates $<\\bar{q}q>$ and\n$<qq>$ in vacuum is generally made by relativistic effective potentials in the\nmean field approximation in 2D, 3D and 4D models with two flavor and $N_c$\ncolor massless fermions. It is found that in ground states of these models,\ninterplay between the two condensates mainly depend on the ratio $G_S/H_S$ for\n2D and 4D case or $G_S/H_P$ for 3D case, where $G_S$, $H_S$ and $H_P$ are\nrespectively the coupling constants in a scalar $(\\bar{q}q)$, a scalar $(qq)$\nand a pseudoscalar $(qq)$ channel. In ground states of all the models, only\npure $<\\bar{q}q>$ condensates could exist if $G_S/H_S$ or $G_S/H_P$ is bigger\nthan the critical value $2/N_c$, the ratio of the color numbers of the fermions\nentering into the condensates $<qq>$ and $<\\bar{q}q>$. As $G_S/H_S$ or\n$G_S/H_P$ decreases to the region below $2/N_c$, differences of the models will\nmanifest themselves. Depending on different models, and also on $N_c$ in 3D\nmodel, one will have or have no the coexistence phase of the two condensates,\nbesides the pure $<qq>$ condensate phase. The $G_S-H_S$ (or $G_S-H_P$) phase\ndiagrams in these models are given. The results also implicate a real\nconstraint on two-flavor QCD-analogous NJL model.\n\n", "human_text": "  Theoretical analysis of interplay between the condensates $<\\bar{q}q>$ and\n$<qq>$ in vacuum is generally made by relativistic effective potentials in the\nmean field approximation in 2D, 3D and 4D models with two flavor and $N_c$\ncolor massless fermions. It is found that in ground states of these models,\ninterplay between the two condensates mainly depend on the ratio $G_S/H_S$ for\n2D and 4D case or $G_S/H_P$ for 3D case, where $G_S$, $H_S$ and $H_P$ are\nrespectively the coupling constants in a scalar $(\\bar{q}q)$, a scalar $(qq)$\nand a pseudoscalar $(qq)$ channel. In ground states of all the models, only\npure $<\\bar{q}q>$ condensates could exist if $G_S/H_S$ or $G_S/H_P$ is bigger\nthan the critical value $2/N_c$, the ratio of the color numbers of the fermions\nentering into the condensates $<qq>$ and $<\\bar{q}q>$. As $G_S/H_S$ or\n$G_S/H_P$ decreases to the region below $2/N_c$, differences of the models will\nmanifest themselves. Depending on different models, and also on $N_c$ in 3D\nmodel, one will have or have no the coexistence phase of the two condensates,\nbesides the pure $<qq>$ condensate phase. The $G_S-H_S$ (or $G_S-H_P$) phase\ndiagrams in these models are given. The results also implicate a real\nconstraint on two-flavor QCD-analogous NJL model.\n", "machine_text": "\nThis paper investigates the influence of a $<\\bar{q}q>$ and $<qq>$ condensates on the energy of a system in 2D, 3D and 4D models that consist of massless fermions, two flavors and $N_c$ colors. An effective potential is employed in the mean-field approximation to investigate the ground state of these models. It has been established that for models to exist in a ground state with a pure $<\\bar{q}q>$, the ratio of the coupling constants ($G_S/H_S$ in 2D and 4D or $G_S/H_P$ in 3D) must be greater than $2/N_c$, which is the ratio of the colors of the fermions that form the condensates. A decrease in the value of $G_S/H_S$ or $G_S/H_P$ has been seen to lead to differences between the models in terms of the coexistence of the two condensates, $<\\bar{q}q>$ and $<qq>$, and this is dependent on the model, as well as $N_c$ in the 3D model. A $G_S-H_S$ or $G_S-H_P$ phase diagram is given in the paper, which also suggests constraints on two-flavor QCD-NJL models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0841}
{"prompt": "Rephrase the abstract of an article with title 'Hitting probabilities for systems of non-linear stochastic heat\n  equations with multiplicative noise'.\n  We consider a system of d non-linear stochastic heat equations in spatial\ndimension 1 driven by d-dimensional space-time white noise. The non-linearities\nappear both as additive drift terms and as multipliers of the noise. Using\ntechniques of Malliavin calculus, we establish upper and lower bounds on the\none-point density of the solution u(t,x), and upper bounds of Gaussian-type on\nthe two-point density of (u(s,y),u(t,x)). In particular, this estimate\nquantifies how this density degenerates as (s,y) converges to (t,x). From these\nresults, we deduce upper and lower bounds on hitting probabilities of the\nprocess {u(t,x)}_{t \\in \\mathbb{R}_+, x \\in [0,1]}, in terms of respectively\nHausdorff measure and Newtonian capacity. These estimates make it possible to\nshow that points are polar when d >6 and are not polar when d<6. We also show\nthat the Hausdorff dimension of the range of the process is 6 when d>6, and\ngive analogous results for the processes t \\mapsto u(t,x) and x \\mapsto u(t,x).\nFinally, we obtain the values of the Hausdorff dimensions of the level sets of\nthese processes.\n\n", "human_text": "  We consider a system of d non-linear stochastic heat equations in spatial\ndimension 1 driven by d-dimensional space-time white noise. The non-linearities\nappear both as additive drift terms and as multipliers of the noise. Using\ntechniques of Malliavin calculus, we establish upper and lower bounds on the\none-point density of the solution u(t,x), and upper bounds of Gaussian-type on\nthe two-point density of (u(s,y),u(t,x)). In particular, this estimate\nquantifies how this density degenerates as (s,y) converges to (t,x). From these\nresults, we deduce upper and lower bounds on hitting probabilities of the\nprocess {u(t,x)}_{t \\in \\mathbb{R}_+, x \\in [0,1]}, in terms of respectively\nHausdorff measure and Newtonian capacity. These estimates make it possible to\nshow that points are polar when d >6 and are not polar when d<6. We also show\nthat the Hausdorff dimension of the range of the process is 6 when d>6, and\ngive analogous results for the processes t \\mapsto u(t,x) and x \\mapsto u(t,x).\nFinally, we obtain the values of the Hausdorff dimensions of the level sets of\nthese processes.\n", "machine_text": "\nUsing methods of Malliavin calculus, this article provides quantified estimates of the one- and two-point densities of solutions to systems of non-linear stochastic heat equations with multiplicative noise in spatial dimension 1. Our analysis focuses on bounding the one-point density, the two-point density as (s, y) approaches (t,x), as well as the hitting probabilities of the process {u(t, x)}_{t \\in \\mathbb{R}_+, x \\in [0,1]}. Ultimately, this paper provides a better understanding of the range, Hausdorff dimension, and level sets of these processes for both d small and large.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1312}
{"prompt": "Rephrase the abstract of an article with title 'Absorption features of high redshift galactic winds'.\n  The environment of high-redshift galaxies is characterized by both\nwind-driven outflowing gas and gravitationally infalling streams. To\ninvestigate such galaxy-IGM interplay we have generated synthetic optical\nabsorption line spectra piercing the volume surrounding a starbursting analog\nof a Lyman Break Galaxy selected in a $z \\approx 3$ output from a SPH\nsimulation, including a detailed treatment of mechanical feedback from winds.\nDistributions for several observable species (HI, CIII, CIV, SiII, SiIII, SiIV,\nOVI, OVII, and OVIII) have been derived by post-processing the simulation\noutputs. The hot wind material is characterized by the presence of\nhigh-ionization species such as OVI, OVII, and OVIII (the latter two observable\nonly in X-ray bands); the colder ($T<10^{5.5}$ K) infalling streams can be\ninstead identified by the combined presence of SiII, SiIII, and CIII optical\nabsorption together with OVI that surrounds the cooler gas clumps. However,\nboth line profile and Pixel Optical Depth analysis of the synthetic spectra\nshow that the intergalactic filament in which the wind-blowing galaxy is\nembedded produces absorption signatures that closely mimic those of the wind\nenvironment. We conclude that may be difficult to clearly identify wind-blowing\ngalaxies and their complex gaseous environment at high redshift in optical QSO\nabsorption-line spectra based solely on the observed ion absorption patterns.\n\n", "human_text": "  The environment of high-redshift galaxies is characterized by both\nwind-driven outflowing gas and gravitationally infalling streams. To\ninvestigate such galaxy-IGM interplay we have generated synthetic optical\nabsorption line spectra piercing the volume surrounding a starbursting analog\nof a Lyman Break Galaxy selected in a $z \\approx 3$ output from a SPH\nsimulation, including a detailed treatment of mechanical feedback from winds.\nDistributions for several observable species (HI, CIII, CIV, SiII, SiIII, SiIV,\nOVI, OVII, and OVIII) have been derived by post-processing the simulation\noutputs. The hot wind material is characterized by the presence of\nhigh-ionization species such as OVI, OVII, and OVIII (the latter two observable\nonly in X-ray bands); the colder ($T<10^{5.5}$ K) infalling streams can be\ninstead identified by the combined presence of SiII, SiIII, and CIII optical\nabsorption together with OVI that surrounds the cooler gas clumps. However,\nboth line profile and Pixel Optical Depth analysis of the synthetic spectra\nshow that the intergalactic filament in which the wind-blowing galaxy is\nembedded produces absorption signatures that closely mimic those of the wind\nenvironment. We conclude that may be difficult to clearly identify wind-blowing\ngalaxies and their complex gaseous environment at high redshift in optical QSO\nabsorption-line spectra based solely on the observed ion absorption patterns.\n", "machine_text": "This article analyzes the effects of outflowing and gravitationally infalling gas on the environment of high redshift galaxies. Using a simulation with a starbursting Lyman Break Galaxy at a redshift of approximately 3, synthetic optical absorption line spectra have been generated that account for the mechanical feedback from winds. This article then examines the distributions of species such as HI, CIII, CIV, SiII, SiIII, SiIV, OVI, OVII, and OVIII. The analysis revealed that the infalling streams are characterized by the presence of species such as SiII, SiIII and CIII, and the wind by species such as OVI, OVII, and OVIII. However, due to the intergalactic filament in which the wind-blowing galaxy is embedded, the wind environment may be impossible to distinguish from similar optical absorption patterns produced in QSO spectra.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2143}
{"prompt": "Rephrase the abstract of an article with title 'Non-circular motion evidences in the circumnuclear region of M100 (NGC\n  4321)'.\n  We analyse new integral field spectroscopy of the inner region (central 2.5\nkpc) of the spiral galaxy NGC 4321 to study the peculiar kinematics of this\nregion. Fourier analysis of the velocity residuals obtained by subtracting an\naxisymmetric rotation model from the $\\rm H\\alpha$ velocity field, indicates\nthat the distortions are {\\em global} features generated by an $m=2$\nperturbation of the gravitational potential which can be explained by the\nnuclear bar. This bar has been previously observed in the near-infrared but not\nin the optical continuum dominated by star formation. We detect the optical\ncounterpart of this bar in the 2D distribution of the old stellar population\n(inferred from the equivalent width map of the stellar absorption lines). We\napply the Tremaine--Weinberg method to the stellar velocity field to calculate\nthe pattern speed of the inner bar, obtaining a value of\n$\\Omega_b$=160$\\pm70\\rm km s^{-1} kpc^{-1} $. This value is considerably la\nrger than the one obtained when a simple bar model is considered. However the\nuncertainties in the pattern speed determination prevent us to give support to\nalternative scenarios.\n\n", "human_text": "  We analyse new integral field spectroscopy of the inner region (central 2.5\nkpc) of the spiral galaxy NGC 4321 to study the peculiar kinematics of this\nregion. Fourier analysis of the velocity residuals obtained by subtracting an\naxisymmetric rotation model from the $\\rm H\\alpha$ velocity field, indicates\nthat the distortions are {\\em global} features generated by an $m=2$\nperturbation of the gravitational potential which can be explained by the\nnuclear bar. This bar has been previously observed in the near-infrared but not\nin the optical continuum dominated by star formation. We detect the optical\ncounterpart of this bar in the 2D distribution of the old stellar population\n(inferred from the equivalent width map of the stellar absorption lines). We\napply the Tremaine--Weinberg method to the stellar velocity field to calculate\nthe pattern speed of the inner bar, obtaining a value of\n$\\Omega_b$=160$\\pm70\\rm km s^{-1} kpc^{-1} $. This value is considerably la\nrger than the one obtained when a simple bar model is considered. However the\nuncertainties in the pattern speed determination prevent us to give support to\nalternative scenarios.\n", "machine_text": "\nThrough the use of integral field spectroscopy in the central 2.5 kpc of the spiral galaxy NGC 4321, we have characterized global features of the peculiar kinematics associated with this region. Applying Fourier techniques to the velocity residuals of $\\rm H\\alpha$ reveals the presence of a nuclear bar. This bar is also seen in the near-infrared, yet has not been visible up to now in optical continuum light dominated by star formation. The two-dimensional distribution of the old stellar population, as derived from the equivalent width map of stellar absorption lines, allows us to detect its optical counterpart. Utilizing the Tremaine-Weinberg method, the pattern speed of the inner bar can be computed - yielding an approximate value of $\\Omega_b$=160$\\pm70\\rm km s^{-1} kpc^{-1}$. Nevertheless, the determination is susceptible to uncertainty and further investigation is needed to confirm its accuracy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1945}
{"prompt": "Rephrase the abstract of an article with title 'Distances of the bulge globular clusters Terzan 5, Liller 1, UKS 1 and\n  Terzan 4 based on HST NICMOS photometry'.\n  A large number of pulsars and X-rays sources are detected in globular\nclusters. To understand the structure and content of these clusters, accurate\ndistances are required. We derive the distances of Terzan 5, Liller 1 and UKS 1\nusing as a reference a recent distance determination of NGC 6528, based on\nHST/NICMOS and NTT/SOFI infrared photometry. The distance of the metal-poor\ncluster Terzan 4 was derived from a comparison with M92 in NICMOS bands.\nDistances of the metal-rich clusters are obtained by comparison of the\nHorizontal Branch (HB) level of the clusters, relative to the reddening line\npassing through the HB of NGC 6528. We use methods based on NICMOS bands and\ntransformations to J and H magnitudes with different assumptions. Liller~1 and\nTerzan~4 are found to be at the central bulge distance, UKS~1 is beyond the\nGalactic center, while Terzan 5 is closer to the Sun than the other four\nclusters. The distance of Terzan 5 is of paramount importance, given the impact\nof its population of 21 pulsars, which is related to the high cluster density.\nThe distance of Terzan 5 is found to be d$_{\\odot}$=5.5$\\pm$0.9 kpc from the\nSun, thus closer to us than values given in studies of pulsars in Terzan 5. As\na consequence, the higher cluster density is even more favourable for formation\nof the millisecond pulsars recently detected in this cluster.\n\n", "human_text": "  A large number of pulsars and X-rays sources are detected in globular\nclusters. To understand the structure and content of these clusters, accurate\ndistances are required. We derive the distances of Terzan 5, Liller 1 and UKS 1\nusing as a reference a recent distance determination of NGC 6528, based on\nHST/NICMOS and NTT/SOFI infrared photometry. The distance of the metal-poor\ncluster Terzan 4 was derived from a comparison with M92 in NICMOS bands.\nDistances of the metal-rich clusters are obtained by comparison of the\nHorizontal Branch (HB) level of the clusters, relative to the reddening line\npassing through the HB of NGC 6528. We use methods based on NICMOS bands and\ntransformations to J and H magnitudes with different assumptions. Liller~1 and\nTerzan~4 are found to be at the central bulge distance, UKS~1 is beyond the\nGalactic center, while Terzan 5 is closer to the Sun than the other four\nclusters. The distance of Terzan 5 is of paramount importance, given the impact\nof its population of 21 pulsars, which is related to the high cluster density.\nThe distance of Terzan 5 is found to be d$_{\\odot}$=5.5$\\pm$0.9 kpc from the\nSun, thus closer to us than values given in studies of pulsars in Terzan 5. As\na consequence, the higher cluster density is even more favourable for formation\nof the millisecond pulsars recently detected in this cluster.\n", "machine_text": "\nUsing HST/NICMOS and NTT/SOFI infrared photometry, we have determined accurate distances for four globular clusters in the Galactic bulge; Terzan 5, Liller 1, UKS 1 and Terzan 4. We studied the distance to the metal-rich clusters using the Horizontal Branch relative to the reddening line of NGC 6528. Transformations to J and H magnitudes with different assumptions were also used. Liller 1 and Terzan 4 were discovered to be the same distance as NGC 6528, while UKS 1 was farther and Terzan 5 was found to be 5.5 $\\pm$ 0.9 kpc from the sun. The close proximity of Terzan 5 to the solar system creates an environment in which the high cluster density can be ideal for the formation of millisecond pulsars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.403}
{"prompt": "Rephrase the abstract of an article with title 'Space Velocities of Southern Globular Clusters. V. A Low Galactic\n  Latitude Sample'.\n  We have measured the absolute proper motions of globular clusters NGC 2808,\n3201, 4372, 4833, 5927 and 5986. The proper motions are on the Hipparcos system\nand they are the first determinations ever made for these low Galactic latitude\nclusters. The proper motion uncertainties range from 0.3 to 0.5 mas/yr. The\ninferred orbits indicate that 1) the single metal rich cluster in our sample,\nNGC 5927, dynamically belongs to the thick disk, 2) the remaining metal poor\nclusters have rather low-energy orbits of high eccentricity; among these, there\nappear to be two \"pairs\" of dynamically associated clusters, 3) the most\nenergetic cluster in our sample, NGC 3201 is on a highly retrograde orbit --\nwhich had already been surmised from its radial velocity alone -- with an\napocentric distance of 22 kpc, and 4) none of the metal poor clusters appear to\nbe associated with the recently detected SDSS streams, or with the Monoceros\nstructure.\n  These are the first results of the Southern Proper-Motion Program (SPM) where\nthe second-epoch observations are taken with the CCD camera system recently\ninstalled on the double astrograph at El Leoncito, Argentina.\n\n", "human_text": "  We have measured the absolute proper motions of globular clusters NGC 2808,\n3201, 4372, 4833, 5927 and 5986. The proper motions are on the Hipparcos system\nand they are the first determinations ever made for these low Galactic latitude\nclusters. The proper motion uncertainties range from 0.3 to 0.5 mas/yr. The\ninferred orbits indicate that 1) the single metal rich cluster in our sample,\nNGC 5927, dynamically belongs to the thick disk, 2) the remaining metal poor\nclusters have rather low-energy orbits of high eccentricity; among these, there\nappear to be two \"pairs\" of dynamically associated clusters, 3) the most\nenergetic cluster in our sample, NGC 3201 is on a highly retrograde orbit --\nwhich had already been surmised from its radial velocity alone -- with an\napocentric distance of 22 kpc, and 4) none of the metal poor clusters appear to\nbe associated with the recently detected SDSS streams, or with the Monoceros\nstructure.\n  These are the first results of the Southern Proper-Motion Program (SPM) where\nthe second-epoch observations are taken with the CCD camera system recently\ninstalled on the double astrograph at El Leoncito, Argentina.\n", "machine_text": "\nThis paper provides the absolute proper motions of six globular clusters (NGC 2808,\n3201, 4372, 4833, 5927 and 5986) from the Hipparcos system which have not been previously measured. We find that the proper motion uncertainties range from 0.3 to 0.5 mas/yr. Our results suggest that one of the clusters (NGC 5927) belongs to the thick disk and that the rest are on highly eccentric orbits of low energy. We deduce that the most energetic cluster (NGC 3201) is on a retrograde orbit reaching out to 22 kpc. Additionally, none of the clusters appear to be related to the recently discovered SDSS streams nor the Monoceros structure. This research is part of the Southern Proper-Motion Program (SPM) whose second-epoch observations were taken with a CCD camera attached to the double astrograph at El Leoncito, Argentina.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3438}
{"prompt": "Rephrase the abstract of an article with title 'Direct CP violation in $\\bar{B}^0 \\to \\rho^0(\\omega)\\rho^0(\\omega) \\to\n  \\pi^+\\pi^-\\pi^+\\pi^-$'.\n  We study the direct CP violation in $\\bar{B}^0 \\to\n\\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$ (with unpolarized\n$\\rho^0(\\omega)$) via the $\\rho-\\omega$ mixing mechanism which causes a large\nstrong phase difference and consequently a large CP violating asymmetry when\nthe masses of the $\\pi^+\\pi^-$ pairs are in the vicinity of the $\\omega$\nresonance. Since there are two $\\rho (\\omega)$ mesons in the intermediate state\n$\\rho-\\omega$ mixing contributes twice to the first order of isospin violation,\nleading to an even larger CP violating asymmetry (could be 30% -- 50% larger)\nthan in the case where only one $\\rho (\\omega)$ meson is involved. The CP\nviolating asymmetry depends on the Cabibbo-Kobayashi-Maskawa (CKM) matrix\nelements and the hadronic matrix elements. The factorization approach is\napplied in the calculation of the hadronic matrix elements with the\nnonfactorizable effects being included effectively in an effective parameter,\n$N_c$. We give the constraint on the range of $N_c$ from the latest\nexperimental data for the branching ratios for $\\bar{B}^0 \\to\\rho^0\\rho^0$ and\n$\\bar{B}^0 \\to\\rho^+\\rho^-$. We find that the CP violating asymmetry could be\nvery large (even more than 90% for some values of $N_c$). It is shown that the\nsensitivity of the CP violating asymmetry to $N_c$ is large compared with its\nsmaller sensitivity to the CKM matrix elements. We also discuss the possibility\nto remove the mod $(\\pi)$ ambiguity in the determination of the CP violating\nphase angle $\\alpha$ through the measurement of the CP violating asymmetry in\nthe decay $\\bar{B}^0\\to \\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$.\n\n", "human_text": "  We study the direct CP violation in $\\bar{B}^0 \\to\n\\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$ (with unpolarized\n$\\rho^0(\\omega)$) via the $\\rho-\\omega$ mixing mechanism which causes a large\nstrong phase difference and consequently a large CP violating asymmetry when\nthe masses of the $\\pi^+\\pi^-$ pairs are in the vicinity of the $\\omega$\nresonance. Since there are two $\\rho (\\omega)$ mesons in the intermediate state\n$\\rho-\\omega$ mixing contributes twice to the first order of isospin violation,\nleading to an even larger CP violating asymmetry (could be 30% -- 50% larger)\nthan in the case where only one $\\rho (\\omega)$ meson is involved. The CP\nviolating asymmetry depends on the Cabibbo-Kobayashi-Maskawa (CKM) matrix\nelements and the hadronic matrix elements. The factorization approach is\napplied in the calculation of the hadronic matrix elements with the\nnonfactorizable effects being included effectively in an effective parameter,\n$N_c$. We give the constraint on the range of $N_c$ from the latest\nexperimental data for the branching ratios for $\\bar{B}^0 \\to\\rho^0\\rho^0$ and\n$\\bar{B}^0 \\to\\rho^+\\rho^-$. We find that the CP violating asymmetry could be\nvery large (even more than 90% for some values of $N_c$). It is shown that the\nsensitivity of the CP violating asymmetry to $N_c$ is large compared with its\nsmaller sensitivity to the CKM matrix elements. We also discuss the possibility\nto remove the mod $(\\pi)$ ambiguity in the determination of the CP violating\nphase angle $\\alpha$ through the measurement of the CP violating asymmetry in\nthe decay $\\bar{B}^0\\to \\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$.\n", "machine_text": "\nIn this article, we investigate the direct CP violation in $\\bar{B}^0 \\to \\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$ with unpolarized $\\rho^0(\\omega)$s. With two $\\rho (\\omega)$ mesons in the intermediate state, the $\\rho-\\omega$ mixing process can create a great strong phase difference which can produce a large CP violating asymmetry when the masses of the $\\pi^+\\pi^-$ pairs are close to the $\\omega$ resonance. We resort to the factorization approach in calculating the hadronic matrix elements and a factor $N_c$ is included to represent the non-factorizable effects, giving an even bigger CP asymmetry (possibly 30%- 50% larger). We analyze the data of the experimental branching ratios for $\\bar{B}^0 \\to \\rho^0\\rho^0$ and $\\bar{B}^0 \\to \\rho^+\\rho^-$, providing constraint on the value of $N_c$ and prospects of very large CP violating asymmetry (in some cases more than 90%). The CP violating phase angle $\\alpha$ can also be accurately determined through the observation of the CP violating asymmetry.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3132}
{"prompt": "Rephrase the abstract of an article with title 'A Diagrammatic Category for the Representation Theory of U_q(sl_n)'.\n  This thesis provides a partial answer to a question posed by Greg Kuperberg\nin q-alg/9712003 and again by Justin Roberts as problem 12.18 in \"Problems on\ninvariants of knots and 3-manifolds\", math.GT/0406190, essentially: \"Can one\ndescribe the category of representations of the quantum group U_q(sl_n)\n(thought of as a spherical category) via generators and relations?\"\n  For each n \\geq 0, I define a certain tensor category of trivalent graphs,\nmodulo isotopy, and construct a functor from this category onto (a full\nsubcategory of) the category of representations of the quantum group U_q(sl_n).\nOne would like to describe completely the kernel of this functor, by providing\ngenerators. The resulting quotient of the diagrammatic category would then be a\ncategory equivalent to the representation category of U_q(sl_n).\n  I make significant progress towards this, describing certain generators of\nthe kernel, and some obstructions to further elements. It remains a conjecture\nthat these relations generate the kernel. My results extend those of\nq-alg/9712003, MR1659228, math.QA/0310143 and math.GT/0506403.\n  The argument is essentially by constructing a diagrammatic version of the\nforgetful functor coming from the inclusion of U_q(sl_{n-1}) in U_q(sl_n}. We\nknow this functor is faithful, so a diagram is in the kernel for n exactly if\nits image under the diagrammatic forgetful functor is in the kernel for n-1.\nThis allows us to perform inductive calculations, both establishing families of\nelements of the kernel, and finding obstructions.\n\n", "human_text": "  This thesis provides a partial answer to a question posed by Greg Kuperberg\nin q-alg/9712003 and again by Justin Roberts as problem 12.18 in \"Problems on\ninvariants of knots and 3-manifolds\", math.GT/0406190, essentially: \"Can one\ndescribe the category of representations of the quantum group U_q(sl_n)\n(thought of as a spherical category) via generators and relations?\"\n  For each n \\geq 0, I define a certain tensor category of trivalent graphs,\nmodulo isotopy, and construct a functor from this category onto (a full\nsubcategory of) the category of representations of the quantum group U_q(sl_n).\nOne would like to describe completely the kernel of this functor, by providing\ngenerators. The resulting quotient of the diagrammatic category would then be a\ncategory equivalent to the representation category of U_q(sl_n).\n  I make significant progress towards this, describing certain generators of\nthe kernel, and some obstructions to further elements. It remains a conjecture\nthat these relations generate the kernel. My results extend those of\nq-alg/9712003, MR1659228, math.QA/0310143 and math.GT/0506403.\n  The argument is essentially by constructing a diagrammatic version of the\nforgetful functor coming from the inclusion of U_q(sl_{n-1}) in U_q(sl_n}. We\nknow this functor is faithful, so a diagram is in the kernel for n exactly if\nits image under the diagrammatic forgetful functor is in the kernel for n-1.\nThis allows us to perform inductive calculations, both establishing families of\nelements of the kernel, and finding obstructions.\n", "machine_text": "\nIn this thesis, a sequence of results is presented towards a description of a tensor category of trivalent graphs that is equivalent to the representation category of the quantum group U_q(sl_n). It is a partial answer to a question posed by Greg Kuperberg in q-alg/9712003 and again by Justin Roberts as problem 12.18 in \"Problems on Invariants of Knots and 3-Manifolds\", math.GT/0406190, regarding a possible diagrammatic representation of the spherical category of U_q(sl_n) representations. A diagrammatic forgetful functor is constructed to establish an inductive approach that reveals both classes of elements in the kernel, as well as obstructions which form its conjecture. This is an extension of prior knowledge in q-alg/9712003, MR1659228, math.QA/0310143, and math.GT/0506403.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1503}
{"prompt": "Rephrase the abstract of an article with title 'ATLAS sensitivity to Wtb anomalous couplings in top quark decays'.\n  We study the sensitivity of the ATLAS experiment to Wtb anomalous couplings\nin top pair production with semileptonic decay, pp -> t tbar -> W+ b W- bbar,\nwith one of the W bosons decaying leptonically and the other hadronically.\nSeveral observables are examined, including the W helicity fractions and new\nquantities recently introduced, such as the ratios of helicity fractions and\nsome angular asymmetries defined in the W rest frame. The dependence on\nanomalous couplings of all these observables has been previously obtained. In\nthis work we show that some of the new observables also have smaller systematic\nuncertainties than the helicity fractions, with a dependence on anomalous\ncouplings similar or stronger than for helicity fractions. Consequently, their\nmeasurement can significantly improve the limits on anomalous couplings.\nMoreover, the most sensitive measurements can be combined. In this case, the\nprecision achieved in the determination of Wtb anomalous couplings can be of a\nfew percent in the semileptonic channel alone.\n\n", "human_text": "  We study the sensitivity of the ATLAS experiment to Wtb anomalous couplings\nin top pair production with semileptonic decay, pp -> t tbar -> W+ b W- bbar,\nwith one of the W bosons decaying leptonically and the other hadronically.\nSeveral observables are examined, including the W helicity fractions and new\nquantities recently introduced, such as the ratios of helicity fractions and\nsome angular asymmetries defined in the W rest frame. The dependence on\nanomalous couplings of all these observables has been previously obtained. In\nthis work we show that some of the new observables also have smaller systematic\nuncertainties than the helicity fractions, with a dependence on anomalous\ncouplings similar or stronger than for helicity fractions. Consequently, their\nmeasurement can significantly improve the limits on anomalous couplings.\nMoreover, the most sensitive measurements can be combined. In this case, the\nprecision achieved in the determination of Wtb anomalous couplings can be of a\nfew percent in the semileptonic channel alone.\n", "machine_text": "\nThe ATLAS experiment was examined to determine its degree of sensitivity to any possible Wtb anomalous couplings found in top quark decays in the semi-leptonic processes of pp -> t tbar -> W+ b W- bbar, where one of the W bosons decay is leptonic and the other hadronic. Various measurements, such as the W helicity fractions and newly introduced ratios of helicity fractions and angular asymmetries in the W rest frame, have been analyzed to assess their dependence on such anomalous couplings. It has been found that certain observables have smaller systematic uncertainties than the helicity fractions, and also effectively identify a dependence on anomalous couplings that is either similar to or above that of the helicity fractions. Through these measurements, meaningful limits can be placed on these anomalous couplings. If these measurements are combined, the resulting precision in determining the presence of Wtb anomalous couplings can be within a few percent in the semi-leptonic channel alone.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3041}
{"prompt": "Rephrase the abstract of an article with title 'Isospin asymmetry in the continuum of the A=14 mirror nuclei'.\n  We study the isospin asymmetry in the isoscalar (IS) excitations in the\nmirror nuclei $^{14}$O and $^{14}$C by using the Hartree-Fock(HF)+random phase\napproximation (RPA) linear response function theory with a Skyrme interaction\nto take into account the continuum effect properly. The asymmetry in the IS\nmonopole, dipole responses is pointed out in the continuum near the particle\nthreshold with respect to the excitation energy and the sum rule strength. On\nthe other hand, no clear sign of the asymmetry is found in the giant resonance\n(GR) region. In the quadrupole case, the calculated strengths of the mirror\nnuclei show almost the same energy dependence from the threshold to the GR\nregion. It is found that the transition densities of the monopole response show\nan extended halo structure near the threshold, while those of GR region show a\ntypical radial dependence of the compressional collective mode without any halo\neffect. Contrary to the transition densities of the monopole response, those of\nquadrupole response do not show any sign of the extended feature of wave\nfunctions neither near the threshold nor the GR energy region. Calculated\nstrength distributions of the IS multipole states are compared with recent\nexperimental data obtained by the multipole decomposition analysis of $\\alpha $\ninelastic scattering on $^{14}$O.\n\n", "human_text": "  We study the isospin asymmetry in the isoscalar (IS) excitations in the\nmirror nuclei $^{14}$O and $^{14}$C by using the Hartree-Fock(HF)+random phase\napproximation (RPA) linear response function theory with a Skyrme interaction\nto take into account the continuum effect properly. The asymmetry in the IS\nmonopole, dipole responses is pointed out in the continuum near the particle\nthreshold with respect to the excitation energy and the sum rule strength. On\nthe other hand, no clear sign of the asymmetry is found in the giant resonance\n(GR) region. In the quadrupole case, the calculated strengths of the mirror\nnuclei show almost the same energy dependence from the threshold to the GR\nregion. It is found that the transition densities of the monopole response show\nan extended halo structure near the threshold, while those of GR region show a\ntypical radial dependence of the compressional collective mode without any halo\neffect. Contrary to the transition densities of the monopole response, those of\nquadrupole response do not show any sign of the extended feature of wave\nfunctions neither near the threshold nor the GR energy region. Calculated\nstrength distributions of the IS multipole states are compared with recent\nexperimental data obtained by the multipole decomposition analysis of $\\alpha $\ninelastic scattering on $^{14}$O.\n", "machine_text": "\nThis article investigates the isospin asymmetry present in the excitations of the mirror nuclei $^{14}$O and $^{14}$C in the isoscalar (IS) formation, using Hartree-Fock(HF)+Random Phase Approximation (RPA) linear response theory with a Skyrme interaction in order to take into account the continuum effect properly. Results point out asymmetry in the IS monopole and dipole responses close to the particle threshold with respect to the excitation energy and strength. However, no similar result can be seen in the Giant Resonance (GR) region. Quadrupole cases show that the respective strengths of the mirror nuclei have almost the same energy dependence near the threshold and GR region. Analyzing the transition densities of the monopole response near the threshold show an extended halo structure, while GR response does not show any extended feature of the wave functions. The IS multipole strength distributions are compared with recent experiments from $\\alpha $ inelastic scattering results on the nucleus $^{14}$O.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1878}
{"prompt": "Rephrase the abstract of an article with title 'The effect of stellar-mass black holes on the structural evolution of\n  massive star clusters'.\n  We present the results of realistic N-body modelling of massive star clusters\nin the Magellanic Clouds, aimed at investigating a dynamical origin for the\nradius-age trend observed in these systems. We find that stellar-mass black\nholes, formed in the supernova explosions of the most massive cluster stars,\ncan constitute a dynamically important population. If a significant number of\nblack holes are retained (here we assume complete retention), these objects\nrapidly form a dense core where interactions are common, resulting in the\nscattering of black holes into the cluster halo, and the ejection of black\nholes from the cluster. These two processes heat the stellar component,\nresulting in prolonged core expansion of a magnitude matching the observations.\nSignificant core evolution is also observed in Magellanic Cloud clusters at\nearly times. We find that this does not result from the action of black holes,\nbut can be reproduced by the effects of mass-loss due to rapid stellar\nevolution in a primordially mass segregated cluster.\n\n", "human_text": "  We present the results of realistic N-body modelling of massive star clusters\nin the Magellanic Clouds, aimed at investigating a dynamical origin for the\nradius-age trend observed in these systems. We find that stellar-mass black\nholes, formed in the supernova explosions of the most massive cluster stars,\ncan constitute a dynamically important population. If a significant number of\nblack holes are retained (here we assume complete retention), these objects\nrapidly form a dense core where interactions are common, resulting in the\nscattering of black holes into the cluster halo, and the ejection of black\nholes from the cluster. These two processes heat the stellar component,\nresulting in prolonged core expansion of a magnitude matching the observations.\nSignificant core evolution is also observed in Magellanic Cloud clusters at\nearly times. We find that this does not result from the action of black holes,\nbut can be reproduced by the effects of mass-loss due to rapid stellar\nevolution in a primordially mass segregated cluster.\n", "machine_text": "\nThe results of numerical simulations of massive star clusters within the Magellanic Clouds were studied in order to determine whether stellar-mass black holes, formed from the supernova explosions of some of the most massive stars, affect their structural evolution. It was found that if these black holes were retained in the cluster completely, they would rapidly form a dense core and interact heavily, resulting in both black hole scattering into the halo of the cluster and ejection of black holes. The resulting heating of the stellar component would lead to extended core expansion of a size corresponding to observations. We also saw that the early core evolution in the Magellanic Cloud clusters was not due to action of the black holes but is reproducible by the effects of mass-loss from rapid stellar evolution in a mass segregated cluster.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2494}
{"prompt": "Rephrase the abstract of an article with title 'NodeTrix: Hybrid Representation for Analyzing Social Networks'.\n  The need to visualize large social networks is growing as hardware\ncapabilities make analyzing large networks feasible and many new data sets\nbecome available. Unfortunately, the visualizations in existing systems do not\nsatisfactorily answer the basic dilemma of being readable both for the global\nstructure of the network and also for detailed analysis of local communities.\nTo address this problem, we present NodeTrix, a hybrid representation for\nnetworks that combines the advantages of two traditional representations:\nnode-link diagrams are used to show the global structure of a network, while\narbitrary portions of the network can be shown as adjacency matrices to better\nsupport the analysis of communities. A key contribution is a set of interaction\ntechniques. These allow analysts to create a NodeTrix visualization by dragging\nselections from either a node-link or a matrix, flexibly manipulate the\nNodeTrix representation to explore the dataset, and create meaningful summary\nvisualizations of their findings. Finally, we present a case study applying\nNodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate\nthe capabilities of NodeTrix as both an exploration tool and an effective means\nof communicating results.\n\n", "human_text": "  The need to visualize large social networks is growing as hardware\ncapabilities make analyzing large networks feasible and many new data sets\nbecome available. Unfortunately, the visualizations in existing systems do not\nsatisfactorily answer the basic dilemma of being readable both for the global\nstructure of the network and also for detailed analysis of local communities.\nTo address this problem, we present NodeTrix, a hybrid representation for\nnetworks that combines the advantages of two traditional representations:\nnode-link diagrams are used to show the global structure of a network, while\narbitrary portions of the network can be shown as adjacency matrices to better\nsupport the analysis of communities. A key contribution is a set of interaction\ntechniques. These allow analysts to create a NodeTrix visualization by dragging\nselections from either a node-link or a matrix, flexibly manipulate the\nNodeTrix representation to explore the dataset, and create meaningful summary\nvisualizations of their findings. Finally, we present a case study applying\nNodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate\nthe capabilities of NodeTrix as both an exploration tool and an effective means\nof communicating results.\n", "machine_text": "\nLarge social networks are increasingly becoming easier to analyze due to advances in computing technology, providing opportunities for the discovery of new insights within these datasets. NodeTrix is a hybrid visual representation for social networks that combines the advantages of node-link diagrams and adjacency matrices. This facilitates a more thorough exploration of global network structures and local community communities. Interaction techniques are introduced allowing a node-link or matrix selection to create a NodeTrix visualization, which can then be flexibly manipulated to uncover new relationships. We conducted a case study using the InfoVis 2004 co-authorship dataset to illustrate the power of NodeTrix as both an exploration tool and a way to effectively communicate data findings.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0599}
{"prompt": "Rephrase the abstract of an article with title 'The magnetic field topology associated to two M flares'.\n  On 27 October, 2003, two GOES M-class flares occurred in the lapse of three\nhours in active region NOAA 10486. The two flares were confined and their\nassociated brightenings appeared at the same location, displaying a very\nsimilar shape both at the chromospheric and coronal levels. We focus on the\nanalysis of magnetic field (SOHO/MDI), chromospheric (HASTA, Kanzelhoehe Solar\nObservatory, TRACE) and coronal (TRACE) observations. By combining our data\nanalysis with a model of the coronal magnetic field, we compute the magnetic\nfield topology associated to the two M flares. We find that both events can be\nexplained in terms of a localized magnetic reconnection process occurring at a\ncoronal magnetic null point. This null point is also present at the same\nlocation one day later, on 28 October, 2003. Magnetic energy release at this\nnull point was proposed as the origin of a localized event that occurred\nindependently with a large X17 flare on 28 October, 2003, at 11:01 UT. The\nthree events, those on 27 October and the one on 28 October, are homologous.\nOur results show that coronal null points can be stable topological structures\nwhere energy release via magnetic reconnection can happen, as proposed by\nclassical magnetic reconnection models.\n\n", "human_text": "  On 27 October, 2003, two GOES M-class flares occurred in the lapse of three\nhours in active region NOAA 10486. The two flares were confined and their\nassociated brightenings appeared at the same location, displaying a very\nsimilar shape both at the chromospheric and coronal levels. We focus on the\nanalysis of magnetic field (SOHO/MDI), chromospheric (HASTA, Kanzelhoehe Solar\nObservatory, TRACE) and coronal (TRACE) observations. By combining our data\nanalysis with a model of the coronal magnetic field, we compute the magnetic\nfield topology associated to the two M flares. We find that both events can be\nexplained in terms of a localized magnetic reconnection process occurring at a\ncoronal magnetic null point. This null point is also present at the same\nlocation one day later, on 28 October, 2003. Magnetic energy release at this\nnull point was proposed as the origin of a localized event that occurred\nindependently with a large X17 flare on 28 October, 2003, at 11:01 UT. The\nthree events, those on 27 October and the one on 28 October, are homologous.\nOur results show that coronal null points can be stable topological structures\nwhere energy release via magnetic reconnection can happen, as proposed by\nclassical magnetic reconnection models.\n", "machine_text": "\nIn this study, we concentrate on analyzing magnetic field (SOHO/MDI), chromospheric (HASTA, Kanzelhoehe Solar Observatory, TRACE) and coronal (TRACE) observational data from two GOES M-class flares which occurred in active region NOAA 10486 in a three-hour period on 27 October, 2003. Our results demonstrate that the magnetic field topology associated with these flares can be explained in terms of a localized magnetic reconnection event happening at a coronal null point. The same null point still existed one day later, on 28 October, 2003 and was suggested as the cause of the large X17 flare at 11:01 UT on that day. Consequently, it may be concluded that coronal null points are stable topological structures where energy can be released through magnetic reconnection, as proposed by earlier magnetic reconnection models.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0242}
{"prompt": "Rephrase the abstract of an article with title 'Inferring dynamic genetic networks with low order independencies'.\n  In this paper, we propose a novel inference method for dynamic genetic\nnetworks which makes it possible to face with a number of time measurements n\nmuch smaller than the number of genes p. The approach is based on the concept\nof low order conditional dependence graph that we extend here in the case of\nDynamic Bayesian Networks. Most of our results are based on the theory of\ngraphical models associated with the Directed Acyclic Graphs (DAGs). In this\nway, we define a minimal DAG G which describes exactly the full order\nconditional dependencies given the past of the process. Then, to face with the\nlarge p and small n estimation case, we propose to approximate DAG G by\nconsidering low order conditional independencies. We introduce partial qth\norder conditional dependence DAGs G(q) and analyze their probabilistic\nproperties. In general, DAGs G(q) differ from DAG G but still reflect relevant\ndependence facts for sparse networks such as genetic networks. By using this\napproximation, we set out a non-bayesian inference method and demonstrate the\neffectiveness of this approach on both simulated and real data analysis. The\ninference procedure is implemented in the R package 'G1DBN' freely available\nfrom the CRAN archive.\n\n", "human_text": "  In this paper, we propose a novel inference method for dynamic genetic\nnetworks which makes it possible to face with a number of time measurements n\nmuch smaller than the number of genes p. The approach is based on the concept\nof low order conditional dependence graph that we extend here in the case of\nDynamic Bayesian Networks. Most of our results are based on the theory of\ngraphical models associated with the Directed Acyclic Graphs (DAGs). In this\nway, we define a minimal DAG G which describes exactly the full order\nconditional dependencies given the past of the process. Then, to face with the\nlarge p and small n estimation case, we propose to approximate DAG G by\nconsidering low order conditional independencies. We introduce partial qth\norder conditional dependence DAGs G(q) and analyze their probabilistic\nproperties. In general, DAGs G(q) differ from DAG G but still reflect relevant\ndependence facts for sparse networks such as genetic networks. By using this\napproximation, we set out a non-bayesian inference method and demonstrate the\neffectiveness of this approach on both simulated and real data analysis. The\ninference procedure is implemented in the R package 'G1DBN' freely available\nfrom the CRAN archive.\n", "machine_text": "This article presents a method for inferring dynamic genetic networks using low order independencies. Using Directed Acyclic Graphs (DAGs), we can create minimal DAGs which describe the full conditional dependence based on the past of the process. However, the large number of genes and small number of time measurements can make this difficult, so instead, we consider low order conditional independence DAGs, G(q), which still reflect relevant dependence facts for sparse networks. We propose a non-bayesian inference method to analyze simulated and real data, which is available through the R package 'G1DBN' on the CRAN archive.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2551}
{"prompt": "Rephrase the abstract of an article with title 'The discrete dipole approximation for simulation of light scattering by\n  particles much larger than the wavelength'.\n  In this manuscript we investigate the capabilities of the Discrete Dipole\nApproximation (DDA) to simulate scattering from particles that are much larger\nthan the wavelength of the incident light, and describe an optimized publicly\navailable DDA computer program that processes the large number of dipoles\nrequired for such simulations. Numerical simulations of light scattering by\nspheres with size parameters x up to 160 and 40 for refractive index m=1.05 and\n2 respectively are presented and compared with exact results of the Mie theory.\nErrors of both integral and angle-resolved scattering quantities generally\nincrease with m and show no systematic dependence on x. Computational times\nincrease steeply with both x and m, reaching values of more than 2 weeks on a\ncluster of 64 processors. The main distinctive feature of the computer program\nis the ability to parallelize a single DDA simulation over a cluster of\ncomputers, which allows it to simulate light scattering by very large\nparticles, like the ones that are considered in this manuscript. Current\nlimitations and possible ways for improvement are discussed.\n\n", "human_text": "  In this manuscript we investigate the capabilities of the Discrete Dipole\nApproximation (DDA) to simulate scattering from particles that are much larger\nthan the wavelength of the incident light, and describe an optimized publicly\navailable DDA computer program that processes the large number of dipoles\nrequired for such simulations. Numerical simulations of light scattering by\nspheres with size parameters x up to 160 and 40 for refractive index m=1.05 and\n2 respectively are presented and compared with exact results of the Mie theory.\nErrors of both integral and angle-resolved scattering quantities generally\nincrease with m and show no systematic dependence on x. Computational times\nincrease steeply with both x and m, reaching values of more than 2 weeks on a\ncluster of 64 processors. The main distinctive feature of the computer program\nis the ability to parallelize a single DDA simulation over a cluster of\ncomputers, which allows it to simulate light scattering by very large\nparticles, like the ones that are considered in this manuscript. Current\nlimitations and possible ways for improvement are discussed.\n", "machine_text": "\nThis study evaluates the capability of the Discrete Dipole Approximation (DDA) in modelling the light scattering from particles that are much larger than the wave wavelength. We describe a highly efficient, publically-available DDA program that is capable of processing the numerous dipoles required for these kinds of simulations. We examine scattering in spheres for different refractive indices, with the size parameter varying from x=160 to 40, and compare the results of DDA with those of the Mie Theory. The errors in both integral and angle-resolved scattering quantities augment as the refraction index increases, with no discernible relation to the size parameter. Additionally, the computational times required for the simulations rise with the size parameter as well as refraction index, taking up to 2 weeks on a cluster system composed of 64 processors. Aside from its functionality to parallelize a single DDA simulation over multiple computers, this computer program's leading feature is its ability to simulate the scattering of very large particles. Eventually, we provide a discussion of possible solutions to the current restrictions in the program.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0037}
{"prompt": "Rephrase the abstract of an article with title 'Bubbles in the Self-Accelerating Universe'.\n  We revisit the issue of the stability in the Dvali-Gabadadze-Porrati model,\nby considering the nucleation of bubbles of the conventional branch within the\nself-accelerating branch. We construct an instanton describing this process in\nthe thin wall approximation. On one side of the bubble wall, the bulk consists\nof the exterior of the brane while on the other side it is the interior. The\nsolution requires the presence of a 2-brane (the bubble wall) which induces the\ntransition. However, we show that this instanton cannot be realized as the thin\nwall limit of any smooth solution. Once the bubble thickness is resolved, the\nequations of motion do not allow O(4) symmetric solutions joining the two\nbranches. We conclude that the thin wall instanton is unphysical, and that one\ncannot have processes connecting the two branches, unless negative tension\nbubble walls are introduced. This also suggests that the self-accelerating\nbranch does not decay into the conventional branch nucleating bubbles. We\ncomment on other kinds of bubbles that could interpolate between the two\nbranches.\n\n", "human_text": "  We revisit the issue of the stability in the Dvali-Gabadadze-Porrati model,\nby considering the nucleation of bubbles of the conventional branch within the\nself-accelerating branch. We construct an instanton describing this process in\nthe thin wall approximation. On one side of the bubble wall, the bulk consists\nof the exterior of the brane while on the other side it is the interior. The\nsolution requires the presence of a 2-brane (the bubble wall) which induces the\ntransition. However, we show that this instanton cannot be realized as the thin\nwall limit of any smooth solution. Once the bubble thickness is resolved, the\nequations of motion do not allow O(4) symmetric solutions joining the two\nbranches. We conclude that the thin wall instanton is unphysical, and that one\ncannot have processes connecting the two branches, unless negative tension\nbubble walls are introduced. This also suggests that the self-accelerating\nbranch does not decay into the conventional branch nucleating bubbles. We\ncomment on other kinds of bubbles that could interpolate between the two\nbranches.\n", "machine_text": "We analyze the Dvali-Gabadadze-Porrati model to investigate the stability of its self-accelerating universe. We introduce a bubble which connects the conventional branch and the self-accelerating branch of the model. In our study, a 2-brane serves as a wall between the two separated universes. Despite constructing an instanton in the thin wall approximation to describe the process, our analysis demonstrates that it cannot be physically realized in the O(4) symmetric universe. Such a process can only be facilitated by the introduction of negative tension bubble walls. As a result, the  self-accelerating universe does not decay into the conventional branch. We discuss various other kinds of bubbles capable of mediating the process.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.198}
{"prompt": "Rephrase the abstract of an article with title 'On the Incidence of C IV Absorbers Along the Sightlines to Gamma-Ray\n  Bursts'.\n  We report on the statistics of strong (W_r > 0.15 A) C IV absorbers at\nz=1.5-3.5 toward high-redshift gamma-ray bursts (GRBs). In contrast with a\nrecent survey for strong Mg II absorption systems at z < 2, we find that the\nnumber of C IV absorbers per unit redshift dN/dz does not show a significant\ndeviation from previous surveys using quasi-stellar objects (QSOs) as\nbackground sources. We find that the number density of C IV toward GRBs is\ndN/dz(z~1.5)= 2.2 +2.8/-1.4, dN/dz(z~2.5)= 2.3 +1.8/-1.1 and dN/dz(z~3.5)= 1.1\n+2.6/-0.9. These numbers are consistent with previous C IV surveys using QSO\nspectra. Binning the entire dataset, we set a 95% c.l. upper limit to the\nexcess of C IV absorbers along GRB sightlines at twice the incidence observed\nalong QSO sightlines. Furthermore, the distribution of equivalent widths of the\nGRB and QSO samples are consistent with being drawn from the same parent\npopulation. Although the results for Mg II and C IV absorbers along GRB\nsightlines appear to contradict one another, we note that the surveys are\nnearly disjoint: the C IV survey corresponds to higher redshift and more highly\nionized gas than the Mg II survey. Nevertheless, analysis on larger statistical\nsamples may constrain properties of the galaxies hosting these metals (e.g.\nmass, dust content) and/or the coherence-length of the gas giving rise to the\nmetal-line absorption.\n\n", "human_text": "  We report on the statistics of strong (W_r > 0.15 A) C IV absorbers at\nz=1.5-3.5 toward high-redshift gamma-ray bursts (GRBs). In contrast with a\nrecent survey for strong Mg II absorption systems at z < 2, we find that the\nnumber of C IV absorbers per unit redshift dN/dz does not show a significant\ndeviation from previous surveys using quasi-stellar objects (QSOs) as\nbackground sources. We find that the number density of C IV toward GRBs is\ndN/dz(z~1.5)= 2.2 +2.8/-1.4, dN/dz(z~2.5)= 2.3 +1.8/-1.1 and dN/dz(z~3.5)= 1.1\n+2.6/-0.9. These numbers are consistent with previous C IV surveys using QSO\nspectra. Binning the entire dataset, we set a 95% c.l. upper limit to the\nexcess of C IV absorbers along GRB sightlines at twice the incidence observed\nalong QSO sightlines. Furthermore, the distribution of equivalent widths of the\nGRB and QSO samples are consistent with being drawn from the same parent\npopulation. Although the results for Mg II and C IV absorbers along GRB\nsightlines appear to contradict one another, we note that the surveys are\nnearly disjoint: the C IV survey corresponds to higher redshift and more highly\nionized gas than the Mg II survey. Nevertheless, analysis on larger statistical\nsamples may constrain properties of the galaxies hosting these metals (e.g.\nmass, dust content) and/or the coherence-length of the gas giving rise to the\nmetal-line absorption.\n", "machine_text": "\nWe analyze the statistics of strong C IV absorption systems at z=1.5-3.5 toward gamma-ray bursts. Surprisingly, the rate of absorption (per unit redshift) is not higher than that observed toward quasar sightlines. We establish an upper limit of twice the observed incidence of C IV absorbers along GRB sightlines compared to quasar sightlines at a 95% confidence level. Furthermore, the distribution of equivalent widths of the two samples is consistent with being drawn from the same parent population. With larger statistical samples, future studies may be able to probe properties of the galaxies hosting the metals, such as mass and dust content, and the structure of the medium causing the metal line absorption.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0387}
{"prompt": "Rephrase the abstract of an article with title 'Accurate description of optical precursors and their relation to\n  weak-field coherent optical transients'.\n  We study theoretically the propagation of a step-modulated optical field as\nit passes through a dispersive dielectric made up of a dilute collection of\noscillators characterized by a single narrow-band resonance. The propagated\nfield is given in terms of an integral of a Fourier type, which cannot be\nevaluated even for simple models of the dispersive dielectric. The fact that\nthe oscillators have a low number density (dilute medium) and have a\nnarrow-band resonance allows us to simplify the integrand. In this case, the\nintegral can be evaluated exactly, although it is not possible using this\nmethod to separate out the transient part of the propagated field known as\noptical precursors. We also use an asymptotic method (saddle-point method) to\nevaluate the integral. The contributions to the integral related to the\nsaddle-points of the integrand give rise to the optical precursors. We obtain\nanalytic expressions for the precursor fields and the domain over which the\nasymptotic method is valid. When combined to obtain the total transient field,\nwe find that the agreement between the solutions obtained by the asymptotic and\nthe exact methods is excellent. Our results demonstrate that precursors can\npersist for many nanoseconds and the chirp in the instantaneous frequency of\nthe precursors can manifest itself in beats in the transmitted intensity. Our\nwork strongly suggests that precursors have been observed in many previous\nexperiments.\n\n", "human_text": "  We study theoretically the propagation of a step-modulated optical field as\nit passes through a dispersive dielectric made up of a dilute collection of\noscillators characterized by a single narrow-band resonance. The propagated\nfield is given in terms of an integral of a Fourier type, which cannot be\nevaluated even for simple models of the dispersive dielectric. The fact that\nthe oscillators have a low number density (dilute medium) and have a\nnarrow-band resonance allows us to simplify the integrand. In this case, the\nintegral can be evaluated exactly, although it is not possible using this\nmethod to separate out the transient part of the propagated field known as\noptical precursors. We also use an asymptotic method (saddle-point method) to\nevaluate the integral. The contributions to the integral related to the\nsaddle-points of the integrand give rise to the optical precursors. We obtain\nanalytic expressions for the precursor fields and the domain over which the\nasymptotic method is valid. When combined to obtain the total transient field,\nwe find that the agreement between the solutions obtained by the asymptotic and\nthe exact methods is excellent. Our results demonstrate that precursors can\npersist for many nanoseconds and the chirp in the instantaneous frequency of\nthe precursors can manifest itself in beats in the transmitted intensity. Our\nwork strongly suggests that precursors have been observed in many previous\nexperiments.\n", "machine_text": "\nThis article presents a theoretical study of optical precursors and their relationship to weak-field coherent optical transients. We evaluate an integral of the Fourier type in order to determine the propagated light field for a step-modulated optical field travelling through a dispersive dielectric consisting of a small number of oscillators, each with a narrow-band resonance. An asymptotic method (saddle-point method) is then employed to calculate the precursor fields and their related domains of validity. When the total transient field is computed, combining the asymptotic and exact methods produces excellent agreement in the results. This study reveals that optical precursors can endure for many nanoseconds and the instantaneous frequency chirp can form beats in the transmitted intensity. Our findings suggest that precursors might have already been detected in many preceding experiments.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.4238}
{"prompt": "Rephrase the abstract of an article with title 'The orbit, mass, size, albedo, and density of (65489) Ceto/Phorcys: A\n  tidally-evolved binary Centaur'.\n  Hubble Space Telescope observations of Uranus- and Neptune-crossing object\n(65489) Ceto/Phorcys (provisionally designated 2003 FX128) reveal it to be a\nclose binary system. The mutual orbit has a period of 9.554 +/- 0.011 days and\na semimajor axis of 1840 +/- 48 km. These values enable computation of a system\nmass of (5.41 +/- 0.42) 10^18 kg. Spitzer Space Telescope observations of\nthermal emission at 24 and 70 microns are combined with visible photometry to\nconstrain the system's effective radius (109 +10/-11 km) and geometric albedo\n(0.084 +0.021/-0.014). We estimate the average bulk density to be 1.37\n+0.66/-0.32 g cm^-3, consistent with ice plus rocky and/or carbonaceous\nmaterials. This density contrasts with lower densities recently measured with\nthe same technique for three other comparably-sized outer Solar System binaries\n(617) Patroclus, (26308) 1998 SM165, and (47171) 1999 TC36, and is closer to\nthe density of the saturnian irregular satellite Phoebe. The mutual orbit of\nCeto and Phorcys is nearly circular, with an eccentricity <= 0.015. This\nobservation is consistent with calculations suggesting that the system should\ntidally evolve on a timescale shorter than the age of the solar system.\n\n", "human_text": "  Hubble Space Telescope observations of Uranus- and Neptune-crossing object\n(65489) Ceto/Phorcys (provisionally designated 2003 FX128) reveal it to be a\nclose binary system. The mutual orbit has a period of 9.554 +/- 0.011 days and\na semimajor axis of 1840 +/- 48 km. These values enable computation of a system\nmass of (5.41 +/- 0.42) 10^18 kg. Spitzer Space Telescope observations of\nthermal emission at 24 and 70 microns are combined with visible photometry to\nconstrain the system's effective radius (109 +10/-11 km) and geometric albedo\n(0.084 +0.021/-0.014). We estimate the average bulk density to be 1.37\n+0.66/-0.32 g cm^-3, consistent with ice plus rocky and/or carbonaceous\nmaterials. This density contrasts with lower densities recently measured with\nthe same technique for three other comparably-sized outer Solar System binaries\n(617) Patroclus, (26308) 1998 SM165, and (47171) 1999 TC36, and is closer to\nthe density of the saturnian irregular satellite Phoebe. The mutual orbit of\nCeto and Phorcys is nearly circular, with an eccentricity <= 0.015. This\nobservation is consistent with calculations suggesting that the system should\ntidally evolve on a timescale shorter than the age of the solar system.\n", "machine_text": "\n\nAnalysis of Hubble Space Telescope and Spitzer Space Telescope observations of Uranus- and Neptune-crossing object (65489) Ceto/Phorcys (provisionally designated 2003 FX128) has revealed it to be a close binary system. The period and semimajor axis of the mutual orbit enabled determination of the system's mass, effective radius and albedo, which along with thermal emission estimations resulted in an average bulk density of 1.37 + 0.66/-0.32 g cm^-3. This is higher than that determined for three similarly-sized outer Solar System binaries and closer to the density of the saturnian irregular satellite Phoebe. Additionally, the orbit is near-circular with an eccentricity of <= 0.015, as predicted by theoretical calculations concerning how the system will evolve via tidal forces over a timescale shorter than the age of the solar system.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1523}
{"prompt": "Rephrase the abstract of an article with title 'Retired A Stars and Their Companions: Exoplanets Orbiting Three\n  Intermediate-Mass Subgiants'.\n  We report precision Doppler measurements of three intermediate-mass subgiants\nfrom Lick and Keck Observatories. All three stars show variability in their\nradial velocities consistent with planet-mass companions in Keplerian orbits.\nWe find a planet with a minimum mass of 2.5 Mjup in a 351.5 day orbit around HD\n192699, a planet with a minimum mass of 2.0 Mjup in a 341.1 day orbit around HD\n210702, and a planet with a minimum mass of 0.61 Mjup in a 297.3 day orbit\naround HD 175541. Stellar mass estimates from evolutionary models indicate that\nall of these stars were formerly A-type dwarfs with masses ranging from 1.65 to\n1.85 Msun. These three long-period planets would not have been detectable\nduring their stars' main-sequence phases due to the large rotational velocities\nand stellar jitter exhibited by early-type dwarfs. There are now 9 \"retired\"\n(evolved) A-type stars (Mstar > 1.6 Msun) with known planets. All 9 planets\norbit at distances a \\geq 0.78 AU, which is significantly different than the\nsemimajor axis distribution of planets around lower-mass stars. We examine the\npossibility that the observed lack of close-in planets is due to engulfment by\ntheir expanding host stars, but we find that this explanation is inadequate\ngiven the relatively small stellar radii of K giants (Rstar < 32 Rsun = 0.15\nAU) and subgiants (Rstar < 7 Rsun = 0.03 AU). Instead, we conclude that planets\naround intermediate-mass stars reside preferentially beyond ~0.8 AU, which may\nbe a reflection of different formation and migration histories of planets\naround A-type stars.\n\n", "human_text": "  We report precision Doppler measurements of three intermediate-mass subgiants\nfrom Lick and Keck Observatories. All three stars show variability in their\nradial velocities consistent with planet-mass companions in Keplerian orbits.\nWe find a planet with a minimum mass of 2.5 Mjup in a 351.5 day orbit around HD\n192699, a planet with a minimum mass of 2.0 Mjup in a 341.1 day orbit around HD\n210702, and a planet with a minimum mass of 0.61 Mjup in a 297.3 day orbit\naround HD 175541. Stellar mass estimates from evolutionary models indicate that\nall of these stars were formerly A-type dwarfs with masses ranging from 1.65 to\n1.85 Msun. These three long-period planets would not have been detectable\nduring their stars' main-sequence phases due to the large rotational velocities\nand stellar jitter exhibited by early-type dwarfs. There are now 9 \"retired\"\n(evolved) A-type stars (Mstar > 1.6 Msun) with known planets. All 9 planets\norbit at distances a \\geq 0.78 AU, which is significantly different than the\nsemimajor axis distribution of planets around lower-mass stars. We examine the\npossibility that the observed lack of close-in planets is due to engulfment by\ntheir expanding host stars, but we find that this explanation is inadequate\ngiven the relatively small stellar radii of K giants (Rstar < 32 Rsun = 0.15\nAU) and subgiants (Rstar < 7 Rsun = 0.03 AU). Instead, we conclude that planets\naround intermediate-mass stars reside preferentially beyond ~0.8 AU, which may\nbe a reflection of different formation and migration histories of planets\naround A-type stars.\n", "machine_text": "\nThis work presents the discovery of exoplanets orbiting three intermediate-mass subgiants by precise Doppler measurements of the said stars. The radial velocities of these stars display variations indicative of Keplerian orbits of planetary-mass companions. The planets, with masses of 2.5, 2.0, and 0.61Mjup respectively, are orbiting HD 192699, HD 210702, and HD 175541 at distances of 351.5, 341.1, and 297.3 day, respectively. Through the use of evolutionary models, it is found that these were formerly A-type dwarfs with masses ranging from 1.65-1.85Msun. Investigations further reveal that the missing close-in planets may not be explained by the envelopment of stars in relation to their expanding host stars. Therefore, this work suggests that the observed lack of planets near A-type stars may be due to the different formation and migration histories of the planetary bodies around such stars.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2455}
{"prompt": "Rephrase the abstract of an article with title 'How a \"Hit\" is Born: The Emergence of Popularity from the Dynamics of\n  Collective Choice'.\n  In recent times there has been a surge of interest in seeking out patterns in\nthe aggregate behavior of socio-economic systems. One such domain is the\nemergence of statistical regularities in the evolution of collective choice\nfrom individual behavior. This is manifested in the sudden emergence of\npopularity or \"success\" of certain ideas or products, compared to their\nnumerous, often very similar, competitors. In this paper, we present an\nempirical study of a wide range of popularity distributions, spanning from\nscientific paper citations to movie gross income. Our results show that in the\nmajority of cases, the distribution follows a log-normal form, suggesting that\nmultiplicative stochastic processes are the basis for emergence of popular\nentities. This suggests the existence of some general principles of complex\norganization leading to the emergence of popularity. We discuss the theoretical\nprinciples needed to explain this socio-economic phenomenon, and present a\nmodel for collective behavior that exhibits bimodality, which has been observed\nin certain empirical popularity distributions.\n\n", "human_text": "  In recent times there has been a surge of interest in seeking out patterns in\nthe aggregate behavior of socio-economic systems. One such domain is the\nemergence of statistical regularities in the evolution of collective choice\nfrom individual behavior. This is manifested in the sudden emergence of\npopularity or \"success\" of certain ideas or products, compared to their\nnumerous, often very similar, competitors. In this paper, we present an\nempirical study of a wide range of popularity distributions, spanning from\nscientific paper citations to movie gross income. Our results show that in the\nmajority of cases, the distribution follows a log-normal form, suggesting that\nmultiplicative stochastic processes are the basis for emergence of popular\nentities. This suggests the existence of some general principles of complex\norganization leading to the emergence of popularity. We discuss the theoretical\nprinciples needed to explain this socio-economic phenomenon, and present a\nmodel for collective behavior that exhibits bimodality, which has been observed\nin certain empirical popularity distributions.\n", "machine_text": "\nRecent research has focused on analyzing patterns of collective behavior in socio-economic systems and how different choices come to be seen as popular or \"hits\". This article examines numerous popularity distributions, such as citations to scientific papers and movie gross income figures in order to understand this phenomenon. We find in the majority of cases that these distributions follow a log-normal form, which implies that underlying multiplicative stochastic processes had a significant impact. The evidence suggests that general principles of complex organization are responsible for generating popular entities. As a result, a proposed model of collective behavior is presented to explain the bimodality which can be observed in certain popularity distributions.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2955}
{"prompt": "Rephrase the abstract of an article with title 'Magnetohydrostatic solar prominences in near-potential coronal magnetic\n  fields'.\n  We present numerical magnetohydrostatic solutions describing the\ngravitationally stratified, bulk equilibrium of cool, dense prominence plasma\nembedded in a near-potential coronal field. These solutions are calculated\nusing the FINESSE magnetohydrodynamics equilibrium solver and describe the\nmorphologies of magnetic field distributions in and around prominences and the\ncool prominence plasma that these fields support. The equilibrium condition for\nthis class of problem is usually different in distinct subdomains, separated by\nfree boundaries, across which solutions are matched by suitable continuity or\njump conditions describing force balance. We employ our precise finite element\nelliptic solver to calculate solutions not accessible by previous analytical\ntechniques with temperature or entropy prescribed as free functions of the\nmagnetic flux function, including a range of values of the polytropic index,\ntemperature variations mainly across magnetic field lines and photospheric\nfield profiles sheared close to the polarity inversion line. Out of the many\nexamples computed here, perhaps the most noteworthy is one which reproduces\nprecisely the three-part structure often encountered in observations: a cool\ndense prominence within a cavity/flux rope embedded in a hot corona. The\nstability properties of these new equilibria, which may be relevant to solar\neruptions, can be determined in the form of a full resistive MHD spectrum using\na companion hyperbolic stability solver.\n\n", "human_text": "  We present numerical magnetohydrostatic solutions describing the\ngravitationally stratified, bulk equilibrium of cool, dense prominence plasma\nembedded in a near-potential coronal field. These solutions are calculated\nusing the FINESSE magnetohydrodynamics equilibrium solver and describe the\nmorphologies of magnetic field distributions in and around prominences and the\ncool prominence plasma that these fields support. The equilibrium condition for\nthis class of problem is usually different in distinct subdomains, separated by\nfree boundaries, across which solutions are matched by suitable continuity or\njump conditions describing force balance. We employ our precise finite element\nelliptic solver to calculate solutions not accessible by previous analytical\ntechniques with temperature or entropy prescribed as free functions of the\nmagnetic flux function, including a range of values of the polytropic index,\ntemperature variations mainly across magnetic field lines and photospheric\nfield profiles sheared close to the polarity inversion line. Out of the many\nexamples computed here, perhaps the most noteworthy is one which reproduces\nprecisely the three-part structure often encountered in observations: a cool\ndense prominence within a cavity/flux rope embedded in a hot corona. The\nstability properties of these new equilibria, which may be relevant to solar\neruptions, can be determined in the form of a full resistive MHD spectrum using\na companion hyperbolic stability solver.\n", "machine_text": "This article investigates numerical magnetohydrostatic solutions that analyze the equilibrium of cool, dense prominence plasma encapsulated in near-potential coronal magnetic fields. We utilize the FINESSE magnetohydrodynamic equilibrium solver to facilitate the understanding of the magnetic field configurations that are responsible for sustaining the prominence and the resulting plasma. Boundary and continuity conditions are determined to match solutions in different domains. The finite element elliptic solver is employed to observe a range of polytropic index, temperature variations, and photospheric field profiles. We also find that our new equilibria may be related to solar eruptions, the associated stability properties of the equilibria can be further determined through a resistive MHD spectrum.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.3956}
{"prompt": "Rephrase the abstract of an article with title 'Revisiting the Issues On Netflow Sample and Export Performance'.\n  The high volume of packets and packet rates of traffic on some router links\nmakes it exceedingly difficult for routers to examine every packet in order to\nkeep detailed statistics about the traffic which is traversing the router.\nSampling is commonly applied on routers in order to limit the load incurred by\nthe collection of information that the router has to undertake when evaluating\nflow information for monitoring purposes. The sampling process in nearly all\ncases is a deterministic process of choosing 1 in every N packets on a\nper-interface basis, and then forming the flow statistics based on the\ncollected sampled statistics. Even though this sampling may not be significant\nfor some statistics, such as packet rate, others can be severely distorted.\nHowever, it is important to consider the sampling techniques and their relative\naccuracy when applied to different traffic patterns. The main disadvantage of\nsampling is the loss of accuracy in the collected trace when compared to the\noriginal traffic stream. To date there has not been a detailed analysis of the\nimpact of sampling at a router in various traffic profiles and flow criteria.\nIn this paper, we assess the performance of the sampling process as used in\nNetFlow in detail, and we discuss some techniques for the compensation of loss\nof monitoring detail.\n\n", "human_text": "  The high volume of packets and packet rates of traffic on some router links\nmakes it exceedingly difficult for routers to examine every packet in order to\nkeep detailed statistics about the traffic which is traversing the router.\nSampling is commonly applied on routers in order to limit the load incurred by\nthe collection of information that the router has to undertake when evaluating\nflow information for monitoring purposes. The sampling process in nearly all\ncases is a deterministic process of choosing 1 in every N packets on a\nper-interface basis, and then forming the flow statistics based on the\ncollected sampled statistics. Even though this sampling may not be significant\nfor some statistics, such as packet rate, others can be severely distorted.\nHowever, it is important to consider the sampling techniques and their relative\naccuracy when applied to different traffic patterns. The main disadvantage of\nsampling is the loss of accuracy in the collected trace when compared to the\noriginal traffic stream. To date there has not been a detailed analysis of the\nimpact of sampling at a router in various traffic profiles and flow criteria.\nIn this paper, we assess the performance of the sampling process as used in\nNetFlow in detail, and we discuss some techniques for the compensation of loss\nof monitoring detail.\n", "machine_text": "\nThis paper investigates the drawbacks of sampling when used on a router for traffic monitoring. Sampling is a process of selecting a packet from every N packets for the purposes of compiling flow information. This process, though beneficial in terms of saving processing time on the router, can produce inaccurate results when compared to the original traffic stream. We look into the various traffic profiles and flow criteria to assess the efficiency of the sampling process in NetFlow, and also propose possible solutions to improve monitoring data accuracy.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.073}
{"prompt": "Rephrase the abstract of an article with title 'Controlled collisions of a single atom and ion guided by movable\n  trapping potentials'.\n  We consider a system composed of a trapped atom and a trapped ion. The ion\ncharge induces in the atom an electric dipole moment, which attracts it with an\nr^{-4} dependence at large distances. In the regime considered here, the\ncharacteristic range of the atom-ion interaction is comparable or larger than\nthe characteristic size of the trapping potential, which excludes the\napplication of the contact pseudopotential. The short-range part of the\ninteraction is described in the framework of quantum-defect theory, by\nintroducing some short-range parameters, which can be related to the s-wave\nscattering length. When the separation between traps is changed we observe\ntrap-induced shape resonances between molecular bound states and vibrational\nstates of the external trapping potential. Our analysis is extended to\nquasi-one-dimensional geometries, when the scattering exhibit\nconfinement-induced resonances, similar to the ones studied before for\nshort-range interactions. For quasi-one-dimensional systems we investigate the\neffects of coupling between the center of mass and relative motion, which\noccurs for different trapping frequencies of atom and ion traps. Finally, we\nshow how the two types of resonances can be employed for quantum state control\nand spectroscopy of atom-ion molecules.\n\n", "human_text": "  We consider a system composed of a trapped atom and a trapped ion. The ion\ncharge induces in the atom an electric dipole moment, which attracts it with an\nr^{-4} dependence at large distances. In the regime considered here, the\ncharacteristic range of the atom-ion interaction is comparable or larger than\nthe characteristic size of the trapping potential, which excludes the\napplication of the contact pseudopotential. The short-range part of the\ninteraction is described in the framework of quantum-defect theory, by\nintroducing some short-range parameters, which can be related to the s-wave\nscattering length. When the separation between traps is changed we observe\ntrap-induced shape resonances between molecular bound states and vibrational\nstates of the external trapping potential. Our analysis is extended to\nquasi-one-dimensional geometries, when the scattering exhibit\nconfinement-induced resonances, similar to the ones studied before for\nshort-range interactions. For quasi-one-dimensional systems we investigate the\neffects of coupling between the center of mass and relative motion, which\noccurs for different trapping frequencies of atom and ion traps. Finally, we\nshow how the two types of resonances can be employed for quantum state control\nand spectroscopy of atom-ion molecules.\n", "machine_text": "\nThis article examines the collisions of a single trapped atom and a trapped ion, exploring the effects of an electric dipole moment generated by the ion. The interaction between the two is described using quantum-defect theory, and is found to exhibit shape and confinement-induced resonances which depend on the separation and dimensions of the trapping potentials. We also discuss how these resonances can be used for state control and spectroscopy of atom-ion molecules.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.1037}
{"prompt": "Rephrase the abstract of an article with title 'Effect of electron-electron interaction on the phonon-mediated spin\n  relaxation in quantum dots'.\n  We estimate the spin relaxation rate due to spin-orbit coupling and acoustic\nphonon scattering in weakly-confined quantum dots with up to five interacting\nelectrons. The Full Configuration Interaction approach is used to account for\nthe inter-electron repulsion, and Rashba and Dresselhaus spin-orbit couplings\nare exactly diagonalized. We show that electron-electron interaction strongly\naffects spin-orbit admixture in the sample. Consequently, relaxation rates\nstrongly depend on the number of carriers confined in the dot. We identify the\nmechanisms which may lead to improved spin stability in few electron (>2)\nquantum dots as compared to the usual one and two electron devices. Finally, we\ndiscuss recent experiments on triplet-singlet transitions in GaAs dots subject\nto external magnetic fields. Our simulations are in good agreement with the\nexperimental findings, and support the interpretation of the observed spin\nrelaxation as being due to spin-orbit coupling assisted by acoustic phonon\nemission.\n\n", "human_text": "  We estimate the spin relaxation rate due to spin-orbit coupling and acoustic\nphonon scattering in weakly-confined quantum dots with up to five interacting\nelectrons. The Full Configuration Interaction approach is used to account for\nthe inter-electron repulsion, and Rashba and Dresselhaus spin-orbit couplings\nare exactly diagonalized. We show that electron-electron interaction strongly\naffects spin-orbit admixture in the sample. Consequently, relaxation rates\nstrongly depend on the number of carriers confined in the dot. We identify the\nmechanisms which may lead to improved spin stability in few electron (>2)\nquantum dots as compared to the usual one and two electron devices. Finally, we\ndiscuss recent experiments on triplet-singlet transitions in GaAs dots subject\nto external magnetic fields. Our simulations are in good agreement with the\nexperimental findings, and support the interpretation of the observed spin\nrelaxation as being due to spin-orbit coupling assisted by acoustic phonon\nemission.\n", "machine_text": "\nIn this article, we investigate how electron-electron interaction can affect spin relaxation premiated by phonons in quantum dots. We apply the Full Configuration Interaction approach to examine the spin-orbit coupling with Rashba and Dresselhaus couplings, and spins are effectively stabilized with the number of confined electrons, due to the spin-orbit admixture change arising from the electron-electron interaction. We further compare the simulations with recent tripled-singlet transition experiments conducted on GaAs dots with external magnetic fields. Our results are in agreement with the experimental findings, reinforcing the conjecture that spin-orbit coupling aided by phonon emission is the main cause of spin relaxation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0868}
{"prompt": "Rephrase the abstract of an article with title 'IGR J00234+6141 : a new INTEGRAL source identified as an Intermediate\n  polar'.\n  Following an extensive survey of the galactic plane by the INTEGRAL\nsatellite, new hard X-ray sources are discovered with a significant fraction of\nCataclysmic Variables (CVs) among them. We report here the identification of\none of these hard X-ray sources, IGR J00234+6141, as an accreting magnetic\nwhite dwarf of intermediate polar type. We analyse the high energy emission of\nthe INTEGRAL source using all available data and provide complementary optical\nphotometric and spectroscopic data obtained respectively in August and October\n2006. Based on a refined INTEGRAL position, we confirm the proposed optical\nidentification. We clearly detect the presence of a 564 s periodic optical\nmodulation that we identify as the rotation of the white dwarf. The analysis of\nthe optical spectrum also demonstrates that the emission lines show a\nmodulation in radial velocity with an orbital period of Porb = (4.033 +/-\n0.005) hr. The two periodicities indicate that IGR00234+6141 is a magnetic CV\nof the intermediate polar type. This is one of the faintest and hardest sources\nof this type detected by INTEGRAL. This confirms earlier conclusions that IPs\ncontribute significantly to the population of galactic X-ray sources and\nrepresent a significant fraction of the high energy background.\n\n", "human_text": "  Following an extensive survey of the galactic plane by the INTEGRAL\nsatellite, new hard X-ray sources are discovered with a significant fraction of\nCataclysmic Variables (CVs) among them. We report here the identification of\none of these hard X-ray sources, IGR J00234+6141, as an accreting magnetic\nwhite dwarf of intermediate polar type. We analyse the high energy emission of\nthe INTEGRAL source using all available data and provide complementary optical\nphotometric and spectroscopic data obtained respectively in August and October\n2006. Based on a refined INTEGRAL position, we confirm the proposed optical\nidentification. We clearly detect the presence of a 564 s periodic optical\nmodulation that we identify as the rotation of the white dwarf. The analysis of\nthe optical spectrum also demonstrates that the emission lines show a\nmodulation in radial velocity with an orbital period of Porb = (4.033 +/-\n0.005) hr. The two periodicities indicate that IGR00234+6141 is a magnetic CV\nof the intermediate polar type. This is one of the faintest and hardest sources\nof this type detected by INTEGRAL. This confirms earlier conclusions that IPs\ncontribute significantly to the population of galactic X-ray sources and\nrepresent a significant fraction of the high energy background.\n", "machine_text": "\n\nA survey of the galactic plane conducted by the INTEGRAL satellite has revealed a substantial amount of new sources emitting hard X-rays, a significant fraction of which are Cataclysmic Variables (CVs). This paper focuses on one of the discovered sources, IGR J00234+6141, and identifies it as an accreting magnetic white dwarf of intermediate polar type. Our study included a more detailed analysis of the emission from the INTEGRAL source and further optical photometric and spectroscopic data obtained in 2006. Based on the refined INTEGRAL position and the detected 564 s optical modulation, we were able to confirm the proposed optical identification. Moreover, an orbital period of 4.033 +/- 0.005 hr was detected from the emission line modulation in the system's radial velocity. This confirms IGR J00234+6141 as a magnetic CV of intermediate polar type. It is one of the dimmest and hardest of its kind ever detected by INTEGRAL, indicating that such systems constitute a notable contribution to the high-energy background.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1433}
{"prompt": "Rephrase the abstract of an article with title 'Chemical evolution of the Small Magellanic Cloud based on planetary\n  nebulae'.\n  We investigate the chemical evolution of the Small Magellanic Cloud (SMC)\nbased on abundance data of planetary nebulae (PNe). The main goal is to\ninvestigate the time evolution of the oxygen abundance in this galaxy by\nderiving an age-metallicity relation. Such a relation is of fundamental\nimportance as an observational constraint of chemical evolution models of the\nSMC. We have used high quality PNe data in order to derive the properties of\nthe progenitor stars, so that the stellar ages could be estimated. We collected\na large number of measured spectral fluxes for each nebula, and derived\naccurate physical parameters and nebular abundances. New spectral data for a\nsample of SMC PNe obtained between 1999 and 2002 are also presented. These data\nare used together with data available in the literature to improve the accuracy\nof the fluxes for each spectral line. We obtained accurate chemical abundances\nfor PNe in the Small Magellanic Cloud, which can be useful as tools in the\nstudy of the chemical evolution of this galaxy and of Local Group galaxies. We\npresent the resulting oxygen versus age diagram and a similar relation\ninvolving the [Fe/H] metallicity based on a correlation with stellar data. We\ndiscuss the implications of the derived age-metallicity relation for the SMC\nformation, in particular by suggesting a star formation burst in the last 2-3\nGyr.\n\n", "human_text": "  We investigate the chemical evolution of the Small Magellanic Cloud (SMC)\nbased on abundance data of planetary nebulae (PNe). The main goal is to\ninvestigate the time evolution of the oxygen abundance in this galaxy by\nderiving an age-metallicity relation. Such a relation is of fundamental\nimportance as an observational constraint of chemical evolution models of the\nSMC. We have used high quality PNe data in order to derive the properties of\nthe progenitor stars, so that the stellar ages could be estimated. We collected\na large number of measured spectral fluxes for each nebula, and derived\naccurate physical parameters and nebular abundances. New spectral data for a\nsample of SMC PNe obtained between 1999 and 2002 are also presented. These data\nare used together with data available in the literature to improve the accuracy\nof the fluxes for each spectral line. We obtained accurate chemical abundances\nfor PNe in the Small Magellanic Cloud, which can be useful as tools in the\nstudy of the chemical evolution of this galaxy and of Local Group galaxies. We\npresent the resulting oxygen versus age diagram and a similar relation\ninvolving the [Fe/H] metallicity based on a correlation with stellar data. We\ndiscuss the implications of the derived age-metallicity relation for the SMC\nformation, in particular by suggesting a star formation burst in the last 2-3\nGyr.\n", "machine_text": "\nBased on high quality abundance data from planetary nebulae (PNe), this study investigates the chemical evolution of the Small Magellanic Cloud (SMC). Using a number of new and existing spectral fluxes, we were able to accurately estimate the age and chemical composition of the progenitor stars giving rise to the PNe. We present an age-metallicity relation in terms of both oxygen and [Fe/H] for the SMC that suggests a star formation burst occurring in the last 2-3 Gyr. Our results improve the accuracy of nebular abundances, providing useful information for the study of the chemical evolution of the SMC as well as other galaxies in the Local Group.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1967}
{"prompt": "Rephrase the abstract of an article with title 'A Multiphilic Descriptor for Chemical Reactivity and Selectivity'.\n  In line with the local philicity concept proposed by Chattaraj et al.\n(Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and\na dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.;\nToro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic\ndescriptor. It is defined as the difference between nucleophilic (Wk+) and\nelectrophilic (Wk-) condensed philicity functions. This descriptor is capable\nof simultaneously explaining the nucleophilicity and electrophilicity of the\ngiven atomic sites in the molecule. Variation of these quantities along the\npath of a soft reaction is also analyzed. Predictive ability of this descriptor\nhas been successfully tested on the selected systems and reactions.\nCorresponding force profiles are also analyzed in some representative cases.\nAlso, to study the intra- and intermolecular reactivities another related\ndescriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over\nthe electrophilicity in it has been defined and tested on all-metal aromatic\ncompounds.\n\n", "human_text": "  In line with the local philicity concept proposed by Chattaraj et al.\n(Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and\na dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.;\nToro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic\ndescriptor. It is defined as the difference between nucleophilic (Wk+) and\nelectrophilic (Wk-) condensed philicity functions. This descriptor is capable\nof simultaneously explaining the nucleophilicity and electrophilicity of the\ngiven atomic sites in the molecule. Variation of these quantities along the\npath of a soft reaction is also analyzed. Predictive ability of this descriptor\nhas been successfully tested on the selected systems and reactions.\nCorresponding force profiles are also analyzed in some representative cases.\nAlso, to study the intra- and intermolecular reactivities another related\ndescriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over\nthe electrophilicity in it has been defined and tested on all-metal aromatic\ncompounds.\n", "machine_text": "\nThis paper introduces a novel multiphilic descriptor based on the local philicity concept of Chattaraj et al. and the two descriptors formulated by Toro-Labbe and compatriots. The multiphilic descriptor is the difference of nucleophilic (Wk+) and electrophilic (Wk-) condensed philicity functions, which makes it possible to explain the nucleophilicity and electrophilicity of an atomic site in a molecule simultaneously. We examine its predictive capabilities on the selected systems and their reactions, as well as the appropriate force profiles, by utilizing the nucleophilicity excess (DelW-+) towards nucleophiles over electrophilicity on all-metal aromatic compounds.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0334}
{"prompt": "Rephrase the abstract of an article with title 'Gravity dual of 1+1 dimensional Bjorken expansion'.\n  We study the application of AdS/CFT duality to longitudinal boost invariant\nBjorken expansion of QCD matter produced in ultrarelativistic heavy ion\ncollisions. As the exact (1+4)-dimensional bulk solutions for the\n(1+3)-dimensional boundary theory are not known, we investigate in detail the\n(1+1)-dimensional boundary theory, where the bulk is AdS_3 gravity. We find an\nexact bulk solution, show that this solution describes part of the spinless\nBanados-Teitelboim-Zanelli (BTZ) black hole with the angular dimension\nunwrapped, and use the thermodynamics of the BTZ hole to recover the\ntime-dependent temperature and entropy density on the boundary. After\nseparating from the holographic energy-momentum tensor a vacuum contribution,\ngiven by the extremal black hole limit in the bulk, we find that the boundary\nfluid is an ideal gas in local thermal equilibrium. Including angular momentum\nin the bulk gives a boundary flow that is boost invariant but has a nonzero\nlongitudinal velocity with respect to the Bjorken expansion.\n\n", "human_text": "  We study the application of AdS/CFT duality to longitudinal boost invariant\nBjorken expansion of QCD matter produced in ultrarelativistic heavy ion\ncollisions. As the exact (1+4)-dimensional bulk solutions for the\n(1+3)-dimensional boundary theory are not known, we investigate in detail the\n(1+1)-dimensional boundary theory, where the bulk is AdS_3 gravity. We find an\nexact bulk solution, show that this solution describes part of the spinless\nBanados-Teitelboim-Zanelli (BTZ) black hole with the angular dimension\nunwrapped, and use the thermodynamics of the BTZ hole to recover the\ntime-dependent temperature and entropy density on the boundary. After\nseparating from the holographic energy-momentum tensor a vacuum contribution,\ngiven by the extremal black hole limit in the bulk, we find that the boundary\nfluid is an ideal gas in local thermal equilibrium. Including angular momentum\nin the bulk gives a boundary flow that is boost invariant but has a nonzero\nlongitudinal velocity with respect to the Bjorken expansion.\n", "machine_text": "\nUsing AdS/CFT duality, we demonstrate the ability of gravity to model the dynamics of a 1+1 dimensional Bjorken expansion in QCD. We focus on finding an exact bulk solution and show that this solution can be used to describe part of the spinless Banados-Teitelboim-Zanelli (BTZ) black hole, with the angular dimension unwrapped. Then, utilizing thermodynamics of the BTZ black hole to compute the time-dependent temperature and entropy density at the boundary, we identify the boundary fluid as an ideal gas in local thermal equilibrium. We find that with angular momentum of the bulk, it produces a boundary flow that is boost invariant but with a nonzero longitudinal velocity compared to the Bjorken expansion.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1791}
{"prompt": "Rephrase the abstract of an article with title 'The ACS Survey of Galactic Globular Clusters. II. Stellar Evolution\n  Tracks, Isochrones, Luminosity Functions, and Synthetic Horizontal-Branch\n  Models'.\n  The ACS Survey of Galactic Globular Clusters, an HST Treasury Project, will\ndeliver high quality, homogeneous photometry of 65 globular clusters. This\npaper introduces a new collection of stellar evolution tracks and isochrones\nsuitable for analyzing the ACS Survey data. Stellar evolution models were\ncomputed at [Fe/H]= -2.5, -2.0, -1.5, -1.0, -0.5, and 0; [alpha/Fe]= -0.2, 0,\n0.2, 0.4, 0.6, and 0.8; and three initial He abundances for masses from 0.1 to\n1.8 Msun and ages from 2 to 15 Gyr. Each isochrone spans a wide range in\nluminosity from Mv~14 up to the tip of the red giant branch. These are\ncomplemented by a set of He-burning tracks that extend from the zero age\nhorizontal branch to the onset of thermal pulsations on the asymptotic giant\nbranch. In addition, a set of computer programs are provided that make it\npossible to interpolate the isochrones in [Fe/H], generate luminosity functions\nfrom the isochrones, and create synthetic horizontal branch models. The tracks\nand isochrones have been converted to the observational plane with two\ndifferent color-Teff transformations, one synthetic and one semi-empirical, in\nground-based B, V, and I, and F606W and F814W for both ACS-WFC and WFPC2\nsystems. All models and programs presented in this paper are available from\nhttp://stellar.dartmouth.edu/~models/\n\n", "human_text": "  The ACS Survey of Galactic Globular Clusters, an HST Treasury Project, will\ndeliver high quality, homogeneous photometry of 65 globular clusters. This\npaper introduces a new collection of stellar evolution tracks and isochrones\nsuitable for analyzing the ACS Survey data. Stellar evolution models were\ncomputed at [Fe/H]= -2.5, -2.0, -1.5, -1.0, -0.5, and 0; [alpha/Fe]= -0.2, 0,\n0.2, 0.4, 0.6, and 0.8; and three initial He abundances for masses from 0.1 to\n1.8 Msun and ages from 2 to 15 Gyr. Each isochrone spans a wide range in\nluminosity from Mv~14 up to the tip of the red giant branch. These are\ncomplemented by a set of He-burning tracks that extend from the zero age\nhorizontal branch to the onset of thermal pulsations on the asymptotic giant\nbranch. In addition, a set of computer programs are provided that make it\npossible to interpolate the isochrones in [Fe/H], generate luminosity functions\nfrom the isochrones, and create synthetic horizontal branch models. The tracks\nand isochrones have been converted to the observational plane with two\ndifferent color-Teff transformations, one synthetic and one semi-empirical, in\nground-based B, V, and I, and F606W and F814W for both ACS-WFC and WFPC2\nsystems. All models and programs presented in this paper are available from\nhttp://stellar.dartmouth.edu/~models/\n", "machine_text": "This paper presents the results of a HST Treasury Project, the ACS Survey of Galactic Globular Clusters, which provides high resolution, homogeneous photometry of 65 globular clusters. It introduces a library of stellar evolution tracks, isochrones and luminosity functions for different metal abundances, initial helium abundances and mass ranges from 0.1 to 1.8 solar masses and 2 to 15 Gyr age range. He-burning tracks and synthetic horizontal branch models are included, along with corresponding programs that allow interpolation of isochrones and generation of luminosity functions. The tracks have been converted to observational plane in several color/temperature systems, and all models and programs are available online.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0847}
{"prompt": "Rephrase the abstract of an article with title 'A dynamical analysis of the 14 Her planetary system'.\n  Precision radial velocity (RV) measurements of the Sun-like dwarf\n  14 Herculis published by Naef et. al (2004), Butler et. al (2006) and\n  Wittenmyer et al (2007) reveal a Jovian planet in a 1760 day orbit and a\ntrend indicating the second distant object. On the grounds of dynamical\nconsiderations, we test a hypothesis that the trend can be explained by the\npresence of an additional giant planet. We derive dynamical limits to th\norbital parameters of the putative outer Jovian companion in an orbit within\n~13 AU. In this case, the mutual interactions between the Jovian planets are\nimportant for the long-term stability of the system. The best self-consistent\nand stable Newtonian fit to an edge-on configuration of Jovian planets has the\nouter planet in 9 AU orbit with a moderate eccentricity ~0.2 and confined to a\nzone spanned by the low-order mean motion resonances 5:1 and 6:1. This solution\nlies in a shallow minimum of \\Chi and persists over a wide range of the system\ninclination. Other stable configurations within 1\\sigma confidence interval of\nthe best fit are possible for the semi-major axis of the outer planet in the\nrange of (6,13) AU and the eccentricity in the range of (0,0.3). The orbital\ninclination cannot yet be determined but when it decreases, both planetary\nmasses approach ~10 Jupiter masses and for ~30 deg the hierarchy of the masses\nis reversed.\n\n", "human_text": "  Precision radial velocity (RV) measurements of the Sun-like dwarf\n  14 Herculis published by Naef et. al (2004), Butler et. al (2006) and\n  Wittenmyer et al (2007) reveal a Jovian planet in a 1760 day orbit and a\ntrend indicating the second distant object. On the grounds of dynamical\nconsiderations, we test a hypothesis that the trend can be explained by the\npresence of an additional giant planet. We derive dynamical limits to th\norbital parameters of the putative outer Jovian companion in an orbit within\n~13 AU. In this case, the mutual interactions between the Jovian planets are\nimportant for the long-term stability of the system. The best self-consistent\nand stable Newtonian fit to an edge-on configuration of Jovian planets has the\nouter planet in 9 AU orbit with a moderate eccentricity ~0.2 and confined to a\nzone spanned by the low-order mean motion resonances 5:1 and 6:1. This solution\nlies in a shallow minimum of \\Chi and persists over a wide range of the system\ninclination. Other stable configurations within 1\\sigma confidence interval of\nthe best fit are possible for the semi-major axis of the outer planet in the\nrange of (6,13) AU and the eccentricity in the range of (0,0.3). The orbital\ninclination cannot yet be determined but when it decreases, both planetary\nmasses approach ~10 Jupiter masses and for ~30 deg the hierarchy of the masses\nis reversed.\n", "machine_text": "An analysis of the dynamical aspects of the 14 Her planetary system is presented here. Naef et al. (2004), Butler et al. (2006) and Wittenmyer et al. (2007) have previously identified a Jovian planet in a 1760 day orbit and a trend that may be due to a second, outer object. Through fundamental dynamical considerations, this paper tests the hypothesis that such an outer object is a Jovian planet with an orbital period of 13 AU or less. The optimal stable solution of this system features two Jovian planets with semi-major axes of 9 AU and orbital eccentricities ranging from 0 to 0.3, although other stable configurations are possible. The ratio between the two planets\u2019 masses can reverse at an orbital inclination of 30 degrees.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1858}
{"prompt": "Rephrase the abstract of an article with title 'On the change of latitude of Arctic East Siberia at the end of the\n  Pleistocene'.\n  Mammoths lived in Arctic East Siberia. In this region there is not sufficient\nsunlight over the year for the growth of the plants on which these animals\nfeed. Therefore the latitude of this region was lower before the end of the\nPleistocene. As the cause of this geographic pole shift, we postulate a massive\nobject, which moved in an extremely eccentric orbit and was hot from tidal work\nand solar radiation. Evaporation produced a disk-shaped cloud of ions around\nthe Sun. This cloud partially shielded the solar radiation, producing the cold\nand warm periods that characterize the Pleistocene. The shielding depends on\nthe inclination of Earth's orbit, which has a period of 100'000 years. The\ncloud builds up to a density at which inelastic particle collisions induce its\ncollapse The resulting near-periodic time dependence resembles that of\nDansgaard-Oeschger events. During cold periods fine grained inclusions were\ndeposited into the ice. The Pleistocene ended when the massive object had a\nclose encounter with the Earth, which suffered a one per mil stretching\ndeformation. While the deformation relaxed to an equilibrium shape in one to\nseveral years, the globe turned relative to the rotation axis: The North Pole\nmoved from Greenland to the Arctic Sea. The massive object was torn to pieces,\nwhich evaporated.\n\n", "human_text": "  Mammoths lived in Arctic East Siberia. In this region there is not sufficient\nsunlight over the year for the growth of the plants on which these animals\nfeed. Therefore the latitude of this region was lower before the end of the\nPleistocene. As the cause of this geographic pole shift, we postulate a massive\nobject, which moved in an extremely eccentric orbit and was hot from tidal work\nand solar radiation. Evaporation produced a disk-shaped cloud of ions around\nthe Sun. This cloud partially shielded the solar radiation, producing the cold\nand warm periods that characterize the Pleistocene. The shielding depends on\nthe inclination of Earth's orbit, which has a period of 100'000 years. The\ncloud builds up to a density at which inelastic particle collisions induce its\ncollapse The resulting near-periodic time dependence resembles that of\nDansgaard-Oeschger events. During cold periods fine grained inclusions were\ndeposited into the ice. The Pleistocene ended when the massive object had a\nclose encounter with the Earth, which suffered a one per mil stretching\ndeformation. While the deformation relaxed to an equilibrium shape in one to\nseveral years, the globe turned relative to the rotation axis: The North Pole\nmoved from Greenland to the Arctic Sea. The massive object was torn to pieces,\nwhich evaporated.\n", "machine_text": "\nAt the end of the Pleistocene, Arctic East Siberia underwent a significant change in its latitude due to clues pointing to a large body orbiting the Sun in an extremely eccentric trajectory. This massive object generated heat from tidal work and solar radiation and created a disk-shaped cloud of ions around the Sun, effectively shielding the sunlight to produce periods of extreme cold and warm temperatures characteristic of the Pleistocene. This climate disruption also caused fine-grained particles to be deposited into the ice. Eventually, the massive interloper had a close encounter with the Earth, causing a one-per mil stretching deformation, a shift in the Earth's rotation axis, and ultimately the movement of the North Pole from Greenland to the Arctic Sea. When the deformation returned to equilibrium, the large object was destroyed and evaporated.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2489}
{"prompt": "Rephrase the abstract of an article with title 'Stability of the splay state in pulse--coupled networks'.\n  The stability of the dynamical states characterized by a uniform firing rate\n({\\it splay states}) is analyzed in a network of globally coupled leaky\nintegrate-and-fire neurons. This is done by reducing the set of differential\nequations to a map that is investigated in the limit of large network size. We\nshow that the stability of the splay state depends crucially on the ratio\nbetween the pulse--width and the inter-spike interval. More precisely, the\nspectrum of Floquet exponents turns out to consist of three components: (i) one\nthat coincides with the predictions of the mean-field analysis [Abbott-van\nVreesvijk, 1993]; (ii) a component measuring the instability of\n\"finite-frequency\" modes; (iii) a number of \"isolated\" eigenvalues that are\nconnected to the characteristics of the single pulse and may give rise to\nstrong instabilities (the Floquet exponent being proportional to the network\nsize). Finally, as a side result, we find that the splay state can be stable\neven for inhibitory coupling.\n\n", "human_text": "  The stability of the dynamical states characterized by a uniform firing rate\n({\\it splay states}) is analyzed in a network of globally coupled leaky\nintegrate-and-fire neurons. This is done by reducing the set of differential\nequations to a map that is investigated in the limit of large network size. We\nshow that the stability of the splay state depends crucially on the ratio\nbetween the pulse--width and the inter-spike interval. More precisely, the\nspectrum of Floquet exponents turns out to consist of three components: (i) one\nthat coincides with the predictions of the mean-field analysis [Abbott-van\nVreesvijk, 1993]; (ii) a component measuring the instability of\n\"finite-frequency\" modes; (iii) a number of \"isolated\" eigenvalues that are\nconnected to the characteristics of the single pulse and may give rise to\nstrong instabilities (the Floquet exponent being proportional to the network\nsize). Finally, as a side result, we find that the splay state can be stable\neven for inhibitory coupling.\n", "machine_text": "\nBy utilizing a set of differential equations to reduce the set of dynamics in a coupled leaky integrate-and-fire neuron network, an examination of the stability of uniform firing rate ({\\it splay states}) occurs. This analysis reveals that the stability of this splay state depends heavily on the ratio between the pulse-width and inter-spike interval. Three components comprise the spectrum: (i) correlates to the original mean-field analysis; (ii) evaluates the instability of finite-frequency modes; (iii) captures isolated eigenvalues that are connected to the individual pulse and can cause great instabilities (with the Floquet exponent proportionate to the network size). Furthermore, it is also concluded that inhibitory coupling holds the capability to provide a stable splay state.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2811}
{"prompt": "Rephrase the abstract of an article with title 'Angular momentum conservation and torsional oscillations in the Sun and\n  solar-like stars'.\n  The solar torsional oscillations, i.e., the perturbations of the angular\nvelocity of rotation associated with the eleven-year activity cycle, are a\nmanifestation of the interaction among the interior magnetic fields, amplified\nand modulated by the solar dynamo, and rotation, meridional flow and turbulent\nthermal transport. Therefore, they can be used, at least in principle, to put\nconstraints on that interaction. Similar phenomena are expected to be observed\nin solar-like stars and can be modelled to shed light on analogous interactions\nin different environments. The source of the torsional oscillations is\ninvestigated by means of a model for the angular momentum transport within the\nconvection zone. A description of the torsional oscillations is introduced,\nbased on an analytical solution of the angular momentum equation in the\nmean-field approach. It provides information on the intensity and location of\nthe torques producing the redistribution of the angular momentum within the\nconvection zone of the Sun along the activity cycle. The method can be extended\nto solar-like stars for which some information on the time-dependence of the\ndifferential rotation is becoming available. Illustrative applications to the\nSun and solar-like stars are presented. Under the hypothesis that the solar\ntorsional oscillations are due to the mean-field Lorentz force, the mean\namplitude of the Maxwell stresses and the phase relationship between poloidal\nand toroidal field components are obtained. Our preliminary results show the\ncapability of the proposed approach to constrain the amplitude, phase and\nlocation of the perturbations leading to the observed torsional oscillations.\n\n", "human_text": "  The solar torsional oscillations, i.e., the perturbations of the angular\nvelocity of rotation associated with the eleven-year activity cycle, are a\nmanifestation of the interaction among the interior magnetic fields, amplified\nand modulated by the solar dynamo, and rotation, meridional flow and turbulent\nthermal transport. Therefore, they can be used, at least in principle, to put\nconstraints on that interaction. Similar phenomena are expected to be observed\nin solar-like stars and can be modelled to shed light on analogous interactions\nin different environments. The source of the torsional oscillations is\ninvestigated by means of a model for the angular momentum transport within the\nconvection zone. A description of the torsional oscillations is introduced,\nbased on an analytical solution of the angular momentum equation in the\nmean-field approach. It provides information on the intensity and location of\nthe torques producing the redistribution of the angular momentum within the\nconvection zone of the Sun along the activity cycle. The method can be extended\nto solar-like stars for which some information on the time-dependence of the\ndifferential rotation is becoming available. Illustrative applications to the\nSun and solar-like stars are presented. Under the hypothesis that the solar\ntorsional oscillations are due to the mean-field Lorentz force, the mean\namplitude of the Maxwell stresses and the phase relationship between poloidal\nand toroidal field components are obtained. Our preliminary results show the\ncapability of the proposed approach to constrain the amplitude, phase and\nlocation of the perturbations leading to the observed torsional oscillations.\n", "machine_text": "This study focuses on the source and investigation of solar torsional oscillations, as well as extensions of them to other solar-like stars. A mathematical model is proposed to evaluate the transport of angular momentum inside the convection zone. Applying this method to the Sun, data is gathered regarding the magnitude, location, and intensity of the perturbing forces causing the variability in surface rotation rate. In addition, similar conditions of solar-like stars are also considered. Results from the model are then used to estimate the amplitude and phase relationship of poloidal and toroidal field components resulting from the mean-field Lorentz force. In cases of both the Sun and solar-like stars, the proposed model can be used to assess the magnitude and position of the torsional oscillations identified.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1623}
{"prompt": "Rephrase the abstract of an article with title 'Towards a microscopic theory of toroidal moments in bulk periodic\n  crystals'.\n  We present a theoretical analysis of magnetic toroidal moments in periodic\nsystems, in the limit in which the toroidal moments are caused by a time and\nspace reversal symmetry breaking arrangement of localized magnetic dipole\nmoments. We summarize the basic definitions for finite systems and address the\nquestion of how to generalize these definitions to the bulk periodic case. We\ndefine the toroidization as the toroidal moment per unit cell volume, and we\nshow that periodic boundary conditions lead to a multivaluedness of the\ntoroidization, which suggests that only differences in toroidization are\nmeaningful observable quantities. Our analysis bears strong analogy to the\nmodern theory of electric polarization in bulk periodic systems, but we also\npoint out some important differences between the two cases. We then discuss the\ninstructive example of a one-dimensional chain of magnetic moments, and we show\nhow to properly calculate changes of the toroidization for this system.\nFinally, we evaluate and discuss the toroidization (in the local dipole limit)\nof four important example materials: BaNiF_4, LiCoPO_4, GaFeO_3, and BiFeO_3.\n\n", "human_text": "  We present a theoretical analysis of magnetic toroidal moments in periodic\nsystems, in the limit in which the toroidal moments are caused by a time and\nspace reversal symmetry breaking arrangement of localized magnetic dipole\nmoments. We summarize the basic definitions for finite systems and address the\nquestion of how to generalize these definitions to the bulk periodic case. We\ndefine the toroidization as the toroidal moment per unit cell volume, and we\nshow that periodic boundary conditions lead to a multivaluedness of the\ntoroidization, which suggests that only differences in toroidization are\nmeaningful observable quantities. Our analysis bears strong analogy to the\nmodern theory of electric polarization in bulk periodic systems, but we also\npoint out some important differences between the two cases. We then discuss the\ninstructive example of a one-dimensional chain of magnetic moments, and we show\nhow to properly calculate changes of the toroidization for this system.\nFinally, we evaluate and discuss the toroidization (in the local dipole limit)\nof four important example materials: BaNiF_4, LiCoPO_4, GaFeO_3, and BiFeO_3.\n", "machine_text": "This article presents a theoretical exploration into magnetic toroidal moments in periodic systems, motivated by breaking of time and space reversal symmetries by magnetic dipoles. We define the toroidization as a quantity of measurement and argue that it is uniquely determined for each unit cell. We provide instruction via a one-dimensional chain of magnetic moments, and then evaluate and discuss toroidization of four representative materials. Our analysis has strong parallels with the study of electric polarization in bulk periodic systems, and some differences specifically in the magnetic context.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.1974}
{"prompt": "Rephrase the abstract of an article with title 'Reggeization of N=8 Supergravity and N=4 Yang-Mills Theory II'.\n  The loop expansion for the n-point functions of N=4 Yang-Mills theory and N=8\nsupergravity can be formulated as the loop expansion of scalar field theory\nwith an infinite subclass being the ladder diagrams. We consider the sum of\nladder diagrams for gluon-gluon and graviton-graviton scattering in the Regge\nlimit. The reggeization of the gluon and the graviton is discussed in this\ncontext and that of hep-th/0701217. If the Bern, Dixon, Smirnov conjecture for\nplanar gluon-gluon scattering is correct, then the ladder sum for SU(N) gauge\ntheory at large N, correctly gives the Regge limit, with Regge trajectory\nfunction proportional to the cusp anomalous dimension.\n  In graviton-graviton scattering it is argued that the graviton lies on a\nRegge trajectory. Regge cuts are also present due to infinite sums of\nnon-planar graphs. The multiple exchange of Regge poles in non-planar graphs\ncan give a countable infinite number of moving Regge cuts which accumulate near\ns=0. It is conjectured that this may be related to the infinite number of\nnon-perturbative massless states which remain in the limit discussed by Green,\nOoguri and Schwarz.\n\n", "human_text": "  The loop expansion for the n-point functions of N=4 Yang-Mills theory and N=8\nsupergravity can be formulated as the loop expansion of scalar field theory\nwith an infinite subclass being the ladder diagrams. We consider the sum of\nladder diagrams for gluon-gluon and graviton-graviton scattering in the Regge\nlimit. The reggeization of the gluon and the graviton is discussed in this\ncontext and that of hep-th/0701217. If the Bern, Dixon, Smirnov conjecture for\nplanar gluon-gluon scattering is correct, then the ladder sum for SU(N) gauge\ntheory at large N, correctly gives the Regge limit, with Regge trajectory\nfunction proportional to the cusp anomalous dimension.\n  In graviton-graviton scattering it is argued that the graviton lies on a\nRegge trajectory. Regge cuts are also present due to infinite sums of\nnon-planar graphs. The multiple exchange of Regge poles in non-planar graphs\ncan give a countable infinite number of moving Regge cuts which accumulate near\ns=0. It is conjectured that this may be related to the infinite number of\nnon-perturbative massless states which remain in the limit discussed by Green,\nOoguri and Schwarz.\n", "machine_text": "This article examines the loop expansions for n-point functions of N=4 Yang-Mills theory and N=8 supergravity. It investigates the reggeization of both the gluon and the graviton. If the Bern, Dixon, Smirnov conjecture for planar gluon-gluon scattering is valid, then the ladder sum of SU(N) gauge theory completes the Regge limit with the trajectory function proportional to the cusp anomalous dimension. When it comes to graviton-graviton scattering, the corresponding Regge trajectory is constructed, as well as Regge cuts due to infinite sums of non-planar graphs. Finally, this article postulates that multiple exchanges of Regge poles in non-planar graphs may be connected to the existence of infinite number of non-perturbative massless states discovered by Green, Ooguri and Schwarz.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 706.0917}
{"prompt": "Rephrase the abstract of an article with title 'On purely transmitting defects in affine Toda field theory'.\n  Affine Toda field theories with a purely transmitting integrable defect are\nconsidered and the model based on a_2 is analysed in detail. After providing a\ncomplete characterization of the problem in a classical framework, a suitable\nquantum transmission matrix, able to describe the interaction between an\nintegrable defect and solitons, is found. Two independent paths are taken to\nreach the result. One is an investigation of the triangle equations using the\nS-matrix for the imaginary coupling bulk affine Toda field theories proposed by\nHollowood, and the other uses a functional integral approach together with a\nbootstrap procedure. Evidence to support the results is collected in various\nways: for instance, through the calculation of the transmission factors for the\nlightest breathers. While previous discoveries within the sine-Gordon model\nmotivated this study, there are several new phenomena displayed in the a_2\nmodel including intriguing disparities between the classical and the quantum\npictures. For example, in the quantum framework, for a specific range of the\ncoupling constant that excludes a neighbourhood of the classical limit, there\nis an unstable bound state.\n\n", "human_text": "  Affine Toda field theories with a purely transmitting integrable defect are\nconsidered and the model based on a_2 is analysed in detail. After providing a\ncomplete characterization of the problem in a classical framework, a suitable\nquantum transmission matrix, able to describe the interaction between an\nintegrable defect and solitons, is found. Two independent paths are taken to\nreach the result. One is an investigation of the triangle equations using the\nS-matrix for the imaginary coupling bulk affine Toda field theories proposed by\nHollowood, and the other uses a functional integral approach together with a\nbootstrap procedure. Evidence to support the results is collected in various\nways: for instance, through the calculation of the transmission factors for the\nlightest breathers. While previous discoveries within the sine-Gordon model\nmotivated this study, there are several new phenomena displayed in the a_2\nmodel including intriguing disparities between the classical and the quantum\npictures. For example, in the quantum framework, for a specific range of the\ncoupling constant that excludes a neighbourhood of the classical limit, there\nis an unstable bound state.\n", "machine_text": "\nThis article investigates the presence and characteristics of purely transmitting defects in Affine Toda field theories, taking the model based on a_2 as a point of focus. A wide range of methods are used to confirm the predictions and reveal any peculiarities, including analysis of triangle equations using S-matrix from Hollowood, functional integral approach coupled with a bootstrap procedure, and the calculation of transmission factors for the lightest breathers. It has been observed that the quantum and classical pictures may differ; for instance, in a quantum context, a specific range of the coupling constant can lead to an unstable bound state, contrary to what can be seen in the classical framework.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.1066}
{"prompt": "Rephrase the abstract of an article with title 'A Connection Between Bulge Properties and the Bimodality of Galaxies'.\n  The global colors of galaxies have recently been shown to follow bimodal\ndistributions. Galaxies separate into a ``red sequence'', populated\nprototypically by early-type galaxies, and a ``blue cloud'', whose typical\nobjects are late-type disk galaxies. Intermediate-type (Sa-Sbc) galaxies\npopulate both regions. It has been suggested that this bimodality reflects the\ntwo-component nature of disk-bulge galaxies. However, it has now been\nestablished that there are two types of bulges: ``classical bulges'' that are\ndynamically hot systems resembling (little) ellipticals, and ``pseudobulges'',\ndynamically cold, flattened, disk-like structures that could not have formed\nvia violent relaxation. Therefore thee question is whether at types Sa-Sbc,\nwhere both bulge types are found, the red-blue dichotomy separates galaxies at\nsome value of disk-to-bulge ratio, $B/T$, or, whether it separates galaxies of\ndifferent bulge type, irrespective of their $B/T$. We identify classical bulges\nand pseudobulges morphologically with HST images in a sample of nearby\ngalaxies. Detailed surface photometry reveals that: (1) The red -- blue\ndichotomy is a function of bulge type: at the same $B/T$, pseudobulges are in\nglobally blue galaxies and classical bulges are in globally red galaxies. (2)\nBulge type also predicts where the galaxy lies in other (bimodal) global\nstructural parameters. (3) Hence, the red -- blue dichotomy is not due to\ndecreasing bulge prominence alone, and the bulge type of a galaxy carries\nsignificance for the galaxy's evolutionary history ... (Abridged)\n\n", "human_text": "  The global colors of galaxies have recently been shown to follow bimodal\ndistributions. Galaxies separate into a ``red sequence'', populated\nprototypically by early-type galaxies, and a ``blue cloud'', whose typical\nobjects are late-type disk galaxies. Intermediate-type (Sa-Sbc) galaxies\npopulate both regions. It has been suggested that this bimodality reflects the\ntwo-component nature of disk-bulge galaxies. However, it has now been\nestablished that there are two types of bulges: ``classical bulges'' that are\ndynamically hot systems resembling (little) ellipticals, and ``pseudobulges'',\ndynamically cold, flattened, disk-like structures that could not have formed\nvia violent relaxation. Therefore thee question is whether at types Sa-Sbc,\nwhere both bulge types are found, the red-blue dichotomy separates galaxies at\nsome value of disk-to-bulge ratio, $B/T$, or, whether it separates galaxies of\ndifferent bulge type, irrespective of their $B/T$. We identify classical bulges\nand pseudobulges morphologically with HST images in a sample of nearby\ngalaxies. Detailed surface photometry reveals that: (1) The red -- blue\ndichotomy is a function of bulge type: at the same $B/T$, pseudobulges are in\nglobally blue galaxies and classical bulges are in globally red galaxies. (2)\nBulge type also predicts where the galaxy lies in other (bimodal) global\nstructural parameters. (3) Hence, the red -- blue dichotomy is not due to\ndecreasing bulge prominence alone, and the bulge type of a galaxy carries\nsignificance for the galaxy's evolutionary history ... (Abridged)\n", "machine_text": "\nRecently, it has been proposed that bimodality in global colors of galaxies is related to the two-part makeup of disk-bulge galaxies. This bimodality separates galaxies into a ``red sequence'', populated mainly by early-type galaxies, and a ``blue cloud'' composed mainly of late-type disk galaxies. Intermediate types (Sa-Sbc) can be found in both areas. In a sample of nearby galaxies, an analysis has been conducted with high-resolution images to better understand the connection between bulge properties and bimodal color distribution. The findings show that the red-blue dichotomy is linked to the type of bulge and not solely due to bulge prominence, giving information to the evolutionary history of the galaxy. It has been shown that classical bulges, which appear more like ellipticals, have a global red color while pseudobulges, which are flattened and disk-like, are found in globally blue galaxies, regardless of the disk-to-bulge ratio. In addition, the type of bulge connects to other global structural parameters.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0973}
{"prompt": "Rephrase the abstract of an article with title 'Trigonometric parallaxes of high velocity halo white dwarf candidates'.\n  The status of 38 halo white dwarf candidates identified by Oppenheimer et al.\n(2001) has been intensively discussed by various authors. In analyses\nundertaken to date, trigonometric parallaxes are crucial missing data. Distance\nmeasurements are mandatory to kinematically segregate halo object from disk\nobjects and hence enable a more reliable estimate of the local density of halo\ndark matter residing in such objects.\n  We present trigonometric parallax measurements for 15 candidate halo white\ndwarfs (WDs) selected from the Oppenheimer et al. (2001) list. We observed the\nstars using the ESO 1.56-m Danish Telescope and ESO 2.2-m telescope from August\n2001 to July 2004. Parallaxes with accuracies of 1--2 mas were determined\nyielding relative errors on distances of $\\sim5$% for 6 objects, $\\sim12$% for\n3 objects, and $\\sim20$% for two more objects. Four stars appear to be too\ndistant (probably farther than 100 pc) to have measurable parallaxes in our\nobservations. Distances, absolute magnitudes and revised space velocities were\nderived for the 15 halo WDs from the Oppenheimer et al. (2001) list. Halo\nmembership is confirmed unambiguously for 6 objects while 5 objects may be\nthick disk members and 4 objects are too distant to draw any conclusion based\nsolely on kinematics. Comparing our trigonometric parallaxes with photometric\nparallaxes used in previous work reveals an overestimation of distance as\nderived from photometric techniques. This new data set can be used to revise\nthe halo white dwarf space density, and that analysis will be presented in a\nsubsequent publication.\n\n", "human_text": "  The status of 38 halo white dwarf candidates identified by Oppenheimer et al.\n(2001) has been intensively discussed by various authors. In analyses\nundertaken to date, trigonometric parallaxes are crucial missing data. Distance\nmeasurements are mandatory to kinematically segregate halo object from disk\nobjects and hence enable a more reliable estimate of the local density of halo\ndark matter residing in such objects.\n  We present trigonometric parallax measurements for 15 candidate halo white\ndwarfs (WDs) selected from the Oppenheimer et al. (2001) list. We observed the\nstars using the ESO 1.56-m Danish Telescope and ESO 2.2-m telescope from August\n2001 to July 2004. Parallaxes with accuracies of 1--2 mas were determined\nyielding relative errors on distances of $\\sim5$% for 6 objects, $\\sim12$% for\n3 objects, and $\\sim20$% for two more objects. Four stars appear to be too\ndistant (probably farther than 100 pc) to have measurable parallaxes in our\nobservations. Distances, absolute magnitudes and revised space velocities were\nderived for the 15 halo WDs from the Oppenheimer et al. (2001) list. Halo\nmembership is confirmed unambiguously for 6 objects while 5 objects may be\nthick disk members and 4 objects are too distant to draw any conclusion based\nsolely on kinematics. Comparing our trigonometric parallaxes with photometric\nparallaxes used in previous work reveals an overestimation of distance as\nderived from photometric techniques. This new data set can be used to revise\nthe halo white dwarf space density, and that analysis will be presented in a\nsubsequent publication.\n", "machine_text": "\nWe present a collection of trigonometric parallax measurements for 15 halo white dwarf (WD) candidates from Oppenheimer et al. (2001). The stars were observed from August 2001 to July 2004 using the ESO 1.56-m Danish Telescope and ESO 2.2-m telescope. Parallaxes for 6 objects had a relative error of ~5%, 3 objects had a relative error of ~12%, and two more objects had a relative error of ~20%. Our data set provides reliable estimates of distance, absolute magnitude and revised space velocities for the 15 halo WDs. It was determined that 6 of them are unambiguous halo members, 5 may be thick disk members, and 4 were too distant to draw any conclusions. Furthermore, our trigonometric parallaxes were compared to photometric parallaxes used in previous studies and showed an overestimation of distances with photometric techniques. This information can be used to revise the halo white dwarf space density, and the analysis of this will be presented in a future paper.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.0355}
{"prompt": "Rephrase the abstract of an article with title 'SIM PlanetQuest Key Project Precursor Observations to Detect Gas Giant\n  Planets Around Young Stars'.\n  We present a review of precursor observing programs for the SIM PlanetQuest\nKey project devoted to detecting Jupiter mass planets around young stars. In\norder to ensure that the stars in the sample are free of various sources of\nastrometric noise that might impede the detection of planets, we have initiated\nprograms to collect photometry, high contrast images, interferometric data and\nradial velocities for stars in both the Northern and Southern hemispheres. We\nhave completed a high contrast imaging survey of target stars in Taurus and the\nPleiades and found no definitive common proper motion companions within one\narcsecond (140 AU) of the SIM targets. Our radial velocity surveys have shown\nthat many of the target stars in Sco-Cen are fast rotators and a few stars in\nTaurus and the Pleiades may have sub-stellar companions. Interferometric data\nof a few stars in Taurus show no signs of stellar or sub-stellar companions\nwith separations of <5 mas. The photometric survey suggests that approximately\nhalf of the stars initially selected for this program are variable to a degree\n(1 sigma>0.1 mag) that would degrade the astrometric accuracy achievable for\nthat star. While the precursor programs are still a work in progress, we\nprovide a comprehensive list of all targets ranked according to their viability\nas a result of the observations taken to date. By far, the observable that\nmoves the most targets from the SIM-YSO program is photometric variability.\n\n", "human_text": "  We present a review of precursor observing programs for the SIM PlanetQuest\nKey project devoted to detecting Jupiter mass planets around young stars. In\norder to ensure that the stars in the sample are free of various sources of\nastrometric noise that might impede the detection of planets, we have initiated\nprograms to collect photometry, high contrast images, interferometric data and\nradial velocities for stars in both the Northern and Southern hemispheres. We\nhave completed a high contrast imaging survey of target stars in Taurus and the\nPleiades and found no definitive common proper motion companions within one\narcsecond (140 AU) of the SIM targets. Our radial velocity surveys have shown\nthat many of the target stars in Sco-Cen are fast rotators and a few stars in\nTaurus and the Pleiades may have sub-stellar companions. Interferometric data\nof a few stars in Taurus show no signs of stellar or sub-stellar companions\nwith separations of <5 mas. The photometric survey suggests that approximately\nhalf of the stars initially selected for this program are variable to a degree\n(1 sigma>0.1 mag) that would degrade the astrometric accuracy achievable for\nthat star. While the precursor programs are still a work in progress, we\nprovide a comprehensive list of all targets ranked according to their viability\nas a result of the observations taken to date. By far, the observable that\nmoves the most targets from the SIM-YSO program is photometric variability.\n", "machine_text": "\nThis paper reviews the observational programs carried out as part of the SIM PlanetQuest Key project aimed at locating giant gas planets around young stars. TO reduce potential sources of astrometric noise that could hinder planet detection, studies involving photometry, high contrast imaging, interferometry and radial velocity have been conducted on stars in both the northern and southern hemispheres. High contrast imaging in Taurus and the Pleiades failed to detect any potential companions within a 140 AU radius of the SIM targets, while radial velocity surveys revealed a few possible sub-stellar companions in Taurus and the Pleiades. Imaging of certain stars in Taurus with interferometry showed no signs of stellar or sub-stellar companions closer than 5 mas. The photometric survey also estimated that about half of the initially chosen stars possess a degree of variability (with 1 sigma>0.1 mag) that would impede the requisite precision for detecting astrometry. We present a list of all targets assessed according to the outcomes of the current observational program, demonstrating that variability to any considerable degree proves to be the leading factor in eliminating stars from the SIM-YSO program.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.3687}
{"prompt": "Rephrase the abstract of an article with title 'Absolute Calibration and Characterization of the Multiband Imaging\n  Photometer for Spitzer. II. 70 micron Imaging'.\n  The absolute calibration and characterization of the Multiband Imaging\nPhotometer for Spitzer (MIPS) 70 micron coarse- and fine-scale imaging modes\nare presented based on over 2.5 years of observations. Accurate photometry\n(especially for faint sources) requires two simple processing steps beyond the\nstandard data reduction to remove long-term detector transients. Point spread\nfunction (PSF) fitting photometry is found to give more accurate flux densities\nthan aperture photometry. Based on the PSF fitting photometry, the calibration\nfactor shows no strong trend with flux density, background, spectral type,\nexposure time, or time since anneals. The coarse-scale calibration sample\nincludes observations of stars with flux densities from 22 mJy to 17 Jy, on\nbackgrounds from 4 to 26 MJy sr^-1, and with spectral types from B to M. The\ncoarse-scale calibration is 702 +/- 35 MJy sr^-1 MIPS70^-1 (5% uncertainty) and\nis based on measurements of 66 stars. The instrumental units of the MIPS 70\nmicron coarse- and fine-scale imaging modes are called MIPS70 and MIPS70F,\nrespectively. The photometric repeatability is calculated to be 4.5% from two\nstars measured during every MIPS campaign and includes variations on all time\nscales probed. The preliminary fine-scale calibration factor is 2894 +/- 294\nMJy sr^-1 MIPS70F^-1 (10% uncertainty) based on 10 stars. The uncertainty in\nthe coarse- and fine-scale calibration factors are dominated by the 4.5%\nphotometric repeatability and the small sample size, respectively. The 5-sigma,\n500 s sensitivity of the coarse-scale observations is 6-8 mJy. This work shows\nthat the MIPS 70 micron array produces accurate, well calibrated photometry and\nvalidates the MIPS 70 micron operating strategy, especially the use of frequent\nstimulator flashes to track the changing responsivities of the Ge:Ga detectors.\n\n", "human_text": "  The absolute calibration and characterization of the Multiband Imaging\nPhotometer for Spitzer (MIPS) 70 micron coarse- and fine-scale imaging modes\nare presented based on over 2.5 years of observations. Accurate photometry\n(especially for faint sources) requires two simple processing steps beyond the\nstandard data reduction to remove long-term detector transients. Point spread\nfunction (PSF) fitting photometry is found to give more accurate flux densities\nthan aperture photometry. Based on the PSF fitting photometry, the calibration\nfactor shows no strong trend with flux density, background, spectral type,\nexposure time, or time since anneals. The coarse-scale calibration sample\nincludes observations of stars with flux densities from 22 mJy to 17 Jy, on\nbackgrounds from 4 to 26 MJy sr^-1, and with spectral types from B to M. The\ncoarse-scale calibration is 702 +/- 35 MJy sr^-1 MIPS70^-1 (5% uncertainty) and\nis based on measurements of 66 stars. The instrumental units of the MIPS 70\nmicron coarse- and fine-scale imaging modes are called MIPS70 and MIPS70F,\nrespectively. The photometric repeatability is calculated to be 4.5% from two\nstars measured during every MIPS campaign and includes variations on all time\nscales probed. The preliminary fine-scale calibration factor is 2894 +/- 294\nMJy sr^-1 MIPS70F^-1 (10% uncertainty) based on 10 stars. The uncertainty in\nthe coarse- and fine-scale calibration factors are dominated by the 4.5%\nphotometric repeatability and the small sample size, respectively. The 5-sigma,\n500 s sensitivity of the coarse-scale observations is 6-8 mJy. This work shows\nthat the MIPS 70 micron array produces accurate, well calibrated photometry and\nvalidates the MIPS 70 micron operating strategy, especially the use of frequent\nstimulator flashes to track the changing responsivities of the Ge:Ga detectors.\n", "machine_text": "This work presents the absolute calibration and characterization of the Multiband Imaging Photometer for Spitzer (MIPS) 70 micron modes, based on over two and a half years of observation. In order to attain precise photometry (particularly for faint sources), two additional steps after the standard data reduction are required to remove long-term detector fluctuations. Point spread function fitting is discovered to provide more accurate flux densities than aperture photometry. The calibration amounts to 702 +/- 35 MJy sr^-1 MIPS70^-1 (5% variation), 66 stars used for assessment. The photometric consistency is established to be 4.5% from two stars throughout every MIPS mission and includes fluctuation on every time scale studied. The preliminary fine-scale calibration factor is 2894 +/- 294 MJy sr^-1 MIPS70F^-1 (10% uncertainty) and is dependent on ten stars. The uncertainty in the coarse- and fine-scale calibration factors are mainly due to the 4.5% photometric repeatability and the small sample size, respectively. The 5-sigma, 500s sensitivity of the coarse-scale observations is 6-8 mJy. The results here effectively display the accuracy of MIPS 70 micron measurements and affirm the MIPS 70 micron functioning strategy, preincluding the use of regular stimulator flashes to measure the fluctuating responsivities of the Ge:Ga detectors.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 704.2196}
{"prompt": "Rephrase the abstract of an article with title 'The SWIRE-VVDS-CFHTLS surveys: stellar mass assembly over the last 10\n  Gyears. Evidence for a major build up of the red sequence between z=2 and z=1'.\n  (abridged abstract) We present an analysis of the stellar mass growth over\nthe last 10 Gyrs using a large 3.6$\\mu$ selected sample. We split our sample\ninto active (blue) and quiescent (red) galaxies. Our measurements of the K-LFs\nand LD evolution support the idea that a large fraction of galaxies is already\nassembled at $z\\sim 1.2$. Based on the analysis of the evolution of the stellar\nmass-to-light ratio (in K-band) for the spectroscopic sub-sample, we derive the\nstellar mass density for the entire sample. We find that the global evolution\nof the stellar mass density is well reproduced by the star formation rate\nderived from UV dust corrected measurements. Over the last 8Gyrs, we observe\nthat the stellar mass density of the active population remains approximately\nconstant while it gradually increases for the quiescent population over the\nsame timescale. As a consequence, the growth of the stellar mass in the\nquiescent population must be due to the shutoff of star formation in active\ngalaxies that migrate into the quiescent population. From $z=2$ to $z=1.2$, we\nobserve a major build-up of the quiescent population with an increase by a\nfactor of 10 in stellar mass, suggesting that we are observing the epoch when\nan increasing fraction of galaxies are ending their star formation activity and\nstart to build up the red sequence.\n\n", "human_text": "  (abridged abstract) We present an analysis of the stellar mass growth over\nthe last 10 Gyrs using a large 3.6$\\mu$ selected sample. We split our sample\ninto active (blue) and quiescent (red) galaxies. Our measurements of the K-LFs\nand LD evolution support the idea that a large fraction of galaxies is already\nassembled at $z\\sim 1.2$. Based on the analysis of the evolution of the stellar\nmass-to-light ratio (in K-band) for the spectroscopic sub-sample, we derive the\nstellar mass density for the entire sample. We find that the global evolution\nof the stellar mass density is well reproduced by the star formation rate\nderived from UV dust corrected measurements. Over the last 8Gyrs, we observe\nthat the stellar mass density of the active population remains approximately\nconstant while it gradually increases for the quiescent population over the\nsame timescale. As a consequence, the growth of the stellar mass in the\nquiescent population must be due to the shutoff of star formation in active\ngalaxies that migrate into the quiescent population. From $z=2$ to $z=1.2$, we\nobserve a major build-up of the quiescent population with an increase by a\nfactor of 10 in stellar mass, suggesting that we are observing the epoch when\nan increasing fraction of galaxies are ending their star formation activity and\nstart to build up the red sequence.\n", "machine_text": "\nWe present an investigation of the mass assembly of stars observed over the last 10 billion years utilizing a vast 3.6-$\\mu$m selected sample. After dividing our sample into active (blue) and passive (red) galaxies, our measurements of K-LFs and LD evolution support the notion that a large proportion of galaxies had already assembled by $z \\sim 1.2$. Utilizing the stellar mass-to-light proportion (in K-band) of our spectroscopic subsample, the total stellar mass of the sample is calculated. Results demonstrate that the global development of this mass is mostly comparable to the star formation rate concluded from UV dust corrected measurements. In addition, the active population exhibits a consistent stellar mass density over the 8 billion year observation period, whilst the quiescent population steadily increases. These outcomes suggest that the growth of the stellar mass in the passive population is a result of the halting of star formation in active galaxies that have shifted to the inactive population. From $z=2$ to $z=1.2$, there is a strong build-up in the quiescent population, with an observed increase by a factor of 10, implying that this epoch had an elevated number of galaxies concluding their star formation activity and forming the red sequence.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.2438}
{"prompt": "Rephrase the abstract of an article with title 'Spectroscopy of moderately high-redshift RCS-1 clusters'.\n  We present spectroscopic observations of 11 moderately high-redshift (z~0.7-\n1.0) clusters from the first Red-Sequence Cluster Survey (RCS-1). We find\nexcellent agreement between the red-sequence estimated redshift and the\nspectroscopic redshift, with a scatter of 10% at z>0.7. At the high-redshift\nend (z>~0.9) of the sample, we find two of the systems selected are projections\nof pairs of comparably rich systems, with red-sequences too close to\ndiscriminate in (R-z') colour. In one of these systems, the two components are\nclose enough to be physically associated. For a subsample of clusters with\nsufficient spectroscopic members, we examine the correlation between B_gcR\n(optical richness) and the dynamical mass inferred from the velocity\ndispersion. We find these measurements to be compatible, within the relatively\nlarge uncertainties, with the correlation established at lower redshift for the\nX-ray selected CNOC1 clusters and also for a lower redshift sample of RCS-1\nclusters. Confirmation of this and calibration of the scatter in the relation\nwill require larger samples of clusters at these and higher redshifts.\n[abridged]\n\n", "human_text": "  We present spectroscopic observations of 11 moderately high-redshift (z~0.7-\n1.0) clusters from the first Red-Sequence Cluster Survey (RCS-1). We find\nexcellent agreement between the red-sequence estimated redshift and the\nspectroscopic redshift, with a scatter of 10% at z>0.7. At the high-redshift\nend (z>~0.9) of the sample, we find two of the systems selected are projections\nof pairs of comparably rich systems, with red-sequences too close to\ndiscriminate in (R-z') colour. In one of these systems, the two components are\nclose enough to be physically associated. For a subsample of clusters with\nsufficient spectroscopic members, we examine the correlation between B_gcR\n(optical richness) and the dynamical mass inferred from the velocity\ndispersion. We find these measurements to be compatible, within the relatively\nlarge uncertainties, with the correlation established at lower redshift for the\nX-ray selected CNOC1 clusters and also for a lower redshift sample of RCS-1\nclusters. Confirmation of this and calibration of the scatter in the relation\nwill require larger samples of clusters at these and higher redshifts.\n[abridged]\n", "machine_text": "\nWe conducted spectroscopic observations on 11 clusters in the Red-Sequence Cluster Survey at moderate redshifts (z=0.7-1.0). We found a close correspondence between the estimated redshifts based on the color of the red-sequence, and the spectroscopically-obtained redshifts, with only 10% scatter. In two of the clusters, we identified pairs of comparable clusters projecting close enough to appear as a single object from the survey. When examining a subset of clusters with sufficient spectroscopic members, the correlation between optical richness and dynamical mass was consistent with what is seen for clusters observed at lower redshifts, albeit with large uncertainties. Further study with larger datasets is needed to confirm and refine this correlation.", "model": "text-davinci-003", "source": "arxiv", "source_ID": 705.0782}
