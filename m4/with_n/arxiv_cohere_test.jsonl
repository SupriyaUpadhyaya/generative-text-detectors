{"prompt": "Generate an abstract for work with title: Faithful Effective-One-Body waveforms of small-mass-ratio coalescing\n  black-hole binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2519, "human_text": "  We address the problem of constructing high-accuracy, faithful analytic\nwaveforms describing the gravitational wave signal emitted by inspiralling and\ncoalescing binary black holes. We work within the Effective-One-Body (EOB)\nframework and propose a methodology for improving the current\n(waveform)implementations of this framework based on understanding, element by\nelement, the physics behind each feature of the waveform, and on systematically\ncomparing various EOB-based waveforms with ``exact'' waveforms obtained by\nnumerical relativity approaches. The present paper focuses on small-mass-ratio\nnon-spinning binary systems, which can be conveniently studied by\nRegge-Wheeler-Zerilli-type methods. Our results include: (i) a resummed,\n3PN-accurate description of the inspiral waveform, (ii) a better description of\nradiation reaction during the plunge, (iii) a refined analytic expression for\nthe plunge waveform, (iv) an improved treatment of the matching between the\nplunge and ring-down waveforms. This improved implementation of the EOB\napproach allows us to construct complete analytic waveforms which exhibit a\nremarkable agreement with the ``exact'' ones in modulus, frequency and phase.\nIn particular, the analytic and numerical waveforms stay in phase, during the\nwhole process, within $\\pm 1.1 %$ of a cycle. We expect that the extension of\nour methodology to the comparable-mass case will be able to generate comparably\naccurate analytic waveforms of direct use for the ground-based network of\ninterferometric detectors of gravitational waves.\n", "machine_text": "\nWe study the effects of small-mass-ratio on the evolution of coalescing black-hole binaries, by means of numerical-relativity simulations, and in the limit of strong gravitational interactions between the black holes and the host galaxies. For these galaxies we consider both spherically symmetric and axi-symmetric potential fields. We find that the merger process is generally faster for black-hole binaries with small mass ratios, and that this speed-up is more pronounced for binaries evolving in axi-symmetric galaxies. In the case of spherically symmetric galaxies, the typical lifetime of a small-mass-ratio binary is longer than that of a large-mass-ratio binary, but the evolution is more complex, with more frequent exchange of energy with the host galaxy, and hence more opportunities for the transfer of mass from the binary to the galaxy. We also find that in all cases the energy and angular momentum of the system are preserved, with the possible exception of the initial stages of the evolution, where the system may receive or lose large amounts of energy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pairing based cooling of Fermi gases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0271, "human_text": "  We propose a pairing-based method for cooling an atomic Fermi gas. A three\ncomponent (labels 1, 2, 3) mixture of Fermions is considered where the\ncomponents 1 and 2 interact and, for instance, form pairs whereas the component\n3 is in the normal state. For cooling, the components 2 and 3 are coupled by an\nelectromagnetic field. Since the quasiparticle distributions in the paired and\nin the normal states are different, the coupling leads to cooling of the normal\nstate even when initially $T_{paired}\\geq T_{normal}$ (notation $T_S\\geq T_N$).\nThe cooling efficiency is given by the pairing energy and by the linewidth of\nthe coupling field. No superfluidity is required: any type of pairing, or other\nphenomenon that produces a suitable spectral density, is sufficient. In\nprinciple, the paired state could be cooled as well but this requires\n$T_N<T_S$. The method has a conceptual analogy to cooling based on\nsuperconductor -- normal metal (SN) tunneling junctions. Main differences arise\nfrom the exact momentum conservation in the case of the field-matter coupling\nvs. non-conservation of momentum in the solid state tunneling process.\nMoreover, the role of processes that relax the energy conservation requirement\nin the tunneling, e.g. thermal fluctuations of an external reservoir, is now\nplayed by the linewidth of the field. The proposed method should be\nexperimentally feasible due to its close connection to RF-spectroscopy of\nultracold gases which is already in use.\n", "machine_text": "\n\nWe consider a recently proposed method to cool atomic gases that does not require the atoms to be laser cooled or trapped. This method relies on the collective excitation of the atomic gas by a sequence of coherent light pulses, which is possible thanks to the giant photon absorption cross section and the narrow width of the electronic energy levels in atomic gases. In this work we study this cooling method in more detail, with the aim of understanding the fundamental physical mechanisms that determine its efficiency. In particular, we consider the role of the atomic interaction, which is an important and poorly understood quantity in atomic gases, and we show that it has a strong influence on the cooling rate. We also propose a simple method to estimate the cooling rate, based on a model that relates the temperature, the density and the interaction, which can be used to predict the cooling rate as a function of the frequency of the light pulses. Our results suggest that this cooling method is efficient for temperatures above a few Kelvin, provided that the frequency of the light pulses is large enough.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraints on the Abundance of Highly Ionized Proto-Cluster Regions\n  from the Absence of Large Voids in the Lyman Alpha Forest. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2584, "human_text": "  Energetic feedback processes during the formation of galaxy clusters may have\nheated and ionized a large fraction of the intergalactic gas in proto-cluster\nregions. When such a highly ionized hot ``super-bubble'' falls along the\nsightline to a background quasar, it would be seen as a large void, with little\nor no absorption, in the Lyman alpha forest. We examine the spectra of 137\nquasars in the Sloan Digital Sky Survey, to search for such voids, and find no\nclear evidence of their existence. The size distribution of voids in the range\n5-70 Angstrom (corresponding to physical sizes of approximately 3-35 comoving\nMpc/h) is consistent with the standard model for the Lyman alpha forest without\nadditional hot bubbles. We adapt a physical model for HII bubble growth during\ncosmological reionization (Furlanetto, Zaldarriaga and Hernquist 2004), to\ndescribe the expected size-distribution of hot super-bubbles at redshift around\nz = 3. This model incorporates the conjoining of bubbles around individual\nneighboring galaxies. Using the non-detection of voids, we find that models in\nwhich the volume filling factor of hot bubbles exceeds approximately 20 percent\nat z=3 can be ruled out, primarily because they overproduce the number of large\n(40-50 Angstrom) voids. We conclude that any pre-heating mechanism that\nexplains galaxy cluster observations must avoid heating the low-density gas in\nthe proto-cluster regions, either by operating relatively recently (z<3) or by\ndepositing entropy in the high-density regions.\n", "machine_text": "\nWe present a method to constrain the abundance of highly ionized regions in the early universe by analyzing the distribution of ionized hydrogen in the Ly\u03b1 forest. Our method is based on the fact that the ionization of hydrogen increases with the growth of the universe, while the density of ionized gas decreases with the expansion of the universe and the formation of voids. Therefore, the ratio of ionized gas to the total gas should increase with the growth of the universe. We find that the observed distribution of highly ionized gas in the Ly\u03b1 forest is consistent with the model in which the abundance of highly ionized gas is constant. This conclusion is supported by a detailed comparison between the predictions of our model and the observations. We also show that the observed abundance of highly ionized gas is inconsistent with the models in which the abundance of highly ionized gas increases or decreases with the growth of the universe. The main result of our work is a set of constraints on the abundance of highly ionized gas in the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Origin of the Dichotomy of Early-Type Galaxies: The Role of Dry\n  Mergers and AGN Feedback. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0932, "human_text": "  Using a semi-analytical model for galaxy formation, combined with a large\nN-body simulation, we investigate the origin of the dichotomy among early-type\ngalaxies. We find that boxy galaxies originate from mergers with a progenitor\nmass ratio $n < 2$ and with a combined cold gas mass fraction $F_{\\rm cold} <\n0.1$. Our model accurately reproduces the observed fraction of boxy systems as\na function of luminosity and halo mass, for both central galaxies and\nsatellites. After correcting for the stellar mass dependence, the properties of\nthe last major merger of early-type galaxies are independent of their halo\nmass. This provides theoretical support for the conjecture of Pasquali et al\n(2007) that the stellar mass of an early-type galaxy is the main parameter that\ngoverns its isophotal shape. We argue that the observed dichotomy of early-type\ngalaxies has a natural explanation within hierarchical structure formation, and\ndoes not require AGN feedback. Rather, we argue that it owes to the fact that\nmore massive systems (i) have more massive progenitors, (ii) assemble later,\nand (iii) have a larger fraction of early-type progenitors. Each of these three\ntrends causes the cold gas mass fraction of the progenitors of more massive\nearly-types to be lower, so that their last major merger was dryer. Finally,\nour model predicts that (i) less than 10 percent of all early-type galaxies\nform in major mergers that involve two early-type progenitors, (ii) more than\n95 percent of all boxy early-type galaxies with $M_* < 2 \\times 10^{10} h^{-1}\n\\Msun$ are satellite galaxies, and (iii) about 70 percent of all low mass\nearly-types do not form a supermassive black hole binary at their last major\nmerger. The latter may help to explain why low mass early-types have central\ncusps, while their massive counterparts have cores.\n", "machine_text": "\nWe present a physical model that accounts for the observed properties of early-type galaxies in a manner that is consistent with the predictions of the cold dark matter theory on large scales, but does not require ad-hoc fine-tuning. In our model, the galaxies are treated as overdense regions in an otherwise rarefied Universe, and are assumed to have formed through the collapse of perturbations that are either (i) small-scale fluctuations in a smooth distribution, (ii) droplets formed through the gravitational collapse of larger density peaks, or (iii) a combination of these two. We show that this model naturally explains why galaxies are found in groups, why they have the sizes they do, why they have the colours they do, and why they are evolving the way they do. In particular, the model predicts that galaxies should exhibit a strong correlation between their mass and their colour, with massive galaxies being mostly blue and small galaxies being mostly red. We show that this prediction is consistent with observations, provided that the galaxy colours are corrected for the age of the Universe. We also show that the model predicts that the large-scale structure of the galaxies should be formed through the gravitational collapse of large density peaks, rather than through the accretion of smaller galaxies. We discuss the implications of our model for the theories of galaxy formation and evolution, and for the interpretation of observations of galaxies and large-scale structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Discovery of 1000 km/s Outflows in Massive Post-starburst Galaxies\n  at z=0.6. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0527, "human_text": "  Numerical simulations suggest that active galactic nuclei (AGNs) play an\nimportant role in the formation of early-type galaxies by expelling gas and\ndust in powerful galactic winds and quenching star formation. However, the\nexistence of AGN feedback capable of halting galaxy-wide star formation has yet\nto be observationally confirmed. To investigate this question, we have obtained\nspectra of 14 post-starburst galaxies at z~0.6 to search for evidence of\ngalactic winds. In 10/14 galaxies we detect Mg II 2796,2803 absorption lines\nwhich are blueshifted by 490 - 2020 km/s with respect to the stars. The median\nblueshift is 1140 km/s. We hypothesize that the outflowing gas represents a\nfossil galactic wind launched near the peak of the galaxy's activity, a few 100\nMyr ago. The velocities we measure are intermediate between those of luminous\nstarbursts and broad absorption line quasars, which suggests that feedback from\nan AGN may have played a role in expelling cool gas and shutting down star\nformation.\n", "machine_text": "\nWe present observations of the unique galaxies Ghostly Perspective and Psychological, found in the COSMOS survey at z=0.6. These galaxies contain an excess of radio sources, indicating a large number of supernovae (SNe) in their past. Using the Australian Telescope, we have imaged the gas and stars in these galaxies, finding that the gas is moving at unprecedented speeds of up to 1000 km/s, much faster than the stars. We show that the gas in these galaxies has been ripped out of them by the SNe, and is moving so fast because the galaxies have been heavily distorted by their past star-formation and the infall of intergalactic gas. We calculate that the gas has been accelerated to these extreme speeds by a powerful torque, caused by the infall of gas and the strong local intergalactic magnetic field. This is the first time that such fast outflows have been discovered in massive galaxies at high-redshift. This discovery changes our understanding of how galaxies evolve at high-redshift, and provides a possible explanation for the unusual features of massive galaxies in the distant Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3986, "human_text": "  A generalized geometric method is developed for constructing exact solutions\nof gravitational field equations in Einstein theory and generalizations. First,\nwe apply the formalism of nonholonomic frame deformations (formally considered\nfor nonholonomic manifolds and Finsler spaces) when the gravitational field\nequations transform into systems of nonlinear partial differential equations\nwhich can be integrated in general form. The new classes of solutions are\ndefined by generic off-diagonal metrics depending on integration functions on\none, two and three (or three and four) variables if we consider four (or five)\ndimensional spacetimes. Second, we use a general scheme when one (two)\nparameter families of exact solutions are defined by any source-free solutions\nof Einstein's equations with one (two) Killing vector field(s). A successive\niteration procedure results in new classes of solutions characterized by an\ninfinite number of parameters for a non-Abelian group involving arbitrary\nfunctions on one variable. Five classes of exact off-diagonal solutions are\nconstructed in vacuum Einstein and in string gravity describing solitonic\npp-wave interactions. We explore possible physical consequences of such\nsolutions derived from primary Schwarzschild or pp-wave metrics.\n", "machine_text": "\nParametric nonholonomic frame transforms and exact solutions in gravity\n\nWe consider a class of exact solutions of the Einstein equations of motion in a curved background spacetime, in the form of a parametric nonholonomic frame transform. The main examples of this type of solution are the Landau, Kerr and Reissner-Nordstr\u00f6m metrics, which describe a uniform spinning disk, a spinning black hole, and a spherically symmetric object with a big bang type expansion, respectively. In the case of a spinning object the nonholonomicity is related to the geometric structure of the space-time. We show that in the case of a Kerr or Reissner-Nordstr\u00f6m metric the nonholonomicity is of a purely dynamical origin, and is related to the Killing generator of the symmetry group of the background space-time. As an application, we consider the simplest case of a scalar particle moving on a Kerr background. We show that the corresponding motion is a completely symmetric and coordinate independent solution, which describes a uniformly accelerated particle with a relativistic velocity increase. We also show that this solution has a simple geometric structure, and discuss a possible physical interpretation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strategies for the Design of a Slide-o-Cam Transmission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1036, "human_text": "  The optimization of the pressure angle in a cam-follower transmission is\nreported in this paper. This transmission is based on Slide-o-Cam, a cam\nmechanism with multiple rollers mounted on a common translating follower. The\ndesign of Slide-o-Cam, a transmission intended to produce a sliding motion from\na turning drive, or vice versa, was reported elsewhere. This transmission\nprovides pure-rolling motion, thereby reducing the friction of rack-and-pinions\nand linear drives. The pressure angle is a suitable performance index for this\ntransmission because it determines the amount of force transmitted to the load\nvs. that transmitted to the machine frame. Two alternative design strategies\nare studied, namely, (i) increase the number of lobes on each cam or (ii)\nincrease the number of cams. This device is intended to replace the current\nball-screws in Orthoglide, a three-DOF parallel robot for the production of\ntranslational motions, currently under development at Ecole Centrale de Nantes\nfor machining applications.\n", "machine_text": "\n\nStrategies for the Design of a Slide-o-Cam Transmission\nThis paper presents the design and analysis of a transmission for a light-duty, off-highway vehicle. The transmission design is a simple, mechanical, automatic, four-wheel-drive, four-wheel-steer transmission. The vehicle will be used to navigate rough, uneven terrain and thus will be subjected to severe conditions. The design is based on the concept of a slide-o-cam, which is a device that converts linear motion into rotary motion. The slide-o-cam is a component of the transmission that is mounted on the input shaft. The slide-o-cam is designed to move axially along the input shaft, thereby providing the correct ratio between the input shaft and the output shaft. The transmission is designed to have a variable ratio between the input shaft and the output shaft, which will allow the vehicle to travel at different speeds. The transmission is designed to have a high ratio, which will allow the vehicle to travel at a high speed. The transmission is designed to have a low ratio, which will allow the vehicle to travel at a low speed. The transmission is designed to have a reverse ratio, which will allow the vehicle to travel in reverse. The transmission is designed to have a neutral ratio, which will allow the vehicle to be in neutral. The transmission is designed to have a four-wheel-drive ratio, which will allow the vehicle to be in four-wheel drive. The transmission is designed to have a four-wheel-steer ratio, which will allow the vehicle to be in four-wheel steer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer Observations of Transient, Extended Dust in Two Elliptical\n  Galaxies: New Evidence of Recent Feedback Energy Release in Galactic Cores. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.371, "human_text": "  Spitzer observations of extended dust in two optically normal elliptical\ngalaxies provide a new confirmation of buoyant feedback outflow in the hot gas\natmospheres around these galaxies. AGN feedback energy is required to prevent\nwholesale cooling and star formation in these group-centered galaxies. In NGC\n5044 we observe interstellar (presumably PAH) emission at 8 microns out to\nabout 5 kpc. Both NGC 5044 and 4636 have extended 70 microns emission from cold\ndust exceeding that expected from stellar mass loss. The sputtering lifetime of\nthis extended dust in the ~1keV interstellar gas, ~10^7 yrs, establishes the\ntime when the dust first entered the hot gas. Evidently the extended dust\noriginated in dusty disks or clouds, commonly observed in elliptical galaxy\ncores, that were disrupted, heated and buoyantly transported outward. The\nsurviving central dust in NGC 5044 and 4636 has been disrupted into many small\nfilaments. It is remarkable that the asymmetrically extended 8 micron emission\nin NGC 5044 is spatially coincident with Halpha+[NII] emission from warm gas. A\ncalculation shows that dust-assisted cooling in buoyant hot gas moving out from\nthe galactic core can cool within a few kpc in about ~10^7 yrs, explaining the\noptical line emission observed. The X-ray images of both galaxies are\ndisturbed. All timescales for transient activity - restoration of equilibrium\nand buoyant transport in the hot gas, dynamics of surviving dust fragments, and\ndust sputtering - are consistent with a central release of feedback energy in\nboth galaxies about 10^7 yrs ago.\n", "machine_text": "\n\nWe present observations of transient, extended dust in the nuclei of two elliptical galaxies (M106 and M31), obtained with the Spitzer Space Telescope as part of the Spitzer Infrared Extra-galactic Legacy Archive Survey. The dust clouds are detected in archival images from the Spitzer Deep Near-Infrared Extragalactic Survey, using a combination of thermal and Near-Infrared Camera (NIRCam) data. The dust clouds are absent in archival data from the Multiband Imaging Photometer for Spitzer (MIPS), which shows that they are not just out-of-focus clumps of dust in our own galaxy. The two galaxies are at similar redshifts (z ~ 1), but have different histories of accretion and feedback, with M106 having experienced several episodes of merging and M31 being more quiescent. The dust clouds are located in the cores of the galaxies, and have the appearance of discrete, non-rotating features that were perhaps released from molecular clouds and are now propagating through the galaxies. The M106 cloud is possibly a merger-driven event, while the M31 cloud is more consistent with a accretion-driven event. We discuss several mechanisms by which such clouds could be produced, and conclude that they are likely to be a manifestation of recent feedback energy release in the cores of galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HST/ACS Coronagraphic Observations of the Dust Surrounding HD 100546. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1507, "human_text": "  We present ACS/HST coronagraphic observations of HD 100546, a B9.5 star, 103\npc away from the sun, taken in the F435W, F606W, and F814W bands. Scattered\nlight is detected up to 14'' from the star. The observations are consistent\nwith the presence of an extended flattened nebula with the same inclination as\nthe inner disk. The well-known ``spiral arms'' are clearly observed and they\ntrail the rotating disk material. Weaker arms never before reported are also\nseen. The inter-arm space becomes brighter, but the structures become more\nneutral in color at longer wavelengths, which is not consistent with models\nthat assume that they are due to the effects of a warped disk. Along the major\ndisk axis, the colors of the scattered-light relative to the star are \\Delta\n(F435W-F606W) ~ 0.0--0.2 mags and \\Delta (F435W-F814W)~0.5--1 mags. To explain\nthese colors, we explore the role of asymmetric scattering, reddening, and\nlarge minimum sizes on ISM-like grains. We conclude each of these hypotheses by\nitself cannot explain the colors. The disk colors are similar to those derived\nfor Kuiper Belt objects, suggesting that the same processes responsible for\ntheir colors may be at work here. We argue that we are observing only the\ngeometrically thick, optically thin envelope of the disk, while the optically\nthick disk responsible for the far-IR emission is undetected. The observed\nspiral arms are then structures on this envelope. The colors indicate that the\nextended nebulosity is not a remnant of the infalling envelope but reprocessed\ndisk material.\n", "machine_text": "\n\nWe present the first coronagraphic images of the disk of dust surrounding the nearby star HD 100546. These images were obtained with the NASA/ESA Hubble Space Telescope's Advanced Camera for Surveys (ACS) and the High Resolution Imaging Spectrometer (HRIS), during the Hubble Deep Outer Planet Survey (HOPS) Programme. HD 100546 is a star similar to our Sun, but is located 17 light-years away from us. In 1995, it was discovered to have a disk of dust surrounding it, by astronomers using the Hubble Space Telescope. We have now imaged this dust disk with unprecedented resolution, and have discovered that it is much more complicated than astronomers had previously realised. In particular, we find that the disk has at least one ring-like feature, in addition to the central disk. We also find that the dust is not distributed evenly in the disk, but is instead clumped together in several places. Our results are consistent with the disk having been perturbed by the passage of a planet or planets, and provide a dramatic demonstration of the power of Hubble to study the disks of dust and gas surrounding stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: First CO J=6-5, 4-3 detections in local ULIRGs: the dense gas in Mrk231,\n  and its colling budget. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0811, "human_text": "  We report on detections of the high-excitation CO J=6-5, J=4-3 lines in\nMrk231, a prototypical Ultra Luminous Infrared Galaxy (ULIRG) and Seyfert 1\nQSO. These observations are combined with CO J=3-2, HCN J=4-3 (this work), and\nCO J=2-1, J=1-0, 13CO J=2-1, HCN J=1-0 measurements taken from the literature\nto provide better constraints on the properties of the molecular gas in an\nextreme starburst/QSO in the local Universe. We find that the CO J=4-3 and\nJ=6-5 transitions trace a different gas phase from that dominating the lower\nthree CO transitions, with n(H_2) ~ (1-3)x10^4 cm-3 and Tk ~ (40-70) K. This\nphase is responsible for the luminous HCN emission, and contains most of the H2\ngas mass of this galaxy. The total CO line cooling emanating from this dense\nphase is found similar to that of the [CII] line at 158 micron, suggesting a\nvery different thermal balance to that seen in lower IR-luminosity galaxies,\nand one likely dominated by dense photon-dominated regions. Our dense\n\"sampling\" of the CO rotational ladder and the HCN lines enables us to produce\nwell-constrained Spectral Line Energy Distributions (SLEDs) for the dense\nmolecular gas in Mrk231 and compare them to those of high redshift starbursts,\nmany of which have SLEDs that may be affected by strong lensing. Finally, we\nuse our local molecular line excitation template to assess the capabilities of\nfuture cm and mm/sub-mm arrays in detecting CO and HCN transitions in similar\nsystems throughout the local and distant universe.\n", "machine_text": "\n\nWe present the first CO J=6-5, 4-3 detections in two local ULIRGs: Mrk231 and Mrk650. These detections provide a critical benchmark for comparison with models of molecular cloud formation and evolution. We find that the derived molecular line luminosities are consistent with the CO-dark cloud model of Churchwell & 1996, if the molecular clouds are thermally-stratified with the CO-rich layer placed near the cloud's cold trap. The model also predicts that the CO luminosity should be proportional to the cloud's cooling budget, which is in turn proportional to the cloud's mass. We find that this prediction is consistent with the observed correlation between the molecular line luminosity and the total infrared luminosity, both in the optically-selected sample of clouds and in the subset of clouds that are particularly dense. This indicates that the cloud's mass is indeed proportional to its cooling budget, at least for the dense clouds in our sample. We find that the most dense clouds have a cooling budget that is about 2-4 times their mass, consistent with the predictions of the model. However, we also find that the least dense clouds have a cooling budget that is about 10 times their mass. This is a problem for the model, which predicts that the cooling budget should be proportional to the cloud's mass. We discuss several possible explanations for this discrepancy, including the possibility that the least dense clouds are not yet gravitationally stable. We find that the relative molecular line luminosity of the inner region compared to the outer region is consistent with the cloud being isothermal, at least for the cases where we have sufficient resolution to distinguish between the inner and outer regions. We discuss the implications of our results for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Accurate description of optical precursors and their relation to\n  weak-field coherent optical transients. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4238, "human_text": "  We study theoretically the propagation of a step-modulated optical field as\nit passes through a dispersive dielectric made up of a dilute collection of\noscillators characterized by a single narrow-band resonance. The propagated\nfield is given in terms of an integral of a Fourier type, which cannot be\nevaluated even for simple models of the dispersive dielectric. The fact that\nthe oscillators have a low number density (dilute medium) and have a\nnarrow-band resonance allows us to simplify the integrand. In this case, the\nintegral can be evaluated exactly, although it is not possible using this\nmethod to separate out the transient part of the propagated field known as\noptical precursors. We also use an asymptotic method (saddle-point method) to\nevaluate the integral. The contributions to the integral related to the\nsaddle-points of the integrand give rise to the optical precursors. We obtain\nanalytic expressions for the precursor fields and the domain over which the\nasymptotic method is valid. When combined to obtain the total transient field,\nwe find that the agreement between the solutions obtained by the asymptotic and\nthe exact methods is excellent. Our results demonstrate that precursors can\npersist for many nanoseconds and the chirp in the instantaneous frequency of\nthe precursors can manifest itself in beats in the transmitted intensity. Our\nwork strongly suggests that precursors have been observed in many previous\nexperiments.\n", "machine_text": "\n\nAccurate description of optical precursors and their relation to weak-field coherent optical transients\n\nWe present an accurate theoretical description of the optical precursor phenomenon. The description is based on a rigorous analysis of the dynamics of a laser pulse as it passes through a spatially extended pre- fibre. We show that a full description of the precursor requires an accurate solution of the optical wave equation in a spatially extended system. The solution is found by using the correct form of the relaxation of the pulse to the radiation pressure, which is shown to be different for different pulse shapes. We show that the correct relaxation of the pulse results in the evolution of a complex spatial pattern of field intensity, which contains information about the dynamics of the system. The description is confirmed by a comparison with previously published results, which used an approximate description of the precursor. We also present a simple and exact description of the relation between the precursor and the coherent transient that follows it.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum mechanical approach to decoherence and relaxation generated by\n  fluctuating environment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0194, "human_text": "  We consider an electrostatic qubit, interacting with a fluctuating charge of\nsingle electron transistor (SET) in the framework of exactly solvable model.\nThe SET plays a role of the fluctuating environment affecting the qubit's\nparameters in a controllable way. We derive the rate equations describing\ndynamics of the entire system for both weak and strong qubit-SET coupling.\nSolving these equation we obtain decoherence and relaxation rates of the qubit,\nas well as the spectral density of the fluctuating qubit's parameters. We found\nthat in the weak coupling regime the decoherence and relaxation rates are\ndirectly related to the spectral density taken at Rabi or at zero frequency,\ndepending on what a particular qubit's parameters is fluctuating. This relation\nholds also in the presence of weak back-action of the qubit on the fluctuating\nenvironment. In the case of strong back-action, such simple relationship no\nlonger holds, even if the qubit-SET coupling is small. It does not hold either\nin the strong-coupling regime, even in the absence of the back-action. In\naddition, we found that our model predicts localization of the qubit in the\nstrong-coupling regime, resembling that of the spin-boson model.\n", "machine_text": "\n\nWe investigate a system of two qubits in a fluctuating environment, as a model of decoherence and relaxation processes generated by thermal and other fluctuations in the environment. The model is approached from the framework of quantum mechanics, and the influence of the environment is accounted for by a Lindblad-like operator. The equations of motion of the qubits are solved analytically, and the exact form of the solution, including the effect of the environment, is derived. The special case of pure dephasing is discussed in some detail, and the results are compared with the predictions of the standard Boltzmann-like equation for relaxation in a fluctuating environment. Our results show that in certain parameter ranges the dynamics of the qubits can be effectively described by the standard Boltzmann equation, with a single relaxation rate. In other ranges, however, the relaxation dynamics is more complex, and can be well described by a combination of two or more relaxation rates, depending on the relation between the relevant time-scales of the qubit and the environment. We also discuss the implications of our results for a realistic model of decoherence and relaxation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quasi Equilibrium Grid Algorithm: geometric construction for model\n  reduction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2317, "human_text": "  The Method of Invariant Grid (MIG) is an iterative procedure for model\nreduction in chemical kinetics which is based on the notion of Slow Invariant\nManifold (SIM) [1-4]. Important role, in that method, is played by the initial\ngrid which, once refined, gives a description of the invariant manifold: the\ninvariant grid. A convenient way to get a first approximation of the SIM is\ngiven by the Spectral Quasi Equilibrium Manifold (SQEM) [1-2]. In the present\npaper, a flexible numerical method to construct the discrete analog of a Quasi\nEquilibrium Manifold, in any dimension, is presented. That object is named\nQuasi Equilibrium Grid (QEG), while the procedure Quasi Equilibrium Grid\nAlgorithm. Extensions of the QEM notion are also suggested. The QEG is a\nnumerical tool which can be used to find a grid-based approximation for the\nlocus of minima of a convex function under some linear constraints. The method\nis validated by construction of one and two-dimensional grids for model\nhydrogen oxidation reaction.\n", "machine_text": "\n\nWe present a geometric construction of the quasi-equilibrium grid algorithm and use it to derive a simple analytical expression for the reduced potential function. The quasi-equilibrium grid algorithm is an efficient method for obtaining a approximate basis of the relaxed potential function in an iteratively motivated basis pursuit algorithm. We show that our construction can be used to derive a simple expression for the reduced potential function that is accurate close to the boundaries of the atoms and in the limit of a large number of atoms. The resulting algorithm is very simple and is shown to be capable of converging quickly to a good approximation of the reduced potential function. We also show how the geometric construction can be used to derive a simple formula for the best basis of the reduced potential function in the least squares sense. The simplicity of the formula allows one to easily control the bias of the approximation by changing the number of basis functions and the strength of the relaxing Potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Regular homogeneous T-models with vacuum dark fluid. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2368, "human_text": "  We present the class of regular homogeneous T-models with vacuum dark fluid,\nassociated with a variable cosmological term. The vacuum fluid is defined by\nthe symmetry of its stress-energy tensor, i.e., its invariance under Lorentz\nboosts in a distinguished spatial direction (p_j=-\\rho), which makes this fluid\nessentially anisotropic and allows its density to evolve. Typical features of\nhomogeneous regular T-models are: the existence of a Killing horizon; beginning\nof the cosmological evolution from a null bang at the horizon; the existence of\na regular static pre-bang region visible to cosmological observers; creation of\nmatter from anisotropic vacuum, accompanied by very rapid isotropization. We\nstudy in detail the spherically symmetric regular T-models on the basis of a\ngeneral exact solution for a mixture of the vacuum fluid and dustlike matter\nand apply it to give numerical estimates for a particular model which\nillustrates the ability of cosmological T-models to satisfy the observational\nconstraints.\n", "machine_text": "\nWe show that the construction of a regular homogeneous T-model with a dark fluid in the vacuum gives rise to a solution of Einstein's field equations with a cosmological constant, which is an exact solution with a constant ratio of the circumference of a circle to its radius, that is, a solution with a homogeneous and isotropic space-time. In this model the energy density of the dark fluid is equal to the cosmological constant. We show that the resulting space-time can be described by the regular homogeneous T-model with a dark fluid in the vacuum, that is, by the sum of the relativistic potion and the rest of the space-time. As a result, the cosmological constant appears as a dynamic variable, that is, as a function of the scale factor. The model has a local Lorentzian group, and therefore it is interpretable. The model can describe a space-time with a slowly varying cosmological constant, that is, with a slowly varying energy density of the dark fluid. The slowly varying energy density can be interpreted as a slowly varying cosmological constant or, in the framework of the standard model, as a slowly varying value of the effective action.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Retaining Black Holes with Very Large Recoil Velocities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1548, "human_text": "  Recent numerical simulations of binary black hole mergers show the\npossibility of producing very large recoil velocities (> 3000 km/s). Kicks of\nthis magnitude should be sufficient to eject the final black hole from\nvirtually any galactic potential. This result has been seen as a potential\ncontradiction with observations of supermassive black holes residing in the\ncenters of most galaxies in the local universe. Using an extremely simplified\nmerger tree model, we show that, even in the limit of very large ejection\nprobability, after a small number of merger generations there should still be\nan appreciable fraction (>50%) of galaxies with supermassive black holes today.\nWe go on to argue that the inclusion of more realistic physics ingredients in\nthe merger model should systematically increase this retention fraction,\nhelping to resolve a potential conflict between theory and observation. Lastly,\nwe develop a more realistic Monte Carlo model to confirm the qualitative\narguments and estimate occupation fractions as a function of the central\ngalactic velocity dispersion.\n", "machine_text": "\n\nWe consider the problem of retaining a particle within a black hole, for a range of black hole spin and momenta. We show that the largest orbit that can be retained is limited by the size of the event horizon, and that for this orbit the particle's velocity must be comparable to the speed of light. We consider a range of possible physical mechanisms that might be used to drive a particle into such a large orbit, and find that only mechanisms that extract energy from the black hole, by increasing its entropy, can accomplish this. We then consider the specific case of a particle with very large recoil velocity, and find that such a particle can be retained in a wide range of black holes if the particle is scattered by a photon with a large energy. We show that there is a simple relationship between the black hole spin, the photon energy, and the probability that the particle will be scattered by the photon, and we present a qualitative explanation for this relationship. We also show that this mechanism for retaining a particle can be made to work for a wide range of initial conditions, without requiring fine tuning. We also show that the same mechanism can be used to produce a range of interesting effects, such as super-fast orbits, and the ejection of matter from a black hole.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A \"diamond-ring\" star: the unusual morphologic structure of a young\n  (multiple?) object. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3236, "human_text": "  We have observed IRAS06468-0325 obtaining optical and infrared images through\nIJHKs and L' filters, K-band low-resolution spectroscopy, together with\nmillimetre line observations of CO and CS. IRAS06468-0325 has a very unusual\nand enigmatic morphology with two components: a bright, close to point-like\nsource (the diamond) and a sharp-edge ring-like structure (the ring). The\nsource is not detected in the optical, at wavelengths shorter than the I-band.\nThe diamond is seen in all the imaging bands observed. The ring-like structure\nin IRAS06468-0325 is clearly seen in the I, J, H, and Ks. It is not detected in\nthe L'-band image. Infrared colours of the diamond are compatible with excess\ncircumstellar emission and a young stellar nature. A strongly non-gaussian and\nmoderately bright CO(1-0) and {13}CO(2-1) lines are seen towards\nIRAS06468-0325, at v_{LSR} of 30.5 km s{-1} (corresponding to a kinematic\ndistance of 3 kpc). Very weak C{18}O(2-1) and CS(2-1) lines were detected.\nK-band spectra of the diamond and of the ring are similar both in the slope of\nthe continuum and in the presence of lines supporting the idea that the ring is\nreflected light from the diamond. With the current data, a few different\nscenarios are possible to explain the morphology of this object. However, the\navailable data seem to favour that the morphology of IRAS06468-0325 correspond\nto a young stellar multiple system in a transient stage where a binary\nco-exists with a circumbinary disc, similar to the case of GG Tau. In this\ncase, the sharpness of the well-defined ring may be due to tidal truncation\nfrom dynamic interactions between components in a binary or multiple stellar\nsystem. IRAS06468-0325 may be an important rare case that illustrates a\nshort-lived stage of the process of binary or multiple star formation.\n", "machine_text": "\nA \"diamond-ring\" star: the unusual morphologic structure of a young (multiple?) object\n\nWe present observations of a young (ionic and gas) object, which we dub \"diamond-ring star,\" due to its unusual and very bright chromatic structure. We found it using the Wise star catalogue, which contains an all-sky survey at V=8. The unique thing about this object is that, unlike every other young stellar object, it does not show a point-like source, but a disk-like structure with many colours, and a structure that very much resembles the \" diamond-ring\" that some amateurs were lucky to observe during the total solar eclipse of August 21, 2017. The colours in our object are due to the fact that the light from the central star is First Order interference, while the light from the outskirts is Rayleigh scattering. We also found a companion object, which we initially dismissed as a background star, but it is also a young object, though much less bright and much more distant. It has a point-like structure, which could be a single star or a binary, and it is also surrounded by a disk-like structure with many colours, which could be an evolved version of the \"diamond-ring\" structure. We discuss the nature of these objects, and the possibility that the bright object may be a young multiple object, possibly a triplet. We also discuss the possibility that the bright object is a disk around a very young (and thus very large) giant planet, which would explain its unusual nature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Gene Duplication Models for Evolving Regulatory Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3808, "human_text": "  Background: Duplication of genes is important for evolution of molecular\nnetworks. Many authors have therefore considered gene duplication as a driving\nforce in shaping the topology of molecular networks. In particular it has been\nnoted that growth via duplication would act as an implicit way of preferential\nattachment, and thereby provide the observed broad degree distributions of\nmolecular networks.\n  Results: We extend current models of gene duplication and rewiring by\nincluding directions and the fact that molecular networks are not a result of\nunidirectional growth. We introduce upstream sites and downstream shapes to\nquantify potential links during duplication and rewiring. We find that this in\nitself generates the observed scaling of transcription factors for genome sites\nin procaryotes. The dynamical model can generate a scale-free degree\ndistribution, p(k)&prop; 1/k^&gamma;, with exponent &gamma;=1 in the\nnon-growing case, and with &gamma;>1 when the network is growing.\n  Conclusions: We find that duplication of genes followed by substantial\nrecombination of upstream regions could generate main features of genetic\nregulatory networks. Our steady state degree distribution is however to broad\nto be consistent with data, thereby suggesting that selective pruning acts as a\nmain additional constraint on duplicated genes. Our analysis shows that gene\nduplication can only be a main cause for the observed broad degree\ndistributions, if there is also substantial recombinations between upstream\nregions of genes.\n", "machine_text": "\n\nOn Gene Duplication Models for Evolving Regulatory Networks\n\nRegulatory networks control gene expression by regulating the binding of transcription factors to DNA. They are a central organizing principle in biology, and their dynamics are thought to be critical for the evolution of many complex traits. We study regulatory evolution by asking how gene duplications affect the architecture of regulatory networks. We focus on the evolution of gene expression levels, which are often highly heritable and have important fitness consequences. We develop a new model that enables us to study the dynamics of gene expression levels in the presence of gene duplications. We find that gene duplications have complex effects on gene expression levels, and in many cases can drive them to evolve in an optimizing direction. We show that this effect can be understood by considering both the direct effect of duplicating a gene, and the indirect effects of duplicating regulatory connections that influence the expression of the gene. Our model also makes specific predictions about the evolutionary dynamics of gene expression levels, which we test using a combination of computational and experimental methods. Our results suggest that these predictions could be used to distinguish between different gene duplication models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spheroidal and torsional modes of quasistatic shear oscillations in the\n  solid globe models of nuclear physics and pulsar astrophysics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1732, "human_text": "  The past three decades of investigation on nuclear physics and pulsar\nastrophysics have seen gradual recognition that elastodynamic approach to the\ncontinuum mechanics of nuclear matter provides proper account of macroscopic\nmotions of degenerate Fermi-matter constituting interior of the nuclear\nmaterial objects, the densest of all known today. This paper focuses on one\ntheoretical issue of this development which is concerned with oscillatory\nbehavior of a viscoelastic solid globe in the regime of quasistatic,\nforce-free, non-compressional oscillations less investigated in the literature\ncompared to oscillations in the regime of standing shear waves. We show that in\nthis case the problem of computing frequency and lifetime of spheroidal and\ntorsional modes of non-radial shear vibrations damped by viscosity can be\nunambiguously resolved by working from the energy balance equation and taking\nadvantage of the Rayleigh's variational method. The efficiency of this method\nis demonstrated by solid globe models of nuclear physics and pulsar\nastrophysics dealing with oscillations of a spherical mass of a viscoelastic\nFermi-solid with homogeneous and non-homogeneous profiles of the bulk density,\nthe shear modulus, and the shear viscosity.\n", "machine_text": "\nWe consider spheroidal and torsional modes of quasistatic shear oscillations in the solid globe models of nuclear physics and pulsar astrophysics. The problem is reduced to the study of the frequency-dependent shear modulus, C, in a spheroidal shell of uniform thickness. We show than nonzero values of C can be obtained only if the thickness of the shell is equal to a quarter of the wavelength of the corresponding spheroidal mode. This condition can be satisfied only for a limited set of frequencies corresponding to the so-called edge modes. We also found a simple expression for the frequency-dependent shear modulus in terms of the Laplace transform of the solution to the three-dimensional Love wave equation in a spheroidal shell. The resulting expression for C is very similar to the one obtained by transfer matrices method for the propagation of flexural waves in a thin-walled tube. Our result for the shear modulus also implies that the frequency-dependent bulk modulus in a solid sphere is equal to the shear modulus in a thin-walled tube with the same wall thickness and density.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Advantages of Four Dimensions for Composite Higgs Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.138, "human_text": "  We examine the relationship between little Higgs and 5d composite models with\nidentical symmetry structures. By performing an \"extreme\" deconstruction, one\ncan reduce any warped composite model to a little Higgs theory on a handful of\nsites. This allows us to use 4d intuition and the powerful constraints of\nnonlinear sigma models to elucidate obscure points in the original setup. We\nfind that the finiteness of the Higgs potential in 5d is due to the same\ncollective symmetry breaking as in the little Higgs. We compare a 4d and a 5d\nmodel with the same symmetry to the data. Reviewing the constraints on models\nrelated to the Minimal Composite Higgs (hep-ph/0412089), we see that it has\ndifficulty in producing acceptable values for S, T, and m_{top} simultaneously.\nBy contrast, in a global analysis, the Minimal Moose with custodial symmetry is\nviable in a large region of its parameter space and suffers from no numeric\ntunings. We conjecture that this result is generic for 4d and 5d models with\nidentical symmetries. The data will less strongly constrain the little theory.\n", "machine_text": "\nWe study the simplest non-trivial composite Higgs model which is an extension of the minimal supersymmetric extension of the Standard Model (MSSM) by two Higgs doublets and two sets of quark doublets. We show that such a model can be made ( Philosophically speaking ) consistent and stable against the automations of the corresponding supersymmetric model by introducing a new Higgs doublet, in addition to the two standard Higgs doublets, which is always hidden in the MSSM. This hidden Higgs doublet is the \" fourth dimension \" in our title, which does not mean a physical dimension but a \" technical \" dimension in the sense that it does not appear in the physical states and therefore does not lead to an expansion of the physical basis. We show that this model can be made stable and consistent by an appropriate choice of the three Higgs doublets and the quark doublets. We solve exactly the relevant MSSM for this model, and show that the only non-trivial MSSM scalar which is not a physical state is the one that is hidden by the construction. We show that the hidden MSSM scalar can be eliminated by a small modification of the standard MSSM so that the only MSSM scalars which are not physical states are the two standard Higgs doublets. We show that the model with the two Higgs doublets and the quark doublets is equivalent to the MSSM, except for the extra quark degrees of freedom which are \" eaten up \" by the MSSM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the dimension of subspaces with bounded Schmidt rank. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0705, "human_text": "  We consider the question of how large a subspace of a given bipartite quantum\nsystem can be when the subspace contains only highly entangled states. This is\nmotivated in part by results of Hayden et al., which show that in large d x\nd--dimensional systems there exist random subspaces of dimension almost d^2,\nall of whose states have entropy of entanglement at least log d - O(1). It is\nalso related to results due to Parthasarathy on the dimension of completely\nentangled subspaces, which have connections with the construction of\nunextendible product bases. Here we take as entanglement measure the Schmidt\nrank, and determine, for every pair of local dimensions dA and dB, and every r,\nthe largest dimension of a subspace consisting only of entangled states of\nSchmidt rank r or larger. This exact answer is a significant improvement on the\nbest bounds that can be obtained using random subspace techniques. We also\ndetermine the converse: the largest dimension of a subspace with an upper bound\non the Schmidt rank. Finally, we discuss the question of subspaces containing\nonly states with Schmidt equal to r.\n", "machine_text": "\n\nWe show that a natural dimension function for subspaces of Hilbert spaces is related to the Schmidt rank of the subspace. This leads to a simple characterization of subspaces with bounded Schmidt rank in terms of an inequality on inner products. We apply this characterization to the problem of finding an orthonormal basis for a subspace with bounded Schmidt rank.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On smooth foliations with Morse singularities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0164, "human_text": "  Let $M$ be a smooth manifold and let $\\F$ be a codimension one, $C^\\infty$\nfoliation on $M$, with isolated singularities of Morse type. The study and\nclassification of pairs $(M,\\F)$ is a challenging (and difficult) problem. In\nthis setting, a classical result due to Reeb \\cite{Reeb} states that a manifold\nadmitting a foliation with exactly two center-type singularities is a sphere.\nIn particular this is true if the foliation is given by a function. Along these\nlines a result due to Eells and Kuiper \\cite{Ku-Ee} classify manifolds having a\nreal-valued function admitting exactly three non-degenerate singular points. In\nthe present paper, we prove a generalization of the above mentioned results. To\ndo this, we first describe the possible arrangements of pairs of singularities\nand the corresponding codimension one invariant sets, and then we give an\nelimination procedure for suitable center-saddle and some saddle-saddle\nconfigurations (of consecutive indices). In the second part, we investigate if\nother classical results, such as Haefliger and Novikov (Compact Leaf) theorems,\nproved for regular foliations, still hold true in presence of singularities. At\nthis purpose, in the singular set, $Sing(\\F)$ of the foliation $\\F$, we\nconsider {\\em{weakly stable}} components, that we define as those components\nadmitting a neighborhood where all leaves are compact. If $Sing(\\F)$ admits\nonly weakly stable components, given by smoothly embedded curves diffeomorphic\nto $S^1$, we are able to extend Haefliger's theorem. Finally, the existence of\na closed curve, transverse to the foliation, leads us to state a Novikov-type\nresult.\n", "machine_text": "\n\nWe show that a certain class of smooth foliations of a 4-manifold admits a decomposition into smooth and corner pieces, and that each component of this decomposition is locally of the same genus. If the manifold is additionally equipped with a metric with negative Curvature, we show that the smooth pieces of the decomposition are parabolic submanifolds, and that the corner pieces are locally at most 3-codimensional. As an application, we give a description of the subspace of steady velocity fields of a certain class of self- degenerating manifolds in terms of a minimal model program.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Charmless Three-body Decays of B Mesons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1049, "human_text": "  Charmless 3-body decays of B mesons are studied in the framework of the\nfactorization approach. The nonresonant contributions arising from $B\\to\nP_1P_2$ transitions are evaluated using heavy meson chiral perturbation theory\n(HMChPT). The momentum dependence of nonresonant amplitudes is assumed to be in\nthe exponential form $e^{-\\alpha_{NR}} p_B\\cdot(p_i+p_j)}$ so that the HMChPT\nresults are recovered in the soft meson limit $p_i, p_j\\to 0$. In addition, we\nhave identified another large source of the nonresonant signal in the matrix\nelements of scalar densities, e.g. $<K\\bar K|\\bar ss|0>$, which can be\nconstrained from the decay $\\bar B^0\\to K_SK_SK_S$ or $B^-\\to K^-K_SK_S$. The\nintermediate vector meson contributions to 3-body decays are identified through\nthe vector current, while the scalar meson resonances are mainly associated\nwith the scalar density. Their effects are described in terms of the\nBreit-Wigner formalism. Our main results are: (i) All KKK modes are dominated\nby the nonresonant background. The predicted branching ratios of\n$K^+K^-K_{S(L)}$, $K^+K^-K^-$ and $K^-K_SK_S$ modes are consistent with the\ndata within errors. (ii) Although the penguin-dominated $B^0\\to K^+K^-K_{S}$\ndecay is subject to a potentially significant tree pollution, its effective\n$\\sin 2\\beta$ is very similar to that of the $K_SK_SK_S$ mode. However, direct\nCP asymmetry of the former, being of order -4%, is more prominent than the\nlatter. (iii) For $B\\to K\\pi\\pi$ decays, we found sizable nonresonant\ncontributions in $K^-\\pi^+\\pi^-$ and $\\bar K^0\\pi^+\\pi^-$ modes, in agreement\nwith the Belle measurements but larger than the BaBar result.\n", "machine_text": "\n\nWe present an analysis of charmless three-body decays of B mesons, where one of the two b quarks is reconstructed as a hadron in the final state. We use a sample of 3.9 million $B\\overline{B}$ pairs collected at the $\\Upsilon(4S)$ center of mass energy by the BaBar detector at the SLAC PEP-II $e^+e^-$ accelerator. The hadronized b quark is found to have hadronization times between 2 and 4.5 GeV/c^2, with a mean of 3.4 GeV/c^2. We also find a strong correlation between the hadronization time and the longitudinal polarization of the hadronized b quark. A fit to the data gives a hadronization mechanism with a quark-antiquark interaction strength of $\\lambda_{\\rm quark}^2\\sim 1.6\\, \\text{GeV}^2$. The charmless three-body decays of B mesons are sensitive to the hadronization mechanism and the final state interactions. We present an analysis of the $\\eta\\overline{\\eta}$ pair production in charmless three-body decays of B mesons. We find $\\langle \\eta\\overline{\\eta} \\rangle\\sim 10^{-9}$ pairs per $B\\overline{B}$ pair. We present a possible explanation for the small value of the $\\langle \\eta\\overline{\\eta} \\rangle$ in terms of the hadronization mechanism and the final state interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraining Models of Neutrino Mass and Neutrino Interactions with the\n  Planck Satellite. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3271, "human_text": "  In several classes of particle physics models -- ranging from the classical\nMajoron models, to the more recent scenarios of late neutrino masses or\nMass-Varying Neutrinos -- one or more of the neutrinos are postulated to couple\nto a new light scalar field. As a result of this coupling, neutrinos in the\nearly universe instead of streaming freely could form a self-coupled fluid,\nwith potentially observable signatures in the Cosmic Microwave Background and\nthe large scale structure of the universe. We re-examine the constraints on\nthis scenario from the presently available cosmological data and investigate\nthe sensitivity expected from the Planck satellite. In the first case, we find\nthat the sensitivity strongly depends on which piece of data is used. The SDSS\nMain sample data, combined with WMAP and other data, disfavors the scenario of\nthree coupled neutrinos at about the 3.5$\\sigma$ confidence level, but also\nfavors a high number of freely streaming neutrinos, with the best fit at 5.2.\nIf the matter power spectrum is instead taken from the SDSS Large Red Galaxy\nsample, best fit point has 2.5 freely streaming neutrinos, but the scenario\nwith three coupled neutrinos becomes allowed at $2\\sigma$. In contrast, Planck\nalone will exclude even a single self-coupled neutrino at the $4.2\\sigma$\nconfidence level, and will determine the total radiation at CMB epoch to\n$\\Delta N_\\nu^{eff} = ^{+0.5}_{-0.3}$ ($1\\sigma$ errors). We investigate the\nrobustness of this result with respect to the details of Planck's detector.\nThis sensitivity to neutrino free-streaming implies that Planck will be capable\nof probing a large region of the Mass-Varying Neutrino parameter space. Planck\nmay also be sensitive to a scale of neutrino mass generation as high as 1 TeV.\n", "machine_text": "\nWe present the results of a joint analysis of the constraints on neutrino mass and interactions from the latest Planck results, in the framework of a general purpose neutrino model that has previously been fitted to a large number of neutrino oscillation observations. We find that the Planck constraints can be accommodated within this model, given that the mass and the mixing angle are correlated in a way that is consistent with the absence of a phase transition in the early universe. The model that best fits the Planck constraints predicts a muon neutrino mass of 2.4 eV (68% confidence interval: 1.3-3.1 eV), in agreement with the current Planck determination of the neutrino mass. We show that the best-fit model contains two non-zero neutrino masses, with a maximum mass ratio of 1.5. We discuss the prospects of detecting such a mixture with current and future neutrino oscillation experiments, and place an upper bound on the probability of such a mixture for a range of neutrino mass values. We find that the best-fit model has a neutrino effective Dirac mass of 0.18 eV (68% confidence interval: 0.13-0.25 eV), consistent with the result from the Planck analysis of the galactic neutrino flux, and an order of magnitude larger than the Dirac mass of the down-type quark. We show that this order of magnitude difference in the Dirac masses is consistent with the idea that the active neutrinos are nearly massless, while the sterile neutrinos are massive, and that this is the simplest way to accommodate the Planck constraints.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Impact of Cosmic Rays on Population III Star Formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3634, "human_text": "  We explore the implications of a possible cosmic ray (CR) background\ngenerated during the first supernova explosions that end the brief lives of\nmassive Population III stars. We show that such a CR background could have\nsignificantly influenced the cooling and collapse of primordial gas clouds in\nminihaloes around redshifts of z ~ 15 - 20, provided the CR flux was sufficient\nto yield an ionization rate greater than about 10^-19 s^-1 near the center of\nthe minihalo. The presence of CRs with energies less than approximately 10^7 eV\nwould indirectly enhance the molecular cooling in these regions, and we\nestimate that the resulting lower temperatures in these minihaloes would yield\na characteristic stellar mass as low as ~ 10 M_sun. CRs have a less pronounced\neffect on the cooling and collapse of primordial gas clouds inside more massive\ndark matter haloes with virial masses greater than approximately 10^8 M_sun at\nthe later stages of cosmological structure formation around z ~ 10 - 15. In\nthese clouds, even without CR flux the molecular abundance is already\nsufficient to allow cooling to the floor set by the temperature of the cosmic\nmicrowave background.\n", "machine_text": "\nWe present a new mechanism for the formation of the first stars in the universe based on the ionization of hydrogen and helium by ambient ultraviolet (UV) radiation and the subsequent formation of extended electric fields in the interstellar medium. We show that the electric fields can reach values in excess of 100 kV/cm over interstellar clouds of gas and dust, sufficient to overcome the ionization balance and trigger a collapse to form stars. We explain that the ionization and field formation processes are driven by the continued cosmic ray (CR) flux from the early universe, which was recently shown to have been higher than previously thought. We evaluate the star formation rate (SFR) that can be triggered by the CR ionization mechanism, and show that it is consistent with the observations of the cosmic microwave background radiation and the observed SFRs in local galaxies. We further show that the distribution of the first stars is sensitive to the initial conditions in the ionization and field formation processes, and present a simple model for the distribution of the first stars. We explain that the CR ionization mechanism has important implications for the synthesis of heavy elements in the first stars, as it implies that the primordial gas was already partially ionized, and therefore the early stars had to form in environments with much higher metallicity than previously thought. We also discuss the possibility that the local galaxies were formed through a process of re-ionization of the gas clouds, triggered by supernova (SN) explosions in the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical properties of Er3+ doped alkali-chloro phosphate glasses for\n  optical amplifiers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0847, "human_text": "  A new class of Erbium doped glasses with compositions xNa2O - (60-x)PbCl2 -\n40P2O5 (x=0, 10, 20 and 30) were fabricated and characterized for optical\nproperties. Absorption spectra were analyzed for important Judd-Ofelt\nparameters from the integrated intensities of various Er3+ glass absorption\nbands. Photoluminescence (PL) and its decay behavior studies were carried out\nfor the transition 4I13/2 -> 4I15/2. A systematic correlation between the\nJudd-Ofelt parameter {omega}2 and the covalent nature of the glass matrix was\nobserved, due to increased role of bridging oxygens in the glass network. The\nPL broadness and life times of 4I13/2_> 4I15/2 transition were typically in the\nrange of 40-60nm and 2.13-2.5ms respectively. These glasses broadly showed high\ntransparency, high refractive index, shorter life times and, most importantly,\nthese glasses were found to be capable of being doped with larger\nconcentrations of Er3+ (up to 4 wt%). Increase of Er3+ concentration resulted\nin the increase in PL line-widths with no significant effect of concentration\nquenching, indicating that these glasses are suitable for optical\nfibre/waveguide amplifiers.\n", "machine_text": "\n\nWe investigated the optical properties of Er3+ doped alkali-chloro phosphate glasses for optical amplifiers. The glasses were synthesized by a conventional melt quenching method. The microstructure of the glasses was examined by transmission electron microscopy, and the presence of a high density of defects, such as vacancies and non-bridging oxygen holes, was observed. The Er3+ doped glasses were found to be thermally stable after melting and quenching. The glass transition temperature was determined to be 434 K, and the temperature corresponding to 10% of the glass decomposition was 632 K. The relative amount of glass decomposition was measured to be 5.0% after heating for 72 h at 632 K. The thermal expansion coefficient was found to be 85 \u00d7 10\u22127 K\u22121. The optical transmission spectra of the Er3+ doped glasses were measured, and the results showed that the glasses were transparent in the visible region and the near-infrared region. The measured glass refractive indices were 1.5972, 1.5958, 1.5955, and 1.5949 for glasses with Er3+ concentrations of 0.5, 1.0, 2.0, and 4.0 mole %, respectively. The absorption spectra of the glasses were measured and the results showed that the glasses exhibited a strong absorption band around 1.5 \u03bcm and a weak absorption band around 0.8 \u03bcm. The relative intensities of the 0.8 \u03bcm and 1.5 \u03bcm absorption bands were measured to be 1:1.5 for the glass with Er3+ concentration of 0.5 mole %, 1:2.5 for the glass with Er3+ concentration of 1.0 mole %, 1:3.5 for the glass with Er3+ concentration of 2.0 mole %, and 1:4.0 for the glass with Er3+ concentration of 4.0 mole %, respectively. The obtained results showed that the glasses were suitable for the preparation of optical amplifiers for optical communication systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Satellite Galaxies and Fossil Groups in the Millennium Simulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2009, "human_text": "  We use a semianalytic galaxy catalogue constructed from the Millennium\nSimulation to study the satellites of isolated galaxies in the LCDM cosmogony.\nThis sample (~80,000$ bright primaries, surrounded by ~178,000 satellites)\nallows the characterization, with minimal statistical uncertainty, of the\ndynamical properties of satellite/primary galaxy systems in a LCDM universe. We\nfind that, overall, the satellite population traces the dark matter rather\nwell: its spatial distribution and kinematics may be approximated by an NFW\nprofile with a mildly anisotropic velocity distribution. Their spatial\ndistribution is also mildly anisotropic, with a well-defined ``anti-Holmberg''\neffect that reflects the misalignment between the major axis and angular\nmomentum of the host halo. The isolation criteria for our primaries picks not\nonly galaxies in sparse environments, but also a number of primaries at the\ncentre of ''fossil'' groups. We find that the abundance and luminosity function\nof these unusual systems are in reasonable agreement with the few available\nobservational constraints. We recover the expected L_{host} \\sigma_{sat}^3\nrelation for LCDM models for truly-isolated primaries. Less strict primary\nselection, however, leads to substantial modification of the scaling relation.\nOur analysis also highlights a number of difficulties afflicting studies that\nrely on blind stacking of satellite systems to constrain the mean halo mass of\nthe primary galaxies.\n", "machine_text": "\n\nWe present the first study of satellite galaxies and fossil groups in a realistic galaxy formation simulation. We use the Millennium Simulation, a large scale cosmological hydrodynamical simulation including both dark matter and gas, with a resolution of $44\\,$hMpc, which can be used to study the formation history of galaxies up to redshift $z\\sim 1$. In our analysis we identify satellite galaxies using three different methods, and use the galaxy membership probabilities to derive the satellite metallicity and star formation density distribution. We find that the satellite galaxy population as a whole is very metal-poor and displays a star formation density excess of $\\sim 30\\%$ with respect to the main galaxy population, but the satellites of individual galaxies show much larger differences, up to an excess of $\\sim 300\\%$. We find that the stellar mass of the largest satellite in a system is proportional to the stellar mass of the main galaxy, and we show this relation to be consistent with the prediction of the Barred-iminicity theory of galaxy formation. We also analyse the formation of fossil groups, and find that the probability of a group of galaxies to be fossil is inversely proportional to the group mass. We discuss our results in the context of theories of galaxy formation and the formation history of the Local Volume Group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lensing, reddening and extinction effects of MgII absorbers from z=0.4\n  to z=2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0898, "human_text": "  Using a sample of almost 7000 strong MgII absorbers with 0.4 < z < 2.2\ndetected in the SDSS DR4 dataset, we investigate the gravitational lensing and\ndust extinction effects they induce on background quasars. After carefully\nquantifying several selection biases, we isolate the reddening effects as a\nfunction of redshift and absorber rest equivalent width, W_0. We find the\namount of dust to increase with cosmic time as (1+z)^(-1.1 +/- 0.4), following\nthe evolution of cosmic star density or integrated star formation rate. We\nmeasure the reddening effects over a factor 30 in E(B-V) and we find the dust\ncolumn density to be proportional to W_0^(1.9 +/- 0.2), which provides an\nimportant scaling for theoretical modeling of metal absorbers. We also measure\nthe dust-to-metals ratio and find it similar to that of the Milky Way.\n  In contrast to previous studies, we do not detect any gravitational\nmagnification by MgII systems. We measure the upper limit \\mu<1.10 and discuss\nthe origin of the discrepancy. Finally, we estimate the fraction of absorbers\nmissed due to extinction effects and show that it rises from 1 to 50% in the\nrange 1<W_0<6 Angstrom. We parametrize this effect and provide a correction for\nrecovering the intrinsic distribution of absorber rest equivalent widths.\n", "machine_text": "\nWe present the results of a systematic investigation of the properties of strong MgII absorbers in the redshift range z=0.4 to z=2. We aim to determine the relative strengths of the lensing, reddening and extinction effects in these objects, and to derive the physical parameters of the lenses and the absorbing gas. We have identified strong MgII absorbers in 19 quasars, in most cases by using the Hubble Space Telescope, and determined the corresponding redshifts. We find that in 17 cases the lensing effect is dominant, in one case the reddening effect is dominant and in one case the extinction effect is dominant. We derive the lens model parameters in the case of a strong lensing effect, and find that the lensing objects are located at mean redshift z=1.36, with a scatter of 0.3 in redshift. We estimate the ratio of the lensing to extinction effects, and find that it is relatively constant, with a scatter of 0.3, independent of the quasar redshift. We find that the mean reddening is E(H-K)=0.38, with a scatter of 0.07 in redness, and that the mean extinction is A(H-K)=0.51, with a scatter of 0.06 in extinction. The physical parameters of the absorbing gas are derived in the case of a strong extinction effect. We conclude that strong MgII absorbers in the redshift range under consideration are in general lenses, and that the properties of the absorbing gas in these objects are consistent with a steady state model with constant relative matter distribution and optical depth.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-saturating magnetoresistance of inhomogeneous conductors: comparison\n  of experiment and simulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0393, "human_text": "  The silver chalcogenides provide a striking example of the benefits of\nimperfection. Nanothreads of excess silver cause distortions in the current\nflow that yield a linear and non-saturating transverse magnetoresistance (MR).\nAssociated with the large and positive MR is a negative longitudinal MR. The\nlongitudinal MR only occurs in the three-dimensional limit and thereby permits\nthe determination of a characteristic length scale set by the spatial\ninhomogeneity. We find that this fundamental inhomogeneity length can be as\nlarge as ten microns. Systematic measurements of the diagonal and off-diagonal\ncomponents of the resistivity tensor in various sample geometries show clear\nevidence of the distorted current paths posited in theoretical simulations. We\nuse a random resistor network model to fit the linear MR, and expand it from\ntwo to three dimensions to depict current distortions in the third (thickness)\ndimension. When compared directly to experiments on Ag$_{2\\pm\\delta}$Se and\nAg$_{2\\pm\\delta}$Te, in magnetic fields up to 55 T, the model identifies\nconductivity fluctuations due to macroscopic inhomogeneities as the underlying\nphysical mechanism. It also accounts reasonably quantitatively for the various\ncomponents of the resistivity tensor observed in the experiments.\n", "machine_text": "\nWe present a systematic study of the non-saturating magnetoresistance of inhomogeneous conductors using a combination of experiments and simulations. We show that the non-saturating magnetoresistance exhibits a strong sensitivity to the structural and morphological properties of the inhomogeneous conductor. In particular, we show that the non-saturating magnetoresistance increases with the structural inhomogeneity of the conductor, and that it is possible to engineer the non-saturating magnetoresistance by introducing structural inhomogeneities in a uniform conductor. We also show that the non-saturating magnetoresistance decreases with increasing conductor thickness, and that it can be enhanced by patterning the conductor in a periodically repetitive structure. Our results suggest that the non-saturating magnetoresistance could be used as a probe for the structural and morphological properties of conductors.\n\nWe have designed and fabricated a planar inductor that can be integrated with a high-Q resonator. The inductor consists of a three-layer stack of a thin-film ferromagnetic layer, an insulating layer, and a conductor layer. The conductor layer is patterned into a periodically repetitive structure. We show that the inductor exhibits a strong non-saturating magnetoresistance, which increases with the structural inhomogeneity of the inductor. We also show that the non-saturating magnetoresistance can be tuned by the structural inhomogeneities in the inductor. The results suggest that the non-saturating magnetoresistance could be used as a probe for the structural and morphological properties of conductors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vacuum Energy and Renormalization on the Edge. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1084, "human_text": "  The vacuum dependence on boundary conditions in quantum field theories is\nanalysed from a very general viewpoint. From this perspective the\nrenormalization prescriptions not only imply the renormalization of the\ncouplings of the theory in the bulk but also the appearance of a flow in the\nspace of boundary conditions. For regular boundaries this flow has a large\nvariety of fixed points and no cyclic orbit. The family of fixed points\nincludes Neumann and Dirichlet boundary conditions. In one-dimensional field\ntheories pseudoperiodic and quasiperiodic boundary conditions are also RG fixed\npoints. Under these conditions massless bosonic free field theories are\nconformally invariant. Among all fixed points only Neumann boundary conditions\nare infrared stable fixed points. All other conformal invariant boundary\nconditions become unstable under some relevant perturbations. In finite volumes\nwe analyse the dependence of the vacuum energy along the trajectories of the\nrenormalization group flow providing an interesting framework for dark energy\nevolution. On the contrary, the renormalization group flow on the boundary does\nnot affect the leading behaviour of the entanglement entropy of the vacuum in\none-dimensional conformally invariant bosonic theories.\n", "machine_text": "\n\nWe have developed a new method for computing the effective action in quantum field theory in the presence of a static point-like defect. The effective action can be viewed as the renormalization of the action function due to the presence of an additional non-abelian symplectic group in the theory. The main idea is to use the representations of the non-abelian symplectic group to control the renormalization. The method is very general and can be applied to any quantum field theory with a non-abelian symplectic group. We apply the method to the problem of a static defect in the presence of a non-abelian gauge group. The defect can be viewed as a solution to the spontaneous breaking of the symmetry group. We show that the effective action has a minimum as a function of the defect mass, and that the minimum can be understood in terms of the renormalization of the field theory. The renormalization function can be obtained explicitly, and the minimum can be found analytically. The method can be used to compute the effective action for any defect in the presence of a non-abelian symplectic group. The method can also be used to study the renormalization of the action function due to the presence of a non-abelian symplectic group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Origin of magnetoelectric behavior in BiFeO$_3$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.046, "human_text": "  The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of\naccurate density functional calculations. The structural, electronic, magnetic,\nand ferroelectric properties of BiFeO$_3$ are predicted correctly without\nincluding strong correlation effect in the calculation. Moreover, the\nexperimentally-observed elongation of cubic perovskite-like lattice along the\n[111] direction is correctly reproduced. At high pressure we predicted a\npressure-induced structural transition and the total energy calculations at\nexpanded lattice show two lower energy ferroelectric phases, closer in energy\nto the ground state phase. Band-structure calculations show that BiFeO$_3$ will\nbe an insulator in A- and G-type antiferromagnetic phases and a metal in other\nmagnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using\nvarious tools and electron localization function analysis shows that\nstereochemically active lone-pair electrons at the Bi sites are responsible for\ndisplacements of the Bi atoms from the centro-symmetric to the\nnoncentrosymmetric structure and hence the ferroelectricity. A large\nferroelectric polarization (88.7 $\\mu$C/cm$^{2}$) is predicted in accordance\nwith recent experimental findings. The net polarization is found to mainly ($>$\n98%) originate from Bi atoms. Moreover the large scatter in experimentally\nreported polarization values is due to the large anisotropy in the spontaneous\npolarization.\n", "machine_text": "\nWe have discovered an unusual magneto-electric effect in BiFeO3, a multiferroic material. This effect is not present in the bulk form of the material, but only in a limited temperature region close to the structural phase transition. We show that this effect can be explained by a mechanism of magnetic domain wall motion assisted by an electromechanical instability. We have observed that the stray field of the magnetic domains can be enhanced by a factor of up to 2 by applying a small DC electric field, which results in a large electric field across the domain walls. This large field is necessary to drive the domain wall motion in the ordered state, in which the wall energy is increased by a geometric effect. We have also found that the wall motion is always accompanied by a large increase of the magnetic resistivity, by a factor of up to 3, in the same temperature region. We show that this increase can be explained by a model of elastic strain and magneto-mechanical coupling. Our results suggest that the exotic behavior of BiFeO3 is caused by a strong magneto-mechanical coupling in this material.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The evolution of interstellar clouds in a streaming hot plasma including\n  heat conduction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3592, "human_text": "  To examine the evolution of giant molecular clouds in the stream of a hot\nplasma we performed two-dimensional hydrodynamical simulations that take full\naccount of self-gravity, heating and cooling effects and heat conduction by\nelectrons. We use the thermal conductivity of a fully ionized hydrogen plasma\nproposed by Spitzer and a saturated heat flux according to Cowie & McKee in\nregions where the mean free path of the electrons is large compared to the\ntemperature scaleheight. Significant structural and evolutionary differences\noccur between simulations with and without heat conduction. Dense clouds in\npure dynamical models experience dynamical destruction by Kelvin-Helmholtz (KH)\ninstability. In static models heat conduction leads to evaporation of such\nclouds. Heat conduction acting on clouds in a gas stream smooths out steep\ntemperature and density gradients at the edge of the cloud because the\nconduction timescale is shorter than the cooling timescale. This diminishes the\nvelocity gradient between the streaming plasma and the cloud, so that the\ntimescale for the onset of KH instabilities increases, and the surface of the\ncloud becomes less susceptible to KH instabilities. The stabilisation effect of\nheat conduction against KH instability is more pronounced for smaller and less\nmassive clouds. As in the static case more realistic cloud conditions allow\nheat conduction to transfer hot material onto the cloud's surface and to mix\nthe accreted gas deeper into the cloud.\n", "machine_text": "\nWe present a detailed study of the evolution of interstellar clouds in a streaming hot plasma including heat conduction. Our aim is to investigate the effects of the heat flow on the density structure of the cloud and the subsequent effects on the evolution of the cloud. We solve the hydrodynamic equations for a cloud with a given density structure which is interacting with a streaming hot plasma. The streaming motion is described by a single-phase model with a temperature-dependent viscosity. Convection is included in the model in the form of a passive scalar field. The effect of the heat conduction is incorporated by solving the energy equation in a thermally homogeneous cloud. The evolution of the cloud is investigated for different initial conditions and parameter values. We show that the heat flow can have a significant effect on the cloud evolution. The most remarkable effects are the increase of the local cloud density and the development of density structures which are most likely to be observed inreality.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measuring Electric Fields From Surface Contaminants with Neutral Atoms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2027, "human_text": "  In this paper we demonstrate a technique of utilizing magnetically trapped\nneutral Rb-87 atoms to measure the magnitude and direction of stray electric\nfields emanating from surface contaminants. We apply an alternating external\nelectric field that adds to (or subtracts from) the stray field in such a way\nas to resonantly drive the trapped atoms into a mechanical dipole oscillation.\nThe growth rate of the oscillation's amplitude provides information about the\nmagnitude and sign of the stray field gradient. Using this measurement\ntechnique, we are able to reconstruct the vector electric field produced by\nsurface contaminants. In addition, we can accurately measure the electric\nfields generated from adsorbed atoms purposely placed onto the surface and\naccount for their systematic effects, which can plague a precision\nsurface-force measurement. We show that baking the substrate can reduce the\nelectric fields emanating from adsorbate, and that the mechanism for reduction\nis likely surface diffusion, not desorption.\n", "machine_text": "\n\nMeasuring Electric Fields From Surface Contaminants with Neutral Atoms.\n\nWe present a new method to measure the electric field generated by surface contaminants. Our approach is based on the use of neutral atoms to probe the field. We show that a statistical ensemble of neutral atoms, if prepared in a state with a well-defined spatial distribution, can be used to map the field in the vicinity of a surface. The method does not require the atoms to be charged, ionized, or contacted by a conductive probe. It therefore bypasses the need to bring a charge carrier close to the surface, and can be used to measure electric fields in hostile environments and in situations where the field is strongly inhomogeneous. We demonstrate the method by measuring the field generated by a single contaminant on a semiconductor surface. Our current approach is limited by the need to infer the field from a statistical ensemble of atoms. We discuss how the method can be improved by preparing atoms in a particular quantum state, in which the field-induced orbital motion of an atom can be directly measured.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gas-grain chemistry in cold interstellar cloud cores with a microscopic\n  Monte Carlo approach to surface chemistry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2704, "human_text": "  AIM: We have recently developed a microscopic Monte Carlo approach to study\nsurface chemistry on interstellar grains and the morphology of ice mantles. The\nmethod is designed to eliminate the problems inherent in the rate-equation\nformalism to surface chemistry. Here we report the first use of this method in\na chemical model of cold interstellar cloud cores that includes both gas-phase\nand surface chemistry. The surface chemical network consists of a small number\nof diffusive reactions that can produce molecular oxygen, water, carbon\ndioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation\nis started by running a gas-phase model including accretion onto grains but no\nsurface chemistry or evaporation. The starting surface consists of either flat\nor rough olivine. We introduce the surface chemistry of the three species H, O\nand CO in an iterative manner using our stochastic technique. Under the\nconditions of the simulation, only atomic hydrogen can evaporate to a\nsignificant extent. Although it has little effect on other gas-phase species,\nthe evaporation of atomic hydrogen changes its gas-phase abundance, which in\nturn changes the flux of atomic hydrogen onto grains. The effect on the surface\nchemistry is treated until convergence occurs. We neglect all non-thermal\ndesorptive processes. RESULTS: We determine the mantle abundances of assorted\nmolecules as a function of time through 2x10^5 yr. Our method also allows\ndetermination of the abundance of each molecule in specific monolayers. The\nmantle results can be compared with observations of water, carbon dioxide,\ncarbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than\na slight underproduction of mantle CO, our results are in very good agreement\nwith observations.\n", "machine_text": "\n\nWe present a microscopic Monte Carlo approach to surface chemistry suitable for application to cold interstellar cloud cores. The method is based on a random walk algorithm and accounts for both gas-grain and grain-grain chemistry. We consider a simplified chemical system consisting of only a few elements and focus on the competition between the various chemical processes as the most important quantity to describe. The model is compared to previous models based on a statistical equilibrium approach and the different methods are compared in a simplified one-dimensional scenario. We find that the relative importance of the different chemical processes is correctly reproduced by our microscopic approach, provided that the initial conditions are chosen such that a chemical equilibrium is indeed obtained. The main difference between the statistical and the microscopic approach is that the latter takes into account the actual reaction probabilities, whereas the former uses only equilibrium constants. The good agreement between theory and observation for the simple chemical system considered suggests that a microscopic approach is indeed appropriate to describe surface chemistry in cold cloud cores, provided that the chemistry is not too complex.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Transition region features observed with Hinode/EIS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1856, "human_text": "  Two types of active region feature prominent at transition region\ntemperatures are identified in Hinode/EIS data of AR 10938 taken on 2007\nJanuary 20. The footpoints of 1 MK TRACE loops are shown to emit strongly in\nemission lines formed at log T=5.4-5.8, allowing the temperature increase along\nthe footpoints to be clearly seen. A density diagnostic of Mg VII yields the\ndensity in the footpoints, with one loop showing a decrease from 3x10^9 cm^-3\nat the base to 1.5x10^9 cm^-3 at a projected height of 20 Mm. The second\nfeature is a compact active region transition region brightening which is\nparticularly intense in O V emission (log T=5.4) but also has a signature at\ntemperatures up to log T=6.3. The Mg VII diagnostic gives a density of 4x10^10\ncm^-3, and emission lines of Mg VI and Mg VII show line profiles broadened by\n50 km/s and wings extending beyond 200 km/s. Continuum emission in the short\nwavelength band is also found to be enhanced, and is suggested to be free-bound\nemission from recombination onto He^+.\n", "machine_text": "\n\nThe solar transition region is a crucial but relatively poorly understood region of the solar atmosphere, where the temperature increases rapidly from approximately 6000 K to 1 MK. The dynamics in this region is complex, due in part to the competing gravitational and magnetic forces. The large-scale magnetic field is generally frozen into the convection, but on a local scale the field can be highly dynamic, with regions of enhanced, decreasing, or even vanishing magnetic field strength. The region is also the site of many interesting small-scale phenomena, such as solar flares and nanoflares. The behavior of the transition region is key to understanding solar wind acceleration, as well as the formation of solar active regions.\nIn order to better understand the solar transition region, we have used data from the Hinode spacecraft's EIS (EUV Imaging Spectrometer) instrument. We have analyzed the visible and ultraviolet data in combination with magnetic field data from the H\u03b1 telescope, in order to study the dynamic features in the transition region. In particular, we have looked at how the magnetic field is structured in this region, and how this field structure relates to the observed dynamic features.\nWe have found a strong correlation between the dynamic features and the magnetic field strength. In particular, we find that the appearance of small-scale dynamic features is highly dependent on the local magnetic field strength. These results suggest that the magnetic field plays a key role in the dynamics of the transition region, and point to the importance of considering the small-scale features in future transition region studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing the Structure of Gamma-Ray Burst Jets with Steep Decay Phase of\n  their Early X-ray Afterglows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1055, "human_text": "  We show that the jet structure of gamma-ray bursts (GRBs) can be investigated\nwith the tail emission of the prompt GRB. The tail emission which we consider\nis identified as a steep-decay component of the early X-ray afterglow observed\nby the X-ray Telescope onboard Swift. Using a Monte Carlo method, we derive,\nfor the first time, the distribution of the decay index of the GRB tail\nemission for various jet models. The new definitions of the zero of time and\nthe time interval of a fitting region are proposed. These definitions for\nfitting the light curve lead us an unique definition of the decay index, which\nis useful to investigate the structure of the GRB jet. We find that if the GRB\njet has a core-envelope structure, the predicted distribution of the decay\nindex of the tail has a wide scatter and has multiple peaks, which cannot be\nseen for the case of the uniform and the Gaussian jet. Therefore, the decay\nindex distribution tells us the information on the jet structure. Especially,\nif we observe events whose decay index is less than about 2, both the uniform\nand the Gaussian jet models will be disfavored according to our simulation\nstudy.\n", "machine_text": "\nWe propose a method to constrain the structure of gamma-ray burst (GRB) jets by measuring the steepness of the decay phase of their early X-ray afterglows. We find that for decays with indices 1/2 \u2272 \u03b1 \u2272 4/3, a simple model in which the jet is treated as a viscous fluid in hydrodynamic equilibrium can quantitatively reproduce the data, provided that the burst energy is in the range $3\\times10^{36}-10^{37}$ erg and the inner structure of the jet is locally isothermal with a constant density \u03c1 \u223c 1.4  \ud83e\udca0 0.7  \ud83e\udca0 0.2  kg m\u22123. We conclude that a substantial part of the jet must be made up of an isothermal region with a constant density  \u223c 1.4  \ud83e\udca0 0.7  \ud83e\udca0 0.2  kg m\u22123, possibly a streamlined core with a very high ionization fraction. This interpretation is consistent with recent observations of high-ionization-fraction regions in some long-duration GRBs. For decays with \u03b1 \u2273 4/3, our model fails to reproduce the data, and we discuss several possible physical explanations for this. We also discuss the effect of an optional power law decay index n \u223c 1.3  \ud83e\udca0 1.4, which was reported in some recent observations, on our model. We show that this power law index can be accounted for if the density distribution has a double-power-law profile, with a power law index n \u223c 2.3  \ud83e\udca0 1.4 in the inner part of the isothermal region and a shallower index n \u223c 1.1  \ud83e\udca0 1.2 in the outer part.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Kirillov-Reshetikhin conjecture : the general case. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2838, "human_text": "  We prove the Kirillov-Reshetikhin (KR) conjecture in the general case : for\nall twisted quantum affine algebras we prove that the characters of KR modules\nsolve the twisted Q-system and we get explicit formulas for the character of\ntheir tensor products (the untwisted simply-laced case was treated by Najakima,\nand the untwisted case by the author). The proof is uniform and provides\nseveral new developments for the representation theory of twisted quantum\naffine algebras, including twisted Frenkel-Reshetikhin q-characters (expected\nby Frenkel-Reshetikhin and Frenkel-Mukhin). We also prove the twisted T-system.\nAs an application we get explicit formulas for the twisted q-characters of\nfundamental representations for all types, including the formulas for types\nD_4^{(3)}, E_6^{(2)} conjectured by Reshetikhin. We prove the formulas for KR\nmodules in types A_n^{(2)} and D_4^{(3)} conjectured by Kuniba-Suzuki.\nEventually our results imply the conjectural branching rules [HKOTT] to the\nquantum subalgebra of finite type.\n", "machine_text": "\n\nKirillov-Reshetikhin conjecture : the general case\nThe motivation for this work is the study of the properties of positive weighted Chow motives over local and global fields. In this paper, we present an approach to the Kirillov-Reshetikhin conjecture on positive motive classification in terms of deformations of algebraic varieties. We show that the Kirillov-Reshetikhin conjecture is a special case of a more general conjecture on the structure of positive motive deformations. We give a criterion for the consistency of this conjecture in the case of local fields.\n\nLet $k$ be a local field. Let $M$ be a positive motive. We write $M$ uniquely as a finite conjunction of simple motives. Let $M_0$ be the smallest positive motive; that is, the intersection of all simple motives. We say that $M$ is a deformation of $M_0$ if there exists a $k$-linear homomorphism $\\varphi: M_0 \\to M$ such that the following properties hold.\n\n(i) $\\varphi$ is an injective map on simple motives;\n(ii) $\\varphi$ induces an isomorphism on the quotient $M_0/M$;\n(iii) if $\\varphi(M_0) = M_0$, then $\\varphi$ is an isomorphism.\n\nWe show that the Kirillov-Reshetikhin conjecture is a special case of the following more general conjecture on positive motive deformations.\n\nLet $M$ be a positive motive. We write $M$ uniquely as a finite conjunction of simple motives. Let $M_0$ be the smallest positive motive; that is, the intersection of all simple motives. We say that $M$ is a deformation of $M_0$ if there exists a linear homomorphism $\\varphi: M_0 \\to M$ such that the following properties hold.\n\n(i) $\\varphi$ is an injective map on simple motives;\n(ii) $\\varphi$ induces an isomorphism on the quotient $M_0/M$;\n(iii) if $\\varphi(M_0) = M_0$, then $\\varphi$ is an isomorphism.\n\nWe give a criterion for the consistency of this conjecture in the case of local fields.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Cut-off Covering Spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3822, "human_text": "  We introduce the $R$ cut-off covering spectrum and the cut-off covering\nspectrum of a complete length space or Riemannian manifold. The spectra measure\nthe sizes of localized holes in the space and are defined using covering spaces\ncalled $\\delta$ covers and $R$ cut-off $\\delta$ covers. They are investigated\nusing $\\delta$ homotopies which are homotopies via grids whose squares are\nmapped into balls of radius $\\delta$.\n  On locally compact spaces, we prove that these new spectra are subsets of the\nclosure of the length spectrum. We prove the $R$ cut-off covering spectrum is\nalmost continuous with respect to the pointed Gromov-Hausdorff convergence of\nspaces and that the cut-off covering spectrum is also relatively well behaved.\nThis is not true of the covering spectrum defined in our earlier work which was\nshown to be well behaved on compact spaces. We close by analyzing these spectra\non Riemannian manifolds with lower bounds on their sectional and Ricci\ncurvature and their limit spaces.\n", "machine_text": "\n\nWe show that a natural generalization of the covering spectrum of a finite dimensional vector space to the case of an infinite dimensional vector space can be obtained by using the cut-off functions. We give some applications to the theory of Banach algebras and to the theory of Fredholm operators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Distortion of Gravitational-Wave Packets Due to their Self-Gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1149, "human_text": "  When a source emits a gravity-wave (GW) pulse over a short period of time,\nthe leading edge of the GW signal is redshifted more than the inner boundary of\nthe pulse. The GW pulse is distorted by the gravitational effect of the\nself-energy residing in between these shells. We illustrate this distortion for\nGW pulses from the final plunge of black hole (BH) binaries, leading to the\nevolution of the GW profile as a function of the radial distance from the\nsource. The distortion depends on the total GW energy released and the duration\nof the emission, scaled by the total binary mass, M. The effect should be\nrelevant in finite box simulations where the waveforms are extracted within a\nradius of <~ 100M. For characteristic emission parameters at the final plunge\nbetween binary BHs of arbitrary spins, this effect could distort the simulated\nGW templates for LIGO and LISA by a fraction of 0.001. Accounting for the wave\ndistortion would significantly decrease the waveform extraction errors in\nnumerical simulations.\n", "machine_text": "\n\nDistortion of Gravitational-Wave Packets Due to their Self-Gravity\n\nWe consider the distortion of a weakly nonlinear Gravitational-Wave (GW) packet as it propagates in a spherically symmetric self-gravitating object. We show that this distortion is related to the kinematic properties of the packet and the spherically symmetric self-gravity solution. By performing a Taylor expansion of the self-gravity solution, we can express the distortion in terms of the packet's center-of-mass velocity and the first and second derivatives of the self-gravity solution with respect to the amplitude. We show that the contribution to the distortion from higher-order terms in this Taylor expansion can be bounded by a constant, which depends on the packet's kinematic properties. This bound is independent of the radius of the self-gravitating object. In particular, it does not tend to infinity as the radius tends to zero. This bound can be used to predict the distortion of a weakly nonlinear GW packet as it propagates in a spherically symmetric self-gravitating object, regardless of whether the solution is known analytically. We also investigate the effects of eccentricity and nonsphericity on the distortion of GW packets. In particular, we show that the distortion is sensitive to the instantaneous aspect ratio of a nonspherical self-gravitating object, but it is not sensitive to the mean aspect ratio. We also show that the distortion due to the self-gravity of a spherically symmetric object is always less than the distortion due to the self-gravity of a nonspherical object with the same volume.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Extended Comment on \"One-Range Addition Theorems for Coulomb Interaction\n  Potential and Its Derivatives\" by I. I. Guseinov (Chem. Phys. Vol. 309\n  (2005), pp. 209 - 213). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1088, "human_text": "  Addition theorems are principal tools that express a function $f (\\bm{r} \\pm\n\\bm{r}')$ in terms of products of other functions that only depend on either\n$\\bm{r}$ or $\\bm{r}'$. The best known example of such an addition theorem is\nthe Laplace expansion of the Coulomb potential which possesses a characteristic\ntwo-range form. Guseinov [Chem. Phys. {\\bf 309}, 209 - 213 (2005)] derived\none-range addition theorems for the Coulomb potential via the limit $\\beta \\to\n0$ in previously derived one-range addition theorems for the Yukawa potential\n$\\exp \\bigl(-\\beta | \\bm{r}-\\bm{r}'| \\bigr) /| \\bm{r}-\\bm{r}'|$. At first\nsight, this looks like a remarkable achievement, but from a mathematical point\nof view, Guseinov's work is at best questionable and in some cases\nfundamentally flawed. One-range addition theorems are expansions in terms of\nfunctions that are complete and orthonormal in a given Hilbert space, but\nGuseinov replaced the complete and orthonormal functions by nonorthogonal\nSlater-type functions and rearranged the resulting expansions. This is a\ndangerous operation whose validity must be checked. It is shown that the\none-center limit $\\bm{r}' = \\bm{0}$ of Guseinov's rearranged Yukawa addition\ntheorems as well as of several other addition theorems does not exist.\nMoreover, the Coulomb potential does not belong to any of the Hilbert spaces\nimplicitly used by Guseinov. Accordingly, one-range addition theorems for the\nCoulomb potential diverge in the mean. Instead, these one-range addition\ntheorems have to interpreted as expansions of generalized functions in the\nsense of Schwartz that converge weakly in suitable functionals.\n", "machine_text": "\n\nWe comment on the paper by Guseinov on the evaluation of the derivative of the non-relativistic interaction energy with the Coulomb interaction potential. The error in the proof of Theorem 1 is analyzed. A general formula for the derivative of the interaction energy is obtained. An estimate of the numerical value of the derivative of the interaction energy is obtained in terms of the Riemann zeta function. The explicit form of the derivative of the interaction energy is obtained in the case of the center of mass frame and the inertial frame. An application of the obtained results to the problem of minimizing the interaction energy between two particles is proposed. The formula for the derivative of the interaction energy between two particles, obtained in this work, has a simple geometric interpretation. The work done by one of the particles in the process of moving from the initial position to the final position can be represented in the interaction potential energy surface as a sum of two components: the work done by the external force and the work done by the interaction potential. An analytical formula for the work done by the interaction potential is obtained.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral method for matching exterior and interior elliptic problems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0643, "human_text": "  A spectral method is described for solving coupled elliptic problems on an\ninterior and an exterior domain. The method is formulated and tested on the\ntwo-dimensional interior Poisson and exterior Laplace problems, whose solutions\nand their normal derivatives are required to be continuous across the\ninterface. A complete basis of homogeneous solutions for the interior and\nexterior regions, corresponding to all possible Dirichlet boundary values at\nthe interface, are calculated in a preprocessing step. This basis is used to\nconstruct the influence matrix which serves to transform the coupled boundary\nconditions into conditions on the interior problem. Chebyshev approximations\nare used to represent both the interior solutions and the boundary values. A\nstandard Chebyshev spectral method is used to calculate the interior solutions.\nThe exterior harmonic solutions are calculated as the convolution of the\nfree-space Green's function with a surface density; this surface density is\nitself the solution to an integral equation which has an analytic solution when\nthe boundary values are given as a Chebyshev expansion. Properties of Chebyshev\napproximations insure that the basis of exterior harmonic functions represents\nthe external near-boundary solutions uniformly. The method is tested by\ncalculating the electrostatic potential resulting from charge distributions in\na rectangle. The resulting influence matrix is well-conditioned and solutions\nconverge exponentially as the resolution is increased. The generalization of\nthis approach to three-dimensional problems is discussed, in particular the\nmagnetohydrodynamic equations in a finite cylindrical domain surrounded by a\nvacuum.\n", "machine_text": "\n\nSpectral method for matching exterior and interior elliptic problems\n\nWe consider the problem of matching two elliptic PDEs, one with boundary conditions on the exterior of a bounded domain and the other with boundary conditions on the interior of the same domain. The motivation for this work is to develop a general method for matching two-dimensional (2D) exterior problems and two-dimensional interior problems. We propose a general and systematic spectral method for the problem and show that it is applicable to a wide class of exterior and interior elliptic problems.\n\nThe method consists of two steps. In the first step, we solve the Dirichlet problem for the elliptic PDE on the exterior of the domain with the help of a spectral technique, and in the second step, we solve the elliptic PDE on the interior of the domain with the help of the solution of the Dirichlet problem and the boundary conditions on the interior of the domain.\n\nWe show that the proposed method is applicable to a wide class of exterior and interior elliptic problems. We consider both 2D and 3D problems and obtain the optimal error estimate of the method in the energy norm. We also discuss the application of the method to the solution of various practical problems in different fields, such as mechanics, mathematics, and engineering.\n\nIn this article, we present the motivation for the research, the key ideas and methodology, the results obtained, the problem the work attempts to solve and any practical or theoretical applications from the findings or implications for future research in a formal academic and scientific writing voice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Transient behavior of surface plasmon polaritons scattered at a\n  subwavelength groove. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0703, "human_text": "  We present a numerical study and analytical model of the optical near-field\ndiffracted in the vicinity of subwavelength grooves milled in silver surfaces.\nThe Green's tensor approach permits computation of the phase and amplitude\ndependence of the diffracted wave as a function of the groove geometry. It is\nshown that the field diffracted along the interface by the groove is equivalent\nto replacing the groove by an oscillating dipolar line source. An analytic\nexpression is derived from the Green's function formalism, that reproduces well\nthe asymptotic surface plasmon polariton (SPP) wave as well as the transient\nsurface wave in the near-zone close to the groove. The agreement between this\nmodel and the full simulation is very good, showing that the transient\n\"near-zone\" regime does not depend on the precise shape of the groove. Finally,\nit is shown that a composite diffractive evanescent wave model that includes\nthe asymptotic SPP can describe the wavelength evolution in this transient\nnear-zone. Such a semi-analytical model may be useful for the design and\noptimization of more elaborate photonic circuits whose behavior in large part\nwill be controlled by surface waves.\n", "machine_text": "\n\nWe study the transient behavior of surface plasmon polaritons scattered at a subwavelength groove. We show that the transmission coefficient of a surface plasmon wave scattered at a groove depends on the excitation frequency, the groove width, and the angle of incidence, and it exhibits several interesting features such as a peak or a dip at the resonance frequency. We explain these phenomena by analytically solving the scattering problem for a groove with a rectangular cross-section. Our analytical results are in good agreement with the numerical results obtained by solving the three-dimensional Maxwell equations. We also numerically investigate the scattering from a V-shaped groove, which can be realized by etching a shallow V-shaped trench in a thin gold film. Our results show that the transient behavior of surface plasmon polaritons scattered at a V-shaped groove is very different from that scattered at a groove with a rectangular cross-section, which may be useful for realizing optical switches and modulators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radio Astrometric Detection and Characterization of Extra-Solar Planets:\n  A White Paper Submitted to the NSF ExoPlanet Task Force. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0238, "human_text": "  The extraordinary astrometric accuracy of radio interferometry creates an\nimportant and unique opportunity for the discovery and characterization of\nexo-planets. Currently, the Very Long Baseline Array can routinely achieve\nbetter than 100 microarcsecond accuracy, and can approach 10 microarcsecond\nwith careful calibration. We describe here RIPL, the Radio Interferometric\nPLanet search, a new program with the VLBA and the Green Bank 100 m telescope\nthat will survey 29 low-mass, active stars over 3 years with sub-Jovian planet\nmass sensitivity at 1 AU. An upgrade of the VLBA bandwidth will increase\nastrometric accuracy by an order of magnitude. Ultimately, the colossal\ncollecting area of the Square Kilometer Array could push astrometric accuracy\nto 1 microarcsecond, making detection and characterizaiton of Earth mass\nplanets possible.\n  RIPL and other future radio astrometric planet searches occupy a unique\nvolume in planet discovery and characterization parameter space. The parameter\nspace of astrometric searches gives greater sensitivity to planets at large\nradii than radial velocity searches. For the VLBA and the expanded VLBA, the\ntargets of radio astrometric surveys are by necessity nearby, low-mass, active\nstars, which cannot be studied efficiently through the radial velocity method,\ncoronagraphy, or optical interferometry. For the SKA, detection sensitivity\nwill extend to solar-type stars. Planets discovered through radio astrometric\nmethods will be suitable for characterization through extreme adaptive optics.\n  The complementarity of radio astrometric techniques with other methods\ndemonstrates that radio astrometry can play an important role in the roadmap\nfor exoplanet discovery and characterization.\n", "machine_text": "\nWe propose a new method of detecting extra-solar planets using radio astrometry. Our method combines data from existing and future radio telescopes to achieve a level of sensitivity unprecedented in extra-solar planet detection. The key idea is to use an existing high-resolution radio telescope to measure the position of a radio source relative to a reference point in the sky, and use this measurement to detect the motion of an exoplanet as it orbits its host star. The measurement is done by observing the source for several years, during which the exoplanet will move a small amount relative to the host star. We show that this method can detect an exoplanet with a mass as small as a few times the mass of the Earth, at a distance of up to several thousand light-years. We also show that the method can be used to characterize the exoplanet, by measuring its mass, radius, and orbital parameters. The main challenges for the method are: (1) detecting the very small motion of the exoplanet, (2) achieving the high angular resolution required to resolve the motion of the exoplanet, and (3) avoiding the contamination of the exoplanet signal by stellar Proper Motion. We discuss the method in detail, and evaluate the required resources. We find that the method can be implemented with existing telescopes, with a dedication of a few percent of their observing time, and without any significant modification to their hardware or software. We also find that the method will have a very high yield, since it will detect a large fraction of the exoplanets that are expected to exist in our Galaxy. We expect that this method will play a major role in the detection and characterization of extra-solar planets in the coming decades.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structures in the Universe and Origin of Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1448, "human_text": "  The analysis of images (of obtained in various ranges of the lengths of\nwaves) of luminous objects in the Universe by means of a method of multilevel\ndynamic contrasting led author to the conclusions: a) the structures of all\nobservable galaxies represents a complicated constructions which have the\ntendency to self-similarity and made of separate (basic) blocks, which are a\ncoaxially tubular structures and a cartwheel-like structures; b) the majority\nof observable objects in the Universe are luminous butt-ends of almost\ninvisible (of almost completely transparent) of filamentary formations which\nstructures are seen only near to their luminous butt-ends; c) the result of\nanalysis of images of cosmic objects show the structure of many pairs of\ncooperating galaxies point to opportunity of their formation at butt-ends\ngenerated in a place of break of the similar filament; d) the interacting\ngalaxies (M 81 and M 82) show they are butt-ends of sawed off of two branches\nof a treelike filament and their interaction is coming out through this\nfilament; e) as our Universe is in dynamics the processes of formation of\nstars, galaxies and their congestions can go presently by means of a fracturing\nof filaments with a corresponding diameters and of the time for their such\nformation is necessary much less, than along existing standard model.\n", "machine_text": "\n\nWe have developed a model of the evolution of the Universe and the origin of galaxies. Our model is based on the idea that the evolution of the Universe is a process of successive generations of structures, in each of which the structures of the previous generation are shattered and the pieces are reassembled into more complex structures. The first generation of structures consists of small fluctuations in the density of the Universe that grow in size and become the seeds for the formation of galaxies. The second generation of structures are the galaxies that form from the seeds, and the third generation are the clusters of galaxies that form from the galaxies. We have shown that the evolution of the Universe is a process of exponential growth, and that the growth rate is related to the average density of the Universe. We have also shown that the structure of the Universe is self-organized, and that the process of evolution is driven by the energy released by the formation of structures. We have estimated the growth rate of the Universe and the average density of the Universe, and we have shown that they are consistent with the observed evolution of the Universe. We have also shown that the growth rate of the Universe is related to the average density of the Universe, and that the growth rate is higher when the average density is higher. We have shown that the evolution of the Universe is a process of successive generations of structures, and that the structures of each generation are more complex than the structures of the previous generation. We have also shown that the process of evolution is driven by the energy released by the formation of structures, and that the energy is used to form the next generation of structures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Families of holomorphic bundles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2629, "human_text": "  The first goal of the article is to solve several fundamental problems in the\ntheory of holomorphic bundles over non-algebraic manifolds: For instance we\nprove that stability and semi-stability are Zariski open properties in families\nwhen the Gauduchon degree map is a topological invariant, or when the parameter\nmanifold is compact. Second we show that, for a generically stable family of\nbundles over a K\\\"ahler manifold, the Petersson-Weil form extends as a closed\npositive current on the whole parameter space of the family. This extension\ntheorem uses classical tools from Yang-Mills theory developed by Donaldson\n(e.g. the Donaldson functional and the heat equation for Hermitian metrics on a\nholomorphic bundle). We apply these results to study families of bundles over a\nK\\\"ahlerian manifold $Y$ parameterized by a non-K\\\"ahlerian surface $X$,\nproving that such families must satisfy very restrictive conditions. These\nresults play an important role in our program to prove existence of curves on\nclass VII surfaces.\n", "machine_text": "\n\nWe establish a one-to-one correspondence between families of holomorphic vector bundles on a given complex projective space and families of linear subspace arrangements in the associated real vector space. As an application, we give a description of semisimple families of holomorphic vector bundles in terms of a minimal model program. We show that the real vector space associated to a semisimple family of holomorphic vector bundles is isomorphic to the real vector space associated to a family of linear subspace arrangements, and that the isomorphism classes of holomorphic vector bundles on a complex projective space is in one-to-one correspondence with the isomorphism classes of linear subspace arrangements in the associated real vector space. As another application, we give a description of families of holomorphic vector bundles on a given complex projective space in terms of a model program which involves the minimal model of a real vector space arrangement and the annihilator of a certain subspace.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relation between exchange-only optimized potential and Kohn-Sham methods\n  with finite basis sets; solution of a paradox. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1717, "human_text": "  Arguments showing that exchange-only optimized effective potential (xOEP)\nmethods, with finite basis sets, cannot in general yield the Hartree-Fock (HF)\nground state energy, but a higher one, are given. While the orbital products of\na complete basis are linearly dependent, the HF ground state energy can only be\nobtained via a basis set xOEP scheme in the special case that all products of\noccupied and unoccupied orbitals emerging from the employed orbital basis set\nare linearly independent from each other. In this case, however, exchange\npotentials leading to the HF ground state energy exhibit unphysical\noscillations and do not represent a Kohn-Sham (KS) exchange potential. These\nfindings solve the seemingly paradoxical results of Staroverov, Scuseria and\nDavidson that certain finite basis set xOEP calculations lead to the HF ground\nstate energy despite the fact that within a real space (or complete basis)\nrepresentation the xOEP ground state energy is always higher than the HF\nenergy. Moreover, whether or not the occupied and unoccupied orbital products\nare linearly independent, it is shown that basis set xOEP methods only\nrepresent exact exchange-only (EXX) KS methods, i.e., proper density-functional\nmethods, if the orbital basis set and the auxiliary basis set representing the\nexchange potential are balanced to each other, i.e., if the orbital basis is\ncomprehensive enough for a given auxiliary basis. Otherwise xOEP methods do not\nrepresent EXX KS methods and yield unphysical exchange potentials.\n", "machine_text": "\nWe study the relation between exact (or \"exchange-only optimized\") potential methods, which are exact in the sense that they use only the exact, optimized potential between any two basis functions, and more standard Kohn-Sham (KS) methods, which are exact in the sense that they use the optimized (but potentially inexact) potential between any two basis functions. This relation has been largely ignored in the literature, despite the fact that many exact potential methods have been developed over the years, including the exact covalent potential, the Coulomb potential, the Restricted Active Space (RAS) potential, the Emax potential, the Active Space Augmentation (ASA) potential, the Quickovec potential, and various \"iotk\" potentials. We find that many of the exact potential methods can be obtained as an approximation to the more standard KS methods by making a few relatively simple changes, and that the accuracy of these approximate methods can be improved by making relatively minor modifications to the basis sets. However, we also find that the performance of these methods depends on the choice of an appropriate reference state, and in particular that there is a \"paradox\" that the best results are generally obtained by using a reference state that has a relatively high total energy. We discuss the various exact potential methods in detail, and develop an approximation procedure that can be used to obtain an approximate basis set for the KS methods that gives relatively good results for a large number of important applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Beryllium in Ultra-Lithium-Deficient Halo Stars - The Blue Straggler\n  Connection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1551, "human_text": "  There are nine metal-deficient stars that have Li abundances well below the\nLi plateau that is defined by over 100 unevolved stars with temperatures above\n5800 K and values of [Fe/H] $<$ $-$1.0. Abundances of Be have been determined\nfor most of these ultra-Li-deficient stars in order to investigate the cause of\nthe Li deficiencies. High-resolution and high signal-to-noise spectra have been\nobtained in the Be II spectral region near 3130 \\AA for six ultra-Li-deficient\nstars with the Keck I telescope and its new uv-sensitive CCD on the upgraded\nHIRES. The spectrum synthesis technique has been used to determine Be\nabundances. All six stars are found to have Be deficiencies also. Two have\nmeasurable - but reduced - Be and four have only upper limits on Be. These\nresults are consistent with the idea that these Li- and Be-deficient stars are\nanalogous to blue stragglers. The stars have undergone mass transfer events (or\nmergers) which destroy or dilute both Li and Be. The findings cannot be matched\nby the models that predict that the deficiencies are due to extra-mixing in a\nsubset of halo stars that were initially rapid rotators, with the possible\nexception of one star, G 139-8. Because the ultra-Li-deficient stars are also\nBe-deficient, they appear to be genuine outliers in population of halo stars\nused to determine the value of primordial Li; they no longer have the Li in\ntheir atmospheres that was produced in the Big Bang.\n", "machine_text": "\nWe present photometry and spectroscopy of three ultra-lithium-deficient (ULD) halo stars in the solar neighbourhood, two of which are blue stragglers (BSs). The properties of these stars are consistent with the general picture of the evolution of massive Bs in globular clusters, but they also reveal some distinctive features. In particular, the inner-shell hydrogen-deficient and carbon-rich nature of these stars is consistent with a scenario in which a non-convective core helium-burning phase occurs in an advanced stage of stellar evolution. We also discuss the nature of the lithium deficiency in these stars. Although a large fraction of the gas in the outer convective envelope has been lost, a significant amount of mixing and enrichment with hydrogen and helium from the core must have occurred to produce the observed lithium abundances. We propose that this mixing is related to the core helium-burning phase and is due to violent convection events associated with the onset of core helium burning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A p-adic quasi-quadratic point counting algorithm. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0234, "human_text": "  In this article we give an algorithm for the computation of the number of\nrational points on the Jacobian variety of a generic ordinary hyperelliptic\ncurve defined over a finite field of cardinality $q$ with time complexity\n$O(n^{2+o(1)})$ and space complexity $O(n^2)$, where $n=\\log(q)$. In the latter\ncomplexity estimate the genus and the characteristic are assumed as fixed. Our\nalgorithm forms a generalization of both, the AGM algorithm of J.-F. Mestre and\nthe canonical lifting method of T. Satoh. We canonically lift a certain\narithmetic invariant of the Jacobian of the hyperelliptic curve in terms of\ntheta constants. The theta null values are computed with respect to a\nsemi-canonical theta structure of level $2^\\nu p$ where $\\nu >0$ is an integer\nand $p=\\mathrm{char}(\\F_q)>2$. The results of this paper suggest a global\npositive answer to the question whether there exists a quasi-quadratic time\nalgorithm for the computation of the number of rational points on a generic\nordinary abelian variety defined over a finite field.\n", "machine_text": "\nWe present a p-adic quasi-quadratic point counting algorithm for an elliptic curve over a function field of a proper scheme. Our method is based on the idea of representing the point counting function as a p-adic exponential, and using the structure of the p-adic exponential to derive an efficient algorithm. The main ingredient is a careful analysis of the relation between the exponential and the associated pushing-down argument. We deduce that, if the exponential is represented by a series of poorest terms, the number of terms needed is bounded from above by the number of distinct points on the curve. This bound is tight for the case of elliptic curves over cyclotomic fields, and we deduce that the number of terms is equal to the number of torsion points on the elliptic curve. We present an algorithm for computing this number. As an application, we show that our algorithm is able to count the torsion points of an elliptic curve over a number field in a number of steps that is independent of the conductor of the field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Global Approach to the Theory of Special Finsler Manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0053, "human_text": "  The aim of the present paper is to provide a global presentation of the\ntheory of special Finsler manifolds. We introduce and investigate globally (or\nintrinsically, free from local coordinates) many of the most important and most\ncommonly used special Finsler manifolds: locally Minkowskian, Berwald,\nLandesberg, general Landesberg, $P$-reducible, $C$-reducible,\nsemi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent,\n$C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of\nthe second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like,\n$R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant\ncurvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global\ndefinitions of these special Finsler manifolds are introduced. Various\nrelationships between the different types of the considered special Finsler\nmanifolds are found. Many local results, known in the literature, are proved\nglobally and several new results are obtained. As a by-product, interesting\nidentities and properties concerning the torsion tensor fields and the\ncurvature tensor fields are deduced. Although our investigation is entirely\nglobal, we provide; for comparison reasons, an appendix presenting a local\ncounterpart of our global approach and the local definitions of the special\nFinsler spaces considered.\n", "machine_text": "\n\nWe propose and investigate a new class of special Finsler manifolds which we call Relative Finsler manifolds. These are Finsler manifolds with a linear connection, that is, a connection such that the metric and its dual metric are related by a metric tensor of the second order. We show that such manifolds have a special class of curves, called relative geodesics, that generalize the notion of geodesics in a Finsler manifold and provide a geometrically meaningful notion of parallel transport on such manifolds. We further study the properties of the corresponding adjoint metric and show that it satisfies the Bonnet-Myers-Steele equations. As an application we show that every relative Finsler manifold is an immerseion of a ( Relative ) Riemannian manifold. We also show that a Finsler manifold with a linear connection is a relative Finsler manifold if and only if it admits a metric of the second order. As another application we show that every Finsler manifold with a constant curvature is a relative Finsler manifold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High Resolution X-Ray Imaging of the Center of IC342. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.077, "human_text": "  We presented the result of a high resolution (FWHM~0.5'') 12 ks Chandra HRC-I\nobservation of the starburst galaxy IC342 taken on 2 April 2006. We identified\n23 X-ray sources within the central 30' x 30' region of IC342. Our HRC-I\nobservation resolved the historical Ultraluminous X-ray sources (ULX), X3, near\nthe nucleus into 2 sources, namely C12 and C13, for the first time. The\nbrighter source C12, with L(0.08-10keV)=(6.66\\pm0.45)\\times10^{38}ergs^-1, was\nspatially extended (~82 pc x 127 pc). From the astrometric registration of the\nX-ray image, C12 was at R.A.=03h:46m:48.43s, decl.=+68d05m47.45s, and was\ncloser to the nucleus than C13. Thus we concluded that source was not an ULX\nand must instead be associated with the nucleus. The fainter source C13, with\nL(0.08-10keV)=(5.1\\pm1.4) x 10^{37}ergs^-1 was consistent with a point source\nand located $6.51'' at P.A. 240 degree of C12.\n  We also analyzed astrometrically corrected optical Hubble Space Telescope and\nradio Very Large Array images, a comparison with the X-ray image showed\nsimilarities in their morphologies. Regions of star formation within the\ncentral region of IC342 were clearly visible in HST H alpha image and this was\nthe region where 3 optical star clusters and correspondingly our detected X-ray\nsource C12 were observed. We found that a predicted X-ray emission from\nstarburst was very close to the observed X-ray luminosity of C12, suggesting\nthat nuclear X-ray emission in IC342 was dominated by starburst. Furthermore,\nwe discussed the possibility of AGN in the nucleus of IC342. Although our data\nwas not enough to give a firm existence of an AGN, it could not be discarded.\n", "machine_text": "\n\nIC 342 is a young, high-mass star-forming region in the constellation of Camelopardalis. The ionized gas in the center of this molecular cloud is energized by a recently-formed, massive star, designated as 3.4 million solar masses by Appenzeller et al. (1997). We present here high-resolution X-ray images of the central region, obtained with the Chandra Observatory. These data reveal the presence of a bright X-ray source at the center of IC 342, which we attribute to the presence of a collimated outflow from the high-mass star. We find that the observed X-ray surface brightness is consistent with a single, power law distribution with a slope of -1.4 \u00b1 0.1. The half-light radius is estimated to be  \u223c 1.3 kpc, and the X-ray surface brightness is  \u223c 2.5 kpc2. We find that the X-ray emission is most likely due to a combination of a shocked wind from the high-mass star and material evaporated from the molecular cloud. We show that a simple formulation of the ionization-hydrogen-streaming-Expansion (IHSX) model is consistent with the observed X-ray surface brightness distribution. Alternatively, the X-ray emission may be due to a combination of a shocked wind from the high-mass star and material evaporated from the molecular cloud. We discuss the properties of the high-mass star and the evolution of the X-ray emitting region.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Landau (\\Gamma,\\chi)-automorphic functions on \\mathbb{C}^n of magnitude\n  \\nu. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1763, "human_text": "  We investigate the spectral theory of the invariant Landau Hamiltonian\n$\\La^\\nu$ acting on the space ${\\mathcal{F}}^\\nu_{\\Gamma,\\chi}$ of\n$(\\Gamma,\\chi)$-automotphic functions on $\\C^n$, for given real number $\\nu>0$,\nlattice $\\Gamma$ of $\\C^n$ and a map $\\chi:\\Gamma\\to U(1)$ such that the\ntriplet $(\\nu,\\Gamma,\\chi)$ satisfies a Riemann-Dirac quantization type\ncondition. More precisely, we show that the eigenspace $\n{\\mathcal{E}}^\\nu_{\\Gamma,\\chi}(\\lambda)=\\set{f\\in\n{\\mathcal{F}}^\\nu_{\\Gamma,\\chi}; \\La^\\nu f = \\nu(2\\lambda+n) f}$;\n$\\lambda\\in\\C,$ is non trivial if and only if $\\lambda=l=0,1,2, ...$. In such\ncase, ${\\mathcal{E}}^\\nu_{\\Gamma,\\chi}(l)$ is a finite dimensional vector space\nwhose the dimension is given explicitly. We show also that the eigenspace\n${\\mathcal{E}}^\\nu_{\\Gamma,\\chi}(0)$ associated to the lowest Landau level of\n$\\La^\\nu$ is isomorphic to the space, ${\\mathcal{O}}^\\nu_{\\Gamma,\\chi}(\\C^n)$,\nof holomorphic functions on $\\C^n$ satisfying $$ g(z+\\gamma) = \\chi(\\gamma)\ne^{\\frac \\nu 2 |\\gamma|^2+\\nu\\scal{z,\\gamma}}g(z), \\eqno{(*)} $$ that we can\nrealize also as the null space of the differential operator\n$\\sum\\limits_{j=1}\\limits^n(\\frac{-\\partial^2}{\\partial z_j\\partial \\bar z_j} +\n\\nu \\bar z_j \\frac{\\partial}{\\partial \\bar z_j})$ acting on $\\mathcal C^\\infty$\nfunctions on $\\C^n$ satisfying $(*)$.\n", "machine_text": "\nWe introduce the concept of Landau (\\Gamma,\\chi)-automorphic functions on \\mathbb{C}^n of magnitude \\nu, associated to an n-dimensional Landau lattice and an endomorphism of the symmetric group. We show that any such function can be uniquely represented as a polynomial of two variables of the type \\phi(\\Gamma,\\chi) = (1-\\zeta\\Gamma)\\over\\zeta + \\eta\\chi + \\gamma, where the three parameters \\zeta, \\eta, and \\gamma can be taken in a special range of values. We find an asymptotic formula for the number of such functions as the dimension increases, as well as an asymptotic formula for the number of special functions of the type (\\Gamma,\\chi) \\in \\mathfrak{g}^* (the adjoint group of the Lie algebra \\mathfrak{g} of the symmetric group). As an application, we show that the asymmetric Lie algebra \\mathfrak{g}_\\infty of the symmetric group has the structure of a limit of symmetric Lie algebras, each of which is isomorphic to \\mathfrak{g}^* / \\mathfrak{g} (the quotient group), with the isomorphism given by the action of the group of Landau (\\Gamma,\\chi)-automorphic functions on \\mathfrak{g}^* .", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA\n  Networks with Delay Constraints. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3878, "human_text": "  A game-theoretic framework is used to study the effect of constellation size\non the energy efficiency of wireless networks for M-QAM modulation. A\nnon-cooperative game is proposed in which each user seeks to choose its\ntransmit power (and possibly transmit symbol rate) as well as the constellation\nsize in order to maximize its own utility while satisfying its delay\nquality-of-service (QoS) constraint. The utility function used here measures\nthe number of reliable bits transmitted per joule of energy consumed, and is\nparticularly suitable for energy-constrained networks. The best-response\nstrategies and Nash equilibrium solution for the proposed game are derived. It\nis shown that in order to maximize its utility (in bits per joule), a user must\nchoose the lowest constellation size that can accommodate the user's delay\nconstraint. Using this framework, the tradeoffs among energy efficiency, delay,\nthroughput and constellation size are also studied and quantified. The effect\nof trellis-coded modulation on energy efficiency is also discussed.\n", "machine_text": "\nWe propose and analyze a game-theoretic approach to energy-efficient modulation in CDMA networks with delay constraints. We consider a setting where the base stations of a CDMA network are subject to power constraints, while the mobile terminals are subject to delay constraints. The base stations and the mobile terminals can choose from a finite set of modulation and coding schemes, with the goal of maximizing the network throughput while minimizing the energy consumption and the delay. We model the problem as a non-cooperative game, where the base stations and the mobile terminals are players who compete for the network resources. The game is played in rounds, where each round corresponds to a frame of the CDMA network. We define a utility function that captures the trade-off between the energy consumption, the delay, and the throughput, and use this utility function to model the behavior of the players. We analyze the game-theoretic approach using a simulation-based method, and show that the proposed approach achieves a near-optimal performance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Variation of fundamental constants: theory and observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3704, "human_text": "  Review of recent works devoted to the variation of the fundamental constants\nis presented including atomic clocks, quasar absorption spectra, and Oklo\nnatural nuclear reactor data. Assuming linear variation with time we can\ncompare different results. From the quasar absorption spectra:\n  $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$. A combination of this\nresult and the atomic clock results gives the best limt on variation of\n$\\alpha$: $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$. The\nOklo natural reactor gives the best limit on the variation of\n$m_s/\\Lambda_{QCD}$ where $m_s$ is the strange quark mass.\n  Huge enhancement of the relative variation effects happens in transitions\nbetween close atomic, molecular and nuclear energy levels. We suggest several\nnew cases where the levels are very narrow. Large enhancement of the variation\neffects is also possible in cold atomic and molecular collisions near Feshbach\nresonance. Massive bodies (stars or galaxies) can also affect physical\nconstants. They have large scalar charge $S$ proportional to number of\nparticles which produces a Coulomb-like scalar field $U=S/r$. This leads to a\nvariation of the fundamental constants proportional to the gravitational\npotential, e.g. $\\delta \\alpha/ \\alpha = k_\\alpha \\delta (GM/ r c^2)$. We\ncompare different manifestations of this effect.The strongest limit\n  $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$.\n", "machine_text": "\nWe propose a new method for the experimental estimation of the fine-structure constant (\u03b1) and the proton-to-electron mass ratio (\u03b1e) that does not require knowledge of either the electron mass (m_(e)) or the proton mass (m_(p)). Our method is based on measuring the energy levels of the hydrogen atom, the so-called hydrogenic levels. We show that if the energy of the first hydrogenic level is measured with a high enough accuracy, \u03b1 and \u03b1e can be extracted from this measurement without knowledge of m_(e) and m_(p). We evaluate the accuracy with which \u03b1 and \u03b1e can be determined from a measurement of the first hydrogenic level, and we propose a method to measure this level with the required accuracy. Our proposed method requires a precise determination of the inverse square of the fine-structure constant, which can be obtained by measuring the molecular spectrum of hydrogen chloride (HCl). We show that a measurement of the HCl spectrum with an accuracy of $\\sim 1\\%$ can be used to determine \u03b1 and \u03b1e with an accuracy of $\\sim 1\\%$. We present an analysis of the experimental conditions that must be satisfied to measure the hydrogenic levels with the required accuracy, and we propose a method to measure these levels using a microwave cavity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Entangling Independent Photons by Time Measurement. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0758, "human_text": "  A quantum system composed of two or more subsystems can be in an entangled\nstate, i.e. a state in which the properties of the global system are well\ndefined but the properties of each subsystem are not. Entanglement is at the\nheart of quantum physics, both for its conceptual foundations and for\napplications in information processing and quantum communication. Remarkably,\nentanglement can be \"swapped\": if one prepares two independent entangled pairs\nA1-A2 and B1-B2, a joint measurement on A1 and B1 (called a \"Bell-State\nMeasurement\", BSM) has the effect of projecting A2 and B2 onto an entangled\nstate, although these two particles have never interacted or shared any common\npast[1,2]. Experiments using twin photons produced by spontaneous parametric\ndown-conversion (SPDC) have already demonstrated entanglement swapping[3-6],\nbut here we present its first realization using continuous wave (CW) sources,\nas originally proposed[2]. The challenge was to achieve sufficiently sharp\nsynchronization of the photons in the BSM. Using narrow-band filters, the\ncoherence time of the photons that undergo the BSM is significantly increased,\nexceeding the temporal resolution of the detectors. Hence pulsed sources can be\nreplaced by CW sources, which do not require any synchronization[6,7], allowing\nfor the first time the use of completely autonomous sources. Our experiment\nexploits recent progress in the time precision of photon detectors, in the\nefficiency of photon pair production by SPDC with waveguides in nonlinear\ncrystals[8], and in the stability of narrow-band filters. This approach is\nindependent of the form of entanglement; we employed time-bin entangled\nphotons[9] at telecom wavelengths. Our setup is robust against thermal or\nmechanical fluctuations in optical fibres thanks to cm-long coherence lengths.\n", "machine_text": "\n\nWe propose and analyze a scheme to entangle independent photons which does not require light to propagate between the entangled photons. This is in contrast to previous entanglement generation schemes which require some form of light propagation (including nonlinear interactions, emission from a spontaneous parametric down-convention, or transmission through a diffuser or similar scramble element). Our scheme relies on a precise time measurement of the arrival of the photons at a detector. We show that this can be achieved by a combination of a narrow-band filter and a picosecond voltage pulse applied to a fast photodiode. In order to entangle two photons which are not in causal contact, we propose to use two different narrow-band filters with slightly overlapping spectra. The time windows of the two detectors are then synchronized by a control signal, which also serves to trigger the emission of the photons. We analyze the scheme and particularize it to various experimental realizations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Red Sequence Cluster Finding in the Millennium Simulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0211, "human_text": "  We investigate halo mass selection properties of red-sequence cluster finders\nusing galaxy populations of the Millennium Simulation (MS). A clear red\nsequence exists for MS galaxies in massive halos at redshifts z < 1, and we use\nthis knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h\nprojections of the simulated volume. At low redshift (z=0.4), we find that 90%\nof the clusters found have galaxy membership dominated by a single, real-space\nhalo, and that 10% are blended systems for which no single halo contributes a\nmajority of a cluster's membership. At z=1, the fraction of blends increases to\n22%, as weaker redshift evolution in observed color extends the comoving length\nprobed by a fixed range of color. Other factors contributing to the increased\nblending at high-z include broadening of the red sequence and confusion from a\nlarger number of intermediate mass halos hosting bright red galaxies of\nmagnitude similar to those in higher mass halos. Our method produces catalogs\nof cluster candidates whose halo mass selection function, p(M|\\Ngal,z), is\ncharacterized by a bimodal log-normal model with a dominant component that\nreproduces well the real-space distribution, and a redshift-dependent tail that\nis broader and displaced by a factor ~2 lower in mass. We discuss implications\nfor X-ray properties of optically selected clusters and offer ideas for\nimproving both mock catalogs and cluster-finding in future surveys.\n", "machine_text": "\n\nRed Sequence Cluster Finding in the Millennium Simulation\n\nWe present a new algorithm to find red sequence clusters in the Millennium Simulation. The motivation for this work is to provide an efficient algorithm to find the large scale structure of the Millennium Simulation. The Millennium Simulation is a large scale numerical simulation of the evolution of the universe. It has been run with different physical parameters, and the results are available as a database. The aim of this work is to investigate the large scale structure of the Millennium Simulation, and to compare the results with the observations of the large scale structure in the universe. The key idea is to use the random forest algorithm to find the red sequence clusters in the Millennium Simulation. The random forest algorithm is a machine learning algorithm that is used to find the clusters in the data. The results of this work show that the random forest algorithm is an effective tool to find the red sequence clusters in the Millennium Simulation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effective conservation of energy and momentum algorithm using switching\n  potentials suitable for molecular dynamics simulation of thermodynamical\n  systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0556, "human_text": "  During a crossover via a switching mechanism from one 2-body potential to\nanother as might be applied in modeling (chemical) reactions in the vicinity of\nbond formation, energy violations would occur due to finite step size which\ndetermines the trajectory of the particles relative to the potential\ninteractions of the unbonded state by numerical (e.g. Verlet) integration. This\nproblem is overcome by an algorithm which preserves the coordinates of the\nsystem for each move, but corrects for energy discrepancies by ensuring both\nenergy and momentum conservation in the dynamics. The algorithm is tested for a\nhysteresis loop reaction model with an without the implementation of the\nalgorithm. The tests involve checking the rate of energy flow out of the MD\nsimulation box; in the equilibrium state, no net rate of flows within\nexperimental error should be observed. The temperature and pressure of the box\nshould also be invariant within the range of fluctuation of these quantities.\nIt is demonstrated that the algorithm satisfies these criteria.\n", "machine_text": "\nWe propose a new effective conservation of energy and momentum algorithm using switching potentials suitable for molecular dynamics simulation of thermodynamical systems. We show that by using the elastic and inelastic switching potentials, the total energy and momentum can be conserved independently of the details of the simulation method used. This is achieved by using a thermodynamical model with two degrees of freedom q and p, which represent the total energy and the total momentum, respectively, and two additional auxiliary functions, which are related to the inelastic switching. The main advantage of the new algorithm is that it is not necessary to know the exact form of the inelastic switching potential. We show that in the limit of a large number of degrees of freedom, the algorithm is equivalent to the original molecular dynamics simulation. As an example application, we consider a model of a glassy material containing hard and soft particles. We find that the new algorithm is more efficient than the original algorithm in case of a large number of particles and long simulation times.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Performance Evaluation of Encounter-based Worm Interactions Based\n  on Node Characteristics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2025, "human_text": "  An encounter-based network is a frequently disconnected wireless ad-hoc\nnetwork requiring nearby neighbors to store and forward data utilizing mobility\nand encounters over time. Using traditional approaches such as gateways or\nfirewalls for deterring worm propagation in encounter-based networks is\ninappropriate. Because this type of network is highly dynamic and has no\nspecific boundary, a distributed counter-worm mechanism is needed. We propose\nmodels for the worm interaction approach that relies upon automated beneficial\nworm generation to alleviate problems of worm propagation in such networks. We\nstudy and analyze the impact of key mobile node characteristics including node\ncooperation, immunization, on-off behavior on the worm propagations and\ninteractions. We validate our proposed model using extensive simulations. We\nalso find that, in addition to immunization, cooperation can reduce the level\nof worm infection. Furthermore, on-off behavior linearly impacts only timing\naspect but not the overall infection. Using realistic mobile network\nmeasurements, we find that encounters are non-uniform, the trends are\nconsistent with the model but the magnitudes are drastically different.\nImmunization seems to be the most effective in such scenarios. These findings\nprovide insight that we hope would aid to develop counter-worm protocols in\nfuture encounter-based networks.\n", "machine_text": "\n\nNode-based interactions are central to a wide range of applications, including collaboration networks, protein interaction networks, and communication networks. We consider a specific class of node-based interactions, namely encounter-based interactions, in which the activity of each node depends only on its current neighbors. We propose a simple model in which each node keeps track of the number of its neighbors and the sum of their activities. The node then uses these quantities to determine its own activity. We show that this model is capable of producing a wide range of complex behavior, such as power-law degree distributions and small-world properties, while remaining analytically tractable. We use this model to analyze two real-world networks, namely the collaboration network of scientific papers and the calling network of mobile phones, and show that our model is able to reproduce a variety of features present in these networks. We also use our model to analyze a synthetic network in which the node attributes are generated according to a probability distribution, and show that our model is able to extract meaningful information about this distribution from the activity of the nodes. Our work suggests that encounter-based interactions can be a powerful and analytically tractable abstraction of node-based interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Resonating singlet valence plaquettes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0846, "human_text": "  We consider the simplest generalizations of the valence bond physics of SU(2)\nsinglets to SU(N) singlets that comprise objects with N sites -- these are\nSU(N) singlet plaquettes with N=3 and N=4 in three spatial dimensions.\nSpecifically, we search for a quantum mechanical liquid of such objects -- a\nresonating singlet valence plaquette phase that generalizes the celebrated\nresonating valence bond phase for SU(2) spins. We extend the Rokhsar-Kivelson\nconstruction of the quantum dimer model to the simplest SU(4) model for valence\nplaquette dynamics on a cubic lattice. The phase diagram of the resulting\nquantum plaquette model is analyzed both analytically and numerically. We find\nthat the ground state is solid everywhere, including at the Rokhsar-Kivelson\npoint where the ground state is an equal amplitude sum. By contrast, the equal\namplitude sum of SU(3) singlet triangular plaquettes on the face centered cubic\nlattice is liquid and thus a candidate for describing a resonating single\nvalence plaquette phase, given a suitably defined local Hamiltonian.\n", "machine_text": "\nWe investigate the role of plaquettes in the description of the ground state of certain correlated quantum systems. We show that a large class of such systems, including finite and infinite chains, ladders, and honeycombs, can be understood via the concept of a singlet plaquette. In particular, we show that such systems are characterized by a unique number, the singlet plaquette index, which can be thought of as the number of non-empty singlet plaquettes required to fill up all the cells of the system. We consider the case of chains and ladders and show that the singlet plquette index is related to the length of the system as well as to the number of internal edges. We show further that in all such systems the singlet plquette index is a continuous function of the parameters of the system and that it takes only discrete values. We analyze in detail the case of honeycombs and show that in this case the singlet plquette index is related to the size of the honeycombs as well as to the number of their internal edges and that it takes only even values.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear Evolution of Baryon Acoustic Oscillations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2783, "human_text": "  We study the nonlinear evolution of the baryon acoustic oscillations (BAO) in\nthe dark matter power spectrum and correlation function using renormalized\nperturbation theory (RPT). In a previous paper we showed that RPT successfully\npredicts the damping of acoustic oscillations; here we extend our calculation\nto the enhancement of power due to mode-coupling. We show that mode-coupling\ngenerates additional oscillations that are out of phase with those in the\nlinear spectrum, leading to shifts in the scales of oscillation nodes defined\nwith respect to a smooth spectrum. When Fourier transformed, these out of phase\noscillations induce percent-level shifts in the acoustic peak of the two-point\ncorrelation function. We present predictions for these shifts as a function of\nredshift; these should be considered as a robust lower limit to the more\nrealistic case that includes in addition redshift distortions and galaxy bias.\nWe show that these nonlinear effects occur at very large scales, leading to a\nbreakdown of linear theory at scales much larger than commonly thought. We\ndiscuss why virialized halo profiles are not responsible for these effects,\nwhich can be understood from basic physics of gravitational instability. Our\nresults are in excellent agreement with numerical simulations, and can be used\nas a starting point for modeling BAO in future observations. To meet this end,\nwe suggest a simple physically motivated model to correct for the shifts caused\nby mode-coupling.\n", "machine_text": "\nWe have developed a new algorithm for finding the precise nonlinear evolution of the Baryon Acoustic Oscillations (BAO) scale in a universe that has been approximated by a Friedmann-Roberson-Walker cosmology with both a variable equation of state (EOF) parameter $w(a)$ and a variable cosmological constant $\\Lambda(a)$, where $a$ is the scale factor. Our new algorithm is based on the Discrete Fourier Transform (DFT) technique and the Fast Fourier Transform (FFT) algorithm. This new algorithm provides a more efficient and more precise way of finding the BAO scale evolution in the presence of both a variable EOF and a variable cosmological constant. In particular, our algorithm can find the BAO scale evolution at any redshift with a computational cost that is $\\mathcal{O}(\\log n)$, where $n$ is the number of input data points. Our new algorithm has been validated by comparing its results with those obtained using the conventional method based on the least squares technique. Our validation shows that our new algorithm is more precise and more efficient than the conventional method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The multiple viewpoints as approach to information retrieval within\n  collaborative development context. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1162, "human_text": "  Nowadays, to achieve competitive advantage, the industrial companies are\nconsidering that success is sustained to great product development. That is to\nmanage the product throughout its entire lifecycle. Achieving this goal\nrequires a tight collaboration between actors from a wide variety of domains,\nusing different software tools producing various product data types and\nformats. The actors' collaboration is mainly based on the exchange /share\nproduct information. The representation of the actors' viewpoints is the\nunderlying requirement of the collaborative product development. The multiple\nviewpoints approach was designed to provide an organizational framework\nfollowing the actors' perspectives in the collaboration, and their\nrelationships. The approach acknowledges the inevitability of multiple\nintegration of product information as different views, promotes gathering of\nactors' interest, and encourages retrieved adequate information while providing\nsupport for integration through PLM and/or SCM collaboration. In this paper, a\nmultiple viewpoints representation is proposed. The product, process,\norganization information models are discussed. A series of issues referring to\nthe viewpoints representation are discussed in detail. Based on XML standard,\ntaking electrical connector as an example, an application case of part of\nproduct information modeling is stated.\n", "machine_text": "\n\nThe multiple viewpoints as approach to information retrieval within collaborative development context. \n\nWe are motivated by the observation that software development, due to its nature, has to deal with a huge amount of information of highly diverse nature. The information may be located in different places, in various forms and representations, and related to very different contexts. For example, requirements for a new product may be gathered from customers by marketing people, while development team gets requirements from product management and tries to make sense of them in the context of existing products and their limitations. At the same time, development team has to deal with technical documentation produced by the vendors of the used technologies, with the requests from the product management to adjust the product to the changing market, with the problems encountered during the development and with the need to document the product for the future maintenance. We observe that such diversity and amount of information require special approach to its retrieval, management and storage. We claim that the collaborative development context brings new requirements and challenges to the information retrieval process and suggest a new approach, which is based on the multiple viewpoints concept, to solve the information retrieval and management problems within collaborative development context.\n\nThe proposed approach is based on the assumption that the information about the same object can be represented from different viewpoints, and the information retrieval effectiveness can be improved by using the multiple representations. In order to prove this assumption we consider the example of requirements information management. We describe the architecture of the proposed approach and present the results of its evaluation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Search for Planets Transiting the M Dwarf Debris Disk Host, AU\n  Microscopii. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3584, "human_text": "  We present high cadence, high precision multi-band photometry of the young,\nM1Ve, debris disk star, AU Microscopii. The data were obtained in three\ncontinuum filters spanning a wavelength range from 4500\\AA to 6600\\AA, plus\nH$\\alpha$, over 28 nights in 2005. The lightcurves show intrinsic stellar\nvariability due to starspots with an amplitude in the blue band of 0.051\nmagnitudes and a period of 4.847 days. In addition, three large flares were\ndetected in the data which all occur near the minimum brightness of the star.\nWe remove the intrinsic stellar variability and combine the lightcurves of all\nthe filters in order to search for transits by possible planetary companions\norbiting in the plane of the nearly edge-on debris disk. The combined final\nlightcurve has a sampling of 0.35 minutes and a standard deviation of 6.8\nmillimags (mmag). We performed Monte Carlo simulations by adding fake transits\nto the observed lightcurve and find with 95% significance that there are no\nJupiter mass planets orbiting in the plane of the debris disk on circular\norbits with periods, P $\\le 5$ days. In addition, there are no young\nNeptune-like planets (with radii 2.5$\\times$ smaller than the young Jupiter) on\ncircular orbits with periods, P $\\le 3$ days.\n", "machine_text": "\nWe present phase-resolved spectroscopy and photometry of AU Microscopii from Keck Observatory that reveal new orbital parameters for the debris disk, including a relatively low mass (Mdisk < 3x10^32 kg) and a radius that is a factor of >3 larger than previously reported. We find the disk to be comprised of dust at a range of heliocentric distances, including a belt at ~1.5 AU, which could be the source of the disk's halo. We present high-resolution spectroscopy and photometry of the star that is consistent with a kinematic age of 2.6 Gyr. The disk does not exhibit any evidence of an embedded planet, despite having a dynamical lifetime of >3 Gyr. We search for transits by the known giant planets, and find that only a transiting planet with a radius >4.5 RJ would be detectable at the 5-sigma level. We discuss these results in the context of the giant planet's origins, and suggest that the system was either born with a large number of giant planets that have since been dynamically ejected, or that the giant planets formed later. We present an upper limit on the number of giant planets in the system of 0.5.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mapping the Cosmological Confidence Ball Surface. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2605, "human_text": "  We present a new technique to compute simultaneously valid confidence\nintervals for a set of model parameters. We apply our method to the Wilkinson\nMicrowave Anisotropy Probe's (WMAP) Cosmic Microwave Background (CMB) data,\nexploring a seven dimensional space (tau, Omega_DE, Omega_M, omega_DM, omega_B,\nf_nu, n_s). We find two distinct regions-of-interest: the standard Concordance\nModel, and a region with large values of omega_DM, omega_B and H_0. This second\npeak in parameter space can be rejected by applying a constraint (or a prior)\non the allowable values of the Hubble constant. Our new technique uses a\nnon-parametric fit to the data, along with a frequentist approach and a smart\nsearch algorithm to map out a statistical confidence surface. The result is a\nconfidence ``ball'': a set of parameter values that contains the true value\nwith probability at least 1-alpha. Our algorithm performs a role similar to the\noften used Markov Chain Monte Carlo (MCMC), which samples from the posterior\nprobability function in order to provide Bayesian credible intervals on the\nparameters. While the MCMC approach samples densely around a peak in the\nposterior, our new technique allows cosmologists to perform efficient analyses\naround any regions of interest: e.g., the peak itself, or, possibly more\nimportantly, the 1-alpha confidence surface.\n", "machine_text": "\nWe present a new algorithm for computing the confidence ball surface of a cosmological model that is applicable to general Gaussian prior marginal distributions and not restricted to circular voids. The algorithm is based on a combination of the min-max and mode-maximization methods. We show that the choice of the prior marginals has a significant impact on the shape of the confidence ball surface. For example, the choice of a Gaussian prior with a large variance produces a very different shape than the choice of a Gaussian prior with a small variance. We analyze the physical implications of different choices of prior marginals on the shape of the confidence ball surface. Our analysis shows that the confidence ball surface is very sensitive to the choice of prior marginals and small changes in the prior marginals can produce large changes in the shape of the confidence ball surface. For example, a change in the variance of the Gaussian prior that corresponds to an order of magnitude change in the standard deviation produces a change in the volume of the confidence ball surface that is proportional to the cube of the variance. We show that the confidence ball surface can be described by a few parameters that correspond to physical quantities and we provide a method for computing the parameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strings on AdS_2 and the High-Energy Limit of Noncritical M-Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.223, "human_text": "  Noncritical M-theory in 2+1 dimensions has been defined as a double-scaling\nlimit of a nonrelativistic Fermi liquid on a flat two-dimensional plane. Here\nwe study this noncritical M-theory in the limit of high energies, analogous to\nthe \\alpha'\\to\\infty limit of string theory. In the related case of\ntwo-dimensional Type 0A strings, it has been argued that the conformal\n\\alpha'\\to\\infty limit leads to AdS_2 with a propagating fermion whose mass is\nset by the value of the RR flux. Here we provide evidence that in the\nhigh-energy limit, the natural ground state of noncritical M-theory similarly\ndescribes the AdS_2\\times S^1 spacetime, with a massless propagating fermion.\nWe argue that the spacetime effective theory in this background is captured by\na topological higher-spin extension of conformal Chern-Simons gravity in 2+1\ndimensions, consistently coupled to a massless Dirac field. Intriguingly, the\ntwo-dimensional plane populated by the original nonrelativistic fermions is\nessentially the twistor space associated with the symmetry group of the\nAdS_2\\times S^1 spacetime; thus, at least in the high-energy limit, noncritical\nM-theory can be nonperturbatively described as a \"Fermi liquid on twistor\nspace.\"\n", "machine_text": "\n\nWe consider the properties of closed strings at vanishing temperature in AdS_2. We show that the low-energy effective action for a closed string in AdS_2 is non-critical M-theory, with the radius of the AdS_2 boundary playing the role of the string length. The high-energy effective action is described by a dimensional reduction of the effective Nambu-Goldstone action for a string in a flat space-time. The latter has a cosmological constant and a massless scalar field as basic ingredients. We calculate the effective actions for a closed string in AdS_2 with a non-trivial radius and show that the high-energy effective action has the same form as the non-critical M-theory effective action. This has the advantage that our result can be used to make non-trivial predictions for the high-energy behavior of M-theory. We also study the possible boundary conditions for a closed string in AdS_2 and find that the only boundary conditions which can be implemented are those which leave the AdS_2 bulk invariant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A possible explanation why the Theta+ is seen in some experiments and\n  not in others. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3045, "human_text": "  To understand the whole set of positive and null data on the\nTheta+(1530)-production, we suggest the hypothesis that multiquark hadrons are\nmainly generated from many-quark states, which emerge either as short-term\nhadron fluctuations, or as hadron remnants in hard processes. This approach\nallows us to describe both non-observation of the Theta+ in current null\nexperiments and peculiar features of its production in positive experiments.\nFurther, we are able to propose new experiments that might be decisive for the\nproblem of the Theta+ existence. Distributions of the Theta+ in such\nexperiments can give important information both on higher Fock components of\nconventional hadrons and about structure and hadronization properties of hadron\nremnants produced in hard processes. We also explain that description of\nmultiquark hadrons may require a modified form of the constituent quark model,\nwith quark masses and couplings being intermediate between their values for the\nfamiliar constituent quarks and the current ones.\n", "machine_text": "\nWe present a possible explanation why the \u03b8+ is seen in some experiments and not in others. We consider a model of the \u03b8+ involving two fermionic fields and a scalar field, which is invariant under the general symmetry group of the \u03b8+. We show that the probability for the \u03b8+ to be excited can be very small, provided that the vacuum state is very close to a symmetry state of the model. As an application, we discuss the case of the \u03b8+ in an axion-less model of the strong force, where it is expected to be very weakly excited. We also comment on the case of the \u03b8+ in the standard model, where it is totally quenched, in spite of the fact that the vacuum state is very far from a symmetry state.\n\nWe thank L. Polyakov for useful discussions. M.B. thanks A. Bergliaffa for useful comments. This work has been supported in part by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (ERC grant agreement No. 84766), by the U.S. National Science Foundation (NSF) under grant no. DMR-1306594, and by the Argentina, Brazil, Chile, Colombia and Uruguay (ABC-U) consortium through a grant to the IMPA by CONICOR from the Tinker Foundation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nova Geminorum 1912 and the Origin of the Idea of Gravitational Lensing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0963, "human_text": "  Einstein's early calculations of gravitational lensing, contained in a\nscratch notebook and dated to the spring of 1912, are reexamined. A hitherto\nunknown letter by Einstein suggests that he entertained the idea of explaining\nthe phenomenon of new stars by gravitational lensing in the fall of 1915 much\nmore seriously than was previously assumed. A reexamination of the relevant\ncalculations by Einstein shows that, indeed, at least some of them most likely\ndate from early October 1915. But in support of earlier historical\ninterpretation of Einstein's notes, it is argued that the appearance of Nova\nGeminorum 1912 (DN Gem) in March 1912 may, in fact, provide a relevant context\nand motivation for Einstein's lensing calculations on the occasion of his first\nmeeting with Erwin Freundlich during a visit in Berlin in April 1912. We also\ncomment on the significance of Einstein's consideration of gravitational\nlensing in the fall of 1915 for the reconstruction of Einstein's final steps in\nhis path towards general relativity.\n", "machine_text": "\n\nIn 1912, a nova in the star cluster Pleiades occurred. The nova was in the photographic field of the young and brilliant astronomer from Denmark, Poul Andersen. Because the nova was in the same star cluster as the recently discovered binary star Pleione, Andersen suggested that the nova was simply a disappearance of a third body in the same system. However, the spectra of the nova showed it to be a classical nova, which was subsequently named Nova Geminorum 1912. Andersen's hypothesis of a disappearance in the Pleione system was soon forgotten. In this paper, we briefly review the history of Nova Geminorum 1912 and the idea of gravitational lensing. We analyze the observations of the nova in the light of the available data and also in the light of the modern understanding of the nova phenomenon. We show that the nova was indeed in the Pleione system and that the observations support the idea that it was a case of gravitational lensing. Thus, a century ago, an astronomer was on the right track to discover one of the most spectacular phenomena in astronomy: gravitational lensing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Intricate Knots in Proteins: Function and Evolution. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0191, "human_text": "  A number of recently discovered protein structures incorporate a rather\nunexpected structural feature: a knot in the polypeptide backbone. These knots\nare extremely rare, but their occurrence is likely connected to protein\nfunction in as yet unexplored fashion. Our analysis of the complete Protein\nData Bank reveals several new knots which, along with previously discovered\nones, can shed light on such connections. In particular, we identify the most\ncomplex knot discovered to date in human ubiquitin hydrolase, and suggest that\nits entangled topology protects it against unfolding and degradation by the\nproteasome. Knots in proteins are typically preserved across species and\nsometimes even across kingdoms. However, we also identify a knot which only\nappears in some transcarbamylases while being absent in homologous proteins of\nsimilar structure. The emergence of the knot is accompanied by a shift in the\nenzymatic function of the protein. We suggest that the simple insertion of a\nshort DNA fragment into the gene may suffice to turn an unknotted into a\nknotted structure in this protein.\n", "machine_text": "\nIntricate Knots in Proteins: Function and Evolution\nThe function of a protein is encoded in its amino acid sequence and is determined by the intrinsic properties of its constituent amino acids as well as by the amino acid sequence itself. The knowledge of the function of a protein is essential for understanding its role in the cell and its contribution to the onset and progression of disease. A large number of proteins are involved in the execution of a particular function and work in a concerted manner to achieve a specific goal, such as the assembly of an organelle, the duplication of a cell, or the propagation of a signal. Elucidating the principles by which proteins execute their function is essential not only for understanding the physiology of the cell, but also for the rational design of pharmaceutical agents that can modulate protein function for therapeutic purposes. We have developed a computational method that uses only the amino acid sequence of a protein to extract the principles by which it executes its function. We show that the protein function is encoded in the functional organization of its constituent amino acids, which we term the protein's \"intricate knots.\" We have identified the intricate knots in a large number of proteins from various organisms, and we show that these knots are evolutionarily conserved. Our results suggest that the intricate knots are \"carrying the function\" of the protein and have important implications for protein function, evolution, and design.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Wide Field Spectrograph (WiFeS). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0287, "human_text": "  This paper describes the Wide Field Spectrograph (WiFeS) under construction\nat the Research School of Astronomy and Astrophysics (RSAA) of the Australian\nNational University (ANU) for the ANU 2.3m telescope at the Siding Spring\nObservatory. WiFeS is a powerful integral field, double-beam, concentric,\nimage-slicing spectrograph designed to deliver excellent thoughput, wavelength\nstability, spectrophotometric performance and superb image quality along with\nwide spectral coverage throughout the 320-950 nm wavelength region. It provides\na 25x38 arcsec. field with 0.5 arcsec. sampling along each of twenty five 38X1\narcsec slitlets. The output format is optimized to match the 4096x4096 pixel\nCCD detectors in each of two cameras individually optimized for the blue and\nthe red ends of the spectrum, respectively. A process of \"interleaved\nnod-and-shuffle\" will be applied to permit quantum noise-limited sky\nsubtraction. Using VPH gratings, spectral resolutions of 3000 and 7000 are\nprovided. The full spectral range is covered in a single exposure at R=3000,\nand in two exposures in the R=7000 mode. The use of transmissive coated optics,\nVPH gratings and optimized mirror coatings ensures a throughput (including\ntelescope atmosphere and detector) > 30% over a wide spectral range. The\nconcentric image-slicer design ensures an excellent and uniform image quality\nacross the full field. To maximize scientific return, the whole instrument is\nconfigured for remote observing, pipeline data reduction, and the accumulation\nof calibration image libraries.\n", "machine_text": "\n\nWe present the design and expected performance of WiFeS, a wide field, high resolution, optical spectrograph to be installed at the Anglo-Australian Telescope. WiFeS will provide a spectral resolution of $\\sim 2000$ at $\\sim 5-7$ arcmin field of view, over the wavelength range $\\rm 3700-10000$ \u00c5. The spectrograph is based on a bench-mounted, cryogenically cooled, grated echelle spectrograph with a reflective grating. We will achieve a high level of completeness by using a seven-element, all-refractive, on-axis imaging lens to distribute the light from a 20\" telescope among 32-34 simultaneous fibres. The fibres will feed two parallel bench-mounted spectrographs each with an integrated spectral resolution of $\\rm 5000-10000$. We expect to obtain an efficiency of $\\sim 60$% and a typical S/N of $\\rm 50$ per hour of on-time observation. We will achieve a time resolution of $\\rm 5-15$ seconds. The science drivers for WiFeS are: a) to record the redshifts of optical transient phenomena with a view to identifying potential optical counterparts to gravitational waves sources; b) to study the chemical and physical properties of stellar atmospheres and solar structure; c) to explore the structure and evolution of the interstellar medium; and d) to investigate the distribution and properties of the intergalactic medium. We expect that WiFeS will provide a step-change in Australia's ability to access time-series observations of transient phenomena in the optical and NIR, as well as provide unique high-resolution capabilities in the UV and NIR.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Formation and Collapse of Quiescent Cloud Cores Induced by Dynamic\n  Compressions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0559, "human_text": "  (Abridged) We present numerical hydrodynamical simulations of the formation,\nevolution and gravitational collapse of isothermal molecular cloud cores. A\ncompressive wave is set up in a constant sub-Jeans density distribution of\nradius r = 1 pc. As the wave travels through the simulation grid, a\nshock-bounded spherical shell is formed. The inner shock of this shell reaches\nand bounces off the center, leaving behind a central core with an initially\nalmost uniform density distribution, surrounded by an envelope consisting of\nthe material in the shock-bounded shell, with a power-law density profile that\nat late times approaches a logarithmic slope of -2 even in non-collapsing\ncases. The resulting density structure resembles a quiescent core of radius <\n0.1 pc, with a Bonnor-Ebert-like (BE-like) profile, although it has significant\ndynamical differences: it is initially non-self-gravitating and confined by the\nram pressure of the infalling material, and consequently, growing continuously\nin mass and size. With the appropriate parameters, the core mass eventually\nreaches an effective Jeans mass, at which time the core begins to collapse.\nThus, there is necessarily a time delay between the appearance of the core and\nthe onset of its collapse, but this is not due to the dissipation of its\ninternal turbulence as it is often believed. These results suggest that\npre-stellar cores may approximate Bonnor-Ebert structures which are however of\nvariable mass and may or may not experience gravitational collapse, in\nqualitative agreement with the large observed frequency of cores with BE-like\nprofiles.\n", "machine_text": "\n\nDynamic compressions are motions in the atmosphere that are both fast and intense enough to disrupt the local thermodynamic equilibrium, and are therefore capable of modifying the distribution of clouds. A number of cloud microstructure processes have been proposed to explain how clouds respond to dynamic compressions, but the most plausible mechanisms remain debated. Here we show, using large-eddy simulation, that the growth and subsequent collapse of quiescent cloud cores is a robust feature of dynamic compressions in a stratified boundary layer. We observe the growth of cloud cores in response to an increase in the rate of compression, and their subsequent collapse due to a reduction of the rate of compression or to an extreme event that disrupts the cloud core. We describe the physical processes that are most plausible to explain the formation and collapse of these cloud cores, and we quantify their importance by comparing different parameterizations in a cloud microphysical model. We find that thecollapseofcloudcoresintothediskisbestdescribedbymainlybyahydrophilicbrain.\ncloud core is associated with an increase in the cloud liquid water content and cloud base mass flux, and a decrease in the cloud fraction. The sensitivity of the model to the different parameterizations suggests that different physical processes are important for the formation and the collapse of cloud cores. We also find that the parameterization of the cloud microphysical model has a strong influence on the model's ability to reproduce the large-eddy simulation results, indicating that the representation of cloud microphysical processes is important for the prediction of weather and climate.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multi-wavelength analysis of 18um-selected galaxies in the AKARI/IRC\n  monitor field towards the North Ecliptic Pole. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1365, "human_text": "  We present an initial analysis of AKARI 18um-selected galaxies using all 9\nphotometric bands at 2-24um available in the InfraRed Camera (IRC), in order to\ndemonstrate new capabilities of AKARI cosmological surveys. We detected 72\nsources at 18um in an area of 50.2 arcmin^2 in the AKARI/IRC monitor field\ntowards the North Ecliptic Pole (NEP). From this sample, 25 galaxies with\nprobable redshifts z>~ 0.5 are selected with a single colour cut (N2-N3>0.1)\nfor a detailed SED analysis with ground-based BVRi'z'JK data. Using an SED\nradiative transfer model of starbursts covering the wavelength range UV --\nsubmm, we derive photometric redshifts from the optical-MIR SEDs of\n18um-selected galaxies. From the best-fit SED models, we show that the IRC\nall-band photometry is capable of tracing the steep rise in flux at the blue\nside of the PAH 6.2um emission feature. This indicates that the IRC all-band\nphotometry is useful to constrain the redshift of infrared galaxies,\nspecifically for dusty galaxies with a less prominent 4000A break. Also, we\nfind that the flux dip between the PAH 7.7 and 11.2um emission feature is\nrecognizable in the observed SEDs of galaxies at z~1. By using such a colour\nanomaly due to the PAH and silicate absorption features, unique samples of\nULIRGs at z~1, `silicate-break' galaxies, can be constructed from large\ncosmological surveys of AKARI towards the NEP, i.e. the NEP-Deep and NEP-Wide\nsurvey. This pilot study suggests the possibility of detecting many interesting\ngalaxy properties in the NEP-Deep and Wide surveys, such as a systematic\ndifference in SEDs between high- and low-z ULIRGs, and a large variation of the\nPAH inter-band strength ratio in galaxies at high redshifts. [abridged]\n", "machine_text": "\nWe present a multi-wavelength analysis of 18um-selected galaxies in the AKARI/IRC monitor field towards the North Ecliptic Pole. We find that the 18um-selected galaxies are statistically consistent with the general population of galaxies in the field, in terms of their color, surface brightness, and surface-area distribution. We also find that the 18um-selected galaxies are on average slightly less blue, and have higher surface brightness, than the galaxies selected by other far-infrared colors. These results suggest that the 18um-color selection is efficient in finding galaxies with strong far-infrared emission lines, but the selection is slightly conservative, as the 18um-selected galaxies contain somewhat less faint galaxies. We present an automated method to measure the far-infrared line luminosity of the 18um-selected galaxies, and use this method to search for high-redshift galaxies with the line luminosity of interest. We find four galaxies with a relatively high far-infrared line luminosity. One of these galaxies is likely at a high redshift (z >> 5), while the other three galaxies are at intermediate redshift (z < 5). We discuss the nature of these galaxies, and find that the high-redshift galaxy may be a distant galaxy with a high star formation rate, while the three intermediate-redshift galaxies are likely local galaxies with a low star formation rate but with strong molecular lines.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the nature of the short duration GRB 050906. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1705, "human_text": "  We present deep optical and infrared observations of the short duration GRB\n050906. Although no X-ray or optical/IR afterglow was discovered to deep\nlimits, the error circle of the GRB (as derived from the Swift BAT) is unusual\nincontaining the relatively local starburst galaxy IC328. This makes GRB 050906\na candidate burst from a soft-gamma repeater, similar to the giant flare from\nSGR 1806-20. The probability of chance alignment of a given BAT position with\nsuch a galaxy is small (<1%), although the size of the error circle (2.6\narcminute radius) is such that a higher-z origin can't be ruled out. Indeed,\nthe error circle also includes a moderately rich galaxy cluster at z=0.43,\nwhich is a plausible location for the burst given the apparent preference that\nshort GRBs have for regions of high mass density. No residual optical or\ninfrared emission has been observed, either in the form of an afterglow or\nlater time emission from any associated supernova-like event. We discuss the\nconstraints these limits place on the progenitor of GRB 050906 based on the\nexpected optical signatures from both SGRs and merging compact object systems.\n", "machine_text": "\n\nWe present a detailed analysis of the short duration gamma-ray burst (GRB) 050906, which was observed on September 6, 2005, by the Swift satellite. The burst lasted for only 2.2 ks, making it the shortest burst observed so far. The observed phenomenology is consistent with the burst engine being a black hole of 3-10 M\n Benoit, 2005. We find that the most parsimonious model for the observed phenomenology is a burst with a constant isotropic-equivalent radiated energy (ERe) of 5 kJ kg-1 and a fluence-weighted isotropic-equivalent radiated energy of 100 kJ kg-1. These two ERe values are almost equal, which implies that the burst was highly focused. We show that this can be explained by a GRB with an energy conversion efficiency \u03b7 from rest-frame isotropic-equivalent kinetic energy to isotropic-equivalent radiated energy of \u03b7 \u223c 0.1 and a burst-wide duty cycle of \u223c 0.1. Such a burst would have an energy release of \u223c 1 kJ. A burst engine with a relatively high rest-frame isotropic-equivalent kinetic energy of  \u223c 10 kJ and a relatively low \u03b7 \u223c 0.1 would produce a burst with a burst-wide duty cycle of \u223c 0.9 and an energy release of  \u223c 100 kJ. We discuss this burst in the context of models in which the burst energy is produced by a low-mass object (LMO) falling onto a massive object (MMO). We find that for this burst to be explained by the standard GRB model in which the burst energy is produced by an LMO falling onto an MMO, the MMO would have to be at least 10 times more massive than the LMO. We discuss the possibility that this burst was produced by a collision between two LMOs of comparable masses, in which case the burst-to-birth ratio would be  \u223c 1.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Growth window and possible mechanism of millimeter-thick single-walled\n  carbon nanotube forests. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1903, "human_text": "  Our group recently reproduced the water-assisted growth method, so-called\n\"super growth\", of millimeter-thick single-walled carbon nanotube (SWNT)\nforests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this\ncurrent work, a parametric study was carried out on both reaction and catalyst\nconditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm)\nyielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3\nsupport enhanced the activity of Fe, Co, and Ni catalysts. The growth window\nfor the rapid SWNT growth was narrow, however. Optimum amount of added H2O\nincreased the SWNT growth rate but further addition of H2O degraded both the\nSWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT\ngrowth, but again, further addition decreased both the SWNT growth rate and\nquality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly\nenhances the SWNT growth rate by supplying the carbon source to the catalyst\nnanoparticles. The origin of the narrow window for rapid SWNT growth will also\nbe discussed.\n", "machine_text": "\n\nGrowth window and possible mechanism of millimeter-thick single-walled carbon nanotube forests\n\nA forest of multi-millimeter-thick single-walled carbon nanotubes (SWCNTs) with a high specific surface area and high thermal conductivity can be synthesized by the thermal chemical vapor deposition (TCVD) method using Fe(NO3)3\u00b79H2O as the catalyst and acetylene as the carbon source, in a reaction chamber with an inner diameter of 8 mm and a length of 200 mm. The effect of the initial concentration of Fe(NO3)3\u00b79H2O on the growth of SWCNTs was investigated. The results showed that the SWCNT forest with a height of more than 2 mm could be synthesized when the initial concentration of Fe(NO3)3\u00b79H2O was lower than 0.167 g\u00b7L\u22121. The SWCNT forest with a height of more than 10 mm could be synthesized when the initial concentration of Fe(NO3)3\u00b79H2O was higher than 1.835 g\u00b7L\u22121. A growth window of 5.667 g\u00b7L\u22121\u00b7h\u22121 was obtained between the initial concentrations of 0. chaotic and 1.835 g\u00b7L\u22121\u00b7h\u22121. The growth rate of the SWCNTs was found to be dependent on the initial concentration of Fe(NO3)3\u00b79H2O. A possible growth mechanism of the SWCNTs was proposed according to the experimental results and some related studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum Electrodynamics of qubits. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2121, "human_text": "  Systematic description of a spin one-half system endowed with magnetic moment\nor any other two-level system (qubit) interacting with the quantized\nelectromagnetic field is developed. This description exploits a close analogy\nbetween a two-level system and the Dirac electron that comes to light when the\ntwo-level system is described within the formalism of second quantization in\nterms of fermionic creation and annihilation operators. The analogy enables one\nto introduce all the powerful tools of relativistic QED (albeit in a greatly\nsimplified form). The Feynman diagrams and the propagators turn out to be very\nuseful. In particular, the QED concept of the vacuum polarization finds its\nclose counterpart in the photon scattering off a two level-system leading via\nthe linear response theory to the general formulas for the atomic\npolarizability and the dynamic single spin susceptibility. To illustrate the\nusefulness of these methods, we calculate the polarizability and susceptibility\nup to the fourth order of perturbation theory. These {\\em ab initio}\ncalculations resolve some ambiguities concerning the sign prescription and the\noptical damping that arise in the phenomenological treatment. We also show that\nthe methods used to study two-level systems (qubits) can be extended to\nmany-level systems (qudits). As an example, we describe the interaction with\nthe quantized electromagnetic field of an atom with four relevant states: one S\nstate and three degenerate P states.\n", "machine_text": "\nWe propose a new approach to quantum electrodynamics (QED) for qubits. Our approach is based on the combination of the concepts of duality and quantization. We show that, in the limit of large quantum numbers, the electric and magnetic fields can be completely described by only a few degrees of freedom. We obtain a very general and robust framework for QED which is applicable to a large class of qubit systems. Our approach provides a very simple and transparent derivation of the low-energy effective action for QED. Our main result is the derivation of an effective action which contains a term that is singular on the whole space-time and has the structure of a topological charge. We show that this term is related to the geometry of the space-time and does not receive any contribution from the dynamics of the qubit. Our approach has several physical implications. In particular, we show that the singular term can be related to the chirality of the qubit and that it gives rise to a new kind of non-linear dynamics, different from the one associated with the standard conception of QED.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Asynchronous games: innocence without alternation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1118, "human_text": "  The notion of innocent strategy was introduced by Hyland and Ong in order to\ncapture the interactive behaviour of lambda-terms and PCF programs. An innocent\nstrategy is defined as an alternating strategy with partial memory, in which\nthe strategy plays according to its view. Extending the definition to\nnon-alternating strategies is problematic, because the traditional definition\nof views is based on the hypothesis that Opponent and Proponent alternate\nduring the interaction. Here, we take advantage of the diagrammatic\nreformulation of alternating innocence in asynchronous games, in order to\nprovide a tentative definition of innocence in non-alternating games. The task\nis interesting, and far from easy. It requires the combination of true\nconcurrency and game semantics in a clean and organic way, clarifying the\nrelationship between asynchronous games and concurrent games in the sense of\nAbramsky and Melli\\`es. It also requires an interactive reformulation of the\nusual acyclicity criterion of linear logic, as well as a directed variant, as a\nscheduling criterion.\n", "machine_text": "\nAsynchronous games are multiplayer online games that do not require all players to play simultaneously. Asynchronous games can be split into two sub-categories: turn-based games and idle games. Turn-based games are multiplayer games in which players take turns to play the game, while idle games are multiplayer games in which players can play the game at their own pace without having to wait for other players to finish their turns.\n\nAsynchronous games have become increasingly popular in recent years, particularly among players who are unable to play games synchronously due to time zone differences or other commitments. Asynchronous games can also be more convenient for players who prefer to play games at their own pace rather than having to play simultaneously with other players.\n\nThis paper examines the social and gameplay dynamics of asynchronous games, and how these dynamics differ from those of synchronous games. The paper will discuss how the lack of synchronous interaction in asynchronous games affects the formation and maintenance of social bonds between players. The paper will also explore how the lack of synchronous interaction affects the gameplay dynamics of asynchronous games, and how these dynamics differ from those of synchronous games.\n\nThe paper will draw on social capital theory to examine the social dynamics of asynchronous games, and will use game theory to examine the gameplay dynamics of asynchronous games. The paper will conclude by discussing the implications of its findings for the design and development of asynchronous games, and for the future of multiplayer online games more broadly.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anatomy of Malicious Singularities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1416, "human_text": "  As well known, the b-boundaries of the closed Friedman world model and of\nSchwarzschild solution consist of a single point. We study this phenomenon in a\nbroader context of differential and structured spaces. We show that it is an\nequivalence relation $\\rho $, defined on the Cauchy completed total space\n$\\bar{E}$ of the frame bundle over a given space-time, that is responsible for\nthis pathology. A singularity is called malicious if the equivalence class\n$[p_0]$ related to the singularity remains in close contact with all other\nequivalence classes, i.e., if $p_0 \\in \\mathrm{cl}[p]$ for every $p \\in E$. We\nformulate conditions for which such a situation occurs. The differential\nstructure of any space-time with malicious singularities consists only of\nconstant functions which means that, from the topological point of view,\neverything collapses to a single point. It was noncommutative geometry that was\nespecially devised to deal with such situations. A noncommutative algebra on\n$\\bar{E}$, which turns out to be a von Neumann algebra of random operators,\nallows us to study probabilistic properties (in a generalized sense) of\nmalicious singularities. Our main result is that, in the noncommutative regime,\neven the strongest singularities are probabilistically irrelevant.\n", "machine_text": "\n\nWe present a model of malicious singularities, which are defined as singular points in a signal that are of interest for a malicious actor. A malicious singularity can be, for example, the start point of a peak, the tip of a peak, or the start point of a trough. We consider two types of malicious singularities, corresponding to two different types of malicious intent: a simple (unforced) malicious singularity, where the malicious actor is interested in a specific value of a signal, and an iterated (forced) malicious singularity, where the malicious actor iteratively forces the signal to a specific value. We show that malicious singularities can be detected by observing the iterated Laurent series of a given signal. We implement our approach in two steps. In the first step, we use a supervised learning approach to build a model that distinguishes between signals containing malicious singularities and signals that do not. In the second step, we use this model to classify signals containing malicious singularities according to the type of singularity. We demonstrate the efficacy of our approach on simulated data, and we discuss the practical aspects of using our approach on real data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Rational points on certain elliptic surfaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2955, "human_text": "  Let $\\mathcal{E}_{f}:y^2=x^3+f(t)x$, where $f\\in\\Q[t]\\setminus\\Q$, and let us\nassume that $\\op{deg}f\\leq 4$. In this paper we prove that if $\\op{deg}f\\leq\n3$, then there exists a rational base change $t\\mapsto\\phi(t)$ such that on the\nsurface $\\cal{E}_{f\\circ\\phi}$ there is a non-torsion section. A similar\ntheorem is valid in case when $\\op{deg}f=4$ and there exists $t_{0}\\in\\Q$ such\nthat infinitely many rational points lie on the curve\n$E_{t_{0}}:y^2=x^3+f(t_{0})x$. In particular, we prove that if $\\op{deg}f=4$\nand $f$ is not an even polynomial, then there is a rational point on\n$\\cal{E}_{f}$. Next, we consider a surface $\\cal{E}^{g}:y^2=x^3+g(t)$, where\n$g\\in\\Q[t]$ is a monic polynomial of degree six. We prove that if the\npolynomial $g$ is not even, there is a rational base change $t\\mapsto\\psi(t)$\nsuch that on the surface $\\cal{E}^{g\\circ\\psi}$ there is a non-torsion section.\nFurthermore, if there exists $t_{0}\\in\\Q$ such that on the curve\n$E^{t_{0}}:y^2=x^3+g(t_{0})$ there are infinitely many rational points, then\nthe set of these $t_{0}$ is infinite. We also present some results concerning\ndiophantine equation of the form $x^2-y^3-g(z)=t$, where $t$ is a variable.\n", "machine_text": "\n\nWe show that a certain family of elliptic surfaces has a natural decomposition into pieces each of which is isometric to a symmetric product of elliptic curves. The isomorphism classes of such surfaces form an abelian group, with the inverse image of a surface in this group being the surface obtained by inverting the symmetric product. We determine the action of this group on the moduli space of such surfaces. As a special case, we give a description of the singular fibers of the associated Fredholm operator.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: FIRST-based survey of Compact Steep Spectrum sources, V.\n  Milliarcsecond-scale morphology of CSS objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0351, "human_text": "  Multifrequency VLBA observations of the final group of ten objects in a\nsample of FIRST-based compact steep spectrum (CSS) sources are presented. The\nsample was selected to investigate whether objects of this kind could be relics\nof radio-loud AGNs switched off at very early stages of their evolution or\npossibly to indicate intermittent activity. Initial observations were made\nusing MERLIN at 5 GHz. The sources have now been observed with the VLBA at 1.7,\n5 and 8.4 GHz in a snapshot mode with phase-referencing. The resulting maps are\npresented along with unpublished 8.4-GHz VLA images of five sources. Some of\nthe sources discussed here show a complex radio morphology and therefore a\ncomplicated past that, in some cases, might indicate intermittent activity. One\nof the sources studied - 1045+352 - is known as a powerful radio and\ninfrared-luminous broad absorption line (BAL) quasar. It is a young CSS object\nwhose asymmetric two-sided morphology on a scale of several hundred parsecs,\nextending in two different directions, may suggest intermittent activity. The\nyoung age and compact structure of 1045+352 is consistent with the evolution\nscenario of BAL quasars. It has also been confirmed that the submillimetre flux\nof 1045+352 can be seriously contaminated by synchrotron emission.\n", "machine_text": "\n FIRST-based survey of Compact Steep Spectrum sources, V.\n  Milliarcsecond-scale morphology of CSS objects\n  We present photometric observations of the compact steep spectrum (CSS) sources in the FIRST survey. We show that the milliarcsecond-scale morphology of CSS sources is different from that of broad absorption line (BAL) sources, which have a characteristic dumbbell shape. We find that the brightness distribution of a large fraction of CSS sources is well described by a power law. Based on this description we derive a simple model which relates the luminosity and the power law index to the number of components and their luminosities. We find that a large fraction (72%) of CSS sources in our survey have two components. We show that single-component sources can be explained either by the presence of a jet which is either pointed directly towards the observer (43%) or is slightly off-axis (11%), or by a highly absorbed source (36%). We also show that multi-component sources can be explained by the presence of an accretion disc around a central engine, except in cases where the disc is edge-on to the line of sight. We derive a correlation between the optical luminosity and the accretion rate for a subset of the sources with available accretion rates. We discuss the implications of our results for the structure and evolution of these sources.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sunyaev-Zel'dovich profiles and scaling relations: modelling effects and\n  observational biases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2535, "human_text": "  We use high-resolution hydrodynamic re-simulations to investigate the\nproperties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters.\nWe compare results obtained using different physical models for the\nintracluster medium (ICM), and show how they modify the SZ emission in terms of\ncluster profiles and scaling relations. We also produce realistic mock\nobservations to verify whether the results from hydrodynamic simulations can be\nconfirmed. We find that SZ profiles depend marginally on the modelled physical\nprocesses, while they exhibit a strong dependence on cluster mass. The central\nand total SZ emission strongly correlate with the cluster X-ray luminosity and\ntemperature. The logarithmic slopes of these scaling relations differ from the\nself-similar predictions by less than 0.2; the normalization of the relations\nis lower for simulations including radiative cooling. The observational test\nsuggests that SZ cluster profiles are unlikely to be able to probe the ICM\nphysics. The total SZ decrement appears to be an observable much more robust\nthan the central intensity, and we suggest using the former to investigate\nscaling relations.\n", "machine_text": "\nWe present a simple model for the formation of Sunyaev-Zel'dovich (SZ) profiles that accounts for the effect of both the variations in the density distribution and the line-of-sight (LOS) integration. We show that this model predicts several new scaling relations for the SZ profile that are not consistent with the simple SZ model that is often used in practice. The main result of our work is a detailed analysis of the effects that various modelling choices have on the shape of the SZ profile. We show that a proper modelling of the SZ effect requires a good knowledge of the distribution of the electron temperature and density, and that this distribution can be very well described by a model in which the gas is treated as a homogeneous sphere with a constant density and temperature, provided that the sphere is big enough. We also show that in this simple model the SZ effect depends only on the total gas mass, and not on the physical size of the sphere. We derive both lower and upper limits for the relative difference between the observed SZ profile and the prediction of our simple model, and we show that these limits can be used to test the assumption of a spherical distribution. We also discuss the effects of observational biases, such as the beaming and the LOS selection effect. We show that both effects can lead to a significant overestimate of the SZ amplitude.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: TRUFAS, a wavelet based algorithm for the rapid detection of planetary\n  transits. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4557, "human_text": "  Aims: We describe a fast, robust and automatic detection algorithm, TRUFAS,\nand apply it to data that are being expected from the CoRoT mission. Methods:\nThe procedure proposed for the detection of planetary transits in light curves\nworks in two steps: 1) a continuous wavelet transformation of the detrended\nlight curve with posterior selection of the optimum scale for transit\ndetection, and 2) a period search in that selected wavelet transformation. The\ndetrending of the light curves are based on Fourier filtering or a discrete\nwavelet transformation. TRUFAS requires the presence of at least 3 transit\nevents in the data. Results: The proposed algorithm is shown to identify\nreliably and quickly the transits that had been included in a standard set of\n999 light curves that simulate CoRoT data. Variations in the pre-processing of\nthe light curves and in the selection of the scale of the wavelet transform\nhave only little effect on TRUFAS' results. Conclusions: TRUFAS is a robust and\nquick transit detection algorithm, especially well suited for the analysis of\nvery large volumes of data from space or ground-based experiments, with long\nenough durations for the target-planets to produce multiple transit events.\n", "machine_text": "\n\nWe present an algorithm for the rapid detection of planetary transits which is based on the use of wavelets. Our method, TRUFAS (Wavelet Transits), uses the fact that the silhouette of a planet against its host star is a pulse-like function which can be well approximated by a wavelet basis. We show that by using the appropriate scaling parameters the precision of the transit time can be significantly improved over a naive analysis. In particular we show that by using a parameter which corresponds to the characteristic time scale of the transit it is possible to achieve a timing precision which is close to the accuracy limit set by the sampling theorem. We present an analysis of the dependence of our method on the choice of basis function as well as the influence of the choice of scaling parameters. We show that for the particular case of detecting transits in grazing eclipses our method is equivalent to a least-squares fit of the data to a linear function. We present a simulation study which investigates the effect of various realistic noise sources on the precision of the transit time as well as the detectability of the transit. We apply our method to real data obtained from the NASA/ESA Hubble Space Telescope and the ground based Automated Planet Finder and show that in both cases a significant improvement in the transit time precision is obtained.\n\nWe describe the motivation for our work and the key ideas and methodology used. We present the results obtained and discuss the problem the work attempts to solve and any practical or theoretical applications from our findings or implications for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Accretion vs colliding wind models for the gamma-ray binary LS I +61\n  303: an assessment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.132, "human_text": "  LS I +61 303 is a puzzling Be/X-ray binary with variable gamma-ray emission\nat up TeV energies. The nature of the compact object and the origin of the\nhigh-energy emission are unclear. One family of models invokes particle\nacceleration in shocks from the collision between the B-star wind and a\nrelativistic pulsar wind, while another centers on a relativistic jet powered\nby accretion. Recent high-resolution radio observations showing a putative\n\"cometary tail\" pointing away from the Be star near periastron have been cited\nas support for the pulsar-wind model. We wish here to carry out a quantitative\nassessment of these competing models for this extraordinary source. We apply a\n3D SPH code for dynamical simulations of both the pulsar-wind-interaction and\naccretion-jet models. The former yields a description of the shape of the\nwind-wind interaction surface. The latter provides an estimation of the\naccretion rate. The results allow critical evaluation of how the two distinct\nmodels confront the data in various wavebands under a range of conditions. When\none accounts for the 3D dynamical wind interaction under realistic constraints\nfor the relative strength of the B-star and pulsar winds, the resulting form of\nthe interaction front does not match the putative \"cometary tail\" claimed from\nradio observations. On the other hand, dynamical simulations of the\naccretion-jet model indicate that the orbital phase variation of accretion\npower includes a secondary broad peak well away from periastron, thus providing\na plausible way to explain the observed TeV gamma ray emission toward apastron.\nWe conclude that the colliding-wind model is not clearly established for LS I\n+61 303, while the accretion-jet model can reproduce many key characteristics\nof the observed TeV gamma-ray emission.\n", "machine_text": "\nWe present a comparison of the two prominent models for low-mass X-ray binaries (LMXBs): the accretion model and the colliding wind model. The comparison is made for the well-studied LMXB LS I +61\u00b0303, which contains a white dwarf with a relatively long spin period (41.2 \u00b1 1.2 min), a relatively low magnetic field (B_WD \u2248 12 MG), and a rapid accretion rate (up to 10\u2077 met per second), and is therefore well suited to test the two models. We find that both models are able to reproduce basic properties of the system, such as the observed accretion rate and spin period. The accretion model is found to be superior in describing the observed relation between the accretion rate and the spin period, and its ability to reproduce observations is improved by including a parameter that allows for a superposition of two different accretion states. We discuss our results in the framework of a simple model that describes the evolution of the system's orbital and spin parameters as a function of the accretion rate.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Projectile Fragmentation of $^{86}$Kr at 64 MeV/nucleon. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4313, "human_text": "  We measured fragmentation cross sections produced using the primary beam of\n$^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross\nsections were obtained by integrating the momentum distributions of isotopes\nwith 25<Z<36 measured using the RIPS fragment separator at RIKEN. The\ncross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend\non the fragment masses, contrary to the simple geometrical models. We compared\nthe extracted cross sections to EPAX; an empirical parameterization of\nfragmentation cross sections. Predictions from current EPAX parameterization\nseverely overestimate the production cross sections of very neutron-rich\nisotopes. Attempts to obtain another set of EPAX parameters specific to the\nreaction studied here, to extrapolate the neutron-rich nuclei more accurately\nhave not been very successful, suggesting that accurate predictions of\nproduction cross sections of nuclei far from the valley of stability require\ninformation of nuclear properties which are not present in EPAX.\n", "machine_text": "\nWe present here the results of a theoretical investigation of the projectile fragmentation of $^{86}$Kr at 64 MeV/nucleon. The motivation for this work is the recent experiment of Shinozaki et al. which observed the appearance of $^{88}$Rb and $^{90}$Sr in the debris from the collision of a 64 MeV/nucleon $^{86}$Kr projectile with a gold target. We solve the many-body problem for the projectile fragmentation using the molecular dynamics method. The $^{86}$Kr molecule is treated as a compound system consisting of two $^{36}$Kr atoms. We found that the structure of the $^{86}$Kr molecule is stabilized by the pairing interaction, and that the molecular dissociation threshold is about 8 MeV/nucleon. We also found that the individual $^{36}$Kr atoms are more loosely bound than the $^{86}$Kr molecule, and that the $^{36}$Kr atoms are almost collision-free at the incident kinetic energy of 64 MeV/nucleon. Therefore, we conclude that the appearance of $^{88}$Rb and $^{90}$Sr in the Shinozaki et al. experiment was due to the dissociation and subsequent collisional ionization of the $^{86}$Kr molecule, and that the $^{36}$Kr atom did not contribute to the formation of the detected nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fractal analysis for sets of non-differentiability of Minkowski's\n  question mark function. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0453, "human_text": "  In this paper we study various fractal geometric aspects of the Minkowski\nquestion mark function $Q.$ We show that the unit interval can be written as\nthe union of the three sets $\\Lambda_{0}:=\\{x:Q'(x)=0\\}$,\n$\\Lambda_{\\infty}:=\\{x:Q'(x)=\\infty\\}$, and $\\Lambda_{\\sim}:=\\{x:Q'(x)$ does\nnot exist and $Q'(x)\\not=\\infty\\}.$ The main result is that the Hausdorff\ndimensions of these sets are related in the following way.\n$\\dim_{H}(\\nu_{F})<\\dim_{H}(\\Lambda_{\\sim})= \\dim_{H} (\\Lambda_{\\infty}) =\n\\dim_{H} (\\mathcal{L}(h_{\\mathrm{top}}))<\\dim_{H}(\\Lambda_{0})=1.$\n  Here, $\\mathcal{L}(h_{\\mathrm{top}})$ refers to the level set of the\n  Stern-Brocot multifractal decomposition at the topological entropy\n  $h_{\\mathrm{top}}=\\log2$ of the Farey map $F,$ and $\\dim_{H}(\\nu_{F})$\ndenotes the Hausdorff dimension of the measure of maximal entropy of the\ndynamical system associated with $F.$ The proofs rely partially on the\nmultifractal formalism for Stern-Brocot intervals and give non-trivial\napplications of this formalism.\n", "machine_text": "\n\nWe investigate the fractal properties of sets of non-differentiability of Minkowski's ?-function, which is known to be non-analytic and non-smooth in the plane and several complicated fractal properties of this function have been obtained in the past. In this paper, we first prove that the set of non-differentiability of the Minkowski ?-function is itself a fractal set. We show that the fractal dimension of this set is strictly between 2 and 3, which is the first strict evidence showing that the fractal dimension of the set of non-differentiability of a function on the plane has a strictly real value strictly between 2 and 3, without any looseness in the proof. Then we show that the boundary of the fractal set of non-differentiability of the Minkowski ?-function is a fractal set with the fractal dimension strictly between 2 and 3. As a by-product, we show that the boundary of the fractal set of non-differentiability of the function f(x)=x if x is rational and f(x)=0 if x is irrational is a fractal set with the fractal dimension 2.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generic Gravitational Wave Signals from the Collapse of Rotating Stellar\n  Cores: A Detailed Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2675, "human_text": "  We present detailed results from performing general relativistic (GR)\nsimulations of stellar core collapse to a proto-neutron star, using a\nmicrophysical equation of state (EoS) as well as an approximate description of\ndeleptonization during the collapse phase. We show that for a wide variety of\nrotation rates and profiles the gravitational wave (GW) burst signals from the\ncore bounce are of a generic type, already known as Type I in the literature.\nIn addition, for most models the characteristic frequency of the GW burst\nsignal lies in a narrow range around approximately 718 Hz. In our systematic\nstudy, using both GR and Newtonian gravity, we identify, individually quantify,\nand discuss in detail the micro- and macrophysical mechanisms leading to this\nresult, i.e. the effects of rotation, the EoS, and deleptonization. We also\ndiscuss the detectability prospects of such GW burst signals by GW detectors,\nand infer that such a generic type of signal templates will likely facilitate a\nmore efficient search in current and future detectors of both interferometric\nand resonant type.\n", "machine_text": "\nWe consider the generic gravitational signals that would be produced by the implosion of a rotating stellar core. We find that such signals possess many of the characteristics of the gravitational signals detected by LIGO during the past two decades. In particular, we find that (i) the dominant signal frequency is roughly proportional to the inverse of the ratio of the core radius to its mass, (ii) the frequency is largely independent of the initial orbital velocity of the core, and (iii) the detected signal amplitude depends roughly on the cube of the ratio of the core radius to its mass. These findings suggest that core implosion might produce detectable gravitational signals, and could potentially be used as a probe of core properties. We find that the signal amplitude is generally too small to be detected by LIGO for reasonable core masses. However, we show that if the core is composed of a mixture of approximately equal parts of two different elements, the signal amplitude can be increased significantly. We consider several different possible core compositions, and find that a mixture of oxygen and hydrogen, or a mixture of helium and hydrogen, would produce the largest signal amplitudes. We also consider several different physical mechanisms that could potentially drive a rotating core to collapse, and find that none of them would produce a signal with the correct frequency. We conclude that the detection of generic gravitational signals from core implosion is unlikely, unless cores are composed of a mixture of two different elements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in\n  hypre and PETSc. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2626, "human_text": "  We describe our software package Block Locally Optimal Preconditioned\nEigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as\na stand-alone serial library, as an external package to PETSc (``Portable,\nExtensible Toolkit for Scientific Computation'', a general purpose suite of\ntools for the scalable solution of partial differential equations and related\nproblems developed by Argonne National Laboratory), and is also built into {\\it\nhypre} (``High Performance Preconditioners'', scalable linear solvers package\ndeveloped by Lawrence Livermore National Laboratory). The present BLOPEX\nrelease includes only one solver--the Locally Optimal Block Preconditioned\nConjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it\nhypre} provides users with advanced high-quality parallel preconditioners for\nlinear systems, in particular, with domain decomposition and multigrid\npreconditioners. With BLOPEX, the same preconditioners can now be efficiently\nused for symmetric eigenvalue problems. PETSc facilitates the integration of\nindependently developed application modules with strict attention to component\ninteroperability, and makes BLOPEX extremely easy to compile and use with\npreconditioners that are available via PETSc. We present the LOBPCG algorithm\nin BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability\nof BLOPEX by testing it on a number of distributed and shared memory parallel\nsystems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron\nworkstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition\nand {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,\nthe standard 7-point finite-difference approximation of the 3-D Laplacian, with\nthe problem size in the range $10^5-10^8$.\n", "machine_text": "\nWe present a simple block locally optimal preconditioned eigenvalue (BLOPEX) method for solving large symmetric eigenvalue problems in hypre and PETSc. Our approach is motivated by the observation that the standard Generalized Minimum Residual method for eigenvalue problems can be made more robust by combining it with a simple block preconditioner that is optimal in a local sense. We show that such a preconditioner can be constructed by combining a general singular value decomposition algorithm with the diagonal of the input matrix, and that this preconditioner can then be used to define a simple but robust eigenvalue solver. In addition, we show that this eigenvalue solver can be made even more robust by using an approximate inverse of the preconditioner as the block preconditioner. We implement our BLOPEX method in hypre and PETSc, and we evaluate its performance on a wide range of eigenvalue problems. Our results show that BLOPEX can be used to solve very large eigenvalue problems, and that it is both robust and efficient.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 4U 0115+63 from RXTE and INTEGRAL Data: Pulse Profile and Cyclotron Line\n  Energy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2874, "human_text": "  We analyze the observations of the transient X-ray pulsar 4U 0115+63 with the\nRXTE and INTEGRAL observatories in a wide X-ray (3-100 keV) energy band during\nits intense outbursts in 1999 and 2004. The energy of the fundamental harmonic\nof the cyclotron resonance absorption line near the maximum of the X-ray flux\nfrom the source (luminosity range 5x10^{37} - 2x10^{38} erg/s) is ~11 keV. When\nthe pulsar luminosity falls below ~5x10^{37} erg/s, the energy of the\nfundamental harmonic is displaced sharply toward the high energies, up to ~16\nkeV. Under the assumption of a dipole magnetic field configuration, this change\nin cyclotron harmonic energy corresponds to a decrease in the height of the\nemitting region by ~2 km, while other spectral parameters, in particular, the\ncutoff energy, remain essentially constant. At a luminosity ~7x10^{37} erg/s,\nfour almost equidistant cyclotron line harmonics are clearly seen in the\nspectrum. This suggests that either the region where the emission originates is\ncompact or the emergent spectrum from different (in height) segments of the\naccretion column is uniform. We have found significant pulse profile variations\nwith energy, luminosity, and time. In particular, we show that the profile\nvariations from pulse to pulse are not reduced to a simple modulation of the\naccretion rate specified by external conditions.\n", "machine_text": "\n\nWe present observations of the transient source 4U 0115+63 from the Rossi X-ray Timing Explorer (RXTE) and the INTEGRAL Observatory. We use the RXTE observations to construct a pulse profile, and we extract the cyclotron line from the INTEGRAL observation. The source is found to be a compact object with a power law spectrum and a radius of curvature of 1.6 kpc. The transient nature of the source is confirmed by the pulse profile, which shows a exponential decay in the power law index during the observed period. The cyclotron line is well described by a three-component model. The high energy component can be described by an adiabatic expansion model, while the low energy component is best described by a model with two temperature intervals. The broad line component is best described by a model with a large number of emitting regions at different temperatures and with different line-of-sight velocities. The high energy emitting region is probably accreting matter at a very high rate, and has a large number of electrons in the inner edge of the accretion disc. We estimate that the mass of the accreting object is 3-10 times the mass of the Sun. The low energy emitting region has a mass of order of one solar mass. We suggest that the broad line component may be due to a large number of low mass X-ray binaries (LMXBs) in a wide orbit around the object, and that the high energy component may be due to the motion of the LMXBs as they orbit the massive object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Incoherent non-Fermi liquid scattering in a Kondo lattice. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2592, "human_text": "  One of the most notorious non-Fermi liquid properties of both archetypal\nheavy-fermion systems [1-4] and the high-Tc copper oxide superconductors [5] is\nan electrical resistivity that evolves linearly with temperature, T. In the\nheavy-fermion superconductor CeCoIn5 [5], this linear behaviour was one of the\nfirst indications of the presence of a zero-temperature instability, or quantum\ncritical point. Here, we report the observation of a unique control parameter\nof T-linear scattering in CeCoIn5, found through systematic chemical\nsubstitutions of both magnetic and non-magnetic rare-earth, R, ions into the Ce\nsub-lattice. We find that the evolution of inelastic scattering in Ce1-xRxCoIn5\nis strongly dependent on the f-electron configuration of the R ion, whereas two\nother key properties -- Cooper-pair breaking and Kondo-lattice coherence -- are\nnot. Thus, T-linear resistivity in CeCoIn5 is intimately related to the nature\nof incoherent scattering centers in the Kondo lattice, which provides insight\ninto the anomalous scattering rate synonymous with quantum criticality [7].\n", "machine_text": "\nWe have performed a systematic angle-resolved photoemission study of the non-Fermi liquid (NFL) state in a Kondo lattice, an antiferromagnetic system with a strong spin-orbit coupling and a small moment per site. The non-Fermi liquid state is induced by a perpendicular magnetic field applied along the antiferromagnetic direction. Our aim was to understand the origin of the incoherent, low-temperature scattering, which was observed in the NFL state, by investigating the role of the spin-orbit coupling and the lattice structure. We found that the spin-orbit coupling, which distorts the lattice and breaks the time-reversal symmetry, gives rise to a significant increase in the scattering amplitude. In addition, the local moment per site and the existence of a finite number of magnetic ions in the lattice play a crucial role in the emergence of the incoherent, low-temperature scattering. Our results suggest that the incoherent scattering in the non-Fermi liquid state is a generic feature of lattices with a strong spin-orbit coupling and a small moment per site, and that it is closely related to the lattice symmetry and the local moment per site.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Computer simulation of model cohesive powders: influence of assembling\n  procedure and contact laws on low consolidation states. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3295, "human_text": "  The structure and mechanical properties of a simple two-dimensional model of\na cohesive powder are investigated by molecular dynamics simulations.\nMicromechanical ingredients involve elasticity, friction, a short range\nattraction and, possibly, rolling resistance (RR) in contacts. The\nmicrostructure of the cohesive packing varies according to the assembling\nprocedure, from rather densely packed if isolated particles are directly\ncompressed to much looser if the formation of large aggregates is allowed prior\nto compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure\nP, acting on grains of diameter $a$, to maximum tensile contact force F0. At\nlow P* the final structure depends on the level of velocity fluctuations at the\nearly stages of cluster aggregation. With RR the coordination number approaches\n2 in the limit of low initial velocities or large rolling friction. The force\nnetwork generally comprises small hyperstatic clusters with forces of the order\nof F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly\nrearranges into force chain-like patterns. Density correlations witness a\nfractal structure, with dimension Df, up to some density-dependent blob size.\nWIth RR Df coincides with the ballistic aggregation result, despite a possibly\ndifferent connectivity. Possible effects of some parameters on material\nstrength are evoked.\n", "machine_text": "\n\nWe present a systematic investigation of the effects of different contact laws and assembling procedures on the structure and mechanical properties of model cohesive powders. We use a simple and robust algorithm to generate initial particles and combine this with different contact models and consolidation strategies. We show that the choice of contact model has a strong influence on the resulting density and structural properties of the powder. For the simple hard-sphere model, we observe that the contact model has little influence on the final density, while for the more realistic Cohesive Wax model, the choice of contact model has a significant effect on the density and the stress/strain curve. We also find that different assembling procedures can produce powders with very different mechanical properties, in particular for the Cohesive Wax model. Our results suggest that in order to obtain a reliable prediction of the mechanical behavior of cohesive powders, a detailed understanding of the evolution of the contact network during the assembling process is crucial.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Many-to-One Throughput Capacity of IEEE 802.11 Multi-hop Wireless\n  Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0528, "human_text": "  This paper investigates the many-to-one throughput capacity (and by symmetry,\none-to-many throughput capacity) of IEEE 802.11 multi-hop networks. It has\ngenerally been assumed in prior studies that the many-to-one throughput\ncapacity is upper-bounded by the link capacity L. Throughput capacity L is not\nachievable under 802.11. This paper introduces the notion of \"canonical\nnetworks\", which is a class of regularly-structured networks whose capacities\ncan be analyzed more easily than unstructured networks. We show that the\nthroughput capacity of canonical networks under 802.11 has an analytical upper\nbound of 3L/4 when the source nodes are two or more hops away from the sink;\nand simulated throughputs of 0.690L (0.740L) when the source nodes are many\nhops away. We conjecture that 3L/4 is also the upper bound for general\nnetworks. When all links have equal length, 2L/3 can be shown to be the upper\nbound for general networks. Our simulations show that 802.11 networks with\nrandom topologies operated with AODV routing can only achieve throughputs far\nbelow the upper bounds. Fortunately, by properly selecting routes near the\ngateway (or by properly positioning the relay nodes leading to the gateway) to\nfashion after the structure of canonical networks, the throughput can be\nimproved significantly by more than 150%. Indeed, in a dense network, it is\nworthwhile to deactivate some of the relay nodes near the sink judiciously.\n", "machine_text": "\n\nWe investigate the many-to-one throughput capacity of IEEE 802.11 multi-hop wireless networks. In contrast to single-hop networks, where the many-to-one throughput capacity grows proportionally with the number of nodes, the many-to-one throughput capacity of multi-hop networks has a far more complicated growth behavior. We show that the many-to-one throughput capacity of multi-hop networks has a super-exponential growth with the number of nodes when the number of hops is fixed and the wireless link errors are independent and identically distributed. The many-to-one throughput capacity is shown to have a sub-exponential growth with the number of nodes when the number of hops is allowed to vary and/or the wireless link errors are not independent and identically distributed. We also investigate the asymptotic behavior of the many-to-one throughput capacity when the network size grows large and the hops-to-node ratio is fixed. Our results show that the many-to-one throughput capacity is not a sharp threshold, as was previously believed, but a gradual function of the number of nodes. In practical multi-hop networks, the many-to-one throughput capacity is often limited by the finite buffer size in intermediate nodes. We analyze the effect of the buffer size on the many-to-one throughput capacity and show that a sufficient large buffer size is critical to achieve a high many-to-one throughput capacity. We also propose a simple scheme to achieve a high many-to-one throughput capacity in multi-hop networks. simulation results show that our proposed scheme can significantly increase the many-to-one throughput capacity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Towards the optimal window for the 2MASS dipole. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0619, "human_text": "  A comparison of the 2MASS flux dipole to the CMB dipole can serve as a method\nto constrain a combination of the cosmological parameter Omega_m and the\nluminosity bias of the 2MASS survey. For this constraint to be as tight as\npossible, it is necessary to maximize the correlation between the two dipoles.\nThis can be achieved by optimizing the survey window through which the flux\ndipole is measured. Here we explicitly construct such a window for the 2MASS\nsurvey. The optimization in essence reduces to excluding from the calculation\nof the flux dipole galaxies brighter than some limiting magnitude K_min of the\nnear-infrared K_s band. This exclusion mitigates nonlinear effects and shot\nnoise from small scales, which decorrelate the 2MASS dipole from the CMB\ndipole. Under the assumption of negligible shot noise we find that the optimal\nvalue of K_min is about five. Inclusion of shot noise shifts the optimal K_min\nto larger values. We present an analytical formula for shot noise for the 2MASS\nflux dipole, to be used in follow-up work with 2MASS data.\n  The misalignment angle between the two dipoles is a sensitive measure of\ntheir correlation: the higher the correlation, the smaller the expectation\nvalue of the angle. A minimum of the misalignment is thus a sign of the optimal\ngravity window. We model analytically the distribution function for the\nmisalignment angle and show that the misalignment estimated by Maller et al. is\nconsistent with the assumed underlying model (though it is greater than the\nexpectation value). We predict with about 90% confidence that the misalignment\nwill decrease if 2MASS galaxies brighter than K_min = 5 mag are excluded from\nthe calculation of the flux dipole. This prediction has been indirectly\nconfirmed by the results of Erdogdu et al. (ABRIDGED)\n", "machine_text": "\n\nWe present a simple, general method for finding the optimal window for detecting a point source in a spherical harmonic decomposition of a galaxy, as well as the corresponding optimal two-point function window. The method is applied to the problem of detecting the 2MASS dipole in the Galactic potential, using the Cl(...)20mg photographic survey. The analysis is performed in the basis set of the density field, using theKick (!) aperture to determine the optimal detection window. We find that the optimal window is sensitive to the radial aperture, but relatively insensitive to the angular aperture. The optimal window is quite large, and can be approximated by a single shell around the true dipole, with a width of about 60 degrees. We find that a good approximation to the optimal window can be found by assuming that the magnitude of the source is proportional to the local galaxy density, and that the detectability is inversely proportional to the square of the local galaxy density. We show that this approximation is accurate to within a few percent for detectabilities above 4sigma. The optimal window for the two-point function is found by a similar method, and we find that the optimal separation for the 2MASS-redshift experiment is about 1 kpc, independent of the radial aperture used to extract the spherical harmonic decomposition.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Orbifoldes speciales et classification bimeromorphe des varietes\n  kaehleriennes compactes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0737, "human_text": "  This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\\it\ncategory} of geometric orbifolds. These interpolate between (compact K\\\" ahler)\nmanifolds and such manifolds with logarithmic structure. These geometric\norbifolds are considered from the point of view of their geometry, and thus\nequipped with the usual invariants of varieties: morphisms and bimeromorphic\nmaps, differential forms, fundamental groups and universal covers, fields of\ndefinition and rational points. The most elementary properties, directly\nadapted from the case of varieties without orbifold structure, are established\nhere. The arguments of [Ca01] can then be directly adapted to extend the main\nstructure results to this orbifold category. We hope to come back to deeper\naspects later. The motivation is that the natural frame for the theory of\nclassification of compact K\\\" ahler (and complex projective) manifolds includes\nat least the category of orbifolds, as shown in [Ca01] by the fonctorial\ndecomposition of {\\it special} manifolds as tower of orbifolds with either\n$\\kappa_+=-\\infty$ or $\\kappa=0$, and also, seemingly, by the minimal model\nprogram, in which most proofs work only after the adjunction of a \"boundary\".\n  Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds\nextension properties not satisfied in the category of varieties without\norbifold structure, permitting to express invariants of the total space from\nthose of the generic fibre and of the base. For example, the natural sequence\nof fundamental groups is exact there; also the total space is special if so are\nthe generic fibre and the base. This makes this category suitable to lift\nproperties from orbifolds having either $\\kappa_+=-\\infty$ or $\\kappa=0$ to\nthose which are special.\n", "machine_text": "\nOrbifoldes speciales et classification bimeromorphe des varietes kaehleriennes compactes. Cette memoire traite les orbifoldes speciales, dont l'immuable contour entra\u00eene un changement de symmetry, et propose une classification bimeromorphe des vari\u00e9t\u00e9s kaehleriennes compactes. On peut finder le Gone la Grassmannian d'un certain point de l'espace grassesniain, qui est alors isomorphe \u00e0 un certain Claude\u2013Shafarevich sur l'immuable contour. On s'int\u00e9ressera donc \u00e0 la structure des orbifoldes speciales, notamment au fait que certains sont isomorphe \u00e0 un special domaine de $SL_2({\\bf C})$. On s'appuie sur une description \u00e9tale des orbifoldes speciales par certains FAAG-manifolds. Ensuite, on classify les vari\u00e9t\u00e9s kaehleriennes compactes de certains orbifoldes speciales. On peut moreover retrouver certains galaxies isomorphe \u00e0 l'immuable contour. C'est un probl\u00e8me trait\u00e9 plus \u00e9tudiant que les orbifoldes speciales, mais n\u00e9 sur pas mal de d\u00e9veloppements motiviques. On a alors le cas k\u00e4hleriennes cians \u00e0 certains points de l'espace grassesniain, et pour certains elements de l'ordre stable sur l'immuable contour.\n\nWe consider the structure of special orbifolds and the classification of compact K\u00e4hler varieties of special orbifolds. We show that certain special orbifolds are isomorphic to certain FAAG-manifolds, and that every special orbifold can be obtained as an orbit fold of a special orbifold. We show that certain special orbifolds are isomorphic to certain SL2-IR-manifolds. As an application, we show that certain stable elements of the B-metric can be recovered from special orbifolds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anonymity in the Wild: Mixes on unstructured networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.043, "human_text": "  As decentralized computing scenarios get ever more popular, unstructured\ntopologies are natural candidates to consider running mix networks upon. We\nconsider mix network topologies where mixes are placed on the nodes of an\nunstructured network, such as social networks and scale-free random networks.\nWe explore the efficiency and traffic analysis resistance properties of mix\nnetworks based on unstructured topologies as opposed to theoretically optimal\nstructured topologies, under high latency conditions. We consider a mix of\ndirected and undirected network models, as well as one real world case study --\nthe LiveJournal friendship network topology. Our analysis indicates that\nmix-networks based on scale-free and small-world topologies have, firstly,\nmix-route lengths that are roughly comparable to those in expander graphs;\nsecond, that compromise of the most central nodes has little effect on\nanonymization properties, and third, batch sizes required for warding off\nintersection attacks need to be an order of magnitude higher in unstructured\nnetworks in comparison with expander graph topologies.\n", "machine_text": "\n\nWe are motivated by the recent phenomenon of social and information networks, which has received significant attention from the research community and the industry. In particular, we focus on networks where the links do not have associated weights, and therefore, the graph is said to be unstructured. We study the problem of anonymity on unstructured networks. We define anonymity as the property that, for each link, the removal of that link does not change the number of anonymous nodes. We show that anonymity is a generic property of networks, in the sense that it is preserved by a large class of graph operations. We use this fact to characterize anonymity on unstructured networks. We find that the largest anonymous subgraph has a large number of components, and that the average degree of the nodes in this subgraph is small. We show that this result is tight in a sense that, if we consider a particular class of operations that preserve anonymity, the largest anonymous subgraph has the same number of components and the average degree is the same. We complement our study with an experimental investigation of anonymity on real-world networks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SDSS J080531.84+481233.0: An Unresolved L Dwarf/T Dwarf Binary. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1965, "human_text": "  SDSS J080531.84+481233.0 is a peculiar L-type dwarf that exhibits unusually\nblue near-infrared and mid-infrared colors and divergent optical (L4) and\nnear-infrared (L9.5) spectral classifications. These peculiar spectral traits\nhave been variously attributed to condensate cloud effects or subsolar\nmetallicity. Here I present an improved near-infrared spectrum of this source\nwhich further demonstrates the presence of weak CH4 absorption at 1.6 micron\nbut no corresponding band at 2.2 micron. It is shown that these features can be\ncollectively reproduced by the combined light spectrum of a binary with L4.5\nand T5 components, as deduced by spectral template matching. Thus, SDSS\nJ080531.84+481233.0 appears to be a new low-mass binary straddling the L\ndwarf/T dwarf transition, an evolutionary phase for brown dwarfs that remains\npoorly understood by current theoretical models. The case of SDSS\nJ080531.84+481233.0 further illustrates how a select range of L dwarf/T dwarf\nbinaries could be identified and characterized without the need for high\nangular resolution imaging or radial velocity monitoring, potentially\nalleviating some of the detection biases and limitations inherent to such\ntechniques.\n", "machine_text": "\n\nWe present photometric observations of the unique system SDSS J080531.84+481233.0 (hereafter J0805) in the course of four years, which show it to be a close binary consisting of an unresolved L dwarf and a T dwarf in a retrograde orbit. This is the first such system to be discovered. The two components are of similar brightness, which precludes resolving the system with current technology. We find that the orbital period is 1.14 \u00b1 0.09 days, the orbital eccentricity is 0.31 \u00b1 0.04, and the orbital inclination is 124.3 \u00b1 1.5 deg. We compute the masses of the two components to be 1.34 \u00b1 0.07 M\u2299 and 1.00 \u00b1 0.05 M\u2299 (both in the solar mass range), and the radii to be 1.63 \u00b1 0.02 R\u2299 and 1.25 \u00b1 0.01 R\u2299 (measured in solar radii). We estimate the age to be roughly 2 Gyr. We find that the T dwarf has a higher effective temperature than the L dwarf by about 3 kK, a difference that is not sufficient to account for the discrepancy in the observed radii. The spectral types of the two components are in agreement with the definition of the T dwarf spectral class in the former rather than the latter sense, with a spectral type of T6 \u00b1 1 (M6 in the old scheme) for the L dwarf and T7 \u00b1 1 (M7 in the old scheme) for the T dwarf. We estimate the metallicity to be [Fe/H] \u2248 +0.1 for the L dwarf and [Fe/H] \u2248 \u22120.5 for the T dwarf, both in agreement with the solar ratio. We discuss the possible evolutionary history of this and similar systems, and the orbital and physical properties of such systems in general.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Aspects of stochastic resonance in reaction-diffusion systems: The\n  nonequilibrium-potential approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1148, "human_text": "  We analyze several aspects of the phenomenon of stochastic resonance in\nreaction-diffusion systems, exploiting the nonequilibrium potential's\nframework. The generalization of this formalism (sketched in the appendix) to\nextended systems is first carried out in the context of a simplified scalar\nmodel, for which stationary patterns can be found analytically. We first show\nhow system-size stochastic resonance arises naturally in this framework, and\nthen how the phenomenon of array-enhanced stochastic resonance can be further\nenhanced by letting the diffusion coefficient depend on the field. A yet less\ntrivial generalization is exemplified by a stylized version of the\nFitzHugh-Nagumo system, a paradigm of the activator-inhibitor class. After\ndiscussing for this system the second aspect enumerated above, we derive from\nit -through an adiabatic-like elimination of the inhibitor field- an effective\nscalar model that includes a nonlocal contribution. Studying the role played by\nthe range of the nonlocal kernel and its effect on stochastic resonance, we\nfind an optimal range that maximizes the system's response.\n", "machine_text": "\n\nWe propose a nonequilibrium-potential approach to the study of stochastic resonance in reaction-diffusion systems. Stochastic resonance is an interesting phenomenon, which is related to the ability of a dynamical system to amplify weak, random signals. We consider the problem of stochastic resonance in a simple reaction-diffusion model with a nonlinear potential. The analysis is performed by a combination of exact, semi-analytical methods and numerical simulations. We find that the dynamics of the model is characterized by two types of stochastic resonance: a conventional type, which is related to the Hopfield resonance, and an unusual, `` diffusion-controlled '' type, which is associated with a transition to a random Walk-like behavior. We also find a new type of behavior: a resonance-like enhancement of the response to a deterministic input, which is due to the presence of a strong, quadratic potential term in the dynamical equation. Our analysis shows that the different types of resonance are related to the symmetry of the potential function and to the way the resonance is excited. The results are explained in terms of a general theory of stochastic resonance, which is based on the concept of the nonequilibrium potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radio Through X-ray Spectral Energy Distributions of 38 Broad Absorption\n  Line Quasars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0538, "human_text": "  We have compiled the largest sample of multiwavelength spectral energy\ndistributions (SEDs) of Broad Absorption Line (BAL) quasars to date, from the\nradio to the X-ray. We present new Spitzer MIPS (24, 70, and 160 micron)\nobservations of 38 BAL quasars in addition to data from the literature and\npublic archives. In general, the mid-infrared properties of BAL quasars are\nconsistent with those of non-BAL quasars of comparable luminosity. In\nparticular, the optical-to-mid-infrared luminosity ratios of the two\npopulations are indistinguishable. We also measure or place upper limits on the\ncontribution of star formation to the far-infrared power. Of 22 (57%) upper\nlimits, seven quasars have sufficiently sensitive constraints to conclude that\nstar formation likely contributes little (<20%) to their far-infrared power.\nThe 17 BAL quasars (45%) with detected excess far-infrared emission likely host\nhyperluminous starbursts with L_fir,SF=10^{13-14} L_sun. Mid-infrared through\nX-ray composite BAL quasar SEDs are presented, incorporating all of the\navailable photometry. Overall, we find no compelling evidence for inherent\ndifferences between the SEDs of BAL vs. non-BAL quasars of comparable\nluminosity. Therefore a ``cocoon'' picture of a typical BAL quasar outflow\nwhereby the wind covers a large fraction of the sky is not supported by the\nmid-infrared SED comparison with normal quasars, and the disk-wind paradigm\nwith a typical radio-quiet quasar hosting a BAL region remains viable.\n", "machine_text": "\n\nWe present radio spectral energy distributions for 38 broad absorption line (BAL) quasars in the 1.4 < z < 2.2 interval, drawn from a larger sample of 44 quasars. The quasars in our sample have rest frame 6.2 < log(O/H) < 7.2,log(O2/H2) < 1.5, and do not show strong evidence of dust obscuration. We present the radio intensity as a function of frequency and compare the radio spectral energy distribution (R-SED) for quasars with strong and weak BALs. We find that the shape of the R-SED depends sensitively on the strength of the BAL. The R-SEDs for quasars with strong BALs resemble those of broad absorption line galaxies (BALGs), displaying a power law with a break at a frequency that depends on the quasar redshift and optical luminosity. In contrast, the R-SEDs for quasars with weak BALs have a different shape, with a break at a higher frequency. We discuss two possible physical mechanisms that could produce these different R-SED shapes. The R-SEDs for both strong and weak BAL quasars are well described by a single power law with a break at a frequency fbreak = (1.2 \u00b1 1.3) GHz, which is independent of the strength of the BAL, the quasar redshift, or the optical luminosity. The R-SEDs for all quasars in our sample, including those with the weakest BALs, have a common shape with a break at fbreak, suggesting that this shape may be universal for quasars with oxygen abundances characteristic of galactic starbursts. This has implications for models of radio emission from galactic objects, where the break frequency is typically assumed to be universal and determined only by the proton temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Atomic force microscopy (AFM) study of thick lamellar stacks of\n  phospholipid bilayers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0196, "human_text": "  We report an Atomic Force Microscopy (AFM) study on thick multi lamellar\nstacks of approx. 10 mum thickness (about 1500 stacked membranes) of DMPC\n(1,2-dimyristoyl-sn-glycero-3-phoshatidylcholine) deposited on silicon wafers.\nThese thick stacks could be stabilized for measurements under excess water or\nsolution. From force curves we determine the compressional modulus B and the\nrupture force F_r of the bilayers in the gel (ripple), the fluid phase and in\nthe range of critical swelling close to the main transition. AFM allows to\nmeasure the compressional modulus of stacked membrane systems and values for B\ncompare well to values reported in the literature. We observe pronounced\nripples on the top layer in the Pbeta' (ripple) phase and find an increasing\nripple period Lambda_r when approaching the temperature of the main phase\ntransition into the fluid Lalpha phase at about 24 C. Metastable ripples with\n2Lambda_r are observed. Lambda_r also increases with increasing osmotic\npressure, i.e., for different concentrations of polyethylene glycol (PEG).\n", "machine_text": "\n\nAtomic force microscopy (AFM) study of thick lamellar stacks of phospholipid bilayers\n\nThe packing and organization of biological molecules in artificial lipid bilayers is important to understand the mechanisms of cell membranes, the basis of the liposomal drug delivery systems, and the self-assembly of lipids. We used atomic force microscopy (AFM) to image the structure of thick lamellar stacks of lipid bilayers formed by the lipid mixtures of DSPC (1,2-distearoyl-sn-glycero-3-phosphocholine) and DPPG (1,2-dipalmitoyl-sn-glycero-3-phospho-rac-(1-glycerol)). In this system, DSPC and DPPG were in a 3:1 ratio, and the final lipid concentration was 5 mg/ml. We used a Department of Defense AFM with a probe scanner, a Nanosensors NCLAS cantilever with a single-walled carbon nanotube tip, and a fluid cell for AFM imaging in a liquid environment. The images showed that the phospholipid molecules were packed in a lateral orientation, forming a series of layers along the fast scan direction. The distance between the layers was approximately 4 nm, corresponding to the thickness of a single lipid bilayer. The number of layers was larger in the middle of the image, where the structure was more compact and had a higher height, and it gradually decreased toward the edges, where the structure was more open and had a lower height. The difference in height between the compact region and the open region was approximately 2 nm, which was equivalent to the length of a single lipid molecule. The fast scan direction of the image was coincident with the long axis of the lipid molecules, which were highly ordered in the lateral direction. Our results showed that the lipid molecules were packed in a series of ordered layers and the packing was highly dependent on the distribution of molecules.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ballistic Graphene Nanoribbon MOSFETs: a full quantum real-space\n  simulation study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0556, "human_text": "  A real-space quantum transport simulator for carbon nanoribbon (CNR) MOSFETs\nhas been developed. Using this simulator, the performance of carbon nanoribbon\n(CNR) MOSFETs is examined in the ballistic limit. The impact of quantum effects\non device performance of CNR MOSFETs is also studied. We found that 2D\nsemi-infinite graphene contacts provide metal-induced-gap-states (MIGS) in the\nCNR channel. These states would provide quantum tunneling in the short channel\ndevice and cause Fermi level pining. These effects cause device performance\ndegradation both on the ON-state and the OFF-state. Pure 1D devices (infinite\ncontacts), however, show no MIGS. Quantum tunneling effects are still playing\nan important role in the device characteristics. Conduction due to band-to-band\ntunneling is accurately captured in our simulations. It is important in these\ndevices, and found to dominate the off-state current. Based on our simulations,\nboth a 1.4nm wide and a 1.8nm wide CNR with channel length of 12.5nm can\noutperform ultra scaled Si devices in terms of drive current capabilities and\nelectrostatic control. Although subthreshold slopes in the forward-bias\nconduction are better than in Si transistors, tunneling currents are important\nand prevent the achievement of the theoretical limit of 60mV/dec.\n", "machine_text": "\nBallistic Graphene Nanoribbon MOSFETs: a full quantum real-space simulation study\n\nWe present a comprehensive study of the electronic transport properties of ballistic graphene nanoribbon metal-oxide-semiconductor field-effect transistors (MOSFETs) using a full quantum real-space simulation technique. We consider the effect of the transverse size of the graphene nanoribbons on the electronic transport properties of the MOSFETs in the ballistic regime. Our simulation results show a clear and systematic change in the electronic transport properties in response to the transverse size of the graphene nanoribbons. In particular, we find that the ballistic transport regime can be significantly extended by reducing the transverse size of the graphene nanoribbons, and that a unique sub-ballistic transport regime, which cannot be achieved in conventional MOSFETs, can be achieved by further reducing the transverse size of the graphene nanoribbons. We also find that the sub-ballistic transport regime can be probed by adjusting the gate voltage, and that the ballistic and sub-ballistic transport regimes can be seamlessly and simultaneously achieved in the same device by tuning the transverse size of the graphene nanoribbons and the gate voltage. Our findings provide a clear and systematic design guideline for the future development of ballistic graphene nanoribbon MOSFETs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Use of ITIL for Process Optimisation in the IT Service Centre of\n  Harz University, exemplified in the Release Management Process. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2351, "human_text": "  This paper details the use of the IT Infrastructure Library Framework (ITIL)\nfor optimising process workflows in the IT Service Centre of Harz University in\nWernigerode, Germany, exemplified by the Release Management Process. It is\ndescribed, how, during the course of a special ITIL project, the As-Is-Status\nof the various original processes was documented as part of the process life\ncycle and then transformed in the To-Be-Status, according to the ITIL Best\nPractice Framework. It is also shown, how the ITIL framework fits into the\nfour-layered-process model, that could be derived from interviews with the\nuniversities IT support staff, and how the various modified processes\ninterconnect with each other to form a value chain. The paper highlights the\nfinal results of the project and gives an outlook on the future use of ITIL as\na business modelling tool in the IT Service Centre of Harz University. It is\ncurrently being considered, whether the process model developed during the\nproject could be used as a reference model for other university IT centres.\n", "machine_text": "\n\nWe are witnessing a fundamental change in the way IT services are delivered, with a shift from a linear, plan-driven approach to a more agile, service-oriented approach. The move towards agile service management has been motivated by the need to respond more quickly to changing business needs and to improve the overall quality of IT services.\n\nIn this paper, we present a case study of the use of ITIL for process optimisation in the IT service centre of a German university. The case study focuses on the release management process, which is responsible for the deployment of new software releases to the university's IT infrastructure. We describe the current state of the release management process and the challenges that the process faces. We then present our approach to process optimisation, which involves the use of ITIL best practices and the implementation of a new tool for managing software releases.\n\nOur results show that the use of ITIL for process optimisation can lead to significant improvements in the efficiency and effectiveness of IT service delivery. In particular, we found that the implementation of a new tool for managing software releases significantly reduced the effort required to deploy new software releases and improved the overall quality of the releases. We also found that the use of ITIL best practices helped to improve the documentation and communication of the release management process, which in turn led to better coordination and collaboration between the various stakeholders involved in the process.\n\nIn conclusion, we believe that the use of ITIL for process optimisation can be a valuable tool for improving the efficiency and effectiveness of IT service delivery. However, it is important to remember that process optimisation is an ongoing effort, and that the use of ITIL should be adapted to the specific needs and requirements of the organisation in question.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A study of the $p d \\to p d \\eta$ reaction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.153, "human_text": "  A study of the $p d \\to p d \\eta$ reaction in the energy range where the\nrecent data from Uppsala are available, is done in the two-step model of $\\eta$\nproduction including the final state interaction. The $\\eta -d$ final state\ninteraction is incorporated through the solution of the Lippmann Schwinger\nequation using an elastic scattering matrix element, $T_{\\eta d \\to \\eta d}$,\nwhich is required to be half off-shell. It is written in a factorized form,\nwith an off-shell form factor multiplying an on-shell part given by an\neffective range expansion up to the fourth power in momentum. The parameters of\nthis expansion have been taken from an existing recent relativistic Faddeev\nequation solution for the $\\eta NN$ system corresponding to different $\\eta-N$\nscattering amplitudes. Calculations have also been done using few body\nequations within a finite rank approximation (FRA) to generate $T_{\\eta d \\to\n\\eta d}$. The $p-d$ final state interaction is included in the spirit of the\nWatson-Migdal prescription by multiplying the matrix element by the inverse of\nthe Jost function. The $\\eta-d$ interaction is found to be dominant in the\nregion of small invariant $\\eta -d$ mass, $M_{\\eta d}$. The $p-d$ interaction\nenhances the cross section in the whole region of $M_{\\eta d}$, but is larger\nfor large $M_{\\eta d}$. We find nearly isotropic angular distributions of the\nproton and the deuteron in the final state. All the above observations are in\nagreement with data. The production mechanism for the entire range of the\nexisting data on the $p d \\to p d \\eta$ reaction seems to be dominated by the\ntwo-step model of $\\eta$ production.\n", "machine_text": "\nWe have performed a study of the $p d \\to p d \\eta$ reaction and have found that the branching ratio (BR) of this reaction is larger than the theoretical value obtained from the quasiparticle random phase approximation (QRPA) and the statistical model (SM) calculations. We have also found that the BR increases with the $p$-beam energy and that the BR has a strong energy dependence. The ratio of the BR obtained from the measured data to the BR obtained from the QRPA and the SM calculations, $BR_{data}/BR_{theory}$, has a minimum around $4 \\times 10^{-3}$ and increases rapidly for $BR_{data}$ larger than this value. We have also found that the $BR_{data}$ is in good agreement with the QRPA and the SM calculations for $BR_{data}$ less than $4 \\times 10^{-3}$. The probability distribution function (PDF) of the $\\eta$-ray intensity has a maximum at $\\eta_{ray} \\sim 1.4 \\times 10^{-3}$ MeV. We have also found that the excited states of $p$-dlium have a large contribution to the $\\eta$-ray intensity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sharp $L^p$-estimates for maximal operators associated to hypersurfaces\n  in $\\bR^3$ for $p>2.$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1006, "human_text": "  We study the boundedness problem for maximal operators $\\M$ associated to\nsmooth hypersurfaces $S$ in 3-dimensional Euclidean space. For $p>2,$ we prove\nthat if no affine tangent plane to $S$ passes through the origin and $S$ is\nanalytic, then the associated maximal operator is bounded on $L^p(\\RR^3)$ if\nand only if $p>h(S),$ where $h(S)$ denotes the so-called height of the surface\n$S.$ For non-analytic finite type $S$ we obtain the same statement with the\nexception of the exponent $p=h(S).$ Our notion of height $h(S)$ is closely\nrelated to A. N. Varchenko's notion of height $h(\\phi)$ for functions $\\phi$\nsuch that $S$ can be locally represented as the graph of $\\phi$ after a\nrotation of coordinates.\n  Several consequences of this result are discussed. In particular we verify a\nconjecture by E.M. Stein and its generalization by A. Iosevich and E. Sawyer on\nthe connection between the decay rate of the Fourier transform of the surface\nmeasure on $S$ and the $L^p$-boundedness of the associated maximal operator\n$\\M$, and a conjecture by Iosevich and Sawyer which relates the\n$L^p$-boundedness of $\\M$ to an integrability condition on $S$ for the distance\nfunction to tangential hyperplanes, in dimension three.\n  In particular, we also give ess. sharp uniform estimates for the Fourier\ntransform of the surface measure on $S,$ thus extending a result by V.N.\nKarpushkin from the analytic to the smooth setting and implicitly verifying a\nconjecture by V.I. Arnol'd in our context.\n", "machine_text": "\n\nLet $\\bR^3$ be the three-dimensional Euclidean space and let ${{\\mathcal H}}$ be the space of symmetric and positive semi-definite linear operators on $\\bR^3$. We denote by $\\Phi$ the classical Hamilton-Jacobi equation in ${{\\mathcal H}}$, that is, the equation $\\Phi(A)=\\mathrm{Tr}(AB^{-1})$ for all $B\\in {{\\mathcal H}}$. Let ${{\\mathcal M}}$ be the space of the maximal operators on $\\bR^3$, that is, the operators $T$ such that for all $x\\in \\bR^3$, $\\langle Tx, x\\rangle\\geq \\langle x, x\\rangle$. In this paper, we show that the $L^2$-norm of the maximal operator associated to a hypersurface in $\\bR^3$ is lower bounded by a constant depending only on the volume of the hypersurface and the dimension of ${{\\mathcal H}}}$. The sharp $L^2$-estimates for maximal operators associated to hypersurfaces in $\\bR^3$ has been an open problem since it was proposed by Hepp and Hankel in 1880. By employing the ideas developed in the paper, we show that the constant in the lower bound has sharp $L^2$-estimates for the special case ${{\\mathcal M}}}={\\mathcal H}^*$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis of long range order. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4382, "human_text": "  A first principles analysis of order-disorder transition in alloys shows that\nordering energy is a function of temperature due to thermal vibrations. The\ninter-nuclear potential energy term converges if zero point vibrations are\nincorporated and this method can replace the Ewald sum method. Core energy\ncontributions to the ordering energy are stored exclusively in superlattice\nlines. The effect of electron-phonon interactions on ordering energy is of the\nsame order of magnitude as ordering energy near transition temperatures and\ncannot be ignored. Ising model and variants are incorrect in explaining alloy\nphase transitions as they ignore the role of electron-phonon interactions\nwithout justification. A theoretical formalism that incorporates the\nDebye-Waller Factor component of electron-phonon interactions in electronic\nstructure calculations already exists and must be adopted when modeling\ntemperature dependent phenomena. It is suggested that DWF correction will\naccount substantially for the discrepancy between experimental and theoretical\nordering energy in Ni3V. Thermal vibrations alter magnetic ordering energy at\nfinite temperatures. The role of electron-phonon interactions in alloy and\nmagnetic phase transitions cannot be ignored and must be incorporated in all\nmodels. This will also ensure consistency with x-ray and electron diffraction\n(alloy transitions) and neutron diffraction (magnetic transitions) results. An\nisotope effect is predicted for (magnetic) phase transitions if the transition\ntemperature is below Debye temperature. Recent observations of an isotope\neffect in magnetic phase transitions confirm our above conclusions and imply\nthat the role of electron-phonon interactions must be incorporated in all\ntheories and models of magnetism to avoid contradictions.\n", "machine_text": "\n\nWe introduce a simple model that shows how long range order can emerge from a system with short range correlations. The model consists of a random walk on a lattice, with a spectral gap at the transition temperature. We find that long range order is fragile against violations of the assumption of independence of the random walks. We show that in the presence of correlations, long range order can be recovered by a simple renormalization group transformation, if the underlying rules of the random walk are followed. Our results suggest that long range order can be very resilient, if the correlations are not too strong and if the system is not too far from the transition temperature.\n\nWe analyze a simple model of statistical mechanics that consists of a random walk on a lattice, with a spectral gap at the transition temperature. We find that long range order is fragile against violations of the assumption of independence of the random walks. We show that in the presence of correlations, long range order can be recovered by a simple renormalization group transformation, if the underlying rules of the random walk are followed. Our results suggest that long range order can be very resilient, if the correlations are not too strong and if the system is not too far from the transition temperature.\n\nWe analyze a simple model of statistical mechanics that consists of a random walk on a lattice, with a spectral gap at the transition temperature. We find that long range order is fragile against violations of the assumption of independence of the random walks. We show that in the presence of correlations, long range order can be recovered by a simple renormalization group transformation, if the underlying rules of the random walk are followed. Our results suggest that long range order can be very resilient, if the correlations are not too strong and if the system is not too far from the transition temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Discovery of extreme asymmetry in the debris disk surrounding HD 15115. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0645, "human_text": "  We report the first scattered light detection of a dusty debris disk\nsurrounding the F2V star HD 15115 using the Hubble Space Telescope in the\noptical, and Keck adaptive optics in the near-infrared. The most remarkable\nproperty of the HD 15115 disk relative to other debris disks is its extreme\nlength asymmetry. The east side of the disk is detected to ~315 AU radius,\nwhereas the west side of the disk has radius >550 AU. We find a blue optical to\nnear-infrared scattered light color relative to the star that indicates grain\nscattering properties similar to the AU Mic debris disk. The existence of a\nlarge debris disk surrounding HD 15115 adds further evidence for membership in\nthe Beta Pic moving group, which was previously argued based on kinematics\nalone. Here we hypothesize that the extreme disk asymmetry is due to dynamical\nperturbations from HIP 12545, an M star 0.5 degrees (0.38 pc) east of HD 15115\nthat shares a common proper motion vector, heliocentric distance, galactic\nspace velocity, and age.\n", "machine_text": "\n\nDiscovery of extreme asymmetry in the debris disk surrounding HD 15115\nWe present photometric detections of dust emission at 850 and 450 micron around the pre-main sequence star HD 15115. The disk is extremely asymmetric, with the emission extending approximately 30 degrees to the northwest of the star, but only 5 degrees to the southeast. The total mass of the disk is 4.0 x 10^32 kg, with a total radius of 2.1 AU, and an inner edge at 0.6 AU. We estimate the disk's thickness to be 6.2 cm. We conclude that the disk was once much more massive, with a minimum mass of 6.4 x 10^34 kg. This is a factor of more than 2 above the minimum mass necessary to form a planet the size of Jupiter. We therefore expect that this disk will collapse within approximately 2 billion years, and that any planets or planetesimals formed from this disk will be large.\n\nWe present the first detection of extreme asymmetry in the debris disk surrounding a pre-main sequence star. The disk is extremely asymmetric, with the emission extending approximately 30 degrees to the northwest of the star, but only 5 degrees to the southeast. The total mass of the disk is 4.0 x 10^32 kg, with a total radius of 2.1 AU, and an inner edge at 0.6 AU. We estimate the disk's thickness to be 6.2 cm. We conclude that the disk was once much more massive, with a minimum mass of 6.4 x 10^34 kg. This is a factor of more than 2 above the minimum mass necessary to form a planet the size of Jupiter. We therefore expect that this disk will collapse within approximately 2 billion years, and that any planets or planetesimals formed from this disk will be large.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer observations of a 24 micron shadow: Bok Globule CB190. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.224, "human_text": "  We present Spitzer observations of the dark globule CB190 (L771). We observe\na roughly circular 24 micron shadow with a 70 arcsec radius. The extinction\nprofile of this shadow matches the profile derived from 2MASS photometry at the\nouter edges of the globule and reaches a maximum of ~32 visual magnitudes at\nthe center. The corresponding mass of CB190 is ~10 Msun. Our 12CO and 13CO J =\n2-1 data over a 10 arcmin X 10 arcmin region centered on the shadow show a\ntemperature ~10 K. The thermal continuum indicates a similar temperature for\nthe dust. The molecular data also show evidence of freezeout onto dust grains.\nWe estimate a distance to CB190 of 400 pc using the spectroscopic parallax of a\nstar associated with the globule. Bonnor-Ebert fits to the density profile, in\nconjunction with this distance, yield xi_max = 7.2, indicating that CB190 may\nbe unstable. The high temperature (56 K) of the best fit Bonnor-Ebert model is\nin contradiction with the CO and thermal continuum data, leading to the\nconclusion that the thermal pressure is not enough to prevent free-fall\ncollapse. We also find that the turbulence in the cloud is inadequate to\nsupport it. However, the cloud may be supported by the magnetic field, if this\nfield is at the average level for dark globules. Since the magnetic field will\neventually leak out through ambipolar diffusion, it is likely that CB190 is\ncollapsing or in a late pre-collapse stage.\n", "machine_text": "\n\nSpitzer observations of a 24 micron shadow: Bok Globule CB190\nWe present observations of the dust continuum and the CO(1->0) line in Bok Globule CB190, made with the Spitzer Space Telescope. These data are the first to be obtained with Spitzer for a dark cloud in the Galactic globular cluster. The cloud's distance from us is about 13 kpc. The Spitzer data are consistent with a model in which the cloud is a 'atorial' structure, with a central concentration of mass, and pressure, and a nearly isothermal outer shell. The mass of the cloud is 1.4 x 10^5 M_Sun, and the temperature is 9 K. We have found no evidence for a cold core in the cloud. The observed CO line suggests a mass-loss rate of  2 x 10^-7 M_Sun yr^-1. We have compared the observed line-centre luminosity of the CO line with predictions from a simple model, and found that the model predicts too much CO line luminosity for the mass of the cloud. We discuss this finding in the context of the 'slingshot' model for the formation of planetary systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing Explanations of the $B\\to\\phi K^*$ Polarization Puzzle. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3915, "human_text": "  $B\\to\\phi K^*$ ($\\btos$) is three separate decays, one for each polarization\nof the final-state vector mesons (one longitudinal, two transverse). It is\nobserved that the fraction of transverse decays, $\\fT$, and the fraction of\nlongitudinal decays, $\\fL$, are roughly equal: $\\fTfL \\simeq 1$, in opposition\nto the naive expectation that $\\fT \\ll \\fL$. If one requires a single\nexplanation of all polarization puzzles, two possibilities remain within the\nstandard model: penguin annihilation and rescattering. In this paper we examine\nthe predictions of these two explanations for $\\fTfL$ in $\\btod$ decays. In $B\n\\to \\rho\\rho$ decays, only $\\bd \\to \\rho^0\\rho^0$ can possibly exhibit a large\n$\\fTfL$. In B decays related by U-spin, we find two promising possibilities:\n(i) $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$)\nand (ii) $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$\n($\\btod$). The measurement of $\\fTfL$ in these pairs of decays will allow us to\ntest penguin annihilation and rescattering. Finally, it is possible to\ndistinguish penguin annihilation from rescattering by performing a\ntime-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$.\n", "machine_text": "\nWe present an explanation for the puzzle of the $B\\to\\phi K^*$ polarization. We show that the puzzle can be resolved by considering the structure of the helicity amplitudes. The up- and down-transmissions in the $B\\to\\phi K^*$ polarimeter experiment can be related to the amplitudes of a ' standardised' polarimeter, which has an artificial helicity of $\\pm \\frac{\\pi}{2}$ associated with the two possible circular polarizations of the incident $B$ meson. This 'standardised' polarimeter is then related to the standard $B\\to\\phi K^*$ polarimeter, with the 'standard' helicity amplitudes modified by a corrective function which depends on the helicity of the incident $B$ meson. We show that this corrective function can be related to the $B\\to\\pi K^*$ helicity amplitude. In this way the $B\\to\\phi K^*$ puzzle can be viewed as a special case of the general problem of measuring the helicity of a meson. We show that the general problem can be solved by means of a 'standardised' polarimeter, whose read-out is related to the standard polarimeter by a corrective function which depends on the helicity of the incident meson. The method is illustrated by a numerical example.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Reparametrization Invariance, the controversial extraction of $\\alpha$\n  from $B\\to\\pi\\pi$ and New Physics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0174, "human_text": "  The extraction of the weak phase $\\alpha$ from $B\\to\\pi\\pi$ decays has been\ncontroversial from a statistical point of view, as the frequentist vs. bayesian\nconfrontation shows. We analyse several relevant questions which have not\ndeserved full attention and pervade the extraction of $\\alpha$.\nReparametrization Invariance proves appropriate to understand those issues. We\nshow that some Standard Model inspired parametrizations can be senseless or\ninadequate if they go beyond the minimal Gronau and London assumptions: the\nsingle weak phase $\\alpha$ just in the $\\Delta I=3/2$ amplitudes, the isospin\nrelations and experimental data. Beside those analyses, we extract $\\alpha$\nthrough the use of several adequate parametrizations, showing that there is no\nrelevant discrepancy between frequentist and bayesian results. The most\nrelevant information, in terms of $\\alpha$, is the exclusion of values around\n$\\alpha\\sim \\pi/4$; this result is valid in the presence of arbitrary New\nPhysics contributions to the $\\Delta I=1/2$ piece.\n", "machine_text": "\n\nWe show that the weak flavor violating parameter $\\alpha$ can be extracted from the B meson final state produced in $B\\to\\pi\\pi$ collisions, in a way which is largely insensitive to the underlying theory. The extraction is based on the observation that the final state is largely invariant under reparametrization of the longitudinal momenta of the two mesons. We show that this is equivalent to the requirement that the matrix element of a fermionic operator constructed from the longitudinal momenta is conserved. We pay particular attention to the case where the reparametrization invariance is not respected, which we dub the ``controversial'' extraction of $\\alpha$ from $B\\to\\pi\\pi$. We show that such an extraction is equivalent to the assumption that the longitudinal momenta are predetermined, and that this assumption can be made without loss of generality. We show that the reparametrization invariance of the $B\\to\\pi\\pi$ final state is a strong constraint on the dynamics of the system, and can be used to derive a new relation between the $B$ and $D$ meson final states. This relation could be useful in searching for new physics in $B\\to\\pi\\pi$ collisions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The effect of stellar-mass black holes on the structural evolution of\n  massive star clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2494, "human_text": "  We present the results of realistic N-body modelling of massive star clusters\nin the Magellanic Clouds, aimed at investigating a dynamical origin for the\nradius-age trend observed in these systems. We find that stellar-mass black\nholes, formed in the supernova explosions of the most massive cluster stars,\ncan constitute a dynamically important population. If a significant number of\nblack holes are retained (here we assume complete retention), these objects\nrapidly form a dense core where interactions are common, resulting in the\nscattering of black holes into the cluster halo, and the ejection of black\nholes from the cluster. These two processes heat the stellar component,\nresulting in prolonged core expansion of a magnitude matching the observations.\nSignificant core evolution is also observed in Magellanic Cloud clusters at\nearly times. We find that this does not result from the action of black holes,\nbut can be reproduced by the effects of mass-loss due to rapid stellar\nevolution in a primordially mass segregated cluster.\n", "machine_text": "\n\nWe have developed a new method to study the dynamical evolution of massive star clusters in the presence of stellar-mass black holes (BHs). Our method is based on a set of improved secular evolution simulations, which include a realistic distribution of stellar-mass BHs in the galactic field, an improved treatment of the stellar dynamics, and an updated set of initial conditions that include the effects of the feedback from the evicted massive stars. We find that the dynamical evolution of massive star clusters is significantly affected by the presence of stellar-mass BHs, and that the clusters are able to withstand only a small perturbation by these compact objects. Our results suggest that massive star clusters can become stable reservoirs for massive stars in the galactic field, unless disturbed by a massive perturbation, such as a galactic collision. We discuss our results in the context of the recent observations of the stellar-mass BH  M87* and the implications for the dynamical evolution of massive star clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA\n  Networks with Delay QoS Constraints. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1788, "human_text": "  A game-theoretic framework is used to study the effect of constellation size\non the energy efficiency of wireless networks for M-QAM modulation. A\nnon-cooperative game is proposed in which each user seeks to choose its\ntransmit power (and possibly transmit symbol rate) as well as the constellation\nsize in order to maximize its own utility while satisfying its delay\nquality-of-service (QoS) constraint. The utility function used here measures\nthe number of reliable bits transmitted per joule of energy consumed, and is\nparticularly suitable for energy-constrained networks. The best-response\nstrategies and Nash equilibrium solution for the proposed game are derived. It\nis shown that in order to maximize its utility (in bits per joule), a user must\nchoose the lowest constellation size that can accommodate the user's delay\nconstraint. This strategy is different from one that would maximize spectral\nefficiency. Using this framework, the tradeoffs among energy efficiency, delay,\nthroughput and constellation size are also studied and quantified. In addition,\nthe effect of trellis-coded modulation on energy efficiency is discussed.\n", "machine_text": "\nWe propose and analyze a game-theoretic approach to energy-efficient modulation in CDMA networks with delay QoS constraints. We consider a setting where the base stations are energy-constrained and the subscribers are delay-constrained. The base stations and the subscribers are allowed to negotiate over the modulation level to be used. We model this negotiation as a game, where the base stations and the subscribers are the players. We assume that the players are selfish and that they only care about their own utility, which we model as the respective amount of energy or delay. We show that the resulting game has a unique Nash Equilibrium (NE), which we characterize. We then analyze the performance of this NE, in terms of the energy consumption of the network and the delay suffered by the subscribers. We show that the NE achieves a near-optimal tradeoff between these two performance metrics. We also analyze the effect of different factors, such as the number of players, the types of players, and the initial conditions, on the outcome of the game. Finally, we discuss the practical implications of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bayesian reconstruction of the cosmological large-scale structure:\n  methodology, inverse algorithms and numerical optimization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0429, "human_text": "  We address the inverse problem of cosmic large-scale structure reconstruction\nfrom a Bayesian perspective. For a linear data model, a number of known and\nnovel reconstruction schemes, which differ in terms of the underlying signal\nprior, data likelihood, and numerical inverse extra-regularization schemes are\nderived and classified. The Bayesian methodology presented in this paper tries\nto unify and extend the following methods: Wiener-filtering, Tikhonov\nregularization, Ridge regression, Maximum Entropy, and inverse regularization\ntechniques. The inverse techniques considered here are the asymptotic\nregularization, the Jacobi, Steepest Descent, Newton-Raphson,\nLandweber-Fridman, and both linear and non-linear Krylov methods based on\nFletcher-Reeves, Polak-Ribiere, and Hestenes-Stiefel Conjugate Gradients. The\nstructures of the up-to-date highest-performing algorithms are presented, based\non an operator scheme, which permits one to exploit the power of fast Fourier\ntransforms. Using such an implementation of the generalized Wiener-filter in\nthe novel ARGO-software package, the different numerical schemes are\nbenchmarked with 1-, 2-, and 3-dimensional problems including structured white\nand Poissonian noise, data windowing and blurring effects. A novel numerical\nKrylov scheme is shown to be superior in terms of performance and fidelity.\nThese fast inverse methods ultimately will enable the application of sampling\ntechniques to explore complex joint posterior distributions. We outline how the\nspace of the dark-matter density field, the peculiar velocity field, and the\npower spectrum can jointly be investigated by a Gibbs-sampling process. Such a\nmethod can be applied for the redshift distortions correction of the observed\ngalaxies and for time-reversal reconstructions of the initial density field.\n", "machine_text": "\nWe present a new Bayesian methodology for the reconstruction of the large-scale structure of the Universe from galaxy redshift surveys. Our method is based on a hierarchical Bayes model that allows us to infer the underlying large-scale structure at the same time as we fit the observed galaxies to this structure. We show that this method provides a more natural way to infer the large-scale structure than the classical linear inversion method. Our new approach results in a highly non-linear optimization problem, and we present an efficient numerical method to solve this optimization problem. We apply our method to the case of the large-scale structure induced by a Gaussian random field. We show that our method is as efficient as the standard linear method, but that it is much more robust with respect to the choice of the prior and the observed galaxies. We finally discuss the generalization of our method to more complex models, and the implications of our method for the determination of the parameters of the model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Surprising Reversal of Temperatures in the Brown-Dwarf Eclipsing\n  Binary 2MASS J05352184-0546085. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3106, "human_text": "  The newly discovered brown-dwarf eclipsing binary 2MASS J05352184-0546085\nprovides a unique laboratory for testing the predictions of theoretical models\nof brown-dwarf formation and evolution. The finding that the lower-mass brown\ndwarf in this system is hotter than its higher-mass companion represents a\nchallenge to brown-dwarf evolutionary models, none of which predict this\nbehavior. Here we present updated determinations of the basic physical\nproperties of 2M0535-05, bolstering the surprising reversal of temperatures\nwith mass in this system. We compare these measurements with widely used\nbrown-dwarf evolutionary tracks, and find that the temperature reversal can be\nexplained by some models if the components of 2M0535-05 are mildly non-coeval,\npossibly consistent with dynamical simulations of brown-dwarf formation.\nAlternatively, a strong magnetic field on the higher-mass brown dwarf might\nexplain its anomalously low surface temperature, consistent with emerging\nevidence that convection is suppressed in magnetically active, low-mass stars.\nFinally, we discuss future observational and theoretical work needed to further\ncharacterize and understand this benchmark system.\n", "machine_text": "\nWe present photometric observations of the brown-dwarf eclipsing binary 2MASS J05352184-0546085, which show a surprising reversal of temperatures in the primary and secondary components. The system consists of a +62\u00b0C brown dwarf with a mass of 73 MJup, and a \u221234\u00b0C brown dwarf with a mass of 50 MJup. We observe the system in photometric twilight, when the brighter object is occulted by the cooler object. The system has been observed with the 2MASS survey, the Magellan Telescopes, and the Very Large Array. We find that the masses of the two brown dwarfs are too close to be explained by a single mass model in which the masses are equal. This suggests that the system must have formed through the fragmentation of a single object, with the two fragments having very different temperatures. This is the first system in which a significant change in temperature between components has been detected, and the first demonstration that brown-dwarf binaries can be formed by the fragmentation of a single object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anomalous structural and mechanical properties of solids confined in\n  quasi one dimensional strips. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3135, "human_text": "  We show using computer simulations and mean field theory that a system of\nparticles in two dimensions, when confined laterally by a pair of parallel hard\nwalls within a quasi one dimensional channel, possesses several anomalous\nstructural and mechanical properties not observed in the bulk. Depending on the\ndensity $\\rho$ and the distance between the walls $L_y$, the system shows\nstructural characteristics analogous to a weakly modulated liquid, a strongly\nmodulated smectic, a triangular solid or a buckled phase. At fixed $\\rho$, a\nchange in $L_y$ leads to many reentrant discontinuous transitions involving\nchanges in the number of layers parallel to the confining walls depending\ncrucially on the commensurability of inter-layer spacing with $L_y$. The solid\nshows resistance to elongation but not to shear. When strained beyond the\nelastic limit it fails undergoing plastic deformation but surprisingly, as the\nstrain is reversed, the material recovers completely and returns to its\noriginal undeformed state. We obtain the phase diagram from mean field theory\nand finite size simulations and discuss the effect of fluctuations.\n", "machine_text": "\n\nWe have developed a theory of elastic and inelastic properties of solids which are confined in quasi one dimensional strips. We have considered a solid which is resting on a hard substrate and the interfacial traction force is negligible compared to the strength of the solid. Our theory is based on the assumption that the strain energy in the constrained solid is a function of the strain in the thickness direction, the bending moments in the strip, and the shear forces in the strip. We show that, as a result of the interplay between the stiffness of the solid and the constraint provided by the strip, the structural and mechanical properties of the solid in the strip can differ significantly from those of the bulk solid, and these properties can be engineered by suitable design of the strip. In particular, we show that, if the solid is elastic and the strip is wide enough, the solid will not experience any stress even when a large deformation is applied to the strip. On the other hand, if the solid is inelastic and the strip is narrow, the solid can experience stresses which can be higher than the bulk yield stress of the solid. We also discuss the effect of various geometrical parameters of the strip on the structural and mechanical properties of the solid in the strip. Our results can have practical implications in several areas of research including geotechnical and civil engineering, materials science and engineering, and bioengineering.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Optical Source Catalog of the North Ecliptic Pole Region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1182, "human_text": "  We present a five (u*,g',r',i',z') band optical photometry catalog of the\nsources in the North Ecliptic Pole (NEP) region based on deep observations made\nwith MegaCam at CFHT. The source catalog covers about 2 square degree area\ncentered at the NEP and reaches depths of about 26 mag for u*, g', r' bands,\nabout 25 mag for i' band, and about 24 mag for z' band (4 sigma detection over\nan 1 arcsec aperture). The total number of cataloged sources brighter than r'=\n23 mag is about 56,000 including both point sources and extended sources. From\nthe investigation of photometric properties using the color-magnitude diagrams\nand color-color diagrams, we have found that the colors of extended sources are\nmostly (u*-r') < 3.0 and (g'-z') > 0.5. This can be used to separate the\nextended sources from the point sources reliably, even for the faint source\ndomain where typical morphological classification schemes hardly work\nefficiently. We have derived an empirical color-redshift relation of the red\nsequence galaxies using the Sloan Digital Sky Survey data. By applying this\nrelation to our photometry catalog and searching for any spatial overdensities,\nwe have found two galaxy clusters and one nearby galaxy group.\n", "machine_text": "\n\nWe present a catalog of 3,67 \u00d7 10^3 extragalactic optical sources in a half-square degree survey of the North Ecliptic Pole region with Subaru/SuprimeCam. The sources are selected by their colors and by their spatial distribution to be free from galactic contamination. We find a total of 2,755 galaxy groups and 7,702 galaxies in these groups. The catalog galaxy groups have an average redshift of 2.54 \u00b1 0.07, and their number density is 3.01 \u00b1 0.01 groups per square degree. The catalog galaxies have an average redshift of 2.47 \u00b1 0.05, and their number density is 6.13 \u00b1 0.03 galaxies per group. We have verified that our algorithm for detecting galaxy groups is not biased by the distribution of bright stars. This catalog is useful for studying large-scale structure, galaxy formation, and the relationship between the two.\n\nWe present an algorithm to detect galaxy groups in an optical image. We first use a Difference of Gaussians filter to detect galaxies, then use a nearest-neighbor algorithm to group the galaxies according to their spatial distribution, and finally fit a two-dimensional (2D) Kingman statistical graphical model to the galaxy positions to determine the number density of the groups. The number density of groups in our catalog is 3.01 \u00b1 0.01 groups per square degree, consistent with the number density of groups in the 2D universe, as obtained from large-scale structure surveys. This algorithm has several advantages: it is simple and efficient, it does not require an estimate of the background galaxy number density, and it is independent of the galaxy morphology or the survey method. Therefore, this algorithm can be applied to any galaxy catalog to extract groups.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On generalized entropy measures and pathways. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0326, "human_text": "  Product probability property, known in the literature as statistical\nindependence, is examined first. Then generalized entropies are introduced, all\nof which give generalizations to Shannon entropy. It is shown that the nature\nof the recursivity postulate automatically determines the logarithmic\nfunctional form for Shannon entropy. Due to the logarithmic nature, Shannon\nentropy naturally gives rise to additivity, when applied to situations having\nproduct probability property. It is argued that the natural process is\nnon-additivity, important, for example, in statistical mechanics, even in\nproduct probability property situations and additivity can hold due to the\ninvolvement of a recursivity postulate leading to a logarithmic function.\nGeneralizations, including Mathai's generalized entropy are introduced and some\nof the properties are examined. Situations are examined where Mathai's entropy\nleads to pathway models, exponential and power law behavior and related\ndifferential equations. Connection of Mathai's entropy to Kerridge's measure of\n\"inaccuracy\" is also explored.\n", "machine_text": "\n\nWe consider the problem of constructing generalized entropy measures, which are introduced in a recent paper of ours. These measures are constructed by defining the trace of the Local Operator Attribute Value Probability (LOAVP) in a basis of elementary symmetric functions of the underlying attribute values. Here we show that these measures are related to the symplectic and anti-symplectic maps of the underlying attribute space. In particular, we show that if the generalized entropy measure issymplectic, then the underlying attribute space has a Hamiltonian structure, and the generalized entropy is the momentum map of the Hamiltonian system. We also discuss the problem of finding the generalized entropy of a given object (or, equivalently, finding the object whose generalized entropy is a given value), and show that this is an NP-hard problem. We also present a methodology for finding an approximation to the generalized entropy measure of an object, by first finding the symplectic and anti-symplectic maps of the attribute space, and then projecting the desired generalized entropy measure onto the span of the basis of elementary symmetric functions used to define the generalized entropy measure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Massive CP$^1$ theory from a microscopic model for doped\n  antiferromagnets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1918, "human_text": "  A path-integral for the t-J model in two dimensions is constructed based on\nDirac quantization, with an action found originally by Wiegmann (Phys. Rev.\nLett. {\\bf 60}, 821 (1988); Nucl. Phys. B323, 311 (1989)). Concentrating on the\nlow doping limit, we assume short range antiferromagnetic order of the spin\ndegrees of freedom. Going over to a local spin quantization axis of the dopant\nfermions, that follows the spin degree of freedom, staggered CP$^1$ fields\nresult and the constraint against double occupancy can be resolved. The\nstaggered CP$^1$ fields are split into slow and fast modes, such that after a\ngradient expansion, and after integrating out the fast modes and the dopant\nfermions, a CP$^1$ field-theory with a massive gauge field is obtained that\ndescribes generically incommensurate coplanar magnetic structures, as discussed\npreviously in the context of frustrated quantum antiferromagnets. Hence, the\npossibility of deconfined spinons is opened by doping a colinear\nantiferromagnet.\n", "machine_text": "\nWe develop a microscopic model for doped antiferromagnets that exhibits a massive CP$^1$ ground state and investigate the thermodynamic and dynamic properties of the system. We show that the model has a unique ground state with respect to a suitable action functional, and that it is characterized by a non-degenerate peak at the single-particle level. The possible phases of the system are determined by a competition between an extended Kondo effect and a spin-glass-like instability. We find a slow cooling of the system that is accompanied by a continuous shift of the order parameter, and we show that this cooling is anomalously slow compared to the predictions of the Perdew-Burke-Ernzerhof (PBE) approximation. The slow cooling is in direct conflict with the predictions of the Kondo-like theory that is derived from the PBE approximation and that is applicable to the case without a spin-glass-like instability. We also find a temperature dependence of the static structure factor that is in qualitative disagreement with the Kondo-like theory. The slow cooling and the non-Kldoness of the static structure factor can be understood by a dynamic mechanism that is induced by the spin-glass-like instability.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Connecting LHC, ILC, and Quintessence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2375, "human_text": "  If the cold dark matter consists of weakly interacting massive particles\n(WIMPs), anticipated measurements of the WIMP properties at the Large Hadron\nCollider (LHC) and the International Linear Collider (ILC) will provide an\nunprecedented experimental probe of cosmology at temperatures of order 1 GeV.\nIt is worth emphasizing that the expected outcome of these tests may or may not\nbe consistent with the picture of standard cosmology. For example, in\nkination-dominated quintessence models of dark energy, the dark matter relic\nabundance can be significantly enhanced compared to that obtained from freeze\nout in a radiation-dominated universe. Collider measurements then will\nsimultaneously probe both dark matter and dark energy. In this article, we\ninvestigate the precision to which the LHC and ILC can determine the dark\nmatter and dark energy parameters under those circumstances. We use an\nillustrative set of four benchmark points in minimal supergravity in analogy\nwith the four LCC benchmark points. The precision achievable together at the\nLHC and ILC is sufficient to discover kination-dominated quintessence, under\nthe assumption that the WIMPs are the only dark matter component. The LHC and\nILC can thus play important roles as alternative probes of both dark matter and\ndark energy.\n", "machine_text": "\nWe show that LHC and ILC can be connected via a Quintessence scenario in which the messenger field has a complex structure. The model is an extension of the one recently proposed by Degrassi et al. (arXiv:1302.7166). We find that such a model can be made to work in a realistic way, provided that the messenger field is a complex scalar field with a very small (of the order of the Planck scale) non-zero vacuum expectation value, and provided that the messenger field is not introduced as a \"new\" field, but rather as a \"change\" in the dynamics of an already existing (symmetric) scalar field. We show that in this case the dynamics of the symmetric scalar field can be made to display the same features of the standard Quintessence scenario, with a small modification in the parameters. We analyze the model in some detail and find that the new Quintessence scenario has all the features of the standard one, including the ability to give a dynamical explanation to the acceleration of the Universe, the ability to produce a scalar field which has the correct value at the correct time (the so-called \" scalar curate\" problem), and the ability to consistently generate a spectrum of cosmic rays which is in agreement with observations. We also find that the model is consistent with the cosmological constant being exactly zero.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near and Mid-IR Photometry of the Pleiades, and a New List of Substellar\n  Candidate Members. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1832, "human_text": "  We make use of new near and mid-IR photometry of the Pleiades cluster in\norder to help identify proposed cluster members. We also use the new photometry\nwith previously published photometry to define the single-star main sequence\nlocus at the age of the Pleiades in a variety of color-magnitude planes.\n  The new near and mid-IR photometry extend effectively two magnitudes deeper\nthan the 2MASS All-Sky Point Source catalog, and hence allow us to select a new\nset of candidate very low mass and sub-stellar mass members of the Pleiades in\nthe central square degree of the cluster. We identify 42 new candidate members\nfainter than Ks =14 (corresponding to 0.1 Mo). These candidate members should\neventually allow a better estimate of the cluster mass function to be made down\nto of order 0.04 solar masses.\n  We also use new IRAC data, in particular the images obtained at 8 um, in\norder to comment briefly on interstellar dust in and near the Pleiades. We\nconfirm, as expected, that -- with one exception -- a sample of low mass stars\nrecently identified as having 24 um excesses due to debris disks do not have\nsignificant excesses at IRAC wavelengths. However, evidence is also presented\nthat several of the Pleiades high mass stars are found to be impacting with\nlocal condensations of the molecular cloud that is passing through the Pleiades\nat the current epoch.\n", "machine_text": "\n\nWe present a catalogue of low-resolution near-infrared photometry for 78 of the nearest stars to the Sun, drawn from a database of 5 million pixel images taken with the Hubble Space Telescope's Near Infrared Camera and Multi-Object Spectrometer. These data are used to derive the radii, temperatures, and ages of these stars. We find that the confirmed members of the Pleiades, or Seven Sisters, are between 200 and 400 million years old, but that there are many more members in this cluster than are currently listed. A new list of candidate members is presented, including many stars that are more than twice the age of the Sun. We show that many field stars with high proper motion that were previously considered to be members of the Pleiades are instead more distant stars. The ages of the suspected member stars are consistent with a Pleiades age of about 250 million years, with a margin of error of about 50%. This is in agreement with the results of an independent analysis of high-resolution spectroscopy of cluster members. The derived cluster properties are consistent with a simple model in which the cluster has grown by consecutive mergers of Horowitz-Ramsbottom (HR) clouds, the most recent of which was about 250 million years ago. We also present a catalog of mid-infrared photometry for this same group of 78 stars. We find that the mid-infrared colors are consistent with the stars being singly or doubly mantled by dust clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Black Holes and Large N Species Solution to the Hierarchy Problem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.205, "human_text": "  We provide the perturbative and non-perturbative arguments showing that\ntheories with large number of species of the quantum fields, imply an\ninevitable hierarchy between the masses of the species and the Planck scale,\nshedding a different light on the hierarchy problem. In particular, using the\nblack hole physics, we prove that any consistent theory that includes N number\nof the Z_2-conserved species of the quantum fields of mass \\Lambda, puts a\nlower bound on the Planck mass, which in large N limit is given by N\\Lambda^2.\nAn useful byproduct of this proof is that any exactly conserved quantum charge,\nnot associated with a long-range classical field, must be defined maximum\nmodulo N, bounded by the the ratio of the Planck to the unit charge masses\nsquared. For example, a continuous global U(1) `baryon number' symmetry, must\nbe explicitly broken by gravity, at least down to a Z_N subgroup, with N\nbounded by the ratio of the Planck to baryon masses squared. The same\nconstraint applies to any discrete gauge symmetry, as well as to other\nquantum-mechanically detectable black hole charges that are associated with the\nmassive quantum hair of the black hole. We show that the\ngravitationally-coupled N-species sector that solves the gauge hirearchy\nproblem, should be probed by LHC.\n", "machine_text": "\n\nWe show that the higher-dimensional formulation of Einstein's equations, in a suitable choice of coordinates, can be exactly solved for a Schwarzschild black hole, with the solution describing an N-species  fluids interpretation of a black hole, in a large N limit. This is done by an integral transform of the Einstein equations which has as its kernel the species kernel of the Poincare group. This formulation allows a solution of the Einstein equations for an N-species fluids system which asymptotically approaches the solution for a black hole in the limit N \u2192 \u221e. We solve this system of equations numerically in the limit N = 1000, in a grid size independent of the mass M and radius R of the black hole, and find a very good agreement with the exact solution for a Schwarzschild black hole, given in terms of the geodesic collision coordinates. Our result is independent of the choice of the initial conditions, which is an interesting feature of the solution. We discuss the physical and mathematical meanings of our result, in the framework of the Large N approach to quantum gravity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The host galaxies of strong CaII QSO absorption systems at z<0.5. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3462, "human_text": "  We present new imaging and spectroscopic observations of the fields of five\nQSOs with very strong intervening CaII absorption systems at redshifts z<0.5\nselected from the Sloan Digital Sky Survey. Recent studies of these very rare\nabsorbers indicate that they may be related to damped Lyman alpha systems\n(DLAs). In all five cases we identify a galaxy at the redshift of the CaII\nsystem with impact parameters up to ~24 kpc. In four out of five cases the\ngalaxies are luminous (L ~L*), metal-rich (Z ~Zsun), massive (velocity\ndispersion, sigma ~100 km/s) spirals. Their star formation rates, deduced from\nHalpha emission, are high, in the range SFR = 0.3 - 30 Msun/yr. In our\nanalysis, we paid particular attention to correcting the observed emission line\nfluxes for stellar absorption and dust extinction. We show that these effects\nare important for a correct SFR estimate; their neglect in previous low-z\nstudies of DLA-selected galaxies has probably led to an underestimate of the\nstar formation activity in at least some DLA hosts. We discuss possible links\nbetween CaII-selected galaxies and DLAs and outline future observations which\nwill help clarify the relationship between these different classes of QSO\nabsorbers.\n", "machine_text": "\n\nWe present a catalog of galaxies likely to host strong CaII QSO absorption systems at z<0.5, based on a sample of about 500 QSOs with available H-alpha images. The sample is selected from the SDSS, and QSOs with hydrogen halos are excluded. The galaxies in the catalog are candidate luminous galaxies in the redshift range 0.125<=z<=1.5, with a probability of 50% that the QSO is at the same redshift as the host galaxy. The catalog contains 636 galaxies, and the galaxies are found to be slightly more likely to be in clusters than field galaxies. The catalog is useful for studies of large scale structure, galaxy evolution, and the QSO absorption systems themselves.\n\nWe have developed a technique for detecting host galaxies for strong CaII QSO absorption systems at z<0.5. The method relies on identifying likely QSOs in the SDSS with available H-alpha images, and then using the H-alpha images to select candidate host galaxies. We find 636 galaxies in the host galaxy catalog, and the galaxies are slightly more likely to be in clusters than field galaxies. The catalog is useful for studies of large scale structure, galaxy evolution, and the QSO absorption systems themselves.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Tests of Bayesian Model Selection Techniques for Gravitational Wave\n  Astronomy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1808, "human_text": "  The analysis of gravitational wave data involves many model selection\nproblems. The most important example is the detection problem of selecting\nbetween the data being consistent with instrument noise alone, or instrument\nnoise and a gravitational wave signal. The analysis of data from ground based\ngravitational wave detectors is mostly conducted using classical statistics,\nand methods such as the Neyman-Pearson criteria are used for model selection.\nFuture space based detectors, such as the \\emph{Laser Interferometer Space\nAntenna} (LISA), are expected to produced rich data streams containing the\nsignals from many millions of sources. Determining the number of sources that\nare resolvable, and the most appropriate description of each source poses a\nchallenging model selection problem that may best be addressed in a Bayesian\nframework. An important class of LISA sources are the millions of low-mass\nbinary systems within our own galaxy, tens of thousands of which will be\ndetectable. Not only are the number of sources unknown, but so are the number\nof parameters required to model the waveforms. For example, a significant\nsubset of the resolvable galactic binaries will exhibit orbital frequency\nevolution, while a smaller number will have measurable eccentricity. In the\nBayesian approach to model selection one needs to compute the Bayes factor\nbetween competing models. Here we explore various methods for computing Bayes\nfactors in the context of determining which galactic binaries have measurable\nfrequency evolution. The methods explored include a Reverse Jump Markov Chain\nMonte Carlo (RJMCMC) algorithm, Savage-Dickie density ratios, the Schwarz-Bayes\nInformation Criterion (BIC), and the Laplace approximation to the model\nevidence. We find good agreement between all of the approaches.\n", "machine_text": "\nWe present tests of Bayesian model selection techniques for gravitational wave data. Our focus is on the problem of model selection for data containing gravitational waves from multiple sources. We evaluate the ability of the Bayesian information criterion (BIC) and Bayes factor (BF) to distinguish between different models of this data. We find that the BIC is inconsistent and the BF is only marginally consistent with the hypothesis that the correct model is the model that minimizes the BIC or BF. These results suggest that model selection based on the BIC or BF is unlikely to be successful in practice. We also evaluate the performance of model selection using cross-validation. We find that cross-validation is more reliable, although it may still be problematic in practice. Our results suggest that the model selection problem for data containing gravitational waves from multiple sources is non-trivial and that it may be difficult to develop a practical algorithm for model selection in this context.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New smooth hybrid inflation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3786, "human_text": "  We consider the extension of the supersymmetric Pati-Salam model which solves\nthe b-quark mass problem of supersymmetric grand unified models with exact\nYukawa unification and universal boundary conditions and leads to the so-called\nnew shifted hybrid inflationary scenario. We show that this model can also lead\nto a new version of smooth hybrid inflation based only on renormalizable\ninteractions provided that a particular parameter of its superpotential is\nsomewhat small. The potential possesses valleys of minima with classical\ninclination, which can be used as inflationary paths. The model is consistent\nwith the fitting of the three-year Wilkinson microwave anisotropy probe data by\nthe standard power-law cosmological model with cold dark matter and a\ncosmological constant. In particular, the spectral index turns out to be\nadequately small so that it is compatible with the data. Moreover, the\nPati-Salam gauge group is broken to the standard model gauge group during\ninflation and, thus, no monopoles are formed at the end of inflation.\nSupergravity corrections based on a non-minimal Kaehler potential with a\nconvenient choice of a sign keep the spectral index comfortably within the\nallowed range without generating maxima and minima of the potential on the\ninflationary path. So, unnatural restrictions on the initial conditions for\ninflation can be avoided.\n", "machine_text": "\nWe propose and analyze a new hybrid inflation model with smooth terminal conditions. Our approach is based on the construction of a standard deviation of the innovations of a TIME-INNOVATION process, which is related to a proposed new type of theasia.me/en/blog/7567-New-Smooth-Hybrid-Inflation-Model. We show that this new type of inflation model can be nestsort.net/e1/64/64e1f3e03bfc4e7d9eb71e1df49ca3c7/download/ satisfactory for modeling several types of inflation processes. We focus on the simplest case of a geometric process and a pure linear process. In the first case, the model has a locally stationary process as a limiting case, while in the second case, the model converges to a process with a constant level. We also analyze the properties of the proposed model in a more general setting. In particular, we show that the model has a good fit to the data and produces credible intervals for the unknown parameters. We also analyze the sensitivity of our results to the choice of the smoothing parameter. Finally, we point out some possible applications of our results in the context of modeling the dynamics of inflation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Polymer Quantum Mechanics and its Continuum Limit. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0007, "human_text": "  A rather non-standard quantum representation of the canonical commutation\nrelations of quantum mechanics systems, known as the polymer representation has\ngained some attention in recent years, due to its possible relation with Planck\nscale physics. In particular, this approach has been followed in a symmetric\nsector of loop quantum gravity known as loop quantum cosmology. Here we explore\ndifferent aspects of the relation between the ordinary Schroedinger theory and\nthe polymer description. The paper has two parts. In the first one, we derive\nthe polymer quantum mechanics starting from the ordinary Schroedinger theory\nand show that the polymer description arises as an appropriate limit. In the\nsecond part we consider the continuum limit of this theory, namely, the reverse\nprocess in which one starts from the discrete theory and tries to recover back\nthe ordinary Schroedinger quantum mechanics. We consider several examples of\ninterest, including the harmonic oscillator, the free particle and a simple\ncosmological model.\n", "machine_text": "\nWe consider a system of many polymers in solution that interact via an external force that is applied to each pair of polymers. We study the statistical equilibrium of this system, and find that the polymers form clusters whose sizes are given by a power law distribution. This is in contrast to the traditional picture of polymers in solution, where the thermodynamic equilibrium is described by a mean-field theory based on the solution of the mean-field Boltzmann equation. We show that this difference is due to a breakdown of the assumptions that were used to derive the mean-field theory. In particular, we show that the polymer-polymer interactions in the system considered are non-local, and are thus not described by the mean-field theory. We then derive a new theory for the statistical equilibrium in the presence of an external force, which includes a correction to the mean-field theory. The new theory predicts that the polymer clusters become less dense as the external force increases, in clear contrast to the predictions of the mean-field theory. We analyze this disagreement, and show that it is due to the fact that the mean-field theory predicts a non-monotonic dependence of the polymer-polymer interaction strength on the external force, while our theory predicts a strictly monotonic dependence. We then consider the limit of our theory as the number of polymers in the system tends to infinity, and show that it describes a model of polymer quantum mechanics in a Box, which is a system with a large number of infinitely-lived polymers that interact via a non-local potential, and are in statistical equilibrium in the presence of an external force. We analyze this model, and show that it describes a system with anomalous diffusion and ballistic transport, which is analogous to the anomalous behavior observed in recent experiments on pedestrians.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SW Sextantis stars: the dominant population of CVs with orbital periods\n  between 3-4 hours. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1129, "human_text": "  [Abridged] We present time-series optical photometry of five new CVs\nidentified by the Hamburg Quasar Survey. The eclipses observed in HS 0129+2933,\nHS 0220+0603, and HS 0455+8315 provided very accurate orbital periods of\n3.35129827(65), 3.58098501(34), and 3.56937674(26) h, respectively. HS\n0805+3822 shows grazing eclipses and has a likely orbital period of 3.2169(2)\nh. Time-resolved optical spectroscopy of the new CVs (with the exception of HS\n0805+3822) is also presented. Radial velocity studies provided an orbital\nperiod of 3.55 h for HS 1813+6122, which allowed us to identify the observed\nphotometric signal at 3.39 h as a negative superhump wave. The spectroscopic\nbehaviour clearly identifies these new CVs as new SW Sextantis stars. These new\nadditions increase the number of known SW Sex stars to 35. Almost 40 per cent\nof the total SW Sex population do not show eclipses, invalidating the\nrequirement of eclipses as a defining characteristic of the class and the\nmodels based on a high orbital inclination geometry alone. On the other hand,\nthe predominance of orbital periods in the narrow 3-4.5 h range is becoming\nmore pronounced. In fact, almost half the CVs which populate the 3-4.5 h period\ninterval are definite members of the class. These statistics are confirmed by\nour results from the Hamburg Quasar Survey CVs. Remarkably, 54 per cent of the\nHamburg nova-like variables have been identified as SW Sex stars with orbital\nperiods in the 3-4.5 h range. The observation of this pile-up of systems close\nto the upper boundary of the period gap is difficult to reconcile with the\nstandard theory of CV evolution, as the SW Sex stars are believed to have the\nhighest mass transfer rates among CVs. Finally, we review the full range of\ncommon properties that the SW Sex stars exhibit.\n", "machine_text": "\n\nWe present photometric detections of 21 of the 22 SW Sextantis stars with well-determined orbital periods between 3-4 hours. The large majority of these CVs show the characteristic short-period evolutionary properties of the SW Sextantis stars: small-sized spots, high photometric precision, and a temperature-vibration relationship. The exception is HD 3 genetics, which has a relatively large spot and a temperature-ionization relationship. The properties of these CVs are consistent with a dominant population of SW Sextantis stars in the 3-4 hour orbital period regime. We estimate the orbital period distribution of the SW Sextantis stars in this range to be Gaussian with a width of 0.13 hours. We also present evidence that the group may be Complete Mitochondrial DNA (cmDNA) heterogenerous, based on the size-frequency distribution of the spots. If this is the case, the group may have formed through the accretion of satellites around the most massive member. \n\nWe find that the SW Sextantis stars with well-determined orbital periods between 3-4 hours have the same general properties as those with orbital periods between 5-6 hours, except that the latter are generally larger in size and have a higher surface gravity. We conclude that the SW Sextantis stars with orbital periods between 3-4 hours are the dominant population in that range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mixed Meson Masses with Domain-Wall Valence and Staggered Sea Fermions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0572, "human_text": "  Mixed action lattice calculations allow for an additive lattice spacing\ndependent mass renormalization of mesons composed of one sea and one valence\nquark, regardless of the type of fermion discretization methods used in the\nvalence and sea sectors. The value of the mass renormalization depends upon the\nlattice actions used. This mixed meson mass shift is an important lattice\nartifact to determine for mixed action calculations; because it modifies the\npion mass, it plays a central role in the low energy dynamics of all hadronic\ncorrelation functions. We determine the leading order, $\\mathcal{O}(a^2)$, and\nnext to leading order, $\\mathcal{O}(a^2 m_\\pi^2)$, additive mass shift of\n\\textit{valence-sea} mesons for a mixed lattice action with domain-wall valence\nfermions and rooted staggered sea fermions, relevant to the majority of current\nlarge scale mixed action lattice efforts. We find that on the asqtad improved\ncoarse MILC lattices, this additive mass shift is well parameterized in lattice\nunits by $\\Delta(am)^2 = 0.034(2) -0.06(2) (a m_\\pi)^2$, which in physical\nunits, using $a=0.125$ fm, corresponds to $\\Delta(m)^2 = (291\\pm 8\n\\textrm{MeV})^2 -0.06(2) m_\\pi^2$. In terms of the mixed action effective field\ntheory parameters, the corresponding mass shift is given by $a^2\n\\Delta_\\mathrm{Mix} = (316 \\pm 4 \\textrm{MeV})^2$ at leading order plus\nnext-to-leading order corrections including the necessary chiral logarithms for\nthis mixed action calculation, determined in this work. Within the precision of\nour calculation, one can not distinguish between the full next-to-leading order\neffective field theory analysis of this additive mixed meson mass shift and the\nparameterization given above.\n", "machine_text": "\n\nWe study the masses of mesons as a function of the amount of seniority using the domain-wall fermion (DWF) approach. We show that the mass relations in the quark model (QM) can be recovered in the limit of large seniority, where the quark and antiquark contributions to the meson mass are comparable. The main new feature in the DWF approach is that, in addition to the quark and antiquark contributions, there is a finite non-perturbative term in the meson mass. We show that this non-perturbative term is small for light mesons but becomes comparable to the quark and antiquark terms for heavy mesons. As a result, the mass relations for heavy mesons are different from the QM mass relations. We evaluate the meson masses for several realistic DWF parameter sets and find that the predictions of the DWF approach are consistent with the current quark model parametrizations. One exception is the mass of the Strange quark which is larger in the DWF approach. We explain this exception by the fact that the Strange quark is particularly light and therefore is more sensitive to the non-perturbative terms. We also discuss the relation between the DWF and QM approaches to meson masses and find that the two approaches are not fully equivalent. Finally, we show that the DWF approach can be used to study the meson mass singularity and to understand the mechanism of its softening.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: ATLAS sensitivity to Wtb anomalous couplings in top quark decays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3041, "human_text": "  We study the sensitivity of the ATLAS experiment to Wtb anomalous couplings\nin top pair production with semileptonic decay, pp -> t tbar -> W+ b W- bbar,\nwith one of the W bosons decaying leptonically and the other hadronically.\nSeveral observables are examined, including the W helicity fractions and new\nquantities recently introduced, such as the ratios of helicity fractions and\nsome angular asymmetries defined in the W rest frame. The dependence on\nanomalous couplings of all these observables has been previously obtained. In\nthis work we show that some of the new observables also have smaller systematic\nuncertainties than the helicity fractions, with a dependence on anomalous\ncouplings similar or stronger than for helicity fractions. Consequently, their\nmeasurement can significantly improve the limits on anomalous couplings.\nMoreover, the most sensitive measurements can be combined. In this case, the\nprecision achieved in the determination of Wtb anomalous couplings can be of a\nfew percent in the semileptonic channel alone.\n", "machine_text": "\n\nWe present a study of the ATLAS search for a violation of the Wtb unordered flavor symmetry in top quark decays. We consider events with two jets and two missing transverse energy, where one of the jets is identified as a top quark candidate, in the final state. We evaluate the sensitivity of the analysis to a permanent Wtb flavor violation and to a transient Wtb flavor violation. For the permanent case we use the latest ATLAS cross section predictions, and we evaluate the expected number of events in the full 2011 LHC data set, in the 9\u00a0fb\u22121 Run 1 data, and in a future Run 2 data set with the full LHC luminosity. For the transient case we evaluate the sensitivity to a single top quark decay with a lifetime of 1 ns, and to a single top quark decay with a lifetime of 10 ns. The expected number of events in the full 2011 LHC data set, in the 9\u00a0fb\u22121 Run 1 data, and in a future Run 2 data set with the full LHC luminosity is also evaluated. We find that the full LHC data set can yield a clear indication of a permanent Wtb flavor violation, if the underlying theory is able to produce a coupling to the top quark of the order of 1%. A transient Wtb flavor violation can be probed with a single top quark lifetime of \u00a010 ns.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray detection of the substellar twin 2MASS J11011926-7732383 AB. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2301, "human_text": "  2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star\nforming region, is a rare wide-separation brown dwarf binary. XMM-Newton and\nChandra observations of 2M1101AB have allowed us to examine the influence of\nphysical parameters (mass, bolometric luminosity and effective temperature) on\nX-ray emission from a coeval pair of substellar objects. The spatial resolution\nof XMM-Newton is not sufficient to separate contributions from the two\ncomponents in the binary. The X-ray source detected with XMM-Newton has a\ncolumn density compatible with the infrared extinction of component A. On the\nother hand, the binary is resolved with Chandra, and the bulk of the X-ray\nemission is clearly associated with the photospherically cooler component B.\nThese apparently contradictory results point at strong variability of 2M1101's\nX-ray emission. Combined with previous sensitive X-ray observations from\nlow-mass members of ChaI, we find a decline of X-ray luminosity with decreasing\n(sub)stellar mass that is typical for star forming regions. 2M1101B is the\ncoolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in\nX-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members,\nand therefore relatively luminous. Most bona fide brown dwarfs of Cha I have\nremained below the sensitivity limits of available X-ray observations, because\nof their low luminosity associated with higher age.\n", "machine_text": "\n\nWe present photometric detections of the substellar twin 2MASS J11011926-7732383 AB at optical and near-infrared wavelengths using the NASA/ESA Hubble Space Telescope and the VLT/FORS. We find that the photospheres of the stars are not obscured by the disk, in contradiction to previous claims. We also find that the disk is slightly eccentric and inclined to the line joining the two stars, in agreement with the predictions of analytical models. We show that the disk's properties are consistent with a model in which the disk forms via the accretion of planetesimals. The measured disk properties are consistent with a relatively rapid (by solar system standards) migration of the giant planets, a scenario that is supported by dynamical models. The derived mass of the disk is consistent with a mass formed by the accretion of planetesimals but is inconsistent with the mass required to form giant planets by the accretion of planetesimals. We discuss various scenarios that could explain this discrepancy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamic Properties of Molecular Motors in Burnt-Bridge Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.069, "human_text": "  Dynamic properties of molecular motors that fuel their motion by actively\ninteracting with underlying molecular tracks are studied theoretically via\ndiscrete-state stochastic ``burnt-bridge'' models. The transport of the\nparticles is viewed as an effective diffusion along one-dimensional lattices\nwith periodically distributed weak links. When an unbiased random walker passes\nthe weak link it can be destroyed (``burned'') with probability p, providing a\nbias in the motion of the molecular motor. A new theoretical approach that\nallows one to calculate exactly all dynamic properties of motor proteins, such\nas velocity and dispersion, at general conditions is presented. It is found\nthat dispersion is a decreasing function of the concentration of bridges, while\nthe dependence of dispersion on the burning probability is more complex. Our\ncalculations also show a gap in dispersion for very low concentrations of weak\nlinks which indicates a dynamic phase transition between unbiased and biased\ndiffusion regimes. Theoretical findings are supported by Monte Carlo computer\nsimulations.\n", "machine_text": "\n\nDynamic Properties of Molecular Motors in Burnt-Bridge Models\nWe study the dynamic properties of molecular motors in burnt-bridge models. We show that the two main non-trivial dynamic states of the motor, the bound state and the unbound state, can be stable in a large range of parameters, including the extreme cases of very fast and very slow kinetics. We find a large variety of dynamic patterns, including a rich phenomenology of different types of flipping between the bound and unbound state, and different types of trajectories in the unbound state. Our findings are consistent with a large number of physical processes taking place in the dynamics of the motor, which can roughly be divided into two classes, fast and slow processes. The fast processes are related to the energy fluctuations in the motor and to the thermal agitation, and can give rise to a variety of dynamic patterns. The slow processes are related to the tunneling of the ligand molecule towards the binding site, and to the subsequent binding and unbinding. We show that the dynamics of the motor can be very well described by a simple Markov chain, which can be fully optimized, thus providing a powerful tool for the study of the dynamic properties of molecular motors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Charge Polarization Effects and Hole Spectra Characteristics in\n  Alxgai-xN/Gan Superlattices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2735, "human_text": "  We study the effects of charge polarization on the extended physical\nproperties of superlattices, such as transmission coefficients and valence band\nstructure. We consider both linear and parabolic modulation of the band edge.\nBased on the theory of finite periodic systems (TFPS), analytic expressions and\nhigh precision calculations of the relevant physical quantities for n-cell\nsystems are obtained. New and also well-known features of these systems are\nidentified. Besides the well-known energy bandstructure, we also have the field\nbandstructure, with interesting characteristics.Wider field gaps at stronger\ninternal electric fields and higher density of field bands for larger layer\nwidths are some of these characteristics. Well denned level density asymmetries\nidentify the minibands induced by charge polarization or the so-called Quantum\nConfining Stark Effect. We present the n-cell transmission amplitudes,\ntransmission coefficients and miniband structures for different values of the\nrelevant parameters.\n", "machine_text": "\nWe have investigated the charge polarization effects and hole spectra characteristics in AlxGa1-xN/GaN superlattices (SLs) with different aluminum (Al) mole fractions, x, and different periods, P. Both optical and transport measurements are reported. For the optical measurements, we used a mercury lamp as an excitation source, and observed the photoluminescence (PL) and electroluminescence (EL) spectra. We found that the intensities of the satellite peaks in the EL spectra increased as x increased, and the main peak in the EL spectra blue-shifted as P decreased. For the transport measurements, we used an Au electrode as a top contact, and observed the capacitance-voltage (C-V) and current-voltage (I-V) characteristics. We found that the capacitance decreased as x increased, and the conductance increased as P decreased. The ideality factors of the C-V characteristics were greater than one, and the I-V characteristics showed non- ohmic behavior. We also found that the current density was higher when x was greater and P was smaller. These results were explained by considering the structural and optical properties of the SLs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear generalized functions and the Heisenberg-Pauli foundations of\n  Quantum Field Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2396, "human_text": "  In 1929 Heisenberg and Pauli laid the foundations of QFT by quantizing the\nfields (method of canonical quantization). This general theory of quantized\nfields has remained undisputed up to now. We show how the unmodified\nHeisenberg-Pauli calculations make sense mathematically by using a theory of\ngeneralized functions adapted to nonlinear operations. By providing an\nappropriate mathematical setting, nonlinear generalized functions open doors\nfor their understanding but there remains presumably very hard technical\nproblems. (i) Domains of the interacting field operators: a priori the H-P\ncalculations give time dependent dense domains, what is not very convenient;\n(ii) Calculations of the resulting matrix elements of the S operator: from the\nunitarity of the S operator as a whole there are no longer ``infinities,'' but\na priori there is no other hope than heavy computer calculations; (iii)\nConnection with renormalization theory: it should provide an approximation when\nthe coupling constant is small. The aim of this paper is to present, on the\ngrounds of a standard mathematical model of QFT (a self interacting scalar\nboson field), a basis for improvement without significant prerequisites in\nmathematics and physics. It is an attempt to use nonlinear generalized\nfunctions in QFT, starting directly from the calculations made by physicists,\nin the same way as they have already been used in classical mechanics and\ngeneral relativity.\n", "machine_text": "\nWe show that nonlinear generalized functions (NGF) can be used to provide a rigorous theoretical foundation for Quantum Field Theory (QFT) that is free from the limitations of conventional Taylor-series expansions. The conventional expansions are shown to be equivalent to a particular basis set of NGF. The resulting theory is manifestly Lorentz invariant,  symmetric under the exchange of the poisson- sabotages, and yet has a very simple structure that is consistent with the principles of Quantum Theory. In particular, we show that the NGF approach naturally avoids the use of the moment-generating-functionals (MGF) that have been at the basis of much of the controversy and confusion that has surrounded the foundations of QFT. MGF have an interpretation as being related to the inner product of Hilbert space operators, but the NGF approach is strictly manifestly positivist and does not rely on any such interpretation. We show that the NGF basis set is complete, in the sense that any function can be expressed as a linear combination of the basis elements, and yet has a very simple structure that is consistent with the principles of Quantum Theory. The approach is related to the more general approach of Lagrangian Field Theory, but the NGF basis set is shown to be uniquely suited to the requirements of QFT. We also show that the NGF approach can be used to provide a rigorous foundation for the Generalized Lagrangian formalism that has been proposed as a possible alternative to the conventional Lagrangian formalism of QFT. The resulting theory is manifestly Lorentz invariant,  symmetric under the exchange of the poisson-sabotages, and yet has a very simple structure that is consistent with the principles of Quantum Theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Surface Structure in an Accretion Disk Annulus with Comparable Radiation\n  and Gas Pressure. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0314, "human_text": "  We have employed a 3-d energy-conserving radiation MHD code to simulate the\nvertical structure and thermodynamics of a shearing box whose parameters were\nchosen so that the radiation and gas pressures would be comparable. The upper\nlayers of this disk segment are magnetically-dominated, creating conditions\nappropriate for both photon bubble and Parker instabilities. We find little\nevidence for photon bubbles, even though the simulation has enough spatial\nresolution to see them and their predicted growth rates are high. On the other\nhand, there is strong evidence for Parker instabilities, and they appear to\ndominate the evolution of the magnetically supported surface layers. The disk\nphotosphere is complex, with large density inhomogeneities at both the\nscattering and effective (thermalization) photospheres of the evolving\nhorizontally-averaged structure. Both the dominant magnetic support and the\ninhomogeneities are likely to have strong effects on the spectrum and\npolarization of thermal photons emerging from the disk atmosphere. The\ninhomogeneities are also large enough to affect models of reflection spectra\nfrom the atmospheres of accretion disks.\n", "machine_text": "\nWe present surface structure observations in the mid-plane of a fully evacuated annulus, in which a radiative inner wall and a gas-pressurized outer wall are separated by a nearly uniform gap. Our observations show a clear signature of surface waves that we attribute to the presence of a true surface, despite the fact that the dominant surface tension force in the gap is directed radially inward. We attribute this to the comparable strength of the inward-directed surface tension and the outward-directed gas pressure forces. The inner surface is effectively stiffer than the outer surface, due to the higher surface tension. We show that this result can be understood from a simple consideration of the stress equilibrium on the two walls, in the limit of small surface wavelength. We observe a strong correlation between the wavelength of surface structures and the angle between the surface tension force and the radius, which is a direct signature of this effect. We also show that the same considerations would apply to an accretion disk, where the surface tension is balanced by the inward-directed centrifugal force. Our results suggest that the inner edge of the accretion disk is a true surface, despite the fact that the dominant surface tension force is directed radially inward.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bulk viscosity in a cold CFL superfluid. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3909, "human_text": "  We compute one of the bulk viscosity coefficients of cold CFL quark matter in\nthe temperature regime where the contribution of mesons, quarks and gluons to\ntransport phenomena is Boltzmann suppressed. In that regime dissipation occurs\ndue to collisions of superfluid phonons, the Goldstone modes associated to the\nspontaneous breaking of baryon symmetry. We first review the hydrodynamics of\nrelativistic superfluids, and remind that there are at least three bulk\nviscosity coefficients in these systems. We then compute the bulk viscosity\ncoefficient associated to the normal fluid component of the superfluid. In our\nanalysis we use Son's effective field theory for the superfluid phonon, amended\nto include scale breaking effects proportional to the square of the strange\nquark mass m_s. We compute the bulk viscosity at leading order in the scale\nbreaking parameter, and find that it is dominated by collinear splitting and\njoining processes. The resulting transport coefficient is zeta=0.011 m_s^4/T,\ngrowing at low temperature T until the phonon fluid description stops making\nsense. Our results are relevant to study the rotational properties of a compact\nstar formed by CFL quark matter.\n", "machine_text": "\nWe study the bulk viscosity of a cold CFL superfluid, with a focus on the dynamic Casimir effect. We consider the limit in which the bulk viscosity is dominated by the dynamic Casimir effect, and show that the dynamic Casimir effect has a non-monotonic dependence on the temperature. We calculate the bulk viscosity in this limit, and find that it has a minimum at a temperature that depends on the mass of the atoms in the superfluid. We show that this minimum is protected by a mechanism that is analogous to the one that protects the order parameter from becoming positive. We then consider a generalization of the model in which the kinetic energy is not a constant, but is related to the bulk viscosity by a parameter that may be positive or negative. We show that the bulk viscosity in this case has a minimum that is protected by a different mechanism. We then consider the limit in which the kinetic energy is a constant, and show that the bulk viscosity has a minimum at a temperature that depends on the value of the kinetic energy. We finally show that the bulk viscosity has a non-monotonic dependence on the temperature in this limit as well.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-Perturbative Corrections and Modularity in N=1 Type IIB\n  Compactifications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3253, "human_text": "  Non-perturbative corrections and modular properties of four-dimensional type\nIIB Calabi-Yau orientifolds are discussed. It is shown that certain\nnon-perturbative alpha' corrections survive in the large volume limit of the\norientifold and periodically correct the Kahler potential. These corrections\ndepend on the NS-NS two form and have to be completed by D-instanton\ncontributions to transform covariantely under symmetries of the type IIB\norientifold background. It is shown that generically also the D-instanton\nsuperpotential depends on the two-form moduli as well as on the complex\ndilaton. These contributions can arise through theta-functions with the dilaton\nas modular parameter. An orientifold of the Enriques Calabi-Yau allows to\nillustrate these general considerations. It is shown that this compactification\nleads to a controlled four-dimensional N=1 effective theory due to the absence\nof various quantum corrections. Making contact to the underlying topological\nstring theory the D-instanton superpotential is proposed to be related to a\nspecific modular form counting D3, D1, D(-1) degeneracies on the Enriques\nCalabi-Yau.\n", "machine_text": "\nWe study non-perturbative corrections to the quantum structure of N=1 type IIB superconductors in various compactifications of the underlying lattice models. We show that a generic feature of such corrections is the enhancement of the fragmentation functions as compared to the perturbative results. The difference between the two sets of results is particularly large in the case of the so-called kissing number (or Z) models, where it exhibits a series of plateaux, which can be understood in terms of the structure of the associated finitedimensional representations. We show that the corrections can be organised into three categories, which are related to the different flavour structures which occur in the various compactifications. Within each category the structure of the correction is very similar and can be described by a simple modularity argument. The different categories of corrections have different relationships to the perturbative results, and in particular the so-called KT transition in the perturbative theory corresponds to a transition between two of the categories of non-perturbative corrections.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Computing modular polynomials in quasi-linear time. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3177, "human_text": "  We analyse and compare the complexity of several algorithms for computing\nmodular polynomials. We show that an algorithm relying on floating point\nevaluation of modular functions and on interpolation, which has received little\nattention in the literature, has a complexity that is essentially (up to\nlogarithmic factors) linear in the size of the computed polynomials. In\nparticular, it obtains the classical modular polynomials $\\Phi_\\ell$ of prime\nlevel $\\ell$ in time O (\\ell^3 \\log^4 \\ell \\log \\log \\ell). Besides treating\nmodular polynomials for $\\Gamma^0 (\\ell)$, which are an important ingredient in\nmany algorithms dealing with isogenies of elliptic curves, the algorithm is\neasily adapted to more general situations. Composite levels are handled just as\neasily as prime levels, as well as polynomials between a modular function and\nits transform of prime level, such as the Schl\\\"afli polynomials and their\ngeneralisations. Our distributed implementation of the algorithm confirms the\ntheoretical analysis by computing modular equations of record level around\n10000 in less than two weeks on ten processors.\n", "machine_text": "\n\nWe show how to compute, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that remain constant on a proper subspace of $\\mathbb{R}^n$. We show how this relates to the problem of finding, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that are divisible by a given polynomial $f \\in \\mathbb{Z}^n[x]$, and how this, in turn, relates to the problem of computing the dominance order of $f$, that is, the order in which the terms of $f$ dominate one another. We also show how to compute, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that are congruent to a given polynomial modulo a given polynomial $f \\in \\mathbb{Z}^n[x]$, and how this relates to the problem of computing the index of $f$, that is, the smallest non-negative integer $e$ such that $f^e$ is divisible by $x^d$ for some $d$ with $0\\le d\\le n$ (the so-called \"exponent of $f$\"). Finally, we show how to compute, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that are incongruent to a given polynomial modulo a given polynomial $f \\in \\mathbb{Z}^n[x]$, and how this relates to the problem of computing the index of $f$, that is, the smallest non-negative integer $e$ such that $f^e$ is incongruent to the zero polynomial modulo $x^d$ for some $d$ with $0\\le d\\le n$ (the so-called \"exponent of $f$\").", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Three Years of Mira Variable CCD Photometry: What Has Been Learned?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2762, "human_text": "  The subject of micro-variability among Mira stars has received increased\nattention since DeLaverny et al. (1998) reported short-term brightness\nvariations in 15 percent of the 250 Mira or Long Period Variable stars surveyed\nusing the broadband 340 to 890 nm Hp filter on the HIPPARCOS satellite. The\nabrupt variations reported ranged 0.2 to 1.1 magnitudes, on time-scales between\n2 to 100 hours, with a preponderance found nearer Mira minimum light phases.\nHowever, the HIPPARCOS sampling frequency was extremely sparse and required\nconfirmation because of potentially important atmospheric dynamics and\ndust-formation physics that could be revealed. We report on Mira light curve\nsub-structure based on new CCD V and R band data, augmenting the known light\ncurves of Hipparcos-selected long period variables [LPVs], and interpret same\nin terms of [1] interior structure, [2] atmospheric structure change, and/or\n[3] formation of circumstellar [CS] structure. We propose that the alleged\nmicro-variability among Miras is largely undersampled, transient overtone\npulsation structure in the light curves.\n", "machine_text": "\n\nWe present the results of three years of photometric monitoring of the Mira variables with the HST/WFPC2, with a particular focus on the evolution of the accretion phases. We find that accretion episodes of different stars do not have the same duration and that the times when these episodes occur are not exactly periodic, although their length and their occurrence show some degree of periodicity. These results are consistent with a model in which the accretion episodes are triggered by the tidal interaction of the secondary star with the primary, and in which the actual occurrence of accretion episodes is randomly perturbed around a period. We find that the accretion phases can be further divided in two different subphases, which have different durations for each star. We have determined a robust period for the six brighter Mira variables in our sample, and find that the length of the accretion episode is in rough proportion with the period, with a correlation coefficient of 0.91. Our data also reveal that the accretion phases of different stars are not simultaneous, and that they are not exactly symmetric about the mean orbital period. We find that the distribution of the length of the accretion episodes is bimodal, with the bulk of the episodes being of intermediate duration, and that the long and short episodes occur with significantly different probabilities. The Mira variables appear to be in a transition between two different regimes, which have different properties. Our observations are consistent with a model in which the accretion episode is a random process, with the length of the episodes following an exponential distribution, and with the mean length being in proportion with the period. We discuss the implication of our results for the different models proposed to explain the observed accretion episodes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Revisiting the effect of nearby supernova remnants on local cosmic rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3336, "human_text": "  In an earlier paper, the effect of the nearby known supernova remnants (SNRs)\non the local cosmic-rays (CRs) was studied, considering different possible\nforms of the particle injection time. The present work is a continuation of the\nprevious work, but assumes a more realistic model of CR propagation in the\nGalaxy. The previous work assumed an unbounded three-dimensional diffusion\nregion, whereas the present one considers a flat cylindrical disc bounded in\nboth the radial and vertical directions. The study has found that the effect of\nthe vertical halo boundary $H$ on the local SNR contribution to the observed CR\nanisotropy is negligible as long as $H\\gtrsim 2kpc$. Considering the values of\nthe halo height $H\\gtrsim 2kpc$ obtained by different authors, the present work\nsuggests that the study of the effect of local sources on the CR anisotropy can\nbe carried out without having much information on $H$ and hence, using the much\nsimpler three-dimentional unbounded solution. Finally, the present work\ndiscusses about the possibility of explaining the observed anisotropy below the\nknee by a single dominant source with properly chosen source parameters, and\nclaims that the source may be an \\textit{undetected} old SNR with a\ncharacteristic age of $\\sim 1.5\\times 10^5 yr$ located at a distance of $\\sim\n0.57 kpc$ from the Sun.\n", "machine_text": "\n\nWe revisit the effect of nearby supernova (SN) remnants on local cosmic rays (CRs) by analyzing a sample of 51 SN remnants within 50 pc of the Sun and 28 SN events that occurred within 1 kpc of the Sun during the last several million years. We show that the local excess of CRs over the background, as measured by the CR index, is significantly correlated with the rate of SN events within 1 kpc, but is not correlated with the number of nearby SN remnants. This suggests that the local CR excess is due to a combination of the interplanetary transport of CRs from old SN events and the recent termination of the CR injection from nearby SN remnants, but is not due to the continued injection of CRs from these SN remnants. We find that the local CR excess is best described by a power law with an index of 1.89 \u00b1 0.01. This is consistent with a simple model in which the local CR excess is due to a combination of the interplanetary transport of CRs from old SN events and the recent termination of the CR injection from nearby SN remnants, and in which the power law index is determined only by the history of SN events within 1 kpc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Matching WMAP 3-yrs results with the Cosmological Slingshot Primordial\n  Spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0025, "human_text": "  We consider a recently proposed scenario for the generation of primordial\ncosmological perturbations, the so called Cosmological Slingshot scenario. We\nfirstly obtain a general expression for the Slingshot primordial power spectrum\nwhich extends previous results by including a blue pre-bounce residual\ncontribution at large scales. Starting from this expression we numerically\ncompute the CMB temperature and polarization power spectra arising from the\nSlingshot scenario and show that they excellently match the standard WMAP\n3-years best-fit results. In particular, if the residual blue spectrum is far\nabove the largest WMAP observed scale, the Slingshot primordial spectrum fits\nthe data well by only fixing its amplitude and spectral index at the pivot\nscale k_p=10^{-3}h x Mpc^{-1}. We finally show that all possible distinctive\nSlingshot signatures in the CMB power spectra are confined to very low\nmultipoles and thus very hard to detect due to large cosmic variance dominated\nerror bars at these scales.\n", "machine_text": "\nWe present a detailed comparison of the 3-yr WMAP results with the Cosmological Slingshot Primordial Spectrum (COPS) in the regime $10^{-5} \\le q \\le 10^{-3}$. We show that the agreement between the two methods is excellent over the entire range of mass ratios $q$ and for all three elements of the COPS (the Dirac, Flip, and Jazz components). We explain the origin of a small disagreement between the WMAP results and the Flip and Jazz components of the COPS in the regime $q \\sim 10^{-4}$. We show that a simple model in which the primordial spectrum is the COPS multiplied by a small smooth function, can quantitatively reproduce the WMAP results. The model can be further simplified by assuming that the amplitude of the spectrum is inversely proportional to $q^2$. This model can be used to extract the amplitude of the spectrum in the range $q \\sim 10^{-4}$ to $q \\sim 10^{-2}$ with an accuracy comparable to that of the WMAP analysis. We explain why this model is consistent with the assumption that the primordial spectrum is the COPS multiplied by a small smooth function.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structure of the stationary state of the asymmetric target process. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0907, "human_text": "  We introduce a novel migration process, the target process. This process is\ndual to the zero-range process (ZRP) in the sense that, while for the ZRP the\nrate of transfer of a particle only depends on the occupation of the departure\nsite, it only depends on the occupation of the arrival site for the target\nprocess. More precisely, duality associates to a given ZRP a unique target\nprocess, and vice-versa. If the dynamics is symmetric, i.e., in the absence of\na bias, both processes have the same stationary-state product measure. In this\nwork we focus our interest on the situation where the latter measure exhibits a\ncontinuous condensation transition at some finite critical density $\\rho_c$,\nirrespective of the dimensionality. The novelty comes from the case of\nasymmetric dynamics, where the target process has a nontrivial fluctuating\nstationary state, whose characteristics depend on the dimensionality. In one\ndimension, the system remains homogeneous at any finite density. An alternating\nscenario however prevails in the high-density regime: typical configurations\nconsist of long alternating sequences of highly occupied and less occupied\nsites. The local density of the latter is equal to $\\rho_c$ and their\noccupation distribution is critical. In dimension two and above, the asymmetric\ntarget process exhibits a phase transition at a threshold density $\\rho_0$ much\nlarger than $\\rho_c$. The system is homogeneous at any density below $\\rho_0$,\nwhereas for higher densities it exhibits an extended condensate elongated along\nthe direction of the mean current, on top of a critical background with density\n$\\rho_c$.\n", "machine_text": "\n\nWe study the stationary state of the asymmetric simple target process. The motivation for this work is the fact that the stationary state of the asymmetric simple target process has not been studied before, despite the fact that this state is completely deterministic. We show that this stationary state is in general not unique. We then compute the stationary state of the asymmetric simple target process for some special cases, and study its properties. We also show how the knowledge of the stationary state of the asymmetric simple target process can be used to compute the stationary state of some other queueing processes.\n\nThe key ideas and methodology used in this work are the techniques of matrix analysis and the computation of the stationary distribution of queueing processes.\n\nThe results obtained in this work are the computation of the stationary state of the asymmetric simple target process in some special cases, and the obtained properties of this state. We also show how the knowledge of the stationary state of the asymmetric simple target process can be used to compute the stationary state of some other queueing processes.\n\nThis work attempts to solve the problem of computing the stationary state of the asymmetric simple target process, and to study its properties.\n\nThis work has practical applications in the analysis and design of queueing systems with general service time distributions, and in the analysis of the stationary state of some special queueing processes.\n\nThis work also has theoretical applications in the study of the structure of the stationary state of queueing processes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Adjointability of densely defined closed operators and the\n  Magajna-Schweizer Theorem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2576, "human_text": "  In this notes unbounded regular operators on Hilbert $C^*$-modules over\narbitrary $C^*$-algebras are discussed. A densely defined operator $t$\npossesses an adjoint operator if the graph of $t$ is an orthogonal summand.\nMoreover, for a densely defined operator $t$ the graph of $t$ is orthogonally\ncomplemented and the range of $P_FP_{G(t)^\\bot}$ is dense in its biorthogonal\ncomplement if and only if $t$ is regular. For a given $C^*$-algebra $\\mathcal\nA$ any densely defined $\\mathcal A$-linear closed operator $t$ between Hilbert\n$C^*$-modules is regular, if and only if any densely defined $\\mathcal\nA$-linear closed operator $t$ between Hilbert $C^*$-modules admits a densely\ndefined adjoint operator, if and only if $\\mathcal A$ is a $C^*$-algebra of\ncompact operators. Some further characterizations of closed and regular modular\noperators are obtained.\n  Changes 1: Improved results, corrected misprints, added references. Accepted\nby J. Operator Theory, August 2007 / Changes 2: Filled gap in the proof of Thm.\n3.1, changes in the formulations of Cor. 3.2 and Thm. 3.4, updated references\nand address of the second author.\n", "machine_text": "\n\nLet $\\mathcal{H}$ and $\\mathcal{K}$ be Hilbert spaces. We show that a densely defined closed operator $A\\in\\mathcal{L}( \\mathcal{H},\\mathcal{K} )$ is adjointable if and only if $\\mathcal{K}$ is the continuous dual of $\\mathcal{H}$. As a by-product we give a description of the space of all adjointable densely defined closed operators. We show that this space is isomorphic to the space of all continuous linear functionals. As a special case we obtain a characterization of the injective class of all densely defined closed operators. Also we show that the injective class is a linear subspace of the space of all densely defined closed operators. We show that the set of all densely defined closed operators is a linear subspace of the space of all closed operators. We show that every densely defined closed operator can be represented as a limit of an n-multipliers of a positive densely defined closed operator where $n\\in\\mathbb{N}$ and $0\\leq n\\leq\\infty$. We show that every densely defined closed operator can be represented as a limit of an injective class of positive densely defined closed operators. We show that every densely defined closed operator can be represented as a limit of an injective class of positive densely defined closed operators. As a by-product we obtain an alternative description of the injective class of positive densely defined closed operators. We show that every densely defined closed operator can be represented as a limit of an injective class of positive densely defined closed operators. As a by-product we obtain an alternative description of the injective class of positive densely defined closed operators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The velocity structure of moving magnetic feature pairs around sunspots:\n  support for the U-loop model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2507, "human_text": "  Using data recorded by the Michelson Doppler Imager (MDI) instrument on the\nSolar and Heliospheric Observatory (SOHO), we have traced 123 pairs of opposite\nmagnetic polarity moving magnetic features (MMFs) in three active regions NOAA\nARs 8375, 0330 and 9575. At the time of observation, AR 8375 was young, AR 0330\nmature, and AR 9575 decaying. The vertical velocity indicates that the elements\nof MMF pairs with polarity opposite to that of the sunspot support a downflow\nof around 50-100 m s$^{-1}$. The average Doppler shift difference between\nnegative and positive elements of an MMF pair is about 150 m s$^{-1}$ in AR\n8375, 100 m s$^{-1}$ in AR 0330, and 20 m s$^{-1}$ in AR 9575. These\nobservational results are in agreement with the model that MMF pairs are part\nof a U-loop emanating from the sunspot's magnetic canopy. According to this\nmodel the downflow is caused by the Evershed flow returning below the solar\nsurface. For AR 8375, the horizontal velocity of MMFs ranges from 0.1 km\ns$^{-1}$ to 0.7 km s$^{-1}$, and on average, the velocity of an MMF pair\ndecreases significantly (from 0.6 km s$^{-1}$ to 0.35 km s$^{-1}$) with\nincreasing distance from the MMF's birth place. This result suggests that the\nchange in MMF flow speed does not reflect the radial structure of the moat\nflow, but rather is intrinsic to the evolution of the MMF pairs. This result is\nalso in agreement with the U-loop model of MMF pairs. We also find that\nproperties of MMF pairs, most strikingly the lifetime, depend on the evolution\nstages of the parent sunspot. The mean lifetimes of MMF pairs in ARs 9575 and\n0330 are 0.7 hours and 1.6 hours, respectively, which is considerably shorter\nthan the 4 hours lifetime previously found for AR 8375.\n", "machine_text": "\nWe present a detailed analysis of the velocity structure of moving magnetic features (MMFs) around sunspots, based on high-resolution observations of the solar photosphere in the extreme-ultraviolet (EUV) and ultraviolet (UV) wavebands. We find that the majority of MMFs are associated with sunspot pairs, with each member of a pair moving in a different direction. We show that the distribution of MMF velocities is consistent with the U-loop model for the formation of sunspot pairs, in which the motion of the magnetic dipole structure (or \"U-loop\") is the dominant driver of the movement of MMFs. We also find that MMFs around sunspot pairs are on average faster and more elongated than MMFs around single sunspots, consistent with the U-loop model. In addition, we find that the relative velocity between MMFs in a sunspot pair increases with increasing separation, which is also consistent with the U-loop model. Our results provide strong support for the U-loop model of sunspot pair formation and have important implications for our understanding of the dynamics of magnetic fields on the solar surface.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Statistics of the Points Where Nodal Lines Intersect a Reference\n  Curve. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.335, "human_text": "  We study the intersection points of a fixed planar curve $\\Gamma$ with the\nnodal set of a translationally invariant and isotropic Gaussian random field\n$\\Psi(\\bi{r})$ and the zeros of its normal derivative across the curve. The\nintersection points form a discrete random process which is the object of this\nstudy. The field probability distribution function is completely specified by\nthe correlation $G(|\\bi{r}-\\bi{r}'|) = <\\Psi(\\bi{r}) \\Psi(\\bi{r}')>$.\n  Given an arbitrary $G(|\\bi{r}-\\bi{r}'|)$, we compute the two point\ncorrelation function of the point process on the line, and derive other\nstatistical measures (repulsion, rigidity) which characterize the short and\nlong range correlations of the intersection points. We use these statistical\nmeasures to quantitatively characterize the complex patterns displayed by\nvarious kinds of nodal networks. We apply these statistics in particular to\nnodal patterns of random waves and of eigenfunctions of chaotic billiards. Of\nspecial interest is the observation that for monochromatic random waves, the\nnumber variance of the intersections with long straight segments grows like $L\n\\ln L$, as opposed to the linear growth predicted by the percolation model,\nwhich was successfully used to predict other long range nodal properties of\nthat field.\n", "machine_text": "\nWe consider the statistics of the points where Nodal Lines, which are families of lines that intersect a given Reference Curve (RC) in a prescribed manner, intersect the RC. The number of these points is counted and their distribution is analyzed. We find that the points are uniformly distributed along the RC, with a variance that is inversely proportional to the length of the RC. Further analysis shows that the distribution of the points is the same for all Nodal Lines that intersect the RC in the prescribed manner, and hence, the statistics of the points are independent of the particular Nodal Lines chosen. We also derive a simple expression for the variance of the number of points in terms of the parameters of the Nodal Lines and the RC. Our results can be used to test the hypothesis that the points where a given Nodal Line intersect the RC are uniformly distributed along the RC. As an application, we consider the problem of selecting the optimal Nodal Lines to intersect a RC in a way that minimizes the number of points, while at the same time satisfying certain constraints on the Nodal Lines.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: GRB 061121: Broadband spectral evolution through the prompt and\n  afterglow phases of a bright burst. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1609, "human_text": "  Swift triggered on a precursor to the main burst of GRB 061121 (z=1.314),\nallowing observations to be made from the optical to gamma-ray bands. Many\nother telescopes, including Konus-Wind, XMM-Newton, ROTSE and the Faulkes\nTelescope North, also observed the burst. The gamma-ray, X-ray and UV/optical\nemission all showed a peak ~75s after the trigger, although the optical and\nX-ray afterglow components also appear early on - before, or during, the main\npeak. Spectral evolution was seen throughout the burst, with the prompt\nemission showing a clear positive correlation between brightness and hardness.\nThe Spectral Energy Distribution (SED) of the prompt emission, stretching from\n1eV up to 1MeV, is very flat, with a peak in the flux density at ~1keV. The\noptical-to-X-ray spectra at this time are better fitted by a broken, rather\nthan single, power-law, similar to previous results for X-ray flares. The SED\nshows spectral hardening as the afterglow evolves with time. This behaviour\nmight be a symptom of self-Comptonisation, although circumstellar densities\nsimilar to those found in the cores of molecular clouds would be required. The\nafterglow also decays too slowly to be accounted for by the standard models.\nAlthough the precursor and main emission show different spectral lags, both are\nconsistent with the lag-luminosity correlation for long bursts. GRB 061121 is\nthe instantaneously brightest long burst yet detected by Swift. Using a\ncombination of Swift and Konus-Wind data, we estimate an isotropic energy of\n2.8x10^53 erg over 1keV - 10MeV in the GRB rest frame. A probable jet break is\ndetected at ~2x10^5s, leading to an estimate of ~10^51 erg for the\nbeaming-corrected gamma-ray energy.\n", "machine_text": "\n\nWe present observations of the broadband spectral evolution of the Crab Nebula (Cebalragureeb) during the prompt and afterglow phases of the bright burst GRB 061121. Our observations constrain the energy deposition in the inner nebula to be  \u223c 4 kJ assuming a typical expansion velocity of 1,000 km s-1. We find that the ionization and evacuation of the gas by the burst is similar to that expected from a small, local supernova explosion, suggesting that the dominant ionizing radiation in the inner nebula is not the burst but rather the recently discovered soft gamma-ray source SGR 1900+14. We estimate the energy of this source to be  \u223c 5 kJ, which is not only comparable to but possibly larger than the energy deposited by the burst. This indicates that SGR 1900+14 is either a very close supernova (within  \u223c 5 kpc) or an intense radio source with a very high energy density ( \u223c 1014\u20131015 W m-3), perhaps powered by a combination of a black hole, massive stars, and active galactic nucleus. Our results imply that further study of the ionization and evacuation of gas in young and old nebulae by energetic bursts and a better understanding of the relative contributions of burst and non-burst ionizing sources are important to the study of galactic and intergalactic medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Maximum solutions of normalized Ricci flows on 4-manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0714, "human_text": "  We consider maximum solution $g(t)$, $t\\in [0, +\\infty)$, to the normalized\nRicci flow. Among other things, we prove that, if $(M, \\omega) $ is a smooth\ncompact symplectic 4-manifold such that $b_2^+(M)>1$ and let\n$g(t),t\\in[0,\\infty)$, be a solution to (1.3) on $M$ whose Ricci curvature\nsatisfies that $|\\text{Ric}(g(t))|\\leq 3$ and additionally $\\chi(M)=3 \\tau\n(M)>0$, then there exists an $m\\in \\mathbb{N}$, and a sequence of points\n$\\{x_{j,k}\\in M\\}$, $j=1, ..., m$, satisfying that, by passing to a\nsubsequence, $$(M, g(t_{k}+t), x_{1,k},..., x_{m,k})\n\\stackrel{d_{GH}}\\longrightarrow (\\coprod_{j=1}^m N_j, g_{\\infty},\nx_{1,\\infty}, ...,, x_{m,\\infty}),$$ $t\\in [0, \\infty)$, in the $m$-pointed\nGromov-Hausdorff sense for any sequence $t_{k}\\longrightarrow \\infty$, where\n$(N_{j}, g_{\\infty})$, $j=1,..., m$, are complete complex hyperbolic orbifolds\nof complex dimension 2 with at most finitely many isolated orbifold points.\nMoreover, the convergence is $C^{\\infty}$ in the non-singular part of\n$\\coprod_1^m N_{j}$ and\n$\\text{Vol}_{g_{0}}(M)=\\sum_{j=1}^{m}\\text{Vol}_{g_{\\infty}}(N_{j})$, where\n$\\chi(M)$ (resp. $\\tau(M)$) is the Euler characteristic (resp. signature) of\n$M$.\n", "machine_text": "\n\nWe introduce a notion of a solution of a normalized Ricci flow on a 4-manifold. We show that such a solution is uniquely determined up to a constant multiple. We show further that such a solution is smooth (for smooth initial data) and that the set of all such solutions is a linear subspace of the space of all continuous functions on the 4-manifold. We then show that this subspace is closed under the addition of smooth functions, and we show that the intersection of this subspace with the space of all functions smooth up to a constant multiple is a subspace of constant functions. We show that every solution of a normalized Ricci flow on a 4-manifold is a linear combination of smooth functions and constant functions in this fashion. We show further that the set of all such solutions is a closed subset of the space of all continuous functions on the 4-manifold. We show finally that every solution of a normalized Ricci flow on a 4-manifold has a special form: it is a function of the principal parts of the Ricci flow, integrated over the 4-manifold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geometric control theory I: mathematical foundations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2362, "human_text": "  A geometric setup for control theory is presented. The argument is developed\nthrough the study of the extremals of action functionals defined on piecewise\ndifferentiable curves, in the presence of differentiable non-holonomic\nconstraints. Special emphasis is put on the tensorial aspects of the theory. To\nstart with, the kinematical foundations, culminating in the so called\nvariational equation, are put on geometrical grounds, via the introduction of\nthe concept of infinitesimal control . On the same basis, the usual\nclassification of the extremals of a variational problem into normal and\nabnormal ones is also rationalized, showing the existence of a purely\nkinematical algorithm assigning to each admissible curve a corresponding\nabnormality index, defined in terms of a suitable linear map. The whole\nmachinery is then applied to constrained variational calculus. The argument\nprovides an interesting revisitation of Pontryagin maximum principle and of the\nErdmann-Weierstrass corner conditions, as well as a proof of the classical\nLagrange multipliers method and a local interpretation of Pontryagin's\nequations as dynamical equations for a free (singular) Hamiltonian system. As a\nfinal, highly non-trivial topic, a sufficient condition for the existence of\nfinite deformations with fixed endpoints is explicitly stated and proved.\n", "machine_text": "\nWe introduce a geometric framework for control theory. The key idea is to regard the evolution of a dynamical system as the flow of a geometric object, a so-called action functional, along the dynamics. This approach provides a unified framework for such diverse areas of control theory as feedback, hybrid systems, and control of partial differential equations. In the first part of the paper, we develop the mathematical foundations of this approach. We show that the evolution of an action functional along a system of differential equations is governed by a second order differential equation, the so-called geometric differential equation. We study some basic properties of this equation. In the second part of the paper, we apply our geometric framework to feedback control theory. We show how to characterize feedback stabilizing controllers in terms of the solutions of the geometric differential equation. Our results generalize classical feedback theory in several ways. In particular, we show that a controller which is stabilizing for a family of related dynamical systems need not be stabilizing for any individual system in the family.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Primordial Evolution in the Finitary Process Soup. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3771, "human_text": "  A general and basic model of primordial evolution--a soup of reacting\nfinitary and discrete processes--is employed to identify and analyze\nfundamental mechanisms that generate and maintain complex structures in\nprebiotic systems. The processes--$\\epsilon$-machines as defined in\ncomputational mechanics--and their interaction networks both provide well\ndefined notions of structure. This enables us to quantitatively demonstrate\nhierarchical self-organization in the soup in terms of complexity. We found\nthat replicating processes evolve the strategy of successively building higher\nlevels of organization by autocatalysis. Moreover, this is facilitated by local\ncomponents that have low structural complexity, but high generality. In effect,\nthe finitary process soup spontaneously evolves a selection pressure that\nfavors such components. In light of the finitary process soup's generality,\nthese results suggest a fundamental law of hierarchical systems: global\ncomplexity requires local simplicity.\n", "machine_text": "\nWe present a study of the evolution of complex behaviors in the finitary process soup, a simple abstract model of evolutionary systems. We show that a large class of behavior-substrate pairs leads to a victorian explosion of behavior, a phenomenon in which new behaviors rapidly overpopulate the space of behaviors, and then slowly die out, with the population of behaviors eventually converging to a stationary distribution. We show that the dynamics of this process is in fact the dynamics of an associated generalized finitary model, a generalization of the finitary process soup to allow for behaviors with non-trivial structure. We then consider the evolution of more complex behaviors, and show that the same dynamics applies, with the additional feature that the limit distribution of behaviors is not stationary, but rather evolving in a manner that depends on the original behavior-substrate pair. We then consider the evolution of still more complex behaviors, and show that this evolution is more complicated, with the additional feature that the evolved behaviors are not always the most fit for the environment, but rather that the most fit behaviors are selected with a probability that depends on their fitness. We finally consider a more general model of behavior evolution that allows for any possible dynamics of behavior change, and show that this model is well-behaved, with the additional feature that the evolved behaviors are not always the most fit for the environment, but rather that the most fit behaviors are selected with a probability that depends on their fitness.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two branches of neutron stars - reconciling a 2M_sun pulsar and SN1987A. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4594, "human_text": "  The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the\nmaximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max,\ndue to a kaon condensation in the stellar core, implies collapse of a too\nmassive deleptonized protoneutron star into a black hole. This would naturally\nexplain the lack of a neutron star in the SN1987A remnant. On the other hand,\nrecent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This\ncontradicts the original Bethe-Brown model, but can be reconciled within\nscenarios proposed in the present Letter. We consider two types of dense matter\nmodels with high-density softening, due to a transition from a non-strange\nN-phase of matter to a strangeness carrying phase S: kaon condensation and\ndeconfinement of quarks. Two scenarios of neutron star formation in stellar\ncore collapse are considered. In the first scenario, realized in sufficiently\nhot and dense supernova cores, nucleation of an S-phase is sufficiently rapid\nso as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the\nsecond scenario, nucleation of the S-phase at neutron star birth is too slow to\nmaterialize, and the star becomes cold without forming an S-phase core. Then,\nstellar mass can increase via accretion, until central density \\rho_crit is\nreached, and the S phase forms. This N branch of neutron stars ends at\nM=M_crit. We select several models of N-phase satifying the necessary condition\nM^N_max > 2M_sun and combine them with models of kaon condensation and quark\ndeconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun,\nwhich is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark\ndeconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and\nPSR J0751+1807.\n", "machine_text": "\nWe present observations of the radio source 2MASS J2126, which is thought to be a low-mass X-ray binary containing a young, spinning neutron star with a relatively long spin-down lifetime. The source has been known for over two decades, but its nature has been controversial. We have observed 2MASS J2126 in outburst, in quiescence, and in a state of orbital decay. Our observations reconcile the apparently conflicting observations of other groups, and we show that the accretion disc is highly asymmetric, with a strong retrograde component. We estimate the accretion rate to be  \u223c 10^( \u2212 9) M_(\u2299) yr^( \u2212 1), which is not only several orders of magnitude less than the accretion rate in the last few thousand years, but is also smaller than the accretion rate needed to explain the observed spin-down of the neutron star. We suggest that the main accretion event occurred in the distant past, and that the accretion disc has been349uttering due to the complicated orbital dynamics caused by the neutron star's asymmetric spin. We show that 2MASS J2126 is the low-mass X-ray binary counterpart of the supernova SN1987A, which would make it the first known object in which a white dwarf and a neutron star co-exist.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Results on axion physics from the CAST Experiment at CERN. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0637, "human_text": "  Axions are expected to be produced in the sun via the Primakoff process. They\nmay be detected through the inverse process in the laboratory, under the\ninfluence of a strong magnetic field, giving rise to X-rays of energies in the\nrange of a few keV. Such an Axion detector is the CERN Axion Solar Telescope\n(CAST), collecting data since 2003. Results have been published, pushing the\naxion-photon coupling g$_{a\\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at\n95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of\nmagnitude lower than previous experimental limits and surpassed for the first\ntime limits set from astrophysical arguments based on the energy-loss concept.\nThe experiment is currently exploring axion masses in the range of 0.02 eV $<\nm_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass\nexplored will be extended up to the limit of 1.1 eV, testing for the first time\nthe region of theoretical axion models with the axion helioscope method.\n", "machine_text": "\n\nAbstract for: Results on axion physics from the CAST Experiment at CERN\n\nWe present the first results from the CAST experiment, which is a search for axions at the CERN PS_PSorraay accelerator. CAST is sensitive to axions with a mass between 1 and 100 times the mass of the proton and with a magnetic moment of $\\mu$B < 3.5 x 10^-26 G\\cm^3$. The CAST detector consists of a series of multi-layer coils, each layer being a multi-brand element. The layers are spaced by a factor of the nuclear magneton to allow for the separation of the axion and other signals. We present here the results from a first analysis of the CAST data set, obtained during the first part of the 2016 run. We show that the CAST detector is able to detect axions with the sought-after properties, and that the best fit to the data is given by an axion with a mass of the order of 1.5 times the mass of the proton. We also show that the CAST detector is sensitive to axion-like particles with a much higher mass, provided that they have a non-zero magnetic moment.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Succinct Indexable Dictionaries with Applications to Encoding $k$-ary\n  Trees, Prefix Sums and Multisets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0552, "human_text": "  We consider the {\\it indexable dictionary} problem, which consists of storing\na set $S \\subseteq \\{0,...,m-1\\}$ for some integer $m$, while supporting the\noperations of $\\Rank(x)$, which returns the number of elements in $S$ that are\nless than $x$ if $x \\in S$, and -1 otherwise; and $\\Select(i)$ which returns\nthe $i$-th smallest element in $S$. We give a data structure that supports both\noperations in O(1) time on the RAM model and requires ${\\cal B}(n,m) + o(n) +\nO(\\lg \\lg m)$ bits to store a set of size $n$, where ${\\cal B}(n,m) = \\ceil{\\lg\n{m \\choose n}}$ is the minimum number of bits required to store any $n$-element\nsubset from a universe of size $m$. Previous dictionaries taking this space\nonly supported (yes/no) membership queries in O(1) time. In the cell probe\nmodel we can remove the $O(\\lg \\lg m)$ additive term in the space bound,\nanswering a question raised by Fich and Miltersen, and Pagh.\n  We present extensions and applications of our indexable dictionary data\nstructure, including:\n  An information-theoretically optimal representation of a $k$-ary cardinal\ntree that supports standard operations in constant time,\n  A representation of a multiset of size $n$ from $\\{0,...,m-1\\}$ in ${\\cal\nB}(n,m+n) + o(n)$ bits that supports (appropriate generalizations of) $\\Rank$\nand $\\Select$ operations in constant time, and\n  A representation of a sequence of $n$ non-negative integers summing up to $m$\nin ${\\cal B}(n,m+n) + o(n)$ bits that supports prefix sum queries in constant\ntime.\n", "machine_text": "\n\nWe introduce a new data structure, called succinct indexable dictionaries, which generalize both hash tables and succinct data structures for sets. In addition, they can be viewed as a generalization of sequences. We show how to use these new data structures to solve a number of problems in different areas, including encoding $k$-ary trees, prefix sums and multisets. In particular, we show that a succinct indexable dictionary can be used to answer set operations (such as intersection, union, and difference) on $k$-ary trees in $O(\\log n)$ time, where $n$ is the number of elements in the $k$-ary tree, for any fixed $k$. We also show how to maintain a dynamic prefix sum using a succinct indexable dictionary in $O(\\log n)$ time, where $n$ is the number of elements in the sequence. In addition, we show how to maintain a dynamic multiset using a succinct indexable dictionary in $O(\\log n)$ time, where $n$ is the number of elements in the multiset. We complement our results with a number of auxiliary results and impossibility results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Jets, Blazars and the EBL in the GLAST-EXIST Era. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4492, "human_text": "  The synergy of GLAST and the proposed EXIST mission as the Black Hole Finder\nProbe in the Beyond Einstein Program is remarkable. With its full-sky per orbit\nhard X-ray imaging (3-600 keV) and \"nuFnu\" sensitivity comparable to GLAST,\nEXIST could measure variability and spectra of Blazars in the hard X-ray\nsynchrotron component simultaneous with GLAST (~10-100GeV) measures of the\ninverse Compton component, thereby uniquely constraining intrinsic source\nspectra and allowing measured high energy spectral breaks to measure the cosmic\ndiffuse extra-galactic background light (EBL) by determining the intervening\ndiffuse IR photon field required to yield the observed break from photon-photon\nabsorption. Such studies also constrain the physics of jets (and parameters and\nindeed the validity of SSC models) and the origin of the >100 MeV gamma-ray\ndiffuse background likely arising from Blazars and jet-dominated sources. An\noverview of the EXIST mission, which could fly in the GLAST era, is given\ntogether with a synopsis of other key synergies of GLAST-EXIST science.\n", "machine_text": "\nWe have made significant progress in understanding the high-energy Universe by observing the high-energy cosmic rays and gamma-rays produced by the extreme objects in our Galaxy and beyond. The era of ground-based gamma-ray astronomy began with the COBE/FIRAS experiment in the early 1990s, and the past two decades have witnessed a dramatic growth in the field, which has been greatly benefited from the efforts of a number of balloon-borne and space-borne missions, in particular the Compton Gamma Ray Observatory (CGRO) and the INTEGRAL satellite. The space-borne Fermi Gamma-ray Space Telescope, which was launched in 2008, is the latest and most sensitive instrument in the field and has greatly expanded our knowledge on the gamma-ray sky, in particular, by detecting a large number of extragalactic sources, many of which are potentially associated with supermassive black holes. In this article, we review the current status and progress in our understanding of the high-energy Universe based on the observations carried out during the last two decades, and discuss the perspectives of the field in the era of the GLAST-EXIST program.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fourier resolved spectroscopy of 4U 1728-34: New Insights into Spectral\n  and Temporal Properties of Low-Mass X-ray Binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1552, "human_text": "  Using archival RXTE data we derive the 2-16 keV Fourier-resolved spectra of\nthe Atoll source 4U 1728-34 in a sequence of its timing states as its low QPO\nfrequency spans the range between 6 and 94 Hz. The increase in the QPO\nfrequency accompanies a spectral transition of the source from its island to\nits banana states. The banana-states' Fourier-resolved spectra are well fitted\nby a single blackbody component with $kT \\sim 2-3$ keV depending on the source\nposition in the color -- color diagram and the Fourier frequency, thus\nindicating that this spectral component is responsible for the source\nvariability on these timescales. This result is in approximate agreement with\nsimilar behavior exhibited by the Z sources, suggesting that, as in that case,\nthe boundary layer -- the likely source of the thermal component -- is\nsupported by radiation pressure. Furthermore, it is found that the iron line at\n$\\sim$6.6 keV, clearly present in the averaged spectra, not apparent within the\nlimitations of our measurements in the frequency-resolved spectra irrespective\nof the frequency range. This would indicate that this spectral component\nexhibits little variability on time scales comprising the interval\n$10^{-2}-10^2$ seconds. In the island state the single blackbody model proved\ninadequate, particularly notable in our lowest frequency band ($0.008-0.8$ Hz).\nAn absorbed powerlaw or an additive blackbody plus hard powerlaw model was\nrequired to obtain a satisfactory fit. Statistics do not allow unambiguous\ndiscrimination between these possible scenarios.\n", "machine_text": "\n\nWe present Fourier resolved spectroscopy of the low-mass X-ray binary 4U 1728-34. We observe the system in quiescence and measure spectral and temporal properties of the outbursts. We find that the accretion disc fluoresces brighter in the blue than in the red, in spite of the fact that the disc is seen nearly edge-on. This effect is explained by a strong temperature dependence of the emission measure. The measured width of the accretion disc is consistent with the disc being stable on the timescale of our observations, which covers several outbursts. We determine the accretion disc density from the measured accretion rate and find that it is a factor of  \u223c 2 lower than expected from assumptions of isothermal accretion and auniform density. The observed frequency-doubled burst modulation and the high-frequency noise in the outburst spectrum are explained by a model in which the inner accretion disc is geometrically stable and the outer accretion disc is stable on the timescale of an outburst but becomes instable on longer timescales. We discuss the origin of the low accretion disc density and the frequent eruptions from quiescence.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Newton's law in supersymmetric braneworld models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4104, "human_text": "  We study the propagation of gravitons within 5-D supersymmetric braneworld\nmodels with a bulk scalar field. The setup considered here consists of a 5-D\nbulk spacetime bounded by two 4-D branes localized at the fixed points of an\n$S^1/Z_2$ orbifold. There is a scalar field $\\phi$ in the bulk which, provided\na superpotential $W(\\phi)$, determines the warped geometry of the 5-D\nspacetime. This type of scenario is common in string theory, where the bulk\nscalar field $\\phi$ is related to the volume of small compact extra dimensions.\nWe show that, after the moduli are stabilized by supersymmetry breaking terms\nlocalized on the branes, the only relevant degrees of freedom in the bulk\nconsist of a 5-D massive spectrum of gravitons. Then we analyze the\ngravitational interaction between massive bodies localized at the positive\ntension brane mediated by these bulk gravitons. It is shown that the Newtonian\npotential describing this interaction picks up a non-trivial contribution at\nshort distances that depends on the shape of the superpotential $W(\\phi)$. We\ncompute this contribution for dilatonic braneworld scenarios $W(\\phi) =\ne^{\\alpha \\phi}$ (where $\\alpha$ is a constant) and discuss the particular case\nof 5-D Heterotic M-theory: It is argued that a specific footprint at micron\nscales could be observable in the near future.\n", "machine_text": "\nWe consider the question of the possibility of extracting from a rotating (asymptotically flat) brane-world a dynamical system which would describe, in the limit of large radius, the behavior of a particle subjected to an inverse square law (ISL) force. Our main result is that this is possible only if the rotation frequency is an odd multiple of the inverse of the ISL coupling. This is consistent with the fact that for even multiples of this frequency the dynamics is governed by a generalized ISL law with a non-zero fourth power of the distance. In the case of a large radius this would correspond to an inverse law with a non-zero fourth power of the radius. In this case the effective Newton's law is not Newton's law anymore, but a generalization which may be non-conservative. In the case of an odd multiple of the inverse of the ISL coupling the dynamics is described by a generalized ISL law with a vanishing fourth power of the distance. This case is physically meaningful only if the inverse square law is a special case of a more general law with a non-zero fourth power of the distance (i.e. the potential has a non-zero fourth power at large distances). We discuss possible physical meanings of this case. In both cases the main condition for the dynamics to be well-defined is that the ratio of the rotation frequency to the inverse of the ISL coupling is an integer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Route to Lambda in conformally coupled phantom cosmology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1651, "human_text": "  In this letter we investigate acceleration in the flat cosmological model\nwith a conformally coupled phantom field and we show that acceleration is its\ngeneric feature. We reduce the dynamics of the model to a 3-dimensional\ndynamical system and analyze it on a invariant 2-dimensional submanifold. Then\nthe concordance FRW model with the cosmological constant $\\Lambda$ is a global\nattractor situated on a 2-dimensional invariant space. We also study the\nbehaviour near this attractor, which can be approximated by the dynamics of the\nlinearized part of the system. We demonstrate that trajectories of the\nconformally coupled phantom scalar field with a simple quadratic potential\ncrosses the cosmological constant barrier infinitely many times in the phase\nspace. The universal behaviour of the scalar field and its potential is also\ncalculated. We conclude that the phantom scalar field conformally coupled to\ngravity gives a natural dynamical mechanism of concentration of the equation of\nstate coefficient around the magical value $w_{\\text{eff}}=-1$. We demonstrate\nroute to Lambda through the infinite times crossing the $w_{\\text{eff}}=-1$\nphantom divide.\n", "machine_text": "\nWe study the problem of realizing a cosmological constant in a conformally coupled phantom cosmology. We show that the easiest way to achieve this is to follow a route that starts with aphantom cosmology with a positive cosmological constant and an attraction-only gravity, and then consider the cosmological constant to be due to a repulsion from an exactly balanced pairwise force. The route is motivated by the fact that in the regime of strong gravity the dominant contribution to the conformal coupling is the Einstein- Gauss term, which is proportional to the gravitational flux, and that this term can be made to be strictly positive by using a phantom cosmology with a positive cosmological constant and an attraction-only gravity. We show that this is the only way to ensure that the conformal coupling will not flip the sign of the cosmological constant. As a byproduct we also show that the effective Einstein-Infeld gravity in this regime has a Weyl-like self-coupling that can be made arbitrarily small by an appropriate choice of the parameters. We comment on the fact that the standard Einstein- Gauss term is proportional to the flux, not the gradient of the flux, which may have some consequences for the problem of identifying the gravity theory with a suitable cosmology.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: In-plane structure and ordering at liquid sodium surfaces and interfaces\n  from ab initio molecular dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3872, "human_text": "  Atoms at liquid metal surfaces are known to form layers parallel to the\nsurface. We analyze the two-dimensional arrangement of atoms within such layers\nat the surface of liquid sodium, using ab initio molecular dynamics (MD)\nsimulations based on density functional theory. Nearest neighbor distributions\nat the surface indicate mostly 5-fold coordination, though there are noticeable\nfractions of 4-fold and 6-fold coordinated atoms. Bond angle distributions\nsuggest a movement toward the angles corresponding to a six-fold coordinated\nhexagonal arrangement of the atoms as the temperature is decreased towards the\nsolidification point. We rationalize these results with a distorted hexagonal\norder at the surface, showing a mixture of regions of five and six-fold\ncoordination. The liquid surface results are compared with classical MD\nsimulations of the liquid surface, with similar effects appearing, and with ab\ninitio MD simulations for a model solid-liquid interface, where a pronounced\nshift towards hexagonal ordering is observed as the temperature is lowered.\n", "machine_text": "\nWe present an overview of our recent work on the in-plane structure and ordering at liquid sodium surfaces and interfaces, based on large-scale ab initio molecular dynamics simulations. We have investigated the structural and dynamic properties of liquid sodium on a range of different substrate materials, including nickel, copper, and iron, as well as pure liquid sodium itself, in order to identify the effects of the different interfacial interactions on the electronic and structural properties of the interface. We have found that the behavior of liquid sodium is very sensitive to the details of the interfacial interaction, with different types of ordering behavior resulting from different interfacial interactions. We have also found that the nature of the ordering at the interface is very sensitive to the details of the electronic structure of the interface, with different types of electronic structure resulting in different types of ordering behavior. We have also found that the dynamic properties of the interface are very sensitive to the details of the interfacial interaction, with different types of interfacial interactions resulting in different types of dynamic behavior.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of capillary-induced interactions beyond the superposition\n  approximation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0013, "human_text": "  Within a general theoretical framework we study the effective,\ndeformation-induced interaction between two colloidal particles trapped at a\nfluid interface in the regime of small deformations. In many studies, this\ninteraction has been computed with the ansatz that the actual interface\nconfiguration for the pair is given by the linear superposition of the\ninterface deformations around the single particles. Here we assess the validity\nof this approach and compute the leading term of the effective interaction for\nlarge interparticle separation beyond this so-called superposition\napproximation. As an application, we consider the experimentally relevant case\nof interface deformations owing to the electrostatic field emanating from\ncharged colloidal particles. In mechanical isolation, i.e., if the net force\nacting on the total system consisting of the particles plus the interface\nvanishes, the superposition approximation is actually invalid. The effective\ncapillary interaction is governed by contributions beyond this approximation\nand turns out to be attractive. For sufficiently small surface charges on the\ncolloids, such that linearization is strictly valid, and at asymptotically\nlarge separations, the effective interaction does not overcome the direct\nelectrostatic repulsion between the colloidal particles.\n", "machine_text": "\nWe consider the theory of capillary-induced interactions beyond the superposition approximation. We show that the dynamics of wetting and dewetting of a solid substrate by a liquid can be described by a general mathematical framework that accounts for the nonlocal nature of capillary interactions. Our approach is based on the notion of a boundary mode, which is a particular type of eigenmode of the Laplace operator that is invariant under the superposition approximation. We show that the nonlocal interaction between a solid substrate and a liquid can be expressed as a sum of boundary modes, and that this expression is valid beyond the superposition approximation. This theory enables us to study the rich set of wetting and dewetting dynamics that are beyond the scope of the superposition approximation, including the formation of liquid bridges and the break-up of wetting films. We show that these dynamics can be understood in terms of the symmetry and stability of the various boundary modes that are involved. We also discuss the practical implications of this theory for the design of functionalized surfaces and interfaces.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Softening of the stiffness of bottlebrush polymers by mutual interaction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3329, "human_text": "  We study bottlebrush macromolecules in a good solvent by small-angle neutron\nscattering (SANS), static light scattering (SLS), and dynamic light scattering\n(DLS). These polymers consist of a linear backbone to which long side chains\nare chemically grafted. The backbone contains about 1600 monomer units (weight\naverage) and every second monomer unit carries side-chains with ca. 60 monomer\nunits. The SLS- and SANS data extrapolated to infinite dilution lead to the\nform factor of the polymer that can be described in terms of a worm-like chain\nwith a contour length of 380 nm and a persistence length of 17.5 nm. An\nanalysis of the DLS data confirm these model parameters. The scattering\nintensities taken at finite concentration can be modeled using the polymer\nreference interaction site model. It reveals a softening of the bottlebrush\npolymers caused by their mutual interaction. We demonstrate that the\npersistence decreases from 17.5 nm down to 5 nm upon increasing the\nconcentration from dilute solution to the highest concentration 40.59 g/l under\nconsideration. The observed softening of the chains is comparable to the\ntheoretically predicted decrease of the electrostatic persistence length of\nlinear polyelectrolyte chains at finite concentrations.\n", "machine_text": "\n\nWe have developed a new algorithm to evaluate the stiffness of bottlebrush polymers in a solvent, which takes into account the anisotropic features of the polymer in a simple and efficient way. The practical application of this algorithm is the prediction of the unknown properties of bottlebrush polymers, which has important consequences in many practical applications, such as the design of new polymers for drug delivery systems. The new algorithm is based on the evaluation of the difference between the solvent-induced energy and the energy of the collapsed state of the polymer, the so-called collapse energy, which gives the difference between the measured stiffness and the intrinsic stiffness of the polymer. The intrinsic stiffness is evaluated from the statistical properties of the monomers, such as the polymerization number and the Flory radius. The practical use of this algorithm is illustrated with the prediction of the stiffness of a new generation of polymers, the so-called double-combed bottlebrush polymers, which have been recently synthesized and which are of great interest for the design of new drug delivery systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray Timing Observations of PSR J1930+1852 in the Crab-like SNR\n  G54.1+0.3. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0973, "human_text": "  We present new X-ray timing and spectral observations of PSR J1930+1852, the\nyoung energetic pulsar at the center of the non-thermal supernova remnant\nG54.1+0.3. Using data obtained with the Rossi X-ray Timing Explorer and Chandra\nX-ray observatories we have derived an updated timing ephemeris of the 136 ms\npulsar spanning 6 years. During this interval, however, the period evolution\nshows significant variability from the best fit constant spin-down rate of\n$\\dot P = 7.5112(6) \\times 10^{-13}$ s s$^{-1}$, suggesting strong timing noise\nand/or glitch activity. The X-ray emission is highly pulsed ($71\\pm5%$\nmodulation) and is characterized by an asymmetric, broad profile ($\\sim 70%$\nduty cycle) which is nearly twice the radio width. The spectrum of the pulsed\nemission is well fitted with an absorbed power law of photon index $\\Gamma =\n1.2\\pm0.2$; this is marginally harder than that of the unpulsed component. The\ntotal 2-10 keV flux of the pulsar is $1.7 \\times 10^{-12}$ erg cm$^{-2}$\ns$^{-1}$. These results confirm PSR J1930+1852 as a typical Crab-like pulsar.\n", "machine_text": "\nWe have carried out a timing observation of the radio pulsar PSR J1930+1852 in the context of a wider search for pulsars in low-mass X-ray binaries (LMXBs). The observations were made with the Whipple Observatory 10-m telescope and the Interferometer Pharos Array (IPA) and covered a period of nearly three years. We find no evidence of a photometric or timing correlation between the radio pulsar and the X-ray transient in the same system, PSR J1930+1852. We determine a 2-sigma upper limit of 4.6 hours on the orbital period of the system, which excludes the low-hard X-ray transient as being in a wide-binodal orbit with many long-period (>> 3 hours) flares. The observed properties of PSR J1930+1852 are consistent with a model in which the radio and X-ray sources are in a narrow-binodal orbit with many short-period (<< 3 hours) flares. We discuss this in the context of known LMXBs and the limited statistics available. We find that a simple model in which the accretion disc is treated as a uniform density sphere of the given radius is consistent with the observed data, and we estimate the accretion disc radii for PSR J1930+1852 and five other LMXBs with well-determined radii. The resulting probability distribution function (PDF) for disc radii is consistent with a power law with a high-mass cut-off of 3 solar masses, but we are unable to distinguish between a steep power law ( P Mrad \u221d r-3) and a shallower power law ( P Mrad \u221d r-2) for the mass distribution. The high-mass cut-off in the accretion disc radius PDF excludes a pure Roster matrix model for the mass distribution, but is consistent with a stepped distribution in which the low-mass (<< 3 solar masses) accretion disc is described by a Roster matrix and the high-mass (>> 3 solar masses) accretion disc is described by a random matrix. We discuss the implications of our results for the theory of LMXBs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Collisions between equal sized ice grain agglomerates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2672, "human_text": "  Following the recent insight in the material structure of comets,\nprotoplanetesimals are assumed to have low densities and to be highly porous\nagglomerates. It is still unclear if planetesimals can be formed from these\nobjects by collisional growth. Therefore, it is important to study numerically\nthe collisional outcome from low velocity impacts of equal sized porous\nagglomerates which are too large to be examined in a laboratory experiment. We\nuse the Lagrangian particle method Smooth Particle Hydrodynamics to solve the\nequations that describe the dynamics of elastic and plastic bodies.\nAdditionally, to account for the influence of porosity, we follow a previous\ndeveloped equation of state and certain relations between the material strength\nand the relative density. Collisional growth seems possible for rather low\ncollision velocities and particular material strengths. The remnants of\ncollisions with impact parameters that are larger than 50% of the radius of the\ncolliding objects tend to rotate. For small impact parameters, the colliding\nobjects are effectively slowed down without a prominent compaction of the\nporous structure, which probably increases the possibility for growth. The\nprotoplanetesimals, however, do not stick together for the most part of the\nemployed material strengths. An important issue in subsequent studies has to be\nthe influence of rotation to collisional growth. Moreover, for realistic\nsimulations of protoplanetesimals it is crucial to know the correct material\nparameters in more detail.\n", "machine_text": "\n\nCollisions between equal-sized ice grain agglomerates\nAgents of erosion, ice grain agglomerates (IGAs) are widespread in the solar system and can have macroscopic impacts on the surfaces of planets and satellites. Collisions between IGAs are expected to be an important process in the evolution of these surfaces, but the existing theories are not able to explain the nature of the impact craters observed. We present a new model of collisions between equal-sized IGAs, which can produce craters of the sizes observed, provided that the IGAs are icy, rather than icy-rocky, and that the collisions are not perfectly elastic. Our model indicates that the craters observed on Europa's surface may have formed by such collisions, whereas on the surface of Pluto's moon Charon, the energy release may have been sufficient to form geological structures on the scale of mountains. We discuss the implications of this model for the energy budgets of icy bodies, and in particular for the thickness of the icy shells of the Europa and the Earth's moon.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The competition of hydrogen-like and isotropic interactions on polymer\n  collapse. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2162, "human_text": "  We investigate a lattice model of polymers where the nearest-neighbour\nmonomer-monomer interaction strengths differ according to whether the local\nconfigurations have so-called ``hydrogen-like'' formations or not. If the\ninteraction strengths are all the same then the classical $\\theta$-point\ncollapse transition occurs on lowering the temperature, and the polymer enters\nthe isotropic liquid-drop phase known as the collapsed globule. On the other\nhand, strongly favouring the hydrogen-like interactions give rise to an\nanisotropic folded (solid-like) phase on lowering the temperature. We use Monte\nCarlo simulations up to a length of 256 to map out the phase diagram in the\nplane of parameters and determine the order of the associated phase\ntransitions. We discuss the connections to semi-flexible polymers and other\npolymer models. Importantly, we demonstrate that for a range of energy\nparameters two phase transitions occur on lowering the temperature, the second\nbeing a transition from the globule state to the crystal state. We argue from\nour data that this globule-to-crystal transition is continuous in two\ndimensions in accord with field-theory arguments concerning Hamiltonian walks,\nbut is first order in three dimensions.\n", "machine_text": "\nThe competition of hydrogen-like and isotropic interactions on polymer collapse\n\nThe competition between hydrogen-like and isotropic interactions in macromolecular systems is an old and controversial problem. The objective of this work is to reexamine this problem in the framework of the Cray surfing model. We consider the effects of different macromolecular interactions on the equilibrium structure and the dynamical properties of the polymer chain. We show that the different interactions compete with each other in a different way for the collapsed and the extended states. Our main result is that the competition between the different interactions is effectively reduced to the competition between the hydrogen-like and the isotropic interactions, if the difference between these two interaction strengths is sufficiently large. The practical consequence of this result is that the collapse of the polymer chain is a truly competitive process, while the dynamics is mainly influenced by the strong hydrogen-like interactions, if the differences in the strengths of the various interactions is sufficiently large. We discuss the relevance of our results for experimental studies of the dynamics of biological macromolecules.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation of ASTROD I test mass charging due to solar energetic\n  particles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3493, "human_text": "  As ASTROD I travels through space, its test mass will accrue charge due to\ngalactic cosmic-rays and solar energetic particles incident on the spacecraft.\nThis test mass charge will result in Coulomb forces between the test mass and\nthe surrounding electrodes. In earlier work using the GEANT4 toolkit, we\npredicted a net charging rate of nearly 9.0 +e/s from cosmic-ray protons\nbetween 0.1 and 1000 GeV at solar maximum, and rising to 26.5 +e/s at solar\nminimum. Here we use GEANT4 to simulate the charging process due to solar\nenergetic particle events and to estimate the magnitude of acceleration noise\ndue to this charging. The predicted charging rates range from 2840 to 64300\n+e/s, at peak intensity, for the 4 largest SEP events in September and October\n1989. For the 2 larger events, the acceleration disturbances due to charging\nexceeds the ASTROD I acceleration noise budget requirement. Continuous\ndischarge should be considered for suppressing this charging noise. The\nacceleration noise during the 2 small events is well below the design target,\nalthough during these events, the net charging rate will be dominated by these\nsolar fluxes.\n", "machine_text": "\nWe present a detailed simulation study of the test mass charging due to solar energetic particles (SEPs) in the Anti-Symmetric Tether Regulation of Outer Disks (ASTROD) I mission. We investigate the charging process on a test mass, which is a conducting sphere, in the presence of a time-dependent background plasma, constituted by a semi-infinite uniform plasma and a spatially dependent background plasma. We solve numerically the nonlinear diffusion equation for the test mass potential, which is a sum of adcpl telegraphic impulse response (TIR) and a low frequency (LF) integral equation. We consider two different shapes for the LF kernel: a punctual kernel and a super-Gaussian kernel, in order to take into account the different spatial structure of the background plasmas. We show that a good agreement between the simulation results and the analytical prediction based on the TIR is obtained when theLF kernel has a punctual form, while it is necessary to use a super-Gaussian kernel to get a good agreement in the case of a spatially dependent background plasma. We also show that theLF potential contribution to the test mass potential can be evaluated analytically in the case of a punctual LF kernel, in good agreement with the simulation results. Finally, we analyze the effect of the spacecraft potential and of the electric field to the test mass charging process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Catastrophic eruption of magnetic flux rope in the corona and solar wind\n  with and without magnetic reconnection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3885, "human_text": "  It is generally believed that the magnetic free energy accumulated in the\ncorona serves as a main energy source for solar explosions such as coronal mass\nejections (CMEs). In the framework of the flux rope catastrophe model for CMEs,\nthe energy may be abruptly released either by an ideal magnetohydrodynamic\n(MHD) catastrophe, which belongs to a global magnetic topological instability\nof the system, or by a fast magnetic reconnection across preexisting or\nrapidly-developing electric current sheets. Both ways of magnetic energy\nrelease are thought to be important to CME dynamics. To disentangle their\ncontributions, we construct a flux rope catastrophe model in the corona and\nsolar wind and compare different cases in which we either prohibit or allow\nmagnetic reconnection to take place across rapidly-growing current sheets\nduring the eruption. It is demonstrated that CMEs, even fast ones, can be\nproduced taking the ideal MHD catastrophe as the only process of magnetic\nenergy release. Nevertheless, the eruptive speed can be significantly enhanced\nafter magnetic reconnection sets in. In addition, a smooth transition from slow\nto fast eruptions is observed when increasing the strength of the background\nmagnetic field, simply because in a stronger field there is more free magnetic\nenergy at the catastrophic point available to be released during an eruption.\nThis suggests that fast and slow CMEs may have an identical driving mechanism.\n", "machine_text": "\nWe present a theory of the catastrophic eruption of a magnetic flux rope in the corona and solar wind, with and without magnetic reconnection. The theory is based on the idea that the energy stored in the winding up of the magnetic flux rope is the main energy source for the eruption. We show that the evolution of the magnetic flux rope is different in the presence and absence of a guide field. In the absence of a guide field, the magnetic flux rope can be unstable against a large-scale eruption even in the quiescent state, which is in disagreement with the observation. In the presence of a guide field, the magnetic flux rope is stable in the quiescent state but can be triggered to a large-scale eruption by a small-scale instability. The different evolution of the magnetic flux rope in the presence and absence of a guide field can be explained by the difference of the energy budget. We also investigate the influence of the resistivity on the evolution of the magnetic flux rope. A high resistivity tends to increase the energy stored in the magnetic flux rope and therefore enhances the possibility for a large-scale eruption.\n\nWe thank T. bundles for helpful discussions. This work was supported by the Research and Development Center of the Ministry of Science and Technology of China (No. RDC (3)021403, 0113018) and the National Natural Science Foundation of China (No. 10774003, 11021092).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Novel String Derived Z' With Stable Proton, Light-Neutrinos and\n  R-parity violation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1256, "human_text": "  The Standard Model indicates the realization of grand unified structures in\nnature, and can only be viewed as an effective theory below a higher energy\ncutoff. While the renormalizable Standard Model forbids proton decay mediating\noperators due to accidental global symmetries, many extensions of the Standard\nModel introduce such dimension four, five and six operators. Furthermore,\nquantum gravity effects are expected to induce proton instability, indicating\nthat the higher energy cutoff scale must be above 10^{16}GeV. Quasi-realistic\nheterotic string models provide the arena to explore how perturbative quantum\ngravity affects the particle physics phenomenology. An appealing explanation\nfor the proton longevity is provided by the existence of an Abelian gauge\nsymmetry that suppresses the proton decay mediating operators. Additionally,\nsuch a low-scale U(1) symmetry should: allow the suppression of the left-handed\nneutrino masses by a seesaw mechanism; allow fermion Yukawa couplings to the\nelectroweak Higgs doublets; be anomaly free; be family universal. These\nrequirements render the existence of such U(1) symmetries in quasi-realistic\nheterotic string models highly non-trivial. We demonstrate the existence of a\nU(1) symmetry that satisfies all of the above requirements in a class of\nleft-right symmetric heterotic string models in the free fermionic formulation.\nThe existence of the extra Z' in the energy range accessible to future\nexperiments is motivated by the requirement of adequate suppression of proton\ndecay mediation. We further show that while the extra U(1) forbids dimension\nfour baryon number violating operators it allows dimension four lepton number\nviolating operators and R-parity violation.\n", "machine_text": "\nWe propose a model with a Z' symmetry group and two families of light-like fermions, one of which is related to the usual Z and the other to the Z' operator. The model is capable of generating a scale invariant representation for the Z' group which may be related to the hidden symmetry behind the strong interaction. The model is an extension of the hidden local symmetry model and contains two generations of hidden local symmetry fermions. In addition to the usual suspects, the quarks and the charged leptons, we include two families of hidden local symmetry fermions with the same masses as the up and down quarks and the electron and the muon, respectively. The gauge bosons are related to the Z and Z' operators in the same way the Z and Z' bosons are related in the hidden local symmetry model. We show that the model is invariant under a general coordinate transformation which relates the hidden local symmetry fermions to the quarks and charged leptons. The model generates a Z' symmetry group which may be related to the hidden symmetry behind the strong interaction. The quarks and charged leptons are related to the hidden local symmetry fermions by a general coordinate transformation which can be implemented by the transformation which relates the Z and Z' bosons in the hidden local symmetry model. We show that the model can generate a scale invariant representation for the Z' group which may be related to the hidden symmetry behind the strong interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Revisiting the slow dynamics of a silica melt using Monte Carlo\n  simulations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2783, "human_text": "  We implement a standard Monte Carlo algorithm to study the slow, equilibrium\ndynamics of a silica melt in a wide temperature regime, from 6100 K down to\n2750 K. We find that the average dynamical behaviour of the system is in\nquantitative agreement with results obtained from molecular dynamics\nsimulations, at least in the long-time regime corresponding to the\nalpha-relaxation. By contrast, the strong thermal vibrations related to the\nBoson peak present at short times in molecular dynamics are efficiently\nsuppressed by the Monte Carlo algorithm. This allows us to reconsider silica\ndynamics in the context of mode-coupling theory, because several shortcomings\nof the theory were previously attributed to thermal vibrations. A mode-coupling\ntheory analysis of our data is qualitatively correct, but quantitative tests of\nthe theory fail, raising doubts about the very existence of an avoided\nsingularity in this system. We discuss the emergence of dynamic heterogeneity\nand report detailed measurements of a decoupling between translational\ndiffusion and structural relaxation, and of a growing four-point dynamic\nsusceptibility. Dynamic heterogeneity appears to be less pronounced than in\nmore fragile glass-forming models, but not of a qualitatively different nature.\n", "machine_text": "\n\nWe revisit the problem of the slow dynamics of a silica melt, using Monte Carlo simulations. We consider the stochastic model recently proposed by Tatara et al. (J. Chem. Phys., 2016, 145, 034105) to describe the molecular dynamics of a silica melt, and we use Monte Carlo simulations to study the relaxation of density and temperature fluctuations in this model. We find that the relaxation times of the density and temperature fluctuations are very long, of the order of $10^{1000}$ and $10^{100}$ respectively. In order to investigate the origin of these long relaxation times, we study the distribution of the probabilities $p_x$ of finding the system in the state $x$ at a given time, for several initial conditions. We show that these distributions are very narrow, and we relate this result to the small value of the variance $\\Delta\\dot x^2/\\dot x$ in the system. We also show that the $p_x$ distributions are not symmetric, and that their asymmetry is related to the initial conditions. We finally discuss the physical meanings of these results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hamiltonian formalism in Friedmann cosmology and its quantization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0672, "human_text": "  We propose a Hamiltonian formalism for a generalized\nFriedmann-Roberson-Walker cosmology model in the presence of both a variable\nequation of state (EOS) parameter $w(a)$ and a variable cosmological constant\n$\\Lambda(a)$, where $a$ is the scale factor. This Hamiltonian system containing\n1 degree of freedom and without constraint, gives Friedmann equations as the\nequation of motion, which describes a mechanical system with a variable mass\nobject moving in a potential field. After an appropriate transformation of the\nscale factor, this system can be further simplified to an object with constant\nmass moving in an effective potential field. In this framework, the $\\Lambda$\ncold dark matter model as the current standard model of cosmology corresponds\nto a harmonic oscillator. We further generalize this formalism to take into\naccount the bulk viscosity and other cases. The Hamiltonian can be quantized\nstraightforwardly, but this is different from the approach of the\nWheeler-DeWitt equation in quantum cosmology.\n", "machine_text": "\n\nIntroduction:\nIn this work we consider the Hamiltonian formalism in Friedmann cosmology and its quantization. We start with a brief review of the Hamiltonian formalism in general, and then we continue with the Hamiltonian formalism in Friedmann cosmology. We derive the Hamiltonian equations in this context and we solve them analytically. The solutions of the homogeneous and isotropic model are the same as the solutions of the Newtonian theory. The non-homogeneous and anisotropic case is more complicated. In this case the solution has two degrees of freedom, which we call \"cosmological constant\" and \"effective density\". We show that the possible values of these two degrees of freedom are restricted by the condition that the total energy is constant. In addition, we show that the solutions of the non-homogeneous and anisotropic case are singular. Finally, we discuss the quantization of the Hamiltonian system. We show that the quantization is equivalent to the quantization of the energy. We also show that the energy is quantized in a discrete set of values. The correspondence between the values of the energy and the values of the cosmological constant and the effective density is also discussed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Controlling for individual heterogeneity in longitudinal models, with\n  applications to student achievement. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1401, "human_text": "  Longitudinal data tracking repeated measurements on individuals are highly\nvalued for research because they offer controls for unmeasured individual\nheterogeneity that might otherwise bias results. Random effects or mixed models\napproaches, which treat individual heterogeneity as part of the model error\nterm and use generalized least squares to estimate model parameters, are often\ncriticized because correlation between unobserved individual effects and other\nmodel variables can lead to biased and inconsistent parameter estimates.\nStarting with an examination of the relationship between random effects and\nfixed effects estimators in the standard unobserved effects model, this article\ndemonstrates through analysis and simulation that the mixed model approach has\na ``bias compression'' property under a general model for individual\nheterogeneity that can mitigate bias due to uncontrolled differences among\nindividuals. The general model is motivated by the complexities of longitudinal\nstudent achievement measures, but the results have broad applicability to\nlongitudinal modeling.\n", "machine_text": "\n\nControlling for individual heterogeneity in longitudinal models, with applications to student achievement\n\nWe consider the problem of controlling for individual heterogeneity in models for stationary longitudinal data. We focus on the widely used random-coefficient model, and consider both linear and quadratic forms of the random coefficients. We propose a new model-based method, which we term the \"category-threshold\" method, for controlling for individual heterogeneity. The method works by defining a threshold on the within-person variance in the random coefficients, and then using the threshold to group individuals according to the magnitude of their within-person coefficient variance. We show that the resulting group-level coefficients are then consistent with the null hypothesis of zero mean and finite variance, against the alternative of constant mean and/or variance. The category-threshold method has several advantages over other methods for controlling for individual heterogeneity. In particular, it is simple and flexible, allowing the researcher to use any linear or quadratic form of the random coefficients, and to set the threshold in any way that is consistent with the data generating process. We demonstrate the performance of the category-threshold method through simulation studies, and apply it to a study of student achievement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Asteroid Deflection: How, where and when?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1805, "human_text": "  To deflect impact-trajectory of massive km^3 and spinning asteroid by a few\nterrestrial radius one need a large momentum exchange. The dragging of huge\nspinning bodies in space by external engine seems difficult or impossible. Our\nsolution is based on the landing of multi screw-rockets, powered by\nmini-nuclear engines, on the body, that dig a small fraction of the soil\nsurface, to use as an exhaust propeller, ejecting it vertically in phase among\nthemselves. Such a mass ejection increases the momentum exchange, their number\nredundancy guarantees the stability of the system. The slow landing (below 40\ncm s^-1) of each engine-unity at those lowest gravity field, may be achieved by\nsave rolling and bouncing along the surface. The engine array tuned activity,\novercomes the asteroid angular velocity. Coherent turning of the jet heads\nincreases the deflection efficiency. A procession along its surface may\ncompensate at best the asteroid spin. A small skin-mass (about 2 10^4 tons) may\nbe ejected by mini nuclear engines. Such prototypes may also build first save\ngalleries for humans on the Moon. Conclusive deflecting tests might be\nperformed on remote asteroids. The incoming asteroid 99942 Apophis (just 2% of\nkm^3) may be deflected safely a few Earth radius. How to tag its trajectory is\ndescribed. Its encounter maybe not just a hazard but an opportunity, learning\nhow to land, dig, build and also to nest save human station inside. Asteroids\namplified deflections by gravity swing maybe driven into longest planetary\njourneys. Mars journey may benefict by Phobos natural asteroid parking and\nfueling role.\n", "machine_text": "\n\nAsteroid Deflection: How, where and when?\n\nAsteroids pose a serious threat to life on Earth and although they strike Earth only rarely, the consequences can be catastrophic. With the current lack of technology to deflect asteroids, the only option is to monitor their positions and attempt to evacuate the area where they are predicted to strike. We present here a new method for deflecting asteroids, which is based on a recently proposed concept of using a fleet of small spacecraft to deflect an asteroid by giving it a small push at the right time. We show that this method is capable of deflecting asteroids with a diameter as large as a few tens of km, which is large enough to be potentially dangerous. We also derive a simple formula that can be used to quickly assess whether an asteroid can be deflected or not, and we discuss the practical aspects of the deflection method, including the number and the relative sizes of the spacecraft, the time frame in which the deflection must be executed, and the choice of the asteroid's target trajectory after it has been deflected. We find that in order to deflect an asteroid whose diameter is on the order of tens of km, a fleet of spacecraft with a total mass of several hundred tons may be required, and the execution time window can be as long as a few months. We also show that an asteroid's target trajectory after deflection can be chosen so that the risk of an accidental collision with another asteroid is minimal. We believe that this method can provide a realistic and practical solution to the problem of asteroid deflection, and we discuss the key technological aspects that need to be developed in order to implement it.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The absolute Galois group acts faithfully on the connected components of\n  the moduli space of surfaces of general type. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1466, "human_text": "  We show that the Galois group $Gal(\\bar{\\Q} /\\Q)$ operates faithfully on the\nset of connected components of the moduli spaces of surfaces of general type,\nand also that for each element $\\sigma \\in Gal(\\bar{\\Q} /\\Q)$ different from\nthe identity and from complex conjugation, there is a surface of general type\nsuch that $X$ and the Galois conjugate variety $X^{\\sigma}$ have nonisomorphic\nfundamental groups. The result was announced by the second author at the\nAlghero Conference 'Topology of algebraic varieties' in september 2006. Before\nthe present paper was actually written, we received a very interesting preprint\nby Robert Easton and Ravi Vakil (\\cite{e-v}), where it is proven, with a\ncompletely different type of examples, that the Galois group $Gal(\\bar{\\Q}\n/\\Q)$ operates faithfully on the set of irreducible components of the moduli\nspaces of surfaces of general type. We also give other simpler examples of\nsurfaces with nonisomorphic fundamental groups which are Galois conjugate,\nhence have isomorphic algebraic fundamental groups.\n", "machine_text": "\nWe show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type. This answers a question of Beukers and Lakes.\n\nThe motivation for this research is the relation between the geometry of the moduli space of surfaces of general type and the geometric properties of the moduli space of vector bundles on surfaces of general type. In particular, we show that the connected components of the moduli space of surfaces of general type are fibered by surfaces with constant mean curvature.\n\nThe key ideas and methodology of this research are as follows. We show that the pull-back of a curve in the moduli space of vector bundles on a surface of general type is a curve in the moduli space of surfaces of general type. Since the absolute Galois group acts faithfully on the moduli space of vector bundles on surfaces of general type, it follows that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type.\n\nThe results obtained are as follows. We show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type. This answers a question of Beukers and Lakes. We also show that the connected components of the moduli space of surfaces of general type are fibered by surfaces with constant mean curvature.\n\nProblem work attempts to solve. We show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type. We show that the connected components of the moduli space of surfaces of general type are fibered by surfaces with constant mean curvature. We also show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type.\n\nAny practical or theoretical applications from your findings or implications for future research. While our results have no practical applications, they do have theoretical implications for future research. For example, our results may be useful in understanding the relation between the geometry of the moduli space of surfaces of general type and the geometric properties of the moduli space of vector bundles on surfaces of general type.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Collective states of the odd-mass nuclei within the framework of the\n  Interacting Vector Boson Model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2169, "human_text": "  A supersymmetric extension of the dynamical symmetry group $Sp^{B}(12,R)$ of\nthe Interacting Vector Boson Model (IVBM), to the orthosymplectic group\n$OSp(2\\Omega/12,R)$ is developed in order to incorporate fermion degrees of\nfreedom into the nuclear dynamics and to encompass the treatment of odd mass\nnuclei. The bosonic sector of the supergroup is used to describe the complex\ncollective spectra of the neighboring even-even nuclei and is considered as a\ncore structure of the odd nucleus. The fermionic sector is represented by the\nfermion spin group $SO^{F}(2\\Omega)\\supset SU^{F}(2)$.\n  The so obtained, new exactly solvable limiting case is applied for the\ndescription of the nuclear collective spectra of odd mass nuclei. The\ntheoretical predictions for different collective bands in three odd mass\nnuclei, namely $^{157}Gd$, $^{173}Yb$ and $^{163}Dy$ from rare earth region are\ncompared with the experiment. The $B(E2)$ transition probabilities for the\n$^{157}Gd$ and $^{163}Dy$ between the states of the ground band are also\nstudied. The important role of the symplectic structure of the model for the\nproper reproduction of the $B(E2)$ behavior is revealed. The obtained results\nreveal the applicability of the models extension.\n", "machine_text": "\nWe investigate the structure of collective states of the odd-mass nuclei within the framework of the Interacting Vector Boson Model. The main goal of the work is to determine the nature of the single-particle basis of the collective states and to establish the connection between the properties of these states and the structure of the original Hamiltonian. We show that the collective states can be constructed as a linear combination of single-particle states with certain properties. The masses and the widths of the collective states can be evaluated by using the single-particle basis and the structure of the original Hamiltonian in a simple and straightforward way. Our results are consistent with the odd-mass nucleus being in a collective state with two different width contributions, one of which is close to the width of the fundamental state and the other is close to the width of the first excited state. We also show that the partial width of the collective state can be evaluated by using the single-particle basis and the structure of the original Hamiltonian. Our results are consistent with the partial width being proportional to the ratio of the single-particle basis to the total number of quark colors in the original Hamiltonian.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation of Heme using DFT+U: a step toward accurate spin-state\n  energetics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2743, "human_text": "  We investigate the DFT+U approach as a viable solution to describe the\nlow-lying states of ligated and unligated iron heme complexes. Besides their\ncentral role in organometallic chemistry, these compounds represent a\nparadigmatic case where LDA, GGA, and common hybrid functionals fail to\nreproduce the experimental magnetic splittings. In particular, the imidazole\npentacoordinated heme is incorrectly described as a triplet by all usual DFT\nflavors. In this study we show that a U parameter close to 4 eV leads to spin\ntransitions and molecular geometries in quantitative agreement with\nexperiments, and that DFT+U represents an appealing tool in the description of\niron porphyrin complexes, at a much reduced cost compared to correlated\nquantum-chemistry methods. The possibility of obtaining the U parameter from\nfirst-principles is explored through a self-consistent linear-response\nformulation. We find that this approach, which proved to be successful in other\niron systems, produces in this case some overestimation with respect to the\noptimal values of U.\n", "machine_text": "\n\nWe present a density functional theory and exact Muffin-Tin (DFT+U) computation of the electronic structure and spin-state energetics of the heme molecule. The goal of this work is to evaluate the accuracy of DFT+U methods in describing the spin-state energetics of transition metal complexes. We focus on the model system heme, which has well-defined spin-state properties, including an open-shell spin-state and a well-defined low-spin state with a relatively small energy difference between the two spin-states. The heme system also provides a benchmark for the evaluation of the breakup of the molecular orbitals into atomic contributions. Our results indicate that the simple DFT+U approach is not adequate for the accurate prediction of the heme spin-state energetics. We find that the biggest deficiency is the failure of the DFT+U method to describe the orbital breakup of the molecular orbitals. We propose that this deficiency may be cured by a more sophisticated treatment of the U, which includes a proper treatment of the correlation effects in the molecular orbitals.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Z^0 \\to 2\\gamma and the Twisted Coproduct of the Poincar\\'{e} Group. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0921, "human_text": "  Yang's theorem forbids the process $Z^0 \\to 2\\gamma$ in any Poincar\\'{e}\ninvariant theory if photons are bosons and their two-particle states transform\nunder the Poincar\\'{e} group in the standard way (under the standard coproduct\nof the Poincar\\'{e} group). This is an important result as it does not depend\non the assumptions of quantum field theory. Recent work on noncommutative\ngeometry requires deforming the above coproduct by the Drinfel'd twist. We\nprove that $Z^0 \\to 2\\gamma$ is forbidden for the twisted coproduct as well.\nThis result is also independent of the assumptions of quantum field theory. As\nan illustration of the use of our general formulae, we further show that $Z^0\n\\to \\nu + \\nu$ is forbidden for the standard or twisted coproduct of the\nPoincar\\'{e} group if the neutrino is massless, even if lepton number is not\nconserved. This is a special case of our general result that a massive particle\nof spin $j$ cannot decay into two identical massless particles of the same\nhelicity if $j$ is odd, regardless of the coproduct used.\n", "machine_text": "\nWe introduce the twisted coproduct of a Poincar\u00e9 group. We show that this is a generalization of the affine Lie algebras to the setting of relative impoverished Poincar\u00e9 groups. As an application we give a description of the twisted coproduct of the Poincar\u00e9 group in terms of left- and right-invariant Poincar\u00e9 polynomials. We also describe the twisted coproduct of the Poincar\u00e9 group in terms of the invariant asked for by Hilbert's 16th problem, namely the number of non-zero derivatives of a solution to a homogeneous polynomial system of differential equations. This allows to give a description of the twisted coproduct of the Poincar\u00e9 group in terms of bi-invariant functions on the space of differential forms on a smooth projective variety. As an application we show that the twisted coproduct of the Poincar\u00e9 group acts on the space of global sections of certain sheaves in a way which is reminiscent of the way the ordinary Poincar\u00e9 group acts on the space of sections of certain vector bundles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effects of the galactic winds on the stellar metallicity distribution of\n  dwarf spheroidal galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2032, "human_text": "  To study the effects of galactic winds on the stellar metallicity\ndistributions and on the evolution of Draco and Ursa Minor dwarf spheroidal\ngalaxies, we compared the predictions of several chemical evolution models,\nadopting different prescriptions for the galactic winds, with the\nphotometrically-derived stellar metallicity distributions of both galaxies. The\nchemical evolution models for Draco and Ursa Minor, which are able to reproduce\nseveral observational features of these two galaxies, such as the several\nabundance ratios, take up-to-date nucleosynthesis into account for\nintermediate-mass stars and supernovae of both types, as well as the effect of\nthese objects on the energetics of the systems. For both galaxies, the model\nthat best fits the data contains an intense continuous galactic wind, occurring\nat a rate proportional to the star formation rate. Models with a wind rate\nassumed to be proportional only to the supernova rate also reproduce the\nobserved SMD, but do not match the gas mass, whereas the models with no\ngalactic winds fail to reproduce the observed SMDs. In the case of Ursa Minor,\nthe same model as in previous works reproduces the observed distribution very\nwell with no need to modify the main parameters of the model. The model for\nDraco, on the other hand, is slightly modified. The observed SMD requires a\nmodel with a lower supernova type Ia thermalization efficiency ($\\eta_{SNeIa}$\n= 0.5 instead of $\\eta_{SNeIa}$ = 1.0) in order to delay the galactic wind,\nwhereas all the other parameters are kept the same. The model results, compared\nto observations, strongly suggest that intense and continuous galactic winds\nplay a very important role in the evolution of local dSphs.\n", "machine_text": "\nWe present an analysis of the stellar metallicity distribution of 72 dwarf spheroidal galaxies (DSGs) in the Local Volume, an area of the Milky Way (MW) that contains a high density of globular clusters. We aim to test the hypothesis that DSGs in this region are affected by the Galactic winds, which should produce a negative correlation between the metallicity and the distance to the MW. We find a very significant correlation ( Metallicities of dwarf galaxies in the Local Volume. We conclude that the Galactic winds have had a strong effect on the evolution of the metallicity of the DSGs in the Local Volume, and that this provides strong support for models in which the Galactic winds are an important regulator of the chemical evolution of the Galactic disc. We discuss our results in the context of the current theories of the formation and evolution of DSGs, and we highlight the need for a better understanding of the detailed physics of the Galactic winds in order to be able to produce more precise predictions for the effects of these winds on the chemical evolution of the Galactic disc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gamma Rays frim the Galactic Centre. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2333, "human_text": "  Recent results from the HESS gamma ray telescope have shown the presence of\nboth a diffuse, extended, flux of gamma rays above ~0.4 TeV and discrete\nsources in and near the Galactic Centre. Here, we put forward a possible\nexplanation in terms of the diffusion of cosmic ray protons from a succession\nof supernova remnants (SNR) in the SgrA* region of the Galaxy plus a\ncontribution from SNR in the rest of the Galactic Centre Region, to be called\nthe Galactic Centre Ridge (GCR). Protons are favoured over electrons because\nthe mG magnetic fields in the Region will attenuate energetic electrons\nseverely. Prominent features are the need for 'anomalous diffusion' of the\nprotons in the whole region and the adoption of low efficiency for SNR\nacceleration in the high density regions. The latter is related by us to the\nwell-known low 'cosmic ray gradient' in the Galaxy. A corroborating feature is\nthe close correlation of inferred cosmic ray intensity with the smoothed\nintensity of 5 GHZ radio radiation. We attribute this to the presence of the\nSNR in the GCR.\n", "machine_text": "\n\nWe present here results of a systematic analysis of \u03b3-ray point sources in the Galactic Centre region carried out with the help of a 60Co exposure of several weeks duration obtained with the Austrian particle detector CEDIC. The main aim of the investigation was to search for new members of the class of hard \u03b3-ray transient sources which include the well known objects Cyg OB2#63 and Cep OB2#lll. The analysis of the \u03b3-ray point source population in the region shows a clear deficit of sources with respect to the predictions of the canonical WMAP-based Galactic model, in agreement with earlier results in the northern Galactic hemisphere. This suggests that the sources in this region, including the well known giant molecular clouds, are in fact less dense than expected from the simple application of the Galactic model. We have identified one hard transient source, named CoRoT-24, in a very low density region between the clouds and show that it has all the characteristics of a member of the group of hard transient sources. We estimate the total number of such objects to be in the range 2-5, depending on the volume considered. This indicates that the formation of such objects is probably linked to large scale density variations and not to the occurrence in molecular clouds which are, in fact, rather poor in such sources.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unitarity analysis of a non-Abelian gauge invariant action with a mass. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0871, "human_text": "  In previous work done by us and coworkers, we have been able to construct a\nlocal, non-Abelian gauge invariant action with a mass parameter, based on the\nnonlocal gauge invariant mass dimension two operator F1/D^2F. The\nrenormalizability of the resulting action was proven to all orders of\nperturbation theory, in the class of linear covariant gauges. We also discussed\nthe perturbative equivalence of the model with ordinary massless Yang-Mills\ngauge theories when the mass is identically zero. Furthermore, we pointed out\nthe existence of a BRST symmetry with corresponding nilpotent charge. In this\npaper, we study the issue of unitarity of this massive gauge model. Firstly, we\nprovide a short review how to discuss the unitarity making use of the BRST\ncharge. Afterwards we make a detailed study of the most general version of our\naction, and we come to the conclusion that the model is not unitary, as we are\nunable to remove all the negative norm states from the physical spectrum in a\nconsistent way.\n", "machine_text": "\nWe study the possibility of a non-Abelian gauge invariant action with a mass for a chiral gauge theory in the presence of an internal symmetry group G. We show that the standard approach to define a mass for a gauge invariant action fails in this case, and we propose a general framework to define a gauge invariant mass for a non-Abelian gauge theory which is motivated by the example of the E8 \u00d7 E8 heterotic theory. In this approach, the mass term is generated by a non-Abelian two form field. We show that this mass term is protected by the internal symmetry group G, and we obtain a gauge invariant action with a mass. This action is non-Abelian, but it is invariant under a proper subset of the elements of the internal symmetry group G. We call this action a \"unitary gauge invariant action with a mass\". We show that this action is related to the effective action of the gauge theory, and that the parameter space of this action is related to the electric charge of the theory. This approach is general and can be applied to any chiral gauge theory with an internal symmetry group G, and we show that the unitarity bound on the strength of the mass term is related to the cardinality of G. We also discuss the relation of this work to the Standard Model and the possibility of a non-Abelian unitary gauge invariant action with a mass for the Standard Model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Formation and Collisional Evolution of Kuiper Belt Objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0259, "human_text": "  This chapter summarizes analytic theory and numerical calculations for the\nformation and collisional evolution of KBOs at 20--150 AU. We describe the main\npredictions of a baseline self-stirring model and show how dynamical\nperturbations from a stellar flyby or stirring by a giant planet modify the\nevolution. Although robust comparisons between observations and theory require\nbetter KBO statistics and more comprehensive calculations, the data are broadly\nconsistent with KBO formation in a massive disk followed by substantial\ncollisional grinding and dynamical ejection. However, there are important\nproblems reconciling the results of coagulation and dynamical calculations.\nContrasting our current understanding of the evolution of KBOs and asteroids\nsuggests that additional observational constraints, such as the identification\nof more dynamical families of KBOs (like the 2003 EL61 family), would provide\nadditional information on the relative roles of collisional grinding and\ndynamical ejection in the Kuiper Belt. The uncertainties also motivate\ncalculations that combine collisional and dynamical evolution, a `unified'\ncalculation that should give us a better picture of KBO formation and\nevolution.\n", "machine_text": "\n\nWe present a formation and evolution model for the Kuiper Belt based on the analysis of its current membership. We first describe a method for determining the relative ages of different Kuiper Belt objects (KBOs) based on their colors. We then utilize these ages in a model that simultaneously forms and collides KBOs to reproduce the observed distribution of colors and surface ages. The model includes an additional source of KBOs that is driven by the chaotic mixing of bodies in the Nice model. We vary the initial conditions for the formation of the Kuiper Belt and study the resulting collisional dynamics. Our results show that KBOs can evolve to their current orbits in as few as 10-50 million years. The source of the efficient collisional evolution is the outward migration of the objects that results from their forward motion and the inward migration of the objects that results from their tidal interaction with a massive terrestrial planet. We explain why the high eccentricity of the KBOs is consistent with their collisional evolution. We also show that a KBO must have had a minimum velocity of 4-6 km/s to reach its current orbit, which eliminates a large number of candidates for the so-called \"short-period comet\" observed to have been in a retrograde orbit around the Sun. Finally, we show that the KBOs are likely to have formed in a narrow range of distances from the Sun, within 5-10 AU.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The InterHourly-Variability (IHV) Index of Geomagnetic Activity and its\n  Use in Deriving the Long-term Variation of Solar Wind Speed. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0961, "human_text": "  We describe the derivation of the InterHourly Variability (IHV) index of\ngeomagnetic activity. The IHV-index for a geomagnetic element is mechanically\nderived from hourly values as the sum of the unsigned differences between\nadjacent hours over a seven-hour interval centered on local midnight. The index\nis derived separately for stations in both hemispheres within six longitude\nsectors using only local night hours. It is intended as a long-term index.\nAvailable data allows derivation of the index back well into the 19th century.\nOn a time scale of a 27-day Bartels rotation, IHV averages for stations with\ncorrected geomagnetic latitude less than 55 degrees are strongly correlated\nwith midlatitude range indices. Assuming a constant calibration of the aa-index\nwe find that observed yearly values of aa before the year 1957 are 2.9 nT too\nsmall compared to values calculated from IHV using the regression constants\nbased on 1980-2004. We interpret this discrepancy as an indication that the\ncalibration of the aa index is in error before 1957. There is no such problem\nwith the ap index. Rotation averages of IHV are also strongly correlated with\nsolar wind parameters (BV^2). On a time scale of a year combining the IHV-index\nand the recently-developed Inter-Diurnal Variability (IDV) index (giving B)\nallows determination of solar wind speed, V, from 1890-present. Over the\n~120-year series, the yearly mean solar wind speed varied from a low of 303\nkm/s in 1902 to a high value of 545 km/s in 2003. The calculated yearly values\nof the product BV using B and V separately derived from IDV and IHV agree\nquantitatively with (completely independent) BV derived from the amplitude of\nthe diurnal variation of the H component in the polar caps since 1926 and\nsporadically beyond.\n", "machine_text": "\n\nWe have developed a new index of geomagnetic activity, the InterHourly-Variability (IHV) index, based on the interhourly variability of the geomagnetic field, which is related to the ionospheric and tropospheric conditions as well as the solar wind intensity. Our results show that the IHV index has clear quasi-11-year and quasi-7-year cycles that are closely related to the solar cycle. We show that the IHV index can be used to derive the long-term variation of the solar wind speed from observations of the geomagnetic field. We have tested this derived solar wind speed by comparing it with independent measurements of the solar wind speed made by the Ulysses spacecraft. The comparison shows a high degree of consistency between the long-term variations of the solar wind speed derived from the IHV index and the direct measurements made by Ulysses. This indicates that the IHV index can be used to derive the long-term variation of the solar wind speed from observations of the geomagnetic field. The IHV index has clear applications in the prediction of space weather.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Integral Field Spectroscopy of the Extended Emission-Line Region of 4C\n  37.43. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4365, "human_text": "  We present Gemini integral field spectroscopy and Keck II longslit\nspectroscopy of the extended emission-line region (EELR) around the quasar 4C\n37.43. The velocity structure of the ionized gas is complex and cannot be\nexplained globally by a simple dynamical model. The spectra from the clouds are\ninconsistent with shock or ``shock + precursor'' ionization models, but they\nare consistent with photoionization by the quasar nucleus. The best-fit\nphotoionization model requires a low-metallicity (12+log(O/H) < 8.7) two-phase\nmedium, consisting of a matter-bounded diffuse component with a unity\nfilling-factor (N ~ 1 \\cc, T ~ 15000 K), in which are embedded small, dense\nclouds (N ~ 400 \\cc, T ~ 10^4 K). The high-density clouds are transient and can\nbe re-generated through compressing the diffuse medium by low-speed shocks (V_S\n\\lesssim 100 \\kms). Our photoionization model gives a total mass for the\nionized gas of about 3x10^{10} M_sun, and the total kinetic energy implied by\nthis mass and the observed velocity field is ~2x10^{58} ergs. The fact that\nluminous EELRs are confined to steep-spectrum radio-loud quasars, yet show no\nmorphological correspondence to the radio jets, suggests that the driving force\nproducing the 4C 37.43 EELR was a roughly spherical blast wave initiated by the\nproduction of the jet. That such a mechanism seems capable of ejecting a mass\ncomparable to that of the total interstellar medium of the Milky Way suggests\nthat ``quasar-mode'' feedback may indeed be an efficient means of regulating\nstar formation in the early universe.\n", "machine_text": "\nWe present integral field spectroscopy of the extended emission-line region (EELR) of 4C 37.43, a bright and nearby galaxy in the optical state, with the aim of characterizing the ionization structure of its extended atmosphere. We observe a strong correlation between ionization and stellar content: the ionized gas is mostly located in the regions of the galaxy that contain young and massive stars. In addition, we find that the ionization structure is extremely regular, with the ionization probability decreasing in a radial fashion from the galaxy's center. We interpret this radial decline as due to the combined effect of a large-scale ionization wave and the superposition of many small-scale localised ionization sources, the latter most likely related to the massive star-forming regions. We have verified that this radial decrease in ionization probability is not due to dust obscuration. Our results suggest that a simple model in which ionization is driven by a single wave of ionization originating in the galaxy's centre cannot account for the ionization structure of the EELR.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Highly turbulent solutions of LANS-alpha and their LES potential. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1928, "human_text": "  We compute solutions of the Lagrangian-Averaged Navier-Stokes alpha-model\n(LANS) for significantly higher Reynolds numbers (up to Re 8300) than have\npreviously been accomplished. This allows sufficient separation of scales to\nobserve a Navier-Stokes (NS) inertial range followed by a 2nd LANS inertial\nrange. The analysis of the third-order structure function scaling supports the\npredicted l^3 scaling; it corresponds to a k^(-1) scaling of the energy\nspectrum. The energy spectrum itself shows a different scaling which goes as\nk^1. This latter spectrum is consistent with the absence of stretching in the\nsub-filter scales due to the Taylor frozen-in hypothesis employed as a closure\nin the derivation of LANS. These two scalings are conjectured to coexist in\ndifferent spatial portions of the flow. The l^3 (E(k) k^(-1)) scaling is\nsubdominant to k^1 in the energy spectrum, but the l^3 scaling is responsible\nfor the direct energy cascade, as no cascade can result from motions with no\ninternal degrees of freedom. We verify the prediction for the size of the LANS\nattractor resulting from this scaling. From this, we give a methodology either\nfor arriving at grid-independent solutions for LANS, or for obtaining a\nformulation of a LES optimal in the context of the alpha models. The fully\nconverged grid-independent LANS may not be the best approximation to a direct\nnumerical simulation of the NS equations since the minimum error is a balance\nbetween truncation errors and the approximation error due to using LANS instead\nof the primitive equations. Furthermore, the small-scale behavior of LANS\ncontributes to a reduction of flux at constant energy, leading to a shallower\nenergy spectrum for large alpha. These small-scale features, do not preclude\nLANS to reproduce correctly the intermittency properties of high Re flow.\n", "machine_text": "\nWe study the potential of Large-Eddy Simulation (LES) for highly turbulent solutions of the L fluid model (LANS-alpha) which was recently shown to possess intrinsic large-scale motions. The analysis is based on a recent derivation of the LES equations for the LANS-alpha model which takes into account the non-conservative terms in the original conservation laws. We show that the LES equations for LANS-alpha inherit the key properties of the LES equations for the classical Navier-Stokes equations. In particular, we show that (i) the new LES equations are unconditionally stable for all parameters in the range of validity of LANS-alpha, (ii) the energy transfer to the mean flow is controlled by a single parameter which is proportional to the square of the flow velocity, (iii) this energy transfer is very efficient in spite of the fact that the largest scales are not allowed to grow very fast, and (iv) the new LES equations are very similar to the LES equations for the Navier-Stokes equations. We finally discuss the potential and limitations of LES for highly turbulent solutions of LANS-alpha.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 3-He in the Milky Way Interstellar Medium: Ionization Structure. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1939, "human_text": "  The cosmic abundance of the 3-He isotope has important implications for many\nfields of astrophysics. We are using the 8.665 GHz hyperfine transition of\n3-He+ to determine the 3-He/H abundance in Milky Way HII regions and planetary\nnebulae. This is one in a series of papers in which we discuss issues involved\nin deriving accurate 3-He/H abundance ratios from the available measurements.\nHere we describe the ionization correction we use to convert the 3-He+/H+\nabundance, y3+, to the 3-He/H abundance, y3. In principle the nebular\nionization structure can significantly influence the y3 derived for individual\nsources. We find that in general there is insufficient information available to\nmake a detailed ionization correction. Here we make a simple correction and\nassess its validity. The correction is based on radio recombination line\nmeasurements of H+ and 4-He+, together with simple core-halo source models. We\nuse these models to establish criteria that allow us to identify sources that\ncan be accurately corrected for ionization and those that cannot. We argue that\nthis effect cannot be very large for most of the sources in our observational\nsample. For a wide range of models of nebular ionization structure we find that\nthe ionization correction factor varies from 1 to 1.8. Although large\ncorrections are possible, there would have to be a conspiracy between the\ndensity and ionization structure for us to underestimate the ionization\ncorrection by a substantial amount.\n", "machine_text": "\nWe present observations of the 3-He content in a large sample of Galactic sight lines, which together cover the full 360 deg^2 sky visible from the Northern Hemisphere. We find that the 3-He abundance in the interstellar medium (ISM) increases with radius in all directions, consistent with the expectation that the ISM is dynamically stratified and that the 3-He is concentrated in the inner regions. We find a mean 3-He abundance of 3.01 +1.08 (1\u03c3) x 10^-4, rising to 3.81 +1.08 (1\u03c3) x 10^-4 at a Galacto-centric distance of 8 kpc. This is consistent with the 3-He being produced in the galactic interior and radially diffusing outward. The mean relative abundance of 3-He with respect to H_2 is 5.4 +2.1 (1\u03c3) x 10^-4, but this ratio is not uniform. We find that the ratio is higher in the inner Galacto-centric distance range, and lower in the outer range, with a turnover at a Galacto-centric distance of  \u223c 6 kpc. This is consistent with the hypothesis that the 3-He is produced in the core and the diffuses outward, while the H_2 is produced in the outer Galaxy and diffuses inward. We find that the gas phase metallicity of the ISM is correlated with the 3-He abundance, with the 3-He being more abundant in gas of higher metallicity. We discuss this finding in the context of the relative metallicity of the gas phase and solid phase of the ISM. We find that the radial distribution of the 3-He in the ISM is consistent with the expectation that the 3-He is produced in the core and the outer regions of the Galaxy are not yet affected by the production. We discuss this in the context of the Galaxy's history and the evolution of the 3-He abundance in the ISM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Grain Retention and Formation of Planetesimals near the Snow Line in\n  MRI-driven Turbulent Protoplanetary Disks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1272, "human_text": "  The first challenge in the formation of both terrestrial planets and the\ncores of gas giants is the retention of grains in protoplanetary disks. In most\nregions of these disks, gas attains sub-Keplerian speeds as a consequence of a\nnegative pressure gradient. Hydrodynamic drag leads to orbital decay and\ndepletion of the solid material in the disk, with characteristic timescales as\nshort as only a few hundred years for meter-sized objects at 1 AU. In this\npaper, we suggest a particle retention mechanism which promotes the\naccumulation of grains and the formation of planetesimals near the water\nsublimation front or ``snow line.'' This model is based on the assumption that,\nin the regions most interesting for planet formation, the viscous evolution of\nthe disk is due to turbulence driven by the magneto-rotational instability\n(MRI) in the surface layers of the disk. The depth to which MRI effectively\ngenerates turbulence is a strong function of the grain size and abundance. A\nsharp increase in the grain-to-gas density ratio across the snow line reduces\nthe column depth of the active layer. As the disk evolves towards a\nquasi-steady-state, this change in the active layer creates a local maximum in\nradial distribution of the gas surface density and pressure, causing the gas to\nrotate at super-Keplerian speed and halting the inward migration of grains.\nThis senario presents a robust process for grain retention which may aid in the\nformation of proto-gas-giant cores preferentially near the snow line.\n", "machine_text": "\n\nWe investigate the effects of planetesimal formation and growth on the retention of different size grains in protoplanetary disks. We employ a hybrid algorithm combining Monte Carlo and molecular dynamics simulations to follow the collisional evolution of grains and planetesimals. We find that planetesimal formation and growth is most efficient near the snow line, where a large number of small planetesimals can grow into large bodies by colliding with pebbles and staying in the disk. We show that this efficient planetesimal retention due to multiple growth events can explain the preference for large planetesimals over the distance of the disk, without the need for a radial dependence of the planetesimal formation efficiency. Within our model, planetesimals grow efficiently as long as their size is larger than a threshold of about 1 cm. Below this threshold, the number of planetesimals is in general too small to explain the large number of planetesimals larger than 1 km observed in exoplanet systems. We discuss how this threshold may have been reached in the disk by planetesimal formation and evolution. Our model implies that planetesimals grow efficiently as long as the disk has a turbulence intensity above a certain threshold, which is about log(\u03a9/L) \u223c -1.5, where \u03a9 is the typicality length and L is the disk's radial extent. We show that this turbulence level is typical for the solar nebula and many other protoplanetary disks, and is therefore sufficient to explain the rapid growth of planetesimals observed in the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Some properties of the resonant state in quantum mechanics and its\n  computation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1388, "human_text": "  The resonant state of the open quantum system is studied from the viewpoint\nof the outgoing momentum flux. We show that the number of particles is\nconserved for a resonant state, if we use an expanding volume of integration in\norder to take account of the outgoing momentum flux; the number of particles\nwould decay exponentially in a fixed volume of integration. Moreover, we\nintroduce new numerical methods of treating the resonant state with the use of\nthe effective potential. We first give a numerical method of finding a\nresonance pole in the complex energy plane. The method seeks an energy\neigenvalue iteratively. We found that our method leads to a super-convergence,\nthe convergence exponential with respect to the iteration step. The present\nmethod is completely independent of commonly used complex scaling. We also give\na numerical trick for computing the time evolution of the resonant state in a\nlimited spatial area. Since the wave function of the resonant state is\ndiverging away from the scattering potential, it has been previously difficult\nto follow its time evolution numerically in a finite area.\n", "machine_text": "\nWe investigate some properties of the resonant state in quantum mechanics and its computation. We show that the resonant state is very sensitive to the parameters in the Hamiltonian. We find that the optimal quantum algorithm to produce the resonant state, in the asymptotic regime, has the same structure as the classical one. We also show that the computation of the simplest case of the resonant state, the so-called form-factor problem, can be solved with a quantum algorithm that has the same structure as the classical one, but the quantum algorithm is much faster than the classical one. This shows that the resonant state is not as special as it may seem. We also investigate the relation between the resonant state and the ground state. We show that if we have an exact solution of the Schr\u00f6dinger equation for the ground state, then we can use this to produce an approximate solution for the resonant state. We show that this is an important property in practice, for example in the computation of the ground state of the Hamiltonian.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pioneer Anomaly and Accelerating Universe as Effects of the Minkowski\n  Space Conformal Symmetry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2745, "human_text": "  On the basis of the nonisometric transformations subgroup of the SO(4.2)\ngroup, the nonlinear time inhomogeneity one-parameter conformal transformations\nare constructed. The connection between the group parameter and the Hubble\nconstant H0 is established. It is shown that the existence of an anomalous\nblue-shifted frequency drift is a pure kinematic manifestation of the time\ninhomogeneity induced by the Universe expansion. This conclusion is confirmed\nvia a generalization of the standard Special Relativity clock synchronization\nprocedure to the space expanding case. The obtained formulae are in accordance\nwith the observable Pioneer Anomaly effect. The anomalous blue-shifted drift is\nuniversal, does not depend on the presence of graviting centers and can be, in\nprinciple, observed on any frequencies under suitable experimental conditions.\nThe explicit analytic expression for the speed of recession--intergalactic\ndistance ratio is obtained in the form of a function of the red shift z valid\nin the whole range of its variation. In the small z limit this expression\nexactly reproduces the Hubble law. The maximum value of this function at\nz=0.475 quantitatively corresponds to the experimentally found value z(exp) =\n0.46 +/- 0.13 of the transition from the decelerated to the accelerated\nexpansion of the Universe.\n", "machine_text": "\n\nWe show that the Pioneer anomaly and the accelerating universe can be considered as effects of the Minkowski space conformal symmetry. The relativistic corrections to the predicted Galileo acceleration can be obtained from the 4-acceleration and the scalar curvature, in the presence of a small constant acceleration applied to the spaceship. The corrected acceleration shows a linear rise with the distance, reaching the cosmological constant value at large distances. The model is consistent with the observed Pioneer anomaly and with the standard cosmological model, within the precision of the experimental data. We also derive a simple formula for the correction to the acceleration, in terms of the proper time and the distance. The conformal symmetry of the Minkowski space also affects the gravitational field. If the source of the field is moving in a curved space, the field is also curved, in a different way for each of the two possible signs of the scalar curvature. We show that this effect may have interesting applications in quantum gravity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear Dynamics of Infectious Diseases Transfer with Possible\n  Applications for Tubercular Infection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1434, "human_text": "  In this paper, we model a nonlinear dynamics of infectious diseases transfer.\nParticularly, we study possible applications to tubercular infection in models\nwith different profiles (peak values) of the population density dependence on\nspatial coordinates. Our approach is based on the well known method of\ninstantons which has been used by the authors to describe kinetics of adiabatic\nchemical reactions as a function of the heat-bath temperature and other system\nparameters. In our approach, we use \"social temperature\" T as one of the\ncontrolling parameters. Increase of T leads to acceleration of the infectious\ndiseases transfer. The \"blockage\" effect for the infectious diseases transfer\nhas been demonstrated in the case when peak values (in the population density)\nare equal to one and under condition that the \"social temperature\" is low.\nExistence of such effect essentially depends from environment \"activity\"\n(social and prophylactic). Results of our modeling qualitatively meet the\ntuberculosis dynamic spread data in Penza region of Russia.\n", "machine_text": "\n\nTuberculosis (TB) still represents a serious health problem, being one of the main causes of death worldwide. The complex nature of TB and the emerging problems associated with the occurrence of TB are among the main reasons for the lack of efficiency of traditional TB control measures. It is in this context that recent efforts have been made to use mathematical models for a better understanding of TB as a disease and to design optimal control measures. In this sense, the classic paradigm of susceptible-exposed-infectious-removed has been revised and new concepts such as the influence of the spatial structure and the dynamics of the infection have been added. In this work, we present a review of the recent advances in the field of mathematical models of TB, focusing on the effects of the spatial structure and the role of nonlinear dynamics. We analyze the different models proposed in the literature, discussing their assumptions, limitations and results, and we draw attention to the most relevant aspects of each model for a better understanding of the disease dynamics. We also point out open questions and discuss possible applications of the models in order to improve TB control measures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ongoing Galactic Accretion: Simulations and Observations of Condensed\n  Gas in Hot Halos. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0357, "human_text": "  Ongoing accretion onto galactic disks has been recently theorized to progress\nvia the unstable cooling of the baryonic halo into condensed clouds. These\nclouds have been identified as analogous to the High-Velocity Clouds (HVCs)\nobserved in HI in our Galaxy. Here we compare the distribution of HVCs observed\naround our own Galaxy and extra-planar gas around the Andromeda galaxy to these\npossible HVC analogs in a simulation of galaxy formation that naturally\ngenerates these condensed clouds. We find a very good correspondence between\nthese observations and the simulation, in terms of number, angular size,\nvelocity distribution, overall flux and flux distribution of the clouds. We\nshow that condensed cloud accretion only accounts for ~ 0.2 M_solar / year of\nthe current overall Galactic accretion in the simulations. We also find that\nthe simulated halo clouds accelerate and become more massive as they fall\ntoward the disk. The parameter space of the simulated clouds is consistent with\nall of the observed HVC complexes that have distance constraints, except the\nMagellanic Stream which is known to have a different origin. We also find that\nnearly half of these simulated halo clouds would be indistinguishable from\nlower-velocity gas and that this effect is strongest further from the disk of\nthe galaxy, thus indicating a possible missing population of HVCs. These\nresults indicate that the majority of HVCs are consistent with being infalling,\ncondensed clouds that are a remnant of Galaxy formation.\n", "machine_text": "\nWe present numerical simulations and observations of the effects of accretion shock heating on the evolution of molecular clouds in galactic halos. We find that a significant fraction of the gas in the inner part of the halos is heated to temperatures well above the critical temperature for molecular hydrogen, and that this fraction increases with accretion rate. For molecular clouds in these hot halos, we show that the virialization timescale decreases with increasing temperature, and that the clouds are able to survive for much longer times than clouds in the cold halos. We discuss a mechanism that can explain the simultaneous heating and longevity of molecular clouds in hot halos, based on the idea that the clouds are able to thermally stratify and thus to protect their inner regions from direct heating by the shock. We also discuss the effects of the hot halos on the chemical composition of the gas in the clouds, and we show that the chemical evolution is different in cold and hot halos. In particular, we find that the hot halos contain less heavy elements than the cold halos, in qualitative agreement with observations of the chemical composition of the gas in the Galactic halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: VSOP: The Variable Star One-shot Project I. Project presentation and\n  first data release. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4195, "human_text": "  The Variable Star One-shot Project (VSOP) is aimed at (1) providing the\nvariability type and spectral type of all unstudied variable stars, (2)\nprocess, publish, and make the data available as automatically as possible, and\n(3) generate serendipitous discoveries. This first paper describes the project\nitself, the acquisition of the data, the dataflow, the spectroscopic analysis\nand the on-line availability of the fully calibrated and reduced data. We also\npresent the results on the 221 stars observed during the first semester of the\nproject. We used the high-resolution echelle spectrographs HARPS and FEROS in\nthe ESO La Silla Observatory (Chile) to survey known variable stars. Once\nreduced by the dedicated pipelines, the radial velocities are determined from\ncross correlation with synthetic template spectra, and the spectral types are\ndetermined by an automatic minimum distance matching to synthetic spectra, with\ntraditional manual spectral typing cross-checks. The variability types are\ndetermined by manually evaluating the available light curves and the\nspectroscopy. In the future, a new automatic classifier, currently being\ndeveloped by members of the VSOP team, based on these spectroscopic data and on\nthe photometric classifier developed for the COROT and Gaia space missions,\nwill be used. We confirm or revise spectral types of 221 variable stars from\nthe GCVS. We identify 26 previously unknown multiple systems, among them\nseveral visual binaries with spectroscopic binary individual components. We\npresent new individual results for the multiple systems V349 Vel and BC Gru,\nfor the composite spectrum star V4385 Sgr, for the T-Tauri star V1045 Sco, and\nfor DM Boo which we re-classify as a BY Draconis variable. The complete data\nrelease can be accessed via the VSOP web site.\n", "machine_text": "\n\nVSOP: The Variable Star One-shot Project I. Project presentation and first data release.\n\nWe present VSOP, a one-shot variable star observing project using the International Space Station. The project obtained its first observations in January 2017, and in this article we present the project hardware and software, and the first scientific data release. VSOP consists of a camera and a spectrograph, both built by the Italian company CoRIn, installed outside the Columbus module of the International Space Station. The instruments are controlled by the VSOP package, a software suite developed by the VSOP team. VSOP is designed to measure the brightness and color of up to 50,000 stars in our Galaxy, and to obtain high-resolution spectroscopy for up to 1000 stars. The stars will be observed during the twilight zone, when the ISS is in sunlight but the stars are visible, to achieve the best compromise between a large number of stars observed and the quality of the observations. The VSOP data will be used to study stellar brightnesses and colors, to search for new variable stars, to study the structure and kinematics of the Galactic globular clusters, to search for planets around other stars, and to obtain high-resolution spectra of Galactic stars and extra-galactic galaxies. Here we present the first VSOP data release, containing the brightness and color measurements for 100,000 stars in the Galactic globular clusters M5 and M13. The VSOP database will be released to the public after the end of the mission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sparse and Dense Encoding in Layered Associative Network of Spiking\n  Neurons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2491, "human_text": "  A synfire chain is a simple neural network model which can propagate stable\nsynchronous spikes called a pulse packet and widely researched. However how\nsynfire chains coexist in one network remains to be elucidated. We have studied\nthe activity of a layered associative network of Leaky Integrate-and-Fire\nneurons in which connection we embed memory patterns by the Hebbian Learning.\nWe analyzed their activity by the Fokker-Planck method. In our previous report,\nwhen a half of neurons belongs to each memory pattern (memory pattern rate\n$F=0.5$), the temporal profiles of the network activity is split into\ntemporally clustered groups called sublattices under certain input conditions.\nIn this study, we show that when the network is sparsely connected ($F<0.5$),\nsynchronous firings of the memory pattern are promoted. On the contrary, the\ndensely connected network ($F>0.5$) inhibit synchronous firings. The sparseness\nand denseness also effect the basin of attraction and the storage capacity of\nthe embedded memory patterns. We show that the sparsely(densely) connected\nnetworks enlarge(shrink) the basion of attraction and increase(decrease) the\nstorage capacity.\n", "machine_text": "\n\nLayered associative network of spiking neurons is a simple model of cortical tissue, where groups of neurons in one layer are connected to groups of neurons in the next layer. We show that this model can be used to effectively solve the sparse and dense encoding problems. The motivation for this work is the understanding of how cortical tissue processes information to solve these two important tasks, and the insight that a simple model may be able to emulate the behavior of cortical tissue. We show that a layered associative network of spiking neurons can sparse and dense encode input patterns when the network is trained with a set of input patterns that are generated by adding Gaussian white noise to the desired sparse or dense encoded patterns. We show that a small number of parameters can control the strength of the sparse or dense encoding and the width of the encoded patterns. Since the parameters are coupled, they can be efficiently adjusted during a single training session. We also show that the weights of the connections in the network can be efficiently adjusted using an error back-propagation algorithm. Our model also shows some interesting properties of how the network dynamics changes with the number of layers. The theoretical analysis of the proposed model and the practical results obtained with the simulations show that this model is very flexible in learning to sparse and dense encode input patterns.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamic Effects Increasing Network Vulnerability to Cascading Failures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1952, "human_text": "  We study cascading failures in networks using a dynamical flow model based on\nsimple conservation and distribution laws to investigate the impact of\ntransient dynamics caused by the rebalancing of loads after an initial network\nfailure (triggering event). It is found that considering the flow dynamics may\nimply reduced network robustness compared to previous static overload failure\nmodels. This is due to the transient oscillations or overshooting in the loads,\nwhen the flow dynamics adjusts to the new (remaining) network structure. We\nobtain {\\em upper} and {\\em lower} limits to network robustness, and it is\nshown that {\\it two} time scales $\\tau$ and $\\tau_0$, defined by the network\ndynamics, are important to consider prior to accurately addressing network\nrobustness or vulnerability. The robustness of networks showing cascading\nfailures is generally determined by a complex interplay between the network\ntopology and flow dynamics, where the ratio $\\chi=\\tau/\\tau_0$ determines the\nrelative role of the two of them.\n", "machine_text": "\n\nWe consider the problem of increasing network vulnerability to cascading failures. We first review several cascading failure phenomena that have been observed in practice, and for which an analytical understanding has been developed. We then present a general model of a network in which the vulnerability to failure is allowed to dynamically increase as a consequence of local failures. We show that the simplest such model, in which the vulnerability is increased according to a fixed rule, can explain several phenomena that have been observed in real-world networks, including the threshold of the fraction of nodes that needs to fail for the network to stop functioning. We also derive a simple formula for the average number of nodes that need to fail for the network to be rendered inoperable, which has practical applications in estimating the reliability of a network. We then consider the more general case of a network in which the vulnerability is increased dynamically, and we derive a condition that must be satisfied by the dynamics in order for the network to become more vulnerable to failure. We finally consider the problem of estimating the parameters of the dynamic rule by using measurements of the fraction of nodes that fail in response to an injected failure, and we show that this problem can be solved in a least-squares sense.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Inter-network regions of the Sun at millimetre wavelengths. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2304, "human_text": "  The continuum intensity at wavelengths around 1 mm provides an excellent way\nto probe the solar chromosphere. Future high-resolution millimetre arrays, such\nas the Atacama Large Millimeter Array (ALMA), will thus produce valuable input\nfor the ongoing controversy on the thermal structure and the dynamics of this\nlayer. Synthetic brightness temperature maps are calculated on basis of\nthree-dimensional radiation (magneto-)hydrodynamic (MHD) simulations. While the\nmillimetre continuum at 0.3mm originates mainly from the upper photosphere, the\nlonger wavelengths considered here map the low and middle chromosphere. The\neffective formation height increases generally with wavelength and also from\ndisk-centre towards the solar limb. The average intensity contribution\nfunctions are usually rather broad and in some cases they are even\ndouble-peaked as there are contributions from hot shock waves and cool\npost-shock regions in the model chromosphere. Taking into account the\ndeviations from ionisation equilibrium for hydrogen gives a less strong\nvariation of the electron density and with it of the optical depth. The result\nis a narrower formation height range. The average brightness temperature\nincreases with wavelength and towards the limb. The relative contrast depends\non wavelength in the same way as the average intensity but decreases towards\nthe limb. The dependence of the brightness temperature distribution on\nwavelength and disk-position can be explained with the differences in formation\nheight and the variation of temperature fluctuations with height in the model\natmospheres.\n", "machine_text": "\n\nWe present here observations of the Sun at millimetre wavelengths, made with the bolometer array TEFLON/FEP (TF) on the Atacama Large Millimeter Array (ALMA). We observe the solar photosphere at 70 GHz and 80 GHz, and study the brightness distribution at these two frequencies in comparison with the behaviour of the Sun at visible and ultraviolet (UV) wavelengths. The most notable feature in the millimetre data is the appearance of large-scale structures, with a distribution of brightness maxima and minima that is superimposed on the large-scale photospheric features. We show that these millimetre features are related to the distribution of photospheric magnetic flux, as observed in the photosphere itself and in the UV. The correlation is not exact, because the millimetre data are affected by noise and by large-scale brightness variations that are not correlated with the magnetic field. We determine the positions of the magnetic features in the millimetre data by adjusting the magnetic field positions in such a way that the correlation between the two is maximised. We find that the resulting magnetic features in the millimetre data have a spatial resolution that is somewhat higher than in the visible and UV data, and are able to resolve some small-scale features that are not visible in the other data. We discuss this in the framework of a simple model in which the magnetic flux is proportional to the total radiative emission at millimetre wavelengths, and show that this model is in reasonable agreement with the data. We find that the total radiative emission is slightly higher in the millimetre data than would be expected from the magnetic flux, and discuss this in the framework of different physical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Carbon Nanotube Thin Film Field Emitting Diode: Understanding the System\n  Response Based on Multiphysics Modeling. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.168, "human_text": "  In this paper, we model the evolution and self-assembly of randomly oriented\ncarbon nanotubes (CNTs), grown on a metallic substrate in the form of a thin\nfilm for field emission under diode configuration. Despite high output, the\ncurrent in such a thin film device often decays drastically. The present paper\nis focused on understanding this problem. A systematic, multiphysics based\nmodelling approach is proposed. First, a nucleation coupled model for\ndegradation of the CNT thin film is derived, where the CNTs are assumed to\ndecay by fragmentation and formation of clusters. The random orientation of the\nCNTs and the electromechanical interaction are then modeled to explain the\nself-assembly. The degraded state of the CNTs and the electromechanical force\nare employed to update the orientation of the CNTs. Field emission current at\nthe device scale is finally obtained by using the Fowler-Nordheim equation and\nintegration over the computational cell surfaces on the anode side. The\nsimulated results are in close agreement with the experimental results. Based\non the developed model, numerical simulations aimed at understanding the\neffects of various geometric parameters and their statistical features on the\ndevice current history are reported.\n", "machine_text": "\nThe motivation for this work is to understand the physical and electrical mechanisms that govern the electron emission from carbon nanotube thin film field emitting diode (Thin Film FED) in order to improve the efficiency and long-term stability of the device. The key idea is to use multiphysics modeling to investigate the dynamic behavior of the electron emission process. The methodology is based on the combination of hydrodynamic and ballistic models. The results obtained from the simulation show that the hydrodynamic model can explain the observed current-voltage characteristics of the Thin Film FED, and the ballistic model can be used to predict the emission current density as a function of the electric field strength. The practical application of this work is to design and optimize the structure of the Thin Film FED in order to achieve high emission current density and long-term stability. The theoretical application of this work is to understand the physical and electrical mechanisms that govern the electron emission process in the Thin Film FED.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolution of interstellar dust and stardust in the solar neighbourhood. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1155, "human_text": "  The abundance evolution of interstellar dust species originating from stellar\nsources and from condensation in molecular clouds in the local interstellar\nmedium of the Milky Way is studied and the input of dust material to the Solar\nSystem is determined. A one-zone chemical evolution model of the Milky Way for\nthe elemental composition of the disk combined with an evolution model for its\ninterstellar dust component similar to that of Dwek (1998) is developed. The\ndust model considers dust-mass return from AGB stars as calculated from\nsynthetic AGB models combined with models for dust condensation in stellar\noutflows. Supernova dust formation is included in a simple parameterized form\nwhich is gauged by observed abundances of presolar dust grains with supernova\norigin. For dust growth in the ISM a simple method is developed for coupling\nthis with disk and dust evolution models. The time evolution of the abundance\nof the following dust species is followed in the model: silicate, carbon,\nsilicon carbide, and iron dust from AGB stars and from SNe as well as silicate,\ncarbon, and iron dust grown in molecular clouds. It is shown that the\ninterstellar dust population is dominated by dust accreted in molecular clouds;\nmost of the dust material entering the Solar System at its formation does not\nshow isotopic abundance anomalies of the refractory elements, i.e.,\ninconspicuous isotopic abundances do not point to a Solar System origin of dust\ngrains. The observed abundance ratios of presolar dust grains formed in SN\nejecta and in AGB star outflows requires that for the ejecta from SNe the\nfraction of refractory elements condensed into dust is 0.15 for carbon dust and\nis quite small ($\\sim10^{-4}$) for other dust species.\n", "machine_text": "\nWe present an analysis of the evolution of interstellar and stardust within the solar neighbourhood, based on the observation of more than a thousand nearby stars. We show that the local interstellar medium is a large-scale turbulent structure, and that this turbulence is responsible for the relative increase in the mass of small grains in the local interstellar medium compared to the ISM in the distant solar neighbourhood. We determine the growth rate of the small fraction of the ISM, and find that it is in agreement with the prediction of the localisation theory, according to which small grains grow efficiently in the inner part of the ISM. We also show that the growth of the small fraction of the ISM is compatible with a pure diffusion process, in spite of the large-scale structure of the ISM. In addition, we find that the large-scale structure of the local ISM contains a significant amount of stardust, which has been recycled from old stars to the new ones. We compare our predictions concerning the evolution of stardust with observations of old stars, and find a good agreement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Super-Poissonian Shot Noise as a Measure of Dephasing in Closed Quantum\n  Dots. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2668, "human_text": "  Electron-electron interactions play a major role in determining the\nlow-temperature rate of phase loss of electrons in mesoscopic systems. The\nstudy of the dephasing rate is expected to contribute to the understanding of\nthe many-body nature of such systems. Closed quantum dots are of special\ninterest in this respect, due to theoretical predictions suggesting a possible\ntransition temperature below which the dephasing rate vanishes. This prediction\nhas attracted much attention, since closed quantum dots are prime candidates\nfor storage units in quantum computers, and thus their phase coherence\nproperties are of great importance. However, an effective method for measuring\nthe dephasing rate within a closed quantum dot is still lacking. Here we study\ntwo-level systems and show that the Fano factor has a sharp peak as a function\nof the chemical potential, the location of which can be simply related to the\ndephasing rate. We thus suggest to use the properties of the Fano factor peak\nin the super-Poissonian regime as a probe for the dephasing rate.\n", "machine_text": "\nWe report a new method for measuring the inherent dephasing in quantum dots. We show that one can use the shot noise in the emission from a quantum dot to infer the amount of dephasing in the dot. Our approach is based on the fact that for a large class of quantum dots the shot noise has a  super-Poissonian distribution. We show that a simple measurement of the shot noise amplitude can be used to estimate the dephasing, and that this method is more precise than other methods that have been proposed. We also show that our method can be used to distinguish between different sources of dephasing, such as thermal noise and the splitting of the quantum dot energy levels. \n\nWe motivate our work by considering a simple model of a quantum dot, and showing that a shot noise measurement can be used to distinguish between different types of dephasing in the dot. We then propose a practical shot noise measurement scheme, and show that one can obtain a shot noise spectrum by measuring the shot noise amplitude as a function of the laser intensity. We show that our proposed scheme is more precise than other methods that have been proposed for measuring the dephasing in a quantum dot. \n\nOur method can be used to study the dephasing in a quantum dot, and can be used to distinguish between different sources of dephasing. Our method is particularly useful for measuring the dephasing in a quantum dot that is in a solid-state matrix, where other methods that have been proposed are not applicable. Our method can also be used to study the dephasing in a single quantum dot in a cavity, or in a linear chain of quantum dots. We also propose a simple scheme for measuring the dephasing time in a quantum dot, which may be useful for characterizing the dephasing in a quantum dot.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unambiguous coherent state identification: Searching a quantum database. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1892, "human_text": "  We consider an unambiguous identification of an unknown coherent state with\none of two unknown coherent reference states. Specifically, we consider two\nmodes of an electromagnetic field prepared in unknown coherent states alpha_1\nand alpha_2, respectively. The third mode is prepared either in the state\nalpha_1 or in the state alpha_2. The task is to identify (unambiguously) which\nof the two modes are in the same state. We present a scheme consisting of three\nbeamsplitters capable to perform this task. Although we don't prove the\noptimality, we show that the performance of the proposed setup is better than\nthe generalization of the optimal measurement known for a finite-dimensional\ncase. We show that a single beamsplitter is capable to perform an unambiguous\nquantum state comparison for coherent states optimally. Finally we propose an\nexperimental setup consisting of 2N-1 beamsplitters for unambiguous\nidentification among N unknown coherent states. This setup can be considered as\na search in a quantum database. The elements of the database are unknown\ncoherent states encoded in different modes of an electromagnetic field. The\ntask is to specify the two modes that are excited in the same, though unknown,\ncoherent state.\n", "machine_text": "\n\nUnambiguous coherent state identification: Searching a quantum database\nWe propose and analyze a quantum algorithm for unambiguous identification of coherent states of a qubit from a quantum database. The algorithm makes use of the quantum superposition principle and can be realized with elementary quantum gates. We show that if the states to be distinguished are not close in the quantum state space, then the algorithm has a high probability of success. In particular, if one wants to distinguish between two different coherent states which are not close in the Hilbert space, then success can be guaranteed by using only a constant number of quantum gates and resources. We analyze the algorithm efficiency as a function of the distance in the quantum state space between the states to be distinguished and show that it is a continuous function with a sharp threshold. The practical consequence is that one can implement the algorithm in practice with a given number of quantum gates and resources, and if it does not work, then it is guaranteed that it will not work, no matter how long one waits.\n\nWe also propose a quantum algorithm for searching a quantum database for a given state \u03c8. The algorithm is based on the quantum operation of shallow discrimination and uses a series of discrimination operations, each of which discards half of the states in the database which are not close to \u03c8. We show that if \u03c8 is not close to any of the states in the database, then the algorithm has a high probability of success. As for the coherent state identification problem, we analyze the algorithm efficiency as a function of the distance in the quantum state space between \u03c8 and the states in the database, and show that it is a continuous function with a sharp threshold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Extrasolar Planet Census with a Space-based Microlensing Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0454, "human_text": "  A space-based gravitational microlensing exoplanet survey will provide a\nstatistical census of exoplanets with masses down to 0.1 Earth-masses and\norbital separations ranging from 0.5AU to infinity. This includes analogs to\nall the Solar System's planets except for Mercury, as well as most types of\nplanets predicted by planet formation theories. Such a survey will provide\nresults on the frequency of planets around all types of stars except those with\nshort lifetimes. Close-in planets with separations < 0.5 AU are invisible to a\nspace-based microlensing survey, but these can be found by Kepler. Other\nmethods, including ground-based microlensing, cannot approach the comprehensive\nstatistics on the mass and semi-major axis distribution of extrasolar planets\nthat a space-based microlensing survey will provide. The terrestrial planet\nsensitivity of a ground-based microlensing survey is limited to the vicinity of\nthe Einstein radius at 2-3 AU, and space-based imaging is needed to identify\nand determine the mass of the planetary host stars for the vast majority of\nplanets discovered by microlensing. Thus, a space-based microlensing survey is\nlikely to be the only way to gain a comprehensive understanding of the nature\nof planetary systems, which is needed to understand planet formation and\nhabitability. The proposed Microlensing Planet Finder (MPF) mission is an\nexample of a space-based microlensing survey that can accomplish these\nobjectives with proven technology and a cost that fits comfortably under the\nNASA Discovery Program cost cap.\n", "machine_text": "\n\nWe present a space-based microlens survey strategy that uses a combination of fine-grained photometry and astrometry to census extrasolar planets around Milky Way stars. Our method is based on a statistical analysis of the intrinsic microlens light-curve shape and an evaluation of the accuracy with which such curves can be measured. We show that the survey can achieve a level of sensitivity such that it would be capable of detecting planets the size of Mars at the distance of the Earth from the Sun, provided that they are not more than a few AU from their host stars. We describe the types of cameras and telescopes that would be needed for such a survey, and the data processing and telescope/instrument handling required, and present an analysis of the likely yield of the survey. We find that a 5-year survey using a single 1-m telescope would be capable of detecting at least one image per year, and that a network of 4 such telescopes would be capable of detecting up to 10 images per year. We also find that, given the current distribution of telescope time, a survey such as this would require a dedicated telescope network. We discuss the various types of follow-up observations that could be used to characterize the exoplanets detected.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An integral field spectroscopic survey for high redshift damped\n  Lyman-alpha galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0654, "human_text": "  We search for galaxy counterparts to damped Lyman-alpha absorbers (DLAs) at\nz>2 towards nine quasars, which have 14 DLAs and 8 sub-DLAs in their spectra.\nWe use integral field spectroscopy to search for Ly-alpha emission line objects\nat the redshifts of the absorption systems. Besides recovering two previously\nconfirmed objects, we find six statistically significant candidate Ly-alpha\nemission line objects. The candidates are identified as having wavelengths\nclose to the DLA line where the background quasar emission is absorbed. In\ncomparison with the six currently known Ly-alpha emitting DLA galaxies the\ncandidates have similar line fluxes and line widths, while velocity offsets\nbetween the emission lines and systemic DLA redshifts are larger. The impact\nparameters are larger than 10 kpc, and lower column density systems are found\nat larger impact parameters. Assuming that a single gas cloud extends from the\nQSO line of sight to the location of the candidate emission line, we find that\nthe average candidate DLA galaxy is surrounded by neutral gas with an\nexponential scale length of ~5 kpc.\n", "machine_text": "\n\nWe present a catalogue of 75 high redshift damped Lyman-alpha galaxies (DLAs) observed with integral field spectroscopy on the Hubble Space Telescope. These galaxies were selected from an image-based catalogue of over 250 DLA candidates found in an Hubble Ultra-Deep Field survey for bright galaxies with strong ultraviolet ionization continuum sources. Our integral field spectroscopy confirmed that all of our galaxies are at high redshift (z < 1), and revealed the redshifts and optical line-of-sight velocities for each galaxy. We find that the mean redshift of our sample is 0.86 (0.78 - 0.92), and the mean line-of-sight velocity is -69 km/s (68 - -74 km/s). Using the updated distance measurements from the Hubble Deep Field Survey, we find that the DLA galaxies lie at mean distances of 80 - 200 Mpc. Our high redshift DLAs are found to be relatively rich in neutral hydrogen gas (10 - 25 per cent of the critical density for reionization), and are possibly the galaxies responsible for the reionization of the Universe. We discuss our galaxies in the context of other high redshift DLAs, and in terms of galaxy formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detailed kinetic study of the ring opening of cycloalkanes by CBS-QB3\n  calculations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.07, "human_text": "  This work reports a theoretical study of the gas phase unimolecular\ndecomposition of cyclobutane, cyclopentane and cyclohexane by means of quantum\nchemical calculations. A biradical mechanism has been envisaged for each\ncycloalkane, and the main routes for the decomposition of the biradicals formed\nhave been investigated at the CBS-QB3 level of theory. Thermochemical data\n(\\delta H^0_f, S^0, C^0_p) for all the involved species have been obtained by\nmeans of isodesmic reactions. The contribution of hindered rotors has also been\nincluded. Activation barriers of each reaction have been analyzed to assess the\n1 energetically most favorable pathways for the decomposition of biradicals.\nRate constants have been derived for all elementary reactions using transition\nstate theory at 1 atm and temperatures ranging from 600 to 2000 K. Global rate\nconstant for the decomposition of the cyclic alkanes in molecular products have\nbeen calculated. Comparison between calculated and experimental results allowed\nto validate the theoretical approach. An important result is that the\nrotational barriers between the conformers, which are usually neglected, are of\nimportance in decomposition rate of the largest biradicals. Ring strain\nenergies (RSE) in transition states for ring opening have been estimated and\nshow that the main part of RSE contained in the cyclic reactants is removed\nupon the activation process.\n", "machine_text": "\n\nWe present a detailed kinetic study of the ring opening of cycloalkanes by CBS-QB3 calculations. The motivation for the work was the significant discrepancy between the experimentally observed reaction pathways and the paths predicted by QST2, the most widely used method for describing non-bonded interactions. Our key ideas and methodology were to carefully examine the effects of four factors that have been proposed to affect the ring opening process: (1) the ring strain, (2) the aliphatic carbon chain length, (3) the number of carbon atoms in the largest ring, and (4) the position of the ring-opening event. Our results obtained from CBS-QB3 calculations show that these four factors do not have a major effect on the ring-opening process. We also discuss the reasons why QST2 may have failed to describe the reaction pathway. Our work attempts to solve the problem of how to model the ring-opening process of cycloalkanes and has practical implications for the design of new drugs and the study of the mechanism of drug action.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetic fluctuations in n-type high-$T_c$ superconductors reveal\n  breakdown of fermiology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4424, "human_text": "  By combining experimental measurements of the quasiparticle and dynamical\nmagnetic properties of optimally electron-doped Pr$_{0.88}$LaCe$_{0.12}$CuO$_4$\nwith theoretical calculations we demonstrate that the conventional fermiology\napproach cannot possibly account for the magnetic fluctuations in these\nmaterials. In particular, we perform tunneling experiments on the very same\nsample for which a dynamical magnetic resonance has been reported recently and\nuse photoemission data by others on a similar sample to characterize the\nfermionic quasiparticle excitations in great detail. We subsequently use this\ninformation to calculate the magnetic response within the conventional\nfermiology framework as applied in a large body of work for the hole-doped\nsuperconductors to find a profound disagreement between the theoretical\nexpectations and the measurements: this approach predicts a step-like feature\nrather than a sharp resonance peak, it underestimates the intensity of the\nresonance by an order of magnitude, it suggests an unreasonable temperature\ndependence of the resonance, and most severely, it predicts that most of the\nspectral weight resides in incommensurate wings which are a key feature of the\nhole-doped cuprates but have never been observed in the electron-doped\ncounterparts. Our findings strongly suggest that the magnetic fluctuations\nreflect the quantum-mechanical competition between antiferromagnetic and\nsuperconducting orders.\n", "machine_text": "\nWe have performed a systematic study of the evolution of the spin correlation function in the n-type high-$T_c$ superconductor CeCoIn_5 at low temperatures, in the weak-to-non-correlated regime, using neutron-scattering techniques. We find that the single-particle spectral function at theCo-based Fermi surface is shredded into a large number of multiply-degenerate, commensurate quantum states. The nature of this structure is consistent with a crossover from a regular, higher-dimensional, periodic spectrum to a coarsely-faceted, lower-dimensional, non-periodic spectrum. We show this by performing a mathematical analysis of the recent theory of dresser pockets. The results explain why the pairing correlation function in this material does not follow the universal behavior predicted by the Dresselhaus-Dresse-Wohlfarth theory, but instead shows a strong preference for in-plane correlations. We also show that this breakdown of fermiology has a strong impact on the effective two-spinon correlation function, in a way which is consistent with the large number of low-spin states produced by the Megan mechanism. Our results suggest that the breakdown of the periodic structure of the spectral function is a generic feature of cuprate-based superconductors, and may be a signature of the onset of a low-spin state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A New Tool for Seismology--the Cumulative Spectral Power. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.11, "human_text": "  The power spectral density (PSD) function is commonly used to specify\nseismometer performance. It is derived from the FFT of acceleration and\ncorrection is made for the transfer function of the instrument that generated\nthe data. As with any such spectrum of density (`per Hz') type, the noise\ninherent to a PSD is large. This article illustrates the value of a function\nthat is derived from the PSD and for which the influence of noise is\nsignificantly reduced. Called the cumulative spectral power (CSP), it is\nobtained from the PSD through the noise-reducing process of integration. The\nmaximum of the CSP (corresponding to the longest graphed value of the period)\nprovides a means for estimating the total vibrational power of the earth. The\npresent author has significantly simplified the process of PSD generation. Thus\nroutine graphing is straightforwared-of first the FFT, followed by the\ngeneration of both a PSD and its associated CSP. The unique properties of the\nCSP make it valuable for the study of a variety of earth dynamics. For example,\nthe strking simplicity of a CSP graph generated from a record containing a\nstrong teleseismic earthquake is undoubtedly important to the development and\nrefinement of any viable theory of earthquake dynamics.\n", "machine_text": "\n\nA New Tool for Seismology--the Cumulative Spectral Power.\n\nWe introduce a new measure of seismic activity, based on the cumulative spectral power, which we name the \"cumulative spectral moment.\" This measure has several attractive features, including the property that it is decorrelated with the location, size, and orientation of the fault system. We show that the cumulative spectral moment is related to the familiar moment magnitude scale, but the relationship is very weak, which makes the cumulative spectral moment a more robust measure of seismic activity. We find that the cumulative spectral moment has a clear inverse relation with the rate of moment release, which we show is a consequence of the physical relation between the seismic moment and the energy radiated by the Earth's vibrations. We point out that the conventional seismic moment is not a good measure of activity because it is very strongly correlated with the size and orientation of the fault system. We show that the cumulative spectral moment has several other interesting properties, including a strong tendency to increase in bursts, a tendency to have a power law distribution on long time scales, and a linear relation with the amount of energy released by the seismic events. The cumulative spectral moment has several practical applications, including as a way to detect activity that is not visible on other moment measures, as a way to identify different seismic sources, and as a way to study the dynamics of the moment release.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scattering amplitudes in strongly coupled N=4 SYM from semiclassical\n  strings in AdS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2113, "human_text": "  Very recently in arXiv:0705.0303 Alday and Maldacena gave a string theory\nprescription for computing (all) planar amplitudes in N=4 supersymmetric gauge\ntheory at strong coupling using the AdS/CFT correspondence. These amplitudes\nare determined by a classical string solution and contain a universal\nexponential factor involving the action of the classical string. On the gauge\ntheory side, expressions for perturbative amplitudes at strong coupling were\npreviously proposed only for specific helicities of external particles -- the\nmaximally helicity violating or MHV amplitudes. These follow from the\nexponential ansatz of Bern, Dixon and Smirnov for MHV amplitudes in N=4 SYM. In\nthis paper we examine the amplitudes dependence on helicities and\nparticle-types of external states. We consider the prefactor of string\namplitudes and give arguments suggesting that the prefactor at strong coupling\nshould be the same as the Yang-Mills tree-level amplitude for the same process.\nThis implies that scattering amplitudes in N=4 SYM simplify dramatically in the\nstrong coupling limit. It follows from our proposal that in this limit all (MHV\nand non-MHV) n-point amplitudes are given by the (known) tree-level Yang-Mills\nresult times the helicity-independent (and particle-type-independent) universal\nexponential.\n", "machine_text": "\nWe give a detailed derivation of the N=4 superYang-Mills scattering amplitudes in the semiclassical limit from the string theory in anti-de Sitter space. In particular we show that the string theory in anti-de Sitter space is equivalent to the N=4 superYang-Mills theory with a non-Abelian symmetry group with certain parameters in the space-time. We obtain the scattering amplitudes in the limit where the non-Abelian symmetry group becomes Abelian and the parameters go to their semiclassical values. As an application we consider the N=4 superYang-Mills theory with an adjoint representation $\\Gamma^+$ of the non-Abelian symmetry group and obtain the scattering amplitudes in the semiclassical limit for a single adjoint representation and for a combination of several adjoint representations. We compare our results with the recent results of Deiss and Stern (arXiv:1205.5667) who consider the Yang-Mills theory with an adjoint representation and obtain the semiclassical scattering amplitudes by using the Regge theory. We show that our approach is more general and can be applied to the theories with an arbitrary representation of the non-Abelian symmetry group, not only to the adjoint representation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mass loss from Luminous Blue Variables and Quasi-Periodic Modulations of\n  Radio Supernovae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2689, "human_text": "  Massive stars, supernovae (SNe), and long-duration gamma-ray bursts (GRBs)\nhave a huge impact on their environment. Despite their importance, a\ncomprehensive knowledge of which massive stars produce which SN/GRB is hitherto\nlacking. We present a brief overview about our knowledge of mass loss in the\nHertzsprung-Russell Diagram (HRD) covering evolutionary phases of the OB main\nsequence, the unstable Luminous Blue Variable (LBV) stage, and the Wolf-Rayet\n(WR) phase. Despite the fact that metals produced by ``self-enrichment'' in WR\natmospheres exceed the initial -- host galaxy -- metallicity, by orders of\nmagnitude, a particularly strong dependence of the mass-loss rate on the\ninitial metallicity is found for WR stars at sub-solar metallicities (1/10 --\n1/100 solar). This provides a significant boost to the collapsar model for\nGRBs, as it may present a viable mechanism to prevent the loss of angular\nmomentum by stellar winds at low metallicity, whilst strong Galactic WR winds\nmay inhibit GRBs occurring at solar metallicities. Furthermore, we discuss\nrecently reported quasi-sinusoidal modulations in the radio lightcurves of SNe\n2001ig and 2003bg. We show that both the sinusoidal behaviour and the\nrecurrence timescale of these modulations are consistent with the predicted\nmass-loss behaviour of LBVs, and we suggest LBVs may be the progenitors of some\ncore-collapse SNe.\n", "machine_text": "\n\nWe present a model for the mass loss from Luminous Blue Variables (LBVs) and the quasi-periodic modulations of Radio Supernovae (RSNe). The model is based on the assumption that the mass loss from LBVs and the accretion onto RSNs is driven by the same dynamical mechanism. The model also accounts for the evolution of the system's internal structure, in particular, the core-envelope system. We show that the mass-loss rate from LBVs is proportional to the shocked gas density, and the proportionality constant is given by the square of the frequency of the quasi-periodic modulation of RSNs. We evaluate the time-scales of the mass loss and the evolution of the core-envelope system. We show that the mass-loss rate is high at the early stage of evolution, but it is very low at the late stage of evolution. Therefore, the mass-loss rate is rather well controlled, and it is not likely that the massive gas ejection from LBVs causes the quasi-periodic modulations of RSNs. We discuss several possible physical mechanisms of the quasi-periodic modulations, and we show that a simple model of a single-frequency model can explain a wide range of observed properties of the quasi-periodic modulations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum Hall ferromagnetism in graphene: a SU(4) bosonization approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3671, "human_text": "  We study the quantum Hall effect in graphene at filling factors \\nu = 0 and\n\\nu = \\pm, concentrating on the quantum Hall ferromagnetic regime, within a\nnon-perturbative bosonization formalism. We start by developing a bosonization\nscheme for electrons with two discrete degrees of freedom (spin-1/2 and\npseudospin-1/2) restricted to the lowest Landau level. Three distinct phases\nare considered, namely the so-called spin-pseudospin, spin, and pseudospin\nphases. The first corresponds to a quarter-filled (\\nu =-1) while the others to\na half-filled (\\nu = 0) lowest Landau level. In each case, we show that the\nelementary neutral excitations can be treated approximately as a set of\nn-independent kinds of boson excitations. The boson representation of the\nprojected electron density, the spin, pseudospin, and mixed spin-pseudospin\ndensity operators are derived. We then apply the developed formalism to the\neffective continuous model, which includes SU(4) symmetry breaking terms,\nrecently proposed by Alicea and Fisher. For each quantum Hall state, an\neffective interacting boson model is derived and the dispersion relations of\nthe elementary excitations are analytically calculated. We propose that the\ncharged excitations (quantum Hall skyrmions) can be described as a coherent\nstate of bosons. We calculate the semiclassical limit of the boson model\nderived from the SU(4) invariant part of the original fermionic Hamiltonian and\nshow that it agrees with the results of Arovas and co-workers for SU(N) quantum\nHall skyrmions. We briefly discuss the influence of the SU(4) symmetry breaking\nterms in the skyrmion energy.\n", "machine_text": "\nWe investigate the problem of endowing graphene with a non-trivial band structure by means of a SU(4) bosonization. In particular we show that a peculiar kind of quasi-particle, called a fermitron, can arise in this setting. This new kind of particle is characterized by a non-trivial internal structure, giving rise to a large number of distinct eigenvalues for the kinetic energy. We show that this fact has important consequences for the nature of the non-trivial band structure that may be obtained in this way. In particular we show that the resulting band structure may be described in terms of a set of inter-related Higgs bundles, which are protected by a set of non-trivial symmetries, and which may be related to the so-called Higgs ghosts. We show that this structure may be understood as a kind of quantum Hall effect, in which the \"cyclotron\" is replaced by a \"fermitron\". We also show that a large class of gauge symmetries may be realized in this setting, in a way which is consistent with the theory of Higgs bundles. This suggests that the structure we obtain is a generalization of the ordinary quantum Hall effect to a large class of systems which include graphene.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Solar heavy element abundance: constraints from frequency separation\n  ratios of low-degree p modes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3154, "human_text": "  We use very precise frequencies of low-degree solar-oscillation modes\nmeasured from 4752 days of data collected by the Birmingham Solar-Oscillations\nNetwork (BiSON) to derive seismic information on the solar core. We compare\nthese observations to results from a large Monte Carlo simulation of standard\nsolar models, and use the results to constrain the mean molecular weight of the\nsolar core, and the metallicity of the solar convection zone. We find that only\na high value of solar metallicity is consistent with the seismic observations.\nWe can determine the mean molecular weight of the solar core to a very high\nprecision, and, dependent on the sequence of Monte Carlo models used, find that\nthe average mean molecular weight in the inner 20% by radius of the Sun ranges\nfrom 0.7209 to 0.7231, with uncertainties of less than 0.5% on each value. Our\nlowest seismic estimate of solar metallicity is Z=0.0187 and our highest is\nZ=0.0239, with uncertainties in the range of 12--19%. Our results indicate that\nthe discrepancies between solar models constructed with low metallicity and the\nhelioseismic observations extend to the solar core and thus cannot be\nattributed to deficiencies in the modeling of the solar convection zone.\n", "machine_text": "\n\nWe present an analysis of the frequency separation ratios (FSRs) of low-degree p modes for 78 F- and G-type stars in an effort to derive solar abundances of the heavy elements. The FSRs are computed using the public socialism database (SDB), which contains high-resolution spectroscopic data that have been analyzed in support of the NASA Themis mission. We have derived the abundances of the heavy elements for each star in the SDB sample by fitting the observed FSRs to the theoretical relationships derived from the Solar Census Database (SCD). We find that the derived abundances are in good agreement with those obtained from a recent analysis of high-resolution solar spectrum data (169 elements, this work) and with the chemical composition of the Sun as derived from the study of the solar photosphere (93 elements, these data). We determine the abundances of nine elements (Ce, Cr, Fe, Co, Ni, Cu, Zn, Ga, In, and Sn) for which the SCD relationships were derived from a sample of 34 G stars which have no detected magnetic activity. The derived abundances are in good agreement with those obtained from a sample of 14 G stars which have detected magnetic activity (Bohigas et al., 1999). We conclude that the SCD relationships for these elements can be applied to solar twins, even if the latter have magnetic activity. We discuss the impact of the assumptions made in the derivation of the SCD relationships on the derived abundances, and we point out evidence that the diffusion coefficients used to derive the SCD relationships may be too large. We also discuss the impact of the possible differences between the observing and model stars in the derivation of the FSRs on the derived abundances. We find that these effects are negligible for the analysis of the FSRs of low-degree p modes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: GLSM's for partial flag manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1761, "human_text": "  In this paper we outline some aspects of nonabelian gauged linear sigma\nmodels. First, we review how partial flag manifolds (generalizing\nGrassmannians) are described physically by nonabelian gauged linear sigma\nmodels, paying attention to realizations of tangent bundles and other aspects\npertinent to (0,2) models. Second, we review constructions of Calabi-Yau\ncomplete intersections within such flag manifolds, and properties of the gauged\nlinear sigma models. We discuss a number of examples of nonabelian GLSM's in\nwhich the Kahler phases are not birational, and in which at least one phase is\nrealized in some fashion other than as a complete intersection, extending\nprevious work of Hori-Tong. We also review an example of an abelian GLSM\nexhibiting the same phenomenon. We tentatively identify the mathematical\nrelationship between such non-birational phases, as examples of Kuznetsov's\nhomological projective duality. Finally, we discuss linear sigma model moduli\nspaces in these gauged linear sigma models. We argue that the moduli spaces\nbeing realized physically by these GLSM's are precisely Quot and hyperquot\nschemes, as one would expect mathematically.\n", "machine_text": "\nWe introduce a general framework for the study of semi-simple submanifolds of flag manifolds. Flag manifolds are semi-simple by definition, so the question of simplicity is settled. However, they are also specified by a partition into subspaces, which can be nontrivial. We show that a generic semi-simple submanold of a flag manifold is a partially-flagged submanifold, i.e., it is a submanifold of the flag manifold on which the restriction of the flagging remains a flagging. We consider several classes of semi-simple submanifolds which have natural motivations from the theory of discrete semi-simple submanifolds of Lie groups. In particular, we show that any such submanifold is a partially-flagged submanold. We show that a submanifold of a flag manifold is a partially-flagged submanifold if and only if it is an inclusion of a subspace of the flag manifold. This answers a question of Greene, and provides a necessary and sufficient condition for a submanold to be a partially-flagged submanold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Capacity Gain from Two-Transmitter and Two-Receiver Cooperation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3644, "human_text": "  Capacity improvement from transmitter and receiver cooperation is\ninvestigated in a two-transmitter, two-receiver network with phase fading and\nfull channel state information available at all terminals. The transmitters\ncooperate by first exchanging messages over an orthogonal transmitter\ncooperation channel, then encoding jointly with dirty paper coding. The\nreceivers cooperate by using Wyner-Ziv compress-and-forward over an analogous\northogonal receiver cooperation channel. To account for the cost of\ncooperation, the allocation of network power and bandwidth among the data and\ncooperation channels is studied. It is shown that transmitter cooperation\noutperforms receiver cooperation and improves capacity over non-cooperative\ntransmission under most operating conditions when the cooperation channel is\nstrong. However, a weak cooperation channel limits the transmitter cooperation\nrate; in this case receiver cooperation is more advantageous.\nTransmitter-and-receiver cooperation offers sizable additional capacity gain\nover transmitter-only cooperation at low SNR, whereas at high SNR transmitter\ncooperation alone captures most of the cooperative capacity improvement.\n", "machine_text": "\n\nWe investigate cooperation among two transmitters and two receivers in a wireless relay network. We assume that the two transmitters have independent information to send to the two receivers, and that they share a common (wireless) relay channel to communicate. We find that the relays can substantially increase the capacity of the network, in the sense that the rates achievable by the transmitters increase substantially if the relays are allowed to cooperate in the transmission process. We show that this result can be guaranteed by using a generalized family of schedules, which we call semi- schedules, to describe the cooperation protocol. We analyze the performance of the protocol under various assumptions about the models for the wireless channels and the information available at the relays. In particular, we show that in a network where the receivers are assumed to have perfect information about the wireless channels and where the transmitters have correlated information, the capacity gain provided by the relays can be very large. We also consider the effect of allowing the relays to make errors in their transmission process, and show that even in this case, the relays can still increase the capacity of the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radiative Transfer Effect on Ultraviolet Pumping of the 21cm Line in the\n  High Redshift Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0895, "human_text": "  During the epoch of reionization the 21cm signal is sensitive to the\nscattering rate of the ultraviolet photons, redshifting across the Lyman_alpha\nresonance. Here we calculate the photon scattering rate profile for a single\nultraviolet source. After taking into account previously neglected natural\nbroadening of the resonance line, we find that photons approach the resonance\nfrequency and experience most scatterings at a significantly smaller distance\nfrom the source than naively expected r=(dnu/nu_0)(c/H), where dnu=nu-nu_0 is\nthe initial frequency offset, and the discrepancy increases as the initial\nfrequency offset decreases. As a consequence, the scattering rate P(r) drops\nmuch faster with increasing distance than the previously assumed 1/r^2 profile.\nNear the source (r<1Mpc comoving), the scattering rate of photons that redshift\ninto the Ly_alpha resonance converges to P(r) \\propto r^{-7/3}. The scattering\nrate of Ly_alpha photons produced by splitting of photons that redshift into a\nhigher resonance (Ly_gamma, Ly_delta, etc.) is only weakly affected by the\nradiative transfer, while the sum of scattering rates of Ly_alpha photons\nproduced from all higher resonances also converges to P(r) \\propto r^{-7/3}\nnear the source. At 15<z<35, on scales of ~0.01-20Mpc/h (comoving), the total\nscattering rate of Ly_alpha photons from all Lyman resonances is found to be\nhigher by a factor of ~1+0.3[(1+z)/20]^{2/3} than obtained without full\nradiative transfer. Consequently, during the early stage of reionization, the\ndifferential brightness of 21cm signal against the cosmic microwave background\nis also boosted by a similar factor.\n", "machine_text": "\n\nWe present a radiative transfer investigation of the ultraviolet (UV) pumping of the 21cm line in the high redshift universe. We consider the effect of the radiative transfer in the intergalactic medium (IGM) and the impact of the discrete absorption and emission by the gas on the 21cm line. We find that the radiative transfer in the IGM has little effect on the central part of the 21cm line, but produces a characteristic broadened wings. The discrete absorption and emission by the gas results in a systematic shift of the 21cm line, and can produce a misleading signal if the absorption and the emission are not properly accounted for. We also present a model for the radiative transfer in the IGM that can be used to predict the 21cm line radiative transfer in a given medium. \n\nWe have investigated the radiative transfer effect on the ultraviolet (UV) pumping of the 21cm line in the high redshift universe. We have found that the radiative transfer in the intergalactic medium (IGM) has little effect on the central part of the 21cm line, but produces a characteristic broadened wings. The discrete absorption and emission by the gas results in a systematic shift of the 21cm line, and can produce a misleading signal if the absorption and the emission are not properly accounted for. We have also presented a model for the radiative transfer in the IGM that can be used to predict the 21cm line radiative transfer in a given medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Haunted Halos of Andromeda and Triangulum: A panorama of galaxy\n  formation in action. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1318, "human_text": "  We present a deep photometric survey of M31, conducted with the CFHT and INT,\ncovering the inner 50 kpc of the galaxy, the Southern quadrant out to 150 kpc,\nand extending to M33. This is the first systematic panoramic study of this very\noutermost region of galaxies. We detect several streams and other large-scale\nstructures, and two new dwarf galaxies: And XV and XVI. The discovery of\nsubstructure on the minor axis, together with the fact that the light profile\nbetween 0.5 < R < 1.3 follows the exponential ``extended disk'', is\nparticularly important in shedding light on the mixed and sometimes conflicting\nresults reported in previous studies. Underlying the substructures lies a\nfaint, metal-poor, smooth and extremely extended halo, reaching out to at least\n150 kpc. The smooth halo component in M31 has a profile that can be fit with a\nHernquist model of immense scale radius ~55 kpc, almost a factor of 4 larger\nthan theoretical predictions. Alternatively a power-law with exponent -1.91 +/-\n0.11 can be fit to the profile. The total luminosity of this structure is\nsimilar to that of the halo of the Milky Way. This vast, smooth, underlying\nhalo is reminiscent of a classical monolithic model and completely unexpected\nfrom modern galaxy formation models. M33 is also found to have an extended\nmetal-poor halo component, which can be fit with a Hernquist model also of\nscale radius ~55 kpc. These extended slowly-decreasing halos will provide a\nchallenge and strong constraints for further modeling. [Abridged]\n", "machine_text": "\nWe present a panoramic imaging survey of the stellar halos in the galaxies of Andromeda (M31) and Triangulum (M33), a pair of giant spiral galaxies in the Local Group. We find that the stellar halos of both galaxies aredominated by the repeated accretion of dwarf galaxies, whose orbits are controlled by the gravity of the giant galaxies. In the case of M33, we have discovered a chain of 16 accretion events, a number that increases to 37 if the satellites in the widest orbits are included. These satellites show a well-defined correlation between their orbital speeds and distances, indicating that the accretion events are governed by the viscous evolution of the satellite clouds. We have identified the galaxies that were involved in the accretion events and determined their orbits. We have also estimated the mass of the accreted satellites and compared it with the theoretical predictions of the galactic encounter problem. Our analysis reveals that the observed accretion events are consistent with the repeated accretion of satellites with masses between 10^8 and 10^9 M_(\u2299), and that the encounter problem can successfully explain the origin of the observed structure in the stellar halos of M33. In the case of M31, we have discovered four main accretion events, and the interpretation of these events requires an additional mechanism to explain the exceptional concentration of mass in the western half of the galaxy. We discuss several possibilities, including the possible contribution of supermassive black holes to the dynamical evolution of the stellar halos.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An expansion for self-interacting random walks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0614, "human_text": "  We derive a perturbation expansion for general self-interacting random walks,\nwhere steps are made on the basis of the history of the path. Examples of\nmodels where this expansion applies are reinforced random walk, excited random\nwalk, the true (weakly) self-avoiding walk, loop-erased random walk, and\nannealed random walk in random environment.\n  In this paper we show that the expansion gives rise to useful formulae for\nthe speed and variance of the random walk, when these quantities are known to\nexist. The results and formulae of this paper have been used elsewhere by the\nauthors to prove monotonicity properties for the speed (in high dimensions) of\nexcited random walk and related models, and certain models of random walk in\nrandom environment.\n  We also derive a law of large numbers and central limit theorem (with\nexplicit error terms) directly from this expansion, under strong assumptions on\nthe expansion coefficients. The assumptions are shown to be satisfied by\nexcited random walk in high dimensions with small excitation parameter, a model\nof reinforced random walk with underlying drift and small reinforcement\nparameter, and certain models of random walk in random environment under strong\nellipticity conditions. This is the extended version of the paper, where we\nprovide all proofs.\n", "machine_text": "\nWe consider an expansion for self-interacting random walks. The expansion is in terms of the probability of large deviations from the mean. The motivation for this work is to provide a general method for constructing expansions for random walks which are self-similar in the limit. The key ideas are that, for any positive real number $\\epsilon$, the probability of a large deviation from the mean can be written as a power series in terms of the generating function for the random walk and $\\epsilon$. To derive this result, we first show that the probability of a large deviation from the mean for the simple random walk can be written as a power series in terms of the generating function. We then show that the probability of a large deviation from the mean for a self-interacting random walk can be written as a power series in terms of the generating function for the random walk and a small parameter $\\epsilon$. The resulting expansion for the probability of a large deviation from the mean for a self-interacting random walk is shown to agree with the result of Foster and rather nicely unify the results of different researchers. The problem this work attempts to solve is to construct a general expansion for self-interacting random walks which is self-similar in the limit. The practical application of this work is that it provides a general method for constructing expansions for self-interacting random walks. The theoretical application of this work is that it provides a general method for constructing expansions for random walks which are self-similar in the limit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The remarkable X-ray spectrum of the Broad-Line Radio Galaxy 3C 445. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3053, "human_text": "  We present the results of the analysis of an archival 15 ks XMM-Newton\nobservation of the nearby (z=0.057) radio-loud source 3C445, optically\nclassified as a Broad-Line Radio Galaxy. While the RGS data are of insufficient\nquality to allow a meaningful analysis, the EPIC data show a remarkable X-ray\nspectrum. The 2-10 keV continuum is described by a heavily absorbed (Nh~ 1e22 -\n1e23 cm-2) power law with photon index Gamma ~1.4, and strong (R~2) cold\nreflection. A narrow, unresolved Fe Kalpha emission line is detected,\nconfirming previous findings, with EW 120eV. A soft excess is present below 2\nkeV over the extrapolation of the hard X-ray power law, which we model with a\npower law with the same photon index as the hard power law, absorbed by a\ncolumn density Nh=6e20 cm-2 in excess to Galactic. A host of emission lines are\npresent below 2 keV, confirming previous indications from ASCA, due to H- and\nHe-like O, Mg, and Si. We attribute the origin of the lines to a photoionized\ngas, with properties very similar to radio-quiet obscured AGN. Two different\nionized media, or a single stratified medium, are required to fit the soft\nX-ray data satisfactorily. The similarity of the X-ray spectrum of 3C445 to\nSeyferts underscores that the central engines of radio-loud and radio-quiet AGN\nsimilarly host both cold and warm gas.\n", "machine_text": "\n\nWe present a study of the X-ray spectrum of the broad-line radio galaxy 3C 445. We find that the iron line at 6.4 keV is significantly blended with a line at 7.2 keV, which we attribute to the decay of radioactive thorium. This is the first detection of a thorium line in the X-ray spectrum of a galaxy. The intensity of the thorium line is at least one order of magnitude higher than that of the iron line. The observed count rate of the thorium line is also one order of magnitude higher than the predicted one based on the measured thorium content in the galaxy. This implies that the thorium is not distributed homogeneously in the inner 4 kpc of the galaxy, and there may be a large amount of thorium in the central region. The observation also suggests that the 6.4 keV iron line may be contaminated by the thorium line in many broad-line radio galaxies. We have estimated the energy distribution of the X-ray radiation from the non-thermal continuum, and find that the contribution from the thermal continuum is only 7% of the total X-ray flux. This suggests that the accretion onto the supermassive black hole in the central region is not very efficient. The fraction of the X-ray flux from the core region of 3C 445 is estimated to be about 30%. The shape of the X-ray spectrum is well described by a power law with a photon index of 1.8. We have compared the X-ray spectra of 3C 445 with those of three other nearby broad-line radio galaxies (3C 231, 3C 334, and 3C 933), and found that they are very different. This suggests that the accretion onto the supermassive black hole is efficient in some broad-line radio galaxies, but not in others.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Efficient Simulations of Early Structure Formation and Reionization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0946, "human_text": "  We present a method to construct semi-numerical ``simulations'', which can\nefficiently generate realizations of halo distributions and ionization maps at\nhigh redshifts. Our procedure combines an excursion-set approach with\nfirst-order Lagrangian perturbation theory and operates directly on the linear\ndensity and velocity fields. As such, the achievable dynamic range with our\nalgorithm surpasses the current practical limit of N-body codes by orders of\nmagnitude. This is particularly significant in studies of reionization, where\nthe dynamic range is the principal limiting factor. We test our halo-finding\nand HII bubble-finding algorithms independently against N-body simulations with\nradiative transfer and obtain excellent agreement. We compute the size\ndistributions of ionized and neutral regions in our maps. We find even larger\nionized bubbles than do purely analytic models at the same volume-weighted mean\nhydrogen neutral fraction. We also generate maps and power spectra of 21-cm\nbrightness temperature fluctuations, which for the first time include\ncorrections due to gas bulk velocities. We find that velocities widen the tails\nof the temperature distributions and increase small-scale power, though these\neffects quickly diminish as reionization progresses. We also include some\npreliminary results from a simulation run with the largest dynamic range to\ndate: a 250 Mpc box that resolves halos with masses M >~ 2.2 x10^8 M_sun. We\nshow that accurately modeling the late stages of reionization requires such\nlarge scales. The speed and dynamic range provided by our semi-numerical\napproach will be extremely useful in the modeling of early structure formation\nand reionization.\n", "machine_text": "\nWe present a detailed study of the structure and evolution of the cosmic large-scale structure, using a combination of sophisticated numerical simulations and semi-analytic models. We find that the large-scale structure grows efficiently, in a self-similar manner, with a power law exponent of 1.7 \u00b1 0.1, and is consistent with the predictions of the standard theory of structure formation. However, we find that the small-scale structure, responsible for the bulk of the mass, has a different power law exponent, 2.4 \u00b1 0.2, and is more efficiently coupled to the large-scale structure than the standard theory predicts. Our results suggest that the small-scale structure forms efficiently, in a self-similar manner, with the large-scale structure. We also present a detailed study of the evolution of ionization in the early Universe. We find that the ionization fraction increases non-monotonically, with a power law exponent of 2.4 \u00b1 0.2, and is consistent with the predictions of the standard theory of reionization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HD 98800: A 10-Myr-Old Transition Disk. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.038, "human_text": "  We present the mid-infrared spectrum, obtained with the Spitzer Infrared\nSpectrograph (IRS), of HD 98800, a quadruple star system located in the\n10-Myr-old TW Hydrae association. It has a known mid-infrared excess that\narises from a circumbinary disk around the B components of the system. The IRS\nspectrum confirms that the disk around HD 98800 B displays no excess emission\nbelow about 5.5 micron, implying an optically thick disk wall at 5.9 AU and an\ninner, cleared-out region; however, some optically thin dust, consisting mainly\nof 3-micron-sized silicate dust grains, orbits the binary in a ring between 1.5\nand 2 AU. The peculiar structure and apparent lack of gas in the HD 98800 B\ndisk suggests that this system is likely already at the debris disks stage,\nwith a tidally truncated circumbinary disk of larger dust particles and an\ninner, second-generation dust ring, possibly held up by the resonances of a\nplanet. The unusually large infrared excess can be explained by gravitational\nperturbations of the Aa+Ab pair puffing up the outer dust ring and causing\nfrequent collisions among the larger particles.\n", "machine_text": "\n\nHD 98800: A 10-Myr-Old Transition Disk\n\nWe present high-resolution observations of the disk surrounding the young solar-like star HD 98800. These data include images obtained with the Hubble Space Telescope (HST) that reveal the disk to be a transition disk with a diameter of approximately 80 au. We find that the disk is comprised of two distinct parts: a compact inner region with a radius of approximately 20-30 au and a more extended outer region with a radius of approximately 50-80 au. The disk is generally well-circumscribed by a rim, except for a cavity of approximately 5-10 au in radius at the position of the terrestrial planet mass companion discovered in 2005. We estimate that the mass of the disk is 41 lunar masses (0.2 Earth masses) assuming a density of 1.6 g cm^3. We discuss the possible formation mechanisms for the disk and examine the potential for the disk to evolve into an analog of the solar system. We find that if the disk was formed by the accretion of planetesimals, it would have required an accretion rate of 0.01 Earth masses per Myr, similar to the rate estimated for the growth of the giant planets. We discuss the relative amounts of material in the disk and the likelihood that this disk may be the remains of a tumultuous planet formation process. We also examine the disk's habitability and find that the disk has a volatile content of approximately 0.01 Earth masses and a dust mass of approximately 0.02 Earth masses. We conclude that this disk is unlikely to be a habitable analog for the solar system, and thus is not a likely candidate for the search for extraterrestrial life. We discuss the implications of this disk for planet formation theory, and we highlight the need for further observations, both to verify our basic characterization of this disk and to better constrain the disk's properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Massive enhancement of electron-phonon coupling in doped graphene by an\n  electronic singularity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3264, "human_text": "  The nature of the coupling leading to superconductivity in layered materials\nsuch as high-Tc superconductors and graphite intercalation compounds (GICs) is\nstill unresolved. In both systems, interactions of electrons with either\nphonons or other electrons or both have been proposed to explain\nsuperconductivity. In the high-Tc cuprates, the presence of a Van Hove\nsingularity (VHS) in the density of states near the Fermi level was long ago\nproposed to enhance the many-body couplings and therefore may play a role in\nsuperconductivity. Such a singularity can cause an anisotropic variation in the\ncoupling strength, which may partially explain the so-called nodal-antinodal\ndichotomy in the cuprates. Here we show that the topology of the graphene band\nstructure at dopings comparable to the GICs is quite similar to that of the\ncuprates and that the quasiparticle dynamics in graphene have a similar\ndichotomy. Namely, the electron-phonon coupling is highly anisotropic,\ndiverging near a saddle point in the graphene electronic band structure. These\nresults support the important role of the VHS in layered materials and the\npossible optimization of Tc by tuning the VHS with respect to the Fermi level.\n", "machine_text": "\n\nWe investigate a system consisting of a single layer graphene sheet with a perpendicular electric field applied, which has a non-zero gradient at the sheet's edge. In contrast to the bulk electric field, the edge field is shown to enhance the electron-phonon coupling in the graphene. The enhanced coupling induced by the edge field is found to have a strong temperature dependence, in contrast to the coupling in the bulk, which is weakly temperature dependent. We explain this difference by a detailed analysis of the mechanism of the electron-phonon coupling in the presence of the edge field. We show that the coupling in the bulk is governed by the standard Boltzmann transport equation, while the coupling in the vicinity of the edge is controlled by a boundary condition, which can be drastically altered by a small change of the edge field strength. We predict that a similar enhancement of the electron-phonon coupling can be achieved by a perpendicular magnetic field, which has a non-zero gradient at the sheet's edge. Our predictions can be tested by a number of recent experiments, which have already probed the interaction between electrons, phonons and an external magnetic field in single layer graphene.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New Close Binary Systems from the SDSS-I (Data Release Five) and the\n  Search for Magnetic White Dwarfs in Cataclysmic Variable Progenitor Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0789, "human_text": "  We present the latest catalog of more than 1200 spectroscopically-selected\nclose binary systems observed with the Sloan Digital Sky Survey through Data\nRelease Five. We use the catalog to search for magnetic white dwarfs in\ncataclysmic variable progenitor systems. Given that approximately 25% of\ncataclysmic variables contain a magnetic white dwarf, and that our large sample\nof close binary systems should contain many progenitors of cataclysmic\nvariables, it is quite surprising that we find only two potential magnetic\nwhite dwarfs in this sample. The candidate magnetic white dwarfs, if confirmed,\nwould possess relatively low magnetic field strengths (B_WD < 10 MG) that are\nsimilar to those of intermediate-Polars but are much less than the average\nfield strength of the current Polar population. Additional observations of\nthese systems are required to definitively cast the white dwarfs as magnetic.\nEven if these two systems prove to be the first evidence of detached magnetic\nwhite dwarf + M dwarf binaries, there is still a large disparity between the\nproperties of the presently known cataclysmic variable population and the\npresumed close binary progenitors.\n", "machine_text": "\n\nWe present 22 new close binary systems observed with the SDSS-I (Data Release Five). These systems consist of 11 detached binaries, 5 semidetached binaries, and 6 white dwarfs with a close companion. We present basic properties such as the orbital period, the relative mass, and the orbital elements for these systems. We also present the photometry of the systems. In addition, we present our new catalog of 2,000 magnetic white dwarfs observed with the SDSS-I, and we determine the fraction of magnetic white dwarfs in close binary systems. We show that the fraction of magnetic white dwarfs in close binary systems is significantly higher than the fraction of magnetic white dwarfs in the general population of white dwarfs. We discuss this result in the framework of the evolution of close binary systems. We also present a comparison of the observed properties of magnetic white dwarfs in close binary systems with the properties of magnetic white dwarfs in the general population of white dwarfs. We show that magnetic white dwarfs in close binary systems tend to have lower magnetic field strengths, lower masses, and higher temperatures than magnetic white dwarfs in the general population. We discuss these results in the framework of the evolution of magnetic white dwarfs in close binary systems and the properties of the progenitor stars of these systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A High-Resolution Survey of Low-Redshift QSO Absorption Lines:\n  Statistics and Physical Conditions of O VI Absorbers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1214, "human_text": "  Using high-resolution UV spectra of 16 low-z QSOs, we study the physical\nconditions and statistics of O VI absorption in the IGM at z < 0.5. We identify\n51 intervening (z_{abs} << z_{QSO}) O VI systems comprised of 77 individual\ncomponents, and we find 14 \"proximate\" systems (z_{abs} ~ z_{QSO}) containing\n34 components. For intervening systems [components] with rest-frame equivalent\nwidth W_{r} > 30 mA, the number of O VI absorbers per unit redshift dN/dz =\n15.6(+2.9/-2.4) [21.0(+3.2/-2.8)], and this decreases to dN/dz = 0.9(+1.0/-0.5)\n[0.3(+0.7/-0.3)] for W_{r} > 300 mA. The number per redshift increases steeply\nas z_{abs} approaches z_{QSO}, and some proximate absorbers have substantially\nlower H I/O VI ratios. The lower proximate ratios could be partially due to\nionization effects but also require higher metallicities. We find that 37% of\nthe intervening O VI absorbers have velocity centroids that are well-aligned\nwith corresponding H I absorption. If the O VI and the H I trace the same gas,\nthe relatively small differences in line widths imply the absorbers are cool\nwith T < 10^{5} K. Most of these well-aligned absorbers have the\ncharacteristics of metal-enriched photoionized gas. However, the O VI in the\napparently simple and cold systems could be associated with a hot phase with T\n~ 10^{5.5} K if the metallicity is high enough to cause the associated broad Ly\nalpha absorption to be too weak to detect. We show that 53% of the intervening\nO VI systems are complex multiphase absorbers that can accommodate both lower\nmetallicity collisionally-ionized gas with T > 10^{5} K and cold photoionzed\ngas.\n", "machine_text": "\n\nWe present a high-resolution survey of low-redshift (z < 1) QSO absorption lines in the O VI band, with the goal of studying the physical conditions and statistics of O VI absorbers. We use the Millennium N-Body simulation to generate synthetic absorption lines at low resolution, which we then upscale to a high resolution of $\\sim 1000$ lines per galaxy. We compare the simulated absorption lines to the observed ones, and use the results to set limits on the strength of O VI absorption and the fraction of the intergalactic medium (IGM) that is absorbing. We find that the distribution of absorption lines is in good agreement with the predictions of the N-body simulation, and use this to set limits on the mean strength of O VI absorption in the IGM. We show that the fraction of the IGM that is absorbing is, on average, smaller than the fraction that is transmitting. We also study the physical conditions of the absorbers by modeling the O VI absorption lines with a simple collisional model. We find that the temperature and density of the IGM are in good agreement with previous results based on observations of the H I and CO lines. We also discuss the effect of dust on the O VI absorption lines, and find that it has a significant effect only for lines of sight (LOS) close to galaxies. Our results suggest that the O VI band is probably the best probe of the physical conditions in the IGM at low redshift.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Evolution of Protoplanetary Disks Around Millisecond Pulsars: The\n  PSR 1257 +12 System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3063, "human_text": "  We model the evolution of protoplanetary disks surrounding millisecond\npulsars, using PSR 1257+12 as a test case. Initial conditions were chosen to\ncorrespond to initial angular momenta expected for supernova-fallback disks and\ndisks formed from the tidal disruption of a companion star. Models were run\nunder two models for the viscous evolution of disks: fully viscous and layered\naccretion disk models. Supernova-fallback disks result in a distribution of\nsolids confined to within 1-2 AU and produce the requisite material to form the\nthree known planets surrounding PSR 1257+12. Tidal disruption disks tend to\nslightly underproduce solids interior to 1 AU, required for forming the pulsar\nplanets, while overproducing the amount of solids where no body, lunar mass or\ngreater, exists. Disks evolving under 'layered' accretion spread somewhat less\nand deposit a higher column density of solids into the disk. In all cases,\ncircumpulsar gas dissipates on $\\lesssim 10^{5}$ year timescales, making\nformation of gas giant planets highly unlikely.\n", "machine_text": "\n\nWe present phase-resolved optical and near-infrared observations of the protoplanetary disk in the PSR 1257 +12 system. We find that the disk is characterized by a ring-like structure with a peak surface density of 1.7 \u00d7 10 \u22123 M \u22c5 yr \u22121 located at  \u223c 70 RJ, which is more than 150 pc from the millisecond pulsar. The disk has a relatively high surface density compared to those found in Galactic disks, possibly as a result of the efficient accretion of gas and dust by the central star. The disk is radiating at a rate of  \u223c 7.2 R \u22c5 yr \u22121 , which corresponds to a gas temperature of  \u223c 170 K. We estimate the disk's lifetime to be  \u223c 200 Myr, which is similar to the lifetime of disks in the Galactic disk population. We also present a detailed analysis of the disk's chemical composition. We find that the disk has a higher abundance of carbon relative to hydrogen and a lower oxygen abundance compared to the solar neighborhood. Our results suggest that the disk formed in a molecular cloud with a higher molecular fraction and a lower atomic fraction compared to the Galactic disk population. We discuss our results in the context of disk evolution and compare our findings to other disks observed in low-mass star-forming regions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Poisson approximation for non-backtracking random walks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0867, "human_text": "  Random walks on expander graphs were thoroughly studied, with the important\nmotivation that, under some natural conditions, these walks mix quickly and\nprovide an efficient method of sampling the vertices of a graph. Alon,\nBenjamini, Lubetzky and Sodin studied non-backtracking random walks on regular\ngraphs, and showed that their mixing rate may be up to twice as fast as that of\nthe simple random walk. As an application, they showed that the maximal number\nof visits to a vertex, made by a non-backtracking random walk of length $n$ on\na high-girth $n$-vertex regular expander, is typically $(1+o(1))\\frac{\\log\nn}{\\log\\log n}$, as in the case of the balls and bins experiment. They further\nasked whether one can establish the precise distribution of the visits such a\nwalk makes.\n  In this work, we answer the above question by combining a generalized form of\nBrun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote\nthe number of vertices visited precisely $t$ times by a non-backtracking random\nwalk of length $n$ on a regular $n$-vertex expander of fixed degree and girth\n$g$. We prove that if $g=\\omega(1)$, then for any fixed $t$, $N_t/n$ is\ntypically $\\frac{1}{\\mathrm{e}t!}+o(1)$. Furthermore, if $g=\\Omega(\\log\\log\nn)$, then $N_t/n$ is typically $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all\n$t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq\n(1+o(1))\\frac{\\log n}{\\log\\log n}$. In particular, we obtain the above result\non the typical maximal number of visits to a single vertex, with an improved\nthreshold window. The essence of the proof lies in showing that variables\ncounting the number of visits to a set of sufficiently distant vertices are\nasymptotically independent Poisson variables.\n", "machine_text": "\n\nWe consider a simple model of random walks in which the step-size is allowed to be non-uniform. We show that such random walks can have a variety of behaviours, some of which are not captured by the standard Boltzmann\u2013Gibbs\u2013Shannon framework. In particular, such walks can have non-backtracking trajectories even in the thermodynamic limit. We show that this is because the random walk can have correlations on higher-level structures (i.e., correlations between the walk's global features), in addition to the local correlations between the steps of the walk. We also show that the occurrence of such higher-level correlations depends on the details of the step-size distribution. We consider different possible forms for the step-size distribution and find that a heavy-tailed form of distribution gives rise to a walk which is strongly non-backtracking, even in the presence of a large number of steps. Our results show that the traditional Boltzmann\u2013Gibbs\u2013Shannon framework needs to be extended in order to describe random walks with non-uniform step-size.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radion Phenomenology in Realistic Warped Space Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3844, "human_text": "  We investigate the phenomenology of the Randall-Sundrum radion in realistic\nmodels of electroweak symmetry breaking with bulk gauge and fermion fields,\nsince the radion may turn out to be the lightest particle in such models. We\ncalculate the coupling of the radion in such scenarios to bulk fermion and\ngauge modes. Special attention needs to be devoted to the coupling to massless\ngauge fields (photon, gluon), since it is well known that loop effects may be\nimportant for these fields. We also present a detailed explanation of these\ncouplings from the CFT interpretation. We then use these couplings to determine\nthe radion branching fractions and discuss some of the discovery potential of\nthe LHC for the radion. We find that the gamma-gamma signal is enhanced over\nmost of the range of the radion mass over the gamma-gamma signal of a SM Higgs,\nas long as the RS scale is sufficiently low. However, the signal significance\ndepends strongly on free parameters that characterize the magnitude of bare\nbrane-localized kinetic terms for the massless gauge fields. In the absence of\nsuch terms, the signal can be be enhanced over the traditional RS1 models\n(where all standard model fields are localized on the IR brane), but the signal\ncan also be reduced compared to RS1 if the brane localized terms are sizeable.\nWe also show that for larger radion masses, where the gamma-gamma signal is no\nlonger significant, one can use the usual 4 lepton signal to discover the\nradion.\n", "machine_text": "\n\nRadion phenomenology in realistic warped space models\n\nWe propose a general framework for radion phenomenology in realistic warped space models. We demonstrate that radion emission in realistic warped space models is fundamentally different from that in flat space, and that this difference is captured by a geometrically induced distortion of the classical luminance-based radion metric. This distortion is a general feature of realistic warped space models, and is not related to any particular theory of gravity. As an application, we analyze a model of radion emission from a black hole in a spatially warped background, and show that this model can be used to test the no-hair theorem in a realistic warped space setting.\n\nWe consider the radion emission from a point source in a warped space. We find that the radiation intensity measured by an observer in a distant flat space is related to the radion intensity in the source's rest frame by a factor that depends on the source's distance from the spatial warping boundary, and on the angle between the observer's and the source's respective rest frames. The factor can be arbitrarily large or small. We show that this effect is due to a geometrically induced distortion of the radion metric in realistic warped space models.\n\nWe analyze a simple model of radion emission from a black hole in a spatially warped background. The model consists of a black hole with a radion spectrum that is affected by the warped space in which it is embedded. We find that the resulting radion emission from the black hole can be used to test the no-hair theorem in a realistic warped space setting.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 8.4GHz VLBI observations of SN2004et in NGC6946. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3853, "human_text": "  We report on 8.4GHz Very Long Baseline Interferometry (VLBI) observations of\nthe type II-P supernova SN2004et in the spiral galaxy NGC 6946, made on 20\nFebruary 2005 (151 days after explosion). The Very Large Array (VLA) flux\ndensity was 1.23$\\pm$0.07 mJy, corresponding to an isotropic luminosity at\n8.4GHz of (4.45$\\pm$0.3)$\\times10^{25}$ erg s$^{-1}$ Hz$^{-1}$ and a brightness\ntemperature of (1.3$\\pm$0.3)$\\times10^{8}$ K. We also provide an improved\nsource position, accurate to about 0.5 mas in each coordinate. The VLBI image\nshows a clear asymmetry. From model fitting of the size of the radio emission,\nwe estimate a minimum expansion velocity of 15,700$\\pm$2,000 km s$^{-1}$. This\nvelocity is more than twice the expected mean expansion velocity estimated from\na synchrotron self-absorbed emission model, thus suggesting that synchrotron\nself-absorption is not relevant for this supernova. With the benefit of an\noptical spectrum obtained 12 days after explosion, we favor an emission model\nwhich consists of two hot spots on an underlying expanding shell of width\ncomparable to that of SN 1993J.\n", "machine_text": "\n\nWe present 8.4 GHz VLBI observations of SN 2004et in NGC 6946. These data were obtained with the VLBA and EVLA in the hope of detecting a supernova in the very earliest stages of evolution. The supernova was discovered at an optical magnitude of 17.2, four days after the explosion. The VLBI observations were made three days after the discovery, when the optical magnitude was 9.9. The source was clearly detected in both the VLBA and EVLA data, but the images are heavily affected by RFI. The supernova is resolved in the VLBA data, but the EVLA image is too contaminated by RFI to be useful. We find that the supernova has a brightness temperature of about 5 keV, corresponding to an energy release of 4 x 10^36 erg s^-1. The brightness temperature is almost constant on a timescale of hours, but the supernova is evolving on a timescale of days. We find that the supernova is likely to be a member of the TN 1991ea-like class of supernovae. The lack of a well-defined point source in the EVLA data is consistent with the supernova being surrounded by a shell of expanding material, as has been observed in several other TN 1991ea-like supernoves at later times.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Star-Formation in Low Radio Luminosity AGN from the Sloan Digital Sky\n  Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2074, "human_text": "  We investigate faint radio emission from low- to high-luminosity Active\nGalactic Nuclei (AGN) selected from the Sloan Digital Sky Survey (SDSS). Their\nradio properties are inferred by co-adding large ensembles of radio image\ncut-outs from the FIRST survey, as almost all of the sources are individually\nundetected. We correlate the median radio flux densities against a range of\nother sample properties, including median values for redshift, [OIII]\nluminosity, emission line ratios, and the strength of the 4000A break. We\ndetect a strong trend for sources that are actively undergoing star-formation\nto have excess radio emission beyond the ~10^28 ergs/s/Hz level found for\nsources without any discernible star-formation. Furthermore, this additional\nradio emission correlates well with the strength of the 4000A break in the\noptical spectrum, and may be used to assess the age of the star-forming\ncomponent. We examine two subsamples, one containing the systems with emission\nline ratios most like star-forming systems, and one with the sources that have\ncharacteristic AGN ratios. This division also separates the mechanism\nresponsible for the radio emission (star-formation vs. AGN). For both cases we\nfind a strong, almost identical, correlation between [OIII] and radio\nluminosity, with the AGN sample extending toward lower, and the star-formation\nsample toward higher luminosities. A clearer separation between the two\nsubsamples is seen as function of the central velocity dispersion of the host\ngalaxy. For systems with similar redshifts and velocity dispersions, the\nstar-formation subsample is brighter than the AGN in the radio by an order of\nmagnitude. This underlines the notion that the radio emission in star-forming\nsystems can dominate the emission associated with the AGN.\n", "machine_text": "\n\nWe present a study of star formation in low radio luminosity active galactic nuclei (AGN) from the SDSS. We find a strong correlation between radio and far-infrared luminosity, but no such correlation with optical or ultraviolet luminosity. We also find a correlation between radio and far-infrared luminosity and the star formation rate (SFR), but no such correlation for the optical/ultraviolet SFR. These results suggest that the star formation in these galaxies is fueled by the AGN. We find a significant correlation between radio/far-infrared and optical/ultraviolet SFR for galaxies with known redshift, but no correlation for galaxies with unknown redshift. We find that the galaxies with known redshift tend to be at higher redshift. This could be because the correlation between radio/far-infrared and optical/ultraviolet SFR is a purely cosmic phenomenon, and the higher redshift galaxies are simply closer to this correlation. We present a simple model in which star formation in these galaxies is fueled by the AGN, and find that this model can explain the correlation between radio/far-infrared and optical/ultraviolet SFR for galaxies with known redshift. We discuss several other possible physical mechanisms that could explain the correlation between radio/far-infrared and optical/ultraviolet SFR for galaxies with unknown redshift.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: ARCRAIDER I: Detailed optical and X-ray analysis of the cooling flow\n  cluster Z3146. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4053, "human_text": "  We present a detailed analysis of the medium redshift (z=0.2906) galaxy\ncluster Z3146 which is part of the ongoing ARCRAIDER project, a systematic\nsearch for gravitational arcs in massive clusters of galaxies. The analysis of\nZ3146 is based on deep optical wide field observations in the B, V and R bands\nobtained with the WFI@ESO2.2m, and shallow archival WFPC2@HST taken with the\nF606W filter, which are used for strong as well as weak lensing analyses.\nAdditionally we have used publicly available XMM/Newton observations for a\ndetailed X-ray analysis of Z3146. Both methods, lensing and X-ray, were used to\ndetermine the dynamical state and to estimate the total mass. We also\nidentified four gravitational arc candidates. We find this cluster to be in a\nrelaxed state, which is confirmed by a large cooling flow with nominal\n~1600M_\\odot per year, regular galaxy density and light distributions and a\nregular shape of the weak lensing mass reconstruction. The mass content derived\nwith the different methods agrees well within 25% at r_{200}=1661\nh_{70}^{-1}kpc indicating a velocity dispersion of\n\\sigma_v=869^{+124}_{-153}km/s.\n", "machine_text": "\n\nWe present an analysis of the optical and X-ray properties of the cooling flow cluster Z3146. We find that the cluster contains a large number of cool detached clumps, and that the clumps and the intracluster medium can be distinguished on the basis of their X-ray temperatures. We estimate the temperatures of the intracluster gas and the detached clumps, and find that they differ by about 2.5 kK. We argue that the cool detached clumps have been formed through the collapse of large voids, and that the intracluster gas has been compressed by the infall of these clumps. We find that the surface brightness of the cluster is not uniform, but has a correlation with the local X-ray temperature. We interpret this correlation in terms of the contribution of the detached clumps to the total surface brightness. We find that the cool detached clumps have a mean mass of 4.3 kM\u22c5 pc\u22122, and that they are responsible for 17% of the total surface brightness. The highest surface brightness is found in the regions with the highest X-ray temperature, where the contribution from detached clumps is small. We conclude that the intracluster gas is responsible for the bulk of the cluster's surface brightness, while the detached clumps give rise to the peaks and the high surface brightness in the outskirts of the cluster.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Chi2 and chi3 harmonic generation at a critical power in inhomogeneous\n  doubly resonant cavities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3652, "human_text": "  We derive general conditions for 100 percent frequency conversion in any\ndoubly resonant nonlinear cavity, for both second- and third-harmonic\ngeneration via chi2 and chi3 nonlinearities. We find that conversion efficiency\nis optimized for a certain critical power depending on the cavity parameters,\nand assuming reasonable parameters we predict 100 percent conversion using\nmilliwatts of power or less. These results follow from a semi-analytical\ncoupled-mode theory framework which is generalized from previous work to\ninclude both chi2 and chi3 media as well as inhomogeneous (fully vectorial)\ncavities, analyzed in the high-efficiency limit where down-conversion processes\nlead to a maximum efficiency at the critical power, and which is verified by\ndirect finite-difference time-domain (FDTD) simulations of the nonlinear\nMaxwell equations. Explicit formulas for the nonlinear coupling coefficients\nare derived in terms of the linear cavity eigenmodes, which can be used to\ndesign and evaluate cavities in arbitrary geometries.\n", "machine_text": "\n\nWe consider the formation of harmonics in a cavity where an initially homogeneous distribution of standing waves is disrupted by a thin absorbing layer. We show that a critical power exists above which a transition takes place to a state in which the waves are perfectly uniform. Below this critical power, the number of non-zero harmonics is infinite. In this state, the least number of harmonics is given by the well-known expression for the case of a homogeneously filled cavity. The transition is related to a change in the spatial profile of the standing waves, in particular to a singularity that appears in the bulk of the medium. We show that such a transition is generic for any finite perturbation of the homogenous state, and can be understood from the zero-order approximation to the slowly-varying envelope approximation. We analyze the distribution of the harmonics in the transient regime, and show that the formation of the harmonic spectrum is governed by a simple probabilistic argument. We also discuss the case of a gradually-varying perturbation, and show that the distribution of harmonics in this case is given by a superposition of the harmonics associated with the two extreme cases.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observation of Electron-Hole Puddles in Graphene Using a Scanning Single\n  Electron Transistor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.218, "human_text": "  The electronic density of states of graphene is equivalent to that of\nrelativistic electrons. In the absence of disorder or external doping the Fermi\nenergy lies at the Dirac point where the density of states vanishes. Although\ntransport measurements at high carrier densities indicate rather high\nmobilities, many questions pertaining to disorder remain unanswered. In\nparticular, it has been argued theoretically, that when the average carrier\ndensity is zero, the inescapable presence of disorder will lead to electron and\nhole puddles with equal probability. In this work, we use a scanning single\nelectron transistor to image the carrier density landscape of graphene in the\nvicinity of the neutrality point. Our results clearly show the electron-hole\npuddles expected theoretically. In addition, our measurement technique enables\nto determine locally the density of states in graphene. In contrast to\npreviously studied massive two dimensional electron systems, the kinetic\ncontribution to the density of states accounts quantitatively for the measured\nsignal. Our results suggests that exchange and correlation effects are either\nweak or have canceling contributions.\n", "machine_text": "\n\nWe report a scanning tunneling microscopy-based device in which a scanning single-electron transistor is used to detect the formation of electron-hole puddles in monolayer graphene on a dielectric substrate. When a conducting tip is scanned close to the surface, the number of electrons in the puddle is found to increase in a spatially-dependent fashion, in agreement with theoretical predictions. Our results suggest that the spatial variations in the puddle density can be used to image local variations in the density of surface states. We show that the spatial profile of the puddle is sensitive to the position of the tip with respect to the graphene sheet, the tip-sample distance, and the bias voltage applied between the tip and graphene. We also show that the number of electrons in the puddle is sensitive to the density of states and to the applied bias voltage. Our results demonstrate that the scanning single-electron transistor can be used as a powerful tool for the study of nanoscale charge transport in graphene.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fundamental Parameters of He-Weak and He-Strong Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0541, "human_text": "  We carried out low resolution spectroscopic observations in the wavelength\nrange 3400-4700 A of 20 He-weak and 8 He-strong stars to determine their\nfundamental parameters by means of the Divan-Chalonge-Barbier (BCD)\nspectrophotometric system. For a few He-weak stars we also estimate the\neffective temperatures and the angular diameters by integrating absolute fluxes\nobserved over a wide spectral range. Non-LTE model calculations are carried out\nto study the influence of the He/H abundance ratio on the emergent radiation of\nHe-strong stars and on their Teff determination. We find that the effective\ntemperatures, surface gravities and bolometric absolute magnitudes of He-weak\nstars estimated with the BCD system and the integrated flux method are in good\nagreement between each other, and they also agree with previous determinations\nbased on several different methods. The mean discrepancy between the visual\nabsolute magnitudes derived using the Hipparcos parallaxes and the BCD values\nis on average 0.3 mag for He-weak stars, while it is 0.5 mag for He-strong\nstars. For He-strong stars, we note that the BCD calibration, based on stars in\nthe solar environment, leads to overestimated values of Teff. By means of model\natmosphere calculations with enhanced He/H abundance ratios we show that larger\nHe/H ratios produce smaller BD which naturally explains the Teff\noverestimation. We take advantage of these calculations to introduce a method\nto estimate the He/H abundance ratio in He-strong stars. The BD of HD 37479\nsuggests that the Teff of this star remains fairly constant as the star\nspectrum undergoes changes in the intensity of H and He absorption lines. Data\nfor the He-strong star HD 66765 are reported for the first time.\n", "machine_text": "\n\nWe have carried out a systematic study of the fundamental parameters of both He-weak and He-strong stars. Our aim has been to identify and study the different evolutionary channels of these stars, in particular the transition between the main sequence and the first evolved phase, as well as to determine the main physical properties of the various types of these stars. We have found that a correlation exists between the fundamental parameters of these stars, in particular between the stellar mass and the helium abundance. Our results also suggest that a direct measurement of the helium abundance is not possible without an accurate knowledge of the effective temperature and the stellar mass. As an application of our method we have derived an empirical relation between the helium abundance and the other fundamental parameters. We have also found that the fundamental parameters of these stars are well described by a simple stellar model in which the evolution of the star is driven by its own radiative properties and that of a simple geometric model in which the expansion of the star is described by a perfect gas equation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The habitability of super-Earths in Gliese 581. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3758, "human_text": "  Aims: The planetary system around the M star Gliese 581 consists of a hot\nNeptune (Gl 581b) and two super-Earths (Gl 581c and Gl 581d). The habitability\nof this system with respect to the super-Earths is investigated following a\nconcept that studies the long-term possibility of photosynthetic biomass\nproduction on a dynamically active planet. Methods: A thermal evolution model\nfor a super-Earth is used to calculate the sources and sinks of atmospheric\ncarbon dioxide. The habitable zone is determined by the limits of biological\nproductivity on the planetary surface. Models with different ratios of land /\nocean coverage are investigated. Results: The super-Earth Gl 581c is clearly\noutside the habitable zone, since it is too close to the star. In contrast, Gl\n581d is a tidally locked habitable super-Earth near the outer edge of the\nhabitable zone. Despite the adverse conditions on this planet, at least some\nprimitive forms of life may be able to exist on its surface.Therefore, Gl 581d\nis an interesting target for the planned TPF/Darwin missions to search for\nbiomarkers in planetary atmospheres.\n", "machine_text": "\n\nWe investigate the habitability of super-Earths in Gliese 581. The Gliese 581 system is composed of three planets and one star. The inner most planet, Gliese 581e, is a super-Earth with a mass between Earth and Neptune. It is located in the star's habitable zone, where liquid water can exist on the planet's surface. We evaluate the habitability of Gliese 581e, and address the question of whether it is habitable. The super-Earth has a mass large enough to hold a thick atmosphere. Its mass is also large enough so that it is not tidally locked with its host star, which means that the same side of the planet always faces the star (in the same way that the same side of the Moon is always visible from Earth). We estimate the energy needed to heat the super-Earth's atmosphere to be in the range of 10^32 to 10^33 W, which is only a factor of a few larger than the solar flux it receives. We also estimate the emissivity of the super-Earth to be low, so that it can retain its atmosphere. We find that a super-Earth with a thick atmosphere, like the one in the Gliese 581 system, can be habitable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Control of mechanical systems on Lie groups and ideal hydrodynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2886, "human_text": "  In contrast to the Euler-Poincar{\\'e} reduction of geodesic flows of left- or\nright-invariant metrics on Lie groups to the corresponding Lie algebra (or its\ndual), one can consider the reduction of the geodesic flows to the group\nitself. The reduced vector field has a remarkable hydrodynamic interpretation:\nit is a velocity field for a stationary flow of an ideal fluid. Right- or\nleft-invariant symmetry fields of the reduced field define vortex manifolds for\nsuch flows.\n  Consider now a mechanical system, whose configuration space is a Lie group\nand whose Lagrangian is invariant to left translations on that group, and\nassume that the mass geometry of the system may change under the action of\ninternal control forces. Such system can also be reduced to the Lie group. With\nno controls, this mechanical system describes a geodesic flow of the\nleft-invariant metric, given by the Lagrangian, and thus its reduced flow is a\nstationary ideal fluid flow on the Lie group. The standard control problem for\nsuch system is to find the conditions, under which the system can be brought\nfrom any initial position in the configuration space to another preassigned\nposition by changing its mass geometry. We show that under these conditions, by\nchanging the mass geometry, one can also bring one vortex manifold to any other\npreassigned vortex manifold.\n", "machine_text": "\n\nWe consider the question of controlling mechanical systems on Lie groups, focusing on the case of ideal hydrodynamics. We show that the traditional control methods of ideal hydrodynamics on the basis of the maximum principles can be naturally formulated on the space of symmetry groups. We propose a generalization of the standard control methods to the case of multi-parametric systems, when the system is represented in the symmetrical space by a linear combination of the elements of the symmetry group. Within this approach, the control problem is reduced to the optimization of a certain functional, which has the properties of a quadratic form. The optimization problem is shown to be equivalent to the solution of a certain partial differential equation. We analyze the properties of this equation and solve it analytically in the case of 2-parametric systems. We also discuss the question of the existence of a solution for the control problem and propose an algorithm for its numerical solution in the case of multi-parametric systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generalized Twistor Transform And Dualities, With A New Description of\n  Particles With Spin, Beyond Free and Massless. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0296, "human_text": "  A generalized twistor transform for spinning particles in 3+1 dimensions is\nconstructed that beautifully unifies many types of spinning systems by mapping\nthem to the same twistor, thus predicting an infinite set of duality relations\namong spinning systems with different Hamiltonians. Usual 1T-physics is not\nequipped to explain the duality relationships and unification between these\nsystems. We use 2T-physics in 4+2 dimensions to uncover new properties of\ntwistors, and expect that our approach will prove to be useful for practical\napplications as well as for a deeper understanding of fundamental physics.\nUnexpected structures for a new description of spinning particles emerge. A\nunifying symmetry SU(2,3) that includes conformal symmetry SU(2,2)=SO(4,2) in\nthe massless case, turns out to be a fundamental property underlying the\ndualities of a large set of spinning systems, including those that occur in\nhigh spin theories. This may lead to new forms of string theory backgrounds as\nwell as to new methods for studying various corners of M theory. In this paper\nwe present the main concepts, and in a companion paper we give other details.\n", "machine_text": "\n\nWe propose a new formalism for a generalized torsor transform and an associated twisted doubled duality, with a new description of particles with spin, beyond free and massless. The new formulation is based on a formalism of 2-spinsorps and 2-spinors in the 3-dimensional Euclidean space. We show that the 3-spinors can be regarded as a particular case of 2-spinors. In particular, we show that, in the new formalism, the 3-spinors can be obtained from the 2-spinors by an affine transformation. We show that the formalism of 2-spinors can be further generalized to the 4-dimensional Euclidean space. As an application, we propose a new description of the relativistic particles with spin, beyond the free and massless case. We show that our new description of the relativistic particles with spin can be obtained from the Dirac equation by a formalism of constrained 2-spinors. We show that our new description of the relativistic particles with spin can be further obtained from the constrained 2-spinors by an affine transformation. We show that the Dirac equation can be regarded as a particular case of a constrained 2-spinor equation. We show that the constrained 2-spinor equation can be further generalized to the 4-dimensional Euclidean space. We show that the constrained 2-spinor equation can be obtained from the 3-spinorps by a formalism of constrained 3-spinors. We show that the constrained 3-spinors can be further obtained from the 3-spinors by an affine transformation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multiple Parton Scattering in Nuclei: Quark-quark Scattering. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0106, "human_text": "  Modifications to quark and antiquark fragmentation functions due to\nquark-quark (antiquark) double scattering in nuclear medium are studied\nsystematically up to order \\cal{O}(\\alpha_{s}^2)$ in deeply inelastic\nscattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$,\ntwist-four contributions from quark-quark (antiquark) rescattering also exhibit\nthe Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon\nbremsstrahlung induced by multiple parton scattering. Compared to quark-gluon\nscattering, the modification, which is dominated by $t$-channel quark-quark\n(antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the\nratio of quark and gluon distributions in the medium. Such a modification is\nnot negligible for realistic kinematics and finite medium size. The\nmodifications to quark (antiquark) fragmentation functions from quark-antiquark\nannihilation processes are shown to be determined by the antiquark (quark)\ndistribution density in the medium. The asymmetry in quark and antiquark\ndistributions in nuclei will lead to different modifications of quark and\nantiquark fragmentation functions inside a nucleus, which qualitatively\nexplains the experimentally observed flavor dependence of the leading hadron\nsuppression in semi-inclusive DIS off nuclear targets. The quark-antiquark\nannihilation processes also mix quark and gluon fragmentation functions in the\nlarge fractional momentum region, leading to a flavor dependence of jet\nquenching in heavy-ion collisions.\n", "machine_text": "\nMultiple Parton Scattering in Nuclei: Quark-quark Scattering\nWe study the multiple parton scattering (MPS) in nuclei within the framework of the quark-quark scattering (Q2SCAT) model. The Q2SCAT model has been developed to study the hardest quantum chromodynamics (QCD) processes in nuclei and it is based on the combination of the quark-meson coupling constant (CM) and the quark- antiquark coupling constant (CA). In this work we investigate the effects of the relevant structure functions (SFs) of the fundamental building blocks of nuclei, the nucleons, on the description of the MPS in nuclei. For this purpose, we consider the simple case of a nucleus composed of two identical nucleons, i.e. the deuteron, and study the effects of the two relevant SFs of the nucleons, namely the total cross section (CT) and the coherent cross section (CC), on the description of the MPS in the deuteron. In particular, we find that the inclusion of the CT and CC in the Q2SCAT model significantly improves the description of the MPS in the deuteron, since it allows to properly describe the underlying quark-quark degrees of freedom and their associated complex dynamics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmological Shock Waves in the Large Scale Structure of the Universe:\n  Non-gravitational Effects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1521, "human_text": "  Cosmological shock waves result from supersonic flow motions induced by\nhierarchical clustering of nonlinear structures in the universe. These shocks\ngovern the nature of cosmic plasma through thermalization of gas and\nacceleration of nonthermal, cosmic-ray (CR) particles. We study the statistics\nand energetics of shocks formed in cosmological simulations of a concordance\n$\\Lambda$CDM universe, with a special emphasis on the effects of\nnon-gravitational processes such as radiative cooling, photoionization/heating,\nand galactic superwind feedbacks. Adopting an improved model for gas\nthermalization and CR acceleration efficiencies based on nonlinear diffusive\nshock acceleration calculations, we then estimate the gas thermal energy and\nthe CR energy dissipated at shocks through the history of the universe. Since\nshocks can serve as sites for generation of vorticity, we also examine the\nvorticity that should have been generated mostly at curved shocks in\ncosmological simulations. We find that the dynamics and energetics of shocks\nare governed primarily by the gravity of matter, so other non-gravitational\nprocesses do not affect significantly the global energy dissipation and\nvorticity generation at cosmological shocks. Our results reinforce scenarios in\nwhich the intracluster medium and warm-hot intergalactic medium contain\nenergetically significant populations of nonthermal particles and turbulent\nflow motions.\n", "machine_text": "\nWe study the effects of non-gravitational forces on large scale structure in a homogeneous and isotropic cosmology with a variable equation of state (EOS) parameter \u03c9(a). In particular we consider a model in which the EOS parameter \u03c9(a) is given by the gradient of a smooth function that varies very slowly as a function of a, with a sharp transition at a \u2248 0.4. This model is used to investigate the effects of non-gravitational forces on the large scale structure of the Universe. We find that the density field is well described by a Gaussian kernel with a scale of the order of the transition scale a \u2248 0.4, in agreement with the scale expected from the theory of gravitational instability. The power law index of the density field is found to be in good agreement with the index expected from gravitational instability, and in disagreement with the index expected from the shock wave theory. The contribution of non-gravitational forces to the large scale structure is found to be small and its signature is mostly washed out by the gravitational forces. We conclude that non-gravitational forces do not significantly affect the large scale structure of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Signatures of Heavy Z-prime in the Extra U(1) Superstring Inspired\n  Model: RGEs Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2532, "human_text": "  In the extra U(1) superstring inspired model, we examine the electroweak and\nU(1)-prime symmetry breaking with the singlet and exotic quark D, D+{\\c}along\nwith the study of heavy Z-prime boson in accordance with the top quark mass\nregion. For this, we have done the analysis of complete renormalization group\nequations (RGEs)pertaining to the anomaly free E-{\\6}-Eta model of rank 5. The\nZ-prime is found to the order of TeV or above with allowed small Z-Zprime\nmixing angle, for which the large singlet VEV is required. This is done by\nconsidering the only non-universality of Yukawa couplings at GUT scale because\nthese do not obey the E-{\\6}relationship and also satisfies the unitarity\nconstraints both at GUT and weak scale, where rest of the parameters, i.e.,\ngaugino masses, tri-linear couplings, and soft supersymmetric breaking masses\nare kept universal at GUT scale with the gauge couplings unification. The large\nvalue of Yukawa couplings (order of 1) triggered the symmetry breaking\nradiatively and induces the effective-Mu parameter at the electroweak scale and\nlead to a viable low energy spectrum at weak scale.\n", "machine_text": "\nWe study the signatures of heavy Z-prime in the extra U(1) superstring inspired model (EUM) and find that they are consistent with the heavy Z-prime scenario in the framework of the EUM. This conclusion is drawn from a careful analysis of the RGEs (root generating functions) associated with the EUM. This analysis shows that the EUM can produce a universal RGE that is consistent with the heavy Z-prime scenario and its spawned chiral superfields. This RGE is in the form of an infinite dimensional cup product that shows a strong non-trivial correlation function in its leading term. The construction and the analysis of the RGEs associated with the EUM is a non-trivial task, which is different from the analysis of the RGEs in the framework of the minimal U(1) extension of the EUM. As an application, we give a simple description of the RGEs associated with the EUM in the case when the EUM has a minimal U(1) extension. This description allows one to understand the RGEs of the EUM in the minimal U(1) extension in the sense that the RGEs of the EUM in its minimal U(1) extension are \" eld theoretic generalizations \" of the RGEs associated with the EUM itself.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SNO+: predictions from standard solar models and spin flavour precession. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.407, "human_text": "  Time variability of the solar neutrino flux especially in the low and\nintermediate energy sector remains an open question and, if it exists, it is\nlikely to be originated from the magnetic moment transition from active to\nlight sterile neutrinos at times of intense solar activity and magnetic field.\nWe examine the prospects for the SNO+ experiment to address this important\nissue and to distinguish between the two classes of solar models which are\ncurrently identified as corresponding to a high (SSM I) and a low (SSM II)\nheavy element abundance. We also evaluate the predictions from these two models\nfor the Chlorine experiment event rate in the standard LMA and LMA+Spin Flavour\nPrecession (SFP) scenarios. It is found that after three years of SNO+ data\ntaking, the pep flux measurement will be able to discriminate between the\nstandard LMA and LMA+SFP scenarios, independently of which is the correct solar\nmodel. If the LMA rate is measured, SFP with $B_0 \\sim 280kG$ for the resonant\n$\\Delta m^2_{01}$ can be excluded at more than $4\\sigma$. A low rate would\nsignal new physics, excluding all the 90% allowed range of the standard LMA\nsolution at 3$\\sigma$, and a time variability would be a strong signature of\nthe SFP model. The CNO fluxes are the ones for which the two SSM predictions\nexhibit the largest differences, so their measurement at SNO+ will be important\nto favour one or the other. The distinction will be clearer after LMA or SFP\nare confirmed with pep, but still, a CNO measurement at the level of SSM I/LMA\nwill disfavour SSM II at about $3 \\sigma$. We conclude that consistency between\nfuture pep and CNO flux measurements at SNO+ and Chlorine would either favour\nan LMA+SFP scenario or favour SSM II over SSM I.\n", "machine_text": "\n\nWe present predictions, derived from standard solar models, for the properties of the solar neutrino flux expected from the SNO+ experiment. We consider the full range of physical possibilities for the solar model, including those which are not compatible with a standard atmospheric model. We show that the standard solar model predicts a neutrino flux that is consistent with the current SNO result, but is inconsistent with the SNO+ result in a pure geo-charAtron source. We then consider a non-standard solar model in which the partisan flux from geo-charAtron and from a stellar companion are comparable. We show that such a model can produce a neutrino flux that is consistent with both the SNO and SNO+ results, if the spin-flavor precession of the neutrinos is small compared to the Earth's orbital precession. We estimate the necessary precession to be $\\sim 10^{-25}$, which is small compared to the $\\sim 10^{8}$ precession that the Earth's orbit undergoes in one year, but is not strictly forbidden by the standard solar model. We show that this non-standard model can also explain the \"OVERFLOW\" and \"UNDiagnostics\" signals in the SNO data, which remain unexplained in the standard model. We also consider a model in which the solar mass is reduced, while keeping the baryonic mass fixed, and show that such a model can produce a neutrino flux consistent with the SNO+ result, if the flavor-spin precession is large enough. We discuss the implications of our results for future solar neutrino experiments, for the solar model, and for the origin of the solar neutrino flux.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Production of a sterile species: quantum kinetics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0703, "human_text": "  Production of a sterile species is studied within an effective model of\nactive-sterile neutrino mixing in a medium in thermal equilibrium. The quantum\nkinetic equations for the distribution functions and coherences are obtained\nfrom two independent methods: the effective action and the quantum master\nequation. The decoherence time scale for active-sterile oscillations is\n$\\tau_{dec} = 2/\\Gamma_{aa}$, but the evolution of the distribution functions\nis determined by the two different time scales associated with the damping\nrates of the quasiparticle modes in the medium: $\\Gamma_1=\\Gamma_{aa}\\cos^2\\tm\n; \\Gamma_2=\\Gamma_{aa}\\sin^2\\tm$ where $\\Gamma_{aa}$ is the interaction rate of\nthe active species in absence of mixing and $\\tm$ the mixing angle in the\nmedium. These two time scales are widely different away from MSW resonances and\npreclude the kinetic description of active-sterile production in terms of a\nsimple rate equation. We give the complete set of quantum kinetic equations for\nthe active and sterile populations and coherences and discuss in detail the\nvarious approximations. A generalization of the active-sterile transition\nprobability \\emph{in a medium} is provided via the quantum master equation. We\nderive explicitly the usual quantum kinetic equations in terms of the\n``polarization vector'' and show their equivalence to those obtained from the\nquantum master equation and effective action.\n", "machine_text": "\n\nWe investigate the quantum kinetics of a system which has the capability of producing a sterile species. We develop a general approach which treats the dynamics of the system as a whole, and take into account the correlations between the various degrees of freedom in the system. This approach is based on the idea that the total number of photons in the system is conserved. We show that such a general approach is equivalent to a set of independent, uncorrelated degree of freedom models, each of which describes the dynamics of the corresponding degree of freedom in the system. The independent models are solved and the solution to the general model is obtained by taking the sum of the solutions to the independent models. The special case of a system with two degrees of freedom is solved analytically, and the solution is used to obtain a general formula for the stationary distribution of the total number of photons in the system. We also discuss the general properties of the solution to the full model, and show how the general solution can be used to derive the stationary distribution for a wide class of input functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dimer Models, Free Fermions and Super Quantum Mechanics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1645, "human_text": "  This note relates topics in statistical mechanics, graph theory and\ncombinatorics, lattice quantum field theory, super quantum mechanics and string\ntheory. We give a precise relation between the dimer model on a graph embedded\non a torus and the massless free Majorana fermion living on the same lattice. A\nloop expansion of the fermion determinant is performed, where the loops turn\nout to be compositions of two perfect matchings. These loop states are sorted\ninto co-chain groups using categorification techniques similar to the ones used\nfor categorifying knot polynomials. The Euler characteristic of the resulting\nco-chain complex recovers the Newton polynomial of the dimer model. We\nre-interpret this system as supersymmetric quantum mechanics, where\nconfigurations with vanishing net winding number form the ground states.\nFinally, we make use of the quiver gauge theory - dimer model correspondence to\nobtain an interpretation of the loops in terms of the physics of D-branes\nprobing a toric Calabi-Yau singularity.\n", "machine_text": "\nWe propose and analyze a model of a statistical ensemble of dimers which has a continuum of discrete states. The model is studied in the limit of a large number of dimers. We show that the model is exactly solvable and we calculate the probability distribution of the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution. The special case of a dimer model with free fermions is also analyzed. We show that in this case the model is not exactly solvable, but that a probabilistic approach can be used to determine the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution. We also analyze a model of a statistical ensemble of free fermions. We show that the model is exactly solvable and we calculate the probability distribution of the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution. We also analyze a model of a statistical ensemble of \"super-quantum\" particles. We show that the model is exactly solvable and we calculate the probability distribution of the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A High-Throughput Cross-Layer Scheme for Distributed Wireless Ad Hoc\n  Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2841, "human_text": "  In wireless ad hoc networks, distributed nodes can collaboratively form an\nantenna array for long-distance communications to achieve high energy\nefficiency. In recent work, Ochiai, et al., have shown that such collaborative\nbeamforming can achieve a statistically nice beampattern with a narrow main\nlobe and low sidelobes. However, the process of collaboration introduces\nsignificant delay, since all collaborating nodes need access to the same\ninformation. In this paper, a technique that significantly reduces the\ncollaboration overhead is proposed. It consists of two phases. In the first\nphase, nodes transmit locally in a random access fashion. Collisions, when they\noccur, are viewed as linear mixtures of the collided packets. In the second\nphase, a set of cooperating nodes acts as a distributed antenna system and\nbeamform the received analog waveform to one or more faraway destinations. This\nstep requires multiplication of the received analog waveform by a complex\nnumber, which is independently computed by each cooperating node, and which\nenables separation of the collided packets based on their final destination.\nThe scheme requires that each node has global knowledge of the network\ncoordinates. The proposed scheme can achieve high throughput, which in certain\ncases exceeds one.\n", "machine_text": "\nWe propose a high-throughput cross-layer scheme for distributed wireless ad hoc networks. Our scheme is based on a new cross-layer design framework that we call \"Multi-Service-Cross-Layer Design\" (MSCLD). Given the important role that cross-layer design plays in the ad hoc network setting, our MSCLD framework can lead to more efficient network protocols. Our scheme is evaluated through simulations and it is shown that it can achieve high throughput as well as improved fairness. \n\nA significant amount of research in the field of wireless ad hoc networks has focused on the issue of quality-of-service (QoS) provisioning. QoS provisioning in ad hoc networks has been a challenging task due to the limited bandwidth as well as the highly dynamic nature of the network. In addition, the difficulty in meeting QoS requirements in multi-hop wireless ad hoc networks has not yet been studied. Most of the existing work on this topic focuses on the single-hop or cluster-based ad hoc networks. In this paper, we propose a new cross-layer scheme for multi-hop wireless ad hoc networks that can achieve QoS provisioning while maintaining high throughput. \n\nOur scheme is based on a new cross-layer design framework that we call \"Multi-Service-Cross-Layer Design\" (MSCLD). Given the important role that cross-layer design plays in the ad hoc network setting, our MSCLD framework can lead to more efficient network protocols. Our scheme is evaluated through simulations and it is shown that it can achieve high throughput as well as improved fairness.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galois theory of iterated endomorphisms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2384, "human_text": "  Given an abelian algebraic group $A$ over a global field $F$, $\\alpha \\in\nA(F)$, and a prime $\\ell$, the set of all preimages of $\\alpha$ under some\niterate of $[\\ell]$ generates an extension of $F$ that contains all\n$\\ell$-power torsion points as well as a Kummer-type extension. We analyze the\nGalois group of this extension, and for several classes of $A$ we give a simple\ncharacterization of when the Galois group is as large as possible up to\nconstraints imposed by the endomorphism ring or the Weil pairing. This Galois\ngroup encodes information about the density of primes $\\p$ in the ring of\nintegers of $F$ such that the order of $(\\alpha \\bmod{\\p})$ is prime to $\\ell$.\nWe compute this density in the general case for several classes of $A$,\nincluding elliptic curves and one-dimensional tori. For example, if $F$ is a\nnumber field, $A/F$ is an elliptic curve with surjective 2-adic representation\nand $\\alpha \\in A(F)$ with $\\alpha \\not\\in 2A(F(A[4]))$, then the density of\n$\\mathfrak{p}$ with ($\\alpha \\bmod{\\p}$) having odd order is 11/21.\n", "machine_text": "\nWe show that any iterated endomorphism on a polynomial algebra over a field has a common general form: it is either an iterated map to an algebra over a field or it is a combination of such iterated maps with an iterated map to the field itself. As an application, we give a description of the iterated endomorphisms of the polynomial algebra over a field in terms of the polynomial algebra's non-zero pivot elements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Design of Parallel Kinematic Machine Tools Using Kinetostatic\n  Performance Criteria. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1038, "human_text": "  Most industrial machine tools have a serial kinematic architecture, which\nmeans that each axis has to carry the following one, including its actuators\nand joints. High Speed Machining highlights some drawbacks of such\narchitectures: heavy moving parts require from the machine structure high\nstiffness to limit bending problems that lower the machine accuracy, and limit\nthe dynamic performances of the feed axes. That is why PKMs attract more and\nmore researchers and companies, because they are claimed to offer several\nadvantages over their serial counterparts, like high structural rigidity and\nhigh dynamic capacities. Indeed, the parallel kinematic arrangement of the\nlinks provides higher stiffness and lower moving masses that reduce inertia\neffects. Thus, PKMs have better dynamic performances. However, the design of a\nparallel kinematic machine tool (PKMT) is a hard task that requires further\nresearch studies before wide industrial use can be expected. Many criteria need\nto be taken into account in the design of a PKMT. We pay special attention to\nthe description of kinetostatic criteria that rely on the conditioning of the\nJacobian matrix of the mechanism. The organisation of this paper is as follows:\nnext section introduces general remarks about PKMs, then is explained why PKMs\ncan be interesting alternative machine tool designs. Then are presented\nexisting PKMTs. An application to the design of a small-scale machine tool\nprototype developed at IRCCyN is presented at the end of this paper.\n", "machine_text": "\nWe propose a methodology for the design of parallel kinematic machine tools based on the use of kinetostatic performance criteria. The motivation for this work is the difficulty in designing and analyzing the behavior of parallel kinematic machine tools based on conventional kinematic performance criteria, due to the complex non-linear relationship between the kinematic and kinetostatic characteristics. The proposed methodology is based on the use of a parameter called the \"kinetostatic defect\", which represents the deviation of the actual kinetostatic characteristics of a machine from the desired ones. The kinetostatic defect is related to the work actually performed by the drive motors, and is calculated using the concept of virtual work. By defining a functional relationship between the kinetostatic defect and the conventional kinematic performance criteria, the design of parallel kinematic machine tools can be simplified. The proposed methodology is demonstrated by means of an example.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new search for planet transits in NGC 6791. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1668, "human_text": "  Context. Searching for planets in open clusters allows us to study the\neffects of dynamical environment on planet formation and evolution.\n  Aims. Considering the strong dependence of planet frequency on stellar\nmetallicity, we studied the metal rich old open cluster NGC 6791 and searched\nfor close-in planets using the transit technique.\n  Methods. A ten-night observational campaign was performed using the\nCanada-France-Hawaii Telescope (3.6m), the San Pedro M\\'artir telescope (2.1m),\nand the Loiano telescope (1.5m). To increase the transit detection probability\nwe also made use of the Bruntt et al. (2003) eight-nights observational\ncampaign. Adequate photometric precision for the detection of planetary\ntransits was achieved.\n  Results. Should the frequency and properties of close-in planets in NGC 6791\nbe similar to those orbiting field stars of similar metallicity, then detailed\nsimulations foresee the presence of 2-3 transiting planets. Instead, we do not\nconfirm the transit candidates proposed by Bruntt et al. (2003). The\nprobability that the null detection is simply due to chance coincidence is\nestimated to be 3%-10%, depending on the metallicity assumed for the cluster.\n  Conclusions. Possible explanations of the null-detection of transits include:\n(i) a lower frequency of close-in planets in star clusters; (ii) a smaller\nplanetary radius for planets orbiting super metal rich stars; or (iii)\nlimitations in the basic assumptions. More extensive photometry with 3-4m class\ntelescopes is required to allow conclusive inferences about the frequency of\nplanets in NGC 6791.\n", "machine_text": "\n\nWe present the results of a new search for transits by giant planets in the solar-like star NGC 6791. We have previously reported two transit events in this star, which were attributed to a giant planet with an orbit very similar to that of our own Jupiter. Here we present two more transit events observed in 2019 and 2021, as well as additional transit data for the previously reported events. The new transit events are very similar to the previously reported events, indicating that the giant planet has an orbit with a radius of 1.5\u20132.0 astronomical units, an orbital period 11\u201312 years, and a mass at least 1.5 times that of Jupiter. The combined data set is consistent with a giant planet in a circular orbit, but the transient nature of the transit events and the relatively small number of observations (nine transit events observed in four different years) make a precise determination of the orbital elements impossible. The continued observation of this star is needed to properly characterize the giant planet and its orbit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stable oscillations of a predator-prey probabilistic cellular automaton:\n  a mean-field approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0512, "human_text": "  We analyze a probabilistic cellular automaton describing the dynamics of\ncoexistence of a predator-prey system. The individuals of each species are\nlocalized over the sites of a lattice and the local stochastic updating rules\nare inspired on the processes of the Lotka-Volterra model. Two levels of\nmean-field approximations are set up. The simple approximation is equivalent to\nan extended patch model, a simple metapopulation model with patches colonized\nby prey, patches colonized by predators and empty patches. This approximation\nis capable of describing the limited available space for species occupancy. The\npair approximation is moreover able to describe two types of coexistence of\nprey and predators: one where population densities are constant in time and\nanother displaying self-sustained time-oscillations of the population\ndensities. The oscillations are associated with limit cycles and arise through\na Hopf bifurcation. They are stable against changes in the initial conditions\nand, in this sense, they differ from the Lotka-Volterra cycles which depend on\ninitial conditions. In this respect, the present model is biologically more\nrealistic than the Lotka-Volterra model.\n", "machine_text": "\nWe consider a probabilistic cellular automaton describing the dynamics of coexistence of a predator-prey system with infinite total population and study the conditions for the emergence of self-sustained limit cycles. The automaton is mean-field, i.e. the local stochastic update rules are inspired on the processes of the elementary units (the cells) without taking into account their spatial arrangement. We find that a spatial structure of patches, in which the prey has an advantage over the predator, is necessary for the emergence of self-sustained limit cycles. We also show that limit cycles can be stable against changes in the initial conditions and, in this case, the automaton has a global steady state in which the number of prey and predator cells is independent of the initial conditions. As an example application, we consider a patchy landscape where the local stochastic rules describe the dynamics of the limiting case of the ratio of the prey and predator densities, as obtained from a simple ecological model with patchy spatial structure. We show that this model has a stable limit cycle and the conditions for its emergence are similar to the ones obtained for the mean-field case.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Our Peculiar Motion Away from the Local Void. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4139, "human_text": "  The peculiar velocity of the Local Group of galaxies manifested in the Cosmic\nMicrowave Background dipole is found to decompose into three dominant\ncomponents. The three components are clearly separated because they arise on\ndistinct spatial scales and are fortuitously almost orthogonal in their\ninfluences. The nearest, which is distinguished by a velocity discontinuity at\n~7 Mpc, arises from the evacuation of the Local Void. We lie in the Local Sheet\nthat bounds the void. Random motions within the Local Sheet are small. Our\nGalaxy participates in the bulk motion of the Local Sheet away from the Local\nVoid. The component of our motion on an intermediate scale is attributed to the\nVirgo Cluster and its surroundings, 17 Mpc away. The third and largest\ncomponent is an attraction on scales larger than 3000 km/s and centered near\nthe direction of the Centaurus Cluster. The amplitudes of the three components\nare 259, 185, and 455 km/s, respectively, adding collectively to 631 km/s in\nthe reference frame of the Local Sheet. Taking the nearby influences into\naccount causes the residual attributed to large scales to align with observed\nconcentrations of distant galaxies and reduces somewhat the amplitude of motion\nattributed to their pull. On small scales, in addition to the motion of our\nLocal Sheet away from the Local Void, the nearest adjacent filament, the Leo\nSpur, is seen to be moving in a direction that will lead to convergence with\nour filament. Finally, a good distance to an isolated galaxy within the Local\nVoid reveals that this dwarf system has a motion of at least 230 km/s away from\nthe void center. Given the velocities expected from gravitational instability\ntheory in the standard cosmological paradigm, the distance to the center of the\nLocal Void must be at least 23 Mpc from our position. The Local Void is large!\n", "machine_text": "\n\nOur Peculiar Motion Away from the Local Void\nWe have recently discovered a peculiar motion of our solar system away from the local void. We do not know the origin of this motion but suspect it has something to do with our motion within our own void. Our void is much larger than the local one and it has many more planets, which move around in a very complicated manner. We have made some progress in understanding this motion by studying the motion of the local void and the peculiar motion of our solar system. We have learned that the local void is moving in a very simple manner, which we can describe using some basic mathematical tools. We have also learned that our solar system is moving in a way that is much more complicated and we are not able to describe it using these same tools.\n\nWe are not sure what the origin of this peculiar motion is, but we suspect it has something to do with the way our solar system moves within our own void. We have studied the motion of our solar system within our void and we have learned that it is very complicated. We have also learned that the local void is moving in a very simple manner, which we can describe using some basic mathematical tools. We have tried to use these tools to describe the motion of our solar system but we have not been able to do so.\n\nWe have learned that the local void is moving in a very simple manner, which we can describe using some basic mathematical tools. We have also learned that our solar system is moving in a way that is much more complicated and we are not able to describe it using these same tools. We are not sure what the origin of this peculiar motion is, but we suspect it has something to do with the way our solar system moves within our own void.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fundamental Limits to Position Determination by Concentration Gradients. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3639, "human_text": "  Position determination in biological systems is often achieved through\nprotein concentration gradients. Measuring the local concentration of such a\nprotein with a spatially-varying distribution allows the measurement of\nposition within the system. In order for these systems to work effectively,\nposition determination must be robust to noise. Here, we calculate fundamental\nlimits to the precision of position determination by concentration gradients\ndue to unavoidable biochemical noise perturbing the gradients. We focus on\ngradient proteins with first order reaction kinetics. Systems of this type have\nbeen experimentally characterised in both developmental and cell biology\nsettings. For a single gradient we show that, through time-averaging, great\nprecision can potentially be achieved even with very low protein copy numbers.\nAs a second example, we investigate the ability of a system with oppositely\ndirected gradients to find its centre. With this mechanism, positional\nprecision close to the centre improves more slowly with increasing averaging\ntime, and so longer averaging times or higher copy numbers are required for\nhigh precision. For both single and double gradients, we demonstrate the\nexistence of optimal length scales for the gradients, where precision is\nmaximized, as well as analyzing how precision depends on the size of the\nconcentration measuring apparatus. Our results provide fundamental constraints\non the positional precision supplied by concentration gradients in various\ncontexts, including both in developmental biology and also within a single\ncell.\n", "machine_text": "\n\nWe consider the fundamental limits to position determination by concentration gradients. We show that the resolution is limited by the amount of information in the gradient. The effects of noise and finite bandwidth on the position resolution are also studied. The practical consequences of the theoretical results are discussed in the light of recent experiments.\n\nWe consider the problem of position determination by measuring the concentration of a target in a sample with a known concentration gradient. We show that the resolution is limited by the amount of information in the gradient. In particular, the theoretical resolution limit is about 3 times the standard deviation of the concentration gradient. The effects of noise and finite bandwidth on the position resolution are also studied. The practical consequences of the theoretical results are discussed in the light of recent experiments.\n\nThe motivation for this work is to understand the fundamental limits to position determination by concentration gradients. We show that the resolution is limited by the amount of information in the gradient. The effects of noise and finite bandwidth on the position resolution are also studied. The practical consequences of the theoretical results are discussed in the light of recent experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Millennium Galaxy Catalogue: The local supermassive black hole mass\n  function in early- and late-type galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0316, "human_text": "  We provide a new estimate of the local supermassive black hole mass function\nusing (i) the empirical relation between supermassive black hole mass and the\nSersic index of the host spheroidal stellar system and (ii) the measured\n(spheroid) Sersic indices drawn from 10k galaxies in the Millennium Galaxy\nCatalogue. The observational simplicity of our approach, and the direct\nmeasurements of the black hole predictor quantity, i.e. the Sersic index, for\nboth elliptical galaxies and the bulges of disc galaxies makes it\nstraightforward to estimate accurate black hole masses in early- and late-type\ngalaxies alike. We have parameterised the supermassive black hole mass function\nwith a Schechter function and find, at the low-mass end, a logarithmic slope\n(1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxy\nsample. Considering spheroidal stellar systems brighter than M_B = -18 mag, and\nintegrating down to black hole masses of 10^6 M_sun, we find that the local\nmass density of supermassive black holes in early-type galaxies rho_{bh,\nearly-type} = (3.5+/-1.2) x 10^5 h^3_{70} M_sun Mpc^{-3}, and in late-type\ngalaxies rho_{bh, late-type} = (1.0+/-0.5) x 10^5 h^3_{70} M_sun Mpc^{-3}. The\nuncertainties are derived from Monte Carlo simulations which include\nuncertainties in the M_bh-n relation, the catalogue of Sersic indices, the\ngalaxy weights and Malmquist bias. The combined, cosmological, supermassive\nblack hole mass density is thus Omega_{bh, total} = (3.2+/-1.2) x 10^{-6} h_70.\nThat is, using a new and independent method, we conclude that (0.007+/-0.003)\nh^3_{70} per cent of the universe's baryons are presently locked up in\nsupermassive black holes at the centres of galaxies.\n", "machine_text": "\nWe present the first estimate of the local supermassive black hole (SMBH) mass function in early- and late-type galaxies, based on a sample of 2,write custom essay type=&#34;wide-plain&#34; galaxies selected from the Millennium Galaxy Catalogue. We find that the local SMBH mass function is well described by a power law with a strong cut-off at log(M/Mpc^2) &lt; -1.7. The power law index and the magnitude of the cut-off are independent of galaxy type, morphology, size, and local group membership. Within this large sample, we find no evidence for a correlation between the local SMBH mass and galactic mass, star formation rate, or black hole accretion rate. We estimate the total number of SMBHs in our sample to be 1.9 x 10^4, with a total mass of 4.4 x 10^7 Mpc^2. The corresponding SMBH mass function is log(M/Mpc^2) = -1.38 \u00b1 0.08, with a total uncertainty of 6.5 per cent. We discuss our results in the context of galaxy evolution, the formation of the SMBH mass function, and the connection between local SMBH properties and the large-scale structure of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lyman Break Galaxies at z~5: Rest-frame UV Spectra II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1145, "human_text": "  We present the results of spectroscopy of Lyman Break Galaxies (LBGs) at z~5\nin the J0053+1234 field with the Faint Object Camera and Spectrograph on the\nSubaru telescope. Among 5 bright candidates with z' < 25.0 mag, 2 objects are\nconfirmed to be at z~5 from their Ly alpha emission and the continuum\ndepression shortward of Ly alpha. The EWs of Ly alpha emission of the 2 LBGs\nare not so strong to be detected as Ly alpha emitters, and one of them shows\nstrong low-ionized interstellar (LIS) metal absorption lines. Two faint objects\nwith z' \\geq 25.0 mag are also confirmed to be at z~5, and their spectra show\nstrong Ly alpha emission in contrast to the bright ones. These results suggest\na deficiency of strong Ly alpha emission in bright LBGs at z~5, which has been\ndiscussed in our previous paper. Combined with our previous spectra of LBGs at\nz~5 obtained around the Hubble Deep Field-North (HDF-N), we made a composite\nspectrum of UV luminous (M_1400 \\leq -21.5 mag) LBGs at z~5. The resultant\nspectrum shows a weak Ly alpha emission and strong LIS absorptions which\nsuggests that the bright LBGs at z~5 have chemically evolved at least to ~0.1\nsolar metallicity. For a part of our sample in the HDF-N region, we obtained\nnear-to-mid infrared data, which constraint stellar masses of these objects.\nWith the stellar mass and the metallicity estimated from LIS absorptions, the\nmetallicities of the LBGs at z~5 tend to be lower than those of the galaxies\nwith the same stellar mass at z \\lesssim 2, although the uncertainty is very\nlarge.\n", "machine_text": "\n\nWe present a catalogue of 75 galaxies identified as Lyman break galaxies (LBGs) at z~5 from an imaging survey with two 8k x 8k cameras covering a field of 1.3 sq. deg. from the Canada-France-Hawaii Telescope. The galaxies were selected using a proprietary algorithm based on their rest-frame UV colours and the locations of known LBGs in the local volume at z~1-2. We present their locations, morphological classifications, and rest-frame UV colours. These galaxies are candidates for further spectroscopy, to measure their line-of-sight velocities and hence to probe the kinematics of the intergalactic medium at this epoch. Our sample is almost uniform in rest-frame UV colour, with a median colour of +0.06 in the rest-frame U-V colour-magnitude diagram. The galaxies are typically slightly bluer in colour than the local LBGs at z~1-2, and the vast majority have colours typical of galaxies in the early stages of formation. We discuss the properties of the galaxies in the sample, and in particular, we show that the sample contains a higher fraction of bright galaxies than the local LBG population, in agreement with the fact that the galaxies in the local LBG sample are known to be more distant galaxies in the local volume at z~1-2. We also show that the galaxies in our sample are preferentially found in the same regions as the local LBGs, but that they tend to be somewhat further away from the galaxies in the local LBG sample. This implies that the local LBG population at z~1-2 is not a random sample of all the LBGs in the local volume, but is instead a sample of the closest LBGs to us.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dual Computations of Non-abelian Yang-Mills on the Lattice. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2629, "human_text": "  In the past several decades there have been a number of proposals for\ncomputing with dual forms of non-abelian Yang-Mills theories on the lattice.\nMotivated by the gauge-invariant, geometric picture offered by dual models and\nsuccessful applications of duality in the U(1) case, we revisit the question of\nwhether it is practical to perform numerical computation using non-abelian dual\nmodels. Specifically, we consider three-dimensional SU(2) pure Yang-Mills as an\naccessible yet non-trivial case in which the gauge group is non-abelian. Using\nmethods developed recently in the context of spin foam quantum gravity, we\nderive an algorithm for efficiently computing the dual amplitude and describe\nMetropolis moves for sampling the dual ensemble. We relate our algorithms to\nprior work in non-abelian dual computations of Hari Dass and his collaborators,\naddressing several problems that have been left open. We report results of spin\nexpectation value computations over a range of lattice sizes and couplings that\nare in agreement with our conventional lattice computations. We conclude with\nan outlook on further development of dual methods and their application to\nproblems of current interest.\n", "machine_text": "\n\nWe study the fundamental problem of computing the non-abelian Yang-Mills group on the lattice. We show that this problem is in general more difficult than computing the abelian variety of the same dimension. We consider different techniques which can be used to solve this problem, including the use ofcharacters, three-term recurrence, and the translation method. In the case of the pure Yang-Mills group, we show that any solution to this problem must take the form of a polynomial in the fundamental representation of the group. This reduces the problem to an issue of determining the root system of the group, and hence to the problem of classifying three-term recurrent integrals of the fundamental representation. We present an algorithm which classifies such integrals, and show that this algorithm can be used to solve the pure Yang-Mills case. We also show that this problem is equivalent to the problem of finding an embedding of the pure Yang-Mills group into a finite-dimensional representation of its generalizations. This in turn reduces to the problem of finding an integral representation of the generalized Yang-Mills group which contains a particular sub representation. We present an algorithm which finds such an integral representation. As an application, we use our algorithm to show that certain categories of symmetrically acting finite-dimensional representations of the pure Yang-Mills group have the structure of an equivariant category.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stringy E-functions of hypersurfaces and of Brieskorn singularities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0798, "human_text": "  We show that for a hypersurface Batyrev's stringy E-function can be seen as a\nresidue of the Hodge zeta function, a specialization of the motivic zeta\nfunction of Denef and Loeser. This is a nice application of inversion of\nadjunction. If an affine hypersurface is given by a polynomial that is\nnon-degenerate with respect to its Newton polyhedron, then the motivic zeta\nfunction and thus the stringy E-function can be computed from this Newton\npolyhedron (by work of Artal, Cassou-Nogues, Luengo and Melle based on an\nalgorithm of Denef and Hoornaert). We use this procedure to obtain an easy way\nto compute the contribution of a Brieskorn singularity to the stringy\nE-function. As a corollary, we prove that stringy Hodge numbers of varieties\nwith a certain class of strictly canonical Brieskorn singularities are\nnonnegative. We conclude by computing an interesting 6-dimensional example. It\nshows that a result, implying nonnegativity of stringy Hodge numbers in lower\ndimensional cases, obtained in our previous paper, is not true in higher\ndimension.\n", "machine_text": "\n\nWe continue our study of stringy E-functions of hypersurfaces and of Brieskorn singularities. We show that the Euler characteristic of a Brieskorn Singularity is an invariant of the K3 surface. As an application we give a description of Brieskorn singularities in terms of matrixSKI-theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Recovering galaxy star formation and metallicity histories from spectra\n  using VESPA. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0941, "human_text": "  We introduce VErsatile SPectral Analysis (VESPA): a new method which aims to\nrecover robust star formation and metallicity histories from galactic spectra.\nVESPA uses the full spectral range to construct a galaxy history from synthetic\nmodels. We investigate the use of an adaptative parametrization grid to recover\nreliable star formation histories on a galaxy-by-galaxy basis. Our goal is\nrobustness as opposed to high resolution histories, and the method is designed\nto return high time resolution only where the data demand it. In this paper we\ndetail the method and we present our findings when we apply VESPA to synthetic\nand real Sloan Digital Sky Survey (SDSS) spectroscopic data. We show that the\nnumber of parameters that can be recovered from a spectrum depends strongly on\nthe signal-to-noise, wavelength coverage and presence or absence of a young\npopulation. For a typical SDSS sample of galaxies, we can normally recover\nbetween 2 to 5 stellar populations. We find very good agreement between VESPA\nand our previous analysis of the SDSS sample with MOPED.\n", "machine_text": "\nWe present a new method for recovering galaxy star formation and metallicity histories from spectral data using the Visual EXpression System for Physics and Astronomy (VESPA). We demonstrate the effectiveness of the method by applying it to a set of high-resolution, high signal-to-noise ratio (SNR) spectra of galaxies in the distant Universe, obtained with the Hubble Space Telescope (HST). The method is based on the recognition that the strengths of the metal absorption lines are proportional to the metallicity of the galaxy, while the star formation rate is proportional to the total H\u03b1 luminosity. We have implemented these relations in VESPA, using the principal component analysis (PCA) method to extract the corresponding parameters. We find that the method is reliable and robust, and we demonstrate that the recovered parameters are consistent with those derived from the photometric analysis of the same galaxies, thus providing a robust spectral diagnosis of galaxy properties. The method is suitable for low SNR spectra as well as high SNR spectra, and can thus be applied to a variety of astronomical data sets, including, for example, the high-redshift Universe, where the SNR is often low.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Absolute Calibration and Characterization of the Multiband Imaging\n  Photometer for Spitzer. I. The Stellar Calibrator Sample and the 24 micron\n  Calibration. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2195, "human_text": "  We present the stellar calibrator sample and the conversion from instrumental\nto physical units for the 24 micron channel of the Multiband Imaging Photometer\nfor Spitzer (MIPS). The primary calibrators are A stars, and the calibration\nfactor based on those stars is 4.54*10^{-2} MJy sr^{-1} (DN/s)^{-1}, with a\nnominal uncertainty of 2%. We discuss the data-reduction procedures required to\nattain this accuracy; without these procdures, the calibration factor obtained\nusing the automated pipeline at the Spitzer Science Center is 1.6% +/- 0.6%\nlower. We extend this work to predict 24 micron flux densities for a sample of\n238 stars which covers a larger range of flux densities and spectral types. We\npresent a total of 348 measurements of 141 stars at 24 micron. This sample\ncovers a factor of ~460 in 24 micron flux density, from 8.6 mJy up to 4.0 Jy.\nWe show that the calibration is linear over that range with respect to target\nflux and background level. The calibration is based on observations made using\n3-second exposures; a preliminary analysis shows that the calibration factor\nmay be 1% and 2% lower for 10- and 30-second exposures, respectively. We also\ndemonstrate that the calibration is very stable: over the course of the\nmission, repeated measurements of our routine calibrator, HD 159330, show a\nroot-mean-square scatter of only 0.4%. Finally, we show that the point spread\nfunction (PSF) is well measured and allows us to calibrate extended sources\naccurately; Infrared Astronomy Satellite (IRAS) and MIPS measurements of a\nsample of nearby galaxies are identical within the uncertainties.\n", "machine_text": "\n\nWe present the results of a program to calibrate and characterize the Multiband Imaging Photometer for Spitzer (MIPS) with the Spitzer Space Telescope. We describe the methodology used to obtain the absolute calibration and the properties of the Stellar Calibrator Sample, which consists of 892 stars in four colors with known spectral types. We show that the absolute calibration is stable to within 3% over the full Spitzer mission and that the scatter in the measurements is in agreement with the requirements of the mission. We present the MIPS 24 micron flux calibration as a function of wavelength and the conversion factors to and from units of excess thermal emission in units of MJy/sr. We show that the main contribution to the scatter in the MIPS 24 micron measurements is due to the presence of thermal emission from the Spitzer spacecraft and that a correction based on the observed behavior can be applied to reduce the scatter to within the mission requirement of 20%. We show that the MIPS photometric measurements are stable to within 4% over the full Spitzer mission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Network statistics on early English Syntax: Structural criteria. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3708, "human_text": "  This paper includes a reflection on the role of networks in the study of\nEnglish language acquisition, as well as a collection of practical criteria to\nannotate free-speech corpora from children utterances. At the theoretical\nlevel, the main claim of this paper is that syntactic networks should be\ninterpreted as the outcome of the use of the syntactic machinery. Thus, the\nintrinsic features of such machinery are not accessible directly from (known)\nnetwork properties. Rather, what one can see are the global patterns of its use\nand, thus, a global view of the power and organization of the underlying\ngrammar. Taking a look into more practical issues, the paper examines how to\nbuild a net from the projection of syntactic relations. Recall that, as opposed\nto adult grammars, early-child language has not a well-defined concept of\nstructure. To overcome such difficulty, we develop a set of systematic criteria\nassuming constituency hierarchy and a grammar based on lexico-thematic\nrelations. At the end, what we obtain is a well defined corpora annotation that\nenables us i) to perform statistics on the size of structures and ii) to build\na network from syntactic relations over which we can perform the standard\nmeasures of complexity. We also provide a detailed example.\n", "machine_text": "\n\nNetwork statistics on early English Syntax: Structural criteria\n\nWe apply network statistics to a corpus of Old English to investigate its syntax in terms of structural criteria. The investigation comprises four steps. First, we compile a distributional analysis of the most frequent items and ranks them by their degree of association. Second, we apply network statistics to the ranked set of items in order to identify the most central items. Third, we compare the most central items in the network with the items ranked as the most frequent in the distributional analysis, in order to isolate items that are central in the network but not frequent in the distributional analysis. These items are marked as exceptional. Fourth, we compile a list of the most frequent items in the network that are not ranked as the most frequent in the distributional analysis. These items are marked as frequent. In addition, we identify the items that are most central in the network and also frequent, and mark these as especially frequent. We then compare the distribution of exceptional, frequent, and especially frequent items in the network with the distribution of items in the same categories based on their occurrence in a manually annotated reference corpus. The comparison shows that the distribution of items in the network is consistent with the manually annotated reference corpus in terms of both the number of items in each category and their relative frequency. There are, however, two notable differences. First, the network has many more especially frequent items than the reference corpus. Second, the network has many fewer frequent items than the reference corpus. We discuss possible reasons for these differences and conclude that they are most likely due to the particular properties of the network. Our results therefore provide evidence that network statistics can be used to investigate structural criteria in syntax.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Araucaria Project. The Distance to the Local Group Galaxy WLM from\n  Cepheid Variables discovered in a Wide-Field Imaging Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2075, "human_text": "  We have conducted an extensive wide-field imaging survey for Cepheid\nvariables in the Local Group irregular galaxy WLM. From data obtained on 101\nnights, we have discovered 60 Cepheids which include 14 of the 15 Cepheid\nvariables previously detected by Sandage and Carlson. Down to a period of 3\ndays, our Cepheid survey in WLM should be practically complete. Importantly, we\nhave found for the first time a long-period Cepheid (P=54.2 days) in this\ngalaxy, alleviating the puzzle that WLM with its many blue, massive stars does\nnot contain Cepheids with periods longer than about 10 days. Our data define\ntight period-luminosity relations in V, I and the reddening-free Wesenheit\nmagnitude ${\\rm W}_{\\rm I}$ which are all extremely well fit by the\ncorresponding slopes of the LMC Cepheid PL relation, suggesting no change of\nthe PL relation slope down to a Cepheid metal abundance of about -1.0 dex, in\nagreement with other recent studies. We derive a true distance modulus to WLM\nof 25.144 $\\pm$0.03 (r) $\\pm$0.07 (s) mag from our data, in good agreement with\nthe earlier 24.92 $\\pm$ 0.21 mag determination of Lee, Freedman and Madore\n(1993a) from Cepheid variables. The quoted value of the systematic uncertainty\ndoes not include the contribution from the LMC distance which we have assumed\nto be 18.50 mag, as in the previous papers in our project.\n", "machine_text": "\n\nWe present the Araucaria Project, a wide-field imaging survey for Cepheid variables in galaxies within 100 Mpc, with the aim of measuring the distance to the Local Group galaxy WLM. We describe the survey methodology, the data processing pipeline, and the results from the analysis of the first year of data, comprising 2, Edelmann, M. E. et al. 2018, ApJ, 853, 34, 10.3838/ apj.2017.85S1. The survey covers an area of 3.4 steradians with 3, 70-arcmin diameter fields, selected to be free of dust and highly extinction, and to contain a high-redshift galaxy cluster in the background for purposes of distance calibration. The cluster is a member of the Great Attractor, at a distance of 200 Mpc, providing a highly reliable indicator of the distance to our galaxy. The cluster is also well-studied, providing an anchor for the distance measurement. The galaxies in the survey are extracted from the SDSS DR7, and the Cepheid variables are identified with the TYC catalogue. We find three candidate Cepheid variables in the first year of data. We discuss the quality of the candidates, and show that one of them is a known variable, and that the other two are likely to be variables, but that further observations are required to confirm this. We also show that there are a number of known variables in the survey area that were not extracted from SDSS DR7, providing a useful archive of variables for future studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dark Matter in Gauge Mediation from Emergent Supersymmetry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2258, "human_text": "  We investigated the viability of neutralino dark matter in the gauge\nmediation from emergent supersymmetry proposal. In this proposal, supersymmetry\nis broken at Planck scale and consequently, the gravitino is superheavy and\ncompletely decouples from the low energy theory. Squarks and sleptons obtain\ntheir soft masses dominantly through gauge mediation with other mechanisms\nhighly suppressed. The lightest supersymmetric partner, in contrast to\ntraditional gauge mediation, is a neutralino which is also a dark matter\ncandidate. By explicit calculation of the low energy spectra, the parameter\nspace was constrained using the WMAP observed relic density of dark matter,\nLEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic\nB-meson decays. We found that the model has intriguing hybrid features such as\na nearly gauge-mediated spectrum (the exception being the superheavy gravitino)\nbut with a dominant mSUGRA-like bino-stau coannihilation channel and at large\n$\\tan \\beta$, A-resonance-like annihilation.\n", "machine_text": "\nWe propose a new mechanism for the generation of dark matter in gauge mediation theories, based on the emergent breaking of supersymmetry in the presence of non-Abelian symmetries. We show that the resulting dark matter candidates can have a wide range of masses, from being extremely light to being heavier than the standard model particles. We discuss the experimental signatures of our mechanism and find that they are different for different masses. Our main results are summarized as follows. (i) We show that for dark matter particles to be extremely light, the non-Abelian symmetries in the theory must be very close to the weak scale, and the resulting theory is not very attractive from the practical point of view. (ii) We show that for dark matter particles to be heavy, the non-Abelian symmetries must be very large, and we discuss a simple model in which this is the case. (iii) We show that there is a special intermediate mass range, for which the non-Abelian symmetries are not too small and not too large, and in which the theory is particularly well- behaved and attractive.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Culminating paths. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0694, "human_text": "  Let a and b be two positive integers. A culminating path is a path of Z^2\nthat starts from (0,0), consists of steps (1,a) and (1,-b), stays above the\nx-axis and ends at the highest ordinate it ever reaches. These paths were first\nencountered in bioinformatics, in the analysis of similarity search algorithms.\nThey are also related to certain models of Lorentzian gravity in theoretical\nphysics. We first show that the language on a two letter alphabet that\nnaturally encodes culminating paths is not context-free. Then, we focus on the\nenumeration of culminating paths. A step by step approach, combined with the\nkernel method, provides a closed form expression for the generating fucntion of\nculminating paths ending at a (generic) height k. In the case a=b, we derive\nfrom this expression the asymptotic behaviour of the number of culminating\npaths of length n. When a>b, we obtain the asymptotic behaviour by a simpler\nargument. When a<b, we only determine the exponential growth of the number of\nculminating paths. Finally, we study the uniform random generation of\nculminating paths via various methods. The rejection approach, coupled with a\nsymmetry argument, gives an algorithm that is linear when a>= b, with no\nprecomputation stage nor non-linear storage required. The choice of the best\nalgorithm is not as clear when a<b. An elementary recursive approach yields a\nlinear algorithm after a precomputation stage involving O(n^3) arithmetic\noperations, but we also present some alternatives that may be more efficient in\npractise.\n", "machine_text": "\n\nCulminating paths\n\nWe present a new approach to the problem of computing the shortest paths between two points on a grid, which is motivated by the need to solve this problem for large graphs on large grids. We show that if the underlying graph is a tree, then one can preprocess the graph in order to find a vector of shortest path lengths between every pair of points. This vector is indexed by the two points, and is of size n\u00d7n, where n is the number of points on the grid. Given two points p and q, one can then find the shortest path between p and q by simply taking the minimum over i and j of the elements of the vector. For more general graphs, the preprocessing step is more involved, but it is still possible to compute a vector of shortest path lengths in this way. We show that this algorithm is much more efficient than the naive algorithm of computing the shortest path for every pair of points.\n\nOur work differs from previous work on this problem in several ways. First, we give a more general algorithm that is applicable to a wider class of inputs. In particular, our algorithm is guaranteed to work on graphs that are not tree-like. Also, previous work on this problem was restricted to square grids, while our algorithm is applicable to general rectilinear grids. Finally, our algorithm has a much better worst-case running time. In particular, we show that if the underlying graph is a tree, then our algorithm runs in O(n2log n) time, where n is the number of points on the grid. For more general graphs, the running time is still polynomial in n.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modules over operads and functors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.309, "human_text": "  In the theory of operads we consider functors of generalized symmetric powers\ndefined by sums of coinvariant modules under actions of symmetric groups. One\nobserves classically that the construction of symmetric functors provides an\nisomorphism from the category of symmetric modules to a subcategory of the\ncategory of functors on the base category. The purpose of this book is to\nobtain a similar relationship for functors on a category of algebras over an\noperad.\n  We observe that right modules over operads, symmetric modules equipped with a\nright operad action, give rise to functors on categories of algebras and we\nprove that this construction yields an embedding of categories. Then we check\nthat right modules over operads form a model category. In addition we prove\nthat weak-equivalences of right modules correspond to pointwise\nweak-equivalences at the functor level. As a conclusion, we obtain that right\nmodules over operads supply good models for the homotopy of associated functors\non algebras over operads.\n", "machine_text": "\nWe study modules over operads and functors. We show that modules over operads are ubiquitous in algebra, geometry, and representation theory, and we explain how they arise in many different situations. We give a criterion for when two modules over operads are isomorphic, and we use this criterion to give a complete description of the category of modules over the operad of symmetric bisets. We show that this category is isomorphic to the category of modules over the full subcategory of the category of sets that consists of those sets that have a symmetric difference. We show that this category of modules is monadic over the category of sets. We then turn to the study of functors. We give a general criterion for when a functor F between two categories of modules is a tensor functor, and we use this criterion to give a complete description of the category of functors from the category of modules over the operad of symmetric bisets to the category of modules over the operad of sets. We show that this category of functors is isomorphic to the category of functors from the category of modules over the full subcategory of the category of sets that consists of those sets that have a symmetric difference. We show that this category of functors is monadic over the category of modules over the operad of sets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolutionary dynamics of the most populated genotype on rugged fitness\n  landscapes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0406, "human_text": "  We consider an asexual population evolving on rugged fitness landscapes which\nare defined on the multi-dimensional genotypic space and have many local\noptima. We track the most populated genotype as it changes when the population\njumps from a fitness peak to a better one during the process of adaptation.\nThis is done using the dynamics of the shell model which is a simplified\nversion of the quasispecies model for infinite populations and standard\nWright-Fisher dynamics for large finite populations. We show that the\npopulation fraction of a genotype obtained within the quasispecies model and\nthe shell model match for fit genotypes and at short times, but the dynamics of\nthe two models are identical for questions related to the most populated\ngenotype. We calculate exactly several properties of the jumps in infinite\npopulations some of which were obtained numerically in previous works. We also\npresent our preliminary simulation results for finite populations. In\nparticular, we measure the jump distribution in time and find that it decays as\n$t^{-2}$ as in the quasispecies problem.\n", "machine_text": "\n\nWe investigated the dynamics of gene frequencies on rugged fitness landscapes using an evolutionary model with explicit representation of phenotypic fitness. We considered the evolution of selfish genotypes, that is, genotypes that have no effect on the fitness of other genotypes. Our results show that rugged fitness landscapes can be stable against invasion of selfish genotypes if the degree of ruggedness is not too large. We found that the invasibility of a population is determined by the relative distribution of fitnesses of the individuals within the population. The higher the relative fitness of the individuals in the population, the easier it is for the population to resist invasion of a selfish genotype. We also found that the population can invade the population of a selfish genotype if the distribution of the fitnesses of the individuals in the population is peaked on the fitness landscape. The probability of this invasion event increases with the sharpness of the peak and the number of individuals in the population. Our results suggest that the invasibility of a population to invasion by a selfish genotype depends only on the global structure of the fitness landscape and not on the particular genotypes that occupy the landscape.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: How a \"Hit\" is Born: The Emergence of Popularity from the Dynamics of\n  Collective Choice. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2955, "human_text": "  In recent times there has been a surge of interest in seeking out patterns in\nthe aggregate behavior of socio-economic systems. One such domain is the\nemergence of statistical regularities in the evolution of collective choice\nfrom individual behavior. This is manifested in the sudden emergence of\npopularity or \"success\" of certain ideas or products, compared to their\nnumerous, often very similar, competitors. In this paper, we present an\nempirical study of a wide range of popularity distributions, spanning from\nscientific paper citations to movie gross income. Our results show that in the\nmajority of cases, the distribution follows a log-normal form, suggesting that\nmultiplicative stochastic processes are the basis for emergence of popular\nentities. This suggests the existence of some general principles of complex\norganization leading to the emergence of popularity. We discuss the theoretical\nprinciples needed to explain this socio-economic phenomenon, and present a\nmodel for collective behavior that exhibits bimodality, which has been observed\nin certain empirical popularity distributions.\n", "machine_text": "\n\nHow a \"Hit\" is Born: The Emergence of Popularity from the Dynamics of Collective Choice\n\nWe study the emergence of popularity in a cultural market where consumers choose from a large number of items. We develop a model in which items are selected from a slate of options that is too large to allow for an efficient choice process. We find that the dynamics of choice have a crucial impact on the emergence of popularity. In particular, we show that the frequency with which an item is chosen can be sharply increased by creating an item that is chosen in between two other items that are already popular. To explore the mechanism behind this effect we introduce the concept of \"Russian Doll Learning,\" which captures the idea that consumers learn about the popularity of an item based on their own preferences as well as the preferences of other consumers. We show that Russian Doll Learning can dramatically increase the chances for an item to become popular, and that the effect is particularly strong when the number of items is large. Our findings help to explain why some items become extremely popular even though they do not possess any unique features that would make them stand out from other items.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A ferrofluid based neural network: design of an analogue associative\n  memory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3402, "human_text": "  We analyse an associative memory based on a ferrofluid, consisting of a\nsystem of magnetic nano-particles suspended in a carrier fluid of variable\nviscosity subject to patterns of magnetic fields from an array of input and\noutput magnetic pads. The association relies on forming patterns in the\nferrofluid during a trainingdphase, in which the magnetic dipoles are free to\nmove and rotate to minimize the total energy of the system. Once equilibrated\nin energy for a given input-output magnetic field pattern-pair the particles\nare fully or partially immobilized by cooling the carrier liquid. Thus produced\nparticle distributions control the memory states, which are read out\nmagnetically using spin-valve sensors incorporated in the output pads. The\nactual memory consists of spin distributions that is dynamic in nature,\nrealized only in response to the input patterns that the system has been\ntrained for. Two training algorithms for storing multiple patterns are\ninvestigated. Using Monte Carlo simulations of the physical system we\ndemonstrate that the device is capable of storing and recalling two sets of\nimages, each with an accuracy approaching 100%.\n", "machine_text": "\nWe present a novel ferrofluid based neural network for the design of an analogue associative memory. The motivation for this work is the need for a low-cost, fast, and portable artificial neural network that can be used in non-electrical and remote areas. The key idea is the use of a ferrofluid, which is a stable suspension of magnetic nanoparticles in a liquid, as the artificial synapse. We show that the magnetic properties of the ferrofluid can be used to change the synaptic strength, which is the basis for learning and memory. The methodology is based on the use of a permanent magnet to apply a magnetic field to the ferrofluid and change its properties. The results obtained show that the ferrofluid based neural network is capable of learning and remembering input patterns. The problem this work attempts to solve is the need for a low-cost and portable artificial neural network. The practical application of this work is the potential use of a ferrofluid based neural network as an analogue associative memory. The theoretical application of this work is the further understanding of the potential use of magnetic materials in artificial neural networks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation of Single Reed Instruments Oscillations Based on Modal\n  Decomposition of Bore and Reed Dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2803, "human_text": "  This paper investigates the sound production in a system made of a bore\ncoupled with a reed valve. Extending previous work (Debut, 2004), the input\nimpedance of the bore is projected on the modes of the air column. The acoustic\npressure is therefore calculated as the sum of modal components. The\nairr&#114;&#64258;ow blown into the bore is modulated by reed motion, assuming\nthe reed to be a single degree of freedom oscillator. Calculation of\nself-sustained oscillations controlled by time-varying mouth pressure and\nplayer's embouchure parameter is performed using ODE solvers. Results emphasize\nthe par ticipation of the whole set of components in the mode locking process.\nAnother impor tant feature is the mutual inn&#110;&#64258;uence of reed and\nbore resonance during growing blowing pressure transients, oscillation\nthreshold being altered by the reed natural frequency and the reed damping.\nSteady-state oscillations are also investigated and compared with results given\nby harmonic balance method and by digital sound synthesis.\n", "machine_text": "\n\nWe present a method for simulation of single reed instrument oscillations based on the modal decomposition of bore and reed dynamics. The governing equations for the dynamic behavior of a single reed instrument are formulated in the basis of the thin-shell theory and the method of stationary stress. The problem is then solved by the FEM method. The Modal Decomposition (MD) technique is applied to reduce the computation efforts. In the MD method the instrument is considered as a linear system with multiple degrees of freedom (DOF). Each DOF has a proper dynamic model. The technique of theNormal Mode Analysis is used to identify the dynamic model of each DOF. The identified dynamic models are then assembled to obtain the total model of the instrument. The proposed method is applied to simulate the dynamic behavior of a single reed instrument. The results are compared with the available experimental data. The obtained good agreement between the simulation results and the experiment proves the effectiveness of the proposed method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complexity Considerations, cSAT Lower Bound. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0514, "human_text": "  This article discusses completeness of Boolean Algebra as First Order Theory\nin Goedel's meaning. If Theory is complete then any possible transformation is\nequivalent to some transformation using axioms, predicates etc. defined for\nthis theory. If formula is to be proved (or disproved) then it has to be\nreduced to axioms. If every transformation is deducible then also optimal\ntransformation is deducible. If every transformation is exponential then\noptimal one is too, what allows to define lower bound for discussed problem to\nbe exponential (outside P). Then we show algorithm for NDTM solving the same\nproblem in O(n^c) (so problem is in NP), what proves that P \\neq NP.\n  Article proves also that result of relativisation of P=NP question and oracle\nshown by Baker-Gill-Solovay distinguish between deterministic and\nnon-deterministic calculation models. If there exists oracle A for which\nP^A=NP^A then A consists of infinite number of algorithms, DTMs, axioms and\npredicates, or like NDTM infinite number of simultaneous states.\n", "machine_text": "\n\nConsiderations of complexity are common in computer science. We present a complexity consideration which has not been well studied: the worst-case running time of a randomized algorithm which is guaranteed to output the correct answer with a probability of 2-1 is at most a constant factor larger than the worst-case running time of the same algorithm without the guarantee. This answers a question oficzkowski andzlatar in the negative: it is not sufficient for an $\\mathcal{O}(\\log n)$ algorithm to output the correct answer with probability 2-1 in order to achieve an $\\mathcal{O}(n)$ worst-case running time. We show that the probability of the output of a randomized algorithm achieving any given confidence level is closely related to the worst-case running time of the same algorithm. We show that the class of problems which can be solved in worst-case $\\mathcal{O}(n)$ time by a randomized algorithm which outputs the correct answer with probability 2-1 is the same as the class of problems which can be solved in worst-case $\\mathcal{O}(n)$ time by a deterministic algorithm. We show how to use the study of randomized algorithms which output the correct answer with high probability to obtain new lower bounds for the complexity of several important problems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Systematic Scan for 7-colourings of the Grid. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1625, "human_text": "  We study the mixing time of a systematic scan Markov chain for sampling from\nthe uniform distribution on proper 7-colourings of a finite rectangular\nsub-grid of the infinite square lattice, the grid. A systematic scan Markov\nchain cycles through finite-size subsets of vertices in a deterministic order\nand updates the colours assigned to the vertices of each subset. The systematic\nscan Markov chain that we present cycles through subsets consisting of 2x2\nsub-grids and updates the colours assigned to the vertices using a procedure\nknown as heat-bath. We give a computer-assisted proof that this systematic scan\nMarkov chain mixes in O(log n) scans, where n is the size of the rectangular\nsub-grid. We make use of a heuristic to compute required couplings of\ncolourings of 2x2 sub-grids. This is the first time the mixing time of a\nsystematic scan Markov chain on the grid has been shown to mix for less than 8\ncolours. We also give partial results that underline the challenges of proving\nrapid mixing of a systematic scan Markov chain for sampling 6-colourings of the\ngrid by considering 2x3 and 3x3 sub-grids.\n", "machine_text": "\n\nWe systematically search for 7-colourings of the grid in which no two adjacent squares have the same colour. We show that every such 7-colouring can be obtained from a 3-colouring of the grid by adding two rows and two columns, each of which has all seven colours. We show further that the number of such 7-colourings is equal to the number of ways to 3-colour the grid such that no two adjacent squares have the same colour and no two rows or columns have the same colour. Thus, the number of 7-colourings of the grid is at most 7!2^3. We show that this number is at most 7!2^3 by exhibiting a 7-colouring of the grid with this property and by proving that no 7-colouring of the grid with this property can have a repeated colour. We also show that there are at most 5!2^3 3-colourings of the grid with the property that no two adjacent squares have the same colour and no two rows or columns have the same colour. Thus, the number of 7-colourings of the grid is at least 2(5!2^3) greater than the number of 3-colourings of the grid with the property that no two adjacent squares have the same colour and no two rows or columns have the same colour. We also show that the number of 7-colourings of the grid is at most 2(5!2^3) less than the number of 3-colourings of the grid with the property that no two adjacent squares have the same colour and no two rows or columns have the same colour.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Using Images to create a Hierarchical Grid Spatial Index. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0204, "human_text": "  This paper presents a hybrid approach to spatial indexing of two dimensional\ndata. It sheds new light on the age old problem by thinking of the traditional\nalgorithms as working with images. Inspiration is drawn from an analogous\nsituation that is found in machine and human vision. Image processing\ntechniques are used to assist in the spatial indexing of the data. A fixed grid\napproach is used and bins with too many records are sub-divided hierarchically.\nSearch queries are pre-computed for bins that do not contain any data records.\nThis has the effect of dividing the search space up into non rectangular\nregions which are based on the spatial properties of the data. The bucketing\nquad tree can be considered as an image with a resolution of two by two for\neach layer. The results show that this method performs better than the quad\ntree if there are more divisions per layer. This confirms our suspicions that\nthe algorithm works better if it gets to look at the data with higher\nresolution images. An elegant class structure is developed where the\nimplementation of concrete spatial indexes for a particular data type merely\nrelies on rendering the data onto an image.\n", "machine_text": "\n\nWe present a new image representation, which we call a hierarchical grid spatial index, that is designed to improve the efficiency of evaluating queries that require aggregation of image pixels within a specified rectangle. To generate this representation, we first divide each image into a number of tiles. We then identify the edges of these tiles and the boundaries between foreground and background regions. Based on this information, we compute a hierarchical clustering of the tiles to obtain a compact representation of the images. To evaluate a query, we traverse this hierarchy from the root node to the leaf nodes that intersect the query rectangle. We aggregate the pixel values at each level by summing the values in the child nodes. Finally, we return the result to the user. We show that this new representation is particularly useful for evaluating spatial queries that require the aggregation of image pixels within a rectangle. We present experimental results that demonstrate the efficiency of our representation compared to the naive approach of evaluating such queries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unicast and Multicast Qos Routing with Soft Constraint Logic Programming. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1783, "human_text": "  We present a formal model to represent and solve the unicast/multicast\nrouting problem in networks with Quality of Service (QoS) requirements. To\nattain this, first we translate the network adapting it to a weighted graph\n(unicast) or and-or graph (multicast), where the weight on a connector\ncorresponds to the multidimensional cost of sending a packet on the related\nnetwork link: each component of the weights vector represents a different QoS\nmetric value (e.g. bandwidth, cost, delay, packet loss). The second step\nconsists in writing this graph as a program in Soft Constraint Logic\nProgramming (SCLP): the engine of this framework is then able to find the best\npaths/trees by optimizing their costs and solving the constraints imposed on\nthem (e.g. delay < 40msec), thus finding a solution to QoS routing problems.\nMoreover, c-semiring structures are a convenient tool to model QoS metrics. At\nlast, we provide an implementation of the framework over scale-free networks\nand we suggest how the performance can be improved.\n", "machine_text": "\n\nWe propose a framework for joint unicast and multicast QoS routing using soft constraint logic programming. Our framework is based on a generic mechanism that can handle both unicast and multicast routing with the same formalism. In this framework, a router is abstracted as a label-switching device that receives packets with labeled edges and outputs packets with labeled edges. The input and output labeled edges are related by a set of edge-rewrite rules. A rule specifies the conditions for matching an input edge and the resulting output edge. Our framework handles both quality-driven routing and hop-by-hop routing. In quality-driven routing, the rules are selected to achieve a given QoS requirement, while in hop-by-hop routing, the rules are selected to minimize the number of hops or to achieve some other optimization criteria. We present an implementation of our framework using the DISTO principle, which combines decision-theoretic and heuristic methods to obtain near-optimal solutions to resource-constrained problems. The implementation is evaluated using simulation, and the results are compared with those of other protocols.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The building up of the disk galaxy M33 and the evolution of the\n  metallicity gradient. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3187, "human_text": "  The evolution of radial gradients of metallicity in disk galaxies and its\nrelation with the disk formation are not well understood. Theoretical models of\ngalactic chemical evolution make contrasting predictions about the time\nevolution of metallicity gradients. To test chemical evolution models and trace\nthe star formation and accretion history of low luminosity disk galaxies we\nfocus on the Local Group galaxy M33. We analyze O/H and S/H abundances in\nplanetary nebulae, H{\\sc ii} regions, and young stars, together with known\n[Fe/H] abundances in the old stellar population of M33. With a theoretical\nmodel, we follow the time evolution of gas (diffuse and condensed in clouds),\nstars, and chemical abundances in the disk of M33, assuming that the galaxy is\naccreting gas from an external reservoir. Our model is able to reproduce the\navailable observational constraints on the distribution of gas and stars in M33\nand to predict the time evolution of several chemical abundances. In\nparticular, we find that a model characterized by a continuous infall of gas on\nthe disk, at a rate of $\\dot M_{\\rm inf}\\approx 1$ $M_\\odot$ yr$^{-1}$, almost\nconstant with time, can also account for the relatively high rate of star\nformation and for the shallow chemical gradients. Supported by a large sample\nof high resolution observations for this nearby galaxy, we conclude that the\nmetallicity in the disk of M33 has increased with time at all radii, with a\ncontinuous flattening of the gradient over the last $\\sim 8$ Gyr.\n", "machine_text": "\n\nWe present a cosmological hydrodynamical model for the formation of the disk galaxy M33, based on the assumption that the accretion of baryonic matter and the metal content are coupled in the process of galaxy evolution. We find that a strong metallicity gradient is naturally built up during the evolution of the disk, with the metal abundance in the core increasing by a factor of about three from the birth to the present time. This is consistent with the observed metallicity distribution in M33, provided that the stars in the core were formed early in the history of the galaxy, while those in the outer parts were formed later. We also show that the large-scale distribution of the molecular hydrogen in M33 is due to a strong evolution of the chemical composition, in particular to the removal of the gas in the core. We discuss the relevance of our results for the understanding of chemical evolution in disk galaxies, and in particular for the controversy about the nature of the molecular hydrogen in M33.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Neutral Networks of Sequence to Shape Maps. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.076, "human_text": "  In this paper we present a novel framework for sequence to shape maps. These\ncombinatorial maps realize exponentially many shapes, and have preimages which\ncontain extended connected subgraphs of diameter n (neutral networks). We prove\nthat all basic properties of RNA folding maps also hold for combinatorial maps.\nOur construction is as follows: suppose we are given a graph $H$ over the $\\{1\n>...,n\\}$ and an alphabet of nucleotides together with a symmetric relation\n$\\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of\nlength n is the maximal H subgraph in which all pairs of nucleotides incident\nto H-edges satisfy $\\mathcal{R}$. Our main result is to prove the existence of\nat least $\\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes\nthat have a preimage with diameter $n$ and a connected component of size at\nleast $(\\frac{1+\\sqrt{5}}{2})^n+(\\frac{1-\\sqrt{5}}{2})^n$. Furthermore, we show\nthat there exists a certain subset of shapes which carries a natural graph\nstructure. In this graph any two shapes are connected by a path of shapes with\nrespective neutral networks of distance one. We finally discuss our results and\nprovide a comparison with RNA folding maps.\n", "machine_text": "\n\nMotivation:\nWhile the extraction of shape features from point clouds is well-developed, it is still an open problem to robustly and efficiently extract higher-level properties, such as genus or dimensions, from large point clouds of different shapes. In this work, we focus on the extraction of sequence to shape maps from large point clouds. \n\nKey ideas and methodology:\nWe propose a simple yet effective algorithm to extract sequence to shape maps from large point clouds. Our method takes advantage of the point cloud's local structure and the hierarchical octree to obtain a low-dimensional representation of the input point cloud. In our method, the shape features are extracted from this low-dimensional representation instead of the original point cloud. Since the low-dimensional representation has a much lower dimensionality than the original point cloud, the shape features can be efficiently extracted in our method. Our method has two main steps. In the first step, we construct a hierarchical octree from the input point cloud. In the second step, we extract the shape features from the leaf nodes of the hierarchical octree. The shape features extracted by our method can be used to represent the input point cloud. \n\nResults:\nWe evaluated our method on two benchmark point clouds. Our method achieved state-of-the-art performance in both tests. \n\nProblem work attempts to solve:\nOur work attempts to solve the problem of extracting sequence to shape maps from large point clouds. Our method is able to robustly and efficiently extract the shape features from large point clouds. \n\nPractical or theoretical applications:\nThe extracted shape features can be used to represent the input point cloud. Our method can be used to extract shape features from large point clouds in practical applications such as object recognition and segmentation. The extracted shape features can also be used in theoretical applications such as shape classification.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fluidization of a vertically oscillated shallow granular layer. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3852, "human_text": "  Molecular dynamics simulations are used to study fluidization of a vertically\nvibrated, three-dimensional shallow granular layer. As the container\nacceleration is increased above g, the granular temperature and root mean\nsquare particle displacement increase, gradually fluidizing the layer. For\nnearly elastic particles, or low shaking frequencies, or small layer depths,\nthe end of the fluidization process is marked by an abrupt increase in the\ngranular temperature and rms particle displacement. The layer is then fully\nfluidized since macroscopic, fluid-like phenomena such as convection rolls and\nsurface waves are observed. Increasing the total dissipation (by either\ndecreasing the restitution coefficient or increasing the total number of\nparticles) decreases the increase in granular temperature and rms particle\ndisplacement at fluidization, and shifts the increase to higher accelerations.\nIncreasing the frequency also decreases the magnitude of the jump, and shifts\nthe change to lower accelerations.\n", "machine_text": "\nWe study the influence of a rigidly-held plane on the dynamics of a shallow granular layer resting on a rigid foundation. The system is excited vertically and the corresponding wave equation is solved analytically. We find a strong difference between the situations where the plane is located at the top or bottom of the layer. In the former case, the system is in a state of quasi-equilibrium, with the acceleration of the granular material being proportional to the vertical displacement given by the wave equation. This is similar to the case of a vertically-oscillated rigid plane on a liquid, where the notion of criticality has been developed. By contrast, when the plane is located at the bottom of the layer, the system is in a state of complete chaos, with the acceleration of the granular material being proportional to the square of the vertical displacement given by the wave equation. Our results suggest that the state of criticality may be achieved by a continuous adjustment of the height of the plane within the granular layer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Almost the supersymmetric Standard Model from intersecting D6-branes on\n  the Z_6' orientifold. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0646, "human_text": "  Intersecting stacks of supersymmetric fractional branes on the Z_6'\norientifold may be used to construct the supersymmetric Standard Model. If a,b\nare the stacks that generate the SU(3)_{colour} and SU(2)_L gauge particles,\nthen, in order to obtain {\\em just} the chiral spectrum of the (supersymmetric)\nStandard Model (with non-zero Yukawa couplings to the Higgs mutiplets), it is\nnecessary that the number of intersections a \\cap b of the stacks a and b, and\nthe number of intersections a \\cap b' of a with the orientifold image b' of b\nsatisfy (a \\cap b,a \\cap b')=(2,1) or (1,2). It is also necessary that there is\nno matter in symmetric representations of the gauge group, and not too much\nmatter in antisymmetric representations, on either stack. Fractional branes\nhaving all of these properties may be constructed on the Z_6' orientifold. We\nconstruct a (four-stack) model with two further stacks, each with just a single\nbrane, which has precisely the matter spectrum of the supersymmetric Standard\nModel, including a single pair of Higgs doublets. However, the gauge group is\nSU(3)_{\\rm colour} x SU(2)_L x U(1)_Y x U(1)_H. Only the Higgs doublets are\ncharged with respect to U(1)_H.\n", "machine_text": "\nWe show that there exists a non-trivial class of intersecting D6-branes on the Z_6' orientifold that is almost the supersymmetric Standard Model. The motivation for this work is the following observation: In the minimal supersymmetric extension of the Standard Model, the three generations of fermions are related by the non-trivial braid group symmetry. We can view this as the result of a particular choice of branes in a\ufffd-theory. We show that a choice of D6-branes on the Z_6' orientifold results in a class of models with the same fermionic structure as the minimal supersymmetric extension of the Standard Model. The key idea is to use the (non-existing) theory of D6-branes on Z_6' as a starting point, and show that the choice of D6-branes corresponding to the Standard Model must intersect in a certain way. The methodology is to work with the induced representations on the space of harmonic functions on the sphere, and show that the restriction to the plane gives rise to the Standard Model. We show that such a choice of branes exists by describing the constraints it must satisfy, and then showing that these constraints can be satisfied by a class of non-trivial choices of branes. We also show that this class of models has a natural extension to the full supersymmetric Standard Model by including the three generations of neutrinos. We also discuss the possibility of further extending this class of models to incorporate higher generations of fermions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing String Theory with CMB. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0647, "human_text": "  Future detection/non-detection of tensor modes from inflation in CMB\nobservations presents a unique way to test certain features of string theory.\nCurrent limit on the ratio of tensor to scalar perturbations, r=T/S, is r <\n0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all\nknown string theory inflation models predict tensor modes well below the level\nof detection. Therefore a possible experimental discovery of tensor modes may\npresent a challenge to string cosmology.\n  The strongest bound on r in string inflation follows from the observation\nthat in most of the models based on the KKLT construction, the value of the\nHubble constant H during inflation must be smaller than the gravitino mass. For\nthe gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an\nextremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r\n> 10^{-3} would imply that the gravitinos in this class of models are\nsuperheavy, m_{3/2} > 10^{13} GeV. This would have important implications for\nparticle phenomenology based on string theory.\n", "machine_text": "\nWe have tested string theory by analyzing the cosmic microwave background (CMB) radiation. Our analysis is based on the precise measurements of the CMB anisotropy made by the COBE/FIRAS instrument. We show that the COBE/FIRAS data can be explained by a simple model in which the fluctuations in the CMB are caused by a random scalar field with a large range. This is strong evidence that string theory is a good description of the early universe.\n\nWe have also tested string theory by analyzing the CMB using the theory of entanglement. We show that the entanglement between the CMB and a detector can be used to test string theory. The entanglement is largest when the detector is in a state that is correlated with the CMB. This is strong evidence that string theory is a good description of the early universe.\n\nWe have also tested string theory by analyzing the CMB using the theory of information. We show that the information content of the CMB can be used to test string theory. The information content is largest when the CMB is in a state that is correlated with the detector. This is strong evidence that string theory is a good description of the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Classification of Finite Dimensional Complex Filiform Leibniz\n  Algebras (Part 2). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3885, "human_text": "  The paper is devoted to classification problem of finite dimensional complex\nnone Lie filiform Leibniz algebras. Actually, the observations show there are\ntwo resources to get classification of filiform Leibniz algebras. The first of\nthem is naturally graded none Lie filiform Leibniz algebras and the another one\nis naturally graded filiform Lie algebras. Using the first resource we get two\ndisjoint classes of filiform Leibniz algebras. The present paper deals with the\nsecond of the above two classes, the first class has been considered in our\nprevious paper. The algebraic classification here means to specify the\nrepresentatives of the orbits, whereas the geometric classification is the\nproblem of finding generic structural constants in the sense of algebraic\ngeometry. Our main effort in this paper is the algebraic classification. We\nsuggest here an algebraic method based on invariants. Utilizing this method for\nany given low dimensional case all filiform Leibniz algebras can be classified.\nMoreover, the results can be used for geometric classification of orbits of\nsuch algebras.\n", "machine_text": "\n\nWe continue the study of filiform algebras which we initiated in our previous paper. We classify finite-dimensional complex filiform Leibniz algebras in a way which generalizes the usual classification of finite-dimensional simple Lie algebras. We show that any finite-dimensional complex filiform Leibniz algebra is isomorphic to a subalgebra of a certain standard algebra, and that this standard algebra has a special class of subalgebras which includes all the simple filiform Leibniz algebras. We then give a description of this special class of subalgebras in terms of a maximal parabolic subalgebra and a minimal injective subalgebra. The importance of this work is that it gives a geometric description of the simple filiform Leibniz algebras in terms of parabolic and injective subalgebras. As an application, we show that any finite-dimensional complex filiform Sprague-Grundy algebra is isomorphic to a subalgebra of a certain standard algebra, and that this standard algebra has a special class of subalgebras which includes all the simple filiform Sprague-Grundy algebras. As a by-product, we give a description of the simple filiform Sprague-Grundy algebras in terms of a maximal parabolic subalgebra and a minimal injective subalgebra.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detection of GRB 060927 at z = 5.47: Implications for the Use of\n  Gamma-Ray Bursts as Probes of the End of the Dark Ages. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1257, "human_text": "  We report on follow-up observations of the GRB 060927 using the ROTSE-IIIa\ntelescope and a suite of larger aperture ground-based telescopes. An optical\nafterglow was detected 20 s after the burst, the earliest rest-frame detection\nof optical emission from any GRB. Spectroscopy performed with the VLT about 13\nhours after the trigger shows a continuum break at lambda ~ 8070 A produced by\nneutral hydrogen absorption at z~5.6. We also detect an absorption line at 8158\nA which we interpret as SiII at z=5.467. Hence, GRB 060927 is the second most\ndistant GRB with a spectroscopically measured redshift. The shape of the red\nwing of the spectral break can be fitted by a damped Lyalpha profile with a\ncolumn density with log(N_HI/cm^-2) ~ 22.5. We discuss the implications of this\nwork for the use of GRBs as probes of the end of the dark ages and draw three\nmain conclusions: i) GRB afterglows originating from z>6 should be relatively\neasy to detect from the ground, but rapid NIR monitoring is necessary to ensure\nthat they are found; ii) The presence of large HI column densities in some GRBs\nhost galaxies at z>5 makes the use of GRBs to probe the reionization epoch via\nspectroscopy of the red damping wing challenging; iii) GRBs appear crucial to\nlocate typical star-forming galaxies at z>5 and therefore the type of galaxies\nresponsible for the reionization of the universe.\n", "machine_text": "\n\nWe report the detection of the short-duration gamma-ray burst (GRB) 060927 at z = 5.47, the most distant burst recorded so far. The burst has a fluence of about 2.6 k_W m^-2, and an isotropic-radiation peak energy of about 1.6 k_T, with a redshift-corrected isotropic-radiation energy of about 4.5 k_T. The burst occurs at a glancing angle of about 45 degrees with respect to the line of sight, and the intrinsic energy distribution is well described by a power law with a photon index of about 1.3. The burst is accompanied by a weak optical afterglow, which is detected by the WFC3/UVIS instrument on board the Hubble Space Telescope (HST) with a depth of about 19 mag, and by the ground-based optical telescopes, with an observed magnitude of about 16 mag. The HST observations are used to determine the burst's position to be about 3 arcmin south-west of the Hubble Deep Field (HDF) source DR2227, in the direction of the Subaru Deep Field (SDF). The location is consistent with the burst occurring in a star-forming region, as dust and gas clouds are visible in the HST images. We find that the burst properties are consistent with those expected from a short-duration burst, and that the burst energy is small compared to known bursts at low redshift. We discuss the use of GRBs as probes of the end of the Dark Ages, and find that bursts with an isotropic-radiation energy of at least 2 k_T would be needed to be detected at redshift 5 and beyond, assuming a line-of-sight coverage of 10 percent.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nurturing Breakthroughs: Lessons from Complexity Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1839, "human_text": "  A general theory of innovation and progress in human society is outlined,\nbased on the combat between two opposite forces (conservatism/inertia and\nspeculative herding \"bubble\" behavior). We contend that human affairs are\ncharacterized by ubiquitous ``bubbles'', which involve huge risks which would\nnot otherwise be taken using standard cost/benefit analysis. Bubbles result\nfrom self-reinforcing positive feedbacks. This leads to explore uncharted\nterritories and niches whose rare successes lead to extraordinary discoveries\nand provide the base for the observed accelerating development of technology\nand of the economy. But the returns are very heterogeneous, very risky and may\nnot occur. In other words, bubbles, which are characteristic definitions of\nhuman activity, allow huge risks to get huge returns over large scales. We\noutline some underlying mathematical structure and a few results involving\npositive feedbacks, emergence, heavy-tailed power laws, outliers/kings/black\nswans, the problem of predictability and the illusion of control, as well as\nsome policy implications.\n", "machine_text": "\n\nWe propose that the complexity of the innovation process has important implications for how breakthrough results are achieved. Our research to date indicates that the relationship between the degree of complexity of the innovation process and the characteristics of breakthrough results is nonlinear. We find that as the complexity of the process increases, the number of breakthrough results decreases, but the impact of the results increases significantly. We also find that the rate of introduction of breakthrough results has an inverse relationship with the degree of process complexity, with the rate of introduction of breakthrough results increasing as the complexity of the process decreases. Our work has important implications for the management of innovation and the design of innovation processes.\n\nOur research to date has focused on two broad areas: the study of complexity and the study of innovation. In the first area, we have been developing a theory of complexity and testing it against empirical data. Our work has shown that complexity is a key driver of breakthrough results. We have also been studying the relationship between complexity and the characteristics of breakthrough results. Our work has shown that as the complexity of the process increases, the number of breakthrough results decreases, but the impact of the results increases significantly. In the second area, we have been studying the innovation process and the factors that affect the introduction of breakthrough results. Our work has shown that the rate of introduction of breakthrough results has an inverse relationship with the degree of process complexity, with the rate of introduction of breakthrough results increasing as the complexity of the process decreases.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The metallicity gradient of M 33: chemical abundances of HII regions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3116, "human_text": "  We present spectroscopic observations of a sample of 72 emission-line\nobjects, including mainly HII regions, in the spiral galaxy M 33. Spectra were\nobtained with the multi-object, wide field spectrograph AF2/WYFFOS at the 4.2m\nWHT telescope. Line intensities, extinction, and electron density were\ndetermined for the whole sample of objects. The aim of the present work was to\nderive chemical and physical parameters of a set of HII regions, and from them\nthe metallicity gradient. Electron temperatures and chemical abundances were\nderived for the 14 HII regions where both [OII] and [OIII] emission line fluxes\nwere measured, including the electron temperature sensitive emission line\n[OIII] 436.3 nm and in a few cases [NII] 575.5 nm. The ionization correction\nfactor (ICF) method was used to derive the total chemical abundances. The\npresence of abundance gradients was inferred from the radial behaviour of\nseveral emission-line ratios, and accurately measured from chemical abundances\ndirectly derived in 14 HII regions. The oxygen abundances of our HII regions,\nlocated in the radial region from ~2 to ~7.2 kpc, gave an oxygen gradient\n-0.054+/-0.011 dex/kpc The overall oxygen gradient for M 33 obtained using ours\nand previous oxygen determinations in a large number of HII regions with direct\nelectron temperature determination as well as abundance in young stars\npresented a two slope shape: -0.19 dex/kpc for the central regions (R<3kpc),\nand -0.038dex/kpc for the outer regions (R>=3kpc).\n", "machine_text": "\n\nWe present a study of the chemical abundances of HII regions in M 33. Our sample consists of HII regions with metallicities that have been determined by a variety of independent methods. We find a good agreement between the metallicities obtained from an analysis of the observed line profiles and those obtained from an analysis of the colors of the HII regions. We find that the metallicities increase towards the outer regions of M 33, in agreement with theoretical predictions of a cosmological chemical evolution model. The increase of the metallicity with radius is well described by a power law of index 1.9 \u00b1 0.1. We also present a comparison between the chemical abundances of HII regions in M 33 and in the Milky Way. In particular, we show that the metallicity of the HII regions in M 33 is, on average, higher than that of the Milky Way, but there is no significant difference in the proportion of elements heavier than iron. We discuss our results in the framework of chemical evolution models, and in particular of the massive-chain-processing model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-sided optimal bounds for Green function of half-spaces for\n  relativistic $\\alpha$-stable process. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1175, "human_text": "  The purpose of this paper is to find optimal estimates for the Green function\nof a half-space of {\\it the relativistic $\\alpha$-stable process} with\nparameter $m$ on $\\Rd$ space. This process has an infinitesimal generator of\nthe form $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2},$ where $0<\\alpha<2$, $m>0$, and\nreduces to the isotropic $\\alpha$-stable process for $m=0$. Its potential\ntheory for open bounded sets has been well developed throughout the recent\nyears however almost nothing was known about the behaviour of the process on\nunbounded sets. The present paper is intended to fill this gap and we provide\ntwo-sided sharp estimates for the Green function for a half-space. As a\nbyproduct we obtain some improvements of the estimates known for bounded sets\nspecially for balls. The advantage of these estimates is a clarification of the\nrelationship between the diameter of the ball and the parameter $m$ of the\nprocess.\n  The main result states that the Green function is comparable with the Green\nfunction for the Brownian motion if the points are away from the boundary of a\nhalf-space and their distance is greater than one. On the other hand for the\nremaining points the Green function is somehow related the Green function for\nthe isotropic $\\alpha$-stable process. For example, for $d\\ge3$, it is\ncomparable with the Green function for the isotropic $\\alpha$-stable process,\nprovided that the points are close enough.\n", "machine_text": "\nWe establish two-sided optimal bounds for the Green function of half-spaces for relativistic $\\alpha$-stable processes. Our approach is based on the rigorous analysis of the asymptotic behavior of the solution as the core of the singularity is approached. The rigorous proof of the bounds established in this work is based on a combination of theinside-out algorithm and the lower bound of the Cauchy integral formula. The main motivation for this research is to investigate the singular behavior of the Green function of half-spaces for relativistic $\\alpha$-stable processes. The key idea is to use the rigorous analysis of the singular behavior of the Green function of half-spaces as the core of the singularity is approached. The main methodology is based on the use of the inside-out algorithm combined with the lower bound of the Cauchy integral formula. The results obtained in this work are two-sided optimal bounds for the Green function of half-spaces for relativistic $\\alpha$-stable processes. The problem this work attempts to solve is to investigate the singular behavior of the Green function of half-spaces for relativistic $\\alpha$-stable processes. The practical application of this work is to develop a rigorous theory for the singular behavior of the Green function of half-spaces for relativistic $\\alpha$-stable processes. The theoretical application of this work is to establish two-sided optimal bounds for the Green function of half-spaces for relativistic $\\alpha$-stable processes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale\n  bar funnelling gas into the nuclear region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3662, "human_text": "  This work is part of the NUGA survey of CO emission in nearby active\ngalaxies. We present observations of NGC4569, a member of the Virgo Cluster. We\nanalyse the molecular gas distribution and kinematics in the central region and\nwe investigate a possible link to the strong starburst present at the nucleus.\n70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is found\nto be concentrated within the inner 800 pc and is distributed along the large\nscale stellar bar seen in near-infrared observations. A hole in the CO\ndistribution coincides with the nucleus where most of the Halpha emission and\nblue light are emitted. The kinematics are modelled in three different ways,\nranging from the purely geometrical to the most physical. This approach allows\nus to constrain progressively the physical properties of the galaxy and\neventually to emerge with a reasonable fit to an analytical model of orbits in\na barred potential. Fitting an axisymmetric model shows that the non-circular\nmotions must be comparable in amplitude to the circular motions (120 km/s).\nFitting a model based on elliptical orbits allows us to identify with\nconfidence the single inner Lindblad resonance (ILR) of the large scale bar.\nFinally, a model based on analytical solutions for the gas particle orbits in a\nweakly barred potential constrained by the ILR radius reproduces the\nobservations well. The mass inflow rate is then estimated and discussed based\non the best fit model solution. The gravitational torques implied by this model\nare able to efficiently funnel the gas inside the ILR down to 300 pc, although\nanother mechanism must take over to fuel the nuclear starburst inside 100 pc.\n", "machine_text": "\n\nMolecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale bar funnelling gas into the nuclear region\n\nWe present observations of molecular gas in the nuclear region of NGC4569, a barred spiral galaxy in which a large-scale bar is responsible for funneling gas into the nuclear region, in a fashion similar to that observed in NGC1365. We have imaged with milliarcsecond resolution, by means of Very Long Baseline Interferometry, the distribution of CO, COJ=1-0, and HCN in the nuclear region of NGC4569. We find that the molecular gas is distributed in a bar-like structure, with the bar being oriented at an angle of 30 deg with respect to the optical bar. The bar is covered by a layer of HCN J=1-0, with a peak abundance of log(OCN/H2) = 1.05 +0.06/-0.05. The distribution of molecular gas in the nuclear region is quite different in the two galaxies, reflecting the different processes taking place in the two galaxies. In particular, while the molecular gas in NGC1365 is distributed in a relatively smooth and roundly shaped structure, in NGC4569 the gas is distributed in a rather irregular fashion, with a large number of dense knots along the bar, and a tail of gas streaming out along the minor axis of the bar. We discuss the origin of these different distributions, in the framework of the \"bar-driven\" and \"dating\" scenarios for the evolution of molecular gas in galactic nuclei. We find that the models in their current form cannot produce molecular gas distributions as observed in both galaxies, in particular the distribution of HCN J=1-0 in NGC4569. We discuss the problems of the models, and suggest that the observed distributions of HCN J=1-0 in NGC4569 and in NGC1365 may be the result of different physical processes, taking place at different galactic scales.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HST/FGS Parallaxes of AM CVn Stars and Astrophysical Consequences. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3855, "human_text": "  We present absolute parallaxes and relative proper motions for five AM CVn\nstars, which we obtained using the Fine Guidance Sensors on board the Hubble\nSpace Telescope. Our parallax measurements translate into distances d(AM\nCVn)=606+135-93 pc, d(HP Lib)=197+14-12 pc, d(CR Boo)=337+44-35 pc, d(V803\nCen)=347+32-27 pc, and d(GP Com)=75+2-2 pc. From these distances we estimate\nthe space density of AM CVn stars and suggest that previous estimates have been\ntoo high by about an order of magnitude. We also infer the mass accretion rates\nwhich allows us to constrain the masses of the donor stars, and we show that\nrelatively massive, semi-degenerate donor stars are favored in all systems\nexcept GP Com. Finally, we give updated estimates for their gravitational-wave\nsignals, relevant for future space missions such as the proposed Laser\nInterferometer Space Antenna (LISA), based on their distances and the inferred\nmasses of the binary components. We show that all systems but GP Com are\nexcellent candidates for detection with LISA.\n", "machine_text": "\n\nWe present new high-precision parallax measurements for 18 stars of the AM CVn type, obtained with the Hubble Space Telescope (HST) and the Fine Guidance Sensor (FGS). These data are combined with previous HST/FGS parallax measurements for 19 other AM CVn stars, resulting in a total of 37 stars with measured parallaxes. We show that the true AM CVn binary Galactic field is much larger than previously thought on the basis of optical observations, and it extends to at least 8 kpc away from the Sun. The new data also suggest that the masses of the AM CVn stars are distributed between 2.5 and 3.5 M\u2299, with a peak at 3.1 M\u2299, in good agreement with the results of the analysis of the optically-selected sample. Finally, we show that the observed distribution of the orbital periods of the AM CVn stars is consistent with the hypothesis that the evolution of these stars is governed by the stripping of their initial hydrogen envelopes, a process that naturally leads to a distribution of orbital periods centered on the synodic period.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electrical transport and optical studies of ferromagnetic Cobalt doped\n  ZnO nanoparticles exhibiting a metal-insulator transition. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1593, "human_text": "  The observed correlation of oxygen vacancies and room temperature\nferromagnetic ordering in Co doped ZnO1-o nanoparticles reported earlier (Naeem\net al Nanotechnology 17, 2675-2680) has been further explored by transport and\noptical measurements. In these particles room temperature ferromagnetic\nordering had been observed to occur only after annealing in forming gas. In the\ncurrent work the optical properties have been studied by diffuse reflection\nspectroscopy in the UV-Vis region and the band gap of the Co doped compositions\nhas been found to decrease with Co addition. Reflections minima are observed at\nthe energies characteristic of Co+2 d-d (tethrahedral symmetry) crystal field\ntransitions, further establishing the presence of Co in substitutional sites.\nElectrical transport measurements on palletized samples of the nanoparticles\nshow that the effect of a forming gas is to strongly decrease the resistivity\nwith increasing Co concentration. For the air annealed and non-ferromagnetic\nsamples the variation in the resistivity as a function of Co content are\nopposite to those observed in the particles prepared in forming gas. The\nferromagnetic samples exhibit an apparent change from insulator to metal with\nincreasing temperatures for T>380K and this change becomes more pronounced with\nincreasing Co content. The magnetic and resistive behaviors are correlated by\nconsidering the model by Calderon et al [M. J. Calderon and S. D. Sarma, Annals\nof Physics 2007 (Accepted doi: 10.1016/j.aop.2007.01.010] where the\nferromagnetism changes from being mediated by polarons in the low temperature\ninsulating region to being mediated by the carriers released from the weakly\nbound states in the higher temperature metallic region.\n", "machine_text": "\n\nWe have synthesized ferromagnetic Co doped ZnO nanoparticles of different Co concentration by using sol-gel method and studied their structural, electrical, and optical properties. The synthesized particles were found to have spherical shape with the size of 100-300 nm as confirmed by transmission electron microscopy. The structural study revealed that the particles are single crystalline and the Co atoms are randomly distributed throughout the particles. The magnetic properties of the particles were studied by using a vibrating sample magnetometer and the particles were found to be ferromagnetic below the critical concentration of Co atoms and superparamagnetic above the critical concentration. The particles exhibited a transition from metallic behavior to insulating behavior as the Co concentration was increased. The electrical transport studies showed that the resistivity of the particles increases as the Co concentration was increased and a steep increase in resistivity was observed at the critical concentration. The particles exhibited a thermally activated behavior for the electrical transport below the critical concentration and a behavior close to the Mott variable range hopping below the critical concentration. The optical studies revealed that the particles exhibited a strong absorption peak below the critical concentration and a weak absorption peak above the critical concentration. The results showed that the electrical and optical properties of the particles are sensitive to the concentration of Co atoms and can be used to detect the presence of a magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: BVRI Surface Photometry of Isolated Spiral Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2041, "human_text": "  A release of multicolor broad band (BVRI) photometry for a subsample of 44\nisolated spirals drawn from the Catalogue of Isolated Galaxies (CIG) is\npresented. Total magnitudes and colors at various circular apertures, as well\nas some global structural/morphological parameters are estimated. Morphology is\nreevaluated through optical and sharp/filtered R band images, (B-I) color index\nmaps, and archive near-IR JHK images from the Two-Micron Survey. The CAS\nstructural parameters (Concentration, Asymmetry, and Clumpiness) were\ncalculated from the images in each one of the bands. The fraction of galaxies\nwith well identified optical/near-IR bars (SB) is 63%, while a 17% more shows\nevidence of weak or suspected bars (SAB). The sample average value of the\nmaximum bar ellipticity is 0.4. Half of the galaxies in the sample shows rings.\nWe identify two candidates for isolated galaxies with disturbed morphology. The\nstructural CAS parameters change with the observed band, and the tendencies\nthey follow with the morphological type and global color are more evident in\nthe redder bands. In any band, the major difference between our isolated\nspirals and a sample of interacting spirals is revealed in the A-S plane. A\ndeep and uniformly observed sample of isolated galaxies is intended for various\npurposes including (i) comparative studies of environmental effects, (ii)\nconfronting model predictions of galaxy evolution and (iii) evaluating the\nchange of galaxy properties with redshift.\n", "machine_text": "\n\nWe present surface photometry of 49 isolated spiral galaxies in the optical bands B, V, R, and I obtained with the Subaru Telescope. The sample galaxies were chosen from the 2 Micron All Sky Survey (2MASS) based on their optical counterparts having an axisymmetric (centered) surface brightness profile. We find that the surface brightness profiles of these galaxies are well described by a single power law in the radial direction. We derive the power law index and find that it is independent of the total optical galaxy luminosity and radius. This implies that the surface brightness profiles of isolated spiral galaxies are not a simple function of the scale of the galaxy. The photometry also shows that the surface brightness profile is not axisymmetric for a significant region of the outer disk, a signature of the influence of the presence of the spiral arms. We derive a parameter, , that measures the radial variation of the surface brightness and show that it is correlated with the total optical galaxy luminosity, radius, and the surface brightness at the center. The correlation with the surface brightness at the center implies that the inner 10% of the galaxy is not a simple power law and may contain multiple components including a central point source. The correlation with radius and total luminosity implies that the outer 80% of the galaxy is also not a simple power law. We conclude that the surface brightness profile of isolated spiral galaxies is not described by a single power law over the whole galaxy, but instead is made up of multiple components. The presence of these components has important implications for the evolution of these galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galactic Wind Signatures around High Redshift Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0652, "human_text": "  We carry out cosmological chemodynamical simulations with different strengths\nof supernova (SN) feedback and study how galactic winds from star-forming\ngalaxies affect the features of hydrogen (HI) and metal (CIV and OVI)\nabsorption systems in the intergalactic medium at high redshift. We find that\nthe outflows tend to escape to low density regions, and hardly affect the dense\nfilaments visible in HI absorption. As a result, the strength of HI absorption\nnear galaxies is not reduced by galactic winds, but even slightly increases. We\nalso find that a lack of HI absorption for lines of sight (LOS) close to\ngalaxies, as found by Adelberger et al., can be created by hot gas around the\ngalaxies induced by accretion shock heating. In contrast to HI, metal\nabsorption systems are sensitive to the presence of winds. The models without\nfeedback can produce the strong CIV and OVI absorption lines in LOS within 50\nkpc from galaxies, while strong SN feedback is capable of creating strong CIV\nand OVI lines out to about twice that distance. We also analyze the mean\ntransmissivity of HI, CIV, and OVI within 1 h$^{-1}$ Mpc from star-forming\ngalaxies. The probability distribution of the transmissivity of HI is\nindependent of the strength of SN feedback, but strong feedback produces LOS\nwith lower transmissivity of metal lines. Additionally, strong feedback can\nproduce strong OVI lines even in cases where HI absorption is weak. We conclude\nthat OVI is probably the best tracer for galactic winds at high redshift.\n", "machine_text": "\n\nWe present an analysis of the stellar content of galaxies in the high redshift Universe, based on a sample of galaxies selected from the Ultra Deep Survey. We find that the stellar populations of galaxies in the redshift range z < 1 have typical metallicities [Fe/H] > +0.5, whereas galaxies at higher redshift (z >> 1) have metallicities that are a factor of ~2 lower. This difference is interpreted as the effect of a 'galactic wind' that has been removing metals from galaxies in the high redshift Universe. We derive an empirical relation between the stellar metallicity and the galaxies' stellar mass, which we use to infer the metallicities of galaxies at very high redshift (z >> 5), where no useful photometric metallicities can be obtained. We find that these galaxies also show the tell-tale sign of a strong metal-poor population, suggesting that galaxies in the early Universe were much more efficient at removing metals than galaxies in the local Universe. We discuss the implications of our findings for the theory of galaxy formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gauge symmetry in Kitaev-type spin models and index theorems on odd\n  manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3829, "human_text": "  We construct an exactly soluble spin-$\\frac{1}2$ model on a honeycomb\nlattice, which is a generalization of Kitaev model. The topological phases of\nthe system are analyzed by study of the ground state sector of this model, the\nvortex-free states. Basically, there are two phases, A phase and B phase. The\nbehaviors of both A and B phases may be studied by mapping the ground state\nsector into a general p-wave paired states of spinless fermions with tunable\npairing parameters on a square lattice. In this p-wave paired state theory, the\nA phase is shown to be the strong paired phase, an insulating phase. The B\nphase may be either gapped or gapless determined by the generalized inversion\nsymmetry is broken or not. The gapped B is the weak pairing phase described by\neither the Moore-Read Pfaffian state of the spinless fermions or anti-Pfaffian\nstate of holes depending on the sign of the next nearest neighbor hopping\namplitude. A phase transition between Pfaffian and anti-Pfaffian states are\nfound in the gapped B phase. Furthermore, we show that there is a hidden SU(2)\ngauge symmetry in our model. In the gapped B phase, the ground state has a\nnon-trivial topological number, the spectral first Chern number or the chiral\ncentral charge, which reflects the chiral anomaly of the edge state. We proved\nthat the topological number is identified to the reduced eta-invariant and this\nanomaly may be cancelled by a bulk Wess-Zumino term of SO(3) group through an\nindex theorem in 2+1 dimensions.\n", "machine_text": "\n\nWe study the relation between gauge symmetry and the structure of odd manifolds in the context of Kitaev-type spin models. We show that the common belief that the symmetry of such models is tightly related to the existence of a symmetry group acting on the spins of the model is not correct. We show that the underlying group of the gauge symmetry of a model can be an infinite analog of the symmetry group of the spins, in the sense that it acts on the sets of spins by taking the ordinary symmetric group SO(n) to the symmetric group SO(n+1). We show further that this result does not imply the existence of an action of the underlying group on the spins. As an application, we give a description of the set of index theorems on odd manifolds in terms of the properties of the discriminant of a trilinear form on the constituent vector space of a representation. We show that this description provides a natural way of classifying the index theorems on odd manifolds according to the symmetry of the underlying group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unravelling the morphologies of Luminous Compact Galaxies using the\n  HST/ACS GOODS survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2177, "human_text": "  (Abridged) Luminous Compact Galaxies (LCGs) (M_B < -20, R_{1/2} < 4.5kpc and\nEW_{0}(OII) >15\\AA) constitute one of the most rapidly evolving galaxy\npopulations over the last ~8 Gyr history of the universe. Due to their\ninherently compact sizes, any detailed quantitative analysis of their\nmorphologies has proved to be difficult in the past. In this work we use the\nhigh angular resolution imaging data, from the HST/ACS GOODS survey, to study\nthe quantitative morphology of a complete sample of LCGs in the redshift range\n0.5 < z < 1.2. We have derived structural parameters for a representative\nsample of 39 LCGs selected from the GOODS-S field, using full 2-dimensional\nsurface brightness profile fitting of the galaxy images in each of the four\nfilters available. B-z color maps are used as an aid in the morphological\nclassification. We then use the rest frame B band bulge flux fraction (B/T) to\ndetermine the morphological class of the galaxies. Mergers were essentially\nidentified visually by the presence of multiple maxima of comparable intensity\nin the rest frame B band images, aided by the color maps to distinguish them\nfrom HII regions. We derive the following morphological mix for our sample of\nintermediate redshift LCGs: Mergers: ~36%, Disk dominated: ~22%, S0: ~20%,\nEarly types: ~7%, Irr/tadpole: ~15%. We establish that our sample LCGs are\nintermediate mass objects with a median stellar mass of Log(M/M_{\\odot})=10.32.\nWe also derive dust enshrouded SFR values ranging from a few to ~65\n$M_{\\odot}$/year using Spitzer 24$\\mu m$ data. We estimate a factor ~11 fall in\nthe comoving number density of blue LCGs from redshifts 0.5 < z < 1.2 to the\ncurrent epoch. We finally discuss the evolutionary scenario of these LCGs which\nmight give us some clues regarding their descendants in the local universe.\n", "machine_text": "\n\nUnravelling the morphologies of Luminous Compact Galaxies using the HST/ACS GOODS survey\n\nWe present a statistical analysis of the morphologies and photometric properties of a sample of 25 Luminous Compact Galaxies (LCGs) selected from the HST/ACS GOODS survey. We use the+/ - aperture photometry and the two-band colour information from the survey to determine the photometric parameters of our sample, and to probe the nature of the observed morphologies. We find that the LCGs in our sample are log(M/Mpc2) 10.5 +/- 1.4, which is consistent with the notion that LCGs are the most compact galactic objects in the Universe. We show that a simple model in which the observed photometric properties are related to the underlying stellar mass, via a power-law scale length, can quantitatively reproduce the observed morphology distribution, without the need to invoke specific physical mechanisms such as the bars and slingshot from the centre. We also show that the observed distribution of colour excesses can be reproduced by a simple model in which the colour excess is related to the local surface or volume density, and is not related to the overall shape of the galaxy. We discuss our results in the context of the current theory of LCG formation, and identify the regions of agreement and disagreement between the predictions of theory and the results of our analysis.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Augmented Sparse Reconstruction of Protein Signaling Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3989, "human_text": "  The problem of reconstructing and identifying intracellular protein signaling\nand biochemical networks is of critical importance in biology today. We sought\nto develop a mathematical approach to this problem using, as a test case, one\nof the most well-studied and clinically important signaling networks in biology\ntoday, the epidermal growth factor receptor (EGFR) driven signaling cascade.\nMore specifically, we suggest a method, augmented sparse reconstruction, for\nthe identification of links among nodes of ordinary differential equation (ODE)\nnetworks from a small set of trajectories with different initial conditions.\nOur method builds a system of representation by using a collection of integrals\nof all given trajectories and by attenuating block of terms in the\nrepresentation itself. The system of representation is then augmented with\nrandom vectors, and minimization of the 1-norm is used to find sparse\nrepresentations for the dynamical interactions of each node. Augmentation by\nrandom vectors is crucial, since sparsity alone is not able to handle the large\nerror-in-variables in the representation. Augmented sparse reconstruction\nallows to consider potentially very large spaces of models and it is able to\ndetect with high accuracy the few relevant links among nodes, even when\nmoderate noise is added to the measured trajectories. After showing the\nperformance of our method on a model of the EGFR protein network, we sketch\nbriefly the potential future therapeutic applications of this approach.\n", "machine_text": "\n\nWe present a new algorithm for sparse reconstruction of continuous-time dynamic models from DNA microarray time-series data. We assume that the underlying dynamical system is described by a set of ordinary differential equations and that the microarray data is obtained by sampling the system at finite and uniform time intervals. The proposed method is based on the Augmented Lagrangian method for sparse optimization. The new algorithm is tested on a number of synthetic examples and the results are compared to those obtained by the original Lagrangian method as well as to those obtained by the widely used Partial Least Squares (PLS) method. We also apply the new algorithm to the analysis of real microarray data sets, obtained from a publicly available resource. In all cases, the proposed method gives comparable or better results than the original Lagrangian method and the PLS method, in terms of both the quality of the reconstructed system and the statistical significance of the parameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spherically symmetric problem on the brane and galactic rotation curves. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0649, "human_text": "  We investigate the braneworld model with induced gravity to clarify the role\nof the cross-over length scale \\ell in the possible explanation of the\ndark-matter phenomenon in astrophysics and in cosmology. Observations of the 21\ncm line from neutral hydrogen clouds in spiral galaxies reveal that the\nrotational velocities remain nearly constant at a value v_c ~ 10^{-3}--10^{-4}\nin the units of the speed of light in the region of the galactic halo. Using\nthe smallness of v_c, we develop a perturbative scheme for reconstructing the\nmetric in a galactic halo. In the leading order of expansion in v_c, at the\ndistances r \\gtrsim v_c \\ell, our result reproduces that obtained in the\nRandall-Sundrum braneworld model. This inequality is satisfied in a real spiral\ngalaxy such as our Milky Way for distances r ~ 3 kpc, at which the rotational\nvelocity curve becomes flat, v_c ~ 7 \\times 10^{-4}, if \\ell \\lesssim 2 Mpc.\nThe gravitational situation in this case can be approximately described by the\nEinstein equations with the so-called Weyl fluid playing the role of dark\nmatter. In the region near the gravitating body, we derive a closed system of\nequations for static spherically symmetric situation under the approximation of\nzero anisotropic stress of the Weyl fluid. We find the Schwarzschild metric to\nbe an approximate vacuum solution of these equations at distances r \\lesssim\n(r_g \\ell^2)^{1/3}. The value \\ell \\lesssim 2 Mpc complies well with the\nsolar-system tests. At the same time, in cosmology, a low-density braneworld\nwith \\ell of this order of magnitude can mimic the expansion properties of the\nhigh-density LCDM (lambda + cold dark matter) universe at late times. Combined\nobservations of galactic rotation curves and gravitational lensing can possibly\ndiscriminate between the higher-dimensional effects and dark matter.\n", "machine_text": "\nWe consider a spherically symmetric problem on the brane and galactic rotation curves. The motivation for the research is to investigate the mechanism of the formation of the galactic rotation curves. The key ideas and methodology are to consider a spherically symmetric potential field $V(r)$, and the induced metric $g(r)$ is obtained by the metric theorem. The spherically symmetric solution with a potential $V(r)$ is obtained by the separation of variables. The galactic rotation curve is the solution of the Poisson equation with a piecewise constant right-hand side, which is the restriction of the solution to the galactic plane. The result obtained is that the galactic rotation curve is the solution of the Poisson equation with a piecewise constant right-hand side, which is the restriction of the solution to the galactic plane. The problem the work attempts to solve is that the mechanism of the formation of the galactic rotation curves is investigated. The work also attempts to show that the potential field $V(r)$ can be obtained by the integration of the divergence of the matter density $\\rho(r)$ in the galactic plane. Any practical or theoretical applications from your findings or implications for future research should be described. The work is applied to the galactic rotation curves and the result obtained is consistent with the observation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Redesigning Computer-based Learning Environments: Evaluation as\n  Communication. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1127, "human_text": "  In the field of evaluation research, computer scientists live constantly upon\ndilemmas and conflicting theories. As evaluation is differently perceived and\nmodeled among educational areas, it is not difficult to become trapped in\ndilemmas, which reflects an epistemological weakness. Additionally, designing\nand developing a computer-based learning scenario is not an easy task.\nAdvancing further, with end-users probing the system in realistic settings, is\neven harder. Computer science research in evaluation faces an immense\nchallenge, having to cope with contributions from several conflicting and\ncontroversial research fields. We believe that deep changes must be made in our\nfield if we are to advance beyond the CBT (computer-based training) learning\nmodel and to build an adequate epistemology for this challenge. The first task\nis to relocate our field by building upon recent results from philosophy,\npsychology, social sciences, and engineering. In this article we locate\nevaluation in respect to communication studies. Evaluation presupposes a\ndefinition of goals to be reached, and we suggest that it is, by many means, a\nsilent communication between teacher and student, peers, and institutional\nentities. If we accept that evaluation can be viewed as set of invisible rules\nknown by nobody, but somehow understood by everybody, we should add\nanthropological inquiries to our research toolkit. The paper is organized\naround some elements of the social communication and how they convey new\ninsights to evaluation research for computer and related scientists. We found\nsome technical limitations and offer discussions on how we relate to technology\nat same time we establish expectancies and perceive others work.\n", "machine_text": "\n\nRedesigning Computer-based Learning Environments: Evaluation as Communication\nThe increasing use of computer technology in schools has led to the development of a variety of computer-based learning environments. In spite of the potential of these new environments to support learning, their current use does not always result in effective learning. This is due in part to the fact that the development of these environments has not been based on sound educational principles. In addition, the fact that these environments are new and often quite complex means that teachers often do not have the necessary skills and knowledge to use them effectively. In this article, we discuss the results of a research project in which we redesigned a computer-based learning environment, with the aim of making it more effective for learning. The key idea behind the redesign was that the environment should be based on sound educational principles and that it should be evaluated in terms of how well it supported learning. We discuss the results of our evaluation, which showed that the redesigned environment was more effective for learning than the original environment. We also discuss the implications of our results for the design and evaluation of computer-based learning environments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Wavelet transforms in a critical interface model for Barkhausen noise. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1574, "human_text": "  We discuss the application of wavelet transforms to a critical interface\nmodel, which is known to provide a good description of Barkhausen noise in soft\nferromagnets. The two-dimensional version of the model (one-dimensional\ninterface) is considered, mainly in the adiabatic limit of very slow driving.\nOn length scales shorter than a crossover length (which grows with the strength\nof surface tension), the effective interface roughness exponent $\\zeta$ is\n$\\simeq 1.20$, close to the expected value for the universality class of the\nquenched Edwards-Wilkinson model. We find that the waiting times between\navalanches are fully uncorrelated, as the wavelet transform of their\nautocorrelations scales as white noise. Similarly, detrended size-size\ncorrelations give a white-noise wavelet transform. Consideration of finite\ndriving rates, still deep within the intermittent regime, shows the wavelet\ntransform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies.\nThis behavior is ascribed to intra-avalanche correlations.\n", "machine_text": "\n\nWavelet Transforms in a Critical Interface Model for Barkhausen Noise\n\nWe investigate the problem of statistical learning of a boundary between two different physical systems, where the observed data is generated by the critical coupling of the systems. Such problems arise, for example, in phase transitions between different statistical mechanics systems, in systems biology, or in the case of threshold-like phenomena in engineering. We consider a model problem in which the observations are samples from a random walk on a lattice, with a randomly chosen step size, and where the transition to a different random walk with a different step size occurs at a threshold value of the step size. The unknown threshold value is estimated from the data by using a wavelet transform. We show that both the empirical distribution of the wavelet coefficients and the minimum cross-validation error of the estimated threshold follow a heavy-tailed distribution, and we provide a rigorous theoretical explanation for this fact. We also show that the learned boundary can be used to generate new, synthetic data with a desired statistical properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer Mid-Infrared Spectroscopy of Infrared Luminous Galaxies at z~2\n  II: Diagnostics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1765, "human_text": "  We present mid-IR spectral decomposition of a sample of 48 Spitzer-selected\nULIRGs spanning z~1-3 and likely L_IR~10^12-10^13Lsun. Our study aims at\nquantifying the star-formation and AGN processes in these sources which recent\nresults suggest have evolved strongly between the observed epoch and today. To\ndo this, we study the mid-IR contribution of PAH emission, continuum, and\nextinction. About 3/4 of our sample are continuum- (i.e. AGN) dominated\nsources, but ~60% of these show PAH emission, suggesting the presence of\nstar-formation activity. These sources have redder mid-IR colors than typical\noptically-selected quasars. About 25% of our sample have strong PAH emission,\nbut none are likely to be pure starbursts as reflected in their relatively high\n5um hot dust continua. However, their steep 30um-to-14um slopes suggest that\nstar-formation might dominate the total infrared luminosity. Six of our z~2\nsources have EW6.2>~0.3um and L_14um>~10^12Lsun (implying L_IR>~10^13Lsun). At\nthese luminosities, such high EW6.2 ULIRGs do not exist in the local Universe.\nWe find a median optical depth at 9.7um of <tau_9.7>=1.4. This is consistent\nwith local IRAS-selected ULIRGs, but differs from early results on\nSCUBA-selected z~2 ULIRGs. Similar to local ULIRGs about 25% of our sample show\nextreme obscuration (tau_9.7>~3) suggesting buried nuclei. In general, we find\nthat our sources are similar to local ULIRGs, but are an order of magnitude\nmore luminous. It is not clear whether our z~2 ULIRGs are simply scaled-up\nversions of local ULIRGs, or subject to fundamentally different physical\nprocesses.\n", "machine_text": "\n\nWe present a diagnostic study of a sample of infrared luminous galaxies (ILGs) selected from the Spitzer Survey of Stellar Structure in Galaxies at z~2, using the Spitzer Mid-Infrared Spectrograph (SMIRS) to measure the gas mass and the stellar mass. We find that the gas mass of these ILGs is, on average, only 1.4 times the stellar mass, and that the distribution of gas masses is well described by a power law with a linear regression fit of the form log(gas mass/stellar mass) = 1.29 + 0.52(stellar mass)^{-0.37}, where the stellar mass is expressed in units of $10^{10} \\ M_{\\odot}$. This is consistent with a simple model in which the gas mass is a constant fraction (1.4) of the stellar mass, regardless of the galaxy's absolute magnitude, density, or star formation rate (SFR). The model also predicts that the minimum gas mass is equal to the stellar mass, and that the gas mass increases superlinearly with the stellar mass. We discuss the implications of our results for models of galaxy formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SubmilliJansky Transients in Archival Radio Observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3158, "human_text": "  [ABRIDGED] We report the results of a 944-epoch survey for transient sources\nwith archival data from the Very Large Array spanning 22 years with a typical\nepoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a\nsingle field of view with a full-width at half-maximum of 8.6' and 5.1',\nrespectively, and achieved a typical point-source detection threshold at the\nbeam center of ~300 microJy per epoch. Ten transient sources were detected with\na significance threshold such that only one false positive would be expected.\nOf these transients, eight were detected in only a single epoch. Two transients\nwere too faint to be detected in individual epochs but were detected in\ntwo-month averages. None of the ten transients was detected in longer-term\naverages or associated with persistent emission in the deep image produced from\nthe combination of all epochs. The cumulative rate for the short timescale\nradio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2\nyr^-1, where the uncertainty is due to the unknown duration of the transients,\n20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/-\n0.4 transient per square degrees above a flux density of 370 microJy. Two\ntransients are associated with galaxies at z=0.040 and z=0.249. These may be\nsimilar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB\n980428. Six transients have no counterparts in the optical or infrared (R=27,\nKs=18). The hosts and progenitors of these transients are unknown.\n", "machine_text": "\n\nWe present a method to search archival radio observations for transients with sensitivity below one Jansky. We show that archival Very Long Baseline Interferometry (VLBI) observations can be searched with a sensitivity of  \u223c 1 \u03bcJansky with a signal-to-noise ratio of  \u223c 5, without any special processing. We present a catalog of 13 new transient sources found in archival VLBI observations, including three sources with fluxes above 10 \u03bcJansky. These transients are correlated with previously known transient sources in the Galactic plane, supporting the hypothesis that the transient population is tightly coupled to the Galactic magnetic field. We find that the observed transient distribution has a power law dependence on Galactic longitude  \u223c -0.35, which is consistent with a simple model in which the transient distribution is controlled by the local magnetic field configuration. Our results imply that the population of transient sources in the Galactic plane is several orders of magnitude larger than previously thought on the basis of optical observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Clustering Coefficients of Protein-Protein Interaction Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3748, "human_text": "  The properties of certain networks are determined by hidden variables that\nare not explicitly measured. The conditional probability (propagator) that a\nvertex with a given value of the hidden variable is connected to k of other\nvertices determines all measurable properties. We study hidden variable models\nand find an averaging approximation that enables us to obtain a general\nanalytical result for the propagator. Analytic results showing the validity of\nthe approximation are obtained. We apply hidden variable models to\nprotein-protein interaction networks (PINs) in which the hidden variable is the\nassociation free-energy, determined by distributions that depend on\nbiochemistry and evolution. We compute degree distributions as well as\nclustering coefficients of several PINs of different species; good agreement\nwith measured data is obtained. For the human interactome two different\nparameter sets give the same degree distributions, but the computed clustering\ncoefficients differ by a factor of about two. This shows that degree\ndistributions are not sufficient to determine the properties of PINs.\n", "machine_text": "\nWe introduce and study a new index, the clustering coefficient of a graph, which measures the density of triangles in the graph. We show that this index is a robust measure of the clustering of the graph, in the sense that it is insensitive to the details of the graph, provided that it is large enough. We apply this new index to protein-protein interaction networks, and show that it can be used to detect communities and to evaluate the significance of an observed community structure. We find that the clustering coefficients of real protein-protein interaction networks are significantly higher than random graphs with the same degree distribution, and we show this by using both a random graph generator and by generating all possible graphs with a given degree distribution. We show that this result is consistent with a model in which the proteins in a network tend to form communities of size three. We also find that the size of the largest community is a good measure of the complexity of the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Gemini Deep Planet Survey -- GDPS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.429, "human_text": "  We present the results of the Gemini Deep Planet Survey, a near-infrared\nadaptive optics search for giant planets and brown dwarfs around nearby young\nstars. The observations were obtained with the Altair adaptive optics system at\nthe Gemini North telescope and angular differential imaging was used to\nsuppress the speckle noise of the central star. Detection limits for the 85\nstars observed are presented, along with a list of all faint point sources\ndetected around them. Typically, the observations are sensitive to angular\nseparations beyond 0.5\" with 5-sigma contrast sensitivities in magnitude\ndifference at 1.6 micron of 9.5 at 0.5\", 12.9 at 1\", 15.0 at 2\", and 16.5 at\n5\". For the typical target of the survey, a 100 Myr old K0 star located 22 pc\nfrom the Sun, the observations are sensitive enough to detect planets more\nmassive than 2 Mjup with a projected separation in the range 40-200 AU. Second\nepoch observations of 48 stars with candidates (out of 54) have confirmed that\nall candidates are unrelated background stars. A detailed statistical analysis\nof the survey results, yielding upper limits on the fractions of stars with\ngiant planet or low mass brown dwarf companions, is presented. Assuming a\nplanet mass distribution dN/dm m^{-1.2} and a semi-major axis distribution\ndN/da a^{-1}, the 95% credible upper limits on the fraction of stars with at\nleast one planet of mass 0.5-13 Mjup are 0.28 for the range 10-25 AU, 0.13 for\n25-50 AU, and 0.093 for 50-250 AU. The 95% credible interval for the fraction\nof stars with at least one brown dwarf companion having a semi-major axis in\nthe range 25-250 AU is 0.019 (-0.015/+0.083), irrespective of any assumption on\nthe mass and semi-major axis distributions. The stars HD 14802, HD 166181, and\nHD 213845 have been resolved into binaries for the first time.\n", "machine_text": "\n\nThe Gemini Deep Planet Survey -- GDPS\n\nThe Gemini Deep Planet Survey (GDPS) is an optical/NIR imaging survey of the solar system's giant planets and their satellites, and the small bodies in the Kuiper Belt, using the international Gemini Observatory. The primary goal of the survey is to study the atmosphere of Jupiter and the structure and evolution of its ring and satellite system, in order to improve our understanding of the planet's history and fate. We will also study the structure and evolution of the satelliets of Saturn, Uranus, and Neptune, as well as the Kuiper Belt.\n\nWe have completed our survey of the giant planets and their satellites, and are now conducting a dedicated survey of the Kuiper Belt. The giant planet survey has resulted in the discovery of many new satellites, and a reclassification of the rings of Saturn and Uranus. The Kuiper Belt survey has resulted in the discovery of many new objects, and a better understanding of the belt's population.\n\nThe GDPS is a joint project of the Gemini Observatory, the California Institute of Technology, and the University of Hawaii. The survey is being conducted with the international Gemini Observatory, using the twin 8-m telescopes on Hawaii and Chile, and the infrared imaging capabilities of the W.M. Keck Observatory, also on Hawaii.\n\nWe have produced a number of scientific results. Here we present some of the key results from the survey.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetorotational Collapse of Population III Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1945, "human_text": "  We perform a series of two-dimensional magnetorotational core-collapse\nsimulations of Pop III stars. Changing the initial distributions of rotation\nand magnetic fields prior to collapse in a parametric manner, we compute 19\nmodels. By so doing, we systematically investigate how rotation and magnetic\nfields affect the collapse dynamics and explore how the properties of the\nblack-hole formations and neutrino emissions could be affected. As for the\nmicrophysics, we employ a realistic equation of state and approximate the\nneutrino transfer by a multiflavour leakage scheme. With these computations, we\nfind that the jet-like explosions are obtained by the magnetodriven shock waves\nif the initial magnetic field is as large as $10^{12}$ G. We point out that the\nblack-hole masses at the formation decrease with the initial field strength, on\nthe other hand, increase with the initial rotation rates. As for the neutrino\nproperties, we point out that the degree of the differential rotation plays an\nimportant role to determine which species of the neutrino luminosity is more\ndominant than the others. Furthermore, we find that the stronger magnetic\nfields make the peak neutrino luminosities smaller, because the magnetic\npressure acts to halt the collapse in the central regions, leading to the\nsuppression of the releasable gravitational binding energies.\n", "machine_text": "\nWe propose that massive Population III stars with weak magnetic fields can form through the magnetorotational collapse of a rotating cloud. We show that such a collapse can occur provided that the magnetic field is sufficiently diluted, the angular momentum is high enough, and the resistivity is low. The simplest case we consider is a uniform magnetic field along the rotation axis. In this case, the instability is triggered when the ratio of the resistivity to the angular momentum per unit mass, \u03c1/L\u22c5kg\u20131, decreases below a critical value of \u03c1/L\u22c5kg\u20131\u22483.3\u00d71020\u03a9m. We show that this condition can be satisfied if the magnetic field is sufficiently weak (B\u22725G) and the angular momentum is high (L\u2273107kg\u22c5m2), as can be the case in a collapsing rotating cloud. The critical resistivity for the instability to be triggered increases with the magnetic field and reaches \u03c1\u22485\u00d71020\u03a9m when B\u22485G. We also consider the more general case of a radially varying magnetic field, which is likely to be present in a collapsing cloud that formed through the accretion of rotating magnetized infalling material. We show that for a collapsing cloud to be stable against the magnetorotational instability, the radial profile of the resistivity has to satisfy \u03c1\u22655\u00d71020\u03a9m, with \u03c1 being the resistivity at the cloud's inner radius. We discuss the effect of the ionization fraction on the critical resistivity and find that a cloud can be stable against the magnetorotational instability even if the ionization fraction \u0393 is relatively high, provided that \u03c1\u2265\u0393\u22c5\u03c10, where \u03c10 is the resistivity of an uncharged gas and \u0393\u22c5\u03c10\u22481020\u03a9m. We also derive a simple expression for the evolution of the frequency \u03c9 of the observed gravitational waves during the magnetorotational collapse of a massive Population III star and find that \u03c9 can be as low as \u03c9\u22481 Hz.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Complexity of Model Checking Higher-Order Fixpoint Logic. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3931, "human_text": "  Higher-Order Fixpoint Logic (HFL) is a hybrid of the simply typed\n\\lambda-calculus and the modal \\lambda-calculus. This makes it a highly\nexpressive temporal logic that is capable of expressing various interesting\ncorrectness properties of programs that are not expressible in the modal\n\\lambda-calculus.\n  This paper provides complexity results for its model checking problem. In\nparticular we consider those fragments of HFL built by using only types of\nbounded order k and arity m. We establish k-fold exponential time completeness\nfor model checking each such fragment. For the upper bound we use fixpoint\nelimination to obtain reachability games that are singly-exponential in the\nsize of the formula and k-fold exponential in the size of the underlying\ntransition system. These games can be solved in deterministic linear time. As a\nsimple consequence, we obtain an exponential time upper bound on the expression\ncomplexity of each such fragment.\n  The lower bound is established by a reduction from the word problem for\nalternating (k-1)-fold exponential space bounded Turing Machines. Since there\nare fixed machines of that type whose word problems are already hard with\nrespect to k-fold exponential time, we obtain, as a corollary, k-fold\nexponential time completeness for the data complexity of our fragments of HFL,\nprovided m exceeds 3. This also yields a hierarchy result in expressive power.\n", "machine_text": "\n\nWe introduce a technique for combining two fundamental concepts of formal system theory, namely (termination) proof checking and ( Fixpoint ) model checking. The motivation for this work is the fact that termination can be viewed as an automatically generated ( recursive ) bisimulation class, and the question arises whether the technique of model checking can be used to automatically check the termination of a system. Our main result is that this is not possible in general, but that it is possible to construct a class of logic programs for which termination can be checked efficiently by model checking. We show how this result can be used to extract a class of logic programs for which the question of whether a program has an infinite execution can be answered by model checking. We also consider a more general setting, in which the class of systems for which model checking can answer the question of termination is significantly enlarged. In this setting, we show how to reduce the problem of termination to a problem of model checking.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Signatures of SUSY Dark Matter at the LHC and in the Spectra of Cosmic\n  Rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3943, "human_text": "  This thesis discusses the search for supersymmetry at the future Large Hadron\nCollider (LHC) and the ongoing construction of one of the four large LHC\nexperiments, the Compact Muon Solenoid (CMS), and focuses on the detection of\nsignals from the annihilation of supersymmetric dark matter in the spectra of\ncosmic rays.\n  Measurements of cosmic ray antiparticles, such as positrons, can impose\nstrong constraints on the nature of new physics beyond the Standard Model.\nHowever, cosmic ray positron measurements are experimentally very challenging\ndue to the vast proton background. A novel approach of positron identification\nwith the space-borne AMS-01 experiment, namely through the detection of\nbremsstrahlung conversion in a silicon microstrip detector, is introduced.\nBremsstrahlung from protons is suppressed by a factor of more than 3*10^6 with\nrespect to positrons. The results of the positron measurement show that the\nbremsstrahlung approach extends the sensitivity range of AMS-01 to positron\nmomenta up to 50 GeV/c, which is far beyond the original scope of the\nexperiment. At momenta above 8 GeV/c there is indication for a positron\noverabundance with respect to model predictions for purely secondary positron\nproduction. Therefore, the AMS-01 data lend further weight to the hints of a\npositron overabundance seen in the data from earlier experiments.\n  The positron fraction measurements from the most recent experiments are\ncombined with the results of this analysis, giving the most precise positron\nfraction data yet available.\n", "machine_text": "\n\nWe propose signatures of weakly-interacting massive particles (WIMPs) of supersymmetric (SUSY) dark matter (DM) in the data from large-scale experiments at the LHC and in the spectra of cosmic rays (CRs). For the LHC experiments, we show that the semi-leptonic and radiative signals of WIMPs in the hadron final states are within the reach of the LHC, and we discuss the prospects of the LHC in searching for the SUSY WIMPs in the multi-tonne and TeV mass ranges. We also show that the expected rate of WIMP-nucleon collisions is large enough to produce the chorus of low-energy neutrinos observed by the IceCube experiment, provided that the WIMP mass is no heavier than a few TeV. As for the CRs, we show that the spectral distribution of CRs is consistent with the picture that the supergravity (SG) scale is close to the CR energy scale, provided that the mass of the lightest SUSY particle (LSP) is not heavier than a few TeV. We also show that the pattern of the primary and secondary CRs is consistent with the picture that the world-line of the CRs is affected by a small-scale (60-120GeV) Brantian symmetry, provided that the LSP mass is not heavier than a few TeV. Our results suggest that a lightweight SUSY scenario is preferred over a heavy SUSY scenario for the DM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Universality of the REM for dynamics of mean-field spin glasses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2135, "human_text": "  We consider a version of a Glauber dynamics for a p-spin\nSherrington--Kirkpatrick model of a spin glass that can be seen as a time\nchange of simple random walk on the N-dimensional hypercube. We show that, for\nany p>2 and any inverse temperature \\beta>0, there exist constants g>0, such\nthat for all exponential time scales, $\\exp(\\gamma N)$, with $\\gamma< g$, the\nproperly rescaled clock process (time-change process), converges to an\n\\alpha-stable subordinator where \\alpha=\\gamma/\\beta^2<1. Moreover, the\ndynamics exhibits aging at these time scales with time-time correlation\nfunction converging to the arcsine law of this \\alpha-stable subordinator. In\nother words, up to rescaling, on these time scales (that are shorter than the\nequilibration time of the system), the dynamics of p-spin models ages in the\nsame way as the REM, and by extension Bouchaud's REM-like trap model,\nconfirming the latter as a universal aging mechanism for a wide range of\nsystems. The SK model (the case p=2) seems to belong to a different\nuniversality class.\n", "machine_text": "\n\nWe consider a family of generalized spin glasses with long-range interactions and study the Universality of the REM (Response to External Fields) for their dynamics. We show that, for glasses whose symmetry is not too badly broken by the external fields, the dynamics is described by a set of master equations which are symmetric under the action of the internal symmetry group of the glass. This symmetry is not an exact one however, and is modified by a certain form of theuidyl representation. Our results are consistent with a large number of exactly solvable models which can be thought of as \"derived\" from the master equations by a process of \" froze-in\" symmetry breaking. In a second part we consider the case of glasses whose symmetry is badly broken by the external fields. We show that the corresponding dynamics is given by a set of differential equations which are symmetric under the action of the internal symmetry group. This symmetry is not an exact one however, and is modified by a certain form of theuidyl representation. Our results are consistent with a large number of exactly solvable models which can be thought of as \"derived\" from the differential equations by a process of \" froze-in\" symmetry breaking.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: XMM-Newton observations of the first unidentified TeV gamma-ray source\n  TeV J2032+4130. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0009, "human_text": "  (abridged) The first unidentified very high energy gamma ray source (TeV\nJ2032+4130) in the Cygnus region has been the subject of intensive search for a\ncounterpart source at other wavelengths. A deep ($\\approx 50$ ksec) exposure of\nTeV J2032+4130 with \\textit{XMM-Newton} has been obtained. The contribution of\npoint sources to the observed X-ray emission from TeV J2032+4130 is subtracted\nfrom the data. The point-source subtracted X-ray data are analyzed using blank\nsky exposures and regions adjacent to the position of TeV J2032+4130 in the\nfield of view covered by the XMM-Newton telescopes to search for diffuse X-ray\nemission. An extended X-ray emission region with a full width half maximum\n(FWHM) size of $\\approx 12$ arc min is found. The centroid of the emission is\nco-located with the position of TeV J2032+4130.The energy spectrum of the\nemission coinciding with the position and extension of TeV J2032+4130 can be\nmodeled by a power-law model with a photon index\n$\\Gamma=1.5\\pm0.2_\\mathrm{stat}\\pm0.3_\\mathrm{sys}$ and an energy flux\nintegrated between 2 and 10 keV of $f_{2-10 \\mathrm{keV}} \\approx 7\\cdot\n10^{-13}$ ergs/(cm$^2$ s) which is lower than the very high energy gamma-ray\nflux observed from TeV J2032+4130. We conclude that the faint extended X-ray\nemission discovered in this observation is the X-ray counterpart of TeV\nJ2032+4130. Formally, it can not be excluded that the extended emission is due\nto an unrelated population of faint, hot ($k_BT\\approx 10$ keV) unresolved\npoint-sources which by chance coincides with the position and extension of TeV\nJ2032+4130. We discuss our findings in the frame of both hadronic and leptonic\ngamma-ray production scenarios.\n", "machine_text": "\nWe present XMM-Newton observations of the first unidentified TeV gamma-ray source, TeV J2032+4130. We find that the X-ray and gamma-ray emission is due to a single entity. The X-ray spectrum is described by a power law with a photon index of 1.9 and a temperature of 3 kT. The intensity is modulated with a source count rate of $6 \\times 10^{-4}$ s$^{-1}$ and a morphology consistent with a single source. The Compton-thinning ratio is 1.5, indicating that the bulk of the gamma-ray emission is likely to be due to thermal Compton-scattering of the X-ray radiation. A 1-10 keV peak luminosity of $3 \\times 10^{36}$ erg s$^{-1}$ and a duty cycle of $25 \\%$ suggest a highly variable and transient source. The observed properties of the source are consistent with a single Wolf-Rayet star with a strong magnetic field and a non-spherically symmetric distribution of matter. We discuss the properties of the source in the context of known Wolf-Rayet stars and the phenomena that may produce the observed X-ray and gamma-ray emission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lifetime Improvement of Wireless Sensor Networks by Collaborative\n  Beamforming and Cooperative Transmission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3396, "human_text": "  Extending network lifetime of battery-operated devices is a key design issue\nthat allows uninterrupted information exchange among distributive nodes in\nwireless sensor networks. Collaborative beamforming (CB) and cooperative\ntransmission (CT) have recently emerged as new communication techniques that\nenable and leverage effective resource sharing among collaborative/cooperative\nnodes. In this paper, we seek to maximize the lifetime of sensor networks by\nusing the new idea that closely located nodes can use CB/CT to reduce the load\nor even avoid packet forwarding requests to nodes that have critical battery\nlife. First, we study the effectiveness of CB/CT to improve the signal strength\nat a faraway destination using energy in nearby nodes. Then, a 2D disk case is\nanalyzed to assess the resulting performance improvement. For general networks,\nif information-generation rates are fixed, the new routing problem is\nformulated as a linear programming problem; otherwise, the cost for routing is\ndynamically adjusted according to the amount of energy remaining and the\neffectiveness of CB/CT. From the analysis and simulation results, it is seen\nthat the proposed schemes can improve the lifetime by about 90% in the 2D disk\nnetwork and by about 10% in the general networks, compared to existing schemes.\n", "machine_text": "\n\n Lifetime Improvement of Wireless Sensor Networks by Collaborative Beamforming and Cooperative Transmission. Wireless sensor networks have many applications in monitoring, tracking and controlling the systems in various fields. In this paper, we study the lifetime of wireless sensor networks (WSNs) using collaborative beamforming and cooperative transmission techniques. We consider the energy efficiency as a performance metric to improve the lifetime of WSNs. The conventional multi-hop WSNs suffer from the overhearing problem, which causes the energy consumption to increase rapidly. To address this problem, we propose a novel collaborative beamforming scheme that enables the nodes to overhear the least possible number of transmissions. We then further improve the lifetime of the network by allowing the nodes to use the multi-hop cooperative transmission technique. We analyze the proposed schemes via simulation and show that the collaborative beamforming and cooperative transmission techniques can significantly improve the lifetime of WSNs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolutionary Neural Gas (ENG): A Model of Self Organizing Network from\n  Input Categorization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0598, "human_text": "  Despite their claimed biological plausibility, most self organizing networks\nhave strict topological constraints and consequently they cannot take into\naccount a wide range of external stimuli. Furthermore their evolution is\nconditioned by deterministic laws which often are not correlated with the\nstructural parameters and the global status of the network, as it should happen\nin a real biological system. In nature the environmental inputs are noise\naffected and fuzzy. Which thing sets the problem to investigate the possibility\nof emergent behaviour in a not strictly constrained net and subjected to\ndifferent inputs. It is here presented a new model of Evolutionary Neural Gas\n(ENG) with any topological constraints, trained by probabilistic laws depending\non the local distortion errors and the network dimension. The network is\nconsidered as a population of nodes that coexist in an ecosystem sharing local\nand global resources. Those particular features allow the network to quickly\nadapt to the environment, according to its dimensions. The ENG model analysis\nshows that the net evolves as a scale-free graph, and justifies in a deeply\nphysical sense- the term gas here used.\n", "machine_text": "\n\nEvolutionary Neural Gas (ENG): A Model of Self Organizing Network from Input Categorization.\n\nWe present a new model of a self organizing network which is capable of learning an optimal categorization of its inputs. The proposed model, called Evolutionary Neural Gas (ENG), is an extension of the original Neural Gas model, which is capable of learning a general, continuously adjusted structure of clusters. The ENG model is based on the recently proposed Evolutionary Artificial Neural Networks (EANN), which are a generalization of multilayer feedforward ANNs to evolutionary systems. In the ENG, the structure of the network is not predefined but is formed during the learning process. The learning algorithm is based on the survival of the fittest principle, where the structures of the networks are evolved to perform the optimal categorization of the input data. We tested the ENG model on several benchmark datasets, including the standard Iris and Wine Quality datasets. The results show the superiority of the ENG model in the task of input categorization, in comparison to the original Neural Gas model and several other competitive models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: QCD Approach to B->D \\pi Decays and CP Violation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1575, "human_text": "  The branching ratios and CP violations of the $B\\to D\\pi$ decays, including\nboth the color-allowed and the color-suppressed modes, are investigated in\ndetail within QCD framework by considering all diagrams which lead to three\neffective currents of two quarks. An intrinsic mass scale as a dynamical gluon\nmass is introduced to treat the infrared divergence caused by the soft\ncollinear approximation in the endpoint regions, and the Cutkosky rule is\nadopted to deal with a physical-region singularity of the on mass-shell quark\npropagators. When the dynamical gluon mass $\\mu_g$ is regarded as a universal\nscale, it is extracted to be around $\\mu_g = 440$ MeV from one of the\nwell-measured $B\\to D\\pi$ decay modes. The resulting predictions for all\nbranching ratios are in agreement with the current experimental measurements.\nAs these decays have no penguin contributions, there are no direct $CP$\nasymmetries. Due to interference between the Cabibbo-suppressed and the\nCabibbo-favored amplitudes, mixing-induced CP violations are predicted in the\n$B\\to D^{\\pm}\\pi^{\\mp}$ decays to be consistent with the experimental data at\n1-$\\sigma$ level. More precise measurements will be helpful to extract weak\nangle $2\\beta+\\gamma$.\n", "machine_text": "\nWe present a QCD approach to B->D \\pi decays and CP violation. We find that the standard unitary theory is able to account for the data in a satisfactory way, after a suitable choice of the parameters. The approach is based on the use of the so-called \" idiot \" fermions, which represent the lightest quark and antiquark pairs. The idiot fermions are assumed to be almost massless and to have a small effective lifetime. Therefore they can only be involved in the decays of heavy quarks. The dynamics of the idiot fermions is described by a master equation, which includes the production and the decay of the idiot fermions as well as their possible interactions with other quarks and antiquarks. We show that the introduction of the idiot fermions allows to understand the experimental data on B->D \\pi and B->D \\pi \\ell^+ \\ell^- decays, in particular the excess of D \\pi \\ell^+ \\ell^- and B\\overline{B} pairs over the Standard Model expectations, without the need of introducing new quark or antiquark states, as it is usually done in the context of the Unitary Theory. In addition, we analyze the role of CP violation in B->D \\pi and B->D \\pi \\ell^+ \\ell^- decays. We show that the standard unitary theory is able to account for the observed CP violation in these decays, if the violating couplings are small and have a suitable form.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Adaptive Strategy for the Classification of G-Protein Coupled\n  Receptors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3453, "human_text": "  One of the major problems in computational biology is the inability of\nexisting classification models to incorporate expanding and new domain\nknowledge. This problem of static classification models is addressed in this\npaper by the introduction of incremental learning for problems in\nbioinformatics. Many machine learning tools have been applied to this problem\nusing static machine learning structures such as neural networks or support\nvector machines that are unable to accommodate new information into their\nexisting models. We utilize the fuzzy ARTMAP as an alternate machine learning\nsystem that has the ability of incrementally learning new data as it becomes\navailable. The fuzzy ARTMAP is found to be comparable to many of the widespread\nmachine learning systems. The use of an evolutionary strategy in the selection\nand combination of individual classifiers into an ensemble system, coupled with\nthe incremental learning ability of the fuzzy ARTMAP is proven to be suitable\nas a pattern classifier. The algorithm presented is tested using data from the\nG-Coupled Protein Receptors Database and shows good accuracy of 83%. The system\npresented is also generally applicable, and can be used in problems in genomics\nand proteomics.\n", "machine_text": "\nThe classification of G-protein coupled receptors (GPCRs) has been largely\nbased on the homology of their amino acid sequences. Because of the\nsequential and evolutionary nature of amino acid changes, however,\ndifferences in the amino acid sequences of GPCRs may not always reflect\nfunctional or pharmacological differences. We have recently proposed a\nmethod for the classification of GPCRs based on their conformational\nfeatures, which we refer to as the 'Conformation Space Method'. In this\npaper, we show that this method is not only 'robust' in that it\nclassifies GPCRs that have already been functionally characterized, but\nthat it can also be used to identify novel classes of GPCRs based on\ntheir conformation space properties. We demonstrate this by identifying\nand characterizing a new class of GPCRs ( referred to as the\n'Family C' GPCRs) whose members have characteristic three-dimensional\nfeatures that are not apparent from their primary amino acid sequence.\nThese 'Family C' GPCRs include the SREB (endothelial differentiation,\nretraction and migration) receptors, which we show to be receptors for\nthe Scarletasterol family of lysophospholipids. We also show that the\nFES (Fibroblast Endothelial sf-1) receptors, which include the\nendothelin A, B and C receptors, and the CENP (centromere-binding\nprotein) receptors, which include the Reelin receptor, both contain the\ncharacteristic 'Family C' conformation space signature. The 'Family C'\nGPCRs are a new class of GPCRs whose three-dimensional structures\ncombine features of both Class A (the secretin-like receptors) and\nClass B (the glutamate receptors). We show that the 'Family C'\nGPCRs are evolutionarily related to the CCK/gastrin-like receptors,\nwhich are the founding members of Class A, and that they constitute a\nnew subfamily within the Class A GPCRs. Our results also suggest that\nthe 'Family C' GPCRs may have evolved from a common ancestor with\nthe Class B GPCRs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Sedentary Survey of Extreme High Energy Peaked BL Lacs III. Results\n  from Optical Spectroscopy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1729, "human_text": "  The multi-frequency Sedentary Survey is a flux limited, statistically\nwell-defined sample of highly X-ray dominated BL Lacertae objects (HBLs) which\nincludes 150 sources. In this paper, the third of the series, we report the\nresults of a dedicated optical spectroscopy campaign that, together with\nresults from other independent optical follow up programs, led to the\nspectroscopic identification of all sources in the sample. We carried out a\nsystematic spectroscopic campaign for the observation of all unidentified\nobjects of the sample using the ESO 3.6m, the KPNO 4m, and the TNG optical\ntelescopes. We present new identifications and optical spectra for 76 sources,\n50 of which are new BL Lac objects, 18 are sources previously referred as BL\nLacs but for which no redshift information was available, and 8 are broad\nemission lines AGNs. We find that the multi-frequency selection technique used\nto build the survey is highly efficient (about 90%) in selecting BL Lacs\nobjects. We present positional and spectroscopic information for all confirmed\nBL Lac objects. Our data allowed us to determined 36 redshifts out of the 50\nnew BL Lacs and 5 new redshifts for the previously known objects. The redshift\ndistribution of the complete sample is presented and compared with that of\nother BL Lacs samples. For 26 sources without recognizable absorption features,\nwe calculated lower limits to the redshift using a method based on simulated\noptical spectra with different ratios between jet and galaxy emission. For a\nsubsample of 38 object with high-quality spectra, we find a correlation between\nthe optical spectral slope, the 1.4 GHz radio luminosity, and the Ca H&K break\nvalue, indicating that for powerful/beamed sources the optical light is\ndominated by the non-thermal emission from the jet.\n", "machine_text": "\nWe present the results of a unique optical spectroscopy survey of a well-studied sample of 42 extremely high energy (EHE) peaked BL Lacertae objects. Our sample consists of sources with extremely high optical variability, a large number of which have known X-ray binaries. We have obtained spectroscopy, with a resolution of $\\sim 1\\%$, of these sources in three different bands ($\\sim 4300$, $\\sim 5500$, and $\\sim 6300$ nm) with the aim of investigating the nature of the absorbing material in these sources, and the distribution of the absorbing material in the inner accretion disk. We find that in the cases where the absorbing material has a well-defined edge, a 1-dimensional (1D) model can well describe the data, thus allowing us to derive the optical depth of the absorbing material. In all cases the optical depth of the absorbing material is $\\sim 2-3$. We find that in the majority of our objects the absorbing material is located in a relatively narrow layer, at a few gravitational radii from the central engine. In one case, however, we find that the absorbing material is much more extended, and a 2-dimensional (2D) model is needed to describe the data. Our results are consistent with a model where the absorbing material is the result of a wind-driven accretion flow, and indicate that the inner accretion disk is only slightly truncated by the presence of the absorbing material. We discuss our results in the framework of a simple model, which allows us to explain the main features of our data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical BVI Imaging and HI Synthesis Observations of the Dwarf Irregular\n  Galaxy ESO 364-G 029. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.305, "human_text": "  As part of an effort to enlarge the number of well-studied Magellanic-type\ngalaxies, we obtained broadband optical imaging and neutral hydrogen radio\nsynthesis observations of the dwarf irregular galaxy ESO 364-G 029. The optical\nmorphology characteristically shows a bar-like main body with a one-sided\nspiral arm, an approximately exponential light distribution, and offset\nphotometric and kinematic centers. The HI distribution is mildly asymmetric\nand, although slightly offset from the photometric center, roughly follows the\noptical brightness distribution, extending to over 1.2 Holmberg radii (where\nmu_B = 26.5 mag/arcsec^2). In particular, the highest HI column densities\nclosely follow the bar, one-arm spiral, and a third optical extension. The\nrotation is solid-body in the inner parts but flattens outside of the optical\nextent. The total HI flux F_HI = 23.1 pm 1.2 Jy km/s, yielding a total HI mass\nM_HI= (6.4 pm 1.7) x 10^8 Msun (for a distance D = 10.8 pm 1.4 Mpc) and a total\nHI mass-to-blue-luminosity ratio M_HI/L_B = (0.96 pm 0.14) Msun / Lsun,B\n(distance independent). The HI data suggest a very complex small-scale HI\nstructure, with evidence of large shells and/or holes, but deeper observations\nare required for a detailed study. Follow-up observations are also desirable\nfor a proper comparison with the Large Magellanic Cloud, where despite an\noptical morphology very similar to ESO 364-G 029 the HI bears little\nresemblance to the optical.\n", "machine_text": "\nWe present optical BVI imaging and HI synthesis observations of the dwarf irregular galaxy ESO 364-G 029, which reveal a nearly face-on barred system with a well-defined bar and a half-symmetrically placed inner ring structure. We discuss the nature of the bar and ring and their possible interactions. The bar is the dominant feature in the stellar distribution and is responsible for the streaky HI distribution. The observed bar structure is consistent with a Keplerian profile, with a characteristic radius of 5.6 kpc and a mass of 4.4 kpc gas mass. The bar has a high surface brightness, and is therefore likely to be optically thick. We estimate the bar to be more than one thousand million years old. The observed bar is longer than the half-light radius, indicating that it is still accreting gas. The gas in the bar is slightly metal-poor compared to the gas in the outer parts of the disk, a signature of a successive accretion history. We show that the bar is responsible for the excess gas in the center of the galaxy. We estimate the current accretion rate to be at least 10^( \u2212 3). The gas in the ring is metal-poor compared to the gas in the bar, suggesting that the ring is an older feature. The mean metallicity of the gas in the bar is 12 +log(O/H) = 7.06, while the gas in the ring has a metallicity of 12 +log(O/H) = 6.55. We discuss several possible formation scenarios for the bar and ring, and conclude that the bar has been formed by a violent interaction between the disk and a gas cloud. The ring may be a fossil feature, or it could have been formed by the interaction of the bar with a second gas cloud. The large vertical scale of the ring (6 kpc) indicates that the dynamics in the center of the galaxy is not two-body dominated, but rather has a more complicated three-body problem. We discuss this in the context of recent results for disk galaxy dynamics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The subpulse modulation properties of pulsars at 92 cm and the frequency\n  dependence of subpulse modulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3572, "human_text": "  A large sample of pulsars has been observed to study their subpulse\nmodulation at an observing wavelength (when achievable) of both 21 and 92 cm\nusing the Westerbork Synthesis Radio Telescope. In this paper we present the\n92-cm data and a comparison is made with the already published 21-cm results.\nWe analysed 191 pulsars at 92 cm using fluctuation spectra. The sample of\npulsars is as unbiased as possible towards any particular pulsar\ncharacteristics. For 15 pulsars drifting subpulses are discovered for the first\ntime and 26 of the new drifters found in the 21-cm data are confirmed. We\ndiscovered nulling for 8 sources and 8 pulsars are found to intermittently emit\nsingle pulses that have pulse energies similar to giant pulses. It is estimated\nthat at least half of the total population of pulsars have drifting subpulses\nwhen observations with a high enough signal-to-noise ratio would be available.\nIt could well be that the drifting subpulse mechanism is an intrinsic property\nof the emission mechanism itself, although for some pulsars it is difficult or\nimpossible to detect. Drifting subpulses are in general found at both\nfrequencies, although the chance of detecting drifting subpulses is possibly\nslightly higher at 92 cm. It appears that the youngest pulsars have the most\ndisordered subpulses and the subpulses become more and more organized into\ndrifting subpulses as the pulsar ages. The correlations with the modulation\nindices are argued to be consistent with the picture in which the radio\nemission can be divided in a drifting subpulse signal plus a quasi-steady\nsignal which becomes, on average, stronger at high observing frequencies. The\nmeasured values of P3 at the two frequencies are highly correlated, but there\nis no evidence for a correlation with other pulsar parameters.\n", "machine_text": "\n\nWe present new observations of the subpulse modulation properties of pulsars at 92 cm and the frequency dependence of subpulse modulation. We use the fast Fourier transform technique to extract the modulation spectrum from the pulse profiles of 13 pulsars observed at a frequency of 92 cm. The observed modulation is decomposed into amplitude and phase modulation, and the resulting power spectra are compared to the power spectra expected for a range of model modulation depths. The best fit to the data is obtained with a model in which the modulation depth is constant and equal to 0.12. This result is consistent with previous observations at 350 MHz and demonstrates that pulsars can support a large amount of modulation at radio frequencies. We also present observations of the frequency dependence of subpulse modulation. These observations show that the modulation depth is proportional to the frequency. This result is consistent with the theory of frequency-dependent modulation and indicates that the electrical activity in the accretion disk is independent of the orbital period of the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Origin of which-way information and generalization of the Born rule. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2877, "human_text": "  The possibility to recover the which-way information, for example in the two\nslit experiment, is based on a natural but implicit assumption about the\nposition of a particle {\\it before} a position measurement is performed on it.\nThis assumption cannot be deduced from the standard postulates of quantum\nmechanics. In the present paper this assumption is made explicit and formally\npostulated as a new rule, the {\\it quantum typicality rule}. This rule\ncorrelates the positions of the particles at two different times, thus defining\ntheir trajectories. Unexpectedly, this rule is also equivalent to the Born rule\nwith regard to the explanation of the results of statistical experiments. For\nthis reason it can be considered a generalization of the Born rule. The\nexistence of the quantum typicality rule strongly suggests the possibility of a\nnew trajectory-based formulation of quantum mechanics. According to this new\nformulation, a closed quantum system is represented as a {\\it quantum process},\nwhich corresponds to a canonical stochastic process in which the probability\nmeasure is replaced by the wave function and the usual frequentist\ninterpretation of probability is replaced by the quantum typicality rule.\n", "machine_text": "\nWe propose a new theory of the origin of conscious perception of oriented information, such as knowing \"which way is up.\" We show that such perception is not derived from the statistically optimal computation of orientation selectivity in downstream neurons, as has been widely assumed. Rather, it arises from an explicit, symmetric dependence on the neural response tobidirectional stimulation in the feedforward pathway. This makes conscious perception of orientation highly resilient to fluctuations in the statistics of the input, and endows it with a high degree of generalization ability. We further show that such a symmetric dependence on bidirectional stimulation cannot be captured by asymmetrically tuned neurons, and can only be accounted for by neurons with symmetric responses to bilateral stimulation, or by a combination of symmetric and asymmetric responses in a specific manner. We analyze a number of candidate neural mechanisms that may give rise to such symmetric responses, and propose a particular mechanism which is consistent with a large body of experimental evidence. We show that this mechanism is capable of producing orientation perception that is resilient to input noise and has a high degree of generalization ability, in a manner consistent with the Born rule. We propose that this mechanism plays a role in a number of perceptual tasks that require conscious detection of oriented information, including orientation discrimination, and explain why orientation perception is generally so resilient to input noise and has such a high degree of generalization ability.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Timing and Lensing of the Colliding Bullet Clusters: barely enough time\n  and gravity to accelerate the bullet. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0094, "human_text": "  We present semi-analytical constraint on the amount of dark matter in the\nmerging bullet galaxy cluster using the classical Local Group timing arguments.\nWe consider particle orbits in potential models which fit the lensing data.\n{\\it Marginally consistent} CDM models in Newtonian gravity are found with a\ntotal mass M_{CDM} = 1 x 10^{15}Msun of Cold DM: the bullet subhalo can move\nwith V_{DM}=3000km/s, and the \"bullet\" X-ray gas can move with\nV_{gas}=4200km/s. These are nearly the {\\it maximum speeds} that are\naccelerable by the gravity of two truncated CDM halos in a Hubble time even\nwithout the ram pressure. Consistency breaks down if one adopts higher end of\nthe error bars for the bullet gas speed (5000-5400km/s), and the bullet gas\nwould not be bound by the sub-cluster halo for the Hubble time. Models with\nV_{DM}~ 4500km/s ~ V_{gas} would invoke unrealistic large amount M_{CDM}=7x\n10^{15}Msun of CDM for a cluster containing only ~ 10^{14}Msun of gas. Our\nresults are generalisable beyond General Relativity, e.g., a speed of\n$4500\\kms$ is easily obtained in the relativistic MONDian lensing model of\nAngus et al. (2007). However, MONDian model with little hot dark matter\n$M_{HDM} \\le 0.6\\times 10^{15}\\msun$ and CDM model with a small halo mass $\\le\n1\\times 10^{15}\\msun$ are barely consistent with lensing and velocity data.\n", "machine_text": "\nWe present an analysis of the dynamics of the accretion disc around the black hole in the LMXB source 1E0658-56. We find that the disc is likely to have been formed by the accretion of the hydrogen gas from a large rotating infalling object, such as a giant planet, that strayed too close to the black hole. The dynamics of the system is consistent with a gravitational slingshot of the bullet cluster, only barely enough time and gravity to accelerate the bullet. The Event Horizon Telescope (EHT) observations of the black hole in 1E0658-56, in combination with the 2015 theory by1966(); 1997(); 2002() that the largest objects in galactic nuclei are the remnants of giant planets that formed around the early galactic nuclei and were later ripped off by the central black holes, suggest that the process of planet formation in the galactic nuclei is a violent one. We propose that the accretion discs around black holes in galactic nuclei are formed by the same process as the discs around young stars, by the accretion of gas from the infalling object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Antiproliferative MCR peptides block physical interaction of insulin\n  with retinoblastoma protein (RB) in human lung cancer cells. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1991, "human_text": "  Fifteen years ago, a structural analysis of the hormone insulin and the\nretinoblastoma tumor suppressor protein (RB) revealed that they may physically\ninteract with one another. Subsequently, an RB peptide corresponding to the\nproposed RB binding site for insulin was found to recognize full-length insulin\nin vitro. As part of efforts aimed at developing this RB peptide into an\nanti-cancer drug, this molecule was chemically coupled to a cellular\ninternalization signal and termed \"MCR peptide\". Meanwhile, several such MCR\npeptide variants have been demonstrated to restrain the proliferation of\ndifferent human cancer cells in vitro and in vivo. Moreover, one of the MCR\npeptides coined MCR-10 was shown to be capable of interfering with the complex\nformation between insulin and RB in HepG2 human hepatoma cells, as monitored by\nimmunofluorescence. This latter result indicating an in vivo association\nbetween insulin and RB was confirmed by a follow-up study combining the methods\nof co-immunoprecipitation and immunoblotting. Here, we provide evidence for the\nexistence of the insulin-RB complex in A549 human non-small cell lung cancer\ncells. Specifically, we demonstrate this heterodimer by means of a magnetic\nbeads-based immunoprecipitation approach and equally show that this dimer can\nbe disrupted by MCR-4 or MCR-10 each of which is known to possess\nantiproliferative properties, yet to a much lesser extent by a control peptide.\nThus, this investigation has yielded another important proof for the occurrence\nof the insulin-RB dimer and, furthermore, its validity as a target for\nantineoplastic MCR peptides.\n", "machine_text": "\nMotivation: The retinoblastoma (RB) protein is a tumor suppressor that plays a central role in cell cycle regulation and in the etiology of several cancers, including lung cancer, where it is frequently lost by RB mutation or by epigenetic inactivation. In our previous work, we showed that a small synthetic peptide corresponding to the C-terminal part of RB (MCR) has antiproliferative and proapoptotic effects in several cancer cells, including lung cancer cells, and that these effects are mediated by inhibition of the physical interaction of MCR with the protein insulin-like growth factor 1 receptor (IR).\nKey ideas and methodology: In the present work, we sought to determine the structural basis for the interaction of MCR with IR and to study the effects of this interaction on cell cycle regulation. We have shown that MCR and IR form a complex in vitro, and that this complex is able to activate the cell cycle inhibitor p21. We have also shown that MCR peptides are able to block the interaction of IR with RB in vivo and to inhibit cell cycle progression in lung cancer cells.\nResults obtained: Our results suggest that the MCR-IR interaction may be a potential therapeutic target in lung cancer and other cancers where RB is mutated or silenced.\nProblem work attempts to solve: The aim of our work was to study the structural basis for the interaction of MCR with IR and to study the effects of this interaction on cell cycle regulation.\nAny practical or theoretical applications from your findings or implications for future research: Our results suggest that the MCR-IR interaction may be a potential therapeutic target in lung cancer and other cancers where RB is mutated or silenced.\n Implications for future research: Our results suggest that the MCR-IR interaction may be a potential therapeutic target in lung cancer and other cancers where RB is mutated or silenced.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galaxy evolution in the infra-red: comparison of a hierarchical galaxy\n  formation model with SPITZER data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1562, "human_text": "  We present predictions for the evolution of the galaxy luminosity function,\nnumber counts and redshift distributions in the IR based on the Lambda-CDM\ncosmological model. We use the combined GALFORM semi-analytical galaxy\nformation model and GRASIL spectrophotometric code to compute galaxy SEDs\nincluding the reprocessing of radiation by dust. The model, which is the same\nas that in Baugh et al (2005), assumes two different IMFs: a normal solar\nneighbourhood IMF for quiescent star formation in disks, and a very top-heavy\nIMF in starbursts triggered by galaxy mergers. We have shown previously that\nthe top-heavy IMF seems to be necessary to explain the number counts of faint\nsub-mm galaxies. We compare the model with observational data from the SPITZER\nSpace Telescope, with the model parameters fixed at values chosen before\nSPITZER data became available. We find that the model matches the observed\nevolution in the IR remarkably well over the whole range of wavelengths probed\nby SPITZER. In particular, the SPITZER data show that there is strong evolution\nin the mid-IR galaxy luminosity function over the redshift range z ~ 0-2, and\nthis is reproduced by our model without requiring any adjustment of parameters.\nOn the other hand, a model with a normal IMF in starbursts predicts far too\nlittle evolution in the mid-IR luminosity function, and is therefore excluded.\n", "machine_text": "\n\nWe present a comparison of the evolution of galaxies in a hierarchical galaxy formation model with the observed distribution of galaxies in the infra-red, as obtained from the SPITZER Deep Extragalactic Survey. We show that the model can reproduce the main properties of the SPITZER infra-red galaxy distribution, in terms of the number density of galaxies, their sizes, and their distribution in space and in time. We find that the main difference between the model and the observations is that the model predicts more galaxies at large redshifts and fewer at small redshifts than are observed. We discuss possible physical reasons for this difference, and we show that relaxing the assumption of perfect galaxy formation in the model can produce a distribution of galaxies more in agreement with observations. Our results suggest that the distribution of galaxies in the SPITZER infra-red survey is consistent with a simple hierarchical galaxy formation model, with some possible additional physical mechanisms such as the inefficient conversion of gas into galaxies, the feedback from massive galaxies, and the presence of large-scale structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What is the order of 2D polymer escape transition?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1857, "human_text": "  An end-grafted flexible polymer chain in 3d space between two pistons\nundergoes an abrupt transition from a confined coil to a flower-like\nconformation when the number of monomers in the chain, N, reaches a critical\nvalue. In 2d geometry, excluded volume interactions between monomers of a chain\nconfined inside a strip of finite length 2L transform the coil conformation\ninto a linear string of blobs. However, the blob picture raises questions on\nthe nature of this escape transition. To check the theoretical predictions\nbased on the blob picture we study 2d single polymer chains with excluded\nvolume interactions and with one end grafted in the middle of a strip of length\n  2L and width H by simulating self-avoiding walks on a square lattice with the\npruned-enriched-Rosenbluth method (PERM). We estimate the free energy, the\nend-to-end distance, the number of imprisoned monomers, the order parameter,\nand its distribution. It is shown that in the thermodynamic limit of large N\nand L but finite L/N, there is a small but finite jump in several average\ncharacteristics, including the order parameter. We also present a theoretical\ndescription based on the Landau free energy approach, which is in good\nagreement with the simulation results. Both simulation results and the\nanalytical theory indicate that the 2d escape transition is a weak first-order\nphase transition.\n", "machine_text": "\nWe study the order of the two-dimensional (2D) polymer escape transition as a function of the system size and the solvent quality using Monte Carlo simulations. We find a strong dependence of the transition order on the system size and the solvent quality. In particular, we observe a critical system size for the transition, above which the order is absolutely first order, and below which the order is second order. We also find a strong dependence of the order on the solvent quality, where the order is generally first order in a good solvent and second order in a bad solvent. In addition, we study the polymer conformation and the statistical properties of the system as a function of the transition order. We find that the polymers adopt a more compact conformation and the system becomes more ordered in a first-order transition, while the polymers adopt a more extended conformation and the system becomes less ordered in a second-order transition. Our results suggest that the 2D polymer escape transition is generally first order, but can be second order in a small system or in a bad solvent.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: MiniBooNE Results and Neutrino Schemes with 2 sterile Neutrinos:\n  Possible Mass Orderings and Observables related to Neutrino Masses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1462, "human_text": "  The MiniBooNE and LSND experiments are compatible with each other when two\nsterile neutrinos are added to the three active ones. In this case there are\neight possible mass orderings. In two of them both sterile neutrinos are\nheavier than the three active ones. In the next two scenarios both sterile\nneutrinos are lighter than the three active ones. The remaining four scenarios\nhave one sterile neutrino heavier and another lighter than the three active\nones. We analyze all scenarios with respect to their predictions for\nmass-related observables. These are the sum of neutrino masses as constrained\nby cosmological observations, the kinematic mass parameter as measurable in the\nKATRIN experiment, and the effective mass governing neutrinoless double beta\ndecay. It is investigated how these non-oscillation probes can distinguish\nbetween the eight scenarios. Six of the eight possible mass orderings predict\npositive signals in the KATRIN and future neutrinoless double beta decay\nexperiments. We also remark on scenarios with three sterile neutrinos. In\naddition we make some comments on the possibility of using decays of high\nenergy astrophysical neutrinos to discriminate between the mass orderings in\npresence of two sterile neutrinos.\n", "machine_text": "\nWe present results of a detailed study of the allowed mass orderings of a simple two-neutrino scenario, the so-called \"lightest- sterile-neutrino- is-a- Dirac-neutrino\" model. We consider all physically allowed mass orderings and use the so-called \" Designer Neutrino\" scheme to extract the required mass matrix elements from the conditions of the standard model. In this way we can derive the masses of the three neutrinos in terms of the fundamental Standard Model parameters and the neutrino masses can be related to the masses of the other elementary particles. In the mass matrix we find the small element (with a value of about 0.07 eV) representing the Dirac neutrino mass. We find that the mass of the lightest sterile neutrino is a multiple of the Dirac neutrino mass, with the value depending on the details of the mixing and the mass ordering. The Dirac neutrino and the sterile neutrinos can be assigned masses within the framework of the standard model without the need to introduce new parameters. We discuss the implications of this scenario for neutrino mass detection and for the question of the mass ordering.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the generalization of the Costas property in the continuum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1379, "human_text": "  We extend the definition of the Costas property to functions in the\ncontinuum, namely on intervals of the reals or the rationals, and argue that\nsuch functions can be used in the same applications as discrete Costas arrays.\nWe construct Costas bijections in the real continuum within the class of\npiecewise continuously differentiable functions, but our attempts to construct\na fractal-like Costas bijection there are successful only under slight but\nnecessary deviations from the usual arithmetic laws. Furthermore, we are able,\ncontingent on the validity of Artin's conjecture, to set up a limiting process\naccording to which sequences of Welch Costas arrays converge to smooth Costas\nbijections over the reals. The situation over the rationals is different:\nthere, we propose an algorithm of great generality and flexibility for the\nconstruction of a Costas fractal bijection. Its success, though, relies heavily\non the enumerability of the rationals, and therefore it cannot be generalized\nover the reals in an obvious way.\n", "machine_text": "\nWe show that a certain generalization of the Costas property holds in the continuum. Let $\\mathfrak{g}$ be a semisimple Lie group with a Levi decomposition $\\mathfrak{g}=\\mathfrak{r}^\\mathfrak{t}\\mathfrak{u}$, where $\\mathfrak{r}$ and $\\mathfrak{t}$ are certain connected and simply connected subspaces of $\\mathfrak{g}$ and $\\mathfrak{u}$ is the real vector space of all upper triangular matrices. Let $\\mathfrak{h}$ be a Cartan subspace of $\\mathfrak{g}$ and $\\mathfrak{f}=\\mathfrak{g}_\\mathfrak{h}^\\mathfrak{h}$ be the adjoint representation of $\\mathfrak{g}$. Let $\\mathfrak{c}$ be a semisimple subspace of $\\mathfrak{f}$. We show that, if $\\pi_\\mathfrak{g}: \\mathfrak{g} \\to \\mathfrak{c}$ is the irreducible representation of $\\mathfrak{g}$ in $\\mathfrak{c}$, then there exists a non-trivial character $\\chi_\\mathfrak{g}:\\mathfrak{g}$ such that $\\chi_\\mathfrak{g}\\pi_\\mathfrak{g}=\\epsilon_\\mathfrak{g}$, where $\\epsilon_\\mathfrak{g}$ is the character of $\\mathfrak{c}$. As an application, we give a description of the root system of $\\mathfrak{g}$ in terms of the structure of $\\mathfrak{c}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray Timing of PSR J1852+0040 in Kesteven 79: Evidence of Neutron Stars\n  Weakly Magnetized at Birth. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0978, "human_text": "  The 105-ms X-ray pulsar J1852+0040 is the central compact object (CCO) in SNR\nKes 79. We report a sensitive upper limit on its radio flux density of 12 uJy\nat 2 GHz using the NRAO GBT. Timing using XMM and Chandra over a 2.4 yr span\nreveals no significant change in its spin period. The 2 sigma upper limit on\nthe period derivative leads, in the dipole spin-down formalism, to an energy\nloss rate E-dot < 7e33 ergs/s, surface magnetic field strength B_p < 1.5e11 G,\nand characteristic age tau_c = P/2P-dot > 8 Myr. This tau_c exceeds the age of\nthe SNR by 3 orders of magnitude, implying that the pulsar was born spinning at\nits current period. However, the X-ray luminosity of PSR J1852+0040, L(bol) ~\n3e33(d/7.1 kpc)^2 ergs/s is a large fraction of E-dot, which challenges the\nrotation-powered assumption. Instead, its high blackbody temperature,\n0.46+/-0.04 keV, small blackbody radius ~ 0.8 km, and large pulsed fraction, ~\n80%, may be evidence of accretion onto a polar cap, possibly from a fallback\ndisk made of supernova debris. If B_p < 1e10 G, an accretion disk can penetrate\nthe light cylinder and interact with the magnetosphere while resulting torques\non the neutron star remain within the observed limits. A weak B-field is also\ninferred in another CCO, the 424-ms pulsar 1E 1207.4-5209, from its steady spin\nand soft X-ray absorption lines. We propose this origin of radio-quiet CCOs:\nthe B-field, derived from a turbulent dynamo, is weaker if the NS is formed\nspinning slowly, which enables it to accrete SN debris. Accretion excludes\nneutron stars born with both B_p < 1e11 G and P > 0.1 s from radio pulsar\nsurveys, where B_p < 1e11 G is not encountered except among very old (tau_c >\n40 Myr) or recycled pulsars. Finally, such a CCO, if born in SN 1987A, could\nexplain the non-detection of a pulsar there.\n", "machine_text": "\nWe present observations of the low-mass X-ray binary PSR J1852+0040 in the Galactic globular cluster Kesteven 79. The system consists of a magnetized, weakly- magnetized-at-birth neutron star with a relatively long spin-down lifetime, accreting from a Donor, and an accretion disc around the Donor. We observed the system in quiescence, and found that the accretion disc is not actively accreting, and that the system is in a relatively long spin-down epoch. Our observations are consistent with the disc being in a quiescent state, possibly due to a relatively high mass-transfer rate during accretion, compared to the accretion rate during the short spin-up epochs. We conclude that a large fraction of low-mass X-ray binaries in globular clusters are in this type of quiescent state, and that this could provide a natural explanation for the lack of in-between states (accreting but with a low accretion rate) observed in low-mass X-ray binaries in our Galaxy. We find that the accretion disc in PSR J1852+0040 is geometrically thin, with a thickness of $\\sim 10$ times the accretion disc radius, and with a mass distribution that is consistent with a uniform density disc. We discuss the implications of this for the stability of the disc, and find that it is consistent with a relatively long spin-down lifetime of the system. We find that the observed spin-down rate is consistent with the system having been weakly magnetized at birth, and having experienced relatively large torque from accretion in the past. We discuss the implications of this for the low-mass X-ray binary initial mass function, and for the accretion history of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman\n  Break Galaxy at z=3.07. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1721, "human_text": "  We report the detection of CO(3-2) emission from a bright, gravitationally\nlensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07\nusing the Plateau de Bure Interferometer. This is only the second detection of\nmolecular gas emission from an LBG and yields an intrinsic molecular gas mass\nof (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG\nindicates that it comprises two components separated by ~2 kpc. The CO emission\nis unresolved, and appears to be centered on the intrinsically fainter (and\nalso less highly magnified) of the two UV components. The width of the CO line\nindicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc.\nEmploying mid-infrared observations from Spitzer we derive a stellar mass of\n~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the\nmolecular gas will be consumed in ~40 Myr. The gas fractions, star-formation\nefficiencies and line widths suggests that LBGJ213512 is a high-redshift,\ngas-rich analog of a local luminous infrared galaxy. This galaxy has a similar\ngas-to-dynamical mass fraction as observed in the submillimeter-selected\npopulation, although the gas surface density and star-formation efficiency is a\nfactor of 3x less, suggesting less vigorous activity. We discuss the\nuncertainties in our conclusions arising from adopting a CO-to-H2 conversion\nfactor appropriate for either the Milky Way or local luminous infrared\ngalaxies. These observations demonstrate that current facilities, when aided by\nfortuitous gravitational magnification, can study 'ordinary' galaxies at\nhigh-redshift and so act as pathfinders for ALMA.\n", "machine_text": "\n\nWe present a detailed study of a highly magnified Lyman break galaxy (LBM) at z=3.07 in order to investigate the role of the molecular line in galaxy formation and evolution. We find that the far ultraviolet (FUV) and near-infrared (NIR) photometry, combined with the dust emission, are able to constrain the relative gas and star formation rates (GIFs) in these galaxies. We find that LBMs at high magnifications are more likely to be gas-rich and have higher GIFs than LBMs at low magnifications. This is consistent with the hypothesis that LBMs at high magnifications are more evolved galaxies that have formed stars more efficiently. We show that the relative strength of the molecular line compared to the dust and FUV/NIR continuum is correlated with the evolution of the galaxy, with more evolved galaxies having lower relative molecular line strengths. We also present an analysis of the morphologies of LBMs in order to further probe the evolution of these galaxies. We find that LBMs at high magnifications are more likely to have complex morphologies, while LBMs at low magnifications are more likely to have simple morphologies. This is consistent with the hypothesis that LBMs at high magnifications are more evolved galaxies that have formed stars and are undergoing further mergers and interactions, producing more complex and irregular morphologies. Our results suggest that the molecular line can be used as a tracer of galaxy evolution and star formation in LBMs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Room temperature spin polarized magnetic semiconductor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2993, "human_text": "  Alternating layers of granular Iron (Fe) and Titanium dioxide\n(TiO$_{2-\\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$)\nsubstrates in low oxygen chamber pressure using a controlled pulsed laser\nablation deposition technique. The total thickness of the film was about 200\nnm. The films show ferromagnetic behavior for temperatures ranging from 4 to\n$400 ^oK$. The layered film structure was characterized as p-type magnetic\nsemiconductor at $300 ^oK$ with a carrier density of the order of $10^{20}\n/cm^3$. The undoped pure TiO$_{2-\\delta}$ film was characterized as an n-type\nmagnetic semiconductor. The hole carriers were excited at the interface between\nthe granular Fe and TiO$_{2-\\delta}$ layers similar to holes excited in the\nmetal/n-type semiconductor interface commonly observed in\nMetal-Oxide-Semiconductor (MOS) devices. The holes at the interface were\npolarized in an applied magnetic field raising the possibility that these\ngranular MOS structures can be utilized for practical spintronic device\napplications.\n", "machine_text": "\nWe have investigated the spin-dependent transport in a ferromagnetic (FM) semiconductor (Bi0.5Fe0.5)0.9Te0.1) with a room temperature (RT) spin-orbital-liquid (SOL) order, in an effort to understand the mechanism of the spin-mediated transport in such materials, and to explore its potential for spintronic applications. We have found that the spin-diffusion length (L) in this material is much shorter than the previously reported L values in non-magnetic semiconductors, which is consistent with the notion that the spin-mediated transport in magnetic semiconductors is inherently different from the ordinary charge-mediated transport. We have also found that the room temperature L value in this material is large enough (6.5 \u03bcm) to be potentially useful for spintronic applications. We have further found that the low temperature (T< 100 K) behavior of the spin-induced magnetoresistance (MR) is consistent with the standard Boltzmann transport model, but the RT behavior of the MR is different from the behavior predicted by this model. We have explained this discrepancy by a model in which the RT MR is dominated by the re-population of the mobile carriers at the Fermi level after their spin-dependent diffusion. We have also found that the MR is sensitive to an external magnetic field even in the absence of any spin-polarization of the injected carriers, which is consistent with the notion that the MR in magnetic semiconductors is due to the spin-dependent scattering of the carriers by the internal spin-ordsal moment, and is therefore different from the MR in magnetic metals, in which the MR is due to the spin-dependent scattering of the spin-polarized carriers by the internal spin-orbit moment. Finally, we have found that the temperature dependence of the MR in this material is consistent with the model in which the RT MR is dominated by the re-population of the mobile carriers at the Fermi level after their spin-dependent diffusion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Kinematic Evolution of Strong MgII Absorbers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0515, "human_text": "  We consider the evolution of strong (W_r(2796) > 0.3A) MgII absorbers, most\nof which are closely related to luminous galaxies. Using 20 high resolution\nquasar spectra from the VLT/UVES public archive, we examine 33 strong MgII\nabsorbers in the redshift range 0.3 < z < 2.5. We compare and supplement this\nsample with 23 strong MgII absorbers at 0.4 < z < 1.4 observed previously with\nHIRES/Keck. We find that neither equivalent width nor kinematic spread (the\noptical depth weighted second moment of velocity) of MgII2796 evolve. However,\nthe kinematic spread is sensitive to the highest velocity component, and\ntherefore not as sensitive to additional weak components at intermediate\nvelocities relative to the profile center. The fraction of absorbing pixels\nwithin the full velocity range of the system does show a trend of decreasing\nwith decreasing redshift. Most high redshift systems (14/20) exhibit absorption\nover the entire system velocity range, which differs from the result for low\nredshift systems (18/36) at the 95% level. This leads to a smaller number of\nseparate subsystems for high redshift systems because weak absorping components\ntend to connect the stronger regions of absorption. We hypothesize that low\nredshift MgII profiles are more likely to represent well formed galaxies, many\nof which have kinematics consistent with a disk/halo structure. High redshift\nMgII profiles are more likely to show evidence of complex protogalactic\nstructures, with multiple accretion or outflow events. Although these results\nare derived from measurements of gas kinematics, they are consistent with\nhierarchical galaxy formation evidenced by deep galaxy surveys.\n", "machine_text": "\n\nWe present a study of the kinematic structure of strong MgII absorbers in the solar photosphere. We use a combination of photospheric magnetic field measurements and spectroscopy of a small-area weakly-magnetized region in the photosphere to show that the kinematic structure of strong MgII absorbers is due to the superposition of three different populations of photospheric granules: (i) fast-moving granules at high latitudes, (ii) slow-moving granules at low latitudes, and (iii) a population of granules with intermediate speeds at all latitudes. We find that each of these three populations has a different velocity structure function (VSF), with the fast-moving granules having a VSF that is characterized by a cut-off at low frequencies and a slow-moving population that has a flat VSF. We show that these two populations can be fit well by power law distributions with different exponents. In contrast, the intermediate-speed population has a VSF that is well described by a single power law with a frequency-independent exponent. We argue that the observed VSFs are consistent with the different populations of granules being subject to different magnetic field strengths, with the fast-moving granules at high latitudes being subject to stronger magnetic fields and the slow-moving granules at low latitudes being subject to weaker magnetic fields. We show that the VSF for the intermediate-speed population can be fit well by a power law with an exponent of \u22121.7, suggesting that this population is subject to intermediate magnetic field strengths. We discuss various physical mechanisms that could give rise to these different populations of granules and find that the most promising mechanism is that the different populations correspond to different temperature structures, with the fast-moving granules at high latitudes being the coolest and the slow-moving granules at low latitudes being the warmest.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The generator coordinate method in time-dependent density-functional\n  theory: memory made simple. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2855, "human_text": "  The generator coordinate (GC) method is a variational approach to the quantum\nmany-body problem in which interacting many-body wave functions are constructed\nas superpositions of (generally nonorthogonal) eigenstates of auxiliary\nHamiltonians containing a deformation parameter. This paper presents a\ntime-dependent extension of the GC method as a new approach to improve existing\napproximations of the exchange-correlation (XC) potential in time-dependent\ndensity-functional theory (TDDFT). The time-dependent GC method is shown to be\na conceptually and computationally simple tool to build memory effects into any\nexisting adiabatic XC potential. As an illustration, the method is applied to\ndriven parametric oscillations of two interacting electrons in a harmonic\npotential (Hooke's atom). It is demonstrated that a proper choice of\ntime-dependent generator coordinates in conjunction with the adiabatic\nlocal-density approximation reproduces the exact linear and nonlinear\ntwo-electron dynamics quite accurately, including features associated with\ndouble excitations that cannot be captured by TDDFT in the adiabatic\napproximation.\n", "machine_text": "\nThe generator coordinate method in time-dependent density-functional theory: memory made simple\n\nWe present a simple method to evaluate the exact eigenvalues and eigenvectors of the spatial Laplace operator in a time-dependent density-functional theory (TDDFT) calculation. The method, which we dub the generator coordinate method, is based on a formal similarity transformation of the time-dependent Kohn-Rostoker Green function (TDKGF) which yields a matrix representation of the Laplace operator in the basis of the coherent states of the TDKGF. The use of the generator coordinate method allows one to solve the eigenvalue and eigenvector problems in TDDFT calculations exactly, without the need for the introduction of any additional memory variables. We show that the method can be applied to both time-independent and time-dependent systems, and we present a thorough analysis of its application to a class of time-dependent systems for which the solution of the eigenvalue and eigenvector problems is particularly difficult.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Inhomogeneities in the Universe and the Fitting Problem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1029, "human_text": "  Observational cosmology provides us with a large number of high precision\ndata which are used to derive models trying to reproduce ``on the mean'' our\nobservable patch of the Universe. Most of these attempts are achieved in the\nframework of a Friedmann-Lema\\^itre cosmology where large scale homogeneity is\nassumed. However, we know, from the observation of structures at increasing\nscales, that these models are only approximations of a smoothed or averaged\ninhomogeneous underlying patern. Anyhow, when modelling the Universe, the usual\nmethod is to use continuous functions representing the kinematical scalars of\nthe velocity field, implicitly assuming that they represent volume averages of\nthe corresponding fine-scale inhomogeneous quantities, then put them into the\nEinstein equations which are solved to give the model and its dependance upon a\nnumber of parameters arbitrarily defined. In General Relativity, such a method\nis very much involved since the equations which determine the metric tensor and\nthe quantities calculated from it are highly nonlinear. The question raised by\nthe method consisting of determining the parameters of an a priori assumed FLRW\nmodel from observational data is the ``fitting problem'' brought to general\nattention by Ellis and Stoeger in the 80's. This problem has recently\nexperienced a reniewed attention due to the amount of available data and the\nincrease of the minimum scale at which homogeneity can be assumed. We propose a\ndiscussion of this issue in the light of the latest developments of\nobservational and theoretical cosmology.\n", "machine_text": "\nWe present an analysis of the impact of inhomogeneities in the Universe on the fitting problem. We show that the probability distribution of the measurements can be non-Gaussian even if the true distribution is Gaussian, provided that the measurements are sufficiently inhomogeneously spaced in space. We analyze this effect for different choices of the probability distribution of the noise, and show that in the case of a uniform noise distribution the effect is most severe, leading to a significant degradation of the statistical significance. On the other hand, if the noise distribution is peaked on small scales, the impact of the inhomogeneities is negligible. We analyze the optimal distribution of the measurements for a given noise distribution, and show that for a Gaussian noise distribution the optimal distribution is a highly non-uniform one, while for a Laplace noise distribution the optimal distribution is very uniform. We finally propose a simple method to reduce the impact of the inhomogeneities, which consists in performing a spatial binning of the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Thurston norm via Normal Surfaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0673, "human_text": "  Given a triangulation of a closed, oriented, irreducible, atoroidal\n3-manifold every oriented, incompressible surface may be isotoped into normal\nposition relative to the triangulation. Such a normal oriented surface is then\nencoded by non-negative integer weights, 14 for each 3-simplex, that describe\nhow many copies of each oriented normal disc type there are. The Euler\ncharacteristic and homology class are both linear functions of the weights.\nThere is a convex polytope in the space of weights, defined by linear equations\ngiven by the combinatorics of the triangulation, whose image under the homology\nmap is the unit ball, B, of the Thurston norm.\n  Applications of this approach include (1) an algorithm to compute B and hence\nthe Thurston norm of any homology class, (2) an explicit exponential bound on\nthe number of vertices of B in terms of the number of simplices in the\ntriangulation, (3) an algorithm to determine the fibred faces of B and hence an\nalgorithm to decide whether a 3-manifold fibres over the circle.\n", "machine_text": "\n\nWe introduce a family of norms on the space of continuous paths on a simple algebraic variety that generalizes both the Lebesgue and Thurston norms. We show that these norms are equivalent to asking that a function be the restriction to a normal surface of a certain function on the Variety. As an application, we give an example of a function that is continuous on a non- normalize algebraic surface but is not the restriction of a continuous function on the variety.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetic structure of Sm2IrIn8. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.148, "human_text": "  The magnetic structure of the intermetallic antiferromagnet Sm2IrIn8 was\ndetermined using x-ray resonant magnetic scattering (XRMS). Below TN = 14.2,\nSm2IrIn8 has a commensurate antiferromagnetic structure with a propagation\nvector (1/2,0,0). The Sm magnetic moments lie in the ab plane and are rotated\nroughly 18 degrees away from the a axis. The magnetic structure of this\ncompound was obtained by measuring the strong dipolar resonant peak whose\nenhancement was of over two orders of magnitude at the L2 edge. At the L3 edge\nboth quadrupolar and dipolar features were observed in the energy line shape.\nThe magnetic structure and properties of Sm2IrIn8 are found to be consistent\nwith the general trend already seen for the Nd-, Tb- and the Ce-based compounds\nfrom the RmMnIn3m+2n family (R = rare earth; M=Rh or Ir, m = 1, 2; n = 0, 1),\nwhere the crystalline electrical field (CEF) effects determine the direction of\nmagnetic moments and the TN evolution in the series. The measured Neel\ntemperature for Sm2IrIn8 is slightly suppressed when compared to the TN of the\nparent cubic compound SmIn3.\n", "machine_text": "\n\nThe magnetic structure of the rare-earth intermetallic compound Sm2IrIn8 was investigated by means of magnetic susceptibility, magnetometry, and neutron diffraction measurements. We found a long-range magnetic order with a = 8.45 \u00c5 and c = 5.71 \u00c5, which is consistent with the observed magnetic correlations in the ordered phase. To reveal the detailed magnetic structure, we performed a three-dimensional (3D) magnetic vector analysis. The analysis showed a 3D network of magnetic vectors, which were found to originate from a 2D network of magnetic clusters in the basal plane. The magnetic clusters are composed of a few magnetic ions, which are evenly distributed in the cluster. The intercluster magnetic vectors form a 3D network and link the clusters to each other. The long-range magnetic order is related to the antiferromagnetic correlations between the clusters. The 3D magnetic vector analysis also revealed the presence of a non-zero spin-orbit interaction (SOI) along the c axis, which is related to the Dzyaloshinksy-Moriya interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Flavour-Dependent Type II Leptogenesis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1591, "human_text": "  We reanalyse leptogenesis via the out-of-equilibrium decay of the lightest\nright-handed neutrino in type II seesaw scenarios, taking into account\nflavour-dependent effects. In the type II seesaw mechanism, in addition to the\ntype I seesaw contribution, an additional direct mass term for the light\nneutrinos is present. We consider type II seesaw scenarios where this\nadditional contribution arises from the vacuum expectation value of a Higgs\ntriplet, and furthermore an effective model-independent approach. We\ninvestigate bounds on the flavour-specific decay asymmetries, on the mass of\nthe lightest right-handed neutrino and on the reheat temperature of the early\nuniverse, and compare them to the corresponding bounds in the type I seesaw\nframework. We show that while flavour-dependent thermal type II leptogenesis\nbecomes more efficient for larger mass scale of the light neutrinos, and the\nbounds become relaxed, the type I seesaw scenario for leptogenesis becomes more\nconstrained. We also argue that in general, flavour-dependent effects cannot be\nignored when dealing with leptogenesis in type II seesaw models.\n", "machine_text": "\nFlavour-Dependent Type II Leptogenesis\n\nWe study the flavour-dependent formation of heavy nuclei far from stability, so-called type II leptogenesis, in the framework of the interacting- pebble bed model. We find that the favourable branching ratio of the ${}^{10}$ ${}^{56}$ ${}^{90}$ ${}^{144}$ channels is small and decreases with increasing mass number. In contrast, the ${}^{56}$ ${}^{90}$ ${}^{144}$ ${}^{198}$ ${}^{252}$ channels have a strongly flavour-dependent branching ratio and the ${}^{90}$ ${}^{144}$ ${}^{198}$ ${}^{252}$ channels even have a branching ratio that increases with the mass number. We show that this striking difference is due to the strong $(n-1)$- and $(n-2)$-level interactions in the ${}^{56}$ and ${}^{90}$ nuclei that strongly suppress the formation of the ${}^{10}$ and ${}^{144}$ nuclei and to the large $(n-1)$- and $(n-2)$-level interactions in the ${}^{144}$ and ${}^{198}$ nuclei that strongly enhance the formation of the ${}^{56}$ and ${}^{90}$ nuclei. We also discuss the ${}^{10}$ ${}^{90}$ ${}^{198}$ ${}^{252}$ channels and find that their branching ratios are small and increase with the mass number.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effective inverse spectral problem for rational Lax matrices and\n  applications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.012, "human_text": "  We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the\ndesingularization of the characteristic polynomial) and some additional data.\nUsing a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu))\nwe provide a residue-formula for the entries of the Lax matrix in terms of\nbases of dual differentials of weights nu and 1-nu respectively. All objects\nare described in the most explicit terms using Theta functions. Via a sequence\nof ``elementary twists'', we construct sequences of Lax matrices sharing the\nsame spectral curve and polar structure and related by conjugations by rational\nmatrices. Particular choices of elementary twists lead to construction of\nsequences of Lax matrices related to finite--band recurrence relations (i.e.\ndifference operators) sharing the same shape. Recurrences of this kind are\nsatisfied by several types of orthogonal and biorthogonal polynomials. The\nrelevance of formulae obtained to the study of the large degree asymptotics for\nthese polynomials is indicated.\n", "machine_text": "\n\nWe consider effective inverse spectral problems for rational Lax matrices. Such problems were introduced by Donath and Falkirk to study the structure of the solution space of certain partial differential equations. We show that the effective inverse spectral problem is very sensitive to the particular boundary conditions imposed on the rational Lax matrix. In particular, we show that the effective inverse spectral problem is ill-posed for general rational Lax matrices, but is well-posed for certain classes of rational Lax matrices, such as the Somepin- scraps or the voter- scraps. We also show that the effective inverse spectral problem for a rational Lax matrix is equivalent to the solution of a certain Fredholm integral equation of the first kind. We apply our results to prove that certain classes of rational Lax matrices have an effective inverse which is bounded in a neighborhood of the identity matrix. As an application, we give an example of a linear partial differential equation which has a solution space with a \"Friends of infinity\" structure, in the sense of L\u00e4mmer WITHrss and Wirsing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Comparison between Anomalous 6-cm H$_2$CO Absorption and CO(1-0)\n  Emission in the L1204/S140. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0272, "human_text": "  We report observations of the dust cloud L1204 with the Onsala 25-m telescope\nin the 6 cm (1$_{11}-1_{10}$) transition of \\htco. The observed region includes\nthe\n  S140 H${\\alpha}$ arc. This spectral line is seen here in absorption against\nthe cosmic microwave background, indicating the presence of widespread warm\nmolecular gas at intermediate densities. Overall, the distributions of H$_2$CO\nand CO (taken from the literature) are fairly similar, though significant\ndifferences exist at small scales. Most notably, while the CO peak is nearly\ncoincident with the S140 H${\\alpha}$ arc, the maximum H$_2$CO absorption is\nclearly separated from it by a full 10$'$ beam ($\\sim$ 3 pc). We argue that\nthese differences result from differing abundances and excitation requirements.\nThe CO(1-0) line is more optically thick and more biased towards warm gas than\nthe H$_2$CO 6 cm line. On the other hand, formaldehyde is more easily\nphotodissociated and is, therefore, a poorer tracer of the molecular gas\nlocated immediately behind Photon Dominated Regions.\n", "machine_text": "\nWe present an analysis of the 6-cm H$_{2}$CO absorption and CO(1-0) emission in the L1204/S140 region. The main aim of our work is to investigate the possible connection between these two molecular lines. We find that the H$_{2}$CO absorption features are, in fact, due to the photodissociation of CO by the incident far-UV radiation and subsequent recombination with H$_{2}$. We show that this process produces an additional population of CO(1-0) excited state, which is not present in the case of CO photodissociation by IR radiation. The most likely sink for the excited state CO(1-0) is its collision with H$_{2}$ or another CO molecule, resulting in the deexcitation and the CO(1-0) ground state population. We discuss the possibility of using the CO(1-0)-to-CO(0-0) transition as a diagnostic tool for detecting shocked H$_{2}$. Our results are consistent with the earlier suggestion that the far-UV-induced 6-cm H$_{2}$CO absorption may be used for detecting shocked H$_{2}$. We propose that the strength of this absorption may be used as a measure of the degree of H$_{2}$ shocked state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Searching for Gravitational Radiation from Binary Black Hole MACHOs in\n  the Galactic Halo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1514, "human_text": "  The Laser Interferometer Gravitational Wave Observatory (LIGO) is one of a\nnew generation of detectors of gravitational radiation. The existence of\ngravitational radiation was first predicted by Einstein in 1916, however\ngravitational waves have not yet been directly observed. One source of\ngravitation radiation is binary inspiral. Two compact bodies orbiting each\nother, such as a pair of black holes, lose energy to gravitational radiation.\nAs the system loses energy the bodies spiral towards each other. This causes\ntheir orbital speed and the amount of gravitational radiation to increase,\nproducing a characteristic ``chirp'' waveform in the LIGO sensitive band. In\nthis thesis, matched filtering of LIGO science data is used to search for low\nmass binary systems in the halo of dark matter surrounding the Milky Way.\nObservations of gravitational microlensing events of stars in the Large\nMagellanic Cloud suggest that some fraction of the dark matter in the halo may\nbe in the form of Massive Astrophysical Compact Halo Objects (MACHOs). It has\nbeen proposed that low mass black holes formed in the early universe may be a\ncomponent of the MACHO population; some fraction of these black hole MACHOs\nwill be in binary systems and detectable by LIGO. The inspiral from a MACHO\nbinary composed of two 0.5 solar mass black holes enters the LIGO sensitive\nband around 40 Hz. The chirp signal increases in amplitude and frequency,\nsweeping through the sensitive band to 4400 Hz in 140 seconds. By using\nevidence from microlensing events and theoretical predictions of the population\nan upper limit is placed on the rate of black hole MACHO inspirals in the\ngalactic halo.\n", "machine_text": "\n\nWe present non-detections of gravitational radiation (GR) from three binary black hole (BBH) MACHOs in the Galactic halo, as searched for by the LIGO and Virgo detectors, during the ongoing Advanced LIGO Observing run (O4). We consider the prospects for detecting low-mass X-ray binaries (LMXBs) containing black holes in the future, in the context of a growing population of detections of electromagnetic counterparts to LMXBs in the Galactic halo. We discuss how non-detections of GR from known LMXBs containing black holes can constrain the likelihood of detecting new LMXBs in the Galactic halo via the gravitational lensing effect, and the implications of our non-detections for models of accretion onto black holes in LMXBs. We also consider prospects for detecting a gravitating object in the Galactic halo that is not known to be a LMXB, on the basis of its weakly non-linear gravitational signature, and discuss what such a detection would imply about the nature of the halo. We conclude that a large-scale survey of the Galactic halo for weakly non-linear gravitational signatures is an interesting and important direction for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gauge-Higgs Unification and Radiative Electroweak Symmetry Breaking in\n  Warped Extra Dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1281, "human_text": "  We compute the Coleman Weinberg effective potential for the Higgs field in RS\nGauge-Higgs unification scenarios based on a bulk SO(5) x U(1)_X gauge\nsymmetry, with gauge and fermion fields propagating in the bulk and a custodial\nsymmetry protecting the generation of large corrections to the T parameter and\nthe coupling of the Z to the bottom quark. We demonstrate that electroweak\nsymmetry breaking may be realized, with proper generation of the top and bottom\nquark masses for the same region of bulk mass parameters that lead to good\nagreement with precision electroweak data in the presence of a light Higgs. We\ncompute the Higgs mass and demonstrate that for the range of parameters for\nwhich the Higgs boson has Standard Model-like properties, the Higgs mass is\nnaturally in a range that varies between values close to the LEP experimental\nlimit and about 160 GeV. This mass range may be probed at the Tevatron and at\nthe LHC. We analyze the KK spectrum and briefly discuss the phenomenology of\nthe light resonances arising in our model.\n", "machine_text": "\n\nWe propose a mechanism for radiative electroweak symmetry breaking in warped extra dimensions. The physical picture is that theHiggs sector couples to a U(1) gauge group that is itself warped in the extra dimensions. This produces a non-trivial Higgs potential with two distinct mass scales for the Higgs boson, one near the TeV scale and the other near the electroweak scale. The mass term for the Higgs boson is given by a non-trivial curve in the warped extra dimensions. We show that for a large class of warped extra dimension models, the mass term for the Higgs boson is always quadratic, and so the potential is aMexican hat potential. We consider the consequences of this model for the Higgs sector, and show that in certain cases the low-scale Higgs boson can be very light, and the high-scale Higgs boson can be very heavy. We show that this model can naturally explain the \"miracle\" that the Higgs boson is so light. We also show that in this model, the Higgs boson can have a Standard Model (SM) Yukawa coupling, and so the Higgs sector can be related to the SM Yukawa coupling in the same way that the SM Higgs sector is related to the Yukawa coupling in the warped extra dimensions. This has the potential to provide a unified framework for understanding both the Higgs sector and the Yukawa coupling in the warpped extra dimensions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Post-Newtonian gravitational radiation and equations of motion via\n  direct integration of the relaxed Einstein equations. V. Evidence for the\n  strong equivalence principle to second post-Newtonian order. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2243, "human_text": "  Using post-Newtonian equations of motion for fluid bodies valid to the second\npost-Newtonian order, we derive the equations of motion for binary systems with\nfinite-sized, non-spinning but arbitrarily shaped bodies. In particular we\nstudy the contributions of the internal structure of the bodies (such as\nself-gravity) that would diverge if the size of the bodies were to shrink to\nzero. Using a set of virial relations accurate to the first post-Newtonian\norder that reflect the stationarity of each body, and redefining the masses to\ninclude 1PN and 2PN self-gravity terms, we demonstrate the complete\ncancellation of a class of potentially divergent, structure-dependent terms\nthat scale as s^{-1} and s^{-5/2}, where s is the characteristic size of the\nbodies. This is further evidence of the Strong Equivalence Principle, and\nsupports the use of post-Newtonian approximations to derive equations of motion\nfor strong-field bodies such as neutron stars and black holes. This extends\nearlier work done by Kopeikin.\n", "machine_text": "\nWe continue our study of the equations of motion in post-Newtonian theory, obtained via direct integration of the relaxed Einstein equations. In this article, we consider the particular case of a weakly asymmetric double-pulse test configuration, which allows us to test the strong equivalence principle (SEP) to second post-Newtonian order (PN2). In our previous work, which considered a symmetric double-pulse test configuration, we found that thePN2 equations of motion exhibited a form of constraint relaxation, in which the structure of the constraint surface was different in the two post-Newtonian frames moving at different speeds. This finding was inconsistent with the strong equivalence principle, and we were able to show that this inconsistency could be resolved by introducing a small non-singular structure on the constraint surface. In this article, we consider the particular case of a weakly asymmetric double-pulse test configuration, which allows us to test the strong equivalence principle to second post-Newtonian order (PN2). In our previous work, which considered a symmetric double-pulse test configuration, we found that thePN2 equations of motion exhibited a form of constraint relaxation, in which the structure of the constraint surface was different in the two post-Newtonian frames moving at different speeds. This finding was inconsistent with the strong equivalence principle, and we were able to show that this inconsistency could be resolved by introducing a small non-singular structure on the constraint surface.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: One- and two-component bottle-brush polymers: simulations compared to\n  theoretical predictions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1124, "human_text": "  Scaling predictions and results from self-consistent field calculations for\nbottle-brush polymers with a rigid backbone and flexible side chains under good\nsolvent conditions are summarized and their validity and applicability is\nassessed by a comparison with Monte Carlo simulations of a simple lattice\nmodel. It is shown that under typical conditions, as they are also present in\nexperiments, only a rather weak stretching of the side chains is realized, and\nthen the scaling predictions based on the extension of the Daoud-Cotton blob\npicture are not applicable.\n  Also two-component bottle brush polymers are considered, where two types\n(A,B) of side chains are grafted, assuming that monomers of different kind\nrepel each other. In this case, variable solvent quality is allowed for, such\nthat for poor solvent conditions rather dense cylinder-like structures result.\nTheories predict ``Janus Cylinder''-type phase separation along the backbone in\nthis case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth\nmethod (PERM) then are restricted to rather short side chain length.\nNevertheless, evidence is obtained that the phase separation between an A-rich\npart of the cylindrical molecule and a B-rich part can only occur locally. The\ncorrelation length of this microphase separation can be controlled by the\nsolvent quality. This lack of a phase transition is interpreted by an analogy\nwith models for ferromagnets in one space dimension.\n", "machine_text": "\nWe present a theoretical study of the structure and properties of one- and two-component bottle-brush polymers in good solvent, in the limit of large brush height and small number density of macromolecules. The key ideas and methodology are: (i) the description of the polymers' structure by the mean-field theory in the basis of the nearest-neighbor approach, (ii) the assumption that the polymer conformers are tightly packed and fully overlapping, (iii) the calculation of the spatial and orientational correlations, and (iv) the use of the conformational space generated by these correlations for the construction of the configurational trees and the computation of the statistical properties. We compare our theoretical predictions with the results of computer simulations of two recently proposed algorithms for the simulation of bottle-brush polymers in good solvent, which are based on the representation of the brush by a two-level hierarchical tree and on the assumption that the solvent molecules are much more numerous than the polymer molecules. In particular, we show that both algorithms give good predictions of the radial distribution function, if the brush height is large enough, independently of the number density of macromolecules. We also show that the prediction of the configurational tree obtained by the two-component algorithm is in a very good agreement with our theory, if the number density of the polymer is not too large. We discuss the limitations of the simulation algorithms in the description of the bottle-brush structure in the limit of large number density of macromolecules and small brush height.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Discovery of two candidate pulsar wind nebulae in very-high-energy gamma\n  rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1605, "human_text": "  We present the discovery of two very-high-energy gamma-ray sources in an\nongoing systematic search for emission above 100 GeV from pulsar wind nebulae\nin survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov\nTelescopes are ideal tools for searching for extended emission from pulsar wind\nnebulae in the very-high-energy regime. H.E.S.S., with its large field of view\nof 5 degrees and high sensitivity, gives new prospects for the search for these\nobjects. An ongoing systematic search for very-high-energy emission from\nenergetic pulsars over the region of the Galactic plane between -60 degrees < l\n< 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting\ncandidates, the standard H.E.S.S. analysis was applied and a search for\nmulti-wavelength counterparts was performed. We present the discovery of two\nnew candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193.\nH.E.S.S. has proven to be a suitable instrument for pulsar wind nebula\nsearches.\n", "machine_text": "\n\nWe present the discovery of two candidate pulsar wind nebulae (PWNe) in very-high-energy gamma rays (VHEs). The first, identified in archival data from the MAGIC telescope, is associated with the young radio pulsar B1257+12. This is the first definitive detection of a PWN in VHEs, and the first identification of a PWN in any wavelength band based on a firm association with a single pulsar. The second is a likely PWN detected in archival data from the IceCube neutrino telescope, associated with the young radio pulsar B1510+57. This is the first candidate PWN detected in VHEs based on a firm association with a single pulsar. We find that the VHEs from these sources have a power law spectra with a cut-off energy around 100 GeV, and are accompanied by a significant excess of multi-TeV VHEs from the direction of the pulsars. These properties are consistent with a shock-ignition of VHE emission in a PWN, possibly in combination with inverse-Compton scattering of relativistic electrons in the magnetosphere of the pulsars. Our results suggest that a significant fraction of pulsars are likely to host a PWN, and that these objects may be able to explain the origin of the multi-TeV VHEs detected by previous experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-dimensional Ising model with competing interactions and its\n  application to clusters and arrays of $\\pi$-rings and adiabatic quantum\n  computing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1643, "human_text": "  We study planar clusters consisting of loops including a Josephson\n$\\pi$-junction ($\\pi$-rings). Each $\\pi$-ring carries a persistent current and\nbehaves as a classical orbital moment. The type of particular state associated\nwith the orientation of orbital moments at the cluster depends on the\ninteraction between these orbital moments and can be easily controlled, i.e. by\na bias current or by other means. We show that these systems can be described\nby the two-dimensional Ising model with competing nearest-neighbor and diagonal\ninteractions and investigate the phase diagram of this model. The\ncharacteristic features of the model are analyzed based on the exact solutions\nfor small clusters such as a 5-site square plaquette as well as on a mean-field\ntype approach for the infinite square lattice of Ising spins. The results are\ncompared with spin patterns obtained by Monte Carlo simulations for the 100\n$\\times$ 100 square lattice and with experiment. We show that the $\\pi$-ring\nclusters may be used as a new type of superconducting memory elements. The\nobtained results may be verified in experiments and are applicable to adiabatic\nquantum computing where the states are switched adiabatically with the slow\nchange of coupling constants.\n", "machine_text": "\nWe consider a two-dimensional Ising model with competing interactions and its application to clusters and arrays of $\\pi$-rings and adiabatic quantum computing. The Ising model is used to study the influence of various competing interactions on the structure of the ground state and the low-lying excitations. The $\\pi$-rings are used to realize the Ising model in a particular type of cluster and to study its low-lying excitations. We show that the ground state of the cluster Ising model is degenerate and has long-range order. The low-lying excitations of the cluster Ising model are found to be associated with the static subcluster structures. We also study the Ising model on the array of $\\pi$-rings. The ground state of the array Ising model is found to be a superposition of several simple states, and its low-lying excitations are found to be associated with the static array structures. Finally, we discuss the possibility of using the Ising model with competing interactions as a quantum bit for adiabatic quantum computation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information, information processing and gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1154, "human_text": "  I discuss fundamental limits placed on information and information processing\nby gravity. Such limits arise because both information and its processing\nrequire energy, while gravitational collapse (formation of a horizon or black\nhole) restricts the amount of energy allowed in a finite region. Specifically,\nI use a criterion for gravitational collapse called the hoop conjecture. Once\nthe hoop conjecture is assumed a number of results can be obtained directly:\nthe existence of a fundamental uncertainty in spatial distance of order the\nPlanck length, bounds on information (entropy) in a finite region, and a bound\non the rate of information processing in a finite region. In the final section\nI discuss some cosmological issues related to the total amount of information\nin the universe, and note that almost all detailed aspects of the late universe\nare determined by the randomness of quantum outcomes. This paper is based on a\ntalk presented at a 2007 Bellairs Research Institute (McGill University)\nworkshop on black holes and quantum information.\n", "machine_text": "\nWe show that information processing is necessary to explain the behavior of systems with many degrees of freedom in fields such as physics, chemistry, and biology. We find that information processing is always related to the concept of complexity. We define the concept of Complexity as the Information Capacity of a system to process information. We show that the dynamics of systems with many degrees of freedom can be described as a process of increasing complexity. We show that this process of increasing complexity is related to the process of gravitational attraction between bodies. We find that the process of increasing complexity is related to the process of increasing the capacity to process information. We show that the behavior of systems with many degrees of freedom can be explained by the dynamics of information processing. We show that this dynamics of information processing can be described by the concept of complexity. We find that complexity is always related to the Information Capacity of a system to process information.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Kinematics and Dynamics of the Globular Clusters and the Planetary\n  Nebulae of NGC 5128. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1189, "human_text": "  A new kinematic and dynamic study of the halo of the giant elliptical galaxy,\nNGC 5128, is presented. From a spectroscopically confirmed sample of 340\nglobular clusters and 780 planetary nebulae, the rotation amplitude, rotation\naxis, velocity dispersion, and the total dynamical mass are determined for the\nhalo of NGC 5128. The globular cluster kinematics were searched for both radial\ndependence and metallicity dependence by subdividing the globular cluster\nsample into 158 metal-rich ([Fe/H] > -1.0) and 178 metal-poor ([Fe/H] < -1.0)\nglobular clusters. Our results show the kinematics of the metal-rich and\nmetal-poor subpopulations are quite similar. The kinematics are compared to the\nplanetary nebula population where differences are apparent in the outer regions\nof the halo. The total mass of NGC 5128 is found using the Tracer Mass\nestimator (Evans et al. 2003), to determine the mass supported by internal\nrandom motions, and the spherical component of the Jeans equation to determine\nthe mass supported by rotation. We find a total mass of (1.0+/-0.2) x 10^(12)\nMsun from the planetary nebulae data out to a projected radius of 90 kpc and\n(1.3+/-0.5) x 10^(12) Msun from the globular clusters out to a projected radius\nof 50 kpc. Lastly, we present a new and homogeneous catalog of known globular\nclusters in NGC 5128. This catalog combines all previous definitive cluster\nidentifications from radial velocity studies and HST imaging studies, as well\nas 80 new globular clusters from a study of M.A. Beasley et al. (2007, in\npreparation).\n", "machine_text": "\n\nThe kinematics and dynamics of the globular clusters and the planetary nebulae of NGC 5128\n\nWe present a kinematic and dynamic study of the globular clusters and the planetary nebulae of the face-on barred spiral galaxy NGC 5128. The stellar populations of the globular clusters have been derived using high-resolution spectroscopy obtained with the DEIMOS multi-object spectrograph on Keck Observatory. We have measured the orbital speeds of the globular clusters and found that they follow two different radial distributions. The inner clusters have average speeds of 75 km/s and range from 52 to 86 km/s. The outer clusters have average speeds of 55 km/s and range from 44 to 69 km/s. The difference in the speeds of the two populations is statistically significant (p < 0.001, Student's t-test) and implies that the two populations are not genetically related. We have also measured the orbital speeds of the planetary nebulae and found that they are higher than the globular clusters, ranging from 85 to 99 km/s. The average orbital speed of the planetary nebulae is 87 km/s. We conclude that the globular clusters and the planetary nebulae of NGC 5128 have dynamical origins different from each other. The globular clusters were probably born in the same manner as those in the Milky Way, while the planetary nebulae were probably born by the gravitational interactions of the globular clusters with the bar.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stellar Evolution in NGC 6791: Mass Loss on the Red Giant Branch and the\n  Formation of Low Mass White Dwarfs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0977, "human_text": "  We present the first detailed study of the properties (temperatures,\ngravities, and masses) of the NGC 6791 white dwarf population. This unique\nstellar system is both one of the oldest (8 Gyr) and most metal-rich ([Fe/H] ~\n0.4) open clusters in our Galaxy, and has a color-magnitude diagram (CMD) that\nexhibits both a red giant clump and a much hotter extreme horizontal branch.\nFitting the Balmer lines of the white dwarfs in the cluster, using Keck/LRIS\nspectra, suggests that most of these stars are undermassive, <M> = 0.43 +/-\n0.06 Msun, and therefore could not have formed from canonical stellar evolution\ninvolving the helium flash at the tip of the red giant branch. We show that at\nleast 40% of NGC 6791's evolved stars must have lost enough mass on the red\ngiant branch to avoid the flash, and therefore did not convert helium into\ncarbon-oxygen in their core. Such increased mass loss in the evolution of the\nprogenitors of these stars is consistent with the presence of the extreme\nhorizontal branch in the CMD. This unique stellar evolutionary channel also\nnaturally explains the recent finding of a very young age (2.4 Gyr) for NGC\n6791 from white dwarf cooling theory; helium core white dwarfs in this cluster\nwill cool ~3 times slower than carbon-oxygen core stars and therefore the\ncorrected white dwarf cooling age is in fact ~7 Gyr, consistent with the well\nmeasured main-sequence turnoff age. These results provide direct empirical\nevidence that mass loss is much more efficient in high metallicity environments\nand therefore may be critical in interpreting the ultraviolet upturn in\nelliptical galaxies.\n", "machine_text": "\n\nWe present photometric and spectroscopic observations of the red giant branch (RGB) in the globular cluster NGC 6791. The photometry comprises a series of periodograms of over 5500 stars in the cluster, obtained with the Transiting Exoplanet Survey Satellite. The spectroscopic observations were made with the Multi-Object Spectrograph for Infra-Red Astronomy on the Very Large Telescope, and include high-resolution spectroscopy of about 70 of the cluster's red giants, as well as more than 1000 lower resolution spectra of field stars. We determine the evolutionary status of the cluster's red giants by fitting theoretical isochrones to the observed photometry. We find that a significant fraction (43%) of the red giants in the cluster are below the expected mass for the RGB, consistent with the hypothesis that a large number of low-mass stars suffer significant mass loss on the RGB. We show that the current mean metallicity of the RGB is [Fe/H] \u2248 +0.3 dex, consistent with the cluster having formed in a medium- metallicity environment, and having lost a significant fraction of its initial metal content. We discuss the evolution of the cluster and find that the current RGB is very well described by the simple King-oshima model, with an age of 12 Gyr, a star formation rate of 0.45 R\u2299 yr-1, and a mass loss rate of 1.1 R\u2299 yr-1. We find that the cluster has a significant population of low-mass white dwarfs, with a current mass of about 8.5 R\u2299. We show that this population is comprised of stars with initial masses in the range 1.5\u20132.5 M\u2299, that have lost a significant fraction of their mass on the RGB, and that have therefore cooled and contracted to become low-mass white dwarfs. We conclude that significant mass loss on the RGB is a common feature of globular clusters, and that it can have a major impact on the evolution of the cluster, affecting both the structure of the red giant branch and the properties of the low-mass white dwarf population.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Predicting the Solar Cycle using Mean-Field Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2345, "human_text": "  We discuss the difficulties of predicting the solar cycle using mean-field\nmodels. Here we argue that these difficulties arise owing to the significant\nmodulation of the solar activity cycle, and that this modulation arises owing\nto either stochastic or deterministic processes. We analyse the implications\nfor predictability in both of these situations by considering two separate\nsolar dynamo models. The first model represents a stochastically-perturbed flux\ntransport dynamo. Here even very weak stochastic perturbations can give rise to\nsignificant modulation in the activity cycle. This modulation leads to a loss\nof predictability. In the second model, we neglect stochastic effects and\nassume that generation of magnetic field in the Sun can be described by a fully\ndeterministic nonlinear mean-field model -- this is a best case scenario for\nprediction. We designate the output from this deterministic model (with\nparameters chosen to produce chaotically modulated cycles) as a target\ntimeseries that subsequent deterministic mean-field models are required to\npredict. Long-term prediction is impossible even if a model that is correct in\nall details is utilised in the prediction. Furthermore, we show that even\nshort-term prediction is impossible if there is a small discrepancy in the\ninput parameters from the fiducial model. This is the case even if the\npredicting model has been tuned to reproduce the output of previous cycles.\nGiven the inherent uncertainties in determining the transport coefficients and\nnonlinear responses for mean-field models, we argue that this makes predicting\nthe solar cycle using the output from such models impossible.\n", "machine_text": "\nWe develop a simple mean-field model for the solar cycle that is based on the hypothesis that the solar magnetic field is influenced by a combination of a secular trend and a series of periodically oscillating terms. We show that the model is able to reproduce the main features of the solar cycle, including the occurrence of sunspots, their latitudes, and the length of the cycle. We use a Monte Carlo technique to investigate the sensitivity of the model to the choice of the model parameters and to the input series of periodically oscillating terms. We show that the model can be used to predict the future development of the solar cycle. In particular, we find that the model is able to predict the occurrence of a solar maximum several years in advance with a probability higher than 0.5. The prediction is based on the knowledge of the current level of solar activity and on the previous evolution of the cycle. We discuss the relevance of our findings for understanding the underlying physical processes that give rise to the solar cycle.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hidden Symmetry of the CKM and Neutrino Mapping Matrices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4156, "human_text": "  We propose that the smallness of the light quark masses is related to the\nsmallness of the T violation in hadronic weak interactions. Accordingly, for\neach of the two quark sectors (\"upper\" and \"lower\") we construct a 3\\times 3\nmass matrix in a bases of unobserved quark states, such that the \"upper\"and\n\"lower\" basis states correspond exactly via the $W^\\pm$ transitions in the weak\ninteraction. In the zeroth approximation of our formulation, we assume T\nconservation by making all matrix elements real. In addition, we impose a\n\"hidden symmetry\" (invariance under simultaneous translations of all three\nbasis quark states in each sector), which ensures a zero mass eigenstate in\neach sector.\n  Next, we simultaneously break the hidden symmetry and T invariance by\nintroducing a phase factor e^{i\\chi} in the interaction for each sector. The\nJarlskog invariant J_{CKM}, as well as the light quark masses are evaluated in\nterms of the parameters of the model. We find a simple relation with\nJ_{CKM}=(m_dm_s/m_b^2)^{1/2}A\\lambda^3\\cos(\\chi/2), with A and \\lambda the\nWolfenstein parameters. Setting J_{CKM}=3.08 \\times 10^{-5}, m_b=4.7GeV,\nm_s=95MeV, A=0.818 and \\lambda=0.227, we find m_d\\cos^2(\\chi/2) \\simeq 2.4MeV,\nconsistent with the accepted value m_d=3-7MeV.\n  We make a parallel proposal for the lepton sectors. With the hidden symmetry\nand in the approximation of T invariance, both the masses of e and \\nu_1 are\nzero. The neutrino mapping matrix V_\\nu is shown to be of the same\nHarrison-Scott form which is in agreement with experiments. We also examine the\ncorrection due to T violation, and evaluate the corresponding Jarlskog\ninvariant {\\cal J}_\\nu.\n", "machine_text": "\n\nHidden Symmetry of the CKM and Neutrino Mapping Matrices\nWe show that the quark mixing matrix and the neutrino mapping matrix share a common, hidden symmetry which is related to the flavor-changing symmetries of the weak interaction. We consider the simplest case of a narrow quark-flavor distribution with three quark generations and a small number N of active neutrino flavors. The N\u00d7N neutrino mapping matrix is related to the 3\u00d73 quark mixing matrix in a way which allows to deduce the hidden symmetry of the neutrino matrix from the quark mixing matrix. We show that this symmetry is related to the flavor-changing symmetries of the weak interaction. We finally consider a more general case with a wider quark-flavor distribution and a large number N of neutrinos, and we discuss the case of an infinite number N of neutrinos. In all cases we show that the hidden symmetry of the neutrino matrix is related to the quark mixing matrix through a combination of the flavor-changing symmetries of the weak interaction and the general concept of the conservation of quadratic forms.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Top production at the Tevatron/LHC and nonstandard, strongly interacting\n  spin one particles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1499, "human_text": "  In this note, we consider possible constraints from $t \\bar t$ production on\nthe gauge bosons of theories with an extended strong interaction sector such as\naxigluons or flavour universal colorons. Such constraints are found to be\ncompetitive with those obtained from the dijet data. The current $t \\bar t$\ndata from the Tevatron rule out axigluon masses ($m_A$) up to 900 GeV and 850\nGeV at 2 $\\sigma$ and 4 $\\sigma$ levels respectively. For the case of flavour\nuniversal colorons the data rule out a mass ($m_C$) below 800 GeV (780 GeV) at\nthe $2 (4) \\sigma $ level and also the mass range between 900 GeV to 2.1 TeV at\n2 $\\sigma$ level, for $\\cot \\xi = 1$, where $\\xi$ is the mixing angle. For\n$\\cot \\xi =2$ on the other hand, the excluded range is $m_C \\lsim 950 (920)$\nGeV and $m_C \\gsim 1.02 (1.15 \\lsim m_C \\lsim 1.8)$ TeV at $2 \\sigma$ ($4\n\\sigma $) level. We point out that for higher axigluon/coloron masses, even for\nthe dijet channel, the limits on the coloron mass, for $\\cot \\xi = 1$, may be\ndifferent than those for the axigluon. We also compute the expected\nforward-backward asymmetry for the case of the axigluons which would allow it\nto be discriminated against the SM as also the colorons. We further find that\nat the LHC, the signal should be visible in the $t \\bar t$ invariant mass\nspectrum for a wide range of axigluon and coloron masses that are still\nallowed. We point out how top polarisation may be used to further discriminate\nthe axigluon and coloron case from the SM as well as from each other.\n", "machine_text": "\nWe motivate our research by noting that the top quark is unique among quarks in that it can be produced in hadron collisions with a large rate, and thus offers the possibility of studying quarkonia in a new, strongly interacting regime. We briefly review the status of the Tevatron and LHC top quark searches, and outline the conditions that would have to be met in order for the top quark to be produced in large numbers at hadron colliders. We then propose a mechanism for the production of multiple top quarks in hadron collisions, and show that this mechanism is able to produce a significant number of top quarks at the Tevatron, and would be even more efficient at the LHC. We also propose a mechanism for the production of a new type of quarkonia, which we call nonstandard, strongly interacting spin one particles (NSSIPs). We show that NSSIPs can be produced at the Tevatron and LHC, and that they can be distinguished from Standard Model (SM) quarkonia. We finally discuss the experimental signatures of NSSIPs, and outline a search strategy for them at the LHC.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anomalies and de Sitter radiation from the generic black holes in de\n  Sitter spaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3871, "human_text": "  Robinson-Wilczek's recent work shows that, the energy momentum tensor flux\nrequired to cancel gravitational anomaly at the event horizon of a\nSchwarzschild-type black hole has an equivalent form to that of a\n(1+1)-dimensional blackbody radiation at the Hawking temperature. Motivated by\ntheir work, Hawking radiation from the cosmological horizons of the general\nSchwarzschild-de Sitter and Kerr-de Sitter black holes, has been studied by the\nmethod of anomaly cancellation. The result shows that the absorbing gauge\ncurrent and energy momentum tensor fluxes required to cancel gauge and\ngravitational anomalies at the cosmological horizon are precisely equal to\nthose of Hawking radiation from it. It should be emphasized that the effective\nfield theory for generic black holes in de Sitter spaces should be formulated\nwithin the region between the event horizon (EH) and the cosmological horizon\n(CH), to integrate out the classically irrelevant ingoing modes at the EH and\nthe classically irrelevant outgoing modes at the CH, respectively.\n", "machine_text": "\n\nWe study generic black holes in de Sitter spaces. We find two different classes of anomalies. One of them is a result of a local coordinate singularity, and the other is due to the dynamical Casimir effect. The first class of anomalies is eliminated by a change of the coordinate system, while the second one is only partially eliminated and results in a finite thermal mass flux for the black hole. We show that this non-zero mass flux is a result of a special form of the black hole horizon, which is different from the standard round horizon but still allows the black hole to be stable against any perturbations. The physical origin of this special form of the horizon is a strong gravitational interaction between the black hole and the space-time. We show that this interaction is a result of the de Sitter space-time being curved. We call this type of a black hole a de Sitter black hole. It has a finite temperature and a non-zero mass flux. We discuss a physical origin of the de Sitter black hole and show that it is a result of a particular form of the Einstein equations in the de Sitter space-time.\n\nWe also discuss a possibility of a detection of the de Sitter radiation from the de Sitter black hole and show that it is different from the Hawking radiation. The de Sitter radiation is a result of a periodic transient in the dipole moment of the black hole, which is caused by the periodically changing structure of the space-time. We show that this transient is related to a modulation of the Einstein equations and can be induced by a change in the radius of the de Sitter space-time. We calculate the energy flux of the de Sitter radiation and show that it is a very small fraction of the Hawking radiation for any reasonable choice of the de Sitter space-time. We also discuss a possibility of an experimental detection of the de Sitter radiation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information-Based Asset Pricing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1976, "human_text": "  A new framework for asset price dynamics is introduced in which the concept\nof noisy information about future cash flows is used to derive the price\nprocesses. In this framework an asset is defined by its cash-flow structure.\nEach cash flow is modelled by a random variable that can be expressed as a\nfunction of a collection of independent random variables called market factors.\nWith each such \"X-factor\" we associate a market information process, the values\nof which are accessible to market agents. Each information process is a sum of\ntwo terms; one contains true information about the value of the market factor;\nthe other represents \"noise\". The noise term is modelled by an independent\nBrownian bridge. The market filtration is assumed to be that generated by the\naggregate of the independent information processes. The price of an asset is\ngiven by the expectation of the discounted cash flows in the risk-neutral\nmeasure, conditional on the information provided by the market filtration. When\nthe cash flows are the dividend payments associated with equities, an explicit\nmodel is obtained for the share-price, and the prices of options on\ndividend-paying assets are derived. Remarkably, the resulting formula for the\nprice of a European call option is of the Black-Scholes-Merton type. The\ninformation-based framework also generates a natural explanation for the origin\nof stochastic volatility.\n", "machine_text": "\n\nWe show that information-based asset pricing models can be derived from a general principle of combining risk and Knightian uncertainty in a sophisticated way. Our approach is based on a strict synthesis of the traditional capital asset pricing model and the probabilistic methodology of Von Mises. In particular, we demonstrate that a general risk-based asset pricing model can be obtained by combining the moments of the distribution of future cash flows in a particular way, and that such a model can be arbitrage-free only if the distribution of future cash flows is completely specified. In this case, we show that the resulting model can be used to price any kind of asset, including stocks, bonds, options, futures, etc. We also show that the same principle can be used to derive an information-based asset pricing model from the moment structure of the distribution of future cash flows, and that the resulting model can be arbitrage-free only if the distribution of future cash flows is not completely specified. In this case, the model can be used to price assets which are managed in a particular way, and may lead to the pricing of assets that have no future cash flows (such as currencies or commodities).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-equilibrium coherence dynamics in one-dimensional Bose gases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2259, "human_text": "  Low-dimensional systems are beautiful examples of many-body quantum physics.\nFor one-dimensional systems the Luttinger liquid approach provides insight into\nuniversal properties. Much is known of the equilibrium state, both in the\nweakly and strongly interacting regime. However, it remains a challenge to\nprobe the dynamics by which this equilibrium state is reached. Here we present\na direct experimental study of the coherence dynamics in both isolated and\ncoupled degenerate 1d Bose gases. Dynamic splitting is used to create two 1d\nsystems in a phase coherent state. The time evolution of the coherence is\nrevealed in local phase shifts of the subsequently observed interference\npatterns. Completely isolated 1d Bose gases are observed to exhibit a universal\nsub-exponential coherence decay in excellent agreement with recent predictions\nby Burkov et al. [Phys. Rev. Lett. 98, 200404 (2007)]. For two coupled 1d Bose\ngases the coherence factor is observed to approach a non-zero equilibrium value\nas predicted by a Bogoliubov approach. This coupled-system decay to finite\ncoherence is the matter wave equivalent of phase locking two lasers by\ninjection. The non-equilibrium dynamics of superfluids plays an important role\nin a wide range of physical systems, such as superconductors, quantum-Hall\nsystems, superfluid Helium, and spin systems. Our experiments studying\ncoherence dynamics show that 1d Bose gases are ideally suited for investigating\nthis class of phenomena.\n", "machine_text": "\nWe investigate the dynamics of a Bose-Einstein condensate (BEC) in a one-dimensional optical lattice, which is first prepared in a thermal equilibrium state and then rapidly displaced out of equilibrium by a short laser pulse. We find that the dynamics of the BEC during the evolution towards the new equilibrium state can be described by a general theoretical formalism based on the concept of non-equilibrium coherence. Our theory provides a good description of the experimentally observed dynamics in a recent experiment by Lucas et al., in which a one-dimensional BEC in a shallow optical lattice was driven out of equilibrium by a laser pulse. We also make predictions for the dynamics of a BEC in a deep optical lattice, which has not been investigated experimentally so far. Our results are relevant for a better understanding of the dynamics of quasiparticles in non-equilibrium states and for the development of practical schemes for the realization of matter-wave solitons in optical lattices.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gamma-ray probe of cosmic-ray pressure in galaxy clusters and\n  cosmological implications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2588, "human_text": "  Cosmic rays produced in cluster accretion and merger shocks provide pressure\nto the intracluster medium (ICM) and affect the mass estimates of galaxy\nclusters. Although direct evidence for cosmic-ray ions in the ICM is still\nlacking, they produce gamma-ray emission through the decay of neutral pions\nproduced in their collisions with ICM nucleons. We investigate the capability\nof the Gamma-ray Large Area Space Telescope (GLAST) and imaging atmospheric\nCerenkov telescopes (IACTs) for constraining the cosmic-ray pressure\ncontribution to the ICM. We show that GLAST can be used to place stringent\nupper limits, a few per cent for individual nearby rich clusters, on the ratio\nof pressures of the cosmic rays and thermal gas. We further show that it is\npossible to place tight (<~10%) constraints for distant (z <~ 0.25) clusters in\nthe case of hard spectrum, by stacking signals from samples of known clusters.\nThe GLAST limits could be made more precise with the constraint on the\ncosmic-ray spectrum potentially provided by IACTs. Future gamma-ray\nobservations of clusters can constrain the evolution of cosmic-ray energy\ndensity, which would have important implications for cosmological tests with\nupcoming X-ray and Sunyaev-Zel'dovich effect cluster surveys.\n", "machine_text": "\n\nWe present a measurement of the cosmic-ray (CR) pressure in a large volume of the local galaxy cluster Fornax, obtained with the Gamma-Ray unlucky imaging telescope (GRIT). The measurement uses the stacking of ~50,000 CR-excess images obtained with a fish-eye lens, to obtain a map of the CR pressure integrated over the cluster. We find a pressure of $6 \\times 10^{-6}$ cm-5, which is consistent with the pressure measured by the Fermi satellite in the Galactic disk, and with other cluster measurements. We show that this pressure is in agreement with the pressure expected from a simple model in which the CRs are relativistic, and the cluster acts as a perfect drag-free Yorker bottle. In this model, the pressure is given by the relativistic energy loss of the CRs, and depends only on the CR bulk velocity and the cluster radius. We show that this model predicts a pressure of $4-6 \\times 10^{-6}$ cm-5, in good agreement with our measurement, and with other cluster measurements. We discuss the implications of our measurement for CR propagation in clusters, and for the CR source. We find that the pressure is consistent with a simple model in which the CRs are produced by a large number of weakly-ionized sources, with a uniform ionization spectrum, and with a bulk velocity that varies smoothly with the cluster radius.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Recent progresses in the simulation of small-scale magnetic fields. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1848, "human_text": "  New high-resolution observations reveal that small-scale magnetic flux\nconcentrations have a delicate substructure on a spatial scale of 0.1''. Its\nbasic structure can be interpreted in terms of a magnetic flux sheet or tube\nthat vertically extends through the ambient weak-field or field-free atmosphere\nwith which it is in mechanical equilibrium. A more refined interpretation comes\nfrom new three-dimensional magnetohydrodynamic simulations that are capable of\nreproducing the corrugated shape of magnetic flux concentrations and their\nsignature in the visible continuum. Furthermore it is shown that the\ncharacteristic asymmetric shape of the contrast profile of facular granules is\nan effect of radiative transfer across the rarefied atmosphere of the magnetic\nflux concentration. I also discuss three-dimensional radiation\nmagnetohydrodynamic simulations of the integral layers from the top of the\nconvection zone to the mid-chromosphere. They show a highly dynamic\nchromospheric magnetic field, marked by rapidly moving filaments of stronger\nthan average magnetic field that form in the compression zone downstream and\nalong propagating shock fronts. The simulations confirm the picture of flux\nconcentrations that strongly expand through the photosphere into a more\nhomogeneous, space filling chromospheric field. Future directions in the\nsimulation of small-scale magnetic fields are indicated by a few examples of\nvery recent work.\n", "machine_text": "\n\nWe review the state-of-the-art in the simulation of small-scale magnetic fields, including both computational techniques and recent progress in the theory of magnetic nanostructures. We discuss a range of computational methods that have been developed to simulate small-scale magnetic fields, including both empirical approaches and methods that are based on the fundamental laws of physics. We also review recent progress in the theory of magnetic nanostructures, including the development of effective theories for describing the behavior of small magnetic particles and the application of these theories to the design of new magnetic nanostructures.\n\nThe study of small-scale magnetic fields is of interest both for its own sake and for the insight it can provide into the behavior of magnetic materials at the nanoscale. Small-scale magnetic fields can be used to control the behavior of magnetic nanostructures, and they can also be used to sense and manipulate nanoscale magnetic phenomena. In this review, we discuss recent progress in the simulation of small-scale magnetic fields, including both computational techniques and recent progress in the theory of magnetic nanostructures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evaporation of buffer gas-thermalized anions out of a multipole rf ion\n  trap. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0224, "human_text": "  We identify plain evaporation of ions as the fundamental loss mechanism out\nof a multipole ion trap. Using thermalized negative Cl- ions we find that the\nevaporative loss rate is proportional to a Boltzmann factor. This thermodynamic\ndescription sheds new light on the dynamics of particles in time-varying\nconfining potentials. It specifically allows us to extract the effective depth\nof the ion trap as the activation energy for evaporation. As a function of the\nrf amplitude we find two distinct regimes related to the stability of motion of\nthe trapped ions. For low amplitudes the entire trap allows for stable motion\nand the trap depth increases with the rf field. For larger rf amplitudes,\nhowever, rapid energy transfer from the field to the ion motion can occur at\nlarge trap radii, which leads to a reduction of the effective trapping volume.\nIn this regime the trap depth decreases again with increasing rf amplitude. We\ngive an analytical parameterization of the trap depth for various multipole\ntraps that allows predictions of the most favorable trapping conditions.\n", "machine_text": "\n\nWe investigate the evaporation of buffer gas-thermalized anions out of a multipole rf ion trap. The problem of anion loss from a quadrupole ion trap is studied via a Monte Carlo algorithm which describes the collisions between anions and the buffer gas. The dependence of the anion loss rate on the buffer gas pressure, trap voltage and frequency as well as on the thermal velocity of the anions is investigated. We find that anion loss is mostly due to a finite number of large amplitude vibrations which are excited by the buffer gas collisions. Our results are in good agreement with an analytical theory, which is based on the assumption of a large number of thermalized anions. The agreement of the two approaches provides a good test of the respective theories. We also found that anion loss is significantly higher for anions with a large charge to mass ratio than for anions with a small charge to mass ratio. This is explained by a Boltzmann distribution of the thermalized anions in the trap. Finally we found that anion loss is much more efficient if the anions are resonantly excited by an rf field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: GRB blastwaves through wind-shaped circumburst media. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2461, "human_text": "  Context:A significant fraction of progenitors for long gamma-ray bursts\n(GRBs) are believed to be massive stars. The investigation of long GRBs\ntherefore requires modeling the propagation of ultra-relativistic blastwaves\nthrough the circumburst medium surrounding massive stars. We simulate the\nexpansion of an isotropic, adiabatic relativistic fireball into the wind-shaped\nmedium around a massive GRB progenitor. The circumburst medium is composed of a\nrealistically stratified stellar wind zone up to its termination shock,\nfollowed by a region of shocked wind characterized by a constant density. Aims:\nWe followed the evolution of the blastwave through all its stages, including\nthe extremely rapid acceleration up to a Lorentz factor 75 flow, its\ndeceleration by interaction with stellar wind, its passage of the wind\ntermination shock, until its propagation through shocked wind. Methods: We used\nthe adaptive mesh refinement versatile advection code to follow the evolution\nof the fireball. Results: We show that the acceleration from purely thermal to\nultra-relativistic kinetic regimes is abrupt and produces an internally\nstructured blastwave. We resolved the structure of this ultra-relativistic\nshell in all stages, thanks to the adaptive mesh. We comment on the dynamical\nroles played by forward and reverse shock pairs in the phase of interaction\nwith the free stellar wind and clearly identify the complex shock-dominated\nstructure created when the shell crosses the terminal shock. Conclusion: We\nshow that in our model where the terminal shock is taken relatively close to\nthe massive star, the phase of self-similar deceleration of Blandford-McKee\ntype can only be produced in the constant density, shocked wind zone.\n", "machine_text": "\nWe present a detailed study of the interaction of a GRB with a generic circumburst medium, focusing on the case of wind-driven formations. We find that in all cases the energy injection by the GRB is negligible compared to the energy already contained in the medium. This is confirmed by detailed dynamic calculations for simple ( iso-density ) and more realistic ( varying density ) wind-driven flows. We discuss in detail the various physical mechanisms that can give rise to a range of phenomena that have been observed, and we conclude that in most cases a simple ballistic description is sufficient to explain the observations. We do, however, point out a range of phenomena that require a more detailed description, and which therefore may be signatures of an interesting physics that is specific to these media. We also point out that although the energy injection by the GRB is not large, this may not be true for small perturbations on large length scales, and we discuss a range of phenomena that may be due to this sensitivity. We also point out that the interaction of a powerful GRB with a weakly ionized medium may have interesting effects, and we discuss a range of phenomena that may arise in such a case.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Virtual photons in imaginary time: Computing exact Casimir forces via\n  standard numerical-electromagnetism techniques. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3661, "human_text": "  We describe a numerical method to compute Casimir forces in arbitrary\ngeometries, for arbitrary dielectric and metallic materials, with arbitrary\naccuracy (given sufficient computational resources). Our approach, based on\nwell-established integration of the mean stress tensor evaluated via the\nfluctuation-dissipation theorem, is designed to directly exploit fast methods\ndeveloped for classical computational electromagnetism, since it only involves\nrepeated evaluation of the Green's function for imaginary frequencies\n(equivalently, real frequencies in imaginary time). We develop the approach by\nsystematically examining various formulations of Casimir forces from the\nprevious decades and evaluating them according to their suitability for\nnumerical computation. We illustrate our approach with a simple\nfinite-difference frequency-domain implementation, test it for known geometries\nsuch as a cylinder and a plate, and apply it to new geometries. In particular,\nwe show that a piston-like geometry of two squares sliding between metal walls,\nin both two and three dimensions with both perfect and realistic metallic\nmaterials, exhibits a surprising non-monotonic ``lateral'' force from the\nwalls.\n", "machine_text": "\n\nWe present a method, based on standard numerical-electromagnetism techniques, for computing the exact Casimir force between a perfect-conducting parallel-plate capacitor and a dielectric sphere in the presence of a homogeneous, isotropic, and static magnetic field. This method is exact, numerically stable, and does not require the introduction of any auxiliary fields. The computation of the Casimir force between the plates and the dielectric sphere is performed in imaginary time. The only input quantities that are computed in real time are the standard Greens functions for the electromagnetic fields in the spatial domain. The fact that the computation is performed in imaginary time does not mean that it is an approximate computation. Rather, it means that it is a exact computation that is obtained by integrating the relevant Green's functions in imaginary time. We show that the imaginary-time Greens functions for the electric and magnetic fields can be expressed in terms of the standard Greens functions for the fields in the spatial domain. This expression enables us to use standard numerical-electromagnetism techniques to compute the imaginary-time Greens functions. It also allows us to visualize the electromagnetic fields in the spatial domain and in imaginary time. We present a numerical example that illustrates our method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A model for the Globular Cluster extreme anomalies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3401, "human_text": "  In spite of the efforts made in the latest years, still there is no\ncomprehensive explanation for the chemical anomalies of globular cluster stars.\nAmong these, the most striking is oxygen depletion, which reaches values down\nto [O/Fe]~-0.4 in most clusters, but in M13 it goes down to less than [O/Fe]~ -\n1. In this work we suggest that the anomalies are due to the super position of\ntwo different events: 1) PRIMORDIAL SELF-ENRICHMENT: this is asked to explain\nthe oxygen depletion down to a minimum value [O/Fe]~ -0.4; 2) EXTRA MIXING IN A\nFRACTION OF THE STARS ALREADY BORN WITH ANOMALOUS COMPOSITION: these objects,\nstarting with already low [O/Fe], will reduce the oxygen abundance down to the\nmost extreme values. Contrary to other models that invoke extra mixing to\nexplain the chemical anomalies, we suggest that it is active only if there is a\nfraction of the stars in which the primordial composition is not only oxygen\ndepleted, but also extremely helium rich (Y~ 0.4), as found in a few GCs from\ntheir main sequence multiplicity. We propose that the rotational evolution (and\nan associated extra mixing) of extremely helium rich stars may be affected by\nthe fact that they develop a very small or non existent molecular weight\nbarrier during the evolution. We show that extra mixing in these stars, having\ninitial chemistry that has already been CNO processed, affects mainly the\noxygen abundance, and to a much smaller extent if affects the sodium abundance.\nThe model also predicts a large fluorine depletion concomitant with the oxygen\ndepletion, and a further enhancement of the surface helium abundance, which\nreaches values close to Y=0.5 in the computed models. We stress that, in this\ntentative explanation, those stars that are primordially O--depleted, but ARE\nNOT extremely helium rich do not suffer deep extra mixing.\n", "machine_text": "\n\nWe have developed a model that can explain the extreme anomalies observed in Globular Cluster (GC) systems. Our model consists of two components: a correlation matrix element and a non-correlation matrix element. The correlation matrix element represents the correlation between a GC and its companion stars, and can be used to derive the systemic radial velocity. The non-correlation matrix element represents the non-correlated motion of the GC and can be used to derive the peculiar velocity. We show that the peculiar velocity has a lower limit of  \u223c3 km s \u2212 1 for oldGCs and a upper limit of  \u223c120 km s \u2212 1 for youngGCs. We also show that the ratio of the peculiar velocity to the systemic velocity has a uniform lower limit of  \u223c1.5 and a uniform upper limit of  \u223c5 for all GCs. Our model provides a physical explanation for the so-called extreme anomalies and predicts a universal behaviour for all GCs. We have verified our model by applying it to the analysis of the radial velocity data obtained for the globular cluster 47 Tuc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: TrES-3: A Nearby, Massive, Transiting Hot Jupiter in a 31-Hour Orbit. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2004, "human_text": "  We describe the discovery of a massive transiting hot Jupiter with a very\nshort orbital period (1.30619 d), which we name TrES-3. From spectroscopy of\nthe host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +-\n0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We\nestimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal\nvariation of our high-precision radial velocity measurements. This variation\nhas a period and phase consistent with our transit photometry. Our spectra show\nno evidence of line bisector variations that would indicate a blended eclipsing\nbinary star. From detailed modeling of our B and z photometry of the 2.5%-deep\ntransits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary\nradius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of\nthe known transiting exoplanets, facilitating studies of orbital decay and mass\nloss due to evaporation, and making it an excellent target for future studies\nof infrared emission and reflected starlight.\n", "machine_text": "\n\nWe present photometric and spectroscopic observations of the massive transiting exoplanet TrES-3 b, the outermost of the two giant planets in the tight, retrograde-orbit system TrES-3. We found that the planet's inner dayside is significantly hotter than its outer nightside, indicating that the dayside is irradiated by four point sources in addition to the central star. These sources are the three inner giant planets and the Sun, all of which are more or less edge-on to the orbit of TrES-3 b. We estimate that the planet's dayside temperature is Te \u2243 890 K, while the nightside temperature is Tn \u2243 710 K. We explain this temperature difference by heat transport via thermal radiation and spillover of the dayside atmosphere into the nightside hemisphere. We show that this mechanism can also explain the temperature difference observed for the giant planet Neptune. We discuss the implication of these results for the fate of hydrogen-rich planets such as TrES-3 b as they migrate to smaller orbits. \n\nThe giant planet TrES-3 b was discovered in 2007. It has since been determined to be in a retrograde orbit, making it the only giant planet known to have both a retrograde orbit and a tight orbit around its star. The properties of this planet have been extensively studied, but its orbital evolution is not yet understood. We have measured the dayside and nightside temperatures of this planet using photometry and spectroscopy, and found that the dayside temperature is 890 K, while the nightside temperature is only 710 K. We can explain this temperature difference using a model in which the dayside is irradiated by four point sources: the central star, the Sun, and the inner giant planets. We show that this model can also explain the temperature difference observed for the giant planet Neptune. We discuss the implications of our results for the fate of hydrogen-rich planets such as TrES-3 b as they migrate to smaller orbits.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The influence of AGN nuclear parameters on the FRI/FRII dichotomy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1891, "human_text": "  We have investigated the influence of nuclear parameters such as black hole\n(BH) mass and photoionizing luminosity on the FRI/FRII transition in a sample\nof nearby (z<0.2) 3CR radio galaxies. The sample was observed with\nmedium-resolution, optical spectroscopy and contains some galaxies with\nunpublished velocity dispersion measurements and emission-line fluxes. Measured\nvelocity dispersions are 130-340 km/s with a mean of 216 km/s. Converting to BH\nmass, we find that the BH mass distribution is identical for FRIs and FRIIs,\nwith a mean of approximately 2.5x10^8 Msun. We convert [OII] and [OIII]\nemission-line luminosities to photoionizing luminosity under the assumption\nthat the gas is ionized by the nuclear UV continuum. Most of the galaxies with\nFRI morphology and/or low-excitation emission-line spectra have progressively\nlower BH masses at lower photoionizing (and jet) luminosities. This agrees with\nthe Ledlow-Owen relation which states that the radio luminosity at the FRI/FRII\ntransition depends on the optical luminosity of the host, L_radio ~\nL_optical^1.8, because both L_radio and L_optical relate to AGN nuclear\nparameters. When recasting the Ledlow-Owen relation into BH mass versus\nphotoionizing and jet luminosity, we find that the recasted relation describes\nthe sample quite well. The FRI/FRII transition occurs at approximately an order\nof magnitude lower luminosity relative to the Eddington luminosity than the\nsoft-to-hard transition in X-ray binaries. This difference is consistent with\nthe Ledlow-Owen relation, which predicts a weak BH mass dependence in the\ntransition luminosity. We conclude that the FRI/FRII dichotomy is caused by a\ncombination of external and nuclear factors, with the latter dominating.\n", "machine_text": "\nWe present a study of the influence of nuclear parameters of active galactic nuclei (AGN) on the FRI/FRII dichotomy. We consider a large sample of active galaxies with well-studied central engines, for which we have reliable redshift information and high-quality ultraviolet (UV) data from the GALAXY 2000 survey. We find that the relative contribution of the nuclear emission to the total UV emission of the galaxy, as traced by the ratio of the nuclear to the integrated UV luminosity, is a powerful diagnostic of the FRI/FRII dichotomy. We find that the probability of a galaxy being FRI is inversely proportional to this nuclear luminosity ratio. This is consistent with the idea that an AGN with a lower nuclear luminosity is less capable of powering the luminosity of its surrounding IGM, and hence is less likely to be a member of an FRI system. We also find that the accretion rate, as traced by the ratio of the nuclear to the total (nuclear plus IGM) luminosity, is a powerful diagnostic of the friend or foe dichotomy. A higher accretion rate is significantly more likely to be associated with a foe galaxy. We discuss these results in the context of the accretion history of an AGN and the feedback from the central engine to the surrounding IGM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New possible properties of atomic nuclei investigated by non linear\n  methods: Fractal and recurrence quantification analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0903, "human_text": "  For the first time we apply the methodologies of nonlinear analysis to\ninvestigate atomic matter. We use these methods in the analysis of Atomic\nWeights and of Mass Number of atomic nuclei. Using the AutoCorrelation Function\nand Mutual Information we establish the presence of nonlinear effects in the\nmechanism of increasing mass of atomic nuclei considered as a function of the\natomic number. We find that increasing mass is divergent, possibly chaotic. We\nalso investigate the possible existence of a Power Law for atomic nuclei and,\nusing also the technique of the variogram, we conclude that a fractal regime\ncould superintend to the mechanism of increasing mass for nuclei. Finally,\nusing the Hurst exponent, evidence is obtained that the mechanism of increasing\nmass in atomic nuclei is in the fractional Brownian regime. The most\ninteresting results are obtained by using Recurrence Quantification Analysis\n(RQA). New recurrences, psudoperiodicities, self-resemblance and class of\nself-similarities are identified with values of determinism showing oscillating\nvalues indicating the presence of more or less stability during the process of\nincreasing mass of atomic nuclei. In brief, new regimes of regularities are\nidentified for atomic nuclei that deserve to be studied by future researches.\nIn particular an accurate analysis of binding energy values by nonlinear\nmethods is further required.\n", "machine_text": "\nWe have developed a new method for investigating the properties of atomic nuclei, based on the analysis of the distribution of statistical Shannon entropies associated with the emission of radiation by nuclear excited states. We show that, in addition to the well-known properties related to the standard model of atomic nuclei, our method reveals new properties, which are related to the concepts of fractal and recurrence, that we have introduced in this field for the first time. We find that the entropies distribution has a fractal structure, and that this fractal structure is related to the occurrence of recurrent patterns in the distribution of the amplitudes of the emitted radiation. Our method is based on the use of non-linear measures of statistical entropies, such as the difference between the entropies associated with the emission of radiation and the entropies associated with the excitation of the corresponding quantum states. Our results show that the new properties found are related to the violation of the commutativity and the associativity of the operations of multiplication and addition, in the set of the quantum numbers which describe the atomic nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A modified cable formalism for modeling neuronal membranes at high\n  frequencies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3759, "human_text": "  Intracellular recordings of cortical neurons in vivo display intense\nsubthreshold membrane potential (Vm) activity. The power spectral density (PSD)\nof the Vm displays a power-law structure at high frequencies (>50 Hz) with a\nslope of about -2.5. This type of frequency scaling cannot be accounted for by\ntraditional models, as either single-compartment models or models based on\nreconstructed cell morphologies display a frequency scaling with a slope close\nto -4. This slope is due to the fact that the membrane resistance is\n\"short-circuited\" by the capacitance for high frequencies, a situation which\nmay not be realistic. Here, we integrate non-ideal capacitors in cable\nequations to reflect the fact that the capacitance cannot be charged\ninstantaneously. We show that the resulting \"non-ideal\" cable model can be\nsolved analytically using Fourier transforms. Numerical simulations using a\nball-and-stick model yield membrane potential activity with similar frequency\nscaling as in the experiments. We also discuss the consequences of using\nnon-ideal capacitors on other cellular properties such as the transmission of\nhigh frequencies, which is boosted in non-ideal cables, or voltage attenuation\nin dendrites. These results suggest that cable equations based on non-ideal\ncapacitors should be used to capture the behavior of neuronal membranes at high\nfrequencies.\n", "machine_text": "\n\nA modified cable formalism for modeling neuronal membranes at high frequencies\n\nWe have developed a modified cable formalism that enables us to analyze the propagation of extracellularly applied electric fields in cables of arbitrary geometry, including cables that are terminated in neuronal membranes. Our formalism is based on a finite-element model of the cable and includes a dynamic model of the transmembrane potential in the neuronal membranes. We show that this formalism can be used to analyze the effects of geometry and spatial distributions of conductivities in cables on the extracellular signatures of neuronal membranes. In particular, we show that the cables can be treated as if all of their conducting elements were lumped together into a single element, as long as the frequency of the applied field is sufficiently high. We apply our formalism to study the extracellular signatures of cables that are terminated in neuronal membranes and that have complex geometries, and we show that these signatures can be obtained from the solution to a set of simple ordinary differential equations. We also show that our formalism can be used to investigate the effects of cable geometries on the transmission of extracellularly applied signals to the interiors of neuronal membranes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-adiabatic transport in a quantum dot turnstile. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0968, "human_text": "  We present a theoretical study of the electronic transport through a\nmany-level quantum dot driven by time-dependent signals applied at the contacts\nto the leads. If the barriers oscillate out of phase the system operates like a\nturnstile pump under a finite constant bias, as observed in the experiments of\nKouwenhoven {\\it et al.} [Phys. Rev. Lett. {\\bf 67}, 1626 (1991)]. The\ntime-dependent currents and their averages over succesive pumping periods are\ncomputed from the Keldysh formalism for tight-binding models. The calculation\nconsiders a sudden application of the pumping potentials at $t=0$ which leads\nto transient features of the time-dependent and averaged currents during the\nfirst pumping cycles which turn out to be important in the high-frequency\nregime. We show that in the transient regime the efficiency of the system as a\npump is rather poor because it mainly absorbs charge from both leads in order\nto fill the levels located below the bias window. Under a finite bias and a\nlow-frequency pumping signal the charge transferred across the system depends\non the number of levels located within the bias window. The internal charge\ndynamics and the role of energy sidebands are investigated. The so called\nsatellite peaks of the averaged current are observed also in the transient\nregime.\n", "machine_text": "\nWe investigate non-adiabatic transport in a quantum dot turnstile. We consider a broad range of initial conditions and find that the transport is universal, in the sense that the total transport can be predicted from the initial condition most distant from the turnstile. The transport is due to a combination of quantum tunnelling and thermal diffusion, the latter being particularly important for the initial transport away from the turnstile. The transport is found to be ballistic for a range of initial conditions, and the ballisticity is shown to be related to the interatomic distance in the quantum dot. Our results are consistent with the transport being due to a non-adiabatic flip of the electron between two atomic orbits in the quantum dot, resulting in a discrete energy spectrum with a gap between the two orbitals. We also found a good agreement between our results and those obtained by numerical solutions of the time-dependent Schr\u00f6dinger equation for a broad range of initial conditions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Holography in Three-dimensional Kerr-de Sitter Space with a\n  Gravitational Chern-Simons Term. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4381, "human_text": "  The holographic description of the three-dimensional Kerr-de Sitter space\nwith a gravitational Chern-Simons term is studied, in the context of dS/CFT\ncorrespondence. The space has only one (cosmological) event horizon and its\nmass and angular momentum are identified from the holographic energy-momentum\ntensor at the asymptotic infinity. The thermodynamic entropy of the\ncosmological horizon is computed directly from the first law of thermodynamics,\nwith the usual Hawking temperature, and it is found that the usual\nGibbons-Hawking entropy is modified. It is remarked that, due to the\ngravitational Chern-Simons term, (a) the results go beyond analytic\ncontinuation from AdS, (b) the maximum-mass/N-bound conjecture may be violated,\nand (c) the three-dimensional cosmology is chiral. A statistical mechanical\ncomputation of the entropy, from a Cardy-like formula for a dual CFT at the\nasymptotic boundary, is discussed. Some technical difference in the\nChern-Simons energy-momentum tensor, from literatures is remarked also.\n", "machine_text": "\n\nWe consider a semiclassical formulation of three-dimensional holography in the presence of a gravitational Chern-Simons term. We show that a general bulk gravity theory with a Chern-Simons term can be holographically described by a Chern-Weil ( Lagrangian) formulation in the original bulk theory. The main step is to show that the Chern-Simons term in the bulk theory can be identified with a Chern-Weil structure in the bulk theory. As an application, we show that the three-dimensional Einstein-Chern-Simons theory can be holographically described by a Chern-Weil formulation in the three-dimensional Kerr-de Sitter bulk space. We also comment on the difference between our holographic description and the previously known two-dimensional version.\n\nWe consider the semiclassical formulation of three-dimensional holography in the presence of a gravitational Chern-Simons term. We show that a general bulk gravity theory with a Chern-Simons term can be holographically described by a Chern-Weil ( Lagrangian) formulation in the original bulk theory. The main step is to show that the Chern-Simons term in the bulk theory can be identified with a Chern-Weil structure in the bulk theory. As an application, we show that the three-dimensional Einstein-Chern-Simons theory can be holographically described by a Chern-Weil formulation in the three-dimensional Kerr-de Sitter bulk space. We also comment on the difference between our holographic description and the previously known two-dimensional version.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The nature of a broad line radio galaxy: Simultaneous RXTE and Chandra\n  HETG observations of 3C 382. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2756, "human_text": "  We present the results from simultaneous chandra and rxte observations of the\nX-ray bright Broad-Line Radio Galaxy (BLRG) 3C 382. The long (120 ks) exposure\nwith chandra HETG allows a detailed study of the soft X-ray continuum and of\nthe narrow component of the Fe Kalpha line. The rxte PCA data are used to put\nan upper limit on the broad line component and constrain the hard X-ray\ncontinuum. A strong soft excess below 1 keV is observed in the time-averaged\nHETG spectrum, which can be parameterized with a steep power law or a thermal\nmodel. The flux variability at low energies indicates that the origin of the\nsoft excess cannot be entirely ascribed to the circumnuclear diffuse emission,\ndetected by chandra on scales of 20-30 arcsec (22-33 kpc). A narrow (sigma<90\neV) Fe Kalpha line (with EW< 100 eV) is observed by the chandra HEG. Similar\nvalues for the line parameters are measured by the rxte PCA, suggesting that\nthe contribution from a broad line component is negligible. The fact that the\nexposure is split into two observations taken three days apart allows us to\ninvestigate the spectral and temporal evolution of the source on different\ntimescales. Significant flux variability associated with spectral changes is\nobserved on timescales of hours and days. The spectral variability is similar\nto that observed in radio-quiet AGN ruling out a jet-dominated origin of the\nX-rays.\n", "machine_text": "\n\nWe present simultaneous observations of the broad line radio galaxy 3C 382 with the Chandra X-ray Observatory and the Rossi X-ray Timing Explorer. We find that the accretion phase of the blazar is much longer than previously estimated on the basis of optical observations, lasting at least 2.2 kyr. The observed phenomenology is consistent with a smoothly increasing flux triggered at random intervals with a distribution of phases in the binary system. We estimate the accretion rate to be  \u223c 10^( \u2212 2) M_(\u2299) yr^( \u2212 1) and the mass of the black hole to be  \u223c 6.6 kM_(\u2299). We conclude that the accretion phase of blazars is not constant, but rather it is modulated, possibly by the orbital period. We discuss several possibilities for the observed phenomenology, including a model in which the accretion rate is regulated by the orbital period, with many short orbital periods, but accretion episodes of constant duration. The accretion phase may thus be understood as a superposition of many shorter periods, with each period being individually stable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Exact half-BPS Type IIB interface solutions I: Local solution and\n  supersymmetric Janus. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0022, "human_text": "  The complete Type IIB supergravity solutions with 16 supersymmetries are\nobtained on the manifold $AdS_4 \\times S^2 \\times S^2 \\times \\Sigma$ with\n$SO(2,3) \\times SO(3) \\times SO(3)$ symmetry in terms of two holomorphic\nfunctions on a Riemann surface $\\Sigma$, which generally has a boundary. This\nis achieved by reducing the BPS equations using the above symmetry\nrequirements, proving that all solutions of the BPS equations solve the full\nType IIB supergravity field equations, mapping the BPS equations onto a new\nintegrable system akin to the Liouville and Sine-Gordon theories, and mapping\nthis integrable system to a linear equation which can be solved exactly.\nAmongst the infinite class of solutions, a non-singular Janus solution is\nidentified which provides the AdS/CFT dual of the maximally supersymmetric\nYang-Mills interface theory discovered recently. The construction of general\nclasses of globally non-singular solutions, including fully back-reacted $AdS_5\n\\times S^5$ and supersymmetric Janus doped with D5 and/or NS5 branes, is\ndeferred to a companion paper.\n", "machine_text": "\n\nWe construct a family of BPS type IIB interfaces that generalize the construction of junction conditions at BPS type IIA interfaces. These are local solutions of the BPS type IIB equation of motion that are in general exactly half-BPS, and thus may be regarded as Janus solutions in the sense of Bergh and STagg. The construction is motivated by the desire to have a simple model of a BPS interface that is always half-BPS, even when the total BPS charge is odd. This is in contrast to the standard BPS type IIA junction conditions, which are not half-BPS when the total BPS charge is odd. The family of BPS type IIB interfaces we construct has as its limiting case the BPS type IIA junction conditions, and in particular is related to the construction of junction conditions via BPS type IIA pity LPs. We consider the simplest case of a family of BPS type IIB interfaces that is symmetric under the exchange of the ghost and anti-ghost variables. This is the case in which the BPS type IIB interfaces have the structure of BPS type IIA interfaces with an extra term that is the square of the ghost field. We show that such BPS type IIB interfaces can be obtained as the limit of a family of supersymmetric Janus solutions of the BPS type IIB equation of motion, and compute their singularities. We show that the singularities have the structure of anti-self-duality. We then consider a generalization of our construction to the case in which the BPS type IIB interfaces are not symmetric under the exchange of the ghost and anti-ghost variables.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Homogenized spectral problems for exactly solvable operators:\n  asymptotics of polynomial eigenfunctions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2822, "human_text": "  Consider a homogenized spectral pencil of exactly solvable linear\ndifferential operators $T_{\\la}=\\sum_{i=0}^k Q_{i}(z)\\la^{k-i}\\frac\n{d^i}{dz^i}$, where each $Q_{i}(z)$ is a polynomial of degree at most $i$ and\n$\\la$ is the spectral parameter. We show that under mild nondegeneracy\nassumptions for all sufficiently large positive integers $n$ there exist\nexactly $k$ distinct values $\\la_{n,j}$, $1\\le j\\le k$, of the spectral\nparameter $\\la$ such that the operator $T_{\\la}$ has a polynomial eigenfunction\n$p_{n,j}(z)$ of degree $n$. These eigenfunctions split into $k$ different\nfamilies according to the asymptotic behavior of their eigenvalues. We\nconjecture and prove sequential versions of three fundamental properties: the\nlimits $\\Psi_{j}(z)=\\lim_{n\\to\\infty} \\frac{p_{n,j}'(z)}{\\la_{n,j}p_{n,j}(z)}$\nexist, are analytic and satisfy the algebraic equation $\\sum_{i=0}^k Q_{i}(z)\n\\Psi_{j}^i(z)=0$ almost everywhere in $\\bCP$. As a consequence we obtain a\nclass of algebraic functions possessing a branch near $\\infty\\in \\bCP$ which is\nrepresentable as the Cauchy transform of a compactly supported probability\nmeasure.\n", "machine_text": "\nWe consider the problem of finding a basis of polynomial eigenvectors for a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space.\n\nWe consider the problem of finding a basis of polynomial eigenvectors for a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space.\n\nWe consider the problem of finding a basis of polynomial eigenvectors for a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dirichlet sigma models and mean curvature flow. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3985, "human_text": "  The mean curvature flow describes the parabolic deformation of embedded\nbranes in Riemannian geometry driven by their extrinsic mean curvature vector,\nwhich is typically associated to surface tension forces. It is the gradient\nflow of the area functional, and, as such, it is naturally identified with the\nboundary renormalization group equation of Dirichlet sigma models away from\nconformality, to lowest order in perturbation theory. D-branes appear as fixed\npoints of this flow having conformally invariant boundary conditions. Simple\nrunning solutions include the paper-clip and the hair-pin (or grim-reaper)\nmodels on the plane, as well as scaling solutions associated to rational (p, q)\nclosed curves and the decay of two intersecting lines. Stability analysis is\nperformed in several cases while searching for transitions among different\nbrane configurations. The combination of Ricci with the mean curvature flow is\nexamined in detail together with several explicit examples of deforming curves\non curved backgrounds. Some general aspects of the mean curvature flow in\nhigher dimensional ambient spaces are also discussed and obtain consistent\ntruncations to lower dimensional systems. Selected physical applications are\nmentioned in the text, including tachyon condensation in open string theory and\nthe resistive diffusion of force-free fields in magneto-hydrodynamics.\n", "machine_text": "\n\nWe consider the asymptotic behavior of solutions to the heat equation with a nonlinear boundary condition, as the initial data tends to a Dirichlet boundary condition. We show that, in a natural class of examples, the solutions tend to a solution of the Dirichlet sigma model with a nonlinear boundary condition. The main tool is the version of theNash-Moser theorem for a Dirichlet boundary condition. The analysis also provides a motivation for the study of a class of partial differential equations which includes the heat equation with a nonlinear boundary condition, the Navier-Stokes equation with a nonlinear boundary condition and the Euler equations with a transversally varying boundary condition. It also suggests an approach to the study of the limiting behavior of solutions to these equations as the initial data tends to a Dirichlet boundary condition.\n\nThe results in this paper are based on the work of the author and M. Zalaudek. The authors would like to thank M. Zalaudek for many useful discussions and for suggesting this problem. The author would also like to thank the Austrian Science Fund (FWF) for financial support under the project P18007.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The KATRIN sensitivity to the neutrino mass and to right-handed currents\n  in beta decay. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.393, "human_text": "  The aim of the KArlsruhe TRItium Neutrino experiment KATRIN is the\ndetermination of the absolute neutrino mass scale down to 0.2 eV, with\nessentially smaller model dependence than from cosmology and neutrinoless\ndouble beta decay. For this purpose, the integral electron energy spectrum is\nmeasured close to the endpoint of molecular tritium beta decay. The endpoint,\ntogether with the neutrino mass, should be fitted from the KATRIN data as a\nfree parameter. The right-handed couplings change the electron energy spectrum\nclose to the endpoint, therefore they have some effect also to the precise\nneutrino mass determination. The statistical calculations show that, using the\nendpoint as a free parameter, the unaccounted right-handed couplings\nconstrained by many beta decay experiments can change the fitted neutrino mass\nvalue, relative to the true neutrino mass, by not larger than about 5-10 %.\nUsing, incorrectly, the endpoint as a fixed input parameter, the above change\nof the neutrino mass can be much larger, order of 100 %, and for some cases it\ncan happen that for large true neutrino mass value the fitted neutrino mass\nsquared is negative. Publications using fixed endpoint and presenting large\nright-handed coupling effects to the neutrino mass determination are not\nrelevant for the KATRIN experiment.\n", "machine_text": "\nThe KATRIN sensitivity to the neutrino mass and to right-handed currents in beta decay\n  The neutrino mass is a violation of the Standard Model (SM) and can be probed by the measure-ment of the ratio \ue0c1Meb/\ue0c1Meu, where e and u are the SM generations of elementary fermions. The smallest such ratio is expected to be found in beta decays with a very light neutrino mass and a heavy partner (e.g. a charged lepton). The current best prediction for the neutrino mass is \ue0c1Mnu \u223c 1 eV. A large excess of events in the final state with two energetic electrons in the KATRIN experiment would unambiguously indicate the presence of a non-SM neutrino mass \ue0c1Mnu > 1 eV.\n  A non-SM right-handed neutrino current in the beta decay could be searched for by looking for a significant excess of events with a final state containing two electrons and two jets, where the two electrons are produced from the decay of a charged lepton. The search strategy is to use the fact that the flavor changing processes are strictly forbidden in the SM, therefore any significant departure from the SM expectation would be a clear sign of new physics.\n  We show that the proposed KATRIN experiment is sensitive to a right-handed neutrino current in the beta decay, if the neutrino mass is \ue0c1Mnu > 10 GeV. A small excess of events with two electrons and two jets would already be an indication of a non-SM neutrino mass \ue0c1Mnu > 10 GeV.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Role of the rho meson in the description of pion electroproduction\n  experiments at JLab. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1844, "human_text": "  We study the p(e,e' pi+)n reaction in the framework of an effective\nLagrangian approach including nucleon, pi and rho meson degrees of freedom and\nshow the importance of the rho-meson t-pole contribution to sigmaT, the\ntransverse part of cross section. We test two different field representations\nof the rho meson, vector and tensor, and find that the tensor representation of\nthe rho meson is more reliable in the description of the existing data. In\nparticular, we show that the rho-meson t-pole contribution, including the\ninterference with an effective non-local contact term, sufficiently improves\nthe description of the recent JLab data at invariant mass W less 2.2 GeV and Q2\nless 2.5 GeV2/c2. A ``soft'' variant of the strong piNN and rhoNN form factors\nis also found to be compatible with these data. On the basis of the successful\ndescription of both the sigmaL and sigmaT parts of the cross section we discuss\nthe importance of taking into account the sigmaT data when extracting the\ncharge pion form factor Fpi from sigmaL.\n", "machine_text": "\nWe present a brief summary of our work on the role of the rho meson in the description of pion electroproduction experiments at JLab. We discuss the motivation for our research, the key ideas and methodology used, the results obtained, the problem our work attempts to solve, and any practical or theoretical applications of our findings or implications for future research. \n\nOur work aims to better understand the role of the rho meson in the description of pion electroproduction experiments at JLab. We use a formalism that includes the rho meson and the pion in the final state. We fit the data to the theory in a systematic way, and we obtain a good description of the data, which allows us to extract the physical parameters that are needed to understand the pion electroproduction process. \n\nOur work makes use of the fact that the rho meson is an unstable particle that can decay to a variety of final states. We use a formalism that includes the rho meson and the pion in the final state. We fit the data to the theory in a systematic way, and we obtain a good description of the data, which allows us to extract the physical parameters that are needed to understand the pion electroproduction process. \n\nWe have been able to extract the physical parameters that are needed to understand the pion electroproduction process. Our results are in good agreement with the predictions of the Standard Model, and we have been able to constrain some of the theoretical parameters. We have also been able to make predictions for future experiments. \n\nOur work has implications for the future of pion electroproduction experiments. We have been able to make predictions for future experiments, and we have also been able to constrain some of the theoretical parameters. Our work is important for the understanding of the pion electroproduction process, and it has practical applications for the design of future experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraining the Geometry of the Neutron Star RX J1856.5-3754. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4543, "human_text": "  RX J1856.5-3754 is one of the brightest, nearby isolated neutron stars, and\nconsiderable observational resources have been devoted to its study. In\nprevious work, we found that our latest models of a magnetic, hydrogen\natmosphere matches well the entire spectrum, from X-rays to optical (with\nbest-fitting neutron star radius R=14 km, gravitational redshift z_g~0.2, and\nmagnetic field B~4x10^12 G). A remaining puzzle is the non-detection of\nrotational modulation of the X-ray emission, despite extensive searches. The\nsituation changed recently with XMM-Newton observations that uncovered 7 s\npulsations at the 1% level. By comparing the predictions of our model (which\nincludes simple dipolar-like surface distributions of magnetic field and\ntemperature) with the observed brightness variations, we are able to constrain\nthe geometry of RX J1856.5-3754, with one angle < 6 deg and the other angle =\n20-45 deg, though the solutions are not definitive given the observational and\nmodel uncertainties. These angles indicate a close alignment between the\nrotation and magnetic axes or between the rotation axis and the observer. We\ndiscuss our results in the context of RX J1856.5-3754 being a normal radio\npulsar and a candidate for observation by future X-ray polarization missions\nsuch as Constellation-X or XEUS.\n", "machine_text": "\nWe present new radio timing observations of the isolated neutron star RX J1856.5-3754. We find that the system is best described by a Lorentzian orbit with a 6.6 day period, in disagreement with previous suggestions of a longer period. This 6.6 day period is nearly identical to that of the well-studied low-mass X-ray binary 4U0142-69, for which we present a detailed comparison. We find no evidence of any long-term timing variations, but we do observe a secular trend in the data which may be due to small-scale timing variations on timescales of years. We present a formalism which can be used to extract the contribution of such variations to the measured time derivative of the orbital elements. Our best-fit model requires that the accretion disc be eccentric, which is inconsistent with the assumption of a circular orbit, and we discuss possible geometries which could give rise to this. We also present observations of the X-ray and radio brightnesses as a function of orbital phase, which together with the timing observations, constrain the geometry of the accretion disc. We conclude that the disc is unlikely to be in a bipolar geometry, and we discuss the implications of this for the stability of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A discrete computer network model with expanding dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0855, "human_text": "  Complex networks with expanding dimensions are studied, where the networks\nmay be directed and weighted, and network nodes are varying in discrete time in\nthe sense that some new nodes may be added and some old nodes may be removed\nfrom time to time. A model of such networks in computer data transmission is\ndiscussed. Each node on the network has fixed dimensionality, while the\ndimension of the whole network is defined by the total number of nodes. Based\non the spectacular properties of data transmission on computer networks, some\nnew concepts of stable and unstable networks differing from the classical\nLyapunov stability are defined. In particular, a special unstable network\nmodel, called devil network, is introduced and discussed. It is further found\nthat a variety of structures and connection weights affects the network\nstability substantially. Several criteria on stability, instability, and devil\nnetwork are established for a rather general class of networks, where some\nconditions are actually necessary and sufficient. Mathematically, this paper\nmakes a first attempt to rigorously formulate a fundamental issue of modeling\ndiscrete linear time-varying systems with expanding dimensions and study their\nbasic stability property.\n", "machine_text": "\n\nWe consider a simple model of a discrete computer network in which the underlying graph changes with time, as nodes are added to and deleted from the network. We suppose that the addition and deletion of nodes are independent events, and that the underlying graph is a random graph which is generated according to a given probability distribution. Our main results relate the degree distribution of the network at time t to the degree distribution of the network at time t+1. In particular, we show that if the underlying graph is a random graph which is generated according to a given probability distribution, then the degree distribution at time t+1 is approximately multinomial, with parameters which are related to the degree distribution at time t and the probability distribution which is used to generate the underlying graph. As a by-product of our main results, we show that if the underlying graph is a random graph which is generated according to a given probability distribution, then the expected number of links per node is independent of the number of nodes in the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamic response of Ag monolayers adsorbed on Au(100) upon an\n  oscillatory variation of the chemical potential: A Monte Carlo simulation\n  study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.447, "human_text": "  Based on the fact that the underpotential electrochemical deposition of Ag\natoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at\nwell-defined values of the (coexistence) chemical potential ($\\mu_{coex}$), we\nperformed extensive simulations aimed at investigating the hysteretic dynamic\nbehavior of the system close to coexistence upon the application of a periodic\nsignal of the form $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau) $, where\n$\\mu_{o}$ and $\\tau$ are the amplitude and the period of the sweep,\nrespectively. For relatively short periods and small enough amplitudes the\nsystem becomes trapped either at low or high Ag coverage states, as evidenced\nby recording hysteresis loops. This scenario is identified as dynamically\nordered states (DOS), such that the relaxation time $(\\tau_{relax})$ of the\ncorresponding metastable state obeys $\\tau_{relax} > \\tau $. On the other hand,\nby properly increasing $\\mu_{o}$ or/and $\\tau$, one finds that the $Ag$\ncoverage gently follows the external drive (here $\\tau_{relax} < \\tau $) and\nthe system is said to enter into dynamically disordered states (DDS), where\nhysteresis loops show almost symmetric limiting cycles. This symmetry breaking\nbetween limiting cycles driven by an external signal is discussed in terms of\nthe concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and\nDDS, similar to those encountered when a magnetic system is placed in the\npresence of a variable external magnetic field. However, a careful finite-size\nscaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system\ndoes not exhibit true second-order phase transitions but rather a crossover\nbehavior between states. A diagram showing the location of the ordered and\ndisordered states in the $\\mu$ versus $\\tau$ plane is obtained and discussed.\n", "machine_text": "\nWe present a Monte Carlo simulation study of the dynamic response of Ag adsorbates on Au(100) to an oscillatory variation of the chemical potential. We find that the distribution of the adsorbates is affected in a manner that depends on the magnitude of the amplitude of the chemical potential variation as well as on the frequency with which it is varied. Our results show that the distribution of the adsorbates becomes more uniform as the amplitude is increased, but that the standard deviation of the distribution increases as the frequency is increased. We also find that the dynamic response is affected by the history of the variation of the chemical potential, with the distribution of the adsorbates becoming more uniform if the variation is started from a state in which the adsorbates are highly ordered, and becoming more disordered if the variation is started from a state in which the adsorbates are highly disordered. We discuss our results in the framework of a simple model in which the adsorbates are treated as hard disks that can rotate in response to an external torque.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High-energy threshold reaction rates on 0.8 GeV proton-irradiated thick\n  Pb-target. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1024, "human_text": "  This works presents results of activation-aided determination of threshold\nreaction rates in 92 209Bi, natPb, 197Au, 181Ta, 169Tm, natIn, 93Nb, 64Zn,\n65Cu, 63Cu, 59Co, 19F, and 12C samples and in 121 27Al samples. All the samples\nwere aligned with the proton beam axis inside and outside the demountable 92-cm\nthick Pb target of 15-cm diameter assembled of 23 4-cm thick discs. The samples\nwere placed on 12 target disks to reproduce the long axis distribution of\nprotons and neutrons. In June 2006, the target was exposed for 18 hours to a\n800-MeV proton beam extracted from the ITEP U-10 accelerator. The proton\nfluence and the proton beam shape were determined using the 27Al(p,x)7Be\nmonitor reaction. The reaction rates were determined by the direct\ngamma-spectrometry techniques. In total, 1196 gamma-spectra have been measured,\nand about 1500 reaction rates determined. The measured reaction rates were\nsimulated by the MCNPX code using the following databases: ENDF/B6 for neutrons\nbelow 20 MeV, MENDL2 for 20-100 MeV neutrons, and MENDL2P for proton cross\nsections up to 200 MeV. An acceptable agreement of simulations with\nexperimental data has been found.\n", "machine_text": "\nWe present here the results of a comprehensive study of the high-energy threshold reaction rates on a 0.8 GeV proton-irradiated thick Pb target. The main goal of the work is to establish the viability of using such an irradiated target as a source of high-energy X-rays in an X-ray generator. The study consists of measurements of the X-ray yield as a function of the accelerating voltage in an X-ray tube using such a target and of the resulting high-energy threshold reaction rates. We observe a clear and strong peak in the X-ray yield at an accelerating voltage of 60 kV. The corresponding threshold reaction rate is 1.5 \u00b7 10-6 cm2s-1. We also find that the threshold reaction rate increases rapidly with the accelerating voltage, in spite of the fact that the nuclear reactions that are responsible for the X-ray emission become less and less efficient as the proton energy increases. This is explained by the fact that at high accelerating voltages the tube geometry becomes more and more favourable for the emission of high-energy X-rays. We discuss our results in the framework of a simple theoretical model, according to which the X-ray yield is related to the nuclear track density in the target. We estimate the track density in our target and find that it is in reasonable agreement with our model predictions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information diffusion epidemics in social networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0641, "human_text": "  The dynamics of information dissemination in social networks is of paramount\nimportance in processes such as rumors or fads propagation, spread of product\ninnovations or \"word-of-mouth\" communications. Due to the difficulty in\ntracking a specific information when it is transmitted by people, most\nunderstanding of information spreading in social networks comes from models or\nindirect measurements. Here we present an integrated experimental and\ntheoretical framework to understand and quantitatively predict how and when\ninformation spreads over social networks. Using data collected in Viral\nMarketing campaigns that reached over 31,000 individuals in eleven European\nmarkets, we show the large degree of variability of the participants' actions,\ndespite them being confronted with the common task of receiving and forwarding\nthe same piece of information. This have a profound effect on information\ndiffusion: Firstly, most of the transmission takes place due to super-spreading\nevents which would be considered extraordinary in population-average models.\nSecondly, due to the different way individuals schedule information\ntransmission we observe a slowing down of the spreading of information in\nsocial networks that happens in logarithmic time. Quantitative description of\nthe experiments is possible through an stochastic branching process which\ncorroborates the importance of heterogeneity. Since high variability of both\nthe intensity and frequency of human responses are found in many other\nactivities, our findings are pertinent to many other human driven diffusion\nprocesses like rumors, fads, innovations or news which has important\nconsequences for organizations management, communications, marketing or\nelectronic social communities.\n", "machine_text": "\nWe study the problem of information diffusion in social networks. We define an information diffusion epidemic as a rapid and extensive propagation of information in a social network. We identify three basic mechanisms for the diffusion of information: local updating, global updating, and error propagation. We study the effect of these mechanisms on the speed of information diffusion and on the spatial and temporal patterns of diffusion. In particular, we show that the speed of information diffusion increases with the density of the social network, but it decreases with the degree of the social network. We find that the local updating mechanism is the most important one in small social networks, while the global updating mechanism is the most important one in large social networks. We also study the spatial and temporal patterns of information diffusion, and we find that they can be explained by a simple model based on the Hopfield model. Finally, we present a simple model of information diffusion that is consistent with the main results of our study.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near- and Far-Infrared Counterparts of Millimeter Dust Cores in the Vela\n  Molecular Ridge Cloud D. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1228, "human_text": "  The aim of this paper is to identify the young protostellar counterparts\nassociated to dust millimeter cores of the Vela Molecular Ridge Cloud D through\nnew IR observations (H_2 narrow-band at 2.12 micron and N broad band at 10.4\nmicron) along with an investigation performed on the existing IR catalogues.\nThe association of mm continuum emission with infrared sources from catalogues\n(IRAS, MSX, 2MASS), JHK data from the literature and new observations, has been\nestablished according to spatial coincidence, infrared colours and spectral\nenergy distributions. Only 7 out of 29 resolved mm cores (and 16 out of the 26\nunresolved ones) do not exhibit signposts of star formation activity. The other\nones are clearly associated with: far-IR sources, H_2 jets or near-IR objects\nshowing a high intrinsic colour excess. The distribution of the spectral\nindices pertaining to the associated sources is peaked at values typical of\nClass I objects, while three objects are signalled as candidates Class 0\nsources. We remark the high detection rate (30%) of H_2 jets driven by sources\nlocated inside the mm-cores. They appear not driven by the most luminous\nobjects in the field, but rather by less luminous objects in young clusters,\ntestifying the co-existence of both low- and intermediate-mass star formation.\nThe presented results reliably describe the young population of VMR-D. However,\nthe statistical evaluation of activity vs inactivity of the investigated cores,\neven in good agreement with results found for other star forming regions, seems\nto reflect the limiting sensitivity of the available facilities rather than any\nproperty intrinsic to the mm-condensations.\n", "machine_text": "\n\nWe present a search for optically thick dust cores in the Vela Molecular Ridge Cloud D by combining near-infrared and far-infrared images obtained with the Hubble Space Telescope. We find seven core candidates, four of which are associated with the oxygen rich shocked molecular hydrogen sources in the region. One of these cores, in the source VMR D1, contains an optically thick core with a mass of about 15 M . The core is nearly axisymmetric and has a well-defined boundary. It is embedded in a much larger and more extended core of optically thin gas. We discuss this core in the context of models for the formation of massive cores and the termination of star formation in molecular clouds.\n\nWe present a new method for finding optically thick dust cores in molecular clouds. We search for the counterparts of the dust cores in the near-infrared and far-infrared. We find that the far-infrared images are best suited for this purpose because they are insensitive to small temperature variations in the gas. In the Vela Molecular Ridge Cloud D we find a strong correlation between the location of the shocked molecular hydrogen sources and the position of the optically thick cores. We present a model in which the massive cores are formed through the accretion of small cores along the streamline of the supersonic turbulence. The model predicts that massive cores will be found in association with the sources, as we observe in VMR D1. We discuss the implication of this model for the termination of star formation in molecular clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Separability Criterion for multipartite quantum states based on the\n  Bloch representation of density matrices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3942, "human_text": "  We give a new separability criterion, a necessary condition for separability\nof $N$-partite quantum states. The criterion is based on the Bloch\nrepresentation of a $N$-partite quantum state and makes use of multilinear\nalgebra, in particular, the matrization of tensors. Our criterion applies to\n{\\it arbitrary} $N$-partite quantum states in\n$\\mathcal{H}=\\mathcal{H}^{d_1}\\otimes \\mathcal{H}^{d_2} \\otimes ... \\otimes\n\\mathcal{H}^{d_N}.$ The criterion can test whether a $N$-partite state is\nentangled and can be applied to different partitions of the $N$-partite system.\nWe provide examples that show the ability of this criterion to detect\nentanglement. We show that this criterion can detect bound entangled states. We\nprove a sufficiency condition for separability of a 3-partite state,\nstraightforwardly generalizable to the case $N > 3,$ under certain condition.\nWe also give a necessary and sufficient condition for separability of a class\nof $N$-qubit states which includes $N$-qubit PPT states.\n", "machine_text": "\n\nWe introduce a separability criterion for multipartite quantum states based on the Bloch representation of density matrices. The motivation for this work is the fact that, while the separability criterion for bipartite quantum states is well-known and widely used, a similar criterion for multipartite states is not available, despite the fact that such states occur naturally in many physical systems. The key idea is to use the Bloch representation to decompose a density matrix into a direct sum of simpler density matrices, each of which is either completely separable or at most a singlet state. The methodology is to use the Jordan decomposition to reduce the density matrix to a matrix with only diagonal blocks, which can then be further reduced to a direct sum of blocks that are either completely separable or at most a singlet state. The results obtained are that the proposed criterion is satisfied by any multipartite state that is either completely separable or at most a singlet state. The problem the work attempts to solve is to provide a separability criterion for multipartite quantum states that is as simple and straightforward as the criterion for bipartite states. The practical application of the work is that it provides a way to test whether a given multipartite state is separable or not, which could be useful in the study of multipartite quantum systems. The theoretical application of the work is that it provides a way to classify multipartite quantum states according to their level of separability, which could be useful in the study of the properties of quantum systems with more than two participants.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Imaging the Cosmic Matter Distribution using Gravitational Lensing of\n  Pregalactic HI. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0849, "human_text": "  21-cm emission from neutral hydrogen during and before the epoch of cosmic\nreionisation is gravitationally lensed by material at all lower redshifts.\nLow-frequency radio observations of this emission can be used to reconstruct\nthe projected mass distribution of foreground material, both light and dark. We\ncompare the potential imaging capabilities of such 21-cm lensing with those of\nfuture galaxy lensing surveys. We use the Millennium Simulation to simulate\nlarge-area maps of the lensing convergence with the noise, resolution and\nredshift-weighting achievable with a variety of idealised observation\nprogrammes. We find that the signal-to-noise of 21-cm lens maps can far exceed\nthat of any map made using galaxy lensing. If the irreducible noise limit can\nbe reached with a sufficiently large radio telescope, the projected convergence\nmap provides a high-fidelity image of the true matter distribution, allowing\nthe dark matter halos of individual galaxies to be viewed directly, and giving\na wealth of statistical and morphological information about the relative\ndistributions of mass and light. For instrumental designs like that planned for\nthe Square Kilometer Array (SKA), high-fidelity mass imaging may be possible\nnear the resolution limit of the core array of the telescope.\n", "machine_text": "\n\nWe present a new method for constructing a three-dimensional map of the distribution of matter in the Universe, based on the gravitational lensing of the hydrogen (HI) radio galaxies. The method is independent of the galaxies' redshifts, but requires a redshift-dependent calibration of the lensing effect. We have constructed a catalog of 30,000 galaxies in a redshift range of 1 - 2, and use this catalog to calibrate the lensing effect. We show that the method is able to detect the matter distribution in a range of scales from clusters to super clusters, provided that the clusters are located in front of the galaxies. We demonstrate that the method is sensitive to the matter distribution in a range of concentrations from 10 - 10^2 cm^-3. We show that the clusters detected by our method are consistent with the clusters found by the current cluster detection methods. We estimate the statistical significance of our detection, and compare it to the current cluster detection methods. We also discuss the systematic errors in our method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Comment on the statistical analysis in \"A new experimental limit for the\n  stability of the electron\" by H.V. Klapdor-Kleingrothaus, I.V. Krivosheina\n  and I.V. Titkova. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2047, "human_text": "  We point out the evident errors in statistical analysis of the data,\nperformed by Klapdor-Kleingrothaus et al in recently published paper to\nestablish a limit on the stability of electron with respect to the decay into\n$\\nu+\\gamma$. We performed the reestimation of the sensitivity of the\nexperimental setups to the 256 keV gamma emitted in the hypothetical electron\ndecay, and show that in [1] the limits on the electron stability and charge\nnonconservation parameter $\\epsilon_{e\\nu\\gamma}^{2}$ are overestimated by at\nleast a factor of 5. We have revealed evident errors in the statistical\nanalysis, performed by Klapdor-Kleingrothaus et al in a recently published\npaper [1] to establish a limit on the stability of electron with respect to the\ndecay into $\\nu+\\gamma$. The performed reestimation of the sensitivity of the\nexperimental setups to the 256 keV gamma emitted in the hypothetical electron\ndecay, has shown that the limits on the electron stability and charge\nnonconservation parameter $\\epsilon_{e\\nu\\gamma}^{2}$ presented in [1], have\nbeen overestimated by at least a factor of 5.\n", "machine_text": "\nWe comment on the statistical analysis in \"A new experimental limit for the stability of the electron\" by H.V. Klapdor-Kleingrothaus, I.V. Krivosheina and I.V. Titkova. We point out that the criterion of the stability of the electron proposed in this work is not equivalent to the usual definition of the electron stability. The authors introduce the additional condition that the energy of the electron should be minimal not only with respect to the entire potential energy surface, but also with respect to the space of the functions which are regular in the regions of the atomic nuclei and the electrons. As a result the usual definition of the electron stability is not satisfied and the obtained limit for the stability of the electron is larger than the corresponding limit obtained by using the usual definition. The work of the authors is an example of the application of the false logic in the statistical analysis. The obtained limit for the stability of the electron does not correspond to the physically possible values of the electron stability and has no physical meaning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Massive gravity and structure formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1301, "human_text": "  We study the growth of cosmological perturbations in the model of\nLorentz-violating massive gravity. The Friedman equation in this model acquires\nan unconventional term due to the Lorentz-breaking condensates which has the\nequation of state w = -1 / (3 gamma) with gamma being a free parameter taking\nvalues outside of the range [0,1/3]. Apart from the standard contributions, the\nperturbations above the Friedmann background contain an extra piece which is\nproportional to an arbitrary function theta(x) of the space coordinates. This\nfunction appears as an integration constant and corresponds to a\nnon-propagating scalar mode which may, however, become dynamical with the\naccount of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1\nthe ``anomalous'' perturbations grow slower than the standard ones and thus the\nmodel is compatible with observations. Whether the model is experimentally\nacceptable at other values of \\gamma depends on the value of the function\ntheta(x) at the beginning of the radiation-dominated epoch.\n", "machine_text": "\nWe consider massive gravity in the regime where the asymptotic speed of propagation of gravity waves is less than the speed of light. Such a regime can be found by using an auxiliary field theory in which the massive gravity is described by a gauge theory with a non-minimally coupled vector field. In this formalism the massively gravity is effectively described by a pure gravity theory with a structure constant which takes a negative value and with a non-vanishing cosmological constant. This description has a clear physical interpretation: massive gravity is described by an effective four-dimensional theory which contains a two-dimensional gravity theory with a structure constant taking a negative value and with a non-vanishing cosmological constant, coupled to a two-dimensional Yang-Mills theory with a non-minimally coupled vector field. We show that this effective theory describes the same physical system as the massive gravity in the regime where the asymptotic speed of propagation of gravity waves is less than the speed of light. We then use this effective theory to study the early structure formation in the universe. We find that the massive gravity structure formation is different from the pure gravity structure formation, and the massive gravity structure formation is described by a simpler model in which the evolution is determined by the two-dimensional gravity theory with a structure constant taking a negative value and with a non-vanishing cosmological constant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Cosmic Code Comparison Project. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.127, "human_text": "  Current and upcoming cosmological observations allow us to probe structures\non smaller and smaller scales, entering highly nonlinear regimes. In order to\nobtain theoretical predictions in these regimes, large cosmological simulations\nhave to be carried out. The promised high accuracy from observations make the\nsimulation task very demanding: the simulations have to be at least as accurate\nas the observations. This requirement can only be fulfilled by carrying out an\nextensive code validation program. The first step of such a program is the\ncomparison of different cosmology codes including gravitation interactions\nonly. In this paper we extend a recently carried out code comparison project to\ninclude five more simulation codes. We restrict our analysis to a small\ncosmological volume which allows us to investigate properties of halos. For the\nmatter power spectrum and the mass function, the previous results hold, with\nthe codes agreeing at the 10% level over wide dynamic ranges. We extend our\nanalysis to the comparison of halo profiles and investigate the halo count as a\nfunction of local density. We introduce and discuss ParaView as a flexible\nanalysis tool for cosmological simulations, the use of which immensely\nsimplifies the code comparison task.\n", "machine_text": "\nThe Cosmic Code Comparison Project is a collaboration between the Department of Energy's Lawrence Berkeley National Laboratory and the Institute for Code comparison in Cosmology and Astrophysics at the University of Chicago. The goal of this project is to compare the cosmic microwave background radiation data from the WMAP and Planck satellite missions in order to constrain the exact scaling of the amplitude of the first peak in the power spectrum. The project is motivated by the fact that the first peak in the power spectrum is thought to be a key indicator of the level of non-Gaussianity in the early universe, and so precise measurements of this peak are important for understanding the nature of the primordial fluctuations. The comparison of the two data sets will provide a precise measurement of the first peak in the power spectrum, and will also provide a rigorous test of the current models for the power spectrum. The project is expected to provide important constraints on the nature of the primordial fluctuations, and will also provide a rigorous test of the current models for the power spectrum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Characterization of Instrumental Phase Stability. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.216, "human_text": "  Atmospheric water vapor causes significant undesired phase fluctuations for\nthe Submillimeter Array (SMA) interferometer, particularly in its highest\nfrequency observing band of 690 GHz. One proposed solution to this atmospheric\neffect is to observe simultaneously at two separate frequency bands of 230 and\n690 GHz. Although the phase fluctuations have a smaller magnitude at the lower\nfrequency, they can be measured more accurately and on shorter timescales due\nto the greater sensitivity of the array to celestial point source calibrators\nat this frequency. In theory, we can measure the atmospheric phase fluctuations\nin the 230 GHz band, scale them appropriately with frequency, and apply them to\nthe data in 690 band during the post-observation calibration process. The\nultimate limit to this atmospheric phase calibration scheme will be set by the\ninstrumental phase stability of the IF and LO systems. We describe the\nmethodology and initial results of the phase stability characterization of the\nIF and LO systems.\n", "machine_text": "\n\nCharacterization of Instrumental Phase Stability\nThe motivation for this work is the need for high-throughput techniques for measuring the instrumental phase stability of fiber-based components. The goal is to develop an approach that does not require the use of a reference during the measurement. The proposed approach combines the advantages of two different techniques: the transmission-based technique of dual-wave mixing and the reflection-based technique of spectral interferometry. The key idea is to use the spectral interferometry technique to measure the phase contribution of a single-mode fiber and the dual-wave mixing technique to simultaneously measure the phase contribution of a multi-mode fiber. The combination of these two measurements allows us to isolate the instrumental phase contribution. The proposed approach was tested on a simple fiber-based Mach-Zehnder interferometer. The results obtained show that the instrumental phase stability can be characterized with a high degree of confidence using only the proposed approach, without the need for a reference.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measurement of the top-quark mass using missing $E_T$+jets events with\n  secondary vertex $b$-tagging at CDF II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1594, "human_text": "  We present a measurement of the top-quark mass in $p\\bar p$ collisions at\n\\hbox{$\\sqrt{s}=1.96$} TeV which uses events with an inclusive signature of\nmissing transverse energy and jets. % The event selection is sensitive to\n$t\\bar t\\to W^+bW^-\\bar b\\to l\\nu b q q^\\prime \\bar b$ independent of the\nlepton flavor, and results in a large acceptance for $W\\to\\tau\\nu$ decays. %\nAll-hadronic $t\\bar t$ decays and events with identified electrons or muons are\nvetoed to provide a statistically independent sample with respect to all\nprevious measurements. % The top-quark mass is inferred from the distribution\nof the scalar sum of all jet transverse energies and the missing transverse\nenergy. Using 311 pb$^{-1}$ of integrated luminosity recorded by the Collider\nDetector at Fermilab, we measure a top-quark mass $m_t = 172.3\n^{+10.8}_{-9.6}$(stat.)$\\pm 10.8$(syst.) GeV/$c^2$. While the uncertainty on\n$m_t$ is larger than that of other measurements, the result is statistically\nuncorrelated with those of other methods, and thus can help to reduce the\noverall $m_t$ uncertainty when combined with other existing measurements.\n", "machine_text": "\nWe present a measurement of the top-quark mass using missing $E_T$+jets events with secondary vertex $b$-tagging at CDF II. The analysis uses events with at most one jet and one $b$-tag, where the $b$-tag is required to be within a cone around the missing $E_T$ vertex, and the jet is required to be within a cone around the $b$-tag. The $b$-tagging requirement significantly reduces the rate of spurious $b$-tags due to strong background. The mass is measured in the final state with one jet and one $b$-tag, using the resolved $S$-wave-function method. The $b$-tag is assumed to be a top-quark in the final state, and the top-quark mass is determined from the measured $S$-wave function. The analysis uses events in the $\\rm{tt}$-channel with the cdftophat variable set to $\\rm{tt}$ and the vis-ex variable set to $\\rm{tt}$, $\\rm{bb}$, or $\\rm{b}$ and where the number of jets is set to one. The missing $E_T$ is estimated from the $E_T$-jet separation in the event with the largest $E_T$. We observe 3.42+0.47$\\,$sigma $\\rm{top}$ events in the $\\rm{tt}$-channel, and measure the top-quark mass to be $\\rm{mt}$ = $68.06\\,$GeV/c^2 + $1.16\\,$sigma, where $\\rm{mt}$ is the mean and $\\sigma$ is the rms uncertainty.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Compton Scattering of Fe K alpha Lines in Magnetic Cataclysmic Variables. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1516, "human_text": "  Compton scattering of X-rays in the bulk flow of the accretion column in\nmagnetic cataclysmic variables (mCVs) can significantly shift photon energies.\nWe present Monte Carlo simulations based on a nonlinear algorithm demonstrating\nthe effects of Compton scattering on the H-like, He-like and neutral Fe K alpha\nlines produced in the post-shock region of the accretion column. The peak line\nemissivities of the photons in the post-shock flow are taken into consideration\nand frequency shifts due to Doppler effects are also included. We find that\nline profiles are most distorted by Compton scattering effects in strongly\nmagnetized mCVs with a low white dwarf mass and high mass accretion rate and\nwhich are viewed at an oblique angle with respect to the accretion column. The\nresulting line profiles are most sensitive to the inclination angle. We have\nalso explored the effects of modifying the accretion column width and using a\nrealistic emissivity profile. We find that these do not have a significant\noverall effect on the resulting line profiles. A comparison of our simulated\nline spectra with high resolution Chandra/HETGS observations of the mCV GK Per\nindicates that a wing feature redward of the 6.4 keV line may result from\nCompton recoil near the base of the accretion column.\n", "machine_text": "\n\nWe present observations of Fe K alpha lines in a sample of 22 magnetic cataclysmic variables (MCVs) observed with the optical/NIR telescope TANTAN. We use the magnetic field strength and orientation, and the temperature and density structure in the donor and accretor, to construct a model of the magnetic field configuration in the inner few donor stellar radii. We find that a model in which the magnetic field is aligned with the orbital angular momentum but with a large amplitude, i.e. a Larmor precession model, consistently describes the observations. We show that this model predicts a blue wing in the scattered Fe K alpha lines, which is in agreement with observations in a few cases. In addition, the model predicts that the strength of the blue wing depends on the viewing angle, which is in agreement with the observations. We discuss several methods to estimate the strength of the magnetic field from the observations of scattered Fe K alpha lines. We show that the precession model predicts a dependence of the strength of the magnetic field on the viewing angle which is in good agreement with the observations. We also present a model in which the magnetic field is aligned with the viewing angle, but with a large amplitude. This model predicts a red wing in the scattered Fe K alpha lines and we show that this model is in agreement with observations in a few cases. We discuss the physical origin of the different features in the scattered Fe K alpha lines and we compare our predictions with observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Suzaku Observation of the Nucleus of the Radio-Loud Active Galaxy\n  Centaurus A: Constraints on Abundances of the Accreting Material. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3743, "human_text": "  A Suzaku observation of the nucleus of the radio-loud AGN Centaurus A in 2005\nhas yielded a broadband spectrum spanning 0.3 to 250 keV. The net exposure\ntimes after screening were: 70 ks per X-ray Imaging Spectrometer (XIS) camera,\n60.8 ks for the Hard X-ray Detector (HXD) PIN, and 17.1 ks for the HXD-GSO. The\nhard X-rays are fit by two power-laws of the same slope, absorbed by columns of\n1.5 and 7 * 10^{23} cm^{-2} respectively. The spectrum is consistent with\nprevious suggestions that the power-law components are X-ray emission from the\nsub-pc VLBI jet and from Bondi accretion at the core, but it is also consistent\nwith a partial covering interpretation. The soft band is dominated by thermal\nemission from the diffuse plasma and is fit well by a two-temperature VAPEC\nmodel, plus a third power-law component to account for scattered nuclear\nemission, jet emission, and emission from X-ray Binaries and other point\nsources. Narrow fluorescent emission lines from Fe, Si, S, Ar, Ca and Ni are\ndetected. The Fe K alpha line width yields a 200 light-day lower limit on the\ndistance from the black hole to the line-emitting gas. Fe, Ca, and S K-shell\nabsorption edges are detected. Elemental abundances are constrained via\nabsorption edge depths and strengths of the fluorescent and diffuse plasma\nemission lines. The high metallicity ([Fe/H]=+0.1) of the circumnuclear\nmaterial suggests that it could not have originated in the relatively\nmetal-poor outer halo unless enrichment by local star formation has occurred.\nRelative abundances are consistent with enrichment from Type II and Ia\nsupernovae.\n", "machine_text": "\n\nWe present results of a Suzaku hard X-ray observation of the nuclear region of the radio-loud active galaxy Centaurus A. The aim of the observation was to test the hypothesis that the accretion disk of the supermassive black hole, which is responsible for the nuclear emission, iswarmer than the gas in the surrounding bulge. We find that the accretion disk, if it exists, must be at least 4 kK cooler than the gas in the bulge. We also find that the gas in the bulge is at most 6 kK cooler than the gas in the disk. This result rules out the possibility that the gas in the bulge is heated by accretion, and therefore that the bulge is the accretion disk seen at a very large radius. We discuss this result in the framework of simple models of the nuclear region. In addition, we derive constraints on the abundances of the accreiting material, assuming that the gas in the disk is a combination of gas in the bulge and a flow derived from the intergalactic medium. We find that the accretion gas is most probably close to solar in composition, regardless of the origin of the gas in the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Curvature Inspired Cosmological Scenario. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.041, "human_text": "  Using modified gravity with non-linear terms of curvature, $R^2$ and $R^{(r\n+2)}$ (with $r$ being the positive real number and $R$ being the scalar\ncurvature), cosmological scenario,beginning at the Planck scale, is obtained.\nHere, a unified picture of cosmology is obtained from $f(R)-$ gravity. In this\nscenario, universe begins with power-law inflation, followed by deceleration\nand acceleration in the late universe as well as possible collapse of the\nuniverse in future. It is different from $f(R)-$ dark energy models with\nnon-linear curvature terms assumed as dark energy. Here, dark energy terms are\ninduced by linear as well as non-linear terms of curvature in Friedmann\nequation being derived from modified gravity.It is also interesting to see\nthat, in this model, dark radiation and dark matter terms emerge spontaneously\nfrom the gravitational sector. It is found that dark energy, obtained here,\nbehaves as quintessence in the early universe and phantom in the late universe.\nMoreover, analogous to brane-tension in brane-gravity inspired Friedmann\nequation, a tension term $\\lambda$ arises here being called as cosmic tension.\nIt is found that, in the late universe, Friedmann equation (obtained here)\ncontains a term $- \\rho^2/2\\lambda$ ($\\rho$ being the phantom energy density)\nanalogous to a similar term in Friedmann equation with loop quantum effects, if\n$\\lambda > 0$ and brane-gravity correction when $\\lambda < 0.$\n", "machine_text": "\n\nMotivation\nThe motivation for this work is to develop a new cosmological scenario that can explain the origin of the matter in the Universe in a way that is consistent with the principles of physics and the observations that we have made so far. The key idea is to use the concept of curvature to inspire a new cosmological scenario that can explain the origin of the matter in the Universe. The methodology used in this work is to first develop a simple model that can explain the origin of the matter in the Universe, and then to use this model to inspire a new cosmological scenario. The results obtained from this work are a new cosmological scenario that can explain the origin of the matter in the Universe. The problem that this work attempts to solve is the origin of the matter in the Universe. The practical application of this work is to provide a new cosmological scenario that can explain the origin of the matter in the Universe in a way that is consistent with the principles of physics and the observations that we have made so far. The theoretical application of this work is to provide a new cosmological scenario that can explain the origin of the matter in the Universe in a way that is consistent with the principles of physics and the observations that we have made so far.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pseudo-random Puncturing: A Technique to Lower the Error Floor of Turbo\n  Codes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0361, "human_text": "  It has been observed that particular rate-1/2 partially systematic parallel\nconcatenated convolutional codes (PCCCs) can achieve a lower error floor than\nthat of their rate-1/3 parent codes. Nevertheless, good puncturing patterns can\nonly be identified by means of an exhaustive search, whilst convergence towards\nlow bit error probabilities can be problematic when the systematic output of a\nrate-1/2 partially systematic PCCC is heavily punctured. In this paper, we\npresent and study a family of rate-1/2 partially systematic PCCCs, which we\ncall pseudo-randomly punctured codes. We evaluate their bit error rate\nperformance and we show that they always yield a lower error floor than that of\ntheir rate-1/3 parent codes. Furthermore, we compare analytic results to\nsimulations and we demonstrate that their performance converges towards the\nerror floor region, owning to the moderate puncturing of their systematic\noutput. Consequently, we propose pseudo-random puncturing as a means of\nimproving the bandwidth efficiency of a PCCC and simultaneously lowering its\nerror floor.\n", "machine_text": "\n\nPseudo-random Puncturing: A Technique to Lower the Error Floor of Turbo Codes\n\nWe introduce a new technique, called pseudo-random puncturing, to reduce the error floor of turbo codes. This technique has two key ingredients. The first is to use a carefully designed puncturing pattern to generate a high-rate code with a large minimum distance. The second is to use the turbo codes' feedback loop to remove the correlations that may remain in the high-rate code, and thus approach the channel capacity. We show that with a turbo code of rate R=1/2 and an interleaver length of 2^n, the new technique can lower the error floor to about (7/2 + O(1/n))-dB for a large n. For an interleaver length of 2^n, this means that the number of reliable bits per frame is about (7/2 + O(1/n)) times the number of bits that can be reliably transmitted over the channel by the turbo code without any puncturing. This improves on the original turbo code design by about 7 dB. We also show that for large n, the proposed technique converges quickly to its error floor. We implement the proposed technique using both the original turbo code and the recent low-dibit turbo code, and we show that the new technique achieves better performance with both codes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lorentzian and signature changing branes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.338, "human_text": "  General hypersurface layers are considered in order to describe brane-worlds\nand shell cosmologies. No restriction is placed on the causal character of the\nhypersurface which may thus have internal changes of signature. Strengthening\nthe results in our previous letter [1], we confirm that a good, regular and\nconsistent description of signature change is achieved in these brane/shells\nscenarios, while keeping the hypersurface and the bulk completely regular. Our\nformalism allows for a unified description of the traditional timelike\nbranes/shells together with the signature-changing, or pure null, ones. This\nallows for a detailed comparison of the results in both situations. An\napplication to the case of hypersurface layers in static bulks is presented,\nleading to the general Robertson-Walker geometry on the layer --with a possible\nsignature change. Explicit examples on anti de Sitter bulks are then studied.\nThe permitted behaviours in different settings ($Z_{2}$-mirror branes,\nasymmetric shells, signature-changing branes) are analysed in detail. We show\nin particular that (i) in asymmetric shells there is an upper bound for the\nenergy density, and (ii) that the energy density within the brane vanishes when\napproaching a change of signature. The description of a signature change as a\n`singularity' seen from within the brane is considered. We also find new\nrelations between the fundamental constants in the brane/shell, its tension,\nand the cosmological and gravitational constants of the bulk, independently of\nthe existence or not of a change of signature.\n", "machine_text": "\n\nWe consider the properties of Lorentzian and signature changing branes in a general framework of a 4-dimensional spacetime with a non-trivial metric and non-zero cosmological constant. We show that the simplest such a theory is given by the signature changing planes in a 4-dimensional Anti-de Sitter spacetime with a cosmological constant proportional to the volume density of the spacetime. The resulting signatures of the branes are (3+1)-dimensional, (2+2)-dimensional and (1+3)-dimensional. We show that all bulk vibrational states of such a brane must be (3+1)-dimensional. We show that in a generic theory with a non-trivial bulkmetric and non-zero cosmological constant the bulk vibrational states can be (2+2)-dimensional as well as (1+3)-dimensional. The relevant bulkmetric functions are related to the stress-energy tensor and the bulk Lorentzian condition is shown to be equivalent to the energy conditions in the bulk. We discuss the bulk dynamics in the presence of a cosmological constant and relate the resulting theory to the Einstein-Maxwell-Chern theory in a (3+1)-dimensional space-time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multicolor observations of the afterglow of the short/hard GRB 050724. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1273, "human_text": "  New information on short/hard gamma-ray bursts (GRBs) is being gathered\nthanks to the discovery of their optical and X-ray afterglows. However, some\nkey aspects are still poorly understood, including the collimation level of the\noutflow, the duration of the central engine activity, and the properties of the\nprogenitor systems. We want to constrain the physical properties of the short\nGRB 050724 and of its host galaxy, and make some inferences on the global short\nGRB population. We present optical observations of the afterglow of GRB 050724\nand of its host galaxy, significantly expanding the existing dataset for this\nevent. We compare our results with models, complementing them with available\nmeasurements from the literature. We study the afterglow light curve and\nspectrum including X-ray data. We also present observations of the host galaxy.\nThe observed optical emission was likely related to the large flare observed in\nthe X-ray light curve. The apparent steep decay was therefore not due to the\njet effect. Available data are indeed consistent with low collimation, in turn\nimplying a large energy release, comparable to that of long GRBs. The flare\nproperties also constrain the internal shock mechanism, requiring a large\nLorentz factor contrast between the colliding shells. This implies that the\ncentral engine was active at late times, rather than ejecting all shells\nsimultaneously. The host galaxy has red colors and no ongoing star formation,\nconsistent with previous findings on this GRB. However, it is not a pure\nelliptical, and has some faint spiral structure. GRB 050724 provides the most\ncompelling case for association between a short burst and a galaxy with old\nstellar population. It thus plays a pivotal role in constraining progenitors\nmodels, which should allow for long delays between birth and explosion.\n", "machine_text": "\nWe present multicolor observations of the optical afterglow of the short/hard Gamma-Ray Burst (GRB) 050724, made with the Nordic Optical Telescope (NOT) at La Palma, Spain. The observations were triggered by the detection of the burst by the Gamma Ray Burst Monitor (GRBM) on board the INTEGRAL spacecraft. We find that the optical afterglow of GRB 050724 is characterized by a very red continuum, which is consistent with a host galaxy spectral type of M, and a mildly blueshifted ultra-weak NII morphology. The host galaxy has a radius of 1.3 kpc and is at a distance of 60 Mpc. The afterglow exhibits no significant brightenings, and is thus considered to be a steady afterglow. We determine the redshift of the burst to be z = 1.645, which makes this burst the nearest burst observed so far. We discuss the nature of the host galaxy and its possible relationship to the burst, and find that it has properties consistent with a disk galaxy. The burst occurred in a relatively inactive part of the galaxy, at a radius of 7 kpc from the galactic center. This burst is the closest burst to a disk galaxy observed so far, and it suggests that bursts can occur in galaxies which are not predominantly elliptical galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Depletion effects in smectic phases of hard rod--hard sphere mixtures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.114, "human_text": "  It is known that when hard spheres are added to a pure system of hard rods\nthe stability of the smectic phase may be greatly enhanced, and that this\neffect can be rationalised in terms of depletion forces. In the present paper\nwe first study the effect of orientational order on depletion forces in this\nparticular binary system, comparing our results with those obtained adopting\nthe usual approximation of considering the rods parallel and their orientations\nfrozen. We consider mixtures with rods of different aspect ratios and spheres\nof different diameters, and we treat them within Onsager theory. Our results\nindicate that depletion effects, and consequently smectic stability, decrease\nsignificantly as a result of orientational disorder in the smectic phase when\ncompared with corresponding data based on the frozen--orientation\napproximation. These results are discussed in terms of the $\\tau$ parameter,\nwhich has been proposed as a convenient measure of depletion strength. We\npresent closed expressions for $\\tau$, and show that it is intimately connected\nwith the depletion potential. We then analyse the effect of particle geometry\nby comparing results pertaining to systems of parallel rods of different shapes\n(spherocylinders, cylinders and parallelepipeds). We finally provide results\nbased on the Zwanzig approximation of a Fundamental--Measure\ndensity--functional theory applied to mixtures of parallelepipeds and cubes of\ndifferent sizes. In this case, we show that the $\\tau$ parameter exhibits a\nlinear asymptotic behaviour in the limit of large values of the hard--rod\naspect ratio, in conformity with Onsager theory, as well as in the limit of\nlarge values of the ratio of rod breadth to cube side length, $d$, in contrast\nto Onsager approximation, which predicts $\\tau\\sim d^3$.\n", "machine_text": "\nWe investigate depletion effects in smectic phases of hard rod--hard sphere mixtures. The hard rods are represented by theYouthful model with anisotropic hard spheres in a simple cubic arrangement and the smectic phase is obtained by the addition of a quenching agent that acts to form a soft layer between the hard rod layers. We use a single parameter to describe the smectic texture, namely, the ratio of the soft to hard material in the mixture. We find that the smectic texture is very sensitive to this single parameter and that the texture undergoes a continuous evolution as the quenching agent is increased. The texture evolution has several interesting features. For a particular range of quenching agent concentration, the smectic texture is very compact, with hard rod layers almost completely isolated from each other by the soft material. We find that such a compact texture is only possible if the soft material is significantly more effective at quenching the hard rods than the solvent. At high concentrations of quenching agent, the texture becomes extremely loose and approaches a  smectic  phase of pure solvent with hard rods randomly distributed throughout. We find that such a loose texture is only possible if the quenching agent is significantly less effective at quenching the hard rods than the solvent. In both the compact and loose textures, the hard rods form a quasi-regular arrangement, with the long axis of each hard rod nearly parallel to the smectic layers. In addition, we find that the hard rods form an unusual core--shell structure, with the hard cores completely surrounded by a soft shell. The structure is stable with respect to changes in the solvent content. We also investigate the temperature dependence of the hard rod orientation in the smectic phase.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Where post-Newtonian and numerical-relativity waveforms meet. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1305, "human_text": "  We analyze numerical-relativity (NR) waveforms that cover nine orbits (18\ngravitational-wave cycles) before merger of an equal-mass system with low\neccentricity, with numerical uncertainties of 0.25 radians in the phase and\nless than 2% in the amplitude; such accuracy allows a direct comparison with\npost-Newtonian (PN) waveforms. We focus on one of the PN approximants that has\nbeen proposed for use in gravitational-wave data analysis, the restricted 3.5PN\n``TaylorT1'' waveforms, and compare these with a section of the numerical\nwaveform from the second to the eighth orbit, which is about one and a half\norbits before merger. This corresponds to a gravitational-wave frequency range\nof $M\\omega = 0.0455$ to 0.1. Depending on the method of matching PN and NR\nwaveforms, the accumulated phase disagreement over this frequency range can be\nwithin numerical uncertainty. Similar results are found in comparisons with an\nalternative PN approximant, 3PN ``TaylorT3''. The amplitude disagreement, on\nthe other hand, is around 6%, but roughly constant for all 13 cycles that are\ncompared, suggesting that only 4.5 orbits need be simulated to match PN and NR\nwaves with the same accuracy as is possible with nine orbits. If, however, we\nmodel the amplitude up to 2.5PN order, the amplitude disagreement is roughly\nwithin numerical uncertainty up to about 11 cycles before merger.\n", "machine_text": "\nWe discuss the problem of matching up the waveform generated by a full-scale post-Newtonian (PN) model of a binary black hole with that produced by the numerical-relativity (NR) solution of the same system. We show that this is a necessary step toward the construction of a hybrid model which combines the strong gravity and fast evolution of the NR solution with the weak-gravity and slow-evolution approximation of the PN model. We then derive a simple expression for the mismatch between the NR and PN waveform that is valid for an arbitrary NR solution and for an arbitrary PN model. In particular, this expression is shown to be valid both for the NR solutions obtained using the standard slice method as well as the NR solutions obtained using the streamline method. We use this expression to compute the mismatch for a standard NR solution for a non-rotating binary black hole system and for a number of different PN models, including the Churchill-Appleman-diniz, Teukolsky-Fetherolf-N incentini, and Herriott-Tanner models. We find that the discrepancies between the NR and PN waveforms increase approximately as the square of the PN mass parameter $m_{\\rm PN}$, and thus are much more severe for compact binaries than for wide binaries. We also show that for all of these PN models the mismatch between the NR and PN waveforms can be greatly reduced by a simple modification of the PN model which consists of making the radial displacement of the circles of constant latitude proportional to $m_{\\rm PN}^{-2}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Cornell Caltech Atacama Telescope. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3031, "human_text": "  Cornell University, the California Institute for Technology, and the Jet\nPropulsion Laboratory are jointly studying the construction of a 25 m diameter\ntelescope for submillimeter astronomy on a high mountain in northern Chile.\nThis Cornell Caltech Atacama Telescope (CCAT) will combine high sensitivity, a\nwide field of view, and a broad wavelength range to provide an unprecedented\ncapability for deep, large area, multi-color submillimeter surveys to\ncomplement narrow field, high resolution studies with ALMA. CCAT observations\nwill address fundamental themes in contemporary astronomy, notably the\nformation and evolution of galaxies, the nature of the dark matter and dark\nenergy that comprise most of the content of the universe, the formation of\nstars and planets, the conditions in circumstellar disks, and the conditions\nduring the early history of the Solar system. The candidate CCAT site, at 5600\nm in northern Chile, enjoys superb observing conditions. To accommodate large\nformat bolometer cameras, CCAT is designed with a 20 arcmin field of view. CCAT\nwill incorporate closed loop active control of its segmented primary mirror to\nmaintain a half wavefront error of 10 mum rms or less. Instrumentation under\nconsideration includes both short (650 mum-200 mum) and long (2 mm-750 mum)\nwavelength bolometer cameras, direct detection spectrometers, and heterodyne\nreceiver arrays. The University of Colorado, a Canadian university consortium,\nand the UK Astronomy Technology Centre on behalf of the UK community are\npursuing participation in the CCAT consortium. When complete early in the next\ndecade, CCAT will be the largest and most sensitive facility of its class as\nwell as the highest altitude astronomical facility on Earth.\n", "machine_text": "\n\nWe describe the Cornell Caltech Atacama Telescope (CCAT), a proposed 25m diameter telescope to be located at an altitude of 5,000m on the Atacama Plateau in Chile. The telescope will be a joint project of Cornell University and the California Institute of Technology, and will be constructed and operated by a newly formed non-profit organization, the CCAT Corporation. The mission of the telescope is twofold: to advance cosmic microwave background research and to provide a high-resolution, high-sensitivity telescope for astronomical and atmospheric studies. In this article we focus on the scientific capabilities of the telescope and the unique aspects of its design that enable these capabilities. We summarize the results of the Site Selection Study, including the analysis of the optical, thermal, and mechanical properties of the proposed site and the geotechnical analysis of the foundation design. We describe the fully integrated design of the telescope and the adaptive optics system, and the optimization of the design for operation in the Atacama environment. We conclude with a discussion of the scientific opportunities made possible by the combination of the unique telescope design and the excellent site, and the steps that are underway to secure the funding required to build and operate the telescope.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Growth mechanisms and structure of fullerene-like carbon-based thin\n  films: superelastic materials for tribological applications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2258, "human_text": "  In this chapter we review our findings on the bonding structure and growth\nmechanisms of carbon-based thin solid films with fullerene-like (FL)\nmicrostructure. The so-called FL arrangements arise from the curvature and\ncross-linking of basal planes in graphitic-like structures, partially\nresembling that of molecular fullerenes. This three-dimensional superstructure\ntakes advantage of the strength of planar pi bonds in sp2 hybrids and confers\nthe material interesting mechanical properties, such as high hardness, high\nelastic recovery, low-friction and wear-resistance. These properties can be\ntailored by controlling the curvature, size and connectivity of the FL\narrangements, making these materials promising coatings for tribological\napplications. We have focused our interest mostly on carbon nitride (CNx) since\nnitrogen promotes the formation of FL arrangements at low substrate\ntemperatures and they are emerging over pure carbon coatings in tribological\napplications such as protective overcoats in magnetic hard disks. We address\nstructural issues such as origin of plane curvature, nature of the\ncross-linking sites and sp2 clustering, together with growth mechanisms based\non the role of film-forming precursors, chemical re-sputtering or concurrent\nion assistance during growth.\n", "machine_text": "\nWe report on the growth mechanisms and structure of fullerene-like carbon-based thin films: superelastic materials for tribological applications. The motivation for the research is the demand for novel materials with unique properties for tribological applications. The key ideas and methodology are the use of the detonation process as a method for the synthesis of fullerene-like carbons, and the implementation of in situ diagnostics by using a quartz microbalance that allows us to monitor the growth process. The results obtained are the description of the growth mechanisms and the determination of the structural and tribological properties of the films. The problem the work attempts to solve is to find a method for the synthesis of fullerene-like carbon films with tailored properties for tribological applications. Any practical or theoretical applications from the findings or implications for future research include the potential use of fullerene-like carbon films as novel materials with unique properties for tribological applications, and the potential use of the detonation process as a method for the synthesis of nanocarbon materials with tailored properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Interval Conjectures for level Hilbert functions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0806, "human_text": "  We conjecture that the set of all Hilbert functions of (artinian) level\nalgebras enjoys a very natural form of regularity, which we call the {\\em\nInterval Conjecture} (IC): If, for some positive integer $\\alpha $,\n$(1,h_1,...,h_i,...,h_e)$ and $(1,h_1,...,h_i+\\alpha ,...,h_e)$ are both level\n$h$-vectors, then $(1,h_1,...,h_i+\\beta ,...,h_e)$ is also level for each\ninteger $\\beta =0,1,..., \\alpha .$ In the Gorenstein case, i.e. when $h_e=1$,\nwe also supply the {\\em Gorenstein Interval Conjecture} (GIC), which naturally\ngeneralizes the IC, and basically states that the same property simultaneously\nholds for any two symmetric entries, say $h_i$ and $h_{e-i}$, of a Gorenstein\n$h$-vector.\n  These conjectures are inspired by the research performed in this area over\nthe last few years. A series of recent results seems to indicate that it will\nbe nearly impossible to characterize explicitly the sets of all Gorenstein or\nof all level Hilbert functions. Therefore, our conjectures would at least\nprovide the existence of a very strong - and natural - form of order in the\nstructure of such important and complicated sets.\n  We are still far from proving the conjectures at this point. However, we will\nalready solve a few interesting cases, especially when it comes to the IC, in\nthis paper. Among them, that of Gorenstein $h$-vectors of socle degree 4, that\nof level $h$-vectors of socle degree 2, and that of non-unimodal level\n$h$-vectors of socle degree 3 and any given codimension.\n", "machine_text": "\n\nInterval Conjectures for Level Hilbert Functions\n\nWe consider the problem of characterizing the values of level Hilbert functions on certain sets related to the relative consensus zone of a finitely-restarted iteration process. We show that two such sets, which we call the strong interval and the weak interval, are characterized by certain forms of interval conjecture, in a way which generalizes the strong and weak restrictions of the Pisot and Rapoport conjectures for Pisot and Rapoport functions. In particular, we show that if the strong interval conjecture holds for a level Hilbert function, then this function takes its maximum value on the strong interval, and if the weak interval conjecture holds, then this function takes its minimum value on the weak interval. We show further that both the strong and weak interval conjectures are equivalent to certain forms of the strong and weak Restricted Conjectures for Pisot and Rapoport functions, and that both conjectures are also equivalent to a conjecture of Finger on interval functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Stokes phenomenon in the confluence of the hypergeometric equation\n  using Riccati equation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1773, "human_text": "  In this paper we study the confluence of two regular singular points of the\nhypergeometric equation into an irregular one. We study the consequence of the\ndivergence of solutions at the irregular singular point for the unfolded\nsystem. Our study covers a full neighborhood of the origin in the confluence\nparameter space. In particular, we show how the divergence of solutions at the\nirregular singular point explains the presence of logarithmic terms in the\nsolutions at a regular singular point of the unfolded system. For this study,\nwe consider values of the confluence parameter taken in two sectors covering\nthe complex plane. In each sector, we study the monodromy of a first integral\nof a Riccati system related to the hypergeometric equation. Then, on each\nsector, we include the presence of logarithmic terms into a continuous\nphenomenon and view a Stokes multiplier related to a 1-summable solution as the\nlimit of an obstruction that prevents a pair of eigenvectors of the monodromy\noperators, one at each singular point, to coincide.\n", "machine_text": "\nWe consider the Stokes phenomenon in the confluence of the hypergeometric equation using the Riccati equation. We show that the limiting solution of the hypergeometric equation in the form of a generalized airy function can be obtained by using the limit relation between the Riccati and hypergeometric equations. The hypergeometric equation is a generalization of the exponential and logaritaic equations. The hypergeometric equation has many applications in diverse areas of mathematics, physics and engineering. We get the exponential and logaritaic equations as the special cases of the hypergeometric equation. The Stokes phenomenon is the effect of a moderate increase in the right hand side of a differential equation on the solution. The Stokes phenomenon has many applications in diverse areas of physics and engineering. We obtain the asymptotic form of the solution of the hypergeometric equation with a moderate increase in the right hand side. We obtain the special case of the exponential and logaritaic equations in the context of the Stokes phenomenon.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Valley Dependent Optoelectronics from Inversion Symmetry Breaking. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4683, "human_text": "  Inversion symmetry breaking allows contrasted circular dichroism in different\nk-space regions, which takes the extreme form of optical selection rules for\ninterband transitions at high symmetry points. In materials where band-edges\noccur at noncentral valleys, this enables valley dependent interplay of\nelectrons with light of different circular polarizations, in analogy to spin\ndependent optical activities in semiconductors. This discovery is in perfect\nharmony with the previous finding of valley contrasted Bloch band features of\norbital magnetic moment and Berry curvatures from inversion symmetry breaking\n[Phys. Rev. Lett. 99, 236809 (2007)]. A universal connection is revealed\nbetween the k-resolved optical oscillator strength of interband transitions,\nthe orbital magnetic moment and the Berry curvatures, which also provides a\nprinciple for optical measurement of orbital magnetization and intrinsic\nanomalous Hall conductivity in ferromagnetic systems. The general physics is\ndemonstrated in graphene where inversion symmetry breaking leads to valley\ncontrasted optical selection rule for interband transitions. We discuss\ngraphene based valley optoelectronics applications where light polarization\ninformation can be interconverted with electronic information.\n", "machine_text": "\n\nWe propose and demonstrate a novel approach to valley dependent optoelectronics based on symmetry breaking in a ferroelectric layer. We show that the broken symmetry can be used to generate a strong and fast optical response in an adjacent semiconductor layer, which can be used for various optoelectronic applications. Our approach is based on the realization that a symmetry breaking strain field in a ferroelectric layer can be efficiently and periodically mapped to a second material in a layered structure, in a similar way as the spontaneous polarization is mapped to the piezoelectric response in a ferroelectric-piezoelectric bilayer. We demonstrate a strong and fast photoresponse with a high on/off ratio in a photodetector configuration, as well as efficient and fast carrier injection in a light emitting device configuration, both in a nanostructured semiconductor material. Our results open up new avenues for designing nanostructured optoelectronic devices with a strong and fast response, which can be easily integrated with Si technology.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of anomalous diffusive reaction rates on realistic self-affine\n  fractals. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2813, "human_text": "  In this letter, a theoretical method for the analysis of diffusive\nflux/current to limited scale self-affine random fractals is presented and\ncompared with experimentally measured electrochemical current for such\nroughness. The theory explains the several experimental findings of the\ntemporal scale invariance as well as deviation from this of current transients\nin terms of three dominant fractal parameters for the limited-length scales of\nroughness. This theoretical method is based on limited scale power-law\ncharacterization of the interfacial roughness spectrum and the solution of\ndiffusion equation under the diffusion-limited boundary conditions on rough\ninterfaces. More broadly, these calculations challenges the earlier belief that\nthe anomalous behavior is solely dependent on fractal dimension of roughness\nand highlight the potential to apply this equation for the scale invariant\nroughness determination. Finally, the validity of theoretical result is tested\nwith extensive experimental data.\n", "machine_text": "\nWe consider the problem of anomalous diffusive reaction rates on realistic self-affine fractals. We show that such reaction rates are related to the thermal conductivity of the fractal, and that this conductivity in turn is related to the volume conductivities of the positive and negative fractal components. These relationships provide a possible physical explanation for the large number of microscopic reaction channels that are typically associated with anomalous reaction rates on fractals. We analyze the simplest case of a self-affine fractal in one dimension, and evaluate the conductivity of a fractal as a function of its fractal dimension. We find that the conductivity tends to decrease rapidly with increasing fractal dimension, and we show that this decrease is related to the large number of necks or connectors between the positive and negative fractal components. In two and higher dimensions, we find that the conductivity of a fractal is proportional to the product of its volume conductivity and its fractal dimension. We show that this proportionality is consistent with the assumption that the conductivity is related to the average number of connectors per volume. We also derive a simple expression for the conductivity of a self-affine fractal as a function of its fractal dimension in any number of dimensions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is diversity good?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2466, "human_text": "  Prominent ethical and policy issues such as affirmative action and female\nenrollment in science and engineering revolve around the idea that diversity is\ngood. However, even though diversity is an ambiguous concept, a precise\ndefinition is seldom provided. We show that diversity may be construed as a\nfactual description, a craving for symmetry, an intrinsic good, an instrumental\ngood, a symptom, or a side effect. These acceptions differ vastly in their\nnature and properties. The first one cannot lead to any action and the second\none is mistaken. Diversity as intrinsic good is a mere opinion, which cannot be\nconcretely applied; moreover, the most commonly invoked forms of diversity\n(sexual and racial) are not intrinsically good. On the other hand, diversity as\ninstrumental good can be evaluated empirically and can give rise to policies,\nbut these may be very weak. Finally, symptoms and side effects are not actually\nabout diversity. We consider the example of female enrollment in science and\nengineering, interpreting the various arguments found in the literature in\nlight of this polysemy.\n  Keywords: ethics, policy, higher education, female students, minority\nstudents, affirmative action\n", "machine_text": "\nWe are motivated by a desire to understand the effects of diversity on outcomes important to firms. Our interest is both theoretical and empirical. The theoretical motivation is based on the idea that diversity may affect firm performance through increasing the diversity of ideas exchanged in the firm. We expect this to be the case if the diversity is structured, or if it increases the variety of skills and knowledge in the firm. The empirical motivation is based on the observation that firms with higher degrees of diversity, especially racial and gender diversity, tend to have higher levels of performance. We review the theoretical and empirical literature to develop a model of the relationship between diversity, the flow of ideas within the firm, and performance. The model is tested using a sample of firms from the Fortune 500. We find that the model provides a good fit to the data, and that the model can explain the effect of diversity on performance. Our findings suggest that diversity is good for performance, but only if it is structured and leads to the exchange of diverse ideas.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Linkage between Accretion Disks and Blazars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2636, "human_text": "  The magnetic field in an accretion disk is estimated assuming that all of the\nangular momentum within prescribed accretion disk radii is removed by a jet.\nThe magnetic field estimated at the base of the jet is extrapolated to the\nblazar emission region using a model for a relativistic axisymmetric jet\ncombined with some simplifying assumptions based on the relativistic nature of\nthe flow. The extrapolated magnetic field is compared with estimates based upon\nthe synchrotron and inverse Compton emission from three blazars, MKN 501, MKN\n421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self-\nCompton models are inconsistent with the magnetic fields extrapolated in this\nway. However, in two cases inverse Compton models in which a substantial part\nof the soft photon field is generated locally agree well, mainly because these\nmodels imply magnetic field strengths which are closer to being consistent with\nPoynting flux dominated jets. This comparison is based on estimating the mass\naccretion rate from the jet energy flux. Further comparisons along these lines\nwill be facilitated by independent estimates of the mass accretion rate in\nblazars and by more detailed models for jet propagation near the black hole.\n", "machine_text": "\n\nWe present a linkage between accretion disks and blazars. We show that the accretion disks around supermassive black holes can heat the surrounding gas to a temperature capable of sustaining nuclear fusion, and thereby creating a blazar. We show that accretion disks around stellar-mass black holes can produce a jet, but not a blazar. We discuss a simple model in which a fraction of the matter in the accretion disk is heated to a temperature capable of sustaining nuclear fusion, and the rest is accreted onto the black hole. We show that in this model the accretion disk has a sharp inner boundary, and the gas pressure outside this boundary is very small. We show that in this model the accretion disk has a strong faraday Rmongodb, and can therefore be detected at radio wavelengths. We discuss a more elaborate model, in which the gas is heated by compression in the accretion disk, and by friction from the accretion disk. We show that in this model the accretion disk has a steep spectrum, and therefore produces a blazar. We show that in this model the accretion disk has a strong magnetosphere, and therefore can produce a relativistic wind. We discuss the motivation for this work, and we discuss the implications of this work for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cryptoplanet update. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.286, "human_text": "  We have had several talks recently reviewing 11 years of exoplanet\ndiscoveries through radial velocity variations, or from transits, or from\nmicrolensing. More than 200 exoplanets have been found, including some around\npulsars that we do not discuss here.\n  My physical definition for a planet is a roughly spherical, self-gravitating\nbody more massive than 10**26 g formed from the leftover material in a\nprotostellar disk after the protostar forms. Radiation from the protostar\npushes the inner wall of the disk outward. The material agglomerates and forms\nplanets in radial sequence. The outer planets are formed slowly by classical\ndynamical mechanisms acting in the snow zone. Planets have dense cores because\nof agglomeration.\n  Not one of the exoplanets discovered thus far is a planet. They are\ncryptoplanets formed from matter ejected by protostars. When protostars have\nexcessive infall at high latitudes, they partially balance angular momentum\nthrough outflow at the equator as they spin up. The ejected matter is trapped\nin the magnetic torus formed between the star and the disk, like a tokamak. The\ntokamak eventully reconnects and magnetic compression forms self-gravitating\nremnants trapped and compressed by a closed spherical magnetic field,\nspheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They\ncan merge with each other or fall into the star or be ejected. They can grow by\naccreting gas. They have a low density core and abundances characteristic of\nthe protostar. Their masses, radii, densities, and orbits are random, and are\ninconsistent with the parameters for planets. They tend to have lower density\nthan planets.\n", "machine_text": "\n\nCryptoplanet update\nThis work presents an update to our previous work on cryptoplanets. In this work, we present a detailed analysis of the astrometric data for the Kepler-107 system. We find that the system contains two planets, one with a mass close to that of the Earth. This is the second system found by the Kepler Mission that contains a rocky planet in the habitable zone. We also present a new method to constrain the thickness of the atmosphere of Kepler planets. The method is based on a combination of atmospheric modeling and an analysis of the diffraction patterns produced by the atmospheres of transiting planets. With this method we constrain the atmospheric thickness of the two large gas giants in the Kepler-107 system. We find that the atmosphere of the larger planet is optically thick, while the atmosphere of the smaller planet is likely to be thinner. We also present an update to our method to determine the true size of giant planets using a combination of photometric and spectroscopic observations. We apply this method to the gas giants in the Kepler-107 system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Outer jet X-ray and radio emission in R Aquarii: 1999.8 to 2004.0. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.257, "human_text": "  Chandra and VLA observations of the symbiotic star R Aqr in 2004 reveal\nsignificant changes over the three to four year interval between these\nobservations and previous observations taken with the VLA in 1999 and with\nChandra in 2000. This paper reports on the evolution of the outer thermal X-ray\nlobe-jets and radio jets. The emission from the outer X-ray lobe-jets lies\nfarther away from the central binary than the outer radio jets, and comes from\nmaterial interpreted as being shock heated to ~10^6 K, a likely result of\ncollision between high speed material ejected from the central binary and\nregions of enhanced gas density. Between 2000 and 2004, the Northeast (NE)\nouter X-ray lobe-jet moved out away from the central binary, with an apparent\nprojected motion of ~580 km s^-1. The Southwest (SW) outer X-ray lobe-jet\nalmost disappeared between 2000 and 2004, presumably due to adiabatic expansion\nand cooling. The NE radio bright spot also moved away from the central binary\nbetween 2000 and 2004, but with a smaller apparent velocity than of the NE\nX-ray bright spot. The SW outer lobe-jet was not detected in the radio in\neither 1999 or 2004. The density and mass of the X-ray emitting material is\nestimated. Cooling times, shock speeds, pressure and confinement are discussed.\n", "machine_text": "\n\nWe present new X-ray and radio observations of the accretion disc around R Aquarii. These data, obtained over the period 1999.8 to 2004.0, are the most complete monitoring of the X-ray and radio emission from this source to date, and they are the first such data to be acquired since the mid-1990s. We find that the X-ray and radio luminosities have increased by factors of 1.4 and 1.6 respectively since the last monitoring campaign. We show that the accretion disc is now radiating at the same X-ray and radio luminosity as it was in 1995, after a period of quiescence in which the luminosity had been reduced by factors of 3 and 5 respectively. The radial and vertical structures in the X-ray and radio emission are consistent with the disc being oriented close to face-on to us, as it was in 1995. We estimate that the inner disc has a temperature of about 0.75 keV, and that the outer disc has a temperature of about 1.25 keV. These temperatures are only slightly higher than in 1995. We discuss these results in the context of a simple model in which the accretion disc is fed by episodic accretion events.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-cooperative games for spreading code optimization, power control and\n  receiver design in wireless data networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0783, "human_text": "  This paper focuses on the issue of energy efficiency in wireless data\nnetworks through a game theoretic approach. The case considered is that in\nwhich each user is allowed to vary its transmit power, spreading code, and\nuplink receiver in order to maximize its own utility, which is here defined as\nthe ratio of data throughput to transmit power. In particular, the case in\nwhich linear multiuser detectors are employed at the receiver is treated first,\nand, then, the more challenging case in which non-linear decision feedback\nmultiuser receivers are adopted is addressed. It is shown that, for both\nreceivers, the problem at hand of utility maximization can be regarded as a\nnon-cooperative game, and it is proved that a unique Nash equilibrium point\nexists. Simulation results show that significant performance gains can be\nobtained through both non-linear processing and spreading code optimization; in\nparticular, for systems with a number of users not larger than the processing\ngain, remarkable gains come from spreading code optimization, while, for\noverloaded systems, the largest gainscome from the use of non-linear\nprocessing. In every case, however, the non-cooperative games proposed here are\nshown to outperform competing alternatives.\n", "machine_text": "\n\nWe consider the problem of jointly optimizing the codebooks at the transmitter and the receiver in a multiple access network while minimizing the overall power consumption. We show that this problem can be formulated and solved as a non-cooperative game, in which the players are the transmitters and the receiver. We consider two levels of cooperation among the transmitters: (i) when all the transmitters use the same codebook, and (ii) when the transmitters use different, but related codebooks. In both cases, we show that the game has a unique solution, which is efficiently solvable. We then extend the results to the problem of joint optimization of the codebooks at the transmitter and the receiver, as well as the power allocation, in a wireless data network. We show that this problem can be formulated and solved as a non-cooperative game, in which the players are the transmitters and the receiver. We consider two levels of cooperation among the transmitters: (i) when all the transmitters use the same codebook, and (ii) when the transmitters use different, but related codebooks. In both cases, we show that the game has a unique solution, which is efficiently solvable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complementarity in the Bohr-Einstein Photon Box. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2762, "human_text": "  The photon box thought experiment can be considered a forerunner of the\nEPR-experiment: by performing suitable measurements on the box it is possible\nto ``prepare'' the photon, long after it has escaped, in either of two\ncomplementary states. Consistency requires that the corresponding box\nmeasurements be complementary as well. At first sight it seems, however, that\nthese measurements can be jointly performed with arbitrary precision: they\npertain to different systems (the center of mass of the box and an internal\nclock, respectively). But this is deceptive. As we show by explicit\ncalculation, although the relevant quantities are simultaneously measurable,\nthey develop non-vanishing commutators when calculated back to the time of\nescape of the photon. This justifies Bohr's qualitative arguments in a precise\nway; and it illustrates how the details of the dynamics conspire to guarantee\nthe requirements of complementarity. In addition, our calculations exhibit a\n``fine structure'' in the distribution of the uncertainties over the\ncomplementary quantities: depending on \\textit{when} the box measurement is\nperformed, the resulting quantum description of the photon differs. This brings\nus close to the argumentation of the later EPR thought experiment.\n", "machine_text": "\nWe consider a thought experiment based on the Bohr-Einstein photon box. The motivation for our work is to understand the complementarity inherent in the quantum theory of light. We show that if we try to prepare a pure state of a single-photon in a photon box, then we can only achieve this in a limited number of ways. The analysis of these possibilities shows that the complementarity principle is encoded in the dynamics of the photon box. In particular, we find a clear signature of the standard complementarity principle in the form of a distinction between a quantum-mechanical and a classical (winning- Ticket) approach to a quantum-optical game. We also show that if we try to prepare a mixed state of a single-photon in a photon box, then the dynamics of the photon box will always be such that the final state will be well described by a thermal mixture. Our analysis shows that this fact is encoded in the dynamics of the photon box, in the form of a distinction between a quantum-mechanical and a classical (winning-Ticket) approach to a quantum-optical game.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relaxation of a dewetting contact line Part 2: Experiments. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3583, "human_text": "  The dynamics of receding contact lines is investigated experimentally through\ncontrolled perturbations of a meniscus in a dip coating experiment. We first\ncharacterize stationary menisci and their breakdown at the coating transition.\nIt is then shown that the dynamics of both liquid deposition and\nlong-wavelength perturbations adiabatically follow these stationary states.\nThis provides a first experimental access to the entire bifurcation diagram of\ndynamical wetting, confirming the hydrodynamic theory developed in Part 1. In\ncontrast to quasi-static theories based on a dynamic contact angle, we\ndemonstrate that the transition strongly depends on the large scale flow\ngeometry. We then establish the dispersion relation for large wavenumbers, for\nwhich we find that sigma is linear in q. The speed dependence of sigma is well\ndescribed by hydrodynamic theory, in particular the absence of diverging\ntime-scales at the critical point. Finally, we highlight some open problems\nrelated to contact angle hysteresis that lead beyond the current description.\n", "machine_text": "\nWe continue our study of the relaxation of a dewetting contact line (Part 1: Theory) by analyzing the experimental results of our previous work. We first confirm the theoretical prediction that the contact area decreases in a manner that is consistent with the contact line moving in a series of small jerks. We then show that the experimental data are consistent with the assumption that the distribution of the interfacial tension over the contact area is independent of the contact area itself. This allows us to evaluate the impact of the relative spatial distribution of the interfacial tension over the contact area on the dynamics of the contact line. We find that the assumption of a constant distribution of interfacial tension over the contact area results in a good qualitative description of the data, but the quantitative description is somewhat inaccurate. We then consider a more general model in which the distribution of interfacial tension over the contact area is allowed to vary in a prescribed way. We find that this model is able to provide a good quantitative description of the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Possible X-ray diagnostic for jet/disk dominance in Type 1 AGN. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1587, "human_text": "  Using Rossi X-ray Timing Explorer Seyfert 1 and 1.2 data spanning 9 years, we\nstudy correlations between X-ray spectral features. The sample consists of 350\ntime-resolved spectra from 12 Seyfert 1 and 1.2 galaxies. Each spectrum is\nfitted to a model with an intrinsic powerlaw X-ray spectrum produced close to\nthe central black hole that is reprocessed and absorbed by material around the\nblack hole. To test the robustness of our results, we performed Monte Carlo\nsimulations of the spectral sample. We find a complex relationship between the\niron line equivalent width (EW) and the underlying power law index (Gamma). The\ndata reveal a correlation between Gamma and EW which turns over at Gamma <~ 2,\nbut finds a weak anti-correlation for steeper photon indices. We propose that\nthis relationship is driven by dilution of a disk spectrum (which includes the\nnarrow iron line) by a beamed jet component and, hence, could be used as a\ndiagnostic of jet-dominance. In addition, our sample shows a strong correlation\nbetween the reflection fraction (R) and Gamma, but we find that it is likely\nthe result of modeling degeneracies. We also see the X-ray Baldwin effect (an\nanti-correlation between the 2-10 keV X-ray luminosity and EW) for the sample\nas a whole, but not for the individual galaxies and galaxy types.\n", "machine_text": "\n\nWe have carried out a statistical study of the X-ray emission in a sample of Type 1 active galactic nuclei (AGN) in which the accretion-disc luminosity has been estimated from optical and N-ray observations. We have used the mean X-ray count-rate as a function of the accretion-disc luminosity to infer the dominate power law behaviour of the X-ray emission. The inferred power law indices are found to be distributed in a wide range, and in addition, the shape of the X-ray count-rate - accretion-disc luminosity relation is very poorly described by a single power law. These results suggest that the power law index of the X-ray emission is not uniquely related to the accretion-disc luminosity, but rather, the relation is likely to be complex and dependent on the detailed structure of the accretion disc and the innermost region of the jet. We have found a significant correlation between the X-ray power law index and the accretion-disc structure as revealed by high-resolution imaging of the accretion disc. Our results suggest that the jet power law index is a useful diagnostic for the dominant contribution to the accretion-flow luminosity: either the disc or the jet.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonholonomic Ricci Flows: III. Curve Flows and Solitonic Hierarchies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2062, "human_text": "  The geometric constructions are elaborated on (semi) Riemannian manifolds and\nvector bundles provided with nonintegrable distributions defining nonlinear\nconnection structures induced canonically by metric tensors. Such spaces are\ncalled nonholonomic manifolds and described by two equivalent linear\nconnections also induced in unique forms by a metric tensor (the Levi Civita\nand the canonical distinguished connection, d-connection). The lifts of\ngeometric objects on tangent bundles are performed for certain classes of\nd-connections and frame transforms when the Riemann tensor is parametrized by\nconstant matrix coefficients. For such configurations, the flows of\nnon-stretching curves and corresponding bi-Hamilton and solitonic hierarchies\nencode information about Ricci flow evolution, Einstein spaces and exact\nsolutions in gravity and geometric mechanics. The applied methods were\nelaborated formally in Finsler geometry and allows us to develop the formalism\nfor generalized Riemann-Finsler and Lagrange spaces. Nevertheless, all\ngeometric constructions can be equivalently re-defined for the Levi Civita\nconnections and holonomic frames on (semi) Riemannian manifolds.\n", "machine_text": "\nWe consider the nonholonomic Ricci flow on a symplectic manifold, namely the flow of the Ricci tensor that is generated by the standard Ricci flow and the additional flow of the tensor that is induced by the nonholonomic contribution to theChristoffel symbols. We show that this flow is a curve flow, that is, it is an infinitesimal generator of a deformation of curves in the symmetric andantisymmetric parts of the fiber of a vector field along the curve. The geometric properties of such a flow are similar to those of a Fano flow. In particular,  we show that a certain class of nonsymmetric Fano flows is equivalent to a class of nonholonomic Ricci flows on certain kinds of symplectic manifolds. We also discuss some geometric properties of the associated singularity. We show that the nonholonomic Ricci flow is a solitonic flow, that is, it has a constant speed in a certain class of symplectic manifolds. As an application, we show that the fiber of a generic curve flow is an isotropic submanifold of the symmetric and antisymmetric parts of the fiber of a vector field along the curve.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multidimensional fluid motions with planar waves. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2311, "human_text": "  In the classical one-dimensional solution of fluid dynamics equations all\nunknown functions depend only on time t and Cartesian coordinate x. Although\nfluid spreads in all directions (velocity vector has three components) the\nwhole picture of motion is relatively simple: trajectory of one fluid particle\nfrom plane x=const completely determines motion of the whole plane. Basing on\nthe symmetry analysis of differential equations we propose generalization of\nthis solution allowing movements in different directions of fluid particles\nbelonging to plane x=const. At that, all functions but an angle determining the\ndirection of particle's motion depend on t and x only, whereas the angle\ndepends on all coordinates. In this solution the whole picture of motion\nsuperposes from identical trajectories placed under different angles in 3D\nspace. Orientations of the trajectories are restricted by a finite relation\npossessing functional arbitrariness. The solution describes three-dimensional\nnonlinear processes and singularities in infinitely conducting plasma, gas or\nincompressible liquid.\n", "machine_text": "\n\nWe consider the problem of describing fluid motions in a many-dimensional space. We restrict ourselves to the case of motions of ideal fluids, i.e., fluids with no internal viscosity and no bulk stress, in order to be able to describe the fluid motions by a small number of parameters. Our approach is based on the analysis of the Fourier spectrum of the velocity field. We show that a multidimensional fluid can be characterized by a few parameters in the same way as the one-dimensional case. In particular, we show that any smooth map from the set of spherical harmonics to the set of wave vectors in the space can be uniquely inverted. This provides a method for describing the structure of the velocity field. We also consider the problem of describing the shape of the velocity field in the space. We show that the velocity field of a multidimensional fluid has a simple structure if it is not changing too fast in a neighborhood of a point. In particular, we show that the shape of the velocity field is described by a few parameters in the same way as the one-dimensional case.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A theorem about relative entropy of quantum states with an application\n  to privacy in quantum communication. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2437, "human_text": "  We prove the following theorem about relative entropy of quantum states.\n\"Substate theorem: Let rho and sigma be quantum states in the same Hilbert\nspace with relative entropy S(rho|sigma) = Tr rho (log rho - log sigma) = c.\nThen for all epsilon > 0, there is a state rho' such that the trace distance\n||rho' - rho||_t = Tr sqrt{(rho' - rho)^2} <= epsilon, and\nrho'/2^{O(c/epsilon^2)} <= sigma.\"\n  It states that if the relative entropy of rho and sigma is small, then there\nis a state rho' close to rho, i.e. with small trace distance ||rho' - rho||_t,\nthat when scaled down by a factor 2^{O(c)} `sits inside', or becomes a\n`substate' of, sigma. This result has several applications in quantum\ncommunication complexity and cryptography. Using the substate theorem, we\nderive a privacy trade-off for the set membership problem in the two-party\nquantum communication model. Here Alice is given a subset A of [n], Bob an\ninput i in [n], and they need to determine if i in A.\n  \"Privacy trade-off for set membership: In any two-party quantum communication\nprotocol for the set membership problem, if Bob reveals only k bits of\ninformation about his input, then Alice must reveal at least n/2^{O(k)} bits of\ninformation about her input.\"\n  We also discuss relationships between various information theoretic\nquantities that arise naturally in the context of the substate theorem.\n", "machine_text": "\nWe introduce a technique for characterizing entanglement which avoids the usual formalism of entanglement measures. We show that this technique can be used to prove a version of theHTML obtained by rearranging the mathematical symbols in the proof of theSets results characterizing entanglement. We show that this version of the inequality implies theSets results, and that the technique can be used to prove several otherresults in quantum information theory. We also show how our technique can be used to characterize the amount of information that can be extracted from a quantum state by partial measurements. Finally, we show that our technique can be used to prove a version of the much stronger Iguess that in any experiment one can think of, there is a measurement that can be performed such that the outcome of this measurement has a positive probability of being correct. Our technique provides a way of proving such an assurance for any measurement with a positive-semidefinite Fisher information. We also show that the technique can be used to prove a version of the that is independent of the particular measurement employed. We show that the proposed technique can be used to prove several otherresults in quantum information theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-Infrared Spectra of the Black Hole X-Ray Binary, A0620-00. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0267, "human_text": "  We present broadband NIR spectra of A0620-00 obtained with SpeX on the IRTF.\nThe spectrum is characterized by a blue continuum on which are superimposed\nbroad emission lines of HI and HeII and a host of narrower absorption lines of\nneutral metals and molecules. Spectral type standard star spectra scaled to the\ndereddened spectrum of A0620-00 in K exceed the A0620-00 spectrum in J and H\nfor all stars of spectral type K7V or earlier, demonstrating that the donor\nstar, unless later than K7V, cannot be the sole NIR flux source in A0620-00. In\naddition, the atomic absorption lines in the K3V spectrum are too weak with\nrespect to those of A0620-00 even at 100% donor star contribution, restricting\nthe spectral type of the donor star in A0620-00 to later than K3V. Comparison\nof the A0620-00 spectrum to scaled K star spectra indicates that the CO\nabsorption features are significantly weaker in A0620-00 than in field dwarf\nstars. Fits of scaled model spectra of a Roche lobe-filling donor star to the\nspectrum of A0620-00 show that the best match to the CO absorption lines is\nobtained when the C abundance is reduced to [C/H] = -1.5. The donor star\ncontribution in the H waveband is determined to be 82+-2%. Combined with\nprevious published results from Froning & Robinson (2001) and Marsh et al.\n(1994), this gives a precise mass for the black hole in A0620-00 of M_BH =\n9.7+-0.6 M_solar.\n", "machine_text": "\n\nWe present near-infrared (NIR) spectroscopy and photometry of the black hole X-ray binary A0620-00. The motivation for our research is to better understand the accretion process in this object, which has been experiencing a large variability in its optical and NIR light during the last two years. We have performed a time series of NIR spectroscopy with the VISIR instrument at the Very Large Telescope Array, which allowed us to study the inner accretion flow in the broad-line region. We find that the accretion flow is variable on timescales of days, consistent with the observed variability in the optical and NIR light of the source. We find that the observed variability in the accretion flow is not correlated with the orbital period, but rather with the accretion phase. We find that the accretion flow is blueshifted during the early part of the accretion phase, consistent with an inward-directed accretion flow, while it is redshifted at later times, consistent with an outward-directed accretion flow. We find that the accretion flow is at its blueshifted peak when the accretion efficiency is highest, while it is at its redshifted minimum when the accretion efficiency is lowest. We also present NIR photometry of the source, which shows variability on timescales of days. We find that the variability in the photometry is not correlated with the orbital period, but rather with the accretion phase. We find that the brightness is highest when the accretion flow is blueshifted, while it is lowest when the accretion flow is redshifted. We discuss our results in the context of other black hole X-ray binaries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scaling Relations of Compressible MHD Turbulence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2464, "human_text": "  We study scaling relations of compressible strongly magnetized turbulence. We\nfind a good correspondence of our results with the Fleck (1996) model of\ncompressible hydrodynamic turbulence. In particular, we find that the\ndensity-weighted velocity, i.e. $u \\equiv \\rho^{1/3} v$, proposed in Kritsuk et\nal. (2007) obeys the Kolmogorov scaling, i.e. $E_{u}(k)\\sim k^{-5/3}$ for the\nhigh Mach number turbulence. Similarly, we find that the exponents of the third\norder structure functions for $u$ stay equal to unity for the all the Mach\nnumbers studied. The scaling of higher order correlations obeys the She-Leveque\n(1994) scalings corresponding to the two-dimensional dissipative structures,\nand this result does not change with the Mach number either. In contrast to $v$\nwhich exhibits different scaling parallel and perpendicular to the local\nmagnetic field, the scaling of $u$ is similar in both directions. In addition,\nwe find that the peaks of density create a hierarchy in which both physical and\ncolumn densities decrease with the scale in accordance to the Fleck (1996)\npredictions. This hierarchy can be related ubiquitous small ionized and neutral\nstructures (SINS) in the interstellar gas. We believe that studies of\nstatistics of the column density peaks can provide both consistency check for\nthe turbulence velocity studies and insight into supersonic turbulence, when\nthe velocity information is not available.\n", "machine_text": "\n\nWe study the statistical properties of the velocity field in compressible MHD turbulence. We show that, for a large class of numerical simulations, the velocity field is well described by a scaling relation that relates the mean velocity to the velocity fluctuations and the compression ratio. Within this class of simulations, the standard deviation of the velocity field scales as the square of the mean velocity. We show this result by fitting the empirical scaling relation to the data with an appropriate model. We also show that the model can be used to extract the local compression ratio in regions of the flow. We find that the local compression ratio is correlated with the local mean velocity, but that the correlation is very weak. We also show that the local compression ratio is uncorrelated with the local standard deviation of the velocity field. We discuss these results in the framework of the Gurruwiwi-Ohno model, and show that the Gurruwiwi-Ohno model can be used to quantitatively reproduce our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detection of Crab Giant Pulses Using the Mileura Widefield Array Low\n  Frequency Demonstrator Field Prototype System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0404, "human_text": "  We report on the detection of giant pulses from the Crab Nebula pulsar at a\nfrequency of 200 MHz using the field deployment system designed for the Mileura\nWidefield Array's Low Frequency Demonstrator (MWA-LFD). Our observations are\namong the first high-quality detections at such low frequencies. The measured\npulse shapes are deconvolved for interstellar pulse broadening, yielding a\npulse-broadening time of 670$\\pm$100 $\\mu$s, and the implied strength of\nscattering (scattering measure) is the lowest that is estimated towards the\nCrab nebula from observations made so far. The sensitivity of the system is\nlargely dictated by the sky background, and our simple equipment is capable of\ndetecting pulses that are brighter than $\\sim$9 kJy in amplitude. The brightest\ngiant pulse detected in our data has a peak amplitude of $\\sim$50 kJy, and the\nimplied brightness temperature is $10^{31.6}$ K. We discuss the giant pulse\ndetection prospects with the full MWA-LFD system. With a sensitivity over two\norders of magnitude larger than the prototype equipment, the full system will\nbe capable of detecting such bright giant pulses out to a wide range of\nGalactic distances; from $\\sim$8 to $\\sim$30 kpc depending on the frequency.\nThe MWA-LFD will thus be a highly promising instrument for the studies of giant\npulses and other fast radio transients at low frequencies.\n", "machine_text": "\n\nWe report on a pilot study for the detection of crab giant pulses (GPs) using the Mileura Widefield Array (MWA) Low Frequency Demonstrator (LFD) Field Prototype system. The LFD is a precursor to the MWA LFD which will be a dedicated low frequency array for the investigation of a wide range of astrophysical phenomena in the frequency range of 20-200 Hz. The MWA LFD will be constructed and operated as a collaborative facility by the Australian National University (ANU) and CSIRO, with ANU responsible for the construction and operation of the LFD Field Prototype. We describe the LFD Field Prototype system and the motivation for the research, and report on the results of our pilot study for the detection of crab GPs. We describe the data processing pipeline and the criteria used to identify crab GPs, and present the frequency distribution of GP occurrence. We show that the LFD Field Prototype system has sufficient sensitivity to detect crab GPs, and discuss the prospects for using the LFD for further study of crab GP occurrence and its possible relation to other astrophysical phenomena.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The origin of the molecular emission around the southern hemisphere Re 4\n  IRS - HH 188 region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1427, "human_text": "  We present SEST observations of the molecular environment ahead of the\nsouthern Herbig-Haro object 188 (HH188), associated with the low-mass protostar\nRe4 IRS. We have also used the SuperCosmos Halpha survey to search for Halpha\nemission associated with the Re4 IRS - HH188 region. The aim of the present\nwork is to study the properties of the molecular gas and to better characterize\nthis southern star forming region. We mapped the HCO+ 3-2 and H13CO+ 1-0\nemission around the YSO and took spectra of the CH3OH 2(0)-1(0)A+ and\n2(-1)-1(-1)E and SO 6(5)-5(4) towards the central source. Column densities are\nderived and different scenarios are considered to explain the origin of the\nmolecular emission. HCO+ arises from a relatively compact region around the\nYSO; however, its peak emission is displaced to the south following the outflow\ndirection. Our chemical analysis indicates that a plausible scenario is that\nmost of the emission arises from the cold, illuminated dense gas ahead of the\nHH188 object. We have also found that HH188, a high excitation object, seems to\nbe part of a parsec scale and highly collimated HH system. Re4 IRS is probably\na binary protostellar system, in the late Class 0 or Class I phase. One of the\nprotostars, invisible in the near-IR, seems to power the HH188 system.\n", "machine_text": "\nWe present photometric detections of the CH and CN molecular lines in the source IRS - HH 188. The relative molecular luminosity of the source is  \u223c 10 38  W. We determine a radial molecular velocity of  \u223c 19  km s \u2212 1. This velocity is in good agreement with the measured proper motion of the ionised gas in the same source, thus confirming the hypothesis that the molecular gas and the ionised gas are the same physical entity. We have compared the observed distribution of the molecular gas with theoretical models. The best agreement is obtained with a model in which the molecular gas is distributed in a series of rings, with the molecular velocity at the centre being higher than the observed value. We discuss two possible mechanisms for producing this distribution, and conclude that the distribution has to be produced by a non-homogeneous process. We also discuss the distribution of the molecular gas in the region, and conclude that it is not possible to produce this distribution by a model in which the molecular gas is smoothly distributed with a constant velocity. We present a model in which the molecular gas is distributed in a series of expanding rings, with the number density of the rings declining exponentially with radius. We show that this model can produce the observed distribution of the molecular gas, with the number density being higher at the edge of the region than in its interior. We also discuss a model in which the molecular gas is distributed in a sphere, with the molecular velocity at the centre being higher than the observed value. We show that this model can also produce the observed distribution of the molecular gas, with the number density being higher at the edge of the region than in its interior.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Chandra Observations of Supernova 1987A. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0209, "human_text": "  We have been monitoring Supernova (SN) 1987A with {\\it Chandra X-Ray\nObservatory} since 1999. We present a review of previous results from our {\\it\nChandra} observations, and some preliminary results from new {\\it Chandra} data\nobtained in 2006 and 2007. High resolution imaging and spectroscopic studies of\nSN 1987A with {\\it Chandra} reveal that X-ray emission of SN 1987A originates\nfrom the hot gas heated by interaction of the blast wave with the ring-like\ndense circumstellar medium (CSM) that was produced by the massive progenitor's\nequatorial stellar winds before the SN explosion. The blast wave is now\nsweeping through dense CSM all around the inner ring, and thus SN 1987A is\nrapidly brightening in soft X-rays. At the age of 20 yr (as of 2007 January),\nX-ray luminosity of SN 1987A is $L_{\\rm X}$ $\\sim$ 2.4 $\\times$ 10$^{36}$ ergs\ns$^{-1}$ in the 0.5$-$10 keV band. X-ray emission is described by two-component\nplane shock model with electron temperatures of $kT$ $\\sim$ 0.3 and 2 keV. As\nthe shock front interacts with dense CSM all around the inner ring, the X-ray\nremnant is now expanding at a much slower rate of $v$ $\\sim$ 1400 km s$^{-1}$\nthan it was until 2004 ($v$ $\\sim$ 6000 km s$^{-1}$).\n", "machine_text": "\n\nWe present a detailed study of the supernova (SN) 1987A, based on observations with the Chandra X-ray Observatory. We find that the SN 1987A is still accreting matter, although at a rate that is most likely to be less than 1 M\u22c5 yr\u22121. We estimate the energy released in the first seven years of the supernova to be about 2.4 \u00d7 1051 erg, which corresponds to an excess energy with respect to the Chandrasekhar limit of about 3.4%. We find that the energy release rate has decreased significantly since the supernova burst, and is now only about 7% of the burst rate. We also find that the gas in the SN 1987A is still at high temperature, and that the temperature does not decrease as quickly as the accretion rate. This may be explained by the fact that the gas is not well mixed, and so the gas that is accreting has a higher temperature than the gas that has already been accreted. We discuss this in the framework of a simple model in which the accretion of gas is due to the infall of clumps of gas. The gas that has already been accreted is likely to have a temperature that is close to the Chandrasekhar limit, and so the overall temperature of the gas in the SN 1987A is likely to decrease slowly as the accretion continues.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Performance of the Charge Injection Capability of Suzaku XIS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1771, "human_text": "  A charge injection technique is applied to the X-ray CCD camera, XIS (X-ray\nImaging Spectrometer) onboard Suzaku. The charge transfer inefficiency (CTI) in\neach CCD column (vertical transfer channel) is measured by the injection of\ncharge packets into a transfer channel and subsequent readout. This paper\nreports the performances of the charge injection capability based on the ground\nexperiments using a radiation damaged device, and in-orbit measurements of the\nXIS. The ground experiments show that charges are stably injected with the\ndispersion of 91eV in FWHM in a specific column for the charges equivalent to\nthe X-ray energy of 5.1keV. This dispersion width is significantly smaller than\nthat of the X-ray events of 113eV (FWHM) at approximately the same energy. The\namount of charge loss during transfer in a specific column, which is measured\nwith the charge injection capability, is consistent with that measured with the\ncalibration source. These results indicate that the charge injection technique\ncan accurately measure column-dependent charge losses rather than the\ncalibration sources. The column-to-column CTI correction to the calibration\nsource spectra significantly reduces the line widths compared to those with a\ncolumn-averaged CTI correction (from 193eV to 173eV in FWHM on an average at\nthe time of one year after the launch). In addition, this method significantly\nreduces the low energy tail in the line profile of the calibration source\nspectrum.\n", "machine_text": "\n\nWe have investigated the charge injection capability of the X-ray imaging spectrometer (XIS) on board the Suzaku satellite, by utilizing the Hard X-ray transient hunter (HXT) instrument on board the Swift satellite. The charge injection is a major source of background in the energy-dispersive X-ray spectrometry (EDS) analysis of impulsive transient sources, and therefore has important implications for the study of such sources. We found that the charge injection effect produced by XIS is moderate and the injected charge is not depolarized immediately. The temporal behavior of the charge injection is consistent with a model in which the injected charge is distributed in a finite volume conductor, with a time constant longer than the duration of the transient event. We also found that the count rate in the energy range above 2 keV, where the XIS sensitivity is dominated by the charge injection, is depressed by a factor of  \u223c 4 immediately after the transient event. We discuss the implications of our results for the study of transient sources and the improvement of the data processing for the EDS analysis of transient events.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The time evolution of cosmological redshift as a test of dark energy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.235, "human_text": "  The variation of the expansion rate of the Universe with time produces an\nevolution in the cosmological redshift of distant sources (for example quasar\nLyman-$\\alpha$ absorption lines), that might be directly observed by future\nultra stable, high-resolution spectrographs (such as CODEX) coupled to\nextremely large telescopes (such as European Southern Observatory's Extremely\nLarge Telescope, ELT). This would open a new window to explore the physical\nmechanism responsible for the current acceleration of the Universe. We\ninvestigate the evolution of cosmological redshift from a variety of dark\nenergy models, and compare it with simulated data. We perform a Fisher matrix\nanalysis and discuss the prospects for constraining the parameters of these\nmodels and for discriminating among competing candidates. We find that, because\nof parameter degeneracies, and of the inherent technical difficulties involved\nin this kind of observations, the uncertainties on parameter reconstruction can\nbe rather large unless strong external priors are assumed. However, the method\ncould be a valuable complementary cosmological tool, and give important\ninsights on the dynamics of dark energy, not obtainable using other probes.\n", "machine_text": "\nWe have developed a new method to test the dark energy hypothesis by monitoring the evolution of cosmological redshift. Our method is independent of the choice of the distance metric and does not require a high confidence in the distance measurements. We show that our method is more sensitive to the evolution of the distance than the conventional method. This is because the conventional method uses the instantaneous distance measurements while our method uses the average distance measurements. Also our method is less vulnerable to systematics in the distance measurements. We show that our method can detect a slow-down of the evolution of the redshift at the 3sigma confidence level if the evolution of the distance is slowed down by a factor of  \u223c 2. We also show that our method can detect a fast-rise of the evolution of the redshift at the 3sigma confidence level if the evolution of the distance is accelerated by a factor of  \u223c 2. We estimate the systematic uncertainty in our method and show that our method is comparable to the conventional method in this respect. We also discuss the prospects of measuring the evolution of the redshift with the Next Generation Failure (ngc).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ly-alpha Emission-Line Galaxies at z = 3.1 in the Extended Chandra Deep\n  Field South. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3917, "human_text": "  We describe the results of an extremely deep, 0.28 deg^2 survey for z = 3.1\nLy-alpha emission-line galaxies in the Extended Chandra Deep Field South. By\nusing a narrow-band 5000 Anstrom filter and complementary broadband photometry\nfrom the MUSYC survey, we identify a statistically complete sample of 162\ngalaxies with monochromatic fluxes brighter than 1.5 x 10^-17 ergs cm^-2 s^-1\nand observers frame equivalent widths greater than 80 Angstroms. We show that\nthe equivalent width distribution of these objects follows an exponential with\na rest-frame scale length of w_0 = 76 +/- 10 Angstroms. In addition, we show\nthat in the emission line, the luminosity function of Ly-alpha galaxies has a\nfaint-end power-law slope of alpha = -1.49 +/- 0.4, a bright-end cutoff of log\nL^* = 42.64 +/- 0.2, and a space density above our detection thresholds of 1.46\n+/- 0.12 x 10^-3 h70^3 galaxies Mpc^-3. Finally, by comparing the emission-line\nand continuum properties of the LAEs, we show that the star-formation rates\nderived from Ly-alpha are ~3 times lower than those inferred from the\nrest-frame UV continuum. We use this offset to deduce the existence of a small\namount of internal extinction within the host galaxies. This extinction,\ncoupled with the lack of extremely-high equivalent width emitters, argues that\nthese galaxies are not primordial Pop III objects, though they are young and\nrelatively chemically unevolved.\n", "machine_text": "\n\nWe present the results of a narrow band imaging survey for Ly-alpha emission-line galaxies (ELGs) in the Extended Chandra Deep Field South (ECDF-S). The survey was conducted with Subaru/SuprimeCam at $z=3.1$, over an area of $2.37\\times 1.00$ degrees, and with $\\delta_{\\rm band}$ = $1.0$ arcmin. This is the first ELG survey conducted over an extragalactic sky field at intermediate redshift (z < 1), providing a unique view of the large-scale structure of the Universe at this epoch. We find 784 ELGs in our survey, with an estimated ELG number density of $2.5 \\times 10^{-2}$ deg$^{-1}$. The ELGs show a large degree of organisation, with a number of distinct groups and filaments, some of which extend several degrees. The properties of the ELGs (number density, sizes, and luminosities) are consistent with the large-scale distribution of galaxies in the Universe at z = 3.1, as traced by the survey galaxies in the optical and near-infrared, and by the distribution of intergalactic hydrogen at that epoch. The properties of the ELGs are inconsistent with the predictions of the currently popular theories of galaxy formation that assume a slow accretion history of galaxies in large scale structures, but are consistent with the predictions of theories that assume that galaxies in large-scale structure form through violent merging events. We show that the distribution of the ELGs is well described by a simple power law, with the probability of finding an ELG decreasing as the square of the distance from the nearest large scale structure. This provides strong evidence that large-scale structure forms through the aggregation of ELGs, rather than the accretion of galaxies in smooth accelerators. We discuss the implications of our results for theories of galaxy formation and large-scale structure formation, and for the nature of the intergalactic medium at z < 1.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Long Period, Massive Binaries HD 37366 and HD 54662: Potential\n  Targets for Long Baseline Optical Interferometry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3229, "human_text": "  We present the results from an optical spectroscopic analysis of the massive\nstars HD 37366 and HD 54662. We find that HD 37366 is a double-lined\nspectroscopic binary with a period of 31.8187 +/- 0.0004 days, and HD 54662 is\nalso a double lined binary with a much longer period of 557.8 +/- 0.3 days. The\nprimary of HD 37366 is classified as O9.5 V, and it contributes approximately\ntwo-thirds of the optical flux. The less luminous secondary is a broad-lined,\nearly B-type main-sequence star. Tomographic reconstruction of the individual\nspectra of HD 37366 reveals absorption lines present in each component,\nenabling us to constrain the nature of the secondary and physical\ncharacteristics of both stars. Tomographic reconstruction was not possible for\nHD 54662; however, we do present mean spectra from our observations that show\nthat the secondary component is approximately half as bright as the primary.\nThe observed spectral energy distributions (SEDs) were fit with model SEDs and\ngalactic reddening curves to determine the angular sizes of the stars. By\nassuming radii appropriate for their classifications, we determine distance\nranges of 1.4 - 1.9 and 1.2 - 1.5 kpc for HD 37366 and HD 54662, respectively.\n", "machine_text": "\n\nThe Long Period, Massive Binaries HD 37366 and HD 54662: Potential Targets for Long Baseline Optical Interferometry\n\nWe present high-resolution spectroscopy and photometry of the massive binary systems HD 37366 and HD 54662. We find that both systems are well-behaved and stable on time scales of at least several decades. The masses of the companions are 37M\u2299 and 34M\u2299 for HD 37366 and HD 54662, respectively. Both systems are sufficiently well-behaved that they may be useful targets for long baseline optical interferometry. We derive orbital elements for both systems, and find that the orbits are not perfectly periodic. We discuss the physical properties of the stars and their companions, and the evolution of the systems. We find that both systems are likely to have evolved from the main sequence in a Helium-rich envelope, and thus both are likely to be magnetically-quiet Helium-burning stars. We discuss the prospects for detection of sub-stellar companions using both interferometry and high-resolution spectroscopy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bounds on quark mass matrices elements due to measured properties of the\n  mixing matrix and present values of the quark masses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2851, "human_text": "  We obtain constraints on possible structures of mass matrices in the quark\nsector by using as experimental restrictions the determined values of the quark\nmasses at the $M_Z$ energy scale, the magnitudes of the quark mixing matrix\nelements $V_{\\rm ud}$, $V_{\\rm us}$, $V_{\\rm cd}$, and $V_{\\rm cs}$, and the\nJarlskog invariant $J(V)$. Different cases of specific mass matrices are\nexamined in detail. The quality of the fits for the Fritzsch and Stech type\nmass matrices is about the same with $\\chi^2/{\\rm dof}=4.23/3=1.41$ and\n$\\chi^2/{\\rm dof}=9.10/4=2.28$, respectively. The fit for a simple\ngeneralization (one extra parameter) of the Fritzsch type matrices, in the\nphysical basis, is much better with $\\chi^2/{\\rm dof}=1.89/4=0.47$. For\ncomparison we also include the results using the quark masses at the 2 GeV\nenergy scale. The fits obtained at this energy scale are similar to that at\n$M_Z$ energy scale, implying that our results are unaffected by the evolution\nof the quark masses from 2 to 91 GeV.\n", "machine_text": "\n\nWe show that the elements of the quark mass matrices can be bounded from below by using the properties of the mixing matrix and the present values of the quark masses. The bounds obtained are sufficiently tight to rule out the possibility of a quark mass as small as the electron mass. The motivation for this work is to provide a simple argument that the quark mass matrices have positive definite elements, thus removing one possible technical problem in the formulation of the Einstein-Maxwell theory. The key idea is to use the fact that the non-singlet quark mixing matrix has real positive elements, whereas the singlet quark mixing matrix has elements which can be either positive or negative. The problem this work attempts to solve is to provide a simple and physically intuitive argument that the quark mass matrices have positive definite elements. The practical application of this work is that it removes one possible technical problem in the formulation of the Einstein-Maxwell theory. The theoretical application of this work is that it provides a simple argument that the quark mass matrices have positive definite elements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: \"Illusion of control\" in Minority and Parrondo Games. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.112, "human_text": "  Human beings like to believe they are in control of their destiny. This\nubiquitous trait seems to increase motivation and persistence, and is probably\nevolutionarily adaptive. But how good really is our ability to control? How\nsuccessful is our track record in these areas? There is little understanding of\nwhen and under what circumstances we may over-estimate or even lose our ability\nto control and optimize outcomes, especially when they are the result of\naggregations of individual optimization processes. Here, we demonstrate\nanalytically using the theory of Markov Chains and by numerical simulations in\ntwo classes of games, the Minority game and the Parrondo Games, that agents who\noptimize their strategy based on past information actually perform worse than\nnon-optimizing agents. In other words, low-entropy (more informative)\nstrategies under-perform high-entropy (or random) strategies. This provides a\nprecise definition of the \"illusion of control\" in set-ups a priori defined to\nemphasize the importance of optimization.\n", "machine_text": "\n\nWe study the illusion of control in minority and Parrondo games. We show that the illusion of control can be maintained in a minority game by means of a suitable randomization of the game's starting point. We also show that the illusion of control can be maintained in a Parrondo game if the randomization is performed on the moves rather than on the starting point. The main difference between the minority and Parrondo cases is that, while the minority game has a single Nash equilibria, the Parrondo game can have several, and the randomization must be designed in such a way that the illusion of control is maintained for all of them. We analyze the randomizations of the minority and Parrondo games by means of a suitable generalization of the concept of vertigo to random games, and we derive simple sufficient conditions for the randomization of the minority and Parrondo games that guarantee the maintenance of the illusion of control. We finally study the connection between the randomization of the minority and Parrondo games and the classical concepts ofrandomized retrospectively deterministic and stochastic games.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A CLT for Information-theoretic statistics of Gram random matrices with\n  a given variance profile. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0166, "human_text": "  Consider a $N\\times n$ random matrix $Y_n=(Y_{ij}^{n})$ where the entries are\ngiven by $$ Y_{ij}^{n}=\\frac{\\sigma_{ij}(n)}{\\sqrt{n}} X_{ij}^{n} $$ the\n$X_{ij}^{n}$ being centered, independent and identically distributed random\nvariables with unit variance and $(\\sigma_{ij}(n); 1\\le i\\le N, 1\\le j\\le n)$\nbeing an array of numbers we shall refer to as a variance profile. We study in\nthis article the fluctuations of the random variable $$ \\log\\det(Y_n Y_n^* +\n\\rho I_N) $$ where $Y^*$ is the Hermitian adjoint of $Y$ and $\\rho > 0$ is an\nadditional parameter. We prove that when centered and properly rescaled, this\nrandom variable satisfies a Central Limit Theorem (CLT) and has a Gaussian\nlimit whose parameters are identified. A complete description of the scaling\nparameter is given; in particular it is shown that an additional term appears\nin this parameter in the case where the 4$^\\textrm{th}$ moment of the\n$X_{ij}$'s differs from the 4$^{\\textrm{th}}$ moment of a Gaussian random\nvariable. Such a CLT is of interest in the field of wireless communications.\n", "machine_text": "\nWe consider a simple model of random matrices which is based on the independence of the entries of the matrix from each other and from the entries of the second row and second column. We show that such matrices have a specific distribution of the Mahalanobis metric and that this distribution depends only on the variance profile of the matrix, which is described by two parameters. This allows us to introduce a family of distributions of the Mahalanobis metric which is indexed by the variance profile. We show that this family has a limiting distribution which is an equivariant diffusion process. We obtain the distribution of the Trace of the matrix, which allows us to introduce a random symmetric positive definite matrix with a given variance profile. We show that this random matrix has a limiting distribution which is the normal random symmetric positive definite matrix. As an application, we show that the limiting distribution of the gradient of the mutual information is the Fr\u00e9chet random gradient.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Studies of Thermally Unstable Accretion Disks around Black Holes with\n  Adaptive Pseudo-Spectral Domain Decomposition Method I. Limit-Cycle Behavior\n  in the Case of Moderate Viscosity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2283, "human_text": "  We present a numerical method for spatially 1.5-dimensional and\ntime-dependent studies of accretion disks around black holes, that is\noriginated from a combination of the standard pseudo-spectral method and the\nadaptive domain decomposition method existing in the literature, but with a\nnumber of improvements in both the numerical and physical senses. In\nparticular, we introduce a new treatment for the connection at the interfaces\nof decomposed subdomains, construct an adaptive function for the mapping\nbetween the Chebyshev-Gauss-Lobatto collocation points and the physical\ncollocation points in each subdomain, and modify the over-simplified\n1-dimensional basic equations of accretion flows to account for the effects of\nviscous stresses in both the azimuthal and radial directions. Our method is\nverified by reproducing the best results obtained previously by Szuszkiewicz &\nMiller on the limit-cycle behavior of thermally unstable accretion disks with\nmoderate viscosity. A new finding is that, according to our computations, the\nBernoulli function of the matter in such disks is always and everywhere\nnegative, so that outflows are unlikely to originate from these disks. We are\nencouraged to study the more difficult case of thermally unstable accretion\ndisks with strong viscosity, and wish to report our results in a subsequent\npaper.\n", "machine_text": "\nWe study limit-cycle behavior in the evolution of thermally unstable accretion disks around black holes with moderate viscosity. We employ the adaptive pseudo-spectral domain decomposition method, which is newly developed in this work, to accurately solve the viscousdisk equations with theopycnic-based boundary conditions on the inner and outer boundaries. We find that the disk eigenmodes are highly sensitive to the ratio of the viscous to thermal resistances, which may cause a significant decay in the amplitude of the fastest eigenmode even when the disk is slightly viscously stable. We also find that the disk becomes locally stable against small-scale perturbations in the inner region, which is consistent with the results of the linear stability analysis. The behavior of the local viscous coefficient, which is obtained from the solution of the disk equations, shows a strong correlation with the evolution of the disk structure in the inner region. Our results suggest that the local viscous coefficient may be a good indicator of the onset of the limit-cycle behavior in the inner region, even in the case of a thermally unstable disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Rotation and activity of pre-main-sequence stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3266, "human_text": "  We present a study of rotation (vsini) and chromospheric activity (Halpha EW)\nbased on an extensive set of high-resolution optical spectra obtained with MIKE\non the 6.5m Magellan Clay telescope. Our targets are 74 F-M dwarfs in the young\nstellar associations Eta Cha, TW Hydrae, Beta Pic, and Tuc-Hor, spanning ages\nfrom 6 to 30 Myr. While the Halpha EW for most F and G stars are consistent\nwith pure photospheric absorption, most K and M stars show chromospheric\nemission. By comparing Halpha EW in our sample to results in the literature, we\nsee a clear evolutionary sequence: Chromospheric activity declines steadily\nfrom the T Tauri phase to the main sequence. Using activity as an age\nindicator, we find a plausible age range for the Tuc-Hor association of 10-40\nMyr. Between 5 and 30 Myr, we do not see evidence for rotational braking in the\ntotal sample, thus angular momentum is conserved, in contrast to younger stars.\nThis difference indicates a change in the rotational regulation at 5-10 Myr,\npossibly because disk braking cannot operate longer than typical disk\nlifetimes, allowing the objects to spin up. The rotation-activity relation is\nflat in our sample; in contrast to main-sequence stars, there is no linear\ncorrelation for slow rotators. We argue that this is because young stars\ngenerate their magnetic fields in a fundamentally different way from\nmain-sequence stars, and not just the result of a saturated solar-type dynamo.\nBy comparing our rotational velocities with published rotation periods for a\nsubset of stars, we determine ages of 13 (7-20) Myr and 9 (7-17} Myr for the\nEta Cha and TWA associations, respectively, consistent with previous estimates.\nThus we conclude that stellar radii from evolutionary models by Baraffe et al.\n(1998) are in agreement with the observed radii within +-15%. (abridged)\n", "machine_text": "\n\nPre-main-sequence stars are a class of stars that are in the process of evolving from a collapsed cloud of gas and dust to a stable source of light and heat. As these stars evolve, they undergo a period of rapid rotation and activity, during which they can display phenomena such as solar flares and coronal mass ejections. The activity of pre-main-sequence stars is driven by the strong magnetic fields that are generated as the stars collapse and heat up.\n\nThe rotation and activity of pre-main-sequence stars is an important topic of study, as it can provide insight into the processes that occur during the evolution of stars. In addition, pre-main-sequence stars can have a significant impact on the evolution of their solar systems, as they can affect the evolution of planets and other celestial objects.\n\nIn this work, we present a theoretical study of the rotation and activity of pre-main-sequence stars. We consider the effects of various physical processes, such as convection and turbulence, on the rotation and activity of these stars. We find that the rotation and activity of pre-main-sequence stars can be highly variable, depending on the physical processes that are occurring within the stars.\n\nWe also consider the impact of the rotation and activity of pre-main-sequence stars on the evolution of their solar systems. We find that the activity of these stars can have a significant impact on the evolution of planets and other celestial objects, and that the rotation of these stars can affect the stability of their solar systems.\n\nOur results suggest that the rotation and activity of pre-main-sequence stars is an important topic of study, and that further research in this area can provide important insights into the evolution of stars and their solar systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Light curves and colours of the faint Uranian irregular satellites\n  Sycorax, Prospero, Stephano, Setebos and Trinculo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2187, "human_text": "  After the work of Gladman et al. (1998), it is now assessed that many\nirregular satellites are orbiting around Uranus. Despite many studies have been\nperformed in past years, very few is know for the light-curves of these objects\nand inconsistencies are present between colours derived by different authors.\nThis situation motivated our effort to improve both the knowledge of colours\nand light curves. We present and discuss time series observations of Sycorax,\nProspero, Stephano, Setebos and Trinculo, five faint irregular satellites of\nUranus, carried out at VLT, ESO Paranal (Chile) in the nights between 29 and 30\nJuly, 2005 and 25 and 30 November, 2005. We derive light curves for Sycorax and\nProspero and colours for all of these these bodies. For Sycorax we obtain\ncolours B-V =0.839 +/- 0.014, V-R = 0.531 +/- 0.005 and a light curve which is\nsuggestive of a periodical variation with period about 3.6 hours and amplitude\nabout 0.067 +/- 0.004 mag. The periods and colours we derive for Sycorax are in\nagreement with our previous determination in 1999 using NTT. We derive also a\nlight-curve for Prospero which suggests an amplitude of about 0.2 mag and a\nperiodicity of about 4 hours. However, the sparseness of our data, prevents a\nmore precise characterization of the light-curves, and we can not determine\nwether they are one-peaked or two-peaked. Hence, these periods and amplitudes\nhave to be considered preliminary estimates. As for Setebos, Stephano and\nTrinculo the present data do not allow to derive any unambiguous periodicity,\ndespite Setebos displays a significant variability with amplitude about as\nlarge as that of Prospero. Colours for Prospero, Setebos, Stephano and Trinculo\nare in marginal agreement with the literature.\n", "machine_text": "\n\nWe present new visible and near-infrared photometry of the Uranian irregular satellites Sycorax, Prospero, Stephano, Setebos and Trinculo, obtained with the Hubble Space Telescope. We show that the satellites exhibit considerable colour diversity, particularly in the range 0.8\u20131.5 \u03bcm. Prospero and Stephano are relatively red, while Sycorax, Setebos and Trinculo are much bluer. The colours are stable with time, within the 1% level, except for Stephano, whose colour has changed by ~75% since 1999. We discuss the origin of the colour diversity in terms of different degrees of spacecraft contamination and photodegradation of the polymers and other materials composing the surfaces of the satellites. We estimate the size of the satellites by comparison with the radii of dust particles in the environment, and find that all of the irregulars are larger than 5 km in diameter, except for Setebos. We discuss the implications of our results for the evolution and origin of the irregular satellites, and the surface composition of the larger satellites.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Self assembly of a model multicellular organism resembling the\n  Dictyostelium slime molds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0227, "human_text": "  The evolution of multicellular organisms from monocellular ancestors\nrepresents one of the greatest advances of the history of life. The assembly of\nsuch multicellular organisms requires signalling and response between cells:\nover millions of years these signalling processes have become extremely\nsophisticated and refined by evolution, such that study of modern organisms may\nnot be able to shed much light on the original ancient processes . Here we are\ninterested in determining how simple a signalling method can be, while still\nachieving self-assembly. In 2D a coupled cellular automaton/differential\nequation approach models organisms and chemotaxic chemicals, producing\nspiralling aggregation. In 3D Lennard-Jones-like particles are used to\nrepresent single cells, and their evolution in response to signalling is\nfollowed by molecular dynamics. It is found that if a single cell is able to\nemit a signal which induces others to move towards it, then a colony of\nsingle-cell organisms can assemble into shapes as complex as a tower, a ball\natop a stalk, or a fast-moving slug. The similarity with the behaviour of\nmodern Dictyostelium slime molds signalling with cyclic adenosine monophosphate\n(cAMP) is striking.\n", "machine_text": "\n\nWe have developed a simple model multicellular organism that resembles the real multicellular organism Dictyostelium in several aspects. The model organism is composed of a large number of cells that can communicate with each other via gap junctions. Each cell is modeled as a set of compartments that represent the internal structures of the cell, such as the nucleus, the Golgi apparatus, the endoplasmic reticulum, etc. We used a modified version of the Kermit algorithm to obtain a color-based distinction between the different internal structures. This is achieved by analyzing the 3-dimensional structure of the cells, in particular, the topology of the transport network. The transport network is constructed from the 3-d pixel connectivity, using the information of the location of the internal structures. The communication via the gap junctions is reflected in a long-range synchronization of the internal structures. We show that this model can undergo a development similar to the one observed in the real Dictyostelium. In particular, we observe a transition from a disordered state, in which the cells are not synchronized, to a ordered state, in which the cells are synchronized. This transition is accompanied by a fast increase in the number of gap junctions. We discuss the mechanism of the development and the similarities and differences between the model and the real organism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer-IRAC GLIMPSE of high mass protostellar objects. I Infrared point\n  sources and nebulae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4399, "human_text": "  The GLIMPSE archive was used to obtain 3.6--8.0micron, point source\nphotometry and images for 381 massive protostellar candidates lying in the\nGalactic mid-plane. The colours, magnitudes and spectral indicies of sources in\neach of the 381 target fields were analysed and compared with the predictions\nof 2D radiative transfer model simulations. Although no discernable embedded\nclusters were found in any targets, multiple sources or associations of\nredenned young stellar objects were found in many sources indicating\nmultiplicity at birth. The spectral index ($\\alpha$) of these point sources in\n3.6--8.0mum bands display large values of $\\alpha$=2--5. A color-magnitude\nanalog plot was used to identify 79 infrared counterparts to the HMPOs. Compact\nnebulae are found in 75% of the detected sources with morphologies that can be\nwell described by core-halo, cometary, shell-like and bipolar geometries\nsimilar to those observed in ultra-compact HII regions. The IRAC band SEDs of\nthe IR counterparts of HMPOs are best described to represent YSOs with a mass\nrange of 8--20\\msun in their Class I stages when compared with 2D radiative\ntransfer models. They also suggest that the high $\\alpha$ values represent\nreprocessed star/star+disk emission that is arising in the dense envelopes.\nThus we are witnessing the luminous envelopes around the protostars rather than\ntheir photospheres or disks. We argue that the compact infrared nebulae likely\nreflect the underlying physical structure of the dense cores and are found to\nimitate the morphologies of known UCHII regions. Our results favour models of\ncontinuuing accretion involving both molecular and ionised accretion components\nto build the most massive stars rather than purely molecular rapid accretion\nflows.\n", "machine_text": "\n\nWe present Spitzer-IRAC GLIMPSE (Great Lyon's probe for the inner and mid-plane structure of protoplanetary objects) results for 42 high mass protostellar objects (HMPSOs), and find a strong correlation between the mid-IR and far-IR colors of the HMPSOs. The mid-IR colors show a well-defined difference between compact and extended sources. The compact HMPSOs are characterized by a blue color, while the extended sources are red. The difference in color is such that we can identify unambiguously the nature of the observed HMPSOs in the mid-IR, independently of the resolution. We conclude that the mid-IR color is a powerful tool to study the inner structure of the HMPSOs, and the far-IR a powerful tool to study the outer structure. The correlation between the mid-IR and far-IR colors can be explained by a simple model in which the compact HMPSOs are surrounded by a cold inner layer, and the extended sources are embedded in a hot outer layer. We show that the ratio of the far-IR to mid-IR colors is a strong indicator of the mass of the inner object. Our results suggest that the mass of the inner object is a key parameter in the formation and evolution of HMPSOs, with the mass distribution in the inner few AU possibly controlling the accretion process.\n\nWe present a model in which the non-LTE spectrum of a HMPSO is the sum of the spectra of the inner and outer objects, weighted by the distance $r$. Our model predicts a strong correlation between the mid-IR and far-IR colors of HMPSOs, which we observe in our data. The model can be used to infer the relative mass of the inner and outer objects, provided that the inner object is compact. We discuss several ways in which the compact inner object can form. We show that the observed correlation between the mid-IR and far-IR colors can be used to constrain the mass of the compact object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The anticenter old open cluster NGC 1883: radial velocity and\n  metallicity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.23, "human_text": "  Having already reported on the first photometric study of the\nintermediate-age open cluster NGC 1883 (Carraro et al. 2003), we present in\nthis paper the first spectroscopic multi-epoch investigation of a sample of\nevolved stars in the same cluster. The aim is to derive the cluster membership,\nvelocity and metallicity, and discuss recent claims in the literature (Tadross\n2005) that NGC 1883 is as metal poor as globular clusters in the Halo. Besides,\nbeing one of the few outer Galactic disk intermediate-age open clusters known\nso far, it is an ideal target to improve our knowledge of the Galactic disk\nradial abundance gradient, that is a basic ingredient for any chemical\nevolution model of the Milky Way. The new data we obtained allow us to put NGC\n1883's basic parameters more reliable. We find that the cluster has a mean\nmetallicity of [Fe/H] = -0.20$\\pm$0.22, from which we infer an age\n(650$^{+70}_{-70}$ Myr) close to the Hyades one and a Galactocentric distance\nof 12.3$^{+0.4}_{-0.2}$ kpc. The metal abundance, kinematics, and position make\nNGC 1883 a genuine outer disk intermediate-age open cluster. We confirm that in\nthe outer Galactic disk the abundance gradient is shallower than in the solar\nvicinity.\n", "machine_text": "\n\nThe Anticenter Old Open Cluster NGC 1883: Radial Velocity and Metallicity\n\nWe present a study of the radial velocity and metallicity of 75 stars in the old open cluster NGC 1883. The sample consists of 31 giants and 44 turn-off stars selected from a catalog of over 200 cluster members observed with the Fabry-Perot telescope at La Silla. The radial velocities were measured with the MIKE-700 spectrometer attached to the MIKE-4 telescope at La Silla. The metallicities were obtained from high-resolution spectra taken with the FEROS spectrometer at the 2.2 m telescope at La Silla. The radial velocities show that the cluster is at an average velocity of 60 km s$^{-1}$ and has a systemic velocity of 65 km s$^{-1}$. The metallicities are in the range [Fe/H] = +0.08 to +0.35. These values are in good agreement with the metallicities of turn-off stars in the Pleiades and Hyades, and suggest that the cluster formed in a medium- metallicity gas cloud. The radial velocity distribution of the cluster members is well described by a Gaussian with a width of 8 km s$^{-1}$. The cluster has a tidal radius of 8.9 pc, a half-mass radius of 4.4 pc, and a mass of 2.2 x 10^4 M$_{\\odot}$. We have found no evidence for the presence of an old embedded cluster.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal noise informatics: Totally secure communication via a wire;\n  Zero-power communication; and Thermal noise driven computing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0158, "human_text": "  Very recently, it has been shown that thermal noise and its artificial\nversions (Johnson-like noises) can be utilized as an information carrier with\npeculiar properties therefore it may be proper to call this topic Thermal Noise\nInformatics. Zero Power (Stealth) Communication, Thermal Noise Driven\nComputing, and Totally Secure Classical Communication are relevant examples. In\nthis paper, while we will briefly describe the first and the second subjects,\nwe shall focus on the third subject, the secure classical communication via\nwire. This way of secure telecommunication utilizes the properties of\nJohnson(-like) noise and those of a simple Kirchhoff's loop. The communicator\nis unconditionally secure at the conceptual (circuit theoretical) level and\nthis property is (so far) unique in communication systems based on classical\nphysics. The communicator is superior to quantum alternatives in all known\naspects, except the need of using a wire. In the idealized system, the\neavesdropper can extract zero bit of information without getting uncovered. The\nscheme is naturally protected against the man-in-the-middle attack. The\ncommunication can take place also via currently used power lines or phone\n(wire) lines and it is not only a point-to-point communication like quantum\nchannels but network-ready. Tests have been carried out on a model-line with\nranges beyond the ranges of any known direct quantum communication channel and\nthey indicate unrivalled signal fidelity and security performance. This simple\ndevice has single-wire secure key generation/sharing rates of 0.1, 1, 10, and\n100 bit/second for copper wires with diameters/ranges of 21 mm / 2000 km, 7 mm\n/ 200 km, 2.3 mm / 20 km, and 0.7 mm / 2 km, respectively and it performs with\n0.02% raw-bit error rate (99.98 % fidelity).\n", "machine_text": "\n\nThermal noise informatics: Totally secure communication via a wire; Zero-power communication; and Thermal noise driven computing.\n\nWe present a new approach to information processing that uses thermal noise as the information carrier. We show that the shot noise current in a resistor can be used to transmit information, and that such a channel can be used to implement a one-way communication channel that is totally secure, and requires zero-power from the transmitter. We also show that thermal noise can be used as the information carrier in a two-way communication protocol, and that such a protocol can be used to implement a totally secure communication channel, again, requiring zero-power from the transmitter. We further show that thermal noise can be used as the basis for a computing architecture that is secure, and operates at zero-power. We show that a thermal noise source can be used to drive a watchdog circuit that operates at zero-power, and that such a watchdog circuit can be used to drive a computing element that operates at zero-power. We show that such a zero-power, thermal noise driven watchdog-computing element can be used to implement a totally secure computing architecture.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of Macroscopic Quantum Tunneling in High-T_c c-Axis Josephson\n  Junctions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1418, "human_text": "  We study macroscopic quantum tunneling (MQT) in c-axis twist Josephson\njunctions made of high-T_c superconductors in order to clarify the influence of\nthe anisotropic order parameter symmetry (OPS) on MQT. The dependence of the\nMQT rate on the twist angle $\\gamma$ about the c-axis is calculated by using\nthe functional integral and the bounce method. Due to the d-wave OPS, the\n$\\gamma$ dependence of standard deviation of the switching current distribution\nand the crossover temperature from thermal activation to MQT are found to be\ngiven by $\\cos2\\gamma$ and $\\sqrt{\\cos2\\gamma}$, respectively. We also show\nthat a dissipative effect resulting from the nodal quasiparticle excitation on\nMQT is negligibly small, which is consistent with recent MQT experiments using\nBi${}_2$Sr${}_2$CaCu${}_2$O${}_{8 + \\delta}$ intrinsic junctions. These results\nindicate that MQT in c-axis twist junctions becomes a useful experimental tool\nfor testing the OPS of high-T_c materials at low temperature, and suggest high\npotential of such junctions for qubit applications.\n", "machine_text": "\n\nWe have developed a theory of macroscopic quantum tunneling in high-T_c c-axis Josephson junctions, which we have tested against a variety of experiments. In a typical experiment, a superconducting tape is patterned into a long array of Josephson junctions, each of which is 0.5-1 micron in length and separated by an insulator. When the array is biased with a DC current, each junction is found to have a critical current density for supercurrent passage, I_c, which is several times greater than that expected from an ideal thermodynamic equilibrium condition, and a non-Equilibrium transport behavior, which we show to be in agreement with a model in which a macroscopic quantum tunneling process is invoked to describe the transport in these junctions. We analyze a series of experiments in which the role of the bias current, the thickness of the insulator, and the temperature is varied, in each case successfully explaining the results in terms of a theory of macroscopic quantum tunneling in which a massless exciton-like particle is coherently transported through the barrier between the superconducting electrodes. We also show that the theory predicts a non-monotonic behavior of I_c as a function of the thickness of the insulator, in qualitative agreement with a set of experiments in which the thickness of the insulator is varied over a wide range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evidence Of Dark Matter Annihilations In The WMAP Haze. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3655, "human_text": "  The WMAP experiment has revealed an excess of microwave emission from the\nregion around the center of our Galaxy. It has been suggested that this signal,\nknown as the ``WMAP Haze'', could be synchrotron emission from relativistic\nelectrons and positrons generated in dark matter annihilations. In this letter,\nwe revisit this possibility. We find that the angular distribution of the WMAP\nHaze matches the prediction for dark matter annihilations with a cusped density\nprofile, $\\rho(r) \\propto r^{-1.2}$ in the inner kiloparsecs. Comparing the\nintensity in different WMAP frequency bands, we find that a wide range of\npossible WIMP annihilation modes are consistent with the spectrum of the haze\nfor a WIMP with a mass in the 100 GeV to multi-TeV range. Most interestingly,\nwe find that to generate the observed intensity of the haze, the dark matter\nannihilation cross section is required to be approximately equal to the value\nneeded for a thermal relic, $\\sigma v \\sim 3 \\times 10^{-26}$ cm$^3$/s. No\nboost factors are required. If dark matter annihilations are in fact\nresponsible for the WMAP Haze, and the slope of the halo profile continues into\nthe inner Galaxy, GLAST is expected to detect gamma rays from the dark matter\nannihilations in the Galactic Center if the WIMP mass is less than several\nhundred GeV.\n", "machine_text": "\n\nWe present evidence of dark matter annihilations in the WMAP Haze. The large scale structure in the matter power spectrum observed by WMAP is consistent with a Universe dominated by a Gaussian random field with a scale of approximately 250 hMpc. We show that this is consistent with the location of the peak of the matter power spectrum being a transition between a Gaussian random field and a pixelated one, in a manner analogous to the transition between a Poisson and a binomial distribution. This has the implication that the small scale structure in the matter power spectrum may be described by a pixelated distribution with a scale of order 1 hMpc, and may thus be due to the annihilation of dark matter. We present a simple model which quantitatively describes the small scale structure in the matter power spectrum observed by WMAP, and find that it is consistent with a transition between a Gaussian random field and a pixelated one, with the scale of the pixelation being proportional to the average number density of dark matter. We discuss the implications of this model for the nature of dark matter.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effective anisotropies and energy barriers of magnetic nanoparticles\n  with Neel surface anisotropy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1689, "human_text": "  Magnetic nanoparticles with Neel surface anisotropy, different internal\nstructures, surface arrangements and elongation are modelled as many-spin\nsystems. The results suggest that the energy of many-spin nanoparticles cut\nfrom cubic lattices can be represented by an effective one-spin potential\ncontaining uniaxial and cubic anisotropies. It is shown that the values and\nsigns of the corresponding constants depend strongly on the particle's surface\narrangement, internal structure and elongation. Particles cut from a simple\ncubic lattice have the opposite sign of the effective cubic term, as compared\nto particles cut from the face-centered cubic lattice. Furthermore, other\nremarkable phenomena are observed in nanoparticles with relatively strong\nsurface effects: (i) In elongated particles surface effects can change the sign\nof the uniaxial anisotropy. (ii) In symmetric particles (spherical and\ntruncated octahedral) with cubic core anisotropy surface effects can change its\nsign. We also show that the competition between the core and surface\nanisotropies leads to a new energy that contributes to both the 2nd- and\n4th-order effective anisotropies.\n", "machine_text": "\nEffective anisotropies and energy barriers of magnetic nanoparticles with Neel surface anisotropy.\n\nWe consider the effective anisotropy and the energy barrier of a ferromagnetic nanoparticle in a non-magnetic medium for a range of diameters and aspect ratios, in the limit of small magnetization, assuming the spherical nanoparticles to be fully magnetized and in the limit of large magnetization, assuming the magnetic dipole moment to be confined to the particle surface. The surface anisotropy constant depends on the ratio of the particle diameter to the exchange length. The anisotropy constant becomes positive for particles with diameters smaller than the exchange length and negative for particles with diameters much larger than the exchange length. We show that, for particles with diameters smaller than the exchange length, the energy barrier has a minimum with the direction of the easy axis of the surface anisotropy. In contrast, for particles with diameters much larger than the exchange length, the energy barrier has a maximum with the direction of the easy axis of the surface anisotropy. Our results can be used to optimize the magnetic response of nanoparticles with different diameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Note on the Inapproximability of Correlation Clustering. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2092, "human_text": "  We consider inapproximability of the correlation clustering problem defined\nas follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\"\n(similar) or \"-\" (dissimilar), correlation clustering seeks to partition the\nvertices into clusters so that the number of pairs correctly (resp.\nincorrectly) classified with respect to the labels is maximized (resp.\nminimized). The two complementary problems are called MaxAgree and MinDisagree,\nrespectively, and have been studied on complete graphs, where every edge is\nlabeled, and general graphs, where some edge might not have been labeled.\nNatural edge-weighted versions of both problems have been studied as well. Let\nS-MaxAgree denote the weighted problem where all weights are taken from set S,\nwe show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\delta})$\nessentially belongs to the same hardness class in the following sense: if there\nis a polynomial time algorithm that approximates S-MaxAgree within a factor of\n$\\lambda = O(\\log{|V|})$ with high probability, then for any choice of S',\nS'-MaxAgree can be approximated in polynomial time within a factor of $(\\lambda\n+ \\epsilon)$, where $\\epsilon > 0$ can be arbitrarily small, with high\nprobability. A similar statement also holds for $S-MinDisagree. This result\nimplies it is hard (assuming $NP \\neq RP$) to approximate unweighted MaxAgree\nwithin a factor of $80/79-\\epsilon$, improving upon a previous known factor of\n$116/115-\\epsilon$ by Charikar et. al. \\cite{Chari05}.\n", "machine_text": "\n\nWe show that correlation clustering, a popular clustering algorithm that has been used to extract subtle structure in data, is NP-hard to approximate to within any constant factor. This answers a question oftradition, and suggests that approximation algorithms for this problem are unlikely to be found.\n\nWe show further that even if the problem is approximable, the approximation algorithm would have to be \" KT-cladistic\". This answers a question ofLgetInstance()ance, and suggests that such an algorithm would have little practical value.\n\nWe show finally that the problem is APX-hard to approximate, and hence unlikely to be approximable in practice.\n\nThese results apply to the problem of finding a minimum correlation among all partitions of the data. They also apply to the problem of finding a partition of minimum correlation among all possible partitions, provided that the number of clusters is fixed. They do not apply to the problem of finding a minimum correlation among all possible partitions, even if the number of clusters is fixed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Hopf Algebra Structure of the Character Rings of Classical Groups. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2029, "human_text": "  The character ring \\CGL of covariant irreducible tensor representations of\nthe general linear group admits a Hopf algebra structure isomorphic to the Hopf\nalgebra \\Sym$ of symmetric functions. Here we study the character rings \\CO and\n\\CSp of the orthogonal and symplectic subgroups of the general linear group\nwithin the same framework of symmetric functions. We show that \\CO and \\CSp\nalso admit natural Hopf algebra structures that are isomorphic to that of \\CGL,\nand hence to \\Sym. The isomorphisms are determined explicitly, along with the\nspecification of standard bases for \\CO and \\CSp analogous to those used for\n\\Sym. A major structural change arising from the adoption of these bases is the\nintroduction of new orthogonal and symplectic Schur-Hall scalar products.\nSignificantly, the adjoint with respect to multiplication no longer coincides,\nas it does in the \\CGL case, with a Foulkes derivative or skew operation. The\nadjoint and Foulkes derivative now require separate definitions, and their\nproperties are explored here in the orthogonal and symplectic cases. Moreover,\nthe Hopf algebras \\CO and \\CSp are not self-dual. The dual Hopf algebras \\CO^*\nand \\CSp^* are identified. Finally, the Hopf algebra of the universal rational\ncharacter ring \\CGLrat of mixed irreducible tensor representations of the\ngeneral linear group is introduced and its structure maps identified.\n", "machine_text": "\n\nWe give a detailed account of the structure of the character rings of the classical groups over fields which are neither algebraic nor topological in origin. The approach is via the study of certain ( raided ) functors which form a two - level structure on the category of finite - dimensional representations of the classical groups. We show that the source and the target of these functors are the hopf algebras and that they are related by the well - known equivalence of categories between the representations of the classical groups and the self - adjoint representations of the symmetric groups. The main tool is the use of the celebrated representation - theoretic fact that the character ring of a representation of a finite group G is isomorphic to the quotient ring of the algebra of G - invariant linear forms on the algebra of all linear forms on the underlying vector space. We show that, in the presence of an algebra isomorphism between the character rings of two representations, the original representations can be recovered from the character rings up to equivalence. As an application, we give a description of the character ring of the regular representation of the symmetric group in terms of the Schur parameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sparticle Spectra and LHC Signatures for Large Volume String\n  Compactifications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3403, "human_text": "  We study the supersymmetric particle spectra and LHC collider observables for\nthe large-volume string models with a fundamental scale of 10^{11} GeV that\narise in moduli-fixed string compactifications with branes and fluxes. The\npresence of magnetic fluxes on the brane world volume, required for chirality,\nperturb the soft terms away from those previously computed in the dilute-flux\nlimit. We use the difference in high-scale gauge couplings to estimate the\nmagnitude of this perturbation and study the potential effects of the magnetic\nfluxes by generating many random spectra with the soft terms perturbed around\nthe dilute flux limit. Even with a 40% variation in the high-scale soft terms\nthe low-energy spectra take a clear and predictive form. The resulting spectra\nare broadly similar to those arising on the SPS1a slope, but more degenerate.\nIn their minimal version the models predict the ratios of gaugino masses to be\nM_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage\nmediation. Among the scalars, the squarks tend to be lighter and the sleptons\nheavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC\ndata for the random spectra in order to study the range of collider\nphenomenology that can occur. We perform a detailed mass reconstruction on one\nexample large-volume string model spectrum. 100 fb^{-1} of integrated\nluminosity is sufficient to discriminate the model from mSUGRA and aspects of\nthe sparticle spectrum can be accurately reconstructed.\n", "machine_text": "\nWe consider the production of sparticles (i.e. lighter counterparts of the standard model quarks and charged leptons) in the framework of large volume string compactifications. In particular, we consider the sparticle spectra which can be generated by wrapping D-branes at different dimensions around a compactification of the large volume string. We find that a significant number of sparticles can be generated, and their masses can be as small as the tree level masses of the standard model quarks and charged leptons. In addition, we find that the produced sparticles can be grouped into several generations, and that the number of generations can be as large as three. We also discuss the production mechanism of the sparticles, and find that the large volume string has the potential to produce sparticles in a large mass range, and in large numbers. Furthermore, we discuss the LHC signatures for the large volume string compactifications, and find that the LHC can potentially see the signatures for a large volume string which is wrapped around a compactification of large radius.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmological Constraints on f(R) Acceleration Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2399, "human_text": "  Models which accelerate the expansion of the universe through the addition of\na function of the Ricci scalar f(R) leave a characteristic signature in the\nlarge-scale structure of the universe at the Compton wavelength scale of the\nextra scalar degree of freedom. We search for such a signature in current\ncosmological data sets: the WMAP cosmic microwave background (CMB) power\nspectrum, SNLS supernovae distance measures, the SDSS luminous red galaxy power\nspectrum, and galaxy-CMB angular correlations. Due to theoretical uncertainties\nin the nonlinear evolution of f(R) models, the galaxy power spectrum\nconservatively yields only weak constraints on the models despite the strong\npredicted signature in the linear matter power spectrum. Currently the tightest\nconstraints involve the modification to the integrated Sachs-Wolfe effect from\ngrowth of gravitational potentials during the acceleration epoch. This effect\nis manifest for large Compton wavelengths in enhanced low multipole power in\nthe CMB and anti-correlation between the CMB and tracers of the potential. They\nplace a bound on the Compton wavelength of the field be less than of order the\nHubble scale.\n", "machine_text": "\nWe consider the constraints that the latest cosmological observations place on f(R) models, which are scalar fields theories with a variable equation of state (f(R) = the function that relates the scalar field variable R to its potential). We show that a f(R) model with a variable equation of state can successfully describe the recent observations, provided that the variable equation of state is very close to a cosmological constant. We consider a possible physical explanation for this result, by analogy with the recently proposed \u2018hypertensor\u2019 model. We also point out that a variable equation of state with a small parameter that is not close to a cosmological constant can successfully describe the recent observations, provided that the parameter is dynamically controlled by the evolution of the Universe. This can be achieved by adding a variable cosmological constant to a model with a variable equation of state, so that the total equation of state is the sum of the two contributions, provided that the cosmological constant contribution is dynamically controlled by the evolution of the Universe. We show that a simple model in which the cosmological constant is related to the variable equation of state by a non-trivial power law can successfully describe the recent observations, provided that the power law parameter is dynamically controlled by the evolution of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: How to clean a dirty floor: Probabilistic potential theory and the\n  Dobrushin uniqueness theorem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3156, "human_text": "  Motivated by the Dobrushin uniqueness theorem in statistical mechanics, we\nconsider the following situation: Let \\alpha be a nonnegative matrix over a\nfinite or countably infinite index set X, and define the \"cleaning operators\"\n\\beta_h = I_{1-h} + I_h \\alpha for h: X \\to [0,1] (here I_f denotes the\ndiagonal matrix with entries f). We ask: For which \"cleaning sequences\" h_1,\nh_2, ... do we have c \\beta_{h_1} ... \\beta_{h_n} \\to 0 for a suitable class of\n\"dirt vectors\" c? We show, under a modest condition on \\alpha, that this occurs\nwhenever \\sum_i h_i = \\infty everywhere on X. More generally, we analyze the\ncleaning of subsets \\Lambda \\subseteq X and the final distribution of dirt on\nthe complement of \\Lambda. We show that when supp(h_i) \\subseteq \\Lambda with\n\\sum_i h_i = \\infty everywhere on \\Lambda, the operators \\beta_{h_1} ...\n\\beta_{h_n} converge as n \\to \\infty to the \"balayage operator\" \\Pi_\\Lambda =\n\\sum_{k=0}^\\infty (I_\\Lambda \\alpha)^k I_{\\Lambda^c). These results are\nobtained in two ways: by a fairly simple matrix formalism, and by a more\npowerful tree formalism that corresponds to working with formal power series in\nwhich the matrix elements of \\alpha are treated as noncommuting indeterminates.\n", "machine_text": "\n\nWe consider the problem of how to clean a dirty floor in a room with two entrances. We suppose that the dirt on the floor is distributed according to a given probability measure and that the cleaner has two strategies available: a standard strategy, which is a fixed procedure that always cleans the floor in the same way, and a random strategy, which chooses a random path over the floor and thus has the potential to be more efficient in principle. We investigate the behavior of the random strategy as the dirt on the floor becomes more concentrated, that is, as the potential function becomes more non-null. We show that the random strategy converges to the standard strategy as the potential function goes to infinity. This convergence is guaranteed by a uniqueness theorem due to Dobrushin. We derive an approximation theorem that relates the random strategy to a finite number of non-overlapping regions of the floor, and thus to the kind of random walk that is known as a random walk on a lattice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory for superconductivity in a magnetic field: A local approximation\n  approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2394, "human_text": "  We present a microscopic theory for superconductivity in a magnetic field\nbased on a local approximation approach. We derive an expression for free\nenergy density $F$ as a function of temperature $T$ and vector potential {\\bf\na}, and two basic equations of the theory: the first is an implicit solution\nfor energy gap parameter amplitude $|\\Delta_{\\bf k}|$ as a function of wave\nvector {\\bf k}, temperature $T$ and vector potential {\\bf a}; and the second is\na London-like relation between electrical current density {\\bf j} and vector\npotential {\\bf a}, with an ``effective superconducting electron density'' $n_s$\nthat is both $T$- and {\\bf a}-dependent. The two equations allow determination\nof spatial variations of {\\bf a} and $|\\Delta_{\\bf k}|$ in a superconductor for\ngiven temperature $T$, applied magnetic field ${\\bf H}_a$ and sample geometry.\nThe theory shows the existence of a ``partly-paired state,'' in which paired\nelectrons (having $|\\Delta_{\\bf k}|>0$) and de-paired electrons (having\n$|\\Delta_{\\bf k}|=0$) co-exist. Such a ``partly-paired state'' exists even at\nT=0 when $H_a$ is above a threshold for a given sample, giving rise to a\nnon-vanishing Knight shift at T=0 for $H_a$ above the threshold. We expect the\ntheory to be valid for highly-local superconductors for all temperatures and\nmagnetic fields below the superconducting transition. In the low-field limit,\nthe theory reduces to the local-limit result of BCS. As examples, we apply the\ntheory to the case of a semi-infinite superconductor in an applied magnetic\nfield ${\\bf H}_a$ parallel to the surface of the superconductor and the case of\nan isolated vortex in an infinite superconductor, and determine, in each case,\nspatial variations of quantities such as {\\bf a} and $|\\Delta_{\\bf k}|$. We\nalso calculate...\n", "machine_text": "\nWe propose a theory for superconductivity in a magnetic field based on a local approximation approach. Our theory accounts for the anisotropic nature of the superconducting order parameter, the fact that the superconductivity is strongly coupled to the magnetic field, and the energy scales of the problem. Within our framework, superconductivity in a magnetic field is regarded as a competition between anisotropic superconductivity and magnetic order. We determine the minimal anisotropic order parameter and the corresponding symmetry of the superconducting order parameter. Our theory predicts a transition temperature T_c^{*} below which the system is in the normal conducting state with a minimal superconducting order parameter of vanishing magnitude. We also derive a simplified model in which the anisotropic order parameter is replaced by a isotropic one. The predictions of this model are in good agreement with the experimental results for the system with the anisotropic order parameter in a strong magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new comprehensive set of elemental abundances in DLAs III. Star\n  formation histories. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.165, "human_text": "  We obtained comprehensive sets of elemental abundances for eleven damped\nLy-alpha systems (DLAs) at z_DLA=1.7-2.5. In Paper I of this series, we showed\nfor three DLA galaxies that we can derive their star formation histories and\nages from a detailed comparison of their intrinsic abundance patterns with\nchemical evolution models. We determine in this paper the star formation\nproperties of six additional DLA galaxies. The derived results confirm that no\nsingle star formation history explains the diverse sets of abundance patterns\nin DLAs. We demonstrate that the various star formation histories reproducing\nthe DLA abundance patterns are typical of local irregular, dwarf starburst and\nquiescent spiral galaxies. Independent of the star formation history, the DLAs\nhave a common characteristic of being weak star forming galaxies; models with\nhigh star formation efficiencies are ruled out. All the derived DLA star\nformation rates per unit area are moderate or low, with values between -3.2 <\nlog SFR < -1.1 M_sol yr^{-1} kpc^{-2}. The DLA abundance patterns require a\nlarge spread in ages ranging from 20 Myr up to 3 Gyr. The oldest DLA in our\nsample is observed at z_DLA=1.864 with an age estimated to more than 3 Gyr; it\nnicely indicates that galaxies were already forming at z_f>10. But, most of the\nDLAs show ages much younger than that of the Universe at the epoch of\nobservation. Young galaxies thus seem to populate the high redshift Universe at\nz>2, suggesting relatively low redshifts of formation (z~3) for most\nhigh-redshift galaxies. The DLA star formation properties are compared with\nthose of other high-redshift galaxies identified in deep imaging surveys with\nthe aim of obtaining a global picture of high-redshift objects.\n", "machine_text": "\nWe present a new comprehensive set of elemental abundances in dwarf late-type stars (DLAs) from high-resolution, high signal-to-noise ratio echelle spectroscopy of a carefully selected sample of 98 DLAs with solar metallicity. We have derived abundances for 31 chemical elements (Na, Mg, Al, Si, K, Ca, Sc, Ti, V, Cr, Mn, Fe, Co, Ni, Cu, Zn, Ga, In, Sn, Pb, Bi, Ce, La, Pr, Nd, Pm, Sm, Eu, Gd, Tb, Dy, Ho, Er, Tm, Yb, Lu) including the elements from hydrogen to nickel, which have not been reported in the literature for this kind of object. The internal consistency of the set of abundances is very good. We have used the new abundances to derive the star formation history (SFH) of the galactic disk. Our results are consistent with a single-zone model for the SFH with a constant star formation rate (SFR) of 2.5 \u00b1 0.2 M\u2299 yr-1. We have also derived a correlation between the space velocity and the metal content of the stars, which can be used to select stars with a large range of metallicities in order to study the variations of the SFH.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Communication Model for Adaptive Service Provisioning in Hybrid\n  Wireless Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.113, "human_text": "  Mobile entities with wireless links are able to form a mobile ad-hoc network.\nSuch an infrastructureless network does not have to be administrated. However,\nself-organizing principles have to be applied to deal with upcoming problems,\ne.g. information dissemination. These kinds of problems are not easy to tackle,\nrequiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks\nis arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could\neliminate the need for any fixed infrastructure, has been damped. The goal is\nto overcome the limitations of pure ad-hoc networks by augmenting them with\ninstant Internet access, e.g. via integration of UMTS respectively GSM links.\nHowever, this raises multiple questions at the technical as well as the\norganizational level. Motivated by characteristics of small-world networks that\ndescribe an efficient network even without central or organized design, this\npaper proposes to combine mobile ad-hoc networks and infrastructured networks\nto form hybrid wireless networks. One main objective is to investigate how this\napproach can reduce the costs of a permanent backbone link and providing in the\nsame way the benefits of useful information from Internet connectivity or\nservice providers. For the purpose of bridging between the different types of\nnetworks, an adequate middleware service is the focus of our investigation.\nThis paper shows our first steps forward to this middleware by introducing the\nInjection Communication paradigm as principal concept.\n", "machine_text": "\nWe propose a communication model for adaptive service provisioning in hybrid wireless networks. Our model is motivated by the observation that, despite the significant advances in wireless communications, the provisioning of high-quality services over wireless networks remains a challenge. In particular, we focus on scenarios where a service provider has to offer services to users with heterogeneous wireless communication capabilities. Our model enables the service provider to efficiently allocate network resources among users with different capabilities, while maximizing the overall service quality perceived by all users. The model is based on a stochastic reward model, which takes into account the service quality perceived by each user and the wireless communication capabilities of each user. We show that the proposed model is equivalent to a stochastic game, where the service provider and the users are the players. We analyze the game and propose a solution, which results in a system of stochastic differential equations. We show that this system of equations has a unique solution, which corresponds to the optimal allocation of network resources among the users. Finally, we validate our results through simulations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-Markovian entanglement dynamics of quantum continuous variable\n  systems in thermal environments. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0996, "human_text": "  We study two continuous variable systems (or two harmonic oscillators) and\ninvestigate their entanglement evolution under the influence of non-Markovian\nthermal environments. The continuous variable systems could be two modes of\nelectromagnetic fields or two nanomechanical oscillators in the quantum domain.\nWe use quantum open system method to derive the non-Markovian master equations\nof the reduced density matrix for two different but related models of the\ncontinuous variable systems. The two models both consist of two interacting\nharmonic oscillators. In model A, each of the two oscillators is coupled to its\nown independent thermal reservoir, while in model B the two oscillators are\ncoupled to a common reservoir. To quantify the degrees of entanglement for the\nbipartite continuous variable systems in Gaussian states, logarithmic\nnegativity is used. We find that the dynamics of the quantum entanglement is\nsensitive to the initial states, the oscillator-oscillator interaction, the\noscillator-environment interaction and the coupling to a common bath or to\ndifferent, independent baths.\n", "machine_text": "\nWe study non-Markovian entanglement dynamics of quantum continuous variable systems in thermal environments. We show that thermal noise can have a significant impact on the entanglement dynamics, in particular the entanglement per time evolution, in spite of the fact that it does not change the average entanglement. Our results indicate that a careful account of the non-Markovian dynamics is essential for a complete description of the effects of the environment on entanglement. We also analyze the time-evolution of the tomahawk state, a special state which is robust against thermal noise, and show that it does not evolve according to the usual Markovian dynamics. Finally, we show that the two-time-slot squeezed-statetomahawk-state transformation, recently proposed as a practical scheme for transforming a squeezed state into a tomahawk state, is in fact non-Markovian. Our results have important practical implications for the realization of quantum continuous variable systems in thermal environments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measurement of the spin polarization of the magnetic semiconductor EuS\n  with zero-field and Zeeman-split Andreev reflection spectroscopy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1582, "human_text": "  We report measurements of the spin polarization (\\textbf{\\textit{P}}) of the\nconcentrated magnetic semiconductor EuS using both zero-field and Zeeman-split\nAndreev reflection spectroscopy (ARS) with EuS/Al planar junctions. The\nzero-field ARS spectra are well described by the modified (spin-polarized) BTK\nmodel with expected superconducting energy gap and actual measurement\ntemperature (no additional spectral broadening). The fittings consistently\nyield \\textbf{\\textit{P}} close to 80% regardless of the barrier strength.\nMoreover, we performed ARS in the presence of a Zeeman-splitting of the\nquasiparticle density of states in Al. To describe the Zeeman-split ARS\nspectra, we develop a theoretical model which incorporates the solution to the\nMaki-Fulde equations into the modified BTK analysis. The method enables the\ndetermination of the magnitude as well as the sign of \\textbf{\\textit{P}} with\nARS, and the results are consistent with those from the zero-field ARS. The\nexperiments extend the utility of field-split superconducting spectroscopy from\ntunnel junctions to Andreev junctions of arbitrary barrier strengths.\n", "machine_text": "\nWe present the results of a zero-field and Zeeman-split Andreev reflection spectroscopy study of the spin-dependent transport in single crystals of the magnetic semiconductor EuS. We show that the spin-dependent transport can be explained in terms of a simple model which comprises a non-hysteretic spin-dependent Mott variable range hopping and a uniform spin-dependent Anderson delocalization of the transport across the entire energy spectrum. We show that by using the technique of Andreev reflection spectroscopy we can access the spin-dependent transport in a clean way, without any contribution from the non-Mott variable range hopping. Our results show that the spin-dependent transport in EuS is sensitive to an external magnetic field in a way that is consistent with the predictions of the model. We also found a non-monotonic behavior of the spin-dependent conductivity as a function of the magnetic field, which we explain in terms of a competition between the variable range hopping and the delocalization. Our results are consistent with the idea that the variable range hopping is the relevant mechanism for the transport in the entire magnetic field range, except for the very small magnetic fields, where the Anderson delocalization plays a more important role.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Type D Einstein spacetimes in higher dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0435, "human_text": "  We show that all static spacetimes in higher dimensions are of Weyl types G,\nI_i, D or O. This applies also to stationary spacetimes if additional\nconditions are fulfilled, as for most known black hole/ring solutions. (The\nconclusions change when the Killing generator becomes null, such as at Killing\nhorizons.) Next we demonstrate that the same Weyl types characterize warped\nproduct spacetimes with a one-dimensional Lorentzian (timelike) factor, whereas\nwarped spacetimes with a two-dimensional Lorentzian factor are restricted to\nthe types D or O. By exploring the Bianchi identities, we then analyze the\nsimplest non-trivial case from the above classes - type D vacuum spacetimes,\npossibly with a cosmological constant, dropping, however, the assumptions that\nthe spacetime is static, stationary or warped. It is shown that for ``generic''\ntype D vacuum spacetimes the corresponding principal null directions are\ngeodetic in any dimension (this applies also to type II spacetimes). For n>=5,\nhowever, there may exist particular cases of type D spacetimes which admit\nnon-geodetic multiple principal null directions and we present such examples in\nany n>=7. Further studies are restricted to five dimensions, where the type D\nWeyl tensor is described by a 3x3 matrix \\Phi_{ij}. In the case with\n``twistfree'' (A_{ij}=0) principal null geodesics we show that in a ``generic''\ncase \\Phi_{ij} is symmetric and eigenvectors of \\Phi_{ij} coincide with those\nof the expansion matrix S_{ij}, providing us with three preferred spacelike\ndirections of the spacetime. Similar results are also obtained when relaxing\nthe twistfree condition and assuming instead that \\Phi_{ij} is symmetric. The\nn=5 Myers-Perry black hole and Kerr-NUT-AdS metrics in arbitrary dimension are\nbriefly studied as specific examples of type D vacuum spacetime.\n", "machine_text": "\n\nWe study type D Einstein spacetimes in higher dimensions. We show that such spacetimes can be fully described by a restricted set of solutions of the Einstein field equations which we call basic solutions. This description can be used to give a simple and elegant derivation and formulation of the type D Einstein spacetime in any dimension greater than two. We also show that, if the principal null directions are arranged in a certain way, the type D Einstein spacetime in higher dimensions can be made to have a simple structure in which the spacetime can be expressed as a special type of curved spacetime in a lower dimension. We show that this special structure is related to the principal null directions in a way which allows the type D Einstein spacetime to be understood as a special type of anti-de Sitter spacetime. We show that the de Sitter spacetime can be obtained as a special limiting case of this type D Einstein spacetime in higher dimensions. The results of this paper have been published in the companion paper 'Basic solutions for type D Einstein spacetimes in higher dimensions'.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: G-convergence and homogenization of viscoelastic flows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1088, "human_text": "  The paper is devoted to homogenization of two-phase incompressible\nviscoelastic flows with disordered microstructure. We study two cases. In the\nfirst case, both phases are modeled as Kelvin-Voight viscoelastic materials. In\nthe second case, one phase is a Kelvin-Voight material, and the other is a\nviscous Newtonian fluid. The microscale system contains the conservation of\nmass and balance of momentum equations. The inertial terms in the momentum\nequation incorporate the actual interface advected by the flow. In the\nconstitutive equations, a frozen interface is employed. The interface geometry\nis arbitrary: we do not assume periodicity, statistical homogeneity or scale\nseparation. The problem is homogenized using G-convergence and oscillating test\nfunctions. Since the microscale system is not parabolic, previously known\nconstructions of the test functions do not work here. The test functions\ndeveloped in the paper are non-local in time and satisfy divergence-free\nconstraint exactly. The latter feature enables us to avoid working with\npressure directly. We show that the effective medium is a single phase\nviscoelastic material that is not necessarily of Kelvin-Voight type. The\neffective constitutive equation contains a long memory viscoelastic term, as\nwell as instantaneous elastic and viscous terms.\n", "machine_text": "\n\nWe study the large-scale behavior of viscoelastic flows in simple geometries. We show that a flow in a long cylindrical tube will display super-diffusive behavior, with a coefficient of diffusion that decreases with the reciprocal of the Deborah number. We show that this is due to the combined effects of shear and extension on the flow, and that the super-diffusive exponent depends on the physical properties of the fluid, in particular on the ratio of the shear and extension viscosity. In the limit of a large Deborah number, the flow develops a solid-like behavior, with a strain-rate dependent viscosity, and a dilatancy that depends on the sign of the shear modulus. The spatial structure of the flow is governed by the evolution of a Deborah number field, which is shown to be related to the large-scale structure of the flow through an extra stress-strain relation. In addition, the local structure of the flow is described by a decomposition in elementary volume elements, which evolve according to a local dynamics that depends on the Deborah number field. We also discuss the case of a viscoelastic flow in a planar geometry, for which we show that the large-scale structure is described by a vectorial diffusion equation, with a non-monotonic dependence of the diffusion coefficient on the Deborah number.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: La controverse de 1874 entre Camille Jordan et Leopold Kronecker. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2929, "human_text": "  During the whole of 1874, Camille Jordan and Leopold Kronecker quar- relled\nvigorously over the organisation of the theory of bilinear forms. That theory\npromised a \"general\" and \"homogeneous\" treatment of numerous questions arising\nin various 19th-century theoretical contexts, and it hinged on two theorems,\nstated independently by Jordan and Weierstrass, that would today be considered\nequivalent. It was, however, the perceived difference between those two\ntheorems that sparked the 1874 controversy. Focusing on this quarrel allows us\nto explore the algebraic identity of the polynomial practices of the\nmanipulations of forms in use before the advent of structural approaches to\nlinear algebra. The latter approaches identified these practices with methods\nfor the classification of similar matrices. We show that the prac- tices --\nJordan's canonical reduction and Kronecker's invariant computation -- reflect\nidentities inseparable from the social context of the time. Moreover, these\npractices reveal not only tacit knowledge, local ways of thinking, but also --\nin light of a long history tracing back to the work of Lagrange, Laplace, Cau-\nchy, and Hermite -- two internal philosophies regarding the significance of\ngenerality which are inseparable from two disciplinary ideals opposing algebra\nand arithmetic. By interrogating the cultural identities of such practices,\nthis study aims at a deeper understanding of the history of linear algebra\nwithout focusing on issues related to the origins of theories or structures.\n", "machine_text": "\n\nThe year is 1874. The place is the Office of the Director of the School of Mathematics in Paris. The controversial issue is the teaching of gymnastics. The two protagonists are Camille Jordan, the Director, and Leopold Kronecker, his deputy. The occasion is a memoir submitted by a former student of the School. The document is entitled \"Reflections on the Influence of Gymnastics on the Development of the Body and the Will.\" The student's name is \u00c9mile Cividale. The issue is the advisability of including in the School's curriculum a course in gymnastics.\n\nCamille Jordan is the guardian of the tradition of the \"old school,\" which holds that mathematics is a \"matter of intelligence\" and that gymnastics is a \"matter of will.\" In a draft of a letter to Cividale, Jordan writes: \"I see in it [i.e., in gymnastics] a waste of time, and even a danger for the health of our students.\" His preferred course of action is to \"condemn the practice of gymnastics in our school.\"\n\nIn contrast, Leopold Kronecker is a strong advocate of gymnastics. In his eyes, it is essential to the well-being of the students. In a draft of a letter to Cividale, Kronecker writes: \"I support the initiative of those who wish to teach gymnastics to our students, and I will do all in my power to see that this initiative bears fruit.\"\n\nThe debate goes on for several weeks. The two mathematicians exchange a stream of letters, each one answering the other's arguments. Their personalities clash. The issue becomes one of who is to prevail, Jordan or Kronecker. The outcome is that Kronecker prevails. Mathematics is not to be separated from gymnastics. The teaching of gymnastics is to be given a place in the School's curriculum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Determination of the Far-Infrared Cosmic Background Using COBE/DIRBE and\n  WHAM Data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3966, "human_text": "  Determination of the cosmic infrared background (CIB) at far infrared\nwavelengths using COBE/DIRBE data is limited by the accuracy to which\nforeground interplanetary and Galactic dust emission can be modeled and\nsubtracted. Previous determinations of the far infrared CIB (e.g., Hauser et\nal. 1998) were based on the detection of residual isotropic emission in skymaps\nfrom which the emission from interplanetary dust and the neutral interstellar\nmedium were removed. In this paper we use the Wisconsin H-alpha Mapper (WHAM)\nNorthern Sky Survey as a tracer of the ionized medium to examine the effect of\nthis foreground component on determination of the CIB. We decompose the DIRBE\nfar infrared data for five high Galactic latitude regions into H I and H-alpha\ncorrelated components and a residual component. We find the H-alpha correlated\ncomponent to be consistent with zero for each region, and we find that addition\nof an H-alpha correlated component in modeling the foreground emission has\nnegligible effect on derived CIB results. Our CIB detections and 2 sigma upper\nlimits are essentially the same as those derived by Hauser et al. and are given\nby nu I_nu (nW m-2 sr-1) < 75, < 32, 25 +- 8, and 13 +- 3 at 60, 100, 140, and\n240 microns, respectively. Our residuals have not been subjected to a detailed\nanisotropy test, so our CIB results do not supersede those of Hauser et al. We\nderive upper limits on the 100 micron emissivity of the ionized medium that are\ntypically about 40% of the 100 micron emissivity of the neutral atomic medium.\nThis low value may be caused in part by a lower dust-to-gas mass ratio in the\nionized medium than in the neutral medium, and in part by a shortcoming of\nusing H-alpha intensity as a tracer of far infrared emission.\n", "machine_text": "\n\nWe present a far-infrared (IR) background spectrum of the cosmic background radiation (CBR) determined from the COBE/DIRBE data, and a corresponding set of far-IR spectral models. The data set used for the spectrum compilation consists of the latest COBE/DIRBE data, with a total integration time of 564.4 ks, and the WHAM data with an integration time of 105.4 ks. The high sensitivity of the COBE/DIRBE instrument allows us to measure the background in the far-IR region below 8 \u03bcm with a sensitivity of ~5 mK. The spectrum is featureless with a high level of homogeneity, and is in agreement with a blackbody spectrum with a temperature of 37 K. The fitting procedure used to derive the blackbody temperature from the spectrum is described. The main spectral model parameters are the dust temperature, the total optical depth, and the local excess optical depth. The best-fit model to the data has a dust temperature of 36.5 K, a total optical depth of 1.00, and a local excess optical depth of 0.09. We find that the far-IR CBR is well described by a blackbody spectrum.\n\nThe COBE/DIRBE far-infrared data set is available at: ftp://icola.harvard.edu/COBE/level5/DIRBE/Data_v5.html. The WHAM data set is available at: ftp://slac.stanford.edu/site/ Terrier/WHAM/", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical non-axisymmetric instabilities in rotating relativistic stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1826, "human_text": "  We present new results on dynamical instabilities in rapidly rotating\nneutron-stars. In particular, using numerical simulations in full General\nRelativity, we analyse the effects that the stellar compactness has on the\nthreshold for the onset of the dynamical bar-mode instability, as well as on\nthe appearance of other dynamical instabilities. By using an extrapolation\ntechnique developed and tested in our previous study [1], we explicitly\ndetermine the threshold for a wide range of compactnesses using four sequences\nof models of constant baryonic mass comprising a total of 59 stellar models.\nOur calculation of the threshold is in good agreement with the Newtonian\nprediction and improves the previous post-Newtonian estimates. In addition, we\nfind that for stars with sufficiently large mass and compactness, the m=3\ndeformation is the fastest growing one. For all of the models considered, the\nnon-axisymmetric instability is suppressed on a dynamical timescale with an m=1\ndeformation dominating the final stages of the instability. These results,\ntogether with those presented in [1], suggest that an m=1 deformation\nrepresents a general and late-time feature of non-axisymmetric dynamical\ninstabilities both in full General Relativity and in Newtonian gravity.\n", "machine_text": "\nWe investigate dynamical non-axisymmetric instabilities in rotating relativistic stars. We show that the mirror symmetry of the equilibrium solution breaks down when the star is rotating fast enough, leading to the formation of a `twist'-related instability. This instability is associated with a pair of new vortices, which arise in the high-frequency limit of the solution. We show that this instability is always active when the angular velocity is larger than a certain threshold, which depends on the degree of anisotropy and the angular momentum per unit mass. We observe that the threshold is relatively low, so that this instability may be active in many real stars. We analyse the linear stability of this new instability, and show that it is stable against perturbations that are small in the angular-velocity space. Therefore, this new instability does not grow, but it may trigger other dynamical instabilities that are active in the slowly rotating regime. We find that this new instability is stable against a change in the degree of anisotropy, but it becomes unstable when the anisotropy is increased beyond a certain threshold. This implies that this instability may be active in many different systems, provided that the symmetry of the problem is broken in a relatively mild way. We also show that this instability is related to the previously discovered `utchin' instability, but the two instabilities are different in a number of ways. Our results imply that this new instability may be important in the dynamics of rotating relativistic stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sensitivity of solar off-limb line profiles to electron density\n  stratification and the velocity distribution anisotropy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1127, "human_text": "  The effect of the electron density stratification on the intensity profiles\nof the H I Ly-$\\alpha$ line and the O VI and Mg X doublets formed in solar\ncoronal holes is investigated. We employ an analytical 2-D model of the large\nscale coronal magnetic field that provides a good representation of the corona\nat the minimum of solar activity. We use the mass-flux conservation equation to\ndetermine the outflow speed of the solar wind at any location in the solar\ncorona and take into account the integration along the line of sight (LOS). The\nmain assumption we make is that no anisotropy in the kinetic temperature of the\ncoronal species is considered. We find that at distances greater than 1 Rsun\nfrom the solar surface the widths of the emitted lines of O VI and Mg X are\nsensitive to the details of the adopted electron density stratification.\nHowever, Ly-$\\alpha$, which is a pure radiative line, is hardly affected. The\ncalculated total intensities of Ly-$\\alpha$ and the O VI doublet depend to a\nlesser degree on the density stratification and are comparable to the observed\nones for most of the considered density models. The widths of the observed\nprofiles of Ly-$\\alpha$ and Mg X are well reproduced by most of the considered\nelectron density stratifications, while for the O VI doublet only few\nstratifications give satisfying results. The densities deduced from SOHO data\nresult in O VI profiles whose widths and intensity ratio are relatively close\nto the values observed by UVCS although only isotropic velocity distributions\nare employed. These density profiles also reproduce the other considered\nobservables with good accuracy. Thus the need for a strong anisotropy of the\nvelocity distribution (i.e. a temperature anisotropy) is not so clear cut as\nprevious investigations of UVCS data suggested. ...\n", "machine_text": "\nWe present a method to probe the electron density distribution in the solar corona using the off-limb observation of the solar photosphere. We utilize the fact that the sensitivity of the shape of the solar off-limb line profiles to the variation of the electron density distribution is different in the direction parallel and perpendicular to the solar limbs. Our method is based on the assumption that the off-limb line profile is insensitive to the variation of the electron density in the direction parallel to the solar limbs, while it is sensitive to the variation of the electron density in the direction perpendicular to the solar limbs. The assumption is valid if the electron density distribution is isotropic along the line of sight and if the effect of the temperature distribution along the line of sight is negligible. We show that the off-limb line profile can be used to probe the electron density distribution in the direction perpendicular to the solar limbs if the angle between the electron density gradient and the line of sight is known. We show that the off-limb line profile can be used to constrain the structure of the electron density distribution in the corona if the distribution is stratified along the line of sight. We discuss the implications of our results for the measurement of the solar electron density distribution with off-limb observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal Stability of Metallic Single-Walled Carbon Nanotubes: An O(N)\n  Tight-Binding Molecular Dynamics Simulation Study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1625, "human_text": "  Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to\ninvestigate the thermal stability of (10,10) metallic Single-Walled Carbon\nNanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial\ndirection. Velocity Verlet algorithm along with the canonical ensemble\nmolecular dynamics (NVT) is used to simulate the tubes at the targeted\ntemperatures. The effects of slow and rapid temperature increases on the\nphysical characteristics, structural stability and the energetics of the tube\nare investigated and compared. Simulations are carried out starting from room\ntemperature and the temperature is raised in steps of 300K. Stability of the\nsimulated metallic SWCNT is examined at each step before it is heated to higher\ntemperatures. First indication of structural deformation is observed at 600K.\nFor higher heat treatments the deformations are more pronounced and the bond\nbreaking temperature is reached around 2500K. Gradual (slow) heating and\nthermal equilibrium (fast heating) methods give the value of radial thermal\nexpansion coefficient in the temperature range between 300K-600K as\n0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both\nmethods give the same value of 0.089x10^{-5}(1/K). The ratio of the total\nenergy per atom with respect to temperature is found to be 3x10^{-4} eV/K.\n", "machine_text": "\n\nWe present a first-principles-based tight-binding molecular dynamics (TB-MD) study of the thermodynamic stability of metallic single-walled carbon nanotubes (SWCNTs) with a random number of vacancies, i.e., holes, along their circumference. We consider a large number of randomly generated SWCNTs with up to N = 10 vacancies, and determine their respective stabilities by computing the total energy of each system. We find that the number of stable SWCNTs drops sharply as the number of vacancies increases. Our results agree with previous empirical findings, and suggest that the number of stable SWCNTs decreases exponentially as a function of the number of vacancies. The largest number of vacancies for which we find a stable SWCNT is N = 4. We also investigate the effect of a given vacancy on the stability of the SWCNTs, and find that the presence of a vacancy greatly decreases the stability of the SWCNTs. Our findings are consistent with the idea that vacancies in SWCNTs weaken their structural integrity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structural relaxation around substitutional Cr3+ in MgAl2O4. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0878, "human_text": "  The structural environment of substitutional Cr3+ ion in MgAl2O4 spinel has\nbeen investigated by Cr K-edge Extended X-ray Absorption Fine Structure (EXAFS)\nand X-ray Absorption Near Edge Structure (XANES) spectroscopies.\nFirst-principles computations of the structural relaxation and of the XANES\nspectrum have been performed, with a good agreement to the experiment. The Cr-O\ndistance is close to that in MgCr2O4, indicating a full relaxation of the first\nneighbors, and the second shell of Al atoms relaxes partially. These\nobservations demonstrate that Vegard's law is not obeyed in the MgAl2O4-MgCr2O4\nsolid solution. Despite some angular site distortion, the local D3d symmetry of\nthe B-site of the spinel structure is retained during the substitution of Cr\nfor Al. Here, we show that the relaxation is accomodated by strain-induced bond\nbuckling, with angular tilts of the Mg-centred tetrahedra around the Cr-centred\noctahedron. By contrast, there is no significant alteration of the angles\nbetween the edge-sharing octahedra, which build chains aligned along the three\nfour-fold axes of the cubic structure.\n", "machine_text": "\n\nWe have performed an atomistic study of structural relaxation around substitutional Cr3+ in MgAl2O4. The electronic structure of Cr3+ in the Mg-rich regions was calculated by density-functional theory, and the resulting orbitals were used to calculate the formation energies of Cr3+ in the various possible sites in MgAl2O4. The results of this calculation were used as input to a subsequent molecular dynamics simulation of structural relaxation, in which the atomic positions of the substitutional Cr3+ were allowed to relax in response to the electrostatic and steric interactions with their surroundings. The final atomic positions were used to calculate the binding energy of Cr3+, which was then compared to the formation energy to determine the degree of structural relaxation that had occurred. We found that the Cr3+ ions were able to achieve a high degree of structural relaxation, with the average binding energy being only slightly higher than the formation energy. This indicates that the Cr3+ ions are well-packed and have a stable structure within the MgAl2O4 matrix.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Charge Ordering in Half-Doped Manganites: Weak Charge Disproportion and\n  Leading Mechanisms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1834, "human_text": "  The apparent contradiction between the recently observed weak charge\ndisproportion and the traditional Mn$^{3+}$/Mn$^{4+}$ picture of the\ncharge-orbital orders in half-doped manganites is resolved by a novel Wannier\nstates analysis of the LDA$+U$ electronic structure. Strong electron itinerancy\nin this charge-transfer system significantly delocalizes the occupied\nlow-energy \"Mn$^{3+}$\" Wannier states such that charge leaks into the\n\"Mn$^{4+}$\"-sites. Furthermore, the leading mechanisms of the charge order are\nquantified via our first-principles derivation of the low-energy effective\nHamiltonian. The electron-electron interaction is found to play a role as\nimportant as the electron-lattice interaction. \\ignore{A general picture of\ndoped holes in strongly correlated charge-transfer systems is presented and\napplied to the study of charge order in half-doped manganites, using a novel\nWannier states analysis of the LDA$+U$ electronic structure. While residing\nprimarily in the oxygen atoms, the doped holes form additional effective $e_g$\norbitals at the low-energy scale, leading to an effective Mn$^{3+}$/Mn$^{4+}$\nvalence picture that enables weak charge disproportion, resolving the current\nserious contradictions between the recent experimental observations of charge\ndistribution and traditional models. Furthermore, the leading mechanisms of the\nobserved charge order are quantified via our first-principles derivation of the\nlow-energy effective Hamiltonian\n", "machine_text": "\nWe have performed a systematic study of the evolution of charge ordering and magnetic phase diagram in  half-doped manganites with a low Curie temperature by varying the manganese concentration. Our results show that a substantial charge ordering instability region exists in these manganites, and the ordering is always anti-phase to the magnetic ordering. We have discovered a novel charge ordering state in a low magnetic field, in which the charge disproportion is very weak and the charge transfer is nearly local, in a mechanism we call charge ordering by spin-dependent localization (CSBL). Our results reveal that CSBL is the leading charge ordering mechanism in these manganites, and the weak charge disproportion in this state results from the competition between charge ordering and spin ordering. We also found that the non-magnetic charge ordering state can be stabilized by a large magnetic field, and the resulting charge disproportion is enhanced by the spin-orbital coupling in the magnetic state. Our results provide a novel platform for the study of charge ordering and spin-orbital coupling in metallic manganites.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new Generation of Spectrometer Calibration Techniques based on Optical\n  Frequency Combs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0763, "human_text": "  Typical astronomical spectrographs have a resolution ranging between a few\nhundred to 200.000. Deconvolution and correlation techniques are being employed\nwith a significance down to 1/1000 th of a pixel. HeAr and ThAr lamps are\nusually used for calibration in low and high resolution spectroscopy,\nrespectively. Unfortunately, the emitted lines typically cover only a small\nfraction of the spectrometer's spectral range. Furthermore, their exact\nposition depends strongly on environmental conditions. A problem is the strong\nintensity variation between different (intensity ratios {>300). In addition,\nthe brightness of the lamps is insufficient to illuminate a spectrograph via an\nintegrating sphere, which in turn is important to calibrate a long-slit\nspectrograph, as this is the only way to assure a uniform illumination of the\nspectrograph pupil.\n  Laboratory precision laser spectroscopy has experienced a major advance with\nthe development of optical frequency combs generated by pulsed femto-second\nlasers. These lasers emit a broad spectrum (several hundred nanometers in the\nvisible and near infra-red) of equally-spaced \"comb\" lines with almost uniform\nintensity (intensity ratios typically <10). Self-referencing of the laser\nestablishes a precise ruler in frequency space that can be stabilized to the\n10e-18 uncertainty level, reaching absolute frequency inaccuracies at the\n10e-12 level per day when using the Global Positioning System's (GPS) time\nsignal as the reference. The exploration of the merits of this new technology\nholds the promise for broad-band, highly accurate and reproducible calibration\nrequired for reliable operation of current and next generation astronomic\nspectrometers.\n", "machine_text": "\n\nA new Generation of Spectrometer Calibration Techniques based on Optical Frequency Combs\n\nSpectrometry is a powerful and widely used analytical tool in many scientific disciplines for the precise determination of the spectral distribution of a signal. In recent years, the requirements on the spectral resolution of spectrometers have increased tremendously, reaching the sub-femtosecond domain for some applications. To achieve this, the use of optical frequency combs has been proposed and demonstrated. However, the practical implementation of the method is not straightforward, as it requires a precise knowledge of the spectral properties of the optical frequency comb. In this article, we review and discuss recent progress in the field of optical frequency comb-based spectrometer calibration. In particular, we focus on the techniques that have been developed to determine the spectral envelope of the optical frequency comb, which is a key parameter for the correct interpretation of the experimental data. We also discuss the problem of the frequency stability of the optical frequency comb and the techniques that have been developed to stabilize it. Finally, we present a brief overview of the current state-of-the-art of optical frequency comb-based spectrometry and highlight open questions and future research directions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Intrinsically X-ray Weak Quasar PHL 1811. II. Optical and UV Spectra\n  and Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.094, "human_text": "  This is the second of two papers reporting observations and analysis of the\nunusually bright (m_b=14.4), luminous (M_B=-25.5), nearby (z=0.192) narrow-line\nquasar PHL 1811. The first paper reported that PHL 1811 is intrinsically X-ray\nweak, and presented a spectral energy distribution (SED). Here we present HST\nSTIS optical and UV spectra, and ground-based optical spectra. The optical and\nUV line emission is very unusual. There is no evidence for forbidden or\nsemiforbidden lines. The near-UV spectrum is dominated by very strong FeII and\nFeIII, and unusual low-ionization lines such as NaID and CaII H&K are observed.\nHigh-ionization lines are very weak; CIV has an equivalent width of 6.6A, a\nfactor of ~5 smaller than measured from quasar composite spectra. An unusual\nfeature near 1200A can be deblended in terms of Ly\\alpha, NV, SiII, and CIII*\nusing the blueshifted CIV profile as a template. Photoionization modeling shows\nthat the unusual line emission can be explained qualitatively by the unusually\nsoft SED. Principally, a low gas temperature results in inefficient emission of\ncollisionally excited lines, including the semiforbidden lines generally used\nas density diagnostics. The emission resembles that of high-density gas; in\nboth cases this is a consequence of inefficient cooling. PHL 1811 is very\nunusual, but we note that quasar surveys are generally biased against finding\nsimilar objects.\n", "machine_text": "\nWe present an analysis of the optical and UV spectra of the intrinsically X-ray weak quasar PHL 1811. The optical spectrum is very blue with a high continuum luminosity, which is typical of a quasar in the initial phase of accretion outbursts. A 1-yr continuum variability monitoring shows that the quasar varies by a factor of ~3 in optical luminosity on timescales of days. We have detected an accretion episode in January 2006, when the continuum emission increased by a factor of ~3 in 2 months. The UV continuum is an order of magnitude fainter than the optical continuum, and it is heavily absorbed by the dust clouds in the quasar's host galaxy. We have derived the mean molecular weight of the gas in the accretion region to be 44.4 \u00b1 2.0 atomic units. A 1-yr monitoring of the CO absorption lines in the quasar's host galaxy shows that the molecular gas kinematics is very chaotic and may be driven by the quasar's outbursts. We also present an analysis of the chemical composition of the gas in the accretion region. The gas is relatively rich in carbon and deficient in hydrogen and helium, which is consistent with the gas being accreted from the quasar's host galaxy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Rich methane premixed laminar flames doped by light unsaturated\n  hydrocarbons - Part I : allene and propyne. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0375, "human_text": "  The structure of three laminar premixed rich flames has been investigated: a\npure methane flame and two methane flames doped by allene and propyne,\nrespectively. The gases of the three flames contain 20.9% (molar) of methane\nand 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure\nmethane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to\na ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have\nbeen stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant,\nwith a gas velocity at the burner of 36 cm/s at 333 K. The concentration\nprofiles of stable species were measured by gas chromatography after sampling\nwith a quartz microprobe. Quantified species included carbon monoxide and\ndioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne,\nallene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene,\n1-butyne, vinylacetylene, and benzene. The temperature was measured using a\nPtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from\n700 K close to the burner up to 1850 K. In order to model these new results,\nsome improvements have been made to a mechanism previously developed in our\nlaboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main\nreaction pathways of consumption of allene and propyne and of formation of C6\naromatic species have been derived from flow rate analyses.\n", "machine_text": "\nWe have performed a detailed experimental investigation of rich methane premixed laminar flames doped by light unsaturated hydrocarbons - allene and propyne. Two kinds of burners were used: a Reynolds-numbers based burner and a constant-pressure burner. We have measured the extinction limits for these flames in the presence of various hydrocarbon doping concentrations, the flame temperature, and the radical species concentrations. We have found that the extinction limit for these flames is not affected by the doping and is limited by the fuel-to-air ratio. The temperature of the flame core is not affected by the doping, but the temperature of the unburned mixture fraction is significantly decreased. The increase of the radical species concentrations in the burned mixture fraction is not significant. We have found that the consumption of the doping hydrocarbons is relatively fast, the half-time of allene being about 1ms. In the burned mixture fraction the concentrations of 2-hydroxy-2-methyl-2-propanenal (HMPA) and of 3-methyl-2-butanone (MBO) are significantly increased, while the concentrations of peroxy radicals are not affected. We have performed a comparison between these flames and propane-doped methane flames. We have found that the extinction limits of these two kinds of flames are similar, but the flame temperature and the radical species concentrations are different.\n\nWe have also performed a comparison between the combustion of these light unsaturated hydrocarbons in air and in methane. We have found that the consumption rates of these hydrocarbons are much higher in methane than in air, the half-times being about 0.1ms and 1s, respectively. We have also found that the concentrations of HMPA and MBO are very similar in both media, while the concentrations of peroxy radicals are much higher in air.\n\nThese results are discussed in the framework of the current literature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generalized Brjuno functions associated to $\\alpha$-continued fractions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.169, "human_text": "  For \\alpha in the interval [0,1], we consider the one-parameter family of\n\\alpha-continued fraction maps, which include the Gauss map (\\alpha=1) and the\nnearest integer (\\alpha=1/2) and by-excess (\\alpha=0) continued fraction maps.\nTo each of these expansions, and to each choice of a positive function u on the\ninterval I_\\alpha=(0,max(\\alpha,1-\\alpha)) we associate a generalized Brjuno\nfunction B_(\\alpha,u)(x). For \\alpha=1/2 or \\alpha=1, and u(x)=-\\log(x), these\nfunctions were introduced by Yoccoz in his work on the linearization of\nholomorphic maps. Their regularity properties, including BMO regularity and\ntheir extension to the complex plane, have been thoroughly investigated. We\ncompare the functions obtained with different values of \\alpha and we prove\nthat the set of (\\alpha,u)-Brjuno numbers does not depend on the choice of\n\\alpha provided that \\alpha>0. We then consider the case \\alpha=0,\nu(x)=-\\log(x) and we prove that x is a Brjuno number (for \\alpha> 0) if and\nonly if both x and -x are Brjuno numbers for \\alpha=0.\n", "machine_text": "\nWe introduce generalized Bruno functions associated to $\\alpha$-continued fractions. These generalized Bruno functions are useful in obtaining a combinatorial interpretation of the $\\alpha$-continued fractions. Further, we show that certain special classes of generalized Bruno functions are related to the $\\alpha$-continued fractions.\n\nThe motivation for this work is to provide an combinatorial interpretation of the $\\alpha$-continued fractions which will be useful in attacking the Brun's problem.\n\nThe key ideas and methodology used in this work are as follows: we introduce generalized Bruno functions associated to $\\alpha$-continued fractions; these generalized Bruno functions are useful in obtaining a combinatorial interpretation of the $\\alpha$-continued fractions.\n\nThe results obtained in this work are as follows: we show that certain special classes of generalized Bruno functions are related to the $\\alpha$-continued fractions.\n\nThis work attempts to solve the following problem: given a positive integer $n$, how many partitions of the set $\\{1, 2, \\ldots, n\\}$ with distinct parts does Brun's problem ask us to count? We show that the number of such partitions is equal to the number of $\\alpha$-continued fractions with distinct terms.\n\nThis work has practical applications in attacking Brun's problem.\n\nThis work has theoretical applications in developing a generalization of Brun's problem to the case of non-distinct parts.\n\nThis work suggests future research in the direction of developing a generalization of Brun's problem to the case of non-distinct parts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High Precision CTE-Measurement of SiC-100 for Cryogenic Space-Telescopes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1515, "human_text": "  We present the results of high precision measurements of the thermal\nexpansion of the sintered SiC, SiC-100, intended for use in cryogenic\nspace-telescopes, in which minimization of thermal deformation of the mirror is\ncritical and precise information of the thermal expansion is needed for the\ntelescope design. The temperature range of the measurements extends from room\ntemperature down to $\\sim$ 10 K. Three samples, #1, #2, and #3 were\nmanufactured from blocks of SiC produced in different lots. The thermal\nexpansion of the samples was measured with a cryogenic dilatometer, consisting\nof a laser interferometer, a cryostat, and a mechanical cooler. The typical\nthermal expansion curve is presented using the 8th order polynomial of the\ntemperature. For the three samples, the coefficients of thermal expansion\n(CTE), $\\bar{\\alpha}_{#1}$, $\\bar{\\alpha}_{#2}$, and $\\bar{\\alpha}_{#3}$ were\nderived for temperatures between 293 K and 10 K. The average and the dispersion\n(1 $\\sigma$ rms) of these three CTEs are 0.816 and 0.002 ($\\times 10^{-6}$/K),\nrespectively. No significant difference was detected in the CTE of the three\nsamples from the different lots. Neither inhomogeneity nor anisotropy of the\nCTE was observed. Based on the obtained CTE dispersion, we performed an\nfinite-element-method (FEM) analysis of the thermal deformation of a 3.5 m\ndiameter cryogenic mirror made of six SiC-100 segments. It was shown that the\npresent CTE measurement has a sufficient accuracy well enough for the design of\nthe 3.5 m cryogenic infrared telescope mission, the Space Infrared telescope\nfor Cosmology and Astrophysics (SPICA).\n", "machine_text": "\n\nSummary:\nWe present high precision thermal expansion coefficient measurements of SiC-100 for temperatures down to 50 K. The measurements were performed in the frame of the ESA/CNES CryoPix project to qualify SiC-100 for cryogenic space telescope applications. The thermal expansion coefficient was determined with a relative uncertainty as low as 1.5 ppb/K using a silicon carbide mastersky. We show that SiC-100 has a higher thermal expansion coefficient than ZERODUR but a much higher thermal conductivity. The high thermal conductivity causes a strong temperature dependence of the measured thermal expansion coefficient. We derived a temperature dependent correction curve for the thermal expansion coefficient which can be used to reduce the measurement uncertainty to 0.5 ppb/K. We also present the first test results of a new types of SiC-100: SiC-100 thin disk and SiC-100 bonded to a silicon carbide core. Both types are potential candidates for future cryogenic space telescope applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Sloan Digital Sky Survey Quasar Catalog IV. Fifth Data Release. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0806, "human_text": "  We present the fourth edition of the Sloan Digital Sky Survey (SDSS) Quasar\nCatalog. The catalog contains 77,429 objects; this is an increase of over\n30,000 entries since the previous edition. The catalog consists of the objects\nin the SDSS Fifth Data Release that have luminosities larger than M_i = -22.0\n(in a cosmology with H_0 = 70 km/s/Mpc, Omega_M = 0.3, and Omega_Lambda = 0.7)\nhave at least one emission line with FWHM larger than 1000 km/s, or have\ninteresting/complex absorption features, are fainter than i=15.0, and have\nhighly reliable redshifts. The area covered by the catalog is 5740 sq. deg. The\nquasar redshifts range from 0.08 to 5.41, with a median value of 1.48; the\ncatalog includes 891 quasars at redshifts greater than four, of which 36 are at\nredshifts greater than five. Approximately half of the catalog quasars have i <\n19; nearly all have i < 21. For each object the catalog presents positions\naccurate to better than 0.2 arcsec. rms per coordinate, five-band (ugriz)\nCCD-based photometry with typical accuracy of 0.03 mag, and information on the\nmorphology and selection method. The catalog also contains basic radio,\nnear-infrared, and X-ray emission properties of the quasars, when available,\nfrom other large-area surveys. The calibrated digital spectra cover the\nwavelength region 3800--9200A at a spectral resolution of ~2000. The spectra\ncan be retrieved from the public database using the information provided in the\ncatalog. The average SDSS colors of quasars as a function of redshift, derived\nfrom the catalog entries, are presented in tabular form. Approximately 96% of\nthe objects in the catalog were discovered by the SDSS.\n", "machine_text": "\n\nWe present the SDSS Quasar Catalog IV, Fifth Data Release (Q4). The catalog contains photometric redshifts for 112,\u00e9tartimely-interval quasars observed with the SDSS through 2007 February, with fainter quasars observed through 2009 January. Q4 includes all quasars in the SDSS Data Release 7 (DR7) and in the SDSS Legacy Survey, with the exception of a small number of quasars with very low significance (false-alarm) detections. Q4 also includes quasars from the SDSS's supernova survey, SN Ia, and from the SDSS's extended redshift survey, eBOSS. The quasars in these datasets were observed in the same areas of the sky as the SDSS's main galaxy redshift survey, and have the same two-dimensional (2D) coverage as Q3, with the same Galactic latitude (|b| > 2.5\u00b0) and in most of the same survey areas as Q3. Thus, the sky coverage of quasars in Q4 is similar to that in Q3, but with a significantly larger number of quasars. The quasars in Q4 have been divided into three subsets, based on the optical brightness and redshift distribution of the quasars. Q4R is a randomly subset of the quasars in Q4; Q4S is a subset of quasars selected to have similar optical brightness, redshift distribution, and sky coverage to those in Q3; Q4T is a subset of quasars selected to have similar optical brightness and sky coverage to those in Q3, but with a different (and larger) redshift distribution than Q3. This report describes the selection criteria for the quasars in Q4, and contains tables giving the properties of the quasars in the subsets, Q4R, Q4S, and Q4T.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Magnetar Nature and the Outburst Mechanism of a Transient Anomalous\n  X-ray Pulsar. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3713, "human_text": "  Anomalous X-ray Pulsars (AXPs) belong to a class of neutron stars believed to\nharbor the strongest magnetic fields in the universe, as indicated by their\nenergetic bursts and their rapid spindowns. However, an unambiguous measurement\nof their surface field strengths has not been made to date. It is also not\nknown whether AXP outbursts result from changes in the neutron star magnetic\nfield or crust properties. Here we report a spectroscopic measurement of the\nsurface magnetic field strength of an AXP, XTE J1810$-$197, and solidify its\nmagnetar nature. The field strength obtained from detailed spectral analysis\nand modeling, B = (2.72$\\pm$0.03)$\\times10^{14}$ G, is remarkably close to the\nvalue inferred from the rate of spindown of this source and remains nearly\nconstant during numerous observations spanning over an order of magnitude in\nsource flux. The surface temperature, on the other hand, declines steadily and\ndramatically following the 2003 outburst of this source. Our findings\ndemonstrate that heating occurs in the upper neutron star crust during an\noutburst and sheds light on the transient behaviour of AXPs.\n", "machine_text": "\nWe present observations of the transient anomalous X-ray pulsar XTE J1810$-$197. We find that the accretion phase occurs in pulses, with a frequency that decreases by a factor of ~2 between each pulse. This suggests that the inner accretion disc is not being driven by a steady-state process, but is instead related to the orbital period of a companion. We determine the properties of the companion by fitting a simple model to the observations. We find that the companion has an orbital period of $\\sim$9 hours, which is consistent with a free oscillation period for a particle in the accretion disc, and an orbital decay of $\\sim$5.5 hours, which could be due to tidal interactions. The companion was likely captured by the primary star several thousand years ago. The simple model we use to describe the observations only includes the two fundamental orbital frequencies, but additional terms could be added to describe non-linear effects. We discuss the effect of the accretion disc viscosity on the observed phenomenology. The simple model is in good agreement with the observations, but a more complete model would be necessary to understand the underlying physical mechanism. We discuss how such a model might be constructed, based on the physical properties of the accretion disc and the companion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SQUID-based instrumentation for ultra-low-field MRI. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0661, "human_text": "  Magnetic resonance imaging at ultra-low fields (ULF MRI) is a promising new\nimaging method that uses SQUID sensors to measure the spatially encoded\nprecession of pre-polarized nuclear spin populations at a microtesla-range\nmeasurement field. In this work, a seven-channel SQUID system designed for\nsimultaneous 3D ULF MRI and magnetoencephalography (MEG) is described. The\nsystem includes seven second-order SQUID gradiometers, characterized by\nmagnetic field resolutions of 1.2 - 2.8 fT/rtHz. It is also equipped with five\nsets of coils for 3D Fourier imaging with pre-polarization. Essential technical\ndetails of the design are discussed. The system's ULF MRI performance is\ndemonstrated by multi-channel 3D images of a preserved sheep brain acquired at\n46 microtesla measurement field with pre-polarization at 40 mT. The imaging\nresolution is 2.5 mm x 2.5 mm x 5 mm. The ULF MRI images are compared to images\nof the same brain acquired using conventional high-field MRI. Different ways to\nimprove imaging SNR are discussed.\n", "machine_text": "\n\nIntroduction\n\nWe have previously reported on the design and implementation of a SQUID-based system for ultra-low-field MRI that has the potential to bring the benefits of MRI to a new class of applications that include molecular and functional imaging. Our initial results demonstrate the potential of SQUID-based instrumentation for ultra-low-field MRI, however, several issues must be addressed in order to make this approach practical. In this work, we focus on two of these issues: signal-to-noise ratio and image artifacts.\n\nMethodology\n\nWe have designed a system of parallel SQUID arrays that is capable of eliminating the need for a flux-lock loop and thereby reducing the noise in the detected signal. This system is currently being constructed and will be the subject of future publications. In addition, we have developed a technique for suppressing the image artifacts caused by uniform magnetic fields. This technique is based on the use of a reference channel that measures the uniform field and a filtering procedure that removes the uniform field from the image.\n\nResults\n\nWe have evaluated the image quality obtained with the SQUID-based system and the effectiveness of the filtering procedure in suppressing the image artifacts. The results of this evaluation indicate that this approach is feasible for producing high quality images.\n\nDiscussion\n\nThe results reported in this paper demonstrate that SQUID-based instrumentation for ultra-low-field MRI is a viable approach for producing high quality images. Further work is needed to optimize the design of the SQUID array and the filtering procedure in order to achieve the best possible image quality. In addition, this work has demonstrated that SQUID-based instrumentation can be used to measure the uniform field and thereby enable the suppression of this artifact. This capability is important for producing high quality images and is an area of active research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Produit d'entrelacement et action triangulaire d'alg\\`ebres de Lie. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.384, "human_text": "  Formal actions of Lie algebras over vector spaces are introduced in a purely\nalgebraic way, as a mimic of infinitesimal operations of Banach Lie algebras\nover Banach analytic manifolds. In analogy with the case of abstract groups,\ncomplete wreath products and triangular actions are then defined for Lie\nalgebras acting \"en cascade\" over vector spaces. Finally, a Kaloujnine-Krasner\ntype theorem for Lie algebra extensions is proved.\n  -----\n  En mimant les lois d'op\\'erations infinit\\'esimales des alg\\`ebres de Lie sur\nles vari\\'et\\'e s analytiques banachiques, on introduit de mani\\`ere purement\nalg\\`ebrique la notion d'action formelle d'une alg\\`ebre de Lie sur un espace\nvectoriel. Ensuite, par analogie avec le cas des groupes abstraits, et en\nfaisant op\\'erer les alg\\`ebres de Lie \"en cascade\", on d\\'efinit produit\nd'entrelacement (\"wreath product\") et action triangulaire pour les alg\\`ebres\nde Lie. On d\\'emontre enfin un th\\'eor\\`eme du type Kaloujnine-Krasner pour les\nextensions d'alg\\`ebres de Lie.\n", "machine_text": "\n\nWe construct a general formalism for the determination of products of interplays and the action of triangles of Lie algebras. We apply this formalism to the particular cases of the Heisenberg and killing algebras, and we give a geometric interpretation of the action of the triangles of these algebras on certain spaces of quantum W pumps.\n\nLet $\\Gamma$ and $\\Gamma'$ be Lie algebras; let $\\Gamma$ be simple. We set $\\Phi: \\Gamma\\to \\Gamma'$ to be the unique homomorphism of $\\Gamma$ onto $\\Gamma'$ which satisfies the following property: for every $X$ in $\\Gamma$, the image $\\Phi(X)$ is contained in the radical of $\\Gamma'$. If $\\Phi$ is an isomorphism of $\\Gamma$ onto $\\Gamma'$, then $\\Gamma$ and $\\Gamma'$ are said to be isomorphic. We can now state the main results of this paper.\n\nWe prove the following result.\n\n\\[theorem0\\] Let $\\Gamma$ and $\\Gamma'$ be Lie algebras. If $\\Gamma$ is isomorphic to $\\Gamma'$, then $\\Gamma$ and $\\Gamma'$ are isomorphic to simple Lie algebras.\n\nWe also prove the following result.\n\n\\[theorem1\\] Let $\\Gamma$ and $\\Gamma'$ be Lie algebras. If $\\Gamma$ is isomorphic to $\\Gamma'$, then the killing form $B$ of $\\Gamma$ is induced by the killing form $B'$ of $\\Gamma'$.\n\nWe also show that, if $\\Gamma$ is isomorphic to $\\Gamma'$, then the isomorphism $\\Phi$ satisfies the following property.\n\n\\[theorem2\\] Let $\\Gamma$ and $\\Gamma'$ be Lie algebras. If $\\Gamma$ is isomorphic to $\\Gamma'$, then the isomorphism $\\Phi$ preserves the root system of $\\Gamma$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-infrared polarimetric study of the bipolar nebula IRAS 19312+1950. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2741, "human_text": "  We obtained H-band polarimetric data of IRAS 19312+1950 using the\nnear-infrared camera (CIAO) on the 8 m Subaru telescope. In order to\ninvestigate the physical properties of the central star and the nebula, we\nperformed dust radiative transfer modeling and compared the model results with\nthe observed spectral energy distributions (SEDs), the radial profiles of the\ntotal intensity image, and the fraction of linear polarization map. The total\nintensity image shows a nearly spherical core with ~3\" radius, an S-shaped arm\nextending ~10\" in the northwest to southeast direction, and an extended lobe\ntowards the southwest. The polarization map shows a centro-symmetric vector\nalignment in almost the entire nebula and low polarizations along the S-shaped\narm. These results suggest that the nebula is accompanied by a central star,\nand the S-shaped arm has a physically ring-like structure. From our radiative\ntransfer modeling, we estimated the stellar temperature, the bolometric\nluminosity, and the current mass-loss rate to be 2800 K, 7000 L_sun, and\n5.3x10^{-6} M_sun yr^{-1}, respectively. Taking into account previous\nobservational results, such as the detection of SiO maser emissions and\nsilicate absorption feature in the 10 $\\mu$m spectrum, our dust radiative\ntransfer analysis based on our NIR imaging polarimetry suggests that (1) the\ncentral star of IRAS 19312+1950 is likely to be an oxygen-rich, dust-enshrouded\nAGB star and (2) most of the circumstellar material originates from other\nsources (e.g. ambient dark clouds) rather than as a result of mass loss from\nthe central star.\n", "machine_text": "\n\nWe present a study of the bipolar nebula IRAS 19312+1950, which is the product of the latest stellar evolution of the ONeMg WD 50ql. This object has been the subject of much attention because of its very low temperature, its large mass-loss rate, and its potential to provide clues about the accretion history of magnetic white dwarfs. We present new near-infrared polarimetric images, which we have combined with previous data to produce a more complete map of the emission-line region. These data show a strong indication of circumstellar polarization, which we attribute to theollapse of the magnetic white dwarf. The white dwarf's magnetic field is able to extract rotational energy from the gas, producing a torque that brakes the accretion. This leads to a less violent accretion history and, consequently, to a lower mass-loss rate than would be expected from an unrestrained accretion flow. We show that this braking torque has decreased since the last outburst, probably because the white dwarf's magnetic field has become more distant from the accretion flow. We discuss this mechanism in the framework of the magnetic braking model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hadronization in semi-inclusive deep-inelastic scattering on nuclei. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.327, "human_text": "  A series of semi-inclusive deep-inelastic scattering measurements on\ndeuterium, helium, neon, krypton, and xenon targets has been performed in order\nto study hadronization. The data were collected with the HERMES detector at the\nDESY laboratory using a 27.6 GeV positron or electron beam. Hadron\nmultiplicities on nucleus A relative to those on the deuteron, R_A^h, are\npresented for various hadrons (\\pi^+, \\pi^-, \\pi^0, K^+, K^-, p, and \\bar{p})\nas a function of the virtual-photon energy \\nu, the fraction z of this energy\ntransferred to the hadron, the photon virtuality Q^2, and the hadron transverse\nmomentum squared p_t^2. The data reveal a systematic decrease of R_A^h with the\nmass number A for each hadron type h. Furthermore, R_A^h increases (decreases)\nwith increasing values of \\nu (z), increases slightly with increasing Q^2, and\nis almost independent of p_t^2, except at large values of p_t^2. For pions\ntwo-dimensional distributions also are presented. These indicate that the\ndependences of R_A^{\\pi} on \\nu and z can largely be described as a dependence\non a single variable L_c, which is a combination of \\nu and z. The dependence\non L_c suggests in which kinematic conditions partonic and hadronic mechanisms\nmay be dominant. The behaviour of R_A^{\\pi} at large p_t^2 constitutes\ntentative evidence for a partonic energy-loss mechanism. The A-dependence of\nR_A^h is investigated as a function of \\nu, z, and of L_c. It approximately\nfollows an A^{\\alpha} form with \\alpha \\approx 0.5 - 0.6.\n", "machine_text": "\n\nHadronization in semi-inclusive deep-inelastic scattering on nuclei.\nWe have studied the hadronization mechanism in the framework of the Standard Model (SM) in semi-inclusive deep-inelastic collisions between nuclei and relativistic heavy nuclei at high energies. The evolution of the hadron gas produced in these collisions is governed by the ductility of the nuclei, which is related to the nuclei' size, and by the energy distribution of the hadrons produced in the collisions. We have developed a formalism which describes the hadronization process in these collisions in a unified way, in the framework of the SM, and which takes into account the energy evolution of the hadrons as well as the ductility of the nuclei. Our results show that the hadronization process is different in the two cases, i.e. for relativistic heavy nuclei and for nuclei, and that the difference is due to the different mechanisms which have to saturate in the two cases. Our results also show that the hadron gas produced in these collisions is (ifi the collisions are \"hard\") always thermal, independently of the nucleus' size, and that the hadron gas produced in collisions between relativistic heavy nuclei is less likely to be turbulent than the one produced in collisions between nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Magnetic Fields of Classical T Tauri Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2923, "human_text": "  We report new magnetic field measurements for 14 classical T Tauri stars\n(CTTSs). We combine these data with one previous field determination in order\nto compare our observed field strengths with the field strengths predicted by\nmagnetospheric accretion models. We use literature data on the stellar mass,\nradius, rotation period, and disk accretion rate to predict the field strength\nthat should be present on each of our stars according to these magnetospheric\naccretion models. We show that our measured field values do not correlate with\nthe field strengths predicted by simple magnetospheric accretion theory. We\nalso use our field strength measurements and literature X-ray luminosity data\nto test a recent relationship expressing X-ray luminosity as a function of\nsurface magnetic flux derived from various solar feature and main sequence star\nmeasurements. We find that the T Tauri stars we have observed have weaker than\nexpected X-ray emission by over an order of magnitude on average using this\nrelationship. We suggest the cause for this is actually a result of the very\nstrong fields on these stars which decreases the efficiency with which gas\nmotions in the photosphere can tangle magnetic flux tubes in the corona.\n", "machine_text": "\nWe present a detailed study of the magnetic fields of 21 classical T Tauri stars, 14 of which are members of the TW Hydrae Association. Our observations are made with the Very Long Baseline Array (VLBA) at 1.3 GHz and resolve the stars' magnetospheres to an average spatial resolution of 30 Milliarcseconds. We find that the magnetic fields are directed radially inwards, are less than 10 MG, and have an average field strength of 6.2 MG. The field distribution is very non-uniform, with super-granulation (with sizes between 10 and 20 Mm) being the dominant feature. The fields show large-scale longitudinal and latitudinal structure, probably due to magneto-convection, and in several cases strong magnetic spots are present. We discuss our results in the framework of a simple model of magneto-convection in rotating stars, and present a physical interpretation of our observations. We find that the magnetic field generation is probably due to a combination of internal convection and a slow rotation rate, and that magneto-convection is an efficient mechanism for driving mass-loss from these stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical Coupled-Channel Model of $\\pi N$ Scattering in the W $\\leq$ 2\n  GeV Nucleon Resonance Region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1615, "human_text": "  As a first step to analyze the electromagnetic meson production reactions in\nthe nucleon resonance region, the parameters of the hadronic interactions of a\ndynamical coupled-channel model, developed in {\\it Physics Reports 439, 193\n(2007)}, are determined by fitting the $\\pi N$ scattering data. The channels\nincluded in the calculations are $\\pi N$, $\\eta N$ and $\\pi\\pi N$ which has\n$\\pi\\Delta$, $\\rho N$, and $\\sigma N$ resonant components. The non-resonant\nmeson-baryon interactions of the model are derived from a set of Lagrangians by\nusing a unitary transformation method. One or two bare excited nucleon states\nin each of $S$, $P$, $D$, and $F$ partial waves are included to generate the\nresonant amplitudes in the fits. The parameters of the model are first\ndetermined by fitting as much as possible the empirical $\\pi N$ elastic\nscattering amplitudes of SAID up to 2 GeV. We then refine and confirm the\nresulting parameters by directly comparing the predicted differential cross\nsection and target polarization asymmetry with the original data of the elastic\n$\\pi^{\\pm} p \\to \\pi^{\\pm} p$ and charge-exchange $\\pi^- p \\to \\pi^0 n$\nprocesses. The predicted total cross sections of $\\pi N$ reactions and $\\pi\nN\\to \\eta N$ reactions are also in good agreement with the data. Applications\nof the constructed model in analyzing the electromagnetic meson production data\nas well as the future developments are discussed.\n", "machine_text": "\nWe develop a dynamically coupled-channel model to study $\\pi N$ scattering in the W $\\leq$ 2 GeV Nucleon Resonance Region. The model includes the following channels: elastic $\\pi N$, $\\pi N$ quasi-elastic, and inelastic $\\pi N$ with $\\pi$ and $N$ exchanged. We consider the channels to be coupled in the $\\langle \\rangle$-space. The model is solved exactly and the results are presented as a sum over all the $\\pi N$-Partners in the coupled-channel basis set. We show that the exact results for the $\\pi N$ quasi-elastic and inelastic channels can be obtained as limits of the elastic $\\pi N$ and inelastic $\\pi N$ with $\\pi$ and $N$ exchanged channels, respectively, as the strength of the coupling between the channels goes to zero. The $\\pi N$ quasi-elastic and inelastic channels are further decomposed into the channels with $\\pi$ and $N$ exchanged. The resulting coupled-channel amplitudes are compared with the results obtained from the single-channel basis-set. The effects of the hadron-mesh-validation on the results are also investigated.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pure inductive limit state and Kolmogorov's property. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1987, "human_text": "  Let $(\\clb,\\lambda_t,\\psi)$ be a $C^*$-dynamical system where $(\\lambda_t: t\n\\in \\IT_+)$ be a semigroup of injective endomorphism and $\\psi$ be an\n$(\\lambda_t)$ invariant state on the $C^*$ subalgebra $\\clb$ and $\\IT_+$ is\neither non-negative integers or real numbers. The central aim of this\nexposition is to find a useful criteria for the inductive limit state $\\clb\n\\raro^{\\lambda_t} \\clb$ canonically associated with $\\psi$ to be pure. We\nachieve this by exploring the minimal weak forward and backward Markov\nprocesses associated with the Markov semigroup on the corner von-Neumann\nalgebra of the support projection of the state $\\psi$ to prove that\nKolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition\nfor the inductive state to be pure. As an application of this criteria we find\na sufficient condition for a translation invariant factor state on a one\ndimensional quantum spin chain to be pure. This criteria in a sense complements\ncriteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states.\n", "machine_text": "\nWe consider the problem of characterizing the limiting behavior of a sequence of independent trials with successes and failures, when the probability of success converges to a limit value as the number of trials grows indefinitely large. We show that, under suitable assumptions, the limiting behavior is always described by a compound probability distribution, in which the probability of failure is given by a limiting distribution and the probability of success is given by a shifted and scaled version of the limiting distribution. This generalizes previous results in the literature which considered the special case of a random walk with probabilities of success and failure which are equal and constant. We also show that the limiting distribution has the Kolmogorov property if the original probability of success has this property. That is, the limiting distribution is equal to the limiting distribution of the sum of independent trials with the limiting distribution and with probability one-half.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HS1857+5144: A hot and young pre-cataclysmic variable. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.178, "human_text": "  We report the discovery of a new white dwarf/M dwarf binary, HS1857+5144,\nidentified in the Hamburg Quasar Survey (HQS). Time-resolved optical\nspectroscopy and photometry were carried out to determine the properties of\nthis new cataclysmic variable progenitor pre-CV). The light curves of\nHS1857+5144 display a sinusoidal variation with a period of Porb=383.52 min and\npeak-to-peak amplitudes of 0.7 mag and 1.1 mag in the B-band and R-band,\nrespectively. The large amplitude of the brightness variation results from a\nreflection effect on the heated inner hemisphere of the companion star,\nsuggesting a very high temperature of the white dwarf. Our radial velocity\nstudy confirms the photometric period as the orbital period of the system. A\nmodel atmosphere fit to the spectrum of the white dwarf obtained at minimum\nlight provides limits to its mass and temperature of Mwd=~0.6-1.0 Msun and\nTwd=~70000-100000 K, respectively. The detection of HeII 4686 absorption\nclassifies the primary star of HS1857+5144 as a DAO white dwarf. Combining the\nresults from our spectroscopy and photometry, we estimate the mass of the\ncompanion star and the binary inclination to be Msec=~0.15-0.30 Msun and\ni=~45-55 deg, respectively. We classify HS1857+5144 as one of the youngest\npre-CV known to date. The cooling age of the white dwarf suggests that the\npresent system has just emerged from a common envelope phase ~10^5 yr ago.\nHS1857+5144 will start mass transfer within or below the 2-3h period gap.\n", "machine_text": "\n\nHS1857+5144: A hot and young pre-cataclysmic variable\n\nWe present photometric and spectroscopic observations of the pre-cataclysmic variable (PCV) HS1857+5144 obtained during a recent outburst. The system is a member of the galactic globular cluster M3, and is one of the most massive and rapidly rotating PCVs known. We find that the accretion phase lasts several thousand seconds, which is much longer than typical for PCVs. We observe a large number of small-amplitude eclipses during the accretion phase, which we attribute to the fact that the accretion disc is far from being axisymmetric. We estimate the pre- outburst orbital period to be \u223c70 min, and the spin period, which is slightly longer, to be \u223c73 min. The observed spin-up time is much longer than the orbital period, indicating that the system is in a strongly three-frequency Resonance. The total mass and the orbital and spin periods are consistent with a single massive accretion disc, as opposed to a system with two accretion discs in orbit around a common barycenter, which was previously suggested to explain some peculiarities of this system. We discuss the possible physical origin of the non-axisymmetric structure of the accretion disc, and suggest that the long spin-up time is due to the large moment of inertia of the disc, in combination with the relatively weak accretion torque.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Critical Behaviour of Irreversible Reaction Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0419, "human_text": "  An introductory review on the critical behaviour of some irreversible\nreaction systems is given. The study of these systems has attracted great\nattention during the last decades due to, on the one hand, the rich and complex\nunderlying physics, and on the other hand, their relevance for numerous\ntechnological applications in heterogeneous catalysis, corrosion and coating,\ndevelopment of microelectronic devices, etc. The review is focuses on recent\nadvances in the understanding of irreversible phase transitions (IPT's)\nproviding a survey of the theoretical development of the field during the last\ndecade, as well as a detailed discussion of relevant numerical simulations. The\nLangevin formulation for the treatment of second-order IPT's is discussed.\nDifferent Monte Carlo approaches are also presented in detail and the\nfinite-size scaling analysis of second-order IPT's is described. Special\nattention is devoted to the description of recent progress in the study of\nfirst-order IPT's observed upon catalytic oxidation of carbon monoxide and the\nreduction of nitrogen monoxide, using lattice gas reaction models. Only brief\ncomments are given on other reactions such as the oxidation of hydrogen,\nammonia synthesis, etc. Also, a discussion of relevant experiments is presented\nand measurement are compared with the numerical results. Furthermore, promising\nareas for further research and open questions are also addressed.\n", "machine_text": "\nWe investigate the critical behaviour of irreversible reaction systems. We consider both steady-state and dynamical criticality, and study the relationship between the two. We find that steady-state criticality may be understood in terms of a generalised Nyquist diagram, which we call a criticality diagram. A criticality diagram is derived from a generalised Lotka-Volterra model, which is itself derived from a master equation. We show that the criticality diagram has three distinct regions. We call the boundary between the first and second regions the criticity line, and the boundary between the second and third regions the supercriticality line. We find that the criticality diagram can be used to understand the critical behaviour of a wide range of irreversible reaction systems, including systems that have been previously studied using the singularity theory of Cannon and Articles. We also find that the concept of criticality can be extended to discrete-time dynamical systems, and that a criticality diagram can be defined for such systems. We show that the boundary between the first and second regions of the criticality diagram is the discrete-time equivalent of the criticity line, and that the boundary between the second and third regions is the discrete-time equivalent of the supercriticality line.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new, very massive modular Liquid Argon Imaging Chamber to detect low\n  energy off-axis neutrinos from the CNGS beam. (Project MODULAr). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1422, "human_text": "  The paper is considering an opportunity for the CERN/GranSasso (CNGS)\nneutrino complex, concurrent time-wise with T2K and NOvA, to search for\ntheta_13 oscillations and CP violation. Compared with large water Cherenkov\n(T2K) and fine grained scintillators (NOvA), the LAr-TPC offers a higher\ndetection efficiency and a lower backgrounds, since virtually all channels may\nbe unambiguously recognized. The present proposal, called MODULAr, describes a\n20 kt fiducial volume LAr-TPC, following very closely the technology developed\nfor the ICARUS-T60o, and is focused on the following activities, for which we\nseek an extended international collaboration:\n  (1) the neutrino beam from the CERN 400 GeV proton beam and an optimised horn\nfocussing, eventually with an increased intensity in the framework of the LHC\naccelerator improvement program;\n  (2) A new experimental area LNGS-B, of at least 50000 m3 at 10 km off-axis\nfrom the main Laboratory, eventually upgradable to larger sizes. A location is\nunder consideration at about 1.2 km equivalent water depth;\n  (3) A new LAr Imaging detector of at least 20 kt fiducial mass. Such an\nincrease in the volume over the current ICARUS T600 needs to be carefully\nconsidered. It is concluded that a very large mass is best realised with a set\nof many identical, independent units, each of 5 kt, \"cloning\" the technology of\nthe T600. Further phases may foresee extensions of MODULAr to meet future\nphysics goals.\n  The experiment might reasonably be operational in about 4/5 years, provided a\nnew hall is excavated in the vicinity of the Gran Sasso Laboratory and adequate\nfunding and participation are made available.\n", "machine_text": "\nWe describe a new very massive modular liquid argon imaging chamber which will be used to search for low energy off-axis neutrinos from the CNGS beam. The main motivation for the research is to improve the sensitivity to low energy neutrinos from the CNGS beam over the current state-of-the-art detectors which will lead to a precise measurement of the neutrino-nucleon cross section at low energy. The key idea is to use a large volume of liquid argon as the detection medium, to use 3D array of flash lamps as the illumination system and to use a 3D array of photo-detectors to register the tracks of nuclear particles. We describe the main design features of the detector and the results of a series of measurements which were carried out to test the design and to achieve better understanding of the physical processes which occur in the detector. The main result of the project is the design of the detector which is optimized for the proposed measurement and which will be used for the future neutrino experiments. We also discuss several other scientific projects which will be carried out with the detector and which are important for the physics program of the LDE neutrino group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis on Heavy Quarkonia Transitions with Pion Emission in Terms of\n  the QCD Multipole Expansion and Determination of Mass Spectra of Hybrids. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2074, "human_text": "  One of the most important tasks in high energy physics is search for the\nexotic states, such as glueball, hybrid and multi-quark states. The transitions\n$\\psi(ns)\\to \\psi(ms)+\\pi\\pi$ and $\\Upsilon(ns)\\to \\Upsilon(ms)+\\pi\\pi$ attract\ngreat attentions because they may reveal characteristics of hybrids. In this\nwork, we analyze those transition modes in terms of the theoretical framework\nestablished by Yan and Kuang. It is interesting to notice that the intermediate\nstates between the two gluon-emissions are hybrids, therefore by fitting the\ndata, we are able to determine the mass spectra of hybrids. The ground hybrid\nstates are predicted as 4.23 GeV (for charmonium) and 10.79 GeV (for bottonium)\nwhich do not correspond to any states measured in recent experiments, thus it\nmay imply that very possibly, hybrids mix with regular quarkonia to constitute\nphysical states. Comprehensive comparisons of the potentials for hybrids whose\nparameters are obtained in this scenario with the lattice results are\npresented.\n", "machine_text": "\nWe propose an analysis on heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The motivation for this work is to understand the non-relativistic theory of heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The key ideas and methodology of this work are based on the non-relativistic theory of heavy quarkonia transitions with pion emission. The results obtained in this work are the mass spectra of hybrids and the analysis on heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The problem this work attempts to solve is to understand the non-relativistic theory of heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The practical application of this work is the determination of the mass spectra of hybrids. The theoretical application of this work is the analysis on heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Flaming, bright galaxies along the filaments of A2744. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0273, "human_text": "  The existence of a clumpy, large-scale filamentary structure is at the basis\nof the current paradigm of cosmic formation and evolution of clusters. The\nstar-formation history of galaxies falling into a cluster is altered as a\nresult of the environmental stresses. We investigate the relation between\nsubstructure and properties of the galaxy population in a 30'x30' region\ncentered on the massive merging cluster A2744 at z~0.3. Multi-object\nspectroscopy at low resolution and BVR photometry are used to detect the\npresence of substructure through a Dressler-Schectman analysis and the\nphotometric redshift technique, respectively. Galaxies at the same photometric\nredshift of the cluster are divided into red and blue according to their\ndistribution in the B-R vs. R colour-magnitude diagram. We identify two\nlarge-scale filaments associated with A2744. Along these filaments, the\nblue-to-red galaxy number ratio increases together with the cluster-centric\ndistance but peaks slightly beyond the cluster virial radius. The filaments\nhost a population of bright, large (i.e. more luminous than R* for the main\nbody of the cluster and with angular sizes of 13-22 $h_{70}^{-1}$ kpc) blue\ngalaxies that is hardly found among galaxies lying in a neighbouring\nlow-density environment at the same redshift of the cluster. These results can\nbe interpreted as a manifestation of galaxy harassment.\n", "machine_text": "\n\nFlaming, bright galaxies along the filaments of A2744\n\nWe present a detailed optical study of the rich clusters A2058 and A2744, which contain many spiral galaxies of very low surface brightness. We find that the spiral galaxies in both clusters are not only optically but also physically associated with the clusters' large-scale structure, following the clusters' filaments and clumps. In addition, the spiral galaxies show a strong tendency to align along the cluster's largest filaments, but only in those clusters in which the dominant galaxy population is also highly aligned. We discuss the possibility that the spiral galaxies are actively forming in the clusters' filaments, and that their alignment is due to the influence of the large-scale structure and the resulting distribution of matter and angular momentum. We find that in A2744 the alignment of the spiral galaxies is rather well explained by the distribution of the large-scale structure, but that in A2058 the distribution of the structure is less well described by the alignment of the spiral galaxies. We show that in A2058 the spiral galaxies tend to align with the clusters' small-scale structure, while in A2744 they align with the clusters' large-scale structure. We discuss the physical mechanism responsible for the alignment of the spiral galaxies with the clusters' large-scale structure in A2744.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mean-Field Magnetohydrodynamics of Accretion Disks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0421, "human_text": "  We consider the accretion process in a disk with magnetic fields that are\ndragged in from the interstellar medium by gravitational collapse. Two\ndiffusive processes are at work in the system: (1) \"viscous\" torques exerted by\nturbulent and magnetic stresses, and (2) \"resistive\" redistribution of mass\nwith respect to the magnetic flux arising from the imperfect conduction of\ncurrent. In steady state, self-consistency between the two rates of drift\nrequires that a relationship exists between the coefficients of turbulent\nviscosity and turbulent resistivity. Ignoring any interactions with a stellar\nmagnetosphere, we solve the steady-state equations for a magnetized disk under\nthe gravitational attraction of a mass point and threaded by an amount of\nmagnetic flux consistent with calculations of magnetized gravitational collapse\nin star formation. Our model mean-field equations have an exact analytical\nsolution that corresponds to magnetically diluted Keplerian rotation about the\ncentral mass point. The solution yields the strength of the magnetic field and\nthe surface density as functions of radial position in the disk and their\nconnection with the departure from pure Keplerian rotation in representative\ncases. We compare the predictions of the theory with the available observations\nconcerning T Tauri stars, FU Orionis stars, and low- and high-mass protostars.\nFinally, we speculate on the physical causes for high and low states of the\naccretion disks that surround young stellar objects. One of the more important\nresults of this study is the physical derivation of analytic expressions for\nthe turbulent viscosity and turbulent resistivity.\n", "machine_text": "\n\nWe consider the problem of viscous accretion onto a compact object from a large reservoir of gas, with the object and the gas at different temperatures. We solve the resulting viscous magnetohydrodynamic (MHD) equations in a mean-field approximation. We find that when the gas is at a lower temperature than the object, the accretion flow is turbulent and the turbulence is quenched by the temperature gradient in the direction of the flow, consistent with observations of accretion disks around black holes. The turbulence is characterized by a velocity distribution function with two different power-law exponents, one in the bulk of the disk and the other at the edge. We also find that the temperature distribution in the disk is log-normal and that the standard deviation of the temperature distribution is proportional to the temperature difference between the gas and the object. When the gas is at a higher temperature than the object, we find that the accretion flow is steady and stable, consistent with the observed accretion flow in the solar wind. We discuss the relevance of our results to the problem of accretion control.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraining dark energy via baryon acoustic oscillations in the\n  (an)isotropic light-cone power spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0354, "human_text": "  The measurement of the scale of the baryon acoustic oscillations (BAO) in the\ngalaxy power spectrum as a function of redshift is a promising method to\nconstrain the equation-of-state parameter of the dark energy w. To measure the\nscale of the BAO precisely, a substantial volume of space must be surveyed. We\ntest whether light-cone effects are important and whether the scaling relations\nused to compensate for an incorrect reference cosmology are in this case\nsufficiently accurate. We investigate the degeneracies in the cosmological\nparameters and the benefits of using the two-dimensional anisotropic power\nspectrum. Finally, we estimate the uncertainty with which w can be measured by\nproposed surveys at redshifts of about z=3 and z=1, respectively.\n  In the simulated survey we find that light-cone effects are small and that\nthe simple scaling relations used to correct for the cosmological distortion\nwork fairly well even for large survey volumes. The analysis of the\ntwo-dimensional anisotropic power spectra enables an independent determination\nto be made of the apparent scale of the BAO, perpendicular and parallel to the\nline of sight. This is essential for two-parameter w-models, such as the\nredshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for\nthe matter and baryon density and Delta(H_0)=5% for the Hubble constant, we\nestimate that the BAO measurements of future surveys around z=3 and z=1 will be\nable to constrain, independently of other cosmological probes, a constant w to\n~ 12% and ~ 11% (68% c.l.), respectively.\n", "machine_text": "\n\nWe present a formalism to constrain the dark energy density through its signature on the anisotropic power spectrum of the matter distribution in a galaxy cluster. The formalism is based on the comparison of the measured power spectrum with the one expected from an isotropic distribution of matter in a harmonic potential well. The potential well is created by the baryon acoustic oscillations (BAO) of the matter distribution. The BAO scale is determined from the observed correlation function and used to set the scale of the potential well. We show that the difference between the measured and the predicted power spectrum is sensitive to the dark energy density and can be used to set a bound on the dark energy density. We find that the current observations are consistent with a dark energy density that is less than a certain value, which depends on the BAO scale. The BAO scale can be determined from current observations with an accuracy of about 10%. We discuss the current constraints on the dark energy density and the prospects of future observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The interplay between radio galaxies and cluster environment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0574, "human_text": "  By combining the REFLEX and NORAS cluster datasets with the NVSS radio\ncatalogue, we obtain a sample of 145, z<0.3, X-ray selected clusters brighter\nthan 3 10^(-12) erg/s/cm^2 that show a central radio emission above 3 mJy. For\nvirial masses M_vir<~10^(14.5) M_sun, 11 clusters out of 12 (corresponding to\n92% of the systems) are inhabited by a central radio source. This fraction\ndecreases with higher masses as M_vir^(-0.4) and suggests that the majority of\nX-ray selected clusters host in their centre a radio source brighter than about\n10^(20) W/Hz/sr. A division of the sample into clusters harbouring either\npoint-like or an extended radio-loud AGN reveals that the steepening of the\nL_X-T relation for low-temperature clusters is strongly associated with the\npresence of central radio objects with extended jets and/or lobe structures. In\nthe latter case, L_X\\propto T^(4) while for point-like sources one recovers an\napproximately self-similar relation L_X\\propto T^(2.3). Monte Carlo simulations\nshow that the steepening of the L_X-T relation is not caused by clusters being\nunder-luminous in the X-ray band, but rather by overheating, most likely caused\nby the interplay between the extended radio structures and the intracluster\nmedium. In the case of low-mass systems, we also find a tight correlation\nbetween radio luminosity and cluster temperature. The effects of the central\nradio source on the thermal state of a cluster become less important with\nincreasing cluster mass. (Abridged) The luminosity distribution of the cluster\nradio population differs from that of all radio sources, as there is a deficit\nof low-luminosity (L_R<~10^(22) W/Hz/sr) objects, while the number of\nhigh-luminosity ones is boosted. The net effect on the radio luminosity\nfunction is of a flattening at all luminosities L_R<~ 10^(24) W/Hz/sr.\n", "machine_text": "\n\nWe present here results of a systematic numerical study of the interplay between the dynamics of radio galaxies and the cluster environment. We find that the cluster potential can significantly alter the distribution of radio galaxies in the cluster, in particular in the outskirts where the influence of the cluster is the strongest. We also find that a lack of cluster influence on radio galaxies, as is the case in the Local Group, results in a flatter radio galaxy distribution. Our results suggest that in clusters with a steep radio galaxy distribution, the cluster environment has a strong influence on the radio galaxies, while in clusters with a flat distribution the cluster environment has little influence. We also discuss a possible connection between the distribution of radio galaxies in clusters and the cluster mass distribution. Our results are consistent with a picture where the dynamics of radio galaxies is influenced by the cluster environment, in particular by the distribution of mass in the cluster, but also by other cluster properties, such as the strength of the radio source.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-photon transitions in hydrogen and cosmological recombination. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3033, "human_text": "  We study the two-photon process for the transitions ns --> 1s and nd --> 1s\nin hydrogen up to large n. For n<=20 we provide simple analytic fitting\nformulae to describe the non-resonant part of the two-photon emission profiles.\nCombining these with the analytic form of the cascade-term yields a simple and\naccurate description of the full two-photon decay spectrum, which only involves\na sum over a few intermediate states. We demonstrate that the cascade term\nnaturally leads to a nearly Lorentzian shape of the two-photon profiles in the\nvicinity of the resonances. However, due to quantum-electrodynamical\ncorrections, the two-photon emission spectra deviate significantly from the\nLorentzian shape in the very distant wings of the resonances. We investigate up\nto which distance the two-photon profiles are close to a Lorentzian and discuss\nthe role of the interference term. We then analyze how the deviation of the\ntwo-photon profiles from the Lorentzian shape affects the dynamics of\ncosmological hydrogen recombination. Since in this context the escape of\nphotons from the Lyman-alpha resonance plays a crucial role, we concentrate on\nthe two-photon corrections in the vicinity of the Lyman-alpha line. Our\ncomputations show that the changes in the ionization history due to the\nadditional two-photon process from high shell (n>2) likely do not reach the\npercent-level. For conservative assumptions we find a correction DN_e/N_e~-0.4%\nat redshift z~1160. This is numerically similar to the result of another recent\nstudy; however, the physics leading to this conclusion is rather different. In\nparticular, our calculations of the effective two-photon decay rates yield\nsignificantly different values, where the destructive interference of the\nresonant and non-resonant terms plays a crucial role in this context (abridged)\n", "machine_text": "\nWe consider two-photon transitions in hydrogen and their role in the cosmological recombination history of the Universe. Two-photon transitions in hydrogen are uniquely determined by the fine structure constant, the proton-to-electron mass ratio, and the Dirac constant of the electron. We show that in the presence of a strong magnetic field, two-photon transitions in hydrogen are completely suppressed, in agreement with the observation that the cosmic microwave background does not show any signature of magnetic fields stronger than a few micro-gauss. This result suggests that any attempt to explain the origin of magnetic fields by mechanisms acting on hydrogen alone are likely to be unsuccessful. We also show that two-photon transitions in hydrogen can have a significant effect on the recombination history of the Universe, but only if the electron-to-photon ratio is extremely large. In this case, two-photon transitions can either completely suppress or accelerate recombination, depending on the strength of the magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Aid to Percutaneous Renal Access by Virtual Projection of the Ultrasound\n  Puncture Tract onto Fluoroscopic Images. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4412, "human_text": "  Background and Purpose: Percutaneous renal access in the context of\npercutaneous nephrolithotomy (PCNL) is a difficult technique, requiring rapid\nand precise access to a particular calix. We present a computerized system\ndesigned to improve percutaneous renal access by projecting the ultrasound\npuncture tract onto fluoroscopic images. Materials and Methods: The system\nconsists of a computer and a localizer allowing spatial localization of the\nposition of the various instruments. Without any human intervention, the\nultrasound nephrostomy tract is superimposed in real time onto fluoroscopic\nimages acquired in various views. Results: We tested our approach by laboratory\nexperiments on a phantom. Also, after approval by our institution's Ethics\nCommittee, we validated this technique in the operating room during PCNL in one\npatient. Conclusion: Our system is reliable, and the absence of\nimage-processing procedures makes it robust. We have initiated a prospective\nstudy to validate this technique both for PCNL specialists and as a learning\ntool.\n", "machine_text": "\n\nWe have developed a new method for percutaneous renal access, using virtual projection of the ultrasound puncture tract onto fluoroscopic images. In order to obtain the projection, the ultrasound image and the fluoroscopic image are simultaneously displayed, allowing the puncture to be performed on the basis of the fusion image. In this study, the puncture tracts were projected onto the fluoroscopic images in three different ways. The first method used a simple linear transformation, whereas the other two methods used a more sophisticated transformation that allowed the tract to be curved. To evaluate the accuracy of the projection, a phantom study was performed in which the distance between the tip of a wire inserted into the phantom and its projected image on the fluoroscopic image was measured. The results showed that the projection of the puncture tract was very useful for obtaining the correct puncture site, and that the two curved transformation methods gave better results than the linear method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: J-class operators and hypercyclicity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3354, "human_text": "  The purpose of the present work is to treat a new notion related to linear\ndynamics, which can be viewed as a \"localization\" of the notion of\nhypercyclicity. In particular, let $T$ be a bounded linear operator acting on a\nBanach space $X$ and let $x$ be a non-zero vector in $X$ such that for every\nopen neighborhood $U\\subset X$ of $x$ and every non-empty open set $V\\subset X$\nthere exists a positive integer $n$ such that $T^{n}U\\cap V\\neq\\emptyset$. In\nthis case $T$ will be called a $J$-class operator. We investigate the class of\noperators satisfying the above property and provide various examples. It is\nworthwhile to mention that many results from the theory of hypercyclic\noperators have their analogues in this setting. For example we establish\nresults related to the Bourdon-Feldman theorem and we characterize the\n$J$-class weighted shifts. We would also like to stress that even non-separable\nBanach spaces which do not support topologically transitive operators, as for\nexample $l^{\\infty}(\\mathbb{N})$, do admit $J$-class operators.\n", "machine_text": "\n\nWe introduce and study a class of operators, called J-class operators, that generalize the hypercyclic operators introduced by groinig in the context of operator theory. The main motivation for this work is to understand the common properties of the hypercyclic and J-class operators, which seem to be rather different in their definitions. Our main results are the following: (i) We show that the J-class operators form a linear subspace of the direct sum of the Banach algebras of all J-class operators. (ii) We show that the J-class operators are closed under the formation of the direct sum, the Cartan product, and the symplectic product. (iii) We show that the J-class operators are (url) finite-dimensional. (iv) We show that the J-class operators are generated by the elements of the form , where is the minimal polynomial of , and the complex conjugate of . (v) We show that the J-class operators form a Banach algebra, and that they are isomorphic to the algebra of all operators on the space that commute with a given J-class operator. (vi) We show that any J-class operator is a limit of a sequence of hypercyclic operators. (vii) We show that any hypercyclic operator is a limit of a sequence of J-class operators. (viii) We show that any finite-dimensional, irreducible representation of the J-class operators is isomorphic to a representation of the hypercyclic operators. (ix) We show that the J-class operators form a poset.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Phase structure of a surface model on dynamically triangulated spheres\n  with elastic skeletons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0493, "human_text": "  We find three distinct phases; a tubular phase, a planar phase, and the\nspherical phase, in a triangulated fluid surface model. It is also found that\nthese phases are separated by discontinuous transitions. The fluid surface\nmodel is investigated within the framework of the conventional curvature model\nby using the canonical Monte Carlo simulations with dynamical triangulations.\nThe mechanical strength of the surface is given only by skeletons, and no\ntwo-dimensional bending energy is assumed in the Hamiltonian. The skeletons are\ncomposed of elastic linear-chains and rigid junctions and form a\ncompartmentalized structure on the surface, and for this reason the vertices of\ntriangles can diffuse freely only inside the compartments. As a consequence, an\ninhomogeneous structure is introduced in the model; the surface strength inside\nthe compartments is different from the surface strength on the compartments.\nHowever, the rotational symmetry is not influenced by the elastic skeletons;\nthere is no specific direction on the surface. In addition to the three phases\nmentioned above, a collapsed phase is expected to exist in the low bending\nrigidity regime that was not studied here. The inhomogeneous structure and the\nfluidity of vertices are considered to be the origin of such variety of phases.\n", "machine_text": "\nWe consider a geometric surface model defined on dynamically triangulated spheres with elastic skeletons. The motivation for this work is to provide a robust and well-defined geometrically continuous surface model in the absence of any a-priori assumptions on the geometry of the data. We show that the surface is well-defined and robust by proving that it is insensitive to small additions or removals of vertices and edges in the underlying triangle mesh. We show that this surface is also geometrically meaningful by proving that it has a well-defined and continuous normal vector field. We further prove that the surface model is isometric to the originally input mesh in the sense that it preserves the angles between adjacent triangles. We show that this surface model can be used to develop a simple, yet effective algorithm for computing geodesic paths on the surface. We implement this algorithm and show that the computed geodesic paths are sensitive to small perturbations of the surface model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dirichlet or Potts ?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.245, "human_text": "  When modeling the distribution of a set of data by a mixture of Gaussians,\nthere are two possibilities: i) the classical one is using a set of parameters\nwhich are the proportions, the means and the variances; ii) the second is to\nconsider the proportions as the probabilities of a discrete valued hidden\nvariable. In the first case a usual prior distribution for the proportions is\nthe Dirichlet which accounts for the fact that they have to sum up to one. In\nthe second case, to each data is associated a hidden variable for which we\nconsider two possibilities: a) assuming those variables to be i.i.d. We show\nthen that this scheme is equivalent to the classical mixture model with\nDirichlet prior; b) assuming a Markovian structure. Then we choose the simplest\nmarkovian model which is the Potts distribution. As we will see this model is\nmore appropriate for the case where the data represents the pixels of an image\nfor which the hidden variables represent a segmentation of that image. The main\nobject of this paper is to give some details on these models and different\nalgorithms used for their simulation and the estimation of their parameters.\n  Key Words: Mixture of Gaussians, Dirichlet, Potts, Classification,\nSegmentation.\n", "machine_text": "\n\n Dirichlet or Potts ?\n====================\n\nWe consider the problem of estimating the number of non-zero components of a complex-valued random vector $X \\sim \\mathcal{N}(0,\\Sigma)$ where $\\Sigma$ is a positive-definite matrix. We show that the estimator $\\nu(X)$, defined as the number of positive components of $X$, has an approximate normal distribution with $\\sigma^2 = \\frac{1}{2}\\nu(X)$ as variance. This variance is independent of the dimension $d$ and the number $n$ of components of $X$ and does not increase with the number of components. This is in contrast to the usual $\\chi^2$-test for the number of components which has a variance $2(n-d)$. We show that the approximation becomes exact if the random vector $X$ has only a finite number of components or if the components are independent. We also derive a simple expression for the distribution of the estimator $\\nu(X)$ in terms of the distribution of $X^*$ and theDeterminant function. This allows to give a simple and transparent derivation of the distribution of $\\nu(X)$ in terms of Dirichlet and Potts (or Wronskian) functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two Energy Release Processes for CMEs: MHD Catastrophe and Magnetic\n  Reconnection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3886, "human_text": "  It remains an open question how magnetic energy is rapidly released in the\nsolar corona so as to create solar explosions such as solar flares and coronal\nmass ejections (CMEs). Recent studies have confirmed that a system consisting\nof a flux rope embedded in a background field exhibits a catastrophic behavior,\nand the energy threshold at the catastrophic point may exceed the associated\nopen field energy. The accumulated free energy in the corona is abruptly\nreleased when the catastrophe takes place, and it probably serves as the main\nmeans of energy release for CMEs at least in the initial phase. Such a release\nproceeds via an ideal MHD process in contrast with nonideal ones such as\nmagnetic reconnection. The catastrophe results in a sudden formation of\nelectric current sheets, which naturally provide proper sites for fast magnetic\nreconnection. The reconnection may be identified with a solar flare associated\nwith the CME on one hand, and produces a further acceleration of the CME on the\nother. On this basis, several preliminary suggestions are made for future\nobservational investigations, especially with the proposed KuaFu satellites, on\nthe roles of the MHD catastrophe and magnetic reconnection in the magnetic\nenergy release associated with CMEs and flares.\n", "machine_text": "\n\nWe present a detailed kinetic analysis of the energy release in the formation of coronal mass ejections (CMEs). We consider two energy release processes: the magnetic reconnection and the magnetohydrodynamic (MHD) catastrophe. We evaluate the energy released in the form of particle kinetic energy and in the form of thermal energy. We solve the resistive magnetohydrodynamic equations with the help of the Wissink-Olive model for the density and the glorified k-Ohm's law for the resistivity. The solution is stable against the inverse cube law for the resistivity. We consider two different parameter regimes: (1) small dynamic pressure and large magnetic field and (2) large dynamic pressure and small magnetic field. We solve the equations in a resistive MHD approximation. The obtained solutions are in good agreement with observations. We find that in both regimes the dominant energy release process is the MHD catastrophe. We also found the energy released in the form of particle kinetic energy is significant only in the regime (1). We discuss the implications of our results for the energy budget of CMEs. We also discuss the problem of the low-frequency (LCF) generation in the context of our model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Pair of Bootes: A New Milky Way Satellite. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1378, "human_text": "  As part of preparations for a southern sky search for faint Milky Way dwarf\ngalaxy satellites, we report the discovery of a stellar overdensity in the\nSloan Digital Sky Survey Data Release 5, lying at an angular distance of only\n1.5 degrees from the recently discovered Bo{\\\"o}tes dwarf. The overdensity was\ndetected well above statistical noise by employing a sophisticated data mining\nalgorithm and does not correspond to any catalogued object. Overlaid isochrones\nusing stellar population synthesis models show that the color-magnitude diagram\nof that region has the signature of an old (12 Gyr), metal-poor (${\\rm\nFe/H}\\approx-2.0$) stellar population at a tentative distance of 60 kpc,\nevidently the same heliocentric distance as the Bo\\\"otes dwarf. We estimate the\nnew object to have a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a\nhalf-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc) placing it in an\napparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies,\noccupied only by another recently discovered Milky Way Satellite, Coma\nBerenices.\n", "machine_text": "\n\nWe present a new low-mass satellite of the Milky Way, discovered by the Gaia spacecraft. This object, which we name \"Bootes,\" has a Galactic orbit inclined at an angle of about 75 degrees to the plane of the Galactic disk, and it has a peculiar velocity of about 200 km/s, almost three times that of the Local Standard of Rest. This velocity is similar to that of the recently discovered satellite Leo, but unlike that object, Bootes has a proper motion of about 10 mas/yr, which means that it has not yet been gravitationally bound by the Galaxy and thus is a free satellite. We estimate that Bootes has a mass of about 10^5 solar masses (M_{\u26ab}\u22c5R\u2081\u2080 \u2248 2.4 kpc$^{-1}$), a value that is not only similar to Leo's but also to that of the Large and Small Magellanic Clouds. We discuss the possibility that Bootes, like Leo, may be a dwarf spheroidal satellite, but we also point out that its large peculiar velocity and relatively large proper motion imply a different dynamical history from that of Leo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Oscillation thresholds for \"strinking outwards\" reeds coupled to a\n  resonator. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4242, "human_text": "  This paper considers a \"striking outwards\" reed coupled to a resonator. This\nexpression, due to Helmholtz, is not discussed here : it corresponds to the\nmost common model of a lip-type valve, when the valve is assumed to be a one\ndegree of freedom oscillator. The presented work is an extension of the works\ndone by Wilson and Beavers (1974), Tarnopolsky (2000). The range of the playing\nfrequencies is investigated. The first results are analytical : when no losses\nare present in the resonator, it is proven that the ratio between the threshold\nfrequency and the reed resonance frequency is found to be necessarily within\nthe interval between unity and the square root of 3. This is a musical sixth.\nActually the interval is largely smaller, and this is in accordance with e.g.\nthe results by Cullen et al.. The smallest blowing pressure is found to be\ndirectly related to the quality factor of the reed. Numerical results confirm\nthese statements, and are discussed in comparison with previous ones by Cullen\net al (2000).\n", "machine_text": "\nWe consider the effect of a resonator on the transient response of a flexible cantilever \"strinking outwards\" reed. The transient response is a superposition of the oscillations of the reed and the resonator. We show that the transient response can be described by two different ways, depending on the relative magnitude of the natural frequency of the reed and that of the resonator. If the natural frequency of the resonator is much smaller than that of the reed, the transient response can be described by a single wavelength of the reed's natural frequency. If the resonator's natural frequency is not much smaller than that of the reed, the transient response is a superposition of the waveforms of the two natural frequencies, with a beat frequency given by the difference between the two natural frequencies. We evaluate the threshold value of the resonator's natural frequency for which the transient response switches from the single-wavelength description to the superposition description. We show that this threshold is given by the condition that the resonator's natural frequency is equal to twice the reed's natural frequency. We also derive a simple expression for the magnitude of the beat frequency in the superposition description.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observations towards early-type stars in the ESO-POP survey: II --\n  searches for intermediate and high velocity clouds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1315, "human_text": "  We present CaII K and TiII optical spectra of early-type stars taken mainly\nfrom the UVES Paranal Observatory Project, plus HI 21-cm spectra from the\nVila-Elisa and Leiden-Dwingeloo surveys, which are employed to obtain distances\nto intermediate and high velocity clouds. HI emission at a velocity of -117\nkm/s towards the sightline HD 30677 with NHI=1.7x10^19 cm-2 has no\ncorresponding CaII K absorption, which has a signal-to-noise (S/N) ratio of\n610. The star has a spectroscopically determined distance of 2.7-kpc, and hence\nsets this as a firm lower distance limit towards Anti-Centre cloud ACII.\nTowards another sightline (HD 46185), HI at +122 km/s and NHI=1.2x10^19 cm-2 is\nseen. The CaII K spectrum has a S/N = 780, although no absorption is observed\nat the cloud velocity. This similarly places a firm lower distance limit of\n2.9-kpc towards this parcel of gas that may be an intermediate velocity cloud.\nThe lack of intermediate velocity (IV) CaII K absorption towards HD 196426 at a\nS/N = 500 reinforces a lower distance limit of 700-pc towards this part of\nComplex gp, where NHI is 1.1x10^19 cm-2 and velocity is +78 km/s. Additionally,\nno IV CaII K is seen in absorption in the spectrum of HD 19445, which is strong\nin HI with NHI=8x10^19 cm-2 at -42 km/s, placing a firm although uninteresting\nlower distance limit of 39-pc to this part of IV South. Finally, no HV CaII K\nabsorption is seen towards HD 115363 at a S/N = 410, placing a lower distance\nof 3.2-kpc towards the HVC gas at velocity of +224 km/s and NHI=5.2x10^19 cm-2.\nThis gas is in the same region of the sky as complex WE (Wakker 2001), but at\nhigher velocities. The non-detection of CaII K absorption sets a lower distance\nof 3.2-kpc towards the HVC, which is unsurprising if this feature is indeed\nrelated to the Magellanic System.\n", "machine_text": "\n\nWe present the second part of a two-part study of the gas content of 29 bright early-type stars in the solar neighbourhood, selected from the ESO Proper Motion Survey (ESO-POP). The first part, containing the results of a high-resolution molecular line survey, was published in ApJ 532, 951 (2000). In this part we present a systematic search for intermediate and high velocity clouds using absorption lines of the CO molecule. We find that four of our stars (including the Sun) are clearly associated with such clouds. In the case of two of these clouds, the association is very strong, and the clouds are probably part of the Local Bubble. We find that the CO lines are rather weak and uncertain, and we were unable to identify clouds around several of the stars with strong molecular hydrogen lines. We discuss our non-detections in the light of various models, and suggest that (i) a substantial fraction of early-type stars may be associated with high-velocity clouds, (ii) these clouds may be relatively small, and (iii) high-resolution molecular line surveys are probably the best way to search for such clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ray-tracing and physical-optics analysis of the aperture efficiency in a\n  radio telescope. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3379, "human_text": "  The performance of telescope systems working at microwave or visible/IR\nwavelengths is typically described in terms of different parameters according\nto the wavelength range. Most commercial ray tracing packages have been\nspecifically designed for use with visible/IR systems and thus, though very\nflexible and sophisticated, do not provide the appropriate parameters to fully\ndescribe microwave antennas, and thus to compare with specifications. In this\nwork we demonstrate that the Strehl ratio is equal to the phase efficiency when\nthe apodization factor is taken into account. The phase efficiency is the most\ncritical contribution to the aperture efficiency of an antenna, and the most\ndifficult parameter to optimize during the telescope design. The equivalence\nbetween the Strehl ratio and the phase efficiency gives the designer/user of\nthe telescope the opportunity to use the faster commercial ray-tracing software\nto optimize the design. We also discuss the results of several tests performed\nto check the validity of this relationship that we carried out using a\nray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3,\napplied to three different telescope designs that span a factor of $\\simeq 10\nin terms of D/lambda. The maximum measured discrepancy between phase efficiency\nand Strehl ratio varies between $\\simeq 0.4 and 1.9 up to an offset angle of\n>40 beams, depending on the optical configuration, but it is always less than\n0.5 where the Strehl ratio is >0.95.\n", "machine_text": "\n\nWe present a ray-tracing and physical-optics analysis of the aperture efficiency in a radio telescope. We derive an analytical expression for the aperture efficiency in terms of the optical path length. We obtain a good agreement between our analytical expression and previously published results obtained by other methods. Our derivation is based on a physical-optics analysis of the wave propagation in the telescope. We obtain the distribution of the optical path length in the telescope by ray-tracing. We use this distribution in our physical-optics analysis. We confirm the validity of our approach by comparing our results with previously published results obtained by other methods. We also present a simple and accurate expression for the relative aperture efficiency as a function of the optical path length in the case of a telescope with a single dish. Our expression for the relative aperture efficiency can be easily used to calculate the signal-to-noise ratio in a radio telescope as a function of the optical path length.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spinons and triplons in spatially anisotropic frustrated\n  antiferromagnets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2012, "human_text": "  The search for elementary excitations with fractional quantum numbers is a\ncentral challenge in modern condensed matter physics. We explore the\npossibility in a realistic model for several materials, the spin-1/2 spatially\nanisotropic frustrated Heisenberg antiferromagnet in two dimensions. By\nrestricting the Hilbert space to that expressed by exact eigenstates of the\nHeisenberg chain, we derive an effective Schr\\\"odinger equation valid in the\nweak interchain-coupling regime. The dynamical spin correlations from this\napproach agree quantitatively with inelastic neutron measurements on the\ntriangular antiferromagnet Cs_2CuCl_4. The spectral features in such\nantiferromagnets can be attributed to two types of excitations: descendents of\none-dimensional spinons of individual chains, and coherently propagating\n\"triplon\" bound states of spinon pairs. We argue that triplons are generic\nfeatures of spatially anisotropic frustrated antiferromagnets, and arise\nbecause the bound spinon pair lowers its kinetic energy by propagating between\nchains.\n", "machine_text": "\n\nWe investigate the relation between the spin- and triplet-flavor of massive ( Nuevaola-BO1957 and Heisenberg-OULAMP ) and massless ( ABENGOA-DELGADO-OLIVA-RODRIGUEZ-VAZQUEZ-CUENCA ) triplons in spatially anisotropic frustrated antiferromagnets. The formalism is based on the notion of tripletons (or triplons) and spinons, which are respectively the massive and massless excitation associated with the triplet and spin degrees of freedom of the magnetic system. We show that the triplon-spinon correspondence is different in a frustrated antiferromagnet than in a regular one, due to the appearance of exotic massive and massless excitations, named here massive and massless triplons, in the thermodynamic limit. In particular, the massive triplon is a genuinely massive excitation, while the massless triplon is a genuine massless excitation, but with a finite lifetime. We show further that the lifetime of the massless triplon is related to the dynamical properties of the spin degree of freedom, in contrast to the massless spinon, for which this degree of freedom is always frozen.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A general approach to statistical modeling of physical laws:\n  nonparametric regression. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0089, "human_text": "  Statistical modeling of experimental physical laws is based on the\nprobability density function of measured variables. It is expressed by\nexperimental data via a kernel estimator. The kernel is determined objectively\nby the scattering of data during calibration of experimental setup. A physical\nlaw, which relates measured variables, is optimally extracted from experimental\ndata by the conditional average estimator. It is derived directly from the\nkernel estimator and corresponds to a general nonparametric regression. The\nproposed method is demonstrated by the modeling of a return map of noisy\nchaotic data. In this example, the nonparametric regression is used to predict\na future value of chaotic time series from the present one. The mean predictor\nerror is used in the definition of predictor quality, while the redundancy is\nexpressed by the mean square distance between data points. Both statistics are\nused in a new definition of predictor cost function. From the minimum of the\npredictor cost function, a proper number of data in the model is estimated.\n", "machine_text": "\nWe introduce a general approach to statistical modeling of physical laws based on nonparametric regression. The approach is motivated by the fact that the process of scientific discovery often involves identifying a relationship between physical quantities and then quantitatively characterizing the relationship. We focus on regression-based methods because they are well-suited for exploring nonlinear relationships and because they are used extensively in statistics to model data. Our approach is general and can be applied to any system in which the quantities of interest can be measured experimentally. We demonstrate the effectiveness of our approach by applying it to three problems in physics: (1) we show how to use regression to learn the functional form of an unknown physical law from data, (2) we show how to use regression to fit a physical law to data in a way that reduces the impact of noise on the resulting fit, and (3) we show how to use regression to identify a physical law that describes a data set, even when the form of the physical law is not known in advance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraints on the merging timescale of luminous red galaxies, or, where\n  do all the halos go?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.052, "human_text": "  In the LCDM cosmology dark matter halos grow primarily through the accretion\nof smaller halos. Much of the mass in a halo of 10^14Msun comes in through\naccretion of ~10^13Msun halos. If each such halo hosted one luminous red galaxy\n(LRG) then the accretion of so many halos is at odds with the observed number\nof LRGs in clusters unless these accreted LRGs merge or disrupt on relatively\nshort timescales (~2Gyr). These timescales are consistent with classical\ndynamical friction arguments, and imply that 2-3 LRGs have merged or disrupted\nwithin each halo more massive than 10^14Msun by z=0. The total amount of\nstellar mass brought into these massive halos by z=0 is consistent with\nobservations once the intracluster light (ICL) is included. If disrupted LRGs\nbuild up the ICL, then the hierarchical growth of massive halos implies that a\nsubstantial amount of ICL should also surround satellite LRGs, as suggested by\nrecent observations of the Virgo cluster. Finally, we point out that these\nresults are entirely consistent with a non-evolving clustering strength and\nhalo occupation distribution, and note that observations of the latter in fact\nsupport the hypothesis that merging/disruption of massive galaxies does indeed\ntake place at late times.\n", "machine_text": "\n\nWe present a simple model of the evolution of Luminous Red Galaxies (LRGs) that simultaneously addresses several outstanding issues in the study of this galaxy population, including the question of whether the population is old or young, and the origin of the distinctive morphologies of LRG galaxies. The model consists of a semi-realistic galaxy formation and evolution model coupled with a simple model of LRG formation based on the virialization of massive gas clouds. The model is used to investigate the merging history of LRG galaxies, and in particular, the time since the last major merger. We find that the observed merging timescales are consistent with the predicted merging timescales based on our simple model, except for a few extreme cases. This provides strong evidence that the merging history of LRG galaxies is not different from that of galaxies in general, despite the distinctive morphologies of LRG galaxies. We also use the model to investigate the relation between the mass of the nuclear bulge and the merging timescale, and find that a simple relation is consistent with observations, suggesting that massive nuclear bulges form as a consequence of a major merger. The model has several testable predictions, and suggests several possible ways in which future work can further constrain the merging history of LRG galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Carrier-carrier entanglement and transport resonances in semiconductor\n  quantum dots. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2312, "human_text": "  We study theoretically the entanglement created in a scattering between an\nelectron, incoming from a source lead, and another electron bound in the ground\nstate of a quantum dot, connected to two leads. We analyze the role played by\nthe different kinds of resonances in the transmission spectra and by the number\nof scattering channels, into the amount of quantum correlations between the two\nidentical carriers. It is shown that the entanglement between their energy\nstates is not sensitive to the presence of Breit-Wigner resonances, while it\npresents a peculiar behavior in correspondence of Fano peaks: two close maxima\nseparated by a minimum, for a two-channel scattering, a single maximum for a\nmulti-channel scattering. Such a behavior is ascribed to the different\nmechanisms characterizing the two types of resonances. Our results suggest that\nthe production and detection of entanglement in quantum dot structures may be\ncontrolled by the manipulation of Fano resonances through external fields.\n", "machine_text": "\n\nWe investigate the role of carrier-carrier entanglement and transport resonances in the transport properties of semiconductor quantum dots. We consider a spherical quantum dot attached to the leads, which are attached to the substrates, and a finite-sized quantum dot in a similar configuration, which are placed in a disorder bath. We found that both quantum dots can be in an entanglement-induced negative-temperature state below a certain critical temperature, and the state is very stable against temperature variations. We also found the finite-sized quantum dot to be in a state with very long coherence time, and the dynamics in this state is completely different from the coherent state with low entanglement. We show that these results can be explained by a simple model, in which a certain number of carriers are 'trapped' at the dot-lead interface and their spatial distribution is influenced by entanglement and transport resonances. We also derived a simple formula for the entanglement-induced negative-temperature state. Our results provide a route to engineer non-trivial states in quantum dot systems by using carrier-carrier entanglement and transport resonances.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dyson Indices and Hilbert-Schmidt Separability Functions and\n  Probabilities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3723, "human_text": "  A confluence of numerical and theoretical results leads us to conjecture that\nthe Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional\nconvex sets of complex and real two-qubit states (representable by 4 x 4\ndensity matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning\nare the modifications of two ansatze, recently advanced (quant-ph/0609006),\ninvolving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11}\nrho_{44})/(rho_{22} rho_{33}). We, now, set the separability function\nS_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the\ncomplex case -- conforming to a pattern we find, manifesting the Dyson indices\n(1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2}\n(nu). We also investigate the real and complex qubit-qutrit cases. Now, there\nare two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}),\nnu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably\ncoalesce into the product, eta = nu_1 nu_2 = rho_{11} \\rho_{66}}{\\rho_{33}\n\\rho_{44}}, so that the real and complex separability functions are again\nunivariate in nature.\n", "machine_text": "\n\nWe study two different approaches to nonlinear estimation for Gaussian noise data. The first approach is based on the use of the Dyson indices, and the second approach is based on the use of Hilbert-Schmidt separability functions and the theory of probability. The motivation for the research is that the use of indices and functions in this way allows us to estimate the parameters of the nonlinear system with the minimum amount of computation. In addition, these approaches are naturally suited to be implemented on a computer. The key idea in the research is the use of the properties of the different types of indices and functions. The methodology used is to consider different possible ways of using the indices and functions, and to evaluate the performance of each method by using simulation. The results obtained are that both approaches can be used to estimate the parameters of the nonlinear system with a small amount of computation, and that the use of the indices is more suitable for systems with a small number of parameters, while the use of the functions is more suitable for systems with a large number of parameters. The problem that the work attempts to solve is to find a way to estimate the parameters of a nonlinear system with a small amount of computation, and the work provides a solution to this problem. The practical application of the work is that it provides a way to estimate the parameters of a nonlinear system with a small amount of computation. The theoretical application of the work is that it provides a way to understand the relationship between the indices and the functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Challenging the Cosmological Constant. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1977, "human_text": "  We outline a dynamical dark energy scenario whose signatures may be\nsimultaneously tested by astronomical observations and laboratory experiments.\nThe dark energy is a field with slightly sub-gravitational couplings to matter,\na logarithmic self-interaction potential with a scale tuned to $\\sim 10^{-3}\n{\\rm eV}$, as is usual in quintessence models, and an effective mass $m_\\phi$\ninfluenced by the environmental energy density. Its forces may be suppressed\njust below the current bounds by the chameleon-like mimicry, whereby only outer\nlayers of mass distributions, of thickness $1/m_\\phi$, give off appreciable\nlong range forces. After inflation and reheating, the field is relativistic,\nand attains a Planckian expectation value before Hubble friction freezes it.\nThis can make gravity in space slightly stronger than on Earth. During the\nmatter era, interactions with nonrelativistic matter dig a minimum close to the\nPlanck scale. However, due to its sub-gravitational matter couplings the field\nwill linger away from this minimum until the matter energy density dips below\n$\\sim 10^{-12} {\\rm eV}^4$. Then it starts to roll to the minimum, driving a\nperiod of cosmic acceleration. Among the signatures of this scenario may be\ndark energy equation of state $w \\ne -1$, stronger gravity in dilute mediums,\nthat may influence BBN and appear as an excess of dark matter, and\nsub-millimeter corrections to Newton's law, close to the present laboratory\nlimits.\n", "machine_text": "\n\nWe present a cosmological model that challenges the need for a cosmological constant in a universe with a flat space-time. Our model comprises a modified Einstein-Maxwell-Chern-Weinberg action with a cosmological constant that is absent from the dynamics, thus making the evolution of space-time effectively homeless. We show that this model is capable of producing the large-scale structure of the universe observed today, including the cosmic microwave background radiation, the large-scale galaxy distribution, and the cosmic hydrogen abundance, without the need for a cosmological constant or any other ad-hoc mechanism. We also show that the model can produce a broad range of small-scale structure, including the power spectrum of galaxies, galaxy spin-trails, and the distribution of intergalactic hydrogen, without recourse to a scale-invariant cosmological constant or any other ad-hoc mechanism. We show that the model's dynamics is driven by a combination of the ad-hoc cosmological constant and the dynamics of the Einstein-Maxwell-Chern-Weinberg action, which results in a universe that is scale-invariant and therefore free from the scale- hierarchies that appear in the data. Our model thus provides a simple and elegant explanation for the origin of the large-scale structure of the universe and the small-scale structure within it, without the need for a cosmological constant or any other ad-hoc mechanism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Low-temperature and high-temperature approximations for\n  penetrable-sphere fluids. Comparison with Monte Carlo simulations and\n  integral equation theories. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1069, "human_text": "  The two-body interaction in dilute solutions of polymer chains in good\nsolvents can be modeled by means of effective bounded potentials, the simplest\nof which being that of penetrable spheres (PSs). In this paper we construct two\nsimple analytical theories for the structural properties of PS fluids: a\nlow-temperature (LT) approximation, that can be seen as an extension to PSs of\nthe well-known solution of the Percus-Yevick (PY) equation for hard spheres,\nand a high-temperature (HT) approximation based on the exact asymptotic\nbehavior in the limit of infinite temperature. Monte Carlo simulations for a\nwide range of temperatures and densities are performed to assess the validity\nof both theories. It is found that, despite their simplicity, the HT and LT\napproximations exhibit a fair agreement with the simulation data within their\nrespective domains of applicability, so that they complement each other. A\ncomparison with numerical solutions of the PY and the hypernetted-chain\napproximations is also carried out, the latter showing a very good performance,\nexcept inside the core at low temperatures.\n", "machine_text": "\n\nWe develop low-temperature and high-temperature approximations for the statistical mechanic of fluids composed of penetrable spheres. Theseapproximations are shown to capture the essential features of the system, and are used to study the transition from the low-temperature to the high-temperaturephase. A simple model in which the radius of the spheres is taken to be proportional to the thermal length is used to determine the dynamic structure factor andthe specific heat. The accuracy of the low-temperature approximation is shown to be very good, provided that the thermal length is not too small. The high-temperatureapproximation is less accurate, but is still useful for fluids with very large thermal lengths. The low-temperature approximation is used to derive an integral equationfor the dynamic structure factor. The high-temperature approximation is used to obtain a simplified version of this integral equation. Both integral equations are shownto be in good agreement with Monte Carlo simulations, over a wide range of volume fractions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy dependence of jet transport parameter and parton saturation in\n  quark-gluon plasma. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1352, "human_text": "  We study the evolution and saturation of the gluon distribution function in\nthe quark-gluon plasma as probed by a propagating parton and its effect on the\ncomputation of jet quenching or transport parameter $\\hat{q}$. For thermal\npartons, the saturation scale $Q^2_s$ is found to be proportional to the Debye\nscreening mass $\\mu_D^2$. For hard probes, evolution at small $x=Q^2_s/6ET$\nleads to jet energy dependence of $\\hat{q}$. We study this dependence for both\na conformal gauge theory in weak and strong coupling limit and for (pure gluon)\nQCD. The energy dependence can be used to extract the shear viscosity $\\eta$ of\nthe medium since $\\eta$ can be related to the transport parameter for thermal\npartons in a transport description. We also derive upper bounds on the\ntransport parameter for both energetic and thermal partons. The later leads to\na lower bound on shear viscosity-to-entropy density ratio which is consistent\nwith the conjectured lower bound $\\eta/s\\geq 1/4\\pi$. We also discuss the\nimplications on the study of jet quenching at the BNL Relativistic Heavy Ion\nCollider and the CERN Large Hadron Collider and the bulk properties of the\ndense matter.\n", "machine_text": "\nWe investigate the energy dependence of the transport parameter and the phenomenon of parton saturation in relativistic heavy ion collisions from the point of view of a simplified microscopic model. The model consists of a lattice with a quark-gluon plasma (QGP) and a thermalized gas of lorentzian fragments, both interacting with each other and with the lattice. The model is analyzed by a numerical solution of the resulting Boltzmann equation. The energy dependence of the transport parameter is in qualitative agreement with the data of the Heavy Ion Russia (HIR) Collaboration, although our approach does not take into account the energy dependent QGP evolution and the strong anisotropy of the collisional dynamics. We show that the energy dependence of the transport parameter can be well described by a power law with an index of about 2.5. Our results for the saturation effect are in agreement with the HIR data, if the energy dependent evolution of the QGP is included in the description. We find that the anisotropy of the collisional dynamics is a crucial factor to describe the energy dependence of the transport parameter.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: J/psi Production in an Equilibrating Partonic System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0668, "human_text": "  Any color singlet or octet ccbar pair is created at short distances and then\nexpands to a full size of J/psi. Such a dynamical evolution process is included\nhere in calculations for the J/psi number distribution as a function of\ntransverse momentum and rapidity in central Au-Au collisions at both RHIC and\nLHC energies. The ccbar pairs are produced in the initial collision and in the\npartonic system during the prethermal and thermal stages through the partonic\nchannels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, and then they\ndissociate in the latter two stages. Dissociation of ccbar in the medium occurs\nvia two reactions: (a) color singlet ccbar plus a gluon turns to color octet\nccbar, (b) color octet ccbar plus a gluon persists as color octet. There are\nmodest yields of ccbar in the prethermal stage at RHIC energy and through the\nreactions ab to ccbar [{2S+1}L_J] at LHC energy for partons with large average\nmomentum in the prethermal stage at both collider energies and in the thermal\nstage at LHC energy. Production from the partonic system competes with the\nsuppression of the initial yield in the deconfined medium. Consequently, a\nbulge within -1.5<y<1.5 has been found for the J/psi number distribution and\nthe ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon\ncollisions. This bulge is caused by the partonic system and is thus an\nindicator of a deconfined partonic medium. Based on this result we suggest the\nrapidity region worth measuring in future experiments at RHIC and LHC to be\n-3<y<3.\n", "machine_text": "\nWe study the production of J/psi mesons in an equilibrating partonic system with the help of a particle-to-hole conversion model. The basic assumption of the model is that the partonic system can be represented by a one-particle picture and that the massless quarkonia are produced by a  radial-node conversion mechanism. The model has several parameters that can be adjusted to fit the data. The most important one is the ratio of the momentum transfer to the kinetic energy, which is related to the phase transition between the hadronization and the equilibration stages. The other parameters include the magnitude of the P-factor and the annihilation cross section of the quarkonia. By fitting the model to the data of J/psi meson production in  ultraperipheral collisions of  heavy ions we find that the parameter values are consistent with the model prediction that the equilibrating partonic system is mainly composed of a single (on-shell) parton and that the annihilation of quarkonia is a  very fast process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fifteen Years of High-Resolution Radio Imaging of Supernova 1987A. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0057, "human_text": "  Supernova 1987A in the Large Magellanic Cloud provides a spectacularly\ndetailed view of the aftermath of a core-collapse explosion. The supernova\nejecta initially coasted outward at more than 10% of the speed of light, but in\n1990 were observed to decelerate rapidly as they began to encounter dense\ncircumstellar material expelled by the progenitor star. The resulting shock has\nsubsequently produced steadily brightening radio synchrotron emission, which is\nresolved by the Australia Telescope Compact Array (ATCA) into an expanding\nlimb-brightened shell. Here we present 15 years of ATCA imaging of Supernova\n1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio\nremnant has accelerated in its expansion over this period, from approx 3600\nkm/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of\nthe evolving X-ray shell have been ~15% smaller than the corresponding radio\nvalues, but a simultaneous Fourier analysis of both radio and X-ray data\neliminates this discrepancy, and yields a current diameter for the shell in\nboth wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is\nseen in radio images at all ATCA epochs: the eastern and western rims have\nhigher fluxes than the northern and southern regions, indicating that most of\nthe radio emission comes from the equatorial plane of the system, where the\nprogenitor star's circumstellar wind is thought to be densest. The eastern lobe\nis brighter than and further from the supernova site than the western lobe,\nsuggesting an additional asymmetry in the initial distribution of supernova\nejecta.\n", "machine_text": "\n\nWe present high-resolution (\u03bb/D \u223c 100\u20131000) radio images of the superbubble surrounding the supernova (SN) 1987A. These images show the superbubble in great detail, including many features that were not previously visible at lower resolutions. The superbubble is asymmetric, with a large-scale lobe extending east-northeastward for \u223c 70 pc and a second, smaller-scale lobe extending north-northwestward for \u223c 35 pc. A number of small-scale structures are visible within the superbubble, including a prominent north-south-oriented chain of 3\u20134 arcminute-scale knots. We have found three new jets, bringing the total number of jets in the superbubble to nine. The sources of these jets are not the surviving companion star but instead are likely to be either accretion shock regions or the outer surface of the remnant stellar core. Two of the new jets are north-south-oriented and are collimated along magnetic field lines. The third jet is unique in that it is not collimated but instead is a bipolar flow with a complex structure. We have identified three regions of possible X-ray emission within the superbubble, although none of these regions is spatially coincident with the radio sources. The most likely explanation for the X-ray emission is the interaction of the superbubble with the ambient interstellar medium. We have derived a total mass for the superbubble of \u223c 5  \u00d7 10 36 grams, \u223c 1.4 times the mass of the Sun. This is the most accurate mass estimate to date. The mass is comprised of a inner-bubble region with a higher density and a much lower total mass than the outer superbubble region. We discuss several mechanisms that may have driven the evolution of the superbubble and estimate the rate of mass loss from the superbubble. We find that the mass loss is likely to have been dominated by two-body interactions and that the rate of mass loss has decreased considerably over the past 15 years.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mapping the circumstellar SiO maser emission in R Leo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0682, "human_text": "  The study of the innermost circumstellar layers around AGB stars is crucial\nto understand how these envelopes are formed and evolve. The SiO maser emission\noccurs at a few stellar radii from the central star, providing direct\ninformation on the stellar pulsation and on the chemical and physical\nproperties of these regions. Our data also shed light on several aspects of the\nSiO maser pumping theory that are not well understood yet. We aim to determine}\nthe relative spatial distribution of the 43 GHz and 86 GHz SiO maser lines in\nthe oxygen-rich evolved star R Leo. We have imaged with milliarcsecond\nresolution, by means of Very Long Baseline Interferometry, the 43 GHz (28SiO\nv=1, 2 J=1-0 and 29SiO v=0 J=1-0) and 86 GHz (28SiO v=1 J=2-1 and 29SiO v=0\nJ=2-1) masing regions. We confirm previous results obtained in other\noxygen-rich envelopes. In particular, when comparing the 43 GHz emitting\nregions, the 28SiO v=2 transition is produced in an inner layer, closer to the\ncentral star. On the other hand, the 86 GHz line arises in a clearly farther\nshell. We have also mapped for the first time the 29SiO v=0 J=1-0 emission in R\nLeo. The already reported discrepancy between the observed distributions of the\ndifferent maser lines and the theoretical predictions is also found in R Leo.\n", "machine_text": "\n\nWe present an analysis of the spatial distribution of the 43 GHz and 86 GHz SiO maser lines in the oxygen-rich evolved star R Leo. Our data confirm the presence of a maser spot, which we associate with a spatial accumulation of SiO, likely in a region of high density. We show that this spot is stable on timescales of years, as it must be to explain previous observations, but that its location is not fixed with respect to the stellar position, as has been suggested. Instead, it precesses around the star with a timescale that is roughly two orders of magnitude longer than the orbital period. We derive a simple model in which this precession is caused by the gravitational influence of a massive companion, and we use this model to constrain the masses of the two stars to be 1.95 $M_{\\odot}$ and 1.1 $M_{\\odot}$. This is consistent with the known masses of the main star and its companion, but we have no evidence that this is the correct model: other explanations, such as a migrating spot or a bipolar configuration, are also consistent with the data. We have also measured for the first time the 43 GHz maser line in the companion, but detected no significant emission at 86 GHz.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pseudogap and charge density waves in two dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1544, "human_text": "  An interaction between electrons and lattice vibrations (phonons) results in\ntwo fundamental quantum phenomena in solids: in three dimensions it can turn a\nmetal into a superconductor whereas in one dimension it can turn a metal into\nan insulator. In two dimensions (2D) both superconductivity and charge-density\nwaves (CDW) are believed to be anomalous. In superconducting cuprates, critical\ntransition temperatures are unusually high and the energy gap may stay unclosed\neven above these temperatures (pseudogap). In CDW-bearing dichalcogenides the\nresistivity below the transition can decrease with temperature even faster than\nin the normal phase and a basic prerequisite for the CDW, the favourable\nnesting conditions (when some sections of the Fermi surface appear shifted by\nthe same vector), seems to be absent. Notwithstanding the existence of\nalternatives to conventional theories, both phenomena in 2D still remain the\nmost fascinating puzzles in condensed matter physics. Using the latest\ndevelopments in high-resolution angle-resolved photoemission spectroscopy\n(ARPES) here we show that the normal-state pseudogap also exists in one of the\nmost studied 2D examples, dichalcogenide 2H-TaSe2, and the formation of CDW is\ndriven by a conventional nesting instability, which is masked by the pseudogap.\nOur findings reconcile and explain a number of unusual, as previously believed,\nexperimental responses as well as disprove many alternative theoretical\napproaches. The magnitude, character and anisotropy of the 2D-CDW pseudogap are\nintriguingly similar to those seen in superconducting cuprates.\n", "machine_text": "\n\nWe study pseudogap and charge density wave (CDW) phases in a model Hamiltonian for a two-dimensional (2D) lattice system with long-range interactions. We show that the pseudogap phase is associated with a breakdown of the CDW instability. We consider a general class of lattice Hamiltonians which includes the cuprate and organic conductors as well as several model Hamiltonians for which the CDW instability has been studied before. Our results are consistent with the picture that the pseudogap is a phase in which the system is locally in a CDW state, but the long-range Coulomb interactions are strong enough to destroy the global CDW order. The transition temperature to the pseudogap phase is found to be proportional to the square of the Coulomb interaction strength. We also found a strong dependence on the lattice structure, which indicates that the pseudogap phase is related to a disordered CDW state. \n\nPseudogap and charge density waves in two dimensions, , arXiv:cond-mat/0703.0353v1, 3 Aug. 2007.\n\nWe study pseudogap and charge density wave (CDW) phases in a model Hamiltonian for a two-dimensional (2D) lattice system with long-range interactions. We show that the pseudogap phase is associated with a breakdown of the CDW instability. We consider a general class of lattice Hamiltonians which includes the cuprate and organic conductors as well as several model Hamiltonians for which the CDW instability has been studied before. Our results are consistent with the picture that the pseudogap is a phase in which the system is locally in a CDW state, but the long-range Coulomb interactions are strong enough to destroy the global CDW order. The transition temperature to the pseudogap phase is found to be proportional to the square of the Coulomb interaction strength. We also found a strong dependence on the lattice structure, which indicates that the pseudogap phase is related to a disordered CDW state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detecting and Characterizing Planetary Systems with Transit Timing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0632, "human_text": "  In the coming decades, research in extrasolar planets aims to advance two\ngoals: 1) detecting and characterizing low-mass planets increasingly similar to\nthe Earth, and 2) improving our understanding of planet formation. We present a\nnew planet detection method that is capable of making large advances towards\nboth of these objectives and describe a modest network of telescopes that is\nable to make the requisite observations. In a system where a known planet\ntransits its host star, a second planet in that system will cause the time\nbetween transits to vary. These transit timing variations can be used to infer\nthe orbital elements and mass of the perturbing planet even if it has a mass\nthat is smaller than the mass of the Earth. This detection technique\ncomplements other techniques because it is most sensitive in mean-motion\nresonances where, due to degeneracies, other techniques have reduced\nsensitivity. Small ground-based observatories have already exceeded the\nphotometric precision necessary to detect sub-Earth mass planets. However, TTV\nplanet searches are currently limited by the relatively small number of\nhigh-precision transit data and insufficient observing time on existing\ntelescopes. These issues will be compounded as the number of known transiting\nplanets suitable for TTV study will increase substantially in the near future.\nA relatively modest investment in a ground-based network of small ($\\sim 0.5\n{\\rm m}$ telescopes could provide the needed coverage and so dramatically\nincrease the effectiveness of transit timing observations.\n", "machine_text": "\n\nDetecting and Characterizing Planetary Systems with Transit Timing\n\nWe present a new method to detect planetary systems and to estimate the orbital elements and masses of the components thereof. We monitor the timing of transits of a star by its planet or planets. If the system is orbitally stable, the transit times will repeat with a high degree of accuracy. In a system with many planets, the method can also be used to estimate the masses of the planets. We present an analysis of the transit timing of the exoplanet system Kepler-36. We find that the masses of the two largest planets can be estimated to within a factor of 2, provided that the orbits are known to within 2%. We present a simple method to derive the orbits, which relies on the measurement of only two transits for a system containing three or more planets. For the Kepler-36 system, we show that this method is sufficiently precise to derive the masses of the two largest planets. We show that transit timing can be used to detect multi-planetary systems, and to estimate the masses of the planets therein.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Photon Dominated Region Modeling of Barnard 68. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0913, "human_text": "  We use the Barnard 68 dark globule as a test case for a spherically symmetric\nPDR model exposed to low-UV radiation fields. With a roughly spherical\nmorphology and an accurately determined density profile, Barnard 68 is ideal\nfor this purpose. The processes governing the energy balance in the cloud\nsurface are studied in detail. We compare the spherically symmetric PDR model\nby Stoerzer, Stutzki & Sternberg (1996) to observations of the three lowest\nrotational transitions of 12CO, 13CO J = 2-1 and J = 3-2 as well as the [CI]\n3P_1-3P_0 fine structure transition. We study the role of Polycyclic Aromatic\nHydrocarbons (PAHs) in the chemical network of the PDR model and consider the\nimpact of depletion as well as of a variation of the external FUV field. We\nfind it difficult to simultaneously model the observed 12CO and 13CO emission.\nThe 12CO and [CI] emission can be explained by a PDR model with a external FUV\nfield of 1-0.75 chi_0, but this model fails to reproduce the observed 13CO by a\nfactor of ~2. Adding PAHs to the chemical network increases the [CI] emission\nby 50% in our model but makes [CII] very faint. CO depletion only slightly\nreduces the 12CO and 13CO line intensity (by <10% and <20%, respectively).\nPredictions for the [CII] 2P_3/2-2P_1/2, [CI] 3P_2-3P_1 and 12CO J= 5-4 and 4-3\ntransitions are presented. This allows a test of our model with future\nobservations (APEX, NANTEN2, HERSCHEL, SOFIA).\n", "machine_text": "\n\nThe structure and evolution of the photon-dominated region (PDR) of Barnard 68 are investigated using a large suite of observations obtained with the Hubble Space Telescope. We find that the PDR has a complex and dynamic structure, with a bright rim and a series of bright knots along the inner edge. The PDR also shows a non-axisymmetric structure, with a bright bar-like feature along the west-west direction. We find that the PDR has a smoothly varying surface brightness, with a brightness distribution that is well described by a power law with a high power law index. The PDR has a total mass of 1.1 kpc $M_{\\rm gas}$, which is much larger than the half-light radius of 0.28 kpc. We show that a simple model in which the gas is treated as isothermal and homogenous can quantitatively reproduce the basic features of the PDR, but a more sophisticated model that takes into account the temperature distribution is needed to reproduce the complex structure of the inner edge. We also investigate the distribution of ionized gas in the PDR, and find that it is well described by a two-temperature model with a temperature ratio of 2.2, which is consistent with the predictions of simple theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Personalizing Image Search Results on Flickr. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1676, "human_text": "  The social media site Flickr allows users to upload their photos, annotate\nthem with tags, submit them to groups, and also to form social networks by\nadding other users as contacts. Flickr offers multiple ways of browsing or\nsearching it. One option is tag search, which returns all images tagged with a\nspecific keyword. If the keyword is ambiguous, e.g., ``beetle'' could mean an\ninsect or a car, tag search results will include many images that are not\nrelevant to the sense the user had in mind when executing the query. We claim\nthat users express their photography interests through the metadata they add in\nthe form of contacts and image annotations. We show how to exploit this\nmetadata to personalize search results for the user, thereby improving search\nperformance. First, we show that we can significantly improve search precision\nby filtering tag search results by user's contacts or a larger social network\nthat includes those contact's contacts. Secondly, we describe a probabilistic\nmodel that takes advantage of tag information to discover latent topics\ncontained in the search results. The users' interests can similarly be\ndescribed by the tags they used for annotating their images. The latent topics\nfound by the model are then used to personalize search results by finding\nimages on topics that are of interest to the user.\n", "machine_text": "\n\nPersonalizing Image Search Results on Flickr\n\nWe present an algorithm to personalize image search results on Flickr. We identify four factors that affect users' interaction with search results: visual features of images, textual features of captions and tags, the user's search history, and the social context of the user and the image. We then present a series of experiments to evaluate the impact of these factors on users' engagement with search results. Our experiments use a combination of controlled crowdsourced experiments on Amazon Mechanical Turk and analysis of user data from the Flickr search engine. We find that (1) there is no single dominant factor that improves engagement with search results; (2) personalized search results that take into account multiple factors can be significantly better than the non-personalized results; and (3) there exist \"best\" combinations of factors for different types of queries. We discuss the practical and theoretical implications of our work, and future research directions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Estimation of experimental data redundancy and related statistics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0162, "human_text": "  Redundancy of experimental data is the basic statistic from which the\ncomplexity of a natural phenomenon and the proper number of experiments needed\nfor its exploration can be estimated. The redundancy is expressed by the\nentropy of information pertaining to the probability density function of\nexperimental variables. Since the calculation of entropy is inconvenient due to\nintegration over a range of variables, an approximate expression for redundancy\nis derived that includes only a sum over the set of experimental data about\nthese variables. The approximation makes feasible an efficient estimation of\nthe redundancy of data along with the related experimental information and\ninformation cost function. From the experimental information the complexity of\nthe phenomenon can be simply estimated, while the proper number of experiments\nneeded for its exploration can be determined from the minimum of the cost\nfunction. The performance of the approximate estimation of these statistics is\ndemonstrated on two-dimensional normally distributed random data.\n", "machine_text": "\n\nMotivation\nWe present a new methodology for the estimation of the number of hidden factors in experimental data, based on the principles of information theory. Our approach is different from previous methods in three important aspects: (i) it is applicable to datasets of arbitrary size, (ii) it is not dependent on any specific model, and (iii) it provides a natural way to assess the amount of information in the data and to detect and quantify experimental noise.\nApplication to a genetic dataset\nWe demonstrate the efficacy of our new methodology by applying it to a real dataset of gene expression measurements in which we seek to uncover the true number of hidden factors that explain the observed variation in the data. Our analysis shows that the true number of factors is likely to be much smaller than the number of variables in the data, suggesting that a large proportion of the variation may be due to experimental noise. We show how our method can be used to detect and quantify this noise, and to identify the most informative features in the data.\nConclusion\nOur new methodology for the estimation of experimental data redundancy is broadly applicable to any type of data and any size dataset, and provides a natural way to assess the amount of information in the data and to detect and quantify experimental noise. We demonstrate the efficacy of our approach by applying it to a real dataset of gene expression measurements, and show that our method is able to identify the most informative features in the data and to detect and quantify experimental noise.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: VLBI observations of nineteen GHz-Peaked-Spectrum radio sources at 1.6\n  GHz. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.031, "human_text": "  Aims and Methods: We present the results of VLBI observations of nineteen\nGHz-Peaked-Spectrum (GPS) radio sources at 1.6 GHz. Of them, 15 sources are\nselected from the Parkes Half Jansky (PHJ) sample (Snellen 2002), 4 others are\nfrom our previous observation list. We aimed at imaging the structure of GPS\nsources, searching for Compact Symmetric Objects (CSOs) and studying the\nabsorption for the convex radio spectra of GPS sources.\n  Results: We obtained total intensity 1.6 GHz VLBI images of 17 sources for\nthe first time. Of them, 80% show mini-double-lobe radio structure, indicating\nthat they are CSOs or candidates, and their host AGNs could be edge-on to us.\nThis result suggests that there is a high incidence of mini double-lobe sources\n(or CSOs) in the PHJ sample. The sources J0323+0534, J1135-0021, J1352+0232,\nJ2058+0540, J2123-0112 and J2325-0344 with measured redshift, showing\ndouble-lobe structure with sizes of <1 kpc, are classified as CSOs. Three\nsources J1057+0012, J1600-0037 and J1753+2750 are considered as core-jet\nsources according to their morphologies and flux variability.\n", "machine_text": "\nWe present very long baseline interferometry (VLBI) observations of the nineteen GHz-Peaked-Spectrum ( nineteen GPS) radio sources at 1.6 GHz. We observed twenty-one of the thirty-nine known sources in the 1.6 GHz band, and detected twelve of them. We found that the GPS sources in the 1.6 GHz band are much less bright than in the 3.5 GHz band, but their spectral indices are, in general, flatter. We determined the angular sizes of the detected sources, and found that they are generally larger than those detected in the 3.5 GHz band. We estimated the thermal centroids of the sources, and compared the directions of the optical and radio centroids. We found that the optical and radio centroids are not coincident, but are offset by 6 \u00b1 1 arcsec on average. The offset does not show any correlation with the optical or radio brightness, or with the spectral index of the radio source. We also found that the fraction of the radio source's flux contributed by the thermal emission is 5-10%. We discuss the results in the framework of a model in which the GPS sources are the relics of a thermal filament, and the non-coincidence of the centroids is explained by the fact that the optical and radio filaments are not exactly parallel.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Intervening Metal Systems in GRB and QSO sight-lines: The Mgii and Civ\n  Question. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0706, "human_text": "  Prochter et al. 2006 recently found that the number density of strong\nintervening 0.5<z<2 MgII absorbers detected in gamma-ray burst (GRB) afterglow\nspectra is nearly 4 times larger than in QSO spectra. We have conducted a\nsimilar study using CIV absorbers. Our CIV sample, consisting of a total of 20\nsystems, is drawn from 3 high resolution and high to moderate S/N VLT/UVES\nspectra of 3 long-duration GRB afterglows, covering the redshift interval 1.6<\nz<3.1. The column density distribution and number density of this sample do not\nshow any statistical difference with the same quantities measured in QSO\nspectra. We discuss several possibilities for the discrepancy between CIV and\nMgII absorbers and conclude that a higher dust extinction in the MgII QSO\nsamples studied up to now would give the most straightforward solution.\nHowever, this effect is only important for the strong MgII absorbers.\nRegardless of the reasons for this discrepancy, this result confirms once more\nthat GRBs can be used to detect a side of the universe that was unknown before,\nnot necessarily connected with GRBs themselves, providing an alternative and\nfundamental investigative tool of the cosmic evolution of the universe.\n", "machine_text": "\n\nWe present a simple method to estimate the galaxy number density in the disk of our Milky Way by counting galaxies in an annulus in the direction of the Galactic Rim. Our galaxy census is based on a high signal-to-noise ratio galaxy redshift survey performed with the 6.5 m Magellan Telescopes and covers the redshift range 0.155 < z_gal < 1.33. We find a number density of 2.7 \u00b1 0.9 galaxies per square degree, which translates into an intergalactic volume filling factor of \u03b7_V = 1.9 \u00b1 1.4%. This result is in good agreement with previous estimates based on the 2 Micron All-Sky Survey and with a semi-analytic model of galaxy formation. Our high signal-to-noise ratio data also allow us to study the distribution of galaxies in the Galactic halo. We find that the observed distribution is consistent with a galactic fountain model with a radial galaxy number density that increases smoothly with distance from the Galactic disk before declining abruptly at large distances. The radial galaxy number density is well described by a power law with an index of -1.3 \u00b1 0.2. We have searched for strong galaxy-galaxy lensing in the same survey data. We find three candidates, but none of them could be confirmed by further analysis. We also present a new method to estimate the distance to the Galactic Center based on the position of the sunlit side of the disk. We find that this method produces a distance to the Galactic Center that is in good agreement with other independent measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum spin liquid states in the two dimensional kagome\n  antiferromagnets, ZnxCu4-x(OD)6Cl2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2279, "human_text": "  A three-dimensional system of interacting spins typically develops static\nlong-range order when it is cooled. If the spins are quantum (S = 1/2),\nhowever, novel quantum paramagnetic states may appear. The most highly sought\nstate among them is the resonating valence bond (RVB) state in which every pair\nof neighboring quantum spins form entangled spin singlets (valence bonds) and\nthe singlets are quantum mechanically resonating amongst all the possible\nhighly degenerate pairing states. Here we provide experimental evidence for\nsuch quantum paramagnetic states existing in frustrated antiferromagnets,\nZnxCu4-x(OD)6Cl2, where the S = 1/2 magnetic Cu2+ moments form layers of a\ntwo-dimensional kagome lattice. We find that in Cu4(OD)6Cl2, where distorted\nkagome planes are weakly coupled to each other, a dispersionless excitation\nmode appears in the magnetic excitation spectrum below ~ 20 K, whose\ncharacteristics resemble those of quantum spin singlets in a solid state, known\nas a valence bond solid (VBS), that breaks translational symmetry. Doping\nnonmagnetic Zn2+ ions reduces the distortion of the kagome lattice, and weakens\nthe interplane coupling but also dilutes the magnetic occupancy of the kagome\nlattice. The VBS state is suppressed and for ZnCu3(OD)6Cl2 where the kagome\nplanes are undistorted and 90% occupied by the Cu2+ ions, the low energy spin\nfluctuations in the spin liquid phase become featureless.\n", "machine_text": "\n\nWe have performed a systematic study of the magnetic properties of the two-dimensional (2D) Kagome antiferromagnets, ZnxCu4-x(OD)6Cl2 (x = 0.4, 0.6, 0.8, and 1). The 0.4 < x < 0.6 compounds are the first 2D antiferromagnets that host quantum spin liquid (QSL) states, which are robust against large magnetic fields and temperatures. The 0.4 < x < 0.6 compounds are also the first 2D antiferromagnets that host QSL states with Ising-like (Fg = 2) and dimer-like (Fg = 1) interactions. We have identified three types of QSL states in the 0.4 < x < 0.6 compounds: a thermodynamically stable state in the absence of a magnetic field, a state that is induced by a magnetic field and is thermodynamically stable when the field is removed, and a state that is induced by a magnetic field but is not thermodynamically stable when the field is removed. We have also investigated the effect of a large magnetic field on the QSL states by changing the x value in the 0.4 < x < 0.6 compounds. Our results suggest that the x value has a strong effect on the types of QSL states that are present in the 0.4 < x < 0.6 compounds. We have also performed a systematic study of the magnetic properties of the 2D Kagome antiferromagnet, Zn0.6Cu0.4(OD)6Cl2, in order to determine the effect of a large magnetic field on the QSL states. Our results suggest that the QSL states in this compound are less stable than the QSL states in the 0.4 < x < 0.6 compounds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Extraction of Freshwater and Energy from Atmosphere. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2571, "human_text": "  Author offers and researches a new, cheap method for the extraction of\nfreshwater from the Earth atmosphere. The suggected method is fundamentally\ndictinct from all existing methods that extract freshwater from air. All other\nindustrial methods extract water from a saline water source (in most cases from\nseawater). This new method may be used at any point in the Earth except Polar\nZones. It does not require long-distance freshwater transportation. If seawater\nis not utilized for increasing its productivity, this inexpensive new method is\nvery environment-friendly. The author method has two working versions: (1) the\nfirst variant the warm (hot) atmospheric air is lifted by the inflatable tube\nin a high altitude and atmospheric steam is condenced into freswater: (2) in\nthe second version, the warm air is pumped 20-30 meters under the sea-surface.\nIn the first version, wind and solar heating of air are used for causing air\nflow. In version (2) wind and propeller are used for causing air movment.\n  The first method does not need energy, the second needs a small amount.\nMoreover, in variant (1) the freshwater has a high pressure (>30 or more atm.)\nand can be used for production of energy such as electricity and in that way\nthe freshwater cost is lower. For increasing the productivity the seawater is\ninjected into air and solar air heater may be used. The solar air heater\nproduces a huge amount of electricity as a very powerful electricity generation\nplant. The offered electricity installation in 100 - 200 times cheaper than any\ncommon electric plant of equivalent output.\n  Key words: Extraction freshwater, method of getting freshwater, receiving\nenergy from atmosphere, powerful renewal electric plant.\n", "machine_text": "\n\nTitle: Extraction of Freshwater and Energy from Atmosphere\n\nMotivation:\n\nThe motivation of this work is to explore the possibility of extracting freshwater and energy from the atmosphere. The increasing demand for freshwater and energy, along with the limitations of traditional resources, have made it necessary to explore alternative sources.\n\nKey ideas and methodology:\n\nThe key idea of this work is to use a combination of solar energy and atmospheric water to produce freshwater and energy. The method involves using solar energy to power a water desalination process, which produces freshwater and salt. The salt is then used as a fuel to produce energy, which can be used to power the desalination process.\n\nThe methodology for this work involves the design and construction of a solar-powered desalination system, which uses salt as a fuel to produce energy. The system is designed to be efficient and cost-effective, and to produce a high yield of freshwater and energy.\n\nResults obtained:\n\nThe results of this work show that it is possible to extract freshwater and energy from the atmosphere using a combination of solar energy and atmospheric water. The system designed and constructed for this work was found to be effective in producing freshwater and energy, and to be efficient and cost-effective.\n\nProblem this work attempts to solve:\n\nThe problem this work attempts to solve is the increasing demand for freshwater and energy, and the limitations of traditional resources.\n\nPractical or theoretical applications from findings or implications for future research:\n\nThe practical applications of this work include the potential for the system designed and constructed for this work to be used to produce freshwater and energy on a large scale. The theoretical applications of this work include the potential for the use of atmospheric water as a renewable resource for the production of freshwater and energy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Millimeter dust continuum emission unveiling the true mass of giant\n  molecular clouds in the Small Magellanic Cloud. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3257, "human_text": "  CO observations have been so far the best way to trace molecular gas in\nexternal galaxies, but at low metallicity the gas mass deduced could be largely\nunderestimated. At present, the kinematic information of CO data cubes are used\nto estimate virial masses and trace the total mass of the molecular clouds.\nMillimeter dust emission can also be used as a dense gas tracer and could\nunveil H2 envelopes lacking CO. These different tracers must be compared in\ndifferent environments. This study compares virial masses to masses deduced\nfrom millimeter emission, in two GMC samples: the local molecular clouds in our\nGalaxy and their equivalents in the Small Magellanic Cloud (SMC), one of the\nnearest low metallicity dwarf galaxy. In our Galaxy, mass estimates deduced\nfrom millimeter emission are consistent with masses deduced from gamma ray\nanalysis and trace the total mass of the clouds. Virial masses are\nsystematically larger (twice on average) than mass estimates from millimeter\ndust emission. This difference decreases toward high masses and has already\nbeen reported in previous studies. In the SMC however, molecular cloud masses\ndeduced from SIMBA millimeter observations are systematically higher (twice on\naverage for conservative values of the dust to gas ratio and dust emissivity)\nthan the virial masses from SEST CO observations. The observed excess can not\nbe accounted for by any plausible change of dust properties. Taking a general\nform for the virial theorem, we show that a magnetic field strength of ~15\nmicro Gauss in SMC clouds could provide additional support to the clouds and\nexplain the difference observed. Masses of SMC molecular clouds have therefore\nbeen underestimated so far. Magnetic pressure may contribute significantly to\ntheir support.\n", "machine_text": "\nWe present the results of a far-infrared dust continuum survey of the Small Magellanic Cloud (SMC), aimed at assessing the relative masses of its giant molecular clouds (GMCs) by means of the dust-to-gas ratio. Our analysis benefits from the unique combination of high angular resolution and sensitivity provided by single-dish telescopes operating at millimeter wavelengths. We found that the dust-to-gas ratios of the SMC's main GMCs are, on average, 5-10% of the values found in the Milky Way's Galactic globular clusters. This result challenges the traditional assumption that these clouds are dominated by molecular hydrogen and suggests that a significant fraction of the gas in these clouds is in the form of dust. We discuss this result in the context of recent theoretical work that suggests a strong correlation between the mass of a molecular cloud and the rate at which it forms stars. Our findings suggest that the physical conditions that regulate the conversion of gas to dust may have a strong influence on the star formation rate in molecular clouds, potentially explaining the wide range of star formation rates observed in galactic and extragalactic molecular clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Determination of Low-Energy Parameters of Neutron--Proton Scattering on\n  the Basis of Modern Experimental Data from Partial-Wave Analyses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1024, "human_text": "  The triplet and singlet low-energy parameters in the effective-range\nexpansion for neutron--proton scattering are determined by using the latest\nexperimental data on respective phase shifts from the SAID nucleon--nucleon\ndatabase. The results differ markedly from the analogous parameters obtained on\nthe basis of the phase shifts of the Nijmegen group and contradict the\nparameter values that are presently used as experimental ones. The values found\nwith the aid of the phase shifts from the SAID nucleon--nucleon database for\nthe total cross section for the scattering of zero-energy neutrons by protons,\n$\\sigma_{0}=20.426 $b, and the neutron--proton coherent scattering length,\n$f=-3.755 $fm, agree perfectly with the experimental cross-section values\nobtained by Houk, $\\sigma_{0}=20.436\\pm 0.023 $b, and experimental\nscattering-length values obtained by Houk and Wilson, $f=-3.756\\pm 0.009 $fm,\nbut they contradict cross-section values of $\\sigma_{0}=20.491\\pm 0.014 $b\naccording to Dilg and coherent-scattering-length values of $f=-3.7409\\pm 0.0011\n$fm according to Koester and Nistler.\n", "machine_text": "\nWe have developed a new method for the determination of low-energy parameters of neutron\u2013proton (n\u2013p) scattering on the basis of modern experimental data from partial-wave analyses. The main idea of the method is to use the information on the n\u2013p scattering in the partial-wave regime to determine the width of the dominant partial wave, the so-called partial-wave width (PWW). We show that, in the framework of the Einstein\u2013Bohr theory, the PWW is related to the width of the p-wave resonance in the scattering amplitude. Therefore, the PWW can be determined from the analysis of the experimental data on the p-wave intensity in the partial-wave regime. We demonstrate that this method does not require the assumption of a small parameter, which describes the p-wave contribution to the total cross section in the partial-wave regime. Hence, our method can be used to determine the PWW in the case of a large p-wave contribution to the total cross section. We show that our method is equivalent to the common method based on the analysis of the structure functions in the partial-wave regime. We also discuss the limitations of the method and the cases in which our method can give a reliable result, while the method based on the structure functions can fail.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Towards an Explicit Model of D-brane Inflation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.036, "human_text": "  We present a detailed analysis of an explicit model of warped D-brane\ninflation, incorporating the effects of moduli stabilization. We consider the\npotential for D3-brane motion in a warped conifold background that includes\nfluxes and holomorphically-embedded D7-branes involved in moduli stabilization.\nAlthough the D7-branes significantly modify the inflaton potential, they do not\ncorrect the quadratic term in the potential, and hence do not cause a uniform\nchange in the slow-roll parameter eta. Nevertheless, we present a simple\nexample based on the Kuperstein embedding of D7-branes, z_1=constant, in which\nthe potential can be fine-tuned to be sufficiently flat for inflation. To\nderive this result, it is essential to incorporate the fact that the\ncompactification volume changes slightly as the D3-brane moves. We stress that\nthe compactification geometry dictates certain relationships among the\nparameters in the inflaton Lagrangian, and these microscopic constraints impose\nsevere restrictions on the space of possible models. We note that the shape of\nthe final inflaton potential differs from projections given in earlier studies:\nin configurations where inflation occurs, it does so near an inflection point.\nFinally, we comment on the difficulty of making precise cosmological\npredictions in this scenario. This is the companion paper to arXiv:0705.3837.\n", "machine_text": "\nWe propose a model of D-brane inflation based on the idea that a D-brane is a boundary of a \"membrane\" that has an interior bulk region, and the bulk region \"warps\" in a manner that is controlled by the three-form curvature. This allows us to formulate the model in terms of an explicit bulk function that describes the warping of the bulk region. This formulation has several advantages. First, the bulk function describes a single, continuous, and explicit function, which can be more intuitive and more tractable analytically than the convention of treating the bulk as a disjoint sum of different bulk regions. Second, this approach is better suited for exploring the connection between D-brane inflation and higher-dimensional bulk inflation. In particular, we show that the bulk function has the structure of a three-form, which relates the D-brane inflation to higher-dimensional bulk inflation. Third, we show that the bulk function is related to the geometry of a D-brane particle, and in particular, to its four- momentum, which allows us to formulate the bulk function as the four-momentum of a D-brane particle. This provides a framework for incorporating the dynamics of D-brane particles into the model. We explore several aspects of the model, including the behavior of the bulk function, the evolution of the D-brane particles, and the interactions of the D-brane particles with each other and with the bulk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 3D Radiative Hydrodynamics for Disk Stability Simulations: A Proposed\n  Testing Standard and New Results. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2532, "human_text": "  Recent three-dimensional radiative hydrodynamics simulations of\nprotoplanetary disks report disparate disk behaviors, and these differences\ninvolve the importance of convection to disk cooling, the dependence of disk\ncooling on metallicity, and the stability of disks against fragmentation and\nclump formation. To guarantee trustworthy results, a radiative physics\nalgorithm must demonstrate the capability to handle both the high and low\noptical depth regimes. We develop a test suite that can be used to demonstrate\nan algorithm's ability to relax to known analytic flux and temperature\ndistributions, to follow a contracting slab, and to inhibit or permit\nconvection appropriately. We then show that the radiative algorithm employed by\nMeji\\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al.\n(2006) and Cai et al. (2007, in prep.) pass these tests with reasonable\naccuracy. In addition, we discuss a new algorithm that couples flux-limited\ndiffusion with vertical rays, we apply the test suite, and we discuss the\nresults of evolving the Boley et al. (2006) disk with this new routine.\nAlthough the outcome is significantly different in detail with the new\nalgorithm, we obtain the same qualitative answers. Our disk does not cool fast\ndue to convection, and it is stable to fragmentation. We find an effective\n$\\alpha\\approx 10^{-2}$. In addition, transport is dominated by low-order\nmodes.\n", "machine_text": "\n\nWe present 3D radiative hydrodynamics codes for optically thick\nenvironments developed in two independent programming languages,\nJameson (JAM) and Fortran (FHR), suitable for numerical studies of\nstellar disk stability. We focus on the physical basis and numerical\nimplementations of the radiative transfer and hydrodynamic solvers in\nboth codes. We propose a standard testing protocol which we use to\ncompare the two codes with a view to checking the numerical stability\nand accuracy of the radiative transfer solutions in the presence of\nnon-negligible velocity fields, in both simple cases and more\nrealistic scenarios. We discuss the impact of different physical\n parametrizations on the numerical solutions, with a particular view\nto the stability of axisymmetric turbulence. We present new results\nin the form of global scalings for the temperature and density\nfluctuations in axisymmetric turbulence, which we compare with\nprevious 1D results. We find that the inclusion of a non-negligible\nradiative transfer, in addition to the hydrodynamic contributions,\nsignificantly alters the shape of the fluctuation spectrum, with a\nstantial increase in the variance of the temperature field, while\nthe density variance is only slightly increased.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamics of interacting Brownian particles: a diagrammatic formulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3645, "human_text": "  We present a diagrammatic formulation of a theory for the time dependence of\ndensity fluctuations in equilibrium systems of interacting Brownian particles.\nTo facilitate derivation of the diagrammatic expansion we introduce a basis\nthat consists of orthogonalized many-particle density fluctuations. We obtain\nan exact hierarchy of equations of motion for time-dependent correlations of\northogonalized density fluctuations. To simplify this hierarchy we neglect\ncontributions to the vertices from higher-order cluster expansion terms. An\niterative solution of the resulting equations can be represented by diagrams\nwith three and four-leg vertices. We analyze the structure of the diagrammatic\nseries for the time-dependent density correlation function and obtain a\ndiagrammatic interpretation of reducible and irreducible memory functions. The\none-loop self-consistent approximation for the latter function coincides with\nmode-coupling approximation for Brownian systems that was derived previously\nusing a projection operator approach.\n", "machine_text": "\n\nWe consider the dynamics of interacting Brownian particles in a viscous fluid, with an external driving force that may also be a Brownian motion. We develop a diagrammatic formulation of the problem in terms of a single master variable related to the average velocity of the particles. We then solve this formulation to obtain an analytical expression for the evolution of the master variable, which can be regarded as a 'hydrodynamic limit' of the dynamics of the system. The results obtained show that this formulation is capable of describing several different aspects of the dynamics of the system, and has several interesting and important applications. In particular, we show that a generalized Fisher information metric can be constructed from the solution of the master equation, and that this metric has a simple form in the limit of small Reynolds number. We also show that the master variable has a simple and general expression in terms of a kinetic energy, which is a generalization of the usual kinetic energy of the particles. This allows us to derive a generalized dynamics for the system, which includes a term that arises from the interaction between the particles, and which is an analog of the classical correlation function. We analyze this term and show that it has several interesting and important properties, which are related to the behavior of the system as a whole, rather than to the behavior of individual particles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relaxation of a dewetting contact line Part 1: A full-scale hydrodynamic\n  calculation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3576, "human_text": "  The relaxation of a dewetting contact line is investigated theoretically in\nthe so-called \"Landau-Levich\" geometry in which a vertical solid plate is\nwithdrawn from a bath of partially wetting liquid. The study is performed in\nthe framework of lubrication theory, in which the hydrodynamics is resolved at\nall length scales (from molecular to macroscopic). We investigate the\nbifurcation diagram for unperturbed contact lines, which turns out to be more\ncomplex than expected from simplified 'quasi-static' theories based upon an\napparent contact angle. Linear stability analysis reveals that below the\ncritical capillary number of entrainment, Ca_c, the contact line is linearly\nstable at all wavenumbers. Away from the critical point the dispersion relation\nhas an asymptotic behaviour sigma~|q| and compares well to a quasi-static\napproach. Approaching Ca_c, however, a different mechanism takes over and the\ndispersion evolves from |q| to the more common q^2. These findings imply that\ncontact lines can not be treated as universal objects governed by some\neffective law for the macroscopic contact angle, but viscous effects have to be\ntreated explicitly.\n", "machine_text": "\nWe present a full-scale calculation of the hydrodynamic interactions in a dewetting contact line. The calculation is based on a three-dimensional (3D) representation of the fluid flow in the contact line, in contrast to the conventional two-dimensional (2D) description. We solve the 3D flow equation with the 3D contact line interface in a vertically averaged system. The resulting equation is a quasilinear elliptic equation with a singular boundary condition on the contact line. We solve this equation by an alternating direction implicit (ADI) method. To validate the calculation, we compare the results with those obtained from a 2D calculation. We find that the 3D calculation predicts a contact angle smaller than the one obtained from the 2D calculation. The difference between the 3D and 2D predictions increases with the ratio of the wetting layer thickness to the contact radius. Our 3D calculation also predicts a dewetting contact line velocity that is smaller than the one obtained from the 2D calculation. We discuss these differences and their physical origins.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Jet-disturbed molecular gas near the Seyfert 2 nucleus in M51. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0947, "human_text": "  Previous molecular gas observations at arcsecond-scale resolution of the\nSeyfert 2 galaxy M51 suggest the presence of a dense circumnuclear rotating\ndisk, which may be the reservoir for fueling the active nucleus and obscures it\nfrom direct view in the optical. However, our recent interferometric CO(3-2)\nobservations show a hint of a velocity gradient perpendicular to the rotating\ndisk, which suggests a more complex structure than previously thought. To image\nthe putative circumnuclear molecular gas disk at sub-arcsecond resolution to\nbetter understand both the spatial distribution and kinematics of the molecular\ngas. We carried out CO(2-1) and CO(1-0) line observations of the nuclear region\nof M51 with the new A configuration of the IRAM Plateau de Bure Interferometer,\nyielding a spatial resolution lower than 15 pc. The high resolution images show\nno clear evidence of a disk, aligned nearly east-west and perpendicular to the\nradio jet axis, as suggested by previous observations, but show two separate\nfeatures located on the eastern and western sides of the nucleus. The western\nfeature shows an elongated structure along the jet and a good velocity\ncorrespondence with optical emission lines associated with the jet, suggesting\nthat this feature is a jet-entrained gas. The eastern feature is elongated\nnearly east-west ending around the nucleus. A velocity gradient appears in the\nsame direction with increasingly blueshifted velocities near the nucleus. This\nvelocity gradient is in the opposite sense of that previously inferred for the\nputative circumnuclear disk. Possible explanations for the observed molecular\ngas distribution and kinematics are that a rotating gas disk disturbed by the\njet, gas streaming toward the nucleus, or a ring with another smaller counter-\nor Keplarian-rotating gas disk inside.\n", "machine_text": "\n\nWe present multiwavelength observations of the jet-disturbed molecular gas near the Seyfert 2 nucleus in M51. We combine far-infrared data from the Herschel Space Telescope with submillimeter data from the SCUBA-2 camera on the James Clerk Maxwell Telescope to reveal the distribution of molecular gas, in order to better understand the relationship between the nuclear starburst and the infalling molecular clouds. We find that the bulk of the molecular gas is not contained within the galactic plane, but is instead distributed in a large, off-plane region. The gas in this region is not gravitationally bound to the galaxy and is potentially available to be accreted by the M51 nucleus. We further find that this gas is heated by a non-nuclear source, most likely an oblique jet arising from the nuclear starburst. The gas is cooled as it flows towards the plane, forming a wake behind the jet. We explain this cooling in terms of a simple model in which the gas is cooled by the expanding bubble of the heated gas, similar to the way in which the density and temperature of a gas is reduced when it is inflated inside a balloon. This model provides a natural explanation for the cooling of the gas and the lack of strong far-infrared emission from the gas in the plane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Glimpsing through the high redshift neutral hydrogen fog. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1053, "human_text": "  We analyze the transmitted flux in a sample of 17 QSOs spectra at\n5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral\nhydrogen fraction, xHI, at z~6. We study separately the narrow transmission\nwindows (peaks) and the wide dark portions (gaps) in the observed absorption\nspectra. By comparing the statistics of these spectral features with Lyalpha\nforest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at\nz=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The\nfrequency and physical sizes of the peaks imply an origin in cosmic underdense\nregions and/or in HII regions around faint quasars or galaxies. In one case\n(the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along\nthe LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density\nis explained by the first-ever detected transverse proximity effect in the HI\nLyalpha forest; this indicates that at least some peaks result from a locally\nenhanced radiation field. We then obtain a strong lower limit on the foreground\nQSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be\nsystematically larger than the simulated ones. Reasons for such discrepancy\nmight reside either in the photoionization equilibrium assumption or in\nradiative transfer effects.\n", "machine_text": "\nWe present a study of a large sample of galaxies in the COSMOS field, selected to be nearly invisible in the observed optical and NIR bands, with the aim of gleaning information about the properties of the galaxies and the intergalactic medium in which they are embedded. We find that the galaxies in the sample are, on average, twice as massive as galaxies in the local volume, but have a luminosity and star formation rate typical of galaxies in the local volume. The observed distribution in redshift space is well described by a model in which the volume density of the neutral intergalactic medium varies inversely with the square of the redshift. This indicates that the high-redshift universe is significantly opaque to hydrogen radiation. We show that this is consistent with a model in which the intergalactic medium consists of a small number of very dense regions, embedded in a large volume of relatively empty space, and suggest that the high-redshift intergalactic medium may consist of a small number of relatively massive filaments. We discuss the implications of this finding for galaxy formation at high redshift.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Profinite complexes of curves, their automorphisms and anabelian\n  properties of moduli stacks of curves. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0859, "human_text": "  Let ${\\cal M}_{g,[n]}$, for $2g-2+n>0$, be the D-M moduli stack of smooth\ncurves of genus $g$ labeled by $n$ unordered distinct points. The main result\nof the paper is that a finite, connected \\'etale cover ${\\cal M}^\\l$ of ${\\cal\nM}_{g,[n]}$, defined over a sub-$p$-adic field $k$, is \"almost\" anabelian in\nthe sense conjectured by Grothendieck for curves and their moduli spaces.\n  The precise result is the following. Let $\\pi_1({\\cal M}^\\l_{\\ol{k}})$ be the\ngeometric algebraic fundamental group of ${\\cal M}^\\l$ and let\n${Out}^*(\\pi_1({\\cal M}^\\l_{\\ol{k}}))$ be the group of its exterior\nautomorphisms which preserve the conjugacy classes of elements corresponding to\nsimple loops around the Deligne-Mumford boundary of ${\\cal M}^\\l$ (this is the\n\"$\\ast$-condition\" motivating the \"almost\" above). Let us denote by\n${Out}^*_{G_k}(\\pi_1({\\cal M}^\\l_{\\ol{k}}))$ the subgroup consisting of\nelements which commute with the natural action of the absolute Galois group\n$G_k$ of $k$. Let us assume, moreover, that the generic point of the D-M stack\n${\\cal M}^\\l$ has a trivial automorphisms group. Then, there is a natural\nisomorphism: $${Aut}_k({\\cal M}^\\l)\\cong{Out}^*_{G_k}(\\pi_1({\\cal\nM}^\\l_{\\ol{k}})).$$ This partially extends to moduli spaces of curves the\nanabelian properties proved by Mochizuki for hyperbolic curves over\nsub-$p$-adic fields.\n", "machine_text": "\n\nWe give a survey of the results on profinite complexes of curves, their automorphisms, and anabelian properties of moduli stacks of curves, with an eye towards applications to the study of higher-level stacks. \n\nThe motivation for this work is the geometric and topological properties of moduli stacks of curves in the projective plane, which were extensively studied by S. Abu-Shammala, A. Blumental, P. Grothendieck, J. Kristler, and M. Kac. We focus on the tools and methods used to study these properties. In particular, we present a description of the category of profinite complexes of curves in terms of marked pleats on an affine plane-curve, and show that it is equivalent to the category of profinite complexes of constructive sheaves on a curve. We also show that the category of profinite complexes of constructive sheaves on a curve is isomorphic to the category of profinite complexes of constructive sheaves on a complete interlocked domain. \n\nAs an application of these results, we show that the anabelian properties of moduli stacks of curves are closely related to the anabelian properties of constructive sheaves on a curve. In particular, we show that the category of constructive sheaves on a curve is an abelian category, and that the tensor product of constructive sheaves on a curve is isomorphic to the category of constructive sheaves on a complete interlocked domain. \n\nWe also show that the category of constructive sheaves on a curve is a full subcategory of the category of mixed modules for a relative Levi-Civita stereotype, and that the tensor product of constructive sheaves on a curve is isomorphic to the full subcategory of mixed modules for a relative Levi-Civita stereotype generated by constructive sheaves. \n\nFinally, we show that the category of profinite complexes of constructive sheaves on a curve is equivalent to the category of profinite complexes of mixed modules for a relative Levi-Civita stereotype.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Neutrino Decays and Neutrino Electron Elastic Scattering in Unparticle\n  Physics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0302, "human_text": "  Following Georgi's unparticle scheme, we examine the effective couplings\nbetween neutrinos and unparticle operators. As an immediate consequence,\nneutrinos become unstable and can decay into the unparticle stuff. Assuming the\ndimension transmutation scale is around $\\Lambda^{}_{\\cal U} \\sim 1 ~{\\rm\nTeV}$, we implement the cosmological limit on the neutrino lifetime to\nconstrain the neutrino-unparticle couplings for different scaling dimensions\n$d$. In addition, provided that the electron-unparticle coupling is restricted\ndue to the precise measurement of the anomalous magnetic moment of electron, we\ncalculate the unparticle contribution to the neutrino-electron elastic\nscattering. It is more important to jointly deal with the couplings of the\nunparticle to the standard model particles rather than separately. Taking into\naccount both electron- and neutrino-unparticle couplings, we find that the\nscaling dimension of the scalar unparticle should lie in the narrow range $1 <\nd < 2$ by requiring the observables to be physically meaningful. However, there\nis no consistent range of $d$ for the vector unparticle operator.\n", "machine_text": "\nWe give a microscopic derivation of theosaurus elastic scattering and neutrino decay in the framework of unparticle physics. The lorentz structure of the\u521d journeys is derived from the correlation functions of theAfrican Symposium structure. TheStudies elastic scattering and neutrino decay are described by the backward Matrix elements of the symposium Lorentz structures. We obtained the Diaries elastic scattering and neutrino decay equations in the framework of unparticle physics, and the corresponding flavors and the Speaker Sudra sectors are also obtained. Thenew elastic scattering and neutrino decay equations are more complicated than thestringy ones. We have solved theTransportation elastic scattering and neutrino decay equations in the framework of unparticle physics. The Transport literature elastic scattering and neutrino decay rates are obtained. The Transportelastic scattering and neutrino decay equations are solved in the framework of unparticle physics. The new elastic scattering and neutrino decay rates are obtained and compared with the stringy ones.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy Density-Flux Correlations in an Unusual Quantum State and in the\n  Vacuum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.197, "human_text": "  In this paper we consider the question of the degree to which negative and\npositive energy are intertwined. We examine in more detail a previously studied\nquantum state of the massless minimally coupled scalar field, which we call a\n``Helfer state''. This is a state in which the energy density can be made\narbitrarily negative over an arbitrarily large region of space, but only at one\ninstant in time. In the Helfer state, the negative energy density is\naccompanied by rapidly time-varying energy fluxes. It is the latter feature\nwhich allows the quantum inequalities, bounds which restrict the magnitude and\nduration of negative energy, to hold for this class of states. An observer who\ninitially passes through the negative energy region will quickly encounter\nfluxes of positive energy which subsequently enter the region. We examine in\ndetail the correlation between the energy density and flux in the Helfer state\nin terms of their expectation values. We then study the correlation function\nbetween energy density and flux in the Minkowski vacuum state, for a massless\nminimally coupled scalar field in both two and four dimensions. In this latter\nanalysis we examine correlation functions rather than expectation values.\nRemarkably, we see qualitatively similar behavior to that in the Helfer state.\nMore specifically, an initial negative energy vacuum fluctuation in some region\nof space is correlated with a subsequent flux fluctuation of positive energy\ninto the region. We speculate that the mechanism which ensures that the quantum\ninequalities hold in the Helfer state, as well as in other quantum states\nassociated with negative energy, is, at least in some sense, already\n``encoded'' in the fluctuations of the vacuum.\n", "machine_text": "\nWe present a quantum-optical scheme for generating a two-mode squeezed vacuum state with a prescribed energy density in one of the two modes. The scheme relies on a cross-gain modulation between a squeezed state of one color and a vacuum state of another color in a parametric amplifier. This approach is general and can be applied to any combination of frequencies for which a parametric amplifier with suitable nonlineity is available. We analyze the scheme in detail for the case of a yellow-green laser (frequency-doubled neodymium-yttrium-aluminium-garnet laser) and a red laser (HeNe laser). In this case, the cross-gain modulation is achieved by means of a Michelson interferometer with a Mach-Zehnder interferometer in one arm. We present a simple and general formula for the efficiency of the scheme as a function of the pump power and the interferometric settings. The efficiency can be made large by tuning the Michelson interferometer to obtain constructive interference in the parametric amplifier arm that contains the squeezed state. We also derive a simple formula for the energy flux in one of the two modes of the produced squeezed vacuum state. We analyze the formula and discuss the regime of parameter values in which the energy flux is finite. We finally present a simple formula for the energy density-flux product in the aforementioned regime. We show that this formula results in a unique value for the energy density-flux product in the squeezed vacuum state, which differs from the corresponding value in a classical vacuum state. We discuss possible physical meanings of this difference and its implications for the statistical properties of the vacuum state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is there Evidence for a Hubble bubble? The Nature of Type Ia Supernova\n  Colors and Dust in External Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0367, "human_text": "  We examine recent evidence from the luminosity-redshift relation of Type Ia\nSupernovae (SNe Ia) for the $\\sim 3 \\sigma$ detection of a ``Hubble bubble'' --\na departure of the local value of the Hubble constant from its globally\naveraged value \\citep{Jha:07}. By comparing the MLCS2k2 fits used in that study\nto the results from other light-curve fitters applied to the same data, we\ndemonstrate that this is related to the interpretation of SN color excesses\n(after correction for a light-curve shape-color relation) and the presence of a\ncolor gradient across the local sample. If the slope of the linear relation\n($\\beta$) between SN color excess and luminosity is fit empirically, then the\nbubble disappears. If, on the other hand, the color excess arises purely from\nMilky Way-like dust, then SN data clearly favors a Hubble bubble. We\ndemonstrate that SN data give $\\beta \\simeq 2$, instead of the $\\beta \\simeq 4$\none would expect from purely Milky-Way-like dust. This suggests that either SN\nintrinsic colors are more complicated than can be described with a single\nlight-curve shape parameter, or that dust around SN is unusual. Disentangling\nthese possibilities is both a challenge and an opportunity for large-survey SN\nIa cosmology.\n", "machine_text": "\nWe present a method for identifying and characterizing the regions surrounding galaxies which are responsible for the observed large-scale flows of galaxies in the local volume. We find a good agreement between the regions identified as responsible for the large-scale flows and those found to contain a large number of galaxies with colors similar to those of galaxies in the local volume. In addition, we find that the surface density of these regions increases in a way that is consistent with the observed large-scale flows. We also find that the local volume contains a large number of regions with high surface density and with colors similar to those of galaxies in the local volume, but that it does not contain regions with low surface density and with colors similar to those of galaxies in the local volume. This is consistent with the hypothesis that the local volume is contained within a large-scale structure, and that the large-scale flows observed in the local volume are due to the infall of matter from regions outside the local volume. We discuss several implications of our results for theories of structure formation and for the understanding of the large-scale structure of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantification of discreteness effects in cosmological N-body\n  simulations: II. Evolution up to shell crossing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3697, "human_text": "  We apply a recently developed perturbative formalism which describes the\nevolution under their self-gravity of particles displaced from a perfect\nlattice to quantify precisely, up to shell crossing, the effects of\ndiscreteness in dissipationless cosmological N-body simulations. We give simple\nexpressions, explicitly dependent on the particle density, for the evolution of\npower in each mode as a function of red-shift. For typical starting red-shifts\nthe effect of finite particle number is to {\\it slow down} slightly the growth\nof power compared to that in the fluid limit (e.g. by about ten percent at half\nthe Nyquist frequency), and to induce also dispersion in the growth as a\nfunction of direction at a comparable level. In the limit that the initial\nred-shift tends to infinity, at fixed particle density, the evolution in fact\ndiverges from that in the fluid limit (described by the Zeldovich\napproximation). Contrary to widely held belief, this means that a simulation\nstarted at a red-shift much higher than the red-shift of shell crossing\nactually gives a worse, rather than a better, result. We also study how these\neffects are modified when there is a small-scale regularization of the\ngravitational force. We show that such a smoothing may reduce the anisotropy of\nthe discreteness effects, but it then {\\it increases} their average effect.\nThis behaviour illustrates the fact that the discreteness effects described\nhere are distinct from those usually considered in this context, due to\ntwo-body collisions. Indeed the characteristic time for divergence from the\ncollisionless limit is proportional to $N^{2/3}$, rather than $N/ \\log N$ in\nthe latter case.\n", "machine_text": "\nWe quantify the effects of discreteness in N-body simulations of the formation of dark matter haloes in a universe that evolves up to the formation of the first galaxy cluster. We consider a standard toy model of the evolution of the universe, with a parameter that allows us to tune the effects of discreteness. We vary this parameter to study the transition from a discrete to a continuous description of the evolution of the universe. We find that, in the limit of a small parameter, the discrete evolution is equivalent to the continuous one, apart from a contribution that we attribute to the particle horizon. We quantify this contribution and find that it is small for the volumes considered in the toy model. Therefore, we conclude that the discrete evolution of the matter distribution is not affected by the particle horizon, provided that the volume is large enough. We also show that the formation of structure is only slightly affected by the discreteness of the evolution, except for the first generations of haloes, where the effects can be significant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Product Formulae for Ozsvath-Szabo 4-manifold Invariants. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0339, "human_text": "  We give formulae for the Ozsvath-Szabo invariants of 4-manifolds X obtained\nby fiber sum of two manifolds M_1, M_2 along surfaces S_1, S_2 having trivial\nnormal bundle and genus g>0. The formulae follow from a general theorem on the\nOzsvath-Szabo invariants of the result of gluing two 4-manifolds along a common\nboundary, which is phrased in terms of relative invariants of the pieces. These\nrelative invariants take values in a version of Heegaard Floer homology with\ncoefficients in modules over certain Novikov rings; the fiber sum formula\nfollows from the theorem that this \"perturbed\" version of Heegaard Floer theory\nrecovers the usual Ozsvath-Szabo invariants, when the 4-manifold in question\nhas b^+>1. The construction allows an extension of the definition of the\nOzsvath-Szabo invariants to 4-manifolds having b^+ = 1 depending on certain\nchoices, in close analogy with Seiberg-Witten theory. The product formulae lead\nquickly to calculations of the Ozsvath-Szabo invariants of various 4-manifolds;\nin all cases the results are in accord with the conjectured equivalence between\nthe Ozsvath-Szabo and Seiberg-Witten invariants.\n", "machine_text": "\n\nWe give product formulae for the Ozsvath-Szabo 4-manifold invariants of 3- and 4-dimensional representations of Lie groups. We show that these formulae generalize in an appropriate manner the product formulae ofWCNextTheorem:If $G$ is a locally compact second countable group and $V$ is a finite dimensional representation of $G$ then there is a decomposition $V=\\oplus$ of irreducible representations of $G$. The isomorphism class of $V$ determines an equivalence class of $G$-signed locally compact second countable groups, up to a class of Trivial groups. The decomposition is unique up to equivalence and order. We prove the product formula for the Ozsvath-Szabo invariants of a finite dimensional representation of a locally compact second countable group in the following steps: (1) We give a product formula for the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in the case when the dimension of the representation is $n\\leq 4$. (2) We prove that the product formula for the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in the case when the dimension of the representation is $n\\leq 4$, holds also in the case when the dimension of the representation is $n>4$. (3) We prove that the product formula for the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in the case when the dimension of the representation is $n>4$, holds also in the case when the dimension of the representation is $n\\leq 4$. As an application, we give a description of the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in terms of the canonical action of the group on the regular part of the representation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mid-Infrared Fine Structure Line Ratios in Active Galactic Nuclei\n  Observed with Spitzer IRS: Evidence for Extinction by the Torus. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0547, "human_text": "  We present the first systematic investigation of the [NeV] (14um/24um) and\n[SIII] (18um/33um) infrared line flux ratios, traditionally used to estimate\nthe density of the ionized gas, in a sample of 41 Type 1 and Type 2 active\ngalactic nuclei (AGNs) observed with the Infrared Spectrograph on board\nSpitzer. The majority of galaxies with both [NeV] lines detected have observed\n[NeV] line flux ratios consistent with or below the theoretical low density\nlimit, based on calculations using currently available collision strengths and\nignoring absorption and stimulated emission. We find that Type 2 AGNs have\nlower line flux ratios than Type 1 AGNs and that all of the galaxies with line\nflux ratios below the low density limit are Type 2 AGNs. We argue that\ndifferential infrared extinction to the [NeV] emitting region due to dust in\nthe obscuring torus is responsible for the ratios below the low density limit\nand we suggest that the ratio may be a tracer of the inclination angle of the\ntorus to our line of sight. Because the temperature of the gas, the amount of\nextinction, and the effect of absorption and stimulated emission on the line\nratios are all unknown, we are not able to determine the electron densities\nassociated with the [NeV] line flux ratios for the objects in our sample. We\nalso find that the [SIII] emission from the galaxies in our sample is extended\nand originates primarily in star forming regions. Since the emission from\nlow-ionization species is extended, any analysis using line flux ratios from\nsuch species obtained from slits of different sizes is invalid for most nearby\ngalaxies.\n", "machine_text": "\nWe present here the results of a study of the mid-infrared fine structure line ratios in 98 active galactic nuclei (AGN) observed with Spitzer IRS. The observations were made with the Multiband Imaging Photometer for Spitzer (MIPS) and the InfraRed Array Camera (IRAC), with an average sensitivity of 5sigma on an integration time of $\\sim30$ ks. The sample is complete for galaxies with $M_{\\rm gas} > 10^{10} M_{\\odot}$ and $10^{42} M_{\\odot} \\ year^{-1}$, with $L_{\\rm IR} > 10^{43}$ erg s$^{-1}$, and is almost complete for galaxies with $M_{\\rm gas} \\sim 10^{10}$ M$_{\\odot}$, $L_{\\rm IR} \\sim 10^{42}$ erg s$^{-1}$. We find that the fine structure line ratio $\\lambda_{\\rm rest} / \\lambda_{\\rm complex}$ is on average 1.5 +- 0.5. This is significantly different from the ratio of 1.0 predicted by simple models in which the line-forming region is assumed to be a uniform disc. The observed line ratio varies smoothly with both the ionization timescale and the black hole spin velocity. The standard deviation of the line ratio is $\\sim 0.6$. We show that simple models of a non-uniform line-forming region can explain the observations, provided that the line-forming region is either a flared torus or a disc with a hole at the centre. We discuss our results in the context of other observations of the ionization structure in AGN, and in terms of the size and density distribution of the line-forming region. We show that the simplest model that explains our observations is a flared torus with a hole at the centre, and we discuss the implications of this for future observations of this important region.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Information Rate of MIMO Systems with Finite Rate Channel State\n  Feedback and Power On/Off Strategy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2273, "human_text": "  This paper quantifies the information rate of multiple-input multiple-output\n(MIMO) systems with finite rate channel state feedback and power on/off\nstrategy. In power on/off strategy, a beamforming vector (beam) is either\nturned on (denoted by on-beam) with a constant power or turned off. We prove\nthat the ratio of the optimal number of on-beams and the number of antennas\nconverges to a constant for a given signal-to-noise ratio (SNR) when the number\nof transmit and receive antennas approaches infinity simultaneously and when\nbeamforming is perfect. Based on this result, a near optimal strategy, i.e.,\npower on/off strategy with a constant number of on-beams, is discussed. For\nsuch a strategy, we propose the power efficiency factor to quantify the effect\nof imperfect beamforming. A formula is proposed to compute the maximum power\nefficiency factor achievable given a feedback rate. The information rate of the\noverall MIMO system can be approximated by combining the asymptotic results and\nthe formula for power efficiency factor. Simulations show that this\napproximation is accurate for all SNR regimes.\n", "machine_text": "\nWe investigate the information rate of a multiple-input multiple-output (MIMO) system with a finite rate channel state information feedback and a power on/off strategy. We first derive a simple expression for the information rate, which turns out to be a special case of a general formula. The derived formula is valid for any number of transmit and receive antennas, provided that the channel state information feedback rate is greater than the number of transmit antennas. In addition, we show that in the case of a large number of antennas, the derived formula is also valid when the feedback rate is equal to the number of transmit antennas. In this case, we obtain the well-known diversity-multiplexing trade-off curve. We then propose a simple power on/off strategy that can achieve the same performance as the strategy that maximizing the information rate. The proposed strategy is to switch on the transmit antennas in turn, and to use the switched on antennas to send independent codewords. We analyze the proposed strategy by using the general formula for the information rate. We then show that the proposed strategy achieves the maximum information rate for any number of transmit and receive antennas, provided that the channel state information feedback rate is greater than the number of transmit antennas. In addition, we show that the proposed strategy achieves the maximum information rate when the feedback rate is equal to the number of transmit antennas, provided that the number of receive antennas is greater than the number of transmit antennas.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the nature of two superconducting transitions in the specific heat of\n  PrOs$_4$Sb$_{12}$: Effects of crystal grinding. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4659, "human_text": "  Specific heat, dc- and ac-magnetic susceptibility are reported for a large\nsingle crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room\ntemperature effective paramagnetic moment of the crystal was consistent with\nthe Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The\ncrystal showed two distinct anomalies in the specific heat and an overall\ndiscontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at\n$T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at\n$T_{c2}$ was very sharp, consistent with a good quality of the crystal. We\nobserved a shoulder in $\\chi$' and two peaks in $\\chi$'' below $T_{c1}$.\nHowever, there were no signatures in $\\chi$' of the lower temperature\ntransition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which\nsuppresses the upper superconducting transition in both the specific heat and\nmagnetic susceptibility. $\\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in\nthe powdered sample. Existing data on ground, polished, and sliced crystals\nsuggests the existence of a length scale of order 100 $\\mu$, characterizing the\nhigher temperature superconducting phase.\n", "machine_text": "\nWe have performed a systematic study of the evolution of the superconducting (SC) order parameter and critical magnetic field in PrOs$_4$Sb$_{12}$ by means of measurements of the specific heat. These were carried out on samples which had been ground to various degrees. We found that the critical magnetic field for the magnetic-field-induced SC transition increases with decreasing particle size, in spite of the fact that the magnetic susceptibility is depressed by the same effect. The nature of the two SC transitions in the specific heat is discussed in the framework of a simple model which takes into account the finite size of the particles and the formation of bound pairs. We show that the depression of the magnetic susceptibility has a different origin from the increase in the critical magnetic field for the magnetic-field-induced SC transition. We also found that the electrical resistivity shows a clear signature of the transition to the normal conducting state at the glass transition temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strongly modulated transmission of a spin-split quantum wire with local\n  Rashba interaction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0107, "human_text": "  We investigate the transport properties of ballistic quantum wires in the\npresence of Zeeman spin splittings and a spatially inhomogeneous Rashba\ninteraction. The Zeeman interaction is extended along the wire and produces\ngaps in the energy spectrum which allow electron propagation only for spinors\nlying along a certain direction. For spins in the opposite direction the waves\nare evanescent far away from the Rashba region, which plays the role of the\nscattering center. The most interesting case occurs when the magnetic field is\nperpendicular to the Rashba field. Then, the spins of the asymptotic\nwavefunctions are not eigenfunctions of the Rashba Hamiltonian and the\nresulting coupling between spins in the Rashba region gives rise to sudden\nchanges of the transmission probability when the Fermi energy is swept along\nthe gap. After briefly examining the energy spectrum and eigenfunctions of a\nwire with extended Rashba coupling, we analyze the transmission through a\nregion of localized Rashba interaction, in which a double interface separates a\nregion of constant Rashba interaction from wire leads free from spin-orbit\ncoupling. For energies slightly above the propagation threshold, we find the\nubiquitous occurrence of transmission zeros (antiresonances) which are analyzed\nby matching methods in the one-dimensional limit. We find that a a minimal\ntight-binding model yields analytical transmission lineshapes of Fano\nantiresonance type. More general angular dependences of the external magnetic\nfield is treated within projected Schroedinger equations with Hamiltonian\nmatrix elements mixing wavefunction components. Finally, we consider a\nrealistic quantum wire where the energy subbands are coupled via the Rashba\nintersubband coupling term and discuss its effect on the transmission zeros.\n", "machine_text": "\n\nWe study a quantum wire with a local Rashba interaction that is subjected to a perpendicular magnetic field. The low-lying electronic states, which are completely spin-split in the absence of the field, become weakly or even strongly modulated as the field is increased. We show that this unusual effect is due to a competition between the local Rashba interaction and the magnetic field, which results in the appearance of an additional, non-trivial band structure with respect to the elementary bands of the unmodulated case. Our main tool is a microscopic tight-binding model that is capable of describing the full range of the strength of the local Rashba interaction. We find that a substantial enhancement of the transmission of the spin-split states can be achieved by a proper choice of the parameters of the model, and that the effect is particularly pronounced for a strong local Rashba interaction and a large magnetic field. Our results suggest that a proper design of the local Rashba interaction may be beneficial for spintronic applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Search for a kaonic nuclear state via $^4$He$(K^-, N)$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0297, "human_text": "  Very recently, we have performed a couple of experiments, {\\it{KEK\nPS-E549/E570}}, for the detailed study of the strange tribaryon $S^0(3115)$\nobtained in {\\it{KEK PS-E471}}. These experiments were performed to accumulate\nmuch higher statistics with improved experimental apparatusespecially for the\nbetter proton spectroscopy of the $^4$He({\\it{stopped K}}$^-$, {\\it{N}})\nreaction. In contrast to the previous proton spectrum, no narrow ($\\sim$ 20\nMeV) peak structure was found either in the inclusive $^4$He({\\it{stopped\nK}}$^-$, {\\it{p}}) or in the semi-inclusive $^4$He({\\it{stopped K}}$^-$,\n{\\it{p}}$X^\\pm$) reaction channel, which is equivalent to the previous $E471$\nevent trigger condition. Detailed analysis of the present data and simulation\nshows that the peak, corresponding to $S^0(3115)$, has been an experimental\nartifact. Present analysis does not exclude the possible existence of a much\nwider structure. To be sensitive to such structure and for better understanding\nof the non-mesonic $K^-$ absorption reaction channel, detailed analysis of the\ndata is in progress.\n", "machine_text": "\nWe report on a search for a kaonic nuclear state in $^4$He$(K^-, N)$. The motivation for this work is based on the recent observation of a significant population of $^4$He in the hyperon channel by the H1 experiment, in spite of the fact that the $^4$He$(K^-, N)$ final state is known to be highly suppressed compared to the $^4$He$(K^0, N)$ final state. To explain this observation we consider a model in which the $^4$He$(K^-, N)$ state is a compound state with $^4$He$(K^0, N)$ and $^3$He$(K^-, N)$, and in which the $^4$He$(K^0, N)$ state is a true nuclear state while the $^3$He$(K^-, N)$ state is a kaonic state. The model predicts a significant population of $^4$He in the hyperon channel, in spite of the fact that the $^4$He$(K^-, N)$ state is highly suppressed. We present here results of a search for a kaonic state in $^4$He$(K^-, N)$, based on a data sample collected with the BaBar detector at the PEP2 storage ring. We find no evidence for such a state, and set a 90% C.L. upper limit on the fraction of $^4$He in $^4$He$(K^-, N)$ of $2.4 \\times 10^{-3}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Characterization of the Soluble Nanoparticles Formed through Coulombic\n  Interaction of Bovine Serum Albumin with Anionic Graft Copolymers at Low pH. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3707, "human_text": "  A static light scattering (SLS) study of bovine serum albumin (BSA) mixtures\nwith two anionic graft copolymers of poly (sodium acrylate-co-sodium\n2-acrylamido-2-methyl-1-propanesulphonate)-graft-poly (N,\nN-dimethylacrylamide), with a high composition in poly (N,\nN-dimethylacrylamide) (PDMAM) side chains, revealed the formation of oppositely\ncharged complexes, at pH lower than 4.9, the isoelectric point of BSA. The\ncore-corona nanoparticles formed at pH = 3.00, were characterized. Their\nmolecular weight and radius of gyration were determined by SLS, while their\nhydrodynamic radius was determined by dynamic light scattering. Small angle\nneutron scattering measurements were used to determine the radius of the\ninsoluble complexes, comprising the core of the particles. The values obtained\nindicated that their size and aggregation number of the nanoparticles, were\nsmaller when the content of the graft copolymers in neutral PDMAM side chains\nwas higher. Such particles should be interesting drug delivery candidates, if\nthe gastrointestinal tract was to be used.\n", "machine_text": "\n\nWe investigated the formation of soluble nanoparticles through the Coulombic interaction of bovine serum albumin (BSA) with anionic graft copolymers in aqueous solutions at low pH. The average particle size and the zeta potential of the nanoparticles were determined by dynamic light scattering (DLS), and the morphology of the nanoparticles was examined by transmission electron microscopy (TEM). The results showed that the nanoparticles formed through the Coulombic interaction of BSA with anionic graft copolymers were approximately spherical in shape, and the average particle size was less than 100 nm. The zeta potential of the nanoparticles was highly negative, which was attributed to the anionic groups on the surface of the nanoparticles. The results also showed that the morphology of the nanoparticles was uniform and that they were well dispersed in the solution. We conclude that the Coulombic interaction of BSA with anionic graft copolymers is a potential method for the formation of stable, soluble nanoparticles at low pH.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the morphologies, gas fractions, and star formation rates of small\n  galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.021, "human_text": "  We use a series of N-body/smoothed particle hydrodynamics simulations and\nanalytic arguments to show that the presence of an effective temperature floor\nin the interstellar medium at T_F ~ 10^4 K naturally explains the tendency for\nlow-mass galaxies to be more spheroidal, more gas rich, and less efficient in\nconverting baryons into stars than larger galaxies. The trend arises because\ngas pressure support becomes important compared to angular momentum support in\nsmall dark matter haloes. We suggest that dwarf galaxies with rotational\nvelocities ~ 40 km/s do not originate as thin discs, but rather are born as\nthick, puffy systems. If accreted on to larger haloes, tenuous dwarfs of this\nkind will be more susceptible to gas loss or tidal transformation than\nscaled-down versions of larger spirals. For a constant temperature floor,\npressure support becomes less important in large haloes, and this produces a\ntendency for massive isolated galaxies to have thinner discs and more efficient\nstar formation than their less massive counterparts, as observed.\n", "machine_text": "\n\nWe present a morphological catalog of 667 nearby (Mpc) galaxies, drawn from the 2 Micron All-Sky Survey (2MASS), that have morphologies similar to those of the satellites of the Milky Way and of the Small Magellanic Cloud. We find that the kinematics of these galaxies is well described by a combination of a uniform step function and a radial distribution, which is likely to be due to the infall of these galaxies onto the Galactic and Magellanic clouds. We use the 2MASS photometry to estimate the gas fraction of these galaxies, and find that it is a strong function of morphology: late-type galaxies tend to have a higher gas fraction than early-type galaxies. We also find that the gas fractions of galaxies in the thick disk population are significantly higher than those in the thin disk, and that the gas fraction decreases with galactic radius in both the Milky Way and the Small Magellanic Cloud. These results are consistent with the thick-thin disk structure of the Milky Way, and suggest that the Small Magellanic Cloud may also have a thick-thin structure. We find that the gas fraction has a strong correlation with the star formation rate, with the highest star formation rates occurring in galaxies with gas fractions in the range 0.4-1. We also find that the relation between star formation rate and gas fraction is well described by a power law with a negative power of -0.5. Our results suggest that the relation between gas fraction and star formation rate may be determined by the competition between the gas infall and the radiative feedback from the stellar population.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Refuting the Pseudo Attack on the REESSE1+ Cryptosystem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0492, "human_text": "  We illustrate through example 1 and 2 that the condition at theorem 1 in [8]\ndissatisfies necessity, and the converse proposition of fact 1.1 in [8] does\nnot hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for\nf(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a\nlogic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4\nto be invalid. Demonstrate through ex.4 and 5 that each or the combination of\nqu+1 > qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) +\nf(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4\nand alg.2 based on table 1 are disordered and wrong logically. Further,\nmanifest through a repeated experiment and ex.5 that the data at table 2 is\nfalsified, and the example in [8] is woven elaborately. We explain why Cx = Ax\n* W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To\nthe signature fraud, we point out that [8] misunderstands the existence of T^-1\nand Q^-1 % (M-1), and forging of Q can be easily avoided through moving H.\nTherefore, the conclusion of [8] that REESSE1+ is not secure at all (which\nconnotes that [8] can extract a related private key from any public key in\nREESSE1+) is fully incorrect, and as long as the parameter Omega is fitly\nselected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure.\n", "machine_text": "\nWe refute the pseudo attack on the REESSE1+ cryptosystem. Our motivation is that the pseudo attack can cause a false impression about the security of REESSE1+. The key idea is that the pseudo attack uses a fake (i.e. not truly random) entropy source. We show that as long as the entropy source is not revealed, an attacker can only suspect that it is not truly random. We also show that even if the entropy source is revealed, the pseudo attack does not help to break REESSE1+. As a by-product, we show that the standardize step in the pseudo attack is not necessary. Our methodology is to consider a simple instantiation of REESSE1+ with a standardize step, and show that this instantiation is secure, regardless of whether the pseudo attack is applied or not. Our results are that REESSE1+ is secure, regardless of whether the pseudo attack is applied or not. We also show that the pseudo attack does not help to break any generic instantiation of REESSE1+. As a practical application, our results imply that the pseudo attack does not threaten the security of REESSE1+, even if the entropy source is not truly random. As a theoretical application, our results imply that the pseudo attack is not a generic attack on allRAND-based (or BP-based) cryptosystems, even if the entropy source is not truly random.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Efficient Multidimensional Data Redistribution for Resizable Parallel\n  Computations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2146, "human_text": "  Traditional parallel schedulers running on cluster supercomputers support\nonly static scheduling, where the number of processors allocated to an\napplication remains fixed throughout the execution of the job. This results in\nunder-utilization of idle system resources thereby decreasing overall system\nthroughput. In our research, we have developed a prototype framework called\nReSHAPE, which supports dynamic resizing of parallel MPI applications executing\non distributed memory platforms. The resizing library in ReSHAPE includes\nsupport for releasing and acquiring processors and efficiently redistributing\napplication state to a new set of processors. In this paper, we derive an\nalgorithm for redistributing two-dimensional block-cyclic arrays from $P$ to\n$Q$ processors, organized as 2-D processor grids. The algorithm ensures a\ncontention-free communication schedule for data redistribution if $P_r \\leq\nQ_r$ and $P_c \\leq Q_c$. In other cases, the algorithm implements circular row\nand column shifts on the communication schedule to minimize node contention.\n", "machine_text": "\nWe present a multidimensional data redistribution scheme for dynamically redistributing a large amount of data among multiple processors in a parallel computation. Our scheme is motivated by the need to support dynamic resizing of parallel computations, in which the number of processors may be increased or decreased during the course of the computation. We focus on minimizing the amount of data movement required to support such resizing, while also minimizing the amount of space required to store the redistributed data. Our approach is to use a hierarchical redistributing strategy, in which processors at one level of the hierarchy are used to redistribute data among processors at the next level of the hierarchy. This strategy is applied iteratively until the data is finally redistributed among the processors at the lowest level of the hierarchy. The data redistribution is designed to be efficient, in the sense that each processor receives a large fraction of the data that it will need to compute its portion of the solution, while also minimizing the amount of data stored on each processor. We evaluate the efficiency of our scheme by measuring the amount of data movement and space required for the redistribution, as well as the overhead imposed by the redistribution process. We also present a simple model of the redistributing process, which is used to predict the efficiency of the redistribution process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Deformation principle and further geometrization of physics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3003, "human_text": "  The space-time geometry is considered to be a physical geometry, i.e. a\ngeometry described completely by the world function. All geometrical concepts\nand geometric objects are taken from the proper Euclidean geometry. They are\nexpressed via the Euclidean world function \\sigma_E and declared to be concepts\nand objects of any physical geometry, provided the Euclidean world function\n\\sigma_E is replaced by the world function \\sigma of the physical geometry in\nquestion. The set of physical geometries is more powerful, than the set of\nRiemannian geometries, and one needs to choose a true space-time geometry. In\ngeneral, the physical geometry is multivariant (there are many vectors which\nare equivalent to a given vector, but are not equivalent between themselves).\nThe multivariance admits one to describe quantum effects as geometric effects\nand to consider existence of elementary particles as a geometrical problem,\nwhen the possibility of the physical existence of an elementary geometric\nobject in the form of a physical body is determined by the space-time geometry.\nMultivariance admits one to describe discrete and continuous geometries, using\nthe same technique. A use of physical geometry admits one to realize the\ngeometrical approach to the quantum theory and to the theory of elementary\nparticles.\n", "machine_text": "\nWe propose a new deformation principle of physics based on the \" principle of least action \". The action is here defined as a functional of the densities of the basic physical quantities in the configuration space. The principle of least action is equivalent to the Euler-Lagrange equation in the usual formulation of classical mechanics, but has also a general meaning, independent of the Lagrangian formalism. We show that this new deformation principle is consistent with the principles of relativity and quantum mechanics, and we propose a further geometrization of the physical laws based on this principle. In particular, we show that the fundamental physical laws can be obtained by a local minimum of the action functional, under the assumptions that the dynamics is described by a flow in the configuration space, and that the action is invariant under proper deformations of the configuration space. As an application, we show that the principle of least action is equivalent to the Hamiltonian principle in the case of a flow with a given symmetry.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Midlatitude Cirrus Clouds and Multiple Tropopauses from a 2002-2006\n  Climatology over the SIRTA Observatory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2517, "human_text": "  This study present a comparison of lidar observations of midlatitude cirrus\nclouds over the SIRTA observatory between 2002 and 2006 with multiple\ntropopauses (MT) retrieved from radiosounding temperature profiles. The\ntemporal variability of MT properties (frequency, thickness) are discussed.\nResults show a marked annual cycle, with MT frequency reaching its lowest point\nin May (~18% occurrence of MT) and slowly rising to more than 40% in DJF. The\naverage thickness of the MT also follows an annual cycle, going from less than\n1 km in spring to 1.5 km in late autumn. Comparison with lidar observations\nshow that cirrus clouds show a preference for being located close below the 1st\ntropopause. When the cloud top is above the 1st tropopause (7% of\nobservations), in 20% of cases the cloud base is above it as well, resulting in\na cirrus cloud \"sandwiched\" between the two tropopauses. Compared to the\ngeneral distribution of cirrus, cross-tropopause cirrus show a higher frequency\nof large optical depths, while inter-tropopause cirrus show almost exclusively\nlow optical depths (Tau < 0.03 in 90% of cases) typical of subvisible clouds.\nResults suggest the occurrence of inter-tropopause cirrus clouds is correlated\nwith the frequency of multiple tropopauses.\n", "machine_text": "\n\nMidlatitude Cirrus Clouds and Multiple Tropopauses from a 2002-2006 Climatology over the SIRTA Observatory\n\nWe present a climatology of cirrus clouds and multiple tropopauses observed over the SIRTA Observatory in France, based on four years of lidar observations (2002-2006). Cirrus clouds are found to occupy a large part of the atmosphere above the observatory, with a significant vertical structure. The lidar ratio, defined as the backscattered signal per unit of aerosol optical depth, exhibits a maximum at around 7 km and another one at around 9 km, indicative of the presence of two cloud decks. These cloud decks are also found to have different optical depths, as diagnosed from the fit of a two-layer cloud model to the observations. The high optical depth of the upper cloud deck implies that this cirrus layer has a strong radiative effect on the atmosphere. We show that the temperature of the cirrus clouds increases with height, in qualitative agreement with a positive cloud-top-warming effect. The temperature of the lower cloud deck is instead relatively constant with height, suggesting that it is well mixed. We attribute this to the strong wind shear in the atmosphere. We found that the multiple tropopauses are present in more than 90% of the year, and they are responsible for the large amount of cirrus clouds. Our results suggest that these cirrus clouds are rather long-lived, since they are present in the afternoon as well as in the evening. The multiple tropopauses are also found to be highly correlated with the large-scale dynamics, such as the North Atlantic Oscillation and the Siberian High. We conclude that the multiple tropopauses are a prominent feature of the midlatitude atmosphere, and they have important implications on the transport and the radiative properties of the atmosphere.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral type dependent rotational braking and strong magnetic flux in\n  three components of the late-M multiple system LHS 1070. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2139, "human_text": "  We show individual high resolution spectra of components A, B, and C of the\nnearby late-M type multiple system LHS 1070. Component A is a mid-M star, B and\nC are known to have masses at the threshold to brown dwarfs. From our spectra\nwe measure rotation velocities and the mean magnetic field for all three\ncomponents individually. We find magnetic flux on the order of several\nkilo-Gauss in all components. The rotation velocities of the two late-M objects\nB and C are similar (vsini = 16km/s), the earlier A component is spinning only\nat about half that rate. This suggests weakening of net rotational braking at\nlate-M spectral type, and that the lack of slowly rotating late-M and L dwarfs\nis real. Furthermore, we found that magnetic flux in the B component is about\ntwice as strong as in component C at similar rotation rate. This indicates that\nrotational braking is not proportional to magnetic field strength in fully\nconvective objects, and that a different field topology is the reason for the\nweak braking in low mass objects.\n", "machine_text": "\n\nWe present photometric and spectroscopic observations of the pre-main sequence M1 dwarf LHS 1070 in an attempt to constrain the evolutionary state of this triple system. The two closer components, LHS 1070 A and B, display the characteristics of young, solar-type objects in a close orbit with a short orbital period (83 min), while the more distant component, LHS 1070 C, displays a spectral type that is unusual for a solar twin, with a relatively strong magnetic field (B = 2.6 kG) and a line-of-sight velocity that implies a mass fraction of >70% (by comparison, the solar ratio is approximately 1%). We find that the observed physical properties of the system are consistent with a bound system with the following evolutionary state: LHS 1070 A and B are in a wide orbit around a cool dwarf star (M1) with a low magnetic field (B < 1.5 kG) and a period of approximately 2 kyr. The M1 dwarf has a mass fraction of <30% and has been leaking angular momentum to its companions in a prograde fashion, resulting in the current wide orbit and short orbital period. The low magnetic field of the M1 dwarf is the result of either an initial field that has been diluted by the accretion of a non-magnetic companion or the simple cooling and shrinking of the initial magnetic field as the M1 dwarf has evolved off the main sequence. We have identified only one other triple system with a similar orbital configuration (LHS 3844), although we note that the current orbits in LHS 3844 are not well known. We discuss a number of other possible evolutionary states that are consistent with the available observations. In particular, we suggest that the system has probably evolved from a configuration with two or more brown dwarfs in a wide orbit around a more massive object (M>M1) and that the brown dwarfs have been captured into a much tighter orbit as a result of gravitational interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Koszul duality in deformation quantization, I. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2381, "human_text": "  Let $\\alpha$ be a polynomial Poisson bivector on a finite-dimensional vector\nspace $V$ over $\\mathbb{C}$. Then Kontsevich [K97] gives a formula for a\nquantization $f\\star g$ of the algebra $S(V)^*$. We give a construction of an\nalgebra with the PBW property defined from $\\alpha$ by generators and\nrelations. Namely, we define an algebra as the quotient of the free tensor\nalgebra $T(V^*)$ by relations $x_i\\otimes x_j-x_j\\otimes x_i=R_{ij}(\\hbar)$\nwhere $R_{ij}(\\hbar)\\in T(V^*)\\otimes\\hbar \\mathbb{C}[[\\hbar]]$, $R_{ij}=\\hbar\n\\Sym(\\alpha_{ij})+\\mathcal{O}(\\hbar^2)$, with one relation for each pair of\n$i,j=1...\\dim V$. We prove that the constructed algebra obeys the PBW property,\nand this is a generalization of the Poincar\\'{e}-Birkhoff-Witt theorem. In the\ncase of a linear Poisson structure we get the PBW theorem itself, and for a\nquadratic Poisson structure we get an object closely related to a quantum\n$R$-matrix on $V$. At the same time we get a free resolution of the deformed\nalgebra (for an arbitrary $\\alpha$).\n  The construction of this PBW algebra is rather simple, as well as the proof\nof the PBW property. The major efforts should be undertaken to prove the\nconjecture that in this way we get an algebra isomorphic to the Kontsevich\nstar-algebra.\n", "machine_text": "\n\nWe show that the deformation quantization functor for Poisson Lie algebras preserves the Koszul duality between polynomials and polynomial constraints on the derived category. As an application we give a description of the Poisson Wakforum subtropical algebra in terms of a polynomial constraint on the derived category.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Luminosity function of binary X-ray sources calculated using the\n  Scenario Machine. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.286, "human_text": "  Using the ``Scenario Machine'' we have carried out a population synthesis of\nX-ray binaries for the purpose of modelling of X-ray luminosity functions\n(XLFs) in different types of galaxies: star burst, spiral, and elliptical. This\ncomputer code allows to calculate, by using Monte Carlo simulations, the\nevolution of a large ensemble of binary systems, with proper accounting for the\nspin evolution of magnetized neutron stars.\n  We show that the XLF has no universal type. It depends on the star formation\nrate in the galaxy. Also it is of importance to take into account the evolution\nof binary systems and life times of X-ray stages in theoretical models of such\nfunctions. We have calculated cumulative and differential XLFs for the galaxy\nwith the constant star formation rate. Also we have calculated cumulative\nluminosity functions for different intervals of time after the star formation\nburst in the galaxy and curves depicting the evolution of the X-ray luminosity\nafter the star formation burst in the galaxy.\n", "machine_text": "\n\nWe present a method to estimate the luminosity function of a collection of binary X-ray sources in an uniform manner. The method is based on the Scenario Machine, a computer program that generates synthetic observations of a collection of binary X-ray sources given a specified luminosity function. We use the observed properties of a sample of X-ray binaries to constrain the shape of the luminosity function and generate the corresponding synthetic observations. We then compare the synthetic observations with the observed ones, thereby measuring the statistical significance of the observed properties and their correlations. We find that a power law with an index of 1.2 is consistent with the observations, with a statistical significance of 3.5 standard deviations. We also find that the observed correlation between the orbital period and the binary mass is significant (3.1 standard deviations) and that the mass function is well described by a power law with an index of 2.0. We discuss the implications of our results for models of X-ray binary formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Variation of the Amati Relation with the Cosmological Redshift: a\n  Selection Effect or an Evolution Effect?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3128, "human_text": "  Because of the limit in the number of gamma-ray bursts (GRBs) with available\nredshifts and spectra, all current investigations on the correlation among GRB\nvariables use burst samples with redshifts that span a very large range. The\nevolution and selection effects have thus been ignored, which might have\nimportant influence on the results. In this Letter, we divide the 48\nlong-duration GRBs in Amati (2006, 2007) into four groups with redshift from\nlow to high, each group contains 12 GRBs. Then we fit each group with the Amati\nrelation $\\log E_\\iso = a + b \\log E_\\p$, and check if the parameters $a$ and\n$b$ evolve with the GRB redshift. We find that $a$ and $b$ vary with the mean\nredshift of the GRBs in each group systematically and significantly.\nMonte-Carlo simulations show that there is only $\\sim 4$ percent of chance that\nthe variation is caused by the selection effect arising from the fluence limit.\nHence, our results may indicate that GRBs evolve strongly with the cosmological\nredshift.\n", "machine_text": "\n\nWe have recently investigated the variation of the Amati relation with the cosmological redshift, and found that the probability distribution of the amplitudes of the galaxy redshifts is not in accordance with the prediction of the Amati relation. We have interpreted this result as a possible selection effect due to the fact that we consider only galaxies with known redshifts in our sample, and thus the relation might not hold for galaxies without measured redshifts. We have also pointed out that an evolution effect might have contributed to the discrepancy between the prediction of the Amati relation and the observations. The evolution effect could have acted during the period of the Universe when the galaxies in our sample have been formed, and the evolution speed of the relation might have been higher than the evolution speed of the galaxies. We have discussed that the evolution effect can be tested by a detailed study of the variation of the Amati relation with the galaxy age and with the surface or volume density of the ambient medium. Here we briefly comment on the problem.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Interpreting and predicting the yield of transit surveys: Giant planets\n  in the OGLE fields. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1919, "human_text": "  Transiting extrasolar planets are now discovered jointly by photometric\nsurveys and by radial velocimetry. We want to determine whether the different\ndata sets are compatible between themselves and with models of the evolution of\nextrasolar planets. We simulate directly a population of stars corresponding to\nthe OGLE transit survey and assign them planetary companions based on radial\nvelocimetry discoveries. We use a model of the evolution and structure of giant\nplanets assuming a variable fraction of heavy elements. The output list of\ndetectable planets of the simulations is compared to the real detections. We\nconfirm that the radial velocimetry and photometric survey data sets are\ncompatible within the statistical errors, assuming that planets with periods\nbetween 1 and 2 days are approximately 5 times less frequent than planets with\nperiods between 2 and 5 days. We show that evolution models fitting present\nobservational constraints predict a lack of small giant planets with large\nmasses. We also identify distinct populations of planets: those with short\nperiods (P < 10d) are only found in orbit around metal-rich stars with [Fe/H] >\n-0.07. We further confirm the relative absence of low-mass giant planets at\nsmall orbital distances.\n", "machine_text": "\n\nInterpreting and predicting the yield of transit surveys: Giant planets\nin the OGLE fields\n\nWe present a method for predicting the yield of transit surveys targeting giant planets\naround solar-type stars. We consider the selection effect caused by the survey\nconfiguration, such as the choice of the stellar sample and the observing\nseason. We show that the selection effect can be understood by assuming that the\nobserved giants are at the same orbital distance from their host stars as the\nplanet. We evaluate the efficiency of a survey to detect low-mass giant planets\nby applying our method to the ongoing OGLE survey. We find that giant planets\nwith a mass lower than 1.7 Jupiter masses can be detected with a probability higher\nthan 99% over a survey duration of 5 years for an OGLE-like survey with\n10^4 stars in its target area. We show that the OGLE survey has already\ndetected such low-mass giants in at least 13 stars. We discuss the selection\neffects acting on our observations, and the implications of our method on\nupcoming giant planet transit surveys.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Local purity distillation with bounded classical communication. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4089, "human_text": "  Local pure states are an important resource for quantum computing. The\nproblem of distilling local pure states from mixed ones can be cast in an\ninformation theoretic paradigm. The bipartite version of this problem where\nlocal purity must be distilled from an arbitrary quantum state shared between\ntwo parties, Alice and Bob, is closely related to the problem of separating\nquantum and classical correlations in the state and in particular, to a measure\nof classical correlations called the one-way distillable common randomness. In\nPhys. Rev. A 71, 062303 (2005), the optimal rate of local purity distillation\nis derived when many copies of a bipartite quantum state are shared between\nAlice and Bob, and the parties are allowed unlimited use of a unidirectional\ndephasing channel. In the present paper, we extend this result to the setting\nin which the use of the channel is bounded. We demonstrate that in the case of\na classical-quantum system, the expression for the local purity distilled is\nefficiently computable and provide examples with their tradeoff curves.\n", "machine_text": "\n\nWe consider the problem of distilling a weak solution of a pure solvent into a solvent of higher purity. We suppose that the initial solution is distilled in a single vessel, and that the distillate is collected in a reservoir. The reservoir is connected to a secondary condenser that receives the vapor of the pure solvent from the reservoir. We assume that the amount of vapor is finite and that the solution and the reservoir are well mixed. We show that this distillation process can be described by a simple model. The model consists of a system of ordinary differential equations, where the solution is the composition of the solution and the vapor in the reservoir. The initial conditions of the system are related to the initial solution, and the final condition is that the solution in the reservoir reaches the desired purity level. We show that this model has a unique solution, and we study the parameter regions in which the solution exists and is stable. In particular, we find that the distillate purity level is lower if the vapor in the reservoir is not controlled. We also analyze the model from the perspective of communication theory. We show that the distillation process can be described by a simple symbolic model using bounded classical communication.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical implementation and entanglement distribution in Gaussian valence\n  bond states. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.158, "human_text": "  We study Gaussian valence bond states of continuous variable systems,\nobtained as the outputs of projection operations from an ancillary space of M\ninfinitely entangled bonds connecting neighboring sites, applied at each of $N$\nsites of an harmonic chain. The entanglement distribution in Gaussian valence\nbond states can be controlled by varying the input amount of entanglement\nengineered in a (2M+1)-mode Gaussian state known as the building block, which\nis isomorphic to the projector applied at a given site. We show how this\nmechanism can be interpreted in terms of multiple entanglement swapping from\nthe chain of ancillary bonds, through the building blocks. We provide optical\nschemes to produce bisymmetric three-mode Gaussian building blocks (which\ncorrespond to a single bond, M=1), and study the entanglement structure in the\noutput Gaussian valence bond states. The usefulness of such states for quantum\ncommunication protocols with continuous variables, like telecloning and\nteleportation networks, is finally discussed.\n", "machine_text": "\n\nWe propose and experimentally realize a novel method to produce Gaussian valence bond states, which are a generalization of the concept of Gaussian bosons to the case of massive particles. Our method is based on the idea of dressing a certain class of multipartite entangled states, called Paragraph 2 states, in a laser field. We show that such dressed states are well-approximated by Gaussian functions, and thus are suitable to be used as qubits in quantum information processing. In particular, we investigate a simple scheme for quantum teleportation and gate operations, and show that it is possible to perform these operations by using only Gaussian valence bond states, without the need for any other intermediate qubit registers. We also propose a method to distribute entanglement between different such qubit registers, which is particularly useful in the context of large-scale quantum computers. Our experimental realization of the proposed schemes is based on the use of ultra-cold atomic gases, and we report on the successful implementation of the schemes using our experimental apparatus.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-dimensional N=(2,2) super Yang-Mills theory on computer. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1392, "human_text": "  We carry out preliminary numerical study of Sugino's lattice formulation\n\\cite{Sugino:2004qd,Sugino:2004qdf} of the two-dimensional $\\mathcal{N}=(2,2)$\nsuper Yang-Mills theory (2d $\\mathcal{N}=(2,2)$ SYM) with the gauge group\n$\\SU(2)$. The effect of dynamical fermions is included by re-weighting a\nquenched ensemble by the pfaffian factor. It appears that the complex phase of\nthe pfaffian due to lattice artifacts and flat directions of the classical\npotential are not problematic in Monte Carlo simulation. Various one-point\nsupersymmetric Ward-Takahashi (WT) identities are examined for lattice spacings\nup to $a=0.5/g$ with the fixed physical lattice size $L=4.0/g$, where $g$\ndenotes the gauge coupling constant in two dimensions. WT identities implied by\nan exact fermionic symmetry of the formulation are confirmed in fair accuracy\nand, for most of these identities, the quantum effect of dynamical fermions is\nclearly observed. For WT identities expected only in the continuum limit, the\nresults seem to be consistent with the behavior expected from supersymmetry,\nalthough we do not see clear distintion from the quenched simulation. We\nmeasure also the expectation values of renormalized gauge-invariant bi-linear\noperators of scalar fields.\n", "machine_text": "\n\nWe study the two-dimensional N=(2,2) super Yang-Mills theory on the computer. We use the NumPy library to perform the lattice sum calculations, and use the Feynman-Kac formula to evaluate the sum. We find the critical value of the mass parameter for which the theory is confining, and the massless limit. The results agree with the previous analytical results. We also find the evolutions of the massless states, and find that the half-+\"-state has a faster evolution than the full-+\"-state. This is consistent with the previous result by Bazarov and Taylor, but contrary to the suggestion by lord_k layouts. We find the critical value of the non-Abelian fusion parameter for which the theory is symmetric, and the fusionless limit. The results agree with the previous analytical results. We also find the evolutions of the massless states, and find that the half-+\"-state has a faster evolution than the full-+\"-state. This is consistent with the previous result by Bazarov and Taylor, but contrary to the suggestion by lord_k layouts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Phase resolved measurements of stimulated emission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2296, "human_text": "  The development of the semiconductor quantum cascade laser (QCL) [1] has\nenabled bright coherent sources operating at frequencies between the optical\n(>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for\nfundamental science investigations [2-5] as well as for applications [6].\nHowever, detailed information about the internal processes in QCLs and their\nultrafast dynamics are needed for their further development towards high output\npower, longer wavelengths and stable pulsed operation. We introduce a novel\napproach to study the gain and dynamics of a terahertz (THz) QCL [7] using\nphase resolved measurements of the stimulated emission. This is enabled by\ndirect recording of the emitted electric field with <100 fs time resolution.\nFor the case of the THz QCL we demonstrate the validity of the quantum\nmechanical description of the laser. We show for the first time the real\nbandwidth of the terahertz gain medium, the current dependence of this gain,\nand the losses associated with the wave propagation in the laser waveguide.\n", "machine_text": "\n\nWe have developed a new technique for measuring the time-evolution of the molecular hyperfine spin order with millisecond precision, by monitoring the evolution of the stimulated emission from a flash of laser light as it is turned off. We show that this technique can be used to measure the dynamics of the spin order in several different molecular systems, and that the dynamics of the spin order is in general different from the much faster electronic dynamics. We also show that by using a combination of different laser pulses it is possible to follow the evolution of the spin order from its initial state, through a number of different spin-ordered states, and finally back to the initial state. This allows us to study the dynamics of the spin order in a number of different situations, and we find that the dynamics is in general very different for different molecular systems. We also show that the dynamics of the spin order can be very different in different portions of a single molecular system, so that it is necessary to use a number of different laser pulses in order to fully characterize the dynamics of the spin order in a given molecular system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vector mesons from AdS/TC to the LHC. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2205, "human_text": "  With the use of the AdS/CFT dictionary, a five-dimensional effective\ndescription of dynamical electro-weak symmetry breaking with walking behavior\nis constructed. The minimal model contains only two new parameters, the\nconfinement scale and the effective coupling of the new strong sector. This\nparameter space is restricted by the precision electro-weak constraints and by\nthe requirement that the five-dimensional coupling be perturbative\n(corresponding to the large-N regime in four-dimensional language). The\nlightest observable new states are a set of four nearly degenerate spin-1\nstates with the same quantum numbers as the standard-model electro-weak gauge\nbosons, and masses in the few TeV range. Their decay rate is dominated by\ntwo-fermion final states. The number of pp -> mu mu and pp -> mu nu events is\nstudied as a function of the LHC integrated luminosity and of the two free\nparameters. Discovery at the LHC is possible over a significant part of the\nallowed parameter space up to masses of 4 TeV already with 10/fm of integrated\nluminosity.\n", "machine_text": "\nWe study the production of vector mesons at hadron colliders within the framework of the effective Lagrangian approach. We consider the leading pion pion scattering contribution as well as the secondary vector meson production and the inclusive direct production. In all cases the contribution of a top-quark initiated process is calculated and compared to the Standard Model prediction. We find a significant deviation from the Standard Model which can be described by an additional vector meson coupling to the top-quark. In our scenario the new vector meson coupling is generated through the spontaneous symmetry breaking of a larger group which includes the top-quark and the new vector meson. This scenario is in agreement with the general prediction that new physics can be expected at high energies or large momenta. The parameters of the new vector meson coupling can be constrained by the available data. We discuss the possibility that the new vector meson coupling is related to the non-renormalizable dynamics of the strong interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Trade-off between Processing Gains of an Impulse Radio UWB System in\n  the Presence of Timing Jitter. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3408, "human_text": "  In time hopping impulse radio, $N_f$ pulses of duration $T_c$ are transmitted\nfor each information symbol. This gives rise to two types of processing gain:\n(i) pulse combining gain, which is a factor $N_f$, and (ii) pulse spreading\ngain, which is $N_c=T_f/T_c$, where $T_f$ is the mean interval between two\nsubsequent pulses. This paper investigates the trade-off between these two\ntypes of processing gain in the presence of timing jitter. First, an additive\nwhite Gaussian noise (AWGN) channel is considered and approximate closed form\nexpressions for bit error probability are derived for impulse radio systems\nwith and without pulse-based polarity randomization. Both symbol-synchronous\nand chip-synchronous scenarios are considered. The effects of multiple-access\ninterference and timing jitter on the selection of optimal system parameters\nare explained through theoretical analysis. Finally, a multipath scenario is\nconsidered and the trade-off between processing gains of a synchronous impulse\nradio system with pulse-based polarity randomization is analyzed. The effects\nof the timing jitter, multiple-access interference and inter-frame interference\nare investigated. Simulation studies support the theoretical results.\n", "machine_text": "\n\nWe investigate the impact of timing jitter on the performance of an impulse radio ultra-wideband (IR-UWB) system in a multipath environment. We show that the timing jitter has a negative impact on the bit error rate (BER) and the packet error rate (PER) when the channel is influenced by strong multipath reflections. In particular, for a given impulse position modulation (IPM) symbol duration, we show that the timing jitter can cause interferences between the multipath components, leading to an increase in the BER and PER. To quantify this effect, we propose a metric called the processing gain penalty due to timing jitter (PGPT). We show that the PGPT can be used to predict the performance of an IR-UWB system in the presence of timing jitter, and we provide a simple expression for the PGPT in the case of a single-tone carrier. We also investigate the impact of timing jitter on the performance of an IR-UWB system in the presence of narrowband interference (NBI). We show that the timing jitter can cause the NBI to move in time, leading to an increase in the BER and PER. To quantify this effect, we propose a metric called the processing gain penalty due to timing jitter and NBI (PGPTI). We show that the PGPTI can be used to predict the performance of an IR-UWB system in the presence of timing jitter and NBI, and we provide a simple expression for the PGPTI in the case of a single-tone carrier.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Elongated Structure of the Hercules dSph from Deep LBT Imaging. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1669, "human_text": "  We present a deep, wide-field photometric survey of the newly-discovered\nHercules dwarf spheroidal galaxy, based on data from the Large Binocular\nTelescope. Images in B, V and r were obtained with the Large Binocular Camera\ncovering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This\npermitted the construction of colour-magnitude diagrams that reach\napproximately 1.5 magnitudes below the Hercules main sequence turnoff.\nThree-filter photometry allowed us to preferentially select probable Hercules\nmember stars, and examine the structure of this system at a previously\nunattained level. We find that the Hercules dwarf is highly elongated (3:1),\nconsiderably more so than any other dSph satellite of the Milky Way except the\ndisrupting Sagittarius dwarf. While we cannot rule out that the unusual\nstructure is intrinsic to Hercules as an equilibrium system, our results\nsuggest tidal disruption as a likely cause of this highly elliptical structure.\nGiven the relatively large Galactocentric distance of this system (132 +/- 12\nkpc), signs of tidal disruption would require the Hercules dwarf to be on a\nhighly eccentric orbit around the Milky Way.\n", "machine_text": "\n\nWe present a deep imaging survey for the Hercules double star cluster (dSph) with the Large Binocular Telescope (LBT). We have obtained two sets of images with the LBT Multi-Object Spectrograph (LMOS), one with the near-infrared filter and one with the mid-infrared filter, both at an average depth of ~25 mag. We have combined the two sets of images to produce a single image in which the near-infrared stars are marked in blue and the mid-infrared stars are marked in red. We have analyzed the resulting image to obtain the structural parameters of the dSph. We find that the main body of the dSph has an elongated structure with a projected axis of 37.6 pc and a total extent of 71.8 pc. We also find a number of substructures in the dSph, including several chains of stars, a compact subcluster, and a number of single stars. The largest of the single stars is likely to be the escaped member of the dSph. The properties of the substructures are consistent with the effects of three-body interactions within the dSph. We discuss the properties of the Hercules dSph in the context of other elongated dSphs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Position-Velocity Diagrams for the Maser Emission coming from a\n  Keplerian Ring. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0819, "human_text": "  We have studied the maser emission from a thin, planar, gaseous ring in\nKeplerian rotation around a central mass observed edge-on. The absorption\ncoefficient within the ring is assumed to follow a power law dependence with\nthe distance from the central mass as, k=k0r^{-q}. We have calculated\nposition-velocity diagrams for the most intense maser features, for different\nvalues of the exponent q. We have found that, depending on the value of q,\nthese diagrams can be qualitatively different. The most intense maser emission\nat a given velocity can either come mainly from regions close to the inner or\nouter edges of the amplifying ring or from the line perpendicular to the line\nof sight and passing through the central mass (as is commonly assumed).\nParticularly, when q>1 the position-velocity diagram is qualitatively similar\nto the one observed for the water maser emission in the nucleus of the galaxy\nNGC 4258. In the context of this simple model, we conclude that in this object\nthe absorption coefficient depends on the radius of the amplifying ring as a\ndecreasing function, in order to have significant emission coming from the\ninner edge of the ring.\n", "machine_text": "\n\nWe present here the analysis of the position-velocity diagrams for the Maser emission coming from a Keplerian ring. Our analysis shows that such diagrams are sensitive to the three-dimensional structure of the background stars and the masing region. We have developed a model which allows us to study the structure of the rings from the analysis of the diagrams, in the same way as has been done for the colliding-wind binary stars. The model consists in considering that the masers are located on an evacuated circular ring, which is being distorted by the gravitational field of the central star. We have compared the model predictions with the data for the circle overlaid on the HSQSO field, and found a good agreement between the two. We have also compared the results of the model with the data for the POSS Ring. Our analysis shows that the data can be described within the framework of the model, if the ring is not distorted, but is rather slightly displaced towards the North-West. We discuss this result in the framework of a possible three-dimensional structure for the POSS Ring, involving a collision between two rings.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The dust temperatures of the prestellar cores in the rho Oph main cloud\n  and in other star forming regions: consequences for the core mass function. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2941, "human_text": "  We estimate the dust temperatures of the clumps in the rho Oph main cloud\ntaking into account the 3D geometry of the region, and external heating from\nthe interstellar radiation field and from HD147879,a nearby luminous B2V star,\nwhich is believed to dominate the radiation field in the region. We find that\nthe regions where prestellar cores are observed (i.e. at optical visual\nextinctions >7 mag) are colder than ~10-11K. These dust temperatures are\nsmaller than those which previous studies of the same region have assumed. We\nuse the new dust temperatures to estimate the masses of the prestellar cores in\nthe rho Oph main cloud from mm observations, and we find core masses that are\nlarger than previous estimates by a factor of ~2-3. This affects the core mass\nfunction (CMF) of the region; we find that the mass at which the core mass\nspectrum steepens from a slope alpha~1.5 to a slope alpha~2.5 has moved from\n~0.5 Msun to ~1Msun. In contrast with the CMF in other star forming regions\n(e.g. Orion), there is no indication for a turnover down to the completeness\nlimit (~0.2Msun), but the CMF may flatten at around ~0.4Msun. We generalize our\nresults to the prestellar cores in Taurus and in Orion. In Taurus the ambient\nradiation field heating the prestellar cores is believed to be weaker than than\nthat in rho Oph. Hence, the dust temperatures of the cores in Taurus are\nexpected to be below ~ 10-11 K.In Orion the radiation field is believed to be\n10^3 times stronger than the standard interstellar radiation field. Based on\nthis assumption we estimate that the dust temperatures of the prestellar cores\nin Orion are around ~20-30K.\n", "machine_text": "\n\nWe present observations of the dust temperatures of the prestellar cores in the rho Ophiuchi main cloud and in other star forming regions. The data were obtained with the heterodyne LiFT instrument, mounted on the Herschel-IRS instrument on the Herschel Space Telescope, during the Herschel Open Time Programme \"The Dust Temperature of Pre-Stellar Cores\" (HOPT 34). The observations consist of 23 galaxies in the Local Volume Experiment (LVE) and four clouds in the Orion region: the rho Ophiuchi main cloud, the Orion molecular cloud, the Running Man Nebula, and the Cartwheel Nebula. We find that the core mass function in the rho Ophiuchi main cloud follows the Salpeter function with a core mass of $1-3M_{\\odot}$ and a Salpeter parameter $\\alpha_{\\rm{core}}\\sim 2.5$, while the core mass function in the Orion region follows the Kruckenberg function with a core mass of $0.2-1M_{\\odot}$ and a Salpeter parameter $\\alpha_{\\rm{core}}\\sim 1.5$. This implies that the rho Ophiuchi main cloud has a lower mass than the Orion region, which is in agreement with other independent observations. We also find that the temperatures in the cores are correlated with the local metallicity, with the cores in the Galactic plane (Z=0.001-0.02) being on average warmer than the cores in the extragalactic clouds (Z=0.0001-0.001).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Excluded volume, local structural cooperativity,and the polymer physics\n  of protein folding rates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0185, "human_text": "  A coarse-grained variational model is used to investigate the polymer\ndynamics of barrier crossing for a diverse set of two-state folding proteins.\nThe model gives reliable folding rate predictions provided excluded volume\nterms that induce minor structural cooperativity are included in the\ninteraction potential. In general, the cooperative folding routes have sharper\ninterfaces between folded and unfolded regions of the folding nucleus and\nhigher free energy barriers. The calculated free energy barriers are strongly\ncorrelated with native topology as characterized by contact order. Increasing\nthe rigidity of the folding nucleus changes the local structure of the\ntransition state ensemble non-uniformly across the set of protein studied.\nNeverthless, the calculated prefactors k0 are found to be relatively uniform\nacross the protein set, with variation in 1/k0 less than a factor of five. This\ndirect calculation justifies the common assumption that the prefactor is\nroughly the same for all small two-state folding proteins. Using the barrier\nheights obtained from the model and the best fit monomer relaxation time 30ns,\nwe find that 1/k0 (1-5)us (with average 1/k0 4us). This model can be extended\nto study subtle aspects of folding such as the variation of the folding rate\nwith stability or solvent viscosity, and the onset of downhill folding.\n", "machine_text": "\nWe introduce a simple physical model of excluded volume and local structural cooperativity to study the effects of these factors on the polymer physics of protein folding. Our results show a direct, qualitative connection between excluded volume and the polymer physics of protein folding, in terms of the behavior of the freely-jointed chain model. We show that excluded volume is equivalent to a increase of the internal energy of the freely-jointed chain model, that is, a positive bend energy. We derive a simple approximation for the effect of excluded volume on the folding rate, which we term the \"local cooperativity approximation\". This approximation is exact for a large class of simple protein structures. Our results show that the folding rate is proportional to the square of the number of residues in the protein, which is consistent with the observation that proteins with a larger number of residues fold more slowly. We also show that proteins with a higher local cooperativity fold more slowly. Our results suggest that local structural cooperativity and excluded volume are the dominant factors in the polymer physics of protein folding, and they have a large impact on the folding rates of proteins.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: First proper motions of thin dust filaments at the Galactic Center. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3675, "human_text": "  Context: L'-band (3.8 micron) images of the Galactic Center show a large\nnumber of thin filaments in the mini-spiral, located west of the mini-cavity\nand along the inner edge of the Northern Arm. One possible mechanism that could\nproduce such structures is the interaction of a central wind with the\nmini-spiral. Additionally, we identify similar features that appear to be\nassociated with stars. Aims: We present the first proper motion measurements of\nthe thin dust filaments observed in the central parsec around SgrA* and\ninvestigate possible mechanisms that could be responsible for the observed\nmotions. Methods: The observations have been carried out using the NACO\nadaptive optics system at the ESO VLT. The images have been transformed to a\ncommon coordinate system and features of interest were extracted. Then a\ncross-correlation technique could be performed in order to determine the\noffsets between the features with respect to their position in the reference\nepoch. Results: We derive the proper motions of a number of filaments and 2\ncometary shaped dusty sources close (in projection) to SgrA*. We show that the\nshape and the motion of the filaments does not agree with a purely Keplerian\nmotion of the gas in the potential of the supermassive black hole at the\nposition of SgrA*. Therefore, additional mechanisms must be responsible for\ntheir formation and motion. We argue that the properties of the filaments are\nprobably related to an outflow from the disk of young mass-losing stars around\nSgrA*. In part, the outflow may originate from the black hole itself. We also\npresent some evidence and theoretical considerations that the outflow may be\ncollimated.\n", "machine_text": "\n\nFirst proper motions of thin dust filaments at the Galactic Center\nThe structure and dynamics of the Galactic Center are important clues to understanding the evolution of our Galaxy. We present proper motion measurements for 34 thin dust filaments (tdf) in the Galactic Center region using data from the Two Micron All Sky Survey and the SDSS. The tdfs have ages on the order of 10 Myr and their proper motions are between 2 and 8 km/s. We find that the younger tdfs (ages $< 1.5$ Gyr) have proper motions that are systematically higher than the older tdfs, with a mean excess of $\\sim 3$ km/s. We also find that the proper motion distribution of the tdfs is different from that of the Galactic stars, with a higher fraction of tdfs having proper motions in the range $-1$ to $+1$ km/s. This may indicate that the tdfs have a different origin than the Galactic disk, and it may imply a Galactic breakup event in the past. We discuss our results in the context of models for the formation and evolution of the Galactic Center.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Compact X-ray Source 1E 1547.0-5408 and the Radio Shell\n  G327.24-0.13: A New Proposed Association between a Candidate Magnetar and a\n  Candidate Supernova Remnant. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1054, "human_text": "  We present X-ray, infrared and radio observations of the field centered on\nX-ray source 1E 1547.0-5408 in the Galactic Plane. A new Chandra observation of\nthis source shows it is unresolved at arc-second resolution, and a new XMM\nobservation shows that its X-ray spectrum is best described by an absorbed\npower-law and blackbody model. A comparison of the X-ray flux observed from\nthis source between 1980 and 2006 reveals that its absorbed 0.5-10 keV X-ray\nflux decreased from ~2x10^-12 ergs cm-2 s-1 to ~3x10^-13 ergs cm-2 during this\nperiod. The most recent XMM observation allows us to put a 5 sigma confidence\nupper limit of 14% for the 0.5-10 keV peak-to-peak pulsed fraction. A\nnear-infrared observation of this field shows a source with magnitude Ks =\n15.9+/-0.2 near the position of 1E 1547.0-5408, but the implied X-ray to\ninfrared flux ratio indicates the infrared emission is from an unrelated field\nsource, allowing us to limit the IR magnitude of 1E 1547.0-5408 to >17.5.\nArchival radio observations reveal that 1E 1547.0-5408 sits at the center of a\nfaint, small (4' diameter) radio shell, G327.24-0.13, which is possibly a\npreviously unidentified supernova remnant. The X-ray properties of 1E\n1547.0-5408 suggest that this source is a magnetar - a young neutron star whose\nX-ray emission is powered by the decay of its extremely strong magnetic field.\nThe spatial coincidence between this source and G327.24-0.13 suggests that 1E\n1547.0-5408 is associated with a young supernova remnant, supporting a neutron\nstar interpretation. Additional observations are needed to confirm the nature\nof both 1E 1547.0-5408 and G327.24-0.13, and to determine if these sources are\nassociated. If so, this pair will be an important addition to the small number\nof known associations between magnetars and supernova remnants.\n", "machine_text": "\nWe present new observations of the candidate magnetic white dwarf 1E 1547.0-5408 and the nearby supernova remnant G327.24-0.13, which together form the X-ray transient designated CompXsr1. We find that the white dwarf's spin-down power is consistent with a relatively long spin period of 41.3 ms, and we show that the accretion rate has decreased by a factor of 4 since the source was discovered in August 2013. These observations are consistent with a scenario in which the accretion onto the white dwarf has ceased, in spite of the continued presence of an accretion disc around the white dwarf. We propose that the supernova remnant G327.0-0.13 is the probable origin of the CompXsr1 outburst, and that the supernova explosion has pushed the white dwarf to the edge of the remnant, causing the white dwarf to begin accreting matter from the remnant. This is consistent with the observed radial distribution of the radio emission from G327.0-0.13, which is elongated along the direction of the white dwarf's orbit around the remnant. We show that a previously proposed association between the white dwarf 1E 1547.0-5408 and the young stellar object 1E 22594500-613 cannot be correct, on the basis of both the white dwarf's spin period and the relative motions of the white dwarf and the young stellar object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A double main sequence turn-off in the rich star cluster NGC 1846 in the\n  Large Magellanic Cloud. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.336, "human_text": "  We report on HST/ACS photometry of the rich intermediate-age star cluster NGC\n1846 in the Large Magellanic Cloud, which clearly reveals the presence of a\ndouble main sequence turn-off in this object. Despite this, the main sequence,\nsub-giant branch, and red giant branch are all narrow and well-defined, and the\nred clump is compact. We examine the spatial distribution of turn-off stars and\ndemonstrate that all belong to NGC 1846 rather than to any field star\npopulation. In addition, the spatial distributions of the two sets of turn-off\nstars may exhibit different central concentrations and some asymmetries. By\nfitting isochrones, we show that the properties of the colour-magnitude diagram\ncan be explained if there are two stellar populations of equivalent metal\nabundance in NGC 1846, differing in age by approximately 300 Myr. The absolute\nages of the two populations are ~1.9 and ~2.2 Gyr, although there may be a\nsystematic error of up to +/-0.4 Gyr in these values. The metal abundance\ninferred from isochrone fitting is [M/H] ~ -0.40, consistent with spectroscopic\nmeasurements of [Fe/H]. We propose that the observed properties of NGC 1846 can\nbe explained if this object originated via the tidal capture of two star\nclusters formed separately in a star cluster group in a single giant molecular\ncloud. This scenario accounts naturally for the age difference and uniform\nmetallicity of the two member populations, as well as the differences in their\nspatial distributions.\n", "machine_text": "\nWe present photometric and spectroscopic observations of the rich star cluster NGC 1846 in the Large Magellanic Cloud. Our main result is the detection of a double main sequence turn-off in the cluster. The main sequence in stellar clusters is defined by the relationship between the spectral type and the effective temperature of a star. The main sequence turn-off (MSTO) is the point where the most massive stars become too hot to produce hydrogen fusion in their cores and are therefore no longer on the main sequence. These very massive stars then become supergiants. We found a significant overabundance of massive supergiant stars in NGC 1846. The cluster is young, so the massive stars are still in the main sequence. Therefore, the MSTO must have been reached recently, which implies that the massive stars have been burning for a shorter time than the lower mass stars. The observed MSTO, together with the cluster's young age, therefore suggests a two-fold process of star formation in NGC 1846: first the low-mass stars formed, and then the massive stars formed later. We discuss our results in the framework of simple theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hot Jupiters in binary star systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0732, "human_text": "  Radial velocity surveys find Jupiter mass planets with semi-major axes a less\nthan 0.1 AU around ~1% of solar-type stars; counting planets with $a$ as large\nas 5 AU, the fraction of stars having planets reaches ~ 10% {Marcy,Butler}. An\nexamination of the distribution of semi-major axes shows that there is a clear\nexcess of planets with orbital periods around 3 or 4 days, corresponding to\na~0.03$ AU, with a sharp cutoff at shorter periods (see Figure 1). It is\nbelieved that Jupiter mass planets form at large distances from their parent\nstars; some fraction then migrate in to produce the short period objects. We\nargue that a significant fraction of the `hot Jupiters' (a<0.1 AU) may arise in\nbinary star systems in which the orbit of the binary is highly inclined to the\norbit of the planet. Mutual torques between the two orbits drive down the\nminimum separation or periapse r_p between the planet and its host star (the\nKozai mechanism). This periapse collapse is halted when tidal friction on the\nplanet circularizes the orbit faster than Kozai torque can excite it. The same\nfriction then circularizes the planet orbit, producing hot Jupiters with the\npeak of the semimajor axis distribution lying around 3 days. For the observed\ndistributions of binary separation, eccentricity and mass ratio, roughly 2.5%\nof planets with initial semimajor axis a_p ~ 5au will migrate to within 0.1au\nof their parent star. Kozai migration could account for 10% or more of the\nobserved hot Jupiters.\n", "machine_text": "\n\nHot Jupiters in binary star systems\nWe present phase-resolved spectroscopy and photometry of the giant planets in the hot Jupiter systems TWA 5 and TWA 7. The observations were made with the Hubble Space Telescope (HST) during the course of the Hubble Outer Planet Quest (OPQ) program. We find that both giants are inflated hot Jupiters, with equilibrium temperatures of \u22481000 K and \u22481280 K for TWA 5b and TWA 7b, respectively. The measured angular sizes of the giants are in good agreement with those obtained from models in which the giants are treated as perfect gases, but in disagreement with models in which the effects of interior structure are included. The radii of both giants are larger than predicted by theoretical models, but this discrepancy can be explained by small-scale mixing of heavy elements in the interior. We find that the kinematics of the giant planets are consistent with a perfectly coplanar orbit, and thus the giant planets in these systems do not exhibit significant orbital decay. We discuss these findings in the context of hot Jupiter system evolution, and consider the prospects for observing giant planet thermodynamics with the upcoming James Webb Space Telescope.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mapping the Youngest Galaxies to Redshift One. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0643, "human_text": "  We describe results of a narrow band search for ultra-strong emission line\ngalaxies (USELs) with EW(H beta) > 30 A. 542 candidate galaxies are found in a\nhalf square degree survey using two ~100 Angstrom 8150 A and 9140 A filters\nwith Subaru/SuprimeCam. Followup spectroscopy for randomly selected objects in\nthe sample with KeckII/DEIMOS shows they consist of [OIII] 5007, [OII] 3727,\nand H alpha selected strong-emission line galaxies at intermediate redshifts (z\n< 1), and Ly alpha emitting galaxies at high-redshift (z >> 5). We determine\nthe H beta luminosity functions and the star formation density of the USELs,\nwhich is 5-10% of the value found from ultraviolet continuum objects at z=0-1,\nsuggesting they correspond to a major epoch in galaxy formation at these\nredshifts. Many USELs show the temperature-sensitive [OIII] 4363 auroral lines\nand about a dozen have oxygen abundances characteristic of eXtremely Metal Poor\nGalaxies (XMPGs). These XMPGs are the most distant known today. Our high yield\nrate of XMPGs suggests this is a powerful method for finding such populations.\nThe lowest metallicity measured in our sample is 12+log(O/H) = 7.06\n(6.78-7.44), close to the minimum metallicity found in local galaxies. The\nluminosities, metallicities and star formation rates of USELs are consistent\nwith the strong emitters being start-up intermediate mass galaxies and suggest\nthat galaxies are still forming in relatively chemically pristine sites at z <\n1.\n", "machine_text": "\n\nMapping the Youngest Galaxies to Redshift One\n\nWe present the results of a narrow band imaging survey for galaxies in the first year of the Universe. We describe the motivation for the research, the key ideas and methodology, the results obtained, the problem the work attempts to solve and any practical or theoretical applications from the findings or implications for future research.\n\nThe first galaxies in the Universe are thought to have formed during the Epoch of Reionization, a period that spanned from the end of the Neutral Era, when the Universe was filled with hydrogen and helium atoms, to the period when the first galaxies were forming. We present the results of a narrow band imaging survey for galaxies in the first year of the Universe. Our survey uses narrow band filters, in the range of $8 - 10 \\AA, and a 3'x3' field of view to search for galaxies in the first hundred million years of the Universe. We find three galaxies in our survey that are candidate galaxies from this era. We determine the redshift of these galaxies to be between $z=8.6 - 10.4$. These galaxies are found in a region of the sky that is richest in the intergalactic hydrogen gas that was the target of the Hubble Deep Field survey. Our galaxies are much fainter than the galaxies found by Hubble, which are at redshifts of $z \\sim 1.5$. This implies that galaxies were still forming in relatively chemically pristine sites at these high redshifts. We discuss the implications of these galaxies on the epoch of reionization and the future of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complex marginal deformations of D3-brane geometries, their Penrose\n  limits and giant gravitons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2067, "human_text": "  We apply the Lunin--Maldacena construction of gravity duals to beta-deformed\ngauge theories to a class of Type IIB backgrounds with U(1)^3 global symmetry,\nwhich include the multicenter D3-brane backgrounds dual to the Coulomb branch\nof N=4 super Yang-Mills and the rotating D3-brane backgrounds dual to the\ntheory at finite temperature and chemical potential. After a general\ndiscussion, we present the full form of the deformed metrics for three special\ncases, which can be used for the study of various aspects of the\nmarginally-deformed gauge theories. We also construct the Penrose limits of the\nsolutions dual to the Coulomb branch along a certain set of geodesics and, for\nthe resulting PP--wave metrics, we examine the effect of beta-deformations on\nthe giant graviton states. We find that giant gravitons exist only up to a\ncritical value of the sigma-deformation parameter, are not degenerate in energy\nwith the point graviton, and remain perturbatively stable. Finally, we probe\nthe sigma-deformed multicenter solutions by examining the static heavy-quark\npotential by means of Wilson loops. We find situations that give rise to\ncomplete screening as well as linear confinement, with the latter arising is an\nintriguing way reminiscent of phase transitions in statistical systems.\n", "machine_text": "\nWe consider the geometry of certain complex structures in D3-branes, which are non-trivial generalizations of Calabi-Yau or Anti-de Sitter 3-branes. These structures can be thought of as arising from creating an edge or a handle on a D3-brane. We show that, although the bulk geometry is not changed by these manipulations, the field theory on the boundary of the brane is dramatically altered. In particular, we show that these geometries are related to certain Limit Deformations of D3-branes which are known to have enormous practical importance in string theory. We show that the bulk geometry of these Limit Deformations is related to the bulk geometry of the original D3-branes in a natural way, and that the field theory on the boundary is related to the geometry of the original D3-brane in a rather more complicated fashion. In the case that the D3-brane is a Calabi-Yau brane, we show that the related Limit Deformation is a giant graviton with a (possibly complex) radius which is directly related to the (real) volume of the original Calabi-Yau brane. We also consider the case of an Anti-de Sitter brane, and show that the related Limit Deformation is a giant graviton with a real radius which is directly related to the (real) volume of the original Anti-de Sitter brane. We finally discuss some open questions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Shelling-type orderings of regular CW-complexes and acyclic matchings of\n  the Salvetti complex. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3107, "human_text": "  Motivated by the work of Salvetti and Settepanella we introduce certain total\norderings of the faces of any shellable regular CW-complex (called\n`shelling-type orderings') that can be used to explicitly construct maximum\nacyclic matchings of the poset of cells of the given complex. Building on an\napplication of this method to the classical zonotope shellings we describe a\nclass of maximum acyclic matchings for the Salvetti complex of a linear\ncomplexified arrangement. To do this, we introduce and study a new\ncombinatorial stratification of the Salvetti complex. For the obtained acyclic\nmatchings we give an explicit description of the critical cells that depends\nonly on the chosen linear extension of the poset of regions. It is always\npossible to choose the linear extension so that the critical cells can be\nexplicitly constructed from the chambers of the arrangement via the bijection\nto no-broken-circuit sets defined by Jewell and Orlik. Our method can be\ngeneralized to arbitraty oriented matroids.\n", "machine_text": "\n\nWe study the category of shellable ordering of finite regular CW-complexes and the category of acyclic matchings of the Salvetti complex. We show that these two categories are equivalent. As a byproduct, we give a description of the category of shellable orderings in terms of rational numbers.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Star-forming Region NGC 346 in the Small Magellanic Cloud with\n  Hubble Space Telescope ACS Observations. II. Photometric Study of the\n  Intermediate-Age Star Cluster BS 90. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2942, "human_text": "  We present the results of our investigation of the intermediate-age star\ncluster BS 90, located in the vicinity of the HII region N 66 in the SMC,\nobserved with HST/ACS. The high-resolution data provide a unique opportunity\nfor a very detailed photometric study performed on one of the rare\nintermediate-age rich SMC clusters. The complete set of observations is\ncentered on the association NGC 346 and contains almost 100,000 stars down to V\n~28 mag. In this study we focus on the northern part of the region, which\ncovers almost the whole stellar content of BS 90. We construct its stellar\nsurface density profile and derive structural parameters. Isochrone fits on the\nCMD of the cluster results in an age of about 4.5 Gyr. The luminosity function\nis constructed and the present-day mass function of BS 90 has been obtained\nusing the mass-luminosity relation, derived from the isochrone models. We found\na slope between -1.30 and -0.95, comparable or somewhat shallower than a\ntypical Salpeter IMF. Examination of the radial dependence of the mass function\nshows a steeper slope at larger radial distances, indicating mass segregation\nin the cluster. The derived half-mass relaxation time of 0.95 Gyr suggests that\nthe cluster is mass segregated due to its dynamical evolution. From the\nisochrone model fits we derive a metallicity for BS 90 of [Fe/H]=-0.72, which\nadds an important point to the age-metallicity relation of the SMC. We discuss\nour findings on this relation in comparison to other SMC clusters.\n", "machine_text": "\n\nWe present a photometric study of the intermediate-age star cluster BS 90 in the star-forming region NGC 346 in the Small Magellanic Cloud. We used archival Hubble Space Telescope/Advanced Camera for Surveys observations of cluster members and HST/WFPC2 images of the ionization structure to select a subset of 72 cluster members in the field which are free from the influence of the ionization structure. We then obtained high-resolution echelle spectra of these objects with the Hubble Space Telescope/High Resolution Spectrograph and used the resulting absolute photometry to investigate the cluster properties. We find that the cluster is at an intermediate age between the young (log(T/yr) \u223c 8) and old (log(T/yr) \u223c 4) clusters in the region. We estimate the cluster age to be log(T/yr) \u223c 6.2 \u00b1 1.1, assuming a distance to the Small Magellanic Cloud of 50 \u00b1 5 kpc. We find that the cluster is coeval with the superbubbles and contains a relatively large number of Wolf-Rayet stars. The cluster has a power law density distribution with a radial scale of 1.4 \u00b1 0.1 kpc. We discuss the cluster in the context of recent theories of star formation in OB associations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Single Transverse-Spin Asymmetry in Hadronic Dijet Production. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1196, "human_text": "  We study the single transverse-spin asymmetry for dijet production in\nhadronic collisions in both the collinear QCD factorization approach and the\nBrodsky-Hwang-Schmidt model. We show that a nonvanishing asymmetry is generated\nby both initial-state and final-state interactions, and that the final-state\ninteractions dominate. We find that in the leading kinematic region where the\ntransverse momentum imbalance of the two jets, q_\\perp = P_{1\\perp}+P_{2\\perp},\nis much less than the momentum of either jet, the contribution from the lowest\nnon-trivial perturbative order to both the spin-averaged and the spin-dependent\ndijet cross sections can be factorized into a hard part that is a function only\nof the averaged jet momentum P_\\perp = (P_{1\\perp}-P_{2\\perp})/2, and\nperturbatively generated transverse momentum dependent (TMD) parton\ndistributions. We show that the spin asymmetry at this non-trivial perturbative\norder can be described by the TMD parton distributions defined in either\nsemi-inclusive DIS or the Drell-Yan process. We derive the same hard parts from\nboth the collinear factorization approach and in the context of the\nBrodsky-Hwang-Schmidt model, verifying that they are not sensitive to details\nof the factorized long distance physics.\n", "machine_text": "\nWe present the first three-dimensional measurement of the transverse-spin asymmetry (TSA) in hadronic Dijet production in the forward region, at a longitudinal momentum distribution of the Dijet pairs in the range 0.4<p_T<1.1 GeV/c, and an average Dijet pair production rate of 3.3 events per \u03bcB\u00b7GeV. We use a data sample collected with the BaBar detector at the PEP2 storage ring, corresponding to 232 million $ppbar$ pairs. The results are consistent with the hypothesis that the TSA is related to the three-dimensional structure of the produced hadrons, in that it is larger for more compact systems. We show that the TSA is consistent with the hadron pairs being produced by a direct collision between the $ppbar$ pairs, with a TSA of $(0.09\\pm 0.09) \\times 10^{-3}$ and a relative TSA magnitude of $0.71\\pm 0.03$. This is in agreement with theoretical predictions based on the semi-classical Boltzmann equation. We also present evidence that the TSA is smaller when the hadron pairs are produced by an intermediate hadron, with a TSA of $(0.38\\pm 0.17) \\times 10^{-3}$ and a relative TSA magnitude of $0.91\\pm 0.09$. We discuss the results in the framework of the standard quark model and show that a quarkonia-inspired model with an additional quark degree of freedom can also explain our data without any fine-tuning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Black-body components in Gamma-Ray Bursts spectra?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3438, "human_text": "  We study 7 Gamma Ray Bursts (GRBs), detected both by the BATSE instrument,\non-board the Compton Gamma Ray Observatory, and by the Wide Field Camera (WFC),\non-board BeppoSAX. These bursts have measured spectroscopic redshifts and are a\nsizeable fraction of the bursts defining the correlation between the peak\nenergy E_peak (i.e. the peak of the vFv spectrum) and the total prompt\nisotropic energy E_iso (the so called \"Amati\" relation). Recent theoretical\ninterpretations of this correlation assume that black-body emission dominates\nthe time resolved spectra of GRBs, even if, in the time integrated spectrum,\nits presence may be hidden by the change of its temperature and by the dilution\nof a possible non-thermal power law component. We perform a time resolved\nspectral analysis, and show that the sum of a power-law and a black-body gives\nacceptable fits to the time dependent spectra within the BATSE energy range,\nbut overpredicts the flux in the WFC X-ray range. Moreover, a fit with a cutoff\npower-law plus a black-body is consistent with the WFC data, but the black-body\ncomponent contributes a negligible fraction of the total flux. On the contrary,\nwe find that fitting the spectra with a Band model or a simple cutoff power-law\nmodel yields an X-ray flux and spectral slope which well matches the WFC\nspectra.\n", "machine_text": "\n\nWe find that a black-body model can successfully describe the non-Fluke spectrum of a Gamma-Ray Burst (GRB) if the burst has a spectral index that is generally greater than -1. This result is consistent with a simple physical model in which the black-body radiation is due to thermal re-radiation from the photosphere, and the cut-off power-law component is due to simple geometric effects. We have derived a simple analytic expression for the cut-off power-law component in terms of the black-body temperature, the burst's spectral index, and a parameter which represents the geometric truncation of the spectrum. We find that this parameter has a value between 1 and 2 for all observed GRBs, and take this to be an indication that the emission region has a generally Gaussian size distribution. This has implications for models in which the burst emission region is tightly coupled to the surrounding accretion disc. We show that a simple black-body model can provide a good description of the observed GRB spectra without the need to invoke either a fluke component or a cut-off power-law component, and discuss the implications of this for the physical models of GRB emission regions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal inertia of near-Earth asteroids and implications for the\n  magnitude of the Yarkovsky effect. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1915, "human_text": "  Thermal inertia determines the temperature distribution over the surface of\nan asteroid and therefore governs the magnitude the Yarkovsky effect. The\nlatter causes gradual drifting of the orbits of km-sized asteroids and plays an\nimportant role in the delivery of near-Earth asteroids (NEAs) from the main\nbelt and in the dynamical spreading of asteroid families. At present, very\nlittle is known about the thermal inertia of asteroids in the km size range.\nHere we show that the average thermal inertia of a sample of NEAs in the\nkm-size range is 200 $\\pm$ 40 J m&#8722;2 s&#8722;0.5 K&#8722;1. Furthermore,\nwe identify a trend of increasing thermal inertia with decreasing asteroid\ndiameter, D. This indicates that the dependence of the drift rate of the\norbital semimajor axis on the size of asteroids due to the Yarkovsky effect is\na more complex function than the generally adopted D^(&#8722;1) dependence, and\nthat the size distribution of objects injected by Yarkovsky-driven orbital\nmobility into the NEA source regions is less skewed to smaller sizes than\ngenerally assumed. We discuss how this fact may help to explain the small\ndifference in the slope of the size distribution of km-sized NEAs and main-belt\nasteroids.\n", "machine_text": "\n\nThermal inertia of near-Earth asteroids and implications for the magnitude of the Yarkovsky effect\n\nThe Yarkovsky effect describes the small but steady force that affects the orbit of a small near-Earth asteroid (NEA) due to the asteroid's gradual rotation and the change in the amount of sunlight absorbed on its surface. Scientists have been able to estimate the Yarkovsky effect for most NEAs. However, the thermal inertia of the surface of a large NEA can be very high, especially for those with a thick regolith layer, which makes the calculation of the Yarkovsky effect more uncertain. \n\nWe use a simple model to investigate the effects of thermal inertia on the Yarkovsky effect. We consider the case of an NEA with a regolith layer several meters thick. We find that the standard method used to estimate the Yarkovsky effect yields a larger value for an object with high thermal inertia than for one with low thermal inertia. We show that this is due to the standard method failing to take into account the cooling rate of the interior of the object. We correct this deficiency and show that the corrected Yarkovsky effect for an object with high thermal inertia is in fact smaller than for an object with low thermal inertia. We also investigate the effect of surface thermal inertia on the spin-up rate of an NEA, due to the Yarkovsky effect, and find that this is very small.\n\nWe conclude that the Yarkovsky effect is not likely to have a large effect on the orbits of large, high-thermal-inertia NEAs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Particle-vibration coupling within covariant density functional theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1044, "human_text": "  Covariant density functional theory, which has so far been applied only\nwithin the framework of static and time dependent mean field theory is extended\nto include Particle-Vibration Coupling (PVC) in a consistent way. Starting from\na conventional energy functional we calculate the low-lying collective\nvibrations in Relativistic Random Phase Approximation (RRPA) and construct an\nenergy dependent self-energy for the Dyson equation. The resulting\nBethe-Salpeter equation in the particle-hole ($ph$) channel is solved in the\nTime Blocking Approximation (TBA). No additional parameters are used and double\ncounting is avoided by a proper subtraction method. The same energy functional,\ni.e. the same set of coupling constants, generates the Dirac-Hartree\nsingle-particle spectrum, the static part of the residual $ph$-interaction and\nthe particle-phonon coupling vertices. Therefore a fully consistent description\nof nuclear excited states is developed. This method is applied for an\ninvestigation of damping phenomena in the spherical nuclei with closed shells\n$^{208}$Pb and $^{132}$Sn. Since the phonon coupling terms enrich the RRPA\nspectrum with a multitude of $ph\\otimes$phonon components a noticeable\nfragmentation of the giant resonances is found, which is in full agreement with\nexperimental data and with results of the semi-phenomenological\nnon-relativistic approach.\n", "machine_text": "\nWe propose a modification to the covariant density functional theory (CDFT) that enables the treatment of small vibrations in the presence of a finite array of point-like scatterers. The motivation for this work is the problem of particle-vibration coupling in photonic crystals, where the oscillations of the semiconductor lattice are driven by the presence of acoustic waves, and the resulting lattice vibrations scatter light. We show that the standard CDFT Hamiltonian is ill-defined when the array of scatterers is finite, because the expansion in the basis of the reciprocal space is incomplete. Our modification remedies this problem by introducing a finite basis set of non-periodic reciprocal space functions that are in one-to-one correspondence with the finite array of scatterers. Within this basis set, we can expand the reciprocal space- bathecd field in a complete set of orthogonal functions that are in general not eigenvectors of the Hamiltonian. The use of this general basis set enables us to evaluate the two-particle correlation functions, and to quantify the effect of the vibrations on the transport properties of the system. We show that our method is applicable to both finite and infinite systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: National Scientific Facilities and Their Science Impact on\n  Non-Biomedical Research. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1797, "human_text": "  H-index, proposed by Hirsch is a good indicator of the impact of a\nscientist's research. When evaluating departments, institutions or labs, the\nimportance of h-index can be further enhanced when properly calibrated for\nsize. Particularly acute is the issue of federally funded facilities whose\nnumber of actively publishing scientists frequently dwarfs that of academic\ndepartments. Recently Molinari and Molinari developed a methodology that shows\nthe h-index has a universal growth rate for large numbers of papers, allowing\nfor meaningful comparisons between institutions.\n  An additional challenge when comparing large institutions is that fields have\ndistinct internal cultures, with different typical rates of publication and\ncitation; biology is more highly cited than physics, which is more highly cited\nthan engineering. For this reason, this study has focused on the physical\nsciences, engineering, and technology, and has excluded bio-medical research.\nComparisons between individual disciplines are reported here to provide\ncontextual framework. Generally, it was found that the universal growth rate of\nMolinari and Molinari holds well across all the categories considered,\ntestifying to the robustness of both their growth law and our results.\n  The overall goal here is to set the highest standard of comparison for\nfederal investment in science; comparisons are made with the nations preeminent\nprivate and public institutions. We find that many among the national\nfacilities compare favorably in research impact with the nations leading\nuniversities.\n", "machine_text": "\nWe have developed a suite of analyses to better understand the science impacts of national scientific facilities (NSF), a major category of big science infrastructure. We have identified a wide variety of impacts, including both intended and unintended impacts, that are both scientific and non-scientific in nature. We find that the largest facilities have the greatest impacts, in terms of both the number and the size of the impacts. We have identified a variety of factors that are associated with larger impacts, including the presence of in-house staff scientists, the use of competitive grant awards to drive the research agenda, the use of partnerships to leverage the facility, the use of a peer review system to allocate facility resources, the engagement of faculty from multiple universities, and the targeting of large-scale, long-term science questions. We also find that a large fraction of the impacts of NSF facilities are difficult to attribute to any particular researcher, laboratory, or institution, suggesting the importance of considering the impacts of facilities as a whole, in addition to the impacts of individual scientists, laboratories, or institutions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmogenic neutrinos as a probe of the transition from Galactic to\n  extragalactic cosmic rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0979, "human_text": "  There are two promising scenarios that explain the ankle, which is a dip in\nthe spectrum of cosmic rays at $\\sim 10^{19}$ eV. A scenario interprets the\nankle as the transition from Galactic to extragalactic cosmic rays ({\\it\nankle-transition scenario}), while the other is that the dip caused by pair\nproduction on the cosmic microwave background radiation ({\\it proton-dip\nscenario}). In this paper, we consider whether cosmogenic neutrinos can be a\nclue to judge which scenario is favored. We calculated the fluxes of cosmogenic\nneutrinos following these scenarios with plausible physical parameter sets, and\nfound several important features as follows. First of all, the neutrino flux at\n$\\sim 10^{20}$ eV becomes much higher in the ankle-transition scenario as long\nas the maximum energy of the cosmic rays at sources is sufficiently high. On\nthe other hand, the neutrino spectrum has a characteristic peak at $\\sim\n10^{16}$ eV in the proton-dip scenario on the condition that extragalactic\nprotons significantly contribute to the observed cosmic rays down to $10^{17}$\neV. Thus, we conclude cosmogenic neutrinos should give us a clue to judge which\nscenario is favored, unless these features are masked by the neutrino\nbackground coming from possible, powerful neutrino sources such as AGNs and\nGRBs. We also found an interesting feature that the neutrino flux at $\\sim\n10^{18}$ eV depends only on the cosmological evolution of the cosmic ray\nsources. That means cosmogenic neutrinos with the energy bring us information\non the cosmological evolution of the sources of ultra-high energy cosmic rays.\nFinally, we compare the fluxes of cosmogenic neutrinos with the expected\nsensitivity curves of several neutrino detectors, and conclude the detection of\ncosmogenic neutrinos in the near future is promising.\n", "machine_text": "\nWe present a new method to determine the relative contribution of the three major sources of cosmic rays (CRs): the sun, the galaxy, and extragalactic objects. The method is based on the detection of cosmogenic neutrinos, which are produced in the neutrino-nucleon collisions that occur as CRs traverse the interstellar medium. We show that, in contrast to the large uncertainty in the current determination of the extragalactic CRs based on the measurement of the helium-3 (3He) abundance in meteorites, the neutrino method provides a direct and precise measurement of the extragalactic component. We evaluate the prospects of detecting the neutrinos with a detector in the ice cap over the Antarctica, and determine the necessary exposure to obtain a precise measurement of the extragalactic CRs. The main scientific motivation of the neutrino method is to provide a precise determination of the transition between the galactic and extragalactic CRs, which is important for the understanding of the formation of the CRs, the interstellar medium, and the chemical evolution of the Galaxy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Light nuclei in galactic globular clusters : constraints on the\n  self-enrichment scenario from nucleosynthesis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3331, "human_text": "  Hydrogen-burning is the root cause of the star-to-star abundance variations\nof light nuclei in Galactic globular clusters (GC). In the present work we\nconstrain the physical conditions that gave rise to the observed abundance\npatterns of Li, C, N, O, Na, Mg, Al, as well as Mg isotopes in the typical case\nof NGC6752. We perform nucleosynthesis calculations at constant temperature,\nadopting realistic initial abundances for the proto-cluster gas. We use a\ndetailed nuclear reaction network and state-of-the-art nuclear reaction rates.\nAlthough simplistic, our analysis provides original results and new constraints\non the self-enrichment scenario for GCs. Our parametrized calculations allow us\nto determine a narrow range of temperature where the observed extreme\nabundances of all light elements and isotopes in NGC6752 are nicely reproduced\nsimultaneously. This agreement is obtained after mixing of the H-processed\nmaterial with 30 % of unprocessed gas. The observed C-N, O-Na, Mg-Al, Li-Na and\nF-Na anticorrelations, as well as the behaviour of the Mg isotopes can be\nrecovered by assuming mixing with even larger dilution factors. Li production\nby the stars that build up the other abundance anomalies is not mandatory in\nthe case of NGC 6752. Observations of O, Na, Mg and Al constrain the\ntemperature range for H-burning; such temperatures are encountered in the two\nmain candidate ``polluters'' proposed for GCs, namely massive AGBs and the most\nmassive main-sequence stars. (Abridged).\n", "machine_text": "\nWe present constraints on the self-enrichment scenario for light nuclei in galactic globular clusters from nucleosynthesis. We consider the chemical evolution of the cluster as a function of the cluster's age and the primordial abundance of the light nuclei. We find that the enrichment process is very fast at the beginning, but that the cluster is still able to retain the signature of its primordial abundance, despite having a different overall composition. This is because the relative abundances of the light nuclei are very well conserved during the evolution of the cluster. The main sinks of the light nuclei are the formation of heavy nuclei and the ejection of the cluster's gas. We also show that the difference between the cluster's primordial and current abundances has a different origin for each light nucleus, and that this origin is related to the size of the clusters. Our results are consistent with the chemical evolution of the clusters being mainly governed by the relative abundances of the light nuclei, and not by the absolute abundances of these nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unequal dimensional small balls and quantization on Grassmann Manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2278, "human_text": "  The Grassmann manifold G_{n,p}(L) is the set of all p-dimensional planes\n(through the origin) in the n-dimensional Euclidean space L^{n}, where L is\neither R or C. This paper considers an unequal dimensional quantization in\nwhich a source in G_{n,p}(L) is quantized through a code in G_{n,q}(L), where p\nand q are not necessarily the same. It is different from most works in\nliterature where p\\equiv q. The analysis for unequal dimensional quantization\nis based on the volume of a metric ball in G_{n,p}(L) whose center is in\nG_{n,q}(L). Our chief result is a closed-form formula for the volume of a\nmetric ball when the radius is sufficiently small. This volume formula holds\nfor Grassmann manifolds with arbitrary n, p, q and L, while previous results\npertained only to some special cases. Based on this volume formula, several\nbounds are derived for the rate distortion tradeoff assuming the quantization\nrate is sufficiently high. The lower and upper bounds on the distortion rate\nfunction are asymptotically identical, and so precisely quantify the asymptotic\nrate distortion tradeoff. We also show that random codes are asymptotically\noptimal in the sense that they achieve the minimum achievable distortion with\nprobability one as n and the code rate approach infinity linearly. Finally, we\ndiscuss some applications of the derived results to communication theory. A\ngeometric interpretation in the Grassmann manifold is developed for capacity\ncalculation of additive white Gaussian noise channel. Further, the derived\ndistortion rate function is beneficial to characterizing the effect of\nbeamforming matrix selection in multi-antenna communications.\n", "machine_text": "\n\nWe show that on a Grassmann manifold the quantization of the symmetric and anti-symmetric Fearless symmetry transformations of the odd-dimensional small balls differs. This answers a question of Denisov- Rocco-S Meyers, but in our setting the result is more general, in the sense that we do not assume that the odd-dimensional balls are contained in the even-dimensional submanifolds.\n\nLet $\\Goo$ be a real Grassmann manifold and let $\\Gmm$ be its symmetric product. We show that the quantization of the symmetric and anti-symmetric Fearless symmetry transformations of the odd-dimensional small balls of $\\Gmm$ differs.\n\nThe idea is to use the Grassmannian description of $\\Gmm$ in terms of the symmetric and anti-symmetric $\\delta$-Neumann functions on $\\Goo$. If $\\Goo$ is the space of symmetric $\\delta$-Neumann functions, then $\\Gmm$ is the Grassmannian of symmetric $\\delta$-Neumann functions, seen as a subspace of the space of symmetric $\\delta$-Neumann functions on $\\Goo^{2}$.\n\nWe give an example of a Grassmann manifold with an anti-symmetric $\\delta$-Neumann function, and show that the quantization of the symmetric and anti-symmetric Fearless symmetry transformations of the odd-dimensional small balls of $\\Gmm$ differs. As an application, we give a description of the odd-dimensional small balls of $\\Gmm$ in terms of the anti-symmetric $\\delta$-Neumann functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Disclinations, dislocations and continuous defects: a reappraisal. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3055, "human_text": "  Disclinations, first observed in mesomorphic phases, are relevant to a number\nof ill-ordered condensed matter media, with continuous symmetries or frustrated\norder. They also appear in polycrystals at the edges of grain boundaries. They\nare of limited interest in solid single crystals, where, owing to their large\nelastic stresses, they mostly appear in close pairs of opposite signs. The\nrelaxation mechanisms associated with a disclination in its creation, motion,\nchange of shape, involve an interplay with continuous or quantized dislocations\nand/or continuous disclinations. These are attached to the disclinations or are\nakin to Nye's dislocation densities, well suited here. The notion of 'extended\nVolterra process' takes these relaxation processes into account and covers\ndifferent situations where this interplay takes place. These concepts are\nillustrated by applications in amorphous solids, mesomorphic phases and\nfrustrated media in their curved habit space. The powerful topological theory\nof line defects only considers defects stable against relaxation processes\ncompatible with the structure considered. It can be seen as a simplified case\nof the approach considered here, well suited for media of high plasticity\nor/and complex structures. Topological stability cannot guarantee energetic\nstability and sometimes cannot distinguish finer details of structure of\ndefects.\n", "machine_text": "\nWe have developed a new method for the determination of dislocations in electron diffraction, based on the analysis of the Kikuchi patterns. The method is sensitive to the dislocation density, independent of the dislocation distribution, and does not require an empirical calibration curve. We have applied the method to a single crystal of YBa2Cu3O7, a good conductor, in which the dislocation density has been previously determined by theReachfug technique. Our results agree with the previous determination, but, in addition, we have found that the dislocations are not distributed randomly, but tend to be arranged in a preferred direction, which we attribute to the influence of the magnetic field. We have also determined the dislocation density in a single crystal of SrTiO3, a bad conductor, and in a polycrystalline sample of YBa2Cu3O7. In both cases, the dislocation density was much higher than in the single crystal. We discuss our results in the framework of the theory of dislocations in ionic crystals.\n\nThe main result of this work is the development of a new method for the determination of dislocations in ionic crystals, based on the analysis of the Kikuchi patterns in electron diffraction. The method is sensitive to the dislocation density, independent of the dislocation distribution, and does not require an empirical calibration curve. We have applied the method to a single crystal of YBa2Cu3O7 and to a single crystal of SrTiO3, and in both cases we have found that the dislocations are not distributed randomly, but tend to be arranged in a preferred direction, which we attribute to the influence of the magnetic field in the case of YBa2Cu3O7, and to the influence of the strain in the case of SrTiO3. We have also determined the dislocation density in a polycrystalline sample of YBa2Cu3O7, and in this case the dislocation density was much higher than in the single crystal. We discuss our results in the framework of the theory of dislocations in ionic crystals.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A New Proof of Pappus's Theorem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3424, "human_text": "  Any stretching of Ringel's non-Pappus pseudoline arrangement when projected\ninto the Euclidean plane, implicitly contains a particular arrangement of nine\ntriangles. This arrangement has a complex constraint involving the sines of its\nangles. These constraints cannot be satisfied by any projection of the initial\narrangement. This is sufficient to prove Pappus's theorem. The derivation of\nthe constraint is via systems of inequalities arising from the polar\ncoordinates of the lines. These systems are linear in r for any given theta,\nand their solubility can be analysed in terms of the signs of determinants. The\nevaluation of the determinants is via a normal form for sums of products of\nsines, giving a powerful system of trigonometric identities. The particular\nresult is generalized to arrangements derived from three edge connected totally\ncyclic directed graphs, conjectured to be sufficient for a complete analysis of\nangle constraining arrangements of lines, and thus a full response to Ringel's\nslope conjecture. These methods are generally applicable to the realizability\nproblem for rank 3 oriented matroids.\n", "machine_text": "\n\nWe present a new and elementary proof of Pappus's theorem, namely that any Pappus system (a system of three circles in general position in the plane such that all three circles are orthogonal to each other) is equivalent to the orthogonal projection of a certain tetrahedron on the plane. Our proof does not use the tools of projective geometry, as do all previous proofs, but proceeds by establishing a one-to-one correspondence between Pappus systems and certain \"off-center\" equilateral triangles. We show that any Pappus system can be obtained from such an \"off-center\" equilateral triangle by a sequence of reflections and rotations, and that this sequence has the same effect on the equilateral triangle as does the orthogonal projection of a tetrahedron onto the plane. Our proof is based on the properties of reflections in circles and on the observation that four reflections in circles, or equivalently, four orthogonal projections of a tetrahedron onto the plane, can be obtained by means of a single isometric reflection in the plane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A rigidity theorem for the mapping class group action on the space of\n  unmeasured foliations on a surface. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1837, "human_text": "  Let $S$ be a surface of finite type which is not a sphere with at most four\npunctures, a torus with at most two punctures, or a closed surface of genus\ntwo. Let $\\mathcal{MF}$ be the space of equivalence classes of measured\nfoliations of compact support on $S$ and let $\\mathcal{UMF}$ be the quotient\nspace of $\\mathcal{MF}$ obtained by identifying two equivalence classes\nwhenever they can be represented by topologically equivalent foliations, that\nis, forgetting the transverse measure. The extended mapping class group\n$\\Gamma^*$ of $S$ acts as by homeomorphisms of $\\mathcal{UMF}$. We show that\nthe restriction of the action of the whole homeomorphism group of\n$\\mathcal{UMF}$ on some dense subset of $\\mathcal{UMF}$ coincides with the\naction of $\\Gamma^*$ on that subset. More precisely, let $\\mathcal{D}$ be the\nnatural image in $\\mathcal{UMF}$ of the set of homotopy classes of not\nnecessarily connected essential disjoint and pairwise nonhomotopic simple\nclosed curves on $S$. The set $\\mathcal{D}$ is dense in $\\mathcal{UMF}$, it is\ninvariant by the action of $\\Gamma^*$ on $\\mathcal{UMF}$ and the restriction of\nthe action of $\\Gamma^*$ on $\\mathcal{D}$ is faithful. We prove that the\nrestriction of the action on $\\mathcal{D}$ of the group\n$\\mathrm{Homeo}(\\mathcal{UMF})$ coincides with the action of $\\Gamma^*(S)$ on\nthat subspace.\n", "machine_text": "\n\nWe prove a rigidity theorem for the mapping class group action on the space of unmeasured foliations on a surface. Let $\\pi:S^1\\to M$ be a covering space action. We show that the induced action on the space of unmeasured foliations is given by a mapping class group element. As an application, we give a description of the fixed points of this action.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Higher K-theory via universal invariants. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.242, "human_text": "  Using the formalism of Grothendieck's derivators, we construct `the universal\nlocalizing invariant of dg categories'. By this, we mean a morphism U_l from\nthe pointed derivator associated with the Morita homotopy theory of dg\ncategories to a triangulated strong derivator M^loc such that U_l commutes with\nfiltered homotopy colimits, preserves the point, sends each exact sequence of\ndg categories to a triangle and is universal for these properties. Similary, we\nconstruct the `the universal additive invariant of dg categories', i.e. the\nuniversal morphism of derivators U_a to a strong triangulated derivator M^add\nwhich satisfies the first two properties but the third one only for split exact\nsequences. We prove that Waldhausen K-theory appears as a mapping space in the\ntarget of the universal additive invariant. This is the first conceptual\ncharacterization of Quillen-Waldhausen's K-theory since its definition in the\nearly 70's. As an application we obtain for free the higher Chern characters\nfrom K-theory to cyclic homology.\n", "machine_text": "\n\nWe give a short survey of some of the main results of the theory of K-theory, as developed by Grothendieck and his school. We present the material in an informal way, attempting to explain the main ideas and to give the reader an intuition for the theory, rather than a rigorous and complete account of the various results. We describe the main ingredients of the theory of K-theory, and explain how the theory developed from attempts to understand the structure of algebraic varieties. We explain the connection between K-theory and the theory of linear algebra, and we survey the basic results of the theory of K-modules. We explain how K-theory can be used to produce new invariants of algebraic varieties, and we survey some of the main results of this theory, including the basic results of the theory of universal K-invariants. We explain how K-theory can be used to study the relation between geometry and algebraic topology, and we survey the basic results of the theory of K-theories of topology. We explain the connection between K-theory and the theory of finite dimensional representations of groups, and we survey the basic results of the theory of K-modules for groups. We explain the connection between K-theory and the theory of Shalev-Schaler type theorems, and we survey the basic results of the theory of K-theory for metric spaces.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SN 2005hj: Evidence for Two Classes of Normal-Bright SNe Ia and\n  Implications for Cosmology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4467, "human_text": "  HET Optical spectra covering the evolution from about 6 days before to about\n5 weeks after maximum light and the ROTSE-IIIb unfiltered light curve of the\n\"Branch-normal\" Type Ia Supernova SN 2005hj are presented. The host galaxy\nshows HII region lines at redshift of z=0.0574, which puts the peak unfiltered\nabsolute magnitude at a somewhat over-luminous -19.6. The spectra show weak and\nnarrow SiII lines, and for a period of at least 10 days beginning around\nmaximum light these profiles do not change in width or depth and they indicate\na constant expansion velocity of ~10,600 km/s. We analyzed the observations\nbased on detailed radiation dynamical models in the literature. Whereas delayed\ndetonation and deflagration models have been used to explain the majority of\nSNe Ia, they do not predict a long velocity plateau in the SiII minimum with an\nunvarying line profile. Pulsating delayed detonations and merger scenarios form\nshell-like density structures with properties mostly related to the mass of the\nshell, M_shell, and we discuss how these models may explain the observed SiII\nline evolution; however, these models are based on spherical calculations and\nother possibilities may exist. SN 2005hj is consistent with respect to the\nonset, duration, and velocity of the plateau, the peak luminosity and, within\nthe uncertainties, with the intrinsic colors for models with M_shell=0.2 M_sun.\nOur analysis suggests a distinct class of events hidden within the\nBranch-normal SNe Ia. If the predicted relations between observables are\nconfirmed, they may provide a way to separate these two groups. We discuss the\nimplications of two distinct progenitor classes on cosmological studies\nemploying SNe Ia, including possible differences in the peak luminosity to\nlight curve width relation.\n", "machine_text": "\nWe present observations of SN 2005hj, a nearby, bright, and well-observed Type Ia supernova. The light curve is well described by a sum of two exponential curves with a superimposed tail. The best-fit parameters are a peak absolute magnitude of -15.07 mag, a total light-emission duration of ~140 d, and a supernova (SN) mass of 1.3 \u00a0M\u2299. These properties are consistent with those of a normal-bright SN Ia. Our analysis indicates that the radiative tail, which contributes >10% to the total light budget, has a power law index of -0.9 and a duration of 70 d. We show that this radiative tail has a nearly constant decay rate, which implies that the temperature of the accretion disk is constant during the entire course of the explosion. We argue that this is inconsistent with the commonly held assumption that the accretion disk is fed with material from the rotating shell of the pre-explosion evolved star. We suggest that this disk is fed with material from the inner circumstellar layer, and that the inner layer is heated by radioactive decay and not by the accretion torque. This suggests that the mechanism of explosion in SNe of this class is different from that of the majority of normal-bright SNe. We discuss the implications of this difference for the mechanism of accretion, the understanding of radiative transfer, and the use of SNe as standard candles. We show that the combined light curve of SN 2005hj is consistent with the recent theoretical predictions of Miao et al. (2004), but our analysis suggests that their model needs to be modified. Finally, we argue that the observed properties of SN 2005hj are consistent with a single-zone structure for the accretion disk, and we show that a two-zone structure leads to a worse fit to the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Coriolis force corrections to g-mode spectrum in 1D MHD model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2923, "human_text": "  The corrections to g-mode frequencies caused by the presence of a central\nmagnetic field and rotation of the Sun are calculated. The calculations are\ncarried out in the simple one dimensional magnetohydrodynamical model using the\napproximations which allow one to find the purely analytical spectra of\nmagneto-gravity waves beyond the scope of the JWKB approximation and avoid in a\nsmall background magnetic field the appearance of the cusp resonance which\nlocks a wave within the radiative zone. These analytic results are compared\nwith the satellite observations of the g-mode frequency shifts which are of the\norder one per cent as given in the GOLF experiment at the SoHO board. The main\ncontribution turns out to be the magnetic frequency shift in the strong\nmagnetic field which obeys the used approximations. In particular, the fixed\nmagnetic field strength 700 KG results in the mentioned value of the frequency\nshift for the g-mode of the radial order n=-10. The rotational shift due to the\nCoriolis force appears to be small and does not exceed a fracton of per cent,\n\\alpha_\\Omega < 0.003.\n", "machine_text": "\nWe consider a one-dimensional magnetohydrodynamic model with self-consistently generated mean flow and a superposed turbulent velocity field. We derive a system of nonlinear partial differential equations for the statistical quantities of the model which is shown to be capable of describing several basic hydrodynamic and gyrokinetic phenomena in a statistically steady state regime. After an appropriate regularization, the problem is shown to have a unique solution which is related to the solution of the Navier-Stokes equations with a small but constant temperature gradient and a linear, inviscid, temperature dependent term describing the action of the Coriolis force. We evaluate the Coriolis force spectrum and show that it is related to the power spectrum of the velocity field. Our model is capable of describing various physical situations, such as a pure laminar flow, a flow with a constant mean velocity and a linear temperature gradient, a flow with a constant mean velocity and a parabolic temperature gradient, a flow with a variable mean velocity and a linear temperature gradient, and a turbulent flow. We analyze the influence of the physical parameters of the model on the shape of the solution and we discuss the differences with the case of a stationary fluid. Finally, we comment on the possible physical meanings of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is the Concentration of Dark Matter Halos at Virialization Universal ?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0856, "human_text": "  Several recent studies suggest a correlation between dark matter halo mass\nand the shape of the density profile. We re-analyze simulations from Ricotti\n(2003) in which such a correlation was proposed. We use a standard analysis of\nthe halo density profiles and compare the old simulations to new ones performed\nwith Gadget2, including higher resolution runs. We confirm Ricotti's result\nthat, at virialization, the central log slopes alpha, at 5%-10% of the virial\nradius are correlated with the halo mass and that the halo concentration is a\nuniversal constant. Our results do not contradict the majority of published\npapers: when using a split power law to fit the density profiles, due to the\nalpha-concentration degeneracy, the fits are consistent with halos having a\nuniversal shape with alpha=1 or 1.5 and concentrations that depend on the mass,\nin agreement with results published elsewhere.\n  Recently, several groups have found no evidence for convergence of the inner\nhalo profile to a constant power law. The choice of a split power law\nparameterization used in this letter is motivated by the need to compare our\nresults to previous ones and is formally valid because we are not able to\nresolve regions where the slope of the fitting function reaches its asymptotic\nconstant value. Using a non-parameterized technique, we also show that the\ndensity profiles of dwarf galaxies at z ~ 10 have a log slope shallower than\n0.5 within 5% of the virial radius.\n", "machine_text": "\n\nWe present a simple model of the evolution of dark matter halos from the formation to the virialization stage. Our main result is that the concentration of the dark matter halos, as a function of mass, is universal in the sense that it is independent of the detailed structure of the halos. We show this by comparing our model to the observations of galaxy clusters and to the results of numerical simulations. The model is based on the idea that the formation of structure in the universe can be described by the competition between the growth of halos and the increase of the mean density in the Universe. Our model predicts that the number density of halos is proportional to the volume density of the Universe. This is in agreement with observations, and it implies that the mass of a halo is proportional to the volume of the Universe. In addition, the model predicts that the density profile of a halo is independent of its mass. We discuss the implications of our result for structure formation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Point-contact spectroscopy of the antiferromagnetic superconductor\n  HoNi2B2C in the normal and superconducting state. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3405, "human_text": "  Point-contact (PC) spectroscopy measurements on antiferromagnetic (AF)\n(T_N=5.2K) HoNi2B2C single crystals in the normal and two different\nsuperconducting (SC) states (T_c=8.5K and $T_c^*=5.6K) are reported. The PC\nstudy of the electron-boson(phonon) interaction (EB(P)I) spectral function\nreveals pronounced phonon maxima at 16, 22 and 34meV. For the first time the\nhigh energy maxima at about 50meV and 100meV are resolved. Additionally, an\nadmixture of a crystalline-electric-field (CEF) excitations with a maximum near\n10meV and a `magnetic` peak near 3meV are observed. The contribution of the\n10-meV peak in PC EPI constant \\lambda_PC is evaluated as 20-30%, while\ncontribution of the high energy modes at 50 and 100meV amounts about 10% for\neach maxima, so the superconductivity might be affected by CEF excitations. The\nSC gap in HoNi2B2C exhibits a standard single-band BCS-like dependence, but\nvanishes at $T_c^*=5.6K<T_c, with 2\\Delta/kT_c^*=3.9. The strong coupling\nEliashberg analysis of the low-temperature SC phase with T_c^*=5.6K =T_N,\ncoexisting with the commensurate AF structure, suggests a sizable value of the\nEPI constant \\lambda_s=0.93. We also provide strong support for the recently\nproposed by us ''Fermi surface (FS) separation'' scenario for the coexistence\nof magnetism and superconductivity in magnetic borocarbides, namely, that the\nsuperconductivity in the commensurate AF phase survives at a special (nearly\nisotropic) FS sheet without an admixture of Ho 5d states. Above T_c^* the SC\nfeatures in the PC characteristics are strongly suppressed pointing to a\nspecific weakened SC state between T_c* and T_c.\n", "machine_text": "\n\nWe report point-contact spectroscopy of the superconductor HoNi2B2C in the normal and superconducting state. The superconducting state shows the same spectral features as the normal state, but with a larger spectral gap and a different temperature dependence of the spectral energy. We show that the energy gap in the superconducting state can be explained by a mechanism of thermal activation of the normal state transition. Our results suggest that the electronic structure of this heavy-fermion superconductor is very similar in the normal and superconducting state.\n\nWe have developed a new method for point-contact spectroscopy which does not require a metal tip but instead uses a semiconductor tip which is lightly doped with donors. This method, which we have called Point-Contact Spectroscopy by Non-Tunneling Current (PCSNT), has several advantages over the usual method of point-contact spectroscopy using a metal tip. It is much easier to make a good point contact with a semiconductor tip than with a metal tip, since the semiconductor tip can be made very sharp and has a much higher thermal stability. In addition, the PCSNT method can be used to study the electrical properties of the normal state as well as the superconducting state, whereas the usual method can only be used for the superconducting state.\n\nWe have used the PCSNT method to study the electronic structure of the normal state and the superconducting state of the heavy-fermion superconductor HoNi2B2C. We found that the superconducting state has a different spectral energy distribution than the normal state, with a larger spectral gap, but that the shape of the spectral features is very similar in the two states. We have explained the larger spectral gap in the superconducting state by a mechanism of thermal activation of the normal state transition. Our results suggest that the electronic structure of this heavy-fermion superconductor is very similar in the normal and superconducting state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On over-reflection and generation of Gravito-Alfven waves in solar-type\n  stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3919, "human_text": "  The dynamics of linear perturbations is studied in magnetized plasma shear\nflows with a constant shearing rate and with gravity-induced stratification.\nThe general set of linearized equations is derived and the two-dimensional case\nis considered in detail. The Boussinesq approximation is used in order to\nexamine relatively small-scale perturbations of low-frequency modes:\nGravito-Alfven waves (GAW) and Entropy Mode (EM) perturbations. It is shown\nthat for flows with arbitrary shearing rate there exists a finite time interval\nof non-adiabatic evolution of the perturbations. The non-adiabatic behavior\nmanifests itself in a twofold way, viz. by the over-reflection of the GAWs and\nby the generation of GAWs from EM perturbations. It is shown that these\nphenomena act as efficient transformers of the equilibrium flow energy into the\nenergy of the perturbations for moderate and high shearing rate solar plasma\nflows. Efficient generation of GAW by EM takes place for shearing rates about\nan order of magnitude smaller than necessary for development of a shear\ninstability. The latter fact could have important consequences for the problem\nof angular momentum redistribution within the Sun and solar-type stars.\n", "machine_text": "\nWe investigate the generation of gravito-Alfven waves (GAWs) in solar-type stars. We find that the outward-propagating GAWs can be generated by over-reflection of Alfv\u00e9n waves (AWs) at the inner edge of the boundary layer (BL) when the forcing is directed along the star's rotation axis. We also find that the generation rate is sensitive to the stellar rotation frequency, and that the inner BL can become unstable to the generation of GAWs when the forcing frequency is close to the rotation frequency. We show that the quasistationary structure of the unstable BL is characterized by the presence of a standing GAW, and that the transition to the unstable state is accompanied by a change in the dominant mode of the GAW from a pure Alfv\u00e9nic mode to a damped Alfv\u00e9nic mode with a substantial slow-mode component. The properties of the unstable BL are consistent with the formation of a rotating barrel structure. We find that the standing GAW is stable against the AWs that are generated by the forcing. Therefore, the outer edge of the BL can be considered as a boundary for the GAWs, and the BL itself as a waveguide for the AWs. Within this picture, we derive a simple expression for the coupling coefficient between the forcing and the generated GAWs. We also derive a simple expression for the critical frequency, below which the inner BL becomes unstable to the generation of GAWs. We show that these expressions are consistent with the available numerical and theoretical results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effects of the anomaly on the two-flavor QCD chiral phase transition. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0617, "human_text": "  We use strongly coupled lattice QED with two flavors of massless staggered\nfermions to model the physics of pions in two-flavor massless QCD. Our model\nhas the right chiral symmetries and can be studied efficiently with cluster\nalgorithms. In particular we can tune the strength of the QCD anomaly and thus\nstudy its effects on the chiral phase transition. Our study confirms the widely\naccepted view point that the chiral phase transition is first order in the\nabsence of the anomaly. Turning on the anomaly weakens the transition and turns\nit second order at a critical anomaly strength. The anomaly strength at the\ntricritical point is characterized using $r = (M_{\\eta'}-M_{\\pi})/\\rho_{\\eta'}$\nwhere $M_{\\eta'}, M_{\\pi}$ are the screening masses of the anomalous and\nregular pions and $\\rho_{\\eta'}$ is the mass-scale that governs the low energy\nfluctuations of the anomalous symmetry. We estimate that $r \\sim 7 $ in our\nmodel. This suggests that a strong anomaly at the two-flavor QCD chiral phase\ntransition is necessary to wash out the first order transition.\n", "machine_text": "\nWe study the effects of the anomaly on the two-flavor QCD chiral phase transition. We consider a general definition of the chiral transition temperature, and evaluate the conditions for the anomaly to have a significant effect on the transition. We show that the anomaly can delay the transition, and can even lead to a transition to a phase where the fermionic generators are not balanced. The conditions for this to occur are rather general, and in particular do not require a particular form for the potential between the two fermionic generators. We also derive a general criterion for the transition temperature to be sensitive to the anomaly. We then study the particular case of a point-coupling potential, and evaluate the conditions for a transition temperature to exist in this case. We show that these conditions are rather general, and in particular do not require the anomaly to be large. We finally study the effect of a small anomaly on the thermodynamic properties of the chiral transitions, and in particular on the order parameter and on the critical temperature. We show that small anomalies can have a significant effect on these quantities, even when they do not delay the transition.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the nature of optical nuclei in FR I radio-galaxies from ACS/HST\n  imaging polarimetry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1944, "human_text": "  We obtained optical imaging polarimetry with the ACS/HRC aboard the HST of\nthe 9 closest radio-galaxies in the 3C catalogue with an FR I morphology. The\nnuclear sources seen in direct HST images in these galaxies are found to be\nhighly polarized with levels in the range ~2-11 % with a median value of 7 %.\nWe discuss the different mechanisms that produce polarized emission and\nconclude that the only viable interpretation is a synchrotron origin for the\noptical nuclei. This idea is strengthened by the analogy with the polarization\nproperties of BL Lac objects, providing also further support to the FRI/BL Lac\nunified model. This confirms previous suggestions that the dominant emission\nmechanism in low luminosity radio-loud AGN is related to non-thermal radiation\nproduced by the base of their jets. In addition to the nuclear polarization\n(and to the large scale optical jets), polarization is detected co-spatially\nwith the dusty circumnuclear disks, likely due to dichroic transmission; the\npolarization vectors are tangential to the disks as expected when the magnetic\nfield responsible for the grains alignment is stretched by differential\nrotation. We explored the possibility to detect the polarimetric signature of a\nmisaligned radiation beam in FR I, expected in our sources in the frame of the\nFR I/ BL Lac unification. We did not find this effect in any of the galaxies,\nbut our the results are not conclusive on whether a misaligned beam is indeed\npresent in FR I.\n", "machine_text": "\n\nWe present high-resolution imaging polarimetry of the nuclei of 25 nearby radio galaxies in the first (and most nearby) radio galaxy filament, using data obtained with the Advanced Camera for Surveys (ACS) onboard the Hubble Space Telescope (HST). We find that the light emitted by the nuclear regions is highly polarized, with the percentage of linearly polarized light (PL) ranging from 60% to 80%. The degree of circular polarization (CP) of the light emitted by the nuclei is large ( ranging from 20% to 50% when defined as the fraction of the total light that is polarized in a right-handed direction), indicating that the geometry of the emission is very likely dominated by torus-like structures. We find that the nuclei of radio galaxies in the first filament, in particular those with higher optical luminosity, have a higher degree of polarization in their optical light than the nuclei of radio galaxies in the second filament, even after controlling for distance, radio power, and optical luminosity. Our results suggest that in addition to the torus-like structures revealed by the high degree of CP, the nuclear regions of radio galaxies also contain large amounts of polarized light that is ordered along the direction of the jet, probably due to interaction of the relativistic jet with the torus. We find a correlation between the magnetic field strength measured in the radio band and the degree of CP in the optical band, suggesting that the magnetic field is responsible for the CP structure. Our results also suggest that in radio galaxies the large-scale organization of the magnetic field is likely to be correlated with the large-scale structure of the torus.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing dark energy with steerable wavelets through correlation of WMAP\n  and NVSS local morphological measures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0626, "human_text": "  Using local morphological measures on the sphere defined through a steerable\nwavelet analysis, we examine the three-year WMAP and the NVSS data for\ncorrelation induced by the integrated Sachs-Wolfe (ISW) effect. The steerable\nwavelet constructed from the second derivative of a Gaussian allows one to\ndefine three local morphological measures, namely the signed-intensity,\norientation and elongation of local features. Detections of correlation between\nthe WMAP and NVSS data are made with each of these morphological measures. The\nmost significant detection is obtained in the correlation of the\nsigned-intensity of local features at a significance of 99.9%. By inspecting\nsigned-intensity sky maps, it is possible for the first time to see the\ncorrelation between the WMAP and NVSS data by eye. Foreground contamination and\ninstrumental systematics in the WMAP data are ruled out as the source of all\nsignificant detections of correlation. Our results provide new insight on the\nISW effect by probing the morphological nature of the correlation induced\nbetween the cosmic microwave background and large scale structure of the\nUniverse. Given the current constraints on the flatness of the Universe, our\ndetection of the ISW effect again provides direct and independent evidence for\ndark energy. Moreover, this new morphological analysis may be used in future to\nhelp us to better understand the nature of dark energy.\n", "machine_text": "\nWe propose a new method to probe dark energy by correlating local galaxy density and local galaxy morphology measures extracted from the WMAP and NVSS surveys, respectively. Our method is based on the use of steerable wavelets, which enable us to optimally extract the relevant information from the two surveys. We show that our procedure is sensitive to the dark energy density in a manner that is independent of the specific choice of galaxy density and morphology measures. We find that the cross-correlation function of our optimally extracted density and morphology measures peaks at a dark energy density of omega_0 = -1.01 +/- 0.06 (h = 150 Mpc), in good agreement with the value extracted from the cosmic microwave background anisotropy. Our confidence level is better than 5sigma. We show that our procedure is sensitive to local variations of the dark energy density in a manner that is consistent with a Taylor-scale expansion of the Universe. We also show that our procedure is largely insensitive to the specific choice of galaxy density and morphology measures, as long as they are extracted with the use of steerable wavelets. We discuss the implications of our findings for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Socioeconomic Networks with Long-Range Interactions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0024, "human_text": "  We study a modified version of a model previously proposed by Jackson and\nWolinsky to account for communicating information and allocating goods in\nsocioeconomic networks. In the model, the utility function of each node is\ngiven by a weighted sum of contributions from all accessible nodes. The\nweights, parameterized by the variable $\\delta$, decrease with distance. We\nintroduce a growth mechanism where new nodes attach to the existing network\npreferentially by utility. By increasing $\\delta$, the network structure\nevolves from a power-law to an exponential degree distribution, passing through\na regime characterised by shorter average path length, lower degree\nassortativity and higher central point dominance. In the second part of the\npaper we compare different network structures in terms of the average utility\nreceived by each node. We show that power-law networks provide higher average\nutility than Poisson random networks. This provides a possible justification\nfor the ubiquitousness of scale-free networks in the real world.\n", "machine_text": "\n\nWe investigate a class of random socioeconomic networks with long-range interactions, which are motivated by many real-world social and information networks, where both local and non-local connections are important. We find that these networks are characterized by a few strongly connected nodes (or communities), which are connected to each other by a small number of links, and many weakly connected nodes, which are connected mostly to the strongly connected nodes by a large number of links. This is in sharp contrast to the properties of random networks without long-range interactions, where the degree distribution is power law and the average path length is small. We find that the PageRank algorithm is inefficient in these networks, because it is designed to operate on networks with many local connections. We develop a simple modification of the PageRank algorithm that takes into account the non-local connections, and show that this modified algorithm is more efficient in discovering the strongly connected nodes. Our results suggest that the community detection methods based on the local interactions may be further improved by taking into account the non-local interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: L'Univers en expansion et probl\\`emes d'\\'energie. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1248, "human_text": "  In this paper we first construct a mathematical model for the Universe\nexpansion that started up with the original Big Bang. Next, we discuss the\nproblematic of the mechanical and physical laws invariance regarding the\nspatial frame exchanges. We then prove the (theoretical) existence of a\nvariable metric $g_t$, depending on time and satisfying to a simplified\nEinstein equation, so that all free ordinary trajectories are geodesics. This\nis done by considering the classical Galileo-Newtonian space and time relation,\nby using generalized Newtonian principles and adding the approved physical new\nones (as covariance principle, Mach principle, the Einstein equivalence\nprinciple ...) in order to establish a new cosmological model of the dynamical\nUniverse as being $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$, where $B_e(O,t)$\nis the Euclidean ball of radius $t$ in $\\mathbb R^3$. The cosmological metric\n$g_t$ is totally determined, at time $t$, by the mass energy distribution\n$E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove\nthat the total and global cosmological energy distribution $E_t(X)$ satisfies\nto the wave equation whose solutions are characterized by pseudo-frequencies\ndepending on time and related to the spectrum of the Dirichlet problem on the\nunit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\\Delta$. Our model is\nconsistent in the sense that all Newtonian and classical physical laws are\nvalid as particular cases in classical situations. Then, we show that all basic\nresults of Modern Physics are still valid without using the second postulate of\nspecial relativity nor the uncertainty principle.\n", "machine_text": "\n\nWe present a brief survey of the physical problem of the energy of the expanding universe, with emphasis on the problem of the energy density of the universe and the conditions for its stability. We show that the evolution of the energy of the universe is governed by the principle of energy conservation, and that the energy of the universe is always positive. We discuss the problem of the energy of the universe in the context of the theory of general relativity, and we show that the energy of the universe is bounded from below. We discuss the problem of the stability of the energy of the universe, and we show that the energy of the universe is stable if the principle of energy conservation is satisfied. We show that the energy of the universe is not stable if the principle of energy conservation is not satisfied. We discuss the problem of the energy of the universe in the context of the theory of quantum mechanics, and we show that the energy of the universe is not quantized. We discuss the problem of the energy of the universe in the context of the theory of thermodynamics, and we show that the energy of the universe is not a state function.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Very High Energy Gamma-ray Radiation from the Stellar-mass Black Hole\n  Cygnus X-1. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1505, "human_text": "  We report on the results from the observations in very high energy band (VHE,\nE_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The\nobservations were performed with the MAGIC telescope, for a total of 40 hours\nduring 26 nights, spanning the period between June and November 2006. Searches\nfor steady gamma-ray signals yielded no positive result and upper limits to the\nintegral flux ranging between 1 and 2% of the Crab nebula flux, depending on\nthe energy, have been established. We also analyzed each observation night\nindependently, obtaining evidence of gamma-ray signals at the 4.0 standard\ndeviations (sigma) significance level (3.2 sigma after trial correction) for\n154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41\nUTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search\nfor faster-varying signals within a night resulted in an excess with a\nsignificance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT\nbetween 22h17 and 23h41 UTC. The measured excess is compatible with a\npoint-like source at the position of Cygnus X-1, and excludes the nearby radio\nnebula powered by its relativistic jet. The differential energy spectrum is\nwell fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x\n10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of\nVHE emission from a stellar-mass black hole, and therefore from a confirmed\naccreting X-ray binary.\n", "machine_text": "\nWe present observations of very high energy (VHE, E>100 keV) gamma-ray radiation from the stellar-mass black hole candidate Cygnus X-1. The observations were made with the VHE sensitive imaging atmospheric Cherenkov telescope (IACT) ZTF-magnometer (ZTF-m) and cover a period of more than ten years, from 2007 to 2017. We find that the VHE gamma-ray flux from Cygnus X-1 is highly variable, with a peak flux density of  \u223c 4 \u2212 10 counts per detector per hour (ch/det/hr) and an average flux density of  \u223c 1.3 ch/det/hr during the period of observations. These values correspond to a total VHE gamma-ray luminosity of  \u223c 4.1  \u2217 1036 erg s\u22121 and an average VHE gamma-ray luminosity of  \u223c 1.4  \u2217 1036 erg s\u22121 during the period of observations. We find that the VHE gamma-ray emission from Cygnus X-1 is likely due to the accretion disc around the black hole, in agreement with the predictions of magnetized drum-up models. Our results suggest that the accretion disc around stellar-mass black holes is able to produce a significant amount of VHE gamma-ray radiation, even in the presence of a strong magnetic field, and that much of this VHE gamma-ray radiation is absorbed by the accretion disc itself.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A map of the day-night contrast of the extrasolar planet HD 189733b. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0993, "human_text": "  \"Hot Jupiter\" extrasolar planets are expected to be tidally locked because\nthey are close (<0.05 astronomical units, where 1 AU is the average Sun-Earth\ndistance) to their parent stars, resulting in permanent daysides and\nnightsides. By observing systems where the planet and star periodically eclipse\neach other, several groups have been able to estimate the temperatures of the\ndaysides of these planets. A key question is whether the atmosphere is able to\ntransport the energy incident upon the dayside to the nightside, which will\ndetermine the temperature at different points on the planet's surface. Here we\nreport observations of HD 189733, the closest of these eclipsing planetary\nsystems, over half an orbital period, from which we can construct a 'map' of\nthe distribution of temperatures. We detected the increase in brightness as the\ndayside of the planet rotated into view. We estimate a minimum brightness\ntemperature of 973 +/- 33 K and a maximum brightness temperature of 1212 +/- 11\nK at a wavelength of 8 microns, indicating that energy from the irradiated\ndayside is efficiently redistributed throughout the atmosphere, in contrast to\na recent claim for another hot Jupiter. Our data indicate that the peak\nhemisphere-integrated brightness occurs 16$\\pm$6 degrees before opposition,\ncorresponding to a hot spot shifted east of the substellar point. The secondary\neclipse (when the planet moves behind the star) occurs 120 +/- 24 s later than\npredicted, which may indicate a slightly eccentric orbit.\n", "machine_text": "\n\nA map of the day-night contrast of the extrasolar planet HD 189733b\n\nWe present photometric measurements of the day-night contrast of the extrasolar planet HD 189733b, as observed with the Hubble Space Telescope. We find that the contrast is very sensitive to the spatial distribution of clouds in the atmosphere. If the clouds are distributed in a ring, the contrast is high and symmetric, but if the clouds are only located near the equator, the contrast is much lower and asymmetric. We have developed a simple model that can reproduce our observations provided that the clouds are located above the equatorial region. This model suggests that clouds form at high latitudes and then move towards the equator. Our results are consistent with a wind field that is aligned with the equator and that has a speed between 5 and 10 m/s. We also present a map of the surface gravity, obtained from the same observations. The gravity map shows several large continents and many small islands. The distribution of continents and islands is consistent with a scenario in which the planet is rotatingsynchronously.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the orbital periods of the AM CVn stars HP Librae and V803 Centauri. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0402, "human_text": "  We analyse high-time-resolution spectroscopy of the AM CVn stars HP Librae\nand V803 Centauri, taken with the New Technology Telescope (NTT) and the Very\nLarge Telescope (VLT) of the European Southern Observatory, Chile.\n  We present evidence that the literature value for V803 Cen's orbital period\nis incorrect, based on an observed `S-wave' in the binary's spectrogram. We\nmeasure a spectroscopic period P=1596.4+/-1.2s of the S-wave feature, which is\nsignificantly shorter than the 1611-second periods found in previous\nphotometric studies. We conclude that the latter period likely represents a\n`superhump'. If one assumes that our S-wave period is the orbital period, V803\nCen's mass ratio can be expected to be much less extreme than previously\nthought, at q~0.07 rather than q~0.016. This relaxes the constraints on the\nmasses of the components considerably: the donor star does then not need to be\nfully degenerate, and the mass of the accreting white dwarf no longer has to be\nvery close to the Chandrasekhar limit.\n  For HP Lib, we similarly measure a spectroscopic period P=1102.8+/-0.2s. This\nsupports the identification of HP Lib's photometric periods found in the\nliterature, and the constraints upon the masses derived from them.\n", "machine_text": "\n\nWe present photometric observations of the short-period horizontal-branch (HB) stars HP Librae and V803 Centauri, which allow a precise determination of their orbital periods. The observations cover several orbital revolutions and were obtained under uniform conditions for both stars. We find that the orbital period of HP Librae is 87.12 \u00b1 0.09 min, which is 11.4 \u00b1 0.9% longer than the period determined from the orbital elements derived from spectroscopy. The corresponding systematic effect on the orbital elements is within the formal uncertainty of the spectroscopic measurements. We discuss this period discrepancy with the help of recent models of the orbital evolution of these stars. We also present a detailed study of the full- amplitude behavior of the HB-star modulation in HP Librae. The observed modulation amplitude shows a clear signature of an exponential radial-distance variation superimposed on a linear one. We determine the characteristic parameters of both amplitude variations, and discuss the physical origin of the observed radial-distance variations. We find that the mass-loss rate during the evolution of the system is at most 2.3% of the total stellar mass per 1000 yr. The derived value is lower than the mass-loss rate derived from the observed orbital-elements evolution. We discuss the observed properties of HP Librae and V803 Centauri within the framework of recent theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What happened to the Cosmological QCD Phase Transition?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4149, "human_text": "  The scenario that some first-order phase transitions may have taken place in\nthe early Universe offers us one of the most intriguing and fascinating\nquestions in cosmology. Indeed, the role played by the latent \"heat\" or energy\nreleased in the phase transition is highly nontrivial and may lead to some\nsurprising, important results. In this paper, we take the wisdom that the\ncosmological QCD phase transition, which happened at a time between 10^(-5) sec\nand 10^(-4) sec or at the temperature of about 150 MeV and accounts for\nconfinement of quarks and gluons to within hadrons, would be of first order. To\nget the essence out of the scenario, it is sufficient to approximate the true\nQCD vacuum as one of degenerate theta-vacua and when necessary we try to model\nit effectively via a complex scalar field with spontaneous symmetry breaking.\nWe examine how and when \"pasted\" or \"patched\" domain walls are formed, how long\nsuch walls evolve in the long run, and we believe that the significant portion\nof dark matter could be accounted for in terms of such domain-wall structure\nand its remnants. Of course, the cosmological QCD phase transition happened in\nthe way such that the false vacua associated with baryons and many other\ncolor-singlet objects did not disappear (that is, using the bag-model language,\nthere are bags of radius 1.0 fermi for the baryons) - but the amount of the\nenergy remained in the false vacua is negligible. The latent energy released\ndue to the conversion of the false vacua to the true vacua, in the form of\n\"pasted\" or \"patched\" domain walls in the short run and their numerous evolved\nobjects, should make the concept of the \"radiation-dominated\" epoch, or of the\n\"matter-dominated\" epoch to be re-examined.\n", "machine_text": "\nWe present a model that explains the disappearance of the cosmological quark-deconfined phase transition. The model consists of a simpleeffective potential which at large distance approximates the quark-meson coupling constant and at small distance is an increasing function of the quark-meson coupling constant. The derivative of the potential is anaffine function of the quark-meson coupling constant. We show that this potential has a local minimum at a critical value of the quark-meson coupling constant, which depends only on the ratio of the quark-to-meson masses. We calculate the dependedietric contribution to the effective potential and show that it is negative for a large range of values of the quark-meson coupling constant. This corresponds to the stable deconfined phase. We calculate the dependencquoise function and show that it is positive for a large range of values of the quark-meson coupling constant. This corresponds to the unstable quark-deconfined phase. We show that the stable and unstable phases coexist for a finite range of values of the quark-meson coupling constant. Outside this range the stable phase is unique. We derive a general condition for the disappearance of the quark-deconfined phase transition which does not depend on the specific choice of the effective potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraints on the electroweak chiral Lagrangian from the precision data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2277, "human_text": "  In the framework of the effective field theory method, we use the\nexperimental data and the perturbative unitarity bounds to determine the values\nand uncertainty of all the 11 chiral coefficients ($\\al_i, i=0, ..., 10$) of\nthe standard electroweak chiral Lagrangian. Up to linear terms in $\\al_i$, we\nprovide the one-loop renormalization group equations of all the chiral\ncoefficients, which are calculated in the Feynman-'t Hooft gauge using the\nmodified minimal subtraction scheme. With the improved renormalization group\nequations to sum over the logarithmic corrections, we analyze the current\nexperimental uncertainty of oblique correction parameters, $S(\\Lambda)$ and\n$T(\\Lambda)$. We find that, due to the large uncertainty in the triple\ngauge-boson coupling measurements, the parameter space of positive $S(\\Lambda)$\nfor $\\Lambda > 1$ TeV is still allowed by the current experimental data.\n$T(\\Lambda)$ tends to increase with $\\Lambda$ even in the presence of the\noperators that contribute to the triple and quartic gauge-boson couplings.\n", "machine_text": "\nWe consider the precision constraints on the electroweak chiral Lagrangian from the mass spectra of light quarks and charged leptons. The motivation for this work is the recent observation of the neutrino mass-squared difference from the T2K and the latest Super-Kamiokande experiments, which can constrain the left-right asymmetry in the early Universe to be no more than 1%. We show that the standard model (SM) chiral Lagrangian, which generates a $\\sim 1$% asymmetry in the Universe, is compatible with the current constraints from the neutrino data, and it is also consistent with the results from the $\\overline{B}$-Factory and the LHC, provided that the standard model (SM) Yukawa parameters are small. On the other hand, if the neutrino mass-squared difference is further constrained to be less than the current limit, we find that the SM chiral Lagrangian needs to be fine-tuned in the right direction to accommodate the neutrino data, and it is inconsistent with the results from the $\\overline{B}$-Factory and the LHC. We also show that the constraints from the precision data can be satisfied by a right-handed neutrino with a mass-squared difference as small as $\\sim 10$-40% of the electron mass-squared, provided that the Yukawa parameters are small. We also show that the standard model chiral Lagrangian is consistent with the masses of light quarks and charged leptons if the Yukawa parameters are small, while the minimal chiral Lagrangian is inconsistent with the mass spectra of quarks and leptons if the Yukawa parameters are large. We also discuss the possibility that the chiral Lagrangian is constrained by the standard model data, while it is free from the extra-dimensional gravitational effects.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Physisorption of Nucleobases on Graphene. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1316, "human_text": "  We report the results of our first-principles investigation on the\ninteraction of the nucleobases adenine (A), cytosine (C), guanine (G), thymine\n(T), and uracil (U) with graphene, carried out within the density functional\ntheory framework, with additional calculations utilizing Hartree--Fock plus\nsecond-order Moeller-Plesset perturbation theory. The calculated binding energy\nof the nucleobases shows the following hierarchy: G > T ~ C ~ A > U, with the\nequilibrium configuration being very similar for all five of them. Our results\nclearly demonstrate that the nucleobases exhibit significantly different\ninteraction strengths when physisorbed on graphene. The stabilizing factor in\nthe interaction between the base molecule and graphene sheet is dominated by\nthe molecular polarizability that allows a weakly attractive dispersion force\nto be induced between them. The present study represents a significant step\ntowards a first-principles understanding of how the base sequence of DNA can\naffect its interaction with carbon nanotubes, as observed experimentally.\n", "machine_text": "\nWe report a systematic investigation of the strength and specificity of the interaction between graphene and the four major DNA nucleobases, performed using a combination of density functional theory calculations and experiments. We find that the interaction strength decreases in the order G>A>T>C, with the van der Waals interaction energy being the dominant contribution to the interaction energy for all bases. The largest change in the C\u2013H\u22ef\u03c0 interaction energy upon base adsorption is found to be the main reason for the decrease in the strength of the interaction in the order G>A>T>C. Our results suggest that the strength of the interaction between graphene and nucleobases is not sufficient to form a stable hybrid in which the base would be covalently bound to the graphene sheet. We also show that the selective interaction between graphene and adenine is caused by the large change in the C\u2013H\u22ef\u03c0 interaction energy, in addition to the van der Waals interaction, and is not due to a unique molecular property of adenine.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mixed-up trees: the structure of phylogenetic mixtures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4328, "human_text": "  In this paper we apply new geometric and combinatorial methods to the study\nof phylogenetic mixtures. The focus of the geometric approach is to describe\nthe geometry of phylogenetic mixture distributions for the two state random\ncluster model, which is a generalization of the two state symmetric (CFN)\nmodel. In particular, we show that the set of mixture distributions forms a\nconvex polytope and we calculate its dimension; corollaries include a simple\ncriterion for when a mixture of branch lengths on the star tree can mimic the\nsite pattern frequency vector of a resolved quartet tree. Furthermore, by\ncomputing volumes of polytopes we can clarify how ``common'' non-identifiable\nmixtures are under the CFN model. We also present a new combinatorial result\nwhich extends any identifiability result for a specific pair of trees of size\nsix to arbitrary pairs of trees. Next we present a positive result showing\nidentifiability of rates-across-sites models. Finally, we answer a question\nraised in a previous paper concerning ``mixed branch repulsion'' on trees\nlarger than quartet trees under the CFN model.\n", "machine_text": "\n\nMixed-up trees: the structure of phylogenetic mixtures.\n\nThe study of mixture data has recently become a topic of intense interest in statistical physics, statistical genetics, and computer science. We review some results on the structure of phylogenetic mixtures from our own work and that of others, and discuss some open problems. We also introduce a new model that captures several features of phylogenetic mixtures that are not captured by the traditional model of mixtures of rooted trees. This model can be thought of as a generalization of the traditional model to the setting of unrooted trees, but it also has a direct interpretation in terms of a game between a \"top down\" and a \"bottom up\" process that compete to build a phylogenetic tree. The game has a unique solution that is characterized by a simple condition on the degree of the leaves. We show that this condition is satisfied for a wide class of real data sets. We also show that the simplest non-trivial case of our model, the setting of a constant degree for all leaves, is closely related to the setting of a single rooted tree with an internal node, and that the statistics of this setting satisfy the same restrictions as the statistics of a rooted tree.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Transverse Polarization of Lambda and Lambda-bar Hyperons in Quasireal\n  Photoproduction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3133, "human_text": "  The HERMES experiment has measured the transverse polarization of Lambda and\nLambda-bar hyperons produced inclusively in quasireal photoproduction at a\npositron beam energy of 27.6 GeV. The transverse polarization of the Lambda\nhyperon is found to be positive while the observed Lambda-bar polarization is\ncompatible with zero. The transverse polarization values averaged over the\nkinematic acceptance of HERMES are 0.078 +/- 0.006(stat) +/- 0.012(syst) and\n-0.025 +/- 0.015(stat) +/- 0.018(syst) for Lambda and Lambda-bar hyperons,\nrespectively. The dependences of Lambda and Lambda-bar polarizations on the\nfraction $\\zeta$ of the beam's light-cone momentum carried by the hyperon and\non the hyperon's transverse momentum $p_T$ were investigated. The measured\nLambda polarization rises linearly with $p_T$ and exhibits a different behavior\nfor low and high values of $\\zeta$, which approximately correspond to the\nbackward and forward regions in the center-of-mass frame of the $\\gamma^*N$\nreaction.\n", "machine_text": "\nWe present the first three-dimensional measurement of the transverse polarization of quasireal photoproduction of the Lambda and Lambda-bar hyperons. The measurement was made with the BaBar detector at the PEP-II asymmetric-energy e+e- accelerator at SLAC. We find the transverse polarization fraction to be larger than previously measured with the PEP-II Removeable Pole (RPP) detector at the same accelerator. The large rate of unpolarized photoproduction at small transverse momenta, and the large fraction of longitudinal polarization at large transverse momenta are in agreement with the predictions of theLarry- Missile- Banana (LMB) model. A possible explanation for the discrepancy between the current result and the previous result from the RPP detector is that the longitudinal polarization of the emissive radiation in the LMB model is smaller than observed.\n\nWe also present a model for the transverse polarization of the photoproduction of the Lambda and Lambda-bar hyperons based on the assumption that the polarization is governed by the same mechanisms that govern the polarization of the light emitted by a linear accelerator. This model successfully predicts the polarization dependence on the transverse momenta and the longitudinal polarization fractions observed in both the RPP and the BaBar measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nanostructure and velocity of field-driven solid-on-solid interfaces\n  moving under a phonon-assisted dynamic. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0652, "human_text": "  The nanoscopic structure and the stationary propagation velocity of\n(1+1)-dimensional solid-on-solid interfaces in an Ising lattice-gas model,\nwhich are driven far from equilibrium by an applied force, such as a magnetic\nfield or a difference in (electro)chemical potential, are studied by an\nanalytic nonlinear-response approximation together with kinetic Monte Carlo\nsimulations. Here we consider the case that the system is coupled to a\ntwo-dimensional phonon bath. In the resulting dynamic, transitions that\nconserve the system energy are forbidden, and the effects of the applied force\nand the interaction energies do not factorize (a so-called hard dynamic). In\nfull agreement with previous general theoretical results we find that the local\ninterface width changes dramatically with the applied force. However, in\ncontrast with other hard dynamics, this change is nonmonotonic in the driving\nforce. However, significant differences between theory and simulation are found\nnear two special values of the driving force, where certain transitions allowed\nby the solid-on-solid model become forbidden by the phonon-assisted dynamic.\nOur results represent a significant step toward providing a solid physical\nfoundation for kinetic Monte Carlo simulations.\n", "machine_text": "\nWe investigate the nanoscale structure and dynamics of solid-on-solid interfaces driven by a combination of an electric field and a mechanical strain, using molecular dynamics simulations in the framework of the waitress model. The applied electric field is found to be efficiently concentrated at the solid-on-solid interface, in a way that is different for each of the three distinct phases that the system can be in: the contact phase, the reticular phase, and the so-called Lupas phase. In the contact phase, the electric field is concentrated in a single plane at the bottom of the contacts, while in the reticular and Lupas phases the field is more uniformly distributed throughout the bulk of the material. The local distribution of the electric field in these different phases has a strong effect on the subsequent dynamics of the system, especially in the early stages of the field-driven process, and determines the final nanostructure of the solid-on-solid interface. We find that the applied electric field can have a strong entropically driven dynamics, in addition to the already present thermal fluctuations. The strength of this additional contribution depends on the local distribution of the electric field, as well as on the symmetry of the nanostructure. We also analyze the influence of the applied strain on the dynamics of the system. The analysis of the relaxation pathways shows that the combination of the electric field and the strain can have a strong influence on the structural changes that the system can undergo, as well as on the kinetically allowed pathways.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Coupling between magnetic ordering and structural instabilities in\n  perovskite biferroics: A first-principles study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1251, "human_text": "  We use first-principles density functional theory-based calculations to\ninvestigate structural instabilities in the high symmetry cubic perovskite\nstructure of rare-earth (R $=$ La, Y, Lu) and Bi-based biferroic chromites,\nfocusing on $\\Gamma$ and $R$ point phonons of states with para-, ferro-, and\nantiferromagnetic ordering. We find that (a) the structure with G-type\nantiferromagnetic ordering is most stable, (b) the most dominant structural\ninstabilities in these oxides are the ones associated with rotations of oxygen\noctahedra, and (c) structural instabilities involving changes in Cr-O-Cr bond\nangle depend sensitively on the changes in magnetic ordering. The dependence of\nstructural instabilities on magnetic ordering can be understood in terms of how\nsuper-exchange interactions depend on the Cr-O-Cr bond angles and Cr-O bond\nlengths. We demonstrate how adequate buckling of Cr-O-Cr chains can favour\nferromagnetism. Born effective charges (BEC) calculated using the Berry phase\nexpression are found to be anomalously large for the A-cations, indicating\ntheir chemical relevance to ferroelectric distortions.\n", "machine_text": "\nWe present a first-principles study of the effects of structural instabilities on the magnetic properties of perovskite biferroics. We consider four different types of structural instability which can be captured by the Stillinger-Gr\u00fcneisen, Taylor, Cosmolly and Anti-phase domains models. We find that in all the cases the magnetic properties are significantly affected by the structural distortion, but the nature of this effect is very different in the various systems. In some cases the structural distortion has a large impact on the magnetic properties and can be used to achieve unique effects like a giant Barkhausen effect or a very large and fast switching of the magnetic susceptibility. In other cases the structural effect is small and has a small impact on the magnetic properties. We also find that the nature of the magnetic ordering is affected by the structural instability. In particular we find a strong effect on the kind of magnetic ordering which is stabilized over a wide range of temperatures. We also find a strong effect on the internal magnetic fields which are induced by the magnetic ordering. Our results suggest that in all the cases the structural instability and the magnetic instability are tightly coupled and that the structural instability can be used to achieve unique magnetic properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of Electron Interaction on Statistics of Conductance Oscillations\n  in Open Quantum Dots: Does the Dephasing Time Saturate?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0125, "human_text": "  We perform self-consistent quantum transport calculations in open quantum\ndots taking into account the effect of electron interaction. We demonstrative\nthat in the regime of the ultralow temperatures $2\\pi k_BT\\lesssim\\Delta$\n($\\Delta $ being the mean level spacing), the electron interaction strongly\naffects the conductance oscillations and their statistics leading to a drastic\ndeviation from the corresponding predictions for noninteracting electrons. In\nparticular, it causes smearing of conductance oscillations, which is similar to\nthe effect of temperature or inelastic scattering. For $2\\pi k_BT\\gtrsim\\Delta$\nthe influence of electron interaction on the conductance becomes strongly\ndiminished. Our calculations (that are free from phenomenological parameters of\nthe theory) are in good quantitative agreement with the observed ultralow\ntemperature statistics (Huibers \\textit{et al.}, Phys. Rev. Lett. \\textbf{81},\n1917 (1998)). Our findings question a conventional interpretation of the\nultralow temperature saturation of the coherence time in open dots which is\nbased on the noninteracting theories where the electron interaction is\nneglected and the agrement with the experiment is achieved by introducing\nadditional phenomenological channels of dephasing.\n", "machine_text": "\nWe study the effect of electron-electron interaction on the statistics of conductance oscillations in a quantum dot with two resonant energy levels. We consider a model in which the dot is weakly coupled to a linear reservoir and the driving is provided by a bias current applied to the reservoir. Our theory is based on the combination of a master equation for the probability distribution of the occupation of the quantum dot with an extension of the Einstein-Jacobi theory of quasi-periodic stochastic processes to the case of a non-Markovian system. The model parameters are adjusted to match the experimental data for a number of experiments. We show that the theory predicts a number of interesting features of the statistics of the conductance oscillations, in particular a decrease of the standard deviation of the conductance amplitude as a function of the dephasing time. Our predictions are consistent with a number of experimental observations, but do not agree with other experiments in which the dephasing time is large. We discuss possible physical reasons for this disagreement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonstationary random acoustic and electromagnetic fields as wave\n  diffusion processes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0525, "human_text": "  We investigate the effects of relatively rapid variations of the boundaries\nof an overmoded cavity on the stochastic properties of its interior acoustic or\nelectromagnetic field. For quasi-static variations, this field can be\nrepresented as an ideal incoherent and statistically homogeneous isotropic\nrandom scalar or vector field, respectively. A physical model is constructed\nshowing that the field dynamics can be characterized as a generalized diffusion\nprocess. The Langevin--It\\^{o} and Fokker--Planck equations are derived and\ntheir associated statistics and distributions for the complex analytic field,\nits magnitude and energy density are computed. The energy diffusion parameter\nis found to be proportional to the square of the ratio of the standard\ndeviation of the source field to the characteristic time constant of the\ndynamic process, but is independent of the initial energy density, to first\norder. The energy drift vanishes in the asymptotic limit. The time-energy\nprobability distribution is in general not separable, as a result of\nnonstationarity. A general solution of the Fokker--Planck equation is obtained\nin integral form, together with explicit closed-form solutions for several\nasymptotic cases. The findings extend known results on statistics and\ndistributions of quasi-stationary ideal random fields (pure diffusions), which\nare retrieved as special cases.\n", "machine_text": "\nWe consider a nonstationary random field, modeled as a wide-band random process with a power-law spectrum, subjected to an integral transform, that maps the field into a new field with a different power-law spectrum. The transform can be viewed as an unstable wave-diffusion process, which allows the investigation of the statistical properties of the nonstationary field in the context of the wave-diffusion theory. The random field is shown to be characterized by a stationary power spectrum, that describes the distribution of its energy, and a nonstationary power spectrum, that describes the statistical properties of its time evolution. We show that the nonstationary power spectrum can be obtained from the stationary power spectrum, by means of a simple relationship, and that it describes a wave-diffusion process with a dynamic coefficient related to the stationary power spectrum. A good characterization of the nonstationary random field is given by the wavespeed, that describes the speed at which the random field propagates, and the width of the random field, that describes the size of the random fluctuations. We show that these parameters can be related to the stationary and nonstationary power spectra by means of a simple formula. The wavespeed and the width of the random field can be used to define a new random field, called the random wavespeed field, that describes the speed and the size of the random fluctuations. The random wavespeed field is characterized by a power-law spectrum, that describes the distribution of its energy, and a nonstationary power spectrum, that describes the statistical properties of its time evolution. We show that the nonstationary power spectrum can be obtained from the power-law spectrum, by means of a simple relationship, and that it describes a wave-diffusion process with a dynamic coefficient related to the power-law spectrum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis of thermally stimulated luminescence and conductivity without\n  quasiequilibrium approximation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3497, "human_text": "  Thermally stimulated luminescence (TSL) and conductivity (TSC) are considered\nusing the classical insulator model that assumes one kind of the active trap,\none kind of inactive deep trap, and one kind of the recombination center.\nKinetic equations describing the model are solved numerically without and with\nthe use of the quasiequilibrium (QE) approximation. The QE state parameter qI,,\nthe relative recombination probability g, and a new parameter called\nquasi-stationary (QS) state parameter q*=qIg are used for the analysis of the\nTSL and TSC. The TSL and TSC curves and the temperature dependences of qI, q*,\ng, the recombination lifetime, and the occupancies of active traps and\nrecombination centers are numerically calculated for five sets of kinetic\nparameters and different heating rates. These calculation results show that:\n(1) the upper limit of the heating rate for presence of the QS state appears at\nhigher heating rate than that for the QE state when the retrapping process is\npresent, and (2) the TSL (TSC) curves in the QS state have the properties\nsimilar to those for the TSL (TSC) curves in the QE state. Approximate formulas\nfor calculation of the parameters qI and q* in the initial range of the TSL and\nTSC curves are derived and used in the heating-rate methods, proposed in this\nwork, for determination of those parameters from the calculated TSL curves.\n", "machine_text": "\n\nWe present an analysis of the transient photoconductivity and thermally stimulated luminescence (TSL) of amorphous silicon based on a model of the recombination and thermalization of photo-excited carriers in the amorphous silicon band-gap. Our formalism provides a rigorous thermodynamic framework for the analysis of the transient photoconductivity and TSL, without the assumption of thermal equilibrium, and can be used to study the transient photoconductivity and TSL under various experimental conditions, such as different excitation regimes and measurement procedures. The resulting equations for the transient photoconductivity and TSL can be solved analytically, in a closed form, for a wide range of parameters. The results obtained are in good agreement with both the available experimental data and previous theoretical treatments of the transient photoconductivity and TSL, which used the quasiequilibrium approximation. In particular, our results reproduce the recently reported discrepancy between the transient photoconductivity and steady-state photoconductivity, in the range of intermediate excited-state lifetimes, for the amorphous silicon model systems. Our analysis also reveals a new effect, the dependence of the transient photoconductivity and TSL on the thermalization time, which has not been reported before.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unconventional superconducting pairing by conventional phonons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2697, "human_text": "  The common wisdom that the phonon mechanism of electron pairing in the\nweak-coupling Bardeen-Cooper-Schrieffer (BCS) superconductors leads to\nconventional s-wave Cooper pairs is revised. An inevitable anisotropy of sound\nvelocity in crystals makes the phonon-mediated attraction of electrons\nnon-local in space providing unconventional Cooper pairs with a nonzero orbital\nmomentum in a wide range of electron densities. As a result of this anisotropy\nquasi-two dimensional charge carriers undergo a quantum phase transition from\nan unconventional d-wave superconducting state to a conventional s-wave\nsuperconductor with more carriers per unit cell. In the opposite\nstrong-coupling regime rotational symmetry breaking appears as a result of a\nreduced Coulomb repulsion between unconventional bipolarons dismissing thereby\nsome constraints on unconventional pairing in the Bose-Einstein condensation\n(BEC) limit. The conventional phonons, and not superexchange, are shown to be\nresponsible for the d-wave symmetry of cuprate superconductors, where the\non-site Coulomb repulsion is large.\n", "machine_text": "\n\nWe show that phonons, in a certain range of phonon frequencies, can provide an effective pairing mechanism for superconductivity, without the need of any additional charge transfer between the superconducting layers. We demonstrate this by studying the superconducting properties of a multilayered thin film structure of dielectric and superconducting YBa2Cu3O7\u2212\u03b4 (YBCO) and Y2BaCuO5 (Y211) layers, grown on a buffer layer of LaAlO3 and an SrTiO3 substrate. The dielectric YBCO layer was found to enhance the superconductivity in the Y211 layer, when the phonon frequencies in the YBCO layer are tuned in a certain range. We explain this enhancement by the formation of a pseudogap state in the Y211 layer, induced by a phonon-phonon coupling between the superconducting layers. Our results suggest that a careful design of the structural properties of the superconducting material, which affects the phonon spectrum, may provide an alternative way to design high-T_c superconducting materials by utilizing conventional charge carriers and phonons, without the need of the relatively more difficult to achieve charge transfer pairing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gravitational Stability of Circumnuclear Disks in Elliptical Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0005, "human_text": "  A significant fraction of nearby elliptical galaxies are known to have high\ndensity gas disks in their circumnuclear (CN) region (0.1 to a few kpc). Yet,\nellipticals, especially luminous ones, show little signs of recent star\nformation (SF). To investigate the possible cause of the dearth of SF in these\nsystems, we study the gravitational stability of CN gas disks embedded within\nthe potentials of both the stellar bulge and the central massive black hole\n(BH) in ellipticals. We find that CN disks in higher mass galaxies are\ngenerally more stable than those in lower mass galaxies, because higher mass\ngalaxies tend to have more massive BHs and more centrally concentrated stellar\ndensity profiles. We also consider the case in which the central stellar\ndensity profile has a core, which is often observed for ellipticals whose total\nstellar mass is higher than about 10^11 Msun. Such a cored stellar density\nprofile leads to more unstable CN disks than the power-law density profile\ncharacteristic of less massive galaxies. However, the more massive BHs in\nhigh-mass galaxies act to stabilize the CN disk. Our results demonstrate that\nthe gravitational potentials of both the central BH and the stellar component\nshould be taken into account when studying the properties of CN disks, as their\nstability is sensitive to both the BH mass and the stellar density profile. Our\nresults could explain the observed trend that less luminous ellipticals have a\ngreater tendency to exhibit ongoing SF than giant ellipticals.\n", "machine_text": "\n\nWe study the stability of circumnuclear disks in elliptical galaxies. We find that the gravitational instability of such disks is driven by the global structure of the host galaxy, and is not affected by the local properties of the disk itself. We show that the critical circum- disk density, above which the disk will be gravitationally unstable, is proportional to the square of the effective gravity at the disk's inner boundary. Our analysis reveals that the mass of the disk's inner boundary must be at least 5% of the host galaxy's total mass, in order for the disk to be gravitationally stable. We show that this condition is met only for disks with inner boundaries that are at least 1-2 effective radii away from the galaxy's center. We also find that the dynamical friction acting on the disk by the galactic potential can be as large as the viscous torque internal to the disk, and that it is this dynamical friction that eventually drives the disk to become unstable. Based on our analysis, we conclude that circumnuclear disks with inner boundaries located closer than about 1-2 effective radii to the center of the host galaxy are dynamically unstable, and will be unable to survive for significant lengths of time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The LuckyCam Survey for Very Low Mass Binaries II: 13 new M4.5-M6.0\n  Binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1812, "human_text": "  We present results from a high-angular-resolution survey of 78 very low mass\n(VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15\narcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new\nbinary systems range in separation between 0.18 arcsec and 1.3 arcsec. The\ndistance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with\nprevious results. 9 of the new binary systems have orbital radii > 10 AU,\nincluding a new wide VLM binary with 27 AU projected orbital separation. One of\nthe new systems forms two components of a 2300 AU separation triple system. We\nfind that the orbital radius distribution of the binaries with V-K < 6.5 in\nthis survey appears to be different from that of redder (lower-mass) objects,\nsuggesting a possible rapid change in the orbital radius distribution at around\nthe M5 spectral type. The target sample was also selected to investigate X-ray\nactivity among VLM binaries. There is no detectable correlation between excess\nX-Ray emission and the frequency and binary properties of the VLM systems.\n", "machine_text": "\nWe present the second part of the LuckyCam Survey for very low mass binaries. In this work we present 13 new M4.5-M6.0 binarians. We have also updated the mass function for the first part of the survey. The new mass function can be found in the supplemental material of the first part of the survey. With the current sample we can derive the mass function for M4.0-M5.0 objects. The sample contains bins with 13 objects and the most massive star in the system is between 1.01 and 1.36 solar masses. The most massive system in the sample has a systemic mass of 2.01 solar masses, a period of 87.1 minutes, and a semi-major axis of 9.8 solar radii. The median relative solar radii of the systems is 1.12, while the median orbital period is 78.9 minutes. The mass function for M4.0-M5.0 is well described by a power law with a cut-off mass of M\u22c5host = 1.89 \u00b1 0.08 solar masses, which corresponds to an age of 12.6 Gyr. We find a correlation between the orbital elements and the host star mass. The correlation between the semi-major axis and the host star mass can be described by a power law with a cut-off semi-major axis of a\u22c5host = 7.45 \u00b1 0.75 solar radii, which corresponds to an age of 12.2 Gyr. The correlation between the orbital period and the host star mass can be described by a power law with a cut-off orbital period of P\u22c5host = 61.03 \u00b1 12.68 minutes, which corresponds to an age of 11.6 Gyr. This correlation can be used to derive an age estimate for a given very low mass binary system. We found a median orbital period of 78.9 minutes. Systems with longer orbital periods are likely to be older than the ones with shorter orbital periods. We estimated the age of the sample to be 11.6 \u00b1 1.4 Gyr. The derived mass function for M4.0-M5.0 can be used to derive the age of a given very low mass binary. The best fit age is 12.6 Gyr.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galaxy Colours in the AKARI Deep SEP Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.186, "human_text": "  We investigate the segregation of the extragalactic population via colour\ncriteria to produce an efficient and inexpensive methodology to select specific\nsource populations as a function of far-infrared flux. Combining galaxy\nevolution scenarios and a detailed spectral library of galaxies, we produce\nsimulated catalogues incorporating segregation of the extragalactic population\ninto component types (Normal, star-forming, AGN) via color cuts. As a practical\napplication we apply our criteria to the deepest survey to be undertaken in the\nfar-infrared with the AKARI (formerly ASTRO-F) satellite. Using the\nfar-infrared wavebands of the Far-Infrared Surveyor (FIS, one of the\nfocal-plane instruments on AKARI) we successfully segregate the normal,\nstarburst and ULIRG populations. We also show that with additional MIR imaging\nfrom AKARI's Infrared Camera (IRC), significant contamination and/or degeneracy\ncan be further decreased and show a particular example of the separation of\ncool normal galaxies and cold ULIRG sources. We conclude that our criteria\nprovide an efficient means of selecting source populations (including rare\nluminous objects) and produce colour-segregated source counts without the\nrequirement of time intensive ground-based follow up to differentiate between\nthe general galaxy population.\n", "machine_text": "\n\nWe present colour-magnitude diagrams (CMDs) for a sample of galaxies selected from the AKARI Deep SEP Survey. The sample consists of galaxies in the redshift range 0.005 < z_reio < 1.5 with SEP luminosities in the range 10^36 - 10^37 erg s^-1, of which 50 are active galaxies and 50 are galaxies in the local volume. We use the AKARI archive to extract the necessary photometry and spectroscopy, and fit the resulting CMDs with a single broken power law. We then compare the galaxy colours in the local volume to those of the active galaxies, and find that the colours of the most luminous galaxies in the two samples are consistent with the colours of galaxies in the local volume, but that the colours of the less luminous galaxies in the active galaxy sample are consistent with a different relation, suggesting that the most luminous galaxies in the active galaxy sample are likely to be local galaxies, while the faintest galaxies in the active galaxy sample are likely to be distant galaxies. We discuss this conclusion in the context of the cosmological model, and find that a model in which the star formation density is scale invariant requires that the most luminous galaxies in the active galaxy sample be local galaxies, while a model in which the star formation density is scale dependent requires that the faintest galaxies in the active galaxy sample be distant galaxies. We discuss the implications of this result for galaxy formation in hierarchical structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing outer boundary treatments for the Einstein equations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0782, "human_text": "  Various methods of treating outer boundaries in numerical relativity are\ncompared using a simple test problem: a Schwarzschild black hole with an\noutgoing gravitational wave perturbation. Numerical solutions computed using\ndifferent boundary treatments are compared to a `reference' numerical solution\nobtained by placing the outer boundary at a very large radius. For each\nboundary treatment, the full solutions including constraint violations and\nextracted gravitational waves are compared to those of the reference solution,\nthereby assessing the reflections caused by the artificial boundary. These\ntests use a first-order generalized harmonic formulation of the Einstein\nequations. Constraint-preserving boundary conditions for this system are\nreviewed, and an improved boundary condition on the gauge degrees of freedom is\npresented. Alternate boundary conditions evaluated here include freezing the\nincoming characteristic fields, Sommerfeld boundary conditions, and the\nconstraint-preserving boundary conditions of Kreiss and Winicour. Rather\ndifferent approaches to boundary treatments, such as sponge layers and spatial\ncompactification, are also tested. Overall the best treatment found here\ncombines boundary conditions that preserve the constraints, freeze the\nNewman-Penrose scalar Psi_0, and control gauge reflections.\n", "machine_text": "\nWe study the effectiveness of boundary treatments for the Einstein equations. In particular, we consider the effects of placing an impenetrable boundary, a boundary with a cosine profile, and a penetrable boundary on the solutions to the Einstein equations for a Schwarzschild black hole and a Kerr black hole, respectively. We find that, in contrast to the traditional view, the choice of the outer boundary treatment does not have any significant effect on the shape of the inner horizon, but it does affect the shape of the outer horizon. For the Schwarzschild black hole, we show that a boundary with a cosine profile is effective in producing a spherical outer horizon, whereas an impenetrable boundary is not. For the Kerr black hole, we show that a boundary with a cosine profile is again effective in producing a spherical outer horizon, but a penetrable boundary is effective only if the boundary is very close to the black hole. We also study the energy evolution of the black holes and find that the energy evolution is affected by the outer boundary treatment. For the Schwarzschild black hole, the energy evolution is the same for all the outer boundary treatments considered. For the Kerr black hole, however, the energy evolution depends on the outer boundary treatment. In particular, we show that the energy of the Kerr black hole monotonically decreases in time if the outer boundary is penetrable, but it does not decrease monotonically if the outer boundary is either impenetrable or with a cosine profile. We also show that the energy of the Kerr black hole is strictly decreasing if the outer boundary is with a cosine profile but not strictly decreasing if the outer boundary is impenetrable or penetrable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Room temperature coexistence of large electric polarization and magnetic\n  order in BiFeO3 single crystals. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0404, "human_text": "  From an experimental point of view, room temperature ferroelectricity in\nBiFeO3 is raising many questions. Electric measurements made a long time ago on\nsolid-solutions of BiFeO3 with Pb(Ti,Zr)O3 indicate that a spontaneous electric\npolarization exists in BiFeO3 below the Curie temperature TC=1143K. Yet in most\nreported works, the synthesised samples are too conductive at room temperature\nto get a clear polarization loop in the bulk without any effects of extrinsic\nphysical or chemical parameters. Surprisingly, up to now there has been no\nreport of a P(E) (polarization versus electric field) loop at room temperature\non single crystals of BiFeO3. We describe here our procedure to synthesize\nceramics and to grow good quality sizeable single crystals by a flux method. We\ndemonstrate that BiFeO3 is indeed ferroelectric at room-temperature through\nevidence by Piezoresponse Force Microscopy and P(E) loops. The polarization is\nfound to be large, around 60 microC/cm2, a value that has only been reached in\nthin films. Magnetic measurements using a SQUID magnetometer and Mossbauer\nspectroscopy are also presented. The latter confirms the results of NMR\nmeasurements concerning the anisotropy of the hyperfine field attributed to the\nmagnetic cycloidal structure.\n", "machine_text": "\n\nWe report the observation of a large electric polarization and magnetic order coexistence in single crystals of BiFeO3. The large electric polarization can be tuned by both the magnetic field and the temperature, and it is very stable against the temperature changes. The static and dynamic magnetic properties and the relationship between the electric polarization and the magnetic field are studied. Our results may be useful for the design and development of novel magnetic-non-magnetic nanocomposite materials.\n\nThe structural, magnetic and electric properties of BiFeO3 have attracted increasing attention due to its potential application in magnetic-non-magnetic nanocomposite materials. Single crystals of BiFeO3 were reported to possess a large electric polarization, which could be tuned by both the magnetic field and the temperature. However, the coexistence of large electric polarization and magnetic order in BiFeO3 has not yet been reported, although it is crucial for the design and development of novel magnetic-non-magnetic nanocomposite materials. In this work, we report the observation of a large electric polarization and magnetic order coexistence in single crystals of BiFeO3. The large electric polarization can be tuned by both the magnetic field and the temperature, and it is very stable against the temperature changes. The static and dynamic magnetic properties and the relationship between the electric polarization and the magnetic field are studied. Our results may be useful for the design and development of novel magnetic-non-magnetic nanocomposite materials.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Calibration of the GLAST Burst Monitor detectors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2184, "human_text": "  The GLAST Burst Monitor (GBM) will augment the capabilities of GLAST for the\ndetection of cosmic gamma-ray bursts by extending the energy range (20 MeV to >\n300 GeV) of the Large Area Telescope (LAT) towards lower energies by 2\nBGO-detectors (150 keV to 30 MeV) and 12 NaI(Tl) detectors (10 keV to 1 MeV).\nThe physical detector response of the GBM instrument for GRBs is determined\nwith the help of Monte Carlo simulations, which are supported and verified by\non-ground calibration measurements, performed extensively with the individual\ndetectors at the MPE in 2005. All flight and spare detectors were irradiated\nwith calibrated radioactive sources in the laboratory (from 14 keV to 4.43\nMeV). The energy/channel-relations, the dependences of energy resolution and\neffective areas on the energy and the angular responses were measured. Due to\nthe low number of emission lines of radioactive sources below 100 keV,\ncalibration measurements in the energy range from 10 keV to 60 keV were\nperformed with the X-ray radiometry working group of the\nPhysikalisch-Technische Bundesanstalt (PTB) at the BESSY synchrotron radiation\nfacility, Berlin.\n", "machine_text": "\n\nWe describe results of a program to calibrate the GLAST Burst Monitor (GBM) detectors. The GBM detectors comprise a ring of 24 parallel-connected Cadmium-Zinc-Telluride (CZT) detectors surrounding the GLAST gamma-ray detectors. Each CZT detector has a single-pixel readout circuit, and thus the GBM detectors act as a single pixel image sensor with a spatial resolution of 2.5 degrees. The GBM detectors are used to identify cosmic-ray bursts and to measure the total rate of cosmic rays in the energy range above 100 keV. We describe methods to reduce the time to detect a burst from several seconds to a few milliseconds, to improve the ability to detect bursts that occur close to the time that a gamma-ray burst triggers the GLAST detectors. We also describe methods to improve the spatial resolution of the GBM detectors, by combining the signals from the individual CZT detectors in a way that reduces both the noise and the spatial sensitivity to single-pixel failures. We present measured spatial and temporal responses of the GBM detectors, and we discuss how the responses depend on the selected combination of signals from the individual CZT detectors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Difermion condensates in vacuum in 2-4D four-fermion interaction models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0841, "human_text": "  Theoretical analysis of interplay between the condensates $<\\bar{q}q>$ and\n$<qq>$ in vacuum is generally made by relativistic effective potentials in the\nmean field approximation in 2D, 3D and 4D models with two flavor and $N_c$\ncolor massless fermions. It is found that in ground states of these models,\ninterplay between the two condensates mainly depend on the ratio $G_S/H_S$ for\n2D and 4D case or $G_S/H_P$ for 3D case, where $G_S$, $H_S$ and $H_P$ are\nrespectively the coupling constants in a scalar $(\\bar{q}q)$, a scalar $(qq)$\nand a pseudoscalar $(qq)$ channel. In ground states of all the models, only\npure $<\\bar{q}q>$ condensates could exist if $G_S/H_S$ or $G_S/H_P$ is bigger\nthan the critical value $2/N_c$, the ratio of the color numbers of the fermions\nentering into the condensates $<qq>$ and $<\\bar{q}q>$. As $G_S/H_S$ or\n$G_S/H_P$ decreases to the region below $2/N_c$, differences of the models will\nmanifest themselves. Depending on different models, and also on $N_c$ in 3D\nmodel, one will have or have no the coexistence phase of the two condensates,\nbesides the pure $<qq>$ condensate phase. The $G_S-H_S$ (or $G_S-H_P$) phase\ndiagrams in these models are given. The results also implicate a real\nconstraint on two-flavor QCD-analogous NJL model.\n", "machine_text": "\n\nWe study Difermion condensates in vacuum in 2-4D four-fermion interaction models. We consider an effective two- Fermion model in a four-dimensional space-time in the presence of a non-Abelian symplectic group, which provides a break of the Lorentz invariance. In a four-dimensional space-time, this model has a one-dimensional fermion condensate with a non-Abelian structure. We also consider the evolution of this condensate in a space-time with a three-dimensional axial symmetry. The symplectic group is related to the three-dimensional geometry in the following way: the condensate is either symmetric or antisymmetric under the three-dimensional exchange of the fermions. In a space-time with a four-dimensional rotational symmetry, the fermions are related to the four-dimensional Lorentz invariance. We show that this relation is broken when the condensate becomes symmetric under the three-dimensional exchange of the fermions. This happens in a space-time with a three-dimensional axial symmetry. We also discuss the possibility of the creation of a new quark color by the interaction of the fermions with a D-brane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hitting probabilities for systems of non-linear stochastic heat\n  equations with multiplicative noise. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1312, "human_text": "  We consider a system of d non-linear stochastic heat equations in spatial\ndimension 1 driven by d-dimensional space-time white noise. The non-linearities\nappear both as additive drift terms and as multipliers of the noise. Using\ntechniques of Malliavin calculus, we establish upper and lower bounds on the\none-point density of the solution u(t,x), and upper bounds of Gaussian-type on\nthe two-point density of (u(s,y),u(t,x)). In particular, this estimate\nquantifies how this density degenerates as (s,y) converges to (t,x). From these\nresults, we deduce upper and lower bounds on hitting probabilities of the\nprocess {u(t,x)}_{t \\in \\mathbb{R}_+, x \\in [0,1]}, in terms of respectively\nHausdorff measure and Newtonian capacity. These estimates make it possible to\nshow that points are polar when d >6 and are not polar when d<6. We also show\nthat the Hausdorff dimension of the range of the process is 6 when d>6, and\ngive analogous results for the processes t \\mapsto u(t,x) and x \\mapsto u(t,x).\nFinally, we obtain the values of the Hausdorff dimensions of the level sets of\nthese processes.\n", "machine_text": "\n\nWe consider a system of stochastic heat equations with multiplicative noise. The solution of the system is a random process, whose probability distribution is calculated. This distribution has a strong dependency on the initial conditions, in a way very similar to the one displayed by the solutions of the Cauchy problem for a system of nonlinear ordinary differential equations. For a large class of initial conditions, this distribution has a heavy tail, with a finite number of local maxima. The probability that the solution stays in a small neighborhood of a given value decreases quickly as this value is approached from either side. In particular, the probability that the solution hits a given value from above or below is very small. For a particular choice of the initial conditions, the distribution of the solution is a mixture of two distributions, one with a large number of local maxima, and the other with a large number of local minima. The probabilities that the solution passes from one type of solution to the other are very small.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-IR Spectra of Red Supergiants and Giants. I- Models with Solar and\n  with Mixing-Induced Surface Abundance Ratios. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.212, "human_text": "  We provide a grid of PHOENIX spectra of red giant and supergiant stars, that\nextend through optical and near-IR wavelengths. For the first time, models are\nalso provided with modified surface abundances of C, N and O, as a step towards\naccounting for the changes known to occur due to convective dredge-up (and to\nbe enhanced in the case of rotation). The aims are (i) to assess how well\ncurrent models reproduce observed spectra, (ii) to quantify the effects of the\nabundance changes on the spectra, and (iii) to determine how these changes\naffect estimates of fundamental stellar parameters.\n  Observed giant star spectra can be fitted very well at solar metallicity down\nto about 3400K. Modified surface abundances are preferred in only a minority of\ncases for luminosity class II, possibly indicating mixing in excess of standard\nfirst dredge-up.\n  Supergiant stars show a larger variety of near-IR spectra, and good fits are\ncurrently obtained for about one third of the observations only. Modified\nsurface abundances help reproducing strong CN bands, but do not suffice to\nresolve all the difficulties. The effect of the abundance changes on the\nestimated Teff depends on the wavelength range of observation and can amount\nseveral 100K. Reasons for the remaining discrepancies are discussed.\n", "machine_text": "\nWe present a method for the determination of mixing-induced surface abundance ratios in cool supergiants and giants on the basis of near-infrared (NIR) spectra. The method is based on a least-squares fit to a model of the atmosphere, which includes an equation of state, a microturbulent velocity, and two surface abundance ratios. We apply the method to the analysis of NIR spectra of supergiants and giants in the solar neighborhood. The surface abundance ratios are derived from the analysis of several spectral regions, in which sensitive molecular bands occur. We determine the relative molecular abundance and the mixing-induced surface abundance ratios. The relative molecular abundances are consistent with the solar abundance, except for giants with an evolutionary state close to the red giant branch-point, which show a significant enrichment in C and N. The mixing-induced surface abundance ratios are consistent with a variety of possible interior structures. We discuss our results in the framework of current theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation study of the two-dimensional Burridge-Knopoff model of\n  earthquakes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1871, "human_text": "  Spatiotemporal correlations of the two-dimensional spring-block\n(Burridge-Knopoff) model of earthquakes are extensively studied by means of\nnumerical computer simulations. The model is found to exhibit either\n``subcritical'' or ``supercritical'' behavior, depending on the values of the\nmodel parameters. Transition between these regimes is either continuous or\ndiscontinuous. Seismic events in the ``subcritical'' regime and those in the\n``supercritical'' regime at larger magnitudes exhibit universal scaling\nproperties. In the ``supercritical'' regime, eminent spatiotemporal\ncorrelations, {\\it e.g.}, remarkable growth of seismic activity preceding the\nmainshock, arise in earthquake occurrence, whereas such spatiotemporal\ncorrelations are significantly suppressed in the ``subcritical'' regime.\nSeismic activity is generically suppressed just before the mainshock in a close\nvicinity of the epicenter of the upcoming event while it remains to be active\nin the surroundings (the Mogi doughnut). It is also observed that, before and\nafter the mainshock, the apparent $B$-value of the magnitude distribution\ndecreases or increases in the ``supercritical'' or ``subcritical'' regimes,\nrespectively. Such distinct precursory phenomena may open a way to the\nprediction of the upcoming large event.\n", "machine_text": "\n\nWe study the two-dimensional Burridge-Knopoff model of earthquakes by numerical simulation. The model consists of a background medium in which quakes nucleate and grow in an arcade-like pattern. We find that the dynamic structure of the system is characterized by a large number of branches of different length, which are all connected at their tips. These branches are capable of initiating quakes of various sizes, and the probability distribution of the sizes is given by the Gumbel distribution. In this way, the model is able to generate quakes of all sizes in a manner that is consistent with the observed size distribution of earthquakes. We also find that the dynamic behavior of the system is characterized by an exponential increase in the number of branches as the system evolves, and that the distribution of the number of branches at any time is given by a power law. The finding that the number of branches grows exponentially is consistent with the observation that the number of earthquakes does not change monotonically but rather shows sharp increases and decreases. We also discuss the effect of various model parameters on the dynamic behavior of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Systematic Study of Departures from Chemical Equilibrium in the\n  Atmospheres of Substellar Mass Objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3922, "human_text": "  We present a systematic study of the spectral consequences of departures from\nchemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler\ndwarfs. The temperature/pressure profiles of the non-equilibrium models are\nfully consistent with the non-equilibrium chemistry. Our grid of\nnon-equilibrium models includes spectra for effective temperatures from 200 K\nto 1800 K, three surface gravities, four possible values of the coefficient of\neddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical\nreaction prescriptions. We find that the non-equilibrium overabundance of CO\ntranslates into flux suppressions in the M ($\\sim4-$5 $\\mu$m) band of at most\n$\\sim$40% between effective temperatures of 600 and 1800 K. The effect is\nlargest around $T_{\\rm eff} \\approx 1100$ K. The underabundance of ammonia due\nto non-equilibrium chemistry translates into flux enhancements of no more than\n$\\sim$20% for the $T_{\\rm eff}$ range from 300 to 1800 K, with the largest\neffects at the lowest values of $T_{\\rm eff}$. The magnitude of the departure\nfrom chemical equilibrium increases with decreasing gravity, with increasing\neddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$\nreaction. Though these effects are modest, they lead to better fits with the\nmeasured T dwarf spectra. Furthermore, the suppression in the M band due to\nnon-equilibrium enhancements in the CO abundance disappears below $\\sim$500 K,\nand is only partial above $\\sim$500 K, preserving the M band flux as a useful\ndiagnostic of cool atmospheres and maintaining its importance for searches for\nbrown dwarfs cooler than T dwarfs.\n", "machine_text": "\n\nWe present a systematic study of the departure from chemical equilibrium in the atmospheres of substellar mass objects. The main motivation for this work is the fact that the atmospheres of these objects are known to be chemically non-equilibrium, and the large number of molecular species that have been detected in the atmosphere of the solar twin planet, HD 209458 b, implies that this chemical non-equilibrium may be significant. We focus our study on giant exoplanets and brown dwarfs with known atmospheres, and explore how the chemical composition of these atmospheres depart from chemical equilibrium. We find that the most chemically non-equilibrium atmosphere is that of the brown dwarf, Gliese 667 Cc, which contains several species in excess of what would be expected from equilibrium chemistry, including carbon monoxide and acetone. We also find that giant exoplanet atmospheres are, on average, more chemically equilibrated than brown dwarf atmospheres, and that the chemical equilibrium is strongly dependent on the metallicity of the object. Our results suggest that chemical equilibrium is not well described by the mean molecular weight approach used in this work, and that a more sophisticated approach is needed to properly describe chemical equilibrium in these atmospheres.\n\nWe thank the following people for helpful discussions: C. Bezard, P.E. Bergren, A. Bersten, J.B. League, M.D. 10.1223/\u200b0895685X\u205796, R.W. Darmody, C. Derse, R.F. Howard, K.M. Marteau, R.W. O' 10241/\u200b99\u205712, B.N.S. Pirronello, J.E. Raymond, J.M. Strategies, P.J. Stephenson, R. St\u00fcnitz, M. PAssertion, A.M.S. Smith, and M. Dummel. This work was supported by NASA grant NNG06GH35G and the Australian Research Council through the Centres of Excellence scheme (projects number CE1100010015 and CE120009100). Some of this work was done while C.B. was on sabbatical at the University of Texas at Austin and the University of Colorado, Boulder.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Out-of-equilibrium relaxation of the Edwards-Wilkinson elastic line. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3348, "human_text": "  We study the non-equilibrium relaxation of an elastic line described by the\nEdwards-Wilkinson equation. Although this model is the simplest representation\nof interface dynamics, we highlight that many (not though all) important\naspects of the non-equilibrium relaxation of elastic manifolds are already\npresent in such quadratic and clean systems. We analyze in detail the aging\nbehaviour of several two-times averaged and fluctuating observables taking into\naccount finite-size effects and the crossover to the stationary and equilibrium\nregimes. We start by investigating the structure factor and extracting from its\ndecay a growing correlation length. We present the full two-times and size\ndependence of the interface roughness and we generalize the Family-Vicsek\nscaling form to non-equilibrium situations. We compute the incoherent cattering\nfunction and we compare it to the one measured in other glassy systems. We\nanalyse the response functions, the violation of the fluctuation-dissipation\ntheorem in the aging regime, and its crossover to the equilibrium relation in\nthe stationary regime. Finally, we study the out-of-equilibrium fluctuations of\nthe previously studied two-times functions and we characterize the scaling\nproperties of their probability distribution functions. Our results allow us to\nobtain new insights into other glassy problems such as the aging behavior in\ncolloidal glasses and vortex glasses.\n", "machine_text": "\n\nWe consider a model of a finite chain of rigid disks connected by elastic cords, which is placed on a flat surface and subjected to an arbitrarily time-dependent strain. The equilibration of this system is investigated by a combination of analytical and numerical techniques, which allows us to evaluate the out-of-equilibrium relaxation rates for the shape and the elastic line. Our main result is an exact formula for the relaxation rate of the elastic line, which is shown to agree with previous approximate results obtained from a statistical mechanics approach. In addition, we also obtain an approximate formula for the relaxation rate of the shape. The parameters of our model can be related to the characteristics of the experimental system and the imposed strain in a straightforward manner, which allows us to study the effect of the relevant parameters on the relaxation rate. Our results show that the relaxation rate increases with the number of disks and decreases with the cord stiffness and the spatial correlation of the strain. We also find that the relaxation rate has a minimum, which depends on the cord length and the strain correlation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spatially resolved kinematics and stellar populations of brightest\n  cluster and group galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3097, "human_text": "  We present an examination of the kinematics and stellar populations of a\nsample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies\n(BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise\nGemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these\ngalaxies and use Lick indices to determine ages, metallicities and\nalpha-element abundance ratios out to at least their effective radii. We find\nthat the BGGs and BCGs have very uniform masses, central ages and central\nmetallicities. Examining the radial dependence of their stellar populations, we\nfind no significant velocity dispersion, age, or alpha-enhancement gradients.\nHowever, we find a wide range of metallicity gradients, suggesting a variety of\nformation mechanisms. The range of metallicity gradients observed is surprising\ngiven the homogeneous environment these galaxies probe and their uniform\ncentral stellar populations. However, our results are inconsistent with any\nsingle model of galaxy formation and emphasize the need for more theoretical\nunderstanding of both the origins of metallicity gradients and galaxy formation\nitself. We postulate two possible physical causes for the different formation\nmechanisms.\n", "machine_text": "\n\nWe present spatially resolved kinematics and stellar population properties of the brightest cluster and group galaxies (BCGs), based on a sample of 24 galaxies in 19 groups and clusters selected from the SDSS, and three galaxies in the Leo Group from VLA/CVF data. We find that the kinematics and stellar populations of the BCGs are well described by two parameters: the cluster/groupcentric distance and the galaxycentric distance within the group/cluster. The kinematics and stellar population properties of a given galaxy vary smoothly and continuously with these two distances, and change abruptly at the boundary of the group/cluster. We find no evidence of kinematic or stellar population differentiation within a group/cluster, except possibly in the Leo Group, although the sample is small. We find a correlation between the kinematic properties and stellar population properties, indicating that both are driven by the same physical mechanism. We show that the observed correlation can be explained by a simple model in which the galaxies are described by a set of parameters that vary smoothly and continuously with the cluster/groupcentric and galaxycentric distances. We use the model to predict the kinematic and stellar population properties of a galaxy in a face-on group/cluster, and find that the predicted properties agree well with observations, supporting the model. We discuss the implications of our results for the role of the group/cluster environment in shaping the kinematic and stellar population properties of galaxies, and for the use of the group/cluster environment as a probe of galactic structure and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Diagrammatic Category for the Representation Theory of U_q(sl_n). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1503, "human_text": "  This thesis provides a partial answer to a question posed by Greg Kuperberg\nin q-alg/9712003 and again by Justin Roberts as problem 12.18 in \"Problems on\ninvariants of knots and 3-manifolds\", math.GT/0406190, essentially: \"Can one\ndescribe the category of representations of the quantum group U_q(sl_n)\n(thought of as a spherical category) via generators and relations?\"\n  For each n \\geq 0, I define a certain tensor category of trivalent graphs,\nmodulo isotopy, and construct a functor from this category onto (a full\nsubcategory of) the category of representations of the quantum group U_q(sl_n).\nOne would like to describe completely the kernel of this functor, by providing\ngenerators. The resulting quotient of the diagrammatic category would then be a\ncategory equivalent to the representation category of U_q(sl_n).\n  I make significant progress towards this, describing certain generators of\nthe kernel, and some obstructions to further elements. It remains a conjecture\nthat these relations generate the kernel. My results extend those of\nq-alg/9712003, MR1659228, math.QA/0310143 and math.GT/0506403.\n  The argument is essentially by constructing a diagrammatic version of the\nforgetful functor coming from the inclusion of U_q(sl_{n-1}) in U_q(sl_n}. We\nknow this functor is faithful, so a diagram is in the kernel for n exactly if\nits image under the diagrammatic forgetful functor is in the kernel for n-1.\nThis allows us to perform inductive calculations, both establishing families of\nelements of the kernel, and finding obstructions.\n", "machine_text": "\n\nWe give a diagrammatic category for the representation theory of U_q(sl_n). We show that certain quotient categories of this category are \"acting objects\" in a suitable category of categories.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Search for Single-Top Production at CDF. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2954, "human_text": "  This article reports on recent searches for single-top-quark production by\nthe CDF collaboration at the Tevatron using a data set that corresponds to an\nintegrated luminosity of 955 pb^-1. Three different analyses techniques are\nemployed, one using likelihood discriminants, one neural networks and one\nmatrix elements. The sensitivity to single-top production at the rate predicted\nby the standard model ranges from 2.1 to 2.6 sigma. While the first two\nanalyses observe a deficit of single-top like events compared to the\nexpectation, the matrix element method observes an excess corresponding to a\nbackground fluctuation of 2.3 sigma. The null results of the likelihood and\nneural network analyses translate in upper limits on the cross section of 2.6\\\npb for the t-channel production mode and 3.7 pb for the s-channel mode at the\n95% C.L. The matrix element result corresponds to a measurement of\n2.7^+1.5_-1.3 pb for the combined t- and s-channel single-top cross section. In\naddition, CDF has searched for non-standard model production of\nsingle-top-quarks via the s-channel exchange of a heavy W^\\prime boson. No\nsignal of this process is found resulting in lower mass limits of 760 GeV/c^2\nin case the mass of the right-handed neutrino is smaller than the mass of the\nright-handed W^\\prime or 790 GeV/c^2 in the opposite case.\n", "machine_text": "\n\nWe present here the results of a search for single-top production in p-pbar collisions at \\sqrt{s}=1.96 TeV, based on a sample of beam-dump collisions collected with the CDF detector. We use a signal model with hadronization and reconstruction parameters obtained from a previous search in \\sqrt{s}=1.96 TeV collisions involving a lepton pair and in \\sqrt{s}=0.96 TeV collisions with only one lepton. We use the mass of the lightest neutral hadron as a marker for the produced top quark. The search strategy is based on the analysis of events with one or two leptons, and on the distribution of the hadron masses in the events with two leptons. We observe 2 events with a hadron mass greater than the expected background, and 1 event with a hadron mass in the expected background range. We observe no significant excess over the expected background. We set cross section limits in a range of center-of-mass energy assuming the standard model production mechanism. The analysis presented here is the first search for single-top production in hadron collisions at \\sqrt{s}=1.96 TeV, and the first analysis of top quark production in hadron collisions to use the full CDF data set.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Heat Capacity of PbS: Isotope Effects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1804, "human_text": "  In recent years, the availability of highly pure stable isotopes has made\npossible the investigation of the dependence of the physical properties of\ncrystals, in particular semiconductors, on their isotopic composition.\nFollowing the investigation of the specific heat ($C_p$, $C_v$) of monatomic\ncrystals such as diamond, silicon, and germanium, similar investigations have\nbeen undertaken for the tetrahedral diatomic systems ZnO and GaN (wurtzite\nstructure), for which the effect of the mass of the cation differs from that of\nthe anion. In this article we present measurements for a semiconductor with\nrock salt structure, namely lead sulfide. Because of the large difference in\nthe atomic mass of both constituents ($M_{\\rm Pb}$= 207.21 and ($M_{\\rm\nS}$=32.06 a.m.u., for the natural isotopic abundance) the effects of varying\nthe cation and that of the anion mass are very different for this canonical\nsemiconductor. We compare the measured temperature dependence of $C_p \\approx\nC_v$, and the corresponding derivatives with respect to ($M_{\\rm Pb}$ and\n$M_{\\rm S}$), with \\textit{\\textit{ab initio}} calculations based on the\nlattice dynamics obtained from the local density approximation (LDA) electronic\nband structure. Quantitative deviations between theory and experiment are\nattributed to the absence of spin-orbit interaction in the ABINIT program used\nfor the electronic band structure calculations.\n", "machine_text": "\n\nWe have measured the heat capacity of PbS as a function of temperature for several atoms. The isotope effect on the heat capacity has been determined for the stable isotopes with mass numbers 204, 206, and 208. The heat capacity of PbS is found to be extremely well described by a model in which the electronic contribution to the heat capacity is independent of temperature. The excess heat capacity has a positive temperature coefficient, suggesting that it is due to a contribution from the lattice. The agreement between the model and the data is good for temperatures below T \u2248 100 K, but poor for higher temperatures. The discrepancy is greatest for the isotope with the largest nuclear mass, 208Pb. We have also measured the magnetic specific heat of PbS, but the results are not definitive, as magnetic fields were not sufficiently stable. The low temperature heat capacity of PbS, in spite of its poor agreement with the model, is consistent with the heat capacity being due to lattice vibrations. The high temperature behavior is consistent with a model in which the electronic contribution to the heat capacity is independent of temperature, but the lattice contribution has a positive temperature coefficient. We discuss the results in the framework of a simple model in which the ions move in a square lattice, and the electronic states are described by a tight binding model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Witnessing the formation of a galaxy cluster at z=0.485: optical and\n  X-ray properties of RX J1117.4+0743 ([VMF 98] 097). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2459, "human_text": "  We present a multiwavelength study of the poor cluster RX J1117.4+0743 ([VMF\n98] 097) at z=0.485, based on GMOS/Gemini South g', r' photometry and\nspectroscopy, and XMM-Newton observations. We examine its nature and\nsurroundings by analyzing the projected galaxy distribution, the galaxy\nvelocity distribution, the weak-lensing mass reconstruction, and the X-ray\nspectroscopy and imaging. The cluster shows a complex morphology. It is\ncomposed by at least two structures along the line-of-sight, with velocity\ndispersions of 592+-82 km s^-1 and 391+-85 km s^-1 respectively. Other\nstructures are also detected in X-ray, in the galaxy projected number density\nmap, and by weak-lensing. One of these clumps, could be gravitationally bound\nand associated to the main cluster. The derived temperature and bolometric\nX-ray luminosity reveal that [VMF 98] 097 behave like a normal cluster, in\nagreement with Lx-Tx correlation found for both local (z=0) and moderate\nredshift (z~0.4) clusters. We find that the mass determination inferred from\nweak-lensing is in average 3 to 4.8 times higher (depending on the model\nassumed) than the X-ray mass. We have two possible explanations for this\ndiscrepancy: i) the cluster is in non-equilibrium, then the deviation of the\nX-ray estimated mass from the true value can be as high as a factor of two; ii)\nthe intervening mass along the line-of-sight of the cluster is producing an\nover-estimation of the weak-lensing mass. Based on the analysis presented, we\nconclude that [VMF 98] 097 is a perturbed cluster with at least two\nsubstructures in velocity space and with other nearby structures at projected\ndistances of about 1 h^-1 Mpc. This cluster is an example of a poor cluster\ncaught in the process of accreting sub-structures to become a rich cluster.\n", "machine_text": "\n\nWe present here results of a multiwavelength study of the galaxy cluster RX J1117.4+0743 at z=0.485, in an effort to determine the role of cluster accretion in the formation of massive clusters. We find that this cluster, which is thought to be in the process of accreting a large group of galaxies, has many of the same properties as clusters that are thought to have formed through the accretion of many small groups. These properties include a large fraction of cool, blue galaxies, and a temperature-declining gas profile. We present a detailed study of the cluster's galaxies in the optical and X-ray, and show that the cool, blue galaxies are likely to be a relatively large group that has already been accreted, and that the hot gas in the cluster has not yet been strongly affected by this group's infall. We discuss the importance of this study in the context of the evolution of massive clusters, and suggest that the simplest models of cluster formation that are based on the accretion of small groups may need to be modified.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modeling Repulsive Gravity with Creation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0544, "human_text": "  There is a growing interest in the cosmologists for theories with negative\nenergy scalar fields and creation, in order to model a repulsive gravity. The\nclassical steady state cosmology proposed by Bondi, Gold and Hoyle in 1948, was\nthe first such theory which used a negative kinetic energy creation field to\ninvoke creation of matter. We emphasize that creation plays very crucial role\nin cosmology and provides a natural explanation to the various explosive\nphenomena occurring in local (z<0.1) and extra galactic universe. We exemplify\nthis point of view by considering the resurrected version of this theory - the\nquasi-steady state theory, which tries to relate creation events directly to\nthe large scale dynamics of the universe and supplies more natural explanations\nof the observed phenomena. Although the theory predicts a decelerating universe\nat the present era, it explains successfully the recent SNe Ia observations\n(which require an accelerating universe in the standard cosmology), as we show\nin this paper by performing a Bayesian analysis of the data.\n", "machine_text": "\n\nModeling Repulsive Gravity with Creation\n\nWe propose a model of repulsive gravity in which the gravitational force between two objects is directly proportional to the creation of the objects. We show that this model can be obtained from a modification of the Lovelock mechanism, and that it has the same dynamics as the standard model of repulsive gravity, with the exception that the energy of the system is not conserved. This model has several interesting features, including a new type of creationary black hole, and a new physical meaning for the cosmological constant, and the repulsive gravity between objects can be seen as a signature of the creationary potential between them.\n\nWe begin by motivating the model. We show that a modification of the Lovelock mechanism, which relates the potential of a system to the evolution of the system, can lead to a model of repulsive gravity. We then describe the model, and show that it has the same dynamics as the standard model of repulsive gravity, with the exception that the energy of the system is not conserved. We then analyze the model, and show that it can be used to describe several physical phenomena, including a new type of creationary black hole, and a new physical meaning for the cosmological constant, and the repulsive gravity between objects can be seen as a signature of the creationary potential between them. Finally, we discuss the implications of our results for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Entropy signature of the running cosmological constant. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0174, "human_text": "  Renormalization group (RG) improved cosmologies based upon a RG trajectory of\nQuantum Einstein Gravity (QEG) with realistic parameter values are investigated\nusing a system of cosmological evolution equations which allows for an\nunrestricted energy exchange between the vacuum and the matter sector. It is\ndemonstrated that the scale dependence of the gravitational parameters, the\ncosmological constant in particular, leads to an entropy production in the\nmatter system. The picture emerges that the Universe started out from a state\nof vanishing entropy, and that the radiation entropy observed today is\nessentially due to the coarse graining (RG flow) in the quantum gravity sector\nwhich is related to the expansion of the Universe. Furthermore, the RG improved\nfield equations are shown to possess solutions with an epoch of power law\ninflation immediately after the initial singularity. The inflation is driven by\nthe cosmological constant and ends automatically once the RG running has\nreduced the vacuum energy to the level of the matter energy density.\n", "machine_text": "\nWe show that the running cosmological constant, as obtained from the analysis of the cosmic microwave background radiation, has an entropy signature that is consistent with the assumption that the cosmological constant is a pure quantum state. We consider a general scheme for quantizing the cosmological constant that is invariant under general coordinate transformations and does not require the introduction of a cosmological constant term in the action function. The resulting quantum state is shown to have a particular entropy signature that can be tested against the entropy signature of the running cosmological constant. The entropy signature of the running cosmological constant as extracted from the analysis of the cosmic microwave background radiation is consistent with the cosmological constant being a pure quantum state. We show that the bulk behavior of the entropy signature is a special case of the 'folded spectrum' entropy signature associated with a particular type of general coordinate transformation. The special case of the folded spectrum entropy signature that we consider is shown to be consistent with the assumption that the cosmological constant is a pure quantum state. We discuss a simple physical model that can produce a folded spectrum entropy signature and show that this model is consistent with the assumption that the cosmological constant is a pure quantum state. We also show that the cosine-symmetry of the spatial variations of the cosmological constant is consistent with the assumption that the cosmological constant is a pure quantum state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An experimental test of non-local realism. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2529, "human_text": "  Most working scientists hold fast to the concept of 'realism' - a viewpoint\naccording to which an external reality exists independent of observation. But\nquantum physics has shattered some of our cornerstone beliefs. According to\nBell's theorem, any theory that is based on the joint assumption of realism and\nlocality (meaning that local events cannot be affected by actions in space-like\nseparated regions) is at variance with certain quantum predictions. Experiments\nwith entangled pairs of particles have amply confirmed these quantum\npredictions, thus rendering local realistic theories untenable. Maintaining\nrealism as a fundamental concept would therefore necessitate the introduction\nof 'spooky' actions that defy locality. Here we show by both theory and\nexperiment that a broad and rather reasonable class of such non-local realistic\ntheories is incompatible with experimentally observable quantum correlations.\nIn the experiment, we measure previously untested correlations between two\nentangled photons, and show that these correlations violate an inequality\nproposed by Leggett for non-local realistic theories. Our result suggests that\ngiving up the concept of locality is not sufficient to be consistent with\nquantum experiments, unless certain intuitive features of realism are\nabandoned.\n", "machine_text": "\nWe present an experimental test of non-local realism, based on the idea that if a quantum system is prepared in a state in which the values of certain properties are non-commuting, then a measurement of one of these properties will have an impact on the value of the other property, even when this second property is measured at a distance from the first one. To this end, we prepare an entangled state of two spatially separated qutrits, and perform a joint measurement of their respective amplitudes in a particular basis. We show that the outcome of this measurement has an immediate impact on the value of the quantum state of the other qutrit, in spite of the fact that there is no communication between the two qutrits, nor between the two measurement apparatuses. Our result implies that, even when a quantum system is prepared in a state in which non-local commutativity is guaranteed by the laws of quantum mechanics, this state nevertheless has a well-defined value for the non-commuting properties, and that this value is not affected by a distant measurement of one of these properties. We also analyze a possible experimental realization of this scenario, using current technology, and find that such a realization is within the reach of current experimental capabilities.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The discrete dipole approximation for simulation of light scattering by\n  particles much larger than the wavelength. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0037, "human_text": "  In this manuscript we investigate the capabilities of the Discrete Dipole\nApproximation (DDA) to simulate scattering from particles that are much larger\nthan the wavelength of the incident light, and describe an optimized publicly\navailable DDA computer program that processes the large number of dipoles\nrequired for such simulations. Numerical simulations of light scattering by\nspheres with size parameters x up to 160 and 40 for refractive index m=1.05 and\n2 respectively are presented and compared with exact results of the Mie theory.\nErrors of both integral and angle-resolved scattering quantities generally\nincrease with m and show no systematic dependence on x. Computational times\nincrease steeply with both x and m, reaching values of more than 2 weeks on a\ncluster of 64 processors. The main distinctive feature of the computer program\nis the ability to parallelize a single DDA simulation over a cluster of\ncomputers, which allows it to simulate light scattering by very large\nparticles, like the ones that are considered in this manuscript. Current\nlimitations and possible ways for improvement are discussed.\n", "machine_text": "\nWe propose a simple and general formalism for simulation of light scattering by particles much larger than the wavelength. Our approach is based on the discrete dipole approximation, which is valid when the wavelength is much larger than the size of the scatterer. In this approximation the light scattered by a small particle is approximately described by a sum of elementary dipoles, each of which is aligned along the direction of the electric field of the incident light. We show that the strength of each dipole is proportional to the cube of the distance between the particle and the incident wave-front, and therefore the total scattered light is proportional to the product of the total number of elementary dipoles and the inverse square of the wavelength. Our approach is general and can be applied to any particle that can be described by a set of dipoles, and therefore can be used for simulation of light scattering by most macromolecules and nanoparticles. We also derive an analytical expression for the dipole approximation in the limit of large particles, and use this expression to derive a simple formula for the reduction of the scattered light as the particle size is increased. Our formula shows good agreement with numerical results for large particles, and therefore can be used for an approximate simulation and characterization of light scattering by large particles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Approche variationnelle pour le calcul bay\\'esien dans les probl\\`emes\n  inverses en imagerie. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1914, "human_text": "  In a non supervised Bayesian estimation approach for inverse problems in\nimaging systems, one tries to estimate jointly the unknown image pixels $\\fb$\nand the hyperparameters $\\thetab$. This is, in general, done through the joint\nposterior law $p(\\fb,\\thetab|\\gb)$. The expression of this joint law is often\nvery complex and its exploration through sampling and computation of the point\nestimators such as MAP and posterior means need either optimization of non\nconvex criteria or int\\'egration of non Gaussian and multi variate probability\nlaws. In any of these cases, we need to do approximations. We had explored\nbefore the possibilities of Laplace approximation and sampling by MCMC. In this\npaper, we explore the possibility of approximating this joint law by a\nseparable one in $\\fb$ and in $\\thetab$. This gives the possibility of\ndeveloping iterative algorithms with more reasonable computational cost, in\nparticular, if the approximating laws are choosed in the exponential conjugate\nfamilies. The main objective of this paper is to give details of different\nalgorithms we obtain with different choices of these families.\n", "machine_text": "\n\nAbstract\n\nIn the field of medical imaging, inverse problems arise when one wants to interpret the image data in order to answer a clinical question. For example, in X-ray tomography, the goal is to determine the internal 3D structure of an object from its 2D radiographic projection. Most of the tomographic algorithms assume that the X-ray intensity measured at each voxel of the image is proportional to the volume of the material in that voxel. In practice, however, the measurement is affected by the surrounding material, giving rise to artifacts. We propose a variational approach to solve this inverse problem by incorporating prior knowledge about the possible structure of the material. In particular, we assume that the X-ray attenuation coefficient is a linear combination of basis functions, where the basis functions are related to the structure of the material. By minimizing the difference between the measured data and the projection of the solution, we recover the coefficients of the basis functions and the internal structure of the material. Our approach is general and can be applied to various tomographic algorithms, such as filtered back projection or likelihood-based methods. We illustrate our approach on simulated data, and we apply it to clinical data sets to demonstrate its potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nontrivial Geometries: Bounds on the Curvature of the Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0332, "human_text": "  Probing the geometry of the universe is one of the most important endevours\nin cosmology. Current observational data from the Cosmic Microwave Background\nanisotropy (CMB), galaxy surveys and type Ia supernovae (SNe Ia) strongly\nconstrain the curvature of the universe to be close to zero for a universe\ndominated by a cosmological constant or dark energy with a constant equation of\nstate. Here we investigate the role of cosmic priors on deriving these tight\nbounds on geometry, by considering a landscape motivated scenario with an\noscillating curvature term. We perform a likelihood analysis of current data\nunder such a model of non-trivial geometry and find that the uncertainties on\ncurvature, and correspondingly on parameters of the matter and dark energy\nsectors, are larger. Future dark energy experiments together with CMB data from\nexperiments like Planck could dramatically improve our ability to constrain\ncosmic curvature under such models enabling us to probe possible imprints of\nquantum gravity.\n", "machine_text": "\nWe investigate the possibility of a nontrivial geometry of the universe, and present bounds on the curvature and topology of spacetime that are implied by the assumption that the universe is spatially homogenous and isotropic. We show that the assumption of spatial homogeneity and isotropy allows one to immediately obtain a bound on the largest possible radius of a spherically symmetric space-time, and that this bound is not compatible with the assumption of a nontrivial topology. We then show that this bound can be tightened by using the fact that a nontrivial geometry would imply the existence of a privileged reference frame. We also show that the bound is tight for any spatially inhomogeneous and anisotropic universe that can be described by a spherically symmetric space-time with a radius that is smaller than the bound. We then present a physical argument that the bound is tight for a large class of possible inhomogeneous and anisotropic universes. The argument is based on the idea that if the universe has a nontrivial geometry, then this should be immediately visible in the form of preferred directions and a non-trivial spectrum of the cosmic microwave background radiation. We show that this argument implies a bound on the length of the longest diameter of the universe, and that this bound is tight for a large class of possible geometries. We finally present a general procedure for obtaining tight bounds on the curvature and topology of the universe, based on the assumption that the universe is locally similar to a spherically symmetric space-time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical 3-Space: A Review. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4146, "human_text": "  For some 100 years physics has modelled space and time via the spacetime\nconcept, with space being merely an observer dependent perspective effect of\nthat spacetime - space itself had no observer independent existence - it had no\nontological status, and it certainly had no dynamical description. In recent\nyears this has all changed. In 2002 it was discovered that a dynamical 3-space\nhad been detected many times, including the Michelson-Morley 1887 light-speed\nanisotropy experiment. Here we review the dynamics of this 3-space, tracing its\nevolution from that of an emergent phenomena in the information-theoretic\nProcess Physics to the phenomenological description in terms of a velocity\nfield describing the relative internal motion of the structured 3-space. The\nnew physics of the dynamical 3-space is extensively tested against experimental\nand astronomical observations, including the necessary generalisation of the\nMaxwell, Schrodinger and Dirac equations, leading to a derivation and\nexplanation of gravity as a refraction effect of quantum matter waves. The flat\nand curved spacetime formalisms are derived from the new physics, so explaining\ntheir apparent many successes.\n", "machine_text": "\n\nDynamical 3-Space: A Review\n\nWe introduce the notion of a dynamical 3-space, which is an extension of the concept of a 3-space to the setting of dynamical systems. We review the theory of dynamical 3-spaces and discuss some of their applications, such as to the representation theory of Lie groups and to the analysis of oscillatory and chaotic dynamical systems.\n\nThe theory of 3-spaces has its roots in the representation theory of finite dimensional Lie algebras. For any Lie algebra $\\mathfrak{g}$, there is a unique representation $\\pi: \\mathfrak{g} \\to \\mathfrak{B}^{n}$, where $\\mathfrak{B}$ is the Lie algebra of trace class operators on $\\mathfrak{g}$ and $n$ is the dimension of $\\mathfrak{B}$. This representation is given by the $n$-by-$n$ matrix representation of $\\mathfrak{g}$ on the space of square-integrable complex valued functions $\\mathfrak{B}^{n}$.\n\nFor a generalization of the notion of a 3-space to the setting of dynamical systems, one can define the notion of a dynamical 3-space as a space of functions on a system which are invariant under a finite set of affine transformations of the phase space of the system. The space is typically taken to be the space of square-integrable functions on the phase space, although this is not necessary.\n\nWe review the theory of dynamical 3-spaces, including the basic results on the structure of such spaces and the theory of 3-annihilators. We also discuss some of the applications of dynamical 3-spaces, such as to the representation theory of Lie groups and to the analysis of oscillatory and chaotic dynamical systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The orbit, mass, size, albedo, and density of (65489) Ceto/Phorcys: A\n  tidally-evolved binary Centaur. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1523, "human_text": "  Hubble Space Telescope observations of Uranus- and Neptune-crossing object\n(65489) Ceto/Phorcys (provisionally designated 2003 FX128) reveal it to be a\nclose binary system. The mutual orbit has a period of 9.554 +/- 0.011 days and\na semimajor axis of 1840 +/- 48 km. These values enable computation of a system\nmass of (5.41 +/- 0.42) 10^18 kg. Spitzer Space Telescope observations of\nthermal emission at 24 and 70 microns are combined with visible photometry to\nconstrain the system's effective radius (109 +10/-11 km) and geometric albedo\n(0.084 +0.021/-0.014). We estimate the average bulk density to be 1.37\n+0.66/-0.32 g cm^-3, consistent with ice plus rocky and/or carbonaceous\nmaterials. This density contrasts with lower densities recently measured with\nthe same technique for three other comparably-sized outer Solar System binaries\n(617) Patroclus, (26308) 1998 SM165, and (47171) 1999 TC36, and is closer to\nthe density of the saturnian irregular satellite Phoebe. The mutual orbit of\nCeto and Phorcys is nearly circular, with an eccentricity <= 0.015. This\nobservation is consistent with calculations suggesting that the system should\ntidally evolve on a timescale shorter than the age of the solar system.\n", "machine_text": "\n\nThe orbit, mass, size, albedo, and density of (65489) Ceto/Phorcys: A tidally-evolved binary Centaur\n\nWe present photometric observations of the tidally-evolved binary Centaur (65489) Ceto/Phorcys. Our observations include high-precision photometry from the Canada-France-Hawaii Telescope, and medium-precision photometry from the Fine Guidance Sensor onboard the Hubble Space Telescope. Together these data are used to derive the orbital elements and physical characteristics of the Centaur. We find that Ceto and Phorcys have a relatively circular orbit with many, narrow, eccentric, and closely-spaced orbits superimposed on this baseline. The semimajor axis of the orbit is 133.8 +0.9/-0.9 km, with the period given by the spheroidal orbit being 70.685 +0.016/-0.016 years. The orbital elements are in reasonable agreement with those derived from astrometric observations, with a small but non-zero inclination to the plane of the sky. The true orbit is probably closer to circular than the spheroidal orbit, indicating that this system is very slowly evolving. We estimate the masses of Ceto and Phorcys to be 3.00 +0.09/-0.09 and 2.98 +0.09/-0.09 kg, respectively. The albedos are estimated to be 0.037 +0.007/-0.007 and 0.032 +0.007/-0.007, for Ceto and Phorcys, respectively. The size parameters are 14.1 +0.5/-0.5 and 12.7 +0.5/-0.5, for Ceto and Phorcys, respectively. The density parameters are 1.86 +0.2/-0.2 and 1.86 +0.2/-0.2, for Ceto and Phorcys, respectively. The estimated densities are consistent with the presumption that these objects are mainly icy, with a small rocky core. We conclude that this is a member of the so-called NV3 group of co-orbital, mutually-interacting, tidally-evolved binaries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing General Metric Theories of Gravity with Bursting Neutron Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2426, "human_text": "  I show that several observable properties of bursting neutron stars in metric\ntheories of gravity can be calculated using only conservation laws, Killing\nsymmetries, and the Einstein equivalence principle, without requiring the\nvalidity of the general relativistic field equations. I calculate, in\nparticular, the gravitational redshift of a surface atomic line, the touchdown\nluminosity of a radius-expansion burst, which is believed to be equal to the\nEddington critical luminosity, and the apparent surface area of a neutron star\nas measured during the cooling tails of bursts. I show that, for a general\nmetric theory of gravity, the apparent surface area of a neutron star depends\non the coordinate radius of the stellar surface and on its gravitational\nredshift in the exact same way as in general relativity. On the other hand, the\nEddington critical luminosity depends also on an additional parameter that\nmeasures the degree to which the general relativistic field equations are\nsatisfied. These results can be used in conjunction with current and future\nhigh-energy observations of bursting neutron stars to test general relativity\nin the strong-field regime.\n", "machine_text": "\nWe present a new method for testing theories of gravity with astronomical observations of collapsing neutron stars. Our method is based on measuring the frequency and duration of gravitational waves (GWs) generated during the plunge and subsequent oscillations of a neutron star (NS) into a black hole (BH). We show that these gravitational waves can be used to constrain the parameter space of general metric theories of gravity (GMGTs), including theories that feature a non-minimally coupled scalar field, a generalization of the Einstein-Maxwell-Chern theory, or an extra, possibly nonlinear, metric degree of freedom. We consider various GMGTs and evaluate the effectiveness of our method by comparing the predictions of these theories to the latest observations of the GW source GW150914. We show that our method is sensitive to the basic structure of GMGTs, and can distinguish between theories that feature a minimally coupled scalar field and theories that do not. We also show that our method can place significant constraints on the initial condition of the NS-BH pair, including the mass of the NS and the three other parameters that define its initial orbit, and can rule out some GMGTs with relatively mild non-minimality.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing Inward Motions in Starless Cores Using The HCN J = 1-0 Hyperfine\n  Transitions : A Pointing Survey Toward Central Regions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.293, "human_text": "  We have carried out a survey toward the central regions of 85 starless cores\nin HCN J = 1-0 to study inward motions in the cores. Sixty-four cores were\ndetected with HCN lines. The infall asymmetry in the HCN spectra is found to be\nmore prevalent, and more prominent than in any other previously used infall\ntracers such as CS J = 2-1, DCO+ J = 2-1, and N2H+ J = 1-0. We found close\nrelation between the intensities of the HCN and N2H+ lines. This implies that\nthe HCN is not much depleted in the central regions of the cores. In some\ncores, the HCN spectra show different sign of asymmetry from other molecular\nlines. A few cores show various signs of asymmetry in individual HCN hyperfine\nlines. The distribution of the velocity shift dV of the HCN profiles with\nrespect to the systemic velocity of the optically thin tracer is found to be\nmore shifted toward bluer side than those of other infall tracers, indicating\nthat the HCN traces inward motions more frequently. The dV distribution of each\nHCN hyperfine line for all sources is similar. Moreover the dV values obtained\nfrom different HCN hyperfine lines for each source are nearly similar. These\nmay mean that most of starless cores are in similar kinematic states across the\nlayers of the cores. We identify 17 infall candidates using all available\nindicators such as the velocity shift dV and the blue to red peak intensity\nratio of double peaked profiles for HCN J = 1-0, CS J = 2-1, J = 3-2, DCO+ J =\n2-1, and N2H+ J = 1-0. Four of them, L63, L492, L694-2, and L1197 are found to\nshow higher blue to red ratio in the HCN hyperfine line along the lower\nopacity, suggesting that infall speed becomes higher toward the center.\n", "machine_text": "\nWe present a pointing survey toward the central regions of starless cores in order to probe inward motions using the HCN J = 1-0 hyperfine transition. We use a simple model in which the distribution of HCN is treated as a isothermal, homogenous, and stationary gas in order to derive an expression for the observed distribution of HCN J = 1-0 intensity as a function of radius. We show that this expression can be used to infer the radial distribution of the column density, N(r), and the radial motion, v(r), provided that N(r) and v(r) are known at the inner and outer edges of the core. We present observations toward 46 starless cores in the Taurus-Auriga region. We find that the column density generally increases toward the core centers, consistent with gravitational collapse, except in 6 cases in which the column density is constant. We infer the radial distribution of v(r) in the same 46 cores and find that v(r) is constant in 20 cores, decreases in 8 cores, and increases in 6 cores. We conclude that a large fraction (70%) of the cores show no evidence of inward motions, consistent with the simple assumption of isothermal, homogenous, and stationary gas distribution. We discuss possible physical mechanisms that may produce the non-monotonic distributions of v(r) and N(r) found in some cores.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Enhanced Kondo Effect in an Electron System Dynamically Coupled with\n  Local Optical Phonon. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3874, "human_text": "  We discuss Kondo behavior of a conduction electron system coupled with local\noptical phonon by analyzing the Anderson-Holstein model with the use of a\nnumerical renormalization group (NRG) method. There appear three typical\nregions due to the balance between Coulomb interaction $U_{\\rm ee}$ and\nphonon-mediated attraction $U_{\\rm ph}$. For $U_{\\rm ee}>U_{\\rm ph}$, we\nobserve the standard Kondo effect concerning spin degree of freedom. Since the\nCoulomb interaction is effectively reduced as $U_{\\rm ee}-U_{\\rm ph}$, the\nKondo temperature $T_{\\rm K}$ is increased when $U_{\\rm ph}$ is increased. On\nthe other hand, for $U_{\\rm ee}<U_{\\rm ph}$, there occurs the Kondo effect\nconcerning charge degree of freedom, since vacant and double occupied states\nplay roles of pseudo-spins. Note that in this case, $T_{\\rm K}$ is decreased\nwith the increase of $U_{\\rm ph}$. Namely, $T_{\\rm K}$ should be maximized for\n$U_{\\rm ee} \\approx U_{\\rm ph}$. Then, we analyze in detail the Kondo behavior\nat $U_{\\rm ee}=U_{\\rm ph}$, which is found to be explained by the polaron\nAnderson model with reduced hybridization of polaron and residual repulsive\ninteraction among polarons. By comparing the NRG results of the polaron\nAnderson model with those of the original Anderson-Holstein model, we clarify\nthe Kondo behavior in the competing region of $U_{\\rm ee} \\approx U_{\\rm ph}$.\n", "machine_text": "\n\nWe have investigated a quantum system comprising of a single electron and a single photon, which is dynamically coupled to a thermal reservoir and a local optical phonon. The system is modeled by the effective two-dimensional (2D) nonlinear Schr\u00f6dinger equation with a dissipative term that includes both the finite resistivity and the scattering by the optical phonon. We found a clear signature of the enhanced Kondo effect in the steady state of the system, which has a distinct dependence on the strength of the coupling to the phonon. We explain this effect by the enhanced stability of the single-particle basis renormalization, which in turn depends on the phonon-induced symmetry breaking. We also found a strong enhancement of the temperature dependence of the zero-frequency limit, which can be understood by the presence of an additional term in the dissipative kernel, which is related to the electron-phonon coupling. Our results may be useful in the study of various exotic phenomena related to the interplay between different degrees of freedom in a multi-particle system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Revisiting the Issues On Netflow Sample and Export Performance. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.073, "human_text": "  The high volume of packets and packet rates of traffic on some router links\nmakes it exceedingly difficult for routers to examine every packet in order to\nkeep detailed statistics about the traffic which is traversing the router.\nSampling is commonly applied on routers in order to limit the load incurred by\nthe collection of information that the router has to undertake when evaluating\nflow information for monitoring purposes. The sampling process in nearly all\ncases is a deterministic process of choosing 1 in every N packets on a\nper-interface basis, and then forming the flow statistics based on the\ncollected sampled statistics. Even though this sampling may not be significant\nfor some statistics, such as packet rate, others can be severely distorted.\nHowever, it is important to consider the sampling techniques and their relative\naccuracy when applied to different traffic patterns. The main disadvantage of\nsampling is the loss of accuracy in the collected trace when compared to the\noriginal traffic stream. To date there has not been a detailed analysis of the\nimpact of sampling at a router in various traffic profiles and flow criteria.\nIn this paper, we assess the performance of the sampling process as used in\nNetFlow in detail, and we discuss some techniques for the compensation of loss\nof monitoring detail.\n", "machine_text": "\n\nWe revisit the issues of the sampling and export performance of NetFlow. We improve the characterization of the sampling process and provide a formalism to assess the bias induced by the sampling process. We derive a simple expression to compute the sampling rate, which is not uniform for all flows. We show that an optimal sampling rate exists and is inversely proportional to the product of the flow duration and the number of bytes. We analyze the impact of the sampling rate and the size of the export packets on the export performance. We derive a simple expression for the export bandwidth and show that the optimal export bandwidth is directly proportional to the sampling rate. We implement and evaluate these concepts using real traces. We provide a methodology to assess the accuracy of sampled flow measurements. Our results show that sampling can have a tremendous impact on the exported flow statistics, and that, in general, flow measurements are not accurate. We discuss the implications of our results for the operational practice and we propose a simple method to improve the quality of the sampled flow measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Controlled collisions of a single atom and ion guided by movable\n  trapping potentials. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1037, "human_text": "  We consider a system composed of a trapped atom and a trapped ion. The ion\ncharge induces in the atom an electric dipole moment, which attracts it with an\nr^{-4} dependence at large distances. In the regime considered here, the\ncharacteristic range of the atom-ion interaction is comparable or larger than\nthe characteristic size of the trapping potential, which excludes the\napplication of the contact pseudopotential. The short-range part of the\ninteraction is described in the framework of quantum-defect theory, by\nintroducing some short-range parameters, which can be related to the s-wave\nscattering length. When the separation between traps is changed we observe\ntrap-induced shape resonances between molecular bound states and vibrational\nstates of the external trapping potential. Our analysis is extended to\nquasi-one-dimensional geometries, when the scattering exhibit\nconfinement-induced resonances, similar to the ones studied before for\nshort-range interactions. For quasi-one-dimensional systems we investigate the\neffects of coupling between the center of mass and relative motion, which\noccurs for different trapping frequencies of atom and ion traps. Finally, we\nshow how the two types of resonances can be employed for quantum state control\nand spectroscopy of atom-ion molecules.\n", "machine_text": "\n\nWe study controlled collisions of a single atom and ion guided by movable trapping potentials. We consider a scenario where a single atom is surrounded by a trapping potential in three dimensions and an ion of known energy is made to collide with the atom in a way such that the resulting atom-ion system is also surrounded by a trapping potential. We investigate the motion of the system for different initial conditions and in the presence of different types of trapping potentials. We also study the different ways in which an atom and ion can be combined to form a molecule. Our main results are: (i) We show that the system will always collide with the trapping potential in a way such that the total kinetic energy of the system remains constant. (ii) We show that the system can be made to perform a complete rotation about an axis perpendicular to the plane of the orbit even in the presence of a harmonic potential. (iii) We show that a large number of different molecular states can be obtained by suitable choice of the initial conditions and the type of potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of electron-electron interaction on the phonon-mediated spin\n  relaxation in quantum dots. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0868, "human_text": "  We estimate the spin relaxation rate due to spin-orbit coupling and acoustic\nphonon scattering in weakly-confined quantum dots with up to five interacting\nelectrons. The Full Configuration Interaction approach is used to account for\nthe inter-electron repulsion, and Rashba and Dresselhaus spin-orbit couplings\nare exactly diagonalized. We show that electron-electron interaction strongly\naffects spin-orbit admixture in the sample. Consequently, relaxation rates\nstrongly depend on the number of carriers confined in the dot. We identify the\nmechanisms which may lead to improved spin stability in few electron (>2)\nquantum dots as compared to the usual one and two electron devices. Finally, we\ndiscuss recent experiments on triplet-singlet transitions in GaAs dots subject\nto external magnetic fields. Our simulations are in good agreement with the\nexperimental findings, and support the interpretation of the observed spin\nrelaxation as being due to spin-orbit coupling assisted by acoustic phonon\nemission.\n", "machine_text": "\nWe investigate electron-electron interaction effects on the phonon-mediated spin relaxation in quantum dots by means of analytical and numerical techniques. We consider a spherical quantum dot with a spherically symmetric potential and no internal electric field. We find that the spin-phonon interaction in this system is extremely long-range in character. We show that this is due to a very large value of the acoustic impedance Z, which is directly related to the ratio of the angular momentum to the inverse temperature. Therefore, the relaxation is very fast and the dynamic behavior of the system is completely different from that of the elementary particles, such as electrons and phonons. We show that the dynamic behavior of the system can be well described by a single parameter Y, which is related to the damping ratio of the dynamic evolution. We find that Y is always greater than one, which means that the system always relaxes to a state with less disorder. The results obtained are consistent with the fact that electron-electron interaction reduces the entanglement of the system. We also derive a simple expression for the spin relaxation time in this system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Study in Depth of f0(1370). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1341, "human_text": "  Claims have been made that f0(1370) does not exist. The five primary sets of\ndata requiring its existence are refitted. Major dispersive effects due to the\nopening of the 4pi threshold are included for the first time; the sigma -> 4pi\namplitude plays a strong role. Crystal Barrel data on pbar-p -> 3pizero at rest\nrequire f0(1370) signals of at least 32 and 33 standard deviations in 1S0 and\n3P1 annihilation respectively. Furthermore, they agree within 5 MeV for mass\nand width. Data on pbar-p -> eta-eta-pizero agree and require at least a 19\nstandard deviation contribution. This alone is sufficient to demonstrate the\nexistence of f0(1370). BES II data for J/Psi -> phi-pi-pi contain a visible\nf0(1370) signal > 8 standard devations. In all cases, a resonant phase\nvariation is required. The possibility of a second pole in the sigma amplitude\ndue to the opening of the 4pi channel is excluded. Cern-Munich data for pi-pi\nelastic scattering are fitted well with the inclusion of some mixing between\nsigma, f0(1370) and f0(1500). The pi-pi widths for f2(1565), rho3(1690),\nrho3(1990) and f4(2040) are determined.\n", "machine_text": "\nWe present a study in depth of the radial mode f0(1370), which has been observed in the Sun's atmosphere in the form of small-scale structures. These structures are visible as bright points in the solar photosphere, in photospheric areas of enhanced temperature and low magnetic activity. We find that the amplitude of f0(1370) increases linearly with depth in the photosphere, then remains almost constant in the transition region, and finally decreases exponentially in the corona. The frequency of f0(1370) in the photosphere is slightly higher than that in the corona. Our results indicate that the source of f0(1370) is probably close to the solar surface, in a layer several thousand kilometers thick, and that the energy is carried to the corona by the emerging magnetic field. We propose that f0(1370) is related to the internal dynamics of the Sun and could be excited by different physical processes in different regions. Our findings are consistent with a picture in which the amplitude of f0(1370) is controlled by the competition between the upward and downward propagating components of the wave, which is related to the temperature, density, and magnetic field distribution in the solar atmosphere.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Super stellar clusters with a bimodal hydrodynamic solution: an\n  Approximate Analytic Approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1889, "human_text": "  We look for a simple analytic model to distinguish between stellar clusters\nundergoing a bimodal hydrodynamic solution from those able to drive only a\nstationary wind. Clusters in the bimodal regime undergo strong radiative\ncooling within their densest inner regions, which results in the accumulation\nof the matter injected by supernovae and stellar winds and eventually in the\nformation of further stellar generations, while their outer regions sustain a\nstationary wind. The analytic formulae are derived from the basic hydrodynamic\nequations. Our main assumption, that the density at the star cluster surface\nscales almost linearly with that at the stagnation radius, is based on results\nfrom semi-analytic and full numerical calculations. The analytic formulation\nallows for the determination of the threshold mechanical luminosity that\nseparates clusters evolving in either of the two solutions. It is possible to\nfix the stagnation radius by simple analytic expressions and thus to determine\nthe fractions of the deposited matter that clusters evolving in the bimodal\nregime blow out as a wind or recycle into further stellar generations.\n", "machine_text": "\n\nWe consider the problem of describing the dynamical evolution of stellar clusters in galaxies. We derive a new approximate analytic solution to the coupled hydrodynamic and kinetic equations for a spherically symmetric cluster within a potential field, which includes a correction due to the kinetic energy of the cluster particles. The solution is bimodal, with two different concentrations of the cluster particles, which can be related to the core and the outer regions of the cluster. We find that the relaxation time of the cluster is inversely proportional to the square of the ratio of the kinetic energy to the potential energy. We discuss the physical meaning of the solution, and show that the relaxation time is inversely proportional to the square of the cluster mass. We compare the result with the case of an N-body cluster, and discuss the differences. We also analyze the case of a cluster in a driven potential field, and show that the result can be understood in terms of the optimal distribution of the cluster particles in the potential field. Finally, we discuss some applications of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Multiphilic Descriptor for Chemical Reactivity and Selectivity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0334, "human_text": "  In line with the local philicity concept proposed by Chattaraj et al.\n(Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and\na dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.;\nToro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic\ndescriptor. It is defined as the difference between nucleophilic (Wk+) and\nelectrophilic (Wk-) condensed philicity functions. This descriptor is capable\nof simultaneously explaining the nucleophilicity and electrophilicity of the\ngiven atomic sites in the molecule. Variation of these quantities along the\npath of a soft reaction is also analyzed. Predictive ability of this descriptor\nhas been successfully tested on the selected systems and reactions.\nCorresponding force profiles are also analyzed in some representative cases.\nAlso, to study the intra- and intermolecular reactivities another related\ndescriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over\nthe electrophilicity in it has been defined and tested on all-metal aromatic\ncompounds.\n", "machine_text": "\nA Multiphilic Descriptor for Chemical Reactivity and Selectivity\nThe ability to predict the products of a chemical reaction is a long-standing problem in chemistry, and is a major challenge for organic chemistry in particular. We have developed a new approach to the prediction of organic reaction products, which is based on the idea of a multiphilic descriptor. This descriptor uses a combination of various hydrophobic and hydrophilic properties to characterize the reactants, and is shown to be highly predictive for a wide range of organic reaction types. The approach is tested on a set of 76 different reaction types, and the results are compared to those obtained using other popular descriptor types. The multiphilic descriptor is shown to be the most predictive, with a prediction success rate of 80%. The method is also compared to other recent methods for reaction prediction, and is shown to be competitive with the best of these methods. The practical utility of the multiphilic descriptor is illustrated by its use in the development of a model for the prediction of product selectivity in the Apple Baylis-Hillman reaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Census of Baryons in Galaxy Clusters and Groups. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1726, "human_text": "  We determine the contribution of stars in galaxies, intracluster stars, and\nthe intracluster medium to the total baryon budget in nearby galaxy clusters\nand groups. We find that the baryon mass fraction (f_b) within r500 is constant\nfor systems with M500 between 6e13 and 1e15 Msun. Although f_b is lower than\nthe WMAP value, the shortfall is on the order of both the observational\nsystematic uncertainties and the depletion of baryons within r500 that is\npredicted by simulations. The data therefore provide no compelling evidence for\nundetected baryonic components, particularly any that vary in importance with\ncluster mass. A unique feature of the current analysis is direct inclusion of\nthe contribution of intracluster light (ICL) in the baryon budget. The increase\nin X-ray gas mass fraction with increasing total mass is entirely accounted for\nby a decrease in the total stellar mass fraction, supporting the argument that\nthe behavior of both the stellar and X-ray gas components is dominated by a\ndecrease in star formation efficiency in more massive environments. Within just\nthe stellar component, the fraction of the total stellar luminosity in the BCG\nand ICL decreases as velocity dispersion increases, suggesting that the BCG+ICL\ncomponent, and in particular the dominant ICL component, grows less efficiently\nin higher mass environments. The degree to which this behavior arises from our\nsample selection, which favored systems with central, giant elliptical\ngalaxies, remains unclear. A more robust result is the identification of low\nmass groups with large BCG+ICL components, demonstrating that the creation of\nintracluster stars does not require a massive cluster environment. Within r500\nand r200, the BCG+ICL contributes on average 40% and 33% of the total stellar\nlight, respectively.\n", "machine_text": "\n\nWe present a census of baryons in groups and clusters of galaxies, based on a combination of galaxy redshift surveys and X-ray observations of clusters. We find that the total baryonic content of groups and clusters is 1.8 times that of the local galaxy group, with the groups containing slightly more baryons than the clusters. This result is consistent with the clusters containing relatively massive galaxies in the core, and the groups containing many more low mass galaxies in the outskirts. We find that the groups and clusters contain large amounts of gas, with the gas fraction dropping quickly from the clusters to the groups. This suggests that the gas in the clusters has recently been accreted, and has not yet had time to cool and condense into stars. The clusters and groups also contain large amounts of hot dust, indicating the presence of an active star formation. We find that the groups and clusters contain large amounts of carbon, indicating that the gas in the clusters has not yet cooled and condensed into stars. We discuss the implications of our results for the formation of groups and clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nanomechanics of single keratin fibres: A Raman study of the alpha helix\n  -> beta sheet transition and water effect. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0776, "human_text": "  The use of micro-Raman spectroscopy, through chemical bond nano-scale probes,\nallows the changes in conformations (alpha helix -> beta sheet), chain\norientation, disconnection of disulfide bonds (-20%) and the increase of intra\nand inter-chain distances during the strain to be distinguished. The\ncombination of micro-Raman spectroscopy and a allows a quantitative measure of\nthe extension of chemical bonds in the peptidic chain during loading. The\nnano-structural transformations of keratin during the strain of human hair in a\ndry environment (40-60 % relative humidity) and saturated with water have been\nstudied. The water permits the sliding of the chains and decreases the bond\nenergy hair. Spectral analyses and 2D correlation are two coherent and\nindependent methods to follow change the Raman probes which are sensitive to\nstructural . The between nano-mechanical (Raman) and micro-mechanical\n(strain/stress) analyses confirms the validity of the experimental results,\ntools and principles used, as well as the agreement with the structural model\nof keratin fibres described by Chapman & Hearle.\n", "machine_text": "\nWe present a study of the nanomechanics of single keratin fibres using Raman spectroscopy. The motivation for this work is a desire to understand the mechanical properties of keratin fibres at the molecular level in order to gain fundamental knowledge that may be relevant to the design of new hair care products. We have investigated the effect of water on the alpha helix -> beta sheet transition temperature of the keratin polypeptide using high resolution Raman spectroscopy. We have also characterised the distribution of the different types of bonds present in the keratin fibre. The results of this work show that the water soluble fraction of the keratin fibre consists almost entirely of alpha helical structure, while the water insoluble fraction is largely beta sheet structure. The results also show that the transition temperature for the alpha helix -> beta sheet transition is significantly affected by the presence of water, with the transition temperature being raised by the presence of water. The practical application of this work is that it may be possible to design hair care products that can stabilise the alpha helix structure of the keratin polypeptide, and thus give better curl retention to the hair.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy-Efficient Resource Allocation in Wireless Networks: An Overview\n  of Game-Theoretic Approaches. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1787, "human_text": "  An overview of game-theoretic approaches to energy-efficient resource\nallocation in wireless networks is presented. Focusing on multiple-access\nnetworks, it is demonstrated that game theory can be used as an effective tool\nto study resource allocation in wireless networks with quality-of-service (QoS)\nconstraints. A family of non-cooperative (distributed) games is presented in\nwhich each user seeks to choose a strategy that maximizes its own utility while\nsatisfying its QoS requirements. The utility function considered here measures\nthe number of reliable bits that are transmitted per joule of energy consumed\nand, hence, is particulary suitable for energy-constrained networks. The\nactions available to each user in trying to maximize its own utility are at\nleast the choice of the transmit power and, depending on the situation, the\nuser may also be able to choose its transmission rate, modulation, packet size,\nmultiuser receiver, multi-antenna processing algorithm, or carrier allocation\nstrategy. The best-response strategy and Nash equilibrium for each game is\npresented. Using this game-theoretic framework, the effects of power control,\nrate control, modulation, temporal and spatial signal processing, carrier\nallocation strategy and delay QoS constraints on energy efficiency and network\ncapacity are quantified.\n", "machine_text": "\nWe survey recent game-theoretic approaches to energy-efficient resource allocation in wireless networks. In particular, we focus on the problem of jointly optimizing the energy consumption and the Quality-of-Service (QoS) requirements of a set of users, each having resource requests of different types and QoS requirements, and each being associated with a battery of finite capacity. We first motivate our survey by reviewing the challenges that the energy-constrained operation of wireless networks raises. We then present a game-theoretic formulation of the joint energy-efficient QoS provisioning problem and survey several game-theoretic solution concepts that have been proposed to solve this problem, including game theory, stochastic game theory, and mechanism design. We review both the classical approaches that consider the energy consumption of the users as a resource to be managed and the recent approaches that consider the total energy consumption of the network as a resource to be managed. We discuss the trade-off between the selfish and the socially-optimal behavior of the users, and we survey how this trade-off can be captured via the incentives offered to the users in the different game-theoretic solution concepts. We then survey the existing game-theoretic solution concepts in terms of their flexibility, which is captured by the number of parameters that their design requires, and their efficiency, which is captured by the performance that one can achieve with a given number of parameters. We finally discuss the practical relevance of the surveyed results and the open problems that remain in this field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modeling transcription factor binding events to DNA using a random\n  walker/jumper representation on a 1D/2D lattice with different affinity sites. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2454, "human_text": "  Surviving in a diverse environment requires corresponding organism responses.\nAt the cellular level, such adjustment relies on the transcription factors\n(TFs) which must rapidly find their target sequences amidst a vast amount of\nnon-relevant sequences on DNA molecules. Whether these transcription factors\nlocate their target sites through a 1D or 3D pathway is still a matter of\nspeculation. It has been suggested that the optimum search time is when the\nprotein equally shares its search time between 1D and 3D diffusions. In this\npaper, we study the above problem using a Monte Carlo simulation by considering\na very simple physical model. A 1D strip, representing a DNA, with a number of\nlow affinity sites, corresponding to non-target sites, and high affinity sites,\ncorresponding to target sites, is considered and later extended to a 2D strip.\nWe study the 1D and 3D exploration pathways, and combinations of the two modes\nby considering three different types of molecules: a walker that randomly walks\nalong the strip with no dissociation; a jumper that represents dissociation and\nthen re-association of a TF with the strip at later time at a distant site; and\na hopper that is similar to the jumper but it dissociates and then\nre-associates at a faster rate than the jumper. We analyze the final\nprobability distribution of molecules for each case and find that TFs can\nlocate their targets fast enough even if they spend 15% of their search time\ndiffusing freely in the solution. This indeed agrees with recent experimental\nresults obtained by Elf et al. 2007 and is in contrast with theoretical\nexpectation.\n", "machine_text": "\nWe present a stochastic algorithm to model transcription factor binding events to DNA using a random walker/jumper representation on a 1D/2D lattice with different affinity sites. The algorithm is based on a stochastic solution of the master equation that describes the dynamics of the corresponding random walker/jumper system. We analyze the solution of the master equation in the limit of large number of sites and large number of bound walkers/jumpers. In this regime the solution is shown to converge to a limiting distribution that depends only on the number of sites and the walkers/jumpers, and not on their individual positions. The limiting distribution is shown to be consistent with the well-known model of random monomer binding to a lattice with equal affinity sites. We also analyze the solution of the master equation in the case of non-equal affinity sites and show that the limiting distribution in this case is consistent with a model of non-uniform random monomer binding to a lattice. The results of this work have important practical applications in modeling the evolution of gene expression and the development of cellular phenotypes. In addition, the theoretical results obtained in this work have implications for the theory of random walks on lattices with non-equal affinity sites, and in general for the theory of statistical mechanics systems with non-equal occupancy of the sites.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Study of Direct Photon plus Jet production in CMS Experiment at\n  \\sqrt{s}=14 TeV. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.274, "human_text": "  We present simulation results of $\\gamma$ + Jet analysis using CMS (Compact\nMuon Solenoid) Object-Oriented software at the Large Hadron Collider (LHC)\ncenter of mass energy $\\sqrt{s}$=14 TeV. The study of direct photon production\nhelps in validating the perturbative Quantum Chromodynamics (pQCD) and\nproviding information on the gluon distribution in the nucleons. Direct photon\nprocesses also constitute a major background to several other Standard Model\n(SM) processes and signals of new physics. Thus these processes need to be\nunderstood precisely in the new energy regime. In this work, we have done a\ndetailed study of the GEANT4 simulated $\\gamma$ + jet events generated with\nPythia, and the related background processes. Isolation cuts have been\noptimized for direct photon which improves the signal over background ratio by\n$\\sim25%$ as compared to previous studies done in CMS. The inclusion of a large\n$\\Delta\\phi$ cut between the photon and the leading jet at $40^0$ in the\nanalysis leads to a further increase of $\\sim15%$ in S/B, thus giving an\noverall gain of $\\sim42%$ in S/B ratio.\n", "machine_text": "\n\nWe present the first measurement of the direct photon plus jet production cross section in hadron collisions at \\sqrt{s}=14 TeV performed with the CMS detector at the LHC. The analysis is based on the data collected in 2016 by the CMS collaboration, corresponding to an integrated luminosity of 35.8 fb-1 of collision events containing hadron jets. The cross section is measured for events with two jets and a photon produced in the same hadron collision, in the mass region around 1 TeV. The analysis uses the minimum-bias trigger, selecting events with two jets of hadron-Hadron calorimeter (HCAL) energy above 2.5 GeV, and a photon of energy above 1 GeV produced in the same event. We observe a cross section in good agreement with next-to-leading order theory, corrected for non-perturbative effects, such as jet quenching and jet merging. We also measure the differential cross section as a function of the hadron jet momentum, and find a good agreement with theory, which includes non-perturbative contributions. The measurement is in agreement with theoretical predictions based on the perturbative theory, with a statistical uncertainty of \\sim 3\\% and a systematic uncertainty of \\sim 7%. The results are used to constrain the non-perturbative corrections to the theory and to test the reliability of the perturbative approach to describe the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The First Survey of X-ray Flares from Gamma Ray Bursts Observed by\n  Swift: Spectral Properties and Energetics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1564, "human_text": "  Observations of gamma ray bursts (GRBs) with Swift produced the initially\nsurprising result that many bursts have large X-ray flares superimposed on the\nunderlying afterglow. The flares were sometimes intense, had rapid rise and\ndecay phases, and occurred late relative to the ``prompt'' phase. Some\nremarkable flares are observed with fluence comparable to the prompt GRB\nfluence. Many GRBs have several flares, which are sometimes overlapping. Short,\nintense, repetitive, and late flaring can be most easily understood within the\ncontext of the standard fireball model with the internal engine that powers the\nprompt GRB emission in an active state at late times. However, other models for\nflares have been proposed. Flare origin can be investigated by comparing the\nflare spectra to that of the afterglow and the initial prompt emission. In this\nwork, we have analyzed all significant X-ray flares from the first 110 GRBs\nobserved by Swift. From this sample 33 GRBs were found to have significant\nX-ray flares, with 77 flares that were detected above the 3$\\sigma$ level. In\naddition to temporal analysis presented in a companion paper, a variety of\nspectral models have been fit to each flare. In some cases, we find that the\nspectral fits favor a Band function model, which is more akin to the prompt\nemission than to that of an afterglow. We find that the average fluence of the\nflares is 2.4e-7 erg/cm^2/s in the 0.2-10 keV energy band, which is\napproximately a factor of ten below the average prompt GRB fluence. These\nresults, when combined with those presented in the companion paper on temporal\nproperties of flares, supports the hypothesis that most X-ray flares are\nlate-time activity of the internal engine that spawned the initial GRB; not an\nafterglow related effect.\n", "machine_text": "\nWe present the first survey of X-ray flares from gamma-ray bursts (GRBs) observed by the Swift satellite. The survey consists of 42 X-ray flares from 33 bursts, observed during the period August 2005 to February 2007. We find that the X-ray flux rises faster and is, on average, two times higher during the prompt emission than during the afterglow. The observed phenomenology is consistent with a radioactive decay model in which the parent radionuclide decays with a half-life of  \u223c 2 ms to a stable end-product. For most of the bursts with observed X-ray flares, the total radiated energy in X-rays is  \u223c 5 kJ, which is  \u223c 1% of the total burst energy. We show that the observed X-ray phenomenology can be explained by a simple model in which the X-ray emission arises from a single region, located at the boundary between the radiative and kinetic energy deposition regions. Our model predicts that the X-ray flare should rise with a given burst's total energy deposition and decay with the corresponding kinetic energy deposition. We discuss the implications of our results for the energy budget of GRBs and for the nature of the energy deposition and radiative processes in the bursts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Astrometry with \"Carte du Ciel\" plates, San Fernando zone. I.\n  Digitization and measurement using a flatbed scanner. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.19, "human_text": "  We present an original method of digitizing and astrometrically reducing\n\"Carte du Ciel\" plate material using an inexpensive flatbed scanner, to\ndemonstrate that for this material there is an alternative to more specialized\nmeasuring machines that are very few in number and thus not readily available.\nThe sample of plates chosen to develop this method are original \"Carte du Ciel\"\nplates of the San Fernando zone, photographic material with a mean epoch\n1903.6, and a limiting photographic magnitude ~14.5, covering the declination\nrange of -10 < dec < -2. Digitization has been made using a commercial flatbed\nscanner, demonstrating the internal precision that can be attained with such a\ndevice. A variety of post-scan corrections are shown to be necessary. In\nparticular, the large distortion introduced by the non-uniform action of the\nscanner is modelled using multiple scans of each plate. We also tackle the\nspecific problems associated with the triple-exposure images on some plates and\nthe grid lines present on all. The final measures are reduced to celestial\ncoordinates using the Tycho-2 Catalogue. The internal precision obtained over a\nsingle plate, 3microns ~ 0.18\" in each axis, is comparable to what is realized\nwith similar plate material using slower, less affordable, and less widely\navailable conventional measuring machines, such as a PDS microdensitometer. The\naccuracy attained over large multi-plate areas, employing an overlapping plate\ntechnique, is estimated at 0.2\".\n", "machine_text": "\nWe present a new method to measure the positions of stars using the digital scans of old \"Carte du Ciel\" plates. We focus on a zone of the sky around San Fernando where the plates are of good quality and where the astrometry is relatively simple. We describe the reduction procedure, the necessary calibrations, and the final accuracy of the positions, which is about 2-3 arcsec for stars brighter than mag 6. We find a general agreement with the positions from the GALAHKDP and 2MASS redshifts, with a scatter of about 3 arcsec in Galactic coordinates. We also compare the proper motions from our measurements with those from the Hipparcos catalogue. We find a large scatter in the proper motions, which we attribute to the uncertainty in the knowledge of the plate dates. We discuss the systematic effect of the scanning process on the measured positions. Finally, we present a new method to measure the plate scale using only the stars on the plate, which allows to avoid the use of artificial landmarks, as well as a method to measure the attitude of the plate using only the positions of stars with known proper motion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: INTEGRAL high energy monitoring of the X-ray burster KS 1741-293. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0832, "human_text": "  KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module\nof the Mir space station and identified as an X-ray burster, has not been\ndetected in the hard X band until the advent of the INTEGRAL observatory.\nMoreover this source has been recently object of scientific discussion, being\nalso associated to a nearby extended radio source that in principle could be\nthe supernova remnant produced by the accretion induced collapse in the binary\nsystem. Our long term monitoring with INTEGRAL, covering the period from\nFebruary 2003 to May 2005, confirms that KS 1741-293 is transient in soft and\nhard X band. When the source is active, from a simultaneous JEM-X and IBIS data\nanalysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by\na two component model, a multiple blackbody for the soft emission and a\nComptonized or a cut-off power law model for the hard component. Finally, by\nthe detection of two X-ray bursters with JEM-X, we confirm the bursting nature\nof KS 1741-293, including this source in the class of the hard tailed X-ray\nbursters.\n", "machine_text": "\nWe present here results of a monitoring campaign, carried out with INTEGRAL, of the hard X-ray transient KS 1741-293. The source was observed during a monitoring campaign in February-March 2002, with the INTEGRAL instruments OCK and SPI. We find that the accretion phase lasts at most 2-3 hours, with a few outbursts per year. The observed phenomenology is consistent with a smoothly increasing flux triggered at the periastron passage in a wide eccentric orbit with many short-lived (a few hours) accretion pulses and a final flaring phase of a few minutes when the gas is directly transferred to the white dwarf. The observed phenomenology is consistent with a continuous accretion process in which the gas is first accumulated in a large orbit and then gradually transferred to the white dwarf. The accretion process is likely to be a direct accretion onto the white dwarf. We discuss a possible explanation for the observed phenomenology in terms of a model in which the accretion process is controlled by the instability of a cavity around the white dwarf. We show that the main parameters of the system can be derived from the observed phenomenology. In particular we find that the white dwarf has a relatively long spin period (41-67 min) and that the accretion rate is at most 1.4 10^33 erg s^-1. We discuss a simple model in which the accretion process is treated as a viscous disc around the white dwarf. We show that such a model is consistent with the observed phenomenology and that it predicts a critical accretion rate of log(R_(acc)/R_WD) = -1.1, where R_acc is the accretion rate and R_WD is the radius of the white dwarf.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Decoherence of a driven multilevel quantum system interacting with a\n  multi-bath reservoir. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0995, "human_text": "  A general theory is presented for the treatment of decoherence of a\nmultilevel quantum system (with many degrees of freedom) interacting with\nmulti-bath reservoir and driven by ac fields. In this approach, the system is\ndescribed by a reduced density operator and the multi-bath reservoir is\ncharacterized by a number of spectral densities. The reduced density operator\nis governed by the master equation in which the effect of ac driving fields and\nthe leakage to non-computational states are included. The theory is applied to\nthe study of decoherence of a two-dimensional (2D) SQUID flux qubit coupled to\ncontrol and readout circuits. The predicted results are in very good agreement\nwith available experimental results in the absence of driving fields and with\nthe analytic results of a dissipative two-level system in the presence of weak\ndriving fields. The relaxation and decoherence times versus the parameters and\ntemperature of the control and readout circuits are also explored in details to\nfacilitate the optimization of the 2D SQUID qubit.\n", "machine_text": "\n\nWe investigate the problem of a driven multilevel quantum system interacting with a multi-bath reservoir. We analyze the effects of the driving on the dynamics of the system-reservoir interaction, in particular on the achievable degree of coherence of the driven system. In our analysis we take into account the fact that the dynamics of the system-reservoir interaction is typically very fast, while the driving is done on a longer time-scale. Our main results can be summarized as follows. If the driving is sufficiently fast in comparison to the dynamics of the system-reservoir interaction, then the driven system can achieve a high degree of coherence. If the driving is too slow, however, the coherence will be largely destroyed by the fast dynamics of the system-reservoir interaction. We also find that in order to achieve a high degree of coherence the driving field must be optimized in a way that depends on the details of the system-reservoir interaction. Our results are illustrated with a simple example.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electrostatic Interactions of Asymmetrically Charged Membranes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0893, "human_text": "  We predict the nature (attractive or repulsive) and range (exponentially\nscreened or long-range power law) of the electrostatic interactions of\noppositely charged and planar plates as a function of the salt concentration\nand surface charge densities (whose absolute magnitudes are not necessarily\nequal). An analytical expression for the crossover between attractive and\nrepulsive pressure is obtained as a function of the salt concentration. This\ncondition reduces to the high-salt limit of Parsegian and Gingell where the\ninteraction is exponentially screened and to the zero salt limit of Lau and\nPincus in which the important length scales are the inter-plate separation and\nthe Gouy-Chapman length. In the regime of low salt and high surface charges we\npredict - for any ratio of the charges on the surfaces - that the attractive\npressure is long-ranged as a function of the spacing. The attractive pressure\nis related to the decrease in counter-ion concentration as the inter-plate\ndistance is decreased. Our theory predicts several scaling regimes with\ndifferent scaling expressions for the pressure as function of salinity and\nsurface charge densities. The pressure predictions can be related to surface\nforce experiments of oppositely charged surfaces that are prepared by coating\none of the mica surfaces with an oppositely charged polyelectrolyte.\n", "machine_text": "\n\nWe present a theory of the electrostatic interactions of asymmetrically charged membranes. The theory is based on a simple, first-principles, microscopic model of the membrane, which we solve numerically. We show that the membrane potential is a linear combination of the potentials of the different charged components of the membrane, and that the resulting potential is very well described by a model in which the membrane is represented by a single point charge, located at the center of mass of the membrane. This theory is very general, and can be applied to any system in which the relevant electrostatic interactions are weak, regardless of the detailed structure of the system. As an example application, we consider the role of the electrostatic interactions in the formation of liposomes from lipid molecules. We find that the electrostatic interactions are significant for systems in which the lipids are charged, and that they can either stabilize the resulting liposome, or make it less stable. We also consider the role of the electrostatic interactions in the transport of small charged molecules through a membrane. We find that the dependence of the transport on the molecular charge is in general rather complex, and depends on the detailed structure of the membrane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Trigonometric parallaxes of high velocity halo white dwarf candidates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0355, "human_text": "  The status of 38 halo white dwarf candidates identified by Oppenheimer et al.\n(2001) has been intensively discussed by various authors. In analyses\nundertaken to date, trigonometric parallaxes are crucial missing data. Distance\nmeasurements are mandatory to kinematically segregate halo object from disk\nobjects and hence enable a more reliable estimate of the local density of halo\ndark matter residing in such objects.\n  We present trigonometric parallax measurements for 15 candidate halo white\ndwarfs (WDs) selected from the Oppenheimer et al. (2001) list. We observed the\nstars using the ESO 1.56-m Danish Telescope and ESO 2.2-m telescope from August\n2001 to July 2004. Parallaxes with accuracies of 1--2 mas were determined\nyielding relative errors on distances of $\\sim5$% for 6 objects, $\\sim12$% for\n3 objects, and $\\sim20$% for two more objects. Four stars appear to be too\ndistant (probably farther than 100 pc) to have measurable parallaxes in our\nobservations. Distances, absolute magnitudes and revised space velocities were\nderived for the 15 halo WDs from the Oppenheimer et al. (2001) list. Halo\nmembership is confirmed unambiguously for 6 objects while 5 objects may be\nthick disk members and 4 objects are too distant to draw any conclusion based\nsolely on kinematics. Comparing our trigonometric parallaxes with photometric\nparallaxes used in previous work reveals an overestimation of distance as\nderived from photometric techniques. This new data set can be used to revise\nthe halo white dwarf space density, and that analysis will be presented in a\nsubsequent publication.\n", "machine_text": "\n\nWe present trigonometric parallax measurements for 26 high-velocity halo white dwarf candidates from the first year data set of the ZTF survey. We find that the largest parallax is 6.36 \u00b1 0.13 arcsec for the white dwarf with the highest velocity, indicating an accuracy of  \u223c 1% in the determination of the distance to the high-velocity halo. We find a correlation between the projected velocity and the cosine of the parallax, but it is not a tight correlation and there are several outliers. We find no evidence of large-scale structure in the high-velocity halo. We derive a density distribution for the high-velocity halo, and find it to be consistent with a King- Defineson distribution with a power law index of 1.70 \u00b1 0.01 and a scale length of 2.2 kpc. We find a total of five subclumps in the high-velocity halo, with the largest subclump having a velocity difference of  \u223c 6 kps from the rest of the halo. The subclumps have a higher density than the rest of the halo, but do not exhibit a different density distribution. We also present a search for double white dwarfs using the ZTF data set, and find no evidence of such a system in the high-velocity halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bayesian analysis of the low-resolution polarized 3-year WMAP sky maps. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3643, "human_text": "  We apply a previously developed Gibbs sampling framework to the foreground\ncorrected 3-yr WMAP polarization data and compute the power spectrum and\nresidual foreground template amplitude posterior distributions. We first\nanalyze the co-added Q- and V-band data, and compare our results to the\nlikelihood code published by the WMAP team. We find good agreement, and thus\nverify the numerics and data processing steps of both approaches. However, we\nalso analyze the Q- and V-bands separately, allowing for non-zero EB\ncross-correlations and including two individual foreground template amplitudes\ntracing synchrotron and dust emission. In these analyses, we find tentative\nevidence of systematics: The foreground tracers correlate with each of the Q-\nand V-band sky maps individually, although not with the co-added QV map; there\nis a noticeable negative EB cross-correlation at l <~ 16 in the V-band map; and\nfinally, when relaxing the constraints on EB and BB, noticeable differences are\nobserved between the marginalized band powers in the Q- and V-bands. Further\nstudies of these features are imperative, given the importance of the low-l EE\nspectrum on the optical depth of reionization tau and the spectral index of\nscalar perturbations n_s.\n", "machine_text": "\n\nWe present a Bayesian analysis of the low-resolution polarized 3-year WMAP sky maps. We use a Gaussian process (GP) prior on the power spectrum, with the auto- and cross-power spectrum degrees of freedom as the only parameters. The posteriors on these parameters are computed using a Markov chain Monte Carlo (MCMC) method, based on the Slice Sampler, that allows for efficient sampling from the posterior distribution. We show that the resulting posteriors are close to the ones obtained using the more extensive Markov chain Monte Carlo analysis presented in the WMAP paper. This is confirmed by a formal Kullback-Leibler (KL) divergence calculation. The method also allows for an efficient computation of the likelihood function, which in this case is the ratio of the full-sky power to the power in a set of a priori defined large-scale structures. We use this likelihood function as a proxy for the secondary analysis described in the WMAP paper, which seeks to measure the B-mode in the power spectrum due to large-scale anisotropic structures in the sky. Our results are consistent with the secondary analysis of the WMAP paper, and thus in agreement with the conclusion that the large-scale anisotropic component in the power spectrum is likely to be generated by the cosmic microwave background itself, rather than by the galaxy distribution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer spectral line mapping of supernova remnants: I. Basic data and\n  principal component analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2179, "human_text": "  We report the results of spectroscopic mapping observations carried out\ntoward small (1 x 1 arcmin) regions within the supernova remnants W44, W28,\nIC443, and 3C391 using the Infrared Spectrograph of the Spitzer Space\nTelescope. These observations, covering the 5.2 - 37 micron spectral region,\nhave led to the detection of a total of 15 fine structure transitions of Ne+,\nNe++, Si+, P+, S, S++, Cl+, Fe+, and Fe++; the S(0) - S(7) pure rotational\nlines of molecular hydrogen; and the R(3) and R(4) transitions of hydrogen\ndeuteride. In addition to these 25 spectral lines, the 6.2, 7.7, 8.6, 11.3 and\n12.6 micron PAH emission bands were also observed. Most of the detected line\ntransitions have proven strong enough to map in several sources, providing a\ncomprehensive picture of the relative distribution of the various line\nemissions observable in the Spitzer/IRS bandpass. A principal component\nanalysis of the spectral line maps reveals that the observed emission lines\nfall into five distinct groups, each of which may exhibit a distinct spatial\ndistribution: (1) lines of S and H2 (J > 2); (2) the H2 S(0) line; (3) lines of\nions with appearance potentials less than 13.6 eV; (4) lines of ions with\nappearance potentials greater than 13.6 eV, not including S++; (5) lines of\nS++. Lines of group (1) likely originate in molecular material subject to a\nslow, nondissociative shock that is driven by the overpressure within the\nsupernova remnant, and lines in groups (3) - (5) are associated primarily with\ndissociative shock fronts with a range of (larger) shock velocities. The H2\nS(0) line shows a low-density diffuse emission component, and - in some sources\n- a shock-excited component.\n", "machine_text": "\n\nWe present a catalog of 1251 Spitzer line luminosities of specially selected supernova (SN) remnants in the Local Volume. These data are combined with 42 selected SN remnants in a separate catalog with published Spitzer line luminosities, for a total of 1393 SN remnants. We use principal component analysis (PCA) to explore the linearly dependent structure in the Spitzer line luminosity data. We find a clear correlation of the SN remnant Luminosity (L_Spitzer) with the 3.5 kpc ish radius, R_(3.5), but not with the 6 kpc ish radius, R_(6). The Spitzer line luminosity is not correlated with the age of the remnant, except possibly for the oldest remnants ( >> 5 kyr). The size and the age of a SN remnant are correlated, in that larger remnants are generally older. The Spitzer line luminosity is linearly dependent on the metallicity (Z_Fe) of the SN remnant, but not on the distance to the SN remnant. This is consistent with the known correlation of the Spitzer line luminosity with the age of the remnant, since the metallicity of the remnant is roughly constant with age. We discuss these results in the context of models for SN remnant evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Uniqueness of polynomial canonical representations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2345, "human_text": "  Let P(z) and Q(y) be polynomials of the same degree k>=1 in the complex\nvariables z and y, respectively. In this extended abstract we study the\nnon-linear functional equation P(z)=Q(y(z)), where y(z) is restricted to be\nanalytic in a neighborhood of z=0. We provide sufficient conditions to ensure\nthat all the roots of Q(y) are contained within the range of y(z) as well as to\nhave y(z)=z as the unique analytic solution of the non-linear equation. Our\nresults are motivated from uniqueness considerations of polynomial canonical\nrepresentations of the phase or amplitude terms of oscillatory integrals\nencountered in the asymptotic analysis of the coefficients of mixed powers and\nmultivariable generating functions via saddle-point methods. Uniqueness shall\nprove important for developing algorithms to determine the Taylor coefficients\nof the terms appearing in these representations. The uniqueness of Levinson's\npolynomial canonical representations of analytic functions in several variables\nfollows as a corollary of our one-complex variables results.\n", "machine_text": "\n\nWe show that polynomial canonical representations of non-trivial Lie algebras over fields of characteristic zero are unique in a certain sense. The motivation for this research is the problem of canonical implementations of polynomial representations of Lie algebras. We give an example of a Lie algebra A, with characteristic zero, for which the canonical representation is not induced by a representation of the universal covering group. We show that the problem of canonical implementations of polynomial representations is in general not trivial and that it has to be solved for each Lie algebra separately. We provide a methodology for solving this problem which is based on the description of the polynomial representation in terms of certain generating functions and on the classification of representations of finite groups. This methodology allows us in particular to give a description of the canonical representation of any complex Lie algebra in terms of symmetric and antisymmetric functions. As an application we give a description of the canonical representation of the Lie algebra of a semi-simple Lie group in terms of symmetric and antisymmetric functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Off-center HII regions in power-law density distributions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0711, "human_text": "  The expansion of ionization fronts in uniform and spherically symmetric\npower-law density distributions is a well-studied topic. However, in many\nsituations, such as a star formed at the edge of a molecular cloud core, an\noffset power-law density distribution would be more appropriate. In this paper\na few of the main issues of the formation and expansion of HII regions in such\nmedia are outlined and results are presented for the particular cases where the\nunderlying power laws are 1/r^2 and 1/r^3. A simple criterion is developed for\ndetermining whether the initial photoionized region will be unbounded, which\ndepends on the power-law exponent and the ratio of the equivalent Stroemgren\nradius produced by the star in a uniform medium to the stellar offset distance.\nIn the expansion stage, the ionized volumes will eventually become unbounded\nunless pressure balance with the external medium is reached before the\nionization front velocity becomes supersonic with respect to the ionized gas.\n", "machine_text": "\n\nWe present a study of off-center HII regions in power-law density distributions. The study consists of a comparison of the observed distribution of off-center HII regions in a sample of 19 galaxies with power-law density distributions, obtained from the integral field spectrograph SINFONI on the E-ELT, with the predictions of a simple model in which the formation of HII regions is related to the evolution of the over-density with radius. We find that the model is consistent with the observations and that the distribution of off-center HII regions in these galaxies is well described by a power law with a characteristic radius of 1-2 kpc and a power law index of 1.5-2. This suggests that the formation of off-center HII regions is a universal feature in power-law density distributions and that the simple model we use is valid for galaxies with power-law density distributions of different morphological types. We discuss the physical mechanism that can explain the origin of these off-center HII regions in terms of the competition between the accretion of matter and the conservation of angular momentum. We also show that the model predicts that the number of off-center HII regions is inversely proportional to the square of the central surface density. We discuss the implications of our results for the physical properties of galaxies with power-law density distributions and for the role of the cold gas phase in galaxy evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
